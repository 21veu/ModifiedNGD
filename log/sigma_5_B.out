train data shape torch.Size([256, 2])
train label shape torch.Size([256, 1])
torch.Size([256, 3])
train_data shape torch.Size([3])
seed is  1
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]/home/yuyi/Documents/ModifiedNGD/utils/readData.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
  0%|          | 1/500 [00:00<03:28,  2.39it/s]  1%|          | 3/500 [00:00<01:16,  6.49it/s]  1%|          | 5/500 [00:00<00:53,  9.28it/s]  1%|▏         | 7/500 [00:00<00:43, 11.37it/s]  2%|▏         | 9/500 [00:00<00:38, 12.75it/s]  2%|▏         | 11/500 [00:01<00:35, 13.69it/s]  3%|▎         | 13/500 [00:01<00:33, 14.48it/s]  3%|▎         | 15/500 [00:01<00:32, 14.92it/s]  3%|▎         | 17/500 [00:01<00:31, 15.29it/s]  4%|▍         | 19/500 [00:01<00:31, 15.45it/s]  4%|▍         | 21/500 [00:01<00:30, 15.51it/s]  5%|▍         | 23/500 [00:01<00:30, 15.54it/s]  5%|▌         | 25/500 [00:01<00:30, 15.39it/s]  5%|▌         | 27/500 [00:02<00:30, 15.64it/s]  6%|▌         | 29/500 [00:02<00:29, 15.76it/s]  6%|▌         | 31/500 [00:02<00:29, 15.66it/s]  7%|▋         | 33/500 [00:02<00:29, 15.65it/s]  7%|▋         | 35/500 [00:02<00:29, 15.62it/s]  7%|▋         | 37/500 [00:02<00:29, 15.85it/s]  8%|▊         | 39/500 [00:02<00:29, 15.79it/s]  8%|▊         | 41/500 [00:02<00:28, 15.98it/s]  9%|▊         | 43/500 [00:03<00:29, 15.47it/s]  9%|▉         | 45/500 [00:03<00:29, 15.62it/s]  9%|▉         | 47/500 [00:03<00:29, 15.61it/s] 10%|▉         | 49/500 [00:03<00:28, 15.82it/s] 10%|█         | 51/500 [00:03<00:28, 15.75it/s] 11%|█         | 53/500 [00:03<00:28, 15.45it/s] 11%|█         | 55/500 [00:03<00:28, 15.69it/s] 11%|█▏        | 57/500 [00:03<00:27, 15.92it/s] 12%|█▏        | 59/500 [00:04<00:27, 15.88it/s] 12%|█▏        | 61/500 [00:04<00:27, 15.80it/s] 13%|█▎        | 63/500 [00:04<00:27, 15.93it/s] 13%|█▎        | 65/500 [00:04<00:27, 15.95it/s] 13%|█▎        | 67/500 [00:04<00:28, 15.14it/s] 14%|█▍        | 69/500 [00:04<00:27, 15.53it/s] 14%|█▍        | 71/500 [00:04<00:27, 15.85it/s] 15%|█▍        | 73/500 [00:04<00:26, 16.03it/s] 15%|█▌        | 75/500 [00:05<00:26, 16.21it/s] 15%|█▌        | 77/500 [00:05<00:25, 16.32it/s] 16%|█▌        | 79/500 [00:05<00:25, 16.27it/s] 16%|█▌        | 81/500 [00:05<00:25, 16.37it/s] 17%|█▋        | 83/500 [00:05<00:25, 16.17it/s] 17%|█▋        | 85/500 [00:05<00:27, 15.13it/s] 17%|█▋        | 87/500 [00:05<00:27, 15.17it/s] 18%|█▊        | 89/500 [00:05<00:26, 15.34it/s] 18%|█▊        | 91/500 [00:06<00:27, 15.13it/s] 19%|█▊        | 93/500 [00:06<00:27, 15.06it/s] 19%|█▉        | 95/500 [00:06<00:26, 15.47it/s] 19%|█▉        | 97/500 [00:06<00:25, 15.69it/s] 20%|█▉        | 99/500 [00:06<00:25, 15.86it/s] 20%|██        | 101/500 [00:06<00:25, 15.96it/s] 21%|██        | 103/500 [00:06<00:24, 16.11it/s] 21%|██        | 105/500 [00:06<00:24, 16.25it/s] 21%|██▏       | 107/500 [00:07<00:24, 16.27it/s] 22%|██▏       | 109/500 [00:07<00:24, 16.27it/s] 22%|██▏       | 111/500 [00:07<00:23, 16.33it/s] 23%|██▎       | 113/500 [00:07<00:23, 16.29it/s] 23%|██▎       | 115/500 [00:07<00:23, 16.30it/s] 23%|██▎       | 117/500 [00:07<00:23, 16.29it/s] 24%|██▍       | 119/500 [00:07<00:23, 16.34it/s] 24%|██▍       | 121/500 [00:07<00:23, 16.36it/s] 25%|██▍       | 123/500 [00:08<00:23, 16.33it/s]Epoch:  1  	Training Loss: 0.027221817523241043
Test Loss:  3.6210131645202637
Valid Loss:  3.5539727210998535
Epoch:  2  	Training Loss: 3.5801310539245605
Test Loss:  1638354.0
Valid Loss:  1635422.25
Epoch:  3  	Training Loss: 1637102.5
Test Loss:  4.128355945698719e+31
Valid Loss:  4.152335231115939e+31
Epoch:  4  	Training Loss: 4.146802219424727e+31
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:   25%|██▌       | 125/500 [00:08<00:22, 16.33it/s] 25%|██▌       | 127/500 [00:08<00:22, 16.35it/s] 26%|██▌       | 129/500 [00:08<00:22, 16.45it/s] 26%|██▌       | 131/500 [00:08<00:22, 16.45it/s] 27%|██▋       | 133/500 [00:08<00:22, 16.48it/s] 27%|██▋       | 135/500 [00:08<00:22, 16.51it/s] 27%|██▋       | 137/500 [00:08<00:21, 16.53it/s] 28%|██▊       | 139/500 [00:09<00:21, 16.57it/s] 28%|██▊       | 141/500 [00:09<00:27, 13.04it/s] 29%|██▊       | 143/500 [00:09<00:46,  7.71it/s] 29%|██▉       | 145/500 [00:09<00:41,  8.64it/s] 29%|██▉       | 147/500 [00:10<00:35, 10.01it/s] 30%|██▉       | 149/500 [00:10<00:30, 11.37it/s] 30%|███       | 151/500 [00:10<00:27, 12.51it/s] 31%|███       | 153/500 [00:10<00:25, 13.41it/s] 31%|███       | 155/500 [00:10<00:24, 14.11it/s] 31%|███▏      | 157/500 [00:10<00:23, 14.77it/s] 32%|███▏      | 159/500 [00:10<00:22, 15.25it/s] 32%|███▏      | 161/500 [00:10<00:21, 15.49it/s] 33%|███▎      | 163/500 [00:11<00:21, 15.79it/s] 33%|███▎      | 165/500 [00:11<00:21, 15.89it/s] 33%|███▎      | 167/500 [00:11<00:20, 16.05it/s] 34%|███▍      | 169/500 [00:11<00:20, 16.09it/s] 34%|███▍      | 171/500 [00:11<00:20, 16.12it/s] 35%|███▍      | 173/500 [00:11<00:20, 16.25it/s] 35%|███▌      | 175/500 [00:11<00:20, 16.19it/s] 35%|███▌      | 177/500 [00:11<00:19, 16.33it/s] 36%|███▌      | 179/500 [00:12<00:19, 16.35it/s] 36%|███▌      | 181/500 [00:12<00:19, 16.37it/s] 37%|███▋      | 183/500 [00:12<00:19, 16.39it/s] 37%|███▋      | 185/500 [00:12<00:19, 16.30it/s] 37%|███▋      | 187/500 [00:12<00:19, 16.34it/s] 38%|███▊      | 189/500 [00:12<00:18, 16.38it/s] 38%|███▊      | 191/500 [00:12<00:19, 16.26it/s] 39%|███▊      | 193/500 [00:12<00:19, 16.00it/s] 39%|███▉      | 195/500 [00:13<00:19, 16.01it/s] 39%|███▉      | 197/500 [00:13<00:18, 16.13it/s] 40%|███▉      | 199/500 [00:13<00:18, 15.88it/s] 40%|████      | 201/500 [00:13<00:18, 16.10it/s] 41%|████      | 203/500 [00:13<00:18, 16.13it/s] 41%|████      | 205/500 [00:13<00:18, 16.15it/s] 41%|████▏     | 207/500 [00:13<00:18, 16.24it/s] 42%|████▏     | 209/500 [00:13<00:17, 16.25it/s] 42%|████▏     | 211/500 [00:14<00:18, 15.97it/s] 43%|████▎     | 213/500 [00:14<00:17, 16.16it/s] 43%|████▎     | 215/500 [00:14<00:17, 16.15it/s] 43%|████▎     | 217/500 [00:14<00:17, 16.28it/s] 44%|████▍     | 219/500 [00:14<00:17, 16.26it/s] 44%|████▍     | 221/500 [00:14<00:17, 16.23it/s] 45%|████▍     | 223/500 [00:14<00:17, 16.27it/s] 45%|████▌     | 225/500 [00:14<00:17, 16.11it/s] 45%|████▌     | 227/500 [00:15<00:16, 16.10it/s] 46%|████▌     | 229/500 [00:15<00:16, 16.16it/s] 46%|████▌     | 231/500 [00:15<00:16, 16.19it/s] 47%|████▋     | 233/500 [00:15<00:16, 16.33it/s] 47%|████▋     | 235/500 [00:15<00:16, 16.30it/s] 47%|████▋     | 237/500 [00:15<00:16, 16.39it/s] 48%|████▊     | 239/500 [00:15<00:15, 16.40it/s] 48%|████▊     | 241/500 [00:15<00:15, 16.35it/s] 49%|████▊     | 243/500 [00:15<00:15, 16.45it/s] 49%|████▉     | 245/500 [00:16<00:15, 16.46it/s] 49%|████▉     | 247/500 [00:16<00:15, 16.46it/s]nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
 50%|████▉     | 249/500 [00:16<00:15, 16.38it/s] 50%|█████     | 251/500 [00:16<00:15, 16.48it/s] 51%|█████     | 253/500 [00:16<00:14, 16.49it/s] 51%|█████     | 255/500 [00:16<00:14, 16.50it/s] 51%|█████▏    | 257/500 [00:16<00:14, 16.52it/s] 52%|█████▏    | 259/500 [00:16<00:14, 16.42it/s] 52%|█████▏    | 261/500 [00:17<00:14, 16.53it/s] 53%|█████▎    | 263/500 [00:17<00:14, 16.55it/s] 53%|█████▎    | 265/500 [00:17<00:14, 16.56it/s] 53%|█████▎    | 267/500 [00:17<00:14, 16.52it/s] 54%|█████▍    | 269/500 [00:17<00:14, 16.41it/s] 54%|█████▍    | 271/500 [00:17<00:13, 16.46it/s] 55%|█████▍    | 273/500 [00:17<00:13, 16.48it/s] 55%|█████▌    | 275/500 [00:17<00:13, 16.48it/s] 55%|█████▌    | 277/500 [00:18<00:13, 16.50it/s] 56%|█████▌    | 279/500 [00:18<00:13, 16.37it/s] 56%|█████▌    | 281/500 [00:18<00:13, 16.43it/s] 57%|█████▋    | 283/500 [00:18<00:13, 16.51it/s] 57%|█████▋    | 285/500 [00:18<00:13, 16.36it/s] 57%|█████▋    | 287/500 [00:18<00:13, 16.28it/s] 58%|█████▊    | 289/500 [00:18<00:12, 16.35it/s] 58%|█████▊    | 291/500 [00:19<00:16, 12.54it/s] 59%|█████▊    | 293/500 [00:19<00:15, 13.52it/s] 59%|█████▉    | 295/500 [00:19<00:14, 14.17it/s] 59%|█████▉    | 297/500 [00:19<00:13, 14.84it/s] 60%|█████▉    | 299/500 [00:19<00:13, 15.35it/s] 60%|██████    | 301/500 [00:19<00:12, 15.61it/s] 61%|██████    | 303/500 [00:19<00:12, 15.71it/s] 61%|██████    | 305/500 [00:19<00:12, 15.66it/s] 61%|██████▏   | 307/500 [00:20<00:12, 15.72it/s] 62%|██████▏   | 309/500 [00:20<00:12, 15.89it/s] 62%|██████▏   | 311/500 [00:20<00:12, 15.69it/s] 63%|██████▎   | 313/500 [00:20<00:11, 15.84it/s] 63%|██████▎   | 315/500 [00:20<00:11, 15.55it/s] 63%|██████▎   | 317/500 [00:20<00:11, 15.84it/s] 64%|██████▍   | 319/500 [00:20<00:11, 15.93it/s] 64%|██████▍   | 321/500 [00:20<00:11, 16.06it/s] 65%|██████▍   | 323/500 [00:21<00:10, 16.21it/s] 65%|██████▌   | 325/500 [00:21<00:10, 16.35it/s] 65%|██████▌   | 327/500 [00:21<00:10, 16.41it/s] 66%|██████▌   | 329/500 [00:21<00:10, 16.48it/s] 66%|██████▌   | 331/500 [00:21<00:10, 16.35it/s] 67%|██████▋   | 333/500 [00:21<00:10, 15.92it/s] 67%|██████▋   | 335/500 [00:21<00:10, 16.05it/s] 67%|██████▋   | 337/500 [00:21<00:10, 16.03it/s] 68%|██████▊   | 339/500 [00:22<00:09, 16.20it/s] 68%|██████▊   | 341/500 [00:22<00:09, 16.11it/s] 69%|██████▊   | 343/500 [00:22<00:09, 16.26it/s] 69%|██████▉   | 345/500 [00:22<00:09, 16.35it/s] 69%|██████▉   | 347/500 [00:22<00:09, 16.32it/s] 70%|██████▉   | 349/500 [00:22<00:09, 16.41it/s] 70%|███████   | 351/500 [00:22<00:09, 16.34it/s] 71%|███████   | 353/500 [00:22<00:08, 16.44it/s] 71%|███████   | 355/500 [00:22<00:08, 16.21it/s] 71%|███████▏  | 357/500 [00:23<00:08, 16.26it/s] 72%|███████▏  | 359/500 [00:23<00:08, 16.41it/s] 72%|███████▏  | 361/500 [00:23<00:08, 16.47it/s] 73%|███████▎  | 363/500 [00:23<00:08, 16.49it/s] 73%|███████▎  | 365/500 [00:23<00:08, 16.42it/s] 73%|███████▎  | 367/500 [00:23<00:08, 16.51it/s] 74%|███████▍  | 369/500 [00:23<00:07, 16.57it/s] 74%|███████▍  | 371/500 [00:23<00:07, 16.56it/s]Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
 75%|███████▍  | 373/500 [00:24<00:07, 16.53it/s] 75%|███████▌  | 375/500 [00:24<00:07, 16.46it/s] 75%|███████▌  | 377/500 [00:24<00:07, 16.54it/s] 76%|███████▌  | 379/500 [00:24<00:07, 16.57it/s] 76%|███████▌  | 381/500 [00:24<00:07, 16.62it/s] 77%|███████▋  | 383/500 [00:24<00:07, 16.65it/s] 77%|███████▋  | 385/500 [00:24<00:06, 16.47it/s] 77%|███████▋  | 387/500 [00:24<00:06, 16.56it/s] 78%|███████▊  | 389/500 [00:25<00:06, 16.59it/s] 78%|███████▊  | 391/500 [00:25<00:06, 16.58it/s] 79%|███████▊  | 393/500 [00:25<00:06, 16.34it/s] 79%|███████▉  | 395/500 [00:25<00:06, 16.18it/s] 79%|███████▉  | 397/500 [00:25<00:06, 16.31it/s] 80%|███████▉  | 399/500 [00:25<00:06, 16.42it/s] 80%|████████  | 401/500 [00:25<00:06, 16.46it/s] 81%|████████  | 403/500 [00:25<00:05, 16.51it/s] 81%|████████  | 405/500 [00:26<00:09,  9.85it/s] 81%|████████▏ | 407/500 [00:26<00:11,  7.86it/s] 82%|████████▏ | 409/500 [00:26<00:10,  8.57it/s] 82%|████████▏ | 411/500 [00:26<00:09,  9.80it/s] 83%|████████▎ | 413/500 [00:27<00:07, 11.17it/s] 83%|████████▎ | 415/500 [00:27<00:06, 12.38it/s] 83%|████████▎ | 417/500 [00:27<00:06, 13.44it/s] 84%|████████▍ | 419/500 [00:27<00:05, 14.23it/s] 84%|████████▍ | 421/500 [00:27<00:05, 14.84it/s] 85%|████████▍ | 423/500 [00:27<00:05, 15.19it/s] 85%|████████▌ | 425/500 [00:27<00:04, 15.35it/s] 85%|████████▌ | 427/500 [00:27<00:04, 15.57it/s] 86%|████████▌ | 429/500 [00:28<00:04, 15.77it/s] 86%|████████▌ | 431/500 [00:28<00:04, 15.87it/s] 87%|████████▋ | 433/500 [00:28<00:04, 16.07it/s] 87%|████████▋ | 435/500 [00:28<00:04, 16.09it/s] 87%|████████▋ | 437/500 [00:28<00:03, 16.20it/s] 88%|████████▊ | 439/500 [00:28<00:03, 16.02it/s] 88%|████████▊ | 441/500 [00:28<00:03, 16.13it/s] 89%|████████▊ | 443/500 [00:28<00:03, 16.13it/s] 89%|████████▉ | 445/500 [00:29<00:03, 16.05it/s] 89%|████████▉ | 447/500 [00:29<00:03, 16.18it/s] 90%|████████▉ | 449/500 [00:29<00:03, 16.09it/s] 90%|█████████ | 451/500 [00:29<00:03, 16.03it/s] 91%|█████████ | 453/500 [00:29<00:02, 16.05it/s] 91%|█████████ | 455/500 [00:29<00:02, 16.22it/s] 91%|█████████▏| 457/500 [00:29<00:02, 16.34it/s] 92%|█████████▏| 459/500 [00:29<00:02, 16.45it/s] 92%|█████████▏| 461/500 [00:30<00:02, 16.50it/s] 93%|█████████▎| 463/500 [00:30<00:02, 16.44it/s] 93%|█████████▎| 465/500 [00:30<00:02, 16.52it/s] 93%|█████████▎| 467/500 [00:30<00:01, 16.52it/s] 94%|█████████▍| 469/500 [00:30<00:01, 16.55it/s] 94%|█████████▍| 471/500 [00:30<00:01, 16.20it/s] 95%|█████████▍| 473/500 [00:30<00:01, 16.26it/s] 95%|█████████▌| 475/500 [00:30<00:01, 16.35it/s] 95%|█████████▌| 477/500 [00:31<00:01, 16.42it/s] 96%|█████████▌| 479/500 [00:31<00:01, 16.44it/s] 96%|█████████▌| 481/500 [00:31<00:01, 16.47it/s] 97%|█████████▋| 483/500 [00:31<00:01, 16.41it/s] 97%|█████████▋| 485/500 [00:31<00:00, 16.26it/s] 97%|█████████▋| 487/500 [00:31<00:00, 16.37it/s] 98%|█████████▊| 489/500 [00:31<00:00, 16.34it/s] 98%|█████████▊| 491/500 [00:31<00:00, 16.23it/s] 99%|█████████▊| 493/500 [00:32<00:00, 16.19it/s] 99%|█████████▉| 495/500 [00:32<00:00, 16.33it/s]Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
 99%|█████████▉| 497/500 [00:32<00:00, 16.35it/s]100%|█████████▉| 499/500 [00:32<00:00, 16.21it/s]100%|██████████| 500/500 [00:32<00:00, 15.41it/s]
/home/yuyi/anaconda3/envs/ng/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/autograd/engine.cpp:1151.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  1
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:27,  6.19s/it]  1%|          | 3/500 [00:06<13:41,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:13<10:48,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:37,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:15,  1.19s/it]  7%|▋         | 33/500 [00:26<06:37,  1.18it/s]  7%|▋         | 35/500 [00:26<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:05,  1.19s/it]  9%|▊         | 43/500 [00:33<06:28,  1.17it/s]  9%|▉         | 45/500 [00:33<04:39,  1.63it/s]  9%|▉         | 47/500 [00:33<03:23,  2.22it/s] 10%|▉         | 49/500 [00:34<02:30,  2.99it/s] 10%|█         | 51/500 [00:40<09:00,  1.20s/it] 11%|█         | 53/500 [00:40<06:26,  1.16it/s] 11%|█         | 55/500 [00:40<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:40<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:47<08:42,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:24,  2.98it/s] 14%|█▍        | 71/500 [00:54<08:22,  1.17s/it]Epoch:  1  	Training Loss: 0.027221817523241043
Test Loss:  0.08929210901260376
Valid Loss:  0.09749391674995422
Epoch:  2  	Training Loss: 0.0924326702952385
Test Loss:  0.6527985334396362
Valid Loss:  0.6874809265136719
Epoch:  3  	Training Loss: 0.6760597229003906
Test Loss:  0.028116125613451004
Valid Loss:  0.03620227053761482
Epoch:  4  	Training Loss: 0.03532135486602783
Test Loss:  0.028073975816369057
Valid Loss:  0.0361516997218132
Epoch:  5  	Training Loss: 0.035273026674985886
Test Loss:  0.028038308024406433
Valid Loss:  0.03610870614647865
Epoch:  6  	Training Loss: 0.03523237258195877
Test Loss:  0.02800312265753746
Valid Loss:  0.036066971719264984
Epoch:  7  	Training Loss: 0.03519279882311821
Test Loss:  0.027968037873506546
Valid Loss:  0.03602531552314758
Epoch:  8  	Training Loss: 0.03515331447124481
Test Loss:  0.02793305739760399
Valid Loss:  0.03598374128341675
Epoch:  9  	Training Loss: 0.035113923251628876
Test Loss:  0.027898205444216728
Valid Loss:  0.03594226762652397
Epoch:  10  	Training Loss: 0.03507467359304428
Test Loss:  0.02786361239850521
Valid Loss:  0.035900942981243134
Epoch:  11  	Training Loss: 0.035035718232393265
Test Loss:  0.027829166501760483
Valid Loss:  0.03585977107286453
Epoch:  12  	Training Loss: 0.03499695658683777
Test Loss:  0.02771422453224659
Valid Loss:  0.035756759345531464
Epoch:  13  	Training Loss: 0.03488963097333908
Test Loss:  0.027631832286715508
Valid Loss:  0.03568241372704506
Epoch:  14  	Training Loss: 0.03480697423219681
Test Loss:  0.027571434155106544
Valid Loss:  0.03562692925333977
Epoch:  15  	Training Loss: 0.03474638611078262
Test Loss:  0.027517076581716537
Valid Loss:  0.03557412326335907
Epoch:  16  	Training Loss: 0.03469083458185196
Test Loss:  0.02746393345296383
Valid Loss:  0.03552059084177017
Epoch:  17  	Training Loss: 0.03463621437549591
Test Loss:  0.027411289513111115
Valid Loss:  0.03546705096960068
Epoch:  18  	Training Loss: 0.03458203375339508
Test Loss:  0.02735910750925541
Valid Loss:  0.035413194447755814
Epoch:  19  	Training Loss: 0.034528132528066635
Test Loss:  0.027307242155075073
Valid Loss:  0.03535950928926468
Epoch:  20  	Training Loss: 0.034474484622478485
Test Loss:  0.027255680412054062
Valid Loss:  0.035305965691804886
Epoch:  21  	Training Loss: 0.03442107141017914
Test Loss:  0.027204414829611778
Valid Loss:  0.03525259345769882
Epoch:  22  	Training Loss: 0.03436792269349098
Test Loss:  0.027152176946401596
Valid Loss:  0.035199232399463654
Epoch:  23  	Training Loss: 0.03431399539113045
Test Loss:  0.027100369334220886
Valid Loss:  0.03514551371335983
Epoch:  24  	Training Loss: 0.034260302782058716
Test Loss:  0.027048824355006218
Valid Loss:  0.035091906785964966
Epoch:  25  	Training Loss: 0.0342068113386631
Test Loss:  0.026997558772563934
Valid Loss:  0.03503841161727905
Epoch:  26  	Training Loss: 0.0341535285115242
Test Loss:  0.026946550235152245
Valid Loss:  0.03498503565788269
Epoch:  27  	Training Loss: 0.03410043567419052
Test Loss:  0.02689569629728794
Valid Loss:  0.034932252019643784
Epoch:  28  	Training Loss: 0.03404755890369415
Test Loss:  0.02684520184993744
Valid Loss:  0.03487907350063324
Epoch:  29  	Training Loss: 0.03399486467242241
Test Loss:  0.026794858276844025
Valid Loss:  0.034826502203941345
Epoch:  30  	Training Loss: 0.03394235670566559
Test Loss:  0.026744771748781204
Valid Loss:  0.03477403521537781
Epoch:  31  	Training Loss: 0.033890049904584885
Test Loss:  0.02669493481516838
Valid Loss:  0.03472166508436203
Epoch:  32  	Training Loss: 0.033837929368019104
Test Loss:  0.026646912097930908
Valid Loss:  0.03467034175992012
Epoch:  33  	Training Loss: 0.033787332475185394
Test Loss:  0.026599116623401642
Valid Loss:  0.03461924567818642
Epoch:  34  	Training Loss: 0.033736929297447205
Test Loss:  0.026551509276032448
Valid Loss:  0.03456868231296539
Epoch:  35  	Training Loss: 0.03368675708770752
Test Loss:  0.026504144072532654
Valid Loss:  0.0345182791352272
Epoch:  36  	Training Loss: 0.03363678231835365
Test Loss:  0.0264570489525795
Valid Loss:  0.03446762263774872
Epoch:  37  	Training Loss: 0.033587001264095306
Test Loss:  0.026410134509205818
Valid Loss:  0.03441750258207321
Epoch:  38  	Training Loss: 0.03353741392493248
Test Loss:  0.026363449171185493
Valid Loss:  0.03436752036213875
Epoch:  39  	Training Loss: 0.03348802775144577
Test Loss:  0.026316985487937927
Valid Loss:  0.03431768715381622
Epoch:  40  	Training Loss: 0.033438827842473984
Test Loss:  0.026270736008882523
Valid Loss:  0.034267984330654144
Epoch:  41  	Training Loss: 0.03338981419801712
Test Loss:  0.026224710047245026
Valid Loss:  0.03421842306852341
Epoch:  42  	Training Loss: 0.03334099054336548
Test Loss:  0.026179403066635132
Valid Loss:  0.03416919335722923
Epoch:  43  	Training Loss: 0.0332927331328392
Test Loss:  0.02613426186144352
Valid Loss:  0.03412006050348282
Epoch:  44  	Training Loss: 0.03324461728334427
Test Loss:  0.026089290156960487
Valid Loss:  0.034071020781993866
Epoch:  45  	Training Loss: 0.03319662809371948
Test Loss:  0.02604447491466999
Valid Loss:  0.03402207791805267
Epoch:  46  	Training Loss: 0.03314878046512604
Test Loss:  0.02599981799721718
Valid Loss:  0.03397323936223984
Epoch:  47  	Training Loss: 0.03310106694698334
Test Loss:  0.02595532312989235
Valid Loss:  0.03392448648810387
Epoch:  48  	Training Loss: 0.03305348381400108
Test Loss:  0.025910982862114906
Valid Loss:  0.033875830471515656
Epoch:  49  	Training Loss: 0.033006031066179276
Test Loss:  0.025866787880659103
Valid Loss:  0.0338272750377655
Epoch:  50  	Training Loss: 0.032958708703517914
Test Loss:  0.025822751224040985
Valid Loss:  0.03377881273627281
Epoch:  51  	Training Loss: 0.0329115092754364
Test Loss:  0.02577885612845421
Valid Loss:  0.03373044356703758
Epoch:  52  	Training Loss: 0.03286443650722504
Test Loss:  0.02573503367602825
Valid Loss:  0.033682048320770264
Epoch:  53  	Training Loss: 0.03281738609075546
Test Loss:  0.02569134719669819
Valid Loss:  0.03363373130559921
Epoch:  54  	Training Loss: 0.03277045115828514
Test Loss:  0.02564779482781887
Valid Loss:  0.033585503697395325
Epoch:  55  	Training Loss: 0.032723695039749146
Test Loss:  0.025604411959648132
Valid Loss:  0.03353814780712128
Epoch:  56  	Training Loss: 0.03267703950405121
Test Loss:  0.025561174377799034
Valid Loss:  0.033490873873233795
Epoch:  57  	Training Loss: 0.03263051062822342
Test Loss:  0.025518085807561874
Valid Loss:  0.03344367817044258
Epoch:  58  	Training Loss: 0.03258410841226578
Test Loss:  0.02547510713338852
Valid Loss:  0.03339613974094391
Epoch:  59  	Training Loss: 0.03253781795501709
Test Loss:  0.025432292371988297
Valid Loss:  0.033349089324474335
Epoch:  60  	Training Loss: 0.032491642981767654
Test Loss:  0.025389615446329117
Valid Loss:  0.03330210968852043
Epoch:  61  	Training Loss: 0.03244558721780777
Test Loss:  0.025347072631120682
Valid Loss:  0.0332552008330822
Epoch:  62  	Training Loss: 0.03239963948726654
Test Loss:  0.025305362418293953
Valid Loss:  0.03320905566215515
Epoch:  63  	Training Loss: 0.032354552298784256
Test Loss:  0.025263795629143715
Valid Loss:  0.03316301107406616
Epoch:  64  	Training Loss: 0.032309602946043015
Test Loss:  0.02522237040102482
Valid Loss:  0.03311705216765404
Epoch:  65  	Training Loss: 0.03226477652788162
Test Loss:  0.025181084871292114
Valid Loss:  0.03307119756937027
Epoch:  66  	Training Loss: 0.032220080494880676
Test Loss:  0.025139987468719482
Valid Loss:  0.033025842159986496
Epoch:  67  	Training Loss: 0.03217551112174988
Test Loss:  0.025098975747823715
Valid Loss:  0.03298015519976616
Epoch:  68  	Training Loss: 0.03213106468319893
Test Loss:  0.025058168917894363
Valid Loss:  0.032934993505477905
Epoch:  69  	Training Loss: 0.03208675980567932
Test Loss:  0.025017425417900085
Valid Loss:  0.03288948908448219
Epoch:  70  	Training Loss: 0.03204256296157837
Test Loss:  0.024976886808872223
Valid Loss:  0.03284450247883797
Epoch:  71  	Training Loss: 0.03199850022792816
Test Loss:  0.024936484172940254
Valid Loss:  0.032799601554870605
Epoch:  72  	Training Loss: 0.0319545604288578
Test Loss:  0.024896055459976196
Valid Loss:   15%|█▍        | 73/500 [00:54<05:59,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:01<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:07<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:08<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:08<02:12,  3.02it/s] 20%|██        | 101/500 [01:14<07:47,  1.17s/it] 21%|██        | 103/500 [01:14<05:33,  1.19it/s] 21%|██        | 105/500 [01:15<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:15<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:21<07:41,  1.19s/it] 23%|██▎       | 113/500 [01:21<05:29,  1.17it/s] 23%|██▎       | 115/500 [01:21<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:22<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:22<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:28<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:29<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:35<07:19,  1.19s/it] 27%|██▋       | 133/500 [01:35<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:35<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:35<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:35<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:42<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:42<04:59,  1.19it/s]0.032754093408584595
Epoch:  73  	Training Loss: 0.031910575926303864
Test Loss:  0.024855811148881912
Valid Loss:  0.03270909935235977
Epoch:  74  	Training Loss: 0.03186669200658798
Test Loss:  0.024815678596496582
Valid Loss:  0.032664164900779724
Epoch:  75  	Training Loss: 0.03182290494441986
Test Loss:  0.024775665253400803
Valid Loss:  0.032619308680295944
Epoch:  76  	Training Loss: 0.03177922964096069
Test Loss:  0.02473575621843338
Valid Loss:  0.03257451951503754
Epoch:  77  	Training Loss: 0.03173564746975899
Test Loss:  0.024695985019207
Valid Loss:  0.0325297936797142
Epoch:  78  	Training Loss: 0.03169216960668564
Test Loss:  0.024656333029270172
Valid Loss:  0.03248514235019684
Epoch:  79  	Training Loss: 0.03164878860116005
Test Loss:  0.024616800248622894
Valid Loss:  0.032440558075904846
Epoch:  80  	Training Loss: 0.03160550817847252
Test Loss:  0.02457737736403942
Valid Loss:  0.03239604830741882
Epoch:  81  	Training Loss: 0.03156232833862305
Test Loss:  0.0245380662381649
Valid Loss:  0.03235160559415817
Epoch:  82  	Training Loss: 0.03151923790574074
Test Loss:  0.024499133229255676
Valid Loss:  0.032307494431734085
Epoch:  83  	Training Loss: 0.031476523727178574
Test Loss:  0.024460311979055405
Valid Loss:  0.03226345032453537
Epoch:  84  	Training Loss: 0.03143391013145447
Test Loss:  0.02442159503698349
Valid Loss:  0.032219476997852325
Epoch:  85  	Training Loss: 0.03139139711856842
Test Loss:  0.02438298799097538
Valid Loss:  0.032175589352846146
Epoch:  86  	Training Loss: 0.031348973512649536
Test Loss:  0.02434448152780533
Valid Loss:  0.03213176131248474
Epoch:  87  	Training Loss: 0.031306639313697815
Test Loss:  0.02430608682334423
Valid Loss:  0.03208800405263901
Epoch:  88  	Training Loss: 0.03126440569758415
Test Loss:  0.02426779642701149
Valid Loss:  0.03204432129859924
Epoch:  89  	Training Loss: 0.031222263351082802
Test Loss:  0.024229608476161957
Valid Loss:  0.032000720500946045
Epoch:  90  	Training Loss: 0.031180214136838913
Test Loss:  0.02419152483344078
Valid Loss:  0.03195717930793762
Epoch:  91  	Training Loss: 0.031138256192207336
Test Loss:  0.024153541773557663
Valid Loss:  0.03191371262073517
Epoch:  92  	Training Loss: 0.031096383929252625
Test Loss:  0.02411569282412529
Valid Loss:  0.031870413571596146
Epoch:  93  	Training Loss: 0.031054671853780746
Test Loss:  0.024077944457530975
Valid Loss:  0.031827181577682495
Epoch:  94  	Training Loss: 0.031013041734695435
Test Loss:  0.02404029481112957
Valid Loss:  0.03178401663899422
Epoch:  95  	Training Loss: 0.030971502885222435
Test Loss:  0.024002734571695328
Valid Loss:  0.03174092248082161
Epoch:  96  	Training Loss: 0.030930045992136
Test Loss:  0.023965276777744293
Valid Loss:  0.031697891652584076
Epoch:  97  	Training Loss: 0.03088867850601673
Test Loss:  0.023927908390760422
Valid Loss:  0.03165493160486221
Epoch:  98  	Training Loss: 0.030847392976284027
Test Loss:  0.02389063872396946
Valid Loss:  0.03161204978823662
Epoch:  99  	Training Loss: 0.030806198716163635
Test Loss:  0.02385346218943596
Valid Loss:  0.031569257378578186
Epoch:  100  	Training Loss: 0.03076508268713951
Test Loss:  0.02381637692451477
Valid Loss:  0.03152662515640259
Epoch:  101  	Training Loss: 0.030724048614501953
Test Loss:  0.023779384791851044
Valid Loss:  0.031484056264162064
Epoch:  102  	Training Loss: 0.030683103948831558
Test Loss:  0.0237424373626709
Valid Loss:  0.031441591680049896
Epoch:  103  	Training Loss: 0.030642220750451088
Test Loss:  0.023705583065748215
Valid Loss:  0.0313991941511631
Epoch:  104  	Training Loss: 0.030601419508457184
Test Loss:  0.023668821901082993
Valid Loss:  0.03135686367750168
Epoch:  105  	Training Loss: 0.030560705810785294
Test Loss:  0.023632148280739784
Valid Loss:  0.03131461143493652
Epoch:  106  	Training Loss: 0.03052007034420967
Test Loss:  0.02359556406736374
Valid Loss:  0.031272441148757935
Epoch:  107  	Training Loss: 0.030479520559310913
Test Loss:  0.023559074848890305
Valid Loss:  0.03123031184077263
Epoch:  108  	Training Loss: 0.030439041554927826
Test Loss:  0.023522790521383286
Valid Loss:  0.03118826635181904
Epoch:  109  	Training Loss: 0.030398646369576454
Test Loss:  0.023486599326133728
Valid Loss:  0.031146295368671417
Epoch:  110  	Training Loss: 0.030358335003256798
Test Loss:  0.023450497537851334
Valid Loss:  0.03110438957810402
Epoch:  111  	Training Loss: 0.03031810186803341
Test Loss:  0.023414485156536102
Valid Loss:  0.031062548980116844
Epoch:  112  	Training Loss: 0.030277937650680542
Test Loss:  0.023378442972898483
Valid Loss:  0.031020719558000565
Epoch:  113  	Training Loss: 0.03023775853216648
Test Loss:  0.02334248647093773
Valid Loss:  0.030978959053754807
Epoch:  114  	Training Loss: 0.030197663232684135
Test Loss:  0.02330661565065384
Valid Loss:  0.0309373177587986
Epoch:  115  	Training Loss: 0.030157653614878654
Test Loss:  0.023270845413208008
Valid Loss:  0.030895834788680077
Epoch:  116  	Training Loss: 0.030117718502879143
Test Loss:  0.02323516272008419
Valid Loss:  0.030854424461722374
Epoch:  117  	Training Loss: 0.030077863484621048
Test Loss:  0.023199565708637238
Valid Loss:  0.03081308677792549
Epoch:  118  	Training Loss: 0.03003808483481407
Test Loss:  0.023164052516222
Valid Loss:  0.03077181614935398
Epoch:  119  	Training Loss: 0.02999839559197426
Test Loss:  0.023128638043999672
Valid Loss:  0.030730634927749634
Epoch:  120  	Training Loss: 0.029958777129650116
Test Loss:  0.02309330366551876
Valid Loss:  0.030689524486660957
Epoch:  121  	Training Loss: 0.029919244349002838
Test Loss:  0.023058056831359863
Valid Loss:  0.03064848482608795
Epoch:  122  	Training Loss: 0.029879793524742126
Test Loss:  0.023022770881652832
Valid Loss:  0.03060743771493435
Epoch:  123  	Training Loss: 0.029840320348739624
Test Loss:  0.022987492382526398
Valid Loss:  0.03056667186319828
Epoch:  124  	Training Loss: 0.029800958931446075
Test Loss:  0.022952314466238022
Valid Loss:  0.03052598424255848
Epoch:  125  	Training Loss: 0.02976168319582939
Test Loss:  0.02291722223162651
Valid Loss:  0.0304853655397892
Epoch:  126  	Training Loss: 0.029722491279244423
Test Loss:  0.02288213185966015
Valid Loss:  0.03044501319527626
Epoch:  127  	Training Loss: 0.029683370143175125
Test Loss:  0.02284722775220871
Valid Loss:  0.030404524877667427
Epoch:  128  	Training Loss: 0.029644332826137543
Test Loss:  0.02281232550740242
Valid Loss:  0.03036431409418583
Epoch:  129  	Training Loss: 0.029605384916067123
Test Loss:  0.022777598351240158
Valid Loss:  0.03032396174967289
Epoch:  130  	Training Loss: 0.029566511511802673
Test Loss:  0.02274288237094879
Valid Loss:  0.030283892527222633
Epoch:  131  	Training Loss: 0.029527710750699043
Test Loss:  0.022708334028720856
Valid Loss:  0.030243678018450737
Epoch:  132  	Training Loss: 0.029489003121852875
Test Loss:  0.02267398312687874
Valid Loss:  0.030203938484191895
Epoch:  133  	Training Loss: 0.029450558125972748
Test Loss:  0.022639721632003784
Valid Loss:  0.03016424924135208
Epoch:  134  	Training Loss: 0.029412193223834038
Test Loss:  0.02260556071996689
Valid Loss:  0.030124647542834282
Epoch:  135  	Training Loss: 0.02937391772866249
Test Loss:  0.022571485489606857
Valid Loss:  0.030085116624832153
Epoch:  136  	Training Loss: 0.02933572605252266
Test Loss:  0.02253754995763302
Valid Loss:  0.03004543110728264
Epoch:  137  	Training Loss: 0.0292976014316082
Test Loss:  0.022503647953271866
Valid Loss:  0.030006039887666702
Epoch:  138  	Training Loss: 0.029259562492370605
Test Loss:  0.02246982604265213
Valid Loss:  0.02996671199798584
Epoch:  139  	Training Loss: 0.02922160178422928
Test Loss:  0.022436106577515602
Valid Loss:  0.029927458614110947
Epoch:  140  	Training Loss: 0.029183726757764816
Test Loss:  0.022402454167604446
Valid Loss:  0.029888266697525978
Epoch:  141  	Training Loss: 0.029145922511816025
Test Loss:  0.02236890234053135
Valid Loss:  0.029849151149392128
Epoch:  142  	Training Loss: 0.0291082002222538
Test Loss:  0.022335533052682877
Valid Loss:  0.029810216277837753
Epoch:  143  	Training Loss: 0.029070669785141945
Test Loss:  0.02230224758386612
Valid Loss:  0.029771355912089348
 29%|██▉       | 145/500 [01:42<03:34,  1.65it/s] 29%|██▉       | 147/500 [01:42<02:36,  2.26it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.02it/s] 30%|███       | 151/500 [01:48<06:47,  1.17s/it] 31%|███       | 153/500 [01:49<04:50,  1.19it/s] 31%|███       | 155/500 [01:49<03:28,  1.65it/s] 31%|███▏      | 157/500 [01:49<02:32,  2.26it/s] 32%|███▏      | 159/500 [01:49<01:52,  3.03it/s] 32%|███▏      | 161/500 [01:55<06:35,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:23,  1.64it/s] 33%|███▎      | 167/500 [01:56<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:56<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:02<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:02<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:02<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:03<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.97it/s] 36%|███▌      | 181/500 [02:09<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:09<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:09<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:10<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:16<06:12,  1.21s/it] 39%|███▊      | 193/500 [02:16<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:16<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:16<02:18,  2.19it/s] 40%|███▉      | 199/500 [02:17<01:41,  2.95it/s] 40%|████      | 201/500 [02:23<05:51,  1.17s/it] 41%|████      | 203/500 [02:23<04:10,  1.19it/s] 41%|████      | 205/500 [02:23<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:23<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:23<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:30<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:30<04:01,  1.19it/s]Epoch:  144  	Training Loss: 0.029033221304416656
Test Loss:  0.022269053384661674
Valid Loss:  0.02973257191479206
Epoch:  145  	Training Loss: 0.028995852917432785
Test Loss:  0.022235937416553497
Valid Loss:  0.0296938419342041
Epoch:  146  	Training Loss: 0.028958555310964584
Test Loss:  0.02220289409160614
Valid Loss:  0.02965518645942211
Epoch:  147  	Training Loss: 0.028921332210302353
Test Loss:  0.022169947624206543
Valid Loss:  0.029616601765155792
Epoch:  148  	Training Loss: 0.028884192928671837
Test Loss:  0.022137079387903214
Valid Loss:  0.029578089714050293
Epoch:  149  	Training Loss: 0.02884712629020214
Test Loss:  0.022104283794760704
Valid Loss:  0.02953963540494442
Epoch:  150  	Training Loss: 0.028810136020183563
Test Loss:  0.02207157574594021
Valid Loss:  0.029501264914870262
Epoch:  151  	Training Loss: 0.028773216530680656
Test Loss:  0.022038940340280533
Valid Loss:  0.029462946578860283
Epoch:  152  	Training Loss: 0.028736377134919167
Test Loss:  0.02200625091791153
Valid Loss:  0.02942451648414135
Epoch:  153  	Training Loss: 0.02869943529367447
Test Loss:  0.0219736211001873
Valid Loss:  0.029386144131422043
Epoch:  154  	Training Loss: 0.028662558645009995
Test Loss:  0.02194106951355934
Valid Loss:  0.02934783138334751
Epoch:  155  	Training Loss: 0.02862575650215149
Test Loss:  0.021908601745963097
Valid Loss:  0.029309600591659546
Epoch:  156  	Training Loss: 0.028589025139808655
Test Loss:  0.02187621220946312
Valid Loss:  0.029271429404616356
Epoch:  157  	Training Loss: 0.02855236455798149
Test Loss:  0.021843887865543365
Valid Loss:  0.029233314096927643
Epoch:  158  	Training Loss: 0.0285157710313797
Test Loss:  0.02181163616478443
Valid Loss:  0.02919527143239975
Epoch:  159  	Training Loss: 0.02847925014793873
Test Loss:  0.021779460832476616
Valid Loss:  0.02915729396045208
Epoch:  160  	Training Loss: 0.02844279631972313
Test Loss:  0.02174736186861992
Valid Loss:  0.029119372367858887
Epoch:  161  	Training Loss: 0.028406407684087753
Test Loss:  0.021715320646762848
Valid Loss:  0.029081515967845917
Epoch:  162  	Training Loss: 0.028370089828968048
Test Loss:  0.02168312668800354
Valid Loss:  0.02904343418776989
Epoch:  163  	Training Loss: 0.02833355963230133
Test Loss:  0.021650994196534157
Valid Loss:  0.029005400836467743
Epoch:  164  	Training Loss: 0.02829708531498909
Test Loss:  0.021618925034999847
Valid Loss:  0.028967421501874924
Epoch:  165  	Training Loss: 0.02826068364083767
Test Loss:  0.02158689685165882
Valid Loss:  0.02892971783876419
Epoch:  166  	Training Loss: 0.02822434902191162
Test Loss:  0.021554961800575256
Valid Loss:  0.028891868889331818
Epoch:  167  	Training Loss: 0.028188075870275497
Test Loss:  0.021523071452975273
Valid Loss:  0.028854278847575188
Epoch:  168  	Training Loss: 0.0281518641859293
Test Loss:  0.021491244435310364
Valid Loss:  0.028816748410463333
Epoch:  169  	Training Loss: 0.028115713968873024
Test Loss:  0.021459519863128662
Valid Loss:  0.028779052197933197
Epoch:  170  	Training Loss: 0.02807963266968727
Test Loss:  0.021427828818559647
Valid Loss:  0.028741635382175446
Epoch:  171  	Training Loss: 0.028043609112501144
Test Loss:  0.021396208554506302
Valid Loss:  0.028704263269901276
Epoch:  172  	Training Loss: 0.028007645159959793
Test Loss:  0.02136513590812683
Valid Loss:  0.028667569160461426
Epoch:  173  	Training Loss: 0.027972329407930374
Test Loss:  0.021334141492843628
Valid Loss:  0.028630949556827545
Epoch:  174  	Training Loss: 0.027937084436416626
Test Loss:  0.021303243935108185
Valid Loss:  0.028594180941581726
Epoch:  175  	Training Loss: 0.027901913970708847
Test Loss:  0.021272383630275726
Valid Loss:  0.028557687997817993
Epoch:  176  	Training Loss: 0.027866797521710396
Test Loss:  0.021241609007120132
Valid Loss:  0.028521256521344185
Epoch:  177  	Training Loss: 0.02783176302909851
Test Loss:  0.02121090516448021
Valid Loss:  0.02848488837480545
Epoch:  178  	Training Loss: 0.02779679372906685
Test Loss:  0.02118026092648506
Valid Loss:  0.02844858355820179
Epoch:  179  	Training Loss: 0.027761895209550858
Test Loss:  0.02114970237016678
Valid Loss:  0.0284123532474041
Epoch:  180  	Training Loss: 0.027727069333195686
Test Loss:  0.02111920528113842
Valid Loss:  0.028376175090670586
Epoch:  181  	Training Loss: 0.02769230306148529
Test Loss:  0.02108878269791603
Valid Loss:  0.028340058401226997
Epoch:  182  	Training Loss: 0.027657611295580864
Test Loss:  0.021058619022369385
Valid Loss:  0.02830425649881363
Epoch:  183  	Training Loss: 0.027623221278190613
Test Loss:  0.021028533577919006
Valid Loss:  0.02826852910220623
Epoch:  184  	Training Loss: 0.02758890390396118
Test Loss:  0.020998511463403702
Valid Loss:  0.028232865035533905
Epoch:  185  	Training Loss: 0.027554649859666824
Test Loss:  0.020968563854694366
Valid Loss:  0.02819725126028061
Epoch:  186  	Training Loss: 0.027520472183823586
Test Loss:  0.0209386944770813
Valid Loss:  0.02816172130405903
Epoch:  187  	Training Loss: 0.02748635783791542
Test Loss:  0.020908880978822708
Valid Loss:  0.028126249089837074
Epoch:  188  	Training Loss: 0.027452314272522926
Test Loss:  0.02087913453578949
Valid Loss:  0.028090830892324448
Epoch:  189  	Training Loss: 0.027418334037065506
Test Loss:  0.02084946818649769
Valid Loss:  0.028055476024746895
Epoch:  190  	Training Loss: 0.02738441899418831
Test Loss:  0.020819861441850662
Valid Loss:  0.028020203113555908
Epoch:  191  	Training Loss: 0.02735057845711708
Test Loss:  0.02079032175242901
Valid Loss:  0.027984976768493652
Epoch:  192  	Training Loss: 0.027316799387335777
Test Loss:  0.020760711282491684
Valid Loss:  0.027949640527367592
Epoch:  193  	Training Loss: 0.027282919734716415
Test Loss:  0.02073116973042488
Valid Loss:  0.02791435457766056
Epoch:  194  	Training Loss: 0.027249092236161232
Test Loss:  0.020701684057712555
Valid Loss:  0.027879124507308006
Epoch:  195  	Training Loss: 0.02721533365547657
Test Loss:  0.020672263577580452
Valid Loss:  0.027843955904245377
Epoch:  196  	Training Loss: 0.027181634679436684
Test Loss:  0.02064291015267372
Valid Loss:  0.02780885621905327
Epoch:  197  	Training Loss: 0.027148006483912468
Test Loss:  0.020613621920347214
Valid Loss:  0.027773816138505936
Epoch:  198  	Training Loss: 0.02711443603038788
Test Loss:  0.02058439515531063
Valid Loss:  0.02773883566260338
Epoch:  199  	Training Loss: 0.027080930769443512
Test Loss:  0.02055523172020912
Valid Loss:  0.027703911066055298
Epoch:  200  	Training Loss: 0.02704748325049877
Test Loss:  0.020526131615042686
Valid Loss:  0.027669064700603485
Epoch:  201  	Training Loss: 0.027014106512069702
Test Loss:  0.020497091114521027
Valid Loss:  0.027634259313344955
Epoch:  202  	Training Loss: 0.026980793103575706
Test Loss:  0.02046773210167885
Valid Loss:  0.027599025517702103
Epoch:  203  	Training Loss: 0.02694707363843918
Test Loss:  0.02043842524290085
Valid Loss:  0.02756384015083313
Epoch:  204  	Training Loss: 0.026913408190011978
Test Loss:  0.020409177988767624
Valid Loss:  0.027528710663318634
Epoch:  205  	Training Loss: 0.026879798620939255
Test Loss:  0.020379992201924324
Valid Loss:  0.027493637055158615
Epoch:  206  	Training Loss: 0.02684624306857586
Test Loss:  0.020350854843854904
Valid Loss:  0.027458621188998222
Epoch:  207  	Training Loss: 0.026812739670276642
Test Loss:  0.020321764051914215
Valid Loss:  0.02742365002632141
Epoch:  208  	Training Loss: 0.026779288426041603
Test Loss:  0.0202927403151989
Valid Loss:  0.02738873101770878
Epoch:  209  	Training Loss: 0.02674589306116104
Test Loss:  0.020263757556676865
Valid Loss:  0.027353856712579727
Epoch:  210  	Training Loss: 0.02671254239976406
Test Loss:  0.020234834402799606
Valid Loss:  0.027319038286805153
Epoch:  211  	Training Loss: 0.026679255068302155
Test Loss:  0.020205974578857422
Valid Loss:  0.027284279465675354
Epoch:  212  	Training Loss: 0.026646016165614128
Test Loss:  0.020176848396658897
Valid Loss:  0.0272491704672575
Epoch:  213  	Training Loss: 0.02661246433854103
Test Loss:  0.020147792994976044
Valid Loss:  0.027214132249355316
Epoch:  214  	Training Loss: 0.02657897211611271
Test Loss:  0.020118791610002518
 43%|████▎     | 215/500 [02:30<02:53,  1.65it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:36<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:37<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:37<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:37<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:43<05:11,  1.16s/it] 47%|████▋     | 233/500 [02:43<03:42,  1.20it/s] 47%|████▋     | 235/500 [02:43<02:39,  1.66it/s] 47%|████▋     | 237/500 [02:44<01:55,  2.27it/s] 48%|████▊     | 239/500 [02:44<01:25,  3.04it/s] 48%|████▊     | 241/500 [02:50<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:50<03:33,  1.20it/s] 49%|████▉     | 245/500 [02:50<02:33,  1.66it/s] 49%|████▉     | 247/500 [02:50<01:51,  2.27it/s] 50%|████▉     | 249/500 [02:50<01:22,  3.06it/s] 50%|█████     | 251/500 [02:57<04:53,  1.18s/it] 51%|█████     | 253/500 [02:57<03:29,  1.18it/s] 51%|█████     | 255/500 [02:57<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:57<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:57<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:04<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:04<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:04<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:04<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:04<01:18,  2.94it/s] 54%|█████▍    | 271/500 [03:11<04:33,  1.20s/it] 55%|█████▍    | 273/500 [03:11<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:11<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:11<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:11<01:14,  2.97it/s] 56%|█████▌    | 281/500 [03:17<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:01,  1.19it/s]Valid Loss:  0.027179136872291565
Epoch:  215  	Training Loss: 0.026545535773038864
Test Loss:  0.02008983865380287
Valid Loss:  0.027144193649291992
Epoch:  216  	Training Loss: 0.0265121441334486
Test Loss:  0.020060932263731956
Valid Loss:  0.02710929699242115
Epoch:  217  	Training Loss: 0.026478808373212814
Test Loss:  0.020032089203596115
Valid Loss:  0.02707446739077568
Epoch:  218  	Training Loss: 0.026445530354976654
Test Loss:  0.020003294572234154
Valid Loss:  0.027039676904678345
Epoch:  219  	Training Loss: 0.026412293314933777
Test Loss:  0.019974563270807266
Valid Loss:  0.027004949748516083
Epoch:  220  	Training Loss: 0.026379119604825974
Test Loss:  0.019945871084928513
Valid Loss:  0.0269702710211277
Epoch:  221  	Training Loss: 0.0263459924608469
Test Loss:  0.019917240366339684
Valid Loss:  0.026935655623674393
Epoch:  222  	Training Loss: 0.026312919333577156
Test Loss:  0.019889134913682938
Valid Loss:  0.026901720091700554
Epoch:  223  	Training Loss: 0.0262804813683033
Test Loss:  0.019861096516251564
Valid Loss:  0.026868034154176712
Epoch:  224  	Training Loss: 0.026248101145029068
Test Loss:  0.019833087921142578
Valid Loss:  0.026834208518266678
Epoch:  225  	Training Loss: 0.026215773075819016
Test Loss:  0.019805163145065308
Valid Loss:  0.026800639927387238
Epoch:  226  	Training Loss: 0.02618349716067314
Test Loss:  0.019777270033955574
Valid Loss:  0.02676691673696041
Epoch:  227  	Training Loss: 0.026151282712817192
Test Loss:  0.01974944770336151
Valid Loss:  0.02673324942588806
Epoch:  228  	Training Loss: 0.02611912414431572
Test Loss:  0.019721684977412224
Valid Loss:  0.026699842885136604
Epoch:  229  	Training Loss: 0.026087015867233276
Test Loss:  0.01969396322965622
Valid Loss:  0.026666274294257164
Epoch:  230  	Training Loss: 0.02605496719479561
Test Loss:  0.019666306674480438
Valid Loss:  0.026632975786924362
Epoch:  231  	Training Loss: 0.02602297067642212
Test Loss:  0.01963869109749794
Valid Loss:  0.026599518954753876
Epoch:  232  	Training Loss: 0.025991028174757957
Test Loss:  0.019611161202192307
Valid Loss:  0.02656633034348488
Epoch:  233  	Training Loss: 0.025959152728319168
Test Loss:  0.019583672285079956
Valid Loss:  0.026532988995313644
Epoch:  234  	Training Loss: 0.025927333161234856
Test Loss:  0.019556254148483276
Valid Loss:  0.026499897241592407
Epoch:  235  	Training Loss: 0.025895558297634125
Test Loss:  0.019528858363628387
Valid Loss:  0.02646665647625923
Epoch:  236  	Training Loss: 0.025863848626613617
Test Loss:  0.019501540809869766
Valid Loss:  0.0264336708933115
Epoch:  237  	Training Loss: 0.025832191109657288
Test Loss:  0.019474290311336517
Valid Loss:  0.02640075609087944
Epoch:  238  	Training Loss: 0.025800589472055435
Test Loss:  0.019447073340415955
Valid Loss:  0.026367682963609695
Epoch:  239  	Training Loss: 0.02576903998851776
Test Loss:  0.019419925287365913
Valid Loss:  0.026334863156080246
Epoch:  240  	Training Loss: 0.02573755569756031
Test Loss:  0.01939280703663826
Valid Loss:  0.026301909238100052
Epoch:  241  	Training Loss: 0.025706123560667038
Test Loss:  0.019365772604942322
Valid Loss:  0.026269201189279556
Epoch:  242  	Training Loss: 0.025674734264612198
Test Loss:  0.019339244812726974
Valid Loss:  0.02623714506626129
Epoch:  243  	Training Loss: 0.0256439670920372
Test Loss:  0.019312754273414612
Valid Loss:  0.026204964146018028
Epoch:  244  	Training Loss: 0.025613252073526382
Test Loss:  0.019286340102553368
Valid Loss:  0.026173006743192673
Epoch:  245  	Training Loss: 0.02558259293437004
Test Loss:  0.019259948283433914
Valid Loss:  0.026140913367271423
Epoch:  246  	Training Loss: 0.02555198408663273
Test Loss:  0.01923363283276558
Valid Loss:  0.026109077036380768
Epoch:  247  	Training Loss: 0.025521425530314445
Test Loss:  0.01920737326145172
Valid Loss:  0.026077276095747948
Epoch:  248  	Training Loss: 0.02549092471599579
Test Loss:  0.019181150943040848
Valid Loss:  0.026045355945825577
Epoch:  249  	Training Loss: 0.025460470467805862
Test Loss:  0.01915498450398445
Valid Loss:  0.026013661175966263
Epoch:  250  	Training Loss: 0.025430073961615562
Test Loss:  0.019128888845443726
Valid Loss:  0.02598203346133232
Epoch:  251  	Training Loss: 0.02539972960948944
Test Loss:  0.019102804362773895
Valid Loss:  0.02595025673508644
Epoch:  252  	Training Loss: 0.025369437411427498
Test Loss:  0.019076256081461906
Valid Loss:  0.025918003171682358
Epoch:  253  	Training Loss: 0.02533852867782116
Test Loss:  0.019049743190407753
Valid Loss:  0.025885792449116707
Epoch:  254  	Training Loss: 0.02530767396092415
Test Loss:  0.019023267552256584
Valid Loss:  0.025853469967842102
Epoch:  255  	Training Loss: 0.02527688257396221
Test Loss:  0.018996870145201683
Valid Loss:  0.025821376591920853
Epoch:  256  	Training Loss: 0.02524613030254841
Test Loss:  0.018970511853694916
Valid Loss:  0.025789335370063782
Epoch:  257  	Training Loss: 0.025215428322553635
Test Loss:  0.01894420199096203
Valid Loss:  0.025757156312465668
Epoch:  258  	Training Loss: 0.025184793397784233
Test Loss:  0.018917948007583618
Valid Loss:  0.025725215673446655
Epoch:  259  	Training Loss: 0.025154195725917816
Test Loss:  0.01889173872768879
Valid Loss:  0.025693338364362717
Epoch:  260  	Training Loss: 0.025123652070760727
Test Loss:  0.018865587189793587
Valid Loss:  0.025661498308181763
Epoch:  261  	Training Loss: 0.025093160569667816
Test Loss:  0.018839461728930473
Valid Loss:  0.02562953159213066
Epoch:  262  	Training Loss: 0.025062721222639084
Test Loss:  0.018813686445355415
Valid Loss:  0.02559814788401127
Epoch:  263  	Training Loss: 0.0250326469540596
Test Loss:  0.018787946552038193
Valid Loss:  0.025566818192601204
Epoch:  264  	Training Loss: 0.02500263601541519
Test Loss:  0.018762243911623955
Valid Loss:  0.025535352528095245
Epoch:  265  	Training Loss: 0.024972673505544662
Test Loss:  0.018736612051725388
Valid Loss:  0.025504132732748985
Epoch:  266  	Training Loss: 0.024942763149738312
Test Loss:  0.01871103048324585
Valid Loss:  0.025472961366176605
Epoch:  267  	Training Loss: 0.024912899360060692
Test Loss:  0.018685482442378998
Valid Loss:  0.025441650301218033
Epoch:  268  	Training Loss: 0.024883095175027847
Test Loss:  0.01865999773144722
Valid Loss:  0.025410594418644905
Epoch:  269  	Training Loss: 0.024853339418768883
Test Loss:  0.01863456703722477
Valid Loss:  0.02537958137691021
Epoch:  270  	Training Loss: 0.02482363022863865
Test Loss:  0.018609188497066498
Valid Loss:  0.025348613038659096
Epoch:  271  	Training Loss: 0.024793976917862892
Test Loss:  0.018583834171295166
Valid Loss:  0.025317532941699028
Epoch:  272  	Training Loss: 0.02476438879966736
Test Loss:  0.01855846308171749
Valid Loss:  0.025286544114351273
Epoch:  273  	Training Loss: 0.02473471499979496
Test Loss:  0.018533136695623398
Valid Loss:  0.025255607441067696
Epoch:  274  	Training Loss: 0.024705100804567337
Test Loss:  0.018507838249206543
Valid Loss:  0.02522454783320427
Epoch:  275  	Training Loss: 0.024675536900758743
Test Loss:  0.01848260499536991
Valid Loss:  0.025193721055984497
Epoch:  276  	Training Loss: 0.02464601770043373
Test Loss:  0.018457423895597458
Valid Loss:  0.0251629576086998
Epoch:  277  	Training Loss: 0.024616554379463196
Test Loss:  0.018432270735502243
Valid Loss:  0.025132056325674057
Epoch:  278  	Training Loss: 0.024587145075201988
Test Loss:  0.0184071883559227
Valid Loss:  0.025101378560066223
Epoch:  279  	Training Loss: 0.024557778611779213
Test Loss:  0.018382154405117035
Valid Loss:  0.025070752948522568
Epoch:  280  	Training Loss: 0.02452845685184002
Test Loss:  0.018357163295149803
Valid Loss:  0.025040190666913986
Epoch:  281  	Training Loss: 0.02449919655919075
Test Loss:  0.018332205712795258
Valid Loss:  0.025009486824274063
Epoch:  282  	Training Loss: 0.02446999028325081
Test Loss:  0.018307602033019066
Valid Loss:  0.024979405105113983
Epoch:  283  	Training Loss: 0.02444116584956646
Test Loss:  0.018283050507307053
Valid Loss:  0.024949362501502037
Epoch:  284  	Training Loss: 0.024412404745817184
Test Loss:  0.01825851760804653
Valid Loss:  0.024919183924794197
 57%|█████▋    | 285/500 [03:18<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:18<01:34,  2.26it/s] 58%|█████▊    | 289/500 [03:18<01:09,  3.04it/s] 58%|█████▊    | 291/500 [03:24<04:02,  1.16s/it] 59%|█████▊    | 293/500 [03:24<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:24<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:25<01:07,  3.00it/s] 60%|██████    | 301/500 [03:31<03:55,  1.18s/it] 61%|██████    | 303/500 [03:31<02:47,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:31<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:38<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:38<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:38<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:38<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:38<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:45<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:45<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:45<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:45<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:45<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:52<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:52<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:52<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:52<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:52<00:53,  3.00it/s] 68%|██████▊   | 341/500 [03:58<03:09,  1.19s/it] 69%|██████▊   | 343/500 [03:59<02:14,  1.17it/s] 69%|██████▉   | 345/500 [03:59<01:35,  1.62it/s] 69%|██████▉   | 347/500 [03:59<01:09,  2.20it/s] 70%|██████▉   | 349/500 [03:59<00:51,  2.93it/s] 70%|███████   | 351/500 [04:05<02:54,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s]Epoch:  285  	Training Loss: 0.024383682757616043
Test Loss:  0.01823406293988228
Valid Loss:  0.024889258667826653
Epoch:  286  	Training Loss: 0.02435501292347908
Test Loss:  0.018209664151072502
Valid Loss:  0.024859383702278137
Epoch:  287  	Training Loss: 0.02432641014456749
Test Loss:  0.018185272812843323
Valid Loss:  0.024829378351569176
Epoch:  288  	Training Loss: 0.024297840893268585
Test Loss:  0.018160976469516754
Valid Loss:  0.024799596518278122
Epoch:  289  	Training Loss: 0.02426934242248535
Test Loss:  0.018136730417609215
Valid Loss:  0.024769900366663933
Epoch:  290  	Training Loss: 0.0242408849298954
Test Loss:  0.018112488090991974
Valid Loss:  0.024740034714341164
Epoch:  291  	Training Loss: 0.02421247586607933
Test Loss:  0.01808832585811615
Valid Loss:  0.02471042051911354
Epoch:  292  	Training Loss: 0.02418411523103714
Test Loss:  0.018063850700855255
Valid Loss:  0.024680381640791893
Epoch:  293  	Training Loss: 0.02415536344051361
Test Loss:  0.01803937554359436
Valid Loss:  0.024650201201438904
Epoch:  294  	Training Loss: 0.024126658216118813
Test Loss:  0.018014993518590927
Valid Loss:  0.02462027035653591
Epoch:  295  	Training Loss: 0.024097999557852745
Test Loss:  0.01799064874649048
Valid Loss:  0.02459036558866501
Epoch:  296  	Training Loss: 0.02406938560307026
Test Loss:  0.01796632446348667
Valid Loss:  0.0245603509247303
Epoch:  297  	Training Loss: 0.024040820077061653
Test Loss:  0.017942063510417938
Valid Loss:  0.024530543014407158
Epoch:  298  	Training Loss: 0.024012301117181778
Test Loss:  0.017917867749929428
Valid Loss:  0.024500802159309387
Epoch:  299  	Training Loss: 0.023983832448720932
Test Loss:  0.017893655225634575
Valid Loss:  0.024470916017889977
Epoch:  300  	Training Loss: 0.02395540103316307
Test Loss:  0.01786954328417778
Valid Loss:  0.02444126084446907
Epoch:  301  	Training Loss: 0.02392701804637909
Test Loss:  0.017845474183559418
Valid Loss:  0.024411654099822044
Epoch:  302  	Training Loss: 0.02389868162572384
Test Loss:  0.01782134734094143
Valid Loss:  0.0243818499147892
Epoch:  303  	Training Loss: 0.023870330303907394
Test Loss:  0.017797311767935753
Valid Loss:  0.024352295324206352
Epoch:  304  	Training Loss: 0.02384202741086483
Test Loss:  0.017773298546671867
Valid Loss:  0.024322614073753357
Epoch:  305  	Training Loss: 0.023813778534531593
Test Loss:  0.01774934120476246
Valid Loss:  0.024293143302202225
Epoch:  306  	Training Loss: 0.023785565048456192
Test Loss:  0.01772540807723999
Valid Loss:  0.024263553321361542
Epoch:  307  	Training Loss: 0.023757409304380417
Test Loss:  0.017701562494039536
Valid Loss:  0.024234186857938766
Epoch:  308  	Training Loss: 0.023729296401143074
Test Loss:  0.017677731812000275
Valid Loss:  0.024204863235354424
Epoch:  309  	Training Loss: 0.023701224476099014
Test Loss:  0.017653940245509148
Valid Loss:  0.024175427854061127
Epoch:  310  	Training Loss: 0.023673202842473984
Test Loss:  0.017630208283662796
Valid Loss:  0.024146195501089096
Epoch:  311  	Training Loss: 0.023645222187042236
Test Loss:  0.017606496810913086
Valid Loss:  0.02411685697734356
Epoch:  312  	Training Loss: 0.02361728996038437
Test Loss:  0.01758287101984024
Valid Loss:  0.024087749421596527
Epoch:  313  	Training Loss: 0.023589421063661575
Test Loss:  0.017559252679347992
Valid Loss:  0.0240585096180439
Epoch:  314  	Training Loss: 0.023561600595712662
Test Loss:  0.01753571443259716
Valid Loss:  0.024029504507780075
Epoch:  315  	Training Loss: 0.02353382483124733
Test Loss:  0.01751219481229782
Valid Loss:  0.02400035411119461
Epoch:  316  	Training Loss: 0.02350609004497528
Test Loss:  0.017488742247223854
Valid Loss:  0.0239714365452528
Epoch:  317  	Training Loss: 0.023478401824831963
Test Loss:  0.017465298995375633
Valid Loss:  0.023942388594150543
Epoch:  318  	Training Loss: 0.02345074899494648
Test Loss:  0.01744193583726883
Valid Loss:  0.02391357347369194
Epoch:  319  	Training Loss: 0.023423153907060623
Test Loss:  0.017418576404452324
Valid Loss:  0.023884626105427742
Epoch:  320  	Training Loss: 0.0233956016600132
Test Loss:  0.017395302653312683
Valid Loss:  0.0238559041172266
Epoch:  321  	Training Loss: 0.023368095979094505
Test Loss:  0.017372043803334236
Valid Loss:  0.02382705733180046
Epoch:  322  	Training Loss: 0.023340635001659393
Test Loss:  0.017349379137158394
Valid Loss:  0.023799005895853043
Epoch:  323  	Training Loss: 0.023313898593187332
Test Loss:  0.01732679083943367
Valid Loss:  0.023771166801452637
Epoch:  324  	Training Loss: 0.023287206888198853
Test Loss:  0.01730421930551529
Valid Loss:  0.023743217810988426
Epoch:  325  	Training Loss: 0.023260563611984253
Test Loss:  0.017281722277402878
Valid Loss:  0.02371547557413578
Epoch:  326  	Training Loss: 0.023233966901898384
Test Loss:  0.01725923642516136
Valid Loss:  0.023687615990638733
Epoch:  327  	Training Loss: 0.023207418620586395
Test Loss:  0.01723679155111313
Valid Loss:  0.02365979738533497
Epoch:  328  	Training Loss: 0.02318090945482254
Test Loss:  0.01721443235874176
Valid Loss:  0.0236322320997715
Epoch:  329  	Training Loss: 0.023154456168413162
Test Loss:  0.017192082479596138
Valid Loss:  0.023604510352015495
Epoch:  330  	Training Loss: 0.023128041997551918
Test Loss:  0.0171697698533535
Valid Loss:  0.023576855659484863
Epoch:  331  	Training Loss: 0.0231016855686903
Test Loss:  0.017147542908787727
Valid Loss:  0.023549426347017288
Epoch:  332  	Training Loss: 0.023075368255376816
Test Loss:  0.01712498813867569
Valid Loss:  0.023521428927779198
Epoch:  333  	Training Loss: 0.023048706352710724
Test Loss:  0.01710248738527298
Valid Loss:  0.023493489250540733
Epoch:  334  	Training Loss: 0.023022081702947617
Test Loss:  0.01708006113767624
Valid Loss:  0.02346576750278473
Epoch:  335  	Training Loss: 0.022995511069893837
Test Loss:  0.017057646065950394
Valid Loss:  0.023437920957803726
Epoch:  336  	Training Loss: 0.022968977689743042
Test Loss:  0.017035264521837234
Valid Loss:  0.0234101302921772
Epoch:  337  	Training Loss: 0.022942498326301575
Test Loss:  0.01701296493411064
Valid Loss:  0.023382553830742836
Epoch:  338  	Training Loss: 0.02291606366634369
Test Loss:  0.016990669071674347
Valid Loss:  0.02335485816001892
Epoch:  339  	Training Loss: 0.02288966439664364
Test Loss:  0.016968421638011932
Valid Loss:  0.02332719787955284
Epoch:  340  	Training Loss: 0.022863304242491722
Test Loss:  0.01694621331989765
Valid Loss:  0.023299602791666985
Epoch:  341  	Training Loss: 0.022836996242403984
Test Loss:  0.016924099996685982
Valid Loss:  0.023272216320037842
Epoch:  342  	Training Loss: 0.022810745984315872
Test Loss:  0.01690298318862915
Valid Loss:  0.02324605919420719
Epoch:  343  	Training Loss: 0.022785764187574387
Test Loss:  0.016881931573152542
Valid Loss:  0.023219948634505272
Epoch:  344  	Training Loss: 0.02276083640754223
Test Loss:  0.016860932111740112
Valid Loss:  0.02319388836622238
Epoch:  345  	Training Loss: 0.02273595705628395
Test Loss:  0.016839995980262756
Valid Loss:  0.02316802740097046
Epoch:  346  	Training Loss: 0.022711124271154404
Test Loss:  0.016819091513752937
Valid Loss:  0.02314208447933197
Epoch:  347  	Training Loss: 0.022686349228024483
Test Loss:  0.016798216849565506
Valid Loss:  0.023116162046790123
Epoch:  348  	Training Loss: 0.022661618888378143
Test Loss:  0.0167773999273777
Valid Loss:  0.023090321570634842
Epoch:  349  	Training Loss: 0.022636936977505684
Test Loss:  0.01675661839544773
Valid Loss:  0.02306453511118889
Epoch:  350  	Training Loss: 0.022612307220697403
Test Loss:  0.01673593744635582
Valid Loss:  0.023038925603032112
Epoch:  351  	Training Loss: 0.02258772775530815
Test Loss:  0.01671523228287697
Valid Loss:  0.023013222962617874
Epoch:  352  	Training Loss: 0.022563183680176735
Test Loss:  0.016693556681275368
Valid Loss:  0.022986233234405518
Epoch:  353  	Training Loss: 0.02253745123744011
Test Loss:  0.016671929508447647
Valid Loss:  0.022959277033805847
Epoch:  354  	Training Loss: 0.022511759772896767
Test Loss:  0.016650330275297165
Valid Loss:  0.022932380437850952
Epoch:  355  	Training Loss: 0.022486098110675812
Test Loss:  0.016628772020339966
 71%|███████   | 355/500 [04:06<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:06<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:12<02:47,  1.20s/it] 73%|███████▎  | 363/500 [04:12<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:13<01:24,  1.61it/s] 73%|███████▎  | 367/500 [04:13<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:13<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:19<02:36,  1.21s/it] 75%|███████▍  | 373/500 [04:19<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:20<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:20<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:20<00:41,  2.91it/s] 76%|███████▌  | 381/500 [04:26<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:26<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:27<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:27<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:27<00:37,  2.94it/s] 78%|███████▊  | 391/500 [04:33<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:33<01:31,  1.16it/s] 79%|███████▉  | 395/500 [04:33<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:34<00:47,  2.18it/s] 80%|███████▉  | 399/500 [04:34<00:34,  2.93it/s] 80%|████████  | 401/500 [04:40<01:58,  1.20s/it] 81%|████████  | 403/500 [04:40<01:23,  1.17it/s] 81%|████████  | 405/500 [04:40<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:41<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:41<00:30,  2.97it/s] 82%|████████▏ | 411/500 [04:47<01:48,  1.21s/it] 83%|████████▎ | 413/500 [04:47<01:15,  1.15it/s] 83%|████████▎ | 415/500 [04:47<00:53,  1.59it/s] 83%|████████▎ | 417/500 [04:48<00:38,  2.17it/s] 84%|████████▍ | 419/500 [04:48<00:27,  2.91it/s] 84%|████████▍ | 421/500 [04:54<01:35,  1.21s/it] 85%|████████▍ | 423/500 [04:54<01:06,  1.16it/s] 85%|████████▌ | 425/500 [04:54<00:46,  1.60it/s]Valid Loss:  0.022905521094799042
Epoch:  356  	Training Loss: 0.022460486739873886
Test Loss:  0.016607284545898438
Valid Loss:  0.022878823801875114
Epoch:  357  	Training Loss: 0.02243490144610405
Test Loss:  0.016585780307650566
Valid Loss:  0.022852061316370964
Epoch:  358  	Training Loss: 0.02240936830639839
Test Loss:  0.016564352437853813
Valid Loss:  0.0228253323584795
Epoch:  359  	Training Loss: 0.022383876144886017
Test Loss:  0.01654294691979885
Valid Loss:  0.02279864251613617
Epoch:  360  	Training Loss: 0.022358421236276627
Test Loss:  0.016521576792001724
Valid Loss:  0.02277199737727642
Epoch:  361  	Training Loss: 0.022333018481731415
Test Loss:  0.016500260680913925
Valid Loss:  0.02274540811777115
Epoch:  362  	Training Loss: 0.02230764925479889
Test Loss:  0.01647917926311493
Valid Loss:  0.0227191299200058
Epoch:  363  	Training Loss: 0.022282570600509644
Test Loss:  0.016458135098218918
Valid Loss:  0.022692902013659477
Epoch:  364  	Training Loss: 0.022257544100284576
Test Loss:  0.016437143087387085
Valid Loss:  0.022666722536087036
Epoch:  365  	Training Loss: 0.022232554852962494
Test Loss:  0.016416186466813087
Valid Loss:  0.022640589624643326
Epoch:  366  	Training Loss: 0.02220761403441429
Test Loss:  0.01639528200030327
Valid Loss:  0.0226144976913929
Epoch:  367  	Training Loss: 0.022182714194059372
Test Loss:  0.01637439802289009
Valid Loss:  0.02258848026394844
Epoch:  368  	Training Loss: 0.022157855331897736
Test Loss:  0.016353566199541092
Valid Loss:  0.02256247214972973
Epoch:  369  	Training Loss: 0.02213304676115513
Test Loss:  0.01633276417851448
Valid Loss:  0.022536534816026688
Epoch:  370  	Training Loss: 0.022108271718025208
Test Loss:  0.01631201058626175
Valid Loss:  0.022510632872581482
Epoch:  371  	Training Loss: 0.022083543241024017
Test Loss:  0.016291307285428047
Valid Loss:  0.022484783083200455
Epoch:  372  	Training Loss: 0.022058866918087006
Test Loss:  0.016270391643047333
Valid Loss:  0.022458672523498535
Epoch:  373  	Training Loss: 0.02203393541276455
Test Loss:  0.0162495244294405
Valid Loss:  0.022432589903473854
Epoch:  374  	Training Loss: 0.022009044885635376
Test Loss:  0.01622868701815605
Valid Loss:  0.02240656688809395
Epoch:  375  	Training Loss: 0.021984197199344635
Test Loss:  0.01620788499712944
Valid Loss:  0.022380586713552475
Epoch:  376  	Training Loss: 0.02195938676595688
Test Loss:  0.016187123954296112
Valid Loss:  0.022354643791913986
Epoch:  377  	Training Loss: 0.021934611722826958
Test Loss:  0.016166411340236664
Valid Loss:  0.02232874184846878
Epoch:  378  	Training Loss: 0.02190988138318062
Test Loss:  0.016145717352628708
Valid Loss:  0.022302895784378052
Epoch:  379  	Training Loss: 0.02188519760966301
Test Loss:  0.016125069931149483
Valid Loss:  0.02227707952260971
Epoch:  380  	Training Loss: 0.021860536187887192
Test Loss:  0.01610446721315384
Valid Loss:  0.02225130796432495
Epoch:  381  	Training Loss: 0.021835926920175552
Test Loss:  0.016083886846899986
Valid Loss:  0.022225581109523773
Epoch:  382  	Training Loss: 0.0218113474547863
Test Loss:  0.016063079237937927
Valid Loss:  0.022199539467692375
Epoch:  383  	Training Loss: 0.02178647741675377
Test Loss:  0.01604229398071766
Valid Loss:  0.02217351458966732
Epoch:  384  	Training Loss: 0.021761644631624222
Test Loss:  0.01602155528962612
Valid Loss:  0.02214755490422249
Epoch:  385  	Training Loss: 0.02173685096204281
Test Loss:  0.016000837087631226
Valid Loss:  0.022121625021100044
Epoch:  386  	Training Loss: 0.021712087094783783
Test Loss:  0.01598016545176506
Valid Loss:  0.022095736116170883
Epoch:  387  	Training Loss: 0.02168736606836319
Test Loss:  0.015959538519382477
Valid Loss:  0.022069882601499557
Epoch:  388  	Training Loss: 0.02166268415749073
Test Loss:  0.015938937664031982
Valid Loss:  0.022044096142053604
Epoch:  389  	Training Loss: 0.02163803204894066
Test Loss:  0.015918366611003876
Valid Loss:  0.022018330171704292
Epoch:  390  	Training Loss: 0.02161341905593872
Test Loss:  0.015897830948233604
Valid Loss:  0.021992597728967667
Epoch:  391  	Training Loss: 0.021588854491710663
Test Loss:  0.015877339988946915
Valid Loss:  0.021966924890875816
Epoch:  392  	Training Loss: 0.021564314141869545
Test Loss:  0.015857350081205368
Valid Loss:  0.021941883489489555
Epoch:  393  	Training Loss: 0.021540366113185883
Test Loss:  0.015837373211979866
Valid Loss:  0.02191687375307083
Epoch:  394  	Training Loss: 0.021516460925340652
Test Loss:  0.015817444771528244
Valid Loss:  0.02189190685749054
Epoch:  395  	Training Loss: 0.021492600440979004
Test Loss:  0.015797561034560204
Valid Loss:  0.021866995841264725
Epoch:  396  	Training Loss: 0.021468769758939743
Test Loss:  0.015777703374624252
Valid Loss:  0.021842127665877342
Epoch:  397  	Training Loss: 0.02144499495625496
Test Loss:  0.015757888555526733
Valid Loss:  0.021817291155457497
Epoch:  398  	Training Loss: 0.021421248093247414
Test Loss:  0.015738118439912796
Valid Loss:  0.02179250493645668
Epoch:  399  	Training Loss: 0.02139754220843315
Test Loss:  0.015718379989266396
Valid Loss:  0.021767759695649147
Epoch:  400  	Training Loss: 0.02137388102710247
Test Loss:  0.01569868065416813
Valid Loss:  0.021743055433034897
Epoch:  401  	Training Loss: 0.02135026454925537
Test Loss:  0.015679020434617996
Valid Loss:  0.021718405187129974
Epoch:  402  	Training Loss: 0.021326672285795212
Test Loss:  0.015659162774682045
Valid Loss:  0.02169349417090416
Epoch:  403  	Training Loss: 0.02130286395549774
Test Loss:  0.015639351680874825
Valid Loss:  0.02166862227022648
Epoch:  404  	Training Loss: 0.02127908170223236
Test Loss:  0.015619576908648014
Valid Loss:  0.021643798798322678
Epoch:  405  	Training Loss: 0.021255336701869965
Test Loss:  0.015599831007421017
Valid Loss:  0.021618986502289772
Epoch:  406  	Training Loss: 0.02123164013028145
Test Loss:  0.01558012142777443
Valid Loss:  0.021594252437353134
Epoch:  407  	Training Loss: 0.02120797522366047
Test Loss:  0.015560446307063103
Valid Loss:  0.021569551900029182
Epoch:  408  	Training Loss: 0.021184349432587624
Test Loss:  0.015540821477770805
Valid Loss:  0.021544888615608215
Epoch:  409  	Training Loss: 0.02116076648235321
Test Loss:  0.015521219000220299
Valid Loss:  0.021520264446735382
Epoch:  410  	Training Loss: 0.021137217059731483
Test Loss:  0.015501650050282478
Valid Loss:  0.021495696157217026
Epoch:  411  	Training Loss: 0.02111370675265789
Test Loss:  0.01548212394118309
Valid Loss:  0.02147115394473076
Epoch:  412  	Training Loss: 0.021090218797326088
Test Loss:  0.015461588278412819
Valid Loss:  0.021445278078317642
Epoch:  413  	Training Loss: 0.02106552943587303
Test Loss:  0.015441075898706913
Valid Loss:  0.02141946367919445
Epoch:  414  	Training Loss: 0.021040871739387512
Test Loss:  0.015420614741742611
Valid Loss:  0.02139369398355484
Epoch:  415  	Training Loss: 0.021016236394643784
Test Loss:  0.01540016196668148
Valid Loss:  0.02136794477701187
Epoch:  416  	Training Loss: 0.020991630852222443
Test Loss:  0.015379752032458782
Valid Loss:  0.02134222537279129
Epoch:  417  	Training Loss: 0.02096707560122013
Test Loss:  0.015359376557171345
Valid Loss:  0.02131654880940914
Epoch:  418  	Training Loss: 0.02094253897666931
Test Loss:  0.015339028090238571
Valid Loss:  0.021290913224220276
Epoch:  419  	Training Loss: 0.020918041467666626
Test Loss:  0.015318701975047588
Valid Loss:  0.021265316754579544
Epoch:  420  	Training Loss: 0.020893573760986328
Test Loss:  0.015298419632017612
Valid Loss:  0.0212397500872612
Epoch:  421  	Training Loss: 0.02086913213133812
Test Loss:  0.01527815405279398
Valid Loss:  0.021214205771684647
Epoch:  422  	Training Loss: 0.0208447203040123
Test Loss:  0.015259206295013428
Valid Loss:  0.021190371364355087
Epoch:  423  	Training Loss: 0.020821891725063324
Test Loss:  0.015240298584103584
Valid Loss:  0.021166574209928513
Epoch:  424  	Training Loss: 0.020799102261662483
Test Loss:  0.015221424400806427
Valid Loss:  0.02114281803369522
Epoch:  425  	Training Loss: 0.02077634632587433
Test Loss:  0.01520257443189621
Valid Loss:  0.02111911028623581
Epoch:  426  	Training Loss: 0.02075362578034401
 85%|████████▌ | 427/500 [04:55<00:33,  2.19it/s] 86%|████████▌ | 429/500 [04:55<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:01<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:01<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:01<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:02<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.93it/s] 88%|████████▊ | 441/500 [05:08<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:08<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:08<00:24,  2.18it/s] 90%|████████▉ | 449/500 [05:09<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:15<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:15<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:15<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:15<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:22<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:22<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:22<00:15,  2.20it/s] 94%|█████████▍| 469/500 [05:22<00:10,  2.95it/s] 94%|█████████▍| 471/500 [05:29<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:29<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:29<00:15,  1.60it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.17it/s] 96%|█████████▌| 479/500 [05:29<00:07,  2.90it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:36<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:36<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:36<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:36<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:43<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:43<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:43<00:03,  1.61it/s]Test Loss:  0.015183781273663044
Valid Loss:  0.021095439791679382
Epoch:  427  	Training Loss: 0.020730942487716675
Test Loss:  0.01516500860452652
Valid Loss:  0.021071800962090492
Epoch:  428  	Training Loss: 0.02070830948650837
Test Loss:  0.015146268531680107
Valid Loss:  0.02104821987450123
Epoch:  429  	Training Loss: 0.0206857081502676
Test Loss:  0.015127569437026978
Valid Loss:  0.021024666726589203
Epoch:  430  	Training Loss: 0.020663149654865265
Test Loss:  0.015108911320567131
Valid Loss:  0.02100115269422531
Epoch:  431  	Training Loss: 0.020640626549720764
Test Loss:  0.015090255066752434
Valid Loss:  0.020977571606636047
Epoch:  432  	Training Loss: 0.020618151873350143
Test Loss:  0.015071236528456211
Valid Loss:  0.02095353975892067
Epoch:  433  	Training Loss: 0.020595252513885498
Test Loss:  0.015052269212901592
Valid Loss:  0.020929545164108276
Epoch:  434  	Training Loss: 0.020572395995259285
Test Loss:  0.015033325180411339
Valid Loss:  0.02090560458600521
Epoch:  435  	Training Loss: 0.020549576729536057
Test Loss:  0.015014415606856346
Valid Loss:  0.02088170126080513
Epoch:  436  	Training Loss: 0.020526792854070663
Test Loss:  0.014995552599430084
Valid Loss:  0.020857833325862885
Epoch:  437  	Training Loss: 0.020504042506217957
Test Loss:  0.01497671753168106
Valid Loss:  0.02083401009440422
Epoch:  438  	Training Loss: 0.020481333136558533
Test Loss:  0.014957915060222149
Valid Loss:  0.020810246467590332
Epoch:  439  	Training Loss: 0.020458659157156944
Test Loss:  0.014939159154891968
Valid Loss:  0.020786520093679428
Epoch:  440  	Training Loss: 0.020436035469174385
Test Loss:  0.014920425601303577
Valid Loss:  0.020762823522090912
Epoch:  441  	Training Loss: 0.020413439720869064
Test Loss:  0.014901740476489067
Valid Loss:  0.020739177241921425
Epoch:  442  	Training Loss: 0.02039087750017643
Test Loss:  0.014883230440318584
Valid Loss:  0.020715780556201935
Epoch:  443  	Training Loss: 0.0203685462474823
Test Loss:  0.01486478466540575
Valid Loss:  0.020692413672804832
Epoch:  444  	Training Loss: 0.020346257835626602
Test Loss:  0.014846350066363811
Valid Loss:  0.020669080317020416
Epoch:  445  	Training Loss: 0.020323991775512695
Test Loss:  0.014827940613031387
Valid Loss:  0.020645802840590477
Epoch:  446  	Training Loss: 0.02030176855623722
Test Loss:  0.014809587970376015
Valid Loss:  0.020622573792934418
Epoch:  447  	Training Loss: 0.02027958258986473
Test Loss:  0.014791248366236687
Valid Loss:  0.0205993615090847
Epoch:  448  	Training Loss: 0.02025742456316948
Test Loss:  0.014772938564419746
Valid Loss:  0.020576199516654015
Epoch:  449  	Training Loss: 0.02023530751466751
Test Loss:  0.014754673466086388
Valid Loss:  0.020553067326545715
Epoch:  450  	Training Loss: 0.02021322399377823
Test Loss:  0.014736444689333439
Valid Loss:  0.020529981702566147
Epoch:  451  	Training Loss: 0.020191168412566185
Test Loss:  0.014718238264322281
Valid Loss:  0.02050692029297352
Epoch:  452  	Training Loss: 0.020169153809547424
Test Loss:  0.014699782244861126
Valid Loss:  0.02048354595899582
Epoch:  453  	Training Loss: 0.020146815106272697
Test Loss:  0.014681345783174038
Valid Loss:  0.02046017535030842
Epoch:  454  	Training Loss: 0.020124513655900955
Test Loss:  0.01466294750571251
Valid Loss:  0.020436855033040047
Epoch:  455  	Training Loss: 0.020102236419916153
Test Loss:  0.014644557610154152
Valid Loss:  0.020413575693964958
Epoch:  456  	Training Loss: 0.020079994574189186
Test Loss:  0.01462622545659542
Valid Loss:  0.020390333607792854
Epoch:  457  	Training Loss: 0.020057789981365204
Test Loss:  0.014607907272875309
Valid Loss:  0.020367112010717392
Epoch:  458  	Training Loss: 0.02003561519086361
Test Loss:  0.014589614234864712
Valid Loss:  0.020343944430351257
Epoch:  459  	Training Loss: 0.020013477653265
Test Loss:  0.014571379870176315
Valid Loss:  0.020320815965533257
Epoch:  460  	Training Loss: 0.01999136060476303
Test Loss:  0.014553166925907135
Valid Loss:  0.020297696813941002
Epoch:  461  	Training Loss: 0.019969291985034943
Test Loss:  0.01453496515750885
Valid Loss:  0.020274627953767776
Epoch:  462  	Training Loss: 0.019947245717048645
Test Loss:  0.01451697014272213
Valid Loss:  0.02025180123746395
Epoch:  463  	Training Loss: 0.019925424829125404
Test Loss:  0.014499008655548096
Valid Loss:  0.020229026675224304
Epoch:  464  	Training Loss: 0.01990363746881485
Test Loss:  0.0144810751080513
Valid Loss:  0.020206259563565254
Epoch:  465  	Training Loss: 0.01988188363611698
Test Loss:  0.014463158324360847
Valid Loss:  0.020183544605970383
Epoch:  466  	Training Loss: 0.019860154017806053
Test Loss:  0.014445288106799126
Valid Loss:  0.02016087993979454
Epoch:  467  	Training Loss: 0.019838467240333557
Test Loss:  0.01442744955420494
Valid Loss:  0.02013823762536049
Epoch:  468  	Training Loss: 0.01981681026518345
Test Loss:  0.014409632422029972
Valid Loss:  0.020115628838539124
Epoch:  469  	Training Loss: 0.019795190542936325
Test Loss:  0.014391856268048286
Valid Loss:  0.020093068480491638
Epoch:  470  	Training Loss: 0.019773615524172783
Test Loss:  0.014374108985066414
Valid Loss:  0.02007053792476654
Epoch:  471  	Training Loss: 0.019752059131860733
Test Loss:  0.014356404542922974
Valid Loss:  0.020048044621944427
Epoch:  472  	Training Loss: 0.019730541855096817
Test Loss:  0.014340676367282867
Valid Loss:  0.020028144121170044
Epoch:  473  	Training Loss: 0.01971142366528511
Test Loss:  0.014324989169836044
Valid Loss:  0.02000826597213745
Epoch:  474  	Training Loss: 0.01969234272837639
Test Loss:  0.014309337362647057
Valid Loss:  0.01998843438923359
Epoch:  475  	Training Loss: 0.019673308357596397
Test Loss:  0.014293725602328777
Valid Loss:  0.01996864378452301
Epoch:  476  	Training Loss: 0.019654300063848495
Test Loss:  0.014278130605816841
Valid Loss:  0.019948873668909073
Epoch:  477  	Training Loss: 0.019635332748293877
Test Loss:  0.014262596145272255
Valid Loss:  0.019929181784391403
Epoch:  478  	Training Loss: 0.01961640827357769
Test Loss:  0.01424708403646946
Valid Loss:  0.01990949735045433
Epoch:  479  	Training Loss: 0.01959751918911934
Test Loss:  0.014231596142053604
Valid Loss:  0.01988985389471054
Epoch:  480  	Training Loss: 0.019578661769628525
Test Loss:  0.014216145500540733
Valid Loss:  0.019870243966579437
Epoch:  481  	Training Loss: 0.019559845328330994
Test Loss:  0.014200731180608273
Valid Loss:  0.01985068991780281
Epoch:  482  	Training Loss: 0.01954106241464615
Test Loss:  0.014184265397489071
Valid Loss:  0.019829776138067245
Epoch:  483  	Training Loss: 0.019521024078130722
Test Loss:  0.014167842455208302
Valid Loss:  0.01980890892446041
Epoch:  484  	Training Loss: 0.019501039758324623
Test Loss:  0.014151457697153091
Valid Loss:  0.019788067787885666
Epoch:  485  	Training Loss: 0.019481074064970016
Test Loss:  0.014135096222162247
Valid Loss:  0.019767269492149353
Epoch:  486  	Training Loss: 0.019461143761873245
Test Loss:  0.014118778519332409
Valid Loss:  0.019746512174606323
Epoch:  487  	Training Loss: 0.0194412674754858
Test Loss:  0.014102481305599213
Valid Loss:  0.019725780934095383
Epoch:  488  	Training Loss: 0.019421402364969254
Test Loss:  0.014086224138736725
Valid Loss:  0.01970510184764862
Epoch:  489  	Training Loss: 0.01940157450735569
Test Loss:  0.014069989323616028
Valid Loss:  0.0196844469755888
Epoch:  490  	Training Loss: 0.019381772726774216
Test Loss:  0.014053788967430592
Valid Loss:  0.01966381072998047
Epoch:  491  	Training Loss: 0.019362017512321472
Test Loss:  0.014037612825632095
Valid Loss:  0.019643232226371765
Epoch:  492  	Training Loss: 0.01934228278696537
Test Loss:  0.014020901173353195
Valid Loss:  0.019621970131993294
Epoch:  493  	Training Loss: 0.019321931526064873
Test Loss:  0.01400420255959034
Valid Loss:  0.01960063725709915
Epoch:  494  	Training Loss: 0.01930162124335766
Test Loss:  0.01398757379502058
Valid Loss:  0.019579464569687843
Epoch:  495  	Training Loss: 0.01928134448826313
Test Loss:  0.013970941305160522
Valid Loss:  0.019558213651180267
Epoch:  496  	Training Loss: 0.01926109753549099
Test Loss:  0.013954337686300278
Valid Loss:  0.01953701116144657
 99%|█████████▉| 497/500 [05:43<00:01,  2.19it/s]100%|█████████▉| 499/500 [05:43<00:00,  2.95it/s]100%|██████████| 500/500 [05:43<00:00,  1.45it/s]
Epoch:  497  	Training Loss: 0.019240878522396088
Test Loss:  0.01393776573240757
Valid Loss:  0.019515840336680412
Epoch:  498  	Training Loss: 0.019220704212784767
Test Loss:  0.013921214267611504
Valid Loss:  0.01949470490217209
Epoch:  499  	Training Loss: 0.019200555980205536
Test Loss:  0.013904700987040997
Valid Loss:  0.019473614171147346
Epoch:  500  	Training Loss: 0.019180437549948692
Test Loss:  0.013888220302760601
Valid Loss:  0.019452571868896484
seed is  1
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:46,  6.35s/it]  1%|          | 3/500 [00:06<14:03,  1.70s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:22,  1.88it/s]  2%|▏         | 9/500 [00:06<02:55,  2.80it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:46,  2.14it/s]  4%|▍         | 19/500 [00:13<02:45,  2.90it/s]  4%|▍         | 21/500 [00:26<17:24,  2.18s/it]  5%|▍         | 23/500 [00:26<12:13,  1.54s/it]  5%|▌         | 25/500 [00:26<08:37,  1.09s/it]  5%|▌         | 27/500 [00:26<06:08,  1.28it/s]  6%|▌         | 29/500 [00:27<04:26,  1.77it/s]  6%|▌         | 31/500 [00:39<18:04,  2.31s/it]  7%|▋         | 33/500 [00:39<12:45,  1.64s/it]  7%|▋         | 35/500 [00:40<09:02,  1.17s/it]  7%|▋         | 37/500 [00:40<06:29,  1.19it/s]  8%|▊         | 39/500 [00:40<04:41,  1.64it/s]  8%|▊         | 41/500 [00:46<10:36,  1.39s/it]  9%|▊         | 43/500 [00:46<07:33,  1.01it/s]  9%|▉         | 45/500 [00:47<05:24,  1.40it/s]  9%|▉         | 47/500 [00:47<03:54,  1.93it/s] 10%|▉         | 49/500 [00:47<02:52,  2.62it/s] 10%|█         | 51/500 [00:53<09:04,  1.21s/it] 11%|█         | 53/500 [00:53<06:30,  1.15it/s] 11%|█         | 55/500 [00:53<04:42,  1.58it/s] 11%|█▏        | 57/500 [00:54<03:25,  2.16it/s] 12%|█▏        | 59/500 [00:54<02:31,  2.91it/s] 12%|█▏        | 61/500 [01:00<08:49,  1.21s/it] 13%|█▎        | 63/500 [01:00<06:18,  1.16it/s] 13%|█▎        | 65/500 [01:00<04:32,  1.60it/s] 13%|█▎        | 67/500 [01:01<03:18,  2.19it/s]Epoch:  1  	Training Loss: 0.027221817523241043
Test Loss:  0.021974563598632812
Valid Loss:  0.023239627480506897
Epoch:  2  	Training Loss: 0.02404692955315113
Test Loss:  0.038541413843631744
Valid Loss:  0.04074219986796379
Epoch:  3  	Training Loss: 0.03993983194231987
Test Loss:  0.00328564690425992
Valid Loss:  0.004178548231720924
Epoch:  4  	Training Loss: 0.00436828937381506
Test Loss:  0.003138683270663023
Valid Loss:  0.003926442936062813
Epoch:  5  	Training Loss: 0.00408141128718853
Test Loss:  0.0029822918586432934
Valid Loss:  0.0037110568955540657
Epoch:  6  	Training Loss: 0.0038654727395623922
Test Loss:  0.0028385943733155727
Valid Loss:  0.003526001702994108
Epoch:  7  	Training Loss: 0.0036763495299965143
Test Loss:  0.002737457165494561
Valid Loss:  0.0033858055248856544
Epoch:  8  	Training Loss: 0.0035358129534870386
Test Loss:  0.0026631569489836693
Valid Loss:  0.003272692672908306
Epoch:  9  	Training Loss: 0.0034204102121293545
Test Loss:  0.002596060046926141
Valid Loss:  0.0031724884174764156
Epoch:  10  	Training Loss: 0.003315978916361928
Test Loss:  0.002535104751586914
Valid Loss:  0.0030809580348432064
Epoch:  11  	Training Loss: 0.003219498787075281
Test Loss:  0.0024807900190353394
Valid Loss:  0.00299528194591403
Epoch:  12  	Training Loss: 0.0031299178954213858
Test Loss:  0.0024568415246903896
Valid Loss:  0.0026244577020406723
Epoch:  13  	Training Loss: 0.002731956774368882
Test Loss:  0.0025063902139663696
Valid Loss:  0.0029036079067736864
Epoch:  14  	Training Loss: 0.003004800295457244
Test Loss:  0.005757797509431839
Valid Loss:  0.005442263558506966
Epoch:  15  	Training Loss: 0.005543199833482504
Test Loss:  0.009982755407691002
Valid Loss:  0.010574795305728912
Epoch:  16  	Training Loss: 0.010982755571603775
Test Loss:  0.0032934776972979307
Valid Loss:  0.0028749220073223114
Epoch:  17  	Training Loss: 0.002989746630191803
Test Loss:  0.0020576738752424717
Valid Loss:  0.002295872662216425
Epoch:  18  	Training Loss: 0.0024002252612262964
Test Loss:  0.0020239269360899925
Valid Loss:  0.0021185786463320255
Epoch:  19  	Training Loss: 0.0021997143048793077
Test Loss:  0.0018628257093951106
Valid Loss:  0.0019744536839425564
Epoch:  20  	Training Loss: 0.002035528188571334
Test Loss:  0.0017081855330616236
Valid Loss:  0.0018071932718157768
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.0018596537411212921
Test Loss:  0.0016480922931805253
Valid Loss:  0.0016542710363864899
Epoch:  22  	Training Loss: 0.0016218835953623056
Test Loss:  0.0015878074336797
Valid Loss:  0.0015709534054622054
Epoch:  23  	Training Loss: 0.0016041528433561325
Test Loss:  0.001726070186123252
Valid Loss:  0.001675513107329607
Epoch:  24  	Training Loss: 0.0016197382938116789
Test Loss:  0.001603915705345571
Valid Loss:  0.0015905746258795261
Epoch:  25  	Training Loss: 0.0016247843159362674
Test Loss:  0.0018056512344628572
Valid Loss:  0.0017518698005005717
Epoch:  26  	Training Loss: 0.0016736439429223537
Test Loss:  0.0017107054591178894
Valid Loss:  0.0017225765623152256
Epoch:  27  	Training Loss: 0.001759744598530233
Test Loss:  0.001770858420059085
Valid Loss:  0.0017211250960826874
Epoch:  28  	Training Loss: 0.0016207925509661436
Test Loss:  0.0016753124073147774
Valid Loss:  0.0016972245648503304
Epoch:  29  	Training Loss: 0.0017290393589064479
Test Loss:  0.0015656701289117336
Valid Loss:  0.001503795851022005
Epoch:  30  	Training Loss: 0.0014228904619812965
Test Loss:  0.0014006274286657572
Valid Loss:  0.0012932270765304565
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.0013078822521492839
Test Loss:  0.0013424123171716928
Valid Loss:  0.001195211661979556
Epoch:  32  	Training Loss: 0.0011667297221720219
Test Loss:  0.001315451692789793
Valid Loss:  0.0011815703473985195
Epoch:  33  	Training Loss: 0.0011519459076225758
Test Loss:  0.001293310197070241
Valid Loss:  0.0011705474462360144
Epoch:  34  	Training Loss: 0.001140052918344736
Test Loss:  0.0012798300012946129
Valid Loss:  0.0011637291172519326
Epoch:  35  	Training Loss: 0.0011332419235259295
Test Loss:  0.0012718569487333298
Valid Loss:  0.0011598982382565737
Epoch:  36  	Training Loss: 0.0011297538876533508
Test Loss:  0.0012669352581724524
Valid Loss:  0.0011587413027882576
Epoch:  37  	Training Loss: 0.0011286024237051606
Test Loss:  0.0012625777162611485
Valid Loss:  0.0011580453719943762
Epoch:  38  	Training Loss: 0.001127918716520071
Test Loss:  0.0012589257676154375
Valid Loss:  0.001157569233328104
Epoch:  39  	Training Loss: 0.001127357129007578
Test Loss:  0.0012556654401123524
Valid Loss:  0.001157222781330347
Epoch:  40  	Training Loss: 0.0011268939124420285
Test Loss:  0.0012528072111308575
Valid Loss:  0.0011569680646061897
Epoch:  41  	Training Loss: 0.001126516959629953
Test Loss:  0.0012502508470788598
Valid Loss:  0.001156749902293086
Epoch:  42  	Training Loss: 0.0011261949548497796
Test Loss:  0.0012331018224358559
Valid Loss:  0.0011266175424680114
Epoch:  43  	Training Loss: 0.001100418041460216
Test Loss:  0.0012152548879384995
Valid Loss:  0.0010970312869176269
Epoch:  44  	Training Loss: 0.0010727561311796308
Test Loss:  0.0011950804619118571
Valid Loss:  0.0010656628292053938
Epoch:  45  	Training Loss: 0.001042691757902503
Test Loss:  0.001174244680441916
Valid Loss:  0.0010334679391235113
Epoch:  46  	Training Loss: 0.0010120430961251259
Test Loss:  0.0011510200565680861
Valid Loss:  0.0009994951542466879
Epoch:  47  	Training Loss: 0.0009805606678128242
Test Loss:  0.0011269573587924242
Valid Loss:  0.0009659231291152537
Epoch:  48  	Training Loss: 0.0009492246899753809
Test Loss:  0.0011022706748917699
Valid Loss:  0.0009343501878902316
Epoch:  49  	Training Loss: 0.000919123413041234
Test Loss:  0.0010774735128507018
Valid Loss:  0.000905366672668606
Epoch:  50  	Training Loss: 0.0008910244796425104
Test Loss:  0.0010540682123973966
Valid Loss:  0.0008786548860371113
Epoch:  51  	Training Loss: 0.0008649162482470274
Test Loss:  0.0010307165794074535
Valid Loss:  0.0008543159929104149
Epoch:  52  	Training Loss: 0.0008420946542173624
Test Loss:  0.0010000847978517413
Valid Loss:  0.0008268994279205799
Epoch:  53  	Training Loss: 0.000815303239505738
Test Loss:  0.0009735998464748263
Valid Loss:  0.0008059922838583589
Epoch:  54  	Training Loss: 0.0007943029631860554
Test Loss:  0.0009513118420727551
Valid Loss:  0.0007905992679297924
Epoch:  55  	Training Loss: 0.0007782661123201251
Test Loss:  0.0009333620546385646
Valid Loss:  0.0007784969639033079
Epoch:  56  	Training Loss: 0.0007653057109564543
Test Loss:  0.0009180277120321989
Valid Loss:  0.0007688760524615645
Epoch:  57  	Training Loss: 0.0007547715795226395
Test Loss:  0.0009045652695931494
Valid Loss:  0.0007613326888531446
Epoch:  58  	Training Loss: 0.0007464141817763448
Test Loss:  0.0008926764130592346
Valid Loss:  0.0007545017288066447
Epoch:  59  	Training Loss: 0.000739332172088325
Test Loss:  0.0008822283707559109
Valid Loss:  0.0007483770605176687
Epoch:  60  	Training Loss: 0.0007330842199735343
Test Loss:  0.0008730734698474407
Valid Loss:  0.0007428695680573583
Epoch:  61  	Training Loss: 0.0007274796953424811
Test Loss:  0.0008649928495287895
Valid Loss:  0.0007378270966000855
Epoch:  62  	Training Loss: 0.0007223532302305102
Test Loss:  0.0008547373581677675
Valid Loss:  0.0007325938786379993
Epoch:  63  	Training Loss: 0.0007165850838646293
Test Loss:  0.0008464775746688247
Valid Loss:  0.0007276433170773089
Epoch:  64  	Training Loss: 0.0007113578030839562
Test Loss:  0.0008396323537454009
Valid Loss:  0.000722861266694963
Epoch:  65  	Training Loss: 0.0007064995588734746
Test Loss:  0.0008336599566973746
Valid Loss:  0.000717903720214963
Epoch:  66  	Training Loss: 0.000701668206602335
Test Loss:  0.0008282007765956223
Valid Loss:  0.0007128851721063256
Epoch:  67  	Training Loss: 0.0006967515219002962
Test Loss:  0.0008231946267187595
Valid Loss:  0.0007078602211549878
Epoch:  68  	Training Loss: 0.0006918235449120402
 14%|█▍        | 69/500 [01:01<02:26,  2.93it/s] 14%|█▍        | 71/500 [01:07<08:34,  1.20s/it] 15%|█▍        | 73/500 [01:07<06:08,  1.16it/s] 15%|█▌        | 75/500 [01:07<04:26,  1.60it/s] 15%|█▌        | 77/500 [01:08<03:13,  2.18it/s] 16%|█▌        | 79/500 [01:08<02:23,  2.94it/s] 16%|█▌        | 81/500 [01:14<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:14<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:14<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:14<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:15<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:21<08:14,  1.21s/it] 19%|█▊        | 93/500 [01:21<05:53,  1.15it/s] 19%|█▉        | 95/500 [01:21<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:21<03:04,  2.18it/s] 20%|█▉        | 99/500 [01:22<02:16,  2.94it/s] 20%|██        | 101/500 [01:28<07:54,  1.19s/it] 21%|██        | 103/500 [01:28<05:38,  1.17it/s] 21%|██        | 105/500 [01:28<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:28<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:28<02:11,  2.96it/s] 22%|██▏       | 111/500 [01:35<07:43,  1.19s/it] 23%|██▎       | 113/500 [01:35<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:35<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:35<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:35<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:42<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:42<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:42<03:53,  1.60it/s] 25%|██▌       | 127/500 [01:42<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:42<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:49<07:17,  1.19s/it] 27%|██▋       | 133/500 [01:49<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:49<03:46,  1.61it/s]Test Loss:  0.0008186575723811984
Valid Loss:  0.0007029551197774708
Epoch:  69  	Training Loss: 0.0006870127399452031
Test Loss:  0.0008143839659169316
Valid Loss:  0.0006982596823945642
Epoch:  70  	Training Loss: 0.0006823725998401642
Test Loss:  0.0008101944113150239
Valid Loss:  0.0006937395664863288
Epoch:  71  	Training Loss: 0.000677966745570302
Test Loss:  0.0008063300047069788
Valid Loss:  0.0006895200931467116
Epoch:  72  	Training Loss: 0.0006737918010912836
Test Loss:  0.0008034418569877744
Valid Loss:  0.0006812942447140813
Epoch:  73  	Training Loss: 0.0006671321461908519
Test Loss:  0.0008027009898796678
Valid Loss:  0.0006799634429626167
Epoch:  74  	Training Loss: 0.0006654270109720528
Test Loss:  0.000801490677986294
Valid Loss:  0.0006782744312658906
Epoch:  75  	Training Loss: 0.0006638382328674197
Test Loss:  0.0008002716931514442
Valid Loss:  0.0006767210434190929
Epoch:  76  	Training Loss: 0.0006623020162805915
Test Loss:  0.0007989207515493035
Valid Loss:  0.0006751866894774139
Epoch:  77  	Training Loss: 0.0006608011317439377
Test Loss:  0.0007975202752277255
Valid Loss:  0.0006736938375979662
Epoch:  78  	Training Loss: 0.0006593208527192473
Test Loss:  0.0007960558286868036
Valid Loss:  0.000672227586619556
Epoch:  79  	Training Loss: 0.0006578601314686239
Test Loss:  0.0007945725228637457
Valid Loss:  0.000670804874971509
Epoch:  80  	Training Loss: 0.000656427233479917
Test Loss:  0.0007929624407552183
Valid Loss:  0.0006693988689221442
Epoch:  81  	Training Loss: 0.0006549987010657787
Test Loss:  0.0007912929868325591
Valid Loss:  0.0006679965881630778
Epoch:  82  	Training Loss: 0.0006535814027301967
Test Loss:  0.0007891192799434066
Valid Loss:  0.0006653311429545283
Epoch:  83  	Training Loss: 0.0006511776591651142
Test Loss:  0.0007873563445173204
Valid Loss:  0.0006630381103605032
Epoch:  84  	Training Loss: 0.0006487771752290428
Test Loss:  0.00078535673674196
Valid Loss:  0.0006606951355934143
Epoch:  85  	Training Loss: 0.0006463945610448718
Test Loss:  0.0007832580013200641
Valid Loss:  0.0006582929054275155
Epoch:  86  	Training Loss: 0.0006440278375521302
Test Loss:  0.0007811215473338962
Valid Loss:  0.0006558765890076756
Epoch:  87  	Training Loss: 0.0006416471442207694
Test Loss:  0.000778820423875004
Valid Loss:  0.0006533311679959297
Epoch:  88  	Training Loss: 0.000639191479422152
Test Loss:  0.0007773428224027157
Valid Loss:  0.0006512313848361373
Epoch:  89  	Training Loss: 0.0006371620111167431
Test Loss:  0.0007782634347677231
Valid Loss:  0.0006494303233921528
Epoch:  90  	Training Loss: 0.0006354600191116333
Test Loss:  0.0007759812287986279
Valid Loss:  0.0006471517845056951
Epoch:  91  	Training Loss: 0.0006329930038191378
Test Loss:  0.0007749508367851377
Valid Loss:  0.0006454091053456068
Epoch:  92  	Training Loss: 0.0006313867052085698
Test Loss:  0.0007701890426687896
Valid Loss:  0.0006397415418177843
Epoch:  93  	Training Loss: 0.0006259710644371808
Test Loss:  0.0007654455257579684
Valid Loss:  0.0006328350864350796
Epoch:  94  	Training Loss: 0.0006204253295436502
Test Loss:  0.000762749114073813
Valid Loss:  0.0006319897947832942
Epoch:  95  	Training Loss: 0.0006183144869282842
Test Loss:  0.0007600380922667682
Valid Loss:  0.0006303678965196013
Epoch:  96  	Training Loss: 0.0006165222148410976
Test Loss:  0.0007574234623461962
Valid Loss:  0.0006285990821197629
Epoch:  97  	Training Loss: 0.0006147754611447453
Test Loss:  0.0007550144800916314
Valid Loss:  0.0006268585566431284
Epoch:  98  	Training Loss: 0.0006130629335530102
Test Loss:  0.0007527290727011859
Valid Loss:  0.0006251295562833548
Epoch:  99  	Training Loss: 0.0006113708368502557
Test Loss:  0.0007505519315600395
Valid Loss:  0.0006234297179616988
Epoch:  100  	Training Loss: 0.0006096918368712068
Test Loss:  0.0007484662928618491
Valid Loss:  0.0006217567715793848
Epoch:  101  	Training Loss: 0.0006080390885472298
Test Loss:  0.0007466403767466545
Valid Loss:  0.00062018190510571
Epoch:  102  	Training Loss: 0.0006064243498258293
Test Loss:  0.0007384844939224422
Valid Loss:  0.0006110257236286998
Epoch:  103  	Training Loss: 0.0005978185217827559
Test Loss:  0.0007294799434021115
Valid Loss:  0.0006013892707414925
Epoch:  104  	Training Loss: 0.0005877912626601756
Test Loss:  0.0007190933683887124
Valid Loss:  0.0005909125320613384
Epoch:  105  	Training Loss: 0.0005770483985543251
Test Loss:  0.0007133069448173046
Valid Loss:  0.0005843623075634241
Epoch:  106  	Training Loss: 0.0005702457274310291
Test Loss:  0.0007101197261363268
Valid Loss:  0.0005815541371703148
Epoch:  107  	Training Loss: 0.0005671523977071047
Test Loss:  0.0007059011841192842
Valid Loss:  0.0005784088862128556
Epoch:  108  	Training Loss: 0.0005641509778797626
Test Loss:  0.0007022634381428361
Valid Loss:  0.0005754352896474302
Epoch:  109  	Training Loss: 0.0005612319218926132
Test Loss:  0.0006989614339545369
Valid Loss:  0.0005724921356886625
Epoch:  110  	Training Loss: 0.0005584025639109313
Test Loss:  0.0006959738675504923
Valid Loss:  0.0005696528824046254
Epoch:  111  	Training Loss: 0.0005556544638238847
Test Loss:  0.000693169014994055
Valid Loss:  0.000566846108995378
Epoch:  112  	Training Loss: 0.0005529578775167465
Test Loss:  0.0006875808467157185
Valid Loss:  0.0005623357137665153
Epoch:  113  	Training Loss: 0.0005489962641149759
Test Loss:  0.0006828715559095144
Valid Loss:  0.0005583298625424504
Epoch:  114  	Training Loss: 0.0005451829638332129
Test Loss:  0.0006786197773180902
Valid Loss:  0.0005543442093767226
Epoch:  115  	Training Loss: 0.0005414839833974838
Test Loss:  0.0006747503648512065
Valid Loss:  0.0005505060544237494
Epoch:  116  	Training Loss: 0.0005378854111768305
Test Loss:  0.000670934037771076
Valid Loss:  0.0005468549206852913
Epoch:  117  	Training Loss: 0.0005343757220543921
Test Loss:  0.0006676350021734834
Valid Loss:  0.000543134578038007
Epoch:  118  	Training Loss: 0.000530970748513937
Test Loss:  0.0006642942898906767
Valid Loss:  0.0005396489286795259
Epoch:  119  	Training Loss: 0.0005276651936583221
Test Loss:  0.0006610937416553497
Valid Loss:  0.0005361939547583461
Epoch:  120  	Training Loss: 0.0005244578933343291
Test Loss:  0.0006582633359357715
Valid Loss:  0.0005327623221091926
Epoch:  121  	Training Loss: 0.0005213199183344841
Test Loss:  0.0006552979466505349
Valid Loss:  0.000529496930539608
Epoch:  122  	Training Loss: 0.0005182304885238409
Test Loss:  0.0006545677315443754
Valid Loss:  0.0005292526911944151
Epoch:  123  	Training Loss: 0.000517824781127274
Test Loss:  0.0006538720917887986
Valid Loss:  0.0005290035041980445
Epoch:  124  	Training Loss: 0.000517450156621635
Test Loss:  0.0006532046245411038
Valid Loss:  0.0005287599633447826
Epoch:  125  	Training Loss: 0.0005171035882085562
Test Loss:  0.0006525727221742272
Valid Loss:  0.0005285312654450536
Epoch:  126  	Training Loss: 0.0005167796043679118
Test Loss:  0.0006519814487546682
Valid Loss:  0.0005283110658638179
Epoch:  127  	Training Loss: 0.0005164741887710989
Test Loss:  0.0006514061242341995
Valid Loss:  0.0005280919140204787
Epoch:  128  	Training Loss: 0.0005161845474503934
Test Loss:  0.0006508603692054749
Valid Loss:  0.0005278944736346602
Epoch:  129  	Training Loss: 0.0005159215070307255
Test Loss:  0.0006503883632831275
Valid Loss:  0.0005277357413433492
Epoch:  130  	Training Loss: 0.0005156946135684848
Test Loss:  0.0006499768933281302
Valid Loss:  0.0005276285228319466
Epoch:  131  	Training Loss: 0.0005154974642209709
Test Loss:  0.0006496174028143287
Valid Loss:  0.0005275311414152384
Epoch:  132  	Training Loss: 0.0005153260426595807
Test Loss:  0.0006472265813499689
Valid Loss:  0.0005251095280982554
Epoch:  133  	Training Loss: 0.000513507635332644
Test Loss:  0.0006449763895943761
Valid Loss:  0.0005230309907346964
Epoch:  134  	Training Loss: 0.0005118043627589941
Test Loss:  0.000642862927634269
Valid Loss:  0.0005211192183196545
Epoch:  135  	Training Loss: 0.0005101594142615795
Test Loss:  0.0006408396875485778
Valid Loss:  0.0005192903336137533
Epoch:  136  	Training Loss: 0.0005085449665784836
Test Loss:  0.0006389013724401593
Valid Loss:  0.000517513370141387
 27%|██▋       | 137/500 [01:49<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:49<02:02,  2.96it/s] 28%|██▊       | 141/500 [01:56<07:15,  1.21s/it] 29%|██▊       | 143/500 [01:56<05:10,  1.15it/s] 29%|██▉       | 145/500 [01:56<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:56<02:42,  2.17it/s] 30%|██▉       | 149/500 [01:56<01:59,  2.93it/s] 30%|███       | 151/500 [02:03<07:06,  1.22s/it] 31%|███       | 153/500 [02:03<05:04,  1.14it/s] 31%|███       | 155/500 [02:03<03:38,  1.58it/s] 31%|███▏      | 157/500 [02:03<02:38,  2.16it/s] 32%|███▏      | 159/500 [02:03<01:57,  2.91it/s] 32%|███▏      | 161/500 [02:10<06:52,  1.22s/it] 33%|███▎      | 163/500 [02:10<04:54,  1.15it/s] 33%|███▎      | 165/500 [02:10<03:31,  1.58it/s] 33%|███▎      | 167/500 [02:10<02:34,  2.16it/s] 34%|███▍      | 169/500 [02:10<01:53,  2.91it/s] 34%|███▍      | 171/500 [02:17<06:33,  1.19s/it] 35%|███▍      | 173/500 [02:17<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:17<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:17<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:17<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:24<06:30,  1.22s/it] 37%|███▋      | 183/500 [02:24<04:38,  1.14it/s] 37%|███▋      | 185/500 [02:24<03:19,  1.58it/s] 37%|███▋      | 187/500 [02:24<02:25,  2.16it/s] 38%|███▊      | 189/500 [02:24<01:47,  2.91it/s] 38%|███▊      | 191/500 [02:31<06:08,  1.19s/it] 39%|███▊      | 193/500 [02:31<04:23,  1.17it/s] 39%|███▉      | 195/500 [02:31<03:08,  1.61it/s] 39%|███▉      | 197/500 [02:31<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:31<01:41,  2.97it/s] 40%|████      | 201/500 [02:38<05:54,  1.18s/it] 41%|████      | 203/500 [02:38<04:12,  1.18it/s]Epoch:  137  	Training Loss: 0.0005069550825282931
Test Loss:  0.0006370407063513994
Valid Loss:  0.000515774532686919
Epoch:  138  	Training Loss: 0.000505387841258198
Test Loss:  0.0006352525670081377
Valid Loss:  0.0005140639841556549
Epoch:  139  	Training Loss: 0.0005038414383307099
Test Loss:  0.0006335499929264188
Valid Loss:  0.000512386322952807
Epoch:  140  	Training Loss: 0.000502314418554306
Test Loss:  0.0006319214007817209
Valid Loss:  0.000510738231241703
Epoch:  141  	Training Loss: 0.000500814407132566
Test Loss:  0.000630356720648706
Valid Loss:  0.0005091314669698477
Epoch:  142  	Training Loss: 0.0004993646871298552
Test Loss:  0.0006214996101334691
Valid Loss:  0.0004883704241365194
Epoch:  143  	Training Loss: 0.0004825289361178875
Test Loss:  0.0006152441492304206
Valid Loss:  0.00047342744073830545
Epoch:  144  	Training Loss: 0.00047052354784682393
Test Loss:  0.0006097509176470339
Valid Loss:  0.0004619063693098724
Epoch:  145  	Training Loss: 0.0004610019095707685
Test Loss:  0.0006044927868060768
Valid Loss:  0.0004528705030679703
Epoch:  146  	Training Loss: 0.00045309867709875107
Test Loss:  0.0005991241196170449
Valid Loss:  0.00044517527567222714
Epoch:  147  	Training Loss: 0.00044603634160012007
Test Loss:  0.0005936444504186511
Valid Loss:  0.00043825036846101284
Epoch:  148  	Training Loss: 0.00043944374192506075
Test Loss:  0.0005883619305677712
Valid Loss:  0.00043173355516046286
Epoch:  149  	Training Loss: 0.00043310917681083083
Test Loss:  0.0005830527516081929
Valid Loss:  0.00042549765203148127
Epoch:  150  	Training Loss: 0.00042702126665972173
Test Loss:  0.0005776830948889256
Valid Loss:  0.00041963273542933166
Epoch:  151  	Training Loss: 0.00042131938971579075
Test Loss:  0.0005723090725950897
Valid Loss:  0.0004141915123909712
Epoch:  152  	Training Loss: 0.0004159912932664156
Test Loss:  0.0005545301828533411
Valid Loss:  0.0004024855443276465
Epoch:  153  	Training Loss: 0.0004007084935437888
Test Loss:  0.000545724353287369
Valid Loss:  0.00039861799450591207
Epoch:  154  	Training Loss: 0.0003948204102925956
Test Loss:  0.000539630651473999
Valid Loss:  0.00039635266875848174
Epoch:  155  	Training Loss: 0.0003914819099009037
Test Loss:  0.0005349023849703372
Valid Loss:  0.0003944851632695645
Epoch:  156  	Training Loss: 0.00038908622809685767
Test Loss:  0.0005309419357217848
Valid Loss:  0.00039274131995625794
Epoch:  157  	Training Loss: 0.000387106672860682
Test Loss:  0.0005274933646433055
Valid Loss:  0.00039106246549636126
Epoch:  158  	Training Loss: 0.0003854453098028898
Test Loss:  0.0005245499778538942
Valid Loss:  0.00038952333852648735
Epoch:  159  	Training Loss: 0.0003839738783426583
Test Loss:  0.0005219393642619252
Valid Loss:  0.0003880657604895532
Epoch:  160  	Training Loss: 0.00038260017754510045
Test Loss:  0.0005195532576180995
Valid Loss:  0.0003866475308313966
Epoch:  161  	Training Loss: 0.000381322402972728
Test Loss:  0.0005174315301701427
Valid Loss:  0.0003852896043099463
Epoch:  162  	Training Loss: 0.00038012280128896236
Test Loss:  0.0005103028379380703
Valid Loss:  0.00036749584251083434
Epoch:  163  	Training Loss: 0.00036790347076021135
Test Loss:  0.0005050688632763922
Valid Loss:  0.00035989261232316494
Epoch:  164  	Training Loss: 0.00036055294913239777
Test Loss:  0.0004997544456273317
Valid Loss:  0.00035424972884356976
Epoch:  165  	Training Loss: 0.0003547996748238802
Test Loss:  0.0004952349700033665
Valid Loss:  0.000350006390362978
Epoch:  166  	Training Loss: 0.0003501963219605386
Test Loss:  0.0004910422721877694
Valid Loss:  0.00034644745755940676
Epoch:  167  	Training Loss: 0.0003461603191681206
Test Loss:  0.0004869777476415038
Valid Loss:  0.00034377601696178317
Epoch:  168  	Training Loss: 0.0003430042997933924
Test Loss:  0.00048319954657927155
Valid Loss:  0.00034142762888222933
Epoch:  169  	Training Loss: 0.00034040294121950865
Test Loss:  0.0004797128203790635
Valid Loss:  0.0003394319792278111
Epoch:  170  	Training Loss: 0.0003381434944458306
Test Loss:  0.0004764805198647082
Valid Loss:  0.0003374572261236608
Epoch:  171  	Training Loss: 0.00033607351360842586
Test Loss:  0.00047351460671052337
Valid Loss:  0.0003357621026225388
Epoch:  172  	Training Loss: 0.00033427280141040683
Test Loss:  0.0004697273252531886
Valid Loss:  0.00033563643228262663
Epoch:  173  	Training Loss: 0.00033329034340567887
Test Loss:  0.00046711339382454753
Valid Loss:  0.0003348898608237505
Epoch:  174  	Training Loss: 0.0003324572753626853
Test Loss:  0.00046484507038258016
Valid Loss:  0.00033425138099119067
Epoch:  175  	Training Loss: 0.00033166410867124796
Test Loss:  0.0004628497699741274
Valid Loss:  0.00033364194678142667
Epoch:  176  	Training Loss: 0.00033089646603912115
Test Loss:  0.00046104847569949925
Valid Loss:  0.00033305565011687577
Epoch:  177  	Training Loss: 0.00033015053486451507
Test Loss:  0.00045937520917505026
Valid Loss:  0.000332482042722404
Epoch:  178  	Training Loss: 0.0003294240450486541
Test Loss:  0.00045779708307236433
Valid Loss:  0.00033192127011716366
Epoch:  179  	Training Loss: 0.00032871527946554124
Test Loss:  0.0004562949761748314
Valid Loss:  0.0003313726047053933
Epoch:  180  	Training Loss: 0.00032802289933897555
Test Loss:  0.00045486135059036314
Valid Loss:  0.0003308354935143143
Epoch:  181  	Training Loss: 0.00032734338310547173
Test Loss:  0.00045346474507823586
Valid Loss:  0.0003302971017546952
Epoch:  182  	Training Loss: 0.00032667984487488866
Test Loss:  0.00045352059532888234
Valid Loss:  0.00032925745472311974
Epoch:  183  	Training Loss: 0.00032584165455773473
Test Loss:  0.0004537530767265707
Valid Loss:  0.00032847479451447725
Epoch:  184  	Training Loss: 0.0003250909794587642
Test Loss:  0.00045395834604278207
Valid Loss:  0.00032776163425296545
Epoch:  185  	Training Loss: 0.0003243984538130462
Test Loss:  0.00045411326573230326
Valid Loss:  0.00032709049992263317
Epoch:  186  	Training Loss: 0.0003237560740672052
Test Loss:  0.0004542225506156683
Valid Loss:  0.00032645140890963376
Epoch:  187  	Training Loss: 0.0003231489681638777
Test Loss:  0.0004542851820588112
Valid Loss:  0.0003258513752371073
Epoch:  188  	Training Loss: 0.00032257259590551257
Test Loss:  0.0004543067771010101
Valid Loss:  0.00032527558505535126
Epoch:  189  	Training Loss: 0.00032202075817622244
Test Loss:  0.000454285996966064
Valid Loss:  0.0003247109125368297
Epoch:  190  	Training Loss: 0.00032148935133591294
Test Loss:  0.0004542297392617911
Valid Loss:  0.00032416696194559336
Epoch:  191  	Training Loss: 0.00032097712391987443
Test Loss:  0.0004541352391242981
Valid Loss:  0.0003236287157051265
Epoch:  192  	Training Loss: 0.000320479302899912
Test Loss:  0.0004522183444350958
Valid Loss:  0.00032321945764124393
Epoch:  193  	Training Loss: 0.0003197892219759524
Test Loss:  0.00045052816858515143
Valid Loss:  0.00032277757418341935
Epoch:  194  	Training Loss: 0.0003191762079950422
Test Loss:  0.00044900993816554546
Valid Loss:  0.0003223107778467238
Epoch:  195  	Training Loss: 0.0003186072572134435
Test Loss:  0.00044763137702830136
Valid Loss:  0.00032182587892748415
Epoch:  196  	Training Loss: 0.00031806674087420106
Test Loss:  0.0004463680670596659
Valid Loss:  0.00032133073545992374
Epoch:  197  	Training Loss: 0.000317546131554991
Test Loss:  0.0004452016728464514
Valid Loss:  0.0003208309644833207
Epoch:  198  	Training Loss: 0.0003170398995280266
Test Loss:  0.0004441278870217502
Valid Loss:  0.00032033276511356235
Epoch:  199  	Training Loss: 0.0003165447851642966
Test Loss:  0.00044312977115623653
Valid Loss:  0.0003198370395693928
Epoch:  200  	Training Loss: 0.00031605985714122653
Test Loss:  0.000442192074842751
Valid Loss:  0.0003193422162439674
Epoch:  201  	Training Loss: 0.0003155815356876701
Test Loss:  0.0004413132555782795
Valid Loss:  0.00031885033240541816
Epoch:  202  	Training Loss: 0.00031511083943769336
Test Loss:  0.0004404103965498507
Valid Loss:  0.0003183082735631615
Epoch:  203  	Training Loss: 0.00031452346593141556
Test Loss:  0.00043954583816230297
Valid Loss:  0.0003177532344125211
Epoch:  204  	Training Loss: 0.00031395378755405545
Test Loss:   41%|████      | 205/500 [02:38<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:38<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:38<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:44<05:43,  1.19s/it] 43%|████▎     | 213/500 [02:45<04:04,  1.17it/s] 43%|████▎     | 215/500 [02:45<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:45<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:45<01:34,  2.99it/s] 44%|████▍     | 221/500 [02:51<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:51<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:52<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:52<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:52<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:58<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:58<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:59<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:59<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:59<01:27,  2.97it/s] 48%|████▊     | 241/500 [03:05<05:06,  1.18s/it] 49%|████▊     | 243/500 [03:05<03:38,  1.18it/s] 49%|████▉     | 245/500 [03:05<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:06<01:53,  2.23it/s] 50%|████▉     | 249/500 [03:06<01:23,  2.99it/s] 50%|█████     | 251/500 [03:12<04:53,  1.18s/it] 51%|█████     | 253/500 [03:12<03:29,  1.18it/s] 51%|█████     | 255/500 [03:12<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:12<01:48,  2.23it/s] 52%|█████▏    | 259/500 [03:13<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:19<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:19<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:19<02:22,  1.64it/s] 53%|█████▎    | 267/500 [03:19<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:19<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:26<04:27,  1.17s/it]0.00043872074456885457
Valid Loss:  0.0003171922289766371
Epoch:  205  	Training Loss: 0.0003133978461846709
Test Loss:  0.0004379360470920801
Valid Loss:  0.00031663302797824144
Epoch:  206  	Training Loss: 0.0003128535463474691
Test Loss:  0.00043718708911910653
Valid Loss:  0.0003160757478326559
Epoch:  207  	Training Loss: 0.00031231954926624894
Test Loss:  0.00043647008715197444
Valid Loss:  0.00031552501604892313
Epoch:  208  	Training Loss: 0.0003117950400337577
Test Loss:  0.0004357816360425204
Valid Loss:  0.000314978911774233
Epoch:  209  	Training Loss: 0.00031127972761169076
Test Loss:  0.00043511955300346017
Valid Loss:  0.0003144414513371885
Epoch:  210  	Training Loss: 0.0003107750089839101
Test Loss:  0.00043448287760838866
Valid Loss:  0.00031391228549182415
Epoch:  211  	Training Loss: 0.00031027902150526643
Test Loss:  0.0004338639846537262
Valid Loss:  0.0003133873688057065
Epoch:  212  	Training Loss: 0.00030978795257396996
Test Loss:  0.0004327087663114071
Valid Loss:  0.00031231646426022053
Epoch:  213  	Training Loss: 0.00030891032656654716
Test Loss:  0.00043165034730918705
Valid Loss:  0.0003112816484645009
Epoch:  214  	Training Loss: 0.00030805179267190397
Test Loss:  0.0004306731279939413
Valid Loss:  0.0003102755290456116
Epoch:  215  	Training Loss: 0.00030721043003723025
Test Loss:  0.00042976290569640696
Valid Loss:  0.00030929374042898417
Epoch:  216  	Training Loss: 0.0003063855110667646
Test Loss:  0.0004289045464247465
Valid Loss:  0.00030833063647150993
Epoch:  217  	Training Loss: 0.0003055754059460014
Test Loss:  0.0004280896973796189
Valid Loss:  0.0003073822008445859
Epoch:  218  	Training Loss: 0.000304778222925961
Test Loss:  0.000427314720582217
Valid Loss:  0.00030645093647763133
Epoch:  219  	Training Loss: 0.00030399332172237337
Test Loss:  0.00042657527956180274
Valid Loss:  0.00030553273973055184
Epoch:  220  	Training Loss: 0.0003032200620509684
Test Loss:  0.0004258672706782818
Valid Loss:  0.00030462778522633016
Epoch:  221  	Training Loss: 0.0003024561738129705
Test Loss:  0.00042517835390754044
Valid Loss:  0.00030373327899724245
Epoch:  222  	Training Loss: 0.0003017010458279401
Test Loss:  0.000424915982875973
Valid Loss:  0.00030287314439192414
Epoch:  223  	Training Loss: 0.0003010917571373284
Test Loss:  0.00042491260683164
Valid Loss:  0.000302417844068259
Epoch:  224  	Training Loss: 0.0003005685575772077
Test Loss:  0.0004248135956004262
Valid Loss:  0.00030202322523109615
Epoch:  225  	Training Loss: 0.0003000848228111863
Test Loss:  0.00042462546844035387
Valid Loss:  0.0003016580012626946
Epoch:  226  	Training Loss: 0.0002996285038534552
Test Loss:  0.0004243456060066819
Valid Loss:  0.0003013068053405732
Epoch:  227  	Training Loss: 0.000299193081445992
Test Loss:  0.0004239871050231159
Valid Loss:  0.00030096882255747914
Epoch:  228  	Training Loss: 0.00029877404449507594
Test Loss:  0.0004235586093273014
Valid Loss:  0.00030063773738220334
Epoch:  229  	Training Loss: 0.0002983681333716959
Test Loss:  0.00042307612602598965
Valid Loss:  0.0003003157034981996
Epoch:  230  	Training Loss: 0.0002979708951897919
Test Loss:  0.00042255132575519383
Valid Loss:  0.0003000005381181836
Epoch:  231  	Training Loss: 0.0002975797688122839
Test Loss:  0.00042201223550364375
Valid Loss:  0.00029969733441248536
Epoch:  232  	Training Loss: 0.00029719178564846516
Test Loss:  0.00041965750278905034
Valid Loss:  0.00029822273063473403
Epoch:  233  	Training Loss: 0.0002965273451991379
Test Loss:  0.0004173614433966577
Valid Loss:  0.00029796946910209954
Epoch:  234  	Training Loss: 0.0002959863340947777
Test Loss:  0.0004154022899456322
Valid Loss:  0.0002973323571495712
Epoch:  235  	Training Loss: 0.00029551557963714004
Test Loss:  0.00041362218325957656
Valid Loss:  0.000296949059702456
Epoch:  236  	Training Loss: 0.0002951005008071661
Test Loss:  0.0004121497622691095
Valid Loss:  0.00029644748428836465
Epoch:  237  	Training Loss: 0.0002947250031866133
Test Loss:  0.0004106726555619389
Valid Loss:  0.0002961854333989322
Epoch:  238  	Training Loss: 0.00029438373167067766
Test Loss:  0.0004093860916327685
Valid Loss:  0.00029578537214547396
Epoch:  239  	Training Loss: 0.0002940762205980718
Test Loss:  0.00040807988261803985
Valid Loss:  0.00029555358923971653
Epoch:  240  	Training Loss: 0.0002938035177066922
Test Loss:  0.0004070352588314563
Valid Loss:  0.00029513053596019745
Epoch:  241  	Training Loss: 0.0002935458905994892
Test Loss:  0.00040609948337078094
Valid Loss:  0.00029490209999494255
Epoch:  242  	Training Loss: 0.00029330819961614907
Test Loss:  0.0004061609215568751
Valid Loss:  0.00029341274057514966
Epoch:  243  	Training Loss: 0.0002917771053034812
Test Loss:  0.00040629744762554765
Valid Loss:  0.00029328910750336945
Epoch:  244  	Training Loss: 0.0002908146707341075
Test Loss:  0.00040590556454844773
Valid Loss:  0.0002924552536569536
Epoch:  245  	Training Loss: 0.00029000965878367424
Test Loss:  0.0004054646415170282
Valid Loss:  0.00029188988264650106
Epoch:  246  	Training Loss: 0.0002892840129788965
Test Loss:  0.00040484603960067034
Valid Loss:  0.0002912116178777069
Epoch:  247  	Training Loss: 0.0002885756257455796
Test Loss:  0.00040416032425127923
Valid Loss:  0.0002905569854192436
Epoch:  248  	Training Loss: 0.00028787573683075607
Test Loss:  0.0004033993755001575
Valid Loss:  0.0002898983075283468
Epoch:  249  	Training Loss: 0.00028718545217998326
Test Loss:  0.00040258606895804405
Valid Loss:  0.00028924562502652407
Epoch:  250  	Training Loss: 0.0002865008427761495
Test Loss:  0.0004017241299152374
Valid Loss:  0.0002885923895519227
Epoch:  251  	Training Loss: 0.00028582062805071473
Test Loss:  0.00040082482155412436
Valid Loss:  0.00028794328682124615
Epoch:  252  	Training Loss: 0.0002851469907909632
Test Loss:  0.00039961637230589986
Valid Loss:  0.0002869731397368014
Epoch:  253  	Training Loss: 0.00028437768924050033
Test Loss:  0.0003985142975579947
Valid Loss:  0.0002862359397113323
Epoch:  254  	Training Loss: 0.0002836301573552191
Test Loss:  0.00039741446380503476
Valid Loss:  0.0002854896301869303
Epoch:  255  	Training Loss: 0.0002828856813721359
Test Loss:  0.0003963439376093447
Valid Loss:  0.00028475752333179116
Epoch:  256  	Training Loss: 0.00028214132180437446
Test Loss:  0.00039527961052954197
Valid Loss:  0.0002840216038748622
Epoch:  257  	Training Loss: 0.00028140144422650337
Test Loss:  0.00039422366535291076
Valid Loss:  0.0002832922909874469
Epoch:  258  	Training Loss: 0.00028066657250747085
Test Loss:  0.0003931766841560602
Valid Loss:  0.0002825668198056519
Epoch:  259  	Training Loss: 0.0002799333888106048
Test Loss:  0.000392131507396698
Valid Loss:  0.00028184076654724777
Epoch:  260  	Training Loss: 0.0002792024752125144
Test Loss:  0.0003911091771442443
Valid Loss:  0.00028112094150856137
Epoch:  261  	Training Loss: 0.00027847595629282296
Test Loss:  0.00039009537431411445
Valid Loss:  0.0002804057439789176
Epoch:  262  	Training Loss: 0.00027775432681664824
Test Loss:  0.0003885577025357634
Valid Loss:  0.0002799593494273722
Epoch:  263  	Training Loss: 0.00027705496177077293
Test Loss:  0.0003871463122777641
Valid Loss:  0.00027926149778068066
Epoch:  264  	Training Loss: 0.0002763707307167351
Test Loss:  0.0003858330601360649
Valid Loss:  0.00027863981085829437
Epoch:  265  	Training Loss: 0.0002756882458925247
Test Loss:  0.000384622166166082
Valid Loss:  0.00027800939278677106
Epoch:  266  	Training Loss: 0.00027499330462887883
Test Loss:  0.00038345932262018323
Valid Loss:  0.000277373765129596
Epoch:  267  	Training Loss: 0.0002743011573329568
Test Loss:  0.00038233204395510256
Valid Loss:  0.00027674291050061584
Epoch:  268  	Training Loss: 0.0002736087772063911
Test Loss:  0.00038121972465887666
Valid Loss:  0.00027610885445028543
Epoch:  269  	Training Loss: 0.00027291738661006093
Test Loss:  0.00038011596188880503
Valid Loss:  0.00027547343051992357
Epoch:  270  	Training Loss: 0.0002722256467677653
Test Loss:  0.00037902191979810596
Valid Loss:  0.0002748347178567201
Epoch:  271  	Training Loss: 0.00027153576957061887
Test Loss:  0.00037792581133544445
Valid Loss:  0.0002741896314546466
 55%|█████▍    | 273/500 [03:26<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:26<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:26<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:26<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:32<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:32<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:33<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:33<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:33<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:39<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:39<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:39<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:39<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:40<01:06,  3.03it/s] 60%|██████    | 301/500 [03:46<03:54,  1.18s/it] 61%|██████    | 303/500 [03:46<02:46,  1.18it/s] 61%|██████    | 305/500 [03:46<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:46<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:46<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:53<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:53<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:53<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:53<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:53<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:59<03:29,  1.17s/it] 65%|██████▍   | 323/500 [04:00<02:28,  1.19it/s] 65%|██████▌   | 325/500 [04:00<01:46,  1.65it/s] 65%|██████▌   | 327/500 [04:00<01:16,  2.25it/s] 66%|██████▌   | 329/500 [04:00<00:56,  3.02it/s] 66%|██████▌   | 331/500 [04:06<03:17,  1.17s/it] 67%|██████▋   | 333/500 [04:06<02:20,  1.19it/s] 67%|██████▋   | 335/500 [04:07<01:40,  1.65it/s] 67%|██████▋   | 337/500 [04:07<01:12,  2.25it/s]Epoch:  272  	Training Loss: 0.00027084804605692625
Test Loss:  0.0003776529338210821
Valid Loss:  0.00027346902061253786
Epoch:  273  	Training Loss: 0.00026978529058396816
Test Loss:  0.0003766630543395877
Valid Loss:  0.0002722499775700271
Epoch:  274  	Training Loss: 0.0002687551605049521
Test Loss:  0.0003756910446099937
Valid Loss:  0.00027124560438096523
Epoch:  275  	Training Loss: 0.00026773964054882526
Test Loss:  0.00037456786958500743
Valid Loss:  0.0002701841003727168
Epoch:  276  	Training Loss: 0.000266733521129936
Test Loss:  0.00037340883864089847
Valid Loss:  0.00026915635680779815
Epoch:  277  	Training Loss: 0.00026573738432489336
Test Loss:  0.0003722017863765359
Valid Loss:  0.0002681249170564115
Epoch:  278  	Training Loss: 0.00026474977494217455
Test Loss:  0.0003709792799782008
Valid Loss:  0.0002671077963896096
Epoch:  279  	Training Loss: 0.0002637704601511359
Test Loss:  0.000369742454495281
Valid Loss:  0.00026609632186591625
Epoch:  280  	Training Loss: 0.00026279845042154193
Test Loss:  0.00036850018659606576
Valid Loss:  0.0002650944807101041
Epoch:  281  	Training Loss: 0.00026183557929471135
Test Loss:  0.0003672600432764739
Valid Loss:  0.0002641005557961762
Epoch:  282  	Training Loss: 0.0002608793438412249
Test Loss:  0.00036558479769155383
Valid Loss:  0.00026334146969020367
Epoch:  283  	Training Loss: 0.0002604570472612977
Test Loss:  0.0003640911018010229
Valid Loss:  0.0002631170500535518
Epoch:  284  	Training Loss: 0.0002600850712042302
Test Loss:  0.00036277028266340494
Valid Loss:  0.0002628053189255297
Epoch:  285  	Training Loss: 0.000259736756561324
Test Loss:  0.0003615731548052281
Valid Loss:  0.000262527639279142
Epoch:  286  	Training Loss: 0.0002594029065221548
Test Loss:  0.00036047707544639707
Valid Loss:  0.00026225042529404163
Epoch:  287  	Training Loss: 0.0002590757212601602
Test Loss:  0.00035947110154666007
Valid Loss:  0.0002619709703139961
Epoch:  288  	Training Loss: 0.0002587585477158427
Test Loss:  0.00035854277666658163
Valid Loss:  0.00026170106139034033
Epoch:  289  	Training Loss: 0.0002584471076261252
Test Loss:  0.0003576655872166157
Valid Loss:  0.0002614232653286308
Epoch:  290  	Training Loss: 0.0002581265871413052
Test Loss:  0.000356845062924549
Valid Loss:  0.00026115411310456693
Epoch:  291  	Training Loss: 0.0002578109269961715
Test Loss:  0.00035607421887107193
Valid Loss:  0.0002608901122584939
Epoch:  292  	Training Loss: 0.00025749937049113214
Test Loss:  0.0003575346199795604
Valid Loss:  0.0002617531281430274
Epoch:  293  	Training Loss: 0.00025698303943499923
Test Loss:  0.00035787216620519757
Valid Loss:  0.0002618648868519813
Epoch:  294  	Training Loss: 0.00025688152527436614
Test Loss:  0.00035797496093437076
Valid Loss:  0.00026180423446930945
Epoch:  295  	Training Loss: 0.0002567867049947381
Test Loss:  0.0003580054035410285
Valid Loss:  0.00026170394266955554
Epoch:  296  	Training Loss: 0.0002566933399066329
Test Loss:  0.00035800569457933307
Valid Loss:  0.0002615946577861905
Epoch:  297  	Training Loss: 0.00025660201208665967
Test Loss:  0.0003579943149816245
Valid Loss:  0.00026148694450967014
Epoch:  298  	Training Loss: 0.00025651114992797375
Test Loss:  0.0003579870390240103
Valid Loss:  0.0002613827236928046
Epoch:  299  	Training Loss: 0.000256420491496101
Test Loss:  0.0003579737967811525
Valid Loss:  0.00026127693126909435
Epoch:  300  	Training Loss: 0.00025633093900978565
Test Loss:  0.00035795330768451095
Valid Loss:  0.0002611710224300623
Epoch:  301  	Training Loss: 0.00025624377303756773
Test Loss:  0.0003579322947189212
Valid Loss:  0.00026106712175533175
Epoch:  302  	Training Loss: 0.0002561585861258209
Test Loss:  0.0003567081002984196
Valid Loss:  0.0002593889948911965
Epoch:  303  	Training Loss: 0.0002554117818363011
Test Loss:  0.0003559608303476125
Valid Loss:  0.0002586196642369032
Epoch:  304  	Training Loss: 0.00025495485169813037
Test Loss:  0.0003553114947862923
Valid Loss:  0.0002580804575700313
Epoch:  305  	Training Loss: 0.00025453168200328946
Test Loss:  0.00035469356225803494
Valid Loss:  0.0002576106635387987
Epoch:  306  	Training Loss: 0.0002541138674132526
Test Loss:  0.00035409023985266685
Valid Loss:  0.00025716485106386244
Epoch:  307  	Training Loss: 0.00025369884679093957
Test Loss:  0.00035349559038877487
Valid Loss:  0.0002567269839346409
Epoch:  308  	Training Loss: 0.0002532849321141839
Test Loss:  0.00035290460800752044
Valid Loss:  0.00025628821458667517
Epoch:  309  	Training Loss: 0.00025286871823482215
Test Loss:  0.0003523200284689665
Valid Loss:  0.00025585340335965157
Epoch:  310  	Training Loss: 0.00025245401775464416
Test Loss:  0.00035174156073480844
Valid Loss:  0.00025542074581608176
Epoch:  311  	Training Loss: 0.00025204120902344584
Test Loss:  0.0003511687973514199
Valid Loss:  0.0002549900091253221
Epoch:  312  	Training Loss: 0.00025163026293739676
Test Loss:  0.0003505311906337738
Valid Loss:  0.00025467557134106755
Epoch:  313  	Training Loss: 0.00025127828121185303
Test Loss:  0.00034991296706721187
Valid Loss:  0.0002543359587434679
Epoch:  314  	Training Loss: 0.0002509308105800301
Test Loss:  0.0003493126714602113
Valid Loss:  0.00025398502475582063
Epoch:  315  	Training Loss: 0.0002505849697627127
Test Loss:  0.00034872733522206545
Valid Loss:  0.00025362998712807894
Epoch:  316  	Training Loss: 0.0002502411662135273
Test Loss:  0.0003481549210846424
Valid Loss:  0.00025327439652755857
Epoch:  317  	Training Loss: 0.00024989782832562923
Test Loss:  0.00034759531263262033
Valid Loss:  0.00025291898055002093
Epoch:  318  	Training Loss: 0.00024955515982583165
Test Loss:  0.00034704309655353427
Valid Loss:  0.0002525635063648224
Epoch:  319  	Training Loss: 0.00024921412114053965
Test Loss:  0.00034650065936148167
Valid Loss:  0.00025220931274816394
Epoch:  320  	Training Loss: 0.0002488737227395177
Test Loss:  0.00034596206387504935
Valid Loss:  0.0002518558467272669
Epoch:  321  	Training Loss: 0.0002485336735844612
Test Loss:  0.00034543266519904137
Valid Loss:  0.00025150421424768865
Epoch:  322  	Training Loss: 0.00024819388636387885
Test Loss:  0.0003436635888647288
Valid Loss:  0.000250620418228209
Epoch:  323  	Training Loss: 0.0002475671353749931
Test Loss:  0.0003420590655878186
Valid Loss:  0.0002498373214621097
Epoch:  324  	Training Loss: 0.00024699344066902995
Test Loss:  0.00034062121994793415
Valid Loss:  0.0002491223276592791
Epoch:  325  	Training Loss: 0.0002464700082782656
Test Loss:  0.0003393389342818409
Valid Loss:  0.00024847022723406553
Epoch:  326  	Training Loss: 0.0002459912502672523
Test Loss:  0.0003381943970452994
Valid Loss:  0.0002478649257682264
Epoch:  327  	Training Loss: 0.00024554773699492216
Test Loss:  0.0003371715429238975
Valid Loss:  0.0002472915221005678
Epoch:  328  	Training Loss: 0.00024513062089681625
Test Loss:  0.0003362551797181368
Valid Loss:  0.00024675429449416697
Epoch:  329  	Training Loss: 0.00024473946541547775
Test Loss:  0.00033542816527187824
Valid Loss:  0.00024623796343803406
Epoch:  330  	Training Loss: 0.00024436257081106305
Test Loss:  0.00033468566834926605
Valid Loss:  0.0002457437221892178
Epoch:  331  	Training Loss: 0.0002440040116198361
Test Loss:  0.0003340159892104566
Valid Loss:  0.00024527014466002584
Epoch:  332  	Training Loss: 0.00024366147408727556
Test Loss:  0.0003337740199640393
Valid Loss:  0.00024507413036189973
Epoch:  333  	Training Loss: 0.0002435117494314909
Test Loss:  0.00033352928585372865
Valid Loss:  0.00024485221365466714
Epoch:  334  	Training Loss: 0.00024336669594049454
Test Loss:  0.0003332964261062443
Valid Loss:  0.0002446356520522386
Epoch:  335  	Training Loss: 0.00024322542594745755
Test Loss:  0.00033307401463389397
Valid Loss:  0.0002444233396090567
Epoch:  336  	Training Loss: 0.0002430878666928038
Test Loss:  0.00033286274992860854
Valid Loss:  0.000244215945713222
Epoch:  337  	Training Loss: 0.00024295352341141552
Test Loss:  0.0003326613223180175
Valid Loss:  0.00024401220434810966
Epoch:  338  	Training Loss: 0.00024282319645863026
Test Loss:  0.00033247063402086496
Valid Loss:  0.00024381311959587038
Epoch:  339  	Training Loss: 0.00024269577988889068
 68%|██████▊   | 339/500 [04:07<00:53,  3.03it/s] 68%|██████▊   | 341/500 [04:13<03:04,  1.16s/it] 69%|██████▊   | 343/500 [04:13<02:11,  1.20it/s] 69%|██████▉   | 345/500 [04:13<01:33,  1.66it/s] 69%|██████▉   | 347/500 [04:13<01:07,  2.26it/s] 70%|██████▉   | 349/500 [04:14<00:49,  3.04it/s] 70%|███████   | 351/500 [04:20<02:53,  1.16s/it] 71%|███████   | 353/500 [04:20<02:02,  1.20it/s] 71%|███████   | 355/500 [04:20<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:20<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:20<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:27<02:41,  1.17s/it] 73%|███████▎  | 363/500 [04:27<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:27<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:27<00:58,  2.26it/s] 74%|███████▍  | 369/500 [04:27<00:43,  3.04it/s] 74%|███████▍  | 371/500 [04:33<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:33<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:34<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:34<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:34<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:40<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:40<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:40<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:41<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:41<00:36,  3.03it/s] 78%|███████▊  | 391/500 [04:47<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:47<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:47<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:47<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:48<00:33,  3.00it/s] 80%|████████  | 401/500 [04:54<01:57,  1.19s/it] 81%|████████  | 403/500 [04:54<01:22,  1.17it/s] 81%|████████  | 405/500 [04:54<00:58,  1.62it/s]Test Loss:  0.0003322888514958322
Valid Loss:  0.0002436176291666925
Epoch:  340  	Training Loss: 0.00024256987671833485
Test Loss:  0.0003321117255836725
Valid Loss:  0.00024342061078641564
Epoch:  341  	Training Loss: 0.0002424427366349846
Test Loss:  0.0003319435636512935
Valid Loss:  0.00024322819081135094
Epoch:  342  	Training Loss: 0.00024231852148659527
Test Loss:  0.0003329481987748295
Valid Loss:  0.00024267917615361512
Epoch:  343  	Training Loss: 0.00024112118990160525
Test Loss:  0.0003333365893922746
Valid Loss:  0.00024192694399971515
Epoch:  344  	Training Loss: 0.00024022480647545308
Test Loss:  0.00033352005993947387
Valid Loss:  0.0002411273744655773
Epoch:  345  	Training Loss: 0.00023940898245200515
Test Loss:  0.0003336106601636857
Valid Loss:  0.00024034673697315156
Epoch:  346  	Training Loss: 0.00023866297851782292
Test Loss:  0.00033365876879543066
Valid Loss:  0.00023960578255355358
Epoch:  347  	Training Loss: 0.00023797209723852575
Test Loss:  0.0003336770460009575
Valid Loss:  0.0002388947323197499
Epoch:  348  	Training Loss: 0.00023732639965601265
Test Loss:  0.0003336658119224012
Valid Loss:  0.00023819755006115884
Epoch:  349  	Training Loss: 0.00023671485541854054
Test Loss:  0.00033366045681759715
Valid Loss:  0.00023753824643790722
Epoch:  350  	Training Loss: 0.0002361215592827648
Test Loss:  0.000333612784743309
Valid Loss:  0.00023689409135840833
Epoch:  351  	Training Loss: 0.0002355495234951377
Test Loss:  0.00033356534549966455
Valid Loss:  0.0002362745872233063
Epoch:  352  	Training Loss: 0.00023498033988289535
Test Loss:  0.0003327206941321492
Valid Loss:  0.00023621288710273802
Epoch:  353  	Training Loss: 0.00023483327822759748
Test Loss:  0.0003320029645692557
Valid Loss:  0.00023613989469595253
Epoch:  354  	Training Loss: 0.00023470833548344672
Test Loss:  0.0003313817724119872
Valid Loss:  0.00023605603200849146
Epoch:  355  	Training Loss: 0.00023459785734303296
Test Loss:  0.0003308362211100757
Valid Loss:  0.00023596326354891062
Epoch:  356  	Training Loss: 0.00023449747823178768
Test Loss:  0.00033034791704267263
Valid Loss:  0.0002358648052904755
Epoch:  357  	Training Loss: 0.00023440434597432613
Test Loss:  0.00032990597537718713
Valid Loss:  0.000235760206123814
Epoch:  358  	Training Loss: 0.00023431720910593867
Test Loss:  0.0003295011701993644
Valid Loss:  0.0002356531476834789
Epoch:  359  	Training Loss: 0.00023423475795425475
Test Loss:  0.00032912593451328576
Valid Loss:  0.0002355444012209773
Epoch:  360  	Training Loss: 0.00023415623581968248
Test Loss:  0.00032877575722523034
Valid Loss:  0.00023543483985122293
Epoch:  361  	Training Loss: 0.0002340814971830696
Test Loss:  0.00032844720408320427
Valid Loss:  0.00023532549676019698
Epoch:  362  	Training Loss: 0.00023401013459078968
Test Loss:  0.00032920256489887834
Valid Loss:  0.00023498879454564303
Epoch:  363  	Training Loss: 0.00023325771326199174
Test Loss:  0.0003293337067589164
Valid Loss:  0.0002343598462175578
Epoch:  364  	Training Loss: 0.00023260689340531826
Test Loss:  0.0003292998590040952
Valid Loss:  0.00023372381110675633
Epoch:  365  	Training Loss: 0.00023199888528324664
Test Loss:  0.0003291764878667891
Valid Loss:  0.0002331157447770238
Epoch:  366  	Training Loss: 0.0002314214943908155
Test Loss:  0.0003289810265414417
Valid Loss:  0.00023253331892192364
Epoch:  367  	Training Loss: 0.0002308670518686995
Test Loss:  0.00032872328301891685
Valid Loss:  0.0002319702471140772
Epoch:  368  	Training Loss: 0.00023033010074868798
Test Loss:  0.0003284108533989638
Valid Loss:  0.0002314220619155094
Epoch:  369  	Training Loss: 0.00022981371148489416
Test Loss:  0.000328201858792454
Valid Loss:  0.0002308676193933934
Epoch:  370  	Training Loss: 0.00022932502906769514
Test Loss:  0.0003279574157204479
Valid Loss:  0.00023033356410451233
Epoch:  371  	Training Loss: 0.0002288389950990677
Test Loss:  0.00032762589398771524
Valid Loss:  0.00022979622008278966
Epoch:  372  	Training Loss: 0.0002283503272337839
Test Loss:  0.0003257063217461109
Valid Loss:  0.00022931727289687842
Epoch:  373  	Training Loss: 0.00022762140724807978
Test Loss:  0.0003241621016059071
Valid Loss:  0.00022872262343298644
Epoch:  374  	Training Loss: 0.0002269609394716099
Test Loss:  0.0003228859568480402
Valid Loss:  0.00022809859365224838
Epoch:  375  	Training Loss: 0.00022632969194091856
Test Loss:  0.0003218366764485836
Valid Loss:  0.0002274823491461575
Epoch:  376  	Training Loss: 0.00022571854060515761
Test Loss:  0.00032091065077111125
Valid Loss:  0.00022684648865833879
Epoch:  377  	Training Loss: 0.00022511465067509562
Test Loss:  0.00032008509151637554
Valid Loss:  0.00022621653624810278
Epoch:  378  	Training Loss: 0.00022451879340223968
Test Loss:  0.00031933828722685575
Valid Loss:  0.0002255959261674434
Epoch:  379  	Training Loss: 0.0002239295281469822
Test Loss:  0.0003186403773725033
Valid Loss:  0.00022497476311400533
Epoch:  380  	Training Loss: 0.00022333601373247802
Test Loss:  0.00031797829433344305
Valid Loss:  0.00022435681603383273
Epoch:  381  	Training Loss: 0.00022275085211731493
Test Loss:  0.0003173415607307106
Valid Loss:  0.00022374570835381746
Epoch:  382  	Training Loss: 0.00022217360674403608
Test Loss:  0.00031699647661298513
Valid Loss:  0.00022317570983432233
Epoch:  383  	Training Loss: 0.00022173189790919423
Test Loss:  0.00031670962926000357
Valid Loss:  0.00022272637579590082
Epoch:  384  	Training Loss: 0.00022130757861305028
Test Loss:  0.0003163825022056699
Valid Loss:  0.00022230760077945888
Epoch:  385  	Training Loss: 0.00022089079720899463
Test Loss:  0.00031600744114257395
Valid Loss:  0.00022190110757946968
Epoch:  386  	Training Loss: 0.0002204788033850491
Test Loss:  0.00031561218202114105
Valid Loss:  0.00022151008306536824
Epoch:  387  	Training Loss: 0.00022006750805303454
Test Loss:  0.0003151781565975398
Valid Loss:  0.00022112418082542717
Epoch:  388  	Training Loss: 0.00021966372150927782
Test Loss:  0.0003147234092466533
Valid Loss:  0.0002207439101766795
Epoch:  389  	Training Loss: 0.0002192656829720363
Test Loss:  0.00031424383632838726
Valid Loss:  0.0002203713811468333
Epoch:  390  	Training Loss: 0.00021887317416258156
Test Loss:  0.00031376947299577296
Valid Loss:  0.00022001037723384798
Epoch:  391  	Training Loss: 0.00021848654432687908
Test Loss:  0.00031327505712397397
Valid Loss:  0.0002196451387135312
Epoch:  392  	Training Loss: 0.00021810007456224412
Test Loss:  0.0003122023190371692
Valid Loss:  0.00021842219575773925
Epoch:  393  	Training Loss: 0.00021759716037195176
Test Loss:  0.00031180380028672516
Valid Loss:  0.00021799537353217602
Epoch:  394  	Training Loss: 0.00021725581609643996
Test Loss:  0.0003114424762316048
Valid Loss:  0.00021761146490462124
Epoch:  395  	Training Loss: 0.00021691794972866774
Test Loss:  0.000311086856527254
Valid Loss:  0.00021723282407037914
Epoch:  396  	Training Loss: 0.00021658261539414525
Test Loss:  0.0003107341181021184
Valid Loss:  0.00021685834508389235
Epoch:  397  	Training Loss: 0.00021624968212563545
Test Loss:  0.00031038548331707716
Valid Loss:  0.00021648660185746849
Epoch:  398  	Training Loss: 0.00021591875702142715
Test Loss:  0.0003100393805652857
Valid Loss:  0.0002161181764677167
Epoch:  399  	Training Loss: 0.00021559040760621428
Test Loss:  0.0003096963628195226
Valid Loss:  0.00021575254504568875
Epoch:  400  	Training Loss: 0.00021526424097828567
Test Loss:  0.0003093565464951098
Valid Loss:  0.00021538964938372374
Epoch:  401  	Training Loss: 0.00021494037355296314
Test Loss:  0.00030901937861926854
Valid Loss:  0.0002150295622413978
Epoch:  402  	Training Loss: 0.00021461909636855125
Test Loss:  0.0003071895625907928
Valid Loss:  0.0002148066705558449
Epoch:  403  	Training Loss: 0.00021395698422566056
Test Loss:  0.00030579164740629494
Valid Loss:  0.0002142245211871341
Epoch:  404  	Training Loss: 0.0002133721427526325
Test Loss:  0.0003045378252863884
Valid Loss:  0.00021366230794228613
Epoch:  405  	Training Loss: 0.00021280199871398509
Test Loss:  0.00030339276418089867
Valid Loss:  0.0002131093351636082
Epoch:  406  	Training Loss: 0.0002122411533491686
Test Loss:   81%|████████▏ | 407/500 [04:54<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:54<00:30,  2.99it/s] 82%|████████▏ | 411/500 [05:01<01:44,  1.17s/it] 83%|████████▎ | 413/500 [05:01<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:01<00:51,  1.64it/s] 83%|████████▎ | 417/500 [05:01<00:37,  2.24it/s] 84%|████████▍ | 419/500 [05:01<00:26,  3.01it/s] 84%|████████▍ | 421/500 [05:07<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:08<01:04,  1.19it/s] 85%|████████▌ | 425/500 [05:08<00:45,  1.64it/s] 85%|████████▌ | 427/500 [05:08<00:32,  2.25it/s] 86%|████████▌ | 429/500 [05:08<00:23,  3.02it/s] 86%|████████▌ | 431/500 [05:14<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:14<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:15<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:15<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:15<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:21<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:21<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:21<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:22<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:22<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:28<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:28<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:28<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:28<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:29<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:35<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:35<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:35<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:35<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:35<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:42<00:33,  1.17s/it]0.0003023303288500756
Valid Loss:  0.00021256011677905917
Epoch:  407  	Training Loss: 0.00021168508101254702
Test Loss:  0.00030132976826280355
Valid Loss:  0.00021201753406785429
Epoch:  408  	Training Loss: 0.00021113229740876704
Test Loss:  0.0003003905585501343
Valid Loss:  0.00021147483494132757
Epoch:  409  	Training Loss: 0.0002105734165525064
Test Loss:  0.00029948586598038673
Valid Loss:  0.0002109283668687567
Epoch:  410  	Training Loss: 0.00021001663117203861
Test Loss:  0.0002986082690767944
Valid Loss:  0.00021038594422861934
Epoch:  411  	Training Loss: 0.00020946390577591956
Test Loss:  0.00029775098664686084
Valid Loss:  0.0002098440018016845
Epoch:  412  	Training Loss: 0.00020891505118925124
Test Loss:  0.00029712417745031416
Valid Loss:  0.00020937301451340318
Epoch:  413  	Training Loss: 0.0002085240848828107
Test Loss:  0.00029653028468601406
Valid Loss:  0.0002089996269205585
Epoch:  414  	Training Loss: 0.00020813901210203767
Test Loss:  0.0002959307748824358
Valid Loss:  0.00020862850942648947
Epoch:  415  	Training Loss: 0.00020775632583536208
Test Loss:  0.00029532710323110223
Valid Loss:  0.0002082592254737392
Epoch:  416  	Training Loss: 0.00020737614249810576
Test Loss:  0.0002947214525192976
Valid Loss:  0.0002078927936963737
Epoch:  417  	Training Loss: 0.00020699886954389513
Test Loss:  0.0002941154525615275
Valid Loss:  0.000207529024919495
Epoch:  418  	Training Loss: 0.00020662389579229057
Test Loss:  0.0002935082884505391
Valid Loss:  0.00020716756989713758
Epoch:  419  	Training Loss: 0.00020625183242373168
Test Loss:  0.00029290240490809083
Valid Loss:  0.00020680896705016494
Epoch:  420  	Training Loss: 0.0002058821264654398
Test Loss:  0.00029229786014184356
Valid Loss:  0.0002064520085696131
Epoch:  421  	Training Loss: 0.00020551486522890627
Test Loss:  0.00029169462504796684
Valid Loss:  0.00020609796047210693
Epoch:  422  	Training Loss: 0.00020514975767582655
Test Loss:  0.00029147753957659006
Valid Loss:  0.00020569624030031264
Epoch:  423  	Training Loss: 0.00020495109492912889
Test Loss:  0.0002914068172685802
Valid Loss:  0.0002054782526101917
Epoch:  424  	Training Loss: 0.00020477475482039154
Test Loss:  0.0002913458156399429
Valid Loss:  0.00020528785535134375
Epoch:  425  	Training Loss: 0.0002046066365437582
Test Loss:  0.0002912825730163604
Valid Loss:  0.00020510960894171149
Epoch:  426  	Training Loss: 0.0002044424181804061
Test Loss:  0.0002912136842496693
Valid Loss:  0.00020493647025432438
Epoch:  427  	Training Loss: 0.00020428259449545294
Test Loss:  0.0002911242190748453
Valid Loss:  0.00020476373902056366
Epoch:  428  	Training Loss: 0.00020413004676811397
Test Loss:  0.0002910277107730508
Valid Loss:  0.00020459511142689735
Epoch:  429  	Training Loss: 0.00020398097694851458
Test Loss:  0.0002909294271375984
Valid Loss:  0.00020443146058823913
Epoch:  430  	Training Loss: 0.00020383379887789488
Test Loss:  0.0002908270398620516
Valid Loss:  0.00020427042909432203
Epoch:  431  	Training Loss: 0.00020368941477499902
Test Loss:  0.00029071635799482465
Valid Loss:  0.0002041109837591648
Epoch:  432  	Training Loss: 0.00020354693697299808
Test Loss:  0.00029047299176454544
Valid Loss:  0.0002042377891484648
Epoch:  433  	Training Loss: 0.00020339862385299057
Test Loss:  0.0002902087289839983
Valid Loss:  0.0002043335698544979
Epoch:  434  	Training Loss: 0.00020331300038378686
Test Loss:  0.00028995127649977803
Valid Loss:  0.000204398762434721
Epoch:  435  	Training Loss: 0.0002032534102909267
Test Loss:  0.0002896937367040664
Valid Loss:  0.00020443415269255638
Epoch:  436  	Training Loss: 0.0002032056509051472
Test Loss:  0.0002894449862651527
Valid Loss:  0.0002044491411652416
Epoch:  437  	Training Loss: 0.00020316378504503518
Test Loss:  0.00028921145712956786
Valid Loss:  0.00020445096015464514
Epoch:  438  	Training Loss: 0.0002031253243330866
Test Loss:  0.00028899486642330885
Valid Loss:  0.00020444361143745482
Epoch:  439  	Training Loss: 0.00020308856619521976
Test Loss:  0.0002887954469770193
Valid Loss:  0.00020443032553885132
Epoch:  440  	Training Loss: 0.00020305361249484122
Test Loss:  0.0002886117435991764
Valid Loss:  0.0002044130233116448
Epoch:  441  	Training Loss: 0.00020301935728639364
Test Loss:  0.00028844241751357913
Valid Loss:  0.0002043929707724601
Epoch:  442  	Training Loss: 0.00020298597519285977
Test Loss:  0.00028782119625248015
Valid Loss:  0.0002037830709014088
Epoch:  443  	Training Loss: 0.00020267633954063058
Test Loss:  0.00028726953314617276
Valid Loss:  0.0002034257195191458
Epoch:  444  	Training Loss: 0.0002024275454459712
Test Loss:  0.00028675273642875254
Valid Loss:  0.00020315524307079613
Epoch:  445  	Training Loss: 0.00020218532881699502
Test Loss:  0.00028625386767089367
Valid Loss:  0.00020291373948566616
Epoch:  446  	Training Loss: 0.00020194711396470666
Test Loss:  0.0002857699291780591
Valid Loss:  0.0002026846632361412
Epoch:  447  	Training Loss: 0.00020171122741885483
Test Loss:  0.0002852993493434042
Valid Loss:  0.00020246040367055684
Epoch:  448  	Training Loss: 0.00020147737814113498
Test Loss:  0.00028484119684435427
Valid Loss:  0.00020223947649355978
Epoch:  449  	Training Loss: 0.0002012457698583603
Test Loss:  0.00028439637389965355
Valid Loss:  0.0002020220854319632
Epoch:  450  	Training Loss: 0.00020101747941225767
Test Loss:  0.0002839613880496472
Valid Loss:  0.0002018072991631925
Epoch:  451  	Training Loss: 0.00020079262321814895
Test Loss:  0.0002835369959939271
Valid Loss:  0.0002015951758949086
Epoch:  452  	Training Loss: 0.00020057015353813767
Test Loss:  0.00028273017960600555
Valid Loss:  0.00020139124535489827
Epoch:  453  	Training Loss: 0.00020039276569150388
Test Loss:  0.0002819923684000969
Valid Loss:  0.00020120746921747923
Epoch:  454  	Training Loss: 0.0002002307155635208
Test Loss:  0.00028131873114034534
Valid Loss:  0.00020103785209357738
Epoch:  455  	Training Loss: 0.00020008150022476912
Test Loss:  0.00028070155531167984
Valid Loss:  0.00020087756274733692
Epoch:  456  	Training Loss: 0.00019994020112790167
Test Loss:  0.00028013743576593697
Valid Loss:  0.0002007271978072822
Epoch:  457  	Training Loss: 0.00019980854995083064
Test Loss:  0.00027962285093963146
Valid Loss:  0.0002005849382840097
Epoch:  458  	Training Loss: 0.00019968519336543977
Test Loss:  0.00027915218379348516
Valid Loss:  0.0002004503330681473
Epoch:  459  	Training Loss: 0.00019956883625127375
Test Loss:  0.00027872188366018236
Valid Loss:  0.0002003213157877326
Epoch:  460  	Training Loss: 0.00019945840176660568
Test Loss:  0.0002783284871838987
Valid Loss:  0.0002001980901695788
Epoch:  461  	Training Loss: 0.00019935358432121575
Test Loss:  0.0002779672504402697
Valid Loss:  0.0002000796521315351
Epoch:  462  	Training Loss: 0.00019925282686017454
Test Loss:  0.00027793843764811754
Valid Loss:  0.00019995994807686657
Epoch:  463  	Training Loss: 0.00019899448670912534
Test Loss:  0.00027795048663392663
Valid Loss:  0.0001998288935283199
Epoch:  464  	Training Loss: 0.0001987614086829126
Test Loss:  0.00027798008522950113
Valid Loss:  0.00019968808919657022
Epoch:  465  	Training Loss: 0.00019854515267070383
Test Loss:  0.00027801323449239135
Valid Loss:  0.00019953960145357996
Epoch:  466  	Training Loss: 0.00019834036356769502
Test Loss:  0.0002780416398309171
Valid Loss:  0.00019938507466576993
Epoch:  467  	Training Loss: 0.0001981439854716882
Test Loss:  0.0002780600334517658
Valid Loss:  0.0001992265461012721
Epoch:  468  	Training Loss: 0.00019795369007624686
Test Loss:  0.00027806556317955256
Valid Loss:  0.00019905462977476418
Epoch:  469  	Training Loss: 0.00019776762928813696
Test Loss:  0.00027805654099211097
Valid Loss:  0.00019887748931068927
Epoch:  470  	Training Loss: 0.0001975853811018169
Test Loss:  0.0002780342474579811
Valid Loss:  0.00019869960669893771
Epoch:  471  	Training Loss: 0.00019740709103643894
Test Loss:  0.00027799667441286147
Valid Loss:  0.00019852137484122068
Epoch:  472  	Training Loss: 0.0001972298778127879
Test Loss:  0.0002778622438199818
Valid Loss:  0.0001979826483875513
Epoch:  473  	Training Loss: 0.00019682789570651948
Test Loss:  0.00027776602655649185
 95%|█████████▍| 473/500 [05:42<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:42<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:42<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:42<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:48<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:49<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:49<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:49<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:49<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:55<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:56<00:06,  1.17it/s] 99%|█████████▉| 495/500 [05:56<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:56<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:56<00:00,  2.97it/s]100%|██████████| 500/500 [05:56<00:00,  1.40it/s]
Valid Loss:  0.00019752873049583286
Epoch:  474  	Training Loss: 0.00019644497660920024
Test Loss:  0.00027767440769821405
Valid Loss:  0.00019712078210432082
Epoch:  475  	Training Loss: 0.00019607522699516267
Test Loss:  0.00027758083888329566
Valid Loss:  0.0001967361313290894
Epoch:  476  	Training Loss: 0.00019571243319660425
Test Loss:  0.00027747376589104533
Valid Loss:  0.0001963628747034818
Epoch:  477  	Training Loss: 0.00019535924366209656
Test Loss:  0.00027735409094020724
Valid Loss:  0.00019599635561462492
Epoch:  478  	Training Loss: 0.00019500711641740054
Test Loss:  0.0002772193984128535
Valid Loss:  0.00019563146634027362
Epoch:  479  	Training Loss: 0.0001946588308783248
Test Loss:  0.00027707236586138606
Valid Loss:  0.00019526746473275125
Epoch:  480  	Training Loss: 0.00019431239343248308
Test Loss:  0.0002769132552202791
Valid Loss:  0.00019490343402139843
Epoch:  481  	Training Loss: 0.0001939645444508642
Test Loss:  0.0002767409314401448
Valid Loss:  0.00019454045104794204
Epoch:  482  	Training Loss: 0.0001936201297212392
Test Loss:  0.00027620623586699367
Valid Loss:  0.00019412215624470264
Epoch:  483  	Training Loss: 0.0001932870363816619
Test Loss:  0.00027582631446421146
Valid Loss:  0.00019386797794140875
Epoch:  484  	Training Loss: 0.0001929742138599977
Test Loss:  0.0002753926964942366
Valid Loss:  0.0001935954496730119
Epoch:  485  	Training Loss: 0.00019267742754891515
Test Loss:  0.00027491935179568827
Valid Loss:  0.0001933009480126202
Epoch:  486  	Training Loss: 0.0001923835079651326
Test Loss:  0.00027444050647318363
Valid Loss:  0.00019301430438645184
Epoch:  487  	Training Loss: 0.00019209168385714293
Test Loss:  0.0002739523770287633
Valid Loss:  0.00019272837380412966
Epoch:  488  	Training Loss: 0.00019180183880962431
Test Loss:  0.00027345953276380897
Valid Loss:  0.0001924447569763288
Epoch:  489  	Training Loss: 0.0001915138855110854
Test Loss:  0.00027296203188598156
Valid Loss:  0.00019216304644942284
Epoch:  490  	Training Loss: 0.00019122802768833935
Test Loss:  0.0002724819933064282
Valid Loss:  0.00019188533769920468
Epoch:  491  	Training Loss: 0.00019095146853942424
Test Loss:  0.0002720843185670674
Valid Loss:  0.00019160886586178094
Epoch:  492  	Training Loss: 0.0001906813122332096
Test Loss:  0.000272683915682137
Valid Loss:  0.00019136136688757688
Epoch:  493  	Training Loss: 0.00019002315821126103
Test Loss:  0.0002721041382756084
Valid Loss:  0.0001906431425595656
Epoch:  494  	Training Loss: 0.00018944703333545476
Test Loss:  0.0002717216848395765
Valid Loss:  0.00019004489877261221
Epoch:  495  	Training Loss: 0.00018888336489908397
Test Loss:  0.0002712831483222544
Valid Loss:  0.00018944447219837457
Epoch:  496  	Training Loss: 0.00018833219655789435
Test Loss:  0.0002708417596295476
Valid Loss:  0.0001888614788185805
Epoch:  497  	Training Loss: 0.00018779266974888742
Test Loss:  0.00027038660482503474
Valid Loss:  0.00018828935571946204
Epoch:  498  	Training Loss: 0.00018726362031884491
Test Loss:  0.0002699242322705686
Valid Loss:  0.00018772893236018717
Epoch:  499  	Training Loss: 0.00018674213788472116
Test Loss:  0.0002694738213904202
Valid Loss:  0.0001871800923254341
Epoch:  500  	Training Loss: 0.00018622273637447506
Test Loss:  0.00026901811361312866
Valid Loss:  0.00018663573428057134
seed is  2
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 15.87it/s]  1%|          | 4/500 [00:00<00:31, 15.87it/s]  1%|          | 6/500 [00:00<00:30, 16.31it/s]  2%|▏         | 8/500 [00:00<00:29, 16.41it/s]  2%|▏         | 10/500 [00:00<00:30, 16.30it/s]  2%|▏         | 12/500 [00:00<00:29, 16.43it/s]  3%|▎         | 14/500 [00:00<00:29, 16.48it/s]  3%|▎         | 16/500 [00:00<00:29, 16.53it/s]  4%|▎         | 18/500 [00:01<00:29, 16.55it/s]  4%|▍         | 20/500 [00:01<00:29, 16.48it/s]  4%|▍         | 22/500 [00:01<00:29, 16.25it/s]  5%|▍         | 24/500 [00:01<00:28, 16.42it/s]  5%|▌         | 26/500 [00:01<00:28, 16.52it/s]  6%|▌         | 28/500 [00:01<00:28, 16.55it/s]  6%|▌         | 30/500 [00:01<00:28, 16.62it/s]  6%|▋         | 32/500 [00:01<00:28, 16.53it/s]  7%|▋         | 34/500 [00:02<00:28, 16.59it/s]  7%|▋         | 36/500 [00:02<00:27, 16.71it/s]  8%|▊         | 38/500 [00:02<00:27, 16.68it/s]  8%|▊         | 40/500 [00:02<00:27, 16.55it/s]  8%|▊         | 42/500 [00:02<00:27, 16.44it/s]  9%|▉         | 44/500 [00:02<00:27, 16.49it/s]  9%|▉         | 46/500 [00:02<00:27, 16.56it/s] 10%|▉         | 48/500 [00:02<00:27, 16.54it/s] 10%|█         | 50/500 [00:03<00:27, 16.59it/s] 10%|█         | 52/500 [00:03<00:27, 16.14it/s] 11%|█         | 54/500 [00:03<00:27, 16.07it/s] 11%|█         | 56/500 [00:03<00:27, 16.19it/s] 12%|█▏        | 58/500 [00:03<00:30, 14.50it/s] 12%|█▏        | 60/500 [00:03<00:29, 15.09it/s] 12%|█▏        | 62/500 [00:03<00:28, 15.55it/s] 13%|█▎        | 64/500 [00:03<00:27, 15.90it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.11it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.28it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.40it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.36it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.46it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.52it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.57it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.46it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.49it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.48it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.56it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.47it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.52it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.48it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.45it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.34it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.51it/s] 20%|██        | 100/500 [00:06<00:24, 16.59it/s] 20%|██        | 102/500 [00:06<00:23, 16.73it/s] 21%|██        | 104/500 [00:06<00:23, 16.75it/s] 21%|██        | 106/500 [00:06<00:23, 16.74it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.71it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.72it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.75it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.70it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.66it/s] 24%|██▎       | 118/500 [00:07<00:22, 16.64it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.69it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.70it/s]Epoch:  1  	Training Loss: 0.043680835515260696
Test Loss:  8.152314186096191
Valid Loss:  8.537108421325684
Epoch:  2  	Training Loss: 8.414870262145996
Test Loss:  14005882.0
Valid Loss:  14091938.0
Epoch:  3  	Training Loss: 14070848.0
Test Loss:  2.9365279658851805e+34
Valid Loss:  2.9585907808533325e+34
Epoch:  4  	Training Loss: 2.953065359281986e+34
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:   25%|██▍       | 124/500 [00:07<00:22, 16.71it/s] 25%|██▌       | 126/500 [00:07<00:22, 16.71it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.69it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.59it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.61it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.51it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.56it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.60it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.55it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.59it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.65it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.70it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.70it/s] 30%|███       | 150/500 [00:09<00:20, 16.70it/s] 30%|███       | 152/500 [00:09<00:20, 16.62it/s] 31%|███       | 154/500 [00:09<00:20, 16.57it/s] 31%|███       | 156/500 [00:09<00:21, 16.35it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.35it/s] 32%|███▏      | 160/500 [00:09<00:22, 14.87it/s] 32%|███▏      | 162/500 [00:09<00:21, 15.37it/s] 33%|███▎      | 164/500 [00:10<00:22, 15.13it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.54it/s] 34%|███▎      | 168/500 [00:10<00:20, 15.85it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.89it/s] 34%|███▍      | 172/500 [00:10<00:20, 15.96it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.16it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.26it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.30it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.21it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.34it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.34it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.41it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.50it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.48it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.43it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.44it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.53it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.62it/s] 40%|████      | 200/500 [00:12<00:18, 16.64it/s] 40%|████      | 202/500 [00:12<00:17, 16.69it/s] 41%|████      | 204/500 [00:12<00:17, 16.69it/s] 41%|████      | 206/500 [00:12<00:17, 16.67it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.59it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.55it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.54it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.57it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.56it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.53it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.61it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.63it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.62it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.66it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.63it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.62it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.63it/s] 47%|████▋     | 234/500 [00:14<00:15, 16.63it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.57it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.60it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.62it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.67it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.63it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.40it/s]nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
 50%|████▉     | 248/500 [00:15<00:15, 16.01it/s] 50%|█████     | 250/500 [00:15<00:15, 16.20it/s] 50%|█████     | 252/500 [00:15<00:15, 16.38it/s] 51%|█████     | 254/500 [00:15<00:14, 16.50it/s] 51%|█████     | 256/500 [00:15<00:14, 16.58it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.59it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.61it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.65it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.54it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.98it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.13it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.25it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.35it/s] 55%|█████▍    | 274/500 [00:16<00:14, 16.00it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.21it/s] 56%|█████▌    | 278/500 [00:16<00:14, 15.70it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.20it/s] 56%|█████▋    | 282/500 [00:17<00:14, 15.51it/s] 57%|█████▋    | 284/500 [00:17<00:13, 15.82it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.00it/s] 58%|█████▊    | 288/500 [00:17<00:13, 16.18it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.30it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.38it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.45it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.35it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.47it/s] 60%|██████    | 300/500 [00:18<00:12, 16.52it/s] 60%|██████    | 302/500 [00:18<00:11, 16.57it/s] 61%|██████    | 304/500 [00:18<00:11, 16.57it/s] 61%|██████    | 306/500 [00:18<00:11, 16.60it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.59it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.59it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.58it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.59it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.58it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.53it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.52it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.53it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.47it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.49it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.41it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.49it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.36it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.45it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.50it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.50it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.58it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.50it/s] 69%|██████▉   | 344/500 [00:20<00:09, 16.57it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.58it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.60it/s] 70%|███████   | 350/500 [00:21<00:09, 16.58it/s] 70%|███████   | 352/500 [00:21<00:08, 16.46it/s] 71%|███████   | 354/500 [00:21<00:08, 16.58it/s] 71%|███████   | 356/500 [00:21<00:08, 16.58it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.47it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.48it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.57it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.66it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.70it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.77it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.78it/s]Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
 74%|███████▍  | 372/500 [00:22<00:07, 16.73it/s] 75%|███████▍  | 374/500 [00:22<00:07, 16.71it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.63it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.63it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.69it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.54it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.41it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.29it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.45it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.53it/s] 78%|███████▊  | 392/500 [00:23<00:06, 15.73it/s] 79%|███████▉  | 394/500 [00:24<00:06, 15.86it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.06it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.23it/s] 80%|████████  | 400/500 [00:24<00:06, 16.29it/s] 80%|████████  | 402/500 [00:24<00:05, 16.45it/s] 81%|████████  | 404/500 [00:24<00:05, 16.54it/s] 81%|████████  | 406/500 [00:24<00:05, 16.58it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.53it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.54it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.48it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.57it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.64it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.58it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.54it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.58it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.57it/s] 85%|████████▌ | 426/500 [00:25<00:04, 16.63it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.67it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.64it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.65it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.65it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.72it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.72it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.70it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.62it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.65it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.71it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.73it/s] 90%|█████████ | 450/500 [00:27<00:02, 16.74it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.74it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.75it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.69it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.64it/s] 92%|█████████▏| 460/500 [00:27<00:02, 16.65it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.72it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.72it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.79it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.82it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.78it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.78it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.70it/s] 95%|█████████▌| 476/500 [00:28<00:01, 16.56it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.56it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.58it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.51it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.36it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.46it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.50it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.40it/s] 98%|█████████▊| 492/500 [00:29<00:00, 16.39it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.42it/s]Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
 99%|█████████▉| 496/500 [00:30<00:00, 16.46it/s]100%|█████████▉| 498/500 [00:30<00:00, 16.58it/s]100%|██████████| 500/500 [00:30<00:00, 16.65it/s]100%|██████████| 500/500 [00:30<00:00, 16.45it/s]
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  2
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:26,  6.18s/it]  1%|          | 3/500 [00:06<13:42,  1.65s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:12<10:46,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:37,  3.00it/s]  6%|▌         | 31/500 [00:26<09:08,  1.17s/it]  7%|▋         | 33/500 [00:26<06:31,  1.19it/s]  7%|▋         | 35/500 [00:26<04:41,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:53,  1.16s/it]  9%|▊         | 43/500 [00:33<06:21,  1.20it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:20,  2.25it/s] 10%|▉         | 49/500 [00:33<02:28,  3.03it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:46<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:05,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:11,  2.26it/s] 14%|█▍        | 69/500 [00:47<02:21,  3.04it/s] 14%|█▍        | 71/500 [00:53<08:23,  1.17s/it]Epoch:  1  	Training Loss: 0.043680839240550995
Test Loss:  0.37584736943244934
Valid Loss:  0.4322704076766968
Epoch:  2  	Training Loss: 0.41109201312065125
Test Loss:  6.922115325927734
Valid Loss:  6.844599723815918
Epoch:  3  	Training Loss: 6.86712646484375
Test Loss:  0.033284395933151245
Valid Loss:  0.03623947501182556
Epoch:  4  	Training Loss: 0.03723285347223282
Test Loss:  0.033284373581409454
Valid Loss:  0.03623946011066437
Epoch:  5  	Training Loss: 0.03723283112049103
Test Loss:  0.033284351229667664
Valid Loss:  0.036239441484212875
Epoch:  6  	Training Loss: 0.037232816219329834
Test Loss:  0.03328433260321617
Valid Loss:  0.03623942285776138
Epoch:  7  	Training Loss: 0.03723279386758804
Test Loss:  0.03328430652618408
Valid Loss:  0.03623940423130989
Epoch:  8  	Training Loss: 0.037232767790555954
Test Loss:  0.03328428417444229
Valid Loss:  0.0362393856048584
Epoch:  9  	Training Loss: 0.03723274916410446
Test Loss:  0.0332842580974102
Valid Loss:  0.03623936325311661
Epoch:  10  	Training Loss: 0.03723272308707237
Test Loss:  0.03328423574566841
Valid Loss:  0.03623935580253601
Epoch:  11  	Training Loss: 0.03723270446062088
Test Loss:  0.03328420966863632
Valid Loss:  0.03623932972550392
Epoch:  12  	Training Loss: 0.03723268210887909
Test Loss:  0.03328375518321991
Valid Loss:  0.03623897582292557
Epoch:  13  	Training Loss: 0.03723227605223656
Test Loss:  0.0332832932472229
Valid Loss:  0.03623861446976662
Epoch:  14  	Training Loss: 0.03723186254501343
Test Loss:  0.033282823860645294
Valid Loss:  0.036238253116607666
Epoch:  15  	Training Loss: 0.037231456488370895
Test Loss:  0.033282361924648285
Valid Loss:  0.036237895488739014
Epoch:  16  	Training Loss: 0.03723105043172836
Test Loss:  0.033281899988651276
Valid Loss:  0.03623753413558006
Epoch:  17  	Training Loss: 0.03723064437508583
Test Loss:  0.033281438052654266
Valid Loss:  0.03623718023300171
Epoch:  18  	Training Loss: 0.0372302308678627
Test Loss:  0.03328097239136696
Valid Loss:  0.03623681515455246
Epoch:  19  	Training Loss: 0.03722982481122017
Test Loss:  0.03328050673007965
Valid Loss:  0.03623645007610321
Epoch:  20  	Training Loss: 0.03722941875457764
Test Loss:  0.03328004851937294
Valid Loss:  0.03623609244823456
Epoch:  21  	Training Loss: 0.0372290164232254
Test Loss:  0.03327958285808563
Valid Loss:  0.03623573109507561
Epoch:  22  	Training Loss: 0.03722860664129257
Test Loss:  0.03327912092208862
Valid Loss:  0.036235369741916656
Epoch:  23  	Training Loss: 0.03722820058465004
Test Loss:  0.03327866271138191
Valid Loss:  0.03623500466346741
Epoch:  24  	Training Loss: 0.03722779452800751
Test Loss:  0.033278197050094604
Valid Loss:  0.036234643310308456
Epoch:  25  	Training Loss: 0.037227384746074677
Test Loss:  0.033277735114097595
Valid Loss:  0.03623427450656891
Epoch:  26  	Training Loss: 0.037226978689432144
Test Loss:  0.03327726945281029
Valid Loss:  0.03623391315340996
Epoch:  27  	Training Loss: 0.03722656890749931
Test Loss:  0.03327680751681328
Valid Loss:  0.03623355180025101
Epoch:  28  	Training Loss: 0.03722616285085678
Test Loss:  0.03327634185552597
Valid Loss:  0.036233190447092056
Epoch:  29  	Training Loss: 0.03722575679421425
Test Loss:  0.03327588364481926
Valid Loss:  0.036232829093933105
Epoch:  30  	Training Loss: 0.037225350737571716
Test Loss:  0.03327541798353195
Valid Loss:  0.03623246029019356
Epoch:  31  	Training Loss: 0.037224940955638885
Test Loss:  0.03327495604753494
Valid Loss:  0.03623209893703461
Epoch:  32  	Training Loss: 0.03722453862428665
Test Loss:  0.03327449411153793
Valid Loss:  0.03623173385858536
Epoch:  33  	Training Loss: 0.03722412511706352
Test Loss:  0.033274028450250626
Valid Loss:  0.03623136878013611
Epoch:  34  	Training Loss: 0.03722371533513069
Test Loss:  0.03327356278896332
Valid Loss:  0.03623100370168686
Epoch:  35  	Training Loss: 0.03722330927848816
Test Loss:  0.03327310085296631
Valid Loss:  0.03623063862323761
Epoch:  36  	Training Loss: 0.03722289577126503
Test Loss:  0.033272635191679
Valid Loss:  0.036230266094207764
Epoch:  37  	Training Loss: 0.0372224822640419
Test Loss:  0.03327216953039169
Valid Loss:  0.03622990846633911
Epoch:  38  	Training Loss: 0.03722207248210907
Test Loss:  0.033271707594394684
Valid Loss:  0.036229535937309265
Epoch:  39  	Training Loss: 0.03722166642546654
Test Loss:  0.033271245658397675
Valid Loss:  0.036229170858860016
Epoch:  40  	Training Loss: 0.03722125664353371
Test Loss:  0.03327077999711037
Valid Loss:  0.03622880578041077
Epoch:  41  	Training Loss: 0.037220846861600876
Test Loss:  0.03327031433582306
Valid Loss:  0.03622844070196152
Epoch:  42  	Training Loss: 0.037220437079668045
Test Loss:  0.033269841223955154
Valid Loss:  0.03622807562351227
Epoch:  43  	Training Loss: 0.037220023572444916
Test Loss:  0.03326937183737755
Valid Loss:  0.03622769936919212
Epoch:  44  	Training Loss: 0.03721960633993149
Test Loss:  0.033268898725509644
Valid Loss:  0.036227330565452576
Epoch:  45  	Training Loss: 0.03721918910741806
Test Loss:  0.03326842933893204
Valid Loss:  0.03622695803642273
Epoch:  46  	Training Loss: 0.03721877932548523
Test Loss:  0.03326795995235443
Valid Loss:  0.03622659295797348
Epoch:  47  	Training Loss: 0.0372183658182621
Test Loss:  0.033267486840486526
Valid Loss:  0.03622622787952423
Epoch:  48  	Training Loss: 0.03721794858574867
Test Loss:  0.03326702490448952
Valid Loss:  0.036225855350494385
Epoch:  49  	Training Loss: 0.03721753507852554
Test Loss:  0.033266548067331314
Valid Loss:  0.03622548282146454
Epoch:  50  	Training Loss: 0.037217121571302414
Test Loss:  0.03326607495546341
Valid Loss:  0.03622511029243469
Epoch:  51  	Training Loss: 0.037216704338788986
Test Loss:  0.0332656130194664
Valid Loss:  0.03622474521398544
Epoch:  52  	Training Loss: 0.037216294556856155
Test Loss:  0.03326515108346939
Valid Loss:  0.036224380135536194
Epoch:  53  	Training Loss: 0.03721588850021362
Test Loss:  0.03326468542218208
Valid Loss:  0.036224015057086945
Epoch:  54  	Training Loss: 0.03721547871828079
Test Loss:  0.03326422721147537
Valid Loss:  0.036223649978637695
Epoch:  55  	Training Loss: 0.03721506893634796
Test Loss:  0.033263761550188065
Valid Loss:  0.03622329235076904
Epoch:  56  	Training Loss: 0.03721465915441513
Test Loss:  0.033263299614191055
Valid Loss:  0.036222927272319794
Epoch:  57  	Training Loss: 0.0372142568230629
Test Loss:  0.033262837678194046
Valid Loss:  0.036222562193870544
Epoch:  58  	Training Loss: 0.037213847041130066
Test Loss:  0.033262379467487335
Valid Loss:  0.036222200840711594
Epoch:  59  	Training Loss: 0.037213440984487534
Test Loss:  0.03326191008090973
Valid Loss:  0.03622183948755264
Epoch:  60  	Training Loss: 0.037213034927845
Test Loss:  0.03326145187020302
Valid Loss:  0.036221470683813095
Epoch:  61  	Training Loss: 0.03721262514591217
Test Loss:  0.03326098993420601
Valid Loss:  0.036221109330654144
Epoch:  62  	Training Loss: 0.03721221536397934
Test Loss:  0.0332605242729187
Valid Loss:  0.036220744252204895
Epoch:  63  	Training Loss: 0.03721180558204651
Test Loss:  0.033260054886341095
Valid Loss:  0.036220379173755646
Epoch:  64  	Training Loss: 0.03721139580011368
Test Loss:  0.033259592950344086
Valid Loss:  0.0362200103700161
Epoch:  65  	Training Loss: 0.03721098601818085
Test Loss:  0.03325912356376648
Valid Loss:  0.03621964529156685
Epoch:  66  	Training Loss: 0.037210576236248016
Test Loss:  0.03325866162776947
Valid Loss:  0.0362192802131176
Epoch:  67  	Training Loss: 0.03721015900373459
Test Loss:  0.033258192241191864
Valid Loss:  0.03621890768408775
Epoch:  68  	Training Loss: 0.03720974922180176
Test Loss:  0.033257726579904556
Valid Loss:  0.036218538880348206
Epoch:  69  	Training Loss: 0.03720933943986893
Test Loss:  0.03325726091861725
Valid Loss:  0.036218177527189255
Epoch:  70  	Training Loss: 0.037208929657936096
Test Loss:  0.03325679525732994
Valid Loss:  0.03621780872344971
Epoch:  71  	Training Loss: 0.03720851615071297
Test Loss:  0.03325632959604263
Valid Loss:  0.03621744364500046
Epoch:  72  	Training Loss: 0.037208106368780136
Test Loss:  0.033255863934755325
Valid Loss:  0.03621707856655121
 15%|█▍        | 73/500 [00:53<05:59,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:00<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:07<08:04,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:46,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:09,  1.63it/s] 19%|█▉        | 97/500 [01:07<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:07<02:14,  2.99it/s] 20%|██        | 101/500 [01:14<07:49,  1.18s/it] 21%|██        | 103/500 [01:14<05:35,  1.18it/s] 21%|██        | 105/500 [01:14<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:10,  3.01it/s] 22%|██▏       | 111/500 [01:21<07:39,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:21<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:21<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:27<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:27<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:34<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:34<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.24it/s] 28%|██▊       | 139/500 [01:35<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:41<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:41<04:59,  1.19it/s]Epoch:  73  	Training Loss: 0.037207700312137604
Test Loss:  0.03325539827346802
Valid Loss:  0.03621671348810196
Epoch:  74  	Training Loss: 0.03720729053020477
Test Loss:  0.03325493633747101
Valid Loss:  0.03621634840965271
Epoch:  75  	Training Loss: 0.03720688074827194
Test Loss:  0.0332544669508934
Valid Loss:  0.03621598333120346
Epoch:  76  	Training Loss: 0.03720647096633911
Test Loss:  0.033254001289606094
Valid Loss:  0.03621562197804451
Epoch:  77  	Training Loss: 0.03720606118440628
Test Loss:  0.033253543078899384
Valid Loss:  0.03621525689959526
Epoch:  78  	Training Loss: 0.03720565140247345
Test Loss:  0.033253081142902374
Valid Loss:  0.03621489554643631
Epoch:  79  	Training Loss: 0.03720524534583092
Test Loss:  0.03325261175632477
Valid Loss:  0.03621453046798706
Epoch:  80  	Training Loss: 0.03720483556389809
Test Loss:  0.03325214982032776
Valid Loss:  0.03621416538953781
Epoch:  81  	Training Loss: 0.037204425781965256
Test Loss:  0.03325168043375015
Valid Loss:  0.03621380031108856
Epoch:  82  	Training Loss: 0.03720401972532272
Test Loss:  0.033251211047172546
Valid Loss:  0.036213427782058716
Epoch:  83  	Training Loss: 0.037203602492809296
Test Loss:  0.03325074166059494
Valid Loss:  0.036213066428899765
Epoch:  84  	Training Loss: 0.037203192710876465
Test Loss:  0.03325027599930763
Valid Loss:  0.03621269762516022
Epoch:  85  	Training Loss: 0.03720277547836304
Test Loss:  0.03324979916214943
Valid Loss:  0.03621232509613037
Epoch:  86  	Training Loss: 0.037202365696430206
Test Loss:  0.03324933350086212
Valid Loss:  0.03621196001768112
Epoch:  87  	Training Loss: 0.037201955914497375
Test Loss:  0.033248864114284515
Valid Loss:  0.03621159866452217
Epoch:  88  	Training Loss: 0.03720153868198395
Test Loss:  0.03324839472770691
Valid Loss:  0.03621122986078262
Epoch:  89  	Training Loss: 0.03720112890005112
Test Loss:  0.033247921615839005
Valid Loss:  0.036210864782333374
Epoch:  90  	Training Loss: 0.03720071166753769
Test Loss:  0.0332474559545517
Valid Loss:  0.03621049225330353
Epoch:  91  	Training Loss: 0.03720030188560486
Test Loss:  0.03324698284268379
Valid Loss:  0.03621012717485428
Epoch:  92  	Training Loss: 0.03719988465309143
Test Loss:  0.033246517181396484
Valid Loss:  0.03620975837111473
Epoch:  93  	Training Loss: 0.0371994823217392
Test Loss:  0.033246055245399475
Valid Loss:  0.03620939701795578
Epoch:  94  	Training Loss: 0.037199072539806366
Test Loss:  0.033245597034692764
Valid Loss:  0.03620903566479683
Epoch:  95  	Training Loss: 0.037198662757873535
Test Loss:  0.03324513137340546
Valid Loss:  0.03620867431163788
Epoch:  96  	Training Loss: 0.0371982604265213
Test Loss:  0.03324466943740845
Valid Loss:  0.03620830923318863
Epoch:  97  	Training Loss: 0.03719785064458847
Test Loss:  0.03324420750141144
Valid Loss:  0.03620794415473938
Epoch:  98  	Training Loss: 0.03719744458794594
Test Loss:  0.03324374929070473
Valid Loss:  0.03620758652687073
Epoch:  99  	Training Loss: 0.037197038531303406
Test Loss:  0.03324328362941742
Valid Loss:  0.03620722144842148
Epoch:  100  	Training Loss: 0.03719663247466087
Test Loss:  0.03324281424283981
Valid Loss:  0.03620685636997223
Epoch:  101  	Training Loss: 0.037196218967437744
Test Loss:  0.0332423597574234
Valid Loss:  0.03620649129152298
Epoch:  102  	Training Loss: 0.03719581663608551
Test Loss:  0.03324189782142639
Valid Loss:  0.03620613366365433
Epoch:  103  	Training Loss: 0.03719540685415268
Test Loss:  0.03324143588542938
Valid Loss:  0.03620576858520508
Epoch:  104  	Training Loss: 0.037195004522800446
Test Loss:  0.03324097394943237
Valid Loss:  0.03620540350675583
Epoch:  105  	Training Loss: 0.037194594740867615
Test Loss:  0.03324051946401596
Valid Loss:  0.036205045878887177
Epoch:  106  	Training Loss: 0.03719419240951538
Test Loss:  0.03324005380272865
Valid Loss:  0.03620468080043793
Epoch:  107  	Training Loss: 0.03719377890229225
Test Loss:  0.03323959559202194
Valid Loss:  0.03620431572198868
Epoch:  108  	Training Loss: 0.037193380296230316
Test Loss:  0.03323913365602493
Valid Loss:  0.03620395436882973
Epoch:  109  	Training Loss: 0.037192970514297485
Test Loss:  0.033238671720027924
Valid Loss:  0.036203593015670776
Epoch:  110  	Training Loss: 0.037192560732364655
Test Loss:  0.033238209784030914
Valid Loss:  0.03620322793722153
Epoch:  111  	Training Loss: 0.03719215467572212
Test Loss:  0.0332377552986145
Valid Loss:  0.036202870309352875
Epoch:  112  	Training Loss: 0.03719175234436989
Test Loss:  0.033237285912036896
Valid Loss:  0.03620250150561333
Epoch:  113  	Training Loss: 0.03719133883714676
Test Loss:  0.03323681652545929
Valid Loss:  0.03620213642716408
Epoch:  114  	Training Loss: 0.03719092905521393
Test Loss:  0.03323635458946228
Valid Loss:  0.03620176762342453
Epoch:  115  	Training Loss: 0.0371905192732811
Test Loss:  0.033235885202884674
Valid Loss:  0.03620140254497528
Epoch:  116  	Training Loss: 0.03719010949134827
Test Loss:  0.033235419541597366
Valid Loss:  0.03620103746652603
Epoch:  117  	Training Loss: 0.03718969598412514
Test Loss:  0.03323495388031006
Valid Loss:  0.03620067238807678
Epoch:  118  	Training Loss: 0.037189286202192307
Test Loss:  0.03323449194431305
Valid Loss:  0.03620030730962753
Epoch:  119  	Training Loss: 0.03718887269496918
Test Loss:  0.03323402255773544
Valid Loss:  0.036199938505887985
Epoch:  120  	Training Loss: 0.037188466638326645
Test Loss:  0.033233556896448135
Valid Loss:  0.036199577152729034
Epoch:  121  	Training Loss: 0.037188053131103516
Test Loss:  0.03323309123516083
Valid Loss:  0.036199212074279785
Epoch:  122  	Training Loss: 0.037187643349170685
Test Loss:  0.03323262184858322
Valid Loss:  0.03619883581995964
Epoch:  123  	Training Loss: 0.037187233567237854
Test Loss:  0.03323214873671532
Valid Loss:  0.03619847446680069
Epoch:  124  	Training Loss: 0.037186820060014725
Test Loss:  0.03323168307542801
Valid Loss:  0.03619810566306114
Epoch:  125  	Training Loss: 0.037186406552791595
Test Loss:  0.0332312136888504
Valid Loss:  0.036197736859321594
Epoch:  126  	Training Loss: 0.037185996770858765
Test Loss:  0.033230751752853394
Valid Loss:  0.036197371780872345
Epoch:  127  	Training Loss: 0.03718557953834534
Test Loss:  0.03323028236627579
Valid Loss:  0.0361969992518425
Epoch:  128  	Training Loss: 0.037185169756412506
Test Loss:  0.03322981670498848
Valid Loss:  0.03619663417339325
Epoch:  129  	Training Loss: 0.037184759974479675
Test Loss:  0.033229343593120575
Valid Loss:  0.036196269094944
Epoch:  130  	Training Loss: 0.037184346467256546
Test Loss:  0.03322887793183327
Valid Loss:  0.03619590401649475
Epoch:  131  	Training Loss: 0.037183936685323715
Test Loss:  0.03322841227054596
Valid Loss:  0.0361955352127552
Epoch:  132  	Training Loss: 0.03718351945281029
Test Loss:  0.03322794660925865
Valid Loss:  0.036195166409015656
Epoch:  133  	Training Loss: 0.037183117121458054
Test Loss:  0.03322748839855194
Valid Loss:  0.036194808781147
Epoch:  134  	Training Loss: 0.03718270733952522
Test Loss:  0.03322702273726463
Valid Loss:  0.036194443702697754
Epoch:  135  	Training Loss: 0.03718230128288269
Test Loss:  0.033226557075977325
Valid Loss:  0.0361940823495388
Epoch:  136  	Training Loss: 0.03718189150094986
Test Loss:  0.033226095139980316
Valid Loss:  0.036193713545799255
Epoch:  137  	Training Loss: 0.03718148171901703
Test Loss:  0.03322563320398331
Valid Loss:  0.036193352192640305
Epoch:  138  	Training Loss: 0.037181079387664795
Test Loss:  0.033225167542696
Valid Loss:  0.036192990839481354
Epoch:  139  	Training Loss: 0.037180665880441666
Test Loss:  0.03322470188140869
Valid Loss:  0.0361926294863224
Epoch:  140  	Training Loss: 0.03718025982379913
Test Loss:  0.03322423994541168
Valid Loss:  0.036192264407873154
Epoch:  141  	Training Loss: 0.0371798500418663
Test Loss:  0.03322377800941467
Valid Loss:  0.0361919030547142
Epoch:  142  	Training Loss: 0.03717944398522377
Test Loss:  0.033223316073417664
Valid Loss:  0.036191537976264954
Epoch:  143  	Training Loss: 0.03717903792858124
Test Loss:  0.033222850412130356
Valid Loss:  0.036191176623106
Epoch:  144  	Training Loss: 0.03717862814664841
Test Loss:   29%|██▉       | 145/500 [01:41<03:35,  1.64it/s] 29%|██▉       | 147/500 [01:41<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:41<01:56,  3.01it/s] 30%|███       | 151/500 [01:48<06:47,  1.17s/it] 31%|███       | 153/500 [01:48<04:51,  1.19it/s] 31%|███       | 155/500 [01:48<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:48<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:55<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:23,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:01<06:23,  1.17s/it] 35%|███▍      | 173/500 [02:01<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:17,  1.65it/s] 35%|███▌      | 177/500 [02:02<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:02<01:45,  3.03it/s] 36%|███▌      | 181/500 [02:08<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:08<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<06:00,  1.17s/it] 39%|███▊      | 193/500 [02:15<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:15<03:05,  1.65it/s] 39%|███▉      | 197/500 [02:15<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:15<01:39,  3.02it/s] 40%|████      | 201/500 [02:22<05:50,  1.17s/it] 41%|████      | 203/500 [02:22<04:10,  1.19it/s] 41%|████      | 205/500 [02:22<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:22<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:29<05:43,  1.19s/it] 43%|████▎     | 213/500 [02:29<04:04,  1.17it/s] 43%|████▎     | 215/500 [02:29<02:55,  1.62it/s]0.03322238475084305
Valid Loss:  0.036190811544656754
Epoch:  145  	Training Loss: 0.037178222090005875
Test Loss:  0.03322192281484604
Valid Loss:  0.0361904501914978
Epoch:  146  	Training Loss: 0.03717781603336334
Test Loss:  0.03322146087884903
Valid Loss:  0.03619009256362915
Epoch:  147  	Training Loss: 0.03717740625143051
Test Loss:  0.03322099894285202
Valid Loss:  0.0361897274851799
Epoch:  148  	Training Loss: 0.03717700392007828
Test Loss:  0.033220529556274414
Valid Loss:  0.03618936240673065
Epoch:  149  	Training Loss: 0.037176597863435745
Test Loss:  0.0332200713455677
Valid Loss:  0.0361890010535717
Epoch:  150  	Training Loss: 0.037176188081502914
Test Loss:  0.033219605684280396
Valid Loss:  0.03618863970041275
Epoch:  151  	Training Loss: 0.03717578202486038
Test Loss:  0.03321914002299309
Valid Loss:  0.0361882820725441
Epoch:  152  	Training Loss: 0.03717537224292755
Test Loss:  0.03321867436170578
Valid Loss:  0.03618790581822395
Epoch:  153  	Training Loss: 0.03717495873570442
Test Loss:  0.03321821242570877
Valid Loss:  0.036187544465065
Epoch:  154  	Training Loss: 0.03717454522848129
Test Loss:  0.033217743039131165
Valid Loss:  0.036187171936035156
Epoch:  155  	Training Loss: 0.03717413544654846
Test Loss:  0.03321727365255356
Valid Loss:  0.03618680313229561
Epoch:  156  	Training Loss: 0.037173718214035034
Test Loss:  0.03321680426597595
Valid Loss:  0.03618643432855606
Epoch:  157  	Training Loss: 0.0371733084321022
Test Loss:  0.033216334879398346
Valid Loss:  0.036186061799526215
Epoch:  158  	Training Loss: 0.037172891199588776
Test Loss:  0.03321586549282074
Valid Loss:  0.036185696721076965
Epoch:  159  	Training Loss: 0.037172481417655945
Test Loss:  0.033215396106243134
Valid Loss:  0.03618532419204712
Epoch:  160  	Training Loss: 0.03717206418514252
Test Loss:  0.03321492671966553
Valid Loss:  0.03618495166301727
Epoch:  161  	Training Loss: 0.03717165067791939
Test Loss:  0.03321445733308792
Valid Loss:  0.036184586584568024
Epoch:  162  	Training Loss: 0.03717123717069626
Test Loss:  0.03321400284767151
Valid Loss:  0.03618422895669937
Epoch:  163  	Training Loss: 0.03717083856463432
Test Loss:  0.033213552087545395
Valid Loss:  0.036183878779411316
Epoch:  164  	Training Loss: 0.03717043995857239
Test Loss:  0.033213093876838684
Valid Loss:  0.036183521151542664
Epoch:  165  	Training Loss: 0.03717004135251045
Test Loss:  0.03321263939142227
Valid Loss:  0.03618317097425461
Epoch:  166  	Training Loss: 0.03716963902115822
Test Loss:  0.03321218118071556
Valid Loss:  0.036182813346385956
Epoch:  167  	Training Loss: 0.03716924414038658
Test Loss:  0.03321172669529915
Valid Loss:  0.0361824594438076
Epoch:  168  	Training Loss: 0.03716884180903435
Test Loss:  0.033211275935173035
Valid Loss:  0.03618210554122925
Epoch:  169  	Training Loss: 0.03716844320297241
Test Loss:  0.033210813999176025
Valid Loss:  0.036181751638650894
Epoch:  170  	Training Loss: 0.037168048322200775
Test Loss:  0.03321036696434021
Valid Loss:  0.03618139401078224
Epoch:  171  	Training Loss: 0.03716764599084854
Test Loss:  0.0332099087536335
Valid Loss:  0.03618104010820389
Epoch:  172  	Training Loss: 0.037167251110076904
Test Loss:  0.03320944309234619
Valid Loss:  0.03618067502975464
Epoch:  173  	Training Loss: 0.037166841328144073
Test Loss:  0.03320898488163948
Valid Loss:  0.03618031367659569
Epoch:  174  	Training Loss: 0.03716643154621124
Test Loss:  0.03320851922035217
Valid Loss:  0.03617994859814644
Epoch:  175  	Training Loss: 0.03716602176427841
Test Loss:  0.033208057284355164
Valid Loss:  0.03617958724498749
Epoch:  176  	Training Loss: 0.03716561198234558
Test Loss:  0.033207595348358154
Valid Loss:  0.03617922216653824
Epoch:  177  	Training Loss: 0.03716520592570305
Test Loss:  0.03320712596178055
Valid Loss:  0.03617885708808899
Epoch:  178  	Training Loss: 0.037164799869060516
Test Loss:  0.03320666775107384
Valid Loss:  0.03617849200963974
Epoch:  179  	Training Loss: 0.037164390087127686
Test Loss:  0.03320620581507683
Valid Loss:  0.03617812693119049
Epoch:  180  	Training Loss: 0.037163980305194855
Test Loss:  0.03320574015378952
Valid Loss:  0.03617776185274124
Epoch:  181  	Training Loss: 0.03716357424855232
Test Loss:  0.03320527821779251
Valid Loss:  0.03617739677429199
Epoch:  182  	Training Loss: 0.03716316446661949
Test Loss:  0.0332048162817955
Valid Loss:  0.03617703542113304
Epoch:  183  	Training Loss: 0.03716275840997696
Test Loss:  0.03320435807108879
Valid Loss:  0.03617667406797409
Epoch:  184  	Training Loss: 0.03716235235333443
Test Loss:  0.03320389240980148
Valid Loss:  0.03617630898952484
Epoch:  185  	Training Loss: 0.037161946296691895
Test Loss:  0.033203430473804474
Valid Loss:  0.03617594391107559
Epoch:  186  	Training Loss: 0.037161536514759064
Test Loss:  0.03320297226309776
Valid Loss:  0.03617557883262634
Epoch:  187  	Training Loss: 0.03716112673282623
Test Loss:  0.033202506601810455
Valid Loss:  0.03617522120475769
Epoch:  188  	Training Loss: 0.037160724401474
Test Loss:  0.033202044665813446
Valid Loss:  0.03617485612630844
Epoch:  189  	Training Loss: 0.03716031461954117
Test Loss:  0.03320158272981644
Valid Loss:  0.03617449104785919
Epoch:  190  	Training Loss: 0.03715990483760834
Test Loss:  0.033201124519109726
Valid Loss:  0.03617412969470024
Epoch:  191  	Training Loss: 0.037159498780965805
Test Loss:  0.03320065885782242
Valid Loss:  0.03617376834154129
Epoch:  192  	Training Loss: 0.03715909272432327
Test Loss:  0.03320019692182541
Valid Loss:  0.03617340698838234
Epoch:  193  	Training Loss: 0.03715868666768074
Test Loss:  0.0331997312605381
Valid Loss:  0.03617304190993309
Epoch:  194  	Training Loss: 0.03715828061103821
Test Loss:  0.03319927304983139
Valid Loss:  0.03617268428206444
Epoch:  195  	Training Loss: 0.03715787082910538
Test Loss:  0.03319881111383438
Valid Loss:  0.03617232292890549
Epoch:  196  	Training Loss: 0.03715746849775314
Test Loss:  0.033198341727256775
Valid Loss:  0.03617195785045624
Epoch:  197  	Training Loss: 0.03715706244111061
Test Loss:  0.033197883516550064
Valid Loss:  0.03617159649729729
Epoch:  198  	Training Loss: 0.03715665265917778
Test Loss:  0.033197421580553055
Valid Loss:  0.036171235144138336
Epoch:  199  	Training Loss: 0.03715624660253525
Test Loss:  0.03319695591926575
Valid Loss:  0.03617087006568909
Epoch:  200  	Training Loss: 0.037155840545892715
Test Loss:  0.03319649398326874
Valid Loss:  0.03617051988840103
Epoch:  201  	Training Loss: 0.03715543448925018
Test Loss:  0.03319603204727173
Valid Loss:  0.036170151084661484
Epoch:  202  	Training Loss: 0.03715503215789795
Test Loss:  0.03319557383656502
Valid Loss:  0.03616978973150253
Epoch:  203  	Training Loss: 0.03715462237596512
Test Loss:  0.03319510817527771
Valid Loss:  0.036169424653053284
Epoch:  204  	Training Loss: 0.037154216319322586
Test Loss:  0.0331946462392807
Valid Loss:  0.03616906329989433
Epoch:  205  	Training Loss: 0.037153810262680054
Test Loss:  0.03319418430328369
Valid Loss:  0.03616870194673538
Epoch:  206  	Training Loss: 0.037153396755456924
Test Loss:  0.03319372236728668
Valid Loss:  0.03616833686828613
Epoch:  207  	Training Loss: 0.03715299069881439
Test Loss:  0.03319326043128967
Valid Loss:  0.036167971789836884
Epoch:  208  	Training Loss: 0.03715258464217186
Test Loss:  0.033192798495292664
Valid Loss:  0.036167606711387634
Epoch:  209  	Training Loss: 0.03715217858552933
Test Loss:  0.033192336559295654
Valid Loss:  0.036167245358228683
Epoch:  210  	Training Loss: 0.0371517688035965
Test Loss:  0.033191874623298645
Valid Loss:  0.03616688773036003
Epoch:  211  	Training Loss: 0.03715136647224426
Test Loss:  0.033191412687301636
Valid Loss:  0.03616651892662048
Epoch:  212  	Training Loss: 0.03715095669031143
Test Loss:  0.033190950751304626
Valid Loss:  0.03616616129875183
Epoch:  213  	Training Loss: 0.0371505543589592
Test Loss:  0.033190496265888214
Valid Loss:  0.03616580367088318
Epoch:  214  	Training Loss: 0.03715014457702637
Test Loss:  0.033190034329891205
Valid Loss:  0.03616543859243393
Epoch:  215  	Training Loss: 0.03714974224567413
Test Loss:  0.033189576119184494
Valid Loss:  0.03616508096456528
 43%|████▎     | 217/500 [02:29<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:29<01:34,  2.99it/s] 44%|████▍     | 221/500 [02:35<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:36<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:36<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:42<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:42<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:58,  2.23it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.00it/s] 48%|████▊     | 241/500 [02:49<05:04,  1.17s/it] 49%|████▊     | 243/500 [02:49<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:49<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:49<01:53,  2.24it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.01it/s] 50%|█████     | 251/500 [02:56<04:52,  1.18s/it] 51%|█████     | 253/500 [02:56<03:29,  1.18it/s] 51%|█████     | 255/500 [02:56<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:56<01:49,  2.23it/s] 52%|█████▏    | 259/500 [02:56<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:03<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:03<03:18,  1.19it/s] 53%|█████▎    | 265/500 [03:03<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:03<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:03<01:19,  2.92it/s] 54%|█████▍    | 271/500 [03:10<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:10<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:10<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:10<01:40,  2.21it/s] 56%|█████▌    | 279/500 [03:10<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:16<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:17<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:17<02:11,  1.64it/s]Epoch:  216  	Training Loss: 0.0371493399143219
Test Loss:  0.03318911790847778
Valid Loss:  0.03616471588611603
Epoch:  217  	Training Loss: 0.03714893013238907
Test Loss:  0.033188655972480774
Valid Loss:  0.036164358258247375
Epoch:  218  	Training Loss: 0.037148527801036835
Test Loss:  0.033188194036483765
Valid Loss:  0.03616398945450783
Epoch:  219  	Training Loss: 0.0371481217443943
Test Loss:  0.03318773955106735
Valid Loss:  0.036163635551929474
Epoch:  220  	Training Loss: 0.03714771941304207
Test Loss:  0.03318727761507034
Valid Loss:  0.03616327419877052
Epoch:  221  	Training Loss: 0.037147313356399536
Test Loss:  0.03318681940436363
Valid Loss:  0.03616291284561157
Epoch:  222  	Training Loss: 0.037146907299757004
Test Loss:  0.033186353743076324
Valid Loss:  0.03616254776716232
Epoch:  223  	Training Loss: 0.03714650124311447
Test Loss:  0.03318589925765991
Valid Loss:  0.03616219386458397
Epoch:  224  	Training Loss: 0.03714609891176224
Test Loss:  0.033185429871082306
Valid Loss:  0.03616182878613472
Epoch:  225  	Training Loss: 0.037145692855119705
Test Loss:  0.033184975385665894
Valid Loss:  0.03616146743297577
Epoch:  226  	Training Loss: 0.03714528679847717
Test Loss:  0.033184513449668884
Valid Loss:  0.03616110980510712
Epoch:  227  	Training Loss: 0.03714488446712494
Test Loss:  0.033184051513671875
Valid Loss:  0.036160752177238464
Epoch:  228  	Training Loss: 0.03714447468519211
Test Loss:  0.033183589577674866
Valid Loss:  0.036160387098789215
Epoch:  229  	Training Loss: 0.037144068628549576
Test Loss:  0.033183127641677856
Valid Loss:  0.03616002947092056
Epoch:  230  	Training Loss: 0.03714366257190704
Test Loss:  0.03318266570568085
Valid Loss:  0.036159664392471313
Epoch:  231  	Training Loss: 0.03714326024055481
Test Loss:  0.03318220376968384
Valid Loss:  0.03615930303931236
Epoch:  232  	Training Loss: 0.037142857909202576
Test Loss:  0.033181749284267426
Valid Loss:  0.03615894913673401
Epoch:  233  	Training Loss: 0.03714245185256004
Test Loss:  0.03318129479885101
Valid Loss:  0.036158591508865356
Epoch:  234  	Training Loss: 0.03714205324649811
Test Loss:  0.0331808440387249
Valid Loss:  0.036158233880996704
Epoch:  235  	Training Loss: 0.037141650915145874
Test Loss:  0.03318038210272789
Valid Loss:  0.03615787625312805
Epoch:  236  	Training Loss: 0.03714124858379364
Test Loss:  0.033179931342601776
Valid Loss:  0.0361575186252594
Epoch:  237  	Training Loss: 0.037140846252441406
Test Loss:  0.033179473131895065
Valid Loss:  0.036157164722681046
Epoch:  238  	Training Loss: 0.03714044764637947
Test Loss:  0.033179014921188354
Valid Loss:  0.036156803369522095
Epoch:  239  	Training Loss: 0.037140049040317535
Test Loss:  0.03317856043577194
Valid Loss:  0.03615644574165344
Epoch:  240  	Training Loss: 0.0371396467089653
Test Loss:  0.03317810595035553
Valid Loss:  0.03615609183907509
Epoch:  241  	Training Loss: 0.037139248102903366
Test Loss:  0.03317764773964882
Valid Loss:  0.036155737936496735
Epoch:  242  	Training Loss: 0.03713884577155113
Test Loss:  0.03317718952894211
Valid Loss:  0.036155372858047485
Epoch:  243  	Training Loss: 0.0371384397149086
Test Loss:  0.0331767275929451
Valid Loss:  0.03615501523017883
Epoch:  244  	Training Loss: 0.037138037383556366
Test Loss:  0.03317626565694809
Valid Loss:  0.03615466132760048
Epoch:  245  	Training Loss: 0.037137627601623535
Test Loss:  0.03317580372095108
Valid Loss:  0.03615429624915123
Epoch:  246  	Training Loss: 0.0371372252702713
Test Loss:  0.03317534178495407
Valid Loss:  0.03615393489599228
Epoch:  247  	Training Loss: 0.03713681921362877
Test Loss:  0.03317487612366676
Valid Loss:  0.03615357726812363
Epoch:  248  	Training Loss: 0.03713641315698624
Test Loss:  0.03317441791296005
Valid Loss:  0.03615321218967438
Epoch:  249  	Training Loss: 0.037136010825634
Test Loss:  0.03317395597696304
Valid Loss:  0.036152854561805725
Epoch:  250  	Training Loss: 0.03713560104370117
Test Loss:  0.03317349776625633
Valid Loss:  0.036152489483356476
Epoch:  251  	Training Loss: 0.03713519498705864
Test Loss:  0.033173032104969025
Valid Loss:  0.036152128130197525
Epoch:  252  	Training Loss: 0.03713478893041611
Test Loss:  0.033172570168972015
Valid Loss:  0.036151766777038574
Epoch:  253  	Training Loss: 0.03713438659906387
Test Loss:  0.033172108232975006
Valid Loss:  0.03615140542387962
Epoch:  254  	Training Loss: 0.037133973091840744
Test Loss:  0.033171646296978
Valid Loss:  0.036151040345430374
Epoch:  255  	Training Loss: 0.03713356703519821
Test Loss:  0.03317118063569069
Valid Loss:  0.036150675266981125
Epoch:  256  	Training Loss: 0.03713316470384598
Test Loss:  0.03317071869969368
Valid Loss:  0.03615032136440277
Epoch:  257  	Training Loss: 0.03713275492191315
Test Loss:  0.03317025676369667
Valid Loss:  0.03614995628595352
Epoch:  258  	Training Loss: 0.037132348865270615
Test Loss:  0.03316979110240936
Valid Loss:  0.03614959120750427
Epoch:  259  	Training Loss: 0.03713194280862808
Test Loss:  0.03316933289170265
Valid Loss:  0.03614922612905502
Epoch:  260  	Training Loss: 0.03713153302669525
Test Loss:  0.033168867230415344
Valid Loss:  0.03614886850118637
Epoch:  261  	Training Loss: 0.03713112324476242
Test Loss:  0.033168405294418335
Valid Loss:  0.03614850342273712
Epoch:  262  	Training Loss: 0.03713072091341019
Test Loss:  0.033167943358421326
Valid Loss:  0.03614814206957817
Epoch:  263  	Training Loss: 0.037130311131477356
Test Loss:  0.03316747397184372
Valid Loss:  0.03614777326583862
Epoch:  264  	Training Loss: 0.037129901349544525
Test Loss:  0.03316701203584671
Valid Loss:  0.036147408187389374
Epoch:  265  	Training Loss: 0.037129491567611694
Test Loss:  0.0331665463745594
Valid Loss:  0.036147043108940125
Epoch:  266  	Training Loss: 0.037129081785678864
Test Loss:  0.03316608443856239
Valid Loss:  0.03614668548107147
Epoch:  267  	Training Loss: 0.037128668278455734
Test Loss:  0.033165618777275085
Valid Loss:  0.036146316677331924
Epoch:  268  	Training Loss: 0.0371282622218132
Test Loss:  0.03316514939069748
Valid Loss:  0.036145951598882675
Epoch:  269  	Training Loss: 0.03712785243988037
Test Loss:  0.03316468745470047
Valid Loss:  0.036145590245723724
Epoch:  270  	Training Loss: 0.03712744265794754
Test Loss:  0.033164218068122864
Valid Loss:  0.036145225167274475
Epoch:  271  	Training Loss: 0.03712703660130501
Test Loss:  0.033163756132125854
Valid Loss:  0.03614485263824463
Epoch:  272  	Training Loss: 0.03712662681937218
Test Loss:  0.033163297921419144
Valid Loss:  0.03614449501037598
Epoch:  273  	Training Loss: 0.037126220762729645
Test Loss:  0.033162835985422134
Valid Loss:  0.03614412993192673
Epoch:  274  	Training Loss: 0.037125810980796814
Test Loss:  0.03316237032413483
Valid Loss:  0.036143768578767776
Epoch:  275  	Training Loss: 0.03712540119886398
Test Loss:  0.03316190838813782
Valid Loss:  0.036143407225608826
Epoch:  276  	Training Loss: 0.03712499886751175
Test Loss:  0.03316143900156021
Valid Loss:  0.036143042147159576
Epoch:  277  	Training Loss: 0.03712458908557892
Test Loss:  0.0331609845161438
Valid Loss:  0.03614267706871033
Epoch:  278  	Training Loss: 0.037124183028936386
Test Loss:  0.03316052258014679
Valid Loss:  0.03614231199026108
Epoch:  279  	Training Loss: 0.037123776972293854
Test Loss:  0.03316006436944008
Valid Loss:  0.03614195063710213
Epoch:  280  	Training Loss: 0.03712336719036102
Test Loss:  0.03315960243344307
Valid Loss:  0.036141589283943176
Epoch:  281  	Training Loss: 0.03712296113371849
Test Loss:  0.03315913677215576
Valid Loss:  0.03614122420549393
Epoch:  282  	Training Loss: 0.03712255507707596
Test Loss:  0.03315867483615875
Valid Loss:  0.036140866577625275
Epoch:  283  	Training Loss: 0.037122152745723724
Test Loss:  0.03315822035074234
Valid Loss:  0.03614050894975662
Epoch:  284  	Training Loss: 0.03712174668908119
Test Loss:  0.03315776214003563
Valid Loss:  0.03614014387130737
Epoch:  285  	Training Loss: 0.03712134808301926
Test Loss:  0.03315730392932892
Valid Loss:  0.03613978996872902
Epoch:  286  	Training Loss: 0.037120942026376724
Test Loss:  0.033156849443912506
Valid Loss:  0.036139436066150665
 57%|█████▋    | 287/500 [03:17<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:17<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:23<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:23<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.02it/s] 60%|██████    | 301/500 [03:30<03:54,  1.18s/it] 61%|██████    | 303/500 [03:30<02:46,  1.18it/s] 61%|██████    | 305/500 [03:30<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:30<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:31<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:37<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:37<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:37<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:37<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:37<01:00,  3.00it/s] 64%|██████▍   | 321/500 [03:44<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:44<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:44<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:44<00:57,  3.00it/s] 66%|██████▌   | 331/500 [03:51<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:51<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:51<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:51<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:51<00:53,  3.00it/s] 68%|██████▊   | 341/500 [03:58<03:10,  1.20s/it] 69%|██████▊   | 343/500 [03:58<02:14,  1.17it/s] 69%|██████▉   | 345/500 [03:58<01:36,  1.61it/s] 69%|██████▉   | 347/500 [03:58<01:09,  2.21it/s] 70%|██████▉   | 349/500 [03:58<00:50,  2.97it/s] 70%|███████   | 351/500 [04:05<02:58,  1.20s/it] 71%|███████   | 353/500 [04:05<02:06,  1.17it/s] 71%|███████   | 355/500 [04:05<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:05<01:04,  2.21it/s]Epoch:  287  	Training Loss: 0.03712053969502449
Test Loss:  0.0331563875079155
Valid Loss:  0.036139074712991714
Epoch:  288  	Training Loss: 0.03712013363838196
Test Loss:  0.033155933022499084
Valid Loss:  0.036138713359832764
Epoch:  289  	Training Loss: 0.03711973503232002
Test Loss:  0.03315547853708267
Valid Loss:  0.03613835573196411
Epoch:  290  	Training Loss: 0.03711933270096779
Test Loss:  0.03315502405166626
Valid Loss:  0.03613799810409546
Epoch:  291  	Training Loss: 0.037118930369615555
Test Loss:  0.03315456211566925
Valid Loss:  0.03613764047622681
Epoch:  292  	Training Loss: 0.03711852431297302
Test Loss:  0.03315410390496254
Valid Loss:  0.036137282848358154
Epoch:  293  	Training Loss: 0.03711812198162079
Test Loss:  0.03315364569425583
Valid Loss:  0.0361369252204895
Epoch:  294  	Training Loss: 0.037117719650268555
Test Loss:  0.03315318748354912
Valid Loss:  0.03613656014204025
Epoch:  295  	Training Loss: 0.03711731731891632
Test Loss:  0.03315272554755211
Valid Loss:  0.0361362062394619
Epoch:  296  	Training Loss: 0.03711691498756409
Test Loss:  0.0331522673368454
Valid Loss:  0.036135848611593246
Epoch:  297  	Training Loss: 0.03711651265621185
Test Loss:  0.03315180912613869
Valid Loss:  0.036135490983724594
Epoch:  298  	Training Loss: 0.03711610659956932
Test Loss:  0.03315134346485138
Valid Loss:  0.03613512963056564
Epoch:  299  	Training Loss: 0.03711570426821709
Test Loss:  0.03315088897943497
Valid Loss:  0.03613477200269699
Epoch:  300  	Training Loss: 0.03711530193686485
Test Loss:  0.03315042704343796
Valid Loss:  0.03613441064953804
Epoch:  301  	Training Loss: 0.03711489960551262
Test Loss:  0.03314996883273125
Valid Loss:  0.03613405302166939
Epoch:  302  	Training Loss: 0.03711449354887009
Test Loss:  0.03314950317144394
Valid Loss:  0.03613369166851044
Epoch:  303  	Training Loss: 0.03711409121751785
Test Loss:  0.03314904123544693
Valid Loss:  0.03613332659006119
Epoch:  304  	Training Loss: 0.03711368143558502
Test Loss:  0.03314858302474022
Valid Loss:  0.036132968962192535
Epoch:  305  	Training Loss: 0.03711327537894249
Test Loss:  0.03314811736345291
Valid Loss:  0.036132603883743286
Epoch:  306  	Training Loss: 0.03711286932229996
Test Loss:  0.0331476591527462
Valid Loss:  0.036132246255874634
Epoch:  307  	Training Loss: 0.037112463265657425
Test Loss:  0.03314719721674919
Valid Loss:  0.036131881177425385
Epoch:  308  	Training Loss: 0.037112053483724594
Test Loss:  0.033146731555461884
Valid Loss:  0.03613152354955673
Epoch:  309  	Training Loss: 0.03711164742708206
Test Loss:  0.033146269619464874
Valid Loss:  0.03613115847110748
Epoch:  310  	Training Loss: 0.03711124137043953
Test Loss:  0.033145807683467865
Valid Loss:  0.036130793392658234
Epoch:  311  	Training Loss: 0.037110835313797
Test Loss:  0.033145345747470856
Valid Loss:  0.03613043576478958
Epoch:  312  	Training Loss: 0.037110429257154465
Test Loss:  0.03314489126205444
Valid Loss:  0.03613007068634033
Epoch:  313  	Training Loss: 0.03711002320051193
Test Loss:  0.033144425600767136
Valid Loss:  0.03612971305847168
Epoch:  314  	Training Loss: 0.0371096208691597
Test Loss:  0.033143967390060425
Valid Loss:  0.03612934798002243
Epoch:  315  	Training Loss: 0.037109214812517166
Test Loss:  0.033143509179353714
Valid Loss:  0.03612899035215378
Epoch:  316  	Training Loss: 0.037108808755874634
Test Loss:  0.033143050968647
Valid Loss:  0.03612862899899483
Epoch:  317  	Training Loss: 0.0371084026992321
Test Loss:  0.033142589032649994
Valid Loss:  0.036128267645835876
Epoch:  318  	Training Loss: 0.03710799664258957
Test Loss:  0.033142127096652985
Valid Loss:  0.03612790256738663
Epoch:  319  	Training Loss: 0.037107594311237335
Test Loss:  0.033141665160655975
Valid Loss:  0.036127541214227676
Epoch:  320  	Training Loss: 0.037107184529304504
Test Loss:  0.03314121067523956
Valid Loss:  0.036127179861068726
Epoch:  321  	Training Loss: 0.03710678219795227
Test Loss:  0.033140748739242554
Valid Loss:  0.03612682223320007
Epoch:  322  	Training Loss: 0.03710637614130974
Test Loss:  0.033140286803245544
Valid Loss:  0.036126457154750824
Epoch:  323  	Training Loss: 0.037105970084667206
Test Loss:  0.033139824867248535
Valid Loss:  0.03612609952688217
Epoch:  324  	Training Loss: 0.03710556402802467
Test Loss:  0.033139366656541824
Valid Loss:  0.03612573817372322
Epoch:  325  	Training Loss: 0.03710515797138214
Test Loss:  0.033138908445835114
Valid Loss:  0.03612537309527397
Epoch:  326  	Training Loss: 0.03710475564002991
Test Loss:  0.033138446509838104
Valid Loss:  0.03612501546740532
Epoch:  327  	Training Loss: 0.037104345858097076
Test Loss:  0.033137984573841095
Valid Loss:  0.03612465411424637
Epoch:  328  	Training Loss: 0.03710394352674484
Test Loss:  0.033137522637844086
Valid Loss:  0.036124296486377716
Epoch:  329  	Training Loss: 0.03710353747010231
Test Loss:  0.033137064427137375
Valid Loss:  0.03612393140792847
Epoch:  330  	Training Loss: 0.03710313141345978
Test Loss:  0.033136602491140366
Valid Loss:  0.036123573780059814
Epoch:  331  	Training Loss: 0.037102725356817245
Test Loss:  0.033136144280433655
Valid Loss:  0.036123208701610565
Epoch:  332  	Training Loss: 0.03710231930017471
Test Loss:  0.03313567861914635
Valid Loss:  0.036122843623161316
Epoch:  333  	Training Loss: 0.03710191324353218
Test Loss:  0.03313521668314934
Valid Loss:  0.036122482270002365
Epoch:  334  	Training Loss: 0.03710150718688965
Test Loss:  0.03313475474715233
Valid Loss:  0.036122120916843414
Epoch:  335  	Training Loss: 0.037101101130247116
Test Loss:  0.03313429281115532
Valid Loss:  0.036121759563684464
Epoch:  336  	Training Loss: 0.037100691348314285
Test Loss:  0.03313383460044861
Valid Loss:  0.03612139821052551
Epoch:  337  	Training Loss: 0.03710028529167175
Test Loss:  0.0331333689391613
Valid Loss:  0.03612103313207626
Epoch:  338  	Training Loss: 0.03709987550973892
Test Loss:  0.03313290327787399
Valid Loss:  0.036120668053627014
Epoch:  339  	Training Loss: 0.03709947317838669
Test Loss:  0.03313244879245758
Valid Loss:  0.03612031042575836
Epoch:  340  	Training Loss: 0.03709906339645386
Test Loss:  0.033131979405879974
Valid Loss:  0.03611994534730911
Epoch:  341  	Training Loss: 0.037098657339811325
Test Loss:  0.033131517469882965
Valid Loss:  0.03611958026885986
Epoch:  342  	Training Loss: 0.037098247557878494
Test Loss:  0.033131059259176254
Valid Loss:  0.03611922264099121
Epoch:  343  	Training Loss: 0.03709784150123596
Test Loss:  0.03313059359788895
Valid Loss:  0.03611885756254196
Epoch:  344  	Training Loss: 0.03709743916988373
Test Loss:  0.03313013166189194
Valid Loss:  0.03611849620938301
Epoch:  345  	Training Loss: 0.0370970293879509
Test Loss:  0.033129677176475525
Valid Loss:  0.03611813485622406
Epoch:  346  	Training Loss: 0.03709662705659866
Test Loss:  0.033129215240478516
Valid Loss:  0.03611776977777481
Epoch:  347  	Training Loss: 0.03709621727466583
Test Loss:  0.033128753304481506
Valid Loss:  0.03611740469932556
Epoch:  348  	Training Loss: 0.0370958112180233
Test Loss:  0.0331282913684845
Valid Loss:  0.03611704707145691
Epoch:  349  	Training Loss: 0.03709540516138077
Test Loss:  0.03312782943248749
Valid Loss:  0.03611668199300766
Epoch:  350  	Training Loss: 0.037094999104738235
Test Loss:  0.03312737122178078
Valid Loss:  0.03611631691455841
Epoch:  351  	Training Loss: 0.0370945930480957
Test Loss:  0.03312690928578377
Valid Loss:  0.03611595928668976
Epoch:  352  	Training Loss: 0.03709418326616287
Test Loss:  0.03312645107507706
Valid Loss:  0.036115601658821106
Epoch:  353  	Training Loss: 0.03709378093481064
Test Loss:  0.03312598913908005
Valid Loss:  0.03611523658037186
Epoch:  354  	Training Loss: 0.037093378603458405
Test Loss:  0.03312552720308304
Valid Loss:  0.036114878952503204
Epoch:  355  	Training Loss: 0.03709297627210617
Test Loss:  0.033125072717666626
Valid Loss:  0.036114517599344254
Epoch:  356  	Training Loss: 0.03709256649017334
Test Loss:  0.033124614506959915
Valid Loss:  0.0361141562461853
Epoch:  357  	Training Loss: 0.037092164158821106
Test Loss:  0.033124152570962906
Valid Loss:  0.03611379861831665
 72%|███████▏  | 359/500 [04:05<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:11<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:12<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:12<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:12<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:12<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:18<02:36,  1.21s/it] 75%|███████▍  | 373/500 [04:19<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:19<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:19<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:19<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:25<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:25<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:25<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:26<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:32<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:32<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:32<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:32<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.02it/s] 80%|████████  | 401/500 [04:39<01:54,  1.16s/it] 81%|████████  | 403/500 [04:39<01:20,  1.20it/s] 81%|████████  | 405/500 [04:39<00:57,  1.66it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.27it/s] 82%|████████▏ | 409/500 [04:39<00:29,  3.05it/s] 82%|████████▏ | 411/500 [04:46<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:46<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:52<01:32,  1.18s/it] 85%|████████▍ | 423/500 [04:53<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.24it/s]Epoch:  358  	Training Loss: 0.03709176182746887
Test Loss:  0.0331236906349659
Valid Loss:  0.0361134372651577
Epoch:  359  	Training Loss: 0.03709135577082634
Test Loss:  0.03312323987483978
Valid Loss:  0.03611307591199875
Epoch:  360  	Training Loss: 0.03709094971418381
Test Loss:  0.033122774213552475
Valid Loss:  0.036112718284130096
Epoch:  361  	Training Loss: 0.037090547382831573
Test Loss:  0.033122316002845764
Valid Loss:  0.03611235320568085
Epoch:  362  	Training Loss: 0.03709014505147934
Test Loss:  0.03312186151742935
Valid Loss:  0.03611199930310249
Epoch:  363  	Training Loss: 0.037089742720127106
Test Loss:  0.03312140703201294
Valid Loss:  0.03611164167523384
Epoch:  364  	Training Loss: 0.03708934038877487
Test Loss:  0.03312095254659653
Valid Loss:  0.03611128404736519
Epoch:  365  	Training Loss: 0.037088941782712936
Test Loss:  0.033120494335889816
Valid Loss:  0.036110930144786835
Epoch:  366  	Training Loss: 0.037088543176651
Test Loss:  0.033120039850473404
Valid Loss:  0.03611057251691818
Epoch:  367  	Training Loss: 0.03708814084529877
Test Loss:  0.03311958163976669
Valid Loss:  0.03611021488904953
Epoch:  368  	Training Loss: 0.03708773851394653
Test Loss:  0.03311913460493088
Valid Loss:  0.03610985726118088
Epoch:  369  	Training Loss: 0.0370873361825943
Test Loss:  0.03311867266893387
Valid Loss:  0.036109499633312225
Epoch:  370  	Training Loss: 0.037086937576532364
Test Loss:  0.03311821445822716
Valid Loss:  0.03610914573073387
Epoch:  371  	Training Loss: 0.03708653897047043
Test Loss:  0.033117763698101044
Valid Loss:  0.03610878810286522
Epoch:  372  	Training Loss: 0.037086136639118195
Test Loss:  0.033117301762104034
Valid Loss:  0.03610842302441597
Epoch:  373  	Training Loss: 0.037085726857185364
Test Loss:  0.033116839826107025
Valid Loss:  0.03610806167125702
Epoch:  374  	Training Loss: 0.03708531707525253
Test Loss:  0.033116377890110016
Valid Loss:  0.03610769286751747
Epoch:  375  	Training Loss: 0.0370849072933197
Test Loss:  0.03311591222882271
Valid Loss:  0.03610733523964882
Epoch:  376  	Training Loss: 0.03708450496196747
Test Loss:  0.0331154502928257
Valid Loss:  0.03610696643590927
Epoch:  377  	Training Loss: 0.03708409518003464
Test Loss:  0.03311498835682869
Valid Loss:  0.03610660880804062
Epoch:  378  	Training Loss: 0.03708368539810181
Test Loss:  0.03311452642083168
Valid Loss:  0.03610624372959137
Epoch:  379  	Training Loss: 0.037083279341459274
Test Loss:  0.03311406075954437
Valid Loss:  0.03610587492585182
Epoch:  380  	Training Loss: 0.03708287328481674
Test Loss:  0.03311359882354736
Valid Loss:  0.03610551357269287
Epoch:  381  	Training Loss: 0.03708246350288391
Test Loss:  0.033113136887550354
Valid Loss:  0.03610515221953392
Epoch:  382  	Training Loss: 0.03708205372095108
Test Loss:  0.033112671226263046
Valid Loss:  0.03610479086637497
Epoch:  383  	Training Loss: 0.03708164766430855
Test Loss:  0.033112213015556335
Valid Loss:  0.03610442578792572
Epoch:  384  	Training Loss: 0.03708123788237572
Test Loss:  0.03311174362897873
Valid Loss:  0.03610406070947647
Epoch:  385  	Training Loss: 0.037080831825733185
Test Loss:  0.03311128169298172
Valid Loss:  0.03610369563102722
Epoch:  386  	Training Loss: 0.037080422043800354
Test Loss:  0.03311081603169441
Valid Loss:  0.03610333055257797
Epoch:  387  	Training Loss: 0.03708001598715782
Test Loss:  0.0331103540956974
Valid Loss:  0.03610296547412872
Epoch:  388  	Training Loss: 0.03707960620522499
Test Loss:  0.033109888434410095
Valid Loss:  0.036102600395679474
Epoch:  389  	Training Loss: 0.03707919642329216
Test Loss:  0.03310942277312279
Valid Loss:  0.03610223904252052
Epoch:  390  	Training Loss: 0.03707879036664963
Test Loss:  0.03310896083712578
Valid Loss:  0.036101873964071274
Epoch:  391  	Training Loss: 0.0370783805847168
Test Loss:  0.03310849517583847
Valid Loss:  0.036101508885622025
Epoch:  392  	Training Loss: 0.037077970802783966
Test Loss:  0.03310804069042206
Valid Loss:  0.036101147532463074
Epoch:  393  	Training Loss: 0.037077564746141434
Test Loss:  0.03310757875442505
Valid Loss:  0.036100782454013824
Epoch:  394  	Training Loss: 0.0370771586894989
Test Loss:  0.03310711681842804
Valid Loss:  0.036100417375564575
Epoch:  395  	Training Loss: 0.03707674890756607
Test Loss:  0.03310665488243103
Valid Loss:  0.03610005974769592
Epoch:  396  	Training Loss: 0.03707634657621384
Test Loss:  0.03310619294643402
Valid Loss:  0.036099694669246674
Epoch:  397  	Training Loss: 0.037075936794281006
Test Loss:  0.03310573846101761
Valid Loss:  0.03609933704137802
Epoch:  398  	Training Loss: 0.03707553446292877
Test Loss:  0.0331052765250206
Valid Loss:  0.03609897196292877
Epoch:  399  	Training Loss: 0.03707512840628624
Test Loss:  0.03310481458902359
Valid Loss:  0.03609861060976982
Epoch:  400  	Training Loss: 0.03707472234964371
Test Loss:  0.03310435265302658
Valid Loss:  0.03609824925661087
Epoch:  401  	Training Loss: 0.03707432001829147
Test Loss:  0.03310389816761017
Valid Loss:  0.03609788417816162
Epoch:  402  	Training Loss: 0.03707391023635864
Test Loss:  0.03310342878103256
Valid Loss:  0.03609751909971237
Epoch:  403  	Training Loss: 0.03707350045442581
Test Loss:  0.033102959394454956
Valid Loss:  0.03609715774655342
Epoch:  404  	Training Loss: 0.03707309067249298
Test Loss:  0.03310249745845795
Valid Loss:  0.03609678894281387
Epoch:  405  	Training Loss: 0.03707267716526985
Test Loss:  0.03310203179717064
Valid Loss:  0.036096423864364624
Epoch:  406  	Training Loss: 0.03707227110862732
Test Loss:  0.03310156241059303
Valid Loss:  0.036096058785915375
Epoch:  407  	Training Loss: 0.03707185760140419
Test Loss:  0.033101096749305725
Valid Loss:  0.03609568625688553
Epoch:  408  	Training Loss: 0.03707144409418106
Test Loss:  0.03310063108801842
Valid Loss:  0.03609532117843628
Epoch:  409  	Training Loss: 0.03707103431224823
Test Loss:  0.03310016542673111
Valid Loss:  0.03609495609998703
Epoch:  410  	Training Loss: 0.0370706245303154
Test Loss:  0.0330996997654438
Valid Loss:  0.03609459474682808
Epoch:  411  	Training Loss: 0.03707021474838257
Test Loss:  0.033099234104156494
Valid Loss:  0.03609422594308853
Epoch:  412  	Training Loss: 0.03706980496644974
Test Loss:  0.033098772168159485
Valid Loss:  0.03609386831521988
Epoch:  413  	Training Loss: 0.037069402635097504
Test Loss:  0.03309831768274307
Valid Loss:  0.036093514412641525
Epoch:  414  	Training Loss: 0.03706900030374527
Test Loss:  0.03309786319732666
Valid Loss:  0.03609315678477287
Epoch:  415  	Training Loss: 0.037068601697683334
Test Loss:  0.03309740871191025
Valid Loss:  0.03609280288219452
Epoch:  416  	Training Loss: 0.0370681956410408
Test Loss:  0.03309694677591324
Valid Loss:  0.03609244152903557
Epoch:  417  	Training Loss: 0.03706779330968857
Test Loss:  0.033096492290496826
Valid Loss:  0.036092087626457214
Epoch:  418  	Training Loss: 0.037067390978336334
Test Loss:  0.033096037805080414
Valid Loss:  0.036091722548007965
Epoch:  419  	Training Loss: 0.0370669960975647
Test Loss:  0.033095575869083405
Valid Loss:  0.03609137237071991
Epoch:  420  	Training Loss: 0.03706659376621246
Test Loss:  0.03309512138366699
Valid Loss:  0.03609100729227066
Epoch:  421  	Training Loss: 0.03706618770956993
Test Loss:  0.03309466689825058
Valid Loss:  0.036090653389692307
Epoch:  422  	Training Loss: 0.037065789103507996
Test Loss:  0.03309420496225357
Valid Loss:  0.036090292036533356
Epoch:  423  	Training Loss: 0.03706538677215576
Test Loss:  0.03309375047683716
Valid Loss:  0.0360899344086647
Epoch:  424  	Training Loss: 0.03706498071551323
Test Loss:  0.03309328109025955
Valid Loss:  0.03608957678079605
Epoch:  425  	Training Loss: 0.037064578384160995
Test Loss:  0.03309283033013344
Valid Loss:  0.0360892191529274
Epoch:  426  	Training Loss: 0.03706417232751846
Test Loss:  0.03309236839413643
Valid Loss:  0.03608885407447815
Epoch:  427  	Training Loss: 0.03706376999616623
Test Loss:  0.03309191018342972
Valid Loss:  0.0360884964466095
Epoch:  428  	Training Loss: 0.037063367664813995
Test Loss:  0.03309144824743271
Valid Loss:  0.036088138818740845
Epoch:  429  	Training Loss: 0.037062957882881165
Test Loss:  86%|████████▌ | 429/500 [04:53<00:23,  3.02it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:00<00:27,  2.25it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.03it/s] 88%|████████▊ | 441/500 [05:06<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:13<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:20<00:30,  1.19it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.26it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.04it/s] 94%|█████████▍| 471/500 [05:26<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:34<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:41<00:00,  3.00it/s]100%|██████████| 500/500 [05:41<00:00,  1.47it/s]
 0.033090993762016296
Valid Loss:  0.036087777465581894
Epoch:  430  	Training Loss: 0.03706255555152893
Test Loss:  0.03309053182601929
Valid Loss:  0.03608741611242294
Epoch:  431  	Training Loss: 0.0370621532201767
Test Loss:  0.033090073615312576
Valid Loss:  0.03608705475926399
Epoch:  432  	Training Loss: 0.037061747163534164
Test Loss:  0.033089615404605865
Valid Loss:  0.03608669713139534
Epoch:  433  	Training Loss: 0.03706134110689163
Test Loss:  0.033089153468608856
Valid Loss:  0.03608633205294609
Epoch:  434  	Training Loss: 0.0370609387755394
Test Loss:  0.033088698983192444
Valid Loss:  0.03608597069978714
Epoch:  435  	Training Loss: 0.037060536444187164
Test Loss:  0.033088237047195435
Valid Loss:  0.03608561307191849
Epoch:  436  	Training Loss: 0.03706013038754463
Test Loss:  0.03308778256177902
Valid Loss:  0.03608525171875954
Epoch:  437  	Training Loss: 0.0370597243309021
Test Loss:  0.03308732062578201
Valid Loss:  0.036084890365600586
Epoch:  438  	Training Loss: 0.03705931827425957
Test Loss:  0.0330868661403656
Valid Loss:  0.03608452156186104
Epoch:  439  	Training Loss: 0.03705891594290733
Test Loss:  0.03308640420436859
Valid Loss:  0.036084167659282684
Epoch:  440  	Training Loss: 0.0370585136115551
Test Loss:  0.03308594599366188
Valid Loss:  0.036083802580833435
Epoch:  441  	Training Loss: 0.03705810755491257
Test Loss:  0.03308548778295517
Valid Loss:  0.03608344495296478
Epoch:  442  	Training Loss: 0.037057697772979736
Test Loss:  0.03308502584695816
Valid Loss:  0.03608307987451553
Epoch:  443  	Training Loss: 0.037057291716337204
Test Loss:  0.03308456391096115
Valid Loss:  0.036082714796066284
Epoch:  444  	Training Loss: 0.03705688565969467
Test Loss:  0.03308410197496414
Valid Loss:  0.03608235716819763
Epoch:  445  	Training Loss: 0.03705647587776184
Test Loss:  0.033083636313676834
Valid Loss:  0.03608199208974838
Epoch:  446  	Training Loss: 0.03705607354640961
Test Loss:  0.03308317810297012
Valid Loss:  0.03608162701129913
Epoch:  447  	Training Loss: 0.037055663764476776
Test Loss:  0.033082716166973114
Valid Loss:  0.03608126565814018
Epoch:  448  	Training Loss: 0.037055253982543945
Test Loss:  0.033082250505685806
Valid Loss:  0.03608090430498123
Epoch:  449  	Training Loss: 0.037054844200611115
Test Loss:  0.0330817885696888
Valid Loss:  0.03608053922653198
Epoch:  450  	Training Loss: 0.03705444186925888
Test Loss:  0.03308132663369179
Valid Loss:  0.03608018159866333
Epoch:  451  	Training Loss: 0.03705403581261635
Test Loss:  0.03308086469769478
Valid Loss:  0.03607981279492378
Epoch:  452  	Training Loss: 0.03705362603068352
Test Loss:  0.03308039903640747
Valid Loss:  0.03607945144176483
Epoch:  453  	Training Loss: 0.037053219974040985
Test Loss:  0.03307993710041046
Valid Loss:  0.03607909008860588
Epoch:  454  	Training Loss: 0.037052810192108154
Test Loss:  0.03307947516441345
Valid Loss:  0.03607872873544693
Epoch:  455  	Training Loss: 0.03705240413546562
Test Loss:  0.03307901322841644
Valid Loss:  0.03607835993170738
Epoch:  456  	Training Loss: 0.03705199807882309
Test Loss:  0.033078547567129135
Valid Loss:  0.03607799857854843
Epoch:  457  	Training Loss: 0.03705158829689026
Test Loss:  0.033078089356422424
Valid Loss:  0.03607763350009918
Epoch:  458  	Training Loss: 0.037051185965538025
Test Loss:  0.03307762369513512
Valid Loss:  0.03607727959752083
Epoch:  459  	Training Loss: 0.037050776183605194
Test Loss:  0.03307715803384781
Valid Loss:  0.03607691079378128
Epoch:  460  	Training Loss: 0.03705036640167236
Test Loss:  0.033076703548431396
Valid Loss:  0.03607654571533203
Epoch:  461  	Training Loss: 0.03704996407032013
Test Loss:  0.03307623416185379
Valid Loss:  0.03607618808746338
Epoch:  462  	Training Loss: 0.0370495542883873
Test Loss:  0.03307577967643738
Valid Loss:  0.03607582673430443
Epoch:  463  	Training Loss: 0.03704915568232536
Test Loss:  0.03307532146573067
Valid Loss:  0.036075472831726074
Epoch:  464  	Training Loss: 0.03704875335097313
Test Loss:  0.033074863255023956
Valid Loss:  0.03607511892914772
Epoch:  465  	Training Loss: 0.0370483472943306
Test Loss:  0.033074408769607544
Valid Loss:  0.03607475012540817
Epoch:  466  	Training Loss: 0.03704794496297836
Test Loss:  0.03307395428419113
Valid Loss:  0.03607439994812012
Epoch:  467  	Training Loss: 0.03704754263162613
Test Loss:  0.03307349979877472
Valid Loss:  0.036074042320251465
Epoch:  468  	Training Loss: 0.037047140300273895
Test Loss:  0.03307303786277771
Valid Loss:  0.03607368469238281
Epoch:  469  	Training Loss: 0.03704674541950226
Test Loss:  0.0330725833773613
Valid Loss:  0.03607332333922386
Epoch:  470  	Training Loss: 0.037046343088150024
Test Loss:  0.03307212516665459
Valid Loss:  0.03607296571135521
Epoch:  471  	Training Loss: 0.03704594075679779
Test Loss:  0.033071666955947876
Valid Loss:  0.036072611808776855
Epoch:  472  	Training Loss: 0.03704553842544556
Test Loss:  0.033071208745241165
Valid Loss:  0.0360722541809082
Epoch:  473  	Training Loss: 0.03704513609409332
Test Loss:  0.033070750534534454
Valid Loss:  0.036071889102458954
Epoch:  474  	Training Loss: 0.03704473003745079
Test Loss:  0.033070288598537445
Valid Loss:  0.0360715314745903
Epoch:  475  	Training Loss: 0.03704432398080826
Test Loss:  0.033069830387830734
Valid Loss:  0.03607117012143135
Epoch:  476  	Training Loss: 0.037043917924165726
Test Loss:  0.03306937217712402
Valid Loss:  0.0360708087682724
Epoch:  477  	Training Loss: 0.03704351559281349
Test Loss:  0.033068910241127014
Valid Loss:  0.03607045114040375
Epoch:  478  	Training Loss: 0.03704310953617096
Test Loss:  0.0330684557557106
Valid Loss:  0.0360700860619545
Epoch:  479  	Training Loss: 0.037042707204818726
Test Loss:  0.033067990094423294
Valid Loss:  0.036069728434085846
Epoch:  480  	Training Loss: 0.037042297422885895
Test Loss:  0.03306753188371658
Valid Loss:  0.036069370806217194
Epoch:  481  	Training Loss: 0.03704189881682396
Test Loss:  0.03306707367300987
Valid Loss:  0.03606900945305824
Epoch:  482  	Training Loss: 0.03704149276018143
Test Loss:  0.03306661546230316
Valid Loss:  0.03606864809989929
Epoch:  483  	Training Loss: 0.037041086703538895
Test Loss:  0.03306615352630615
Valid Loss:  0.03606829047203064
Epoch:  484  	Training Loss: 0.03704068064689636
Test Loss:  0.03306569159030914
Valid Loss:  0.03606792539358139
Epoch:  485  	Training Loss: 0.03704027831554413
Test Loss:  0.03306523337960243
Valid Loss:  0.03606756776571274
Epoch:  486  	Training Loss: 0.0370398685336113
Test Loss:  0.033064767718315125
Valid Loss:  0.03606720268726349
Epoch:  487  	Training Loss: 0.037039462476968765
Test Loss:  0.03306431323289871
Valid Loss:  0.03606684133410454
Epoch:  488  	Training Loss: 0.03703906014561653
Test Loss:  0.0330638512969017
Valid Loss:  0.03606647998094559
Epoch:  489  	Training Loss: 0.037038654088974
Test Loss:  0.03306339308619499
Valid Loss:  0.03606611490249634
Epoch:  490  	Training Loss: 0.03703824803233147
Test Loss:  0.03306293487548828
Valid Loss:  0.036065757274627686
Epoch:  491  	Training Loss: 0.037037841975688934
Test Loss:  0.033062469214200974
Valid Loss:  0.036065392196178436
Epoch:  492  	Training Loss: 0.0370374396443367
Test Loss:  0.03306199237704277
Valid Loss:  0.03606501966714859
Epoch:  493  	Training Loss: 0.037037014961242676
Test Loss:  0.03306151181459427
Valid Loss:  0.036064643412828445
Epoch:  494  	Training Loss: 0.03703659027814865
Test Loss:  0.03306103125214577
Valid Loss:  0.036064259707927704
Epoch:  495  	Training Loss: 0.037036169320344925
Test Loss:  0.033060550689697266
Valid Loss:  0.03606388717889786
Epoch:  496  	Training Loss: 0.0370357409119606
Test Loss:  0.033060066401958466
Valid Loss:  0.03606351464986801
Epoch:  497  	Training Loss: 0.03703532740473747
Test Loss:  0.03305958956480026
Valid Loss:  0.03606313467025757
Epoch:  498  	Training Loss: 0.03703489899635315
Test Loss:  0.03305910900235176
Valid Loss:  0.03606276214122772
Epoch:  499  	Training Loss: 0.03703448176383972
Test Loss:  0.03305862843990326
Valid Loss:  0.036062389612197876
Epoch:  500  	Training Loss: 0.0370340570807457
Test Loss:  0.033058151602745056
Valid Loss:  0.03606200963258743
seed is  2
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:54,  6.24s/it]  1%|          | 3/500 [00:06<13:49,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:48,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:19<13:07,  1.62s/it]  3%|▎         | 17/500 [00:19<09:07,  1.13s/it]  4%|▍         | 19/500 [00:19<06:25,  1.25it/s]  4%|▍         | 21/500 [00:26<12:16,  1.54s/it]  5%|▍         | 23/500 [00:26<08:39,  1.09s/it]  5%|▌         | 25/500 [00:32<13:38,  1.72s/it]  5%|▌         | 27/500 [00:32<09:38,  1.22s/it]  6%|▌         | 29/500 [00:32<06:51,  1.14it/s]  6%|▌         | 31/500 [00:39<12:12,  1.56s/it]  7%|▋         | 33/500 [00:39<08:40,  1.11s/it]  7%|▋         | 35/500 [00:39<06:11,  1.25it/s]  7%|▋         | 37/500 [00:39<04:27,  1.73it/s]  8%|▊         | 39/500 [00:39<03:15,  2.36it/s]  8%|▊         | 41/500 [00:46<09:30,  1.24s/it]  9%|▊         | 43/500 [00:46<06:47,  1.12it/s]  9%|▉         | 45/500 [00:46<04:54,  1.54it/s]  9%|▉         | 47/500 [00:46<03:36,  2.09it/s] 10%|▉         | 49/500 [00:46<02:41,  2.80it/s] 10%|█         | 51/500 [00:53<09:02,  1.21s/it] 11%|█         | 53/500 [00:53<06:27,  1.15it/s] 11%|█         | 55/500 [00:53<04:39,  1.59it/s] 11%|█▏        | 57/500 [00:53<03:23,  2.18it/s] 12%|█▏        | 59/500 [00:53<02:31,  2.92it/s] 12%|█▏        | 61/500 [00:59<08:39,  1.18s/it] 13%|█▎        | 63/500 [01:00<06:11,  1.18it/s] 13%|█▎        | 65/500 [01:00<04:28,  1.62it/s] 13%|█▎        | 67/500 [01:00<03:16,  2.21it/s]Epoch:  1  	Training Loss: 0.043680839240550995
Test Loss:  0.0341414250433445
Valid Loss:  0.034157540649175644
Epoch:  2  	Training Loss: 0.035383909940719604
Test Loss:  0.05103123188018799
Valid Loss:  0.05499453842639923
Epoch:  3  	Training Loss: 0.05361176282167435
Test Loss:  0.015866033732891083
Valid Loss:  0.01570064388215542
Epoch:  4  	Training Loss: 0.0166754312813282
Test Loss:  0.006865734700113535
Valid Loss:  0.007500407751649618
Epoch:  5  	Training Loss: 0.007944474928081036
Test Loss:  0.002432209672406316
Valid Loss:  0.0032521728426218033
Epoch:  6  	Training Loss: 0.003313901834189892
Test Loss:  0.0022977343760430813
Valid Loss:  0.0029861603397876024
Epoch:  7  	Training Loss: 0.003016900969669223
Test Loss:  0.0022203358821570873
Valid Loss:  0.0029037808999419212
Epoch:  8  	Training Loss: 0.002996874740347266
Test Loss:  0.002228192985057831
Valid Loss:  0.0027758697979152203
Epoch:  9  	Training Loss: 0.0028008297085762024
Test Loss:  0.002152099506929517
Valid Loss:  0.0028326488099992275
Epoch:  10  	Training Loss: 0.002913385396823287
Test Loss:  0.002137846313416958
Valid Loss:  0.0025617319624871016
Epoch:  11  	Training Loss: 0.0025944244116544724
Test Loss:  0.0020750872790813446
Valid Loss:  0.0027070147916674614
Epoch:  12  	Training Loss: 0.002779079368337989
Test Loss:  0.0027022995054721832
Valid Loss:  0.002051813993602991
Epoch:  13  	Training Loss: 0.0021305216941982508
Test Loss:  0.006060959305614233
Valid Loss:  0.006772220600396395
Epoch:  14  	Training Loss: 0.006684818770736456
Test Loss:  0.07047681510448456
Valid Loss:  0.06817875802516937
Epoch:  15  	Training Loss: 0.06819462031126022
Test Loss:  0.08473212271928787
Valid Loss:  0.07781463861465454
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.0816672295331955
Test Loss:  0.01813562586903572
Valid Loss:  0.02188165672123432
Epoch:  17  	Training Loss: 0.021211979910731316
Test Loss:  0.003724948037415743
Valid Loss:  0.005568763241171837
Epoch:  18  	Training Loss: 0.005536929704248905
Test Loss:  0.0030458546243608
Valid Loss:  0.004534846171736717
Epoch:  19  	Training Loss: 0.0045915162190794945
Test Loss:  0.002711313311010599
Valid Loss:  0.004059889353811741
Epoch:  20  	Training Loss: 0.004121416248381138
Test Loss:  0.0024335994385182858
Valid Loss:  0.0036796589847654104
Epoch:  21  	Training Loss: 0.0037357592955231667
Test Loss:  0.0022084685042500496
Valid Loss:  0.003361927345395088
Epoch:  22  	Training Loss: 0.0034114993177354336
Test Loss:  0.0020965076982975006
Valid Loss:  0.0029306034557521343
Epoch:  23  	Training Loss: 0.0030093626119196415
Test Loss:  0.002254665829241276
Valid Loss:  0.0032331321854144335
Epoch:  24  	Training Loss: 0.003234474454075098
Test Loss:  0.0036493486259132624
Valid Loss:  0.004361011553555727
Epoch:  25  	Training Loss: 0.004425945691764355
Test Loss:  0.004822206683456898
Valid Loss:  0.005960197187960148
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.005883804056793451
Test Loss:  0.002171663101762533
Valid Loss:  0.0030760145746171474
Epoch:  27  	Training Loss: 0.003079263726249337
Test Loss:  0.0017374383751302958
Valid Loss:  0.002562733367085457
Epoch:  28  	Training Loss: 0.0025855121202766895
Test Loss:  0.0015659795608371496
Valid Loss:  0.002331236144527793
Epoch:  29  	Training Loss: 0.0023597292602062225
Test Loss:  0.0014672772958874702
Valid Loss:  0.0021796743385493755
Epoch:  30  	Training Loss: 0.002204595133662224
Test Loss:  0.0013765827752649784
Valid Loss:  0.00203436566516757
Epoch:  31  	Training Loss: 0.0020571467466652393
Test Loss:  0.0013474981533363461
Valid Loss:  0.0019560446962714195
Epoch:  32  	Training Loss: 0.001982199726626277
Test Loss:  0.0012286249548196793
Valid Loss:  0.001688848016783595
Epoch:  33  	Training Loss: 0.0017225523479282856
Test Loss:  0.001206702901981771
Valid Loss:  0.0016497105825692415
Epoch:  34  	Training Loss: 0.0016815916169434786
Test Loss:  0.0011948816245421767
Valid Loss:  0.0016253767535090446
Epoch:  35  	Training Loss: 0.0016562147065997124
Test Loss:  0.0011859266087412834
Valid Loss:  0.001603554468601942
Epoch:  36  	Training Loss: 0.0016341404989361763
Test Loss:  0.001178415142931044
Valid Loss:  0.0015837399987503886
Epoch:  37  	Training Loss: 0.0016136390622705221
Test Loss:  0.0011713625863194466
Valid Loss:  0.0015645972453057766
Epoch:  38  	Training Loss: 0.0015941576566547155
Test Loss:  0.0011650212109088898
Valid Loss:  0.0015462611336261034
Epoch:  39  	Training Loss: 0.0015760349342599511
Test Loss:  0.0011589144123718143
Valid Loss:  0.001528627471998334
Epoch:  40  	Training Loss: 0.001558719901368022
Test Loss:  0.0011530392803251743
Valid Loss:  0.0015117006842046976
Epoch:  41  	Training Loss: 0.0015422352589666843
Test Loss:  0.0011473798658698797
Valid Loss:  0.0014959560940042138
Epoch:  42  	Training Loss: 0.0015265783295035362
Test Loss:  0.0011395665351301432
Valid Loss:  0.0014735396252945065
Epoch:  43  	Training Loss: 0.0015042955055832863
Test Loss:  0.0011331061832606792
Valid Loss:  0.001453442731872201
Epoch:  44  	Training Loss: 0.0014842816162854433
Test Loss:  0.0011271501425653696
Valid Loss:  0.0014345040544867516
Epoch:  45  	Training Loss: 0.0014656016137450933
Test Loss:  0.0011218831641599536
Valid Loss:  0.0014172301162034273
Epoch:  46  	Training Loss: 0.0014486182481050491
Test Loss:  0.0011170385405421257
Valid Loss:  0.0014012588653713465
Epoch:  47  	Training Loss: 0.0014326220843940973
Test Loss:  0.001112654572352767
Valid Loss:  0.001386080402880907
Epoch:  48  	Training Loss: 0.0014177014818415046
Test Loss:  0.0011091114720329642
Valid Loss:  0.00137234793510288
Epoch:  49  	Training Loss: 0.001404107897542417
Test Loss:  0.0011060278629884124
Valid Loss:  0.0013597081415355206
Epoch:  50  	Training Loss: 0.001391267403960228
Test Loss:  0.0011032356414943933
Valid Loss:  0.0013477010652422905
Epoch:  51  	Training Loss: 0.0013791072415187955
Test Loss:  0.0011007653083652258
Valid Loss:  0.0013363155303522944
Epoch:  52  	Training Loss: 0.0013675413792952895
Test Loss:  0.0011057138908654451
Valid Loss:  0.0013120246585458517
Epoch:  53  	Training Loss: 0.0013398760929703712
Test Loss:  0.0011136296670883894
Valid Loss:  0.0012970233801752329
Epoch:  54  	Training Loss: 0.001321578398346901
Test Loss:  0.001122556161135435
Valid Loss:  0.0012884339084848762
Epoch:  55  	Training Loss: 0.001310628722421825
Test Loss:  0.0011310380650684237
Valid Loss:  0.0012828565668314695
Epoch:  56  	Training Loss: 0.0013039058540016413
Test Loss:  0.0011387771228328347
Valid Loss:  0.0012790535110980272
Epoch:  57  	Training Loss: 0.0012991727562621236
Test Loss:  0.0011454424820840359
Valid Loss:  0.0012764735147356987
Epoch:  58  	Training Loss: 0.0012961019529029727
Test Loss:  0.0011511612683534622
Valid Loss:  0.0012748781591653824
Epoch:  59  	Training Loss: 0.0012938060099259019
Test Loss:  0.0011561699211597443
Valid Loss:  0.001273728790692985
Epoch:  60  	Training Loss: 0.001292145811021328
Test Loss:  0.001160342013463378
Valid Loss:  0.0012727733701467514
Epoch:  61  	Training Loss: 0.0012909015640616417
Test Loss:  0.0011638879077509046
Valid Loss:  0.0012720082886517048
Epoch:  62  	Training Loss: 0.0012899070279672742
Test Loss:  0.0011161633301526308
Valid Loss:  0.0012152203125879169
Epoch:  63  	Training Loss: 0.0012322685215622187
Test Loss:  0.0010743379825726151
Valid Loss:  0.001165570574812591
Epoch:  64  	Training Loss: 0.0011799372732639313
Test Loss:  0.0010348743526265025
Valid Loss:  0.0011194683611392975
Epoch:  65  	Training Loss: 0.001131337834522128
Test Loss:  0.0009978297166526318
Valid Loss:  0.0010765364859253168
Epoch:  66  	Training Loss: 0.0010861036134883761
Test Loss:  0.0009638126939535141
Valid Loss:  0.0010366305941715837
Epoch:  67  	Training Loss: 0.0010441094636917114
Test Loss:  0.0009314346825703979
Valid Loss:  0.0009992222767323256
Epoch:  68  	Training Loss: 0.001004919409751892
Test Loss:  0.000902727129869163
 14%|█▍        | 69/500 [01:00<02:25,  2.97it/s] 14%|█▍        | 71/500 [01:06<08:27,  1.18s/it] 15%|█▍        | 73/500 [01:06<06:03,  1.18it/s] 15%|█▌        | 75/500 [01:07<04:21,  1.63it/s] 15%|█▌        | 77/500 [01:07<03:10,  2.22it/s] 16%|█▌        | 79/500 [01:07<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:13<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:13<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:13<04:12,  1.65it/s] 17%|█▋        | 87/500 [01:13<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:14<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:20<07:58,  1.17s/it] 19%|█▊        | 93/500 [01:20<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:20<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:20<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:20<02:12,  3.02it/s] 20%|██        | 101/500 [01:27<07:45,  1.17s/it] 21%|██        | 103/500 [01:27<05:32,  1.19it/s] 21%|██        | 105/500 [01:27<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:27<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:27<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:33<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:34<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:34<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:34<02:52,  2.23it/s] 24%|██▍       | 119/500 [01:34<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:40<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:41<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:41<03:50,  1.62it/s] 25%|██▌       | 127/500 [01:41<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:41<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:47<07:13,  1.17s/it] 27%|██▋       | 133/500 [01:47<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:47<03:43,  1.63it/s]Valid Loss:  0.0009653465240262449
Epoch:  69  	Training Loss: 0.0009684909600764513
Test Loss:  0.0008760566706769168
Valid Loss:  0.0009340621181763709
Epoch:  70  	Training Loss: 0.0009347667219117284
Test Loss:  0.0008513863431289792
Valid Loss:  0.0009044319158419967
Epoch:  71  	Training Loss: 0.0009032386587932706
Test Loss:  0.0008281905320473015
Valid Loss:  0.0008766863611526787
Epoch:  72  	Training Loss: 0.0008738638716749847
Test Loss:  0.0008216286078095436
Valid Loss:  0.0008699248428456485
Epoch:  73  	Training Loss: 0.0008675878052599728
Test Loss:  0.0008160874713212252
Valid Loss:  0.0008637697319500148
Epoch:  74  	Training Loss: 0.0008619101718068123
Test Loss:  0.0008110269554890692
Valid Loss:  0.0008581627043895423
Epoch:  75  	Training Loss: 0.0008564938325434923
Test Loss:  0.0008063582936301827
Valid Loss:  0.0008527847821824253
Epoch:  76  	Training Loss: 0.0008512962376698852
Test Loss:  0.0008022802066989243
Valid Loss:  0.0008476045331917703
Epoch:  77  	Training Loss: 0.0008463225094601512
Test Loss:  0.0007983571849763393
Valid Loss:  0.00084256986156106
Epoch:  78  	Training Loss: 0.0008414818439632654
Test Loss:  0.0007946779951453209
Valid Loss:  0.0008376364130526781
Epoch:  79  	Training Loss: 0.0008367865812033415
Test Loss:  0.0007912084111012518
Valid Loss:  0.0008329122792929411
Epoch:  80  	Training Loss: 0.0008323256624862552
Test Loss:  0.0007879715994931757
Valid Loss:  0.0008286936208605766
Epoch:  81  	Training Loss: 0.0008280659676529467
Test Loss:  0.0007847801898606122
Valid Loss:  0.0008245419012382627
Epoch:  82  	Training Loss: 0.0008238916634581983
Test Loss:  0.0007862437050789595
Valid Loss:  0.0008246678626164794
Epoch:  83  	Training Loss: 0.0008228578371927142
Test Loss:  0.0007876585004851222
Valid Loss:  0.0008246098877862096
Epoch:  84  	Training Loss: 0.0008223983459174633
Test Loss:  0.000788901699706912
Valid Loss:  0.0008244004566222429
Epoch:  85  	Training Loss: 0.0008220294257625937
Test Loss:  0.0007900334312580526
Valid Loss:  0.0008243027841672301
Epoch:  86  	Training Loss: 0.0008217006688937545
Test Loss:  0.0007910822751000524
Valid Loss:  0.0008242138428613544
Epoch:  87  	Training Loss: 0.0008214148692786694
Test Loss:  0.0007918716873973608
Valid Loss:  0.0008240745519287884
Epoch:  88  	Training Loss: 0.0008212063112296164
Test Loss:  0.0007926230318844318
Valid Loss:  0.0008239773451350629
Epoch:  89  	Training Loss: 0.0008210184751078486
Test Loss:  0.000793342653196305
Valid Loss:  0.0008239078451879323
Epoch:  90  	Training Loss: 0.0008208485669456422
Test Loss:  0.0007940143113955855
Valid Loss:  0.0008238452137447894
Epoch:  91  	Training Loss: 0.0008206916972994804
Test Loss:  0.0007946417899802327
Valid Loss:  0.0008237857255153358
Epoch:  92  	Training Loss: 0.0008205479243770242
Test Loss:  0.000795114494394511
Valid Loss:  0.0008233713451772928
Epoch:  93  	Training Loss: 0.0008200387237593532
Test Loss:  0.000795557803940028
Valid Loss:  0.000822988455183804
Epoch:  94  	Training Loss: 0.0008195765549317002
Test Loss:  0.0007959386566653848
Valid Loss:  0.0008225925266742706
Epoch:  95  	Training Loss: 0.000819131382741034
Test Loss:  0.000796325271949172
Valid Loss:  0.0008222569595091045
Epoch:  96  	Training Loss: 0.0008187470957636833
Test Loss:  0.0007966777193360031
Valid Loss:  0.0008219449082389474
Epoch:  97  	Training Loss: 0.0008183815516531467
Test Loss:  0.0007970002479851246
Valid Loss:  0.0008216385613195598
Epoch:  98  	Training Loss: 0.0008180461591109633
Test Loss:  0.0007973170722834766
Valid Loss:  0.0008213708642870188
Epoch:  99  	Training Loss: 0.0008177290437743068
Test Loss:  0.0007975881453603506
Valid Loss:  0.0008211026433855295
Epoch:  100  	Training Loss: 0.0008174166432581842
Test Loss:  0.0007978202775120735
Valid Loss:  0.0008208306971937418
Epoch:  101  	Training Loss: 0.0008171076187863946
Test Loss:  0.0007980175432749093
Valid Loss:  0.0008205549092963338
Epoch:  102  	Training Loss: 0.0008168022613972425
Test Loss:  0.0007945018005557358
Valid Loss:  0.0008136737742461264
Epoch:  103  	Training Loss: 0.0008101066923700273
Test Loss:  0.0007901574717834592
Valid Loss:  0.0008065971196629107
Epoch:  104  	Training Loss: 0.0008033926133066416
Test Loss:  0.0007856538286432624
Valid Loss:  0.0007990955491550267
Epoch:  105  	Training Loss: 0.0007962677045725286
Test Loss:  0.0007798091974109411
Valid Loss:  0.0007912775035947561
Epoch:  106  	Training Loss: 0.0007888185791671276
Test Loss:  0.0007738567073829472
Valid Loss:  0.0007833772106096148
Epoch:  107  	Training Loss: 0.0007808343507349491
Test Loss:  0.0007672732463106513
Valid Loss:  0.0007749045034870505
Epoch:  108  	Training Loss: 0.0007721834699623287
Test Loss:  0.0007607870502397418
Valid Loss:  0.0007659103139303625
Epoch:  109  	Training Loss: 0.0007631771150045097
Test Loss:  0.000753136700950563
Valid Loss:  0.0007562990067526698
Epoch:  110  	Training Loss: 0.0007537404890172184
Test Loss:  0.0007458017207682133
Valid Loss:  0.00074662925908342
Epoch:  111  	Training Loss: 0.000744358345400542
Test Loss:  0.000738447648473084
Valid Loss:  0.0007370732491835952
Epoch:  112  	Training Loss: 0.0007350630476139486
Test Loss:  0.0007389649981632829
Valid Loss:  0.0007370405364781618
Epoch:  113  	Training Loss: 0.0007349465740844607
Test Loss:  0.000739438459277153
Valid Loss:  0.0007369943195953965
Epoch:  114  	Training Loss: 0.0007348390063270926
Test Loss:  0.0007398737943731248
Valid Loss:  0.0007369488012045622
Epoch:  115  	Training Loss: 0.0007347391219809651
Test Loss:  0.0007402750779874623
Valid Loss:  0.0007369053782895207
Epoch:  116  	Training Loss: 0.0007346454076468945
Test Loss:  0.0007406441727653146
Valid Loss:  0.0007368646911345422
Epoch:  117  	Training Loss: 0.0007345580961555243
Test Loss:  0.0007409841055050492
Valid Loss:  0.0007368265651166439
Epoch:  118  	Training Loss: 0.0007344756741076708
Test Loss:  0.0007412954000756145
Valid Loss:  0.0007367895450443029
Epoch:  119  	Training Loss: 0.0007343977340497077
Test Loss:  0.0007415796862915158
Valid Loss:  0.0007367547368630767
Epoch:  120  	Training Loss: 0.0007343237521126866
Test Loss:  0.0007418401073664427
Valid Loss:  0.0007367230718955398
Epoch:  121  	Training Loss: 0.0007342526223510504
Test Loss:  0.0007420781184919178
Valid Loss:  0.0007366919307969511
Epoch:  122  	Training Loss: 0.0007341850432567298
Test Loss:  0.0007412288105115294
Valid Loss:  0.0007367180660367012
Epoch:  123  	Training Loss: 0.00073413853533566
Test Loss:  0.0007404970820061862
Valid Loss:  0.0007367376238107681
Epoch:  124  	Training Loss: 0.0007341016316786408
Test Loss:  0.0007398605812340975
Valid Loss:  0.00073674984741956
Epoch:  125  	Training Loss: 0.0007340713054873049
Test Loss:  0.0007392998086288571
Valid Loss:  0.0007367577054537833
Epoch:  126  	Training Loss: 0.0007340461597777903
Test Loss:  0.0007388020167127252
Valid Loss:  0.0007367599755525589
Epoch:  127  	Training Loss: 0.0007340238080359995
Test Loss:  0.0007383570773527026
Valid Loss:  0.0007367577636614442
Epoch:  128  	Training Loss: 0.0007340040756389499
Test Loss:  0.0007379535818472505
Valid Loss:  0.0007367515936493874
Epoch:  129  	Training Loss: 0.0007339861476793885
Test Loss:  0.000737586582545191
Valid Loss:  0.0007367426878772676
Epoch:  130  	Training Loss: 0.0007339692674577236
Test Loss:  0.0007372471736744046
Valid Loss:  0.0007367314537987113
Epoch:  131  	Training Loss: 0.0007339540752582252
Test Loss:  0.0007369340164586902
Valid Loss:  0.000736718182452023
Epoch:  132  	Training Loss: 0.0007339391740970314
Test Loss:  0.0007205301662907004
Valid Loss:  0.0007174814236350358
Epoch:  133  	Training Loss: 0.0007145978161133826
Test Loss:  0.000703232828527689
Valid Loss:  0.000701055396348238
Epoch:  134  	Training Loss: 0.000697240000590682
Test Loss:  0.0006866548210382462
Valid Loss:  0.0006857927655801177
Epoch:  135  	Training Loss: 0.0006808314938098192
Test Loss:  0.0006712073227390647
Valid Loss:  0.0006717451615259051
Epoch:  136  	Training Loss: 0.0006654981407336891
Test Loss:  0.0006573594291694462
Valid Loss:  0.000658600649330765
Epoch:  137  	Training Loss: 0.0006512610707432032
 27%|██▋       | 137/500 [01:48<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:48<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:54<07:03,  1.18s/it] 29%|██▊       | 143/500 [01:54<05:03,  1.17it/s] 29%|██▉       | 145/500 [01:54<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:55<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:55<01:58,  2.97it/s] 30%|███       | 151/500 [02:01<07:01,  1.21s/it] 31%|███       | 153/500 [02:01<05:00,  1.15it/s] 31%|███       | 155/500 [02:01<03:35,  1.60it/s] 31%|███▏      | 157/500 [02:02<02:36,  2.19it/s] 32%|███▏      | 159/500 [02:02<01:55,  2.94it/s] 32%|███▏      | 161/500 [02:08<06:55,  1.23s/it] 33%|███▎      | 163/500 [02:08<04:56,  1.14it/s] 33%|███▎      | 165/500 [02:08<03:32,  1.57it/s] 33%|███▎      | 167/500 [02:09<02:34,  2.15it/s] 34%|███▍      | 169/500 [02:09<01:54,  2.89it/s] 34%|███▍      | 171/500 [02:15<06:48,  1.24s/it] 35%|███▍      | 173/500 [02:16<04:50,  1.12it/s] 35%|███▌      | 175/500 [02:16<03:28,  1.56it/s] 35%|███▌      | 177/500 [02:16<02:31,  2.13it/s] 36%|███▌      | 179/500 [02:16<01:52,  2.85it/s] 36%|███▌      | 181/500 [02:22<06:28,  1.22s/it] 37%|███▋      | 183/500 [02:23<04:37,  1.14it/s] 37%|███▋      | 185/500 [02:23<03:18,  1.58it/s] 37%|███▋      | 187/500 [02:23<02:24,  2.17it/s] 38%|███▊      | 189/500 [02:23<01:46,  2.92it/s] 38%|███▊      | 191/500 [02:29<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:30<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:30<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:30<02:19,  2.18it/s] 40%|███▉      | 199/500 [02:30<01:42,  2.93it/s] 40%|████      | 201/500 [02:36<05:51,  1.18s/it] 41%|████      | 203/500 [02:36<04:11,  1.18it/s]Test Loss:  0.0006446759216487408
Valid Loss:  0.0006461478187702596
Epoch:  138  	Training Loss: 0.000637842807918787
Test Loss:  0.0006329624447971582
Valid Loss:  0.0006342713604681194
Epoch:  139  	Training Loss: 0.0006250684382393956
Test Loss:  0.0006221443763934076
Valid Loss:  0.0006229471764527261
Epoch:  140  	Training Loss: 0.000612901640124619
Test Loss:  0.0006119770696386695
Valid Loss:  0.0006121422629803419
Epoch:  141  	Training Loss: 0.0006013159872964025
Test Loss:  0.0006024687318131328
Valid Loss:  0.0006018996355123818
Epoch:  142  	Training Loss: 0.0005904295830987394
Test Loss:  0.0005937671521678567
Valid Loss:  0.0005978906410746276
Epoch:  143  	Training Loss: 0.0005852080648764968
Test Loss:  0.0005884728161618114
Valid Loss:  0.0005938067915849388
Epoch:  144  	Training Loss: 0.0005810369038954377
Test Loss:  0.0005846056737937033
Valid Loss:  0.0005898383678868413
Epoch:  145  	Training Loss: 0.0005772251752205193
Test Loss:  0.0005814859177917242
Valid Loss:  0.0005860428791493177
Epoch:  146  	Training Loss: 0.0005736856255680323
Test Loss:  0.0005792201845906675
Valid Loss:  0.0005824781255796552
Epoch:  147  	Training Loss: 0.0005704756476916373
Test Loss:  0.0005771599244326353
Valid Loss:  0.0005790647119283676
Epoch:  148  	Training Loss: 0.0005673801642842591
Test Loss:  0.0005751623539254069
Valid Loss:  0.0005757417529821396
Epoch:  149  	Training Loss: 0.0005643629119731486
Test Loss:  0.0005732346326112747
Valid Loss:  0.0005724910879507661
Epoch:  150  	Training Loss: 0.00056140695232898
Test Loss:  0.0005712476558983326
Valid Loss:  0.0005693257553502917
Epoch:  151  	Training Loss: 0.0005585248582065105
Test Loss:  0.000569709634874016
Valid Loss:  0.0005663649062626064
Epoch:  152  	Training Loss: 0.0005557886324822903
Test Loss:  0.0005643332842737436
Valid Loss:  0.0005581314908340573
Epoch:  153  	Training Loss: 0.0005484145949594676
Test Loss:  0.0005598737625405192
Valid Loss:  0.0005516393575817347
Epoch:  154  	Training Loss: 0.0005418140790425241
Test Loss:  0.0005558839766308665
Valid Loss:  0.00054537522373721
Epoch:  155  	Training Loss: 0.0005356199108064175
Test Loss:  0.000552451005205512
Valid Loss:  0.0005395864136517048
Epoch:  156  	Training Loss: 0.0005302971694618464
Test Loss:  0.0005498495884239674
Valid Loss:  0.0005347095429897308
Epoch:  157  	Training Loss: 0.0005260217003524303
Test Loss:  0.0005475057405419648
Valid Loss:  0.0005311898421496153
Epoch:  158  	Training Loss: 0.0005226376233622432
Test Loss:  0.0005455702776089311
Valid Loss:  0.0005285252118483186
Epoch:  159  	Training Loss: 0.0005200032028369606
Test Loss:  0.0005441932007670403
Valid Loss:  0.0005264387000352144
Epoch:  160  	Training Loss: 0.0005177780403755605
Test Loss:  0.0005429584416560829
Valid Loss:  0.0005247900262475014
Epoch:  161  	Training Loss: 0.0005158840795047581
Test Loss:  0.0005418491782620549
Valid Loss:  0.000523341353982687
Epoch:  162  	Training Loss: 0.000514335697516799
Test Loss:  0.0005425459239631891
Valid Loss:  0.0005234224954620004
Epoch:  163  	Training Loss: 0.0005141741130501032
Test Loss:  0.0005437408108264208
Valid Loss:  0.000523374299518764
Epoch:  164  	Training Loss: 0.0005140552530065179
Test Loss:  0.0005448583979159594
Valid Loss:  0.0005233311094343662
Epoch:  165  	Training Loss: 0.0005139614222571254
Test Loss:  0.0005458613159134984
Valid Loss:  0.0005233006086200476
Epoch:  166  	Training Loss: 0.0005138867418281734
Test Loss:  0.000546755560208112
Valid Loss:  0.0005232797702774405
Epoch:  167  	Training Loss: 0.0005138273118063807
Test Loss:  0.0005475521320477128
Valid Loss:  0.0005232661496847868
Epoch:  168  	Training Loss: 0.0005137801636010408
Test Loss:  0.0005482619162648916
Valid Loss:  0.0005232589901424944
Epoch:  169  	Training Loss: 0.0005137420957908034
Test Loss:  0.000548892596270889
Valid Loss:  0.000523255905136466
Epoch:  170  	Training Loss: 0.0005137113621458411
Test Loss:  0.000549452961422503
Valid Loss:  0.000523254566360265
Epoch:  171  	Training Loss: 0.0005136862164363265
Test Loss:  0.0005499518592841923
Valid Loss:  0.0005232552066445351
Epoch:  172  	Training Loss: 0.0005136653780937195
Test Loss:  0.0005410991725511849
Valid Loss:  0.0005137609550729394
Epoch:  173  	Training Loss: 0.000504985568113625
Test Loss:  0.0005347867263481021
Valid Loss:  0.0005067713791504502
Epoch:  174  	Training Loss: 0.0004976412164978683
Test Loss:  0.0005290590925142169
Valid Loss:  0.0005004742415621877
Epoch:  175  	Training Loss: 0.0004907484981231391
Test Loss:  0.0005237850127741694
Valid Loss:  0.0004945594118908048
Epoch:  176  	Training Loss: 0.0004843135830014944
Test Loss:  0.0005189613439142704
Valid Loss:  0.0004889777628704906
Epoch:  177  	Training Loss: 0.00047830736730247736
Test Loss:  0.0005148188211023808
Valid Loss:  0.00048367289127781987
Epoch:  178  	Training Loss: 0.0004726752813439816
Test Loss:  0.0005110015044920146
Valid Loss:  0.0004787181969732046
Epoch:  179  	Training Loss: 0.0004673295479733497
Test Loss:  0.0005073763895779848
Valid Loss:  0.0004739841679111123
Epoch:  180  	Training Loss: 0.000462227500975132
Test Loss:  0.0005040050600655377
Valid Loss:  0.00046947336522862315
Epoch:  181  	Training Loss: 0.0004573906189762056
Test Loss:  0.0005007914151065052
Valid Loss:  0.00046510808169841766
Epoch:  182  	Training Loss: 0.00045274884905666113
Test Loss:  0.0005008014850318432
Valid Loss:  0.00046511608525179327
Epoch:  183  	Training Loss: 0.0004527040582615882
Test Loss:  0.0005008308216929436
Valid Loss:  0.00046512371045537293
Epoch:  184  	Training Loss: 0.0004526614211499691
Test Loss:  0.0005008676671423018
Valid Loss:  0.0004651297349482775
Epoch:  185  	Training Loss: 0.00045262015191838145
Test Loss:  0.0005009123706258833
Valid Loss:  0.0004651360504794866
Epoch:  186  	Training Loss: 0.00045258080353960395
Test Loss:  0.0005009634769521654
Valid Loss:  0.00046514204586856067
Epoch:  187  	Training Loss: 0.00045254264841787517
Test Loss:  0.0005010212771594524
Valid Loss:  0.00046514649875462055
Epoch:  188  	Training Loss: 0.00045250647235661745
Test Loss:  0.0005010865861549973
Valid Loss:  0.0004651505150832236
Epoch:  189  	Training Loss: 0.0004524728865362704
Test Loss:  0.0005011550965718925
Valid Loss:  0.000465152261313051
Epoch:  190  	Training Loss: 0.0004524411051534116
Test Loss:  0.0005012299516238272
Valid Loss:  0.0004651526687666774
Epoch:  191  	Training Loss: 0.0004524103715084493
Test Loss:  0.0005013073096051812
Valid Loss:  0.00046515290159732103
Epoch:  192  	Training Loss: 0.0004523844690993428
Test Loss:  0.0004993260372430086
Valid Loss:  0.00046332820784300566
Epoch:  193  	Training Loss: 0.0004503130621742457
Test Loss:  0.0004977118223905563
Valid Loss:  0.00046132662100717425
Epoch:  194  	Training Loss: 0.00044837043969891965
Test Loss:  0.0004961859667673707
Valid Loss:  0.0004593252087943256
Epoch:  195  	Training Loss: 0.00044648852781392634
Test Loss:  0.0004947233246639371
Valid Loss:  0.00045736192259937525
Epoch:  196  	Training Loss: 0.0004446767270565033
Test Loss:  0.0004933119053021073
Valid Loss:  0.0004554655170068145
Epoch:  197  	Training Loss: 0.00044291443191468716
Test Loss:  0.0004919421044178307
Valid Loss:  0.00045360298827290535
Epoch:  198  	Training Loss: 0.00044119195081293583
Test Loss:  0.000490671896841377
Valid Loss:  0.00045180978486314416
Epoch:  199  	Training Loss: 0.0004395463038235903
Test Loss:  0.0004894351586699486
Valid Loss:  0.00045012321788817644
Epoch:  200  	Training Loss: 0.00043792452197521925
Test Loss:  0.0004882388166151941
Valid Loss:  0.00044847221579402685
Epoch:  201  	Training Loss: 0.00043632753659039736
Test Loss:  0.0004870858392678201
Valid Loss:  0.0004468505212571472
Epoch:  202  	Training Loss: 0.00043476096470840275
Test Loss:  0.00048718584002926946
Valid Loss:  0.0004468352999538183
Epoch:  203  	Training Loss: 0.00043464970076456666
Test Loss:  0.00048730787239037454
Valid Loss:  0.00044677534606307745
Epoch:  204  	Training Loss: 0.0004345453926362097
Test Loss:  0.0004874418373219669
Valid Loss:  0.0004466948739718646
Epoch:  205  	Training Loss: 0.00043444568291306496
Test Loss:   41%|████      | 205/500 [02:37<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:37<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:37<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:43<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:43<04:02,  1.19it/s] 43%|████▎     | 215/500 [02:43<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:43<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:44<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:50<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:50<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:50<02:49,  1.63it/s] 45%|████▌     | 227/500 [02:50<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:50<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:57<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:57<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:57<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:57<01:58,  2.23it/s] 48%|████▊     | 239/500 [02:57<01:27,  2.99it/s] 48%|████▊     | 241/500 [03:04<05:04,  1.17s/it] 49%|████▊     | 243/500 [03:04<03:37,  1.18it/s] 49%|████▉     | 245/500 [03:04<02:35,  1.64it/s] 49%|████▉     | 247/500 [03:04<01:53,  2.24it/s] 50%|████▉     | 249/500 [03:04<01:23,  3.01it/s] 50%|█████     | 251/500 [03:10<04:53,  1.18s/it] 51%|█████     | 253/500 [03:11<03:29,  1.18it/s] 51%|█████     | 255/500 [03:11<02:29,  1.63it/s] 51%|█████▏    | 257/500 [03:11<01:48,  2.23it/s] 52%|█████▏    | 259/500 [03:11<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:17<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:17<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:18<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:18<01:45,  2.22it/s] 54%|█████▍    | 269/500 [03:18<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:24<04:33,  1.19s/it]0.00048757786862552166
Valid Loss:  0.00044660299317911267
Epoch:  206  	Training Loss: 0.00043434681720100343
Test Loss:  0.00048771093133836985
Valid Loss:  0.00044650453492067754
Epoch:  207  	Training Loss: 0.0004342486790847033
Test Loss:  0.00048784021055325866
Valid Loss:  0.0004464043886400759
Epoch:  208  	Training Loss: 0.00043415138497948647
Test Loss:  0.0004879655025433749
Valid Loss:  0.0004463026416487992
Epoch:  209  	Training Loss: 0.0004340546147432178
Test Loss:  0.0004880874475929886
Valid Loss:  0.00044620115659199655
Epoch:  210  	Training Loss: 0.0004339588340371847
Test Loss:  0.00048820412484928966
Valid Loss:  0.0004460994969122112
Epoch:  211  	Training Loss: 0.00043386316974647343
Test Loss:  0.00048831693129614
Valid Loss:  0.0004459987103473395
Epoch:  212  	Training Loss: 0.0004337682039476931
Test Loss:  0.00048771026195026934
Valid Loss:  0.00044417561730369925
Epoch:  213  	Training Loss: 0.0004319965955801308
Test Loss:  0.0004870162229053676
Valid Loss:  0.0004423903301358223
Epoch:  214  	Training Loss: 0.0004302524612285197
Test Loss:  0.0004862594068981707
Valid Loss:  0.00044063368113711476
Epoch:  215  	Training Loss: 0.000428533589001745
Test Loss:  0.00048546300968155265
Valid Loss:  0.00043890770757570863
Epoch:  216  	Training Loss: 0.00042684676009230316
Test Loss:  0.00048462703125551343
Valid Loss:  0.00043720865505747497
Epoch:  217  	Training Loss: 0.00042518862755969167
Test Loss:  0.00048375141341239214
Valid Loss:  0.000435533031122759
Epoch:  218  	Training Loss: 0.0004235516826156527
Test Loss:  0.00048283449723385274
Valid Loss:  0.0004338753642514348
Epoch:  219  	Training Loss: 0.00042193097760900855
Test Loss:  0.00048189208609983325
Valid Loss:  0.0004322342574596405
Epoch:  220  	Training Loss: 0.0004203385906293988
Test Loss:  0.00048100249841809273
Valid Loss:  0.000430645071901381
Epoch:  221  	Training Loss: 0.00041877070907503366
Test Loss:  0.00048009358579292893
Valid Loss:  0.00042906534508801997
Epoch:  222  	Training Loss: 0.00041722101741470397
Test Loss:  0.000480316870380193
Valid Loss:  0.00042889625183306634
Epoch:  223  	Training Loss: 0.0004170125175733119
Test Loss:  0.0004804503114428371
Valid Loss:  0.0004287839401513338
Epoch:  224  	Training Loss: 0.0004168294253759086
Test Loss:  0.00048055348452180624
Valid Loss:  0.0004286782059352845
Epoch:  225  	Training Loss: 0.0004166776197962463
Test Loss:  0.0004806194920092821
Valid Loss:  0.0004285810864530504
Epoch:  226  	Training Loss: 0.00041654944652691483
Test Loss:  0.00048066003364510834
Valid Loss:  0.00042848207522183657
Epoch:  227  	Training Loss: 0.00041642997530288994
Test Loss:  0.0004806887882295996
Valid Loss:  0.00042838003719225526
Epoch:  228  	Training Loss: 0.00041631358908489347
Test Loss:  0.0004806974611710757
Valid Loss:  0.00042828323785215616
Epoch:  229  	Training Loss: 0.0004162039258517325
Test Loss:  0.00048069702461361885
Valid Loss:  0.0004281836445443332
Epoch:  230  	Training Loss: 0.0004160943499300629
Test Loss:  0.0004806854121852666
Valid Loss:  0.0004280833527445793
Epoch:  231  	Training Loss: 0.00041598553070798516
Test Loss:  0.00048066896852105856
Valid Loss:  0.0004279844288248569
Epoch:  232  	Training Loss: 0.0004158784868195653
Test Loss:  0.000478110508993268
Valid Loss:  0.0004258565604686737
Epoch:  233  	Training Loss: 0.00041434867307543755
Test Loss:  0.00047592842020094395
Valid Loss:  0.00042459837277419865
Epoch:  234  	Training Loss: 0.0004129394656047225
Test Loss:  0.00047405343502759933
Valid Loss:  0.0004231366910971701
Epoch:  235  	Training Loss: 0.0004115937335882336
Test Loss:  0.0004724062455352396
Valid Loss:  0.00042180134914815426
Epoch:  236  	Training Loss: 0.00041029421845451
Test Loss:  0.00047095189802348614
Valid Loss:  0.0004204738070257008
Epoch:  237  	Training Loss: 0.00040903271292336285
Test Loss:  0.00046965439105406404
Valid Loss:  0.0004191836924292147
Epoch:  238  	Training Loss: 0.00040780266863293946
Test Loss:  0.0004684881423600018
Valid Loss:  0.00041791622061282396
Epoch:  239  	Training Loss: 0.0004065990215167403
Test Loss:  0.00046743039274588227
Valid Loss:  0.00041669406346045434
Epoch:  240  	Training Loss: 0.000405419385060668
Test Loss:  0.00046650596777908504
Valid Loss:  0.00041556148789823055
Epoch:  241  	Training Loss: 0.0004042658256366849
Test Loss:  0.00046564993681386113
Valid Loss:  0.0004144217527937144
Epoch:  242  	Training Loss: 0.0004031356074847281
Test Loss:  0.00046491200919263065
Valid Loss:  0.00041346275247633457
Epoch:  243  	Training Loss: 0.00040204034303314984
Test Loss:  0.0004642608400899917
Valid Loss:  0.0004123356193304062
Epoch:  244  	Training Loss: 0.0004010080301668495
Test Loss:  0.00046361557906493545
Valid Loss:  0.00041129658347927034
Epoch:  245  	Training Loss: 0.00040000895387493074
Test Loss:  0.00046297829248942435
Valid Loss:  0.0004102490493096411
Epoch:  246  	Training Loss: 0.0003990227123722434
Test Loss:  0.0004623455461114645
Valid Loss:  0.0004092229064553976
Epoch:  247  	Training Loss: 0.0003980479668825865
Test Loss:  0.00046172679867595434
Valid Loss:  0.00040820747381076217
Epoch:  248  	Training Loss: 0.0003970985999330878
Test Loss:  0.0004611864860635251
Valid Loss:  0.0004072203300893307
Epoch:  249  	Training Loss: 0.000396179937524721
Test Loss:  0.0004606506263371557
Valid Loss:  0.0004062433145008981
Epoch:  250  	Training Loss: 0.0003952709957957268
Test Loss:  0.000460117997135967
Valid Loss:  0.00040527863893657923
Epoch:  251  	Training Loss: 0.00039437395753338933
Test Loss:  0.0004595793434418738
Valid Loss:  0.0004043290391564369
Epoch:  252  	Training Loss: 0.0003934917040169239
Test Loss:  0.0004560523375403136
Valid Loss:  0.00039961759466677904
Epoch:  253  	Training Loss: 0.0003887187922373414
Test Loss:  0.00045272387797012925
Valid Loss:  0.00039500612183474004
Epoch:  254  	Training Loss: 0.0003841525758616626
Test Loss:  0.00044971812167204916
Valid Loss:  0.0003905822813976556
Epoch:  255  	Training Loss: 0.00037978729233145714
Test Loss:  0.0004468507249839604
Valid Loss:  0.00038634787779301405
Epoch:  256  	Training Loss: 0.0003756516380235553
Test Loss:  0.0004442030913196504
Valid Loss:  0.00038230017526075244
Epoch:  257  	Training Loss: 0.0003717663057614118
Test Loss:  0.00044166436418890953
Valid Loss:  0.00037842299207113683
Epoch:  258  	Training Loss: 0.00036804890260100365
Test Loss:  0.00043915683636441827
Valid Loss:  0.00037468376103788614
Epoch:  259  	Training Loss: 0.00036445018486119807
Test Loss:  0.00043674130574800074
Valid Loss:  0.0003710576565936208
Epoch:  260  	Training Loss: 0.00036099139833822846
Test Loss:  0.0004343699256423861
Valid Loss:  0.0003675657499115914
Epoch:  261  	Training Loss: 0.0003576602612156421
Test Loss:  0.00043204406392760575
Valid Loss:  0.00036417937371879816
Epoch:  262  	Training Loss: 0.0003544326755218208
Test Loss:  0.0004307775816414505
Valid Loss:  0.00036190752871334553
Epoch:  263  	Training Loss: 0.0003525224747136235
Test Loss:  0.00042941950960084796
Valid Loss:  0.00035982643021270633
Epoch:  264  	Training Loss: 0.0003507223736960441
Test Loss:  0.0004280121938791126
Valid Loss:  0.00035788631066679955
Epoch:  265  	Training Loss: 0.00034900655737146735
Test Loss:  0.0004265863390173763
Valid Loss:  0.00035605498123914003
Epoch:  266  	Training Loss: 0.00034736149245873094
Test Loss:  0.0004251748905517161
Valid Loss:  0.00035432359436526895
Epoch:  267  	Training Loss: 0.00034579314524307847
Test Loss:  0.0004237871035002172
Valid Loss:  0.000352665432728827
Epoch:  268  	Training Loss: 0.00034427858190611005
Test Loss:  0.00042243051575496793
Valid Loss:  0.0003510706010274589
Epoch:  269  	Training Loss: 0.0003428193158470094
Test Loss:  0.0004211209306959063
Valid Loss:  0.00034954113652929664
Epoch:  270  	Training Loss: 0.0003414167440496385
Test Loss:  0.00041985700954683125
Valid Loss:  0.00034806178882718086
Epoch:  271  	Training Loss: 0.0003400568093638867
Test Loss:  0.00041863913065753877
Valid Loss:  0.0003466286289039999
Epoch:  272  	Training Loss: 0.0003387374454177916
Test Loss:  0.00041792436968535185
Valid Loss:  0.00034665700513869524
 55%|█████▍    | 273/500 [03:24<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:25<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:25<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:25<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:31<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:31<03:04,  1.17it/s] 57%|█████▋    | 285/500 [03:31<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:32<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:32<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:38<04:05,  1.18s/it] 59%|█████▊    | 293/500 [03:38<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:38<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:38<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:38<01:06,  3.01it/s] 60%|██████    | 301/500 [03:45<03:52,  1.17s/it] 61%|██████    | 303/500 [03:45<02:45,  1.19it/s] 61%|██████    | 305/500 [03:45<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:45<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:45<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:52<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:52<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:52<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:52<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:52<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:58<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:59<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:59<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:59<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:59<00:57,  2.99it/s] 66%|██████▌   | 331/500 [04:05<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:06<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:06<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:06<01:13,  2.22it/s] 68%|██████▊   | 339/500 [04:06<00:53,  2.99it/s]Epoch:  273  	Training Loss: 0.0003379944828338921
Test Loss:  0.0004181364784017205
Valid Loss:  0.00034580222563818097
Epoch:  274  	Training Loss: 0.0003373782674316317
Test Loss:  0.0004181498079560697
Valid Loss:  0.0003451506490819156
Epoch:  275  	Training Loss: 0.00033677625469863415
Test Loss:  0.0004181556578259915
Valid Loss:  0.00034447212237864733
Epoch:  276  	Training Loss: 0.00033618375891819596
Test Loss:  0.00041812218842096627
Valid Loss:  0.00034381006844341755
Epoch:  277  	Training Loss: 0.0003356001398060471
Test Loss:  0.000418061506934464
Valid Loss:  0.00034315508673898876
Epoch:  278  	Training Loss: 0.0003350243787281215
Test Loss:  0.00041797501035034657
Valid Loss:  0.00034250784665346146
Epoch:  279  	Training Loss: 0.0003344567376188934
Test Loss:  0.00041786680230870843
Valid Loss:  0.00034186916309408844
Epoch:  280  	Training Loss: 0.000333896663505584
Test Loss:  0.0004177395603619516
Valid Loss:  0.0003412370278965682
Epoch:  281  	Training Loss: 0.00033334363251924515
Test Loss:  0.00041759543819352984
Valid Loss:  0.0003406122559681535
Epoch:  282  	Training Loss: 0.0003327976446598768
Test Loss:  0.00041804590728133917
Valid Loss:  0.0003405118768569082
Epoch:  283  	Training Loss: 0.00033221952617168427
Test Loss:  0.0004186903533991426
Valid Loss:  0.0003403714799787849
Epoch:  284  	Training Loss: 0.0003317951923236251
Test Loss:  0.0004193391650915146
Valid Loss:  0.00034020846942439675
Epoch:  285  	Training Loss: 0.00033145450288429856
Test Loss:  0.0004198549431748688
Valid Loss:  0.0003400384448468685
Epoch:  286  	Training Loss: 0.00033116189297288656
Test Loss:  0.00042028346797451377
Valid Loss:  0.0003398651024326682
Epoch:  287  	Training Loss: 0.0003309062449261546
Test Loss:  0.00042058934923261404
Valid Loss:  0.00033969496143981814
Epoch:  288  	Training Loss: 0.00033067166805267334
Test Loss:  0.0004207827150821686
Valid Loss:  0.00033952383091673255
Epoch:  289  	Training Loss: 0.00033045036252588034
Test Loss:  0.00042087805923074484
Valid Loss:  0.00033935392275452614
Epoch:  290  	Training Loss: 0.00033023860305547714
Test Loss:  0.0004209543112665415
Valid Loss:  0.0003391984791960567
Epoch:  291  	Training Loss: 0.00033004244323819876
Test Loss:  0.00042095116805285215
Valid Loss:  0.00033904510200954974
Epoch:  292  	Training Loss: 0.0003298549563623965
Test Loss:  0.0004199584946036339
Valid Loss:  0.0003377536195330322
Epoch:  293  	Training Loss: 0.0003293674089945853
Test Loss:  0.0004191992338746786
Valid Loss:  0.0003376954991836101
Epoch:  294  	Training Loss: 0.00032895186450332403
Test Loss:  0.00041845167288556695
Valid Loss:  0.0003372125211171806
Epoch:  295  	Training Loss: 0.0003285576531197876
Test Loss:  0.00041773865814320743
Valid Loss:  0.0003369443293195218
Epoch:  296  	Training Loss: 0.00032816885504871607
Test Loss:  0.0004170235770288855
Valid Loss:  0.0003366183955222368
Epoch:  297  	Training Loss: 0.00032778450986370444
Test Loss:  0.000416324328398332
Valid Loss:  0.00033632174017839134
Epoch:  298  	Training Loss: 0.00032741622999310493
Test Loss:  0.0004157509538345039
Valid Loss:  0.00033600727329030633
Epoch:  299  	Training Loss: 0.0003270819433964789
Test Loss:  0.0004151717876084149
Valid Loss:  0.0003357269160915166
Epoch:  300  	Training Loss: 0.00032676028786227107
Test Loss:  0.00041461922228336334
Valid Loss:  0.00033545203041285276
Epoch:  301  	Training Loss: 0.00032644631573930383
Test Loss:  0.000414093432482332
Valid Loss:  0.0003351851482875645
Epoch:  302  	Training Loss: 0.0003261491656303406
Test Loss:  0.0004139399097766727
Valid Loss:  0.0003349655889905989
Epoch:  303  	Training Loss: 0.0003260899684391916
Test Loss:  0.00041380577022209764
Valid Loss:  0.00033486279426142573
Epoch:  304  	Training Loss: 0.0003260400553699583
Test Loss:  0.0004136754432693124
Valid Loss:  0.0003347927122376859
Epoch:  305  	Training Loss: 0.0003259911900386214
Test Loss:  0.0004135489580221474
Valid Loss:  0.00033473296207375824
Epoch:  306  	Training Loss: 0.0003259425866417587
Test Loss:  0.0004134252667427063
Valid Loss:  0.0003346756275277585
Epoch:  307  	Training Loss: 0.00032589409966021776
Test Loss:  0.00041330239037051797
Valid Loss:  0.0003346189623698592
Epoch:  308  	Training Loss: 0.00032584607833996415
Test Loss:  0.0004131836467422545
Valid Loss:  0.0003345631412230432
Epoch:  309  	Training Loss: 0.0003257978823967278
Test Loss:  0.0004130693560000509
Valid Loss:  0.0003345073200762272
Epoch:  310  	Training Loss: 0.0003257498610764742
Test Loss:  0.000412957277148962
Valid Loss:  0.00033445327426306903
Epoch:  311  	Training Loss: 0.0003257037897128612
Test Loss:  0.00041284761391580105
Valid Loss:  0.00033439829712733626
Epoch:  312  	Training Loss: 0.000325657514622435
Test Loss:  0.0004119475488550961
Valid Loss:  0.0003336099616717547
Epoch:  313  	Training Loss: 0.00032494866172783077
Test Loss:  0.00041108072036877275
Valid Loss:  0.0003328778257127851
Epoch:  314  	Training Loss: 0.0003242588718421757
Test Loss:  0.0004102545790374279
Valid Loss:  0.00033216303563676775
Epoch:  315  	Training Loss: 0.00032359029864892364
Test Loss:  0.00040947430534288287
Valid Loss:  0.00033146387431770563
Epoch:  316  	Training Loss: 0.000322944630170241
Test Loss:  0.00040873343823477626
Valid Loss:  0.00033077687839977443
Epoch:  317  	Training Loss: 0.0003223141538910568
Test Loss:  0.0004080232174601406
Valid Loss:  0.0003300973039586097
Epoch:  318  	Training Loss: 0.0003216923214495182
Test Loss:  0.0004073397140018642
Valid Loss:  0.0003294258494861424
Epoch:  319  	Training Loss: 0.0003210794529877603
Test Loss:  0.0004066822293680161
Valid Loss:  0.0003287619329057634
Epoch:  320  	Training Loss: 0.0003204743261449039
Test Loss:  0.0004060487844981253
Valid Loss:  0.00032810482662171125
Epoch:  321  	Training Loss: 0.0003198783379048109
Test Loss:  0.00040545541560277343
Valid Loss:  0.0003274613118264824
Epoch:  322  	Training Loss: 0.00031929771648719907
Test Loss:  0.00040599200292490423
Valid Loss:  0.00032750421087257564
Epoch:  323  	Training Loss: 0.00031896933796815574
Test Loss:  0.00040660612285137177
Valid Loss:  0.0003275033668614924
Epoch:  324  	Training Loss: 0.00031874212436378
Test Loss:  0.000407190527766943
Valid Loss:  0.000327475368976593
Epoch:  325  	Training Loss: 0.00031856278656050563
Test Loss:  0.0004077019402757287
Valid Loss:  0.0003274321206845343
Epoch:  326  	Training Loss: 0.00031841255258768797
Test Loss:  0.0004081269435118884
Valid Loss:  0.0003273809561505914
Epoch:  327  	Training Loss: 0.0003182812943123281
Test Loss:  0.0004084666434209794
Valid Loss:  0.0003273246402386576
Epoch:  328  	Training Loss: 0.0003181628999300301
Test Loss:  0.00040872738463804126
Valid Loss:  0.00032726465724408627
Epoch:  329  	Training Loss: 0.0003180534695275128
Test Loss:  0.00040892045944929123
Valid Loss:  0.00032720272429287434
Epoch:  330  	Training Loss: 0.0003179502673447132
Test Loss:  0.00040905451169237494
Valid Loss:  0.0003271380555815995
Epoch:  331  	Training Loss: 0.0003178517217747867
Test Loss:  0.00040911813266575336
Valid Loss:  0.0003270648594480008
Epoch:  332  	Training Loss: 0.00031775940442457795
Test Loss:  0.0004080065409652889
Valid Loss:  0.0003255658957641572
Epoch:  333  	Training Loss: 0.00031691795447841287
Test Loss:  0.00040661118691787124
Valid Loss:  0.00032468908466398716
Epoch:  334  	Training Loss: 0.00031620997469872236
Test Loss:  0.00040526100201532245
Valid Loss:  0.00032391445711255074
Epoch:  335  	Training Loss: 0.00031553133158013225
Test Loss:  0.00040400971192866564
Valid Loss:  0.0003231766168028116
Epoch:  336  	Training Loss: 0.0003148767864331603
Test Loss:  0.0004028559778816998
Valid Loss:  0.00032246095361188054
Epoch:  337  	Training Loss: 0.0003142431378364563
Test Loss:  0.0004017908941023052
Valid Loss:  0.0003217637713532895
Epoch:  338  	Training Loss: 0.000313627504510805
Test Loss:  0.0004008144314866513
Valid Loss:  0.0003210895520169288
Epoch:  339  	Training Loss: 0.00031303640571422875
Test Loss:  0.0003999246400780976
Valid Loss:  0.0003204277600161731
Epoch:  340  	Training Loss: 0.0003124596260022372
Test Loss:   68%|██████▊   | 341/500 [04:12<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:12<02:12,  1.18it/s] 69%|██████▉   | 345/500 [04:12<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:13<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:13<00:50,  3.01it/s] 70%|███████   | 351/500 [04:19<02:53,  1.17s/it] 71%|███████   | 353/500 [04:19<02:03,  1.19it/s] 71%|███████   | 355/500 [04:19<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:19<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:19<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:26<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:26<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:26<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:26<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:26<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:33<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:33<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:33<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:33<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:33<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:39<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:39<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:40<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:40<00:50,  2.26it/s] 78%|███████▊  | 389/500 [04:40<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:46<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:46<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:46<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:47<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:47<00:33,  3.03it/s] 80%|████████  | 401/500 [04:53<01:57,  1.18s/it] 81%|████████  | 403/500 [04:53<01:22,  1.18it/s] 81%|████████  | 405/500 [04:53<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:53<00:41,  2.23it/s]0.00039909861516207457
Valid Loss:  0.00031977842445485294
Epoch:  341  	Training Loss: 0.0003118952445220202
Test Loss:  0.00039832995389588177
Valid Loss:  0.0003191412833984941
Epoch:  342  	Training Loss: 0.0003113417187705636
Test Loss:  0.0003990383120253682
Valid Loss:  0.0003187499241903424
Epoch:  343  	Training Loss: 0.00031035346910357475
Test Loss:  0.0003991205303464085
Valid Loss:  0.00031784584280103445
Epoch:  344  	Training Loss: 0.0003094917628914118
Test Loss:  0.00039912122883833945
Valid Loss:  0.00031698690145276487
Epoch:  345  	Training Loss: 0.000308665563352406
Test Loss:  0.00039903668221086264
Valid Loss:  0.00031615575426258147
Epoch:  346  	Training Loss: 0.0003078683512285352
Test Loss:  0.00039887899765744805
Valid Loss:  0.00031534291338175535
Epoch:  347  	Training Loss: 0.00030709049315191805
Test Loss:  0.0003986559750046581
Valid Loss:  0.0003145445662084967
Epoch:  348  	Training Loss: 0.0003063285257667303
Test Loss:  0.0003983759379480034
Valid Loss:  0.000313759024720639
Epoch:  349  	Training Loss: 0.00030557828722521663
Test Loss:  0.00039804738480597734
Valid Loss:  0.0003129832912236452
Epoch:  350  	Training Loss: 0.0003048389044124633
Test Loss:  0.00039767424459569156
Valid Loss:  0.0003122159978374839
Epoch:  351  	Training Loss: 0.00030410801991820335
Test Loss:  0.0003972630074713379
Valid Loss:  0.0003114579594694078
Epoch:  352  	Training Loss: 0.00030338598298840225
Test Loss:  0.00039634580025449395
Valid Loss:  0.0003115413128398359
Epoch:  353  	Training Loss: 0.00030325425905175507
Test Loss:  0.0003956352884415537
Valid Loss:  0.00031151523580774665
Epoch:  354  	Training Loss: 0.00030314200557768345
Test Loss:  0.0003950454411096871
Valid Loss:  0.00031145161483436823
Epoch:  355  	Training Loss: 0.00030303592211566865
Test Loss:  0.00039453667704947293
Valid Loss:  0.00031137658515945077
Epoch:  356  	Training Loss: 0.0003029335639439523
Test Loss:  0.00039408719749189913
Valid Loss:  0.0003112992853857577
Epoch:  357  	Training Loss: 0.0003028332721441984
Test Loss:  0.000393684022128582
Valid Loss:  0.00031122181098908186
Epoch:  358  	Training Loss: 0.00030273484298959374
Test Loss:  0.0003933162661269307
Valid Loss:  0.0003111451514996588
Epoch:  359  	Training Loss: 0.0003026374033652246
Test Loss:  0.00039297662442550063
Valid Loss:  0.0003110711113549769
Epoch:  360  	Training Loss: 0.0003025414771400392
Test Loss:  0.00039265997475013137
Valid Loss:  0.00031099768239073455
Epoch:  361  	Training Loss: 0.00030244633671827614
Test Loss:  0.00039236166048794985
Valid Loss:  0.00031092442804947495
Epoch:  362  	Training Loss: 0.0003023517783731222
Test Loss:  0.0003920054587069899
Valid Loss:  0.00030738956411369145
Epoch:  363  	Training Loss: 0.00029981270199641585
Test Loss:  0.00039158761501312256
Valid Loss:  0.0003063588810618967
Epoch:  364  	Training Loss: 0.00029829537379555404
Test Loss:  0.00039103225572034717
Valid Loss:  0.00030576030258089304
Epoch:  365  	Training Loss: 0.0002972843067254871
Test Loss:  0.0003901675809174776
Valid Loss:  0.0003056068089790642
Epoch:  366  	Training Loss: 0.0002966590691357851
Test Loss:  0.0003891779633704573
Valid Loss:  0.0003054118133150041
Epoch:  367  	Training Loss: 0.0002961377031169832
Test Loss:  0.0003881847078446299
Valid Loss:  0.0003051884414162487
Epoch:  368  	Training Loss: 0.00029566441662609577
Test Loss:  0.0003871934022754431
Valid Loss:  0.0003049688821192831
Epoch:  369  	Training Loss: 0.00029523868579417467
Test Loss:  0.0003861894947476685
Valid Loss:  0.0003047723148483783
Epoch:  370  	Training Loss: 0.00029489188455045223
Test Loss:  0.00038516958011314273
Valid Loss:  0.0003045877965632826
Epoch:  371  	Training Loss: 0.0002945918822661042
Test Loss:  0.00038422091165557504
Valid Loss:  0.0003043808974325657
Epoch:  372  	Training Loss: 0.00029430969152599573
Test Loss:  0.00038418645272031426
Valid Loss:  0.0003043116012122482
Epoch:  373  	Training Loss: 0.0002942184219136834
Test Loss:  0.00038414011942222714
Valid Loss:  0.00030424108263105154
Epoch:  374  	Training Loss: 0.0002941293059848249
Test Loss:  0.0003840819117613137
Valid Loss:  0.0003041708841919899
Epoch:  375  	Training Loss: 0.00029404176166281104
Test Loss:  0.00038401427445933223
Valid Loss:  0.000304100860375911
Epoch:  376  	Training Loss: 0.0002939547994174063
Test Loss:  0.0003839370037894696
Valid Loss:  0.0003040321171283722
Epoch:  377  	Training Loss: 0.00029386935057118535
Test Loss:  0.0003838511183857918
Valid Loss:  0.00030396314105018973
Epoch:  378  	Training Loss: 0.00029378541512414813
Test Loss:  0.0003837583935819566
Valid Loss:  0.0003038955619558692
Epoch:  379  	Training Loss: 0.0002937028184533119
Test Loss:  0.00038365786895155907
Valid Loss:  0.0003038282156921923
Epoch:  380  	Training Loss: 0.0002936210948973894
Test Loss:  0.0003835502720903605
Valid Loss:  0.00030376180075109005
Epoch:  381  	Training Loss: 0.0002935401862487197
Test Loss:  0.00038343871710821986
Valid Loss:  0.00030369582236744463
Epoch:  382  	Training Loss: 0.00029346084920689464
Test Loss:  0.00038188937469385564
Valid Loss:  0.0003036145062651485
Epoch:  383  	Training Loss: 0.0002932366915047169
Test Loss:  0.00038057606434449553
Valid Loss:  0.00030341651290655136
Epoch:  384  	Training Loss: 0.00029304451891221106
Test Loss:  0.0003793912474066019
Valid Loss:  0.0003032598178833723
Epoch:  385  	Training Loss: 0.0002928769390564412
Test Loss:  0.0003783309948630631
Valid Loss:  0.0003031211090274155
Epoch:  386  	Training Loss: 0.00029272897518239915
Test Loss:  0.000377384276362136
Valid Loss:  0.00030299799982458353
Epoch:  387  	Training Loss: 0.0002925983862951398
Test Loss:  0.00037652996252290905
Valid Loss:  0.0003028872306458652
Epoch:  388  	Training Loss: 0.0002924808650277555
Test Loss:  0.00037576098111458123
Valid Loss:  0.00030278670601546764
Epoch:  389  	Training Loss: 0.00029237382113933563
Test Loss:  0.00037506897933781147
Valid Loss:  0.0003026948543265462
Epoch:  390  	Training Loss: 0.000292276032269001
Test Loss:  0.00037444414920173585
Valid Loss:  0.0003026094054803252
Epoch:  391  	Training Loss: 0.0002921861014328897
Test Loss:  0.0003738745581358671
Valid Loss:  0.00030252739088609815
Epoch:  392  	Training Loss: 0.0002921057166531682
Test Loss:  0.0003731026081368327
Valid Loss:  0.00030116309062577784
Epoch:  393  	Training Loss: 0.0002908683964051306
Test Loss:  0.0003723665722645819
Valid Loss:  0.0002998871204908937
Epoch:  394  	Training Loss: 0.000289672811049968
Test Loss:  0.0003716267237905413
Valid Loss:  0.0002986550680361688
Epoch:  395  	Training Loss: 0.00028851634124293923
Test Loss:  0.0003708882140927017
Valid Loss:  0.0002974618982989341
Epoch:  396  	Training Loss: 0.00028739424305967987
Test Loss:  0.0003701505484059453
Valid Loss:  0.0002963034203276038
Epoch:  397  	Training Loss: 0.00028630520682781935
Test Loss:  0.0003694131155498326
Valid Loss:  0.00029517640359699726
Epoch:  398  	Training Loss: 0.00028524664230644703
Test Loss:  0.0003686754498630762
Valid Loss:  0.00029407747206278145
Epoch:  399  	Training Loss: 0.0002842140675056726
Test Loss:  0.0003679381334222853
Valid Loss:  0.00029300316236913204
Epoch:  400  	Training Loss: 0.0002832066675182432
Test Loss:  0.0003672042512334883
Valid Loss:  0.0002919557737186551
Epoch:  401  	Training Loss: 0.00028222595574334264
Test Loss:  0.0003664742107503116
Valid Loss:  0.0002909357426688075
Epoch:  402  	Training Loss: 0.00028127041878178716
Test Loss:  0.00036662782076746225
Valid Loss:  0.0002913356584031135
Epoch:  403  	Training Loss: 0.00028108368860557675
Test Loss:  0.0003663783718366176
Valid Loss:  0.00029105463181622326
Epoch:  404  	Training Loss: 0.0002809269935823977
Test Loss:  0.0003661807277239859
Valid Loss:  0.0002910051844082773
Epoch:  405  	Training Loss: 0.0002807769342325628
Test Loss:  0.00036590310628525913
Valid Loss:  0.0002908875176217407
Epoch:  406  	Training Loss: 0.0002806325792334974
Test Loss:  0.00036560388980433345
Valid Loss:  0.0002907948801293969
Epoch:  407  	Training Loss: 0.00028049154207110405
Test Loss:  0.00036527603515423834
Valid Loss:  0.0002906961599364877
 82%|████████▏ | 409/500 [04:54<00:30,  3.00it/s] 82%|████████▏ | 411/500 [05:00<01:44,  1.18s/it] 83%|████████▎ | 413/500 [05:00<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:00<00:51,  1.64it/s] 83%|████████▎ | 417/500 [05:00<00:37,  2.24it/s] 84%|████████▍ | 419/500 [05:00<00:26,  3.01it/s] 84%|████████▍ | 421/500 [05:07<01:32,  1.18s/it] 85%|████████▍ | 423/500 [05:07<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:07<00:45,  1.64it/s] 85%|████████▌ | 427/500 [05:07<00:32,  2.23it/s] 86%|████████▌ | 429/500 [05:07<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:13<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:14<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:14<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:14<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:14<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:20<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:20<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:20<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:21<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:21<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:27<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:27<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:27<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:27<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:28<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:34<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:34<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:34<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:34<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:34<00:10,  2.95it/s] 94%|█████████▍| 471/500 [05:41<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:41<00:22,  1.18it/s]Epoch:  408  	Training Loss: 0.00028035277500748634
Test Loss:  0.00036493121297098696
Valid Loss:  0.000290600408334285
Epoch:  409  	Training Loss: 0.0002802166563924402
Test Loss:  0.0003645741962827742
Valid Loss:  0.00029050608281977475
Epoch:  410  	Training Loss: 0.00028008228400722146
Test Loss:  0.00036420891410671175
Valid Loss:  0.0002904125431086868
Epoch:  411  	Training Loss: 0.0002799498906824738
Test Loss:  0.0003638403723016381
Valid Loss:  0.0002903211279772222
Epoch:  412  	Training Loss: 0.00027982061146758497
Test Loss:  0.00036175691639073193
Valid Loss:  0.0002884448622353375
Epoch:  413  	Training Loss: 0.0002783208037726581
Test Loss:  0.0003597709001041949
Valid Loss:  0.00028672098414972425
Epoch:  414  	Training Loss: 0.00027692256844602525
Test Loss:  0.00035787810338661075
Valid Loss:  0.00028511908021755517
Epoch:  415  	Training Loss: 0.0002756103058345616
Test Loss:  0.0003560834447853267
Valid Loss:  0.0002836198837030679
Epoch:  416  	Training Loss: 0.0002743717923294753
Test Loss:  0.00035438567283563316
Valid Loss:  0.0002822070964612067
Epoch:  417  	Training Loss: 0.0002731976564973593
Test Loss:  0.00035278129507787526
Valid Loss:  0.0002808694844134152
Epoch:  418  	Training Loss: 0.0002720821648836136
Test Loss:  0.000351265596691519
Valid Loss:  0.00027959776343777776
Epoch:  419  	Training Loss: 0.00027102272724732757
Test Loss:  0.0003498378209769726
Valid Loss:  0.00027838657842949033
Epoch:  420  	Training Loss: 0.00027001314447261393
Test Loss:  0.0003484949702396989
Valid Loss:  0.00027723051607608795
Epoch:  421  	Training Loss: 0.0002690498367883265
Test Loss:  0.00034723017597571015
Valid Loss:  0.0002761237556114793
Epoch:  422  	Training Loss: 0.00026812709984369576
Test Loss:  0.00034672816400416195
Valid Loss:  0.0002757463662419468
Epoch:  423  	Training Loss: 0.0002675869036465883
Test Loss:  0.0003462264430709183
Valid Loss:  0.0002752399304881692
Epoch:  424  	Training Loss: 0.0002670857938937843
Test Loss:  0.00034573188167996705
Valid Loss:  0.00027469891938380897
Epoch:  425  	Training Loss: 0.0002666014479473233
Test Loss:  0.00034525146475061774
Valid Loss:  0.00027415703516453505
Epoch:  426  	Training Loss: 0.00026613130467012525
Test Loss:  0.00034478725865483284
Valid Loss:  0.00027362583205103874
Epoch:  427  	Training Loss: 0.0002656749857123941
Test Loss:  0.0003443400200922042
Valid Loss:  0.00027310699806548655
Epoch:  428  	Training Loss: 0.0002652320545166731
Test Loss:  0.00034390963264741004
Valid Loss:  0.00027260143542662263
Epoch:  429  	Training Loss: 0.00026480169617570937
Test Loss:  0.0003434944082982838
Valid Loss:  0.00027210958069190383
Epoch:  430  	Training Loss: 0.0002643841435201466
Test Loss:  0.00034309455077163875
Valid Loss:  0.000271630851784721
Epoch:  431  	Training Loss: 0.0002639783197082579
Test Loss:  0.00034270985634066164
Valid Loss:  0.00027116440469399095
Epoch:  432  	Training Loss: 0.000263583060586825
Test Loss:  0.00034328349283896387
Valid Loss:  0.00027058133855462074
Epoch:  433  	Training Loss: 0.000262687070062384
Test Loss:  0.0003436793922446668
Valid Loss:  0.00026995278312824667
Epoch:  434  	Training Loss: 0.00026191797223873436
Test Loss:  0.0003439508727751672
Valid Loss:  0.00026933979825116694
Epoch:  435  	Training Loss: 0.0002612217213027179
Test Loss:  0.00034415812115184963
Valid Loss:  0.0002687264932319522
Epoch:  436  	Training Loss: 0.0002605656045489013
Test Loss:  0.000344293424859643
Valid Loss:  0.0002681433688849211
Epoch:  437  	Training Loss: 0.00025995317264460027
Test Loss:  0.00034436871646903455
Valid Loss:  0.0002675744181033224
Epoch:  438  	Training Loss: 0.0002593708341009915
Test Loss:  0.00034439031151123345
Valid Loss:  0.0002670129470061511
Epoch:  439  	Training Loss: 0.00025881017791107297
Test Loss:  0.0003443583264015615
Valid Loss:  0.0002664647181518376
Epoch:  440  	Training Loss: 0.00025826977798715234
Test Loss:  0.00034427893115207553
Valid Loss:  0.0002659177116584033
Epoch:  441  	Training Loss: 0.00025774468667805195
Test Loss:  0.00034417310962453485
Valid Loss:  0.00026536828954704106
Epoch:  442  	Training Loss: 0.00025722113787196577
Test Loss:  0.00034287385642528534
Valid Loss:  0.00026494901976548135
Epoch:  443  	Training Loss: 0.0002565882168710232
Test Loss:  0.00034189142752438784
Valid Loss:  0.00026444296236149967
Epoch:  444  	Training Loss: 0.0002559667336754501
Test Loss:  0.00034103839425370097
Valid Loss:  0.0002638811420183629
Epoch:  445  	Training Loss: 0.0002553454542066902
Test Loss:  0.00034026644425466657
Valid Loss:  0.0002632682444527745
Epoch:  446  	Training Loss: 0.0002547123294789344
Test Loss:  0.00033952604280784726
Valid Loss:  0.000262638641288504
Epoch:  447  	Training Loss: 0.0002540738205425441
Test Loss:  0.0003388004843145609
Valid Loss:  0.00026200152933597565
Epoch:  448  	Training Loss: 0.00025343417655676603
Test Loss:  0.0003380799316801131
Valid Loss:  0.0002613641263451427
Epoch:  449  	Training Loss: 0.0002527983160689473
Test Loss:  0.00033735635224729776
Valid Loss:  0.00026073813205584884
Epoch:  450  	Training Loss: 0.00025217514485120773
Test Loss:  0.00033664825605228543
Valid Loss:  0.0002601265150588006
Epoch:  451  	Training Loss: 0.0002515822707209736
Test Loss:  0.00033594315755181015
Valid Loss:  0.00025953020667657256
Epoch:  452  	Training Loss: 0.000251015298999846
Test Loss:  0.0003351900086272508
Valid Loss:  0.00025917860330082476
Epoch:  453  	Training Loss: 0.00025089626433327794
Test Loss:  0.0003344269352965057
Valid Loss:  0.0002590580261312425
Epoch:  454  	Training Loss: 0.0002508045290596783
Test Loss:  0.00033372745383530855
Valid Loss:  0.00025897263549268246
Epoch:  455  	Training Loss: 0.0002507230674382299
Test Loss:  0.00033309365971945226
Valid Loss:  0.0002588984789326787
Epoch:  456  	Training Loss: 0.00025065027875825763
Test Loss:  0.0003325203142594546
Valid Loss:  0.0002588315983302891
Epoch:  457  	Training Loss: 0.000250584096647799
Test Loss:  0.0003320006944704801
Valid Loss:  0.0002587712951935828
Epoch:  458  	Training Loss: 0.0002505237061996013
Test Loss:  0.00033152929972857237
Valid Loss:  0.00025871486286632717
Epoch:  459  	Training Loss: 0.0002504675358068198
Test Loss:  0.0003310999891255051
Valid Loss:  0.00025866288342513144
Epoch:  460  	Training Loss: 0.0002504151198081672
Test Loss:  0.00033070938661694527
Valid Loss:  0.00025861395988613367
Epoch:  461  	Training Loss: 0.00025036605075001717
Test Loss:  0.0003303537960164249
Valid Loss:  0.0002585678012110293
Epoch:  462  	Training Loss: 0.00025031916447915137
Test Loss:  0.00032979215029627085
Valid Loss:  0.0002579934080131352
Epoch:  463  	Training Loss: 0.0002499548136256635
Test Loss:  0.00032928361906670034
Valid Loss:  0.0002575443941168487
Epoch:  464  	Training Loss: 0.0002496016677469015
Test Loss:  0.0003287983126938343
Valid Loss:  0.0002571169752627611
Epoch:  465  	Training Loss: 0.0002492553321644664
Test Loss:  0.0003283301484771073
Valid Loss:  0.0002566977054812014
Epoch:  466  	Training Loss: 0.0002489150210749358
Test Loss:  0.0003278799122199416
Valid Loss:  0.00025628507137298584
Epoch:  467  	Training Loss: 0.00024858067627064884
Test Loss:  0.000327445100992918
Valid Loss:  0.00025587843265384436
Epoch:  468  	Training Loss: 0.00024825186119414866
Test Loss:  0.0003270262386649847
Valid Loss:  0.00025547758559696376
Epoch:  469  	Training Loss: 0.0002479284885339439
Test Loss:  0.000326622452121228
Valid Loss:  0.00025508174439892173
Epoch:  470  	Training Loss: 0.0002476104418747127
Test Loss:  0.00032623211154714227
Valid Loss:  0.0002546922187320888
Epoch:  471  	Training Loss: 0.0002472975174896419
Test Loss:  0.00032585603184998035
Valid Loss:  0.00025430729147046804
Epoch:  472  	Training Loss: 0.0002469894243404269
Test Loss:  0.00032472441671416163
Valid Loss:  0.0002538454136811197
Epoch:  473  	Training Loss: 0.00024618286988697946
Test Loss:  0.0003236194606870413
Valid Loss:  0.0002531727950554341
Epoch:  474  	Training Loss: 0.0002454531495459378
Test Loss:  0.0003226009721402079
Valid Loss:  0.0002524640003684908
Epoch:  475  	Training Loss: 0.000244758790358901
Test Loss:   95%|█████████▌| 475/500 [05:41<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:41<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:41<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:47<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:48<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:48<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:48<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:48<00:03,  3.03it/s] 98%|█████████▊| 491/500 [05:54<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:54<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:55<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:55<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:55<00:00,  3.01it/s]100%|██████████| 500/500 [05:55<00:00,  1.41it/s]
0.0003216656041331589
Valid Loss:  0.0002517625689506531
Epoch:  476  	Training Loss: 0.00024408848548773676
Test Loss:  0.00032077348441816866
Valid Loss:  0.0002510768244974315
Epoch:  477  	Training Loss: 0.00024343102995771915
Test Loss:  0.00031991524156183004
Valid Loss:  0.00025040225591510534
Epoch:  478  	Training Loss: 0.0002427839644951746
Test Loss:  0.0003190839779563248
Valid Loss:  0.0002497359528206289
Epoch:  479  	Training Loss: 0.00024214513541664928
Test Loss:  0.00031826604390516877
Valid Loss:  0.0002490775368642062
Epoch:  480  	Training Loss: 0.000241512170759961
Test Loss:  0.0003174695884808898
Valid Loss:  0.0002484261931385845
Epoch:  481  	Training Loss: 0.00024088579812087119
Test Loss:  0.00031667976872995496
Valid Loss:  0.0002477816306054592
Epoch:  482  	Training Loss: 0.00024026338360272348
Test Loss:  0.0003162184148095548
Valid Loss:  0.0002469020546413958
Epoch:  483  	Training Loss: 0.00023991131456568837
Test Loss:  0.0003159331972710788
Valid Loss:  0.0002466205623932183
Epoch:  484  	Training Loss: 0.00023960575344972312
Test Loss:  0.00031564212986268103
Valid Loss:  0.00024625909281894565
Epoch:  485  	Training Loss: 0.00023930869065225124
Test Loss:  0.00031536706956103444
Valid Loss:  0.000245920498855412
Epoch:  486  	Training Loss: 0.00023901941312942654
Test Loss:  0.0003151034179609269
Valid Loss:  0.00024558650329709053
Epoch:  487  	Training Loss: 0.0002387375570833683
Test Loss:  0.0003148514952044934
Valid Loss:  0.0002452378685120493
Epoch:  488  	Training Loss: 0.00023846296244300902
Test Loss:  0.00031460891477763653
Valid Loss:  0.00024489726638421416
Epoch:  489  	Training Loss: 0.00023819509078748524
Test Loss:  0.0003143771318718791
Valid Loss:  0.00024456402752548456
Epoch:  490  	Training Loss: 0.0002379339566687122
Test Loss:  0.00031415425473824143
Valid Loss:  0.00024423806462436914
Epoch:  491  	Training Loss: 0.00023767912352923304
Test Loss:  0.0003139394102618098
Valid Loss:  0.00024391939223278314
Epoch:  492  	Training Loss: 0.0002374306641286239
Test Loss:  0.0003157935861963779
Valid Loss:  0.00024429563200101256
Epoch:  493  	Training Loss: 0.00023670285008847713
Test Loss:  0.00031637176289223135
Valid Loss:  0.00024345924612134695
Epoch:  494  	Training Loss: 0.00023621850414201617
Test Loss:  0.0003170501731801778
Valid Loss:  0.0002434602502034977
Epoch:  495  	Training Loss: 0.00023585585586261004
Test Loss:  0.0003172201686538756
Valid Loss:  0.00024310286971740425
Epoch:  496  	Training Loss: 0.000235556552070193
Test Loss:  0.0003172962460666895
Valid Loss:  0.00024298587231896818
Epoch:  497  	Training Loss: 0.00023529294412583113
Test Loss:  0.0003171502030454576
Valid Loss:  0.00024277466582134366
Epoch:  498  	Training Loss: 0.00023505050921812654
Test Loss:  0.0003169183910358697
Valid Loss:  0.00024263259547296911
Epoch:  499  	Training Loss: 0.00023481860989704728
Test Loss:  0.00031662051333114505
Valid Loss:  0.00024247533292509615
Epoch:  500  	Training Loss: 0.00023458573559764773
Test Loss:  0.0003162477514706552
Valid Loss:  0.00024231552379205823
seed is  3
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.48it/s]  1%|          | 4/500 [00:00<00:29, 16.56it/s]  1%|          | 6/500 [00:00<00:29, 16.63it/s]  2%|▏         | 8/500 [00:00<00:29, 16.61it/s]  2%|▏         | 10/500 [00:00<00:29, 16.59it/s]  2%|▏         | 12/500 [00:00<00:29, 16.62it/s]  3%|▎         | 14/500 [00:00<00:29, 16.62it/s]  3%|▎         | 16/500 [00:00<00:29, 16.60it/s]  4%|▎         | 18/500 [00:01<00:29, 16.45it/s]  4%|▍         | 20/500 [00:01<00:29, 16.43it/s]  4%|▍         | 22/500 [00:01<00:29, 16.47it/s]  5%|▍         | 24/500 [00:01<00:28, 16.51it/s]  5%|▌         | 26/500 [00:01<00:28, 16.55it/s]  6%|▌         | 28/500 [00:01<00:28, 16.58it/s]  6%|▌         | 30/500 [00:01<00:28, 16.60it/s]  6%|▋         | 32/500 [00:01<00:28, 16.63it/s]  7%|▋         | 34/500 [00:02<00:28, 16.60it/s]  7%|▋         | 36/500 [00:02<00:27, 16.59it/s]  8%|▊         | 38/500 [00:02<00:27, 16.51it/s]  8%|▊         | 40/500 [00:02<00:27, 16.53it/s]  8%|▊         | 42/500 [00:02<00:27, 16.54it/s]  9%|▉         | 44/500 [00:02<00:27, 16.54it/s]  9%|▉         | 46/500 [00:02<00:27, 16.42it/s] 10%|▉         | 48/500 [00:02<00:28, 15.71it/s] 10%|█         | 50/500 [00:03<00:28, 15.57it/s] 10%|█         | 52/500 [00:03<00:29, 15.07it/s] 11%|█         | 54/500 [00:03<00:29, 15.33it/s] 11%|█         | 56/500 [00:03<00:28, 15.71it/s] 12%|█▏        | 58/500 [00:03<00:27, 15.98it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.24it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.46it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.52it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.61it/s] 14%|█▎        | 68/500 [00:04<00:25, 16.66it/s] 14%|█▍        | 70/500 [00:04<00:25, 16.66it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.51it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.63it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.72it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.72it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.70it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.59it/s] 17%|█▋        | 84/500 [00:05<00:24, 16.66it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.67it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.76it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.73it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.74it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.71it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.74it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.74it/s] 20%|██        | 100/500 [00:06<00:23, 16.74it/s] 20%|██        | 102/500 [00:06<00:23, 16.70it/s] 21%|██        | 104/500 [00:06<00:23, 16.70it/s] 21%|██        | 106/500 [00:06<00:23, 16.66it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.70it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.74it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.72it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.72it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.56it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.56it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.55it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.56it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.62it/s]Epoch:  1  	Training Loss: 0.10876578837633133
Test Loss:  2240.87353515625
Valid Loss:  2236.97802734375
Epoch:  2  	Training Loss: 2238.301025390625
Test Loss:  73895675691008.0
Valid Loss:  74237855399936.0
Epoch:  3  	Training Loss: 74163708493824.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.66it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.68it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.68it/s] 26%|██▋       | 132/500 [00:07<00:22, 16.64it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.77it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.01it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.13it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.34it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.50it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.55it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.62it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.67it/s] 30%|███       | 150/500 [00:09<00:20, 16.72it/s] 30%|███       | 152/500 [00:09<00:21, 16.31it/s] 31%|███       | 154/500 [00:09<00:21, 16.38it/s] 31%|███       | 156/500 [00:09<00:20, 16.46it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.47it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.54it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.53it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.29it/s] 33%|███▎      | 166/500 [00:10<00:22, 14.61it/s] 34%|███▎      | 168/500 [00:10<00:23, 13.85it/s] 34%|███▍      | 170/500 [00:10<00:23, 13.94it/s] 34%|███▍      | 172/500 [00:10<00:22, 14.63it/s] 35%|███▍      | 174/500 [00:10<00:21, 15.16it/s] 35%|███▌      | 176/500 [00:10<00:20, 15.56it/s] 36%|███▌      | 178/500 [00:10<00:20, 15.89it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.09it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.23it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.20it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.12it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.27it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.38it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.47it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.58it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.65it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.70it/s] 40%|████      | 200/500 [00:12<00:17, 16.72it/s] 40%|████      | 202/500 [00:12<00:17, 16.61it/s] 41%|████      | 204/500 [00:12<00:17, 16.58it/s] 41%|████      | 206/500 [00:12<00:17, 16.58it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.60it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.62it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.63it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.62it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.63it/s] 44%|████▎     | 218/500 [00:13<00:16, 16.63it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.62it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.63it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.62it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.51it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.39it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.47it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.54it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.61it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.61it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.65it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.67it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.68it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.69it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.56it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.51it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.53it/s] 50%|█████     | 252/500 [00:15<00:14, 16.56it/s] 51%|█████     | 254/500 [00:15<00:14, 16.61it/s] 51%|█████     | 256/500 [00:15<00:14, 16.62it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.63it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.62it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.68it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.54it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.55it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.54it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.55it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.32it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.40it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.18it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.17it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.27it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.28it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.40it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.46it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.50it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.53it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.54it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.62it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.64it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.62it/s] 60%|██████    | 300/500 [00:18<00:12, 16.62it/s] 60%|██████    | 302/500 [00:18<00:11, 16.60it/s] 61%|██████    | 304/500 [00:18<00:11, 16.62it/s] 61%|██████    | 306/500 [00:18<00:11, 16.65it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.62it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.60it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.34it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.41it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.45it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.50it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.54it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.55it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.55it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.59it/s] 66%|██████▌   | 328/500 [00:19<00:10, 16.65it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.63it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.62it/s] 67%|██████▋   | 334/500 [00:20<00:09, 16.61it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.53it/s] 68%|██████▊   | 338/500 [00:20<00:10, 15.02it/s] 68%|██████▊   | 340/500 [00:20<00:10, 14.70it/s] 68%|██████▊   | 342/500 [00:20<00:10, 14.99it/s] 69%|██████▉   | 344/500 [00:21<00:10, 15.24it/s] 69%|██████▉   | 346/500 [00:21<00:09, 15.63it/s] 70%|██████▉   | 348/500 [00:21<00:09, 15.89it/s] 70%|███████   | 350/500 [00:21<00:09, 16.09it/s] 70%|███████   | 352/500 [00:21<00:09, 16.29it/s] 71%|███████   | 354/500 [00:21<00:08, 16.43it/s] 71%|███████   | 356/500 [00:21<00:08, 16.37it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.32it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.40it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.49it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.50it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.52it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.53it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.57it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.57it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.49it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.42it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.40it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.37it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.42it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.39it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.45it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.36it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.28it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.07it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.21it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.32it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.39it/s] 80%|████████  | 400/500 [00:24<00:06, 16.31it/s] 80%|████████  | 402/500 [00:24<00:05, 16.37it/s] 81%|████████  | 404/500 [00:24<00:05, 16.38it/s] 81%|████████  | 406/500 [00:24<00:05, 16.42it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.36it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.45it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.51it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.53it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.57it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.61it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.68it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.51it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.56it/s] 85%|████████▌ | 426/500 [00:25<00:04, 16.64it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.71it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.68it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.68it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.70it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.66it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.65it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.65it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.63it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.59it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.62it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.55it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.30it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.15it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.24it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.25it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.42it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.48it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.33it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.36it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.47it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.59it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.47it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.45it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.31it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.44it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.45it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.57it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.57it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.57it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.47it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.41it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.37it/s] 98%|█████████▊| 492/500 [00:29<00:00, 16.44it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.48it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.48it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.45it/s]100%|██████████| 500/500 [00:30<00:00, 16.32it/s]100%|██████████| 500/500 [00:30<00:00, 16.40it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  3
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:27,  6.19s/it]  1%|          | 3/500 [00:06<13:42,  1.66s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:43,  1.32s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:29,  1.19s/it]  5%|▍         | 23/500 [00:19<06:44,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:08,  1.17s/it]  7%|▋         | 33/500 [00:26<06:31,  1.19it/s]  7%|▋         | 35/500 [00:26<04:41,  1.65it/s]  7%|▋         | 37/500 [00:26<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<08:52,  1.16s/it]  9%|▊         | 43/500 [00:33<06:20,  1.20it/s]  9%|▉         | 45/500 [00:33<04:33,  1.66it/s]  9%|▉         | 47/500 [00:33<03:19,  2.27it/s] 10%|▉         | 49/500 [00:33<02:27,  3.05it/s] 10%|█         | 51/500 [00:40<08:53,  1.19s/it] 11%|█         | 53/500 [00:40<06:21,  1.17it/s] 11%|█         | 55/500 [00:40<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:40<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:40,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.22it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.99it/s] 14%|█▍        | 71/500 [00:53<08:21,  1.17s/it] 15%|█▍        | 73/500 [00:53<05:58,  1.19it/s]Epoch:  1  	Training Loss: 0.10876578837633133
Test Loss:  186.29953002929688
Valid Loss:  184.9873809814453
Epoch:  2  	Training Loss: 185.559326171875
Test Loss:  0.99428391456604
Valid Loss:  0.9293714761734009
Epoch:  3  	Training Loss: 0.9548078775405884
Test Loss:  0.8461716175079346
Valid Loss:  0.7896045446395874
Epoch:  4  	Training Loss: 0.8119996190071106
Test Loss:  0.7203384637832642
Valid Loss:  0.6710179448127747
Epoch:  5  	Training Loss: 0.690761148929596
Test Loss:  0.6134284734725952
Valid Loss:  0.5704065561294556
Epoch:  6  	Training Loss: 0.5878346562385559
Test Loss:  0.5225910544395447
Valid Loss:  0.4850490689277649
Epoch:  7  	Training Loss: 0.5004536509513855
Test Loss:  0.4454048275947571
Valid Loss:  0.4126352071762085
Epoch:  8  	Training Loss: 0.426268994808197
Test Loss:  0.3798130750656128
Valid Loss:  0.3512038588523865
Epoch:  9  	Training Loss: 0.3632860481739044
Test Loss:  0.32406914234161377
Valid Loss:  0.2990903854370117
Epoch:  10  	Training Loss: 0.30981141328811646
Test Loss:  0.27668941020965576
Valid Loss:  0.25488200783729553
Epoch:  11  	Training Loss: 0.2644073963165283
Test Loss:  0.23641395568847656
Valid Loss:  0.21737957000732422
Epoch:  12  	Training Loss: 0.22585344314575195
Test Loss:  0.19697706401348114
Valid Loss:  0.1809321492910385
Epoch:  13  	Training Loss: 0.18827152252197266
Test Loss:  0.16425755620002747
Valid Loss:  0.15074804425239563
Epoch:  14  	Training Loss: 0.15711593627929688
Test Loss:  0.14219240844249725
Valid Loss:  0.1293354332447052
Epoch:  15  	Training Loss: 0.13515491783618927
Test Loss:  0.1389966607093811
Valid Loss:  0.1255437731742859
Epoch:  16  	Training Loss: 0.13160394132137299
Test Loss:  0.13799254596233368
Valid Loss:  0.12444903701543808
Epoch:  17  	Training Loss: 0.13073591887950897
Test Loss:  0.13753949105739594
Valid Loss:  0.12398239970207214
Epoch:  18  	Training Loss: 0.1303049474954605
Test Loss:  0.13735930621623993
Valid Loss:  0.12377852201461792
Epoch:  19  	Training Loss: 0.13012900948524475
Test Loss:  0.13725194334983826
Valid Loss:  0.12368082255125046
Epoch:  20  	Training Loss: 0.13003496825695038
Test Loss:  0.1371861696243286
Valid Loss:  0.12363240122795105
Epoch:  21  	Training Loss: 0.12997978925704956
Test Loss:  0.13715076446533203
Valid Loss:  0.12360866367816925
Epoch:  22  	Training Loss: 0.12994952499866486
Test Loss:  0.1371242105960846
Valid Loss:  0.12358729541301727
Epoch:  23  	Training Loss: 0.12992312014102936
Test Loss:  0.1371040940284729
Valid Loss:  0.12357178330421448
Epoch:  24  	Training Loss: 0.12990199029445648
Test Loss:  0.13708937168121338
Valid Loss:  0.12356328964233398
Epoch:  25  	Training Loss: 0.1298893541097641
Test Loss:  0.1370774209499359
Valid Loss:  0.123555488884449
Epoch:  26  	Training Loss: 0.12987780570983887
Test Loss:  0.1370707005262375
Valid Loss:  0.12354789674282074
Epoch:  27  	Training Loss: 0.12986652553081512
Test Loss:  0.13706441223621368
Valid Loss:  0.12354050576686859
Epoch:  28  	Training Loss: 0.12985603511333466
Test Loss:  0.137058824300766
Valid Loss:  0.12353397160768509
Epoch:  29  	Training Loss: 0.1298479437828064
Test Loss:  0.13705427944660187
Valid Loss:  0.12352851033210754
Epoch:  30  	Training Loss: 0.12984180450439453
Test Loss:  0.13705125451087952
Valid Loss:  0.12352369725704193
Epoch:  31  	Training Loss: 0.1298370361328125
Test Loss:  0.1370488554239273
Valid Loss:  0.12351974844932556
Epoch:  32  	Training Loss: 0.12983371317386627
Test Loss:  0.13704758882522583
Valid Loss:  0.12351633608341217
Epoch:  33  	Training Loss: 0.12983116507530212
Test Loss:  0.1370469182729721
Valid Loss:  0.12351320683956146
Epoch:  34  	Training Loss: 0.12982895970344543
Test Loss:  0.13704629242420197
Valid Loss:  0.1235104501247406
Epoch:  35  	Training Loss: 0.12982729077339172
Test Loss:  0.13704580068588257
Valid Loss:  0.12350861728191376
Epoch:  36  	Training Loss: 0.1298261284828186
Test Loss:  0.13704530894756317
Valid Loss:  0.1235068142414093
Epoch:  37  	Training Loss: 0.12982502579689026
Test Loss:  0.13704487681388855
Valid Loss:  0.12350517511367798
Epoch:  38  	Training Loss: 0.12982407212257385
Test Loss:  0.13704442977905273
Valid Loss:  0.12350385636091232
Epoch:  39  	Training Loss: 0.12982308864593506
Test Loss:  0.1370440125465393
Valid Loss:  0.12350289523601532
Epoch:  40  	Training Loss: 0.12982219457626343
Test Loss:  0.13704365491867065
Valid Loss:  0.12350208312273026
Epoch:  41  	Training Loss: 0.1298215538263321
Test Loss:  0.13704334199428558
Valid Loss:  0.12350157648324966
Epoch:  42  	Training Loss: 0.12982100248336792
Test Loss:  0.1370430439710617
Valid Loss:  0.12350109219551086
Epoch:  43  	Training Loss: 0.1298205852508545
Test Loss:  0.1370427906513214
Valid Loss:  0.12350068986415863
Epoch:  44  	Training Loss: 0.12982024252414703
Test Loss:  0.13704252243041992
Valid Loss:  0.1235002800822258
Epoch:  45  	Training Loss: 0.12981989979743958
Test Loss:  0.13704229891300201
Valid Loss:  0.12349991500377655
Epoch:  46  	Training Loss: 0.12981963157653809
Test Loss:  0.1370421051979065
Valid Loss:  0.12349961698055267
Epoch:  47  	Training Loss: 0.12981945276260376
Test Loss:  0.13704192638397217
Valid Loss:  0.12349937856197357
Epoch:  48  	Training Loss: 0.12981928884983063
Test Loss:  0.13704177737236023
Valid Loss:  0.12349921464920044
Epoch:  49  	Training Loss: 0.1298191249370575
Test Loss:  0.13704170286655426
Valid Loss:  0.12349903583526611
Epoch:  50  	Training Loss: 0.12981897592544556
Test Loss:  0.1370416283607483
Valid Loss:  0.12349885702133179
Epoch:  51  	Training Loss: 0.12981882691383362
Test Loss:  0.13704153895378113
Valid Loss:  0.12349867820739746
Epoch:  52  	Training Loss: 0.12981867790222168
Test Loss:  0.13704147934913635
Valid Loss:  0.12349854409694672
Epoch:  53  	Training Loss: 0.12981857359409332
Test Loss:  0.13704149425029755
Valid Loss:  0.12349840998649597
Epoch:  54  	Training Loss: 0.12981846928596497
Test Loss:  0.13704150915145874
Valid Loss:  0.12349827587604523
Epoch:  55  	Training Loss: 0.1298183649778366
Test Loss:  0.13704152405261993
Valid Loss:  0.12349814921617508
Epoch:  56  	Training Loss: 0.12981826066970825
Test Loss:  0.13704153895378113
Valid Loss:  0.12349801510572433
Epoch:  57  	Training Loss: 0.1298181712627411
Test Loss:  0.13704155385494232
Valid Loss:  0.12349788844585419
Epoch:  58  	Training Loss: 0.12981806695461273
Test Loss:  0.13704156875610352
Valid Loss:  0.12349779903888702
Epoch:  59  	Training Loss: 0.12981797754764557
Test Loss:  0.13704156875610352
Valid Loss:  0.12349773943424225
Epoch:  60  	Training Loss: 0.1298178881406784
Test Loss:  0.13704156875610352
Valid Loss:  0.12349765747785568
Epoch:  61  	Training Loss: 0.12981779873371124
Test Loss:  0.13704156875610352
Valid Loss:  0.12349759042263031
Epoch:  62  	Training Loss: 0.12981772422790527
Test Loss:  0.13704156875610352
Valid Loss:  0.12349752336740494
Epoch:  63  	Training Loss: 0.1298176646232605
Test Loss:  0.1370415836572647
Valid Loss:  0.12349748611450195
Epoch:  64  	Training Loss: 0.12981760501861572
Test Loss:  0.1370415836572647
Valid Loss:  0.12349747121334076
Epoch:  65  	Training Loss: 0.12981754541397095
Test Loss:  0.1370415985584259
Valid Loss:  0.12349745631217957
Epoch:  66  	Training Loss: 0.12981750071048737
Test Loss:  0.1370415985584259
Valid Loss:  0.12349744141101837
Epoch:  67  	Training Loss: 0.12981745600700378
Test Loss:  0.1370416283607483
Valid Loss:  0.12349741905927658
Epoch:  68  	Training Loss: 0.129817396402359
Test Loss:  0.1370416283607483
Valid Loss:  0.12349741160869598
Epoch:  69  	Training Loss: 0.12981735169887543
Test Loss:  0.1370416283607483
Valid Loss:  0.12349739670753479
Epoch:  70  	Training Loss: 0.12981732189655304
Test Loss:  0.1370416283607483
Valid Loss:  0.1234973818063736
Epoch:  71  	Training Loss: 0.12981729209423065
Test Loss:  0.13704164326190948
Valid Loss:  0.1234973818063736
Epoch:  72  	Training Loss: 0.12981727719306946
Test Loss:  0.1370416283607483
Valid Loss:  0.12349735200405121
Epoch:  73  	Training Loss: 0.12981723248958588
Test Loss:  0.1370416283607483
Valid Loss:  0.12349733710289001
 15%|█▌        | 75/500 [00:54<04:18,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.25it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.03it/s] 16%|█▌        | 81/500 [01:00<08:16,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:00<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:01<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:13<14:26,  2.12s/it] 19%|█▊        | 93/500 [01:13<10:12,  1.50s/it] 19%|█▉        | 95/500 [01:20<13:27,  1.99s/it] 19%|█▉        | 97/500 [01:20<09:31,  1.42s/it] 20%|█▉        | 99/500 [01:20<06:45,  1.01s/it] 20%|██        | 101/500 [01:33<17:15,  2.60s/it] 21%|██        | 103/500 [01:33<12:09,  1.84s/it] 21%|██        | 105/500 [01:39<14:39,  2.23s/it] 21%|██▏       | 107/500 [01:39<10:21,  1.58s/it] 22%|██▏       | 109/500 [01:39<07:20,  1.13s/it] 22%|██▏       | 111/500 [01:52<17:09,  2.65s/it] 23%|██▎       | 113/500 [01:52<12:04,  1.87s/it] 23%|██▎       | 115/500 [01:58<14:25,  2.25s/it] 23%|██▎       | 117/500 [01:58<10:10,  1.60s/it] 24%|██▍       | 119/500 [01:58<07:12,  1.14s/it] 24%|██▍       | 119/500 [02:09<07:12,  1.14s/it] 24%|██▍       | 121/500 [02:11<16:51,  2.67s/it] 25%|██▍       | 123/500 [02:11<11:52,  1.89s/it] 25%|██▌       | 125/500 [02:17<14:10,  2.27s/it] 25%|██▌       | 127/500 [02:17<10:00,  1.61s/it] 26%|██▌       | 129/500 [02:18<07:04,  1.15s/it] 26%|██▌       | 129/500 [02:29<07:04,  1.15s/it] 26%|██▌       | 131/500 [02:30<16:22,  2.66s/it] 27%|██▋       | 133/500 [02:30<11:31,  1.89s/it] 27%|██▋       | 135/500 [02:36<13:50,  2.27s/it]Epoch:  74  	Training Loss: 0.1298171877861023
Test Loss:  0.1370416283607483
Valid Loss:  0.12349731475114822
Epoch:  75  	Training Loss: 0.1298171728849411
Test Loss:  0.1370416283607483
Valid Loss:  0.12349729984998703
Epoch:  76  	Training Loss: 0.1298171579837799
Test Loss:  0.1370416134595871
Valid Loss:  0.12349729239940643
Epoch:  77  	Training Loss: 0.12981712818145752
Test Loss:  0.1370415985584259
Valid Loss:  0.12349727004766464
Epoch:  78  	Training Loss: 0.12981709837913513
Test Loss:  0.1370415985584259
Valid Loss:  0.12349724769592285
Epoch:  79  	Training Loss: 0.12981708347797394
Test Loss:  0.1370415985584259
Valid Loss:  0.12349724769592285
Epoch:  80  	Training Loss: 0.12981706857681274
Test Loss:  0.1370415985584259
Valid Loss:  0.12349723279476166
Epoch:  81  	Training Loss: 0.12981705367565155
Test Loss:  0.1370415985584259
Valid Loss:  0.12349721789360046
Epoch:  82  	Training Loss: 0.12981703877449036
Test Loss:  0.1370415985584259
Valid Loss:  0.12349721044301987
Epoch:  83  	Training Loss: 0.12981703877449036
Test Loss:  0.1370415985584259
Valid Loss:  0.12349720299243927
Epoch:  84  	Training Loss: 0.12981700897216797
Test Loss:  0.1370415985584259
Valid Loss:  0.12349718809127808
Epoch:  85  	Training Loss: 0.12981700897216797
Test Loss:  0.1370415836572647
Valid Loss:  0.12349718064069748
Epoch:  86  	Training Loss: 0.12981699407100677
Test Loss:  0.1370415985584259
Valid Loss:  0.12349717319011688
Epoch:  87  	Training Loss: 0.12981697916984558
Test Loss:  0.1370415985584259
Valid Loss:  0.12349716573953629
Epoch:  88  	Training Loss: 0.1298169642686844
Test Loss:  0.1370415985584259
Valid Loss:  0.12349715828895569
Epoch:  89  	Training Loss: 0.1298169642686844
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971433877945
Epoch:  90  	Training Loss: 0.1298169493675232
Test Loss:  0.1370415985584259
Valid Loss:  0.12349715083837509
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.1298169493675232
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971433877945
Epoch:  92  	Training Loss: 0.1298169493675232
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971433877945
Epoch:  93  	Training Loss: 0.1298169493675232
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971433877945
Epoch:  94  	Training Loss: 0.1298169493675232
Test Loss:  0.1370415836572647
Valid Loss:  0.1234971433877945
Epoch:  95  	Training Loss: 0.1298169493675232
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.1298169493675232
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971359372139
Epoch:  97  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  98  	Training Loss: 0.1298169493675232
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  99  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  100  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  102  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  103  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  104  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  105  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  107  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  108  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  109  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  110  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  112  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  113  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  114  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  115  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  117  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  118  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  119  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  120  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  122  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  123  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  124  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  125  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  127  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  128  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  129  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  130  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  132  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  133  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  134  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  135  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.12349710613489151
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
 27%|██▋       | 137/500 [02:37<09:45,  1.61s/it] 28%|██▊       | 139/500 [02:37<06:54,  1.15s/it] 28%|██▊       | 139/500 [02:49<06:54,  1.15s/it] 28%|██▊       | 141/500 [02:49<15:54,  2.66s/it] 29%|██▊       | 143/500 [02:49<11:12,  1.88s/it] 29%|██▉       | 145/500 [02:56<13:23,  2.26s/it] 29%|██▉       | 147/500 [02:56<09:26,  1.61s/it] 30%|██▉       | 149/500 [02:56<06:41,  1.14s/it] 30%|███       | 151/500 [03:08<15:25,  2.65s/it] 31%|███       | 153/500 [03:08<10:51,  1.88s/it] 31%|███       | 155/500 [03:14<12:55,  2.25s/it] 31%|███▏      | 157/500 [03:15<09:06,  1.59s/it] 32%|███▏      | 159/500 [03:15<06:26,  1.13s/it] 32%|███▏      | 161/500 [03:27<15:01,  2.66s/it] 33%|███▎      | 163/500 [03:27<10:34,  1.88s/it] 33%|███▎      | 165/500 [03:34<12:36,  2.26s/it] 33%|███▎      | 167/500 [03:34<08:53,  1.60s/it] 34%|███▍      | 169/500 [03:34<06:17,  1.14s/it] 34%|███▍      | 171/500 [03:47<14:47,  2.70s/it] 35%|███▍      | 173/500 [03:47<10:24,  1.91s/it] 35%|███▌      | 175/500 [03:53<12:21,  2.28s/it] 35%|███▌      | 177/500 [03:53<08:43,  1.62s/it] 36%|███▌      | 179/500 [03:53<06:10,  1.15s/it] 36%|███▌      | 181/500 [04:06<14:15,  2.68s/it] 37%|███▋      | 183/500 [04:06<10:01,  1.90s/it] 37%|███▋      | 185/500 [04:12<11:53,  2.26s/it] 37%|███▋      | 187/500 [04:12<08:22,  1.61s/it] 38%|███▊      | 189/500 [04:12<05:55,  1.14s/it] 38%|███▊      | 191/500 [04:25<13:43,  2.66s/it] 39%|███▊      | 193/500 [04:25<09:38,  1.89s/it] 39%|███▉      | 195/500 [04:31<11:29,  2.26s/it]Epoch:  137  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  138  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  139  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  140  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  142  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  143  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  144  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  145  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  147  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  148  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  149  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  150  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  152  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  153  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  154  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  155  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  157  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  158  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  159  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  160  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  162  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  163  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  164  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  165  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  167  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  168  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  169  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  170  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  172  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  173  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  174  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  175  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  177  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  178  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  179  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  180  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  182  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  183  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  184  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  185  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  187  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  188  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  189  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  190  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  192  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  193  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  194  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  195  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  197  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:   39%|███▉      | 197/500 [04:31<08:05,  1.60s/it] 40%|███▉      | 199/500 [04:31<05:43,  1.14s/it] 40%|████      | 201/500 [04:44<13:18,  2.67s/it] 41%|████      | 203/500 [04:44<09:21,  1.89s/it] 41%|████      | 205/500 [04:50<11:07,  2.26s/it] 41%|████▏     | 207/500 [04:51<07:50,  1.60s/it] 42%|████▏     | 209/500 [04:51<05:32,  1.14s/it] 42%|████▏     | 211/500 [05:03<12:45,  2.65s/it] 43%|████▎     | 213/500 [05:03<08:58,  1.88s/it] 43%|████▎     | 215/500 [05:09<10:41,  2.25s/it] 43%|████▎     | 217/500 [05:10<07:31,  1.60s/it] 44%|████▍     | 219/500 [05:10<05:19,  1.14s/it] 44%|████▍     | 221/500 [05:22<12:21,  2.66s/it] 45%|████▍     | 223/500 [05:22<08:41,  1.88s/it] 45%|████▌     | 225/500 [05:28<10:22,  2.26s/it] 45%|████▌     | 227/500 [05:29<07:18,  1.60s/it] 46%|████▌     | 229/500 [05:29<05:09,  1.14s/it] 46%|████▌     | 229/500 [05:39<05:09,  1.14s/it] 46%|████▌     | 231/500 [05:41<12:00,  2.68s/it] 47%|████▋     | 233/500 [05:41<08:26,  1.90s/it] 47%|████▋     | 235/500 [05:48<10:06,  2.29s/it] 47%|████▋     | 237/500 [05:48<07:06,  1.62s/it] 48%|████▊     | 239/500 [05:48<05:01,  1.16s/it] 48%|████▊     | 239/500 [05:59<05:01,  1.16s/it] 48%|████▊     | 241/500 [06:01<11:38,  2.70s/it] 49%|████▊     | 243/500 [06:01<08:10,  1.91s/it] 49%|████▉     | 245/500 [06:07<09:43,  2.29s/it] 49%|████▉     | 247/500 [06:07<06:50,  1.62s/it] 50%|████▉     | 249/500 [06:07<04:49,  1.15s/it] 50%|████▉     | 249/500 [06:19<04:49,  1.15s/it] 50%|█████     | 251/500 [06:20<11:06,  2.68s/it] 51%|█████     | 253/500 [06:20<07:47,  1.89s/it] 51%|█████     | 255/500 [06:26<09:15,  2.27s/it] 51%|█████▏    | 257/500 [06:26<06:30,  1.61s/it]0.1234971210360527
Epoch:  198  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  199  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  200  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  202  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  203  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  204  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  205  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.12349710613489151
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  207  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  208  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  209  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  210  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  212  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  213  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  214  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  215  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.12349710613489151
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  217  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  218  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  219  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  220  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  222  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  223  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  224  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  225  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  227  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  228  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  229  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  230  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  232  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  233  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  234  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  235  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  237  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  238  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  239  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  240  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  242  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  243  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  244  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  245  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  247  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  248  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  249  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  250  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  252  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  253  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  254  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  255  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  257  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  258  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
 52%|█████▏    | 259/500 [06:27<04:35,  1.14s/it] 52%|█████▏    | 261/500 [06:39<10:34,  2.65s/it] 53%|█████▎    | 263/500 [06:39<07:25,  1.88s/it] 53%|█████▎    | 265/500 [06:45<08:50,  2.26s/it] 53%|█████▎    | 267/500 [06:45<06:13,  1.60s/it] 54%|█████▍    | 269/500 [06:46<04:23,  1.14s/it] 54%|█████▍    | 271/500 [06:58<10:10,  2.66s/it] 55%|█████▍    | 273/500 [06:58<07:08,  1.89s/it] 55%|█████▌    | 275/500 [07:05<08:30,  2.27s/it] 55%|█████▌    | 277/500 [07:05<05:58,  1.61s/it] 56%|█████▌    | 279/500 [07:05<04:13,  1.14s/it] 56%|█████▌    | 281/500 [07:17<09:46,  2.68s/it] 57%|█████▋    | 283/500 [07:17<06:51,  1.90s/it] 57%|█████▋    | 285/500 [07:24<08:07,  2.27s/it] 57%|█████▋    | 287/500 [07:24<05:42,  1.61s/it] 58%|█████▊    | 289/500 [07:24<04:01,  1.15s/it] 58%|█████▊    | 291/500 [07:37<09:22,  2.69s/it] 59%|█████▊    | 293/500 [07:37<06:34,  1.91s/it] 59%|█████▉    | 295/500 [07:43<07:55,  2.32s/it] 59%|█████▉    | 297/500 [07:43<05:34,  1.65s/it] 60%|█████▉    | 299/500 [07:44<03:55,  1.17s/it] 60%|██████    | 301/500 [07:56<09:07,  2.75s/it] 61%|██████    | 303/500 [07:57<06:23,  1.95s/it] 61%|██████    | 305/500 [08:03<07:33,  2.33s/it] 61%|██████▏   | 307/500 [08:03<05:18,  1.65s/it] 62%|██████▏   | 309/500 [08:03<03:44,  1.17s/it] 62%|██████▏   | 311/500 [08:16<08:30,  2.70s/it] 63%|██████▎   | 313/500 [08:16<05:57,  1.91s/it] 63%|██████▎   | 315/500 [08:22<07:04,  2.30s/it] 63%|██████▎   | 317/500 [08:22<04:58,  1.63s/it]Valid Loss:  0.1234971135854721
Epoch:  259  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  260  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  262  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  263  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  264  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  265  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  267  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  268  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  269  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  270  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  272  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  273  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  274  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  275  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  277  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  278  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  279  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  280  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  282  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  283  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  284  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  285  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  287  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  288  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  289  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  290  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  292  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  293  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  294  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  295  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  297  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  298  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  299  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  300  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  302  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  303  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  304  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  305  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  307  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  308  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  309  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  310  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  312  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  313  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  314  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  315  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  317  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  318  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.12349710613489151
Epoch:  319  	Training Loss: 0.1298169195652008
Test Loss:   64%|██████▍   | 319/500 [08:23<03:29,  1.16s/it] 64%|██████▍   | 321/500 [08:35<08:04,  2.70s/it] 65%|██████▍   | 323/500 [08:35<05:38,  1.91s/it] 65%|██████▌   | 325/500 [08:42<06:43,  2.31s/it] 65%|██████▌   | 327/500 [08:42<04:42,  1.64s/it] 66%|██████▌   | 329/500 [08:42<03:19,  1.16s/it] 66%|██████▌   | 331/500 [08:55<07:40,  2.72s/it] 67%|██████▋   | 333/500 [08:55<05:22,  1.93s/it] 67%|██████▋   | 335/500 [09:01<06:22,  2.32s/it] 67%|██████▋   | 337/500 [09:02<04:28,  1.64s/it] 68%|██████▊   | 339/500 [09:02<03:08,  1.17s/it] 68%|██████▊   | 341/500 [09:15<07:16,  2.75s/it] 69%|██████▊   | 343/500 [09:15<05:05,  1.94s/it] 69%|██████▉   | 345/500 [09:21<05:59,  2.32s/it] 69%|██████▉   | 347/500 [09:21<04:11,  1.64s/it] 70%|██████▉   | 349/500 [09:21<02:56,  1.17s/it] 70%|███████   | 351/500 [09:34<06:42,  2.70s/it] 71%|███████   | 353/500 [09:34<04:41,  1.91s/it] 71%|███████   | 355/500 [09:40<05:29,  2.28s/it] 71%|███████▏  | 357/500 [09:40<03:50,  1.62s/it] 72%|███████▏  | 359/500 [09:41<02:42,  1.15s/it] 72%|███████▏  | 361/500 [09:53<06:12,  2.68s/it] 73%|███████▎  | 363/500 [09:53<04:19,  1.90s/it] 73%|███████▎  | 365/500 [09:59<05:06,  2.27s/it] 73%|███████▎  | 367/500 [10:00<03:34,  1.61s/it] 74%|███████▍  | 369/500 [10:00<02:30,  1.15s/it] 74%|███████▍  | 371/500 [10:12<05:44,  2.67s/it] 75%|███████▍  | 373/500 [10:12<04:00,  1.89s/it] 75%|███████▌  | 375/500 [10:19<04:44,  2.27s/it] 75%|███████▌  | 377/500 [10:19<03:18,  1.61s/it] 76%|███████▌  | 379/500 [10:19<02:19,  1.15s/it]0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  320  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  322  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  323  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  324  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  325  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  327  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  328  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  329  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  330  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  332  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  333  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  334  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  335  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  337  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  338  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  339  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  340  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  342  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  343  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  344  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  345  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  347  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  348  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  349  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  350  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  352  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  353  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  354  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  355  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  357  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  358  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  359  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  360  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  362  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  363  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  364  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  365  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  367  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  368  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  369  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  370  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  372  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  373  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  374  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  375  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  377  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  378  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  379  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  380  	Training Loss: 0.1298169195652008
 76%|███████▌  | 379/500 [10:29<02:19,  1.15s/it] 76%|███████▌  | 381/500 [10:31<05:18,  2.68s/it] 77%|███████▋  | 383/500 [10:32<03:41,  1.90s/it] 77%|███████▋  | 385/500 [10:38<04:24,  2.30s/it] 77%|███████▋  | 387/500 [10:38<03:04,  1.63s/it] 78%|███████▊  | 389/500 [10:38<02:08,  1.16s/it] 78%|███████▊  | 389/500 [10:49<02:08,  1.16s/it] 78%|███████▊  | 391/500 [10:51<04:54,  2.70s/it] 79%|███████▊  | 393/500 [10:51<03:24,  1.91s/it] 79%|███████▉  | 395/500 [10:57<04:00,  2.29s/it] 79%|███████▉  | 397/500 [10:58<02:47,  1.62s/it] 80%|███████▉  | 399/500 [10:58<01:56,  1.15s/it] 80%|███████▉  | 399/500 [11:09<01:56,  1.15s/it] 80%|████████  | 401/500 [11:10<04:24,  2.67s/it] 81%|████████  | 403/500 [11:10<03:03,  1.89s/it] 81%|████████  | 405/500 [11:16<03:34,  2.26s/it] 81%|████████▏ | 407/500 [11:17<02:28,  1.60s/it] 82%|████████▏ | 409/500 [11:17<01:43,  1.14s/it] 82%|████████▏ | 411/500 [11:29<03:56,  2.66s/it] 83%|████████▎ | 413/500 [11:29<02:43,  1.88s/it] 83%|████████▎ | 415/500 [11:36<03:13,  2.28s/it] 83%|████████▎ | 417/500 [11:36<02:14,  1.62s/it] 84%|████████▍ | 419/500 [11:36<01:33,  1.15s/it] 84%|████████▍ | 421/500 [11:48<03:31,  2.68s/it] 85%|████████▍ | 423/500 [11:49<02:26,  1.90s/it] 85%|████████▌ | 425/500 [11:55<02:50,  2.27s/it] 85%|████████▌ | 427/500 [11:55<01:57,  1.61s/it] 86%|████████▌ | 429/500 [11:55<01:21,  1.15s/it] 86%|████████▌ | 431/500 [12:08<03:03,  2.66s/it] 87%|████████▋ | 433/500 [12:08<02:06,  1.88s/it] 87%|████████▋ | 435/500 [12:14<02:26,  2.26s/it] 87%|████████▋ | 437/500 [12:14<01:40,  1.60s/it] 88%|████████▊ | 439/500 [12:14<01:09,  1.14s/it]Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  382  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  383  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  384  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  385  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  387  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  388  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  389  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  390  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  392  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  393  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  394  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  395  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  397  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  398  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  399  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  400  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  402  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  403  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  404  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415836572647
Valid Loss:  0.1234971210360527
Epoch:  405  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  407  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  408  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  409  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  410  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.12349710613489151
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  412  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971284866333
Epoch:  413  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  414  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  415  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  417  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  418  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  419  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  420  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  422  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  423  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  424  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  425  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  427  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  428  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  429  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  430  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  432  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.12349710613489151
Epoch:  433  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  434  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  435  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  437  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  438  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  439  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  440  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
 88%|████████▊ | 441/500 [12:27<02:38,  2.68s/it] 89%|████████▊ | 443/500 [12:27<01:48,  1.90s/it] 89%|████████▉ | 445/500 [12:33<02:05,  2.28s/it] 89%|████████▉ | 447/500 [12:33<01:25,  1.62s/it] 90%|████████▉ | 449/500 [12:34<00:58,  1.15s/it] 90%|█████████ | 451/500 [12:46<02:11,  2.68s/it] 91%|█████████ | 453/500 [12:46<01:29,  1.90s/it] 91%|█████████ | 455/500 [12:52<01:42,  2.27s/it] 91%|█████████▏| 457/500 [12:53<01:09,  1.61s/it] 92%|█████████▏| 459/500 [12:53<00:47,  1.15s/it] 92%|█████████▏| 461/500 [13:05<01:43,  2.66s/it] 93%|█████████▎| 463/500 [13:05<01:09,  1.88s/it] 93%|█████████▎| 465/500 [13:12<01:19,  2.27s/it] 93%|█████████▎| 467/500 [13:12<00:53,  1.61s/it] 94%|█████████▍| 469/500 [13:12<00:35,  1.15s/it] 94%|█████████▍| 471/500 [13:24<01:17,  2.68s/it] 95%|█████████▍| 473/500 [13:25<00:51,  1.90s/it] 95%|█████████▌| 475/500 [13:31<00:56,  2.26s/it] 95%|█████████▌| 477/500 [13:31<00:36,  1.61s/it] 96%|█████████▌| 479/500 [13:31<00:23,  1.14s/it] 96%|█████████▌| 481/500 [13:44<00:51,  2.72s/it] 97%|█████████▋| 483/500 [13:44<00:32,  1.93s/it] 97%|█████████▋| 485/500 [13:50<00:34,  2.31s/it] 97%|█████████▋| 487/500 [13:51<00:21,  1.64s/it] 98%|█████████▊| 489/500 [13:51<00:12,  1.17s/it] 98%|█████████▊| 491/500 [14:03<00:24,  2.71s/it] 99%|█████████▊| 493/500 [14:03<00:13,  1.92s/it] 99%|█████████▉| 495/500 [14:10<00:11,  2.30s/it] 99%|█████████▉| 497/500 [14:10<00:04,  1.63s/it]100%|█████████▉| 499/500 [14:10<00:01,  1.16s/it]**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  442  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  443  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  444  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  445  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  447  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  448  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  449  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  450  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  452  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  453  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  454  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  455  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  457  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  458  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  459  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  460  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  462  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  463  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  464  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  465  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  467  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  468  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  469  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  470  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  472  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  473  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  474  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  475  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  477  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  478  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  479  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  480  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  482  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  483  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  484  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  485  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  487  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  488  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  489  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  490  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  492  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  493  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  494  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  495  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  497  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  498  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971210360527
Epoch:  499  	Training Loss: 0.129816934466362
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
Epoch:  500  	Training Loss: 0.1298169195652008
Test Loss:  0.1370415985584259
Valid Loss:  0.1234971135854721
100%|██████████| 500/500 [14:16<00:00,  1.71s/it]
**************************************************learning rate decay**************************************************
seed is  3
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:28,  6.43s/it]  1%|          | 3/500 [00:06<14:15,  1.72s/it]  1%|          | 5/500 [00:06<07:10,  1.15it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<11:16,  1.38s/it]  3%|▎         | 13/500 [00:13<07:40,  1.06it/s]  3%|▎         | 15/500 [00:13<05:20,  1.51it/s]  3%|▎         | 17/500 [00:13<03:48,  2.12it/s]  4%|▍         | 19/500 [00:14<02:46,  2.89it/s]  4%|▍         | 19/500 [00:26<02:46,  2.89it/s]  4%|▍         | 21/500 [00:26<17:26,  2.18s/it]  5%|▍         | 23/500 [00:26<12:14,  1.54s/it]  5%|▌         | 25/500 [00:27<08:38,  1.09s/it]  5%|▌         | 27/500 [00:27<06:09,  1.28it/s]  6%|▌         | 29/500 [00:27<04:25,  1.77it/s]  6%|▌         | 31/500 [00:33<10:34,  1.35s/it]  7%|▋         | 33/500 [00:33<07:31,  1.03it/s]  7%|▋         | 35/500 [00:33<05:23,  1.44it/s]  7%|▋         | 37/500 [00:34<03:54,  1.98it/s]  8%|▊         | 39/500 [00:34<02:52,  2.68it/s]  8%|▊         | 41/500 [00:40<09:18,  1.22s/it]  9%|▊         | 43/500 [00:40<06:38,  1.15it/s]  9%|▉         | 45/500 [00:40<04:46,  1.59it/s]  9%|▉         | 47/500 [00:40<03:28,  2.17it/s] 10%|▉         | 49/500 [00:41<02:34,  2.92it/s] 10%|█         | 51/500 [00:53<16:11,  2.16s/it] 11%|█         | 53/500 [00:54<11:26,  1.54s/it] 11%|█         | 55/500 [00:54<08:07,  1.09s/it] 11%|█▏        | 57/500 [00:54<05:48,  1.27it/s] 12%|█▏        | 59/500 [00:54<04:11,  1.75it/s] 12%|█▏        | 61/500 [01:00<10:07,  1.38s/it] 13%|█▎        | 63/500 [01:01<07:12,  1.01it/s] 13%|█▎        | 65/500 [01:01<05:09,  1.41it/s] 13%|█▎        | 67/500 [01:01<03:43,  1.93it/s] 14%|█▍        | 69/500 [01:01<02:44,  2.62it/s]Epoch:  1  	Training Loss: 0.10876578837633133
Test Loss:  9.286910057067871
Valid Loss:  8.7686767578125
Epoch:  2  	Training Loss: 8.928092956542969
Test Loss:  276.963623046875
Valid Loss:  282.28271484375
Epoch:  3  	Training Loss: 280.51141357421875
Test Loss:  0.07480861246585846
Valid Loss:  0.10025675594806671
Epoch:  4  	Training Loss: 0.10130774229764938
Test Loss:  0.07424169778823853
Valid Loss:  0.099755197763443
Epoch:  5  	Training Loss: 0.10076221823692322
Test Loss:  0.07368922978639603
Valid Loss:  0.09928390383720398
Epoch:  6  	Training Loss: 0.10022910684347153
Test Loss:  0.0731506273150444
Valid Loss:  0.09882359206676483
Epoch:  7  	Training Loss: 0.09970780462026596
Test Loss:  0.0726303830742836
Valid Loss:  0.09837393462657928
Epoch:  8  	Training Loss: 0.09919770061969757
Test Loss:  0.07213859260082245
Valid Loss:  0.09793855249881744
Epoch:  9  	Training Loss: 0.09871213138103485
Test Loss:  0.07166580110788345
Valid Loss:  0.09751996397972107
Epoch:  10  	Training Loss: 0.09824711829423904
Test Loss:  0.07120321691036224
Valid Loss:  0.09710898995399475
Epoch:  11  	Training Loss: 0.09779126942157745
Test Loss:  0.07075066864490509
Valid Loss:  0.09670577198266983
Epoch:  12  	Training Loss: 0.09734439849853516
Test Loss:  0.027486665174365044
Valid Loss:  0.044625528156757355
Epoch:  13  	Training Loss: 0.04069819301366806
Test Loss:  0.019585534930229187
Valid Loss:  0.03516891971230507
Epoch:  14  	Training Loss: 0.03309877961874008
Test Loss:  0.025361791253089905
Valid Loss:  0.03755762428045273
Epoch:  15  	Training Loss: 0.03254549205303192
Test Loss:  0.021702585741877556
Valid Loss:  0.03549721837043762
Epoch:  16  	Training Loss: 0.03389286994934082
Test Loss:  0.03019876591861248
Valid Loss:  0.04130801931023598
Epoch:  17  	Training Loss: 0.03534981608390808
Test Loss:  0.025948219001293182
Valid Loss:  0.03968069702386856
Epoch:  18  	Training Loss: 0.03867543488740921
Test Loss:  0.03777684271335602
Valid Loss:  0.04857499897480011
Epoch:  19  	Training Loss: 0.04147599637508392
Test Loss:  0.03361911326646805
Valid Loss:  0.04811399430036545
Epoch:  20  	Training Loss: 0.04778604209423065
Test Loss:  0.04765062406659126
Valid Loss:  0.058424822986125946
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.05011378601193428
Test Loss:  0.04026671499013901
Valid Loss:  0.049960218369960785
Epoch:  22  	Training Loss: 0.042388275265693665
Test Loss:  0.026251858100295067
Valid Loss:  0.03636948764324188
Epoch:  23  	Training Loss: 0.03522421792149544
Test Loss:  0.023986972868442535
Valid Loss:  0.02889961563050747
Epoch:  24  	Training Loss: 0.02459787204861641
Test Loss:  0.016481200233101845
Valid Loss:  0.020948927849531174
Epoch:  25  	Training Loss: 0.019204918295145035
Test Loss:  0.01589195989072323
Valid Loss:  0.018227003514766693
Epoch:  26  	Training Loss: 0.01603568345308304
Test Loss:  0.013237811625003815
Valid Loss:  0.015314193442463875
Epoch:  27  	Training Loss: 0.013969719409942627
Test Loss:  0.012383509427309036
Valid Loss:  0.013545067049562931
Epoch:  28  	Training Loss: 0.012348920106887817
Test Loss:  0.011092083528637886
Valid Loss:  0.011665109544992447
Epoch:  29  	Training Loss: 0.010870743542909622
Test Loss:  0.010293622501194477
Valid Loss:  0.010236106812953949
Epoch:  30  	Training Loss: 0.00967162474989891
Test Loss:  0.009320536628365517
Valid Loss:  0.009050259366631508
Epoch:  31  	Training Loss: 0.008697114884853363
Test Loss:  0.008453309535980225
Valid Loss:  0.008086549118161201
Epoch:  32  	Training Loss: 0.007890269160270691
Test Loss:  0.009525815956294537
Valid Loss:  0.009176397696137428
Epoch:  33  	Training Loss: 0.009207591414451599
Test Loss:  0.009528644382953644
Valid Loss:  0.008709743618965149
Epoch:  34  	Training Loss: 0.008849915117025375
Test Loss:  0.008603578433394432
Valid Loss:  0.00768441753461957
Epoch:  35  	Training Loss: 0.007897122763097286
Test Loss:  0.008201276883482933
Valid Loss:  0.007220908999443054
Epoch:  36  	Training Loss: 0.0074682533740997314
Test Loss:  0.00795369129627943
Valid Loss:  0.006947449408471584
Epoch:  37  	Training Loss: 0.007206037640571594
Test Loss:  0.007806764449924231
Valid Loss:  0.006754572503268719
Epoch:  38  	Training Loss: 0.007040731608867645
Test Loss:  0.007706286385655403
Valid Loss:  0.00661530252546072
Epoch:  39  	Training Loss: 0.006925693713128567
Test Loss:  0.0076304469257593155
Valid Loss:  0.006522518582642078
Epoch:  40  	Training Loss: 0.006847395561635494
Test Loss:  0.00757908821105957
Valid Loss:  0.006457232870161533
Epoch:  41  	Training Loss: 0.0067874975502491
Test Loss:  0.007544178515672684
Valid Loss:  0.006397727876901627
Epoch:  42  	Training Loss: 0.0067360252141952515
Test Loss:  0.007143620401620865
Valid Loss:  0.006187860853970051
Epoch:  43  	Training Loss: 0.006464301608502865
Test Loss:  0.007005013059824705
Valid Loss:  0.006058895494788885
Epoch:  44  	Training Loss: 0.006361470557749271
Test Loss:  0.006821753457188606
Valid Loss:  0.006055113859474659
Epoch:  45  	Training Loss: 0.006302257068455219
Test Loss:  0.006816748064011335
Valid Loss:  0.005989986937493086
Epoch:  46  	Training Loss: 0.0062689888291060925
Test Loss:  0.006667874753475189
Valid Loss:  0.006057039834558964
Epoch:  47  	Training Loss: 0.006261706352233887
Test Loss:  0.006763306446373463
Valid Loss:  0.0059756869450211525
Epoch:  48  	Training Loss: 0.006247720681130886
Test Loss:  0.006591997109353542
Valid Loss:  0.00607895664870739
Epoch:  49  	Training Loss: 0.006254322826862335
Test Loss:  0.006778777576982975
Valid Loss:  0.005985327064990997
Epoch:  50  	Training Loss: 0.006256342865526676
Test Loss:  0.006560169160366058
Valid Loss:  0.006152545101940632
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.006306275259703398
Test Loss:  0.006224018521606922
Valid Loss:  0.0055519333109259605
Epoch:  52  	Training Loss: 0.0058067115023732185
Test Loss:  0.006194585002958775
Valid Loss:  0.005430320277810097
Epoch:  53  	Training Loss: 0.005716958548873663
Test Loss:  0.006161396391689777
Valid Loss:  0.00532956700772047
Epoch:  54  	Training Loss: 0.005641455762088299
Test Loss:  0.006132639944553375
Valid Loss:  0.0052499109879136086
Epoch:  55  	Training Loss: 0.005582377314567566
Test Loss:  0.006107666064053774
Valid Loss:  0.005186067894101143
Epoch:  56  	Training Loss: 0.005532722920179367
Test Loss:  0.0060866340063512325
Valid Loss:  0.005126722157001495
Epoch:  57  	Training Loss: 0.005483981221914291
Test Loss:  0.006068040616810322
Valid Loss:  0.005078756250441074
Epoch:  58  	Training Loss: 0.0054416656494140625
Test Loss:  0.006052511744201183
Valid Loss:  0.005036321934312582
Epoch:  59  	Training Loss: 0.005403855349868536
Test Loss:  0.006038302555680275
Valid Loss:  0.005001742392778397
Epoch:  60  	Training Loss: 0.005372372455894947
Test Loss:  0.006025451701134443
Valid Loss:  0.0049738166853785515
Epoch:  61  	Training Loss: 0.00534398015588522
Test Loss:  0.00601538922637701
Valid Loss:  0.004948359914124012
Epoch:  62  	Training Loss: 0.005315952003002167
Test Loss:  0.005743079353123903
Valid Loss:  0.00446675019338727
Epoch:  63  	Training Loss: 0.004873021971434355
Test Loss:  0.005724811460822821
Valid Loss:  0.004404516890645027
Epoch:  64  	Training Loss: 0.004811869002878666
Test Loss:  0.0057170516811311245
Valid Loss:  0.004392705392092466
Epoch:  65  	Training Loss: 0.004797079600393772
Test Loss:  0.005707631353288889
Valid Loss:  0.004389192909002304
Epoch:  66  	Training Loss: 0.004790298640727997
Test Loss:  0.005697778891772032
Valid Loss:  0.0043878862634301186
Epoch:  67  	Training Loss: 0.0047860657796263695
Test Loss:  0.005688450299203396
Valid Loss:  0.004387826658785343
Epoch:  68  	Training Loss: 0.004782996606081724
Test Loss:  0.005678689572960138
Valid Loss:  0.004388211295008659
Epoch:  69  	Training Loss: 0.004780483432114124
Test Loss:  0.005670258309692144
Valid Loss:  0.004388857167214155
 14%|█▍        | 71/500 [01:07<08:45,  1.23s/it] 15%|█▍        | 73/500 [01:08<06:15,  1.14it/s] 15%|█▌        | 75/500 [01:08<04:30,  1.57it/s] 15%|█▌        | 77/500 [01:08<03:16,  2.15it/s] 16%|█▌        | 79/500 [01:08<02:24,  2.91it/s] 16%|█▌        | 81/500 [01:14<08:29,  1.22s/it] 17%|█▋        | 83/500 [01:15<06:03,  1.15it/s] 17%|█▋        | 85/500 [01:15<04:21,  1.59it/s] 17%|█▋        | 87/500 [01:15<03:10,  2.17it/s] 18%|█▊        | 89/500 [01:15<02:20,  2.92it/s] 18%|█▊        | 91/500 [01:21<08:04,  1.19s/it] 19%|█▊        | 93/500 [01:21<05:46,  1.17it/s] 19%|█▉        | 95/500 [01:22<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:22<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:22<02:14,  2.99it/s] 20%|██        | 101/500 [01:28<07:53,  1.19s/it] 21%|██        | 103/500 [01:28<05:38,  1.17it/s] 21%|██        | 105/500 [01:28<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:29<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:29<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:35<07:47,  1.20s/it] 23%|██▎       | 113/500 [01:35<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:35<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:36<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:36<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:42<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:42<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:42<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:42<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:42<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:49<07:22,  1.20s/it] 27%|██▋       | 133/500 [01:49<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:49<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:49<02:44,  2.20it/s]Epoch:  70  	Training Loss: 0.004778615199029446
Test Loss:  0.005665462464094162
Valid Loss:  0.004389664623886347
Epoch:  71  	Training Loss: 0.004777462687343359
Test Loss:  0.005661299917846918
Valid Loss:  0.004390450660139322
Epoch:  72  	Training Loss: 0.004776583053171635
Test Loss:  0.005646031815558672
Valid Loss:  0.004414874594658613
Epoch:  73  	Training Loss: 0.0047815581783652306
Test Loss:  0.005573323927819729
Valid Loss:  0.004372572526335716
Epoch:  74  	Training Loss: 0.004742871038615704
Test Loss:  0.00556966383010149
Valid Loss:  0.004368881694972515
Epoch:  75  	Training Loss: 0.004741086158901453
Test Loss:  0.005571635439991951
Valid Loss:  0.004366580862551928
Epoch:  76  	Training Loss: 0.004740345757454634
Test Loss:  0.005574669223278761
Valid Loss:  0.004365085624158382
Epoch:  77  	Training Loss: 0.004739627242088318
Test Loss:  0.005575831979513168
Valid Loss:  0.004362976178526878
Epoch:  78  	Training Loss: 0.004738859832286835
Test Loss:  0.005578044336289167
Valid Loss:  0.004361040890216827
Epoch:  79  	Training Loss: 0.004738224670290947
Test Loss:  0.0055800536647439
Valid Loss:  0.004359387792646885
Epoch:  80  	Training Loss: 0.004737701267004013
Test Loss:  0.005581684410572052
Valid Loss:  0.00435800151899457
Epoch:  81  	Training Loss: 0.004737233277410269
Test Loss:  0.005583165213465691
Valid Loss:  0.004356692545115948
Epoch:  82  	Training Loss: 0.004736790899187326
Test Loss:  0.0054502286948263645
Valid Loss:  0.004288826137781143
Epoch:  83  	Training Loss: 0.004661693703383207
Test Loss:  0.005328710190951824
Valid Loss:  0.0042290231212973595
Epoch:  84  	Training Loss: 0.0045923772267997265
Test Loss:  0.005213155411183834
Valid Loss:  0.004172314424067736
Epoch:  85  	Training Loss: 0.004526639357209206
Test Loss:  0.0051030442118644714
Valid Loss:  0.004118384327739477
Epoch:  86  	Training Loss: 0.0044642118737101555
Test Loss:  0.004998072981834412
Valid Loss:  0.004066983237862587
Epoch:  87  	Training Loss: 0.0044048554264009
Test Loss:  0.004897782579064369
Valid Loss:  0.004018055275082588
Epoch:  88  	Training Loss: 0.004348433576524258
Test Loss:  0.004801810719072819
Valid Loss:  0.003971624653786421
Epoch:  89  	Training Loss: 0.004294790327548981
Test Loss:  0.004709938541054726
Valid Loss:  0.003927523270249367
Epoch:  90  	Training Loss: 0.004243721254169941
Test Loss:  0.004622097127139568
Valid Loss:  0.0038853916339576244
Epoch:  91  	Training Loss: 0.004195009358227253
Test Loss:  0.004537983797490597
Valid Loss:  0.003845357336103916
Epoch:  92  	Training Loss: 0.004148594103753567
Test Loss:  0.004368082154542208
Valid Loss:  0.0037707642186433077
Epoch:  93  	Training Loss: 0.004061627201735973
Test Loss:  0.004230013117194176
Valid Loss:  0.003713407553732395
Epoch:  94  	Training Loss: 0.003988170996308327
Test Loss:  0.004078781232237816
Valid Loss:  0.0036470515187829733
Epoch:  95  	Training Loss: 0.00391205120831728
Test Loss:  0.003954925574362278
Valid Loss:  0.0035975188948214054
Epoch:  96  	Training Loss: 0.0038496293127536774
Test Loss:  0.0038439971394836903
Valid Loss:  0.0035532100591808558
Epoch:  97  	Training Loss: 0.0037932025734335184
Test Loss:  0.0037317059468477964
Valid Loss:  0.0035054199397563934
Epoch:  98  	Training Loss: 0.0037379846908152103
Test Loss:  0.0036355918273329735
Valid Loss:  0.003467822913080454
Epoch:  99  	Training Loss: 0.003689934965223074
Test Loss:  0.0035444297827780247
Valid Loss:  0.003430287353694439
Epoch:  100  	Training Loss: 0.0036457241512835026
Test Loss:  0.0034611118026077747
Valid Loss:  0.003397972323000431
Epoch:  101  	Training Loss: 0.003604409983381629
Test Loss:  0.0033830783795565367
Valid Loss:  0.003365330398082733
Epoch:  102  	Training Loss: 0.003566365223377943
Test Loss:  0.003341489937156439
Valid Loss:  0.0033420822583138943
Epoch:  103  	Training Loss: 0.0035435091704130173
Test Loss:  0.0033047758042812347
Valid Loss:  0.0033219056203961372
Epoch:  104  	Training Loss: 0.0035235127434134483
Test Loss:  0.0032712160609662533
Valid Loss:  0.003303872188553214
Epoch:  105  	Training Loss: 0.0035054581239819527
Test Loss:  0.003240430261939764
Valid Loss:  0.0032873875461518764
Epoch:  106  	Training Loss: 0.003488698974251747
Test Loss:  0.0032116950023919344
Valid Loss:  0.0032719054725021124
Epoch:  107  	Training Loss: 0.0034728143364191055
Test Loss:  0.0031842421740293503
Valid Loss:  0.0032574948854744434
Epoch:  108  	Training Loss: 0.0034577208571135998
Test Loss:  0.0031586275435984135
Valid Loss:  0.003244288032874465
Epoch:  109  	Training Loss: 0.003443503752350807
Test Loss:  0.0031329693738371134
Valid Loss:  0.003231651149690151
Epoch:  110  	Training Loss: 0.0034297306556254625
Test Loss:  0.003109574317932129
Valid Loss:  0.0032194957602769136
Epoch:  111  	Training Loss: 0.003416478168219328
Test Loss:  0.0030852179042994976
Valid Loss:  0.0032079205848276615
Epoch:  112  	Training Loss: 0.0034035409335047007
Test Loss:  0.002988585038110614
Valid Loss:  0.003180511761456728
Epoch:  113  	Training Loss: 0.003365598851814866
Test Loss:  0.0029085539281368256
Valid Loss:  0.0031577558256685734
Epoch:  114  	Training Loss: 0.003333072178065777
Test Loss:  0.002839622087776661
Valid Loss:  0.003137790597975254
Epoch:  115  	Training Loss: 0.0033043925650417805
Test Loss:  0.002778606256470084
Valid Loss:  0.0031199948862195015
Epoch:  116  	Training Loss: 0.0032786736264824867
Test Loss:  0.002724158111959696
Valid Loss:  0.003103854600340128
Epoch:  117  	Training Loss: 0.0032554694917052984
Test Loss:  0.002675282768905163
Valid Loss:  0.0030887299217283726
Epoch:  118  	Training Loss: 0.003234113333746791
Test Loss:  0.0026311033871024847
Valid Loss:  0.00307435542345047
Epoch:  119  	Training Loss: 0.003214267548173666
Test Loss:  0.0025908839888870716
Valid Loss:  0.0030607027001678944
Epoch:  120  	Training Loss: 0.0031958811450749636
Test Loss:  0.00255414517596364
Valid Loss:  0.0030476576648652554
Epoch:  121  	Training Loss: 0.0031787375919520855
Test Loss:  0.0025205803103744984
Valid Loss:  0.00303578469902277
Epoch:  122  	Training Loss: 0.003162982640787959
Test Loss:  0.0024945102632045746
Valid Loss:  0.0029992442578077316
Epoch:  123  	Training Loss: 0.003128723008558154
Test Loss:  0.0024673158768564463
Valid Loss:  0.002963694278150797
Epoch:  124  	Training Loss: 0.00309649296104908
Test Loss:  0.002440445125102997
Valid Loss:  0.002929357811808586
Epoch:  125  	Training Loss: 0.0030656512826681137
Test Loss:  0.0024137457367032766
Valid Loss:  0.0028972795698791742
Epoch:  126  	Training Loss: 0.0030364308040589094
Test Loss:  0.0023876610212028027
Valid Loss:  0.0028670220635831356
Epoch:  127  	Training Loss: 0.0030082757584750652
Test Loss:  0.002361781895160675
Valid Loss:  0.0028370749205350876
Epoch:  128  	Training Loss: 0.002981009194627404
Test Loss:  0.0023314065765589476
Valid Loss:  0.0028010252863168716
Epoch:  129  	Training Loss: 0.0029426629189401865
Test Loss:  0.002280646935105324
Valid Loss:  0.0027305022813379765
Epoch:  130  	Training Loss: 0.0028685827273875475
Test Loss:  0.002236397936940193
Valid Loss:  0.0026591219939291477
Epoch:  131  	Training Loss: 0.002807050012052059
Test Loss:  0.002199640031903982
Valid Loss:  0.0026006940752267838
Epoch:  132  	Training Loss: 0.0027581488247960806
Test Loss:  0.002146491315215826
Valid Loss:  0.0024450640194118023
Epoch:  133  	Training Loss: 0.0026168334297835827
Test Loss:  0.0020918874070048332
Valid Loss:  0.002318092156201601
Epoch:  134  	Training Loss: 0.0024937251582741737
Test Loss:  0.002030970761552453
Valid Loss:  0.002204719465225935
Epoch:  135  	Training Loss: 0.0023812679573893547
Test Loss:  0.0019719249103218317
Valid Loss:  0.0021066651679575443
Epoch:  136  	Training Loss: 0.0022808508947491646
Test Loss:  0.0019144428661093116
Valid Loss:  0.002018560189753771
Epoch:  137  	Training Loss: 0.002187309553846717
Test Loss:  0.001859220676124096
Valid Loss:  0.0019411711255088449
Epoch:  138  	Training Loss: 0.002098354510962963
Test Loss:  0.001805175095796585
Valid Loss:  0.0018609858816489577
Epoch:  139  	Training Loss: 0.002009882591664791
Test Loss:   28%|██▊       | 139/500 [01:49<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:56<07:05,  1.19s/it] 29%|██▊       | 143/500 [01:56<05:04,  1.17it/s] 29%|██▉       | 145/500 [01:56<03:38,  1.62it/s] 29%|██▉       | 147/500 [01:56<02:39,  2.22it/s] 30%|██▉       | 149/500 [01:56<01:57,  2.99it/s] 30%|███       | 151/500 [02:03<07:05,  1.22s/it] 31%|███       | 153/500 [02:03<05:03,  1.14it/s] 31%|███       | 155/500 [02:03<03:38,  1.58it/s] 31%|███▏      | 157/500 [02:03<02:38,  2.17it/s] 32%|███▏      | 159/500 [02:03<01:56,  2.92it/s] 32%|███▏      | 161/500 [02:10<06:46,  1.20s/it] 33%|███▎      | 163/500 [02:10<04:49,  1.16it/s] 33%|███▎      | 165/500 [02:10<03:28,  1.61it/s] 33%|███▎      | 167/500 [02:10<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:10<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:17<06:30,  1.19s/it] 35%|███▍      | 173/500 [02:17<04:38,  1.17it/s] 35%|███▌      | 175/500 [02:17<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:17<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:17<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:24<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:24<04:29,  1.17it/s] 37%|███▋      | 185/500 [02:24<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:24<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:24<01:43,  2.99it/s] 38%|███▊      | 191/500 [02:30<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:31<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:31<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:31<02:16,  2.21it/s] 40%|███▉      | 199/500 [02:31<01:42,  2.93it/s] 40%|████      | 201/500 [02:37<05:50,  1.17s/it] 41%|████      | 203/500 [02:37<04:09,  1.19it/s] 41%|████      | 205/500 [02:38<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:38<02:11,  2.23it/s]0.0017537940293550491
Valid Loss:  0.001787663553841412
Epoch:  140  	Training Loss: 0.0019294766243547201
Test Loss:  0.0017048646695911884
Valid Loss:  0.0017220438458025455
Epoch:  141  	Training Loss: 0.0018557077273726463
Test Loss:  0.0016581375384703279
Valid Loss:  0.0016617262735962868
Epoch:  142  	Training Loss: 0.001785400789231062
Test Loss:  0.00161155650857836
Valid Loss:  0.0016068308614194393
Epoch:  143  	Training Loss: 0.0017328659305348992
Test Loss:  0.0016281583812087774
Valid Loss:  0.0015868827467784286
Epoch:  144  	Training Loss: 0.0017169320490211248
Test Loss:  0.0015819797990843654
Valid Loss:  0.0015629244735464454
Epoch:  145  	Training Loss: 0.0016966857947409153
Test Loss:  0.0015649392735213041
Valid Loss:  0.0015522922622039914
Epoch:  146  	Training Loss: 0.0016869606915861368
Test Loss:  0.0015724191907793283
Valid Loss:  0.0015444704331457615
Epoch:  147  	Training Loss: 0.0016797160496935248
Test Loss:  0.001544377999380231
Valid Loss:  0.001533631468191743
Epoch:  148  	Training Loss: 0.0016690560150891542
Test Loss:  0.0015325576532632113
Valid Loss:  0.0015262493398040533
Epoch:  149  	Training Loss: 0.001660908805206418
Test Loss:  0.001521938480436802
Valid Loss:  0.0015191512648016214
Epoch:  150  	Training Loss: 0.0016531862784177065
Test Loss:  0.0015198059845715761
Valid Loss:  0.001512559363618493
Epoch:  151  	Training Loss: 0.001646130345761776
Test Loss:  0.0015010894276201725
Valid Loss:  0.0015050858492031693
Epoch:  152  	Training Loss: 0.0016381618333980441
Test Loss:  0.001500387559644878
Valid Loss:  0.0014755913289263844
Epoch:  153  	Training Loss: 0.0016030125552788377
Test Loss:  0.0014839167706668377
Valid Loss:  0.0014534916263073683
Epoch:  154  	Training Loss: 0.0015733576146885753
Test Loss:  0.0014748049434274435
Valid Loss:  0.0014365541283041239
Epoch:  155  	Training Loss: 0.0015482478775084019
Test Loss:  0.0014660547021776438
Valid Loss:  0.0014230762608349323
Epoch:  156  	Training Loss: 0.001526047009974718
Test Loss:  0.0014523769496008754
Valid Loss:  0.001408784999512136
Epoch:  157  	Training Loss: 0.001506216125562787
Test Loss:  0.0014457185752689838
Valid Loss:  0.0013942682417109609
Epoch:  158  	Training Loss: 0.0014881909592077136
Test Loss:  0.0014335194136947393
Valid Loss:  0.0013775044353678823
Epoch:  159  	Training Loss: 0.0014717791927978396
Test Loss:  0.0014260807074606419
Valid Loss:  0.0013624816201627254
Epoch:  160  	Training Loss: 0.0014569060876965523
Test Loss:  0.0014162466395646334
Valid Loss:  0.0013486999087035656
Epoch:  161  	Training Loss: 0.0014430857263505459
Test Loss:  0.0014079546090215445
Valid Loss:  0.0013352297246456146
Epoch:  162  	Training Loss: 0.0014286284567788243
Test Loss:  0.0014029891462996602
Valid Loss:  0.001322097610682249
Epoch:  163  	Training Loss: 0.0014139156555756927
Test Loss:  0.0013981801457703114
Valid Loss:  0.001310132211074233
Epoch:  164  	Training Loss: 0.0014003155520185828
Test Loss:  0.0013938674237579107
Valid Loss:  0.0012991649564355612
Epoch:  165  	Training Loss: 0.0013877986930310726
Test Loss:  0.0013900150079280138
Valid Loss:  0.0012881315778940916
Epoch:  166  	Training Loss: 0.0013756444677710533
Test Loss:  0.0013871020637452602
Valid Loss:  0.0012752424227073789
Epoch:  167  	Training Loss: 0.0013637456577271223
Test Loss:  0.001385113806463778
Valid Loss:  0.0012633309233933687
Epoch:  168  	Training Loss: 0.0013529303250834346
Test Loss:  0.001383007736876607
Valid Loss:  0.0012523194309324026
Epoch:  169  	Training Loss: 0.0013424102216959
Test Loss:  0.0013815095881000161
Valid Loss:  0.0012412619544193149
Epoch:  170  	Training Loss: 0.001331557985395193
Test Loss:  0.0013800096930935979
Valid Loss:  0.0012310167076066136
Epoch:  171  	Training Loss: 0.0013210392789915204
Test Loss:  0.0013789793010801077
Valid Loss:  0.0012208709958940744
Epoch:  172  	Training Loss: 0.0013104341924190521
Test Loss:  0.0013696779496967793
Valid Loss:  0.0011826236732304096
Epoch:  173  	Training Loss: 0.0012661403743550181
Test Loss:  0.0013604768319055438
Valid Loss:  0.001157474471256137
Epoch:  174  	Training Loss: 0.0012367900926619768
Test Loss:  0.0013485795352607965
Valid Loss:  0.0011356722097843885
Epoch:  175  	Training Loss: 0.0012118846643716097
Test Loss:  0.0013350339140743017
Valid Loss:  0.0011155109386891127
Epoch:  176  	Training Loss: 0.001189114060252905
Test Loss:  0.001321595860645175
Valid Loss:  0.0010967138223350048
Epoch:  177  	Training Loss: 0.001167670008726418
Test Loss:  0.0013091331347823143
Valid Loss:  0.0010782817844301462
Epoch:  178  	Training Loss: 0.0011461772955954075
Test Loss:  0.0012952899560332298
Valid Loss:  0.0010605012066662312
Epoch:  179  	Training Loss: 0.0011251777177676558
Test Loss:  0.0012818275718018413
Valid Loss:  0.0010428333189338446
Epoch:  180  	Training Loss: 0.0011039880337193608
Test Loss:  0.0012679093051701784
Valid Loss:  0.0010259072296321392
Epoch:  181  	Training Loss: 0.0010833644773811102
Test Loss:  0.0012546511134132743
Valid Loss:  0.001009427709504962
Epoch:  182  	Training Loss: 0.001062789000570774
Test Loss:  0.0012618990149348974
Valid Loss:  0.0010016239248216152
Epoch:  183  	Training Loss: 0.0010512338485568762
Test Loss:  0.0012690650764852762
Valid Loss:  0.000993509660474956
Epoch:  184  	Training Loss: 0.001041487092152238
Test Loss:  0.0012758182128891349
Valid Loss:  0.000986396218650043
Epoch:  185  	Training Loss: 0.0010331665398553014
Test Loss:  0.0012808884494006634
Valid Loss:  0.0009803229477256536
Epoch:  186  	Training Loss: 0.00102601433172822
Test Loss:  0.0012845313176512718
Valid Loss:  0.0009750435128808022
Epoch:  187  	Training Loss: 0.001019766554236412
Test Loss:  0.0012880237773060799
Valid Loss:  0.0009703357354737818
Epoch:  188  	Training Loss: 0.0010141946841031313
Test Loss:  0.0012914974940940738
Valid Loss:  0.000966140883974731
Epoch:  189  	Training Loss: 0.001009209780022502
Test Loss:  0.001294582150876522
Valid Loss:  0.0009623848600313067
Epoch:  190  	Training Loss: 0.001004769466817379
Test Loss:  0.001297416165471077
Valid Loss:  0.0009590098634362221
Epoch:  191  	Training Loss: 0.0010007608216255903
Test Loss:  0.0013000202598050237
Valid Loss:  0.0009559711907058954
Epoch:  192  	Training Loss: 0.0009971370454877615
Test Loss:  0.001254234230145812
Valid Loss:  0.0009429409983567894
Epoch:  193  	Training Loss: 0.000985889695584774
Test Loss:  0.0012374692596495152
Valid Loss:  0.0009294111514464021
Epoch:  194  	Training Loss: 0.0009698197827674448
Test Loss:  0.0012001530267298222
Valid Loss:  0.0009194487938657403
Epoch:  195  	Training Loss: 0.0009606493986211717
Test Loss:  0.0011943564750254154
Valid Loss:  0.0009116182918660343
Epoch:  196  	Training Loss: 0.0009512302931398153
Test Loss:  0.001159812556579709
Valid Loss:  0.0009022917365655303
Epoch:  197  	Training Loss: 0.0009420700371265411
Test Loss:  0.001157562481239438
Valid Loss:  0.0008970118360593915
Epoch:  198  	Training Loss: 0.0009359403047710657
Test Loss:  0.0011295649455860257
Valid Loss:  0.0008900116663426161
Epoch:  199  	Training Loss: 0.0009290296584367752
Test Loss:  0.0011318798642605543
Valid Loss:  0.0008865763666108251
Epoch:  200  	Training Loss: 0.0009247546549886465
Test Loss:  0.0011059567332267761
Valid Loss:  0.0008797531481832266
Epoch:  201  	Training Loss: 0.0009179088519886136
Test Loss:  0.0011062775738537312
Valid Loss:  0.0008769470150582492
Epoch:  202  	Training Loss: 0.0009144764626398683
Test Loss:  0.0011069632600992918
Valid Loss:  0.0008729233522899449
Epoch:  203  	Training Loss: 0.0009096498833969235
Test Loss:  0.0011083008721470833
Valid Loss:  0.0008698197198100388
Epoch:  204  	Training Loss: 0.000906366971321404
Test Loss:  0.0011096912203356624
Valid Loss:  0.0008674674900248647
Epoch:  205  	Training Loss: 0.000904007931239903
Test Loss:  0.0011113849468529224
Valid Loss:  0.0008656097925268114
Epoch:  206  	Training Loss: 0.000902136554941535
Test Loss:  0.0011129843769595027
Valid Loss:  0.0008640691521577537
Epoch:  207  	Training Loss: 0.0009006626205518842
Test Loss:  0.0011144834570586681
Valid Loss:  0.0008626851486042142
 42%|████▏     | 209/500 [02:38<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:44<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:44<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:44<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:45<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:45<01:34,  2.99it/s] 44%|████▍     | 221/500 [02:51<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:51<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:51<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:51<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:52<01:31,  2.98it/s] 46%|████▌     | 231/500 [02:58<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:58<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:58<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:58<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:58<01:26,  3.00it/s] 48%|████▊     | 241/500 [03:05<05:07,  1.19s/it] 49%|████▊     | 243/500 [03:05<03:38,  1.17it/s] 49%|████▉     | 245/500 [03:05<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:05<01:54,  2.21it/s] 50%|████▉     | 249/500 [03:05<01:24,  2.97it/s] 50%|█████     | 251/500 [03:12<04:57,  1.20s/it] 51%|█████     | 253/500 [03:12<03:32,  1.16it/s] 51%|█████     | 255/500 [03:12<02:32,  1.61it/s] 51%|█████▏    | 257/500 [03:12<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:12<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:19<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:19<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:19<02:26,  1.60it/s] 53%|█████▎    | 267/500 [03:19<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:19<01:20,  2.87it/s] 54%|█████▍    | 271/500 [03:26<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:26<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:26<02:18,  1.62it/s]Epoch:  208  	Training Loss: 0.0008993507362902164
Test Loss:  0.0011160050053149462
Valid Loss:  0.000861432752572
Epoch:  209  	Training Loss: 0.0008982049184851348
Test Loss:  0.001117521314881742
Valid Loss:  0.0008604212198406458
Epoch:  210  	Training Loss: 0.0008972986252047122
Test Loss:  0.0011182196903973818
Valid Loss:  0.000859584310092032
Epoch:  211  	Training Loss: 0.0008965865708887577
Test Loss:  0.001119036809541285
Valid Loss:  0.0008589121862314641
Epoch:  212  	Training Loss: 0.0008959174738265574
Test Loss:  0.0011060581309720874
Valid Loss:  0.0008515467052347958
Epoch:  213  	Training Loss: 0.0008868671138770878
Test Loss:  0.0010895562591031194
Valid Loss:  0.0008440209785476327
Epoch:  214  	Training Loss: 0.0008786037797108293
Test Loss:  0.0010747169144451618
Valid Loss:  0.0008369716815650463
Epoch:  215  	Training Loss: 0.0008707895176485181
Test Loss:  0.0010607900330796838
Valid Loss:  0.0008302400819957256
Epoch:  216  	Training Loss: 0.0008633647812530398
Test Loss:  0.0010475576855242252
Valid Loss:  0.000823815877083689
Epoch:  217  	Training Loss: 0.0008563053561374545
Test Loss:  0.0010351559612900019
Valid Loss:  0.000817642081528902
Epoch:  218  	Training Loss: 0.0008495262591168284
Test Loss:  0.0010234002256765962
Valid Loss:  0.0008117338875308633
Epoch:  219  	Training Loss: 0.0008429832523688674
Test Loss:  0.0010122103849425912
Valid Loss:  0.0008060748805291951
Epoch:  220  	Training Loss: 0.0008366816909983754
Test Loss:  0.0010013934224843979
Valid Loss:  0.0008006011485122144
Epoch:  221  	Training Loss: 0.0008305961964651942
Test Loss:  0.0009911202359944582
Valid Loss:  0.0007952776504680514
Epoch:  222  	Training Loss: 0.00082466343883425
Test Loss:  0.0009794544894248247
Valid Loss:  0.0007897786563262343
Epoch:  223  	Training Loss: 0.0008193917456083
Test Loss:  0.0009700446389615536
Valid Loss:  0.0007853442220948637
Epoch:  224  	Training Loss: 0.0008149385685101151
Test Loss:  0.000962032878305763
Valid Loss:  0.0007815925637260079
Epoch:  225  	Training Loss: 0.0008112417999655008
Test Loss:  0.0009552018600516021
Valid Loss:  0.0007784800254739821
Epoch:  226  	Training Loss: 0.0008080222178250551
Test Loss:  0.0009491587989032269
Valid Loss:  0.0007758056744933128
Epoch:  227  	Training Loss: 0.0008053116616792977
Test Loss:  0.0009437478147447109
Valid Loss:  0.0007734440732747316
Epoch:  228  	Training Loss: 0.0008029183372855186
Test Loss:  0.0009390534833073616
Valid Loss:  0.0007712887600064278
Epoch:  229  	Training Loss: 0.0008006871212273836
Test Loss:  0.0009348895982839167
Valid Loss:  0.0007693085935898125
Epoch:  230  	Training Loss: 0.0007986455457285047
Test Loss:  0.0009309356100857258
Valid Loss:  0.0007676047389395535
Epoch:  231  	Training Loss: 0.0007967865094542503
Test Loss:  0.0009272762108594179
Valid Loss:  0.0007660102564841509
Epoch:  232  	Training Loss: 0.0007950523286126554
Test Loss:  0.00093129463493824
Valid Loss:  0.0007564333500340581
Epoch:  233  	Training Loss: 0.0007820901810191572
Test Loss:  0.0009364666766487062
Valid Loss:  0.0007509718416258693
Epoch:  234  	Training Loss: 0.0007746258052065969
Test Loss:  0.0009407162433490157
Valid Loss:  0.0007459826301783323
Epoch:  235  	Training Loss: 0.000768002646509558
Test Loss:  0.0009437610860913992
Valid Loss:  0.000741443713195622
Epoch:  236  	Training Loss: 0.0007622034754604101
Test Loss:  0.0009448121418245137
Valid Loss:  0.0007372437394224107
Epoch:  237  	Training Loss: 0.0007569686276838183
Test Loss:  0.0009453344391658902
Valid Loss:  0.0007333132671192288
Epoch:  238  	Training Loss: 0.0007521675433963537
Test Loss:  0.0009454525425098836
Valid Loss:  0.000729605439119041
Epoch:  239  	Training Loss: 0.000747722340747714
Test Loss:  0.0009452772792428732
Valid Loss:  0.0007261007558554411
Epoch:  240  	Training Loss: 0.000743582786526531
Test Loss:  0.000944928964599967
Valid Loss:  0.0007227992173284292
Epoch:  241  	Training Loss: 0.0007397251902148128
Test Loss:  0.0009445581817999482
Valid Loss:  0.0007197271334007382
Epoch:  242  	Training Loss: 0.0007361291209235787
Test Loss:  0.0009240840445272624
Valid Loss:  0.0007095999317243695
Epoch:  243  	Training Loss: 0.0007256268872879446
Test Loss:  0.0009112486732192338
Valid Loss:  0.0007016225135885179
Epoch:  244  	Training Loss: 0.0007163254776969552
Test Loss:  0.0008993188966996968
Valid Loss:  0.0006941762985661626
Epoch:  245  	Training Loss: 0.0007076294277794659
Test Loss:  0.0008882943075150251
Valid Loss:  0.0006872215308248997
Epoch:  246  	Training Loss: 0.0006994547438807786
Test Loss:  0.0008780659991316497
Valid Loss:  0.000680671539157629
Epoch:  247  	Training Loss: 0.0006917210994288325
Test Loss:  0.000868569128215313
Valid Loss:  0.0006745237624272704
Epoch:  248  	Training Loss: 0.0006844199378974736
Test Loss:  0.0008596836123615503
Valid Loss:  0.0006683559622615576
Epoch:  249  	Training Loss: 0.0006775007350370288
Test Loss:  0.0008513153297826648
Valid Loss:  0.0006620020139962435
Epoch:  250  	Training Loss: 0.0006709289737045765
Test Loss:  0.0008434649207629263
Valid Loss:  0.0006559007451869547
Epoch:  251  	Training Loss: 0.0006646875408478081
Test Loss:  0.0008360522333532572
Valid Loss:  0.000650014728307724
Epoch:  252  	Training Loss: 0.0006587152020074427
Test Loss:  0.0008143993909470737
Valid Loss:  0.0006422776496037841
Epoch:  253  	Training Loss: 0.000650185567792505
Test Loss:  0.0008027735166251659
Valid Loss:  0.0006367156747728586
Epoch:  254  	Training Loss: 0.000642564962618053
Test Loss:  0.0007885980885475874
Valid Loss:  0.0006309498567134142
Epoch:  255  	Training Loss: 0.0006354820798151195
Test Loss:  0.0007776451529935002
Valid Loss:  0.0006259195506572723
Epoch:  256  	Training Loss: 0.0006289002485573292
Test Loss:  0.0007664135191589594
Valid Loss:  0.0006209817947819829
Epoch:  257  	Training Loss: 0.0006227576523087919
Test Loss:  0.0007566798012703657
Valid Loss:  0.0006164503283798695
Epoch:  258  	Training Loss: 0.0006169641856104136
Test Loss:  0.0007470273412764072
Valid Loss:  0.0006119386525824666
Epoch:  259  	Training Loss: 0.000611441966611892
Test Loss:  0.0007381222676485777
Valid Loss:  0.0006077049183659256
Epoch:  260  	Training Loss: 0.0006061628228053451
Test Loss:  0.0007296517724171281
Valid Loss:  0.0006035684491507709
Epoch:  261  	Training Loss: 0.0006010153447277844
Test Loss:  0.0007218975224532187
Valid Loss:  0.0005996337276883423
Epoch:  262  	Training Loss: 0.0005959101254120469
Test Loss:  0.0007175517966970801
Valid Loss:  0.0005988299380987883
Epoch:  263  	Training Loss: 0.0005953743821009994
Test Loss:  0.000714315683580935
Valid Loss:  0.0005982986185699701
Epoch:  264  	Training Loss: 0.000595053774304688
Test Loss:  0.0007118885405361652
Valid Loss:  0.0005979412817396224
Epoch:  265  	Training Loss: 0.0005948616890236735
Test Loss:  0.0007100595394149423
Valid Loss:  0.0005976949469186366
Epoch:  266  	Training Loss: 0.0005947446334175766
Test Loss:  0.0007086732657626271
Valid Loss:  0.0005975225940346718
Epoch:  267  	Training Loss: 0.0005946731544099748
Test Loss:  0.0007076186593621969
Valid Loss:  0.0005973996012471616
Epoch:  268  	Training Loss: 0.0005946268211118877
Test Loss:  0.0007068139966577291
Valid Loss:  0.0005973097868263721
Epoch:  269  	Training Loss: 0.0005945970187895
Test Loss:  0.0007061983342282474
Valid Loss:  0.0005972427898086607
Epoch:  270  	Training Loss: 0.0005945751909166574
Test Loss:  0.0007057251641526818
Valid Loss:  0.0005971917416900396
Epoch:  271  	Training Loss: 0.0005945601733401418
Test Loss:  0.0007053613662719727
Valid Loss:  0.0005971523933112621
Epoch:  272  	Training Loss: 0.0005945474840700626
Test Loss:  0.0007099508075043559
Valid Loss:  0.0005945138400420547
Epoch:  273  	Training Loss: 0.0005896238144487143
Test Loss:  0.0007053342997096479
Valid Loss:  0.0005905341822654009
Epoch:  274  	Training Loss: 0.000585898756980896
Test Loss:  0.0007025529630482197
Valid Loss:  0.0005873403861187398
Epoch:  275  	Training Loss: 0.000582542852498591
Test Loss:  0.0007000192999839783
Valid Loss:  0.0005843513645231724
Epoch:  276  	Training Loss: 0.0005793854361400008
Test Loss:   55%|█████▌    | 277/500 [03:26<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:26<01:14,  2.99it/s] 56%|█████▌    | 281/500 [03:32<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:33<03:04,  1.17it/s] 57%|█████▋    | 285/500 [03:33<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:33<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:33<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:39<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:39<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:40<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:40<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:40<01:07,  2.97it/s] 60%|██████    | 301/500 [03:46<03:57,  1.20s/it] 61%|██████    | 303/500 [03:46<02:49,  1.17it/s] 61%|██████    | 305/500 [03:47<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:47<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:47<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:53<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:53<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:53<01:53,  1.62it/s] 63%|██████▎   | 317/500 [03:54<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:54<01:00,  2.99it/s] 64%|██████▍   | 321/500 [04:00<03:32,  1.19s/it] 65%|██████▍   | 323/500 [04:00<02:30,  1.17it/s] 65%|██████▌   | 325/500 [04:00<01:47,  1.62it/s] 65%|██████▌   | 327/500 [04:00<01:17,  2.22it/s] 66%|██████▌   | 329/500 [04:01<00:57,  2.99it/s] 66%|██████▌   | 331/500 [04:07<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:07<02:21,  1.18it/s] 67%|██████▋   | 335/500 [04:07<01:40,  1.64it/s] 67%|██████▋   | 337/500 [04:07<01:12,  2.24it/s] 68%|██████▊   | 339/500 [04:07<00:53,  3.01it/s] 68%|██████▊   | 341/500 [04:20<05:39,  2.14s/it]0.0006976093864068389
Valid Loss:  0.0005815391195937991
Epoch:  277  	Training Loss: 0.0005764066008850932
Test Loss:  0.0006953445845283568
Valid Loss:  0.0005788897396996617
Epoch:  278  	Training Loss: 0.000573595694731921
Test Loss:  0.0006931998068466783
Valid Loss:  0.000576401362195611
Epoch:  279  	Training Loss: 0.0005709450342692435
Test Loss:  0.0006911928649060428
Valid Loss:  0.0005740911001339555
Epoch:  280  	Training Loss: 0.0005684737116098404
Test Loss:  0.0006892927922308445
Valid Loss:  0.0005719285691156983
Epoch:  281  	Training Loss: 0.0005661704926751554
Test Loss:  0.0006874745595268905
Valid Loss:  0.0005698805907741189
Epoch:  282  	Training Loss: 0.0005639488808810711
Test Loss:  0.0006849545752629638
Valid Loss:  0.0005694227293133736
Epoch:  283  	Training Loss: 0.0005635815323330462
Test Loss:  0.0006832649232819676
Valid Loss:  0.0005691231926903129
Epoch:  284  	Training Loss: 0.0005632702959701419
Test Loss:  0.0006819634581916034
Valid Loss:  0.0005689305253326893
Epoch:  285  	Training Loss: 0.0005629969527944922
Test Loss:  0.0006808689795434475
Valid Loss:  0.0005687725497409701
Epoch:  286  	Training Loss: 0.0005627576028928161
Test Loss:  0.0006799539551138878
Valid Loss:  0.0005686403019353747
Epoch:  287  	Training Loss: 0.0005625463090837002
Test Loss:  0.0006791017949581146
Valid Loss:  0.000568518356885761
Epoch:  288  	Training Loss: 0.0005623649340122938
Test Loss:  0.0006783741991966963
Valid Loss:  0.0005684202187694609
Epoch:  289  	Training Loss: 0.0005621983436867595
Test Loss:  0.000677724601700902
Valid Loss:  0.0005683364579454064
Epoch:  290  	Training Loss: 0.0005620444426313043
Test Loss:  0.0006771183689124882
Valid Loss:  0.0005682608461938798
Epoch:  291  	Training Loss: 0.0005618982831947505
Test Loss:  0.000676558876875788
Valid Loss:  0.0005682000191882253
Epoch:  292  	Training Loss: 0.000561763416044414
Test Loss:  0.0006739328964613378
Valid Loss:  0.0005613199900835752
Epoch:  293  	Training Loss: 0.0005551516078412533
Test Loss:  0.0006719286320731044
Valid Loss:  0.0005551110953092575
Epoch:  294  	Training Loss: 0.0005491394549608231
Test Loss:  0.0006702104583382607
Valid Loss:  0.0005498847458511591
Epoch:  295  	Training Loss: 0.0005439522210508585
Test Loss:  0.0006686728447675705
Valid Loss:  0.0005449233576655388
Epoch:  296  	Training Loss: 0.0005393342580646276
Test Loss:  0.000667322427034378
Valid Loss:  0.0005402861861512065
Epoch:  297  	Training Loss: 0.0005351307336241007
Test Loss:  0.0006662074592895806
Valid Loss:  0.0005360436625778675
Epoch:  298  	Training Loss: 0.0005312301800586283
Test Loss:  0.000665127532556653
Valid Loss:  0.0005321678472682834
Epoch:  299  	Training Loss: 0.0005277115851640701
Test Loss:  0.0006639777566306293
Valid Loss:  0.0005285147344693542
Epoch:  300  	Training Loss: 0.0005244538187980652
Test Loss:  0.0006628392729908228
Valid Loss:  0.0005250975955277681
Epoch:  301  	Training Loss: 0.0005213754484429955
Test Loss:  0.0006616634782403708
Valid Loss:  0.0005218929727561772
Epoch:  302  	Training Loss: 0.0005184832843951881
Test Loss:  0.000664539635181427
Valid Loss:  0.0005224780179560184
Epoch:  303  	Training Loss: 0.0005180069711059332
Test Loss:  0.000664233579300344
Valid Loss:  0.0005223325570113957
Epoch:  304  	Training Loss: 0.00051780795911327
Test Loss:  0.000664043182041496
Valid Loss:  0.0005222198669798672
Epoch:  305  	Training Loss: 0.0005176663980819285
Test Loss:  0.0006639458588324487
Valid Loss:  0.0005221503088250756
Epoch:  306  	Training Loss: 0.0005175567930564284
Test Loss:  0.0006638260092586279
Valid Loss:  0.0005220636958256364
Epoch:  307  	Training Loss: 0.0005174491088837385
Test Loss:  0.0006637090700678527
Valid Loss:  0.0005219784216023982
Epoch:  308  	Training Loss: 0.0005173423560336232
Test Loss:  0.0006636368343606591
Valid Loss:  0.000521891750395298
Epoch:  309  	Training Loss: 0.0005172358942218125
Test Loss:  0.00066356360912323
Valid Loss:  0.0005218066507950425
Epoch:  310  	Training Loss: 0.0005171563825570047
Test Loss:  0.0006636776961386204
Valid Loss:  0.000521737732924521
Epoch:  311  	Training Loss: 0.0005170711665414274
Test Loss:  0.0006635977188125253
Valid Loss:  0.0005216238787397742
Epoch:  312  	Training Loss: 0.000516989384777844
Test Loss:  0.0006481973105110228
Valid Loss:  0.000514614162966609
Epoch:  313  	Training Loss: 0.0005107269971631467
Test Loss:  0.0006426447071135044
Valid Loss:  0.0005101283313706517
Epoch:  314  	Training Loss: 0.0005051338812336326
Test Loss:  0.0006356422672979534
Valid Loss:  0.0005055901128798723
Epoch:  315  	Training Loss: 0.0004997364012524486
Test Loss:  0.000629034882877022
Valid Loss:  0.0005012578330934048
Epoch:  316  	Training Loss: 0.0004945106920786202
Test Loss:  0.0006226914119906723
Valid Loss:  0.0004969945875927806
Epoch:  317  	Training Loss: 0.0004893813747912645
Test Loss:  0.0006164006772451103
Valid Loss:  0.0004927985137328506
Epoch:  318  	Training Loss: 0.0004843849455937743
Test Loss:  0.0006099335732869804
Valid Loss:  0.0004885798553004861
Epoch:  319  	Training Loss: 0.0004795338027179241
Test Loss:  0.0006039837026037276
Valid Loss:  0.00048449437599629164
Epoch:  320  	Training Loss: 0.0004747227067127824
Test Loss:  0.0005978576373308897
Valid Loss:  0.0004804684722330421
Epoch:  321  	Training Loss: 0.0004699930432252586
Test Loss:  0.0005917027592658997
Valid Loss:  0.00047650327906012535
Epoch:  322  	Training Loss: 0.00046536437002941966
Test Loss:  0.0005839681252837181
Valid Loss:  0.00047263901797123253
Epoch:  323  	Training Loss: 0.0004622087290044874
Test Loss:  0.0005795976030640304
Valid Loss:  0.00046938625746406615
Epoch:  324  	Training Loss: 0.00045931024942547083
Test Loss:  0.0005760519416071475
Valid Loss:  0.0004662691499106586
Epoch:  325  	Training Loss: 0.00045647495426237583
Test Loss:  0.0005728460382670164
Valid Loss:  0.0004632217751350254
Epoch:  326  	Training Loss: 0.00045376206981018186
Test Loss:  0.000570818257983774
Valid Loss:  0.00046036025742068887
Epoch:  327  	Training Loss: 0.00045112211955711246
Test Loss:  0.0005681514739990234
Valid Loss:  0.00045749126002192497
Epoch:  328  	Training Loss: 0.0004485341487452388
Test Loss:  0.0005662427865900099
Valid Loss:  0.0004547230782918632
Epoch:  329  	Training Loss: 0.00044600263936445117
Test Loss:  0.0005628191865980625
Valid Loss:  0.0004517908382695168
Epoch:  330  	Training Loss: 0.00044347794027999043
Test Loss:  0.0005599717260338366
Valid Loss:  0.00044906511902809143
Epoch:  331  	Training Loss: 0.00044101555249653757
Test Loss:  0.0005581080913543701
Valid Loss:  0.00044636742677539587
Epoch:  332  	Training Loss: 0.0004385928332339972
Test Loss:  0.0005632061511278152
Valid Loss:  0.0004465441743377596
Epoch:  333  	Training Loss: 0.00043540456681512296
Test Loss:  0.0005430615274235606
Valid Loss:  0.00044113112380728126
Epoch:  334  	Training Loss: 0.0004327697679400444
Test Loss:  0.0005590802757069468
Valid Loss:  0.0004441514320205897
Epoch:  335  	Training Loss: 0.0004307088674977422
Test Loss:  0.0005301741766743362
Valid Loss:  0.0004374025738798082
Epoch:  336  	Training Loss: 0.00042949855560436845
Test Loss:  0.0005631657550111413
Valid Loss:  0.0004459779302123934
Epoch:  337  	Training Loss: 0.0004296513507142663
Test Loss:  0.0005193557590246201
Valid Loss:  0.0004383111372590065
Epoch:  338  	Training Loss: 0.00043210829608142376
Test Loss:  0.0005848708096891642
Valid Loss:  0.00045998720452189445
Epoch:  339  	Training Loss: 0.00043902668403461576
Test Loss:  0.0005181061569601297
Valid Loss:  0.00045418445370160043
Epoch:  340  	Training Loss: 0.00045153062092140317
Test Loss:  0.0006468145293183625
Valid Loss:  0.0005072838976047933
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0004781847819685936
Test Loss:  0.0005500528495758772
Valid Loss:  0.00043261650716885924
Epoch:  342  	Training Loss: 0.00041693943785503507
Test Loss:  0.0005394316976889968
Valid Loss:  0.00042767426930367947
Epoch:  343  	Training Loss: 0.0004137051582802087
Test Loss:  0.0005338166956789792
 69%|██████▊   | 343/500 [04:20<03:58,  1.52s/it] 69%|██████▉   | 345/500 [04:20<02:47,  1.08s/it] 69%|██████▉   | 347/500 [04:20<01:58,  1.29it/s] 70%|██████▉   | 349/500 [04:21<01:24,  1.78it/s] 70%|███████   | 351/500 [04:27<03:22,  1.36s/it] 71%|███████   | 353/500 [04:27<02:22,  1.03it/s] 71%|███████   | 355/500 [04:27<01:41,  1.43it/s] 71%|███████▏  | 357/500 [04:27<01:12,  1.96it/s] 72%|███████▏  | 359/500 [04:28<00:53,  2.66it/s] 72%|███████▏  | 361/500 [04:34<02:48,  1.21s/it] 73%|███████▎  | 363/500 [04:34<01:59,  1.15it/s] 73%|███████▎  | 365/500 [04:34<01:25,  1.59it/s] 73%|███████▎  | 367/500 [04:34<01:01,  2.17it/s] 74%|███████▍  | 369/500 [04:34<00:44,  2.93it/s] 74%|███████▍  | 371/500 [04:41<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:41<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:41<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:41<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:41<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:48<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:48<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:48<01:12,  1.60it/s] 77%|███████▋  | 387/500 [04:48<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:48<00:37,  2.94it/s] 78%|███████▊  | 391/500 [04:55<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:55<01:31,  1.16it/s] 79%|███████▉  | 395/500 [04:55<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:55<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:55<00:34,  2.97it/s] 80%|████████  | 401/500 [05:02<01:59,  1.21s/it] 81%|████████  | 403/500 [05:02<01:24,  1.15it/s] 81%|████████  | 405/500 [05:02<00:59,  1.59it/s] 81%|████████▏ | 407/500 [05:02<00:43,  2.16it/s] 82%|████████▏ | 409/500 [05:02<00:31,  2.88it/s]Valid Loss:  0.0004250889760442078
Epoch:  344  	Training Loss: 0.0004121025267522782
Test Loss:  0.000530252989847213
Valid Loss:  0.00042332091834396124
Epoch:  345  	Training Loss: 0.0004109845613129437
Test Loss:  0.0005277472082525492
Valid Loss:  0.0004219321417622268
Epoch:  346  	Training Loss: 0.00041005705134011805
Test Loss:  0.0005257640732452273
Valid Loss:  0.0004206454032100737
Epoch:  347  	Training Loss: 0.000409172847867012
Test Loss:  0.0005240932223387063
Valid Loss:  0.00041950008017010987
Epoch:  348  	Training Loss: 0.00040838957647792995
Test Loss:  0.0005226728972047567
Valid Loss:  0.00041855318704620004
Epoch:  349  	Training Loss: 0.00040771847125142813
Test Loss:  0.0005213958793319762
Valid Loss:  0.00041767573566175997
Epoch:  350  	Training Loss: 0.00040707935113459826
Test Loss:  0.0005203743348829448
Valid Loss:  0.00041686417534947395
Epoch:  351  	Training Loss: 0.0004065613029524684
Test Loss:  0.0005200075684115291
Valid Loss:  0.0004162904806435108
Epoch:  352  	Training Loss: 0.00040612422162666917
Test Loss:  0.0005191096570342779
Valid Loss:  0.0004147169238422066
Epoch:  353  	Training Loss: 0.000404847611207515
Test Loss:  0.0005182080203667283
Valid Loss:  0.0004132325993850827
Epoch:  354  	Training Loss: 0.0004036066238768399
Test Loss:  0.0005173766985535622
Valid Loss:  0.00041182059794664383
Epoch:  355  	Training Loss: 0.00040241805254481733
Test Loss:  0.0005166017217561603
Valid Loss:  0.0004104619147256017
Epoch:  356  	Training Loss: 0.00040129502303898335
Test Loss:  0.0005158103303983808
Valid Loss:  0.00040915817953646183
Epoch:  357  	Training Loss: 0.00040020496817305684
Test Loss:  0.0005150050856173038
Valid Loss:  0.00040793087100610137
Epoch:  358  	Training Loss: 0.00039915862726047635
Test Loss:  0.0005142792942933738
Valid Loss:  0.000406738807214424
Epoch:  359  	Training Loss: 0.0003981541667599231
Test Loss:  0.0005135453538969159
Valid Loss:  0.00040557398460805416
Epoch:  360  	Training Loss: 0.0003971809637732804
Test Loss:  0.0005128367338329554
Valid Loss:  0.0004044426023028791
Epoch:  361  	Training Loss: 0.00039623587508685887
Test Loss:  0.0005121361464262009
Valid Loss:  0.00040331081254407763
Epoch:  362  	Training Loss: 0.0003953114792238921
Test Loss:  0.0005109313642606139
Valid Loss:  0.0004024866211693734
Epoch:  363  	Training Loss: 0.0003945511416532099
Test Loss:  0.0005100106354802847
Valid Loss:  0.0004017144674435258
Epoch:  364  	Training Loss: 0.00039380398811772466
Test Loss:  0.0005091852508485317
Valid Loss:  0.0004009756667073816
Epoch:  365  	Training Loss: 0.0003930637030862272
Test Loss:  0.000508416211232543
Valid Loss:  0.00040025508496910334
Epoch:  366  	Training Loss: 0.00039232888957485557
Test Loss:  0.0005076788365840912
Valid Loss:  0.0003995489969383925
Epoch:  367  	Training Loss: 0.0003915993729606271
Test Loss:  0.0005070390179753304
Valid Loss:  0.0003988532698713243
Epoch:  368  	Training Loss: 0.0003908796643372625
Test Loss:  0.0005064299330115318
Valid Loss:  0.0003981750924140215
Epoch:  369  	Training Loss: 0.00039017523522488773
Test Loss:  0.0005058347596786916
Valid Loss:  0.0003975133877247572
Epoch:  370  	Training Loss: 0.0003895187983289361
Test Loss:  0.0005056075751781464
Valid Loss:  0.0003968473756685853
Epoch:  371  	Training Loss: 0.00038884306559339166
Test Loss:  0.0005048742168582976
Valid Loss:  0.0003961637557949871
Epoch:  372  	Training Loss: 0.00038820470217615366
Test Loss:  0.0005047332961112261
Valid Loss:  0.0003960471076425165
Epoch:  373  	Training Loss: 0.0003880569711327553
Test Loss:  0.0005046945880167186
Valid Loss:  0.0003960172471124679
Epoch:  374  	Training Loss: 0.0003879953583236784
Test Loss:  0.0005047165905125439
Valid Loss:  0.00039600080344825983
Epoch:  375  	Training Loss: 0.00038795493310317397
Test Loss:  0.0005047493614256382
Valid Loss:  0.00039600301533937454
Epoch:  376  	Training Loss: 0.00038793188286945224
Test Loss:  0.000504780444316566
Valid Loss:  0.0003960063913837075
Epoch:  377  	Training Loss: 0.00038790988037362695
Test Loss:  0.0005048435414209962
Valid Loss:  0.0003960149479098618
Epoch:  378  	Training Loss: 0.00038788956589996815
Test Loss:  0.0005048807943239808
Valid Loss:  0.00039601727621629834
Epoch:  379  	Training Loss: 0.0003878690768033266
Test Loss:  0.00050495530012995
Valid Loss:  0.0003960251633543521
Epoch:  380  	Training Loss: 0.00038785129436291754
Test Loss:  0.0005049954634159803
Valid Loss:  0.00039602851029485464
Epoch:  381  	Training Loss: 0.00038783205673098564
Test Loss:  0.0005050359759479761
Valid Loss:  0.0003960322355851531
Epoch:  382  	Training Loss: 0.00038782000774517655
Test Loss:  0.0005009629530832171
Valid Loss:  0.00039491988718509674
Epoch:  383  	Training Loss: 0.00038697500713169575
Test Loss:  0.0004982903483323753
Valid Loss:  0.00039415439823642373
Epoch:  384  	Training Loss: 0.0003863711026497185
Test Loss:  0.0004963887040503323
Valid Loss:  0.0003935509012080729
Epoch:  385  	Training Loss: 0.0003858695272356272
Test Loss:  0.0004949601134285331
Valid Loss:  0.0003930421662516892
Epoch:  386  	Training Loss: 0.00038542115362361073
Test Loss:  0.0004938326310366392
Valid Loss:  0.00039259172626771033
Epoch:  387  	Training Loss: 0.0003850051434710622
Test Loss:  0.0004929010756313801
Valid Loss:  0.00039217749144881964
Epoch:  388  	Training Loss: 0.00038461264921352267
Test Loss:  0.0004921033978462219
Valid Loss:  0.00039179250597953796
Epoch:  389  	Training Loss: 0.00038423913065344095
Test Loss:  0.0004913986194878817
Valid Loss:  0.0003914266999345273
Epoch:  390  	Training Loss: 0.00038386392407119274
Test Loss:  0.0004907621187157929
Valid Loss:  0.0003910052473656833
Epoch:  391  	Training Loss: 0.00038344564381986856
Test Loss:  0.0004902160144411027
Valid Loss:  0.00039059564005583525
Epoch:  392  	Training Loss: 0.00038304226472973824
Test Loss:  0.0004895567544735968
Valid Loss:  0.0003905181074514985
Epoch:  393  	Training Loss: 0.0003829431952908635
Test Loss:  0.0004889958654530346
Valid Loss:  0.0003904561453964561
Epoch:  394  	Training Loss: 0.0003828514600172639
Test Loss:  0.0004885111702606082
Valid Loss:  0.0003904043696820736
Epoch:  395  	Training Loss: 0.0003827657492365688
Test Loss:  0.0004880873311776668
Valid Loss:  0.0003903634496964514
Epoch:  396  	Training Loss: 0.0003826852480415255
Test Loss:  0.00048771145520731807
Valid Loss:  0.0003903296892531216
Epoch:  397  	Training Loss: 0.0003826077445410192
Test Loss:  0.0004873745492659509
Valid Loss:  0.00039030093466863036
Epoch:  398  	Training Loss: 0.00038253370439633727
Test Loss:  0.00048706657253205776
Valid Loss:  0.00039027491584420204
Epoch:  399  	Training Loss: 0.00038246187614277005
Test Loss:  0.0004867850511800498
Valid Loss:  0.00039025547448545694
Epoch:  400  	Training Loss: 0.0003823940351139754
Test Loss:  0.0004865244263783097
Valid Loss:  0.0003902373427990824
Epoch:  401  	Training Loss: 0.0003823277656920254
Test Loss:  0.0004862801870331168
Valid Loss:  0.00039022136479616165
Epoch:  402  	Training Loss: 0.0003822637954726815
Test Loss:  0.0004868862743023783
Valid Loss:  0.0003890268271788955
Epoch:  403  	Training Loss: 0.0003808935871347785
Test Loss:  0.0004857050662394613
Valid Loss:  0.0003876690461765975
Epoch:  404  	Training Loss: 0.00037970332778058946
Test Loss:  0.00048448238521814346
Valid Loss:  0.00038630992639809847
Epoch:  405  	Training Loss: 0.0003785233129747212
Test Loss:  0.0004832203558180481
Valid Loss:  0.00038495921762660146
Epoch:  406  	Training Loss: 0.00037735243677161634
Test Loss:  0.00048195093404501677
Valid Loss:  0.00038361933548003435
Epoch:  407  	Training Loss: 0.00037619081558659673
Test Loss:  0.0004807088989764452
Valid Loss:  0.00038229173514992
Epoch:  408  	Training Loss: 0.0003750387404579669
Test Loss:  0.00047953525790944695
Valid Loss:  0.0003809694026131183
Epoch:  409  	Training Loss: 0.00037389632780104876
Test Loss:  0.0004783429321832955
Valid Loss:  0.00037965996307320893
Epoch:  410  	Training Loss: 0.0003727623843587935
Test Loss:  0.0004771484527736902
Valid Loss:  0.00037836242699995637
Epoch:  411  	Training Loss: 0.00037163900560699403
 82%|████████▏ | 411/500 [05:09<01:48,  1.21s/it] 83%|████████▎ | 413/500 [05:09<01:15,  1.15it/s] 83%|████████▎ | 415/500 [05:09<00:53,  1.59it/s] 83%|████████▎ | 417/500 [05:09<00:38,  2.18it/s] 84%|████████▍ | 419/500 [05:09<00:27,  2.93it/s] 84%|████████▍ | 421/500 [05:16<01:36,  1.22s/it] 85%|████████▍ | 423/500 [05:16<01:07,  1.14it/s] 85%|████████▌ | 425/500 [05:16<00:47,  1.58it/s] 85%|████████▌ | 427/500 [05:16<00:33,  2.16it/s] 86%|████████▌ | 429/500 [05:16<00:24,  2.92it/s] 86%|████████▌ | 431/500 [05:23<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:23<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:23<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:23<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:23<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:30<01:12,  1.23s/it] 89%|████████▊ | 443/500 [05:30<00:50,  1.14it/s] 89%|████████▉ | 445/500 [05:30<00:34,  1.57it/s] 89%|████████▉ | 447/500 [05:30<00:24,  2.13it/s] 90%|████████▉ | 449/500 [05:31<00:17,  2.88it/s] 90%|█████████ | 451/500 [05:37<00:59,  1.22s/it] 91%|█████████ | 453/500 [05:37<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:37<00:28,  1.58it/s] 91%|█████████▏| 457/500 [05:37<00:19,  2.16it/s] 92%|█████████▏| 459/500 [05:38<00:14,  2.92it/s] 92%|█████████▏| 461/500 [05:44<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:44<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:44<00:22,  1.58it/s] 93%|█████████▎| 467/500 [05:45<00:15,  2.16it/s] 94%|█████████▍| 469/500 [05:45<00:10,  2.90it/s] 94%|█████████▍| 471/500 [05:51<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:51<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:51<00:15,  1.59it/s] 95%|█████████▌| 477/500 [05:52<00:10,  2.17it/s]Test Loss:  0.0004760195151902735
Valid Loss:  0.0003771177143789828
Epoch:  412  	Training Loss: 0.0003705394919961691
Test Loss:  0.0004761645686812699
Valid Loss:  0.0003771948395296931
Epoch:  413  	Training Loss: 0.00037038890877738595
Test Loss:  0.0004760977462865412
Valid Loss:  0.00037721398985013366
Epoch:  414  	Training Loss: 0.0003702591056935489
Test Loss:  0.0004759061266668141
Valid Loss:  0.000377198273781687
Epoch:  415  	Training Loss: 0.0003701391979120672
Test Loss:  0.00047564960550516844
Valid Loss:  0.00037715889629907906
Epoch:  416  	Training Loss: 0.0003700239467434585
Test Loss:  0.0004753611865453422
Valid Loss:  0.00037710624746978283
Epoch:  417  	Training Loss: 0.00036991186789236963
Test Loss:  0.000475052569527179
Valid Loss:  0.0003770460607483983
Epoch:  418  	Training Loss: 0.00036980275763198733
Test Loss:  0.0004747380153276026
Valid Loss:  0.0003769820905290544
Epoch:  419  	Training Loss: 0.0003696962376125157
Test Loss:  0.000474422296974808
Valid Loss:  0.00037691646139137447
Epoch:  420  	Training Loss: 0.00036959227873012424
Test Loss:  0.00047408294631168246
Valid Loss:  0.0003768409660551697
Epoch:  421  	Training Loss: 0.0003694926272146404
Test Loss:  0.0004737598937936127
Valid Loss:  0.00037676800275221467
Epoch:  422  	Training Loss: 0.0003693955368362367
Test Loss:  0.00047342671314254403
Valid Loss:  0.00037625685217790306
Epoch:  423  	Training Loss: 0.0003688603173941374
Test Loss:  0.0004730200453195721
Valid Loss:  0.0003758264356292784
Epoch:  424  	Training Loss: 0.00036838033702224493
Test Loss:  0.00047256206744350493
Valid Loss:  0.0003753924975171685
Epoch:  425  	Training Loss: 0.00036792675382457674
Test Loss:  0.0004720666620414704
Valid Loss:  0.0003749747993424535
Epoch:  426  	Training Loss: 0.0003675101906992495
Test Loss:  0.0004715460818260908
Valid Loss:  0.00037457654252648354
Epoch:  427  	Training Loss: 0.00036715215537697077
Test Loss:  0.00047109005390666425
Valid Loss:  0.00037421632441692054
Epoch:  428  	Training Loss: 0.0003668632125481963
Test Loss:  0.00047068155254237354
Valid Loss:  0.00037387904012575746
Epoch:  429  	Training Loss: 0.00036659772740677
Test Loss:  0.00047027639811858535
Valid Loss:  0.0003735475183930248
Epoch:  430  	Training Loss: 0.00036633526906371117
Test Loss:  0.000469873717520386
Valid Loss:  0.00037321995478123426
Epoch:  431  	Training Loss: 0.00036609009839594364
Test Loss:  0.00046946684597060084
Valid Loss:  0.0003729152958840132
Epoch:  432  	Training Loss: 0.0003658686764538288
Test Loss:  0.0004668289329856634
Valid Loss:  0.0003709773300215602
Epoch:  433  	Training Loss: 0.00036449209437705576
Test Loss:  0.0004649090697057545
Valid Loss:  0.0003693671606015414
Epoch:  434  	Training Loss: 0.0003632655134424567
Test Loss:  0.00046339724212884903
Valid Loss:  0.00036794133484363556
Epoch:  435  	Training Loss: 0.0003621152136474848
Test Loss:  0.0004621283442247659
Valid Loss:  0.0003666028496809304
Epoch:  436  	Training Loss: 0.00036097547854296863
Test Loss:  0.0004610022879205644
Valid Loss:  0.00036534463288262486
Epoch:  437  	Training Loss: 0.0003598672046791762
Test Loss:  0.0004599850217346102
Valid Loss:  0.0003641492803581059
Epoch:  438  	Training Loss: 0.0003587862302083522
Test Loss:  0.0004590002354234457
Valid Loss:  0.0003629973507486284
Epoch:  439  	Training Loss: 0.00035769963869825006
Test Loss:  0.00045797458733431995
Valid Loss:  0.00036176599678583443
Epoch:  440  	Training Loss: 0.00035658685374073684
Test Loss:  0.0004569792654365301
Valid Loss:  0.00036057346733286977
Epoch:  441  	Training Loss: 0.00035550666507333517
Test Loss:  0.0004559886874631047
Valid Loss:  0.0003594114095903933
Epoch:  442  	Training Loss: 0.00035442871740087867
Test Loss:  0.0004556814965326339
Valid Loss:  0.0003593129222281277
Epoch:  443  	Training Loss: 0.0003541860496625304
Test Loss:  0.00045533524826169014
Valid Loss:  0.000359221245162189
Epoch:  444  	Training Loss: 0.0003539661120157689
Test Loss:  0.0004549876321107149
Valid Loss:  0.00035913672763854265
Epoch:  445  	Training Loss: 0.000353764567989856
Test Loss:  0.0004545963602140546
Valid Loss:  0.00035905279219150543
Epoch:  446  	Training Loss: 0.0003535785072017461
Test Loss:  0.0004541944363154471
Valid Loss:  0.00035897083580493927
Epoch:  447  	Training Loss: 0.00035340533941052854
Test Loss:  0.00045376550406217575
Valid Loss:  0.0003588931867852807
Epoch:  448  	Training Loss: 0.00035324550117366016
Test Loss:  0.00045336480252444744
Valid Loss:  0.0003588196123018861
Epoch:  449  	Training Loss: 0.0003530958783812821
Test Loss:  0.0004529471625573933
Valid Loss:  0.0003587496466934681
Epoch:  450  	Training Loss: 0.0003529585083015263
Test Loss:  0.00045257480815052986
Valid Loss:  0.0003586850070860237
Epoch:  451  	Training Loss: 0.0003528306551743299
Test Loss:  0.00045218958985060453
Valid Loss:  0.0003586226957850158
Epoch:  452  	Training Loss: 0.0003527094959281385
Test Loss:  0.00045288188266567886
Valid Loss:  0.0003586186794564128
Epoch:  453  	Training Loss: 0.0003524564381223172
Test Loss:  0.00045321136713027954
Valid Loss:  0.00035852918517775834
Epoch:  454  	Training Loss: 0.00035226496402174234
Test Loss:  0.00045330222928896546
Valid Loss:  0.00035838043550029397
Epoch:  455  	Training Loss: 0.0003520965692587197
Test Loss:  0.0004532688471954316
Valid Loss:  0.0003581955097615719
Epoch:  456  	Training Loss: 0.00035193696385249496
Test Loss:  0.00045315653551369905
Valid Loss:  0.00035800732439383864
Epoch:  457  	Training Loss: 0.00035180128179490566
Test Loss:  0.0004530117439571768
Valid Loss:  0.00035781157203018665
Epoch:  458  	Training Loss: 0.00035166816087439656
Test Loss:  0.000452847161795944
Valid Loss:  0.00035763104096986353
Epoch:  459  	Training Loss: 0.00035153626231476665
Test Loss:  0.00045267381938174367
Valid Loss:  0.00035747283254750073
Epoch:  460  	Training Loss: 0.0003514060808811337
Test Loss:  0.00045249416143633425
Valid Loss:  0.00035731366369873285
Epoch:  461  	Training Loss: 0.0003512779949232936
Test Loss:  0.000452318083262071
Valid Loss:  0.0003571573761291802
Epoch:  462  	Training Loss: 0.0003511531394906342
Test Loss:  0.00045116047840565443
Valid Loss:  0.00035628362093120813
Epoch:  463  	Training Loss: 0.0003504381456878036
Test Loss:  0.0004502835508901626
Valid Loss:  0.0003555422299541533
Epoch:  464  	Training Loss: 0.0003497458528727293
Test Loss:  0.0004495870671235025
Valid Loss:  0.00035485730040818453
Epoch:  465  	Training Loss: 0.000349063309840858
Test Loss:  0.0004489242855925113
Valid Loss:  0.00035417056642472744
Epoch:  466  	Training Loss: 0.00034835192491300404
Test Loss:  0.0004480638890527189
Valid Loss:  0.0003534277784638107
Epoch:  467  	Training Loss: 0.00034768186742439866
Test Loss:  0.000447373982751742
Valid Loss:  0.00035276031121611595
Epoch:  468  	Training Loss: 0.00034700374817475677
Test Loss:  0.0004467344260774553
Valid Loss:  0.00035209886846132576
Epoch:  469  	Training Loss: 0.0003463140456005931
Test Loss:  0.00044613011414185166
Valid Loss:  0.00035146280424669385
Epoch:  470  	Training Loss: 0.0003456353151705116
Test Loss:  0.0004455414891708642
Valid Loss:  0.0003508459194563329
Epoch:  471  	Training Loss: 0.0003449667419772595
Test Loss:  0.0004449549887795001
Valid Loss:  0.00035024184035137296
Epoch:  472  	Training Loss: 0.000344308209605515
Test Loss:  0.0004420805489644408
Valid Loss:  0.0003490828676149249
Epoch:  473  	Training Loss: 0.00034344044979661703
Test Loss:  0.00044009380508214235
Valid Loss:  0.0003481654857750982
Epoch:  474  	Training Loss: 0.00034267164301127195
Test Loss:  0.0004385756328701973
Valid Loss:  0.0003473586402833462
Epoch:  475  	Training Loss: 0.00034193636383861303
Test Loss:  0.000437313923612237
Valid Loss:  0.0003466061898507178
Epoch:  476  	Training Loss: 0.000341213948559016
Test Loss:  0.00043619691859930754
Valid Loss:  0.00034588249400258064
Epoch:  477  	Training Loss: 0.0003405038733035326
Test Loss:  0.0004351929237600416
Valid Loss:  0.0003451880475040525
Epoch:  478  	Training Loss: 0.00033981268643401563
Test Loss:  0.0004342219326645136
Valid Loss:  0.00034451164538040757
 96%|█████████▌| 479/500 [05:52<00:07,  2.92it/s] 96%|█████████▌| 481/500 [05:58<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:58<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:58<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:58<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:58<00:03,  3.00it/s] 98%|█████████▊| 491/500 [06:05<00:10,  1.20s/it] 99%|█████████▊| 493/500 [06:05<00:06,  1.16it/s] 99%|█████████▉| 495/500 [06:05<00:03,  1.60it/s] 99%|█████████▉| 497/500 [06:05<00:01,  2.18it/s]100%|█████████▉| 499/500 [06:06<00:00,  2.94it/s]100%|██████████| 500/500 [06:06<00:00,  1.37it/s]
Epoch:  479  	Training Loss: 0.00033913226798176765
Test Loss:  0.00043331593042239547
Valid Loss:  0.00034385151229798794
Epoch:  480  	Training Loss: 0.00033846835140138865
Test Loss:  0.00043240428203716874
Valid Loss:  0.0003431943478062749
Epoch:  481  	Training Loss: 0.00033780751982703805
Test Loss:  0.0004315319238230586
Valid Loss:  0.00034253974445164204
Epoch:  482  	Training Loss: 0.0003371504135429859
Test Loss:  0.00043201682274229825
Valid Loss:  0.000342664890922606
Epoch:  483  	Training Loss: 0.00033703551162034273
Test Loss:  0.00043242546962574124
Valid Loss:  0.00034278040402568877
Epoch:  484  	Training Loss: 0.0003369585028849542
Test Loss:  0.0004327674978412688
Valid Loss:  0.00034288119059056044
Epoch:  485  	Training Loss: 0.00033690599957481027
Test Loss:  0.000433051201980561
Valid Loss:  0.0003429676580708474
Epoch:  486  	Training Loss: 0.0003368692414369434
Test Loss:  0.00043328653555363417
Valid Loss:  0.0003430387587286532
Epoch:  487  	Training Loss: 0.0003368428151588887
Test Loss:  0.00043348147301003337
Valid Loss:  0.0003430982760619372
Epoch:  488  	Training Loss: 0.000336822762619704
Test Loss:  0.00043364203884266317
Valid Loss:  0.0003431469085626304
Epoch:  489  	Training Loss: 0.00033680733758956194
Test Loss:  0.0004337758291512728
Valid Loss:  0.0003431848017498851
Epoch:  490  	Training Loss: 0.00033679447369650006
Test Loss:  0.0004338867438491434
Valid Loss:  0.00034321408020332456
Epoch:  491  	Training Loss: 0.0003367834724485874
Test Loss:  0.0004339791485108435
Valid Loss:  0.0003432355006225407
Epoch:  492  	Training Loss: 0.0003367734025232494
Test Loss:  0.0004319703148212284
Valid Loss:  0.0003418712876737118
Epoch:  493  	Training Loss: 0.0003358490066602826
Test Loss:  0.00043060741154477
Valid Loss:  0.0003407573967706412
Epoch:  494  	Training Loss: 0.000334983691573143
Test Loss:  0.0004295326070860028
Valid Loss:  0.00033974077086895704
Epoch:  495  	Training Loss: 0.00033413703204132617
Test Loss:  0.00042859118548221886
Valid Loss:  0.00033877172973006964
Epoch:  496  	Training Loss: 0.0003333008789923042
Test Loss:  0.0004277101834304631
Valid Loss:  0.0003378281544428319
Epoch:  497  	Training Loss: 0.00033247267128899693
Test Loss:  0.0004268591874279082
Valid Loss:  0.00033690151758491993
Epoch:  498  	Training Loss: 0.0003316520305816084
Test Loss:  0.0004260214336682111
Valid Loss:  0.00033598783193156123
Epoch:  499  	Training Loss: 0.00033083860762417316
Test Loss:  0.0004251932550687343
Valid Loss:  0.0003350827901158482
Epoch:  500  	Training Loss: 0.00033003222779370844
Test Loss:  0.00042436900548636913
Valid Loss:  0.0003341883420944214
seed is  4
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:39, 12.56it/s]  1%|          | 4/500 [00:00<00:39, 12.46it/s]  1%|          | 6/500 [00:00<00:37, 13.15it/s]  2%|▏         | 8/500 [00:00<00:34, 14.27it/s]  2%|▏         | 10/500 [00:00<00:32, 14.85it/s]  2%|▏         | 12/500 [00:00<00:31, 15.27it/s]  3%|▎         | 14/500 [00:00<00:31, 15.59it/s]  3%|▎         | 16/500 [00:01<00:30, 15.68it/s]  4%|▎         | 18/500 [00:01<00:30, 15.95it/s]  4%|▍         | 20/500 [00:01<00:29, 16.17it/s]  4%|▍         | 22/500 [00:01<00:29, 16.36it/s]  5%|▍         | 24/500 [00:01<00:28, 16.42it/s]  5%|▌         | 26/500 [00:01<00:28, 16.48it/s]  6%|▌         | 28/500 [00:01<00:28, 16.53it/s]  6%|▌         | 30/500 [00:01<00:28, 16.55it/s]  6%|▋         | 32/500 [00:02<00:28, 16.59it/s]  7%|▋         | 34/500 [00:02<00:28, 16.58it/s]  7%|▋         | 36/500 [00:02<00:28, 16.56it/s]  8%|▊         | 38/500 [00:02<00:28, 16.50it/s]  8%|▊         | 40/500 [00:02<00:27, 16.56it/s]  8%|▊         | 42/500 [00:02<00:27, 16.62it/s]  9%|▉         | 44/500 [00:02<00:27, 16.64it/s]  9%|▉         | 46/500 [00:02<00:27, 16.62it/s] 10%|▉         | 48/500 [00:03<00:27, 16.58it/s] 10%|█         | 50/500 [00:03<00:26, 16.67it/s] 10%|█         | 52/500 [00:03<00:26, 16.70it/s] 11%|█         | 54/500 [00:03<00:26, 16.72it/s] 11%|█         | 56/500 [00:03<00:26, 16.67it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.63it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.62it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.58it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.56it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.58it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.55it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.46it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.44it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.54it/s] 15%|█▌        | 76/500 [00:04<00:29, 14.44it/s] 16%|█▌        | 78/500 [00:04<00:28, 14.59it/s] 16%|█▌        | 80/500 [00:05<00:27, 15.16it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.53it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.83it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.00it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.16it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.30it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.24it/s] 19%|█▉        | 94/500 [00:05<00:25, 16.23it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.34it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.42it/s] 20%|██        | 100/500 [00:06<00:24, 16.43it/s] 20%|██        | 102/500 [00:06<00:24, 16.48it/s] 21%|██        | 104/500 [00:06<00:23, 16.53it/s] 21%|██        | 106/500 [00:06<00:24, 16.31it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.28it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.31it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.37it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.54it/s] 23%|██▎       | 116/500 [00:07<00:26, 14.42it/s] 24%|██▎       | 118/500 [00:07<00:27, 13.66it/s] 24%|██▍       | 120/500 [00:07<00:28, 13.28it/s] 24%|██▍       | 122/500 [00:07<00:26, 14.12it/s] 25%|██▍       | 124/500 [00:07<00:25, 14.84it/s]Epoch:  1  	Training Loss: 0.08427952229976654
Test Loss:  2155.11328125
Valid Loss:  2147.11767578125
Epoch:  2  	Training Loss: 2149.38525390625
Test Loss:  6112334388920320.0
Valid Loss:  6136131728965632.0
Epoch:  3  	Training Loss: 6131536113958912.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:24, 15.35it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.78it/s] 26%|██▌       | 130/500 [00:08<00:23, 16.08it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.27it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.42it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.50it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.57it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.53it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.65it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.66it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.67it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.66it/s] 30%|███       | 150/500 [00:09<00:20, 16.67it/s] 30%|███       | 152/500 [00:09<00:20, 16.65it/s] 31%|███       | 154/500 [00:09<00:20, 16.64it/s] 31%|███       | 156/500 [00:09<00:20, 16.62it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.59it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.59it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.56it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.58it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.59it/s] 34%|███▎      | 168/500 [00:10<00:19, 16.65it/s] 34%|███▍      | 170/500 [00:10<00:19, 16.71it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.71it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.75it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.77it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.81it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.63it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.48it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.34it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.30it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.38it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.47it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.49it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.54it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.60it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.66it/s] 40%|████      | 200/500 [00:12<00:18, 16.59it/s] 40%|████      | 202/500 [00:12<00:18, 16.51it/s] 41%|████      | 204/500 [00:12<00:17, 16.57it/s] 41%|████      | 206/500 [00:12<00:17, 16.59it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.59it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.35it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.38it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.03it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.84it/s] 44%|████▎     | 218/500 [00:13<00:18, 15.44it/s] 44%|████▍     | 220/500 [00:13<00:17, 15.66it/s] 44%|████▍     | 222/500 [00:13<00:17, 15.97it/s] 45%|████▍     | 224/500 [00:13<00:17, 15.98it/s] 45%|████▌     | 226/500 [00:14<00:17, 16.00it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.24it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.35it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.44it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.50it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.38it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.43it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.47it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.55it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.60it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.65it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.63it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:14, 16.68it/s] 50%|█████     | 252/500 [00:15<00:14, 16.65it/s] 51%|█████     | 254/500 [00:15<00:14, 16.55it/s] 51%|█████     | 256/500 [00:15<00:14, 16.54it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.56it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.60it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.61it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.60it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.61it/s] 54%|█████▎    | 268/500 [00:16<00:13, 16.62it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.60it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.58it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.58it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.58it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.59it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.59it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.64it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.61it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.50it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.40it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.45it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.42it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.31it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.28it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.25it/s] 60%|██████    | 300/500 [00:18<00:12, 16.36it/s] 60%|██████    | 302/500 [00:18<00:12, 16.42it/s] 61%|██████    | 304/500 [00:18<00:11, 16.41it/s] 61%|██████    | 306/500 [00:18<00:11, 16.38it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.33it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.35it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.41it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.47it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.34it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.20it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.09it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.30it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.29it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.40it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.50it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.14it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.19it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.30it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.48it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.55it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.57it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.59it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.57it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.57it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.61it/s] 70%|███████   | 350/500 [00:21<00:09, 16.61it/s] 70%|███████   | 352/500 [00:21<00:08, 16.45it/s] 71%|███████   | 354/500 [00:21<00:08, 16.54it/s] 71%|███████   | 356/500 [00:21<00:08, 16.41it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.48it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.58it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.63it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.68it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.69it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.70it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.59it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.59it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.54it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.69it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.57it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.68it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.72it/s] 77%|███████▋  | 384/500 [00:23<00:06, 16.69it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.74it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.72it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.74it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.71it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.54it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.50it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.63it/s] 80%|████████  | 400/500 [00:24<00:06, 16.66it/s] 80%|████████  | 402/500 [00:24<00:05, 16.66it/s] 81%|████████  | 404/500 [00:24<00:05, 16.74it/s] 81%|████████  | 406/500 [00:24<00:05, 16.78it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.79it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.76it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.63it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.40it/s] 83%|████████▎ | 416/500 [00:25<00:05, 15.69it/s] 84%|████████▎ | 418/500 [00:25<00:05, 15.98it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.15it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.31it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.14it/s] 85%|████████▌ | 426/500 [00:26<00:04, 14.93it/s] 86%|████████▌ | 428/500 [00:26<00:04, 14.60it/s] 86%|████████▌ | 430/500 [00:26<00:05, 13.83it/s] 86%|████████▋ | 432/500 [00:26<00:05, 13.34it/s] 87%|████████▋ | 434/500 [00:26<00:04, 14.12it/s] 87%|████████▋ | 436/500 [00:26<00:04, 14.71it/s] 88%|████████▊ | 438/500 [00:27<00:04, 15.15it/s] 88%|████████▊ | 440/500 [00:27<00:03, 15.57it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.88it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.13it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.30it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.43it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.45it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.54it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.57it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.34it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.37it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.42it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.38it/s] 93%|█████████▎| 464/500 [00:28<00:02, 15.88it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.11it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.35it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.49it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.60it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.64it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.66it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.71it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.52it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.46it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.53it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.58it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.59it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.60it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.63it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.64it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.61it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.53it/s]100%|██████████| 500/500 [00:30<00:00, 16.45it/s]100%|██████████| 500/500 [00:30<00:00, 16.25it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  4
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:11,  6.28s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:20<09:37,  1.21s/it]  5%|▍         | 23/500 [00:20<06:49,  1.16it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:38,  2.98it/s]  6%|▌         | 31/500 [00:26<09:20,  1.20s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:27<04:48,  1.61it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:37,  2.92it/s]  8%|▊         | 41/500 [00:33<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:43,  1.61it/s]  9%|▉         | 47/500 [00:34<03:27,  2.19it/s] 10%|▉         | 49/500 [00:34<02:33,  2.94it/s] 10%|█         | 51/500 [00:40<09:01,  1.21s/it] 11%|█         | 53/500 [00:41<06:26,  1.16it/s] 11%|█         | 55/500 [00:41<04:39,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:24,  2.17it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.92it/s] 12%|█▏        | 61/500 [00:47<08:45,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:15,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:48<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.95it/s] 14%|█▍        | 71/500 [01:01<15:14,  2.13s/it]Epoch:  1  	Training Loss: 0.08427952229976654
Test Loss:  137.7467498779297
Valid Loss:  134.91278076171875
Epoch:  2  	Training Loss: 135.9120330810547
Test Loss:  0.1009938046336174
Valid Loss:  0.09023924916982651
Epoch:  3  	Training Loss: 0.09589821100234985
Test Loss:  0.10005738586187363
Valid Loss:  0.08939512819051743
Epoch:  4  	Training Loss: 0.09501812607049942
Test Loss:  0.09913541376590729
Valid Loss:  0.08856011182069778
Epoch:  5  	Training Loss: 0.09414736926555634
Test Loss:  0.09861451387405396
Valid Loss:  0.08813217282295227
Epoch:  6  	Training Loss: 0.09368640184402466
Test Loss:  0.09851863980293274
Valid Loss:  0.08804608881473541
Epoch:  7  	Training Loss: 0.09359650313854218
Test Loss:  0.0984228253364563
Valid Loss:  0.08796005696058273
Epoch:  8  	Training Loss: 0.09350666403770447
Test Loss:  0.09832707792520523
Valid Loss:  0.08787410706281662
Epoch:  9  	Training Loss: 0.09341689944267273
Test Loss:  0.09823140501976013
Valid Loss:  0.08778820931911469
Epoch:  10  	Training Loss: 0.09332719445228577
Test Loss:  0.0981357991695404
Valid Loss:  0.08770239353179932
Epoch:  11  	Training Loss: 0.09323756396770477
Test Loss:  0.09804026782512665
Valid Loss:  0.08761663734912872
Epoch:  12  	Training Loss: 0.09314800053834915
Test Loss:  0.09795328974723816
Valid Loss:  0.08753888309001923
Epoch:  13  	Training Loss: 0.09306665509939194
Test Loss:  0.09786637127399445
Valid Loss:  0.0874612033367157
Epoch:  14  	Training Loss: 0.0929853767156601
Test Loss:  0.09777951240539551
Valid Loss:  0.08738358318805695
Epoch:  15  	Training Loss: 0.09290416538715363
Test Loss:  0.09769274294376373
Valid Loss:  0.08730603009462357
Epoch:  16  	Training Loss: 0.09282302856445312
Test Loss:  0.09760604053735733
Valid Loss:  0.08722855150699615
Epoch:  17  	Training Loss: 0.0927419513463974
Test Loss:  0.0975194126367569
Valid Loss:  0.08715112507343292
Epoch:  18  	Training Loss: 0.09266094863414764
Test Loss:  0.09743285179138184
Valid Loss:  0.08707375824451447
Epoch:  19  	Training Loss: 0.09258000552654266
Test Loss:  0.09734635800123215
Valid Loss:  0.08699648082256317
Epoch:  20  	Training Loss: 0.09249913692474365
Test Loss:  0.09725993126630783
Valid Loss:  0.08691926300525665
Epoch:  21  	Training Loss: 0.09241833537817001
Test Loss:  0.09717358648777008
Valid Loss:  0.08684210479259491
Epoch:  22  	Training Loss: 0.09233760088682175
Test Loss:  0.09708743542432785
Valid Loss:  0.08676514029502869
Epoch:  23  	Training Loss: 0.0922570675611496
Test Loss:  0.09700138866901398
Valid Loss:  0.08668826520442963
Epoch:  24  	Training Loss: 0.09217661619186401
Test Loss:  0.09691542387008667
Valid Loss:  0.08661146461963654
Epoch:  25  	Training Loss: 0.0920962542295456
Test Loss:  0.09682954847812653
Valid Loss:  0.0865347608923912
Epoch:  26  	Training Loss: 0.09201598167419434
Test Loss:  0.0967550054192543
Valid Loss:  0.08646406978368759
Epoch:  27  	Training Loss: 0.0919424444437027
Test Loss:  0.09672049432992935
Valid Loss:  0.0864284336566925
Epoch:  28  	Training Loss: 0.09190618991851807
Test Loss:  0.09670598804950714
Valid Loss:  0.08641253411769867
Epoch:  29  	Training Loss: 0.09188957512378693
Test Loss:  0.09669911116361618
Valid Loss:  0.08640339225530624
Epoch:  30  	Training Loss: 0.09188072383403778
Test Loss:  0.09669458866119385
Valid Loss:  0.08639804273843765
Epoch:  31  	Training Loss: 0.09187601506710052
Test Loss:  0.09669104218482971
Valid Loss:  0.08639460057020187
Epoch:  32  	Training Loss: 0.09187276661396027
Test Loss:  0.09668835252523422
Valid Loss:  0.08639174699783325
Epoch:  33  	Training Loss: 0.09187024086713791
Test Loss:  0.09668620675802231
Valid Loss:  0.08638916164636612
Epoch:  34  	Training Loss: 0.09186837077140808
Test Loss:  0.09668444842100143
Valid Loss:  0.08638705313205719
Epoch:  35  	Training Loss: 0.09186698496341705
Test Loss:  0.0966828465461731
Valid Loss:  0.08638541400432587
Epoch:  36  	Training Loss: 0.09186587482690811
Test Loss:  0.09668166935443878
Valid Loss:  0.0863843485713005
Epoch:  37  	Training Loss: 0.09186513721942902
Test Loss:  0.09668071568012238
Valid Loss:  0.08638349175453186
Epoch:  38  	Training Loss: 0.09186454117298126
Test Loss:  0.09667987376451492
Valid Loss:  0.08638276159763336
Epoch:  39  	Training Loss: 0.09186401218175888
Test Loss:  0.0966792032122612
Valid Loss:  0.08638214319944382
Epoch:  40  	Training Loss: 0.09186354279518127
Test Loss:  0.09667856991291046
Valid Loss:  0.08638167381286621
Epoch:  41  	Training Loss: 0.09186314046382904
Test Loss:  0.09667810797691345
Valid Loss:  0.08638130873441696
Epoch:  42  	Training Loss: 0.09186280518770218
Test Loss:  0.0966777503490448
Valid Loss:  0.08638101816177368
Epoch:  43  	Training Loss: 0.09186254441738129
Test Loss:  0.0966774970293045
Valid Loss:  0.08638080954551697
Epoch:  44  	Training Loss: 0.09186234325170517
Test Loss:  0.0966772735118866
Valid Loss:  0.08638063073158264
Epoch:  45  	Training Loss: 0.09186218678951263
Test Loss:  0.09667710214853287
Valid Loss:  0.08638046681880951
Epoch:  46  	Training Loss: 0.09186206758022308
Test Loss:  0.09667696058750153
Valid Loss:  0.08638033270835876
Epoch:  47  	Training Loss: 0.09186197072267532
Test Loss:  0.09667686372995377
Valid Loss:  0.086380235850811
Epoch:  48  	Training Loss: 0.09186191856861115
Test Loss:  0.0966767817735672
Valid Loss:  0.08638016879558563
Epoch:  49  	Training Loss: 0.09186187386512756
Test Loss:  0.09667669981718063
Valid Loss:  0.08638010174036026
Epoch:  50  	Training Loss: 0.09186182916164398
Test Loss:  0.09667663276195526
Valid Loss:  0.08638002723455429
Epoch:  51  	Training Loss: 0.091861791908741
Test Loss:  0.09667657315731049
Valid Loss:  0.08637996017932892
Epoch:  52  	Training Loss: 0.0918617695569992
Test Loss:  0.0966765284538269
Valid Loss:  0.08637990802526474
Epoch:  53  	Training Loss: 0.09186173230409622
Test Loss:  0.09667646884918213
Valid Loss:  0.08637986332178116
Epoch:  54  	Training Loss: 0.09186170995235443
Test Loss:  0.09667642414569855
Valid Loss:  0.08637981861829758
Epoch:  55  	Training Loss: 0.09186168760061264
Test Loss:  0.09667639434337616
Valid Loss:  0.08637978136539459
Epoch:  56  	Training Loss: 0.09186166524887085
Test Loss:  0.09667635709047318
Valid Loss:  0.08637974411249161
Epoch:  57  	Training Loss: 0.09186165034770966
Test Loss:  0.09667632728815079
Valid Loss:  0.08637970685958862
Epoch:  58  	Training Loss: 0.09186162799596786
Test Loss:  0.096676304936409
Valid Loss:  0.08637969195842743
Epoch:  59  	Training Loss: 0.09186162054538727
Test Loss:  0.09667627513408661
Valid Loss:  0.08637966960668564
Epoch:  60  	Training Loss: 0.09186160564422607
Test Loss:  0.09667624533176422
Valid Loss:  0.08637963980436325
Epoch:  61  	Training Loss: 0.09186159074306488
Test Loss:  0.09667623043060303
Valid Loss:  0.08637963235378265
Epoch:  62  	Training Loss: 0.09186159074306488
Test Loss:  0.09667622298002243
Valid Loss:  0.08637961745262146
Epoch:  63  	Training Loss: 0.09186158329248428
Test Loss:  0.09667621552944183
Valid Loss:  0.08637961745262146
Epoch:  64  	Training Loss: 0.09186158329248428
Test Loss:  0.09667620062828064
Valid Loss:  0.08637961745262146
Epoch:  65  	Training Loss: 0.09186157584190369
Test Loss:  0.09667619317770004
Valid Loss:  0.08637961000204086
Epoch:  66  	Training Loss: 0.09186157584190369
Test Loss:  0.09667618572711945
Valid Loss:  0.08637961000204086
Epoch:  67  	Training Loss: 0.09186157584190369
Test Loss:  0.09667617082595825
Valid Loss:  0.08637960255146027
Epoch:  68  	Training Loss: 0.09186156839132309
Test Loss:  0.09667617082595825
Valid Loss:  0.08637959510087967
Epoch:  69  	Training Loss: 0.09186156839132309
Test Loss:  0.09667615592479706
Valid Loss:  0.08637959510087967
Epoch:  70  	Training Loss: 0.09186156094074249
Test Loss:  0.09667615592479706
Valid Loss:  0.08637958765029907
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.09186156094074249
Test Loss:  0.09667614847421646
Valid Loss:  0.08637958765029907
Epoch:  72  	Training Loss: 0.09186156094074249
Test Loss:  0.09667614847421646
 15%|█▍        | 73/500 [01:01<10:46,  1.51s/it] 15%|█▌        | 75/500 [01:07<14:13,  2.01s/it] 15%|█▌        | 77/500 [01:07<10:04,  1.43s/it] 16%|█▌        | 79/500 [01:07<07:09,  1.02s/it] 16%|█▌        | 81/500 [01:20<17:57,  2.57s/it] 17%|█▋        | 83/500 [01:20<12:39,  1.82s/it] 17%|█▋        | 85/500 [01:26<15:20,  2.22s/it] 17%|█▋        | 87/500 [01:26<10:49,  1.57s/it] 18%|█▊        | 89/500 [01:26<07:41,  1.12s/it] 18%|█▊        | 91/500 [01:39<18:19,  2.69s/it] 19%|█▊        | 93/500 [01:39<12:55,  1.90s/it] 19%|█▉        | 95/500 [01:46<15:24,  2.28s/it] 19%|█▉        | 97/500 [01:46<10:52,  1.62s/it] 20%|█▉        | 99/500 [01:46<07:42,  1.15s/it] 20%|██        | 101/500 [01:58<17:47,  2.68s/it] 21%|██        | 103/500 [01:58<12:32,  1.89s/it] 21%|██        | 105/500 [02:05<14:58,  2.28s/it] 21%|██▏       | 107/500 [02:05<10:34,  1.61s/it] 22%|██▏       | 109/500 [02:05<07:29,  1.15s/it] 22%|██▏       | 111/500 [02:18<17:33,  2.71s/it] 23%|██▎       | 113/500 [02:18<12:22,  1.92s/it] 23%|██▎       | 115/500 [02:24<14:50,  2.31s/it] 23%|██▎       | 117/500 [02:24<10:28,  1.64s/it] 24%|██▍       | 119/500 [02:25<07:24,  1.17s/it] 24%|██▍       | 121/500 [02:38<17:24,  2.76s/it] 25%|██▍       | 123/500 [02:38<12:15,  1.95s/it] 25%|██▌       | 125/500 [02:44<14:32,  2.33s/it] 25%|██▌       | 127/500 [02:44<10:14,  1.65s/it] 26%|██▌       | 129/500 [02:44<07:15,  1.17s/it] 26%|██▌       | 131/500 [02:57<16:40,  2.71s/it]Valid Loss:  0.08637958765029907
Epoch:  73  	Training Loss: 0.09186156094074249
Test Loss:  0.09667614102363586
Valid Loss:  0.08637958019971848
Epoch:  74  	Training Loss: 0.09186156094074249
Test Loss:  0.09667613357305527
Valid Loss:  0.08637958019971848
Epoch:  75  	Training Loss: 0.0918615534901619
Test Loss:  0.09667612612247467
Valid Loss:  0.08637957274913788
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.0918615534901619
Test Loss:  0.09667612612247467
Valid Loss:  0.08637957274913788
Epoch:  77  	Training Loss: 0.0918615460395813
Test Loss:  0.09667612612247467
Valid Loss:  0.08637957274913788
Epoch:  78  	Training Loss: 0.0918615534901619
Test Loss:  0.09667612612247467
Valid Loss:  0.08637957274913788
Epoch:  79  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611867189407
Valid Loss:  0.08637956529855728
Epoch:  80  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611867189407
Valid Loss:  0.08637957274913788
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637957274913788
Epoch:  82  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637957274913788
Epoch:  83  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611867189407
Valid Loss:  0.08637957274913788
Epoch:  84  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  85  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  87  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  88  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  89  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  90  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  92  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  93  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  94  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  95  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  97  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  98  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  99  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  100  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  102  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  103  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  104  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  105  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  107  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  108  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  109  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  110  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  112  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  113  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  114  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  115  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  117  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  118  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  119  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  120  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  122  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  123  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  124  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  125  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  127  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  128  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  129  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  130  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  132  	Training Loss: 0.0918615460395813
Test Loss:   27%|██▋       | 133/500 [02:57<11:44,  1.92s/it] 27%|██▋       | 135/500 [03:04<14:02,  2.31s/it] 27%|██▋       | 137/500 [03:04<09:54,  1.64s/it] 28%|██▊       | 139/500 [03:04<07:00,  1.17s/it] 28%|██▊       | 141/500 [03:16<16:09,  2.70s/it] 29%|██▊       | 143/500 [03:16<11:22,  1.91s/it] 29%|██▉       | 145/500 [03:23<13:32,  2.29s/it] 29%|██▉       | 147/500 [03:23<09:33,  1.62s/it] 30%|██▉       | 149/500 [03:23<06:45,  1.16s/it] 30%|██▉       | 149/500 [03:33<06:45,  1.16s/it] 30%|███       | 151/500 [03:36<15:47,  2.72s/it] 31%|███       | 153/500 [03:36<11:07,  1.92s/it] 31%|███       | 155/500 [03:42<13:13,  2.30s/it] 31%|███▏      | 157/500 [03:42<09:19,  1.63s/it] 32%|███▏      | 159/500 [03:43<06:35,  1.16s/it] 32%|███▏      | 159/500 [03:53<06:35,  1.16s/it] 32%|███▏      | 161/500 [03:55<15:10,  2.69s/it] 33%|███▎      | 163/500 [03:55<10:41,  1.90s/it] 33%|███▎      | 165/500 [04:02<12:46,  2.29s/it] 33%|███▎      | 167/500 [04:02<08:59,  1.62s/it] 34%|███▍      | 169/500 [04:02<06:22,  1.15s/it] 34%|███▍      | 169/500 [04:13<06:22,  1.15s/it] 34%|███▍      | 171/500 [04:14<14:36,  2.66s/it] 35%|███▍      | 173/500 [04:14<10:16,  1.89s/it] 35%|███▌      | 175/500 [04:21<12:15,  2.26s/it] 35%|███▌      | 177/500 [04:21<08:38,  1.61s/it] 36%|███▌      | 179/500 [04:21<06:07,  1.14s/it] 36%|███▌      | 179/500 [04:33<06:07,  1.14s/it] 36%|███▌      | 181/500 [04:33<14:13,  2.68s/it] 37%|███▋      | 183/500 [04:34<10:00,  1.89s/it] 37%|███▋      | 185/500 [04:40<11:59,  2.29s/it] 37%|███▋      | 187/500 [04:40<08:27,  1.62s/it] 38%|███▊      | 189/500 [04:40<05:59,  1.15s/it] 38%|███▊      | 191/500 [04:53<14:05,  2.74s/it]0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  133  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  134  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  135  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  137  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  138  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  139  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  140  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  142  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  143  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  144  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  145  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  147  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  148  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  149  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  150  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  152  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  153  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  154  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  155  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  157  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  158  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  159  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  160  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  162  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  163  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  164  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  165  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  167  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  168  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  169  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  170  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  172  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  173  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  174  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  175  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  177  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  178  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  179  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  180  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  182  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  183  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  184  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  185  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  187  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  188  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  189  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  190  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
 39%|███▊      | 193/500 [04:53<09:54,  1.94s/it] 39%|███▉      | 195/500 [05:00<11:46,  2.32s/it] 39%|███▉      | 197/500 [05:00<08:17,  1.64s/it] 40%|███▉      | 199/500 [05:00<05:52,  1.17s/it] 40%|████      | 201/500 [05:12<13:27,  2.70s/it] 41%|████      | 203/500 [05:13<09:27,  1.91s/it] 41%|████      | 205/500 [05:19<11:20,  2.31s/it] 41%|████▏     | 207/500 [05:19<08:00,  1.64s/it] 42%|████▏     | 209/500 [05:19<05:39,  1.17s/it] 42%|████▏     | 211/500 [05:32<13:05,  2.72s/it] 43%|████▎     | 213/500 [05:32<09:14,  1.93s/it] 43%|████▎     | 215/500 [05:39<11:02,  2.33s/it] 43%|████▎     | 217/500 [05:39<07:46,  1.65s/it] 44%|████▍     | 219/500 [05:39<05:29,  1.17s/it] 44%|████▍     | 221/500 [05:52<12:44,  2.74s/it] 45%|████▍     | 223/500 [05:52<08:57,  1.94s/it] 45%|████▌     | 225/500 [05:58<10:37,  2.32s/it] 45%|████▌     | 227/500 [05:58<07:28,  1.64s/it] 46%|████▌     | 229/500 [05:59<05:17,  1.17s/it] 46%|████▌     | 231/500 [06:11<12:08,  2.71s/it] 47%|████▋     | 233/500 [06:11<08:33,  1.92s/it] 47%|████▋     | 235/500 [06:18<10:21,  2.35s/it] 47%|████▋     | 237/500 [06:18<07:17,  1.66s/it] 48%|████▊     | 239/500 [06:18<05:08,  1.18s/it] 48%|████▊     | 241/500 [06:31<12:00,  2.78s/it] 49%|████▊     | 243/500 [06:31<08:25,  1.97s/it] 49%|████▉     | 245/500 [06:38<10:01,  2.36s/it] 49%|████▉     | 247/500 [06:38<07:02,  1.67s/it] 50%|████▉     | 249/500 [06:38<04:58,  1.19s/it]Epoch:  192  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  193  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  194  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  195  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  197  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  198  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  199  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  200  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  202  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  203  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  204  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  205  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  207  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  208  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  209  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  210  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  212  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  213  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  214  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  215  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  217  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  218  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  219  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  220  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  222  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  223  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  224  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  225  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  227  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  228  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  229  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  230  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  232  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  233  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  234  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  235  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  237  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  238  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  239  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  240  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  242  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  243  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  244  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  245  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  247  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  248  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  249  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  250  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
 50%|█████     | 251/500 [06:51<11:32,  2.78s/it] 51%|█████     | 253/500 [06:51<08:06,  1.97s/it] 51%|█████     | 255/500 [06:58<09:33,  2.34s/it] 51%|█████▏    | 257/500 [06:58<06:43,  1.66s/it] 52%|█████▏    | 259/500 [06:58<04:44,  1.18s/it] 52%|█████▏    | 261/500 [07:11<11:00,  2.76s/it] 53%|█████▎    | 263/500 [07:11<07:44,  1.96s/it] 53%|█████▎    | 265/500 [07:17<09:04,  2.32s/it] 53%|█████▎    | 267/500 [07:18<06:22,  1.64s/it] 54%|█████▍    | 269/500 [07:18<04:30,  1.17s/it] 54%|█████▍    | 271/500 [07:30<10:21,  2.71s/it] 55%|█████▍    | 273/500 [07:31<07:16,  1.92s/it] 55%|█████▌    | 275/500 [07:37<08:31,  2.28s/it] 55%|█████▌    | 277/500 [07:37<05:59,  1.61s/it] 56%|█████▌    | 279/500 [07:37<04:13,  1.15s/it] 56%|█████▌    | 281/500 [07:50<09:50,  2.70s/it] 57%|█████▋    | 283/500 [07:50<06:54,  1.91s/it] 57%|█████▋    | 285/500 [07:56<08:14,  2.30s/it] 57%|█████▋    | 287/500 [07:56<05:47,  1.63s/it] 58%|█████▊    | 289/500 [07:56<04:05,  1.16s/it] 58%|█████▊    | 291/500 [08:09<09:25,  2.71s/it] 59%|█████▊    | 293/500 [08:09<06:36,  1.92s/it] 59%|█████▉    | 295/500 [08:16<07:47,  2.28s/it] 59%|█████▉    | 297/500 [08:16<05:28,  1.62s/it] 60%|█████▉    | 299/500 [08:16<03:51,  1.15s/it] 60%|██████    | 301/500 [08:28<08:56,  2.70s/it] 61%|██████    | 303/500 [08:29<06:16,  1.91s/it] 61%|██████    | 305/500 [08:35<07:27,  2.30s/it] 61%|██████▏   | 307/500 [08:35<05:14,  1.63s/it] 62%|██████▏   | 309/500 [08:35<03:41,  1.16s/it]Valid Loss:  0.08637956529855728
Epoch:  252  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  253  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  254  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  255  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  257  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  258  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  259  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  260  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  262  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  263  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  264  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  265  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637956529855728
Epoch:  267  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  268  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  269  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  270  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  272  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  273  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  274  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  275  	Training Loss: 0.0918615385890007
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  277  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  278  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  279  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  280  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  282  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  283  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  284  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  285  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  287  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  288  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  289  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  290  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  292  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  293  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  294  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  295  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  297  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  298  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  299  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  300  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  302  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  303  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  304  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  305  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  307  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  308  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  309  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  310  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0918615460395813
 62%|██████▏   | 311/500 [08:48<08:29,  2.70s/it] 63%|██████▎   | 313/500 [08:48<05:56,  1.91s/it] 63%|██████▎   | 315/500 [08:54<07:00,  2.27s/it] 63%|██████▎   | 317/500 [08:54<04:55,  1.61s/it] 64%|██████▍   | 319/500 [08:54<03:28,  1.15s/it] 64%|██████▍   | 321/500 [09:07<08:00,  2.69s/it] 65%|██████▍   | 323/500 [09:07<05:36,  1.90s/it] 65%|██████▌   | 325/500 [09:13<06:37,  2.27s/it] 65%|██████▌   | 327/500 [09:14<04:38,  1.61s/it] 66%|██████▌   | 329/500 [09:14<03:16,  1.15s/it] 66%|██████▌   | 331/500 [09:26<07:37,  2.71s/it] 67%|██████▋   | 333/500 [09:27<05:20,  1.92s/it] 67%|██████▋   | 335/500 [09:33<06:22,  2.32s/it] 67%|██████▋   | 337/500 [09:33<04:27,  1.64s/it] 68%|██████▊   | 339/500 [09:33<03:08,  1.17s/it] 68%|██████▊   | 339/500 [09:43<03:08,  1.17s/it] 68%|██████▊   | 341/500 [09:46<07:12,  2.72s/it] 69%|██████▊   | 343/500 [09:46<05:02,  1.93s/it] 69%|██████▉   | 345/500 [09:53<05:59,  2.32s/it] 69%|██████▉   | 347/500 [09:53<04:11,  1.64s/it] 70%|██████▉   | 349/500 [09:53<02:56,  1.17s/it] 70%|██████▉   | 349/500 [10:03<02:56,  1.17s/it] 70%|███████   | 351/500 [10:06<06:49,  2.75s/it] 71%|███████   | 353/500 [10:06<04:45,  1.95s/it] 71%|███████   | 355/500 [10:12<05:36,  2.32s/it] 71%|███████▏  | 357/500 [10:12<03:55,  1.64s/it] 72%|███████▏  | 359/500 [10:12<02:45,  1.17s/it] 72%|███████▏  | 359/500 [10:23<02:45,  1.17s/it] 72%|███████▏  | 361/500 [10:25<06:15,  2.70s/it] 73%|███████▎  | 363/500 [10:25<04:21,  1.91s/it] 73%|███████▎  | 365/500 [10:32<05:09,  2.29s/it] 73%|███████▎  | 367/500 [10:32<03:36,  1.63s/it] 74%|███████▍  | 369/500 [10:32<02:31,  1.16s/it]Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  312  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  313  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  314  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  315  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  317  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  318  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  319  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  320  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  322  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  323  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  324  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  325  	Training Loss: 0.0918615385890007
Test Loss:  0.09667609632015228
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  327  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  328  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  329  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  330  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  332  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  333  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  334  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  335  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  337  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  338  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  339  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  340  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  342  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  343  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  344  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  345  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  347  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  348  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  349  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  350  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  352  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  353  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  354  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  355  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  357  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  358  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  359  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  360  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  362  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  363  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  364  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  365  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  367  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  368  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  369  	Training Loss: 0.0918615385890007
Test Loss:  0.09667609632015228
Valid Loss:  0.08637956529855728
Epoch:  370  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
 74%|███████▍  | 369/500 [10:43<02:31,  1.16s/it] 74%|███████▍  | 371/500 [10:44<05:45,  2.68s/it] 75%|███████▍  | 373/500 [10:44<04:00,  1.90s/it] 75%|███████▌  | 375/500 [10:51<04:44,  2.28s/it] 75%|███████▌  | 377/500 [10:51<03:18,  1.62s/it] 76%|███████▌  | 379/500 [10:51<02:19,  1.15s/it] 76%|███████▌  | 379/500 [11:03<02:19,  1.15s/it] 76%|███████▌  | 381/500 [11:04<05:20,  2.69s/it] 77%|███████▋  | 383/500 [11:04<03:42,  1.90s/it] 77%|███████▋  | 385/500 [11:10<04:24,  2.30s/it] 77%|███████▋  | 387/500 [11:10<03:04,  1.63s/it] 78%|███████▊  | 389/500 [11:10<02:08,  1.16s/it] 78%|███████▊  | 391/500 [11:23<04:57,  2.73s/it] 79%|███████▊  | 393/500 [11:23<03:26,  1.93s/it] 79%|███████▉  | 395/500 [11:30<04:05,  2.34s/it] 79%|███████▉  | 397/500 [11:30<02:50,  1.66s/it] 80%|███████▉  | 399/500 [11:30<01:59,  1.18s/it] 80%|████████  | 401/500 [11:43<04:30,  2.73s/it] 81%|████████  | 403/500 [11:43<03:08,  1.94s/it] 81%|████████  | 405/500 [11:49<03:38,  2.30s/it] 81%|████████▏ | 407/500 [11:50<02:32,  1.64s/it] 82%|████████▏ | 409/500 [11:50<01:46,  1.17s/it] 82%|████████▏ | 410/500 [11:56<03:07,  2.09s/it] 82%|████████▏ | 411/500 [12:02<04:19,  2.91s/it] 83%|████████▎ | 413/500 [12:02<02:43,  1.88s/it] 83%|████████▎ | 415/500 [12:09<03:17,  2.32s/it] 83%|████████▎ | 417/500 [12:09<02:11,  1.58s/it] 84%|████████▍ | 419/500 [12:09<01:28,  1.10s/it] 84%|████████▍ | 420/500 [12:15<02:45,  2.06s/it] 84%|████████▍ | 421/500 [12:22<03:53,  2.96s/it] 85%|████████▍ | 423/500 [12:22<02:24,  1.88s/it] 85%|████████▌ | 425/500 [12:28<02:54,  2.33s/it] 85%|████████▌ | 427/500 [12:28<01:55,  1.58s/it] 86%|████████▌ | 429/500 [12:28<01:17,  1.09s/it]Epoch:  371  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  372  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  373  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  374  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  375  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  377  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  378  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  379  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  380  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  382  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  383  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  384  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  385  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  387  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  388  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  389  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  390  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  392  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  393  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  394  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  395  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  397  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  398  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  399  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  400  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  402  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  403  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  404  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  405  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  407  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  408  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  409  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  410  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  412  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  413  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  414  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  415  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  417  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  418  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  419  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  420  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  422  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  423  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  424  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  425  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0918615385890007
Test Loss:  0.09667609632015228
Valid Loss:  0.08637956529855728
Epoch:  427  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  428  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  429  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  430  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
 86%|████████▌ | 431/500 [12:41<03:09,  2.75s/it] 87%|████████▋ | 433/500 [12:41<02:08,  1.92s/it] 87%|████████▋ | 435/500 [12:48<02:30,  2.32s/it] 87%|████████▋ | 437/500 [12:48<01:42,  1.63s/it] 88%|████████▊ | 439/500 [12:48<01:10,  1.16s/it] 88%|████████▊ | 441/500 [13:01<02:41,  2.74s/it] 89%|████████▊ | 443/500 [13:01<01:50,  1.94s/it] 89%|████████▉ | 445/500 [13:07<02:07,  2.31s/it] 89%|████████▉ | 447/500 [13:07<01:26,  1.64s/it] 90%|████████▉ | 449/500 [13:08<00:59,  1.17s/it] 90%|█████████ | 451/500 [13:20<02:14,  2.75s/it] 91%|█████████ | 453/500 [13:21<01:31,  1.95s/it] 91%|█████████ | 455/500 [13:27<01:44,  2.32s/it] 91%|█████████▏| 457/500 [13:27<01:10,  1.65s/it] 92%|█████████▏| 459/500 [13:27<00:48,  1.17s/it] 92%|█████████▏| 461/500 [13:40<01:46,  2.73s/it] 93%|█████████▎| 463/500 [13:40<01:11,  1.93s/it] 93%|█████████▎| 465/500 [13:46<01:20,  2.30s/it] 93%|█████████▎| 467/500 [13:47<00:53,  1.63s/it] 94%|█████████▍| 469/500 [13:47<00:36,  1.16s/it] 94%|█████████▍| 471/500 [13:59<01:18,  2.72s/it] 95%|█████████▍| 473/500 [14:00<00:51,  1.92s/it] 95%|█████████▌| 475/500 [14:06<00:57,  2.30s/it] 95%|█████████▌| 477/500 [14:06<00:37,  1.63s/it] 96%|█████████▌| 479/500 [14:06<00:24,  1.16s/it] 96%|█████████▌| 481/500 [14:19<00:51,  2.69s/it] 97%|█████████▋| 483/500 [14:19<00:32,  1.90s/it] 97%|█████████▋| 485/500 [14:25<00:34,  2.29s/it] 97%|█████████▋| 487/500 [14:25<00:21,  1.63s/it] 98%|█████████▊| 489/500 [14:26<00:12,  1.16s/it]**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  432  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  433  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  434  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  435  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  437  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  438  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  439  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  440  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  442  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  443  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  444  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  445  	Training Loss: 0.0918615385890007
Test Loss:  0.09667609632015228
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  447  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  448  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  449  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  450  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  452  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  453  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  454  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  455  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  457  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  458  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  459  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  460  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  462  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  463  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  464  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  465  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  467  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  468  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  469  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  470  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  472  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  473  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  474  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  475  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  477  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  478  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  479  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  480  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  482  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  483  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  484  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  485  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  487  	Training Loss: 0.0918615460395813
Test Loss:  0.09667609632015228
Valid Loss:  0.08637955784797668
Epoch:  488  	Training Loss: 0.0918615385890007
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  489  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  490  	Training Loss: 0.0918615385890007
Test Loss:  0.09667610377073288
 98%|█████████▊| 491/500 [14:38<00:24,  2.69s/it] 99%|█████████▊| 493/500 [14:38<00:13,  1.90s/it] 99%|█████████▉| 495/500 [14:45<00:11,  2.29s/it] 99%|█████████▉| 497/500 [14:45<00:04,  1.63s/it]100%|█████████▉| 499/500 [14:45<00:01,  1.16s/it]100%|██████████| 500/500 [14:51<00:00,  1.78s/it]
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637956529855728
Epoch:  492  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  493  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  494  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  495  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
Epoch:  497  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  498  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637956529855728
Epoch:  499  	Training Loss: 0.0918615460395813
Test Loss:  0.09667611122131348
Valid Loss:  0.08637955784797668
Epoch:  500  	Training Loss: 0.0918615460395813
Test Loss:  0.09667610377073288
Valid Loss:  0.08637955784797668
**************************************************learning rate decay**************************************************
seed is  4
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:22,  6.18s/it]  1%|          | 3/500 [00:06<13:41,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:30,  1.19s/it]  5%|▍         | 23/500 [00:19<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:37,  2.98it/s]  6%|▌         | 31/500 [00:33<16:49,  2.15s/it]  7%|▋         | 33/500 [00:33<11:52,  1.53s/it]  7%|▋         | 35/500 [00:33<08:25,  1.09s/it]  7%|▋         | 37/500 [00:33<06:01,  1.28it/s]  8%|▊         | 39/500 [00:33<04:20,  1.77it/s]  8%|▊         | 41/500 [00:40<10:22,  1.36s/it]  9%|▊         | 43/500 [00:40<07:23,  1.03it/s]  9%|▉         | 45/500 [00:40<05:17,  1.43it/s]  9%|▉         | 47/500 [00:40<03:49,  1.97it/s] 10%|▉         | 49/500 [00:40<02:48,  2.67it/s] 10%|█         | 51/500 [00:53<16:02,  2.14s/it] 11%|█         | 53/500 [00:53<11:19,  1.52s/it] 11%|█         | 55/500 [00:53<08:02,  1.08s/it] 11%|█▏        | 57/500 [00:53<05:44,  1.29it/s] 12%|█▏        | 59/500 [00:53<04:08,  1.77it/s] 12%|█▏        | 61/500 [01:00<09:52,  1.35s/it] 13%|█▎        | 63/500 [01:00<07:01,  1.04it/s] 13%|█▎        | 65/500 [01:00<05:02,  1.44it/s] 13%|█▎        | 67/500 [01:00<03:38,  1.98it/s] 14%|█▍        | 69/500 [01:00<02:43,  2.64it/s]Epoch:  1  	Training Loss: 0.08427952229976654
Test Loss:  9.320655822753906
Valid Loss:  9.267230987548828
Epoch:  2  	Training Loss: 9.283369064331055
Test Loss:  1218.40869140625
Valid Loss:  1166.223388671875
Epoch:  3  	Training Loss: 1183.50537109375
Test Loss:  3.781515598297119
Valid Loss:  3.847443103790283
Epoch:  4  	Training Loss: 3.87396502494812
Test Loss:  3.7729642391204834
Valid Loss:  3.8403878211975098
Epoch:  5  	Training Loss: 3.8656232357025146
Test Loss:  3.7679250240325928
Valid Loss:  3.8366341590881348
Epoch:  6  	Training Loss: 3.8605315685272217
Test Loss:  3.7632579803466797
Valid Loss:  3.833061933517456
Epoch:  7  	Training Loss: 3.855879783630371
Test Loss:  3.758789300918579
Valid Loss:  3.8300106525421143
Epoch:  8  	Training Loss: 3.851510763168335
Test Loss:  3.754409074783325
Valid Loss:  3.827299118041992
Epoch:  9  	Training Loss: 3.8473801612854004
Test Loss:  3.750335216522217
Valid Loss:  3.824920654296875
Epoch:  10  	Training Loss: 3.8437581062316895
Test Loss:  3.7463746070861816
Valid Loss:  3.822589874267578
Epoch:  11  	Training Loss: 3.840226173400879
Test Loss:  3.7427978515625
Valid Loss:  3.8203248977661133
Epoch:  12  	Training Loss: 3.8368582725524902
Test Loss:  0.2723507881164551
Valid Loss:  0.2883456349372864
Epoch:  13  	Training Loss: 0.2950730323791504
Test Loss:  0.14933443069458008
Valid Loss:  0.20049425959587097
Epoch:  14  	Training Loss: 0.1954909861087799
Test Loss:  0.1153731644153595
Valid Loss:  0.165878027677536
Epoch:  15  	Training Loss: 0.16018138825893402
Test Loss:  0.09164368361234665
Valid Loss:  0.13790544867515564
Epoch:  16  	Training Loss: 0.1326683610677719
Test Loss:  0.07312045991420746
Valid Loss:  0.11514684557914734
Epoch:  17  	Training Loss: 0.11043204367160797
Test Loss:  0.058482103049755096
Valid Loss:  0.09668887406587601
Epoch:  18  	Training Loss: 0.09243235737085342
Test Loss:  0.04692336171865463
Valid Loss:  0.0817219614982605
Epoch:  19  	Training Loss: 0.07785509526729584
Test Loss:  0.03781098127365112
Valid Loss:  0.06958115100860596
Epoch:  20  	Training Loss: 0.06604473292827606
Test Loss:  0.030651429668068886
Valid Loss:  0.05972808972001076
Epoch:  21  	Training Loss: 0.05647251754999161
Test Loss:  0.02504950575530529
Valid Loss:  0.051727890968322754
Epoch:  22  	Training Loss: 0.048711664974689484
Test Loss:  0.010197428055107594
Valid Loss:  0.02252938225865364
Epoch:  23  	Training Loss: 0.021368876099586487
Test Loss:  0.007269219029694796
Valid Loss:  0.01541836280375719
Epoch:  24  	Training Loss: 0.014467764645814896
Test Loss:  0.011691931635141373
Valid Loss:  0.01658765785396099
Epoch:  25  	Training Loss: 0.01610519364476204
Test Loss:  0.02747950702905655
Valid Loss:  0.028907224535942078
Epoch:  26  	Training Loss: 0.02893441542983055
Test Loss:  0.04459068924188614
Valid Loss:  0.04650860279798508
Epoch:  27  	Training Loss: 0.046999432146549225
Test Loss:  0.03889577090740204
Valid Loss:  0.02955949865281582
Epoch:  28  	Training Loss: 0.031303346157073975
Test Loss:  0.01870717480778694
Valid Loss:  0.022192539647221565
Epoch:  29  	Training Loss: 0.02177906408905983
Test Loss:  0.019520748406648636
Valid Loss:  0.015712378546595573
Epoch:  30  	Training Loss: 0.016203459352254868
Test Loss:  0.010207738727331161
Valid Loss:  0.013466395437717438
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.012860898859798908
Test Loss:  0.019426044076681137
Valid Loss:  0.023727450519800186
Epoch:  32  	Training Loss: 0.023120813071727753
Test Loss:  0.006463251076638699
Valid Loss:  0.013498032465577126
Epoch:  33  	Training Loss: 0.012499680742621422
Test Loss:  0.0058432999067008495
Valid Loss:  0.012836948037147522
Epoch:  34  	Training Loss: 0.011874174699187279
Test Loss:  0.005514664575457573
Valid Loss:  0.012419220060110092
Epoch:  35  	Training Loss: 0.011471180245280266
Test Loss:  0.0052576493471860886
Valid Loss:  0.012072288431227207
Epoch:  36  	Training Loss: 0.011135145090520382
Test Loss:  0.005055687390267849
Valid Loss:  0.011779749765992165
Epoch:  37  	Training Loss: 0.010859576985239983
Test Loss:  0.00491249468177557
Valid Loss:  0.011534778401255608
Epoch:  38  	Training Loss: 0.010631220415234566
Test Loss:  0.004801241680979729
Valid Loss:  0.011325869709253311
Epoch:  39  	Training Loss: 0.010438509285449982
Test Loss:  0.004711145535111427
Valid Loss:  0.011145000346004963
Epoch:  40  	Training Loss: 0.010273333638906479
Test Loss:  0.004644552245736122
Valid Loss:  0.010986754670739174
Epoch:  41  	Training Loss: 0.010130012407898903
Test Loss:  0.0045984345488250256
Valid Loss:  0.010842107236385345
Epoch:  42  	Training Loss: 0.009999986737966537
Test Loss:  0.005699974484741688
Valid Loss:  0.011278362944722176
Epoch:  43  	Training Loss: 0.010519180446863174
Test Loss:  0.004345144145190716
Valid Loss:  0.010197566822171211
Epoch:  44  	Training Loss: 0.009401325136423111
Test Loss:  0.004565509967505932
Valid Loss:  0.00971577875316143
Epoch:  45  	Training Loss: 0.00901335384696722
Test Loss:  0.004332532174885273
Valid Loss:  0.010032333433628082
Epoch:  46  	Training Loss: 0.009250527247786522
Test Loss:  0.004466158337891102
Valid Loss:  0.00929204374551773
Epoch:  47  	Training Loss: 0.008641576394438744
Test Loss:  0.004166381899267435
Valid Loss:  0.009471415542066097
Epoch:  48  	Training Loss: 0.008740145713090897
Test Loss:  0.004388008266687393
Valid Loss:  0.009073654189705849
Epoch:  49  	Training Loss: 0.008417360484600067
Test Loss:  0.004147091414779425
Valid Loss:  0.009069478139281273
Epoch:  50  	Training Loss: 0.008382221683859825
Test Loss:  0.004292340017855167
Valid Loss:  0.008938146755099297
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.008279819041490555
Test Loss:  0.004088548012077808
Valid Loss:  0.008296860381960869
Epoch:  52  	Training Loss: 0.007670164108276367
Test Loss:  0.004295017570257187
Valid Loss:  0.008095438592135906
Epoch:  53  	Training Loss: 0.007505535613745451
Test Loss:  0.004237337037920952
Valid Loss:  0.007972748950123787
Epoch:  54  	Training Loss: 0.007384561002254486
Test Loss:  0.004454581532627344
Valid Loss:  0.00785745121538639
Epoch:  55  	Training Loss: 0.007297505624592304
Test Loss:  0.004399138502776623
Valid Loss:  0.007792522199451923
Epoch:  56  	Training Loss: 0.0072349184192717075
Test Loss:  0.0046115294098854065
Valid Loss:  0.007728951051831245
Epoch:  57  	Training Loss: 0.007189138792455196
Test Loss:  0.004543629474937916
Valid Loss:  0.007691986858844757
Epoch:  58  	Training Loss: 0.007155955769121647
Test Loss:  0.004747872240841389
Valid Loss:  0.007657639682292938
Epoch:  59  	Training Loss: 0.007131762336939573
Test Loss:  0.004662110470235348
Valid Loss:  0.007633662782609463
Epoch:  60  	Training Loss: 0.007114247418940067
Test Loss:  0.004860359244048595
Valid Loss:  0.00762270437553525
Epoch:  61  	Training Loss: 0.007104366086423397
Test Loss:  0.00475645624101162
Valid Loss:  0.007626126054674387
Epoch:  62  	Training Loss: 0.007119390647858381
Test Loss:  0.004584670998156071
Valid Loss:  0.007101448718458414
Epoch:  63  	Training Loss: 0.006645213346928358
Test Loss:  0.0044722892343997955
Valid Loss:  0.006712028756737709
Epoch:  64  	Training Loss: 0.0063048177398741245
Test Loss:  0.004373601637780666
Valid Loss:  0.006377553567290306
Epoch:  65  	Training Loss: 0.0060157496482133865
Test Loss:  0.004281597211956978
Valid Loss:  0.006077583413571119
Epoch:  66  	Training Loss: 0.005757456179708242
Test Loss:  0.004195553250610828
Valid Loss:  0.005805668421089649
Epoch:  67  	Training Loss: 0.00552400154992938
Test Loss:  0.004115013405680656
Valid Loss:  0.005558257922530174
Epoch:  68  	Training Loss: 0.0053120823577046394
Test Loss:  0.004038186743855476
Valid Loss:  0.005331480875611305
Epoch:  69  	Training Loss: 0.005118113476783037
Test Loss:  0.003964192233979702
Valid Loss:  0.005122853443026543
Epoch:  70  	Training Loss: 0.004939783364534378
Test Loss:  0.003893110202625394
Valid Loss:   14%|█▍        | 71/500 [01:06<08:43,  1.22s/it] 15%|█▍        | 73/500 [01:07<06:13,  1.14it/s] 15%|█▌        | 75/500 [01:07<04:29,  1.58it/s] 15%|█▌        | 77/500 [01:07<03:16,  2.16it/s] 16%|█▌        | 79/500 [01:07<02:24,  2.91it/s] 16%|█▌        | 81/500 [01:13<08:20,  1.19s/it] 17%|█▋        | 83/500 [01:14<05:57,  1.17it/s] 17%|█▋        | 85/500 [01:14<04:18,  1.61it/s] 17%|█▋        | 87/500 [01:14<03:08,  2.20it/s] 18%|█▊        | 89/500 [01:14<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:20<08:11,  1.20s/it] 19%|█▊        | 93/500 [01:20<05:50,  1.16it/s] 19%|█▉        | 95/500 [01:21<04:12,  1.61it/s] 19%|█▉        | 97/500 [01:21<03:03,  2.20it/s] 20%|█▉        | 99/500 [01:21<02:15,  2.96it/s] 20%|██        | 101/500 [01:27<07:54,  1.19s/it] 21%|██        | 103/500 [01:27<05:38,  1.17it/s] 21%|██        | 105/500 [01:27<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:28<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:28<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:34<07:34,  1.17s/it] 23%|██▎       | 113/500 [01:34<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:34<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:34<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:35<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:41<07:26,  1.18s/it] 25%|██▍       | 123/500 [01:41<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:41<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:41<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:41<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:54<12:53,  2.10s/it] 27%|██▋       | 133/500 [01:54<09:06,  1.49s/it] 27%|██▋       | 135/500 [01:54<06:27,  1.06s/it] 27%|██▋       | 137/500 [01:54<04:36,  1.31it/s]0.0049300603568553925
Epoch:  71  	Training Loss: 0.004774624947458506
Test Loss:  0.0038247823249548674
Valid Loss:  0.004751301370561123
Epoch:  72  	Training Loss: 0.0046212030574679375
Test Loss:  0.003767892252653837
Valid Loss:  0.004736174829304218
Epoch:  73  	Training Loss: 0.004601785913109779
Test Loss:  0.003715753322467208
Valid Loss:  0.00472285458818078
Epoch:  74  	Training Loss: 0.004584468901157379
Test Loss:  0.0036685490049421787
Valid Loss:  0.004711030051112175
Epoch:  75  	Training Loss: 0.004568906035274267
Test Loss:  0.0036259498447179794
Valid Loss:  0.004700344055891037
Epoch:  76  	Training Loss: 0.004554856568574905
Test Loss:  0.0035874522291123867
Valid Loss:  0.0046905046328902245
Epoch:  77  	Training Loss: 0.004541987087577581
Test Loss:  0.0035525928251445293
Valid Loss:  0.0046815089881420135
Epoch:  78  	Training Loss: 0.004530128091573715
Test Loss:  0.0035208144690841436
Valid Loss:  0.004673399031162262
Epoch:  79  	Training Loss: 0.00451907142996788
Test Loss:  0.003491812851279974
Valid Loss:  0.0046658203937113285
Epoch:  80  	Training Loss: 0.004508757498115301
Test Loss:  0.0034654182381927967
Valid Loss:  0.004658618941903114
Epoch:  81  	Training Loss: 0.004499089904129505
Test Loss:  0.0034413556568324566
Valid Loss:  0.00465176347643137
Epoch:  82  	Training Loss: 0.004490047227591276
Test Loss:  0.0034063728526234627
Valid Loss:  0.004633800126612186
Epoch:  83  	Training Loss: 0.004470043815672398
Test Loss:  0.003363892203196883
Valid Loss:  0.004606973379850388
Epoch:  84  	Training Loss: 0.004441526252776384
Test Loss:  0.003332182765007019
Valid Loss:  0.004586491268128157
Epoch:  85  	Training Loss: 0.0044197095558047295
Test Loss:  0.0033190855756402016
Valid Loss:  0.00457534147426486
Epoch:  86  	Training Loss: 0.004408884793519974
Test Loss:  0.0033114678226411343
Valid Loss:  0.004567211493849754
Epoch:  87  	Training Loss: 0.004401395097374916
Test Loss:  0.003304522018879652
Valid Loss:  0.004559997469186783
Epoch:  88  	Training Loss: 0.004394290037453175
Test Loss:  0.003297471208497882
Valid Loss:  0.004553713835775852
Epoch:  89  	Training Loss: 0.004387361463159323
Test Loss:  0.0032905079424381256
Valid Loss:  0.004547604825347662
Epoch:  90  	Training Loss: 0.004380614031106234
Test Loss:  0.0032835323363542557
Valid Loss:  0.00454180222004652
Epoch:  91  	Training Loss: 0.004374024923890829
Test Loss:  0.003276524133980274
Valid Loss:  0.004536033142358065
Epoch:  92  	Training Loss: 0.00436773244291544
Test Loss:  0.0032187961041927338
Valid Loss:  0.004353141877800226
Epoch:  93  	Training Loss: 0.00421229749917984
Test Loss:  0.0031587709672749043
Valid Loss:  0.004184572957456112
Epoch:  94  	Training Loss: 0.00406848918646574
Test Loss:  0.003099344205111265
Valid Loss:  0.00402812659740448
Epoch:  95  	Training Loss: 0.003934676758944988
Test Loss:  0.0030392277985811234
Valid Loss:  0.003882702672854066
Epoch:  96  	Training Loss: 0.0038097654469311237
Test Loss:  0.0029794550500810146
Valid Loss:  0.0037471787072718143
Epoch:  97  	Training Loss: 0.0036933240480720997
Test Loss:  0.002920525148510933
Valid Loss:  0.0036217491142451763
Epoch:  98  	Training Loss: 0.0035859388299286366
Test Loss:  0.0028631966561079025
Valid Loss:  0.0035059205256402493
Epoch:  99  	Training Loss: 0.0034848793875426054
Test Loss:  0.0028078423347324133
Valid Loss:  0.0033964363392442465
Epoch:  100  	Training Loss: 0.0033893194049596786
Test Loss:  0.002754627028480172
Valid Loss:  0.0032936681527644396
Epoch:  101  	Training Loss: 0.003299788571894169
Test Loss:  0.0027035609818995
Valid Loss:  0.0031964012887328863
Epoch:  102  	Training Loss: 0.003214807715266943
Test Loss:  0.0026427253615111113
Valid Loss:  0.003042937023565173
Epoch:  103  	Training Loss: 0.0030769240111112595
Test Loss:  0.00258441804908216
Valid Loss:  0.0029098070226609707
Epoch:  104  	Training Loss: 0.002952275099232793
Test Loss:  0.002530474681407213
Valid Loss:  0.002794895088300109
Epoch:  105  	Training Loss: 0.0028423136100172997
Test Loss:  0.0024788076989352703
Valid Loss:  0.0026955250650644302
Epoch:  106  	Training Loss: 0.002746288664638996
Test Loss:  0.002430470660328865
Valid Loss:  0.002606981201097369
Epoch:  107  	Training Loss: 0.002661345526576042
Test Loss:  0.0023847180418670177
Valid Loss:  0.0025296183302998543
Epoch:  108  	Training Loss: 0.002586814807727933
Test Loss:  0.002341838553547859
Valid Loss:  0.002459571696817875
Epoch:  109  	Training Loss: 0.0025192322209477425
Test Loss:  0.002300611697137356
Valid Loss:  0.0023969216272234917
Epoch:  110  	Training Loss: 0.002458101138472557
Test Loss:  0.0022606109268963337
Valid Loss:  0.002338945399969816
Epoch:  111  	Training Loss: 0.002400639234110713
Test Loss:  0.0022229598835110664
Valid Loss:  0.002284272341057658
Epoch:  112  	Training Loss: 0.002346260938793421
Test Loss:  0.002167942002415657
Valid Loss:  0.002231608610600233
Epoch:  113  	Training Loss: 0.002290210220962763
Test Loss:  0.002136981813237071
Valid Loss:  0.0021897503174841404
Epoch:  114  	Training Loss: 0.0022467602975666523
Test Loss:  0.0021165646612644196
Valid Loss:  0.002152862260118127
Epoch:  115  	Training Loss: 0.002210464561358094
Test Loss:  0.0021016676910221577
Valid Loss:  0.0021200941409915686
Epoch:  116  	Training Loss: 0.0021775467321276665
Test Loss:  0.002089899033308029
Valid Loss:  0.0020898091606795788
Epoch:  117  	Training Loss: 0.0021469478961080313
Test Loss:  0.0020796386525034904
Valid Loss:  0.0020611020736396313
Epoch:  118  	Training Loss: 0.0021180203184485435
Test Loss:  0.0020698632579296827
Valid Loss:  0.002033778466284275
Epoch:  119  	Training Loss: 0.002090523950755596
Test Loss:  0.0020599327981472015
Valid Loss:  0.002007285598665476
Epoch:  120  	Training Loss: 0.0020642231684178114
Test Loss:  0.002049689879640937
Valid Loss:  0.001982111018151045
Epoch:  121  	Training Loss: 0.002039826475083828
Test Loss:  0.0020410665310919285
Valid Loss:  0.001957809319719672
Epoch:  122  	Training Loss: 0.0020163266453891993
Test Loss:  0.0020232461392879486
Valid Loss:  0.0018999751191586256
Epoch:  123  	Training Loss: 0.0019768066704273224
Test Loss:  0.0018956358544528484
Valid Loss:  0.0018924889154732227
Epoch:  124  	Training Loss: 0.0019497907487675548
Test Loss:  0.0019496172899380326
Valid Loss:  0.0018521425081416965
Epoch:  125  	Training Loss: 0.0019331781659275293
Test Loss:  0.001829005079343915
Valid Loss:  0.0018704260000959039
Epoch:  126  	Training Loss: 0.0019269417971372604
Test Loss:  0.001958417473360896
Valid Loss:  0.0018485537730157375
Epoch:  127  	Training Loss: 0.001933275256305933
Test Loss:  0.0018266361439600587
Valid Loss:  0.0019054594449698925
Epoch:  128  	Training Loss: 0.001956088235601783
Test Loss:  0.0020633768290281296
Valid Loss:  0.0019147743005305529
Epoch:  129  	Training Loss: 0.002002348890528083
Test Loss:  0.0019152103923261166
Valid Loss:  0.00203722738660872
Epoch:  130  	Training Loss: 0.002080745529383421
Test Loss:  0.0023285686038434505
Valid Loss:  0.0021130454260855913
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0022061674389988184
Test Loss:  0.001820222707465291
Valid Loss:  0.0017188573256134987
Epoch:  132  	Training Loss: 0.0017935193609446287
Test Loss:  0.0017888210713863373
Valid Loss:  0.0016959435306489468
Epoch:  133  	Training Loss: 0.0017677204450592399
Test Loss:  0.0017773988656699657
Valid Loss:  0.0016897714231163263
Epoch:  134  	Training Loss: 0.0017598139820620418
Test Loss:  0.0017728096572682261
Valid Loss:  0.0016883384669199586
Epoch:  135  	Training Loss: 0.0017573736840859056
Test Loss:  0.0017707161605358124
Valid Loss:  0.0016881373012438416
Epoch:  136  	Training Loss: 0.0017566015012562275
Test Loss:  0.0017696032300591469
Valid Loss:  0.0016881987685337663
Epoch:  137  	Training Loss: 0.0017563439905643463
Test Loss:  0.0017689196392893791
Valid Loss:  0.0016882738564163446
Epoch:  138  	Training Loss: 0.0017562409630045295
Test Loss:  0.0017684283666312695
Valid Loss:  0.0016883229836821556
 28%|██▊       | 139/500 [01:54<03:19,  1.81it/s] 28%|██▊       | 141/500 [02:01<07:57,  1.33s/it] 29%|██▊       | 143/500 [02:01<05:40,  1.05it/s] 29%|██▉       | 145/500 [02:01<04:03,  1.46it/s] 29%|██▉       | 147/500 [02:01<02:56,  2.00it/s] 30%|██▉       | 149/500 [02:01<02:10,  2.70it/s] 30%|███       | 151/500 [02:08<07:05,  1.22s/it] 31%|███       | 153/500 [02:08<05:03,  1.14it/s] 31%|███       | 155/500 [02:08<03:37,  1.59it/s] 31%|███▏      | 157/500 [02:08<02:38,  2.17it/s] 32%|███▏      | 159/500 [02:08<01:56,  2.92it/s] 32%|███▏      | 161/500 [02:14<06:48,  1.21s/it] 33%|███▎      | 163/500 [02:15<04:51,  1.16it/s] 33%|███▎      | 165/500 [02:15<03:30,  1.59it/s] 33%|███▎      | 167/500 [02:15<02:33,  2.17it/s] 34%|███▍      | 169/500 [02:15<01:53,  2.93it/s] 34%|███▍      | 171/500 [02:22<06:36,  1.21s/it] 35%|███▍      | 173/500 [02:22<04:43,  1.16it/s] 35%|███▌      | 175/500 [02:22<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:22<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:22<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:28<06:21,  1.20s/it] 37%|███▋      | 183/500 [02:29<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:29<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:29<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:29<01:44,  2.96it/s] 38%|███▊      | 191/500 [02:35<06:00,  1.17s/it] 39%|███▊      | 193/500 [02:35<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:35<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:36<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:36<01:39,  3.03it/s] 40%|████      | 201/500 [02:42<05:52,  1.18s/it] 41%|████      | 203/500 [02:42<04:10,  1.18it/s] 41%|████      | 205/500 [02:42<03:00,  1.64it/s]Epoch:  139  	Training Loss: 0.001756184035912156
Test Loss:  0.0017680393066257238
Valid Loss:  0.0016883426578715444
Epoch:  140  	Training Loss: 0.001756143057718873
Test Loss:  0.0017677050782367587
Valid Loss:  0.0016883430071175098
Epoch:  141  	Training Loss: 0.0017561062704771757
Test Loss:  0.0017673966940492392
Valid Loss:  0.0016883343923836946
Epoch:  142  	Training Loss: 0.0017560741398483515
Test Loss:  0.0017622440354898572
Valid Loss:  0.0016873239073902369
Epoch:  143  	Training Loss: 0.0017547106835991144
Test Loss:  0.0017577364342287183
Valid Loss:  0.0016863197088241577
Epoch:  144  	Training Loss: 0.0017534323269501328
Test Loss:  0.0017536493251100183
Valid Loss:  0.0016853066626936197
Epoch:  145  	Training Loss: 0.0017522047273814678
Test Loss:  0.0017498612869530916
Valid Loss:  0.0016843084013089538
Epoch:  146  	Training Loss: 0.0017510096076875925
Test Loss:  0.0017462868709117174
Valid Loss:  0.0016833185218274593
Epoch:  147  	Training Loss: 0.0017498447559773922
Test Loss:  0.0017428940627723932
Valid Loss:  0.0016823384212329984
Epoch:  148  	Training Loss: 0.001748705399222672
Test Loss:  0.001739652012474835
Valid Loss:  0.0016813842812553048
Epoch:  149  	Training Loss: 0.0017475918866693974
Test Loss:  0.0017365459352731705
Valid Loss:  0.0016804429469630122
Epoch:  150  	Training Loss: 0.0017465015407651663
Test Loss:  0.0017335605807602406
Valid Loss:  0.0016795180272310972
Epoch:  151  	Training Loss: 0.0017454391345381737
Test Loss:  0.001730700838379562
Valid Loss:  0.001678629545494914
Epoch:  152  	Training Loss: 0.001744423876516521
Test Loss:  0.0017279607709497213
Valid Loss:  0.0016684774309396744
Epoch:  153  	Training Loss: 0.0017311314586549997
Test Loss:  0.0017260528402402997
Valid Loss:  0.00165947200730443
Epoch:  154  	Training Loss: 0.0017187490593641996
Test Loss:  0.001723926281556487
Valid Loss:  0.0016511095454916358
Epoch:  155  	Training Loss: 0.0017073253402486444
Test Loss:  0.0017213895916938782
Valid Loss:  0.001643081195652485
Epoch:  156  	Training Loss: 0.0016964911483228207
Test Loss:  0.0017185762990266085
Valid Loss:  0.0016352193197235465
Epoch:  157  	Training Loss: 0.0016858848975971341
Test Loss:  0.0017155189998447895
Valid Loss:  0.0016274912049993873
Epoch:  158  	Training Loss: 0.0016754693351686
Test Loss:  0.0017122405115514994
Valid Loss:  0.001619877526536584
Epoch:  159  	Training Loss: 0.0016652994090691209
Test Loss:  0.0017086946172639728
Valid Loss:  0.0016124023823067546
Epoch:  160  	Training Loss: 0.0016556531190872192
Test Loss:  0.0017049647867679596
Valid Loss:  0.001605270546860993
Epoch:  161  	Training Loss: 0.0016465287189930677
Test Loss:  0.001701033441349864
Valid Loss:  0.0015982689801603556
Epoch:  162  	Training Loss: 0.0016376556595787406
Test Loss:  0.0016928946133702993
Valid Loss:  0.0015929427463561296
Epoch:  163  	Training Loss: 0.0016314759850502014
Test Loss:  0.001686045783571899
Valid Loss:  0.0015876886900514364
Epoch:  164  	Training Loss: 0.001625608652830124
Test Loss:  0.0016799367731437087
Valid Loss:  0.0015827890019863844
Epoch:  165  	Training Loss: 0.0016203157138079405
Test Loss:  0.0016743466258049011
Valid Loss:  0.0015780520625412464
Epoch:  166  	Training Loss: 0.0016152270836755633
Test Loss:  0.0016691936179995537
Valid Loss:  0.0015734343323856592
Epoch:  167  	Training Loss: 0.0016102686058729887
Test Loss:  0.001664426876232028
Valid Loss:  0.001568918814882636
Epoch:  168  	Training Loss: 0.0016054250299930573
Test Loss:  0.0016599983209744096
Valid Loss:  0.001564507489092648
Epoch:  169  	Training Loss: 0.001600797288119793
Test Loss:  0.0016558811767026782
Valid Loss:  0.0015604273648932576
Epoch:  170  	Training Loss: 0.0015966588398441672
Test Loss:  0.0016520365606993437
Valid Loss:  0.0015564225614070892
Epoch:  171  	Training Loss: 0.001592602115124464
Test Loss:  0.0016484566731378436
Valid Loss:  0.0015524964546784759
Epoch:  172  	Training Loss: 0.0015886297915130854
Test Loss:  0.0016462961211800575
Valid Loss:  0.0015477628912776709
Epoch:  173  	Training Loss: 0.0015842518769204617
Test Loss:  0.001642970833927393
Valid Loss:  0.0015434339875355363
Epoch:  174  	Training Loss: 0.001580001786351204
Test Loss:  0.0016397961881011724
Valid Loss:  0.0015391731867566705
Epoch:  175  	Training Loss: 0.0015758196823298931
Test Loss:  0.0016367875505238771
Valid Loss:  0.001534975366666913
Epoch:  176  	Training Loss: 0.0015718108043074608
Test Loss:  0.0016339366557076573
Valid Loss:  0.0015310723101720214
Epoch:  177  	Training Loss: 0.0015682140365242958
Test Loss:  0.0016312170773744583
Valid Loss:  0.0015272179152816534
Epoch:  178  	Training Loss: 0.001564664184115827
Test Loss:  0.0016286445315927267
Valid Loss:  0.0015234146267175674
Epoch:  179  	Training Loss: 0.0015611655544489622
Test Loss:  0.0016261836281046271
Valid Loss:  0.0015196562744677067
Epoch:  180  	Training Loss: 0.0015577166341245174
Test Loss:  0.0016238349489867687
Valid Loss:  0.0015159411123022437
Epoch:  181  	Training Loss: 0.0015543133486062288
Test Loss:  0.0016216016374528408
Valid Loss:  0.0015122662298381329
Epoch:  182  	Training Loss: 0.0015509515069425106
Test Loss:  0.0016187865985557437
Valid Loss:  0.0015086338389664888
Epoch:  183  	Training Loss: 0.0015475647523999214
Test Loss:  0.0016166529385372996
Valid Loss:  0.0015050627989694476
Epoch:  184  	Training Loss: 0.0015443003503605723
Test Loss:  0.001614989247173071
Valid Loss:  0.0015015648677945137
Epoch:  185  	Training Loss: 0.0015411226777359843
Test Loss:  0.0016136722406372428
Valid Loss:  0.0014980931300669909
Epoch:  186  	Training Loss: 0.0015379972755908966
Test Loss:  0.0016126036643981934
Valid Loss:  0.0014946507290005684
Epoch:  187  	Training Loss: 0.0015350740868598223
Test Loss:  0.0016117196064442396
Valid Loss:  0.0014914682833477855
Epoch:  188  	Training Loss: 0.001532440772280097
Test Loss:  0.0016109638381749392
Valid Loss:  0.0014883101684972644
Epoch:  189  	Training Loss: 0.0015298391226679087
Test Loss:  0.0016103084199130535
Valid Loss:  0.0014851819723844528
Epoch:  190  	Training Loss: 0.0015272630844265223
Test Loss:  0.0016097197076305747
Valid Loss:  0.0014820855576545
Epoch:  191  	Training Loss: 0.0015247170813381672
Test Loss:  0.001609182683750987
Valid Loss:  0.0014790126588195562
Epoch:  192  	Training Loss: 0.001522197388112545
Test Loss:  0.0016089477576315403
Valid Loss:  0.0014781368663534522
Epoch:  193  	Training Loss: 0.001521365949884057
Test Loss:  0.0016081716166809201
Valid Loss:  0.0014774035662412643
Epoch:  194  	Training Loss: 0.001520599122159183
Test Loss:  0.0016070804558694363
Valid Loss:  0.001476741279475391
Epoch:  195  	Training Loss: 0.0015198662877082825
Test Loss:  0.001605823403224349
Valid Loss:  0.0014761177590116858
Epoch:  196  	Training Loss: 0.0015191494021564722
Test Loss:  0.0016044860240072012
Valid Loss:  0.001475512981414795
Epoch:  197  	Training Loss: 0.0015184413641691208
Test Loss:  0.0016031274572014809
Valid Loss:  0.0014749295078217983
Epoch:  198  	Training Loss: 0.0015177433378994465
Test Loss:  0.0016017742455005646
Valid Loss:  0.0014743504580110312
Epoch:  199  	Training Loss: 0.0015170648694038391
Test Loss:  0.0016004506032913923
Valid Loss:  0.0014737944584339857
Epoch:  200  	Training Loss: 0.0015164078213274479
Test Loss:  0.0015991699183359742
Valid Loss:  0.00147324800491333
Epoch:  201  	Training Loss: 0.0015157542657107115
Test Loss:  0.001597921596840024
Valid Loss:  0.0014727003872394562
Epoch:  202  	Training Loss: 0.0015151076950132847
Test Loss:  0.0015978955198079348
Valid Loss:  0.0014726868830621243
Epoch:  203  	Training Loss: 0.0015151051338762045
Test Loss:  0.001597865018993616
Valid Loss:  0.0014726808294653893
Epoch:  204  	Training Loss: 0.0015151004772633314
Test Loss:  0.001597832073457539
Valid Loss:  0.0014726694207638502
Epoch:  205  	Training Loss: 0.0015150951221585274
Test Loss:  0.0015977899311110377
Valid Loss:  0.0014726670924574137
Epoch:  206  	Training Loss: 0.0015150925610214472
Test Loss:  0.001597747323103249
Valid Loss:  0.0014726578956469893
Epoch:  207  	Training Loss: 0.0015150909312069416
Test Loss:   41%|████▏     | 207/500 [02:42<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:43<01:37,  3.00it/s] 42%|████▏     | 211/500 [02:49<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:49<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:49<02:53,  1.65it/s] 43%|████▎     | 217/500 [02:49<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:49<01:32,  3.03it/s] 44%|████▍     | 221/500 [02:56<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:56<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:56<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:56<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:56<01:30,  3.00it/s] 46%|████▌     | 231/500 [03:03<05:24,  1.21s/it] 47%|████▋     | 233/500 [03:03<03:50,  1.16it/s] 47%|████▋     | 235/500 [03:03<02:45,  1.60it/s] 47%|████▋     | 237/500 [03:03<02:00,  2.19it/s] 48%|████▊     | 239/500 [03:03<01:28,  2.94it/s] 48%|████▊     | 241/500 [03:10<05:09,  1.20s/it] 49%|████▊     | 243/500 [03:10<03:40,  1.16it/s] 49%|████▉     | 245/500 [03:10<02:38,  1.61it/s] 49%|████▉     | 247/500 [03:10<01:54,  2.20it/s] 50%|████▉     | 249/500 [03:10<01:24,  2.97it/s] 50%|█████     | 251/500 [03:16<04:54,  1.18s/it] 51%|█████     | 253/500 [03:17<03:30,  1.18it/s] 51%|█████     | 255/500 [03:17<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:17<01:49,  2.23it/s] 52%|█████▏    | 259/500 [03:17<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:23<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:23<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:24<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:24<01:45,  2.22it/s] 54%|█████▍    | 269/500 [03:24<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:30<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:30<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:30<02:17,  1.63it/s]0.0015977028524503112
Valid Loss:  0.0014726553345099092
Epoch:  208  	Training Loss: 0.0015150867402553558
Test Loss:  0.001597653841599822
Valid Loss:  0.0014726470690220594
Epoch:  209  	Training Loss: 0.0015150815015658736
Test Loss:  0.0015976042486727238
Valid Loss:  0.0014726432273164392
Epoch:  210  	Training Loss: 0.0015150802209973335
Test Loss:  0.001597549649886787
Valid Loss:  0.0014726382214576006
Epoch:  211  	Training Loss: 0.0015150777762755752
Test Loss:  0.0015974938869476318
Valid Loss:  0.001472636591643095
Epoch:  212  	Training Loss: 0.0015150753315538168
Test Loss:  0.001597788417711854
Valid Loss:  0.0014664882328361273
Epoch:  213  	Training Loss: 0.0015080523444339633
Test Loss:  0.0015951282111927867
Valid Loss:  0.0014619205612689257
Epoch:  214  	Training Loss: 0.001501910388469696
Test Loss:  0.0015927859349176288
Valid Loss:  0.0014576560351997614
Epoch:  215  	Training Loss: 0.001496398588642478
Test Loss:  0.0015903213061392307
Valid Loss:  0.001453812699764967
Epoch:  216  	Training Loss: 0.001491778763011098
Test Loss:  0.001587988343089819
Valid Loss:  0.0014504045248031616
Epoch:  217  	Training Loss: 0.0014880832750350237
Test Loss:  0.0015859018312767148
Valid Loss:  0.0014474934432655573
Epoch:  218  	Training Loss: 0.0014849785948172212
Test Loss:  0.001584057928994298
Valid Loss:  0.0014444725820794702
Epoch:  219  	Training Loss: 0.0014819878851994872
Test Loss:  0.00158205337356776
Valid Loss:  0.001441677799448371
Epoch:  220  	Training Loss: 0.001479129190556705
Test Loss:  0.001579912262968719
Valid Loss:  0.00143927161116153
Epoch:  221  	Training Loss: 0.0014764871448278427
Test Loss:  0.0015774203930050135
Valid Loss:  0.0014370502904057503
Epoch:  222  	Training Loss: 0.0014739923644810915
Test Loss:  0.0015751905739307404
Valid Loss:  0.0014363201335072517
Epoch:  223  	Training Loss: 0.001473587704822421
Test Loss:  0.001572833163663745
Valid Loss:  0.0014357245527207851
Epoch:  224  	Training Loss: 0.0014732308918610215
Test Loss:  0.0015705162659287453
Valid Loss:  0.0014351895079016685
Epoch:  225  	Training Loss: 0.0014728971291333437
Test Loss:  0.0015683136880397797
Valid Loss:  0.0014346905518323183
Epoch:  226  	Training Loss: 0.0014725851360708475
Test Loss:  0.001566227525472641
Valid Loss:  0.0014342222129926085
Epoch:  227  	Training Loss: 0.0014722966589033604
Test Loss:  0.0015642677899450064
Valid Loss:  0.0014337715692818165
Epoch:  228  	Training Loss: 0.0014720256440341473
Test Loss:  0.0015624333173036575
Valid Loss:  0.0014333371073007584
Epoch:  229  	Training Loss: 0.0014717674348503351
Test Loss:  0.0015607214299961925
Valid Loss:  0.0014329217374324799
Epoch:  230  	Training Loss: 0.0014715248253196478
Test Loss:  0.0015591169940307736
Valid Loss:  0.0014325238298624754
Epoch:  231  	Training Loss: 0.0014713052660226822
Test Loss:  0.0015576109290122986
Valid Loss:  0.0014321345370262861
Epoch:  232  	Training Loss: 0.0014710983959957957
Test Loss:  0.0015570627292618155
Valid Loss:  0.0014320685295388103
Epoch:  233  	Training Loss: 0.0014710032846778631
Test Loss:  0.0015565373469144106
Valid Loss:  0.00143199204467237
Epoch:  234  	Training Loss: 0.0014709096867591143
Test Loss:  0.0015560444444417953
Valid Loss:  0.0014319228939712048
Epoch:  235  	Training Loss: 0.0014708199305459857
Test Loss:  0.001555571099743247
Valid Loss:  0.0014318556059151888
Epoch:  236  	Training Loss: 0.0014707352966070175
Test Loss:  0.001555125811137259
Valid Loss:  0.0014317857567220926
Epoch:  237  	Training Loss: 0.0014706520596519113
Test Loss:  0.0015546991489827633
Valid Loss:  0.0014317152090370655
Epoch:  238  	Training Loss: 0.001470571500249207
Test Loss:  0.001554298447445035
Valid Loss:  0.001431649667210877
Epoch:  239  	Training Loss: 0.0014704978093504906
Test Loss:  0.0015539125306531787
Valid Loss:  0.001431586337275803
Epoch:  240  	Training Loss: 0.0014704236527904868
Test Loss:  0.0015535473357886076
Valid Loss:  0.0014315156731754541
Epoch:  241  	Training Loss: 0.0014703506603837013
Test Loss:  0.0015532101970165968
Valid Loss:  0.0014314530417323112
Epoch:  242  	Training Loss: 0.0014702852349728346
Test Loss:  0.0015515018021687865
Valid Loss:  0.0014285172801464796
Epoch:  243  	Training Loss: 0.001467716647312045
Test Loss:  0.0015500638401135802
Valid Loss:  0.0014256344875320792
Epoch:  244  	Training Loss: 0.0014652051031589508
Test Loss:  0.0015487985219806433
Valid Loss:  0.0014227633364498615
Epoch:  245  	Training Loss: 0.0014627220807597041
Test Loss:  0.0015476529952138662
Valid Loss:  0.0014199179131537676
Epoch:  246  	Training Loss: 0.0014602664159610868
Test Loss:  0.0015465773176401854
Valid Loss:  0.0014170960057526827
Epoch:  247  	Training Loss: 0.0014578360132873058
Test Loss:  0.001545557752251625
Valid Loss:  0.0014142991276457906
Epoch:  248  	Training Loss: 0.001455591875128448
Test Loss:  0.0015445798635482788
Valid Loss:  0.0014117525424808264
Epoch:  249  	Training Loss: 0.0014535696245729923
Test Loss:  0.0015436282847076654
Valid Loss:  0.0014092278433963656
Epoch:  250  	Training Loss: 0.0014515805523842573
Test Loss:  0.001542721875011921
Valid Loss:  0.0014067491283640265
Epoch:  251  	Training Loss: 0.0014496396761387587
Test Loss:  0.0015418394468724728
Valid Loss:  0.0014042911352589726
Epoch:  252  	Training Loss: 0.0014477152144536376
Test Loss:  0.0015414287336170673
Valid Loss:  0.0014036643551662564
Epoch:  253  	Training Loss: 0.0014470919268205762
Test Loss:  0.001540884841233492
Valid Loss:  0.0014030934544280171
Epoch:  254  	Training Loss: 0.0014464831911027431
Test Loss:  0.0015402743592858315
Valid Loss:  0.0014025489799678326
Epoch:  255  	Training Loss: 0.0014458827208727598
Test Loss:  0.0015396594535559416
Valid Loss:  0.0014020288363099098
Epoch:  256  	Training Loss: 0.001445314148440957
Test Loss:  0.0015390341868624091
Valid Loss:  0.001401515444740653
Epoch:  257  	Training Loss: 0.00144474976696074
Test Loss:  0.0015384138096123934
Valid Loss:  0.0014010086888447404
Epoch:  258  	Training Loss: 0.0014441868988797069
Test Loss:  0.0015377961099147797
Valid Loss:  0.0014004998374730349
Epoch:  259  	Training Loss: 0.0014436242636293173
Test Loss:  0.001537189120426774
Valid Loss:  0.0013999948278069496
Epoch:  260  	Training Loss: 0.0014430658193305135
Test Loss:  0.0015365886501967907
Valid Loss:  0.0013994865585118532
Epoch:  261  	Training Loss: 0.001442507142201066
Test Loss:  0.001536061055958271
Valid Loss:  0.0013989845756441355
Epoch:  262  	Training Loss: 0.0014419499784708023
Test Loss:  0.0015354696661233902
Valid Loss:  0.0013985484838485718
Epoch:  263  	Training Loss: 0.0014414347242563963
Test Loss:  0.0015350321773439646
Valid Loss:  0.0013980899238958955
Epoch:  264  	Training Loss: 0.0014409422874450684
Test Loss:  0.001534637063741684
Valid Loss:  0.0013976285699754953
Epoch:  265  	Training Loss: 0.0014404496178030968
Test Loss:  0.0015342572005465627
Valid Loss:  0.0013971822336316109
Epoch:  266  	Training Loss: 0.0014399813953787088
Test Loss:  0.0015338826924562454
Valid Loss:  0.0013967349659651518
Epoch:  267  	Training Loss: 0.0014395116595551372
Test Loss:  0.001533519010990858
Valid Loss:  0.0013962851371616125
Epoch:  268  	Training Loss: 0.0014390498399734497
Test Loss:  0.0015331642935052514
Valid Loss:  0.0013958490453660488
Epoch:  269  	Training Loss: 0.001438602921552956
Test Loss:  0.0015328157460317016
Valid Loss:  0.001395407598465681
Epoch:  270  	Training Loss: 0.0014381594955921173
Test Loss:  0.0015324761625379324
Valid Loss:  0.0013949875719845295
Epoch:  271  	Training Loss: 0.001437739236280322
Test Loss:  0.0015321520622819662
Valid Loss:  0.0013945619575679302
Epoch:  272  	Training Loss: 0.0014373157173395157
Test Loss:  0.0015313784824684262
Valid Loss:  0.001392117701470852
Epoch:  273  	Training Loss: 0.0014353921869769692
Test Loss:  0.0015306489076465368
Valid Loss:  0.0013896969612687826
Epoch:  274  	Training Loss: 0.001433489378541708
Test Loss:  0.0015299408696591854
Valid Loss:  0.0013872988056391478
Epoch:  275  	Training Loss: 0.0014316020533442497
Test Loss:  0.0015292608877643943
Valid Loss:  0.001384918694384396
 55%|█████▌    | 277/500 [03:31<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:31<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:37<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:37<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:37<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:37<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:37<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:44<04:13,  1.21s/it] 59%|█████▊    | 293/500 [03:44<02:59,  1.15it/s] 59%|█████▉    | 295/500 [03:44<02:08,  1.59it/s] 59%|█████▉    | 297/500 [03:44<01:33,  2.18it/s] 60%|█████▉    | 299/500 [03:45<01:08,  2.93it/s] 60%|██████    | 301/500 [03:51<03:55,  1.18s/it] 61%|██████    | 303/500 [03:51<02:47,  1.18it/s] 61%|██████    | 305/500 [03:51<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:51<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:51<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:58<03:48,  1.21s/it] 63%|██████▎   | 313/500 [03:58<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:58<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:58<01:24,  2.16it/s] 64%|██████▍   | 319/500 [03:58<01:03,  2.86it/s] 64%|██████▍   | 321/500 [04:05<03:37,  1.22s/it] 65%|██████▍   | 323/500 [04:05<02:35,  1.14it/s] 65%|██████▌   | 325/500 [04:05<01:52,  1.56it/s] 65%|██████▌   | 327/500 [04:05<01:21,  2.13it/s] 66%|██████▌   | 329/500 [04:06<00:59,  2.88it/s] 66%|██████▌   | 331/500 [04:12<03:24,  1.21s/it] 67%|██████▋   | 333/500 [04:12<02:24,  1.15it/s] 67%|██████▋   | 335/500 [04:12<01:43,  1.60it/s] 67%|██████▋   | 337/500 [04:12<01:14,  2.18it/s] 68%|██████▊   | 339/500 [04:13<00:54,  2.93it/s] 68%|██████▊   | 341/500 [04:19<03:11,  1.20s/it] 69%|██████▊   | 343/500 [04:19<02:15,  1.16it/s]Epoch:  276  	Training Loss: 0.0014297409215942025
Test Loss:  0.0015286020934581757
Valid Loss:  0.0013825701316818595
Epoch:  277  	Training Loss: 0.0014278935268521309
Test Loss:  0.001527970191091299
Valid Loss:  0.0013802585890516639
Epoch:  278  	Training Loss: 0.0014261039905250072
Test Loss:  0.0015273592434823513
Valid Loss:  0.0013779725413769484
Epoch:  279  	Training Loss: 0.0014243306359276175
Test Loss:  0.001526765525341034
Valid Loss:  0.0013757046544924378
Epoch:  280  	Training Loss: 0.0014225731138139963
Test Loss:  0.001526180887594819
Valid Loss:  0.0013734614476561546
Epoch:  281  	Training Loss: 0.0014208328211680055
Test Loss:  0.001525613944977522
Valid Loss:  0.0013712362851947546
Epoch:  282  	Training Loss: 0.0014191076625138521
Test Loss:  0.0015251783188432455
Valid Loss:  0.0013690985506400466
Epoch:  283  	Training Loss: 0.0014174344250932336
Test Loss:  0.0015247728442773223
Valid Loss:  0.001367532997392118
Epoch:  284  	Training Loss: 0.0014157749246805906
Test Loss:  0.001524411141872406
Valid Loss:  0.001366063137538731
Epoch:  285  	Training Loss: 0.00141419330611825
Test Loss:  0.001524078892543912
Valid Loss:  0.0013647375162690878
Epoch:  286  	Training Loss: 0.0014128769980743527
Test Loss:  0.0015237703919410706
Valid Loss:  0.0013634602073580027
Epoch:  287  	Training Loss: 0.0014116293750703335
Test Loss:  0.0015234765596687794
Valid Loss:  0.0013622093247249722
Epoch:  288  	Training Loss: 0.00141041143797338
Test Loss:  0.001523186219856143
Valid Loss:  0.0013609710149466991
Epoch:  289  	Training Loss: 0.0014092051424086094
Test Loss:  0.001522896229289472
Valid Loss:  0.001359740737825632
Epoch:  290  	Training Loss: 0.0014080088585615158
Test Loss:  0.001522611826658249
Valid Loss:  0.0013585167471319437
Epoch:  291  	Training Loss: 0.0014068190939724445
Test Loss:  0.0015223247464746237
Valid Loss:  0.0013572985772043467
Epoch:  292  	Training Loss: 0.001405645627528429
Test Loss:  0.0015221619978547096
Valid Loss:  0.001356187043711543
Epoch:  293  	Training Loss: 0.00140459556132555
Test Loss:  0.001521775033324957
Valid Loss:  0.0013551549054682255
Epoch:  294  	Training Loss: 0.0014036358334124088
Test Loss:  0.001521313562989235
Valid Loss:  0.0013541763182729483
Epoch:  295  	Training Loss: 0.0014027506113052368
Test Loss:  0.0015207914402708411
Valid Loss:  0.0013532175216823816
Epoch:  296  	Training Loss: 0.0014018925139680505
Test Loss:  0.001520241261459887
Valid Loss:  0.0013522752560675144
Epoch:  297  	Training Loss: 0.0014010570012032986
Test Loss:  0.001519706565886736
Valid Loss:  0.001351347891613841
Epoch:  298  	Training Loss: 0.0014002383686602116
Test Loss:  0.0015194122679531574
Valid Loss:  0.001350158010609448
Epoch:  299  	Training Loss: 0.0013993235770612955
Test Loss:  0.00151880644261837
Valid Loss:  0.001349059515632689
Epoch:  300  	Training Loss: 0.001398421241901815
Test Loss:  0.001518120290711522
Valid Loss:  0.0013479936169460416
Epoch:  301  	Training Loss: 0.001397544052451849
Test Loss:  0.0015173808205872774
Valid Loss:  0.0013469754485413432
Epoch:  302  	Training Loss: 0.0013967074919492006
Test Loss:  0.0015171561390161514
Valid Loss:  0.0013461988419294357
Epoch:  303  	Training Loss: 0.00139579176902771
Test Loss:  0.0015170059632509947
Valid Loss:  0.0013454175787046552
Epoch:  304  	Training Loss: 0.001394893741235137
Test Loss:  0.0015168922254815698
Valid Loss:  0.0013446379452943802
Epoch:  305  	Training Loss: 0.0013940066564828157
Test Loss:  0.0015168088721111417
Valid Loss:  0.0013438493479043245
Epoch:  306  	Training Loss: 0.001393130631186068
Test Loss:  0.0015167448436841369
Valid Loss:  0.0013430677354335785
Epoch:  307  	Training Loss: 0.001392262289300561
Test Loss:  0.0015167000237852335
Valid Loss:  0.0013422856573015451
Epoch:  308  	Training Loss: 0.0013914016308262944
Test Loss:  0.001516666729003191
Valid Loss:  0.0013415092835202813
Epoch:  309  	Training Loss: 0.0013905481901019812
Test Loss:  0.001516637858003378
Valid Loss:  0.001340731279924512
Epoch:  310  	Training Loss: 0.001389702083542943
Test Loss:  0.00151661632116884
Valid Loss:  0.0013399614254012704
Epoch:  311  	Training Loss: 0.0013888613320887089
Test Loss:  0.0015165989752858877
Valid Loss:  0.0013391926186159253
Epoch:  312  	Training Loss: 0.0013880275655537844
Test Loss:  0.0015163314528763294
Valid Loss:  0.0013386642094701529
Epoch:  313  	Training Loss: 0.0013874797150492668
Test Loss:  0.0015160813927650452
Valid Loss:  0.0013381264870986342
Epoch:  314  	Training Loss: 0.001386937452480197
Test Loss:  0.0015158425085246563
Valid Loss:  0.00133759924210608
Epoch:  315  	Training Loss: 0.0013864123029634356
Test Loss:  0.0015156103763729334
Valid Loss:  0.0013370958622545004
Epoch:  316  	Training Loss: 0.0013858906459063292
Test Loss:  0.0015153709100559354
Valid Loss:  0.0013366094790399075
Epoch:  317  	Training Loss: 0.001385388197377324
Test Loss:  0.0015151383122429252
Valid Loss:  0.0013361681485548615
Epoch:  318  	Training Loss: 0.001384903211146593
Test Loss:  0.0015148983802646399
Valid Loss:  0.0013357424177229404
Epoch:  319  	Training Loss: 0.0013844214845448732
Test Loss:  0.0015146553050726652
Valid Loss:  0.0013353470712900162
Epoch:  320  	Training Loss: 0.0013839437160640955
Test Loss:  0.0015144003555178642
Valid Loss:  0.0013349598739296198
Epoch:  321  	Training Loss: 0.0013835011050105095
Test Loss:  0.001514136791229248
Valid Loss:  0.0013345933984965086
Epoch:  322  	Training Loss: 0.0013830730458721519
Test Loss:  0.0015145286452025175
Valid Loss:  0.0013328440254554152
Epoch:  323  	Training Loss: 0.0013816356658935547
Test Loss:  0.0015138748567551374
Valid Loss:  0.001331434235908091
Epoch:  324  	Training Loss: 0.0013802428729832172
Test Loss:  0.0015136545989662409
Valid Loss:  0.0013297444675117731
Epoch:  325  	Training Loss: 0.0013786735944449902
Test Loss:  0.0015130327083170414
Valid Loss:  0.0013281734427437186
Epoch:  326  	Training Loss: 0.001377249602228403
Test Loss:  0.001512789400294423
Valid Loss:  0.0013266678433865309
Epoch:  327  	Training Loss: 0.0013759665889665484
Test Loss:  0.0015117626171559095
Valid Loss:  0.0013253353536128998
Epoch:  328  	Training Loss: 0.001374708954244852
Test Loss:  0.0015115973073989153
Valid Loss:  0.001323856064118445
Epoch:  329  	Training Loss: 0.0013734579551964998
Test Loss:  0.0015105600468814373
Valid Loss:  0.001322573283687234
Epoch:  330  	Training Loss: 0.0013721835566684604
Test Loss:  0.001510636880993843
Valid Loss:  0.0013209102908149362
Epoch:  331  	Training Loss: 0.0013707282487303019
Test Loss:  0.0015094848349690437
Valid Loss:  0.0013195163337513804
Epoch:  332  	Training Loss: 0.0013693140354007483
Test Loss:  0.001508631743490696
Valid Loss:  0.0013185616116970778
Epoch:  333  	Training Loss: 0.0013684214791283011
Test Loss:  0.0015075711999088526
Valid Loss:  0.001317666727118194
Epoch:  334  	Training Loss: 0.0013675373047590256
Test Loss:  0.0015065980842337012
Valid Loss:  0.0013167659053578973
Epoch:  335  	Training Loss: 0.001366661163046956
Test Loss:  0.0015056750271469355
Valid Loss:  0.001315872184932232
Epoch:  336  	Training Loss: 0.0013657931704074144
Test Loss:  0.001504798885434866
Valid Loss:  0.0013149856822565198
Epoch:  337  	Training Loss: 0.0013649300672113895
Test Loss:  0.0015039665158838034
Valid Loss:  0.0013141047675162554
Epoch:  338  	Training Loss: 0.0013640722027048469
Test Loss:  0.0015031746588647366
Valid Loss:  0.0013132230378687382
Epoch:  339  	Training Loss: 0.001363222487270832
Test Loss:  0.0015024207532405853
Valid Loss:  0.0013123485259711742
Epoch:  340  	Training Loss: 0.0013623782433569431
Test Loss:  0.0015017101541161537
Valid Loss:  0.0013114878674969077
Epoch:  341  	Training Loss: 0.001361556351184845
Test Loss:  0.0015010295901447535
Valid Loss:  0.0013106351252645254
Epoch:  342  	Training Loss: 0.0013607385335490108
Test Loss:  0.0014995315577834845
Valid Loss:  0.001309622428379953
Epoch:  343  	Training Loss: 0.0013596455100923777
Test Loss:  0.0014988402836024761
Valid Loss:  0.0013085525715723634
Epoch:  344  	Training Loss: 0.0013585860142484307
Test Loss:  0.0014984405133873224
 69%|██████▉   | 345/500 [04:19<01:36,  1.60it/s] 69%|██████▉   | 347/500 [04:19<01:10,  2.16it/s] 70%|██████▉   | 349/500 [04:20<00:52,  2.87it/s] 70%|███████   | 351/500 [04:26<02:56,  1.18s/it] 71%|███████   | 353/500 [04:26<02:04,  1.18it/s] 71%|███████   | 355/500 [04:26<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:26<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:26<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:33<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:33<01:57,  1.16it/s] 73%|███████▎  | 365/500 [04:33<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:33<01:00,  2.18it/s] 74%|███████▍  | 369/500 [04:33<00:44,  2.92it/s] 74%|███████▍  | 371/500 [04:40<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:40<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:40<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:40<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:40<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:47<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:47<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:47<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:47<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:47<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:53<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:53<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:54<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:54<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:54<00:34,  2.94it/s] 80%|████████  | 401/500 [05:00<01:56,  1.18s/it] 81%|████████  | 403/500 [05:00<01:21,  1.18it/s] 81%|████████  | 405/500 [05:00<00:57,  1.64it/s] 81%|████████▏ | 407/500 [05:01<00:41,  2.24it/s] 82%|████████▏ | 409/500 [05:01<00:30,  3.01it/s] 82%|████████▏ | 411/500 [05:07<01:44,  1.17s/it]Valid Loss:  0.00130745698697865
Epoch:  345  	Training Loss: 0.0013575402554124594
Test Loss:  0.0014981536660343409
Valid Loss:  0.0013063743244856596
Epoch:  346  	Training Loss: 0.0013565013650804758
Test Loss:  0.0014979013940319419
Valid Loss:  0.001305299112573266
Epoch:  347  	Training Loss: 0.0013554712058976293
Test Loss:  0.0014976748498156667
Valid Loss:  0.0013042371720075607
Epoch:  348  	Training Loss: 0.0013544568791985512
Test Loss:  0.001497444580309093
Valid Loss:  0.0013031794223934412
Epoch:  349  	Training Loss: 0.0013534444151446223
Test Loss:  0.001497204415500164
Valid Loss:  0.0013021249324083328
Epoch:  350  	Training Loss: 0.0013524373061954975
Test Loss:  0.0014969536568969488
Valid Loss:  0.0013010723050683737
Epoch:  351  	Training Loss: 0.001351434038951993
Test Loss:  0.0014966856688261032
Valid Loss:  0.001300024101510644
Epoch:  352  	Training Loss: 0.001350435079075396
Test Loss:  0.0014959995169192553
Valid Loss:  0.001297962386161089
Epoch:  353  	Training Loss: 0.0013472505379468203
Test Loss:  0.0014964037109166384
Valid Loss:  0.0012961779721081257
Epoch:  354  	Training Loss: 0.0013448933605104685
Test Loss:  0.0014968900941312313
Valid Loss:  0.0012944500194862485
Epoch:  355  	Training Loss: 0.0013426818186417222
Test Loss:  0.0014973196666687727
Valid Loss:  0.0012928452342748642
Epoch:  356  	Training Loss: 0.0013406851794570684
Test Loss:  0.001497647725045681
Valid Loss:  0.0012913104146718979
Epoch:  357  	Training Loss: 0.0013388106599450111
Test Loss:  0.0014978668186813593
Valid Loss:  0.0012898899149149656
Epoch:  358  	Training Loss: 0.0013371061068028212
Test Loss:  0.0014979690313339233
Valid Loss:  0.001288528786972165
Epoch:  359  	Training Loss: 0.0013354567345231771
Test Loss:  0.0014979754341766238
Valid Loss:  0.001287213759496808
Epoch:  360  	Training Loss: 0.0013338909484446049
Test Loss:  0.001497929566539824
Valid Loss:  0.001286036567762494
Epoch:  361  	Training Loss: 0.001332603394985199
Test Loss:  0.0014979655388742685
Valid Loss:  0.0012849064078181982
Epoch:  362  	Training Loss: 0.0013313509989529848
Test Loss:  0.001495820819400251
Valid Loss:  0.0012846997706219554
Epoch:  363  	Training Loss: 0.0013311468064785004
Test Loss:  0.0014935815706849098
Valid Loss:  0.001284570200368762
Epoch:  364  	Training Loss: 0.001330982311628759
Test Loss:  0.001491473987698555
Valid Loss:  0.0012844763696193695
Epoch:  365  	Training Loss: 0.0013308426132425666
Test Loss:  0.0014895391650497913
Valid Loss:  0.0012844062875956297
Epoch:  366  	Training Loss: 0.0013307244516909122
Test Loss:  0.001487775705754757
Valid Loss:  0.0012843457516282797
Epoch:  367  	Training Loss: 0.001330626429989934
Test Loss:  0.001486164634115994
Valid Loss:  0.0012843041913583875
Epoch:  368  	Training Loss: 0.0013305447064340115
Test Loss:  0.0014846990816295147
Valid Loss:  0.0012842691503465176
Epoch:  369  	Training Loss: 0.001330478466115892
Test Loss:  0.001483360305428505
Valid Loss:  0.001284244586713612
Epoch:  370  	Training Loss: 0.0013304166495800018
Test Loss:  0.0014821444638073444
Valid Loss:  0.0012842286378145218
Epoch:  371  	Training Loss: 0.0013303703162819147
Test Loss:  0.0014810282737016678
Valid Loss:  0.0012842139694839716
Epoch:  372  	Training Loss: 0.0013303300365805626
Test Loss:  0.0014803651720285416
Valid Loss:  0.0012839369010180235
Epoch:  373  	Training Loss: 0.001330094994045794
Test Loss:  0.0014796038158237934
Valid Loss:  0.0012836948735639453
Epoch:  374  	Training Loss: 0.0013298686826601624
Test Loss:  0.0014788423432037234
Valid Loss:  0.0012834748486056924
Epoch:  375  	Training Loss: 0.0013296764809638262
Test Loss:  0.0014781162608414888
Valid Loss:  0.001283301506191492
Epoch:  376  	Training Loss: 0.001329503022134304
Test Loss:  0.0014774274313822389
Valid Loss:  0.001283126650378108
Epoch:  377  	Training Loss: 0.0013293316587805748
Test Loss:  0.0014767794637009501
Valid Loss:  0.0012829587794840336
Epoch:  378  	Training Loss: 0.0013291800860315561
Test Loss:  0.0014761683996766806
Valid Loss:  0.0012828089529648423
Epoch:  379  	Training Loss: 0.001329043647274375
Test Loss:  0.0014755948213860393
Valid Loss:  0.0012826742604374886
Epoch:  380  	Training Loss: 0.0013289086055010557
Test Loss:  0.0014750489499419928
Valid Loss:  0.0012825424782931805
Epoch:  381  	Training Loss: 0.0013287748442962766
Test Loss:  0.0014745282242074609
Valid Loss:  0.0012824119767174125
Epoch:  382  	Training Loss: 0.0013286450412124395
Test Loss:  0.0014748589601367712
Valid Loss:  0.0012815538793802261
Epoch:  383  	Training Loss: 0.0013280847342684865
Test Loss:  0.0014735145960003138
Valid Loss:  0.001281079021282494
Epoch:  384  	Training Loss: 0.001327485078945756
Test Loss:  0.0014728077221661806
Valid Loss:  0.0012803706340491772
Epoch:  385  	Training Loss: 0.0013267400208860636
Test Loss:  0.0014717185404151678
Valid Loss:  0.0012797561939805746
Epoch:  386  	Training Loss: 0.0013260097475722432
Test Loss:  0.0014707895461469889
Valid Loss:  0.0012791287153959274
Epoch:  387  	Training Loss: 0.0013252838980406523
Test Loss:  0.0014699090970680118
Valid Loss:  0.001278507406823337
Epoch:  388  	Training Loss: 0.0013245707377791405
Test Loss:  0.0014690915122628212
Valid Loss:  0.0012779018143191934
Epoch:  389  	Training Loss: 0.001323865377344191
Test Loss:  0.0014683284098282456
Valid Loss:  0.0012772965710610151
Epoch:  390  	Training Loss: 0.0013231663033366203
Test Loss:  0.0014676136197522283
Valid Loss:  0.0012766927247866988
Epoch:  391  	Training Loss: 0.0013224754948168993
Test Loss:  0.0014669453958049417
Valid Loss:  0.001276023918762803
Epoch:  392  	Training Loss: 0.0013216861989349127
Test Loss:  0.0014657583087682724
Valid Loss:  0.001275401096791029
Epoch:  393  	Training Loss: 0.0013209156459197402
Test Loss:  0.001465402776375413
Valid Loss:  0.0012746728025376797
Epoch:  394  	Training Loss: 0.0013201974797993898
Test Loss:  0.0014651995152235031
Valid Loss:  0.0012739249505102634
Epoch:  395  	Training Loss: 0.0013194833882153034
Test Loss:  0.0014650255907326937
Valid Loss:  0.0012731659226119518
Epoch:  396  	Training Loss: 0.0013187713921070099
Test Loss:  0.0014648495707660913
Valid Loss:  0.0012724107364192605
Epoch:  397  	Training Loss: 0.0013180660316720605
Test Loss:  0.0014646786730736494
Valid Loss:  0.0012716584606096148
Epoch:  398  	Training Loss: 0.0013173655606806278
Test Loss:  0.0014644984621554613
Valid Loss:  0.0012709227157756686
Epoch:  399  	Training Loss: 0.001316675334237516
Test Loss:  0.0014643300091847777
Valid Loss:  0.0012701876694336534
Epoch:  400  	Training Loss: 0.0013159937225282192
Test Loss:  0.0014641527086496353
Valid Loss:  0.00126945530064404
Epoch:  401  	Training Loss: 0.001315316534601152
Test Loss:  0.001463981345295906
Valid Loss:  0.0012687360867857933
Epoch:  402  	Training Loss: 0.0013146493583917618
Test Loss:  0.0014651163946837187
Valid Loss:  0.001266585779376328
Epoch:  403  	Training Loss: 0.0013132835738360882
Test Loss:  0.001464422675780952
Valid Loss:  0.0012649698182940483
Epoch:  404  	Training Loss: 0.0013120615622028708
Test Loss:  0.0014635382685810328
Valid Loss:  0.0012634191662073135
Epoch:  405  	Training Loss: 0.0013108616694808006
Test Loss:  0.0014626665506511927
Valid Loss:  0.0012618978507816792
Epoch:  406  	Training Loss: 0.001309678191319108
Test Loss:  0.0014618411660194397
Valid Loss:  0.0012603953946381807
Epoch:  407  	Training Loss: 0.001308513805270195
Test Loss:  0.001461050589568913
Valid Loss:  0.0012589187826961279
Epoch:  408  	Training Loss: 0.0013073685113340616
Test Loss:  0.0014603056479245424
Valid Loss:  0.0012574591673910618
Epoch:  409  	Training Loss: 0.0013062396319583058
Test Loss:  0.0014595993561670184
Valid Loss:  0.0012560184113681316
Epoch:  410  	Training Loss: 0.0013050043489784002
Test Loss:  0.0014591405633836985
Valid Loss:  0.0012543577468022704
Epoch:  411  	Training Loss: 0.0013036339078098536
Test Loss:  0.001458404352888465
Valid Loss:  0.0012527769431471825
Epoch:  412  	Training Loss: 0.0013022897765040398
Test Loss:  0.0014564518351107836
Valid Loss:  0.0012519997544586658
 83%|████████▎ | 413/500 [05:07<01:13,  1.19it/s] 83%|████████▎ | 415/500 [05:07<00:51,  1.64it/s] 83%|████████▎ | 417/500 [05:07<00:36,  2.25it/s] 84%|████████▍ | 419/500 [05:07<00:26,  3.03it/s] 84%|████████▍ | 421/500 [05:14<01:34,  1.20s/it] 85%|████████▍ | 423/500 [05:14<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:14<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:14<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:14<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:21<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:21<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:21<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:21<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:21<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:28<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:28<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:28<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:28<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:28<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:34<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:35<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:35<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:35<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:35<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:41<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:41<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:41<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:42<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:42<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:48<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:48<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:48<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:48<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:49<00:06,  3.02it/s]Epoch:  413  	Training Loss: 0.0013014632277190685
Test Loss:  0.001454946119338274
Valid Loss:  0.0012512075481936336
Epoch:  414  	Training Loss: 0.0013006553053855896
Test Loss:  0.0014537370298057795
Valid Loss:  0.0012504077749326825
Epoch:  415  	Training Loss: 0.0012998610036447644
Test Loss:  0.0014527507591992617
Valid Loss:  0.001249600201845169
Epoch:  416  	Training Loss: 0.001299069612286985
Test Loss:  0.0014519579708576202
Valid Loss:  0.0012487971689552069
Epoch:  417  	Training Loss: 0.0012982862535864115
Test Loss:  0.0014512629713863134
Valid Loss:  0.0012479840079322457
Epoch:  418  	Training Loss: 0.0012975095305591822
Test Loss:  0.001450622221454978
Valid Loss:  0.0012471801601350307
Epoch:  419  	Training Loss: 0.0012967431684955955
Test Loss:  0.0014500468969345093
Valid Loss:  0.0012463948223739862
Epoch:  420  	Training Loss: 0.0012960175517946482
Test Loss:  0.0014495132490992546
Valid Loss:  0.0012457146076485515
Epoch:  421  	Training Loss: 0.0012954610865563154
Test Loss:  0.0014490141766145825
Valid Loss:  0.0012450339272618294
Epoch:  422  	Training Loss: 0.0012949059018865228
Test Loss:  0.0014483905397355556
Valid Loss:  0.001244997838512063
Epoch:  423  	Training Loss: 0.0012946596834808588
Test Loss:  0.0014482885599136353
Valid Loss:  0.0012449517380446196
Epoch:  424  	Training Loss: 0.0012944814516231418
Test Loss:  0.001448415219783783
Valid Loss:  0.001244899001903832
Epoch:  425  	Training Loss: 0.0012943362817168236
Test Loss:  0.001448641181923449
Valid Loss:  0.0012448360212147236
Epoch:  426  	Training Loss: 0.0012942338362336159
Test Loss:  0.0014488964807242155
Valid Loss:  0.0012448036577552557
Epoch:  427  	Training Loss: 0.0012941400054842234
Test Loss:  0.0014491514302790165
Valid Loss:  0.0012447729241102934
Epoch:  428  	Training Loss: 0.001294081681407988
Test Loss:  0.0014493970666080713
Valid Loss:  0.0012447393964976072
Epoch:  429  	Training Loss: 0.0012940362794324756
Test Loss:  0.0014496285002678633
Valid Loss:  0.0012447130866348743
Epoch:  430  	Training Loss: 0.0012939900625497103
Test Loss:  0.0014498480595648289
Valid Loss:  0.0012446811888366938
Epoch:  431  	Training Loss: 0.0012939459411427379
Test Loss:  0.0014500601682811975
Valid Loss:  0.0012446559267118573
Epoch:  432  	Training Loss: 0.001293904148042202
Test Loss:  0.0014503911370411515
Valid Loss:  0.001244356855750084
Epoch:  433  	Training Loss: 0.0012937007704749703
Test Loss:  0.0014506361912935972
Valid Loss:  0.0012440778082236648
Epoch:  434  	Training Loss: 0.001293498557060957
Test Loss:  0.0014508706517517567
Valid Loss:  0.0012437980622053146
Epoch:  435  	Training Loss: 0.001293296692892909
Test Loss:  0.0014510861365124583
Valid Loss:  0.0012435195967555046
Epoch:  436  	Training Loss: 0.0012930985540151596
Test Loss:  0.0014512893976643682
Valid Loss:  0.0012432443909347057
Epoch:  437  	Training Loss: 0.0012929023941978812
Test Loss:  0.0014514760114252567
Valid Loss:  0.0012429700000211596
Epoch:  438  	Training Loss: 0.0012927112402394414
Test Loss:  0.001451639924198389
Valid Loss:  0.0012427004985511303
Epoch:  439  	Training Loss: 0.0012925212504342198
Test Loss:  0.0014517951058223844
Valid Loss:  0.0012424340238794684
Epoch:  440  	Training Loss: 0.0012923317262902856
Test Loss:  0.0014519384130835533
Valid Loss:  0.00124216522090137
Epoch:  441  	Training Loss: 0.0012921447632834315
Test Loss:  0.0014520660042762756
Valid Loss:  0.0012418999103829265
Epoch:  442  	Training Loss: 0.0012919584987685084
Test Loss:  0.0014518133830279112
Valid Loss:  0.0012403251603245735
Epoch:  443  	Training Loss: 0.001289944862946868
Test Loss:  0.0014526175800710917
Valid Loss:  0.0012387093156576157
Epoch:  444  	Training Loss: 0.0012882738374173641
Test Loss:  0.0014532307395711541
Valid Loss:  0.0012372463243082166
Epoch:  445  	Training Loss: 0.0012866766192018986
Test Loss:  0.001453867182135582
Valid Loss:  0.0012358292005956173
Epoch:  446  	Training Loss: 0.0012851394712924957
Test Loss:  0.0014544520527124405
Valid Loss:  0.0012344708666205406
Epoch:  447  	Training Loss: 0.0012836628593504429
Test Loss:  0.001454994548112154
Valid Loss:  0.0012331658508628607
Epoch:  448  	Training Loss: 0.0012822402641177177
Test Loss:  0.0014556669630110264
Valid Loss:  0.0012319112429395318
Epoch:  449  	Training Loss: 0.001280896831303835
Test Loss:  0.0014563672011718154
Valid Loss:  0.0012307558208703995
Epoch:  450  	Training Loss: 0.001279706135392189
Test Loss:  0.0014569966588169336
Valid Loss:  0.0012296520872041583
Epoch:  451  	Training Loss: 0.001278646057471633
Test Loss:  0.0014575005043298006
Valid Loss:  0.0012287269346415997
Epoch:  452  	Training Loss: 0.0012778674717992544
Test Loss:  0.001457510399632156
Valid Loss:  0.0012286666315048933
Epoch:  453  	Training Loss: 0.0012778524542227387
Test Loss:  0.001457451144233346
Valid Loss:  0.0012286300770938396
Epoch:  454  	Training Loss: 0.0012778404634445906
Test Loss:  0.0014573481166735291
Valid Loss:  0.0012286124983802438
Epoch:  455  	Training Loss: 0.0012778285890817642
Test Loss:  0.0014572219224646688
Valid Loss:  0.0012285998091101646
Epoch:  456  	Training Loss: 0.0012778190430253744
Test Loss:  0.0014570853672921658
Valid Loss:  0.0012285903794690967
Epoch:  457  	Training Loss: 0.0012778093805536628
Test Loss:  0.001456941943615675
Valid Loss:  0.001228584093041718
Epoch:  458  	Training Loss: 0.0012778012314811349
Test Loss:  0.0014567961916327477
Valid Loss:  0.0012285762932151556
Epoch:  459  	Training Loss: 0.0012777914525941014
Test Loss:  0.0014566527679562569
Valid Loss:  0.001228573266416788
Epoch:  460  	Training Loss: 0.0012777806259691715
Test Loss:  0.0014565065503120422
Valid Loss:  0.0012285674456506968
Epoch:  461  	Training Loss: 0.0012777727097272873
Test Loss:  0.0014563616132363677
Valid Loss:  0.0012285634875297546
Epoch:  462  	Training Loss: 0.0012777631636708975
Test Loss:  0.0014552208594977856
Valid Loss:  0.0012278176145628095
Epoch:  463  	Training Loss: 0.0012767264852300286
Test Loss:  0.001454570097848773
Valid Loss:  0.0012270595179870725
Epoch:  464  	Training Loss: 0.00127577711828053
Test Loss:  0.00145413214340806
Valid Loss:  0.0012262791860848665
Epoch:  465  	Training Loss: 0.0012748554581776261
Test Loss:  0.0014537720708176494
Valid Loss:  0.0012254845350980759
Epoch:  466  	Training Loss: 0.0012739571975544095
Test Loss:  0.0014534378424286842
Valid Loss:  0.001224702806212008
Epoch:  467  	Training Loss: 0.0012731000315397978
Test Loss:  0.001453101052902639
Valid Loss:  0.001223963568918407
Epoch:  468  	Training Loss: 0.0012722669634968042
Test Loss:  0.0014527372550219297
Valid Loss:  0.0012232239823788404
Epoch:  469  	Training Loss: 0.0012714825570583344
Test Loss:  0.00145230651833117
Valid Loss:  0.0012225230457261205
Epoch:  470  	Training Loss: 0.0012707633432000875
Test Loss:  0.0014518331736326218
Valid Loss:  0.0012218458577990532
Epoch:  471  	Training Loss: 0.0012700667139142752
Test Loss:  0.0014513267669826746
Valid Loss:  0.0012211905559524894
Epoch:  472  	Training Loss: 0.0012693749740719795
Test Loss:  0.001449416857212782
Valid Loss:  0.0012193466536700726
Epoch:  473  	Training Loss: 0.0012675811303779483
Test Loss:  0.0014473178889602423
Valid Loss:  0.001217555021867156
Epoch:  474  	Training Loss: 0.0012657939223572612
Test Loss:  0.0014451935421675444
Valid Loss:  0.0012157836463302374
Epoch:  475  	Training Loss: 0.0012640147469937801
Test Loss:  0.0014430837472900748
Valid Loss:  0.0012140210019424558
Epoch:  476  	Training Loss: 0.0012622375506907701
Test Loss:  0.0014410056173801422
Valid Loss:  0.0012122616171836853
Epoch:  477  	Training Loss: 0.0012604669900611043
Test Loss:  0.001438954146578908
Valid Loss:  0.001210508868098259
Epoch:  478  	Training Loss: 0.0012587013188749552
Test Loss:  0.0014369413256645203
Valid Loss:  0.001208745059557259
Epoch:  479  	Training Loss: 0.0012569361133500934
Test Loss:  0.001435031183063984
Valid Loss:  0.001206883112899959
Epoch:  480  	Training Loss: 0.0012551182880997658
Test Loss:  0.0014332244172692299
Valid Loss:  0.0012047506170347333
Epoch:  481  	Training Loss: 0.0012530420208349824
Test Loss:   96%|█████████▌| 481/500 [05:55<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:55<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:55<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:55<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:55<00:03,  3.00it/s] 98%|█████████▊| 491/500 [06:02<00:10,  1.18s/it] 99%|█████████▊| 493/500 [06:02<00:05,  1.17it/s] 99%|█████████▉| 495/500 [06:02<00:03,  1.62it/s] 99%|█████████▉| 497/500 [06:02<00:01,  2.20it/s]100%|█████████▉| 499/500 [06:02<00:00,  2.95it/s]100%|██████████| 500/500 [06:02<00:00,  1.38it/s]
0.0014313131105154753
Valid Loss:  0.0012017851695418358
Epoch:  482  	Training Loss: 0.0012501247692853212
Test Loss:  0.0014264904893934727
Valid Loss:  0.0012018659617751837
Epoch:  483  	Training Loss: 0.001249888213351369
Test Loss:  0.0014237983850762248
Valid Loss:  0.0012018387205898762
Epoch:  484  	Training Loss: 0.0012497503776103258
Test Loss:  0.0014218561118468642
Valid Loss:  0.001201774226501584
Epoch:  485  	Training Loss: 0.0012496416456997395
Test Loss:  0.0014202495804056525
Valid Loss:  0.001201710430905223
Epoch:  486  	Training Loss: 0.0012495534028857946
Test Loss:  0.0014188431669026613
Valid Loss:  0.0012016554828733206
Epoch:  487  	Training Loss: 0.001249481807462871
Test Loss:  0.001417585532180965
Valid Loss:  0.0012016099644824862
Epoch:  488  	Training Loss: 0.001249420689418912
Test Loss:  0.0014164512977004051
Valid Loss:  0.0012015748070552945
Epoch:  489  	Training Loss: 0.0012493720278143883
Test Loss:  0.0014154288219287992
Valid Loss:  0.001201546285301447
Epoch:  490  	Training Loss: 0.0012493283720687032
Test Loss:  0.0014145002933219075
Valid Loss:  0.0012015241663902998
Epoch:  491  	Training Loss: 0.0012492956593632698
Test Loss:  0.0014136587269604206
Valid Loss:  0.0012015067040920258
Epoch:  492  	Training Loss: 0.001249265274964273
Test Loss:  0.0014135672245174646
Valid Loss:  0.0012011280050501227
Epoch:  493  	Training Loss: 0.0012489771470427513
Test Loss:  0.0014134796801954508
Valid Loss:  0.0012007546611130238
Epoch:  494  	Training Loss: 0.0012487208005040884
Test Loss:  0.0014133842196315527
Valid Loss:  0.0012004617601633072
Epoch:  495  	Training Loss: 0.0012485284823924303
Test Loss:  0.0014132964424788952
Valid Loss:  0.0012001628056168556
Epoch:  496  	Training Loss: 0.0012483377940952778
Test Loss:  0.0014132019132375717
Valid Loss:  0.0011998633854091167
Epoch:  497  	Training Loss: 0.0012481451267376542
Test Loss:  0.0014131112257018685
Valid Loss:  0.0011995703680440784
Epoch:  498  	Training Loss: 0.0012479547876864672
Test Loss:  0.0014130172785371542
Valid Loss:  0.0011992794461548328
Epoch:  499  	Training Loss: 0.0012477663112804294
Test Loss:  0.0014129229821264744
Valid Loss:  0.0011990056373178959
Epoch:  500  	Training Loss: 0.001247577602043748
Test Loss:  0.0014128305483609438
Valid Loss:  0.0011987329926341772
seed is  5
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 15.08it/s]  1%|          | 4/500 [00:00<00:31, 15.93it/s]  1%|          | 6/500 [00:00<00:30, 16.25it/s]  2%|▏         | 8/500 [00:00<00:30, 16.31it/s]  2%|▏         | 10/500 [00:00<00:29, 16.48it/s]  2%|▏         | 12/500 [00:00<00:29, 16.55it/s]  3%|▎         | 14/500 [00:00<00:29, 16.58it/s]  3%|▎         | 16/500 [00:00<00:29, 16.60it/s]  4%|▎         | 18/500 [00:01<00:29, 16.61it/s]  4%|▍         | 20/500 [00:01<00:29, 16.49it/s]  4%|▍         | 22/500 [00:01<00:29, 16.47it/s]  5%|▍         | 24/500 [00:01<00:28, 16.48it/s]  5%|▌         | 26/500 [00:01<00:28, 16.35it/s]  6%|▌         | 28/500 [00:01<00:28, 16.42it/s]  6%|▌         | 30/500 [00:01<00:28, 16.52it/s]  6%|▋         | 32/500 [00:01<00:30, 15.56it/s]  7%|▋         | 34/500 [00:02<00:30, 15.16it/s]  7%|▋         | 36/500 [00:02<00:29, 15.67it/s]  8%|▊         | 38/500 [00:02<00:28, 16.00it/s]  8%|▊         | 40/500 [00:02<00:28, 16.24it/s]  8%|▊         | 42/500 [00:02<00:27, 16.43it/s]  9%|▉         | 44/500 [00:02<00:27, 16.52it/s]  9%|▉         | 46/500 [00:02<00:27, 16.61it/s] 10%|▉         | 48/500 [00:02<00:27, 16.48it/s] 10%|█         | 50/500 [00:03<00:27, 16.51it/s] 10%|█         | 52/500 [00:03<00:26, 16.62it/s] 11%|█         | 54/500 [00:03<00:26, 16.65it/s] 11%|█         | 56/500 [00:03<00:26, 16.67it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.68it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.71it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.72it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.72it/s] 13%|█▎        | 66/500 [00:04<00:25, 16.75it/s] 14%|█▎        | 68/500 [00:04<00:25, 16.73it/s] 14%|█▍        | 70/500 [00:04<00:25, 16.61it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.53it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.57it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.57it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.61it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.67it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.69it/s] 17%|█▋        | 84/500 [00:05<00:24, 16.71it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.71it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.60it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.46it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.46it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.42it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.44it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.54it/s] 20%|██        | 100/500 [00:06<00:24, 16.59it/s] 20%|██        | 102/500 [00:06<00:23, 16.59it/s] 21%|██        | 104/500 [00:06<00:23, 16.61it/s] 21%|██        | 106/500 [00:06<00:23, 16.59it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.49it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.48it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.45it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.55it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.61it/s] 24%|██▎       | 118/500 [00:07<00:22, 16.65it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.63it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.55it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.60it/s]Epoch:  1  	Training Loss: 0.20200631022453308
Test Loss:  4756.61865234375
Valid Loss:  4752.7431640625
Epoch:  2  	Training Loss: 4756.10302734375
Test Loss:  7.435614027566285e+16
Valid Loss:  7.464328460920422e+16
Epoch:  3  	Training Loss: 7.458842069696512e+16
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.62it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.66it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.64it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.64it/s] 27%|██▋       | 134/500 [00:08<00:21, 16.64it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.62it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.61it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.57it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.54it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.40it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.35it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.27it/s] 30%|███       | 150/500 [00:09<00:22, 15.28it/s] 30%|███       | 152/500 [00:09<00:22, 15.44it/s] 31%|███       | 154/500 [00:09<00:21, 15.81it/s] 31%|███       | 156/500 [00:09<00:21, 16.07it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.21it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.34it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.41it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.46it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.49it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.52it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.35it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.31it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.45it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.44it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.30it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.41it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.49it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.57it/s] 37%|███▋      | 186/500 [00:11<00:18, 16.64it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.53it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.51it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.49it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.50it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.57it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.59it/s] 40%|████      | 200/500 [00:12<00:18, 16.64it/s] 40%|████      | 202/500 [00:12<00:18, 16.51it/s] 41%|████      | 204/500 [00:12<00:17, 16.45it/s] 41%|████      | 206/500 [00:12<00:17, 16.56it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.58it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.62it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.36it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.13it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.26it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.36it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.36it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.39it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.53it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.54it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.62it/s] 46%|████▌     | 230/500 [00:13<00:16, 16.63it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.62it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.48it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.39it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.49it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.56it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.63it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.67it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.70it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.69it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.66it/s] 50%|█████     | 252/500 [00:15<00:14, 16.69it/s] 51%|█████     | 254/500 [00:15<00:14, 16.70it/s] 51%|█████     | 256/500 [00:15<00:14, 16.69it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.62it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.54it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.52it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.46it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.47it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.47it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.56it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.60it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.58it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.59it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.65it/s] 56%|█████▌    | 280/500 [00:16<00:13, 16.70it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.68it/s] 57%|█████▋    | 284/500 [00:17<00:12, 16.66it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.70it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.72it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.71it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.73it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.56it/s] 59%|█████▉    | 296/500 [00:17<00:12, 16.56it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.45it/s] 60%|██████    | 300/500 [00:18<00:12, 15.62it/s] 60%|██████    | 302/500 [00:18<00:12, 15.89it/s] 61%|██████    | 304/500 [00:18<00:12, 16.14it/s] 61%|██████    | 306/500 [00:18<00:11, 16.29it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.42it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.51it/s] 62%|██████▏   | 312/500 [00:18<00:11, 16.54it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.56it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.57it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.47it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.51it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.43it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.45it/s] 65%|██████▌   | 326/500 [00:19<00:11, 15.70it/s] 66%|██████▌   | 328/500 [00:19<00:10, 15.65it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.77it/s] 66%|██████▋   | 332/500 [00:20<00:10, 15.95it/s] 67%|██████▋   | 334/500 [00:20<00:10, 15.99it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.22it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.29it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.43it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.49it/s] 69%|██████▉   | 344/500 [00:20<00:09, 16.52it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.56it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.50it/s] 70%|███████   | 350/500 [00:21<00:09, 16.51it/s] 70%|███████   | 352/500 [00:21<00:08, 16.52it/s] 71%|███████   | 354/500 [00:21<00:08, 16.50it/s] 71%|███████   | 356/500 [00:21<00:08, 16.55it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.58it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.57it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.57it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.15it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.03it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.47it/s] 74%|███████▍  | 370/500 [00:22<00:08, 15.84it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.14it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.32it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.38it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.49it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.24it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.34it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.36it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.44it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.52it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.56it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.58it/s] 79%|███████▉  | 394/500 [00:23<00:06, 16.59it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.65it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.70it/s] 80%|████████  | 400/500 [00:24<00:06, 16.65it/s] 80%|████████  | 402/500 [00:24<00:05, 16.64it/s] 81%|████████  | 404/500 [00:24<00:05, 16.47it/s] 81%|████████  | 406/500 [00:24<00:05, 16.46it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.49it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.53it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.49it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.54it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.62it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.35it/s] 84%|████████▍ | 420/500 [00:25<00:05, 14.98it/s] 84%|████████▍ | 422/500 [00:25<00:05, 15.14it/s] 85%|████████▍ | 424/500 [00:25<00:04, 15.53it/s] 85%|████████▌ | 426/500 [00:25<00:04, 15.81it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.08it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.16it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.10it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.01it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.17it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.35it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.30it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.34it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.34it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.47it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.39it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.27it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.31it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.41it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.43it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.45it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.48it/s] 92%|█████████▏| 462/500 [00:28<00:02, 15.52it/s] 93%|█████████▎| 464/500 [00:28<00:02, 15.76it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.02it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.21it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.21it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.24it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.06it/s] 95%|█████████▌| 476/500 [00:29<00:01, 15.76it/s] 96%|█████████▌| 478/500 [00:29<00:01, 15.91it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.19it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.33it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.44it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.55it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.64it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.67it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.67it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.68it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.68it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.65it/s]100%|██████████| 500/500 [00:30<00:00, 16.70it/s]100%|██████████| 500/500 [00:30<00:00, 16.40it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  5
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:57,  6.25s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:38,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:42,  2.90it/s]  6%|▌         | 31/500 [00:27<09:30,  1.22s/it]  7%|▋         | 33/500 [00:27<06:47,  1.15it/s]  7%|▋         | 35/500 [00:27<04:53,  1.59it/s]  7%|▋         | 37/500 [00:27<03:35,  2.14it/s]  8%|▊         | 39/500 [00:27<02:42,  2.83it/s]  8%|▊         | 41/500 [00:34<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:40<08:53,  1.19s/it] 11%|█         | 53/500 [00:41<06:21,  1.17it/s] 11%|█         | 55/500 [00:41<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:41<02:27,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:44,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:15,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:29,  1.61it/s] 13%|█▎        | 67/500 [00:48<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.97it/s]Epoch:  1  	Training Loss: 0.2020062953233719
Test Loss:  0.017425162717700005
Valid Loss:  0.021027255803346634
Epoch:  2  	Training Loss: 0.020892508327960968
Test Loss:  0.014008022844791412
Valid Loss:  0.016098804771900177
Epoch:  3  	Training Loss: 0.016439594328403473
Test Loss:  0.011190335266292095
Valid Loss:  0.013283442705869675
Epoch:  4  	Training Loss: 0.013529124669730663
Test Loss:  0.0090517308562994
Valid Loss:  0.010990608483552933
Epoch:  5  	Training Loss: 0.01120406948029995
Test Loss:  0.007391883060336113
Valid Loss:  0.009169220924377441
Epoch:  6  	Training Loss: 0.009358955547213554
Test Loss:  0.006099226884543896
Valid Loss:  0.007718682289123535
Epoch:  7  	Training Loss: 0.007890917360782623
Test Loss:  0.005091859959065914
Valid Loss:  0.006560768000781536
Epoch:  8  	Training Loss: 0.0067186662927269936
Test Loss:  0.004310978576540947
Valid Loss:  0.005636098328977823
Epoch:  9  	Training Loss: 0.005782664753496647
Test Loss:  0.0037082016933709383
Valid Loss:  0.004896701779216528
Epoch:  10  	Training Loss: 0.005034830421209335
Test Loss:  0.003244934370741248
Valid Loss:  0.004305331036448479
Epoch:  11  	Training Loss: 0.0044372957199811935
Test Loss:  0.0028910061810165644
Valid Loss:  0.0038363297935575247
Epoch:  12  	Training Loss: 0.003962454851716757
Test Loss:  0.002626099856570363
Valid Loss:  0.0034682820551097393
Epoch:  13  	Training Loss: 0.0035892126616090536
Test Loss:  0.002428230829536915
Valid Loss:  0.0031726008746773005
Epoch:  14  	Training Loss: 0.003290490945801139
Test Loss:  0.002280771266669035
Valid Loss:  0.002934134565293789
Epoch:  15  	Training Loss: 0.0030500772409141064
Test Loss:  0.0021718633361160755
Valid Loss:  0.0027416725642979145
Epoch:  16  	Training Loss: 0.002856362611055374
Test Loss:  0.0020930469036102295
Valid Loss:  0.0025864378549158573
Epoch:  17  	Training Loss: 0.0027001795824617147
Test Loss:  0.002037211786955595
Valid Loss:  0.002461022464558482
Epoch:  18  	Training Loss: 0.0025741979479789734
Test Loss:  0.00199917983263731
Valid Loss:  0.0023597069084644318
Epoch:  19  	Training Loss: 0.002472563646733761
Test Loss:  0.001974934246391058
Valid Loss:  0.0022778334096074104
Epoch:  20  	Training Loss: 0.002390474546700716
Test Loss:  0.0019609294831752777
Valid Loss:  0.0022115593310445547
Epoch:  21  	Training Loss: 0.0023241424933075905
Test Loss:  0.001954417210072279
Valid Loss:  0.002157832495868206
Epoch:  22  	Training Loss: 0.0022704913280904293
Test Loss:  0.0019538982305675745
Valid Loss:  0.002114244271069765
Epoch:  23  	Training Loss: 0.002227033954113722
Test Loss:  0.0019570242147892714
Valid Loss:  0.0020789073314517736
Epoch:  24  	Training Loss: 0.0021918441634625196
Test Loss:  0.001963511109352112
Valid Loss:  0.0020501655526459217
Epoch:  25  	Training Loss: 0.0021633084397763014
Test Loss:  0.0019714583177119493
Valid Loss:  0.0020267742220312357
Epoch:  26  	Training Loss: 0.0021401536650955677
Test Loss:  0.0019810893572866917
Valid Loss:  0.0020076546352356672
Epoch:  27  	Training Loss: 0.002121302532032132
Test Loss:  0.0019913031719624996
Valid Loss:  0.0019922107458114624
Epoch:  28  	Training Loss: 0.0021059345453977585
Test Loss:  0.0020014490000903606
Valid Loss:  0.0019796083215624094
Epoch:  29  	Training Loss: 0.0020934315398335457
Test Loss:  0.002012084936723113
Valid Loss:  0.001969275064766407
Epoch:  30  	Training Loss: 0.0020831776782870293
Test Loss:  0.0020221585873514414
Valid Loss:  0.001960773952305317
Epoch:  31  	Training Loss: 0.002074794378131628
Test Loss:  0.0020320932380855083
Valid Loss:  0.0019538085907697678
Epoch:  32  	Training Loss: 0.0020679482258856297
Test Loss:  0.002041712636128068
Valid Loss:  0.0019480769988149405
Epoch:  33  	Training Loss: 0.0020622957963496447
Test Loss:  0.0020506330765783787
Valid Loss:  0.0019432984990999103
Epoch:  34  	Training Loss: 0.002057603793218732
Test Loss:  0.002059048041701317
Valid Loss:  0.0019392988178879023
Epoch:  35  	Training Loss: 0.0020537180826067924
Test Loss:  0.0020665221381932497
Valid Loss:  0.0019360031001269817
Epoch:  36  	Training Loss: 0.0020505343563854694
Test Loss:  0.0020738057792186737
Valid Loss:  0.0019332445226609707
Epoch:  37  	Training Loss: 0.0020478933583945036
Test Loss:  0.0020804936066269875
Valid Loss:  0.0019309287890791893
Epoch:  38  	Training Loss: 0.0020457012578845024
Test Loss:  0.0020865483675152063
Valid Loss:  0.0019290170166641474
Epoch:  39  	Training Loss: 0.0020438721403479576
Test Loss:  0.0020924443379044533
Valid Loss:  0.00192735786549747
Epoch:  40  	Training Loss: 0.002042348962277174
Test Loss:  0.0020974779035896063
Valid Loss:  0.0019260940607637167
Epoch:  41  	Training Loss: 0.00204109912738204
Test Loss:  0.002102710073813796
Valid Loss:  0.0019249363103881478
Epoch:  42  	Training Loss: 0.0020400499925017357
Test Loss:  0.002107455860823393
Valid Loss:  0.0019238991662859917
Epoch:  43  	Training Loss: 0.0020391736179590225
Test Loss:  0.0021112344693392515
Valid Loss:  0.001923130126670003
Epoch:  44  	Training Loss: 0.00203842855989933
Test Loss:  0.002115114126354456
Valid Loss:  0.0019224120769649744
Epoch:  45  	Training Loss: 0.0020377961918711662
Test Loss:  0.0021185700315982103
Valid Loss:  0.0019217776134610176
Epoch:  46  	Training Loss: 0.0020372504368424416
Test Loss:  0.0021216864697635174
Valid Loss:  0.0019212153274565935
Epoch:  47  	Training Loss: 0.0020367796532809734
Test Loss:  0.002124498365446925
Valid Loss:  0.001920698443427682
Epoch:  48  	Training Loss: 0.0020363619551062584
Test Loss:  0.0021270113065838814
Valid Loss:  0.0019202260300517082
Epoch:  49  	Training Loss: 0.0020359870977699757
Test Loss:  0.0021292669698596
Valid Loss:  0.0019197850488126278
Epoch:  50  	Training Loss: 0.002035650657489896
Test Loss:  0.0021312907338142395
Valid Loss:  0.0019193748012185097
Epoch:  51  	Training Loss: 0.0020353433210402727
Test Loss:  0.00213309726677835
Valid Loss:  0.0019189973827451468
Epoch:  52  	Training Loss: 0.002035061828792095
Test Loss:  0.00213470752350986
Valid Loss:  0.0019186408026143909
Epoch:  53  	Training Loss: 0.0020347926765680313
Test Loss:  0.0021361419931054115
Valid Loss:  0.0019183083204552531
Epoch:  54  	Training Loss: 0.002034549368545413
Test Loss:  0.002137424424290657
Valid Loss:  0.001918011112138629
Epoch:  55  	Training Loss: 0.0020343181677162647
Test Loss:  0.00213851360604167
Valid Loss:  0.0019177880603820086
Epoch:  56  	Training Loss: 0.0020340955816209316
Test Loss:  0.0021396286319941282
Valid Loss:  0.0019175627967342734
Epoch:  57  	Training Loss: 0.0020338906906545162
Test Loss:  0.0021402696147561073
Valid Loss:  0.0019173939945176244
Epoch:  58  	Training Loss: 0.0020337181631475687
Test Loss:  0.002141427481546998
Valid Loss:  0.0019171908497810364
Epoch:  59  	Training Loss: 0.002033557277172804
Test Loss:  0.002142004668712616
Valid Loss:  0.0019170495215803385
Epoch:  60  	Training Loss: 0.0020334029104560614
Test Loss:  0.002142946468666196
Valid Loss:  0.0019168696599081159
Epoch:  61  	Training Loss: 0.002033253200352192
Test Loss:  0.00214366358704865
Valid Loss:  0.001916706096380949
Epoch:  62  	Training Loss: 0.002033107215538621
Test Loss:  0.002144196769222617
Valid Loss:  0.0019165587145835161
Epoch:  63  	Training Loss: 0.0020329724065959454
Test Loss:  0.0021449944470077753
Valid Loss:  0.0019163854885846376
Epoch:  64  	Training Loss: 0.002032844815403223
Test Loss:  0.0021451525390148163
Valid Loss:  0.001916274311952293
Epoch:  65  	Training Loss: 0.0020327167585492134
Test Loss:  0.0021456792019307613
Valid Loss:  0.0019161334494128823
Epoch:  66  	Training Loss: 0.0020325924269855022
Test Loss:  0.00214614300057292
Valid Loss:  0.0019159979419782758
Epoch:  67  	Training Loss: 0.0020324713550508022
Test Loss:  0.0021464070305228233
Valid Loss:  0.001915878034196794
Epoch:  68  	Training Loss: 0.0020323488861322403
Test Loss:  0.0021467413753271103
Valid Loss:  0.001915752305649221
Epoch:  69  	Training Loss: 0.0020322285126894712
Test Loss:  0.0021470189094543457
Valid Loss:  0.0019156287889927626
Epoch:  70  	Training Loss: 0.0020321086049079895
Test Loss:  0.0021473339293152094
 14%|█▍        | 71/500 [00:54<08:42,  1.22s/it] 15%|█▍        | 73/500 [00:55<06:13,  1.14it/s] 15%|█▌        | 75/500 [00:55<04:28,  1.58it/s] 15%|█▌        | 77/500 [00:55<03:18,  2.14it/s] 16%|█▌        | 79/500 [00:55<02:27,  2.86it/s] 16%|█▌        | 81/500 [01:02<08:32,  1.22s/it] 17%|█▋        | 83/500 [01:02<06:05,  1.14it/s] 17%|█▋        | 85/500 [01:02<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:02<03:11,  2.16it/s] 18%|█▊        | 89/500 [01:02<02:21,  2.91it/s] 18%|█▊        | 91/500 [01:09<08:21,  1.23s/it] 19%|█▊        | 93/500 [01:09<05:57,  1.14it/s] 19%|█▉        | 95/500 [01:09<04:16,  1.58it/s] 19%|█▉        | 97/500 [01:09<03:06,  2.16it/s] 20%|█▉        | 99/500 [01:09<02:19,  2.88it/s] 20%|██        | 101/500 [01:16<07:55,  1.19s/it] 21%|██        | 103/500 [01:16<05:39,  1.17it/s] 21%|██        | 105/500 [01:16<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:16<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:22<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:23<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:23<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:23<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:23<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:29<07:32,  1.20s/it] 25%|██▍       | 123/500 [01:30<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:30<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:30<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:30<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:36<07:27,  1.21s/it] 27%|██▋       | 133/500 [01:37<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:37<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:47,  2.17it/s]Valid Loss:  0.0019154944457113743
Epoch:  71  	Training Loss: 0.0020319903269410133
Test Loss:  0.0021473849192261696
Valid Loss:  0.001915385713800788
Epoch:  72  	Training Loss: 0.0020318706519901752
Test Loss:  0.0021475772373378277
Valid Loss:  0.0019152613822370768
Epoch:  73  	Training Loss: 0.0020317521411925554
Test Loss:  0.0021477153059095144
Valid Loss:  0.0019151376327499747
Epoch:  74  	Training Loss: 0.0020316338632255793
Test Loss:  0.0021478375419974327
Valid Loss:  0.001915015745908022
Epoch:  75  	Training Loss: 0.0020315158180892467
Test Loss:  0.0021481115836650133
Valid Loss:  0.0019148685969412327
Epoch:  76  	Training Loss: 0.002031399169936776
Test Loss:  0.0021478370763361454
Valid Loss:  0.001914786989800632
Epoch:  77  	Training Loss: 0.0020312850829213858
Test Loss:  0.0021479655988514423
Valid Loss:  0.0019146683625876904
Epoch:  78  	Training Loss: 0.0020311716943979263
Test Loss:  0.0021480037830770016
Valid Loss:  0.0019145640544593334
Epoch:  79  	Training Loss: 0.002031059004366398
Test Loss:  0.0021480503492057323
Valid Loss:  0.0019144557882100344
Epoch:  80  	Training Loss: 0.0020309463143348694
Test Loss:  0.0021480813156813383
Valid Loss:  0.001914349035359919
Epoch:  81  	Training Loss: 0.0020308333914726973
Test Loss:  0.002148099010810256
Valid Loss:  0.001914242864586413
Epoch:  82  	Training Loss: 0.002030721865594387
Test Loss:  0.0021481032017618418
Valid Loss:  0.0019141389057040215
Epoch:  83  	Training Loss: 0.0020306105725467205
Test Loss:  0.0021480980794876814
Valid Loss:  0.001914030173793435
Epoch:  84  	Training Loss: 0.002030497882515192
Test Loss:  0.0021480827126652002
Valid Loss:  0.0019139242358505726
Epoch:  85  	Training Loss: 0.0020303875207901
Test Loss:  0.002148060593754053
Valid Loss:  0.0019138234201818705
Epoch:  86  	Training Loss: 0.0020302818156778812
Test Loss:  0.002148034516721964
Valid Loss:  0.001913722138851881
Epoch:  87  	Training Loss: 0.002030173782259226
Test Loss:  0.0021480005234479904
Valid Loss:  0.0019136189948767424
Epoch:  88  	Training Loss: 0.0020300657488405704
Test Loss:  0.002147957682609558
Valid Loss:  0.001913519692607224
Epoch:  89  	Training Loss: 0.002029958413913846
Test Loss:  0.0021479118149727583
Valid Loss:  0.001913413405418396
Epoch:  90  	Training Loss: 0.0020298513118177652
Test Loss:  0.00214785966090858
Valid Loss:  0.0019133120076730847
Epoch:  91  	Training Loss: 0.0020297460723668337
Test Loss:  0.002147803083062172
Valid Loss:  0.0019132101442664862
Epoch:  92  	Training Loss: 0.002029638271778822
Test Loss:  0.0021477483678609133
Valid Loss:  0.0019131076987832785
Epoch:  93  	Training Loss: 0.0020295334979891777
Test Loss:  0.002147683873772621
Valid Loss:  0.0019130115397274494
Epoch:  94  	Training Loss: 0.0020294291898608208
Test Loss:  0.0021476196125149727
Valid Loss:  0.0019129123538732529
Epoch:  95  	Training Loss: 0.002029325347393751
Test Loss:  0.0021475530229508877
Valid Loss:  0.001912816078402102
Epoch:  96  	Training Loss: 0.002029221737757325
Test Loss:  0.0021474824752658606
Valid Loss:  0.0019127246923744678
Epoch:  97  	Training Loss: 0.0020291157998144627
Test Loss:  0.002147412858903408
Valid Loss:  0.00191263179294765
Epoch:  98  	Training Loss: 0.0020290142856538296
Test Loss:  0.002147335559129715
Valid Loss:  0.001912540988996625
Epoch:  99  	Training Loss: 0.0020289127714931965
Test Loss:  0.002147267572581768
Valid Loss:  0.0019124501850456
Epoch:  100  	Training Loss: 0.002028812887147069
Test Loss:  0.0021472000516951084
Valid Loss:  0.0019123621750622988
Epoch:  101  	Training Loss: 0.0020287183579057455
Test Loss:  0.0021471327636390924
Valid Loss:  0.0019122727680951357
Epoch:  102  	Training Loss: 0.002028621267527342
Test Loss:  0.0021470619831234217
Valid Loss:  0.0019121873192489147
Epoch:  103  	Training Loss: 0.002028529066592455
Test Loss:  0.002146991901099682
Valid Loss:  0.0019120963988825679
Epoch:  104  	Training Loss: 0.002028435468673706
Test Loss:  0.002146919257938862
Valid Loss:  0.001912014209665358
Epoch:  105  	Training Loss: 0.002028342802077532
Test Loss:  0.0021468447521328926
Valid Loss:  0.0019119238713756204
Epoch:  106  	Training Loss: 0.0020282501354813576
Test Loss:  0.0021467728074640036
Valid Loss:  0.0019118394702672958
Epoch:  107  	Training Loss: 0.0020281558390706778
Test Loss:  0.0021467001643031836
Valid Loss:  0.0019117544870823622
Epoch:  108  	Training Loss: 0.0020280650351196527
Test Loss:  0.0021466256584972143
Valid Loss:  0.0019116676412522793
Epoch:  109  	Training Loss: 0.0020279744639992714
Test Loss:  0.002146555343642831
Valid Loss:  0.0019115814939141273
Epoch:  110  	Training Loss: 0.002027881797403097
Test Loss:  0.002146481303498149
Valid Loss:  0.0019114968599751592
Epoch:  111  	Training Loss: 0.0020277914591133595
Test Loss:  0.002146407263353467
Valid Loss:  0.001911408151499927
Epoch:  112  	Training Loss: 0.002027699025347829
Test Loss:  0.00214633671566844
Valid Loss:  0.0019113263115286827
Epoch:  113  	Training Loss: 0.0020276117138564587
Test Loss:  0.0021462603472173214
Valid Loss:  0.0019112431909888983
Epoch:  114  	Training Loss: 0.00202752323821187
Test Loss:  0.0021461835131049156
Valid Loss:  0.0019111589062958956
Epoch:  115  	Training Loss: 0.0020274322014302015
Test Loss:  0.0021461118012666702
Valid Loss:  0.0019110755529254675
Epoch:  116  	Training Loss: 0.002027342328801751
Test Loss:  0.0021460314746946096
Valid Loss:  0.0019109892891719937
Epoch:  117  	Training Loss: 0.0020272524561733007
Test Loss:  0.002145955804735422
Valid Loss:  0.0019109065178781748
Epoch:  118  	Training Loss: 0.0020271644461899996
Test Loss:  0.0021458768751472235
Valid Loss:  0.0019108231645077467
Epoch:  119  	Training Loss: 0.00202707527205348
Test Loss:  0.0021457986440509558
Valid Loss:  0.0019107392290607095
Epoch:  120  	Training Loss: 0.0020269849337637424
Test Loss:  0.002145722508430481
Valid Loss:  0.0019106566905975342
Epoch:  121  	Training Loss: 0.0020268966909497976
Test Loss:  0.0021456442773342133
Valid Loss:  0.0019105711253359914
Epoch:  122  	Training Loss: 0.00202680635266006
Test Loss:  0.0021455613896250725
Valid Loss:  0.001910489285364747
Epoch:  123  	Training Loss: 0.002026718109846115
Test Loss:  0.0021454859524965286
Valid Loss:  0.0019104063976556063
Epoch:  124  	Training Loss: 0.0020266310311853886
Test Loss:  0.0021454058587551117
Valid Loss:  0.001910325139760971
Epoch:  125  	Training Loss: 0.0020265425555408
Test Loss:  0.0021453294903039932
Valid Loss:  0.0019102429505437613
Epoch:  126  	Training Loss: 0.002026455942541361
Test Loss:  0.002145246136933565
Valid Loss:  0.001910160994157195
Epoch:  127  	Training Loss: 0.002026369096711278
Test Loss:  0.0021451646462082863
Valid Loss:  0.0019100799690932035
Epoch:  128  	Training Loss: 0.002026280853897333
Test Loss:  0.0021450896747410297
Valid Loss:  0.0019099961500614882
Epoch:  129  	Training Loss: 0.0020261930767446756
Test Loss:  0.0021450109779834747
Valid Loss:  0.0019099132623523474
Epoch:  130  	Training Loss: 0.0020261043682694435
Test Loss:  0.0021449285559356213
Valid Loss:  0.0019098332850262523
Epoch:  131  	Training Loss: 0.0020260182209312916
Test Loss:  0.002144850790500641
Valid Loss:  0.0019097490003332496
Epoch:  132  	Training Loss: 0.0020259302109479904
Test Loss:  0.0021447744220495224
Valid Loss:  0.0019096685573458672
Epoch:  133  	Training Loss: 0.002025843132287264
Test Loss:  0.00214469525963068
Valid Loss:  0.0019095895113423467
Epoch:  134  	Training Loss: 0.0020257579162716866
Test Loss:  0.0021446216851472855
Valid Loss:  0.0019095074385404587
Epoch:  135  	Training Loss: 0.0020256731659173965
Test Loss:  0.0021445394959300756
Valid Loss:  0.0019094268791377544
Epoch:  136  	Training Loss: 0.0020255851559340954
Test Loss:  0.0021444617304950953
Valid Loss:  0.0019093456212431192
Epoch:  137  	Training Loss: 0.0020254994742572308
Test Loss:  0.0021443809382617474
Valid Loss:  0.0019092652946710587
Epoch:  138  	Training Loss: 0.002025413792580366
Test Loss:  0.002144303871318698
Valid Loss:  0.0019091840367764235
Epoch:  139  	Training Loss: 0.002025327645242214
Test Loss:  0.002144226338714361
Valid Loss:   28%|██▊       | 139/500 [01:37<02:04,  2.90it/s] 28%|██▊       | 141/500 [01:43<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:43<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:44<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:44<02:38,  2.22it/s] 30%|██▉       | 149/500 [01:44<01:59,  2.94it/s] 30%|███       | 151/500 [01:50<07:08,  1.23s/it] 31%|███       | 153/500 [01:51<05:05,  1.14it/s] 31%|███       | 155/500 [01:51<03:39,  1.57it/s] 31%|███▏      | 157/500 [01:51<02:39,  2.15it/s] 32%|███▏      | 159/500 [01:51<01:57,  2.90it/s] 32%|███▏      | 161/500 [01:57<06:50,  1.21s/it] 33%|███▎      | 163/500 [01:58<04:52,  1.15it/s] 33%|███▎      | 165/500 [01:58<03:30,  1.59it/s] 33%|███▎      | 167/500 [01:58<02:33,  2.18it/s] 34%|███▍      | 169/500 [01:58<01:52,  2.93it/s] 34%|███▍      | 171/500 [02:04<06:39,  1.21s/it] 35%|███▍      | 173/500 [02:05<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:05<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:05<02:28,  2.17it/s] 36%|███▌      | 179/500 [02:05<01:49,  2.92it/s] 36%|███▌      | 181/500 [02:11<06:25,  1.21s/it] 37%|███▋      | 183/500 [02:12<04:34,  1.15it/s] 37%|███▋      | 185/500 [02:12<03:17,  1.60it/s] 37%|███▋      | 187/500 [02:12<02:23,  2.18it/s] 38%|███▊      | 189/500 [02:12<01:45,  2.94it/s] 38%|███▊      | 191/500 [02:18<06:06,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:23,  1.17it/s] 39%|███▉      | 195/500 [02:19<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:19<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:19<01:41,  2.96it/s] 40%|████      | 201/500 [02:25<05:57,  1.19s/it] 41%|████      | 203/500 [02:25<04:14,  1.17it/s] 41%|████      | 205/500 [02:26<03:02,  1.61it/s] 41%|████▏     | 207/500 [02:26<02:12,  2.21it/s]0.0019091046415269375
Epoch:  140  	Training Loss: 0.002025242429226637
Test Loss:  0.0021441474091261625
Valid Loss:  0.001909023616462946
Epoch:  141  	Training Loss: 0.0020251558162271976
Test Loss:  0.0021440694108605385
Valid Loss:  0.0019089427078142762
Epoch:  142  	Training Loss: 0.0020250696688890457
Test Loss:  0.0021439932752400637
Valid Loss:  0.0019088637782260776
Epoch:  143  	Training Loss: 0.002024985384196043
Test Loss:  0.002143917139619589
Valid Loss:  0.0019087850814685225
Epoch:  144  	Training Loss: 0.002024902729317546
Test Loss:  0.002143843797966838
Valid Loss:  0.0019087065011262894
Epoch:  145  	Training Loss: 0.002024818444624543
Test Loss:  0.002143768360838294
Valid Loss:  0.0019086271058768034
Epoch:  146  	Training Loss: 0.002024734625592828
Test Loss:  0.002143692458048463
Valid Loss:  0.0019085502717643976
Epoch:  147  	Training Loss: 0.0020246508065611124
Test Loss:  0.002143620979040861
Valid Loss:  0.0019084705272689462
Epoch:  148  	Training Loss: 0.002024566987529397
Test Loss:  0.0021435474045574665
Valid Loss:  0.0019083925290033221
Epoch:  149  	Training Loss: 0.0020244834013283253
Test Loss:  0.0021434747613966465
Valid Loss:  0.0019083134829998016
Epoch:  150  	Training Loss: 0.0020243998151272535
Test Loss:  0.0021433972287923098
Valid Loss:  0.0019082357175648212
Epoch:  151  	Training Loss: 0.0020243173930794
Test Loss:  0.0021433266811072826
Valid Loss:  0.0019081560894846916
Epoch:  152  	Training Loss: 0.002024231944233179
Test Loss:  0.002143250312656164
Valid Loss:  0.0019080808851867914
Epoch:  153  	Training Loss: 0.0020241504535079002
Test Loss:  0.002143177669495344
Valid Loss:  0.001908004516735673
Epoch:  154  	Training Loss: 0.002024069894105196
Test Loss:  0.00214310921728611
Valid Loss:  0.0019079293124377728
Epoch:  155  	Training Loss: 0.002023989800363779
Test Loss:  0.0021430368069559336
Valid Loss:  0.0019078507320955396
Epoch:  156  	Training Loss: 0.0020239073783159256
Test Loss:  0.0021429667249321938
Valid Loss:  0.0019077734323218465
Epoch:  157  	Training Loss: 0.002023826353251934
Test Loss:  0.0021428961772471666
Valid Loss:  0.0019076978787779808
Epoch:  158  	Training Loss: 0.002023745561018586
Test Loss:  0.002142824698239565
Valid Loss:  0.0019076225580647588
Epoch:  159  	Training Loss: 0.002023664303123951
Test Loss:  0.002142752520740032
Valid Loss:  0.001907547703012824
Epoch:  160  	Training Loss: 0.0020235832780599594
Test Loss:  0.0021426836028695107
Valid Loss:  0.0019074707524850965
Epoch:  161  	Training Loss: 0.0020235043484717607
Test Loss:  0.0021426077000796795
Valid Loss:  0.0019073933362960815
Epoch:  162  	Training Loss: 0.00202342146076262
Test Loss:  0.0021425404120236635
Valid Loss:  0.001907315687276423
Epoch:  163  	Training Loss: 0.0020233429968357086
Test Loss:  0.0021424645092338324
Valid Loss:  0.0019072429277002811
Epoch:  164  	Training Loss: 0.0020232629030942917
Test Loss:  0.0021423932630568743
Valid Loss:  0.0019071680726483464
Epoch:  165  	Training Loss: 0.002023183275014162
Test Loss:  0.0021423231810331345
Valid Loss:  0.001907093683257699
Epoch:  166  	Training Loss: 0.0020231041125953197
Test Loss:  0.0021422505378723145
Valid Loss:  0.0019070175476372242
Epoch:  167  	Training Loss: 0.00202302448451519
Test Loss:  0.002142177429050207
Valid Loss:  0.001906942343339324
Epoch:  168  	Training Loss: 0.002022943226620555
Test Loss:  0.0021421057172119617
Valid Loss:  0.0019068665569648147
Epoch:  169  	Training Loss: 0.002022863831371069
Test Loss:  0.002142032142728567
Valid Loss:  0.0019067948451265693
Epoch:  170  	Training Loss: 0.0020227856002748013
Test Loss:  0.002141959499567747
Valid Loss:  0.0019067184766754508
Epoch:  171  	Training Loss: 0.0020227041095495224
Test Loss:  0.002141886157914996
Valid Loss:  0.0019066414097324014
Epoch:  172  	Training Loss: 0.0020226258784532547
Test Loss:  0.002141812816262245
Valid Loss:  0.0019065706292167306
Epoch:  173  	Training Loss: 0.0020225464832037687
Test Loss:  0.0021417387761175632
Valid Loss:  0.001906493678689003
Epoch:  174  	Training Loss: 0.0020224670879542828
Test Loss:  0.002141667529940605
Valid Loss:  0.0019064209191128612
Epoch:  175  	Training Loss: 0.002022388856858015
Test Loss:  0.0021415920928120613
Valid Loss:  0.0019063467625528574
Epoch:  176  	Training Loss: 0.00202231016010046
Test Loss:  0.0021415201481431723
Valid Loss:  0.0019062742358073592
Epoch:  177  	Training Loss: 0.0020222312305122614
Test Loss:  0.0021414440125226974
Valid Loss:  0.0019061984494328499
Epoch:  178  	Training Loss: 0.0020221516024321318
Test Loss:  0.0021413741633296013
Valid Loss:  0.0019061241764575243
Epoch:  179  	Training Loss: 0.0020220736041665077
Test Loss:  0.0021413005888462067
Valid Loss:  0.0019060515332967043
Epoch:  180  	Training Loss: 0.0020219949074089527
Test Loss:  0.002141225151717663
Valid Loss:  0.0019059774931520224
Epoch:  181  	Training Loss: 0.0020219162106513977
Test Loss:  0.0021411508787423372
Valid Loss:  0.0019059018231928349
Epoch:  182  	Training Loss: 0.0020218375138938427
Test Loss:  0.002141079865396023
Valid Loss:  0.0019058285979554057
Epoch:  183  	Training Loss: 0.0020217602141201496
Test Loss:  0.0021410086192190647
Valid Loss:  0.0019057556055486202
Epoch:  184  	Training Loss: 0.0020216822158545256
Test Loss:  0.002140938537195325
Valid Loss:  0.0019056826131418347
Epoch:  185  	Training Loss: 0.002021603984758258
Test Loss:  0.002140861703082919
Valid Loss:  0.0019056069431826472
Epoch:  186  	Training Loss: 0.0020215262193232775
Test Loss:  0.0021407899912446737
Valid Loss:  0.001905536511912942
Epoch:  187  	Training Loss: 0.002021449152380228
Test Loss:  0.0021407208405435085
Valid Loss:  0.001905461773276329
Epoch:  188  	Training Loss: 0.0020213713869452477
Test Loss:  0.002140647731721401
Valid Loss:  0.0019053902942687273
Epoch:  189  	Training Loss: 0.0020212940871715546
Test Loss:  0.0021405741572380066
Valid Loss:  0.0019053176511079073
Epoch:  190  	Training Loss: 0.002021217253059149
Test Loss:  0.0021405040752142668
Valid Loss:  0.0019052441930398345
Epoch:  191  	Training Loss: 0.0020211385563015938
Test Loss:  0.0021404314320534468
Valid Loss:  0.001905167126096785
Epoch:  192  	Training Loss: 0.0020210621878504753
Test Loss:  0.0021403601858764887
Valid Loss:  0.0019050982082262635
Epoch:  193  	Training Loss: 0.002020983723923564
Test Loss:  0.002140287309885025
Valid Loss:  0.0019050282426178455
Epoch:  194  	Training Loss: 0.002020907122641802
Test Loss:  0.002140216063708067
Valid Loss:  0.0019049542024731636
Epoch:  195  	Training Loss: 0.0020208305213600397
Test Loss:  0.0021401422563940287
Valid Loss:  0.001904879929497838
Epoch:  196  	Training Loss: 0.0020207539200782776
Test Loss:  0.002140072640031576
Valid Loss:  0.001904807984828949
Epoch:  197  	Training Loss: 0.00202067568898201
Test Loss:  0.002140000695362687
Valid Loss:  0.0019047365058213472
Epoch:  198  	Training Loss: 0.0020205979235470295
Test Loss:  0.0021399296820163727
Valid Loss:  0.0019046647939831018
Epoch:  199  	Training Loss: 0.0020205224864184856
Test Loss:  0.0021398584358394146
Valid Loss:  0.001904593431390822
Epoch:  200  	Training Loss: 0.0020204465836286545
Test Loss:  0.0021397890523076057
Valid Loss:  0.0019045218359678984
Epoch:  201  	Training Loss: 0.0020203678868710995
Test Loss:  0.002139716176316142
Valid Loss:  0.0019044470973312855
Epoch:  202  	Training Loss: 0.0020202919840812683
Test Loss:  0.002139647491276264
Valid Loss:  0.0019043759675696492
Epoch:  203  	Training Loss: 0.0020202158484607935
Test Loss:  0.002139575080946088
Valid Loss:  0.0019043037900701165
Epoch:  204  	Training Loss: 0.0020201413426548243
Test Loss:  0.0021395047660917044
Valid Loss:  0.0019042323110625148
Epoch:  205  	Training Loss: 0.002020064275711775
Test Loss:  0.0021394353825598955
Valid Loss:  0.0019041604828089476
Epoch:  206  	Training Loss: 0.002019987441599369
Test Loss:  0.0021393666975200176
Valid Loss:  0.0019040891202166677
Epoch:  207  	Training Loss: 0.002019911538809538
Test Loss:  0.0021392912603914738
Valid Loss:  0.0019040193874388933
Epoch:  208  	Training Loss: 0.002019836101680994
Test Loss:  0.0021392214111983776
 42%|████▏     | 209/500 [02:26<01:38,  2.97it/s] 42%|████▏     | 211/500 [02:32<05:43,  1.19s/it] 43%|████▎     | 213/500 [02:32<04:04,  1.17it/s] 43%|████▎     | 215/500 [02:32<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:33<02:07,  2.21it/s] 44%|████▍     | 219/500 [02:33<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:39<05:34,  1.20s/it] 45%|████▍     | 223/500 [02:39<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:39<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:40<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:40<01:32,  2.92it/s] 46%|████▌     | 231/500 [02:46<05:29,  1.22s/it] 47%|████▋     | 233/500 [02:46<03:56,  1.13it/s] 47%|████▋     | 235/500 [02:47<02:50,  1.55it/s] 47%|████▋     | 237/500 [02:47<02:04,  2.11it/s] 48%|████▊     | 239/500 [02:47<01:31,  2.85it/s] 48%|████▊     | 241/500 [02:54<05:20,  1.24s/it] 49%|████▊     | 243/500 [02:54<03:48,  1.12it/s] 49%|████▉     | 245/500 [02:54<02:43,  1.56it/s] 49%|████▉     | 247/500 [02:54<01:58,  2.13it/s] 50%|████▉     | 249/500 [02:54<01:27,  2.88it/s] 50%|█████     | 251/500 [03:01<05:00,  1.21s/it] 51%|█████     | 253/500 [03:01<03:34,  1.15it/s] 51%|█████     | 255/500 [03:01<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:01<01:51,  2.19it/s] 52%|█████▏    | 259/500 [03:01<01:21,  2.95it/s] 52%|█████▏    | 261/500 [03:07<04:48,  1.21s/it] 53%|█████▎    | 263/500 [03:08<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:08<02:26,  1.60it/s] 53%|█████▎    | 267/500 [03:08<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:08<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:14<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:14<03:13,  1.18it/s] 55%|█████▌    | 275/500 [03:15<02:18,  1.63it/s]Valid Loss:  0.001903945580124855
Epoch:  209  	Training Loss: 0.002019760198891163
Test Loss:  0.0021391501650214195
Valid Loss:  0.0019038717728108168
Epoch:  210  	Training Loss: 0.002019682666286826
Test Loss:  0.0021390789188444614
Valid Loss:  0.0019038041355088353
Epoch:  211  	Training Loss: 0.0020196072291582823
Test Loss:  0.002139007207006216
Valid Loss:  0.0019037334714084864
Epoch:  212  	Training Loss: 0.0020195324905216694
Test Loss:  0.0021389364264905453
Valid Loss:  0.001903662458062172
Epoch:  213  	Training Loss: 0.0020194558892399073
Test Loss:  0.0021388642489910126
Valid Loss:  0.001903590396977961
Epoch:  214  	Training Loss: 0.0020193811506032944
Test Loss:  0.0021387937013059855
Valid Loss:  0.0019035201985388994
Epoch:  215  	Training Loss: 0.002019306877627969
Test Loss:  0.002138726646080613
Valid Loss:  0.0019034526776522398
Epoch:  216  	Training Loss: 0.0020192316733300686
Test Loss:  0.002138653304427862
Valid Loss:  0.0019033800344914198
Epoch:  217  	Training Loss: 0.002019156003370881
Test Loss:  0.0021385822910815477
Valid Loss:  0.0019033091375604272
Epoch:  218  	Training Loss: 0.002019081264734268
Test Loss:  0.0021385124418884516
Valid Loss:  0.0019032403361052275
Epoch:  219  	Training Loss: 0.0020190062932670116
Test Loss:  0.002138439565896988
Valid Loss:  0.001903169322758913
Epoch:  220  	Training Loss: 0.002018930856138468
Test Loss:  0.0021383699495345354
Valid Loss:  0.001903095981106162
Epoch:  221  	Training Loss: 0.002018856117501855
Test Loss:  0.002138297539204359
Valid Loss:  0.0019030272960662842
Epoch:  222  	Training Loss: 0.0020187809132039547
Test Loss:  0.0021382279228419065
Valid Loss:  0.0019029546529054642
Epoch:  223  	Training Loss: 0.002018705941736698
Test Loss:  0.002138161100447178
Valid Loss:  0.001902888878248632
Epoch:  224  	Training Loss: 0.0020186312031000853
Test Loss:  0.002138090319931507
Valid Loss:  0.0019028157694265246
Epoch:  225  	Training Loss: 0.0020185578614473343
Test Loss:  0.0021380221005529165
Valid Loss:  0.0019027478992938995
Epoch:  226  	Training Loss: 0.002018484054133296
Test Loss:  0.002137949224561453
Valid Loss:  0.0019026771187782288
Epoch:  227  	Training Loss: 0.002018410013988614
Test Loss:  0.0021378803066909313
Valid Loss:  0.0019026044756174088
Epoch:  228  	Training Loss: 0.0020183345768600702
Test Loss:  0.0021378113888204098
Valid Loss:  0.00190253765322268
Epoch:  229  	Training Loss: 0.0020182610023766756
Test Loss:  0.00213774386793375
Valid Loss:  0.0019024669891223311
Epoch:  230  	Training Loss: 0.0020181876607239246
Test Loss:  0.002137674018740654
Valid Loss:  0.001902397838421166
Epoch:  231  	Training Loss: 0.002018111292272806
Test Loss:  0.002137604868039489
Valid Loss:  0.0019023288041353226
Epoch:  232  	Training Loss: 0.002018036786466837
Test Loss:  0.002137532690539956
Valid Loss:  0.0019022580236196518
Epoch:  233  	Training Loss: 0.002017964143306017
Test Loss:  0.0021374623756855726
Valid Loss:  0.0019021902699023485
Epoch:  234  	Training Loss: 0.0020178903359919786
Test Loss:  0.0021373929921537638
Valid Loss:  0.0019021198386326432
Epoch:  235  	Training Loss: 0.002017817460000515
Test Loss:  0.002137323608621955
Valid Loss:  0.0019020518520846963
Epoch:  236  	Training Loss: 0.002017742721363902
Test Loss:  0.002137254923582077
Valid Loss:  0.0019019830506294966
Epoch:  237  	Training Loss: 0.0020176696125417948
Test Loss:  0.0021371860057115555
Valid Loss:  0.001901912735775113
Epoch:  238  	Training Loss: 0.002017595572397113
Test Loss:  0.002137115690857172
Valid Loss:  0.001901844865642488
Epoch:  239  	Training Loss: 0.0020175217650830746
Test Loss:  0.002137046307325363
Valid Loss:  0.0019017738522961736
Epoch:  240  	Training Loss: 0.0020174486562609673
Test Loss:  0.0021369783207774162
Valid Loss:  0.001901705632917583
Epoch:  241  	Training Loss: 0.0020173750817775726
Test Loss:  0.002136906608939171
Valid Loss:  0.0019016377627849579
Epoch:  242  	Training Loss: 0.002017302205786109
Test Loss:  0.002136839088052511
Valid Loss:  0.0019015653524547815
Epoch:  243  	Training Loss: 0.002017229562625289
Test Loss:  0.002136772032827139
Valid Loss:  0.0019014996942132711
Epoch:  244  	Training Loss: 0.002017156220972538
Test Loss:  0.002136704046279192
Valid Loss:  0.0019014314748346806
Epoch:  245  	Training Loss: 0.0020170833449810743
Test Loss:  0.002136634197086096
Valid Loss:  0.0019013626733794808
Epoch:  246  	Training Loss: 0.0020170097704976797
Test Loss:  0.002136567374691367
Valid Loss:  0.0019012943375855684
Epoch:  247  	Training Loss: 0.002016938291490078
Test Loss:  0.002136498922482133
Valid Loss:  0.0019012270495295525
Epoch:  248  	Training Loss: 0.0020168647170066833
Test Loss:  0.0021364286076277494
Valid Loss:  0.0019011576659977436
Epoch:  249  	Training Loss: 0.0020167934708297253
Test Loss:  0.002136357594281435
Valid Loss:  0.0019010896794497967
Epoch:  250  	Training Loss: 0.0020167194306850433
Test Loss:  0.00213629100471735
Valid Loss:  0.001901020877994597
Epoch:  251  	Training Loss: 0.0020166460890322924
Test Loss:  0.0021362255793064833
Valid Loss:  0.0019009518437087536
Epoch:  252  	Training Loss: 0.0020165741443634033
Test Loss:  0.0021361568942666054
Valid Loss:  0.0019008845556527376
Epoch:  253  	Training Loss: 0.0020165028981864452
Test Loss:  0.002136088442057371
Valid Loss:  0.00190081843174994
Epoch:  254  	Training Loss: 0.002016430487856269
Test Loss:  0.0021360227838158607
Valid Loss:  0.001900750445201993
Epoch:  255  	Training Loss: 0.0020163566805422306
Test Loss:  0.0021359575912356377
Valid Loss:  0.0019006829243153334
Epoch:  256  	Training Loss: 0.0020162854343652725
Test Loss:  0.0021358910016715527
Valid Loss:  0.0019006174989044666
Epoch:  257  	Training Loss: 0.002016214421018958
Test Loss:  0.002135822083801031
Valid Loss:  0.0019005495123565197
Epoch:  258  	Training Loss: 0.002016142476350069
Test Loss:  0.002135756891220808
Valid Loss:  0.0019004805944859982
Epoch:  259  	Training Loss: 0.0020160709973424673
Test Loss:  0.0021356898359954357
Valid Loss:  0.0019004158675670624
Epoch:  260  	Training Loss: 0.002015998587012291
Test Loss:  0.002135620452463627
Valid Loss:  0.0019003469496965408
Epoch:  261  	Training Loss: 0.0020159254781901836
Test Loss:  0.0021355529315769672
Valid Loss:  0.001900278264656663
Epoch:  262  	Training Loss: 0.0020158556289970875
Test Loss:  0.002135487273335457
Valid Loss:  0.0019002151675522327
Epoch:  263  	Training Loss: 0.0020157834514975548
Test Loss:  0.0021354216150939465
Valid Loss:  0.0019001455511897802
Epoch:  264  	Training Loss: 0.0020157122053205967
Test Loss:  0.002135352697223425
Valid Loss:  0.0019000795437023044
Epoch:  265  	Training Loss: 0.002015640027821064
Test Loss:  0.0021352835465222597
Valid Loss:  0.001900010509416461
Epoch:  266  	Training Loss: 0.0020155692473053932
Test Loss:  0.0021352178882807493
Valid Loss:  0.0018999464809894562
Epoch:  267  	Training Loss: 0.002015498233959079
Test Loss:  0.0021351478062570095
Valid Loss:  0.0018998798914253712
Epoch:  268  	Training Loss: 0.002015424659475684
Test Loss:  0.002135080751031637
Valid Loss:  0.0018998140003532171
Epoch:  269  	Training Loss: 0.002015355508774519
Test Loss:  0.002135012997314334
Valid Loss:  0.0018997474107891321
Epoch:  270  	Training Loss: 0.0020152833312749863
Test Loss:  0.0021349438466131687
Valid Loss:  0.0018996777944266796
Epoch:  271  	Training Loss: 0.002015212783589959
Test Loss:  0.002134880516678095
Valid Loss:  0.0018996119033545256
Epoch:  272  	Training Loss: 0.00201514083892107
Test Loss:  0.002134814392775297
Valid Loss:  0.0018995460122823715
Epoch:  273  	Training Loss: 0.0020150691270828247
Test Loss:  0.00213474384509027
Valid Loss:  0.001899478491395712
Epoch:  274  	Training Loss: 0.002014999045059085
Test Loss:  0.002134676557034254
Valid Loss:  0.0018994139973074198
Epoch:  275  	Training Loss: 0.002014927566051483
Test Loss:  0.002134609967470169
Valid Loss:  0.0018993483390659094
Epoch:  276  	Training Loss: 0.0020148579496890306
Test Loss:  0.002134540816769004
Valid Loss:  0.001899281283840537
Epoch:  277  	Training Loss: 0.0020147869363427162
Test Loss:  0.0021344716660678387
 55%|█████▌    | 277/500 [03:15<01:40,  2.23it/s] 56%|█████▌    | 279/500 [03:15<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:21<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:21<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:21<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:22<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:22<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:28<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:28<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:28<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:28<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:29<01:07,  2.98it/s] 60%|██████    | 301/500 [03:35<04:00,  1.21s/it] 61%|██████    | 303/500 [03:35<02:50,  1.15it/s] 61%|██████    | 305/500 [03:35<02:02,  1.60it/s] 61%|██████▏   | 307/500 [03:36<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:36<01:05,  2.93it/s] 62%|██████▏   | 311/500 [03:42<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:42<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:42<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:42<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:43<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:49<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:49<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:49<01:47,  1.64it/s] 65%|██████▌   | 327/500 [03:49<01:18,  2.22it/s] 66%|██████▌   | 329/500 [03:49<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:56<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:56<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:56<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:56<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:56<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:03<03:11,  1.20s/it] 69%|██████▊   | 343/500 [04:03<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:03<01:36,  1.60it/s]Valid Loss:  0.0018992158584296703
Epoch:  278  	Training Loss: 0.002014715690165758
Test Loss:  0.00213440228253603
Valid Loss:  0.0018991500837728381
Epoch:  279  	Training Loss: 0.0020146435126662254
Test Loss:  0.002134336158633232
Valid Loss:  0.0018990826793015003
Epoch:  280  	Training Loss: 0.0020145736634731293
Test Loss:  0.00213426910340786
Valid Loss:  0.0018990188837051392
Epoch:  281  	Training Loss: 0.0020145021844655275
Test Loss:  0.0021342027466744184
Valid Loss:  0.001898950431495905
Epoch:  282  	Training Loss: 0.002014432568103075
Test Loss:  0.00213413592427969
Valid Loss:  0.001898883143439889
Epoch:  283  	Training Loss: 0.002014361321926117
Test Loss:  0.002134067937731743
Valid Loss:  0.0018988203955814242
Epoch:  284  	Training Loss: 0.0020142914727330208
Test Loss:  0.0021340008825063705
Valid Loss:  0.0018987536896020174
Epoch:  285  	Training Loss: 0.002014219993725419
Test Loss:  0.0021339335944503546
Valid Loss:  0.0018986868672072887
Epoch:  286  	Training Loss: 0.0020141510758548975
Test Loss:  0.002133866073563695
Valid Loss:  0.0018986222567036748
Epoch:  287  	Training Loss: 0.002014080761000514
Test Loss:  0.002133794594556093
Valid Loss:  0.0018985543865710497
Epoch:  288  	Training Loss: 0.002014010678976774
Test Loss:  0.0021337291691452265
Valid Loss:  0.0018984903581440449
Epoch:  289  	Training Loss: 0.0020139398984611034
Test Loss:  0.0021336644422262907
Valid Loss:  0.0018984228372573853
Epoch:  290  	Training Loss: 0.0020138700492680073
Test Loss:  0.0021335924975574017
Valid Loss:  0.001898359740152955
Epoch:  291  	Training Loss: 0.002013798803091049
Test Loss:  0.0021335273049771786
Valid Loss:  0.001898291171528399
Epoch:  292  	Training Loss: 0.0020137287210673094
Test Loss:  0.0021334602497518063
Valid Loss:  0.0018982270266860723
Epoch:  293  	Training Loss: 0.0020136581733822823
Test Loss:  0.0021333901677280664
Valid Loss:  0.0018981643952429295
Epoch:  294  	Training Loss: 0.0020135901868343353
Test Loss:  0.0021333214826881886
Valid Loss:  0.0018980979220941663
Epoch:  295  	Training Loss: 0.0020135201048105955
Test Loss:  0.002133258618414402
Valid Loss:  0.0018980312161147594
Epoch:  296  	Training Loss: 0.0020134500227868557
Test Loss:  0.002133192727342248
Valid Loss:  0.0018979671876877546
Epoch:  297  	Training Loss: 0.0020133797079324722
Test Loss:  0.002133123343810439
Valid Loss:  0.001897901063784957
Epoch:  298  	Training Loss: 0.0020133093930780888
Test Loss:  0.0021330579183995724
Valid Loss:  0.001897835754789412
Epoch:  299  	Training Loss: 0.0020132409408688545
Test Loss:  0.0021329903975129128
Valid Loss:  0.001897769165225327
Epoch:  300  	Training Loss: 0.0020131710916757584
Test Loss:  0.002132921479642391
Valid Loss:  0.0018977047875523567
Epoch:  301  	Training Loss: 0.002013100776821375
Test Loss:  0.002132854424417019
Valid Loss:  0.0018976377323269844
Epoch:  302  	Training Loss: 0.0020130330231040716
Test Loss:  0.0021327901631593704
Valid Loss:  0.0018975764978677034
Epoch:  303  	Training Loss: 0.0020129610784351826
Test Loss:  0.0021327249705791473
Valid Loss:  0.001897512236610055
Epoch:  304  	Training Loss: 0.0020128926262259483
Test Loss:  0.0021326581481844187
Valid Loss:  0.001897446229122579
Epoch:  305  	Training Loss: 0.002012822078540921
Test Loss:  0.002132589230313897
Valid Loss:  0.0018973834812641144
Epoch:  306  	Training Loss: 0.0020127533935010433
Test Loss:  0.0021325256675481796
Valid Loss:  0.0018973172409459949
Epoch:  307  	Training Loss: 0.0020126844756305218
Test Loss:  0.00213245814666152
Valid Loss:  0.0018972540274262428
Epoch:  308  	Training Loss: 0.002012615092098713
Test Loss:  0.0021323917899280787
Valid Loss:  0.0018971863901242614
Epoch:  309  	Training Loss: 0.002012545010074973
Test Loss:  0.0021323247347027063
Valid Loss:  0.0018971231766045094
Epoch:  310  	Training Loss: 0.0020124767906963825
Test Loss:  0.0021322595421224833
Valid Loss:  0.00189705821685493
Epoch:  311  	Training Loss: 0.002012407872825861
Test Loss:  0.002132195048034191
Valid Loss:  0.0018969944212585688
Epoch:  312  	Training Loss: 0.0020123368594795465
Test Loss:  0.0021321263629943132
Valid Loss:  0.0018969266675412655
Epoch:  313  	Training Loss: 0.002012268640100956
Test Loss:  0.002132060471922159
Valid Loss:  0.0018968652002513409
Epoch:  314  	Training Loss: 0.0020122004207223654
Test Loss:  0.002131993416696787
Valid Loss:  0.0018967994255945086
Epoch:  315  	Training Loss: 0.0020121312700212
Test Loss:  0.002131930785253644
Valid Loss:  0.001896735979244113
Epoch:  316  	Training Loss: 0.0020120637491345406
Test Loss:  0.0021318630315363407
Valid Loss:  0.001896671368740499
Epoch:  317  	Training Loss: 0.0020119938999414444
Test Loss:  0.002131798304617405
Valid Loss:  0.0018966082716360688
Epoch:  318  	Training Loss: 0.002011924749240279
Test Loss:  0.0021317319478839636
Valid Loss:  0.0018965427298098803
Epoch:  319  	Training Loss: 0.002011855598539114
Test Loss:  0.0021316632628440857
Valid Loss:  0.001896475674584508
Epoch:  320  	Training Loss: 0.0020117866806685925
Test Loss:  0.0021315990015864372
Valid Loss:  0.001896414440125227
Epoch:  321  	Training Loss: 0.002011717762798071
Test Loss:  0.0021315317135304213
Valid Loss:  0.0018963507609441876
Epoch:  322  	Training Loss: 0.002011649776250124
Test Loss:  0.002131467219442129
Valid Loss:  0.0018962863832712173
Epoch:  323  	Training Loss: 0.0020115806255489588
Test Loss:  0.002131402026861906
Valid Loss:  0.0018962236354127526
Epoch:  324  	Training Loss: 0.0020115128718316555
Test Loss:  0.002131338231265545
Valid Loss:  0.0018961585592478514
Epoch:  325  	Training Loss: 0.0020114444196224213
Test Loss:  0.002131270244717598
Valid Loss:  0.0018960944144055247
Epoch:  326  	Training Loss: 0.002011375967413187
Test Loss:  0.0021312052849680185
Valid Loss:  0.001896030269563198
Epoch:  327  	Training Loss: 0.002011307282373309
Test Loss:  0.002131139859557152
Valid Loss:  0.0018959683366119862
Epoch:  328  	Training Loss: 0.002011239528656006
Test Loss:  0.0021310742013156414
Valid Loss:  0.0018959033768624067
Epoch:  329  	Training Loss: 0.0020111703779548407
Test Loss:  0.0021310097072273493
Valid Loss:  0.0018958385335281491
Epoch:  330  	Training Loss: 0.002011102857068181
Test Loss:  0.0021309431176632643
Valid Loss:  0.0018957748543471098
Epoch:  331  	Training Loss: 0.0020110332407057285
Test Loss:  0.002130878623574972
Valid Loss:  0.0018957080319523811
Epoch:  332  	Training Loss: 0.0020109652541577816
Test Loss:  0.0021308124996721745
Valid Loss:  0.0018956493586301804
Epoch:  333  	Training Loss: 0.0020108968019485474
Test Loss:  0.0021307477727532387
Valid Loss:  0.0018955832347273827
Epoch:  334  	Training Loss: 0.0020108288154006004
Test Loss:  0.0021306807175278664
Valid Loss:  0.0018955185078084469
Epoch:  335  	Training Loss: 0.002010761760175228
Test Loss:  0.0021306155249476433
Valid Loss:  0.0018954584375023842
Epoch:  336  	Training Loss: 0.002010693307965994
Test Loss:  0.002130551729351282
Valid Loss:  0.001895392662845552
Epoch:  337  	Training Loss: 0.002010625321418047
Test Loss:  0.0021304860711097717
Valid Loss:  0.0018953274702653289
Epoch:  338  	Training Loss: 0.0020105573348701
Test Loss:  0.0021304208785295486
Valid Loss:  0.001895266119390726
Epoch:  339  	Training Loss: 0.0020104902796447277
Test Loss:  0.002130357548594475
Valid Loss:  0.001895199529826641
Epoch:  340  	Training Loss: 0.002010421361774206
Test Loss:  0.00213029095903039
Valid Loss:  0.0018951375968754292
Epoch:  341  	Training Loss: 0.0020103531423956156
Test Loss:  0.002130226232111454
Valid Loss:  0.0018950765952467918
Epoch:  342  	Training Loss: 0.0020102853886783123
Test Loss:  0.00213016290217638
Valid Loss:  0.0018950097728520632
Epoch:  343  	Training Loss: 0.0020102167036384344
Test Loss:  0.002130096312612295
Valid Loss:  0.0018949465593323112
Epoch:  344  	Training Loss: 0.0020101498812437057
Test Loss:  0.0021300320513546467
Valid Loss:  0.0018948852084577084
Epoch:  345  	Training Loss: 0.0020100821275264025
Test Loss:  0.002129967790096998
Valid Loss:  0.0018948197830468416
Epoch:  346  	Training Loss: 0.002010013908147812
Test Loss:  0.002129902131855488
 69%|██████▉   | 347/500 [04:03<01:09,  2.19it/s] 70%|██████▉   | 349/500 [04:03<00:51,  2.95it/s] 70%|███████   | 351/500 [04:10<02:58,  1.20s/it] 71%|███████   | 353/500 [04:10<02:06,  1.17it/s] 71%|███████   | 355/500 [04:10<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:10<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:10<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:16<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:17<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:17<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:17<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:17<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:23<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:24<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:24<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:24<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:24<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:30<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:30<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:31<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:31<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:31<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:37<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:37<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:37<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:38<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:38<00:34,  2.96it/s] 80%|████████  | 401/500 [04:44<01:56,  1.17s/it] 81%|████████  | 403/500 [04:44<01:21,  1.19it/s] 81%|████████  | 405/500 [04:44<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:44<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:45<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:51<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:51<01:14,  1.16it/s]Valid Loss:  0.0018947585485875607
Epoch:  347  	Training Loss: 0.002009945921599865
Test Loss:  0.002129839500412345
Valid Loss:  0.0018946987111121416
Epoch:  348  	Training Loss: 0.002009877236559987
Test Loss:  0.00212977547198534
Valid Loss:  0.0018946302589029074
Epoch:  349  	Training Loss: 0.0020098111126571894
Test Loss:  0.002129710279405117
Valid Loss:  0.0018945676274597645
Epoch:  350  	Training Loss: 0.0020097410306334496
Test Loss:  0.0021296434570103884
Valid Loss:  0.0018945065094158053
Epoch:  351  	Training Loss: 0.002009674906730652
Test Loss:  0.002129580359905958
Valid Loss:  0.001894440851174295
Epoch:  352  	Training Loss: 0.0020096059888601303
Test Loss:  0.0021295174956321716
Valid Loss:  0.0018943795002996922
Epoch:  353  	Training Loss: 0.0020095400977879763
Test Loss:  0.0021294511388987303
Valid Loss:  0.0018943166360259056
Epoch:  354  	Training Loss: 0.002009472344070673
Test Loss:  0.0021293903701007366
Valid Loss:  0.0018942526075989008
Epoch:  355  	Training Loss: 0.0020094062201678753
Test Loss:  0.0021293270401656628
Valid Loss:  0.001894187880679965
Epoch:  356  	Training Loss: 0.0020093389321118593
Test Loss:  0.0021292611490935087
Valid Loss:  0.0018941267626360059
Epoch:  357  	Training Loss: 0.0020092707127332687
Test Loss:  0.0021291961893439293
Valid Loss:  0.001894064829684794
Epoch:  358  	Training Loss: 0.0020092043559998274
Test Loss:  0.00212913379073143
Valid Loss:  0.001894001616165042
Epoch:  359  	Training Loss: 0.0020091368351131678
Test Loss:  0.0021290690638124943
Valid Loss:  0.0018939413130283356
Epoch:  360  	Training Loss: 0.00200907071121037
Test Loss:  0.002129004569724202
Valid Loss:  0.0018938747234642506
Epoch:  361  	Training Loss: 0.002009004121646285
Test Loss:  0.002128942869603634
Valid Loss:  0.0018938167486339808
Epoch:  362  	Training Loss: 0.0020089375320822
Test Loss:  0.0021288758143782616
Valid Loss:  0.0018937535351142287
Epoch:  363  	Training Loss: 0.0020088693127036095
Test Loss:  0.0021288120187819004
Valid Loss:  0.0018936896231025457
Epoch:  364  	Training Loss: 0.0020088027231395245
Test Loss:  0.0021287454292178154
Valid Loss:  0.0018936276901513338
Epoch:  365  	Training Loss: 0.0020087368320673704
Test Loss:  0.0021286814007908106
Valid Loss:  0.0018935638945549726
Epoch:  366  	Training Loss: 0.0020086681470274925
Test Loss:  0.002128619235008955
Valid Loss:  0.0018935042899101973
Epoch:  367  	Training Loss: 0.0020086015574634075
Test Loss:  0.00212855520658195
Valid Loss:  0.0018934416584670544
Epoch:  368  	Training Loss: 0.002008535200729966
Test Loss:  0.00212849210947752
Valid Loss:  0.0018933778628706932
Epoch:  369  	Training Loss: 0.00200846791267395
Test Loss:  0.0021284259855747223
Valid Loss:  0.001893314765766263
Epoch:  370  	Training Loss: 0.0020084024872630835
Test Loss:  0.002128365682438016
Valid Loss:  0.0018932545790448785
Epoch:  371  	Training Loss: 0.00200833473354578
Test Loss:  0.0021282965317368507
Valid Loss:  0.0018931906670331955
Epoch:  372  	Training Loss: 0.002008268143981695
Test Loss:  0.0021282313391566277
Valid Loss:  0.001893130480311811
Epoch:  373  	Training Loss: 0.0020082013215869665
Test Loss:  0.0021281689405441284
Valid Loss:  0.001893065171316266
Epoch:  374  	Training Loss: 0.002008136361837387
Test Loss:  0.002128107473254204
Valid Loss:  0.001893006032332778
Epoch:  375  	Training Loss: 0.0020080702379345894
Test Loss:  0.0021280432119965553
Valid Loss:  0.0018929438665509224
Epoch:  376  	Training Loss: 0.0020080041140317917
Test Loss:  0.0021279798820614815
Valid Loss:  0.001892882864922285
Epoch:  377  	Training Loss: 0.0020079370588064194
Test Loss:  0.0021279146894812584
Valid Loss:  0.0018928213976323605
Epoch:  378  	Training Loss: 0.0020078723318874836
Test Loss:  0.0021278487984091043
Valid Loss:  0.0018927592318505049
Epoch:  379  	Training Loss: 0.002007804811000824
Test Loss:  0.002127787098288536
Valid Loss:  0.0018926982302218676
Epoch:  380  	Training Loss: 0.0020077372901141644
Test Loss:  0.0021277223713696003
Valid Loss:  0.0018926344346255064
Epoch:  381  	Training Loss: 0.0020076725631952286
Test Loss:  0.0021276555489748716
Valid Loss:  0.0018925719195976853
Epoch:  382  	Training Loss: 0.002007606439292431
Test Loss:  0.0021275971084833145
Valid Loss:  0.0018925112672150135
Epoch:  383  	Training Loss: 0.0020075407810509205
Test Loss:  0.002127532847225666
Valid Loss:  0.0018924493342638016
Epoch:  384  	Training Loss: 0.0020074741914868355
Test Loss:  0.0021274718455970287
Valid Loss:  0.0018923883326351643
Epoch:  385  	Training Loss: 0.0020074087660759687
Test Loss:  0.0021274101454764605
Valid Loss:  0.0018923276802524924
Epoch:  386  	Training Loss: 0.002007342642173171
Test Loss:  0.0021273454185575247
Valid Loss:  0.0018922635354101658
Epoch:  387  	Training Loss: 0.0020072779152542353
Test Loss:  0.0021272823214530945
Valid Loss:  0.001892204163596034
Epoch:  388  	Training Loss: 0.002007210161536932
Test Loss:  0.0021272203885018826
Valid Loss:  0.0018921425798907876
Epoch:  389  	Training Loss: 0.002007144968956709
Test Loss:  0.0021271563600748777
Valid Loss:  0.0018920815782621503
Epoch:  390  	Training Loss: 0.0020070765167474747
Test Loss:  0.0021270932629704475
Valid Loss:  0.001892018597573042
Epoch:  391  	Training Loss: 0.002007013652473688
Test Loss:  0.0021270308643579483
Valid Loss:  0.0018919548019766808
Epoch:  392  	Training Loss: 0.002006946597248316
Test Loss:  0.0021269686985760927
Valid Loss:  0.0018918924033641815
Epoch:  393  	Training Loss: 0.0020068821031600237
Test Loss:  0.0021269037388265133
Valid Loss:  0.001891836291179061
Epoch:  394  	Training Loss: 0.0020068150479346514
Test Loss:  0.002126841340214014
Valid Loss:  0.0018917713314294815
Epoch:  395  	Training Loss: 0.0020067491568624973
Test Loss:  0.002126778243109584
Valid Loss:  0.0018917127745226026
Epoch:  396  	Training Loss: 0.0020066844299435616
Test Loss:  0.0021267160773277283
Valid Loss:  0.001891652587801218
Epoch:  397  	Training Loss: 0.00200661807321012
Test Loss:  0.002126651117578149
Valid Loss:  0.001891590771265328
Epoch:  398  	Training Loss: 0.0020065531134605408
Test Loss:  0.0021265875548124313
Valid Loss:  0.0018915280234068632
Epoch:  399  	Training Loss: 0.0020064879208803177
Test Loss:  0.0021265274845063686
Valid Loss:  0.0018914659740403295
Epoch:  400  	Training Loss: 0.00200642179697752
Test Loss:  0.0021264622919261456
Valid Loss:  0.0018914045067504048
Epoch:  401  	Training Loss: 0.0020063556730747223
Test Loss:  0.002126402920112014
Valid Loss:  0.0018913447856903076
Epoch:  402  	Training Loss: 0.002006290713325143
Test Loss:  0.0021263386588543653
Valid Loss:  0.001891280640847981
Epoch:  403  	Training Loss: 0.0020062262192368507
Test Loss:  0.0021262741647660732
Valid Loss:  0.0018912199884653091
Epoch:  404  	Training Loss: 0.0020061598625034094
Test Loss:  0.0021262106020003557
Valid Loss:  0.0018911592196673155
Epoch:  405  	Training Loss: 0.0020060946699231863
Test Loss:  0.002126152627170086
Valid Loss:  0.001891101710498333
Epoch:  406  	Training Loss: 0.0020060287788510323
Test Loss:  0.0021260888315737247
Valid Loss:  0.00189103779848665
Epoch:  407  	Training Loss: 0.002005963120609522
Test Loss:  0.002126025501638651
Valid Loss:  0.0018909760983660817
Epoch:  408  	Training Loss: 0.0020058993250131607
Test Loss:  0.002125962870195508
Valid Loss:  0.0018909175414592028
Epoch:  409  	Training Loss: 0.0020058336667716503
Test Loss:  0.0021258993074297905
Valid Loss:  0.0018908560741692781
Epoch:  410  	Training Loss: 0.0020057675428688526
Test Loss:  0.002125839237123728
Valid Loss:  0.0018907953053712845
Epoch:  411  	Training Loss: 0.002005703281611204
Test Loss:  0.002125777304172516
Valid Loss:  0.0018907351186499
Epoch:  412  	Training Loss: 0.0020056376233696938
Test Loss:  0.0021257163025438786
Valid Loss:  0.001890676561743021
Epoch:  413  	Training Loss: 0.0020055726636201143
Test Loss:  0.0021256539039313793
Valid Loss:  0.0018906127661466599
Epoch:  414  	Training Loss: 0.002005507703870535
Test Loss:  0.0021255856845527887
Valid Loss:  0.001890554209239781
Epoch:  415  	Training Loss: 0.002005442278459668
Test Loss:   83%|████████▎ | 415/500 [04:51<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:51<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.94it/s] 84%|████████▍ | 421/500 [04:58<01:35,  1.21s/it] 85%|████████▍ | 423/500 [04:58<01:07,  1.15it/s] 85%|████████▌ | 425/500 [04:58<00:47,  1.58it/s] 85%|████████▌ | 427/500 [04:58<00:33,  2.17it/s] 86%|████████▌ | 429/500 [04:59<00:24,  2.92it/s] 86%|████████▌ | 431/500 [05:05<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:05<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:05<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:05<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:05<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:12<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:12<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:12<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:12<00:24,  2.20it/s] 90%|████████▉ | 449/500 [05:12<00:17,  2.95it/s] 90%|█████████ | 451/500 [05:19<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:19<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:19<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:19<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:26<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:26<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:26<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:32<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:33<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:33<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:33<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:39<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.16it/s]0.0021255225874483585
Valid Loss:  0.0018904912285506725
Epoch:  416  	Training Loss: 0.002005378482863307
Test Loss:  0.002125462517142296
Valid Loss:  0.0018904320895671844
Epoch:  417  	Training Loss: 0.002005313988775015
Test Loss:  0.002125396393239498
Valid Loss:  0.0018903694581240416
Epoch:  418  	Training Loss: 0.002005248097702861
Test Loss:  0.002125334460288286
Valid Loss:  0.0018903103191405535
Epoch:  419  	Training Loss: 0.0020051838364452124
Test Loss:  0.00212527415715158
Valid Loss:  0.0018902488518506289
Epoch:  420  	Training Loss: 0.002005117479711771
Test Loss:  0.0021252138540148735
Valid Loss:  0.0018901876173913479
Epoch:  421  	Training Loss: 0.00200505368411541
Test Loss:  0.002125148894265294
Valid Loss:  0.0018901289440691471
Epoch:  422  	Training Loss: 0.0020049887243658304
Test Loss:  0.002125087659806013
Valid Loss:  0.001890068408101797
Epoch:  423  	Training Loss: 0.0020049232989549637
Test Loss:  0.002125026425346732
Valid Loss:  0.0018900095019489527
Epoch:  424  	Training Loss: 0.00200485996901989
Test Loss:  0.0021249609999358654
Valid Loss:  0.0018899466376751661
Epoch:  425  	Training Loss: 0.0020047943107783794
Test Loss:  0.00212490139529109
Valid Loss:  0.0018898865673691034
Epoch:  426  	Training Loss: 0.0020047302823513746
Test Loss:  0.0021248392295092344
Valid Loss:  0.0018898248672485352
Epoch:  427  	Training Loss: 0.002004664856940508
Test Loss:  0.0021247779950499535
Valid Loss:  0.0018897659610956907
Epoch:  428  	Training Loss: 0.002004599664360285
Test Loss:  0.0021247132681310177
Valid Loss:  0.0018897056579589844
Epoch:  429  	Training Loss: 0.0020045358687639236
Test Loss:  0.0021246550604701042
Valid Loss:  0.0018896443070843816
Epoch:  430  	Training Loss: 0.0020044713746756315
Test Loss:  0.0021245907992124557
Valid Loss:  0.0018895852845162153
Epoch:  431  	Training Loss: 0.002004405949264765
Test Loss:  0.002124531427398324
Valid Loss:  0.001889524981379509
Epoch:  432  	Training Loss: 0.0020043416880071163
Test Loss:  0.002124468330293894
Valid Loss:  0.001889465027488768
Epoch:  433  	Training Loss: 0.0020042776595801115
Test Loss:  0.0021244054660201073
Valid Loss:  0.001889401813969016
Epoch:  434  	Training Loss: 0.0020042131654918194
Test Loss:  0.002124339807778597
Valid Loss:  0.001889343955554068
Epoch:  435  	Training Loss: 0.00200415076687932
Test Loss:  0.0021242781076580286
Valid Loss:  0.0018892852822318673
Epoch:  436  	Training Loss: 0.0020040867384523153
Test Loss:  0.002124221995472908
Valid Loss:  0.0018892243970185518
Epoch:  437  	Training Loss: 0.0020040187519043684
Test Loss:  0.002124160062521696
Valid Loss:  0.0018891640938818455
Epoch:  438  	Training Loss: 0.002003956353291869
Test Loss:  0.002124098362401128
Valid Loss:  0.0018891080981120467
Epoch:  439  	Training Loss: 0.002003891859203577
Test Loss:  0.0021240361966192722
Valid Loss:  0.001889044069685042
Epoch:  440  	Training Loss: 0.0020038275979459286
Test Loss:  0.0021239740308374166
Valid Loss:  0.0018889850471168756
Epoch:  441  	Training Loss: 0.0020037638023495674
Test Loss:  0.002123911865055561
Valid Loss:  0.001888928236439824
Epoch:  442  	Training Loss: 0.0020036997739225626
Test Loss:  0.0021238515619188547
Valid Loss:  0.0018888667691498995
Epoch:  443  	Training Loss: 0.002003635745495558
Test Loss:  0.0021237903274595737
Valid Loss:  0.0018888056511059403
Epoch:  444  	Training Loss: 0.0020035726483911276
Test Loss:  0.00212372955866158
Valid Loss:  0.0018887445330619812
Epoch:  445  	Training Loss: 0.002003507222980261
Test Loss:  0.0021236666943877935
Valid Loss:  0.001888686092570424
Epoch:  446  	Training Loss: 0.0020034443587064743
Test Loss:  0.002123604528605938
Valid Loss:  0.0018886263715103269
Epoch:  447  	Training Loss: 0.0020033789332956076
Test Loss:  0.002123543992638588
Valid Loss:  0.0018885669996961951
Epoch:  448  	Training Loss: 0.0020033149048686028
Test Loss:  0.002123483456671238
Valid Loss:  0.001888506580144167
Epoch:  449  	Training Loss: 0.002003250876441598
Test Loss:  0.0021234217565506697
Valid Loss:  0.0018884458113461733
Epoch:  450  	Training Loss: 0.002003188244998455
Test Loss:  0.002123359590768814
Valid Loss:  0.0018883851589635015
Epoch:  451  	Training Loss: 0.0020031232852488756
Test Loss:  0.002123297890648246
Valid Loss:  0.0018883252050727606
Epoch:  452  	Training Loss: 0.002003059256821871
Test Loss:  0.0021232415456324816
Valid Loss:  0.0018882681615650654
Epoch:  453  	Training Loss: 0.0020029942970722914
Test Loss:  0.0021231791470199823
Valid Loss:  0.001888207858428359
Epoch:  454  	Training Loss: 0.0020029330626130104
Test Loss:  0.0021231183782219887
Valid Loss:  0.0018881475552916527
Epoch:  455  	Training Loss: 0.0020028676372021437
Test Loss:  0.0021230564452707767
Valid Loss:  0.0018880899297073483
Epoch:  456  	Training Loss: 0.002002805471420288
Test Loss:  0.0021229973062872887
Valid Loss:  0.0018880298594012856
Epoch:  457  	Training Loss: 0.002002740278840065
Test Loss:  0.002122934442013502
Valid Loss:  0.0018879711860790849
Epoch:  458  	Training Loss: 0.002002676948904991
Test Loss:  0.002122873440384865
Valid Loss:  0.0018879116978496313
Epoch:  459  	Training Loss: 0.0020026136189699173
Test Loss:  0.002122812671586871
Valid Loss:  0.001887849997729063
Epoch:  460  	Training Loss: 0.002002549823373556
Test Loss:  0.002122752834111452
Valid Loss:  0.001887793536297977
Epoch:  461  	Training Loss: 0.002002484630793333
Test Loss:  0.002122691832482815
Valid Loss:  0.0018877331167459488
Epoch:  462  	Training Loss: 0.002002422232180834
Test Loss:  0.0021226308308541775
Valid Loss:  0.0018876754911616445
Epoch:  463  	Training Loss: 0.002002359600737691
Test Loss:  0.00212256982922554
Valid Loss:  0.001887613907456398
Epoch:  464  	Training Loss: 0.0020022946409881115
Test Loss:  0.00212250673212111
Valid Loss:  0.0018875575624406338
Epoch:  465  	Training Loss: 0.002002231776714325
Test Loss:  0.002122447593137622
Valid Loss:  0.0018874966772273183
Epoch:  466  	Training Loss: 0.002002167981117964
Test Loss:  0.002122387057170272
Valid Loss:  0.0018874353263527155
Epoch:  467  	Training Loss: 0.00200210465118289
Test Loss:  0.002122325822710991
Valid Loss:  0.0018873766530305147
Epoch:  468  	Training Loss: 0.002002041321247816
Test Loss:  0.002122266683727503
Valid Loss:  0.0018873207736760378
Epoch:  469  	Training Loss: 0.002001978224143386
Test Loss:  0.0021222042851150036
Valid Loss:  0.0018872577929869294
Epoch:  470  	Training Loss: 0.002001914894208312
Test Loss:  0.002122141420841217
Valid Loss:  0.0018872000509873033
Epoch:  471  	Training Loss: 0.002001851098611951
Test Loss:  0.002122084144502878
Valid Loss:  0.0018871405627578497
Epoch:  472  	Training Loss: 0.0020017886999994516
Test Loss:  0.002122021047398448
Valid Loss:  0.0018870844505727291
Epoch:  473  	Training Loss: 0.002001725370064378
Test Loss:  0.0021219609770923853
Valid Loss:  0.0018870227504521608
Epoch:  474  	Training Loss: 0.0020016622729599476
Test Loss:  0.0021219016052782536
Valid Loss:  0.0018869623309001327
Epoch:  475  	Training Loss: 0.0020015984773635864
Test Loss:  0.00212184083648026
Valid Loss:  0.0018869052873924375
Epoch:  476  	Training Loss: 0.0020015358459204435
Test Loss:  0.0021217798348516226
Valid Loss:  0.0018868469633162022
Epoch:  477  	Training Loss: 0.0020014718174934387
Test Loss:  0.002121723722666502
Valid Loss:  0.0018867880571633577
Epoch:  478  	Training Loss: 0.0020014094188809395
Test Loss:  0.0021216601599007845
Valid Loss:  0.001886729383841157
Epoch:  479  	Training Loss: 0.0020013446919620037
Test Loss:  0.002121600089594722
Valid Loss:  0.0018866682657971978
Epoch:  480  	Training Loss: 0.0020012827590107918
Test Loss:  0.0021215411834418774
Valid Loss:  0.0018866080790758133
Epoch:  481  	Training Loss: 0.0020012196619063616
Test Loss:  0.0021214799489825964
Valid Loss:  0.0018865508027374744
Epoch:  482  	Training Loss: 0.0020011570304632187
Test Loss:  0.002121417783200741
Valid Loss:  0.001886493992060423
Epoch:  483  	Training Loss: 0.002001093467697501
Test Loss:  0.0021213546860963106
Valid Loss:  0.0018864338053390384
Epoch:  484  	Training Loss: 0.0020010308362543583
Test Loss:   97%|█████████▋| 485/500 [05:40<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:40<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:46<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:46<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:46<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:47<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:47<00:00,  3.00it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
0.0021212943829596043
Valid Loss:  0.0018863753648474813
Epoch:  485  	Training Loss: 0.0020009675063192844
Test Loss:  0.0021212375722825527
Valid Loss:  0.0018863186705857515
Epoch:  486  	Training Loss: 0.0020009055733680725
Test Loss:  0.002121175639331341
Valid Loss:  0.001886259880848229
Epoch:  487  	Training Loss: 0.0020008436404168606
Test Loss:  0.0021211174316704273
Valid Loss:  0.0018861980643123388
Epoch:  488  	Training Loss: 0.0020007798448204994
Test Loss:  0.0021210554987192154
Valid Loss:  0.0018861409043893218
Epoch:  489  	Training Loss: 0.0020007167477160692
Test Loss:  0.002120992634445429
Valid Loss:  0.0018860832788050175
Epoch:  490  	Training Loss: 0.0020006552804261446
Test Loss:  0.002120932564139366
Valid Loss:  0.0018860240234062076
Epoch:  491  	Training Loss: 0.0020005919504910707
Test Loss:  0.0021208738908171654
Valid Loss:  0.0018859646515920758
Epoch:  492  	Training Loss: 0.0020005283877253532
Test Loss:  0.0021208124235272408
Valid Loss:  0.0018859044648706913
Epoch:  493  	Training Loss: 0.0020004662219434977
Test Loss:  0.002120755147188902
Valid Loss:  0.0018858497496694326
Epoch:  494  	Training Loss: 0.002000402892008424
Test Loss:  0.002120696473866701
Valid Loss:  0.0018857906106859446
Epoch:  495  	Training Loss: 0.002000340959057212
Test Loss:  0.0021206364035606384
Valid Loss:  0.0018857312388718128
Epoch:  496  	Training Loss: 0.0020002787932753563
Test Loss:  0.002120575401932001
Valid Loss:  0.0018856765236705542
Epoch:  497  	Training Loss: 0.002000215696170926
Test Loss:  0.00212051416747272
Valid Loss:  0.001885614008642733
Epoch:  498  	Training Loss: 0.002000152599066496
Test Loss:  0.0021204533986747265
Valid Loss:  0.0018855577800422907
Epoch:  499  	Training Loss: 0.002000090666115284
Test Loss:  0.00212039309553802
Valid Loss:  0.0018854986410588026
Epoch:  500  	Training Loss: 0.0020000289659947157
Test Loss:  0.0021203344222158194
Valid Loss:  0.001885442528873682
seed is  5
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:31,  6.31s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:56,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:42,  1.22s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:27<09:20,  1.20s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:27<04:47,  1.62it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<09:01,  1.18s/it]  9%|▊         | 43/500 [00:33<06:26,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.63it/s]  9%|▉         | 47/500 [00:34<03:22,  2.23it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:55,  1.19s/it] 11%|█         | 53/500 [00:40<06:22,  1.17it/s] 11%|█         | 55/500 [00:41<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:27,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:57,  1.22s/it] 13%|█▎        | 63/500 [00:48<06:23,  1.14it/s] 13%|█▎        | 65/500 [00:48<04:35,  1.58it/s] 13%|█▎        | 67/500 [00:48<03:20,  2.16it/s] 14%|█▍        | 69/500 [00:48<02:28,  2.91it/s] 14%|█▍        | 71/500 [00:54<08:28,  1.19s/it]Epoch:  1  	Training Loss: 0.2020062953233719
Test Loss:  0.13271845877170563
Valid Loss:  0.1189504861831665
Epoch:  2  	Training Loss: 0.12547485530376434
Test Loss:  0.07893550395965576
Valid Loss:  0.06954769790172577
Epoch:  3  	Training Loss: 0.07437099516391754
Test Loss:  0.05999190732836723
Valid Loss:  0.05282088369131088
Epoch:  4  	Training Loss: 0.05679279565811157
Test Loss:  0.04855259507894516
Valid Loss:  0.04320402070879936
Epoch:  5  	Training Loss: 0.04648488759994507
Test Loss:  0.041475653648376465
Valid Loss:  0.037588123232126236
Epoch:  6  	Training Loss: 0.04031936079263687
Test Loss:  0.036949895322322845
Valid Loss:  0.034215569496154785
Epoch:  7  	Training Loss: 0.03651321679353714
Test Loss:  0.033964604139328
Valid Loss:  0.032131128013134
Epoch:  8  	Training Loss: 0.034090716391801834
Test Loss:  0.03190667927265167
Valid Loss:  0.03076769784092903
Epoch:  9  	Training Loss: 0.03246626257896423
Test Loss:  0.030403777956962585
Valid Loss:  0.02979987859725952
Epoch:  10  	Training Loss: 0.031295932829380035
Test Loss:  0.02924324758350849
Valid Loss:  0.029050981625914574
Epoch:  11  	Training Loss: 0.030389754101634026
Test Loss:  0.02829815074801445
Valid Loss:  0.028422601521015167
Epoch:  12  	Training Loss: 0.029638800770044327
Test Loss:  0.026653677225112915
Valid Loss:  0.02704693004488945
Epoch:  13  	Training Loss: 0.028112970292568207
Test Loss:  0.024995803833007812
Valid Loss:  0.025472277775406837
Epoch:  14  	Training Loss: 0.02646450325846672
Test Loss:  0.023533133789896965
Valid Loss:  0.024106333032250404
Epoch:  15  	Training Loss: 0.025062277913093567
Test Loss:  0.022450894117355347
Valid Loss:  0.023138415068387985
Epoch:  16  	Training Loss: 0.02404613420367241
Test Loss:  0.02152634784579277
Valid Loss:  0.022339362651109695
Epoch:  17  	Training Loss: 0.023197509348392487
Test Loss:  0.020707041025161743
Valid Loss:  0.021646467968821526
Epoch:  18  	Training Loss: 0.02245222218334675
Test Loss:  0.019962232559919357
Valid Loss:  0.02101312205195427
Epoch:  19  	Training Loss: 0.02177230641245842
Test Loss:  0.019278433173894882
Valid Loss:  0.020424069836735725
Epoch:  20  	Training Loss: 0.021138863638043404
Test Loss:  0.01863689534366131
Valid Loss:  0.01986234448850155
Epoch:  21  	Training Loss: 0.020540772005915642
Test Loss:  0.01803836040198803
Valid Loss:  0.019330518320202827
Epoch:  22  	Training Loss: 0.019974971190094948
Test Loss:  0.01675053872168064
Valid Loss:  0.01823684573173523
Epoch:  23  	Training Loss: 0.018770132213830948
Test Loss:  0.015749754384160042
Valid Loss:  0.017349611967802048
Epoch:  24  	Training Loss: 0.01781143620610237
Test Loss:  0.014850370585918427
Valid Loss:  0.016529442742466927
Epoch:  25  	Training Loss: 0.016937583684921265
Test Loss:  0.014025717973709106
Valid Loss:  0.015762966126203537
Epoch:  26  	Training Loss: 0.01612696424126625
Test Loss:  0.013264529407024384
Valid Loss:  0.015043998137116432
Epoch:  27  	Training Loss: 0.015371039509773254
Test Loss:  0.01255984976887703
Valid Loss:  0.014368127100169659
Epoch:  28  	Training Loss: 0.014664215967059135
Test Loss:  0.011904734186828136
Valid Loss:  0.013731934130191803
Epoch:  29  	Training Loss: 0.0140009094029665
Test Loss:  0.011295497417449951
Valid Loss:  0.013131678104400635
Epoch:  30  	Training Loss: 0.013377713039517403
Test Loss:  0.010726823471486568
Valid Loss:  0.012565601617097855
Epoch:  31  	Training Loss: 0.012791023589670658
Test Loss:  0.01019530650228262
Valid Loss:  0.012029239907860756
Epoch:  32  	Training Loss: 0.012237478978931904
Test Loss:  0.00986064039170742
Valid Loss:  0.011605087667703629
Epoch:  33  	Training Loss: 0.011835859157145023
Test Loss:  0.009551305323839188
Valid Loss:  0.011227034963667393
Epoch:  34  	Training Loss: 0.011471908539533615
Test Loss:  0.009257310070097446
Valid Loss:  0.010878421366214752
Epoch:  35  	Training Loss: 0.011131818406283855
Test Loss:  0.008974356576800346
Valid Loss:  0.01055253203958273
Epoch:  36  	Training Loss: 0.010810991749167442
Test Loss:  0.008702149614691734
Valid Loss:  0.010252628475427628
Epoch:  37  	Training Loss: 0.010510464198887348
Test Loss:  0.00843843538314104
Valid Loss:  0.009955896064639091
Epoch:  38  	Training Loss: 0.010215585120022297
Test Loss:  0.008183848112821579
Valid Loss:  0.009674709290266037
Epoch:  39  	Training Loss: 0.009934008121490479
Test Loss:  0.007936812937259674
Valid Loss:  0.009415393695235252
Epoch:  40  	Training Loss: 0.009667770937085152
Test Loss:  0.00769862812012434
Valid Loss:  0.00915690790861845
Epoch:  41  	Training Loss: 0.009406878612935543
Test Loss:  0.007468434050679207
Valid Loss:  0.008909421972930431
Epoch:  42  	Training Loss: 0.009156124666333199
Test Loss:  0.007133532781153917
Valid Loss:  0.008540516719222069
Epoch:  43  	Training Loss: 0.008785034529864788
Test Loss:  0.006809825077652931
Valid Loss:  0.008186878636479378
Epoch:  44  	Training Loss: 0.00842776708304882
Test Loss:  0.006527646444737911
Valid Loss:  0.00788424164056778
Epoch:  45  	Training Loss: 0.008123292587697506
Test Loss:  0.006285688374191523
Valid Loss:  0.00762573815882206
Epoch:  46  	Training Loss: 0.007860529236495495
Test Loss:  0.006065632216632366
Valid Loss:  0.00739275012165308
Epoch:  47  	Training Loss: 0.00762154720723629
Test Loss:  0.005860019475221634
Valid Loss:  0.007175998296588659
Epoch:  48  	Training Loss: 0.007399554364383221
Test Loss:  0.0056685046292841434
Valid Loss:  0.0069740284234285355
Epoch:  49  	Training Loss: 0.0071918293833732605
Test Loss:  0.005488325841724873
Valid Loss:  0.006783045828342438
Epoch:  50  	Training Loss: 0.006995080970227718
Test Loss:  0.005319122225046158
Valid Loss:  0.006601504981517792
Epoch:  51  	Training Loss: 0.006807759869843721
Test Loss:  0.0051594385877251625
Valid Loss:  0.00642824824899435
Epoch:  52  	Training Loss: 0.006629154086112976
Test Loss:  0.005003813654184341
Valid Loss:  0.0062582120299339294
Epoch:  53  	Training Loss: 0.006451486609876156
Test Loss:  0.004867389798164368
Valid Loss:  0.006104668602347374
Epoch:  54  	Training Loss: 0.006292308680713177
Test Loss:  0.00474002119153738
Valid Loss:  0.005960076116025448
Epoch:  55  	Training Loss: 0.006143811624497175
Test Loss:  0.004623391665518284
Valid Loss:  0.005825435742735863
Epoch:  56  	Training Loss: 0.0060046361759305
Test Loss:  0.0045153070241212845
Valid Loss:  0.0056976210325956345
Epoch:  57  	Training Loss: 0.005873740650713444
Test Loss:  0.004413929767906666
Valid Loss:  0.005577261559665203
Epoch:  58  	Training Loss: 0.005750604905188084
Test Loss:  0.004315478727221489
Valid Loss:  0.00546152563765645
Epoch:  59  	Training Loss: 0.005632402375340462
Test Loss:  0.004224834032356739
Valid Loss:  0.005354216322302818
Epoch:  60  	Training Loss: 0.005522522609680891
Test Loss:  0.004137266427278519
Valid Loss:  0.005251994356513023
Epoch:  61  	Training Loss: 0.005415844265371561
Test Loss:  0.004051858559250832
Valid Loss:  0.005151277873665094
Epoch:  62  	Training Loss: 0.005311410874128342
Test Loss:  0.0037923920899629593
Valid Loss:  0.0048309629783034325
Epoch:  63  	Training Loss: 0.004986795596778393
Test Loss:  0.0034970862325280905
Valid Loss:  0.004469074308872223
Epoch:  64  	Training Loss: 0.004622953943908215
Test Loss:  0.0032762703485786915
Valid Loss:  0.004211542196571827
Epoch:  65  	Training Loss: 0.004366346634924412
Test Loss:  0.0031238754745572805
Valid Loss:  0.00403179507702589
Epoch:  66  	Training Loss: 0.004187374841421843
Test Loss:  0.0029916525818407536
Valid Loss:  0.0038771568797528744
Epoch:  67  	Training Loss: 0.004030520096421242
Test Loss:  0.0028702309355139732
Valid Loss:  0.0037360009737312794
Epoch:  68  	Training Loss: 0.0038858135230839252
Test Loss:  0.0027566072531044483
Valid Loss:  0.003603766206651926
Epoch:  69  	Training Loss: 0.0037492220290005207
Test Loss:  0.00264968303963542
Valid Loss:  0.0034786094911396503
Epoch:  70  	Training Loss: 0.0036196555010974407
Test Loss:  0.0025484636425971985
Valid Loss:  0.0033601485192775726
Epoch:  71  	Training Loss: 0.0034966457169502974
Test Loss:  0.0024527437053620815
Valid Loss:  0.0032473092433065176
 15%|█▍        | 73/500 [00:54<06:03,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:21,  1.62it/s] 15%|█▌        | 77/500 [00:55<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:55<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:01<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:01<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:01<04:18,  1.61it/s] 17%|█▋        | 87/500 [01:02<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:02<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:08<08:08,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:18,  2.89it/s] 20%|██        | 101/500 [01:15<08:00,  1.20s/it] 21%|██        | 103/500 [01:15<05:43,  1.15it/s] 21%|██        | 105/500 [01:15<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:16<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:16<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:22<07:48,  1.20s/it] 23%|██▎       | 113/500 [01:22<05:34,  1.16it/s] 23%|██▎       | 115/500 [01:22<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:23<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:29<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:29<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:29<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:36<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:36<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:36<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:36<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:36<02:00,  3.00it/s]Epoch:  72  	Training Loss: 0.003379557281732559
Test Loss:  0.002326434012502432
Valid Loss:  0.003070312552154064
Epoch:  73  	Training Loss: 0.003204658394679427
Test Loss:  0.0022240220569074154
Valid Loss:  0.0029610604979097843
Epoch:  74  	Training Loss: 0.0030856155790388584
Test Loss:  0.0021561817266047
Valid Loss:  0.0028778561390936375
Epoch:  75  	Training Loss: 0.0029980051331222057
Test Loss:  0.002113599795848131
Valid Loss:  0.0028215544298291206
Epoch:  76  	Training Loss: 0.0029402198269963264
Test Loss:  0.0020736732985824347
Valid Loss:  0.002770049963146448
Epoch:  77  	Training Loss: 0.002887034323066473
Test Loss:  0.002035935176536441
Valid Loss:  0.0027224549558013678
Epoch:  78  	Training Loss: 0.002837301464751363
Test Loss:  0.0020005926489830017
Valid Loss:  0.0026775046717375517
Epoch:  79  	Training Loss: 0.0027905283495783806
Test Loss:  0.001967234304174781
Valid Loss:  0.002634914591908455
Epoch:  80  	Training Loss: 0.002746371552348137
Test Loss:  0.001936219516210258
Valid Loss:  0.002594840247184038
Epoch:  81  	Training Loss: 0.0027050101198256016
Test Loss:  0.0019075607415288687
Valid Loss:  0.0025575277395546436
Epoch:  82  	Training Loss: 0.002666014013811946
Test Loss:  0.0018583147320896387
Valid Loss:  0.0024922629818320274
Epoch:  83  	Training Loss: 0.002598309889435768
Test Loss:  0.0018045920878648758
Valid Loss:  0.002422627992928028
Epoch:  84  	Training Loss: 0.00252771214582026
Test Loss:  0.0017509713070467114
Valid Loss:  0.0023536724038422108
Epoch:  85  	Training Loss: 0.0024569681845605373
Test Loss:  0.0017045263666659594
Valid Loss:  0.00229562446475029
Epoch:  86  	Training Loss: 0.00239448226056993
Test Loss:  0.0016663551796227694
Valid Loss:  0.0022466506343334913
Epoch:  87  	Training Loss: 0.002343626692891121
Test Loss:  0.0016344308387488127
Valid Loss:  0.0022072545252740383
Epoch:  88  	Training Loss: 0.002301811706274748
Test Loss:  0.0016062699723988771
Valid Loss:  0.002174993511289358
Epoch:  89  	Training Loss: 0.0022676324006170034
Test Loss:  0.0015831207856535912
Valid Loss:  0.0021476279944181442
Epoch:  90  	Training Loss: 0.0022396978456526995
Test Loss:  0.0015636441530659795
Valid Loss:  0.0021240413188934326
Epoch:  91  	Training Loss: 0.0022154508624225855
Test Loss:  0.001545741455629468
Valid Loss:  0.0021027550101280212
Epoch:  92  	Training Loss: 0.0021938311401754618
Test Loss:  0.001448205322958529
Valid Loss:  0.001984049566090107
Epoch:  93  	Training Loss: 0.0020660830195993185
Test Loss:  0.0013723222073167562
Valid Loss:  0.0018869758350774646
Epoch:  94  	Training Loss: 0.001962900161743164
Test Loss:  0.0013219988904893398
Valid Loss:  0.0018145113717764616
Epoch:  95  	Training Loss: 0.001886788522824645
Test Loss:  0.0012820141855627298
Valid Loss:  0.0017526468727737665
Epoch:  96  	Training Loss: 0.001822867663577199
Test Loss:  0.0012445924803614616
Valid Loss:  0.0016956198960542679
Epoch:  97  	Training Loss: 0.0017641738522797823
Test Loss:  0.00121215614490211
Valid Loss:  0.001644959207624197
Epoch:  98  	Training Loss: 0.0017121058190241456
Test Loss:  0.0011854171752929688
Valid Loss:  0.0016008499078452587
Epoch:  99  	Training Loss: 0.0016665763687342405
Test Loss:  0.0011621862649917603
Valid Loss:  0.0015611128183081746
Epoch:  100  	Training Loss: 0.0016257057432085276
Test Loss:  0.0011418662033975124
Valid Loss:  0.0015248459530994296
Epoch:  101  	Training Loss: 0.0015885380562394857
Test Loss:  0.001123516820371151
Valid Loss:  0.0014914677012711763
Epoch:  102  	Training Loss: 0.0015543445479124784
Test Loss:  0.0010946711990982294
Valid Loss:  0.0014401966473087668
Epoch:  103  	Training Loss: 0.001503380248323083
Test Loss:  0.0010827768128365278
Valid Loss:  0.0014130270574241877
Epoch:  104  	Training Loss: 0.0014726445078849792
Test Loss:  0.0010700579732656479
Valid Loss:  0.001382544869557023
Epoch:  105  	Training Loss: 0.0014430573210120201
Test Loss:  0.0010606189025565982
Valid Loss:  0.0013590503949671984
Epoch:  106  	Training Loss: 0.0014186524786055088
Test Loss:  0.0010520238429307938
Valid Loss:  0.001337558263912797
Epoch:  107  	Training Loss: 0.0013962727971374989
Test Loss:  0.0010443823412060738
Valid Loss:  0.0013190458994358778
Epoch:  108  	Training Loss: 0.0013768963981419802
Test Loss:  0.001041937037371099
Valid Loss:  0.0013048427645117044
Epoch:  109  	Training Loss: 0.00136134575586766
Test Loss:  0.001034536981023848
Valid Loss:  0.0012860450660809875
Epoch:  110  	Training Loss: 0.0013423727359622717
Test Loss:  0.0010291313519701362
Valid Loss:  0.0012733489274978638
Epoch:  111  	Training Loss: 0.001328489277511835
Test Loss:  0.0010307715274393559
Valid Loss:  0.0012630248675122857
Epoch:  112  	Training Loss: 0.001317368121817708
Test Loss:  0.0010251000057905912
Valid Loss:  0.0012514794943854213
Epoch:  113  	Training Loss: 0.0013048601103946567
Test Loss:  0.0010206707520410419
Valid Loss:  0.001241157646290958
Epoch:  114  	Training Loss: 0.0012938748113811016
Test Loss:  0.001017101458273828
Valid Loss:  0.0012319728266447783
Epoch:  115  	Training Loss: 0.0012843245640397072
Test Loss:  0.001014022622257471
Valid Loss:  0.0012233736924827099
Epoch:  116  	Training Loss: 0.0012754308991134167
Test Loss:  0.0010111989686265588
Valid Loss:  0.0012153179850429296
Epoch:  117  	Training Loss: 0.0012672222219407558
Test Loss:  0.0010086464462801814
Valid Loss:  0.001208114204928279
Epoch:  118  	Training Loss: 0.0012598406756296754
Test Loss:  0.0010063794907182455
Valid Loss:  0.0012016086839139462
Epoch:  119  	Training Loss: 0.0012530810199677944
Test Loss:  0.0010045240633189678
Valid Loss:  0.001195558812469244
Epoch:  120  	Training Loss: 0.0012467445340007544
Test Loss:  0.0010028365068137646
Valid Loss:  0.001189942704513669
Epoch:  121  	Training Loss: 0.0012407812755554914
Test Loss:  0.0010016888845711946
Valid Loss:  0.001184616470709443
Epoch:  122  	Training Loss: 0.0012352120829746127
Test Loss:  0.0009849409107118845
Valid Loss:  0.001159279840067029
Epoch:  123  	Training Loss: 0.0012085360940545797
Test Loss:  0.0009685602854005992
Valid Loss:  0.0011353825684636831
Epoch:  124  	Training Loss: 0.0011834749020636082
Test Loss:  0.0009569967514835298
Valid Loss:  0.001115432009100914
Epoch:  125  	Training Loss: 0.0011623564641922712
Test Loss:  0.000942402402870357
Valid Loss:  0.0010993210598826408
Epoch:  126  	Training Loss: 0.0011444666888564825
Test Loss:  0.0009380396222695708
Valid Loss:  0.0010823709890246391
Epoch:  127  	Training Loss: 0.0011272125411778688
Test Loss:  0.0009187459363602102
Valid Loss:  0.0010602037655189633
Epoch:  128  	Training Loss: 0.001104186987504363
Test Loss:  0.0009082708857022226
Valid Loss:  0.0010437271557748318
Epoch:  129  	Training Loss: 0.00108660152181983
Test Loss:  0.0008959982078522444
Valid Loss:  0.001028247526846826
Epoch:  130  	Training Loss: 0.0010699292179197073
Test Loss:  0.0008889042073860765
Valid Loss:  0.0010141613893210888
Epoch:  131  	Training Loss: 0.0010547376004979014
Test Loss:  0.0008739247568883002
Valid Loss:  0.0010003249626606703
Epoch:  132  	Training Loss: 0.0010390584357082844
Test Loss:  0.0008568853954784572
Valid Loss:  0.0009803720749914646
Epoch:  133  	Training Loss: 0.0010174079798161983
Test Loss:  0.0008411419694311917
Valid Loss:  0.0009628206607885659
Epoch:  134  	Training Loss: 0.0009979922324419022
Test Loss:  0.00082638009916991
Valid Loss:  0.0009468027856200933
Epoch:  135  	Training Loss: 0.0009803614811971784
Test Loss:  0.0008143672021105886
Valid Loss:  0.0009333605412393808
Epoch:  136  	Training Loss: 0.0009654936147853732
Test Loss:  0.0008055909420363605
Valid Loss:  0.0009222138323821127
Epoch:  137  	Training Loss: 0.0009536206489428878
Test Loss:  0.0007983099203556776
Valid Loss:  0.0009126224904321134
Epoch:  138  	Training Loss: 0.0009435105603188276
Test Loss:  0.0007918662158772349
Valid Loss:  0.0009039713186211884
Epoch:  139  	Training Loss: 0.0009343220153823495
Test Loss:  0.0007858752505853772
Valid Loss:  0.0008961683488450944
Epoch:  140  	Training Loss: 0.0009259608341380954
Test Loss:  0.0007805348141118884
Valid Loss:  0.0008890466997399926
 28%|██▊       | 141/500 [01:43<07:07,  1.19s/it] 29%|██▊       | 143/500 [01:43<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:43<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.97it/s] 30%|███       | 151/500 [01:49<06:47,  1.17s/it] 31%|███       | 153/500 [01:50<04:51,  1.19it/s] 31%|███       | 155/500 [01:50<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:50<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:50<01:52,  3.03it/s] 32%|███▏      | 161/500 [01:56<06:36,  1.17s/it] 33%|███▎      | 163/500 [01:56<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:56<03:23,  1.65it/s] 33%|███▎      | 167/500 [01:57<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:57<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:03<06:30,  1.19s/it] 35%|███▍      | 173/500 [02:03<04:38,  1.17it/s] 35%|███▌      | 175/500 [02:03<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:04<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:04<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:10<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:10<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:10<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:17<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:17<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:17<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:17<02:16,  2.21it/s] 40%|███▉      | 199/500 [02:17<01:41,  2.98it/s] 40%|████      | 201/500 [02:24<05:55,  1.19s/it] 41%|████      | 203/500 [02:24<04:13,  1.17it/s] 41%|████      | 205/500 [02:24<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:24<02:12,  2.22it/s]Epoch:  141  	Training Loss: 0.0009183735237456858
Test Loss:  0.0007757071871310472
Valid Loss:  0.0008823814569041133
Epoch:  142  	Training Loss: 0.0009112396510317922
Test Loss:  0.0007662311545573175
Valid Loss:  0.0008617063867859542
Epoch:  143  	Training Loss: 0.0008899003732949495
Test Loss:  0.0007587694562971592
Valid Loss:  0.0008549786289222538
Epoch:  144  	Training Loss: 0.0008812795276753604
Test Loss:  0.0007601500838063657
Valid Loss:  0.0008497333619743586
Epoch:  145  	Training Loss: 0.000876501901075244
Test Loss:  0.0007564292172901332
Valid Loss:  0.000845642585773021
Epoch:  146  	Training Loss: 0.0008717431919649243
Test Loss:  0.0007563353283330798
Valid Loss:  0.0008436997886747122
Epoch:  147  	Training Loss: 0.0008697024313732982
Test Loss:  0.0007552680326625705
Valid Loss:  0.0008421310922130942
Epoch:  148  	Training Loss: 0.0008679584716446698
Test Loss:  0.0007558882934972644
Valid Loss:  0.0008406543638557196
Epoch:  149  	Training Loss: 0.0008665092173032463
Test Loss:  0.0007544294930994511
Valid Loss:  0.0008390478906221688
Epoch:  150  	Training Loss: 0.0008646313799545169
Test Loss:  0.0007551598828285933
Valid Loss:  0.0008377409540116787
Epoch:  151  	Training Loss: 0.0008634603582322598
Test Loss:  0.0007538410136476159
Valid Loss:  0.0008362133521586657
Epoch:  152  	Training Loss: 0.000861612381413579
Test Loss:  0.0007513690507039428
Valid Loss:  0.0008301821653731167
Epoch:  153  	Training Loss: 0.0008554314263164997
Test Loss:  0.0007497132755815983
Valid Loss:  0.0008253675187006593
Epoch:  154  	Training Loss: 0.0008503664284944534
Test Loss:  0.0007486376562155783
Valid Loss:  0.0008212749962694943
Epoch:  155  	Training Loss: 0.0008463378762826324
Test Loss:  0.0007477068575099111
Valid Loss:  0.0008178135612979531
Epoch:  156  	Training Loss: 0.0008430391899310052
Test Loss:  0.0007468195399269462
Valid Loss:  0.000814726110547781
Epoch:  157  	Training Loss: 0.0008401690283790231
Test Loss:  0.0007459471235051751
Valid Loss:  0.0008119934936985373
Epoch:  158  	Training Loss: 0.0008375797187909484
Test Loss:  0.0007451405399478972
Valid Loss:  0.0008095577359199524
Epoch:  159  	Training Loss: 0.0008353416342288256
Test Loss:  0.0007443794747814536
Valid Loss:  0.0008074351935647428
Epoch:  160  	Training Loss: 0.0008333902223967016
Test Loss:  0.0007436985615640879
Valid Loss:  0.0008054883219301701
Epoch:  161  	Training Loss: 0.0008315449813380837
Test Loss:  0.0007430105470120907
Valid Loss:  0.000803596805781126
Epoch:  162  	Training Loss: 0.000829776399768889
Test Loss:  0.0007374944980256259
Valid Loss:  0.0007956558838486671
Epoch:  163  	Training Loss: 0.0008202874450944364
Test Loss:  0.0007336389389820397
Valid Loss:  0.0007899548509158194
Epoch:  164  	Training Loss: 0.0008133600931614637
Test Loss:  0.0007305423496291041
Valid Loss:  0.000785124022513628
Epoch:  165  	Training Loss: 0.0008076332742348313
Test Loss:  0.0007278099656105042
Valid Loss:  0.0007805023342370987
Epoch:  166  	Training Loss: 0.0008023817790672183
Test Loss:  0.0007252947543747723
Valid Loss:  0.0007760633016005158
Epoch:  167  	Training Loss: 0.0007974245236255229
Test Loss:  0.0007228411268442869
Valid Loss:  0.000771750055719167
Epoch:  168  	Training Loss: 0.0007926215184852481
Test Loss:  0.0007204431458376348
Valid Loss:  0.0007675228407606483
Epoch:  169  	Training Loss: 0.000788018514867872
Test Loss:  0.0007180652464739978
Valid Loss:  0.0007633997593075037
Epoch:  170  	Training Loss: 0.0007835916476324201
Test Loss:  0.0007156750070862472
Valid Loss:  0.0007593270856887102
Epoch:  171  	Training Loss: 0.0007792270043864846
Test Loss:  0.0007133046165108681
Valid Loss:  0.0007553399773314595
Epoch:  172  	Training Loss: 0.0007749808137305081
Test Loss:  0.0007103626849129796
Valid Loss:  0.0007495811441913247
Epoch:  173  	Training Loss: 0.0007690899074077606
Test Loss:  0.0007074173772707582
Valid Loss:  0.0007443447248078883
Epoch:  174  	Training Loss: 0.0007636790396645665
Test Loss:  0.0007044184021651745
Valid Loss:  0.0007395957363769412
Epoch:  175  	Training Loss: 0.0007585439016111195
Test Loss:  0.0007013483555056155
Valid Loss:  0.0007350215455517173
Epoch:  176  	Training Loss: 0.0007535552140325308
Test Loss:  0.0006982253398746252
Valid Loss:  0.0007305539329536259
Epoch:  177  	Training Loss: 0.0007486870745196939
Test Loss:  0.0006952539552003145
Valid Loss:  0.0007263694424182177
Epoch:  178  	Training Loss: 0.0007440021727234125
Test Loss:  0.0006924742483533919
Valid Loss:  0.0007223075954243541
Epoch:  179  	Training Loss: 0.0007394758868031204
Test Loss:  0.0006898731226101518
Valid Loss:  0.0007183371344581246
Epoch:  180  	Training Loss: 0.0007350746891461313
Test Loss:  0.0006874001701362431
Valid Loss:  0.000714452937245369
Epoch:  181  	Training Loss: 0.0007307935156859457
Test Loss:  0.0006849609781056643
Valid Loss:  0.0007106182747520506
Epoch:  182  	Training Loss: 0.00072657031705603
Test Loss:  0.0006810645572841167
Valid Loss:  0.0007034545415081084
Epoch:  183  	Training Loss: 0.0007191110635176301
Test Loss:  0.0006766716833226383
Valid Loss:  0.000697402167133987
Epoch:  184  	Training Loss: 0.0007126583950594068
Test Loss:  0.0006738058291375637
Valid Loss:  0.0006916553829796612
Epoch:  185  	Training Loss: 0.0007069807033985853
Test Loss:  0.0006693047471344471
Valid Loss:  0.0006868955679237843
Epoch:  186  	Training Loss: 0.0007018618052825332
Test Loss:  0.0006671238224953413
Valid Loss:  0.0006819817936047912
Epoch:  187  	Training Loss: 0.0006970784161239862
Test Loss:  0.000662513542920351
Valid Loss:  0.0006780789699405432
Epoch:  188  	Training Loss: 0.0006927374633960426
Test Loss:  0.0006611376884393394
Valid Loss:  0.0006734896451234818
Epoch:  189  	Training Loss: 0.0006883986061438918
Test Loss:  0.0006566715310327709
Valid Loss:  0.0006701492820866406
Epoch:  190  	Training Loss: 0.0006845323368906975
Test Loss:  0.0006558133172802627
Valid Loss:  0.0006661035004071891
Epoch:  191  	Training Loss: 0.0006808969774283469
Test Loss:  0.0006517366273328662
Valid Loss:  0.0006634417222812772
Epoch:  192  	Training Loss: 0.0006776354275643826
Test Loss:  0.0006500552408397198
Valid Loss:  0.0006609380361624062
Epoch:  193  	Training Loss: 0.0006749475724063814
Test Loss:  0.0006484331097453833
Valid Loss:  0.0006584977963939309
Epoch:  194  	Training Loss: 0.0006723252008669078
Test Loss:  0.0006468989886343479
Valid Loss:  0.0006561053451150656
Epoch:  195  	Training Loss: 0.0006697584176436067
Test Loss:  0.0006453957175835967
Valid Loss:  0.0006537690642289817
Epoch:  196  	Training Loss: 0.0006672674790024757
Test Loss:  0.0006439267308451235
Valid Loss:  0.0006514788256026804
Epoch:  197  	Training Loss: 0.0006648347480222583
Test Loss:  0.0006424505263566971
Valid Loss:  0.0006492217071354389
Epoch:  198  	Training Loss: 0.0006624381057918072
Test Loss:  0.0006409691413864493
Valid Loss:  0.000647003180347383
Epoch:  199  	Training Loss: 0.0006600788328796625
Test Loss:  0.0006394849624484777
Valid Loss:  0.0006448269123211503
Epoch:  200  	Training Loss: 0.0006577487802132964
Test Loss:  0.0006379974074661732
Valid Loss:  0.0006426891777664423
Epoch:  201  	Training Loss: 0.0006554714636877179
Test Loss:  0.0006365706212818623
Valid Loss:  0.0006405914318747818
Epoch:  202  	Training Loss: 0.0006532407132908702
Test Loss:  0.0006338891107589006
Valid Loss:  0.0006373224314302206
Epoch:  203  	Training Loss: 0.0006493807886727154
Test Loss:  0.0006315797800198197
Valid Loss:  0.000634330150205642
Epoch:  204  	Training Loss: 0.0006459145224653184
Test Loss:  0.0006294975755736232
Valid Loss:  0.0006314680795185268
Epoch:  205  	Training Loss: 0.0006426653126254678
Test Loss:  0.0006275761406868696
Valid Loss:  0.0006288096774369478
Epoch:  206  	Training Loss: 0.0006396307144314051
Test Loss:  0.0006257404456846416
Valid Loss:  0.0006262245588004589
Epoch:  207  	Training Loss: 0.000636734941508621
Test Loss:  0.0006240617367438972
Valid Loss:  0.0006237402558326721
Epoch:  208  	Training Loss: 0.0006340109976008534
Test Loss:  0.0006224518874660134
Valid Loss:  0.0006212852313183248
 42%|████▏     | 209/500 [02:24<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:31<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:31<04:06,  1.16it/s] 43%|████▎     | 215/500 [02:31<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:31<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:31<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:38<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:38<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:38<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:38<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:38<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:45<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:45<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:45<02:45,  1.61it/s] 47%|████▋     | 237/500 [02:45<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:45<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:51<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:52<03:40,  1.16it/s] 49%|████▉     | 245/500 [02:52<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:52<01:55,  2.20it/s] 50%|████▉     | 249/500 [02:52<01:24,  2.96it/s] 50%|█████     | 251/500 [02:58<04:55,  1.19s/it] 51%|█████     | 253/500 [02:59<03:30,  1.17it/s] 51%|█████     | 255/500 [02:59<02:31,  1.62it/s] 51%|█████▏    | 257/500 [02:59<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:59<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:05<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:05<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:05<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:06<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:06<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:12<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:12<03:11,  1.18it/s] 55%|█████▌    | 275/500 [03:12<02:17,  1.64it/s]Epoch:  209  	Training Loss: 0.0006313595222309232
Test Loss:  0.000620864680968225
Valid Loss:  0.0006189221749082208
Epoch:  210  	Training Loss: 0.0006287540309131145
Test Loss:  0.0006193194421939552
Valid Loss:  0.0006166142411530018
Epoch:  211  	Training Loss: 0.0006262189708650112
Test Loss:  0.0006178405019454658
Valid Loss:  0.000614364049397409
Epoch:  212  	Training Loss: 0.0006237868219614029
Test Loss:  0.000618192192632705
Valid Loss:  0.0006112178089097142
Epoch:  213  	Training Loss: 0.0006211109575815499
Test Loss:  0.000615878903772682
Valid Loss:  0.000609128619544208
Epoch:  214  	Training Loss: 0.0006184374215081334
Test Loss:  0.0006153942085802555
Valid Loss:  0.000606801244430244
Epoch:  215  	Training Loss: 0.0006162248319014907
Test Loss:  0.0006135429721325636
Valid Loss:  0.0006050325464457273
Epoch:  216  	Training Loss: 0.0006140705081634223
Test Loss:  0.0006135760340839624
Valid Loss:  0.0006027314811944962
Epoch:  217  	Training Loss: 0.0006120449397712946
Test Loss:  0.0006117588491179049
Valid Loss:  0.0006011048099026084
Epoch:  218  	Training Loss: 0.0006100743776187301
Test Loss:  0.0006118782330304384
Valid Loss:  0.0005988758057355881
Epoch:  219  	Training Loss: 0.0006081886240281165
Test Loss:  0.000610115472227335
Valid Loss:  0.0005974103696644306
Epoch:  220  	Training Loss: 0.0006063447217456996
Test Loss:  0.000610331364441663
Valid Loss:  0.0005953819490969181
Epoch:  221  	Training Loss: 0.0006046187481842935
Test Loss:  0.0006085826316848397
Valid Loss:  0.0005938697722740471
Epoch:  222  	Training Loss: 0.0006027265917509794
Test Loss:  0.0006071795360185206
Valid Loss:  0.0005917695816606283
Epoch:  223  	Training Loss: 0.0006004503229632974
Test Loss:  0.0006058659055270255
Valid Loss:  0.0005897050723433495
Epoch:  224  	Training Loss: 0.0005982457660138607
Test Loss:  0.000604617758654058
Valid Loss:  0.0005876569775864482
Epoch:  225  	Training Loss: 0.00059609638992697
Test Loss:  0.0006034317193552852
Valid Loss:  0.0005857000360265374
Epoch:  226  	Training Loss: 0.0005940129631198943
Test Loss:  0.000602278218138963
Valid Loss:  0.0005837538046762347
Epoch:  227  	Training Loss: 0.0005919667310081422
Test Loss:  0.0006011927034705877
Valid Loss:  0.0005818537902086973
Epoch:  228  	Training Loss: 0.0005900000687688589
Test Loss:  0.0006001577712595463
Valid Loss:  0.000579986022785306
Epoch:  229  	Training Loss: 0.000588066061027348
Test Loss:  0.0005991391371935606
Valid Loss:  0.0005781750078313053
Epoch:  230  	Training Loss: 0.0005861594690941274
Test Loss:  0.0005981825524941087
Valid Loss:  0.0005764198140241206
Epoch:  231  	Training Loss: 0.0005843534599989653
Test Loss:  0.000597302452661097
Valid Loss:  0.0005746778333559632
Epoch:  232  	Training Loss: 0.000582589884288609
Test Loss:  0.0005968371406197548
Valid Loss:  0.0005713580176234245
Epoch:  233  	Training Loss: 0.0005795334582217038
Test Loss:  0.0005961341084912419
Valid Loss:  0.0005685705691576004
Epoch:  234  	Training Loss: 0.0005769063136540353
Test Loss:  0.0005952982464805245
Valid Loss:  0.0005660222959704697
Epoch:  235  	Training Loss: 0.000574531324673444
Test Loss:  0.0005943745491094887
Valid Loss:  0.0005636219866573811
Epoch:  236  	Training Loss: 0.0005723017966374755
Test Loss:  0.0005934232613071799
Valid Loss:  0.0005613849498331547
Epoch:  237  	Training Loss: 0.0005702144117094576
Test Loss:  0.0005925025325268507
Valid Loss:  0.0005593046080321074
Epoch:  238  	Training Loss: 0.0005682717892341316
Test Loss:  0.0005915692890994251
Valid Loss:  0.0005573230446316302
Epoch:  239  	Training Loss: 0.0005664464551955462
Test Loss:  0.000590711715631187
Valid Loss:  0.0005555023672059178
Epoch:  240  	Training Loss: 0.0005647807847708464
Test Loss:  0.0005899332463741302
Valid Loss:  0.000553866324480623
Epoch:  241  	Training Loss: 0.0005632358370348811
Test Loss:  0.0005891816690564156
Valid Loss:  0.0005522823194041848
Epoch:  242  	Training Loss: 0.0005617422284558415
Test Loss:  0.0005882506375201046
Valid Loss:  0.0005505970912054181
Epoch:  243  	Training Loss: 0.000559746811632067
Test Loss:  0.0005873972550034523
Valid Loss:  0.0005489278701134026
Epoch:  244  	Training Loss: 0.0005578037234954536
Test Loss:  0.0005865799612365663
Valid Loss:  0.0005472844932228327
Epoch:  245  	Training Loss: 0.0005559037090279162
Test Loss:  0.0005857553333044052
Valid Loss:  0.0005456669023260474
Epoch:  246  	Training Loss: 0.0005540736019611359
Test Loss:  0.0005849300068803132
Valid Loss:  0.0005440572858788073
Epoch:  247  	Training Loss: 0.0005522844730876386
Test Loss:  0.0005840987432748079
Valid Loss:  0.0005424630362540483
Epoch:  248  	Training Loss: 0.0005505188601091504
Test Loss:  0.0005832415772601962
Valid Loss:  0.000540889916010201
Epoch:  249  	Training Loss: 0.0005487933522090316
Test Loss:  0.0005824215477332473
Valid Loss:  0.0005393497995100915
Epoch:  250  	Training Loss: 0.0005471177864819765
Test Loss:  0.0005816632765345275
Valid Loss:  0.0005378372734412551
Epoch:  251  	Training Loss: 0.0005455125356093049
Test Loss:  0.000580892781727016
Valid Loss:  0.0005363818490877748
Epoch:  252  	Training Loss: 0.0005439222441054881
Test Loss:  0.0005793481250293553
Valid Loss:  0.0005339620402082801
Epoch:  253  	Training Loss: 0.0005414383485913277
Test Loss:  0.0005779275670647621
Valid Loss:  0.0005316150491125882
Epoch:  254  	Training Loss: 0.0005390488659031689
Test Loss:  0.0005765646928921342
Valid Loss:  0.000529342913068831
Epoch:  255  	Training Loss: 0.0005367312114685774
Test Loss:  0.0005752893630415201
Valid Loss:  0.0005271238624118268
Epoch:  256  	Training Loss: 0.0005345352692529559
Test Loss:  0.0005740678170695901
Valid Loss:  0.0005249372916296124
Epoch:  257  	Training Loss: 0.000532384030520916
Test Loss:  0.0005728630931116641
Valid Loss:  0.0005228192894719541
Epoch:  258  	Training Loss: 0.0005302682984620333
Test Loss:  0.0005716938176192343
Valid Loss:  0.0005207688082009554
Epoch:  259  	Training Loss: 0.0005282479105517268
Test Loss:  0.0005706389201804996
Valid Loss:  0.0005187868955545127
Epoch:  260  	Training Loss: 0.0005263309576548636
Test Loss:  0.0005696328589692712
Valid Loss:  0.000516842701472342
Epoch:  261  	Training Loss: 0.0005244549829512835
Test Loss:  0.0005686503136530519
Valid Loss:  0.0005149095668457448
Epoch:  262  	Training Loss: 0.0005226182984188199
Test Loss:  0.0005680597387254238
Valid Loss:  0.0005136160179972649
Epoch:  263  	Training Loss: 0.0005212305695749819
Test Loss:  0.000567458919249475
Valid Loss:  0.0005123525043018162
Epoch:  264  	Training Loss: 0.0005199352744966745
Test Loss:  0.0005668938392773271
Valid Loss:  0.0005111644859425724
Epoch:  265  	Training Loss: 0.000518728164024651
Test Loss:  0.0005663096671923995
Valid Loss:  0.0005099752452224493
Epoch:  266  	Training Loss: 0.0005175679689273238
Test Loss:  0.0005657256115227938
Valid Loss:  0.000508791534230113
Epoch:  267  	Training Loss: 0.0005164134199731052
Test Loss:  0.0005651459214277565
Valid Loss:  0.0005076206871308386
Epoch:  268  	Training Loss: 0.0005152800586074591
Test Loss:  0.0005645508645102382
Valid Loss:  0.0005064672441221774
Epoch:  269  	Training Loss: 0.0005141834262758493
Test Loss:  0.0005639881128445268
Valid Loss:  0.000505367002915591
Epoch:  270  	Training Loss: 0.000513171311467886
Test Loss:  0.0005634385161101818
Valid Loss:  0.000504307565279305
Epoch:  271  	Training Loss: 0.0005121996509842575
Test Loss:  0.0005628995131701231
Valid Loss:  0.0005033291527070105
Epoch:  272  	Training Loss: 0.0005112633807584643
Test Loss:  0.0005615666741505265
Valid Loss:  0.0005012569599784911
Epoch:  273  	Training Loss: 0.0005092236679047346
Test Loss:  0.0005602690507657826
Valid Loss:  0.0004993564216420054
Epoch:  274  	Training Loss: 0.0005073530483059585
Test Loss:  0.0005590042565017939
Valid Loss:  0.0004976163618266582
Epoch:  275  	Training Loss: 0.0005056189256720245
Test Loss:  0.0005577338743023574
Valid Loss:  0.0004959447542205453
Epoch:  276  	Training Loss: 0.0005039338138885796
Test Loss:  0.0005564625025726855
Valid Loss:  0.0004943482344970107
Epoch:  277  	Training Loss: 0.0005022992845624685
Test Loss:   55%|█████▌    | 277/500 [03:12<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:13<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:19<04:27,  1.22s/it] 57%|█████▋    | 283/500 [03:19<03:10,  1.14it/s] 57%|█████▋    | 285/500 [03:19<02:16,  1.58it/s] 57%|█████▋    | 287/500 [03:20<01:38,  2.15it/s] 58%|█████▊    | 289/500 [03:20<01:12,  2.91it/s] 58%|█████▊    | 291/500 [03:26<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:26<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:26<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:26<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:26<01:07,  2.97it/s] 60%|██████    | 301/500 [03:33<03:59,  1.21s/it] 61%|██████    | 303/500 [03:33<02:50,  1.16it/s] 61%|██████    | 305/500 [03:33<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:33<01:28,  2.19it/s] 62%|██████▏   | 309/500 [03:33<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:40<03:50,  1.22s/it] 63%|██████▎   | 313/500 [03:40<02:43,  1.14it/s] 63%|██████▎   | 315/500 [03:40<01:57,  1.58it/s] 63%|██████▎   | 317/500 [03:40<01:25,  2.15it/s] 64%|██████▍   | 319/500 [03:41<01:02,  2.90it/s] 64%|██████▍   | 321/500 [03:47<03:36,  1.21s/it] 65%|██████▍   | 323/500 [03:47<02:33,  1.15it/s] 65%|██████▌   | 325/500 [03:47<01:49,  1.59it/s] 65%|██████▌   | 327/500 [03:47<01:19,  2.18it/s] 66%|██████▌   | 329/500 [03:48<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:54<03:24,  1.21s/it] 67%|██████▋   | 333/500 [03:54<02:24,  1.15it/s] 67%|██████▋   | 335/500 [03:54<01:43,  1.60it/s] 67%|██████▋   | 337/500 [03:54<01:14,  2.19it/s] 68%|██████▊   | 339/500 [03:55<00:54,  2.95it/s] 68%|██████▊   | 341/500 [04:01<03:13,  1.22s/it] 69%|██████▊   | 343/500 [04:01<02:17,  1.14it/s]0.0005551911890506744
Valid Loss:  0.0004927910049445927
Epoch:  278  	Training Loss: 0.0005007104482501745
Test Loss:  0.0005539680132642388
Valid Loss:  0.0004913064767606556
Epoch:  279  	Training Loss: 0.0004991983296349645
Test Loss:  0.0005528014153242111
Valid Loss:  0.0004898853367194533
Epoch:  280  	Training Loss: 0.0004977540811523795
Test Loss:  0.0005517561221495271
Valid Loss:  0.0004884874797426164
Epoch:  281  	Training Loss: 0.000496346561703831
Test Loss:  0.0005508157191798091
Valid Loss:  0.0004871223063673824
Epoch:  282  	Training Loss: 0.0004949755966663361
Test Loss:  0.0005493198987096548
Valid Loss:  0.00048346671974286437
Epoch:  283  	Training Loss: 0.000490439822897315
Test Loss:  0.0005481963744387031
Valid Loss:  0.00048017402878031135
Epoch:  284  	Training Loss: 0.0004867136594839394
Test Loss:  0.0005470183095894754
Valid Loss:  0.0004772211250383407
Epoch:  285  	Training Loss: 0.00048346654511988163
Test Loss:  0.0005458224914036691
Valid Loss:  0.00047437637113034725
Epoch:  286  	Training Loss: 0.00048043738934211433
Test Loss:  0.000544582842849195
Valid Loss:  0.0004716151161119342
Epoch:  287  	Training Loss: 0.0004775403067469597
Test Loss:  0.000543310132343322
Valid Loss:  0.0004690448986366391
Epoch:  288  	Training Loss: 0.00047485760296694934
Test Loss:  0.0005420486559160054
Valid Loss:  0.00046655102050863206
Epoch:  289  	Training Loss: 0.0004722352314274758
Test Loss:  0.0005407608114182949
Valid Loss:  0.000464128126623109
Epoch:  290  	Training Loss: 0.00046966172521933913
Test Loss:  0.0005394540494307876
Valid Loss:  0.00046177717740647495
Epoch:  291  	Training Loss: 0.00046713577467016876
Test Loss:  0.0005381000810302794
Valid Loss:  0.00045945486635901034
Epoch:  292  	Training Loss: 0.00046472184476442635
Test Loss:  0.0005373064195737243
Valid Loss:  0.00045834353659301996
Epoch:  293  	Training Loss: 0.0004636296653188765
Test Loss:  0.0005364849348552525
Valid Loss:  0.0004572695470415056
Epoch:  294  	Training Loss: 0.0004625552974175662
Test Loss:  0.0005356452893465757
Valid Loss:  0.00045622268225997686
Epoch:  295  	Training Loss: 0.0004615069192368537
Test Loss:  0.0005348059930838645
Valid Loss:  0.0004552127211354673
Epoch:  296  	Training Loss: 0.0004604844143614173
Test Loss:  0.0005339607014320791
Valid Loss:  0.0004542186507023871
Epoch:  297  	Training Loss: 0.0004594748024828732
Test Loss:  0.0005331097054295242
Valid Loss:  0.0004532505408860743
Epoch:  298  	Training Loss: 0.0004584777925629169
Test Loss:  0.0005322791403159499
Valid Loss:  0.00045229351962916553
Epoch:  299  	Training Loss: 0.0004574918420985341
Test Loss:  0.0005315039888955653
Valid Loss:  0.0004513464227784425
Epoch:  300  	Training Loss: 0.00045652041444554925
Test Loss:  0.0005307772080413997
Valid Loss:  0.0004504280805122107
Epoch:  301  	Training Loss: 0.0004555887426249683
Test Loss:  0.0005300850607454777
Valid Loss:  0.0004495176544878632
Epoch:  302  	Training Loss: 0.00045468017924577
Test Loss:  0.0005293203284963965
Valid Loss:  0.00044785405043512583
Epoch:  303  	Training Loss: 0.0004530083970166743
Test Loss:  0.0005285255610942841
Valid Loss:  0.00044628523755818605
Epoch:  304  	Training Loss: 0.0004514702595770359
Test Loss:  0.0005277245072647929
Valid Loss:  0.0004447764658834785
Epoch:  305  	Training Loss: 0.00044998436351306736
Test Loss:  0.0005269169341772795
Valid Loss:  0.0004432944697327912
Epoch:  306  	Training Loss: 0.00044851581333205104
Test Loss:  0.0005260917823761702
Valid Loss:  0.00044183898717164993
Epoch:  307  	Training Loss: 0.00044708704808726907
Test Loss:  0.0005252704722806811
Valid Loss:  0.0004403963393997401
Epoch:  308  	Training Loss: 0.000445671146735549
Test Loss:  0.0005244595231488347
Valid Loss:  0.0004390184476505965
Epoch:  309  	Training Loss: 0.0004442966601345688
Test Loss:  0.0005236404249444604
Valid Loss:  0.00043767818715423346
Epoch:  310  	Training Loss: 0.0004429609689395875
Test Loss:  0.0005228378577157855
Valid Loss:  0.000436376896686852
Epoch:  311  	Training Loss: 0.0004416524898260832
Test Loss:  0.0005220384337007999
Valid Loss:  0.0004350850940681994
Epoch:  312  	Training Loss: 0.0004403549828566611
Test Loss:  0.0005209129303693771
Valid Loss:  0.0004335042031016201
Epoch:  313  	Training Loss: 0.00043892711983062327
Test Loss:  0.0005198083817958832
Valid Loss:  0.00043198151979595423
Epoch:  314  	Training Loss: 0.00043757137609645724
Test Loss:  0.0005187392816878855
Valid Loss:  0.0004305700131226331
Epoch:  315  	Training Loss: 0.0004362760519143194
Test Loss:  0.0005176982376724482
Valid Loss:  0.00042924509034492075
Epoch:  316  	Training Loss: 0.00043503165943548083
Test Loss:  0.0005166699993424118
Valid Loss:  0.00042796647176146507
Epoch:  317  	Training Loss: 0.0004338109283708036
Test Loss:  0.0005156536935828626
Valid Loss:  0.0004267112526576966
Epoch:  318  	Training Loss: 0.0004326119087636471
Test Loss:  0.0005146567127667367
Valid Loss:  0.00042552611557766795
Epoch:  319  	Training Loss: 0.0004314419347792864
Test Loss:  0.0005136711988598108
Valid Loss:  0.0004243560542818159
Epoch:  320  	Training Loss: 0.0004302912566345185
Test Loss:  0.0005127022741362453
Valid Loss:  0.0004232079372741282
Epoch:  321  	Training Loss: 0.00042916875099763274
Test Loss:  0.0005117603577673435
Valid Loss:  0.00042209471575915813
Epoch:  322  	Training Loss: 0.0004280866705812514
Test Loss:  0.0005122664151713252
Valid Loss:  0.00042132189264521003
Epoch:  323  	Training Loss: 0.00042656564619392157
Test Loss:  0.0005127210170030594
Valid Loss:  0.00042065075831487775
Epoch:  324  	Training Loss: 0.0004255436360836029
Test Loss:  0.000513046164996922
Valid Loss:  0.0004199836985208094
Epoch:  325  	Training Loss: 0.00042466199374757707
Test Loss:  0.0005132494261488318
Valid Loss:  0.00041930953739210963
Epoch:  326  	Training Loss: 0.0004238488036207855
Test Loss:  0.0005133281811140478
Valid Loss:  0.0004186416626907885
Epoch:  327  	Training Loss: 0.00042309239506721497
Test Loss:  0.0005133334780111909
Valid Loss:  0.00041797812446020544
Epoch:  328  	Training Loss: 0.00042237178422510624
Test Loss:  0.0005132791120558977
Valid Loss:  0.00041731976671144366
Epoch:  329  	Training Loss: 0.00042168088839389384
Test Loss:  0.0005131667712703347
Valid Loss:  0.00041665928438305855
Epoch:  330  	Training Loss: 0.0004210040788166225
Test Loss:  0.0005130234640091658
Valid Loss:  0.00041600887198001146
Epoch:  331  	Training Loss: 0.0004203373391646892
Test Loss:  0.000512848375365138
Valid Loss:  0.0004153705667704344
Epoch:  332  	Training Loss: 0.0004196787194814533
Test Loss:  0.0005119174020364881
Valid Loss:  0.0004141778335906565
Epoch:  333  	Training Loss: 0.00041865979437716305
Test Loss:  0.0005109953344799578
Valid Loss:  0.0004130583256483078
Epoch:  334  	Training Loss: 0.00041767663788050413
Test Loss:  0.0005100777489133179
Valid Loss:  0.00041199367842637
Epoch:  335  	Training Loss: 0.0004167165607213974
Test Loss:  0.0005091647617518902
Valid Loss:  0.00041096622589975595
Epoch:  336  	Training Loss: 0.00041578643140383065
Test Loss:  0.0005082759307697415
Valid Loss:  0.0004099942743778229
Epoch:  337  	Training Loss: 0.00041489681461825967
Test Loss:  0.0005074026412330568
Valid Loss:  0.0004090802394784987
Epoch:  338  	Training Loss: 0.00041402826900593936
Test Loss:  0.0005065370351076126
Valid Loss:  0.0004081843071617186
Epoch:  339  	Training Loss: 0.0004131686291657388
Test Loss:  0.0005056847585365176
Valid Loss:  0.0004073039162904024
Epoch:  340  	Training Loss: 0.0004123164981137961
Test Loss:  0.0005048438906669617
Valid Loss:  0.00040644046384841204
Epoch:  341  	Training Loss: 0.00041147347656078637
Test Loss:  0.0005040165851823986
Valid Loss:  0.00040558987529948354
Epoch:  342  	Training Loss: 0.0004106369742657989
Test Loss:  0.0005028307205066085
Valid Loss:  0.0004045968526042998
Epoch:  343  	Training Loss: 0.0004096631892025471
Test Loss:  0.0005016960785724223
Valid Loss:  0.00040361809078603983
Epoch:  344  	Training Loss: 0.0004087024135515094
Test Loss:  0.0005005998536944389
Valid Loss:  0.0004026527749374509
Epoch:  345  	Training Loss: 0.00040775450179353356
 69%|██████▉   | 345/500 [04:01<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:02<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:02<00:51,  2.92it/s] 70%|███████   | 351/500 [04:08<02:56,  1.19s/it] 71%|███████   | 353/500 [04:08<02:05,  1.17it/s] 71%|███████   | 355/500 [04:08<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:08<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:08<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:15<02:43,  1.17s/it] 73%|███████▎  | 363/500 [04:15<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:15<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:15<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:15<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:22<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:22<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:22<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:22<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:22<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:28<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:29<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:29<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:29<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:29<00:36,  3.00it/s] 78%|███████▊  | 391/500 [04:35<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:35<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:36<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:36<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:36<00:33,  2.98it/s] 80%|████████  | 401/500 [04:42<01:57,  1.18s/it] 81%|████████  | 403/500 [04:42<01:22,  1.18it/s] 81%|████████  | 405/500 [04:42<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:43<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:43<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:49<01:43,  1.17s/it]Test Loss:  0.0004995513008907437
Valid Loss:  0.0004017055034637451
Epoch:  346  	Training Loss: 0.00040682958206161857
Test Loss:  0.0004985384293831885
Valid Loss:  0.0004007689421996474
Epoch:  347  	Training Loss: 0.0004059154016431421
Test Loss:  0.0004975555930286646
Valid Loss:  0.00039984085015021265
Epoch:  348  	Training Loss: 0.0004050088464282453
Test Loss:  0.000496603490319103
Valid Loss:  0.0003989208198618144
Epoch:  349  	Training Loss: 0.0004041112260892987
Test Loss:  0.0004956746706739068
Valid Loss:  0.0003980087931267917
Epoch:  350  	Training Loss: 0.00040322120185010135
Test Loss:  0.0004947722190991044
Valid Loss:  0.0003971054102294147
Epoch:  351  	Training Loss: 0.00040233792969956994
Test Loss:  0.0004938911879435182
Valid Loss:  0.0003962104092352092
Epoch:  352  	Training Loss: 0.0004014617297798395
Test Loss:  0.0004938615020364523
Valid Loss:  0.00039623852353543043
Epoch:  353  	Training Loss: 0.00040143082151189446
Test Loss:  0.0004938384518027306
Valid Loss:  0.00039626008947379887
Epoch:  354  	Training Loss: 0.0004014045116491616
Test Loss:  0.0004938214551657438
Valid Loss:  0.0003962790360674262
Epoch:  355  	Training Loss: 0.00040137849282473326
Test Loss:  0.0004938076017424464
Valid Loss:  0.0003962941700592637
Epoch:  356  	Training Loss: 0.00040135617018677294
Test Loss:  0.0004938006168231368
Valid Loss:  0.0003963059280067682
Epoch:  357  	Training Loss: 0.00040133437141776085
Test Loss:  0.0004937961930409074
Valid Loss:  0.0003963138733524829
Epoch:  358  	Training Loss: 0.00040131519199348986
Test Loss:  0.0004937901394441724
Valid Loss:  0.00039631963591091335
Epoch:  359  	Training Loss: 0.0004012975550722331
Test Loss:  0.0004937871126458049
Valid Loss:  0.00039632219704799354
Epoch:  360  	Training Loss: 0.0004012787248939276
Test Loss:  0.0004937857738696039
Valid Loss:  0.0003963221679441631
Epoch:  361  	Training Loss: 0.00040126245585270226
Test Loss:  0.0004937846097163856
Valid Loss:  0.0003963209455832839
Epoch:  362  	Training Loss: 0.00040124525548890233
Test Loss:  0.0004926632973365486
Valid Loss:  0.00039493522490374744
Epoch:  363  	Training Loss: 0.0004000672488473356
Test Loss:  0.0004915454192087054
Valid Loss:  0.00039361382368952036
Epoch:  364  	Training Loss: 0.00039892864879220724
Test Loss:  0.00049043376930058
Valid Loss:  0.0003923492331523448
Epoch:  365  	Training Loss: 0.00039782648673281074
Test Loss:  0.0004893260775133967
Valid Loss:  0.00039115254185162485
Epoch:  366  	Training Loss: 0.0003967523225583136
Test Loss:  0.0004882383509539068
Valid Loss:  0.0003900181036442518
Epoch:  367  	Training Loss: 0.0003957158187404275
Test Loss:  0.00048716203309595585
Valid Loss:  0.00038893084274604917
Epoch:  368  	Training Loss: 0.0003947109798900783
Test Loss:  0.0004861131601501256
Valid Loss:  0.00038788263918831944
Epoch:  369  	Training Loss: 0.00039374432526528835
Test Loss:  0.00048508873442187905
Valid Loss:  0.00038686476182192564
Epoch:  370  	Training Loss: 0.0003928152145817876
Test Loss:  0.00048409588634967804
Valid Loss:  0.0003858841664623469
Epoch:  371  	Training Loss: 0.00039192341500893235
Test Loss:  0.000483125913888216
Valid Loss:  0.000384926883270964
Epoch:  372  	Training Loss: 0.00039104701136238873
Test Loss:  0.0004829505633097142
Valid Loss:  0.00038439204217866063
Epoch:  373  	Training Loss: 0.0003903476463165134
Test Loss:  0.0004828287928830832
Valid Loss:  0.0003838693373836577
Epoch:  374  	Training Loss: 0.0003897074784617871
Test Loss:  0.0004827251541428268
Valid Loss:  0.00038335166755132377
Epoch:  375  	Training Loss: 0.0003891147789545357
Test Loss:  0.0004826331860385835
Valid Loss:  0.00038287159986793995
Epoch:  376  	Training Loss: 0.00038855071761645377
Test Loss:  0.00048253763816319406
Valid Loss:  0.00038240113644860685
Epoch:  377  	Training Loss: 0.0003880166623275727
Test Loss:  0.000482436444144696
Valid Loss:  0.0003819259873125702
Epoch:  378  	Training Loss: 0.0003874929097946733
Test Loss:  0.00048233140842057765
Valid Loss:  0.0003814597730524838
Epoch:  379  	Training Loss: 0.00038698085700161755
Test Loss:  0.00048221813631244004
Valid Loss:  0.0003810176276601851
Epoch:  380  	Training Loss: 0.00038647663313895464
Test Loss:  0.0004821036709472537
Valid Loss:  0.00038058124482631683
Epoch:  381  	Training Loss: 0.00038600247353315353
Test Loss:  0.0004819455789402127
Valid Loss:  0.00038014486199244857
Epoch:  382  	Training Loss: 0.00038556038634851575
Test Loss:  0.0004815732245333493
Valid Loss:  0.0003794858348555863
Epoch:  383  	Training Loss: 0.00038490426959469914
Test Loss:  0.000481188646517694
Valid Loss:  0.0003788414178416133
Epoch:  384  	Training Loss: 0.00038426549872383475
Test Loss:  0.0004808063094969839
Valid Loss:  0.00037820677971467376
Epoch:  385  	Training Loss: 0.00038364125066436827
Test Loss:  0.000480427173897624
Valid Loss:  0.0003775854711420834
Epoch:  386  	Training Loss: 0.00038303498877212405
Test Loss:  0.00048005496500991285
Valid Loss:  0.00037698494270443916
Epoch:  387  	Training Loss: 0.0003824470622930676
Test Loss:  0.0004796817956957966
Valid Loss:  0.0003764129360206425
Epoch:  388  	Training Loss: 0.0003818803234025836
Test Loss:  0.0004792935505975038
Valid Loss:  0.00037585257086902857
Epoch:  389  	Training Loss: 0.0003813280491158366
Test Loss:  0.0004789041995536536
Valid Loss:  0.0003753029159270227
Epoch:  390  	Training Loss: 0.00038078019861131907
Test Loss:  0.00047851313138380647
Valid Loss:  0.0003747718292288482
Epoch:  391  	Training Loss: 0.00038023755769245327
Test Loss:  0.00047812017146497965
Valid Loss:  0.00037425162736326456
Epoch:  392  	Training Loss: 0.0003797036479227245
Test Loss:  0.00047790270764380693
Valid Loss:  0.000373294111341238
Epoch:  393  	Training Loss: 0.00037852098466828465
Test Loss:  0.00047765966155566275
Valid Loss:  0.0003723518457263708
Epoch:  394  	Training Loss: 0.0003774302895180881
Test Loss:  0.0004773855325765908
Valid Loss:  0.0003714363556355238
Epoch:  395  	Training Loss: 0.0003764391876757145
Test Loss:  0.0004770904197357595
Valid Loss:  0.00037054537096992135
Epoch:  396  	Training Loss: 0.00037553810398094356
Test Loss:  0.00047677187831141055
Valid Loss:  0.0003696759813465178
Epoch:  397  	Training Loss: 0.00037469289964064956
Test Loss:  0.00047645720769651234
Valid Loss:  0.0003688373835757375
Epoch:  398  	Training Loss: 0.00037387158954516053
Test Loss:  0.000476144312415272
Valid Loss:  0.00036801808164454997
Epoch:  399  	Training Loss: 0.00037307158345356584
Test Loss:  0.0004758278373628855
Valid Loss:  0.0003672090242616832
Epoch:  400  	Training Loss: 0.0003722859255503863
Test Loss:  0.00047551922034472227
Valid Loss:  0.0003664392279461026
Epoch:  401  	Training Loss: 0.00037151895230636
Test Loss:  0.0004752088279929012
Valid Loss:  0.00036567734787240624
Epoch:  402  	Training Loss: 0.0003707675205077976
Test Loss:  0.00047459593042731285
Valid Loss:  0.00036468866164796054
Epoch:  403  	Training Loss: 0.00036988931242376566
Test Loss:  0.00047399886534549296
Valid Loss:  0.0003637576592154801
Epoch:  404  	Training Loss: 0.0003690350567921996
Test Loss:  0.0004734155081678182
Valid Loss:  0.00036286067916080356
Epoch:  405  	Training Loss: 0.0003682095557451248
Test Loss:  0.00047283669118769467
Valid Loss:  0.00036198587622493505
Epoch:  406  	Training Loss: 0.0003673932224046439
Test Loss:  0.0004722607845906168
Valid Loss:  0.00036112498492002487
Epoch:  407  	Training Loss: 0.00036658611497841775
Test Loss:  0.00047169328900054097
Valid Loss:  0.000360281381290406
Epoch:  408  	Training Loss: 0.00036580112646333873
Test Loss:  0.00047113883192650974
Valid Loss:  0.0003594787558540702
Epoch:  409  	Training Loss: 0.0003650401486083865
Test Loss:  0.0004705880128312856
Valid Loss:  0.00035868663690052927
Epoch:  410  	Training Loss: 0.0003642849042080343
Test Loss:  0.0004700335266534239
Valid Loss:  0.0003579090698622167
Epoch:  411  	Training Loss: 0.0003635553875938058
Test Loss:  0.0004694885283242911
Valid Loss:  0.00035714561818167567
Epoch:  412  	Training Loss: 0.0003628419362939894
Test Loss:  0.00046943523921072483
Valid Loss:  0.00035681785084307194
 83%|████████▎ | 413/500 [04:49<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:49<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:49<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:50<00:27,  2.97it/s] 84%|████████▍ | 421/500 [04:56<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:56<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:56<00:45,  1.63it/s] 85%|████████▌ | 427/500 [04:56<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:56<00:23,  3.00it/s] 86%|████████▌ | 431/500 [05:03<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:03<00:57,  1.18it/s] 87%|████████▋ | 435/500 [05:03<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:03<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:03<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:10<01:09,  1.19s/it] 89%|████████▊ | 443/500 [05:10<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:10<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:10<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:10<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:16<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:17<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:17<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:17<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:23<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:23<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:24<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:24<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:24<00:10,  2.92it/s] 94%|█████████▍| 471/500 [05:30<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:30<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:31<00:07,  2.99it/s]Epoch:  413  	Training Loss: 0.0003624404198490083
Test Loss:  0.00046937091974541545
Valid Loss:  0.00035648117773234844
Epoch:  414  	Training Loss: 0.00036205066135153174
Test Loss:  0.0004692977527156472
Valid Loss:  0.0003561486955732107
Epoch:  415  	Training Loss: 0.0003616700414568186
Test Loss:  0.00046921137254685163
Valid Loss:  0.0003558156022336334
Epoch:  416  	Training Loss: 0.0003612996079027653
Test Loss:  0.00046910555101931095
Valid Loss:  0.00035547796869650483
Epoch:  417  	Training Loss: 0.00036093645030632615
Test Loss:  0.0004689890192821622
Valid Loss:  0.00035514472983777523
Epoch:  418  	Training Loss: 0.0003605795791372657
Test Loss:  0.00046886911150068045
Valid Loss:  0.00035480817314237356
Epoch:  419  	Training Loss: 0.00036022590938955545
Test Loss:  0.0004687410837505013
Valid Loss:  0.00035447574919089675
Epoch:  420  	Training Loss: 0.0003598773037083447
Test Loss:  0.00046861221198923886
Valid Loss:  0.0003541485348250717
Epoch:  421  	Training Loss: 0.0003595393500290811
Test Loss:  0.00046847842168062925
Valid Loss:  0.00035382475471124053
Epoch:  422  	Training Loss: 0.00035920285154134035
Test Loss:  0.00046780132106505334
Valid Loss:  0.0003534149727784097
Epoch:  423  	Training Loss: 0.00035884123644791543
Test Loss:  0.0004671291681006551
Valid Loss:  0.00035303106415085495
Epoch:  424  	Training Loss: 0.0003584863734431565
Test Loss:  0.000466473022243008
Valid Loss:  0.00035267058410681784
Epoch:  425  	Training Loss: 0.0003581474593374878
Test Loss:  0.00046582589857280254
Valid Loss:  0.0003523290215525776
Epoch:  426  	Training Loss: 0.0003578157047741115
Test Loss:  0.00046519291936419904
Valid Loss:  0.00035199488047510386
Epoch:  427  	Training Loss: 0.0003574888105504215
Test Loss:  0.0004645693697966635
Valid Loss:  0.0003516603319440037
Epoch:  428  	Training Loss: 0.0003571668639779091
Test Loss:  0.0004639537073671818
Valid Loss:  0.0003513304400257766
Epoch:  429  	Training Loss: 0.0003568496322259307
Test Loss:  0.0004633520729839802
Valid Loss:  0.0003510071837808937
Epoch:  430  	Training Loss: 0.00035653627128340304
Test Loss:  0.0004627643502317369
Valid Loss:  0.00035068608121946454
Epoch:  431  	Training Loss: 0.00035622803261503577
Test Loss:  0.0004621915868483484
Valid Loss:  0.00035037356428802013
Epoch:  432  	Training Loss: 0.00035592238418757915
Test Loss:  0.00046148887486197054
Valid Loss:  0.0003497730940580368
Epoch:  433  	Training Loss: 0.0003552432172000408
Test Loss:  0.0004608111921697855
Valid Loss:  0.0003491553361527622
Epoch:  434  	Training Loss: 0.00035457423655316234
Test Loss:  0.00046014992403797805
Valid Loss:  0.00034852680983021855
Epoch:  435  	Training Loss: 0.0003539093886502087
Test Loss:  0.0004595014324877411
Valid Loss:  0.0003478917933534831
Epoch:  436  	Training Loss: 0.00035325001226738095
Test Loss:  0.000458859110949561
Valid Loss:  0.00034725075238384306
Epoch:  437  	Training Loss: 0.000352593808202073
Test Loss:  0.0004582263354677707
Valid Loss:  0.0003466091875452548
Epoch:  438  	Training Loss: 0.0003519424353726208
Test Loss:  0.00045760514331050217
Valid Loss:  0.00034597236663103104
Epoch:  439  	Training Loss: 0.00035129470052197576
Test Loss:  0.0004569885495584458
Valid Loss:  0.0003453348472248763
Epoch:  440  	Training Loss: 0.00035065150586888194
Test Loss:  0.00045637544826604426
Valid Loss:  0.00034469919046387076
Epoch:  441  	Training Loss: 0.000350010406691581
Test Loss:  0.00045577369746752083
Valid Loss:  0.00034406757913529873
Epoch:  442  	Training Loss: 0.0003493736148811877
Test Loss:  0.00045551746734417975
Valid Loss:  0.00034393960959278047
Epoch:  443  	Training Loss: 0.0003492166579235345
Test Loss:  0.00045526723260991275
Valid Loss:  0.0003438129788264632
Epoch:  444  	Training Loss: 0.00034906077780760825
Test Loss:  0.00045501667773351073
Valid Loss:  0.00034368899650871754
Epoch:  445  	Training Loss: 0.00034890673123300076
Test Loss:  0.00045476615196093917
Valid Loss:  0.0003435687394812703
Epoch:  446  	Training Loss: 0.00034875323763117194
Test Loss:  0.0004545182455331087
Valid Loss:  0.00034344891901127994
Epoch:  447  	Training Loss: 0.00034860114101320505
Test Loss:  0.0004542616370599717
Valid Loss:  0.00034332723589614034
Epoch:  448  	Training Loss: 0.00034845987102016807
Test Loss:  0.0004539996443782002
Valid Loss:  0.00034320581471547484
Epoch:  449  	Training Loss: 0.00034832314122468233
Test Loss:  0.0004537377681117505
Valid Loss:  0.00034308459726162255
Epoch:  450  	Training Loss: 0.0003481862659100443
Test Loss:  0.0004534770851023495
Valid Loss:  0.0003429634089116007
Epoch:  451  	Training Loss: 0.0003480497107375413
Test Loss:  0.00045321948709897697
Valid Loss:  0.00034285217407159507
Epoch:  452  	Training Loss: 0.0003479137667454779
Test Loss:  0.0004527703276835382
Valid Loss:  0.00034203229006379843
Epoch:  453  	Training Loss: 0.00034715805668383837
Test Loss:  0.0004523342358879745
Valid Loss:  0.0003412421210668981
Epoch:  454  	Training Loss: 0.0003464161418378353
Test Loss:  0.00045188242802396417
Valid Loss:  0.00034047249937430024
Epoch:  455  	Training Loss: 0.000345685170032084
Test Loss:  0.0004514258762355894
Valid Loss:  0.00033971574157476425
Epoch:  456  	Training Loss: 0.0003449634532444179
Test Loss:  0.00045097264228388667
Valid Loss:  0.00033897312823683023
Epoch:  457  	Training Loss: 0.00034424857585690916
Test Loss:  0.0004505249089561403
Valid Loss:  0.00033824864658527076
Epoch:  458  	Training Loss: 0.00034354982199147344
Test Loss:  0.0004500758368521929
Valid Loss:  0.0003375441883690655
Epoch:  459  	Training Loss: 0.0003428556374274194
Test Loss:  0.0004496249312069267
Valid Loss:  0.00033685186645016074
Epoch:  460  	Training Loss: 0.00034216500353068113
Test Loss:  0.00044917321065440774
Valid Loss:  0.00033616722794249654
Epoch:  461  	Training Loss: 0.0003414808597881347
Test Loss:  0.0004487127880565822
Valid Loss:  0.0003354863729327917
Epoch:  462  	Training Loss: 0.0003408094053156674
Test Loss:  0.00044714711839333177
Valid Loss:  0.00033394061028957367
Epoch:  463  	Training Loss: 0.0003395509556867182
Test Loss:  0.00044531706953421235
Valid Loss:  0.0003331040497869253
Epoch:  464  	Training Loss: 0.00033854524372145534
Test Loss:  0.0004437531461007893
Valid Loss:  0.00033220433397218585
Epoch:  465  	Training Loss: 0.0003375891246832907
Test Loss:  0.000442322576418519
Valid Loss:  0.00033129024086520076
Epoch:  466  	Training Loss: 0.0003366538730915636
Test Loss:  0.0004409815592225641
Valid Loss:  0.00033039040863513947
Epoch:  467  	Training Loss: 0.0003357327077537775
Test Loss:  0.00043971301056444645
Valid Loss:  0.00032951144385151565
Epoch:  468  	Training Loss: 0.0003348294703755528
Test Loss:  0.00043850738438777626
Valid Loss:  0.00032864202512428164
Epoch:  469  	Training Loss: 0.00033394864294677973
Test Loss:  0.0004373512929305434
Valid Loss:  0.00032779067987576127
Epoch:  470  	Training Loss: 0.0003330902545712888
Test Loss:  0.00043624526006169617
Valid Loss:  0.0003269484150223434
Epoch:  471  	Training Loss: 0.0003322429256513715
Test Loss:  0.000435194669989869
Valid Loss:  0.00032612349605187774
Epoch:  472  	Training Loss: 0.00033140945015475154
Test Loss:  0.00043522531632333994
Valid Loss:  0.0003260740777477622
Epoch:  473  	Training Loss: 0.00033110761432908475
Test Loss:  0.0004352839896455407
Valid Loss:  0.0003260514931753278
Epoch:  474  	Training Loss: 0.0003308729501441121
Test Loss:  0.0004353495023678988
Valid Loss:  0.000326034874888137
Epoch:  475  	Training Loss: 0.00033068383345380425
Test Loss:  0.0004354140837676823
Valid Loss:  0.000326017034240067
Epoch:  476  	Training Loss: 0.0003305243153590709
Test Loss:  0.00043546638335101306
Valid Loss:  0.00032599078258499503
Epoch:  477  	Training Loss: 0.00033038650872185826
Test Loss:  0.0004355099517852068
Valid Loss:  0.00032595667289569974
Epoch:  478  	Training Loss: 0.00033026098390109837
Test Loss:  0.00043554388685151935
Valid Loss:  0.00032591487979516387
Epoch:  479  	Training Loss: 0.0003301451215520501
Test Loss:  0.00043556932359933853
Valid Loss:  0.0003258652868680656
Epoch:  480  	Training Loss: 0.0003300343523733318
 96%|█████████▌| 481/500 [05:37<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:37<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:38<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:38<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:44<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:44<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:45<00:00,  2.96it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
Test Loss:  0.000435579422628507
Valid Loss:  0.00032580812694504857
Epoch:  481  	Training Loss: 0.00032992669730447233
Test Loss:  0.0004355850105639547
Valid Loss:  0.00032574517535977066
Epoch:  482  	Training Loss: 0.00032982329139485955
Test Loss:  0.00043496262514963746
Valid Loss:  0.0003244071267545223
Epoch:  483  	Training Loss: 0.0003288690641056746
Test Loss:  0.00043442234164103866
Valid Loss:  0.00032343529164791107
Epoch:  484  	Training Loss: 0.00032807752722874284
Test Loss:  0.0004338857834227383
Valid Loss:  0.0003226116532459855
Epoch:  485  	Training Loss: 0.0003273391048423946
Test Loss:  0.00043333490611985326
Valid Loss:  0.00032185105374082923
Epoch:  486  	Training Loss: 0.000326616718666628
Test Loss:  0.00043275285861454904
Valid Loss:  0.00032112153712660074
Epoch:  487  	Training Loss: 0.0003259219811297953
Test Loss:  0.00043215445475652814
Valid Loss:  0.00032042653765529394
Epoch:  488  	Training Loss: 0.0003252424648962915
Test Loss:  0.00043155153980478644
Valid Loss:  0.00031975499587133527
Epoch:  489  	Training Loss: 0.00032456725602969527
Test Loss:  0.0004309424839448184
Valid Loss:  0.00031909020617604256
Epoch:  490  	Training Loss: 0.0003238964709453285
Test Loss:  0.00043033191468566656
Valid Loss:  0.00031843071337789297
Epoch:  491  	Training Loss: 0.00032323217601515353
Test Loss:  0.0004297200939618051
Valid Loss:  0.0003177796024829149
Epoch:  492  	Training Loss: 0.0003225740510970354
Test Loss:  0.0004292076046112925
Valid Loss:  0.00031740975100547075
Epoch:  493  	Training Loss: 0.0003221615916118026
Test Loss:  0.00042870434117503464
Valid Loss:  0.0003170351847074926
Epoch:  494  	Training Loss: 0.0003217529156245291
Test Loss:  0.0004282115842215717
Valid Loss:  0.0003166572714690119
Epoch:  495  	Training Loss: 0.00032134505454450846
Test Loss:  0.0004277263069525361
Valid Loss:  0.0003162770299240947
Epoch:  496  	Training Loss: 0.00032093998743221164
Test Loss:  0.0004272491205483675
Valid Loss:  0.00031590613070875406
Epoch:  497  	Training Loss: 0.00032053556060418487
Test Loss:  0.00042677694000303745
Valid Loss:  0.0003155351150780916
Epoch:  498  	Training Loss: 0.00032013480085879564
Test Loss:  0.0004263069131411612
Valid Loss:  0.0003151612472720444
Epoch:  499  	Training Loss: 0.00031973718432709575
Test Loss:  0.0004258405533619225
Valid Loss:  0.0003147899406030774
Epoch:  500  	Training Loss: 0.0003193423035554588
Test Loss:  0.0004253789666108787
Valid Loss:  0.0003144207876175642
seed is  6
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.41it/s]  1%|          | 4/500 [00:00<00:29, 16.55it/s]  1%|          | 6/500 [00:00<00:29, 16.58it/s]  2%|▏         | 8/500 [00:00<00:29, 16.66it/s]  2%|▏         | 10/500 [00:00<00:29, 16.63it/s]  2%|▏         | 12/500 [00:00<00:29, 16.64it/s]  3%|▎         | 14/500 [00:00<00:29, 16.64it/s]  3%|▎         | 16/500 [00:00<00:29, 16.62it/s]  4%|▎         | 18/500 [00:01<00:28, 16.65it/s]  4%|▍         | 20/500 [00:01<00:28, 16.58it/s]  4%|▍         | 22/500 [00:01<00:28, 16.51it/s]  5%|▍         | 24/500 [00:01<00:28, 16.55it/s]  5%|▌         | 26/500 [00:01<00:28, 16.39it/s]  6%|▌         | 28/500 [00:01<00:28, 16.53it/s]  6%|▌         | 30/500 [00:01<00:28, 16.57it/s]  6%|▋         | 32/500 [00:01<00:28, 16.64it/s]  7%|▋         | 34/500 [00:02<00:27, 16.66it/s]  7%|▋         | 36/500 [00:02<00:27, 16.70it/s]  8%|▊         | 38/500 [00:02<00:27, 16.66it/s]  8%|▊         | 40/500 [00:02<00:27, 16.65it/s]  8%|▊         | 42/500 [00:02<00:27, 16.66it/s]  9%|▉         | 44/500 [00:02<00:27, 16.64it/s]  9%|▉         | 46/500 [00:02<00:27, 16.64it/s] 10%|▉         | 48/500 [00:02<00:27, 16.71it/s] 10%|█         | 50/500 [00:03<00:26, 16.72it/s] 10%|█         | 52/500 [00:03<00:26, 16.75it/s] 11%|█         | 54/500 [00:03<00:26, 16.77it/s] 11%|█         | 56/500 [00:03<00:26, 16.77it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.72it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.69it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.51it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.48it/s] 13%|█▎        | 66/500 [00:03<00:26, 16.56it/s] 14%|█▎        | 68/500 [00:04<00:25, 16.62it/s] 14%|█▍        | 70/500 [00:04<00:25, 16.64it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.63it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.66it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.52it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.45it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.41it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.42it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.33it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.39it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.48it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.49it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.53it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.59it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.61it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.63it/s] 20%|██        | 100/500 [00:06<00:24, 16.56it/s] 20%|██        | 102/500 [00:06<00:24, 16.25it/s] 21%|██        | 104/500 [00:06<00:24, 16.31it/s] 21%|██        | 106/500 [00:06<00:23, 16.48it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.58it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.60it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.68it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.66it/s] 23%|██▎       | 116/500 [00:06<00:23, 16.56it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.59it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.60it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.64it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.66it/s]Epoch:  1  	Training Loss: 0.02399960346519947
Test Loss:  68.2520523071289
Valid Loss:  67.57440185546875
Epoch:  2  	Training Loss: 67.74169921875
Test Loss:  17498488832.0
Valid Loss:  17604763648.0
Epoch:  3  	Training Loss: 17577160704.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan 25%|██▌       | 126/500 [00:07<00:22, 16.72it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.70it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.69it/s] 26%|██▋       | 132/500 [00:07<00:22, 16.69it/s] 27%|██▋       | 134/500 [00:08<00:21, 16.72it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.67it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.66it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.62it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.62it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.64it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.65it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.65it/s] 30%|███       | 150/500 [00:09<00:21, 16.65it/s] 30%|███       | 152/500 [00:09<00:20, 16.68it/s] 31%|███       | 154/500 [00:09<00:20, 16.66it/s] 31%|███       | 156/500 [00:09<00:20, 16.64it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.62it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.62it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.70it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.69it/s] 33%|███▎      | 166/500 [00:09<00:20, 16.69it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.60it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.22it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.37it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.40it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.56it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.46it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.23it/s] 36%|███▋      | 182/500 [00:10<00:19, 16.40it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.52it/s] 37%|███▋      | 186/500 [00:11<00:18, 16.65it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.66it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.66it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.63it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.31it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.37it/s] 40%|███▉      | 198/500 [00:11<00:18, 16.33it/s] 40%|████      | 200/500 [00:12<00:18, 16.17it/s] 40%|████      | 202/500 [00:12<00:18, 16.27it/s] 41%|████      | 204/500 [00:12<00:18, 16.42it/s] 41%|████      | 206/500 [00:12<00:17, 16.51it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.59it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.64it/s] 42%|████▏     | 212/500 [00:12<00:18, 15.91it/s] 43%|████▎     | 214/500 [00:12<00:17, 16.10it/s] 43%|████▎     | 216/500 [00:13<00:18, 15.46it/s] 44%|████▎     | 218/500 [00:13<00:18, 15.26it/s] 44%|████▍     | 220/500 [00:13<00:17, 15.68it/s] 44%|████▍     | 222/500 [00:13<00:17, 15.97it/s] 45%|████▍     | 224/500 [00:13<00:17, 15.36it/s] 45%|████▌     | 226/500 [00:13<00:18, 14.79it/s] 46%|████▌     | 228/500 [00:13<00:19, 14.12it/s] 46%|████▌     | 230/500 [00:14<00:18, 14.70it/s] 46%|████▋     | 232/500 [00:14<00:17, 15.23it/s] 47%|████▋     | 234/500 [00:14<00:17, 15.62it/s] 47%|████▋     | 236/500 [00:14<00:16, 15.93it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.17it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.30it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.42it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.46it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.49it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.56it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:15<00:15, 16.62it/s] 50%|█████     | 252/500 [00:15<00:14, 16.67it/s] 51%|█████     | 254/500 [00:15<00:14, 16.68it/s] 51%|█████     | 256/500 [00:15<00:14, 16.73it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.67it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.64it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.62it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.63it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.62it/s] 54%|█████▎    | 268/500 [00:16<00:13, 16.60it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.60it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.64it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.63it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.63it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.63it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.67it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.64it/s] 57%|█████▋    | 284/500 [00:17<00:12, 16.69it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.70it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.71it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.55it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.55it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.47it/s] 59%|█████▉    | 296/500 [00:17<00:12, 16.49it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.52it/s] 60%|██████    | 300/500 [00:18<00:12, 16.43it/s] 60%|██████    | 302/500 [00:18<00:12, 16.47it/s] 61%|██████    | 304/500 [00:18<00:11, 16.50it/s] 61%|██████    | 306/500 [00:18<00:11, 16.53it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.53it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.56it/s] 62%|██████▏   | 312/500 [00:18<00:11, 16.46it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.47it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.53it/s] 64%|██████▎   | 318/500 [00:19<00:10, 16.55it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.58it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.51it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.35it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.47it/s] 66%|██████▌   | 328/500 [00:19<00:10, 16.20it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.11it/s] 66%|██████▋   | 332/500 [00:20<00:10, 15.74it/s] 67%|██████▋   | 334/500 [00:20<00:10, 15.41it/s] 67%|██████▋   | 336/500 [00:20<00:11, 14.90it/s] 68%|██████▊   | 338/500 [00:20<00:10, 15.43it/s] 68%|██████▊   | 340/500 [00:20<00:10, 15.67it/s] 68%|██████▊   | 342/500 [00:20<00:10, 15.22it/s] 69%|██████▉   | 344/500 [00:20<00:10, 15.58it/s] 69%|██████▉   | 346/500 [00:21<00:09, 15.89it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.16it/s] 70%|███████   | 350/500 [00:21<00:09, 16.32it/s] 70%|███████   | 352/500 [00:21<00:08, 16.45it/s] 71%|███████   | 354/500 [00:21<00:08, 16.55it/s] 71%|███████   | 356/500 [00:21<00:08, 16.59it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.62it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.64it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.68it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.70it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.70it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.69it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.75it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.73it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.78it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.76it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.76it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.74it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.82it/s] 77%|███████▋  | 384/500 [00:23<00:06, 16.78it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.80it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.81it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.81it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.78it/s] 79%|███████▉  | 394/500 [00:23<00:06, 16.52it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.52it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.42it/s] 80%|████████  | 400/500 [00:24<00:06, 16.50it/s] 80%|████████  | 402/500 [00:24<00:05, 16.61it/s] 81%|████████  | 404/500 [00:24<00:05, 16.67it/s] 81%|████████  | 406/500 [00:24<00:05, 16.63it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.57it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.34it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.42it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.48it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.55it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.60it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.64it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.57it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.61it/s] 85%|████████▌ | 426/500 [00:25<00:04, 16.49it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.42it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.45it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.53it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.56it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.57it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.62it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.63it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.49it/s] 89%|████████▉ | 444/500 [00:26<00:03, 16.27it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.28it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.40it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.00it/s] 90%|█████████ | 452/500 [00:27<00:03, 15.42it/s] 91%|█████████ | 454/500 [00:27<00:02, 15.68it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.02it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.20it/s] 92%|█████████▏| 460/500 [00:27<00:02, 16.23it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.35it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.48it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.59it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.68it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.69it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.69it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.73it/s] 95%|█████████▌| 476/500 [00:28<00:01, 16.64it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.61it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.54it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.52it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.56it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.65it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.65it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.74it/s] 98%|█████████▊| 492/500 [00:29<00:00, 16.79it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.76it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.76it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:30<00:00, 16.74it/s]100%|██████████| 500/500 [00:30<00:00, 16.72it/s]100%|██████████| 500/500 [00:30<00:00, 16.45it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  6
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:14,  6.28s/it]  1%|          | 3/500 [00:06<13:56,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:59,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:42,  2.95it/s]  4%|▍         | 21/500 [00:20<09:42,  1.22s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:13,  1.18s/it]  7%|▋         | 33/500 [00:27<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.64it/s]  7%|▋         | 37/500 [00:27<03:27,  2.24it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:00,  1.18s/it]  9%|▊         | 43/500 [00:33<06:26,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.63it/s]  9%|▉         | 47/500 [00:34<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:43,  1.17s/it] 11%|█         | 53/500 [00:40<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.26it/s] 12%|█▏        | 59/500 [00:41<02:25,  3.04it/s] 12%|█▏        | 61/500 [00:47<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.03it/s] 14%|█▍        | 71/500 [00:54<08:33,  1.20s/it]Epoch:  1  	Training Loss: 0.02399960160255432
Test Loss:  0.4036567211151123
Valid Loss:  0.3836246728897095
Epoch:  2  	Training Loss: 0.3880329728126526
Test Loss:  3.295313835144043
Valid Loss:  3.256112813949585
Epoch:  3  	Training Loss: 3.278855323791504
Test Loss:  0.03712863847613335
Valid Loss:  0.03490428626537323
Epoch:  4  	Training Loss: 0.03741656243801117
Test Loss:  0.03712745010852814
Valid Loss:  0.03490329533815384
Epoch:  5  	Training Loss: 0.03741548955440521
Test Loss:  0.037126265466213226
Valid Loss:  0.03490230068564415
Epoch:  6  	Training Loss: 0.037414416670799255
Test Loss:  0.037125080823898315
Valid Loss:  0.03490130975842476
Epoch:  7  	Training Loss: 0.0374133437871933
Test Loss:  0.037123896181583405
Valid Loss:  0.03490031510591507
Epoch:  8  	Training Loss: 0.03741227462887764
Test Loss:  0.0371227040886879
Valid Loss:  0.03489932790398598
Epoch:  9  	Training Loss: 0.03741120547056198
Test Loss:  0.037121519446372986
Valid Loss:  0.03489833325147629
Epoch:  10  	Training Loss: 0.03741013631224632
Test Loss:  0.037120334804058075
Valid Loss:  0.0348973423242569
Epoch:  11  	Training Loss: 0.037409063428640366
Test Loss:  0.037119150161743164
Valid Loss:  0.034896351397037506
Epoch:  12  	Training Loss: 0.03740799427032471
Test Loss:  0.03710514307022095
Valid Loss:  0.03488446772098541
Epoch:  13  	Training Loss: 0.037395179271698
Test Loss:  0.03709114342927933
Valid Loss:  0.03487258777022362
Epoch:  14  	Training Loss: 0.037382375448942184
Test Loss:  0.037077151238918304
Valid Loss:  0.03486071527004242
Epoch:  15  	Training Loss: 0.03736957907676697
Test Loss:  0.03706316649913788
Valid Loss:  0.03484885022044182
Epoch:  16  	Training Loss: 0.03735678642988205
Test Loss:  0.03704918548464775
Valid Loss:  0.034836988896131516
Epoch:  17  	Training Loss: 0.03734400123357773
Test Loss:  0.03703521192073822
Valid Loss:  0.03482513874769211
Epoch:  18  	Training Loss: 0.037331223487854004
Test Loss:  0.037021249532699585
Valid Loss:  0.034813292324543
Epoch:  19  	Training Loss: 0.03731844574213028
Test Loss:  0.03700729086995125
Valid Loss:  0.03480144962668419
Epoch:  20  	Training Loss: 0.03730568289756775
Test Loss:  0.03699333965778351
Valid Loss:  0.034789614379405975
Epoch:  21  	Training Loss: 0.03729292005300522
Test Loss:  0.036979395896196365
Valid Loss:  0.03477778285741806
Epoch:  22  	Training Loss: 0.03728017210960388
Test Loss:  0.03696481138467789
Valid Loss:  0.03476541489362717
Epoch:  23  	Training Loss: 0.03726683184504509
Test Loss:  0.03695023059844971
Valid Loss:  0.03475304692983627
Epoch:  24  	Training Loss: 0.037253499031066895
Test Loss:  0.03693566471338272
Valid Loss:  0.03474068641662598
Epoch:  25  	Training Loss: 0.037240177392959595
Test Loss:  0.036921095103025436
Valid Loss:  0.03472832590341568
Epoch:  26  	Training Loss: 0.0372268483042717
Test Loss:  0.03690653666853905
Valid Loss:  0.03471598029136658
Epoch:  27  	Training Loss: 0.037213534116744995
Test Loss:  0.03689197450876236
Valid Loss:  0.034703634679317474
Epoch:  28  	Training Loss: 0.03720022737979889
Test Loss:  0.03687743470072746
Valid Loss:  0.03469128906726837
Epoch:  29  	Training Loss: 0.037186916917562485
Test Loss:  0.03686289116740227
Valid Loss:  0.03467895835638046
Epoch:  30  	Training Loss: 0.037173621356487274
Test Loss:  0.03684835508465767
Valid Loss:  0.034666627645492554
Epoch:  31  	Training Loss: 0.03716032952070236
Test Loss:  0.03683382645249367
Valid Loss:  0.03465430065989494
Epoch:  32  	Training Loss: 0.03714704513549805
Test Loss:  0.03681869059801102
Valid Loss:  0.03464146703481674
Epoch:  33  	Training Loss: 0.037133198231458664
Test Loss:  0.03680356591939926
Valid Loss:  0.03462862968444824
Epoch:  34  	Training Loss: 0.037119366228580475
Test Loss:  0.0367884524166584
Valid Loss:  0.03461580350995064
Epoch:  35  	Training Loss: 0.037105534225702286
Test Loss:  0.03677333891391754
Valid Loss:  0.03460298478603363
Epoch:  36  	Training Loss: 0.037091709673404694
Test Loss:  0.03675823658704758
Valid Loss:  0.03459017723798752
Epoch:  37  	Training Loss: 0.037077903747558594
Test Loss:  0.03674314171075821
Valid Loss:  0.034577373415231705
Epoch:  38  	Training Loss: 0.037064097821712494
Test Loss:  0.036728061735630035
Valid Loss:  0.03456456959247589
Epoch:  39  	Training Loss: 0.037050291895866394
Test Loss:  0.03671298921108246
Valid Loss:  0.03455178439617157
Epoch:  40  	Training Loss: 0.037036508321762085
Test Loss:  0.03669791668653488
Valid Loss:  0.03453900292515755
Epoch:  41  	Training Loss: 0.03702272102236748
Test Loss:  0.0366828553378582
Valid Loss:  0.034526221454143524
Epoch:  42  	Training Loss: 0.037008944898843765
Test Loss:  0.03666733205318451
Valid Loss:  0.03451304882764816
Epoch:  43  	Training Loss: 0.03699474781751633
Test Loss:  0.036651819944381714
Valid Loss:  0.0344998873770237
Epoch:  44  	Training Loss: 0.03698055446147919
Test Loss:  0.03663630783557892
Valid Loss:  0.03448672965168953
Epoch:  45  	Training Loss: 0.036966368556022644
Test Loss:  0.03662080690264702
Valid Loss:  0.03447358310222626
Epoch:  46  	Training Loss: 0.0369521863758564
Test Loss:  0.036605313420295715
Valid Loss:  0.034460436552762985
Epoch:  47  	Training Loss: 0.03693801909685135
Test Loss:  0.03658982366323471
Valid Loss:  0.03444729745388031
Epoch:  48  	Training Loss: 0.036923848092556
Test Loss:  0.0365743488073349
Valid Loss:  0.03443416208028793
Epoch:  49  	Training Loss: 0.036909691989421844
Test Loss:  0.03655887767672539
Valid Loss:  0.03442104160785675
Epoch:  50  	Training Loss: 0.036895543336868286
Test Loss:  0.03654341399669647
Valid Loss:  0.03440792113542557
Epoch:  51  	Training Loss: 0.03688139468431473
Test Loss:  0.036527954041957855
Valid Loss:  0.03439480438828468
Epoch:  52  	Training Loss: 0.036867253482341766
Test Loss:  0.03651214763522148
Valid Loss:  0.03438139706850052
Epoch:  53  	Training Loss: 0.036852795630693436
Test Loss:  0.03649634122848511
Valid Loss:  0.03436799719929695
Epoch:  54  	Training Loss: 0.0368383452296257
Test Loss:  0.036480557173490524
Valid Loss:  0.034354597330093384
Epoch:  55  	Training Loss: 0.03682389855384827
Test Loss:  0.03646477311849594
Valid Loss:  0.03434120863676071
Epoch:  56  	Training Loss: 0.03680945932865143
Test Loss:  0.036448992788791656
Valid Loss:  0.03432781994342804
Epoch:  57  	Training Loss: 0.036795031279325485
Test Loss:  0.036433227360248566
Valid Loss:  0.03431444242596626
Epoch:  58  	Training Loss: 0.03678060322999954
Test Loss:  0.03641746565699577
Valid Loss:  0.03430107235908508
Epoch:  59  	Training Loss: 0.036766186356544495
Test Loss:  0.03640170767903328
Valid Loss:  0.0342877134680748
Epoch:  60  	Training Loss: 0.036751776933670044
Test Loss:  0.03638596832752228
Valid Loss:  0.034274350851774216
Epoch:  61  	Training Loss: 0.03673737496137619
Test Loss:  0.036370232701301575
Valid Loss:  0.03426100313663483
Epoch:  62  	Training Loss: 0.036722976714372635
Test Loss:  0.036354340612888336
Valid Loss:  0.03424752131104469
Epoch:  63  	Training Loss: 0.036708444356918335
Test Loss:  0.03633846342563629
Valid Loss:  0.034234046936035156
Epoch:  64  	Training Loss: 0.036693915724754333
Test Loss:  0.03632258623838425
Valid Loss:  0.034220583736896515
Epoch:  65  	Training Loss: 0.03667939826846123
Test Loss:  0.036306723952293396
Valid Loss:  0.03420712798833847
Epoch:  66  	Training Loss: 0.03666488826274872
Test Loss:  0.03629087284207344
Valid Loss:  0.034193672239780426
Epoch:  67  	Training Loss: 0.03665038198232651
Test Loss:  0.036275021731853485
Valid Loss:  0.03418022394180298
Epoch:  68  	Training Loss: 0.036635883152484894
Test Loss:  0.036259185522794724
Valid Loss:  0.034166790544986725
Epoch:  69  	Training Loss: 0.03662139177322388
Test Loss:  0.036243341863155365
Valid Loss:  0.03415335342288017
Epoch:  70  	Training Loss: 0.03660690411925316
Test Loss:  0.0362275205552578
Valid Loss:  0.034139927476644516
Epoch:  71  	Training Loss: 0.036592427641153336
Test Loss:  0.036211706697940826
Valid Loss:  0.03412650525569916
Epoch:  72  	Training Loss: 0.03657795488834381
Test Loss:  0.036195818334817886
Valid Loss:  0.03411302715539932
 15%|█▍        | 73/500 [00:54<06:06,  1.16it/s] 15%|█▌        | 75/500 [00:54<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:54<03:11,  2.20it/s] 16%|█▌        | 79/500 [00:54<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:01<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.22it/s] 18%|█▊        | 89/500 [01:01<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:07<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:50,  1.18s/it] 21%|██        | 103/500 [01:14<05:35,  1.18it/s] 21%|██        | 105/500 [01:15<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:15<02:10,  3.01it/s] 22%|██▏       | 111/500 [01:21<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:28<07:23,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:35<07:13,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:41<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:42<04:59,  1.19it/s]Epoch:  73  	Training Loss: 0.03656342253088951
Test Loss:  0.036179929971694946
Valid Loss:  0.034099552780389786
Epoch:  74  	Training Loss: 0.03654888644814491
Test Loss:  0.0361640565097332
Valid Loss:  0.034086085855960846
Epoch:  75  	Training Loss: 0.03653436899185181
Test Loss:  0.03614819049835205
Valid Loss:  0.034072622656822205
Epoch:  76  	Training Loss: 0.0365198478102684
Test Loss:  0.0361323282122612
Valid Loss:  0.03405916690826416
Epoch:  77  	Training Loss: 0.03650534152984619
Test Loss:  0.036116473376750946
Valid Loss:  0.03404572233557701
Epoch:  78  	Training Loss: 0.03649083897471428
Test Loss:  0.036100633442401886
Valid Loss:  0.03403227776288986
Epoch:  79  	Training Loss: 0.036476343870162964
Test Loss:  0.036084793508052826
Valid Loss:  0.03401884436607361
Epoch:  80  	Training Loss: 0.036461859941482544
Test Loss:  0.03606896847486496
Valid Loss:  0.03400541841983795
Epoch:  81  	Training Loss: 0.036447376012802124
Test Loss:  0.03605315089225769
Valid Loss:  0.03399199992418289
Epoch:  82  	Training Loss: 0.0364329069852829
Test Loss:  0.03603743016719818
Valid Loss:  0.0339786633849144
Epoch:  83  	Training Loss: 0.036418527364730835
Test Loss:  0.036021728068590164
Valid Loss:  0.0339653380215168
Epoch:  84  	Training Loss: 0.03640415892004967
Test Loss:  0.03600602596998215
Valid Loss:  0.0339520201086998
Epoch:  85  	Training Loss: 0.0363897904753685
Test Loss:  0.035990335047245026
Valid Loss:  0.033938705921173096
Epoch:  86  	Training Loss: 0.036375440657138824
Test Loss:  0.035974644124507904
Valid Loss:  0.03392539173364639
Epoch:  87  	Training Loss: 0.03636108711361885
Test Loss:  0.03595896437764168
Valid Loss:  0.03391209989786148
Epoch:  88  	Training Loss: 0.03634674474596977
Test Loss:  0.03594329580664635
Valid Loss:  0.03389880061149597
Epoch:  89  	Training Loss: 0.03633240610361099
Test Loss:  0.03592763468623161
Valid Loss:  0.03388551250100136
Epoch:  90  	Training Loss: 0.03631807491183281
Test Loss:  0.03591197356581688
Valid Loss:  0.03387222811579704
Epoch:  91  	Training Loss: 0.03630375117063522
Test Loss:  0.03589632362127304
Valid Loss:  0.03385895490646362
Epoch:  92  	Training Loss: 0.036289434880018234
Test Loss:  0.035880863666534424
Valid Loss:  0.03384583443403244
Epoch:  93  	Training Loss: 0.036275286227464676
Test Loss:  0.03586540371179581
Valid Loss:  0.033832721412181854
Epoch:  94  	Training Loss: 0.036261141300201416
Test Loss:  0.035849958658218384
Valid Loss:  0.033819615840911865
Epoch:  95  	Training Loss: 0.03624701499938965
Test Loss:  0.03583452105522156
Valid Loss:  0.03380651772022247
Epoch:  96  	Training Loss: 0.03623288869857788
Test Loss:  0.03581909090280533
Valid Loss:  0.03379342705011368
Epoch:  97  	Training Loss: 0.03621876612305641
Test Loss:  0.0358036607503891
Valid Loss:  0.03378033638000488
Epoch:  98  	Training Loss: 0.03620465472340584
Test Loss:  0.03578824922442436
Valid Loss:  0.03376725688576698
Epoch:  99  	Training Loss: 0.03619054704904556
Test Loss:  0.03577284514904022
Valid Loss:  0.03375418484210968
Epoch:  100  	Training Loss: 0.03617645427584648
Test Loss:  0.03575744479894638
Valid Loss:  0.033741116523742676
Epoch:  101  	Training Loss: 0.0361623615026474
Test Loss:  0.03574204817414284
Valid Loss:  0.03372805938124657
Epoch:  102  	Training Loss: 0.036148279905319214
Test Loss:  0.035727038979530334
Valid Loss:  0.033715322613716125
Epoch:  103  	Training Loss: 0.036134541034698486
Test Loss:  0.03571204096078873
Valid Loss:  0.03370260074734688
Epoch:  104  	Training Loss: 0.03612082079052925
Test Loss:  0.035697050392627716
Valid Loss:  0.03368988260626793
Epoch:  105  	Training Loss: 0.036107100546360016
Test Loss:  0.0356820747256279
Valid Loss:  0.03367716819047928
Epoch:  106  	Training Loss: 0.036093395203351974
Test Loss:  0.035667095333337784
Valid Loss:  0.03366446495056152
Epoch:  107  	Training Loss: 0.03607968986034393
Test Loss:  0.035652123391628265
Valid Loss:  0.03365176543593407
Epoch:  108  	Training Loss: 0.03606599196791649
Test Loss:  0.03563716262578964
Valid Loss:  0.03363906592130661
Epoch:  109  	Training Loss: 0.03605230152606964
Test Loss:  0.035622213035821915
Valid Loss:  0.033626385033130646
Epoch:  110  	Training Loss: 0.03603861853480339
Test Loss:  0.035607267171144485
Valid Loss:  0.03361370041966438
Epoch:  111  	Training Loss: 0.03602494299411774
Test Loss:  0.03559233248233795
Valid Loss:  0.033601030707359314
Epoch:  112  	Training Loss: 0.03601127862930298
Test Loss:  0.035577766597270966
Valid Loss:  0.03358867019414902
Epoch:  113  	Training Loss: 0.035997942090034485
Test Loss:  0.03556320071220398
Valid Loss:  0.03357630968093872
Epoch:  114  	Training Loss: 0.035984620451927185
Test Loss:  0.03554864972829819
Valid Loss:  0.03356395661830902
Epoch:  115  	Training Loss: 0.035971298813819885
Test Loss:  0.035534098744392395
Valid Loss:  0.03355161473155022
Epoch:  116  	Training Loss: 0.03595798462629318
Test Loss:  0.0355195514857769
Valid Loss:  0.03353928029537201
Epoch:  117  	Training Loss: 0.035944677889347076
Test Loss:  0.0355050228536129
Valid Loss:  0.0335269495844841
Epoch:  118  	Training Loss: 0.03593137860298157
Test Loss:  0.0354904942214489
Valid Loss:  0.03351461887359619
Epoch:  119  	Training Loss: 0.03591808304190636
Test Loss:  0.03547597676515579
Valid Loss:  0.03350229561328888
Epoch:  120  	Training Loss: 0.03590479493141174
Test Loss:  0.03546147048473358
Valid Loss:  0.03348998352885246
Epoch:  121  	Training Loss: 0.035891517996788025
Test Loss:  0.03544696420431137
Valid Loss:  0.033477675169706345
Epoch:  122  	Training Loss: 0.03587824106216431
Test Loss:  0.03543293476104736
Valid Loss:  0.03346577286720276
Epoch:  123  	Training Loss: 0.03586540371179581
Test Loss:  0.03541891276836395
Valid Loss:  0.03345387801527977
Epoch:  124  	Training Loss: 0.035852573812007904
Test Loss:  0.03540489450097084
Valid Loss:  0.03344198316335678
Epoch:  125  	Training Loss: 0.03583974391222
Test Loss:  0.035390887409448624
Valid Loss:  0.03343009948730469
Epoch:  126  	Training Loss: 0.035826925188302994
Test Loss:  0.035376887768507004
Valid Loss:  0.03341822326183319
Epoch:  127  	Training Loss: 0.03581411391496658
Test Loss:  0.03536289557814598
Valid Loss:  0.033406347036361694
Epoch:  128  	Training Loss: 0.03580130636692047
Test Loss:  0.035348907113075256
Valid Loss:  0.033394478261470795
Epoch:  129  	Training Loss: 0.035788509994745255
Test Loss:  0.03533492982387543
Valid Loss:  0.03338261693716049
Epoch:  130  	Training Loss: 0.03577571362257004
Test Loss:  0.035320959985256195
Valid Loss:  0.033370763063430786
Epoch:  131  	Training Loss: 0.03576292842626572
Test Loss:  0.03530699759721756
Valid Loss:  0.03335891664028168
Epoch:  132  	Training Loss: 0.03575015440583229
Test Loss:  0.03529348969459534
Valid Loss:  0.03334745764732361
Epoch:  133  	Training Loss: 0.03573779761791229
Test Loss:  0.03527999669313431
Valid Loss:  0.033336006104946136
Epoch:  134  	Training Loss: 0.03572544455528259
Test Loss:  0.03526650369167328
Valid Loss:  0.03332455828785896
Epoch:  135  	Training Loss: 0.03571309894323349
Test Loss:  0.03525301814079285
Valid Loss:  0.03331312537193298
Epoch:  136  	Training Loss: 0.035700760781764984
Test Loss:  0.03523954376578331
Valid Loss:  0.03330168500542641
Epoch:  137  	Training Loss: 0.03568842262029648
Test Loss:  0.03522606939077377
Valid Loss:  0.033290255814790726
Epoch:  138  	Training Loss: 0.03567609190940857
Test Loss:  0.03521260619163513
Valid Loss:  0.033278826624155045
Epoch:  139  	Training Loss: 0.035663772374391556
Test Loss:  0.03519913926720619
Valid Loss:  0.03326741233468056
Epoch:  140  	Training Loss: 0.035651445388793945
Test Loss:  0.035185690969228745
Valid Loss:  0.03325599431991577
Epoch:  141  	Training Loss: 0.03563913702964783
Test Loss:  0.035172238945961
Valid Loss:  0.033244580030441284
Epoch:  142  	Training Loss: 0.03562682867050171
Test Loss:  0.03515931963920593
Valid Loss:  0.033233627676963806
Epoch:  143  	Training Loss: 0.03561501204967499
Test Loss:  0.03514641150832176
Valid Loss:  0.03322267532348633
Epoch:  144  	Training Loss: 0.03560319542884827
Test Loss:  0.03513350710272789
 29%|██▉       | 145/500 [01:42<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:42<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.02it/s] 30%|███       | 151/500 [01:48<06:54,  1.19s/it] 31%|███       | 153/500 [01:48<04:55,  1.17it/s] 31%|███       | 155/500 [01:49<03:32,  1.63it/s] 31%|███▏      | 157/500 [01:49<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:49<01:54,  2.99it/s] 32%|███▏      | 161/500 [01:55<06:48,  1.20s/it] 33%|███▎      | 163/500 [01:55<04:51,  1.16it/s] 33%|███▎      | 165/500 [01:56<03:29,  1.60it/s] 33%|███▎      | 167/500 [01:56<02:31,  2.19it/s] 34%|███▍      | 169/500 [01:56<01:52,  2.95it/s] 34%|███▍      | 171/500 [02:02<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:03<02:23,  2.24it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:09<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:09<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:09<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:10<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:16<06:09,  1.20s/it] 39%|███▊      | 193/500 [02:16<04:23,  1.17it/s] 39%|███▉      | 195/500 [02:16<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:16<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:16<01:41,  2.97it/s] 40%|████      | 201/500 [02:23<05:56,  1.19s/it] 41%|████      | 203/500 [02:23<04:14,  1.17it/s] 41%|████      | 205/500 [02:23<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:30<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:30<04:09,  1.15it/s] 43%|████▎     | 215/500 [02:30<02:58,  1.59it/s]Valid Loss:  0.03321172669529915
Epoch:  145  	Training Loss: 0.03559138625860214
Test Loss:  0.035120610147714615
Valid Loss:  0.033200785517692566
Epoch:  146  	Training Loss: 0.035579584538936615
Test Loss:  0.03510771691799164
Valid Loss:  0.033189840614795685
Epoch:  147  	Training Loss: 0.03556778281927109
Test Loss:  0.03509482368826866
Valid Loss:  0.03317891061306
Epoch:  148  	Training Loss: 0.03555598855018616
Test Loss:  0.03508193790912628
Valid Loss:  0.03316798061132431
Epoch:  149  	Training Loss: 0.035544201731681824
Test Loss:  0.0350690633058548
Valid Loss:  0.03315705060958862
Epoch:  150  	Training Loss: 0.03553241491317749
Test Loss:  0.03505619242787361
Valid Loss:  0.03314613550901413
Epoch:  151  	Training Loss: 0.035520635545253754
Test Loss:  0.035043321549892426
Valid Loss:  0.03313521295785904
Epoch:  152  	Training Loss: 0.035508863627910614
Test Loss:  0.03503095358610153
Valid Loss:  0.03312472254037857
Epoch:  153  	Training Loss: 0.03549754247069359
Test Loss:  0.03501858562231064
Valid Loss:  0.0331142358481884
Epoch:  154  	Training Loss: 0.03548622876405716
Test Loss:  0.03500623255968094
Valid Loss:  0.03310374915599823
Epoch:  155  	Training Loss: 0.03547491878271103
Test Loss:  0.03499387949705124
Valid Loss:  0.033093273639678955
Epoch:  156  	Training Loss: 0.035463619977235794
Test Loss:  0.034981533885002136
Valid Loss:  0.03308280184864998
Epoch:  157  	Training Loss: 0.03545232117176056
Test Loss:  0.03496918827295303
Valid Loss:  0.033072330057621
Epoch:  158  	Training Loss: 0.03544102609157562
Test Loss:  0.034956853836774826
Valid Loss:  0.03306186944246292
Epoch:  159  	Training Loss: 0.03542973846197128
Test Loss:  0.03494452312588692
Valid Loss:  0.03305140882730484
Epoch:  160  	Training Loss: 0.03541845455765724
Test Loss:  0.034932203590869904
Valid Loss:  0.033040955662727356
Epoch:  161  	Training Loss: 0.0354071781039238
Test Loss:  0.03491988033056259
Valid Loss:  0.03303050249814987
Epoch:  162  	Training Loss: 0.03539590165019035
Test Loss:  0.034908078610897064
Valid Loss:  0.033020488917827606
Epoch:  163  	Training Loss: 0.03538510203361511
Test Loss:  0.034896284341812134
Valid Loss:  0.03301048278808594
Epoch:  164  	Training Loss: 0.03537430986762047
Test Loss:  0.0348844900727272
Valid Loss:  0.03300047665834427
Epoch:  165  	Training Loss: 0.035363517701625824
Test Loss:  0.03487270325422287
Valid Loss:  0.032990485429763794
Epoch:  166  	Training Loss: 0.03535272926092148
Test Loss:  0.03486092761158943
Valid Loss:  0.03298048675060272
Epoch:  167  	Training Loss: 0.03534195199608803
Test Loss:  0.0348491445183754
Valid Loss:  0.03297049179673195
Epoch:  168  	Training Loss: 0.03533116728067398
Test Loss:  0.03483737260103226
Valid Loss:  0.03296050801873207
Epoch:  169  	Training Loss: 0.035320401191711426
Test Loss:  0.034825608134269714
Valid Loss:  0.03295052796602249
Epoch:  170  	Training Loss: 0.03530963137745857
Test Loss:  0.03481384739279747
Valid Loss:  0.03294054791331291
Epoch:  171  	Training Loss: 0.03529886528849602
Test Loss:  0.034802086651325226
Valid Loss:  0.03293056786060333
Epoch:  172  	Training Loss: 0.03528810292482376
Test Loss:  0.0347907617688179
Valid Loss:  0.032920971512794495
Epoch:  173  	Training Loss: 0.03527774661779404
Test Loss:  0.03477945178747177
Valid Loss:  0.03291137143969536
Epoch:  174  	Training Loss: 0.03526739403605461
Test Loss:  0.03476813808083534
Valid Loss:  0.03290177509188652
Epoch:  175  	Training Loss: 0.03525703772902489
Test Loss:  0.03475682809948921
Valid Loss:  0.03289218991994858
Epoch:  176  	Training Loss: 0.03524669259786606
Test Loss:  0.03474552929401398
Valid Loss:  0.03288260102272034
Epoch:  177  	Training Loss: 0.03523635119199753
Test Loss:  0.034734223037958145
Valid Loss:  0.032873012125492096
Epoch:  178  	Training Loss: 0.035226009786129
Test Loss:  0.03472292423248291
Valid Loss:  0.03286343067884445
Epoch:  179  	Training Loss: 0.03521566838026047
Test Loss:  0.03471163287758827
Valid Loss:  0.032853852957487106
Epoch:  180  	Training Loss: 0.03520533815026283
Test Loss:  0.034700341522693634
Valid Loss:  0.03284427151083946
Epoch:  181  	Training Loss: 0.0351950041949749
Test Loss:  0.03468906134366989
Valid Loss:  0.032834701240062714
Epoch:  182  	Training Loss: 0.03518467769026756
Test Loss:  0.03467823565006256
Valid Loss:  0.0328255221247673
Epoch:  183  	Training Loss: 0.03517477586865425
Test Loss:  0.034667424857616425
Valid Loss:  0.03281635046005249
Epoch:  184  	Training Loss: 0.035164885222911835
Test Loss:  0.03465661033987999
Valid Loss:  0.03280717879533768
Epoch:  185  	Training Loss: 0.03515498712658882
Test Loss:  0.03464579954743385
Valid Loss:  0.03279801458120346
Epoch:  186  	Training Loss: 0.035145096480846405
Test Loss:  0.03463499993085861
Valid Loss:  0.032788850367069244
Epoch:  187  	Training Loss: 0.035135213285684586
Test Loss:  0.03462419658899307
Valid Loss:  0.032779693603515625
Epoch:  188  	Training Loss: 0.035125330090522766
Test Loss:  0.03461339324712753
Valid Loss:  0.03277053311467171
Epoch:  189  	Training Loss: 0.035115450620651245
Test Loss:  0.03460259735584259
Valid Loss:  0.032761380076408386
Epoch:  190  	Training Loss: 0.035105571150779724
Test Loss:  0.034591808915138245
Valid Loss:  0.032752227038145065
Epoch:  191  	Training Loss: 0.0350956991314888
Test Loss:  0.0345810241997242
Valid Loss:  0.03274307772517204
Epoch:  192  	Training Loss: 0.035085827112197876
Test Loss:  0.03457067534327507
Valid Loss:  0.03273429721593857
Epoch:  193  	Training Loss: 0.035076361149549484
Test Loss:  0.03456033021211624
Valid Loss:  0.03272552788257599
Epoch:  194  	Training Loss: 0.03506689518690109
Test Loss:  0.03454998880624771
Valid Loss:  0.03271676227450371
Epoch:  195  	Training Loss: 0.035057432949543
Test Loss:  0.034539658576250076
Valid Loss:  0.03270799666643143
Epoch:  196  	Training Loss: 0.0350479781627655
Test Loss:  0.03452932834625244
Valid Loss:  0.032699234783649445
Epoch:  197  	Training Loss: 0.03503852337598801
Test Loss:  0.034519001841545105
Valid Loss:  0.03269048035144806
Epoch:  198  	Training Loss: 0.03502907603979111
Test Loss:  0.034508682787418365
Valid Loss:  0.03268171846866608
Epoch:  199  	Training Loss: 0.035019632428884506
Test Loss:  0.03449835628271103
Valid Loss:  0.03267297148704529
Epoch:  200  	Training Loss: 0.035010188817977905
Test Loss:  0.03448805212974548
Valid Loss:  0.0326642245054245
Epoch:  201  	Training Loss: 0.0350007563829422
Test Loss:  0.03447774425148964
Valid Loss:  0.03265548497438431
Epoch:  202  	Training Loss: 0.034991323947906494
Test Loss:  0.03446788340806961
Valid Loss:  0.03264712169766426
Epoch:  203  	Training Loss: 0.03498230129480362
Test Loss:  0.034458011388778687
Valid Loss:  0.03263876214623451
Epoch:  204  	Training Loss: 0.034973274916410446
Test Loss:  0.034448154270648956
Valid Loss:  0.032630398869514465
Epoch:  205  	Training Loss: 0.03496425971388817
Test Loss:  0.03443830460309982
Valid Loss:  0.03262203931808472
Epoch:  206  	Training Loss: 0.03495524078607559
Test Loss:  0.03442844748497009
Valid Loss:  0.032613687217235565
Epoch:  207  	Training Loss: 0.034946225583553314
Test Loss:  0.03441859781742096
Valid Loss:  0.032605335116386414
Epoch:  208  	Training Loss: 0.034937214106321335
Test Loss:  0.03440875560045242
Valid Loss:  0.03259699046611786
Epoch:  209  	Training Loss: 0.03492821007966995
Test Loss:  0.03439891338348389
Valid Loss:  0.032588645815849304
Epoch:  210  	Training Loss: 0.03491920232772827
Test Loss:  0.03438907489180565
Valid Loss:  0.03258030116558075
Epoch:  211  	Training Loss: 0.03491020202636719
Test Loss:  0.03437923640012741
Valid Loss:  0.03257196024060249
Epoch:  212  	Training Loss: 0.034901201725006104
Test Loss:  0.0343698225915432
Valid Loss:  0.03256397694349289
Epoch:  213  	Training Loss: 0.03489258885383606
Test Loss:  0.034360408782958984
Valid Loss:  0.03255598992109299
Epoch:  214  	Training Loss: 0.034883975982666016
Test Loss:  0.03435099124908447
Valid Loss:  0.03254801407456398
Epoch:  215  	Training Loss: 0.03487536311149597
Test Loss:  0.03434158116579056
Valid Loss:  0.032540030777454376
 43%|████▎     | 217/500 [02:30<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:30<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:37<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:37<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:37<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:37<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:44<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:44<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:44<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.25it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:50<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:51<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:51<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:51<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.02it/s] 50%|█████     | 251/500 [02:57<04:54,  1.18s/it] 51%|█████     | 253/500 [02:57<03:29,  1.18it/s] 51%|█████     | 255/500 [02:57<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:58<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:58<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:04<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:05<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:11<04:33,  1.19s/it] 55%|█████▍    | 273/500 [03:11<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:11<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:11<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:12<01:15,  2.94it/s] 56%|█████▌    | 281/500 [03:18<04:22,  1.20s/it] 57%|█████▋    | 283/500 [03:18<03:07,  1.16it/s] 57%|█████▋    | 285/500 [03:18<02:14,  1.60it/s]Epoch:  216  	Training Loss: 0.034866753965616226
Test Loss:  0.03433217853307724
Valid Loss:  0.03253205865621567
Epoch:  217  	Training Loss: 0.03485814854502678
Test Loss:  0.03432277590036392
Valid Loss:  0.03252407908439636
Epoch:  218  	Training Loss: 0.03484954312443733
Test Loss:  0.034313369542360306
Valid Loss:  0.03251611441373825
Epoch:  219  	Training Loss: 0.034840941429138184
Test Loss:  0.03430397808551788
Valid Loss:  0.03250814601778984
Epoch:  220  	Training Loss: 0.03483234718441963
Test Loss:  0.034294579178094864
Valid Loss:  0.03250017762184143
Epoch:  221  	Training Loss: 0.03482375293970108
Test Loss:  0.03428518399596214
Valid Loss:  0.03249221667647362
Epoch:  222  	Training Loss: 0.03481515869498253
Test Loss:  0.03427617624402046
Valid Loss:  0.03248457610607147
Epoch:  223  	Training Loss: 0.03480691462755203
Test Loss:  0.03426716476678848
Valid Loss:  0.032476942986249924
Epoch:  224  	Training Loss: 0.03479867801070213
Test Loss:  0.0342581681907177
Valid Loss:  0.032469309866428375
Epoch:  225  	Training Loss: 0.034790441393852234
Test Loss:  0.03424917161464691
Valid Loss:  0.032461684197187424
Epoch:  226  	Training Loss: 0.03478220850229263
Test Loss:  0.03424017131328583
Valid Loss:  0.03245405852794647
Epoch:  227  	Training Loss: 0.03477397933602333
Test Loss:  0.03423117846250534
Valid Loss:  0.03244642913341522
Epoch:  228  	Training Loss: 0.03476575016975403
Test Loss:  0.034222185611724854
Valid Loss:  0.03243880718946457
Epoch:  229  	Training Loss: 0.03475753217935562
Test Loss:  0.03421320021152496
Valid Loss:  0.032431188970804214
Epoch:  230  	Training Loss: 0.03474930673837662
Test Loss:  0.03420421481132507
Valid Loss:  0.03242357447743416
Epoch:  231  	Training Loss: 0.03474108502268791
Test Loss:  0.03419522941112518
Valid Loss:  0.032415956258773804
Epoch:  232  	Training Loss: 0.034732867032289505
Test Loss:  0.034186623990535736
Valid Loss:  0.032408662140369415
Epoch:  233  	Training Loss: 0.034724995493888855
Test Loss:  0.03417801111936569
Valid Loss:  0.03240136802196503
Epoch:  234  	Training Loss: 0.034717120230197906
Test Loss:  0.03416941314935684
Valid Loss:  0.03239407390356064
Epoch:  235  	Training Loss: 0.034709252417087555
Test Loss:  0.03416081517934799
Valid Loss:  0.03238678351044655
Epoch:  236  	Training Loss: 0.0347013920545578
Test Loss:  0.03415221720933914
Valid Loss:  0.032379500567913055
Epoch:  237  	Training Loss: 0.03469352796673775
Test Loss:  0.03414362296462059
Valid Loss:  0.032372210174798965
Epoch:  238  	Training Loss: 0.034685663878917694
Test Loss:  0.03413502871990204
Valid Loss:  0.03236493095755577
Epoch:  239  	Training Loss: 0.03467780351638794
Test Loss:  0.034126441925764084
Valid Loss:  0.03235764801502228
Epoch:  240  	Training Loss: 0.03466994687914848
Test Loss:  0.03411785513162613
Valid Loss:  0.03235036879777908
Epoch:  241  	Training Loss: 0.03466209024190903
Test Loss:  0.03410927951335907
Valid Loss:  0.032343097031116486
Epoch:  242  	Training Loss: 0.034654244780540466
Test Loss:  0.034101009368896484
Valid Loss:  0.03233609348535538
Epoch:  243  	Training Loss: 0.03464668244123459
Test Loss:  0.034092746675014496
Valid Loss:  0.03232908993959427
Epoch:  244  	Training Loss: 0.03463912755250931
Test Loss:  0.034084487706422806
Valid Loss:  0.03232208639383316
Epoch:  245  	Training Loss: 0.03463157266378403
Test Loss:  0.034076228737831116
Valid Loss:  0.03231509402394295
Epoch:  246  	Training Loss: 0.034624017775058746
Test Loss:  0.034067973494529724
Valid Loss:  0.03230809420347214
Epoch:  247  	Training Loss: 0.034616466611623764
Test Loss:  0.03405971825122833
Valid Loss:  0.032301098108291626
Epoch:  248  	Training Loss: 0.03460891917347908
Test Loss:  0.03405146673321724
Valid Loss:  0.032294102013111115
Epoch:  249  	Training Loss: 0.034601371735334396
Test Loss:  0.034043218940496445
Valid Loss:  0.0322871133685112
Epoch:  250  	Training Loss: 0.03459382429718971
Test Loss:  0.03403497487306595
Valid Loss:  0.032280124723911285
Epoch:  251  	Training Loss: 0.03458628058433533
Test Loss:  0.034026727080345154
Valid Loss:  0.03227313235402107
Epoch:  252  	Training Loss: 0.03457874059677124
Test Loss:  0.03401884809136391
Valid Loss:  0.03226646035909653
Epoch:  253  	Training Loss: 0.034571535885334015
Test Loss:  0.03401096910238266
Valid Loss:  0.03225978836417198
Epoch:  254  	Training Loss: 0.03456433489918709
Test Loss:  0.03400310501456261
Valid Loss:  0.032253116369247437
Epoch:  255  	Training Loss: 0.03455713391304016
Test Loss:  0.03399522975087166
Valid Loss:  0.03224644437432289
Epoch:  256  	Training Loss: 0.034549932926893234
Test Loss:  0.03398735821247101
Valid Loss:  0.03223977982997894
Epoch:  257  	Training Loss: 0.034542739391326904
Test Loss:  0.033979497849941254
Valid Loss:  0.032233111560344696
Epoch:  258  	Training Loss: 0.034535545855760574
Test Loss:  0.0339716300368309
Valid Loss:  0.03222644701600075
Epoch:  259  	Training Loss: 0.034528352320194244
Test Loss:  0.03396376967430115
Valid Loss:  0.0322197824716568
Epoch:  260  	Training Loss: 0.03452116250991821
Test Loss:  0.03395591303706169
Valid Loss:  0.03221312537789345
Epoch:  261  	Training Loss: 0.03451398015022278
Test Loss:  0.033948056399822235
Valid Loss:  0.032206468284130096
Epoch:  262  	Training Loss: 0.03450679033994675
Test Loss:  0.03394051268696785
Valid Loss:  0.032200075685977936
Epoch:  263  	Training Loss: 0.034499891102313995
Test Loss:  0.033932968974113464
Valid Loss:  0.03219367936253548
Epoch:  264  	Training Loss: 0.034492991864681244
Test Loss:  0.03392542526125908
Valid Loss:  0.032187290489673615
Epoch:  265  	Training Loss: 0.03448609262704849
Test Loss:  0.03391788527369499
Valid Loss:  0.03218090534210205
Epoch:  266  	Training Loss: 0.03447920083999634
Test Loss:  0.033910345286130905
Valid Loss:  0.03217451646924019
Epoch:  267  	Training Loss: 0.03447230905294418
Test Loss:  0.03390280902385712
Valid Loss:  0.03216813504695892
Epoch:  268  	Training Loss: 0.03446541726589203
Test Loss:  0.03389527648687363
Valid Loss:  0.03216174989938736
Epoch:  269  	Training Loss: 0.034458525478839874
Test Loss:  0.03388774394989014
Valid Loss:  0.03215537220239639
Epoch:  270  	Training Loss: 0.03445163741707802
Test Loss:  0.033880218863487244
Valid Loss:  0.03214898705482483
Epoch:  271  	Training Loss: 0.03444475680589676
Test Loss:  0.03387269377708435
Valid Loss:  0.03214261308312416
Epoch:  272  	Training Loss: 0.0344378724694252
Test Loss:  0.03386545181274414
Valid Loss:  0.032136477530002594
Epoch:  273  	Training Loss: 0.034431252628564835
Test Loss:  0.03385821729898453
Valid Loss:  0.032130349427461624
Epoch:  274  	Training Loss: 0.03442463278770447
Test Loss:  0.03385097533464432
Valid Loss:  0.032124217599630356
Epoch:  275  	Training Loss: 0.0344180166721344
Test Loss:  0.033843740820884705
Valid Loss:  0.032118089497089386
Epoch:  276  	Training Loss: 0.03441140055656433
Test Loss:  0.03383651003241539
Valid Loss:  0.032111965119838715
Epoch:  277  	Training Loss: 0.03440479189157486
Test Loss:  0.03382927551865578
Valid Loss:  0.032105833292007446
Epoch:  278  	Training Loss: 0.03439817577600479
Test Loss:  0.03382205218076706
Valid Loss:  0.03209971264004707
Epoch:  279  	Training Loss: 0.03439156711101532
Test Loss:  0.033814821392297745
Valid Loss:  0.0320935882627964
Epoch:  280  	Training Loss: 0.03438495844602585
Test Loss:  0.03380759432911873
Valid Loss:  0.03208747133612633
Epoch:  281  	Training Loss: 0.03437834978103638
Test Loss:  0.03380037471652031
Valid Loss:  0.032081346958875656
Epoch:  282  	Training Loss: 0.034371741116046906
Test Loss:  0.03379344195127487
Valid Loss:  0.03207548335194588
Epoch:  283  	Training Loss: 0.03436540812253952
Test Loss:  0.03378652036190033
Valid Loss:  0.0320696197450161
Epoch:  284  	Training Loss: 0.03435908257961273
Test Loss:  0.03377959877252579
Valid Loss:  0.03206375241279602
Epoch:  285  	Training Loss: 0.034352753311395645
Test Loss:  0.033772677183151245
Valid Loss:  0.03205789253115654
Epoch:  286  	Training Loss: 0.03434642404317856
Test Loss:  0.033765759319067
Valid Loss:  0.03205203264951706
 57%|█████▋    | 287/500 [03:18<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:19<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:25<04:14,  1.22s/it] 59%|█████▊    | 293/500 [03:25<03:01,  1.14it/s] 59%|█████▉    | 295/500 [03:25<02:09,  1.58it/s] 59%|█████▉    | 297/500 [03:25<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:26<01:08,  2.92it/s] 60%|██████    | 301/500 [03:32<04:00,  1.21s/it] 61%|██████    | 303/500 [03:32<02:50,  1.16it/s] 61%|██████    | 305/500 [03:32<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:32<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:33<01:04,  2.94it/s] 62%|██████▏   | 311/500 [03:39<03:49,  1.21s/it] 62%|██████▏   | 312/500 [03:39<03:11,  1.02s/it] 63%|██████▎   | 314/500 [03:39<02:10,  1.43it/s] 63%|██████▎   | 316/500 [03:39<01:31,  2.02it/s] 64%|██████▎   | 318/500 [03:40<01:05,  2.79it/s] 64%|██████▍   | 320/500 [03:40<00:48,  3.74it/s] 64%|██████▍   | 322/500 [03:46<03:29,  1.18s/it] 65%|██████▍   | 324/500 [03:46<02:27,  1.19it/s] 65%|██████▌   | 326/500 [03:46<01:44,  1.66it/s] 66%|██████▌   | 328/500 [03:47<01:15,  2.27it/s] 66%|██████▌   | 330/500 [03:47<00:55,  3.05it/s] 66%|██████▋   | 332/500 [03:53<03:22,  1.20s/it] 67%|██████▋   | 334/500 [03:53<02:22,  1.16it/s] 67%|██████▋   | 336/500 [03:53<01:41,  1.61it/s] 68%|██████▊   | 338/500 [03:54<01:13,  2.20it/s] 68%|██████▊   | 340/500 [03:54<00:53,  2.97it/s] 68%|██████▊   | 342/500 [04:00<03:06,  1.18s/it] 69%|██████▉   | 344/500 [04:00<02:11,  1.18it/s] 69%|██████▉   | 346/500 [04:00<01:34,  1.64it/s] 70%|██████▉   | 348/500 [04:00<01:08,  2.23it/s] 70%|███████   | 350/500 [04:00<00:49,  3.01it/s] 70%|███████   | 352/500 [04:07<02:54,  1.18s/it] 71%|███████   | 354/500 [04:07<02:03,  1.18it/s] 71%|███████   | 356/500 [04:07<01:27,  1.64it/s]Epoch:  287  	Training Loss: 0.03434009850025177
Test Loss:  0.03375884145498276
Valid Loss:  0.03204617276787758
Epoch:  288  	Training Loss: 0.03433378040790558
Test Loss:  0.033751919865608215
Valid Loss:  0.0320403166115284
Epoch:  289  	Training Loss: 0.03432745486497879
Test Loss:  0.03374501317739487
Valid Loss:  0.03203446418046951
Epoch:  290  	Training Loss: 0.0343211367726326
Test Loss:  0.03373809903860092
Valid Loss:  0.03202860802412033
Epoch:  291  	Training Loss: 0.03431481868028641
Test Loss:  0.03373119235038757
Valid Loss:  0.032022759318351746
Epoch:  292  	Training Loss: 0.034308500587940216
Test Loss:  0.03372454270720482
Valid Loss:  0.03201713413000107
Epoch:  293  	Training Loss: 0.03430242836475372
Test Loss:  0.03371790796518326
Valid Loss:  0.03201150894165039
Epoch:  294  	Training Loss: 0.03429635614156723
Test Loss:  0.0337112620472908
Valid Loss:  0.03200588375329971
Epoch:  295  	Training Loss: 0.034290287643671036
Test Loss:  0.03370462357997894
Valid Loss:  0.03200026601552963
Epoch:  296  	Training Loss: 0.03428421914577484
Test Loss:  0.033697985112667084
Valid Loss:  0.031994640827178955
Epoch:  297  	Training Loss: 0.03427814692258835
Test Loss:  0.03369135037064552
Valid Loss:  0.03198902681469917
Epoch:  298  	Training Loss: 0.03427208214998245
Test Loss:  0.03368471562862396
Valid Loss:  0.031983405351638794
Epoch:  299  	Training Loss: 0.03426602482795715
Test Loss:  0.0336780846118927
Valid Loss:  0.03197779133915901
Epoch:  300  	Training Loss: 0.03425996005535126
Test Loss:  0.03367145359516144
Valid Loss:  0.03197217732667923
Epoch:  301  	Training Loss: 0.03425389528274536
Test Loss:  0.033664822578430176
Valid Loss:  0.031966567039489746
Epoch:  302  	Training Loss: 0.03424783796072006
Test Loss:  0.033658433705568314
Valid Loss:  0.03196115791797638
Epoch:  303  	Training Loss: 0.034241996705532074
Test Loss:  0.033652037382125854
Valid Loss:  0.031955741345882416
Epoch:  304  	Training Loss: 0.034236155450344086
Test Loss:  0.03364565223455429
Valid Loss:  0.03195033594965935
Epoch:  305  	Training Loss: 0.0342303141951561
Test Loss:  0.03363926708698273
Valid Loss:  0.03194493055343628
Epoch:  306  	Training Loss: 0.034224484115839005
Test Loss:  0.033632878214120865
Valid Loss:  0.03193952515721321
Epoch:  307  	Training Loss: 0.034218646585941315
Test Loss:  0.033626489341259
Valid Loss:  0.031934116035699844
Epoch:  308  	Training Loss: 0.034212809056043625
Test Loss:  0.03362010791897774
Valid Loss:  0.031928714364767075
Epoch:  309  	Training Loss: 0.034206975251436234
Test Loss:  0.03361372649669647
Valid Loss:  0.031923312693834305
Epoch:  310  	Training Loss: 0.03420114517211914
Test Loss:  0.03360734507441521
Valid Loss:  0.031917911022901535
Epoch:  311  	Training Loss: 0.03419531509280205
Test Loss:  0.03360097110271454
Valid Loss:  0.031912509351968765
Epoch:  312  	Training Loss: 0.034189485013484955
Test Loss:  0.033594828099012375
Valid Loss:  0.03190731257200241
Epoch:  313  	Training Loss: 0.03418387472629547
Test Loss:  0.03358868509531021
Valid Loss:  0.031902119517326355
Epoch:  314  	Training Loss: 0.03417826443910599
Test Loss:  0.033582545816898346
Valid Loss:  0.03189692273736
Epoch:  315  	Training Loss: 0.034172654151916504
Test Loss:  0.03357640653848648
Valid Loss:  0.031891725957393646
Epoch:  316  	Training Loss: 0.03416704386472702
Test Loss:  0.033570267260074615
Valid Loss:  0.03188653290271759
Epoch:  317  	Training Loss: 0.03416143357753754
Test Loss:  0.03356413170695305
Valid Loss:  0.031881339848041534
Epoch:  318  	Training Loss: 0.03415583074092865
Test Loss:  0.03355799615383148
Valid Loss:  0.03187614679336548
Epoch:  319  	Training Loss: 0.03415022790431976
Test Loss:  0.033551864326000214
Valid Loss:  0.03187096118927002
Epoch:  320  	Training Loss: 0.034144625067710876
Test Loss:  0.03354572504758835
Valid Loss:  0.031865768134593964
Epoch:  321  	Training Loss: 0.03413902223110199
Test Loss:  0.03353960067033768
Valid Loss:  0.031860582530498505
Epoch:  322  	Training Loss: 0.0341334193944931
Test Loss:  0.03353366628289223
Valid Loss:  0.031855564564466476
Epoch:  323  	Training Loss: 0.03412800282239914
Test Loss:  0.033527739346027374
Valid Loss:  0.03185054659843445
Epoch:  324  	Training Loss: 0.034122586250305176
Test Loss:  0.03352181240916252
Valid Loss:  0.03184553608298302
Epoch:  325  	Training Loss: 0.03411716967821121
Test Loss:  0.03351588547229767
Valid Loss:  0.031840525567531586
Epoch:  326  	Training Loss: 0.03411175683140755
Test Loss:  0.033509962260723114
Valid Loss:  0.03183550387620926
Epoch:  327  	Training Loss: 0.03410634398460388
Test Loss:  0.03350403532385826
Valid Loss:  0.031830497086048126
Epoch:  328  	Training Loss: 0.03410093113780022
Test Loss:  0.033498115837574005
Valid Loss:  0.031825486570596695
Epoch:  329  	Training Loss: 0.03409551829099655
Test Loss:  0.03349218890070915
Valid Loss:  0.031820476055145264
Epoch:  330  	Training Loss: 0.034090109169483185
Test Loss:  0.033486269414424896
Valid Loss:  0.031815461814403534
Epoch:  331  	Training Loss: 0.03408470004796982
Test Loss:  0.03348034620285034
Valid Loss:  0.0318104550242424
Epoch:  332  	Training Loss: 0.03407929465174675
Test Loss:  0.033474620431661606
Valid Loss:  0.031805604696273804
Epoch:  333  	Training Loss: 0.03407406061887741
Test Loss:  0.03346888720989227
Valid Loss:  0.0318007618188858
Epoch:  334  	Training Loss: 0.03406883031129837
Test Loss:  0.03346315771341324
Valid Loss:  0.0317959189414978
Epoch:  335  	Training Loss: 0.03406359627842903
Test Loss:  0.033457428216934204
Valid Loss:  0.0317910760641098
Epoch:  336  	Training Loss: 0.03405836597084999
Test Loss:  0.033451709896326065
Valid Loss:  0.0317862331867218
Epoch:  337  	Training Loss: 0.03405313938856125
Test Loss:  0.03344598412513733
Valid Loss:  0.0317813865840435
Epoch:  338  	Training Loss: 0.03404790535569191
Test Loss:  0.03344026207923889
Valid Loss:  0.0317765474319458
Epoch:  339  	Training Loss: 0.03404267877340317
Test Loss:  0.033434540033340454
Valid Loss:  0.0317717045545578
Epoch:  340  	Training Loss: 0.03403744846582413
Test Loss:  0.03342881798744202
Valid Loss:  0.0317668654024601
Epoch:  341  	Training Loss: 0.034032225608825684
Test Loss:  0.03342309594154358
Valid Loss:  0.031762026250362396
Epoch:  342  	Training Loss: 0.03402700275182724
Test Loss:  0.03341758996248245
Valid Loss:  0.03175736963748932
Epoch:  343  	Training Loss: 0.034021977335214615
Test Loss:  0.03341209143400192
Valid Loss:  0.03175272420048714
Epoch:  344  	Training Loss: 0.03401695191860199
Test Loss:  0.03340660035610199
Valid Loss:  0.031748075038194656
Epoch:  345  	Training Loss: 0.03401193395256996
Test Loss:  0.03340110182762146
Valid Loss:  0.031743425875902176
Epoch:  346  	Training Loss: 0.03400691598653793
Test Loss:  0.03339560702443123
Valid Loss:  0.031738780438899994
Epoch:  347  	Training Loss: 0.03400189429521561
Test Loss:  0.033390112221241
Valid Loss:  0.03173413127660751
Epoch:  348  	Training Loss: 0.03399688005447388
Test Loss:  0.03338461369276047
Valid Loss:  0.03172948956489563
Epoch:  349  	Training Loss: 0.03399186581373215
Test Loss:  0.033379122614860535
Valid Loss:  0.03172484412789345
Epoch:  350  	Training Loss: 0.03398684784770012
Test Loss:  0.0333736389875412
Valid Loss:  0.031720202416181564
Epoch:  351  	Training Loss: 0.03398183733224869
Test Loss:  0.033368147909641266
Valid Loss:  0.03171555697917938
Epoch:  352  	Training Loss: 0.03397681936621666
Test Loss:  0.033362820744514465
Valid Loss:  0.03171105310320854
Epoch:  353  	Training Loss: 0.03397195786237717
Test Loss:  0.033357493579387665
Valid Loss:  0.031706552952528
Epoch:  354  	Training Loss: 0.033967096358537674
Test Loss:  0.03335217386484146
Valid Loss:  0.03170205280184746
Epoch:  355  	Training Loss: 0.03396223485469818
Test Loss:  0.03334684669971466
Valid Loss:  0.031697552651166916
Epoch:  356  	Training Loss: 0.03395737707614899
Test Loss:  0.03334152698516846
Valid Loss:  0.031693052500486374
Epoch:  357  	Training Loss: 0.03395251929759979
Test Loss:  0.033336199820041656
Valid Loss:  0.03168855607509613
Epoch:  358  	Training Loss: 0.0339476615190506
 72%|███████▏  | 358/500 [04:07<01:03,  2.23it/s] 72%|███████▏  | 360/500 [04:07<00:46,  2.98it/s] 72%|███████▏  | 362/500 [04:14<02:46,  1.20s/it] 73%|███████▎  | 364/500 [04:14<01:57,  1.16it/s] 73%|███████▎  | 366/500 [04:14<01:23,  1.60it/s] 74%|███████▎  | 368/500 [04:14<01:00,  2.19it/s] 74%|███████▍  | 370/500 [04:14<00:44,  2.92it/s] 74%|███████▍  | 372/500 [04:21<02:31,  1.18s/it] 75%|███████▍  | 374/500 [04:21<01:46,  1.18it/s] 75%|███████▌  | 376/500 [04:21<01:15,  1.63it/s] 76%|███████▌  | 378/500 [04:21<00:54,  2.23it/s] 76%|███████▌  | 380/500 [04:21<00:40,  3.00it/s] 76%|███████▋  | 382/500 [04:28<02:20,  1.19s/it] 77%|███████▋  | 384/500 [04:28<01:39,  1.17it/s] 77%|███████▋  | 386/500 [04:28<01:10,  1.62it/s] 78%|███████▊  | 388/500 [04:28<00:50,  2.21it/s] 78%|███████▊  | 390/500 [04:28<00:37,  2.91it/s] 78%|███████▊  | 392/500 [04:34<02:07,  1.18s/it] 79%|███████▉  | 394/500 [04:35<01:29,  1.18it/s] 79%|███████▉  | 396/500 [04:35<01:03,  1.63it/s] 80%|███████▉  | 398/500 [04:35<00:45,  2.23it/s] 80%|████████  | 400/500 [04:35<00:33,  2.99it/s] 80%|████████  | 402/500 [04:41<01:56,  1.19s/it] 81%|████████  | 404/500 [04:41<01:21,  1.17it/s] 81%|████████  | 406/500 [04:42<00:57,  1.62it/s] 82%|████████▏ | 408/500 [04:42<00:41,  2.22it/s] 82%|████████▏ | 410/500 [04:42<00:30,  2.93it/s] 82%|████████▏ | 412/500 [04:48<01:45,  1.19s/it] 83%|████████▎ | 414/500 [04:48<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:48<00:51,  1.62it/s] 84%|████████▎ | 418/500 [04:49<00:37,  2.21it/s] 84%|████████▍ | 420/500 [04:49<00:27,  2.95it/s] 84%|████████▍ | 422/500 [04:55<01:32,  1.18s/it] 85%|████████▍ | 424/500 [04:55<01:04,  1.18it/s] 85%|████████▌ | 426/500 [04:55<00:45,  1.63it/s] 86%|████████▌ | 428/500 [04:55<00:32,  2.23it/s]Test Loss:  0.03333088383078575
Valid Loss:  0.03168405592441559
Epoch:  359  	Training Loss: 0.033942803740501404
Test Loss:  0.03332556039094925
Valid Loss:  0.03167956322431564
Epoch:  360  	Training Loss: 0.03393794596195221
Test Loss:  0.033320240676403046
Valid Loss:  0.0316750630736351
Epoch:  361  	Training Loss: 0.033933091908693314
Test Loss:  0.03331492096185684
Valid Loss:  0.03167056664824486
Epoch:  362  	Training Loss: 0.03392823785543442
Test Loss:  0.03330978751182556
Valid Loss:  0.03166622668504715
Epoch:  363  	Training Loss: 0.033923543989658356
Test Loss:  0.033304646611213684
Valid Loss:  0.03166188672184944
Epoch:  364  	Training Loss: 0.03391885757446289
Test Loss:  0.033299513161182404
Valid Loss:  0.031657543033361435
Epoch:  365  	Training Loss: 0.03391416743397713
Test Loss:  0.033294375985860825
Valid Loss:  0.03165320307016373
Epoch:  366  	Training Loss: 0.033909477293491364
Test Loss:  0.03328924626111984
Valid Loss:  0.03164886683225632
Epoch:  367  	Training Loss: 0.0339047946035862
Test Loss:  0.03328411281108856
Valid Loss:  0.03164453059434891
Epoch:  368  	Training Loss: 0.03390010818839073
Test Loss:  0.03327897936105728
Valid Loss:  0.0316401906311512
Epoch:  369  	Training Loss: 0.033895425498485565
Test Loss:  0.0332738496363163
Valid Loss:  0.03163585439324379
Epoch:  370  	Training Loss: 0.0338907390832901
Test Loss:  0.03326871991157532
Valid Loss:  0.03163151443004608
Epoch:  371  	Training Loss: 0.03388606011867523
Test Loss:  0.03326358646154404
Valid Loss:  0.03162718191742897
Epoch:  372  	Training Loss: 0.033881377428770065
Test Loss:  0.033258598297834396
Valid Loss:  0.03162296861410141
Epoch:  373  	Training Loss: 0.033876825124025345
Test Loss:  0.03325360640883446
Valid Loss:  0.03161874786019325
Epoch:  374  	Training Loss: 0.033872269093990326
Test Loss:  0.033248621970415115
Valid Loss:  0.03161453455686569
Epoch:  375  	Training Loss: 0.033867716789245605
Test Loss:  0.03324363753199577
Valid Loss:  0.03161032497882843
Epoch:  376  	Training Loss: 0.033863164484500885
Test Loss:  0.03323864936828613
Valid Loss:  0.03160610795021057
Epoch:  377  	Training Loss: 0.033858612179756165
Test Loss:  0.03323366120457649
Valid Loss:  0.03160189464688301
Epoch:  378  	Training Loss: 0.03385406360030174
Test Loss:  0.03322867676615715
Valid Loss:  0.03159768506884575
Epoch:  379  	Training Loss: 0.03384951502084732
Test Loss:  0.03322368860244751
Valid Loss:  0.03159347549080849
Epoch:  380  	Training Loss: 0.0338449701666832
Test Loss:  0.033218707889318466
Valid Loss:  0.031589262187480927
Epoch:  381  	Training Loss: 0.03384041786193848
Test Loss:  0.03321372717618942
Valid Loss:  0.031585052609443665
Epoch:  382  	Training Loss: 0.03383587300777435
Test Loss:  0.03320888802409172
Valid Loss:  0.03158096596598625
Epoch:  383  	Training Loss: 0.03383145481348038
Test Loss:  0.03320404887199402
Valid Loss:  0.03157687932252884
Epoch:  384  	Training Loss: 0.033827044069767
Test Loss:  0.033199213445186615
Valid Loss:  0.031572792679071426
Epoch:  385  	Training Loss: 0.03382262587547302
Test Loss:  0.03319437801837921
Valid Loss:  0.031568706035614014
Epoch:  386  	Training Loss: 0.033818215131759644
Test Loss:  0.03318954259157181
Valid Loss:  0.0315646231174469
Epoch:  387  	Training Loss: 0.033813804388046265
Test Loss:  0.033184707164764404
Valid Loss:  0.03156053647398949
Epoch:  388  	Training Loss: 0.033809393644332886
Test Loss:  0.033179871737957
Valid Loss:  0.03155645728111267
Epoch:  389  	Training Loss: 0.03380497917532921
Test Loss:  0.033175040036439896
Valid Loss:  0.03155237063765526
Epoch:  390  	Training Loss: 0.03380057215690613
Test Loss:  0.03317020833492279
Valid Loss:  0.03154829144477844
Epoch:  391  	Training Loss: 0.03379616513848305
Test Loss:  0.03316537290811539
Valid Loss:  0.03154420852661133
Epoch:  392  	Training Loss: 0.03379175812005997
Test Loss:  0.03316068649291992
Valid Loss:  0.03154024854302406
Epoch:  393  	Training Loss: 0.033787474036216736
Test Loss:  0.03315600007772446
Valid Loss:  0.0315362885594368
Epoch:  394  	Training Loss: 0.0337831974029541
Test Loss:  0.03315131366252899
Valid Loss:  0.03153233230113983
Epoch:  395  	Training Loss: 0.03377892076969147
Test Loss:  0.03314662724733353
Valid Loss:  0.031528372317552567
Epoch:  396  	Training Loss: 0.03377464413642883
Test Loss:  0.033141933381557465
Valid Loss:  0.0315244123339653
Epoch:  397  	Training Loss: 0.033770374953746796
Test Loss:  0.0331372506916523
Valid Loss:  0.03152045980095863
Epoch:  398  	Training Loss: 0.03376609832048416
Test Loss:  0.03313257545232773
Valid Loss:  0.031516507267951965
Epoch:  399  	Training Loss: 0.033761825412511826
Test Loss:  0.03312788903713226
Valid Loss:  0.0315125472843647
Epoch:  400  	Training Loss: 0.03375755250453949
Test Loss:  0.0331232026219368
Valid Loss:  0.03150859475135803
Epoch:  401  	Training Loss: 0.03375328332185745
Test Loss:  0.03311852738261223
Valid Loss:  0.031504638493061066
Epoch:  402  	Training Loss: 0.03374901041388512
Test Loss:  0.033113956451416016
Valid Loss:  0.031500786542892456
Epoch:  403  	Training Loss: 0.033744845539331436
Test Loss:  0.0331093892455101
Valid Loss:  0.03149693086743355
Epoch:  404  	Training Loss: 0.033740680664777756
Test Loss:  0.03310482203960419
Valid Loss:  0.03149307519197464
Epoch:  405  	Training Loss: 0.033736519515514374
Test Loss:  0.03310025855898857
Valid Loss:  0.03148922324180603
Epoch:  406  	Training Loss: 0.03373235464096069
Test Loss:  0.03309569135308266
Valid Loss:  0.03148537129163742
Epoch:  407  	Training Loss: 0.03372819349169731
Test Loss:  0.03309112787246704
Valid Loss:  0.03148151934146881
Epoch:  408  	Training Loss: 0.03372403234243393
Test Loss:  0.033086564391851425
Valid Loss:  0.0314776673913002
Epoch:  409  	Training Loss: 0.03371986746788025
Test Loss:  0.03308200463652611
Valid Loss:  0.03147381544113159
Epoch:  410  	Training Loss: 0.033715710043907166
Test Loss:  0.033077437430620193
Valid Loss:  0.031469959765672684
Epoch:  411  	Training Loss: 0.033711548894643784
Test Loss:  0.033072881400585175
Valid Loss:  0.03146611154079437
Epoch:  412  	Training Loss: 0.0337073877453804
Test Loss:  0.033068425953388214
Valid Loss:  0.03146235644817352
Epoch:  413  	Training Loss: 0.03370332717895508
Test Loss:  0.03306397795677185
Valid Loss:  0.031458597630262375
Epoch:  414  	Training Loss: 0.03369927033782005
Test Loss:  0.03305952623486519
Valid Loss:  0.03145483881235123
Epoch:  415  	Training Loss: 0.03369520977139473
Test Loss:  0.03305507451295853
Valid Loss:  0.03145108371973038
Epoch:  416  	Training Loss: 0.033691152930259705
Test Loss:  0.033050619065761566
Valid Loss:  0.03144732490181923
Epoch:  417  	Training Loss: 0.03368709236383438
Test Loss:  0.0330461710691452
Valid Loss:  0.03144356980919838
Epoch:  418  	Training Loss: 0.03368303179740906
Test Loss:  0.03304171562194824
Valid Loss:  0.03143981099128723
Epoch:  419  	Training Loss: 0.03367897495627403
Test Loss:  0.03303726762533188
Valid Loss:  0.03143605589866638
Epoch:  420  	Training Loss: 0.03367491811513901
Test Loss:  0.033032819628715515
Valid Loss:  0.03143230453133583
Epoch:  421  	Training Loss: 0.033670857548713684
Test Loss:  0.03302837163209915
Valid Loss:  0.03142854571342468
Epoch:  422  	Training Loss: 0.03366680443286896
Test Loss:  0.03302404657006264
Valid Loss:  0.03142489492893219
Epoch:  423  	Training Loss: 0.033662859350442886
Test Loss:  0.03301972150802612
Valid Loss:  0.031421251595020294
Epoch:  424  	Training Loss: 0.03365892171859741
Test Loss:  0.03301540017127991
Valid Loss:  0.0314176008105278
Epoch:  425  	Training Loss: 0.03365498036146164
Test Loss:  0.03301107883453369
Valid Loss:  0.03141395375132561
Epoch:  426  	Training Loss: 0.03365103527903557
Test Loss:  0.03300675377249718
Valid Loss:  0.03141031041741371
Epoch:  427  	Training Loss: 0.033647097647190094
Test Loss:  0.03300242871046066
Valid Loss:  0.03140665590763092
Epoch:  428  	Training Loss: 0.03364315629005432
Test Loss:  0.032998111099004745
Valid Loss:  0.03140301629900932
Epoch:  429  	Training Loss: 0.03363921493291855
Test Loss:  0.03299378603696823
Valid Loss:   86%|████████▌ | 430/500 [04:56<00:23,  2.98it/s] 86%|████████▋ | 432/500 [05:02<01:20,  1.19s/it] 87%|████████▋ | 434/500 [05:02<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:02<00:39,  1.62it/s] 88%|████████▊ | 438/500 [05:02<00:27,  2.22it/s] 88%|████████▊ | 440/500 [05:02<00:20,  2.98it/s] 88%|████████▊ | 442/500 [05:09<01:08,  1.18s/it] 89%|████████▉ | 444/500 [05:09<00:47,  1.18it/s] 89%|████████▉ | 446/500 [05:09<00:33,  1.63it/s] 90%|████████▉ | 448/500 [05:09<00:23,  2.23it/s] 90%|█████████ | 450/500 [05:09<00:16,  2.99it/s] 90%|█████████ | 452/500 [05:16<00:56,  1.18s/it] 91%|█████████ | 454/500 [05:16<00:38,  1.18it/s] 91%|█████████ | 456/500 [05:16<00:26,  1.64it/s] 92%|█████████▏| 458/500 [05:16<00:18,  2.24it/s] 92%|█████████▏| 460/500 [05:16<00:13,  3.01it/s] 92%|█████████▏| 462/500 [05:22<00:44,  1.18s/it] 93%|█████████▎| 464/500 [05:23<00:30,  1.18it/s] 93%|█████████▎| 466/500 [05:23<00:20,  1.64it/s] 94%|█████████▎| 468/500 [05:23<00:14,  2.24it/s] 94%|█████████▍| 470/500 [05:23<00:09,  3.01it/s] 94%|█████████▍| 472/500 [05:29<00:33,  1.19s/it] 95%|█████████▍| 474/500 [05:29<00:22,  1.18it/s] 95%|█████████▌| 476/500 [05:30<00:14,  1.63it/s] 96%|█████████▌| 478/500 [05:30<00:09,  2.23it/s] 96%|█████████▌| 480/500 [05:30<00:06,  3.00it/s] 96%|█████████▋| 482/500 [05:36<00:21,  1.20s/it] 97%|█████████▋| 484/500 [05:36<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:37<00:08,  1.62it/s] 98%|█████████▊| 488/500 [05:37<00:05,  2.21it/s] 98%|█████████▊| 490/500 [05:37<00:03,  2.97it/s] 98%|█████████▊| 492/500 [05:43<00:09,  1.21s/it] 99%|█████████▉| 494/500 [05:43<00:05,  1.16it/s] 99%|█████████▉| 496/500 [05:43<00:02,  1.60it/s]100%|█████████▉| 498/500 [05:44<00:00,  2.19it/s]100%|██████████| 500/500 [05:44<00:00,  2.94it/s]100%|██████████| 500/500 [05:44<00:00,  1.45it/s]
0.03139937296509743
Epoch:  430  	Training Loss: 0.03363528102636337
Test Loss:  0.03298947215080261
Valid Loss:  0.03139572590589523
Epoch:  431  	Training Loss: 0.0336313433945179
Test Loss:  0.032985150814056396
Valid Loss:  0.03139208257198334
Epoch:  432  	Training Loss: 0.033627405762672424
Test Loss:  0.032980918884277344
Valid Loss:  0.03138851374387741
Epoch:  433  	Training Loss: 0.03362354636192322
Test Loss:  0.03297668695449829
Valid Loss:  0.031384944915771484
Epoch:  434  	Training Loss: 0.03361968696117401
Test Loss:  0.03297245502471924
Valid Loss:  0.03138137608766556
Epoch:  435  	Training Loss: 0.0336158312857151
Test Loss:  0.032968223094940186
Valid Loss:  0.03137780353426933
Epoch:  436  	Training Loss: 0.0336119718849659
Test Loss:  0.03296399861574173
Valid Loss:  0.031374238431453705
Epoch:  437  	Training Loss: 0.033608123660087585
Test Loss:  0.03295976668596268
Valid Loss:  0.03137066960334778
Epoch:  438  	Training Loss: 0.03360426425933838
Test Loss:  0.032955534756183624
Valid Loss:  0.03136710822582245
Epoch:  439  	Training Loss: 0.03360040858387947
Test Loss:  0.03295130655169487
Valid Loss:  0.031363535672426224
Epoch:  440  	Training Loss: 0.03359655290842056
Test Loss:  0.032947078347206116
Valid Loss:  0.031359970569610596
Epoch:  441  	Training Loss: 0.03359270095825195
Test Loss:  0.03294285386800766
Valid Loss:  0.03135640174150467
Epoch:  442  	Training Loss: 0.033588849008083344
Test Loss:  0.03293871879577637
Valid Loss:  0.03135291859507561
Epoch:  443  	Training Loss: 0.0335850827395916
Test Loss:  0.03293459117412567
Valid Loss:  0.031349435448646545
Epoch:  444  	Training Loss: 0.033581316471099854
Test Loss:  0.03293045610189438
Valid Loss:  0.031345948576927185
Epoch:  445  	Training Loss: 0.03357754647731781
Test Loss:  0.032926324754953384
Valid Loss:  0.031342461705207825
Epoch:  446  	Training Loss: 0.033573783934116364
Test Loss:  0.03292219340801239
Valid Loss:  0.031338974833488464
Epoch:  447  	Training Loss: 0.03357002139091492
Test Loss:  0.032918065786361694
Valid Loss:  0.0313354954123497
Epoch:  448  	Training Loss: 0.03356625512242317
Test Loss:  0.0329139307141304
Valid Loss:  0.03133200854063034
Epoch:  449  	Training Loss: 0.03356248885393143
Test Loss:  0.032909803092479706
Valid Loss:  0.03132852911949158
Epoch:  450  	Training Loss: 0.03355872631072998
Test Loss:  0.03290567174553871
Valid Loss:  0.031325045973062515
Epoch:  451  	Training Loss: 0.033554963767528534
Test Loss:  0.03290154039859772
Valid Loss:  0.03132156282663345
Epoch:  452  	Training Loss: 0.03355120122432709
Test Loss:  0.03289748728275299
Valid Loss:  0.031318143010139465
Epoch:  453  	Training Loss: 0.03354750573635101
Test Loss:  0.032893430441617966
Valid Loss:  0.03131472319364548
Epoch:  454  	Training Loss: 0.03354381024837494
Test Loss:  0.03288937360048294
Valid Loss:  0.03131130337715149
Epoch:  455  	Training Loss: 0.033540114760398865
Test Loss:  0.032885320484638214
Valid Loss:  0.0313078835606575
Epoch:  456  	Training Loss: 0.03353641554713249
Test Loss:  0.03288126364350319
Valid Loss:  0.03130446374416351
Epoch:  457  	Training Loss: 0.033532723784446716
Test Loss:  0.03287721425294876
Valid Loss:  0.031301047652959824
Epoch:  458  	Training Loss: 0.03352902829647064
Test Loss:  0.032873161137104034
Valid Loss:  0.031297627836465836
Epoch:  459  	Training Loss: 0.03352533280849457
Test Loss:  0.03286910802125931
Valid Loss:  0.031294211745262146
Epoch:  460  	Training Loss: 0.03352164477109909
Test Loss:  0.03286505490541458
Valid Loss:  0.031290795654058456
Epoch:  461  	Training Loss: 0.033517949283123016
Test Loss:  0.03286100924015045
Valid Loss:  0.03128737956285477
Epoch:  462  	Training Loss: 0.03351426124572754
Test Loss:  0.032857030630111694
Valid Loss:  0.03128403425216675
Epoch:  463  	Training Loss: 0.033510636538267136
Test Loss:  0.03285305202007294
Valid Loss:  0.031280677765607834
Epoch:  464  	Training Loss: 0.03350701555609703
Test Loss:  0.03284908086061478
Valid Loss:  0.03127732500433922
Epoch:  465  	Training Loss: 0.03350339084863663
Test Loss:  0.03284510225057602
Valid Loss:  0.0312739759683609
Epoch:  466  	Training Loss: 0.03349976986646652
Test Loss:  0.03284113109111786
Valid Loss:  0.031270623207092285
Epoch:  467  	Training Loss: 0.03349614888429642
Test Loss:  0.0328371524810791
Valid Loss:  0.03126727044582367
Epoch:  468  	Training Loss: 0.03349253162741661
Test Loss:  0.03283318132162094
Valid Loss:  0.03126392140984535
Epoch:  469  	Training Loss: 0.03348890691995621
Test Loss:  0.03282921016216278
Valid Loss:  0.031260572373867035
Epoch:  470  	Training Loss: 0.0334852896630764
Test Loss:  0.03282523155212402
Valid Loss:  0.031257227063179016
Epoch:  471  	Training Loss: 0.033481672406196594
Test Loss:  0.03282126039266586
Valid Loss:  0.0312538780272007
Epoch:  472  	Training Loss: 0.03347805142402649
Test Loss:  0.032817356288433075
Valid Loss:  0.03125058859586716
Epoch:  473  	Training Loss: 0.03347449749708176
Test Loss:  0.032813459634780884
Valid Loss:  0.031247299164533615
Epoch:  474  	Training Loss: 0.033470939844846725
Test Loss:  0.032809555530548096
Valid Loss:  0.031244011595845222
Epoch:  475  	Training Loss: 0.03346738964319229
Test Loss:  0.032805655151605606
Valid Loss:  0.03124072402715683
Epoch:  476  	Training Loss: 0.03346383571624756
Test Loss:  0.032801754772663116
Valid Loss:  0.031237438321113586
Epoch:  477  	Training Loss: 0.033460285514593124
Test Loss:  0.032797858119010925
Valid Loss:  0.031234147027134895
Epoch:  478  	Training Loss: 0.03345673531293869
Test Loss:  0.032793961465358734
Valid Loss:  0.03123086877167225
Epoch:  479  	Training Loss: 0.03345318138599396
Test Loss:  0.032790057361125946
Valid Loss:  0.031227581202983856
Epoch:  480  	Training Loss: 0.033449627459049225
Test Loss:  0.032786160707473755
Valid Loss:  0.031224297359585762
Epoch:  481  	Training Loss: 0.03344608098268509
Test Loss:  0.032782260328531265
Valid Loss:  0.031221013516187668
Epoch:  482  	Training Loss: 0.033442527055740356
Test Loss:  0.03277845308184624
Valid Loss:  0.031217794865369797
Epoch:  483  	Training Loss: 0.03343905508518219
Test Loss:  0.03277463838458061
Valid Loss:  0.031214583665132523
Epoch:  484  	Training Loss: 0.03343558311462402
Test Loss:  0.03277081996202469
Valid Loss:  0.0312113668769598
Epoch:  485  	Training Loss: 0.03343210741877556
Test Loss:  0.03276701271533966
Valid Loss:  0.03120815008878708
Epoch:  486  	Training Loss: 0.033428631722927094
Test Loss:  0.03276319056749344
Valid Loss:  0.031204937025904655
Epoch:  487  	Training Loss: 0.03342515975236893
Test Loss:  0.032759375870227814
Valid Loss:  0.03120172582566738
Epoch:  488  	Training Loss: 0.03342168405652046
Test Loss:  0.03275556117296219
Valid Loss:  0.03119850903749466
Epoch:  489  	Training Loss: 0.033418208360672
Test Loss:  0.03275175020098686
Valid Loss:  0.031195295974612236
Epoch:  490  	Training Loss: 0.03341473639011383
Test Loss:  0.032747939229011536
Valid Loss:  0.03119208663702011
Epoch:  491  	Training Loss: 0.033411264419555664
Test Loss:  0.03274412453174591
Valid Loss:  0.03118886984884739
Epoch:  492  	Training Loss: 0.0334077887237072
Test Loss:  0.032740361988544464
Valid Loss:  0.0311856959015131
Epoch:  493  	Training Loss: 0.033404361456632614
Test Loss:  0.032736603170633316
Valid Loss:  0.03118252381682396
Epoch:  494  	Training Loss: 0.03340093046426773
Test Loss:  0.03273283317685127
Valid Loss:  0.03117935173213482
Epoch:  495  	Training Loss: 0.033397503197193146
Test Loss:  0.032729074358940125
Valid Loss:  0.031176187098026276
Epoch:  496  	Training Loss: 0.03339407965540886
Test Loss:  0.03272531181573868
Valid Loss:  0.031173016875982285
Epoch:  497  	Training Loss: 0.03339065611362457
Test Loss:  0.03272155299782753
Valid Loss:  0.031169846653938293
Epoch:  498  	Training Loss: 0.03338722884654999
Test Loss:  0.03271779417991638
Valid Loss:  0.03116668201982975
Epoch:  499  	Training Loss: 0.0333838015794754
Test Loss:  0.032714031636714935
Valid Loss:  0.03116351179778576
Epoch:  500  	Training Loss: 0.033380381762981415
Test Loss:  0.032710276544094086
Valid Loss:  0.031160349026322365
seed is  6
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:28,  6.31s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:53,  1.34s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:26<17:30,  2.19s/it]  5%|▍         | 23/500 [00:26<12:17,  1.55s/it]  5%|▌         | 25/500 [00:26<08:40,  1.10s/it]  5%|▌         | 27/500 [00:26<06:11,  1.27it/s]  6%|▌         | 29/500 [00:27<04:27,  1.76it/s]  6%|▌         | 31/500 [00:33<10:27,  1.34s/it]  7%|▋         | 33/500 [00:33<07:26,  1.05it/s]  7%|▋         | 35/500 [00:33<05:20,  1.45it/s]  7%|▋         | 37/500 [00:33<03:51,  2.00it/s]  8%|▊         | 39/500 [00:33<02:50,  2.70it/s]  8%|▊         | 41/500 [00:40<09:15,  1.21s/it]  9%|▊         | 43/500 [00:40<06:36,  1.15it/s]  9%|▉         | 45/500 [00:40<04:44,  1.60it/s]  9%|▉         | 47/500 [00:40<03:27,  2.18it/s] 10%|▉         | 49/500 [00:40<02:33,  2.94it/s] 10%|█         | 51/500 [00:47<08:56,  1.19s/it] 11%|█         | 53/500 [00:47<06:22,  1.17it/s] 11%|█         | 55/500 [00:47<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:47<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:47<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:53<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:53<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:54<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:54<03:11,  2.26it/s] 14%|█▍        | 69/500 [00:54<02:21,  3.04it/s]Epoch:  1  	Training Loss: 0.02399960160255432
Test Loss:  0.028429953381419182
Valid Loss:  0.035810042172670364
Epoch:  2  	Training Loss: 0.03415200114250183
Test Loss:  0.026018554344773293
Valid Loss:  0.0256698876619339
Epoch:  3  	Training Loss: 0.02742077223956585
Test Loss:  0.012410989962518215
Valid Loss:  0.014827677048742771
Epoch:  4  	Training Loss: 0.015155183151364326
Test Loss:  0.010194630362093449
Valid Loss:  0.012638336978852749
Epoch:  5  	Training Loss: 0.01285498682409525
Test Loss:  0.008672891184687614
Valid Loss:  0.010969067923724651
Epoch:  6  	Training Loss: 0.011154703795909882
Test Loss:  0.007451825775206089
Valid Loss:  0.009573454037308693
Epoch:  7  	Training Loss: 0.009746161289513111
Test Loss:  0.006456855218857527
Valid Loss:  0.0084086824208498
Epoch:  8  	Training Loss: 0.008570111356675625
Test Loss:  0.0056461007334291935
Valid Loss:  0.007434638682752848
Epoch:  9  	Training Loss: 0.007587732747197151
Test Loss:  0.004985767416656017
Valid Loss:  0.0066197714768350124
Epoch:  10  	Training Loss: 0.00676693394780159
Test Loss:  0.004449915606528521
Valid Loss:  0.005938280839473009
Epoch:  11  	Training Loss: 0.006080561317503452
Test Loss:  0.004016163293272257
Valid Loss:  0.005367491394281387
Epoch:  12  	Training Loss: 0.005505891516804695
Test Loss:  0.0030579427257180214
Valid Loss:  0.0038832752034068108
Epoch:  13  	Training Loss: 0.004062841646373272
Test Loss:  0.003201777581125498
Valid Loss:  0.003632174339145422
Epoch:  14  	Training Loss: 0.003710333490744233
Test Loss:  0.004496258683502674
Valid Loss:  0.005050583742558956
Epoch:  15  	Training Loss: 0.005213959142565727
Test Loss:  0.019158966839313507
Valid Loss:  0.01941385306417942
Epoch:  16  	Training Loss: 0.019260691478848457
Test Loss:  0.046011485159397125
Valid Loss:  0.04741739481687546
Epoch:  17  	Training Loss: 0.04810265451669693
Test Loss:  0.04336405545473099
Valid Loss:  0.03919130191206932
Epoch:  18  	Training Loss: 0.039872460067272186
Test Loss:  0.007878948003053665
Valid Loss:  0.009830606169998646
Epoch:  19  	Training Loss: 0.010161563754081726
Test Loss:  0.005981959402561188
Valid Loss:  0.0076962122693657875
Epoch:  20  	Training Loss: 0.007749790791422129
Test Loss:  0.005980050191283226
Valid Loss:  0.007629381958395243
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.007675911299884319
Test Loss:  0.004770259838551283
Valid Loss:  0.006143688224256039
Epoch:  22  	Training Loss: 0.006335779093205929
Test Loss:  0.004101663362234831
Valid Loss:  0.005112389102578163
Epoch:  23  	Training Loss: 0.005359864328056574
Test Loss:  0.004014677368104458
Valid Loss:  0.004849915858358145
Epoch:  24  	Training Loss: 0.005058435257524252
Test Loss:  0.003806718857958913
Valid Loss:  0.004506358411163092
Epoch:  25  	Training Loss: 0.004764388781040907
Test Loss:  0.0037651383318006992
Valid Loss:  0.004301261156797409
Epoch:  26  	Training Loss: 0.004522962495684624
Test Loss:  0.0036959312856197357
Valid Loss:  0.004167458042502403
Epoch:  27  	Training Loss: 0.004413405433297157
Test Loss:  0.00377615075558424
Valid Loss:  0.0040986789390444756
Epoch:  28  	Training Loss: 0.004314905032515526
Test Loss:  0.0036192447878420353
Valid Loss:  0.003928717225790024
Epoch:  29  	Training Loss: 0.004169678781181574
Test Loss:  0.0036603757180273533
Valid Loss:  0.0038336447905749083
Epoch:  30  	Training Loss: 0.004058559890836477
Test Loss:  0.003598742187023163
Valid Loss:  0.0037674023769795895
Epoch:  31  	Training Loss: 0.004002366680651903
Test Loss:  0.0037086275406181812
Valid Loss:  0.0037597643677145243
Epoch:  32  	Training Loss: 0.00397968664765358
Test Loss:  0.0035917728673666716
Valid Loss:  0.003662501461803913
Epoch:  33  	Training Loss: 0.0038909162394702435
Test Loss:  0.0036176566500216722
Valid Loss:  0.003624472301453352
Epoch:  34  	Training Loss: 0.003851279616355896
Test Loss:  0.0036199712194502354
Valid Loss:  0.003592494875192642
Epoch:  35  	Training Loss: 0.0038196633104234934
Test Loss:  0.0036251062992960215
Valid Loss:  0.0035649596247822046
Epoch:  36  	Training Loss: 0.0037918039597570896
Test Loss:  0.0036211530677974224
Valid Loss:  0.0035408735275268555
Epoch:  37  	Training Loss: 0.0037679066881537437
Test Loss:  0.003632934298366308
Valid Loss:  0.003522195853292942
Epoch:  38  	Training Loss: 0.003747135866433382
Test Loss:  0.0036280311178416014
Valid Loss:  0.003504316322505474
Epoch:  39  	Training Loss: 0.003729029092937708
Test Loss:  0.0036417455412447453
Valid Loss:  0.0034892025869339705
Epoch:  40  	Training Loss: 0.003713507205247879
Test Loss:  0.003638448193669319
Valid Loss:  0.0034758776891976595
Epoch:  41  	Training Loss: 0.003699680557474494
Test Loss:  0.003652583109214902
Valid Loss:  0.0034644906409084797
Epoch:  42  	Training Loss: 0.0036879079416394234
Test Loss:  0.0035745231434702873
Valid Loss:  0.0033890483900904655
Epoch:  43  	Training Loss: 0.0036060393322259188
Test Loss:  0.0035963752306997776
Valid Loss:  0.003359428374096751
Epoch:  44  	Training Loss: 0.0035732609685510397
Test Loss:  0.003566049737855792
Valid Loss:  0.0033357376232743263
Epoch:  45  	Training Loss: 0.0035490537993609905
Test Loss:  0.0035842955112457275
Valid Loss:  0.00330567080527544
Epoch:  46  	Training Loss: 0.003519047051668167
Test Loss:  0.003558502532541752
Valid Loss:  0.0032880050130188465
Epoch:  47  	Training Loss: 0.003501652041450143
Test Loss:  0.0035781071055680513
Valid Loss:  0.0032762126065790653
Epoch:  48  	Training Loss: 0.0034914009738713503
Test Loss:  0.003572174347937107
Valid Loss:  0.0032688418868929148
Epoch:  49  	Training Loss: 0.0034842994064092636
Test Loss:  0.003587197046726942
Valid Loss:  0.0032604660373181105
Epoch:  50  	Training Loss: 0.003476265352219343
Test Loss:  0.0035826903767883778
Valid Loss:  0.003256480675190687
Epoch:  51  	Training Loss: 0.0034713405184447765
Test Loss:  0.003601659554988146
Valid Loss:  0.003246413543820381
Epoch:  52  	Training Loss: 0.0034611443988978863
Test Loss:  0.003565222956240177
Valid Loss:  0.0032055648043751717
Epoch:  53  	Training Loss: 0.0034160916693508625
Test Loss:  0.003546622581779957
Valid Loss:  0.003172791562974453
Epoch:  54  	Training Loss: 0.003380351699888706
Test Loss:  0.0035362052731215954
Valid Loss:  0.0031506544910371304
Epoch:  55  	Training Loss: 0.0033530904911458492
Test Loss:  0.0035170218907296658
Valid Loss:  0.0031211727764457464
Epoch:  56  	Training Loss: 0.0033208816312253475
Test Loss:  0.0035018236376345158
Valid Loss:  0.0031003474723547697
Epoch:  57  	Training Loss: 0.0032939608208835125
Test Loss:  0.0034746723249554634
Valid Loss:  0.003069629892706871
Epoch:  58  	Training Loss: 0.0032596392557024956
Test Loss:  0.003447592258453369
Valid Loss:  0.003043122123926878
Epoch:  59  	Training Loss: 0.003227977314963937
Test Loss:  0.003417923115193844
Valid Loss:  0.0030097372364252806
Epoch:  60  	Training Loss: 0.00319254444912076
Test Loss:  0.0033911787904798985
Valid Loss:  0.0029817649628967047
Epoch:  61  	Training Loss: 0.0031575316097587347
Test Loss:  0.003353344276547432
Valid Loss:  0.0029460107907652855
Epoch:  62  	Training Loss: 0.003115223255008459
Test Loss:  0.0033573610708117485
Valid Loss:  0.002931552939116955
Epoch:  63  	Training Loss: 0.003100333269685507
Test Loss:  0.003359832800924778
Valid Loss:  0.002918587066233158
Epoch:  64  	Training Loss: 0.0030869152396917343
Test Loss:  0.003361108247190714
Valid Loss:  0.002906506648287177
Epoch:  65  	Training Loss: 0.003074387786909938
Test Loss:  0.0033612153492867947
Valid Loss:  0.0028949733823537827
Epoch:  66  	Training Loss: 0.003062464529648423
Test Loss:  0.0033604176715016365
Valid Loss:  0.0028838454745709896
Epoch:  67  	Training Loss: 0.003051001112908125
Test Loss:  0.003358780173584819
Valid Loss:  0.0028730391059070826
Epoch:  68  	Training Loss: 0.0030399016104638577
Test Loss:  0.003356351051479578
Valid Loss:  0.002862445544451475
Epoch:  69  	Training Loss: 0.003029104322195053
Test Loss:  0.0033534164540469646
Valid Loss:  0.002852328587323427
 14%|█▍        | 71/500 [01:00<08:20,  1.17s/it] 15%|█▍        | 73/500 [01:00<05:57,  1.19it/s] 15%|█▌        | 75/500 [01:00<04:17,  1.65it/s] 15%|█▌        | 77/500 [01:00<03:07,  2.26it/s] 16%|█▌        | 79/500 [01:01<02:18,  3.04it/s] 16%|█▌        | 81/500 [01:07<08:11,  1.17s/it] 17%|█▋        | 83/500 [01:07<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:07<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:07<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:07<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:14<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:14<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:14<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:14<02:13,  3.00it/s] 20%|██        | 101/500 [01:21<07:52,  1.18s/it] 21%|██        | 103/500 [01:21<05:37,  1.18it/s] 21%|██        | 105/500 [01:21<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:21<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:21<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:27<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:27<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:28<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:28<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:28<02:06,  3.00it/s] 24%|██▍       | 121/500 [01:34<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:34<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:35<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:35<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:35<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:41<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:41<05:09,  1.18it/s] 27%|██▋       | 135/500 [01:41<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:41<02:42,  2.24it/s]Epoch:  70  	Training Loss: 0.003018638351932168
Test Loss:  0.0033501319121569395
Valid Loss:  0.0028423648327589035
Epoch:  71  	Training Loss: 0.0030084787867963314
Test Loss:  0.0033469349145889282
Valid Loss:  0.002833044622093439
Epoch:  72  	Training Loss: 0.0029985320288687944
Test Loss:  0.0032334821298718452
Valid Loss:  0.002709748223423958
Epoch:  73  	Training Loss: 0.002867914503440261
Test Loss:  0.003157125785946846
Valid Loss:  0.0026159347034990788
Epoch:  74  	Training Loss: 0.0027691377326846123
Test Loss:  0.00309579074382782
Valid Loss:  0.002549179829657078
Epoch:  75  	Training Loss: 0.002691796747967601
Test Loss:  0.003036088775843382
Valid Loss:  0.0024931584484875202
Epoch:  76  	Training Loss: 0.0026286053471267223
Test Loss:  0.0029744026251137257
Valid Loss:  0.0024399422109127045
Epoch:  77  	Training Loss: 0.002571473829448223
Test Loss:  0.00291204871609807
Valid Loss:  0.0023889862932264805
Epoch:  78  	Training Loss: 0.0025170943699777126
Test Loss:  0.0028504361398518085
Valid Loss:  0.0023393172305077314
Epoch:  79  	Training Loss: 0.002465037861838937
Test Loss:  0.002789936028420925
Valid Loss:  0.0022909357212483883
Epoch:  80  	Training Loss: 0.0024147622752934694
Test Loss:  0.0027307611890137196
Valid Loss:  0.002244512317702174
Epoch:  81  	Training Loss: 0.0023652815725654364
Test Loss:  0.0026729137171059847
Valid Loss:  0.0021999632008373737
Epoch:  82  	Training Loss: 0.0023167086765170097
Test Loss:  0.002622248837724328
Valid Loss:  0.002148998435586691
Epoch:  83  	Training Loss: 0.0022635888308286667
Test Loss:  0.0025479928590357304
Valid Loss:  0.0021078919526189566
Epoch:  84  	Training Loss: 0.0022154883481562138
Test Loss:  0.0024996320717036724
Valid Loss:  0.0020644343458116055
Epoch:  85  	Training Loss: 0.002169844461604953
Test Loss:  0.0024383184500038624
Valid Loss:  0.002027094829827547
Epoch:  86  	Training Loss: 0.002127347979694605
Test Loss:  0.0023909094743430614
Valid Loss:  0.0019894358702003956
Epoch:  87  	Training Loss: 0.002086999360471964
Test Loss:  0.00233789742924273
Valid Loss:  0.0019549871794879436
Epoch:  88  	Training Loss: 0.00204807729460299
Test Loss:  0.0022937008179724216
Valid Loss:  0.0019212160259485245
Epoch:  89  	Training Loss: 0.0020115631632506847
Test Loss:  0.0022509032860398293
Valid Loss:  0.0018906925106421113
Epoch:  90  	Training Loss: 0.001978715881705284
Test Loss:  0.002212317194789648
Valid Loss:  0.0018619889160618186
Epoch:  91  	Training Loss: 0.0019477418391034007
Test Loss:  0.002175238449126482
Valid Loss:  0.0018365213181823492
Epoch:  92  	Training Loss: 0.0019188469741493464
Test Loss:  0.0021073000971227884
Valid Loss:  0.0017970317276194692
Epoch:  93  	Training Loss: 0.0018722463864833117
Test Loss:  0.002052419586107135
Valid Loss:  0.001762589206919074
Epoch:  94  	Training Loss: 0.001833551679737866
Test Loss:  0.001999154221266508
Valid Loss:  0.0017305104993283749
Epoch:  95  	Training Loss: 0.0017980512930080295
Test Loss:  0.0019552838057279587
Valid Loss:  0.0017051906324923038
Epoch:  96  	Training Loss: 0.0017710899701341987
Test Loss:  0.0019207758596166968
Valid Loss:  0.0016840888420119882
Epoch:  97  	Training Loss: 0.001749288639985025
Test Loss:  0.0018943807808682323
Valid Loss:  0.001665811869315803
Epoch:  98  	Training Loss: 0.0017292890697717667
Test Loss:  0.0018744240514934063
Valid Loss:  0.0016493769362568855
Epoch:  99  	Training Loss: 0.001712306635454297
Test Loss:  0.0018563446355983615
Valid Loss:  0.0016347544733434916
Epoch:  100  	Training Loss: 0.001697633764706552
Test Loss:  0.00184172997251153
Valid Loss:  0.0016233085189014673
Epoch:  101  	Training Loss: 0.0016850704560056329
Test Loss:  0.0018286998383700848
Valid Loss:  0.001612500986084342
Epoch:  102  	Training Loss: 0.001674085739068687
Test Loss:  0.0018240949138998985
Valid Loss:  0.001603477168828249
Epoch:  103  	Training Loss: 0.0016661615809425712
Test Loss:  0.0018173856660723686
Valid Loss:  0.001596757210791111
Epoch:  104  	Training Loss: 0.0016593633918091655
Test Loss:  0.001812710310332477
Valid Loss:  0.0015901941806077957
Epoch:  105  	Training Loss: 0.0016530766151845455
Test Loss:  0.0018091776873916388
Valid Loss:  0.0015846365131437778
Epoch:  106  	Training Loss: 0.0016471596900373697
Test Loss:  0.001806325395591557
Valid Loss:  0.0015789318131282926
Epoch:  107  	Training Loss: 0.001641340903006494
Test Loss:  0.0018031971994787455
Valid Loss:  0.0015734895132482052
Epoch:  108  	Training Loss: 0.0016356592532247305
Test Loss:  0.0018004884477704763
Valid Loss:  0.0015683642122894526
Epoch:  109  	Training Loss: 0.0016300780698657036
Test Loss:  0.0017977079842239618
Valid Loss:  0.0015631612623110414
Epoch:  110  	Training Loss: 0.0016245708102360368
Test Loss:  0.0017938835080713034
Valid Loss:  0.0015576521400362253
Epoch:  111  	Training Loss: 0.0016191127942875028
Test Loss:  0.0017899570520967245
Valid Loss:  0.0015526257921010256
Epoch:  112  	Training Loss: 0.001613702392205596
Test Loss:  0.0017859120853245258
Valid Loss:  0.0015462342416867614
Epoch:  113  	Training Loss: 0.0016061761416494846
Test Loss:  0.001781619619578123
Valid Loss:  0.0015404901932924986
Epoch:  114  	Training Loss: 0.0016005135839805007
Test Loss:  0.0017755646258592606
Valid Loss:  0.0015359621029347181
Epoch:  115  	Training Loss: 0.001595339272171259
Test Loss:  0.0017700018361210823
Valid Loss:  0.0015319737140089273
Epoch:  116  	Training Loss: 0.001590772531926632
Test Loss:  0.0017642149468883872
Valid Loss:  0.0015281741507351398
Epoch:  117  	Training Loss: 0.0015866763424128294
Test Loss:  0.0017585025634616613
Valid Loss:  0.001524920342490077
Epoch:  118  	Training Loss: 0.0015828628093004227
Test Loss:  0.0017534447833895683
Valid Loss:  0.0015220699133351445
Epoch:  119  	Training Loss: 0.0015797417145222425
Test Loss:  0.0017490193713456392
Valid Loss:  0.0015193996950984001
Epoch:  120  	Training Loss: 0.0015768189914524555
Test Loss:  0.0017450412269681692
Valid Loss:  0.0015168203972280025
Epoch:  121  	Training Loss: 0.0015739495866000652
Test Loss:  0.001741508487612009
Valid Loss:  0.0015142785850912333
Epoch:  122  	Training Loss: 0.001571115804836154
Test Loss:  0.0017370324349030852
Valid Loss:  0.0015086294151842594
Epoch:  123  	Training Loss: 0.001564988517202437
Test Loss:  0.0017324401997029781
Valid Loss:  0.0015041929436847568
Epoch:  124  	Training Loss: 0.0015601316699758172
Test Loss:  0.0017277561128139496
Valid Loss:  0.001500115031376481
Epoch:  125  	Training Loss: 0.001556082395836711
Test Loss:  0.0017233079997822642
Valid Loss:  0.0014968550531193614
Epoch:  126  	Training Loss: 0.001552727073431015
Test Loss:  0.001719676423817873
Valid Loss:  0.0014937028754502535
Epoch:  127  	Training Loss: 0.001549738459289074
Test Loss:  0.001716398517601192
Valid Loss:  0.0014912767801433802
Epoch:  128  	Training Loss: 0.0015474073588848114
Test Loss:  0.0017138143302872777
Valid Loss:  0.0014890277525410056
Epoch:  129  	Training Loss: 0.001545571256428957
Test Loss:  0.0017109225736930966
Valid Loss:  0.001487099565565586
Epoch:  130  	Training Loss: 0.0015440158313140273
Test Loss:  0.001708496711216867
Valid Loss:  0.001485153567045927
Epoch:  131  	Training Loss: 0.001542653189972043
Test Loss:  0.001705650705844164
Valid Loss:  0.0014833812601864338
Epoch:  132  	Training Loss: 0.001541427569463849
Test Loss:  0.0017042600084096193
Valid Loss:  0.0014819842763245106
Epoch:  133  	Training Loss: 0.0015398028772324324
Test Loss:  0.0017033047042787075
Valid Loss:  0.0014806983526796103
Epoch:  134  	Training Loss: 0.001538444310426712
Test Loss:  0.0017024488188326359
Valid Loss:  0.0014795991592109203
Epoch:  135  	Training Loss: 0.0015372339403256774
Test Loss:  0.0017016443889588118
Valid Loss:  0.0014785914681851864
Epoch:  136  	Training Loss: 0.0015360696706920862
Test Loss:  0.0017007458955049515
Valid Loss:  0.0014775850577279925
Epoch:  137  	Training Loss: 0.001534955808892846
Test Loss:  0.0016997754573822021
Valid Loss:  0.0014766233507543802
Epoch:  138  	Training Loss: 0.0015338801313191652
Test Loss:  0.0016987372655421495
Valid Loss:  0.001475649536587298
 28%|██▊       | 139/500 [01:42<02:00,  3.01it/s] 28%|██▊       | 141/500 [01:48<07:03,  1.18s/it] 29%|██▊       | 143/500 [01:48<05:02,  1.18it/s] 29%|██▉       | 145/500 [01:48<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:48<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:48<01:57,  3.00it/s] 30%|███       | 151/500 [01:55<06:55,  1.19s/it] 31%|███       | 153/500 [01:55<04:56,  1.17it/s] 31%|███       | 155/500 [01:55<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:55<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:55<01:54,  2.98it/s] 32%|███▏      | 161/500 [02:02<06:37,  1.17s/it] 33%|███▎      | 163/500 [02:02<04:43,  1.19it/s] 33%|███▎      | 165/500 [02:02<03:23,  1.65it/s] 33%|███▎      | 167/500 [02:02<02:28,  2.25it/s] 34%|███▍      | 169/500 [02:02<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:08<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:09<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:09<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:09<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:09<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:15<06:10,  1.16s/it] 37%|███▋      | 183/500 [02:15<04:24,  1.20it/s] 37%|███▋      | 185/500 [02:15<03:10,  1.65it/s] 37%|███▋      | 187/500 [02:16<02:18,  2.26it/s] 38%|███▊      | 189/500 [02:16<01:42,  3.03it/s] 38%|███▊      | 191/500 [02:22<06:09,  1.19s/it] 39%|███▊      | 193/500 [02:22<04:23,  1.17it/s] 39%|███▉      | 195/500 [02:22<03:08,  1.61it/s] 39%|███▉      | 197/500 [02:23<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:23<01:41,  2.97it/s] 40%|████      | 201/500 [02:29<05:57,  1.20s/it] 41%|████      | 203/500 [02:29<04:14,  1.16it/s] 41%|████      | 205/500 [02:29<03:02,  1.61it/s]Epoch:  139  	Training Loss: 0.0015328070148825645
Test Loss:  0.0016976844053715467
Valid Loss:  0.0014746924862265587
Epoch:  140  	Training Loss: 0.001531744608655572
Test Loss:  0.0016965946415439248
Valid Loss:  0.0014737306628376245
Epoch:  141  	Training Loss: 0.0015306873247027397
Test Loss:  0.0016955245519056916
Valid Loss:  0.0014727941015735269
Epoch:  142  	Training Loss: 0.0015296365600079298
Test Loss:  0.0016884877113625407
Valid Loss:  0.001464672852307558
Epoch:  143  	Training Loss: 0.0015226452378556132
Test Loss:  0.0016812487738206983
Valid Loss:  0.0014575591776520014
Epoch:  144  	Training Loss: 0.00151602434925735
Test Loss:  0.0016748441848903894
Valid Loss:  0.0014506533043459058
Epoch:  145  	Training Loss: 0.001509665627963841
Test Loss:  0.0016689132899045944
Valid Loss:  0.0014441970270127058
Epoch:  146  	Training Loss: 0.0015035993419587612
Test Loss:  0.0016634231433272362
Valid Loss:  0.0014377182815223932
Epoch:  147  	Training Loss: 0.0014976001111790538
Test Loss:  0.0016578880604356527
Valid Loss:  0.0014313497813418508
Epoch:  148  	Training Loss: 0.0014916958753019571
Test Loss:  0.0016526381950825453
Valid Loss:  0.0014252308756113052
Epoch:  149  	Training Loss: 0.001486014574766159
Test Loss:  0.001648379024118185
Valid Loss:  0.0014194654067978263
Epoch:  150  	Training Loss: 0.001480516279116273
Test Loss:  0.0016445231158286333
Valid Loss:  0.0014136484824120998
Epoch:  151  	Training Loss: 0.0014750976115465164
Test Loss:  0.001640660921111703
Valid Loss:  0.0014081664849072695
Epoch:  152  	Training Loss: 0.001469748211093247
Test Loss:  0.0016391215613111854
Valid Loss:  0.00140561128500849
Epoch:  153  	Training Loss: 0.0014656918356195092
Test Loss:  0.0016378691652789712
Valid Loss:  0.0014035962522029877
Epoch:  154  	Training Loss: 0.001463182270526886
Test Loss:  0.0016348941717296839
Valid Loss:  0.0014022903051227331
Epoch:  155  	Training Loss: 0.001461429288610816
Test Loss:  0.0016326159238815308
Valid Loss:  0.0014009220758453012
Epoch:  156  	Training Loss: 0.0014599626883864403
Test Loss:  0.0016290574567392468
Valid Loss:  0.0014001380186527967
Epoch:  157  	Training Loss: 0.0014586150646209717
Test Loss:  0.0016272164648398757
Valid Loss:  0.0013990455772727728
Epoch:  158  	Training Loss: 0.001457449048757553
Test Loss:  0.0016235359944403172
Valid Loss:  0.0013985862024128437
Epoch:  159  	Training Loss: 0.001456393045373261
Test Loss:  0.0016222132835537195
Valid Loss:  0.0013975336914882064
Epoch:  160  	Training Loss: 0.0014554030494764447
Test Loss:  0.0016184952110052109
Valid Loss:  0.0013972710585221648
Epoch:  161  	Training Loss: 0.0014544506557285786
Test Loss:  0.0016179790254682302
Valid Loss:  0.0013961251825094223
Epoch:  162  	Training Loss: 0.0014535491354763508
Test Loss:  0.001607606653124094
Valid Loss:  0.0013855767901986837
Epoch:  163  	Training Loss: 0.0014435009798035026
Test Loss:  0.0016015918226912618
Valid Loss:  0.0013791185338050127
Epoch:  164  	Training Loss: 0.0014366989489644766
Test Loss:  0.0015959006268531084
Valid Loss:  0.0013735564425587654
Epoch:  165  	Training Loss: 0.0014318071771413088
Test Loss:  0.0015901882434263825
Valid Loss:  0.0013691496569663286
Epoch:  166  	Training Loss: 0.0014276853762567043
Test Loss:  0.0015852013602852821
Valid Loss:  0.0013650234322994947
Epoch:  167  	Training Loss: 0.001423915266059339
Test Loss:  0.0015804804861545563
Valid Loss:  0.0013612566981464624
Epoch:  168  	Training Loss: 0.0014203470200300217
Test Loss:  0.0015766860451549292
Valid Loss:  0.0013576607452705503
Epoch:  169  	Training Loss: 0.0014173490926623344
Test Loss:  0.001573194982483983
Valid Loss:  0.0013546545524150133
Epoch:  170  	Training Loss: 0.0014144093729555607
Test Loss:  0.0015699899522587657
Valid Loss:  0.0013515192549675703
Epoch:  171  	Training Loss: 0.0014115176163613796
Test Loss:  0.0015668801497668028
Valid Loss:  0.0013486938551068306
Epoch:  172  	Training Loss: 0.0014086620649322867
Test Loss:  0.0015642012003809214
Valid Loss:  0.0013447219971567392
Epoch:  173  	Training Loss: 0.00140478799585253
Test Loss:  0.0015617611352354288
Valid Loss:  0.00134088727645576
Epoch:  174  	Training Loss: 0.0014011252205818892
Test Loss:  0.0015594447031617165
Valid Loss:  0.0013372997054830194
Epoch:  175  	Training Loss: 0.001397790270857513
Test Loss:  0.0015572290867567062
Valid Loss:  0.0013342536985874176
Epoch:  176  	Training Loss: 0.00139478943310678
Test Loss:  0.0015550204552710056
Valid Loss:  0.001331415376625955
Epoch:  177  	Training Loss: 0.0013918331824243069
Test Loss:  0.0015528274234384298
Valid Loss:  0.0013286899775266647
Epoch:  178  	Training Loss: 0.0013889775145798922
Test Loss:  0.0015506441704928875
Valid Loss:  0.0013260886771604419
Epoch:  179  	Training Loss: 0.0013862064806744456
Test Loss:  0.0015484641771763563
Valid Loss:  0.0013235569931566715
Epoch:  180  	Training Loss: 0.001383553957566619
Test Loss:  0.0015464078169316053
Valid Loss:  0.0013211758341640234
Epoch:  181  	Training Loss: 0.001381085952743888
Test Loss:  0.0015444073360413313
Valid Loss:  0.0013188992161303759
Epoch:  182  	Training Loss: 0.0013786638155579567
Test Loss:  0.0015419709961861372
Valid Loss:  0.0013164649717509747
Epoch:  183  	Training Loss: 0.001376323401927948
Test Loss:  0.0015394489746540785
Valid Loss:  0.0013141385279595852
Epoch:  184  	Training Loss: 0.0013740460854023695
Test Loss:  0.0015371215995401144
Valid Loss:  0.0013120026560500264
Epoch:  185  	Training Loss: 0.0013717992696911097
Test Loss:  0.001534889917820692
Valid Loss:  0.001310027320869267
Epoch:  186  	Training Loss: 0.0013696178793907166
Test Loss:  0.0015328265726566315
Valid Loss:  0.0013081369688734412
Epoch:  187  	Training Loss: 0.001367662101984024
Test Loss:  0.0015310149174183607
Valid Loss:  0.0013063785154372454
Epoch:  188  	Training Loss: 0.0013658859534189105
Test Loss:  0.0015293058240786195
Valid Loss:  0.0013046290259808302
Epoch:  189  	Training Loss: 0.001364141353406012
Test Loss:  0.0015278940554708242
Valid Loss:  0.001302966382354498
Epoch:  190  	Training Loss: 0.001362523646093905
Test Loss:  0.0015265971887856722
Valid Loss:  0.0013013535644859076
Epoch:  191  	Training Loss: 0.0013609324814751744
Test Loss:  0.001525333384051919
Valid Loss:  0.0012997594894841313
Epoch:  192  	Training Loss: 0.0013593581970781088
Test Loss:  0.0015240266220644116
Valid Loss:  0.0012969991657882929
Epoch:  193  	Training Loss: 0.001356304856017232
Test Loss:  0.0015236703911796212
Valid Loss:  0.0012943015899509192
Epoch:  194  	Training Loss: 0.0013535425532609224
Test Loss:  0.0015228037955239415
Valid Loss:  0.001291837077587843
Epoch:  195  	Training Loss: 0.0013509354321286082
Test Loss:  0.0015218846965581179
Valid Loss:  0.0012895020190626383
Epoch:  196  	Training Loss: 0.0013484159717336297
Test Loss:  0.001520804944448173
Valid Loss:  0.0012873370433226228
Epoch:  197  	Training Loss: 0.001345982775092125
Test Loss:  0.0015196187887340784
Valid Loss:  0.0012852768413722515
Epoch:  198  	Training Loss: 0.0013437377056106925
Test Loss:  0.0015183875802904367
Valid Loss:  0.001283302204683423
Epoch:  199  	Training Loss: 0.0013415936846286058
Test Loss:  0.0015170671977102757
Valid Loss:  0.001281391130760312
Epoch:  200  	Training Loss: 0.001339551294222474
Test Loss:  0.0015157198067754507
Valid Loss:  0.001279538031667471
Epoch:  201  	Training Loss: 0.0013376781716942787
Test Loss:  0.0015143264317885041
Valid Loss:  0.0012777227675542235
Epoch:  202  	Training Loss: 0.0013358776923269033
Test Loss:  0.0015116475988179445
Valid Loss:  0.001274183508940041
Epoch:  203  	Training Loss: 0.0013326467014849186
Test Loss:  0.0015091018285602331
Valid Loss:  0.0012707267887890339
Epoch:  204  	Training Loss: 0.0013295433018356562
Test Loss:  0.0015065876068547368
Valid Loss:  0.001267437357455492
Epoch:  205  	Training Loss: 0.0013265677262097597
Test Loss:  0.0015041569713503122
Valid Loss:  0.001264263060875237
Epoch:  206  	Training Loss: 0.0013236927334219217
Test Loss:  0.001501738210208714
Valid Loss:  0.0012611913261935115
Epoch:  207  	Training Loss: 0.0013209190219640732
Test Loss:   41%|████▏     | 207/500 [02:29<02:12,  2.20it/s] 42%|████▏     | 209/500 [02:30<01:38,  2.97it/s] 42%|████▏     | 211/500 [02:36<05:39,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:36<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:36<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:36<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:43<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:43<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:43<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:43<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:43<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:49<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:50<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:50<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:50<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:50<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:56<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:56<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:57<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:57<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:57<01:23,  3.00it/s] 50%|█████     | 251/500 [03:03<04:53,  1.18s/it] 51%|█████     | 253/500 [03:03<03:29,  1.18it/s] 51%|█████     | 255/500 [03:03<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:04<01:49,  2.23it/s] 52%|█████▏    | 259/500 [03:04<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:10<04:48,  1.21s/it] 53%|█████▎    | 263/500 [03:10<03:25,  1.15it/s] 53%|█████▎    | 265/500 [03:10<02:27,  1.59it/s] 53%|█████▎    | 267/500 [03:11<01:46,  2.18it/s] 54%|█████▍    | 269/500 [03:11<01:18,  2.94it/s] 54%|█████▍    | 271/500 [03:17<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:17<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:17<02:19,  1.61it/s]0.0014993555378168821
Valid Loss:  0.0012581878108903766
Epoch:  208  	Training Loss: 0.001318221096880734
Test Loss:  0.0014970545889809728
Valid Loss:  0.0012552947737276554
Epoch:  209  	Training Loss: 0.0013156458735466003
Test Loss:  0.0014948368771001697
Valid Loss:  0.0012524041812866926
Epoch:  210  	Training Loss: 0.001313098706305027
Test Loss:  0.0014925968134775758
Valid Loss:  0.0012495570117607713
Epoch:  211  	Training Loss: 0.0013105967082083225
Test Loss:  0.0014904735144227743
Valid Loss:  0.0012467667693272233
Epoch:  212  	Training Loss: 0.0013081437209621072
Test Loss:  0.001487803878262639
Valid Loss:  0.0012373477220535278
Epoch:  213  	Training Loss: 0.0012958277948200703
Test Loss:  0.0014891659375280142
Valid Loss:  0.001233099028468132
Epoch:  214  	Training Loss: 0.0012905813055112958
Test Loss:  0.0014897389337420464
Valid Loss:  0.0012287162244319916
Epoch:  215  	Training Loss: 0.0012858447153121233
Test Loss:  0.0014897123910486698
Valid Loss:  0.001224835985340178
Epoch:  216  	Training Loss: 0.0012814434012398124
Test Loss:  0.001489123678766191
Valid Loss:  0.0012211385183036327
Epoch:  217  	Training Loss: 0.0012774758506566286
Test Loss:  0.001488039270043373
Valid Loss:  0.00121756037697196
Epoch:  218  	Training Loss: 0.0012737277429550886
Test Loss:  0.0014865496195852757
Valid Loss:  0.0012140772305428982
Epoch:  219  	Training Loss: 0.0012700515799224377
Test Loss:  0.0014848303981125355
Valid Loss:  0.0012107613729313016
Epoch:  220  	Training Loss: 0.0012664392124861479
Test Loss:  0.0014826704282313585
Valid Loss:  0.0012073359685018659
Epoch:  221  	Training Loss: 0.0012628627009689808
Test Loss:  0.0014804373495280743
Valid Loss:  0.001204096945002675
Epoch:  222  	Training Loss: 0.0012593218125402927
Test Loss:  0.001480177277699113
Valid Loss:  0.0011922715930268168
Epoch:  223  	Training Loss: 0.0012497811112552881
Test Loss:  0.0014587342739105225
Valid Loss:  0.001188570400699973
Epoch:  224  	Training Loss: 0.001242081169039011
Test Loss:  0.0014629110228270292
Valid Loss:  0.0011781190987676382
Epoch:  225  	Training Loss: 0.0012351346667855978
Test Loss:  0.0014421774540096521
Valid Loss:  0.0011761165224015713
Epoch:  226  	Training Loss: 0.0012286724522709846
Test Loss:  0.0014490862376987934
Valid Loss:  0.0011658729054033756
Epoch:  227  	Training Loss: 0.0012226032558828592
Test Loss:  0.0014280300820246339
Valid Loss:  0.0011651201639324427
Epoch:  228  	Training Loss: 0.0012168819084763527
Test Loss:  0.0014373925514519215
Valid Loss:  0.0011550039052963257
Epoch:  229  	Training Loss: 0.0012115243589505553
Test Loss:  0.0014144169399514794
Valid Loss:  0.001155247213318944
Epoch:  230  	Training Loss: 0.0012063283938914537
Test Loss:  0.001426708186045289
Valid Loss:  0.001145048881880939
Epoch:  231  	Training Loss: 0.0012016677064821124
Test Loss:  0.0014014827320352197
Valid Loss:  0.0011467398144304752
Epoch:  232  	Training Loss: 0.001196719822473824
Test Loss:  0.0014075135113671422
Valid Loss:  0.0011328988475725055
Epoch:  233  	Training Loss: 0.00118690961971879
Test Loss:  0.0013959880452603102
Valid Loss:  0.0011306838132441044
Epoch:  234  	Training Loss: 0.001184051507152617
Test Loss:  0.0013903342187404633
Valid Loss:  0.0011283329222351313
Epoch:  235  	Training Loss: 0.0011818911880254745
Test Loss:  0.0013847574591636658
Valid Loss:  0.0011265105567872524
Epoch:  236  	Training Loss: 0.0011800569482147694
Test Loss:  0.00138000282458961
Valid Loss:  0.0011248281225562096
Epoch:  237  	Training Loss: 0.0011784310918301344
Test Loss:  0.001375848543830216
Valid Loss:  0.0011233387049287558
Epoch:  238  	Training Loss: 0.0011770455166697502
Test Loss:  0.0013721941504627466
Valid Loss:  0.0011219617445021868
Epoch:  239  	Training Loss: 0.0011758016189560294
Test Loss:  0.0013689519837498665
Valid Loss:  0.0011207847855985165
Epoch:  240  	Training Loss: 0.001174671808257699
Test Loss:  0.0013660583645105362
Valid Loss:  0.0011196671985089779
Epoch:  241  	Training Loss: 0.0011736038140952587
Test Loss:  0.0013634611386805773
Valid Loss:  0.0011185891926288605
Epoch:  242  	Training Loss: 0.0011725937947630882
Test Loss:  0.001362617826089263
Valid Loss:  0.001114811864681542
Epoch:  243  	Training Loss: 0.0011683469638228416
Test Loss:  0.0013638134114444256
Valid Loss:  0.0011107568861916661
Epoch:  244  	Training Loss: 0.00116451783105731
Test Loss:  0.0013631600886583328
Valid Loss:  0.0011073341593146324
Epoch:  245  	Training Loss: 0.0011610930087044835
Test Loss:  0.0013624569401144981
Valid Loss:  0.001104019582271576
Epoch:  246  	Training Loss: 0.001157986233010888
Test Loss:  0.0013610096648335457
Valid Loss:  0.0011009519221261144
Epoch:  247  	Training Loss: 0.0011550219496712089
Test Loss:  0.0013594109332188964
Valid Loss:  0.0010982435196638107
Epoch:  248  	Training Loss: 0.0011521972483024001
Test Loss:  0.0013573726173490286
Valid Loss:  0.001095742336474359
Epoch:  249  	Training Loss: 0.001149604213424027
Test Loss:  0.0013550511794164777
Valid Loss:  0.0010932949371635914
Epoch:  250  	Training Loss: 0.0011470546014606953
Test Loss:  0.0013526100665330887
Valid Loss:  0.0010908768745139241
Epoch:  251  	Training Loss: 0.0011445459676906466
Test Loss:  0.0013500548666343093
Valid Loss:  0.0010885875672101974
Epoch:  252  	Training Loss: 0.0011421244125813246
Test Loss:  0.0013484832597896457
Valid Loss:  0.0010876769665628672
Epoch:  253  	Training Loss: 0.0011412226594984531
Test Loss:  0.0013462381903082132
Valid Loss:  0.001087000360712409
Epoch:  254  	Training Loss: 0.001140387263149023
Test Loss:  0.0013442214112728834
Valid Loss:  0.0010864206124097109
Epoch:  255  	Training Loss: 0.0011395906331017613
Test Loss:  0.0013422213960438967
Valid Loss:  0.0010858713649213314
Epoch:  256  	Training Loss: 0.0011388431303203106
Test Loss:  0.0013402723707258701
Valid Loss:  0.001085337484255433
Epoch:  257  	Training Loss: 0.0011381050571799278
Test Loss:  0.0013384101912379265
Valid Loss:  0.001084939343854785
Epoch:  258  	Training Loss: 0.0011373884044587612
Test Loss:  0.0013365568593144417
Valid Loss:  0.0010845621582120657
Epoch:  259  	Training Loss: 0.0011368149425834417
Test Loss:  0.0013346842024475336
Valid Loss:  0.0010842806659638882
Epoch:  260  	Training Loss: 0.0011362916557118297
Test Loss:  0.0013328534550964832
Valid Loss:  0.0010840533068403602
Epoch:  261  	Training Loss: 0.0011358626652508974
Test Loss:  0.001330997096374631
Valid Loss:  0.0010838272282853723
Epoch:  262  	Training Loss: 0.0011355236638337374
Test Loss:  0.001328889513388276
Valid Loss:  0.0010785909835249186
Epoch:  263  	Training Loss: 0.0011248039081692696
Test Loss:  0.0013286840403452516
Valid Loss:  0.0010741767473518848
Epoch:  264  	Training Loss: 0.0011177286505699158
Test Loss:  0.0013279635459184647
Valid Loss:  0.0010705097811296582
Epoch:  265  	Training Loss: 0.001112113706767559
Test Loss:  0.0013266275636851788
Valid Loss:  0.0010671019554138184
Epoch:  266  	Training Loss: 0.001107516000047326
Test Loss:  0.001324926968663931
Valid Loss:  0.001064133713953197
Epoch:  267  	Training Loss: 0.0011040550889447331
Test Loss:  0.0013224927242845297
Valid Loss:  0.0010613431222736835
Epoch:  268  	Training Loss: 0.0011008610017597675
Test Loss:  0.001319629023782909
Valid Loss:  0.0010586926946416497
Epoch:  269  	Training Loss: 0.0010978544596582651
Test Loss:  0.0013165617128834128
Valid Loss:  0.0010561333037912846
Epoch:  270  	Training Loss: 0.0010949295246973634
Test Loss:  0.0013133515603840351
Valid Loss:  0.0010536399204283953
Epoch:  271  	Training Loss: 0.001092262682504952
Test Loss:  0.0013101310469210148
Valid Loss:  0.0010512261651456356
Epoch:  272  	Training Loss: 0.0010896171443164349
Test Loss:  0.001301150768995285
Valid Loss:  0.001045773969963193
Epoch:  273  	Training Loss: 0.0010853358544409275
Test Loss:  0.0012845537858083844
Valid Loss:  0.0010443609207868576
Epoch:  274  	Training Loss: 0.0010816007852554321
Test Loss:  0.001282542129047215
Valid Loss:  0.0010390863753855228
Epoch:  275  	Training Loss: 0.0010782757308334112
Test Loss:  0.0012669428251683712
Valid Loss:  0.0010395797435194254
 55%|█████▌    | 277/500 [03:17<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:18<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:24<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:24<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:24<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:24<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:24<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:31<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:31<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:31<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:31<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:31<01:07,  2.96it/s] 60%|█████▉    | 299/500 [03:42<01:07,  2.96it/s] 60%|██████    | 301/500 [03:44<07:04,  2.13s/it] 61%|██████    | 303/500 [03:44<04:58,  1.51s/it] 61%|██████    | 305/500 [03:44<03:30,  1.08s/it] 61%|██████▏   | 307/500 [03:45<02:30,  1.28it/s] 62%|██████▏   | 309/500 [03:45<01:49,  1.75it/s] 62%|██████▏   | 311/500 [03:51<04:22,  1.39s/it] 63%|██████▎   | 313/500 [03:51<03:06,  1.01it/s] 63%|██████▎   | 315/500 [03:52<02:12,  1.39it/s] 63%|██████▎   | 317/500 [03:52<01:35,  1.92it/s] 64%|██████▍   | 319/500 [03:52<01:09,  2.60it/s] 64%|██████▍   | 321/500 [03:58<03:45,  1.26s/it] 65%|██████▍   | 323/500 [03:59<02:39,  1.11it/s] 65%|██████▌   | 325/500 [03:59<01:53,  1.54it/s] 65%|██████▌   | 327/500 [03:59<01:22,  2.11it/s] 66%|██████▌   | 329/500 [03:59<01:00,  2.84it/s] 66%|██████▌   | 331/500 [04:06<03:28,  1.24s/it] 67%|██████▋   | 333/500 [04:06<02:28,  1.13it/s] 67%|██████▋   | 335/500 [04:06<01:45,  1.56it/s] 67%|██████▋   | 337/500 [04:06<01:17,  2.12it/s] 68%|██████▊   | 339/500 [04:06<00:57,  2.81it/s] 68%|██████▊   | 341/500 [04:13<03:13,  1.22s/it]Epoch:  276  	Training Loss: 0.001075460109859705
Test Loss:  0.0012709947768598795
Valid Loss:  0.0010339852888137102
Epoch:  277  	Training Loss: 0.0010729390196502209
Test Loss:  0.001253463327884674
Valid Loss:  0.0010369191877543926
Epoch:  278  	Training Loss: 0.0010708405170589685
Test Loss:  0.001264579826965928
Valid Loss:  0.0010303747840225697
Epoch:  279  	Training Loss: 0.0010694379452615976
Test Loss:  0.001242632744833827
Valid Loss:  0.0010371869429945946
Epoch:  280  	Training Loss: 0.0010690682101994753
Test Loss:  0.0012658847263082862
Valid Loss:  0.0010300083085894585
Epoch:  281  	Training Loss: 0.0010702665895223618
Test Loss:  0.0012361598201096058
Valid Loss:  0.0010442440398037434
Epoch:  282  	Training Loss: 0.001073141465894878
Test Loss:  0.0012464836472645402
Valid Loss:  0.0010095431935042143
Epoch:  283  	Training Loss: 0.001048938138410449
Test Loss:  0.0012322966940701008
Valid Loss:  0.0010075741447508335
Epoch:  284  	Training Loss: 0.0010417239973321557
Test Loss:  0.0012350918259471655
Valid Loss:  0.0010023567592725158
Epoch:  285  	Training Loss: 0.0010383593617007136
Test Loss:  0.00122992810793221
Valid Loss:  0.0010013098362833261
Epoch:  286  	Training Loss: 0.0010357466526329517
Test Loss:  0.0012288608122617006
Valid Loss:  0.0009986747754737735
Epoch:  287  	Training Loss: 0.0010334879625588655
Test Loss:  0.0012255089823156595
Valid Loss:  0.0009971107356250286
Epoch:  288  	Training Loss: 0.0010313214734196663
Test Loss:  0.0012240768410265446
Valid Loss:  0.000995136797428131
Epoch:  289  	Training Loss: 0.0010293563827872276
Test Loss:  0.001221932703629136
Valid Loss:  0.0009936131536960602
Epoch:  290  	Training Loss: 0.0010278281988576055
Test Loss:  0.0012192405993118882
Valid Loss:  0.0009924329351633787
Epoch:  291  	Training Loss: 0.0010263945441693068
Test Loss:  0.0012170425616204739
Valid Loss:  0.0009911410743370652
Epoch:  292  	Training Loss: 0.001024971716105938
Test Loss:  0.0012076400453224778
Valid Loss:  0.0009861293947324157
Epoch:  293  	Training Loss: 0.0010202277917414904
Test Loss:  0.0011972127249464393
Valid Loss:  0.0009829518385231495
Epoch:  294  	Training Loss: 0.0010160100646317005
Test Loss:  0.0011928302701562643
Valid Loss:  0.0009783105924725533
Epoch:  295  	Training Loss: 0.001012348453514278
Test Loss:  0.0011816939804702997
Valid Loss:  0.000977973686531186
Epoch:  296  	Training Loss: 0.0010094393510371447
Test Loss:  0.0011862784158438444
Valid Loss:  0.0009727502474561334
Epoch:  297  	Training Loss: 0.0010077531915158033
Test Loss:  0.001170261180959642
Valid Loss:  0.0009802681161090732
Epoch:  298  	Training Loss: 0.0010087150149047375
Test Loss:  0.001201786333695054
Valid Loss:  0.0009779275860637426
Epoch:  299  	Training Loss: 0.0010167210130020976
Test Loss:  0.0011846341658383608
Valid Loss:  0.001024226425215602
Epoch:  300  	Training Loss: 0.0010444566141813993
Test Loss:  0.0013371373061090708
Valid Loss:  0.0010795722482725978
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0011283224448561668
Test Loss:  0.0011505334405228496
Valid Loss:  0.0009713772451505065
Epoch:  302  	Training Loss: 0.0009993279818445444
Test Loss:  0.0011577354744076729
Valid Loss:  0.0009593230206519365
Epoch:  303  	Training Loss: 0.000991259003058076
Test Loss:  0.0011555796954780817
Valid Loss:  0.0009567055385559797
Epoch:  304  	Training Loss: 0.0009884273167699575
Test Loss:  0.0011537286918610334
Valid Loss:  0.0009540281025692821
Epoch:  305  	Training Loss: 0.0009856496471911669
Test Loss:  0.0011517757084220648
Valid Loss:  0.0009513736004009843
Epoch:  306  	Training Loss: 0.0009829204063862562
Test Loss:  0.0011497843079268932
Valid Loss:  0.0009487965144217014
Epoch:  307  	Training Loss: 0.0009803178254514933
Test Loss:  0.001147715374827385
Valid Loss:  0.0009462659363634884
Epoch:  308  	Training Loss: 0.0009777641389518976
Test Loss:  0.001145592425018549
Valid Loss:  0.000943789491429925
Epoch:  309  	Training Loss: 0.0009752386249601841
Test Loss:  0.0011434373445808887
Valid Loss:  0.0009413750376552343
Epoch:  310  	Training Loss: 0.0009727339493110776
Test Loss:  0.0011412585154175758
Valid Loss:  0.0009389873594045639
Epoch:  311  	Training Loss: 0.0009702381212264299
Test Loss:  0.0011390671133995056
Valid Loss:  0.0009366265148855746
Epoch:  312  	Training Loss: 0.0009677867637947202
Test Loss:  0.0011383412638679147
Valid Loss:  0.0009364400757476687
Epoch:  313  	Training Loss: 0.0009674788452684879
Test Loss:  0.0011377339251339436
Valid Loss:  0.0009362490382045507
Epoch:  314  	Training Loss: 0.0009671869338490069
Test Loss:  0.0011372261215001345
Valid Loss:  0.0009360738331452012
Epoch:  315  	Training Loss: 0.0009669101564213634
Test Loss:  0.0011367714032530785
Valid Loss:  0.00093588896561414
Epoch:  316  	Training Loss: 0.0009666599216870964
Test Loss:  0.0011363578960299492
Valid Loss:  0.0009356949594803154
Epoch:  317  	Training Loss: 0.0009664180688560009
Test Loss:  0.001135983387939632
Valid Loss:  0.0009354980429634452
Epoch:  318  	Training Loss: 0.0009661769727244973
Test Loss:  0.0011356370523571968
Valid Loss:  0.0009353020577691495
Epoch:  319  	Training Loss: 0.0009659396018832922
Test Loss:  0.0011353087611496449
Valid Loss:  0.0009351128828711808
Epoch:  320  	Training Loss: 0.0009657068876549602
Test Loss:  0.0011349956039339304
Valid Loss:  0.0009349234169349074
Epoch:  321  	Training Loss: 0.0009654812747612596
Test Loss:  0.0011346887331455946
Valid Loss:  0.0009347314480692148
Epoch:  322  	Training Loss: 0.0009652711451053619
Test Loss:  0.0011342426296323538
Valid Loss:  0.0009344289428554475
Epoch:  323  	Training Loss: 0.0009649376734159887
Test Loss:  0.001133768237195909
Valid Loss:  0.000934141397010535
Epoch:  324  	Training Loss: 0.0009646055987104774
Test Loss:  0.0011332813883200288
Valid Loss:  0.0009338608360849321
Epoch:  325  	Training Loss: 0.0009642853401601315
Test Loss:  0.0011327851098030806
Valid Loss:  0.0009335806244052947
Epoch:  326  	Training Loss: 0.0009639750351198018
Test Loss:  0.001132284989580512
Valid Loss:  0.0009333046618849039
Epoch:  327  	Training Loss: 0.0009636791655793786
Test Loss:  0.0011317955795675516
Valid Loss:  0.0009330500615760684
Epoch:  328  	Training Loss: 0.0009634270099923015
Test Loss:  0.0011313154827803373
Valid Loss:  0.0009328169981017709
Epoch:  329  	Training Loss: 0.000963208032771945
Test Loss:  0.0011308464454486966
Valid Loss:  0.0009326010476797819
Epoch:  330  	Training Loss: 0.0009630083222873509
Test Loss:  0.001130382646806538
Valid Loss:  0.0009323970298282802
Epoch:  331  	Training Loss: 0.0009628186817280948
Test Loss:  0.0011299261823296547
Valid Loss:  0.0009322170517407358
Epoch:  332  	Training Loss: 0.0009626372484490275
Test Loss:  0.0011287274537608027
Valid Loss:  0.0009302106918767095
Epoch:  333  	Training Loss: 0.0009609982371330261
Test Loss:  0.0011269135866314173
Valid Loss:  0.0009285082342103124
Epoch:  334  	Training Loss: 0.0009594867005944252
Test Loss:  0.0011249968083575368
Valid Loss:  0.0009268943686038256
Epoch:  335  	Training Loss: 0.0009580331388860941
Test Loss:  0.0011231747921556234
Valid Loss:  0.0009253891184926033
Epoch:  336  	Training Loss: 0.0009566931985318661
Test Loss:  0.0011214419500902295
Valid Loss:  0.0009239004575647414
Epoch:  337  	Training Loss: 0.0009553851559758186
Test Loss:  0.0011198078282177448
Valid Loss:  0.000922498176805675
Epoch:  338  	Training Loss: 0.0009541596518829465
Test Loss:  0.0011182489106431603
Valid Loss:  0.00092121004126966
Epoch:  339  	Training Loss: 0.0009529448579996824
Test Loss:  0.00111675716470927
Valid Loss:  0.0009199343621730804
Epoch:  340  	Training Loss: 0.0009517392609268427
Test Loss:  0.0011153275845572352
Valid Loss:  0.0009186656679958105
Epoch:  341  	Training Loss: 0.0009505442576482892
Test Loss:  0.0011139522539451718
Valid Loss:  0.0009174092556349933
Epoch:  342  	Training Loss: 0.0009493613615632057
Test Loss:  0.0011125574819743633
Valid Loss:  0.0009153574937954545
Epoch:  343  	Training Loss: 0.0009474553517065942
Test Loss:   69%|██████▊   | 343/500 [04:13<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:13<01:37,  1.58it/s] 69%|██████▉   | 347/500 [04:13<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:13<00:51,  2.92it/s] 70%|███████   | 351/500 [04:20<02:57,  1.19s/it] 71%|███████   | 353/500 [04:20<02:06,  1.17it/s] 71%|███████   | 355/500 [04:20<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:20<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:20<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:26<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:27<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:27<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:27<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:27<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:33<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:34<01:51,  1.14it/s] 75%|███████▍  | 374/500 [04:34<01:34,  1.34it/s] 75%|███████▌  | 376/500 [04:34<01:04,  1.91it/s] 76%|███████▌  | 378/500 [04:34<00:45,  2.67it/s] 76%|███████▌  | 380/500 [04:34<00:33,  3.62it/s] 76%|███████▋  | 382/500 [04:40<02:16,  1.16s/it] 77%|███████▋  | 384/500 [04:41<01:35,  1.22it/s] 77%|███████▋  | 386/500 [04:41<01:07,  1.69it/s] 78%|███████▊  | 388/500 [04:41<00:48,  2.32it/s] 78%|███████▊  | 390/500 [04:41<00:35,  3.13it/s] 78%|███████▊  | 392/500 [04:47<02:06,  1.17s/it] 79%|███████▉  | 394/500 [04:47<01:28,  1.20it/s] 79%|███████▉  | 396/500 [04:47<01:02,  1.66it/s] 80%|███████▉  | 398/500 [04:48<00:45,  2.26it/s] 80%|████████  | 400/500 [04:48<00:32,  3.05it/s] 80%|████████  | 402/500 [04:54<01:54,  1.17s/it] 81%|████████  | 404/500 [04:54<01:20,  1.20it/s] 81%|████████  | 406/500 [04:54<00:56,  1.65it/s] 82%|████████▏ | 408/500 [04:54<00:40,  2.26it/s] 82%|████████▏ | 410/500 [04:54<00:29,  3.03it/s]0.0011111224303022027
Valid Loss:  0.0009133495041169226
Epoch:  344  	Training Loss: 0.0009455786785110831
Test Loss:  0.0011097205569967628
Valid Loss:  0.0009113932610489428
Epoch:  345  	Training Loss: 0.0009437670232728124
Test Loss:  0.0011083618737757206
Valid Loss:  0.0009094777051359415
Epoch:  346  	Training Loss: 0.0009420323185622692
Test Loss:  0.001107051852159202
Valid Loss:  0.0009076514979824424
Epoch:  347  	Training Loss: 0.0009404121665284038
Test Loss:  0.0011057504452764988
Valid Loss:  0.0009058605064637959
Epoch:  348  	Training Loss: 0.0009388084290549159
Test Loss:  0.0011044598650187254
Valid Loss:  0.0009040829609148204
Epoch:  349  	Training Loss: 0.000937214179430157
Test Loss:  0.001103182090446353
Valid Loss:  0.0009023169986903667
Epoch:  350  	Training Loss: 0.0009356295922771096
Test Loss:  0.0011019115336239338
Valid Loss:  0.0009005942847579718
Epoch:  351  	Training Loss: 0.0009340732940472662
Test Loss:  0.001100665656849742
Valid Loss:  0.00089896225836128
Epoch:  352  	Training Loss: 0.0009325497085228562
Test Loss:  0.0010999696096405387
Valid Loss:  0.0008971423958428204
Epoch:  353  	Training Loss: 0.0009302995167672634
Test Loss:  0.001099542248994112
Valid Loss:  0.0008952280622906983
Epoch:  354  	Training Loss: 0.0009281423408538103
Test Loss:  0.001099088927730918
Valid Loss:  0.0008933445205911994
Epoch:  355  	Training Loss: 0.0009260300430469215
Test Loss:  0.0010985438711941242
Valid Loss:  0.0008914704667404294
Epoch:  356  	Training Loss: 0.0009239545906893909
Test Loss:  0.0010978896170854568
Valid Loss:  0.0008896142244338989
Epoch:  357  	Training Loss: 0.0009219167986884713
Test Loss:  0.0010971310548484325
Valid Loss:  0.0008877755608409643
Epoch:  358  	Training Loss: 0.00091990438522771
Test Loss:  0.0010962800588458776
Valid Loss:  0.0008859545341692865
Epoch:  359  	Training Loss: 0.0009179156622849405
Test Loss:  0.0010953358141705394
Valid Loss:  0.0008841438684612513
Epoch:  360  	Training Loss: 0.0009159516193903983
Test Loss:  0.001094308216124773
Valid Loss:  0.000882344669662416
Epoch:  361  	Training Loss: 0.0009140047477558255
Test Loss:  0.0010932075092568994
Valid Loss:  0.0008805568795651197
Epoch:  362  	Training Loss: 0.0009120721952058375
Test Loss:  0.0010918381158262491
Valid Loss:  0.0008786627440713346
Epoch:  363  	Training Loss: 0.0009101941250264645
Test Loss:  0.0010903979418799281
Valid Loss:  0.0008768311236053705
Epoch:  364  	Training Loss: 0.0009083355544134974
Test Loss:  0.0010889212135225534
Valid Loss:  0.0008750148117542267
Epoch:  365  	Training Loss: 0.0009064832702279091
Test Loss:  0.0010874222498387098
Valid Loss:  0.0008732086280360818
Epoch:  366  	Training Loss: 0.0009046369814313948
Test Loss:  0.0010859528556466103
Valid Loss:  0.0008714073919691145
Epoch:  367  	Training Loss: 0.0009027971536852419
Test Loss:  0.0010844850912690163
Valid Loss:  0.0008696138975210488
Epoch:  368  	Training Loss: 0.0009009932982735336
Test Loss:  0.0010830515529960394
Valid Loss:  0.0008678872836753726
Epoch:  369  	Training Loss: 0.0008992559742182493
Test Loss:  0.0010816305875778198
Valid Loss:  0.0008661749307066202
Epoch:  370  	Training Loss: 0.0008975343080237508
Test Loss:  0.001080103451386094
Valid Loss:  0.0008644071640446782
Epoch:  371  	Training Loss: 0.000895823584869504
Test Loss:  0.0010785567574203014
Valid Loss:  0.0008626673370599747
Epoch:  372  	Training Loss: 0.0008941276464611292
Test Loss:  0.0010775572154670954
Valid Loss:  0.0008624617476016283
Epoch:  373  	Training Loss: 0.0008939428953453898
Test Loss:  0.0010765109909698367
Valid Loss:  0.000862304528709501
Epoch:  374  	Training Loss: 0.0008937685051932931
Test Loss:  0.0010754838585853577
Valid Loss:  0.0008621625602245331
Epoch:  375  	Training Loss: 0.0008935992955230176
Test Loss:  0.0010744920000433922
Valid Loss:  0.0008620292646810412
Epoch:  376  	Training Loss: 0.0008934367215260863
Test Loss:  0.0010735427495092154
Valid Loss:  0.0008619026048108935
Epoch:  377  	Training Loss: 0.0008932780474424362
Test Loss:  0.0010726372711360455
Valid Loss:  0.0008617800194770098
Epoch:  378  	Training Loss: 0.0008931239135563374
Test Loss:  0.0010717706754803658
Valid Loss:  0.0008616601699031889
Epoch:  379  	Training Loss: 0.0008929757168516517
Test Loss:  0.0010709434282034636
Valid Loss:  0.0008615475380793214
Epoch:  380  	Training Loss: 0.0008928348543122411
Test Loss:  0.0010701518040150404
Valid Loss:  0.0008614421240054071
Epoch:  381  	Training Loss: 0.0008926968439482152
Test Loss:  0.0010693938238546252
Valid Loss:  0.0008613381651230156
Epoch:  382  	Training Loss: 0.0008925619185902178
Test Loss:  0.0010690835770219564
Valid Loss:  0.0008602127199992537
Epoch:  383  	Training Loss: 0.0008900303510017693
Test Loss:  0.0010693349177017808
Valid Loss:  0.0008593910606577992
Epoch:  384  	Training Loss: 0.0008883632253855467
Test Loss:  0.0010696813696995378
Valid Loss:  0.0008586131152696908
Epoch:  385  	Training Loss: 0.0008869507582858205
Test Loss:  0.0010699927806854248
Valid Loss:  0.0008578592096455395
Epoch:  386  	Training Loss: 0.0008857372449710965
Test Loss:  0.0010702461004257202
Valid Loss:  0.0008571069920435548
Epoch:  387  	Training Loss: 0.0008845956763252616
Test Loss:  0.0010704156011343002
Valid Loss:  0.00085635477444157
Epoch:  388  	Training Loss: 0.0008835382759571075
Test Loss:  0.00107046018820256
Valid Loss:  0.0008556093089282513
Epoch:  389  	Training Loss: 0.0008825580589473248
Test Loss:  0.0010704111773520708
Valid Loss:  0.000854871585033834
Epoch:  390  	Training Loss: 0.0008816076442599297
Test Loss:  0.0010702734580263495
Valid Loss:  0.0008541436400264502
Epoch:  391  	Training Loss: 0.0008806839468888938
Test Loss:  0.0010700479615479708
Valid Loss:  0.0008534227963536978
Epoch:  392  	Training Loss: 0.000879781786352396
Test Loss:  0.001067944336682558
Valid Loss:  0.0008499934338033199
Epoch:  393  	Training Loss: 0.0008766056271269917
Test Loss:  0.0010653239442035556
Valid Loss:  0.000847195740789175
Epoch:  394  	Training Loss: 0.0008739084005355835
Test Loss:  0.001062426483258605
Valid Loss:  0.0008446562569588423
Epoch:  395  	Training Loss: 0.0008714022696949542
Test Loss:  0.0010594797786325216
Valid Loss:  0.0008423022227361798
Epoch:  396  	Training Loss: 0.0008691706461831927
Test Loss:  0.0010564833646640182
Valid Loss:  0.0008400683291256428
Epoch:  397  	Training Loss: 0.0008671054383739829
Test Loss:  0.0010535751935094595
Valid Loss:  0.0008379680220969021
Epoch:  398  	Training Loss: 0.000865197042003274
Test Loss:  0.0010507622500881553
Valid Loss:  0.0008359161438420415
Epoch:  399  	Training Loss: 0.0008633241523057222
Test Loss:  0.0010480323107913136
Valid Loss:  0.0008339463383890688
Epoch:  400  	Training Loss: 0.0008615432889200747
Test Loss:  0.001045361626893282
Valid Loss:  0.0008320386987179518
Epoch:  401  	Training Loss: 0.0008598170825280249
Test Loss:  0.0010427669622004032
Valid Loss:  0.0008301882771775126
Epoch:  402  	Training Loss: 0.000858150830026716
Test Loss:  0.0010411539115011692
Valid Loss:  0.0008280978072434664
Epoch:  403  	Training Loss: 0.00085643952479586
Test Loss:  0.0010393912671133876
Valid Loss:  0.0008262296323664486
Epoch:  404  	Training Loss: 0.0008548059267923236
Test Loss:  0.0010376174468547106
Valid Loss:  0.0008244556374847889
Epoch:  405  	Training Loss: 0.0008532340871170163
Test Loss:  0.0010358518920838833
Valid Loss:  0.0008227329817600548
Epoch:  406  	Training Loss: 0.000851687858812511
Test Loss:  0.001034104498103261
Valid Loss:  0.0008210457745008171
Epoch:  407  	Training Loss: 0.0008501617703586817
Test Loss:  0.0010323829483240843
Valid Loss:  0.0008194039692170918
Epoch:  408  	Training Loss: 0.0008486564038321376
Test Loss:  0.0010307066841050982
Valid Loss:  0.0008178050047717988
Epoch:  409  	Training Loss: 0.0008471999899484217
Test Loss:  0.0010290592908859253
Valid Loss:  0.0008162246085703373
Epoch:  410  	Training Loss: 0.0008457596995867789
Test Loss:  0.0010274408850818872
Valid Loss:  0.0008146691834554076
Epoch:  411  	Training Loss: 0.0008443378610536456
Test Loss:  0.0010258741676807404
Valid Loss:  0.0008131144568324089
 82%|████████▏ | 412/500 [05:01<01:43,  1.18s/it] 83%|████████▎ | 414/500 [05:01<01:12,  1.19it/s] 83%|████████▎ | 416/500 [05:01<00:51,  1.64it/s] 84%|████████▎ | 418/500 [05:01<00:36,  2.24it/s] 84%|████████▍ | 420/500 [05:01<00:26,  3.02it/s] 84%|████████▍ | 422/500 [05:08<01:32,  1.18s/it] 85%|████████▍ | 424/500 [05:08<01:04,  1.18it/s] 85%|████████▌ | 426/500 [05:08<00:45,  1.64it/s] 86%|████████▌ | 428/500 [05:08<00:32,  2.24it/s] 86%|████████▌ | 430/500 [05:08<00:23,  3.01it/s] 86%|████████▋ | 432/500 [05:14<01:19,  1.17s/it] 87%|████████▋ | 434/500 [05:14<00:55,  1.20it/s] 87%|████████▋ | 436/500 [05:15<00:38,  1.65it/s] 88%|████████▊ | 438/500 [05:15<00:27,  2.26it/s] 88%|████████▊ | 440/500 [05:15<00:19,  3.03it/s] 88%|████████▊ | 442/500 [05:21<01:07,  1.16s/it] 89%|████████▉ | 444/500 [05:21<00:46,  1.20it/s] 89%|████████▉ | 446/500 [05:21<00:32,  1.66it/s] 90%|████████▉ | 448/500 [05:21<00:22,  2.26it/s] 90%|█████████ | 450/500 [05:22<00:16,  3.05it/s] 90%|█████████ | 452/500 [05:28<00:55,  1.16s/it] 91%|█████████ | 454/500 [05:28<00:38,  1.20it/s] 91%|█████████ | 456/500 [05:28<00:26,  1.65it/s] 92%|█████████▏| 458/500 [05:28<00:18,  2.26it/s] 92%|█████████▏| 460/500 [05:28<00:13,  3.04it/s] 92%|█████████▏| 462/500 [05:35<00:44,  1.17s/it] 93%|█████████▎| 464/500 [05:35<00:30,  1.19it/s] 93%|█████████▎| 466/500 [05:35<00:20,  1.65it/s] 94%|█████████▎| 468/500 [05:35<00:14,  2.25it/s] 94%|█████████▍| 470/500 [05:35<00:09,  3.02it/s] 94%|█████████▍| 472/500 [05:41<00:32,  1.17s/it] 95%|█████████▍| 474/500 [05:42<00:21,  1.19it/s] 95%|█████████▌| 476/500 [05:42<00:14,  1.65it/s] 96%|█████████▌| 478/500 [05:42<00:09,  2.25it/s]Epoch:  412  	Training Loss: 0.0008429319714196026
Test Loss:  0.0010244366712868214
Valid Loss:  0.0008129958296194673
Epoch:  413  	Training Loss: 0.0008425188716500998
Test Loss:  0.0010234632063657045
Valid Loss:  0.0008127863984555006
Epoch:  414  	Training Loss: 0.0008421509410254657
Test Loss:  0.0010226587764918804
Valid Loss:  0.0008125402964651585
Epoch:  415  	Training Loss: 0.0008417930221185088
Test Loss:  0.0010219186078757048
Valid Loss:  0.0008122818544507027
Epoch:  416  	Training Loss: 0.0008414449985139072
Test Loss:  0.0010212059132754803
Valid Loss:  0.0008120189886540174
Epoch:  417  	Training Loss: 0.0008411058224737644
Test Loss:  0.001020508585497737
Valid Loss:  0.0008117724792100489
Epoch:  418  	Training Loss: 0.0008407716522924602
Test Loss:  0.0010198189411312342
Valid Loss:  0.0008115299278870225
Epoch:  419  	Training Loss: 0.0008404494728893042
Test Loss:  0.001019126153551042
Valid Loss:  0.0008112884825095534
Epoch:  420  	Training Loss: 0.0008401406812481582
Test Loss:  0.001018442097119987
Valid Loss:  0.0008110519265756011
Epoch:  421  	Training Loss: 0.0008398356731049716
Test Loss:  0.001017762697301805
Valid Loss:  0.0008108153706416488
Epoch:  422  	Training Loss: 0.0008395389886572957
Test Loss:  0.0010176083305850625
Valid Loss:  0.0008098009275272489
Epoch:  423  	Training Loss: 0.000837559113278985
Test Loss:  0.00101782928686589
Valid Loss:  0.0008088388713076711
Epoch:  424  	Training Loss: 0.0008359719067811966
Test Loss:  0.0010180906392633915
Valid Loss:  0.0008078792016021907
Epoch:  425  	Training Loss: 0.000834524049423635
Test Loss:  0.001018267823383212
Valid Loss:  0.0008069300092756748
Epoch:  426  	Training Loss: 0.0008331965655088425
Test Loss:  0.0010182945989072323
Valid Loss:  0.0008060174295678735
Epoch:  427  	Training Loss: 0.0008319814223796129
Test Loss:  0.0010181755060330033
Valid Loss:  0.0008051471668295562
Epoch:  428  	Training Loss: 0.0008308184915222228
Test Loss:  0.001017917413264513
Valid Loss:  0.0008043061243370175
Epoch:  429  	Training Loss: 0.0008296953747048974
Test Loss:  0.0010175281204283237
Valid Loss:  0.0008034870843403041
Epoch:  430  	Training Loss: 0.0008286167867481709
Test Loss:  0.0010169940069317818
Valid Loss:  0.0008026920258998871
Epoch:  431  	Training Loss: 0.0008276380249299109
Test Loss:  0.0010163933038711548
Valid Loss:  0.0008019233355298638
Epoch:  432  	Training Loss: 0.0008267089142464101
Test Loss:  0.0010151665192097425
Valid Loss:  0.00080097810132429
Epoch:  433  	Training Loss: 0.000826116418465972
Test Loss:  0.0010137369390577078
Valid Loss:  0.0008003844995982945
Epoch:  434  	Training Loss: 0.0008256732253357768
Test Loss:  0.0010121313389390707
Valid Loss:  0.0007999541703611612
Epoch:  435  	Training Loss: 0.0008252850966528058
Test Loss:  0.0010106528643518686
Valid Loss:  0.0007995457272045314
Epoch:  436  	Training Loss: 0.0008249280508607626
Test Loss:  0.0010090167634189129
Valid Loss:  0.000799241999629885
Epoch:  437  	Training Loss: 0.0008246007491834462
Test Loss:  0.0010076132602989674
Valid Loss:  0.0007989099249243736
Epoch:  438  	Training Loss: 0.000824284041300416
Test Loss:  0.0010060956701636314
Valid Loss:  0.0007986380951479077
Epoch:  439  	Training Loss: 0.0008239834569394588
Test Loss:  0.0010048260446637869
Valid Loss:  0.0007983507239259779
Epoch:  440  	Training Loss: 0.0008236989961005747
Test Loss:  0.0010034431470558047
Valid Loss:  0.0007981011876836419
Epoch:  441  	Training Loss: 0.0008234221604652703
Test Loss:  0.0010021475609391928
Valid Loss:  0.0007978655048646033
Epoch:  442  	Training Loss: 0.0008231560932472348
Test Loss:  0.0010008274111896753
Valid Loss:  0.0007969749858602881
Epoch:  443  	Training Loss: 0.0008217875729314983
Test Loss:  0.000999894575215876
Valid Loss:  0.0007959649083204567
Epoch:  444  	Training Loss: 0.0008204997284337878
Test Loss:  0.0009990003891289234
Valid Loss:  0.0007949360879138112
Epoch:  445  	Training Loss: 0.000819247798062861
Test Loss:  0.0009980264585465193
Valid Loss:  0.0007939070928841829
Epoch:  446  	Training Loss: 0.0008180536678992212
Test Loss:  0.0009969897801056504
Valid Loss:  0.0007929298444651067
Epoch:  447  	Training Loss: 0.000816897489130497
Test Loss:  0.0009958454174920917
Valid Loss:  0.0007919406634755433
Epoch:  448  	Training Loss: 0.0008157715201377869
Test Loss:  0.0009947428479790688
Valid Loss:  0.0007909723790362477
Epoch:  449  	Training Loss: 0.0008146815234795213
Test Loss:  0.000993580324575305
Valid Loss:  0.0007900361088104546
Epoch:  450  	Training Loss: 0.0008136419928632677
Test Loss:  0.0009923821780830622
Valid Loss:  0.0007891202694736421
Epoch:  451  	Training Loss: 0.0008126226020976901
Test Loss:  0.0009910908993333578
Valid Loss:  0.0007882304489612579
Epoch:  452  	Training Loss: 0.0008117015240713954
Test Loss:  0.0009904982289299369
Valid Loss:  0.0007871863199397922
Epoch:  453  	Training Loss: 0.0008105799788609147
Test Loss:  0.0009897041600197554
Valid Loss:  0.0007863384671509266
Epoch:  454  	Training Loss: 0.0008094809018075466
Test Loss:  0.000988818472251296
Valid Loss:  0.0007855088333599269
Epoch:  455  	Training Loss: 0.0008083969005383551
Test Loss:  0.0009878543205559254
Valid Loss:  0.0007846853695809841
Epoch:  456  	Training Loss: 0.0008073269855231047
Test Loss:  0.0009868210181593895
Valid Loss:  0.0007838690653443336
Epoch:  457  	Training Loss: 0.0008062694687396288
Test Loss:  0.0009857274126261473
Valid Loss:  0.0007830581162124872
Epoch:  458  	Training Loss: 0.000805225339718163
Test Loss:  0.0009845842141658068
Valid Loss:  0.000782258459366858
Epoch:  459  	Training Loss: 0.0008041947148740292
Test Loss:  0.0009833972435444593
Valid Loss:  0.0007814649725332856
Epoch:  460  	Training Loss: 0.0008031869656406343
Test Loss:  0.000982108642347157
Valid Loss:  0.0007806574576534331
Epoch:  461  	Training Loss: 0.0008022183319553733
Test Loss:  0.0009807805763557553
Valid Loss:  0.000779874506406486
Epoch:  462  	Training Loss: 0.0008012651233002543
Test Loss:  0.0009778696112334728
Valid Loss:  0.0007783543551340699
Epoch:  463  	Training Loss: 0.0007996762869879603
Test Loss:  0.0009752211626619101
Valid Loss:  0.0007768525974825025
Epoch:  464  	Training Loss: 0.0007981527596712112
Test Loss:  0.0009727840078994632
Valid Loss:  0.0007754148682579398
Epoch:  465  	Training Loss: 0.0007967037963680923
Test Loss:  0.0009706078562885523
Valid Loss:  0.0007740770815871656
Epoch:  466  	Training Loss: 0.0007953298045322299
Test Loss:  0.0009685572003945708
Valid Loss:  0.0007727439515292645
Epoch:  467  	Training Loss: 0.0007939672796055675
Test Loss:  0.0009666038095019758
Valid Loss:  0.0007714127423241735
Epoch:  468  	Training Loss: 0.0007926158723421395
Test Loss:  0.0009647328406572342
Valid Loss:  0.0007701115682721138
Epoch:  469  	Training Loss: 0.0007912837900221348
Test Loss:  0.0009629273554310203
Valid Loss:  0.0007688177283853292
Epoch:  470  	Training Loss: 0.000789960497058928
Test Loss:  0.0009611805435270071
Valid Loss:  0.0007675365777686238
Epoch:  471  	Training Loss: 0.0007886536186560988
Test Loss:  0.0009594840230420232
Valid Loss:  0.0007662669522687793
Epoch:  472  	Training Loss: 0.0007873516879044473
Test Loss:  0.0009583162609487772
Valid Loss:  0.00076457136310637
Epoch:  473  	Training Loss: 0.0007859245524741709
Test Loss:  0.0009567366796545684
Valid Loss:  0.0007631626212969422
Epoch:  474  	Training Loss: 0.0007845298969186842
Test Loss:  0.0009551281109452248
Valid Loss:  0.0007617807714268565
Epoch:  475  	Training Loss: 0.0007831441471353173
Test Loss:  0.0009536535944789648
Valid Loss:  0.0007603987469337881
Epoch:  476  	Training Loss: 0.0007817717269062996
Test Loss:  0.0009519786108285189
Valid Loss:  0.0007591269677504897
Epoch:  477  	Training Loss: 0.0007804121123626828
Test Loss:  0.0009503342444077134
Valid Loss:  0.0007578522199764848
Epoch:  478  	Training Loss: 0.0007790573872625828
Test Loss:  0.0009487014613114297
Valid Loss:  0.0007566444110125303
Epoch:  479  	Training Loss: 0.000777707900851965
Test Loss:  0.0009470776421949267
Valid Loss:  0.0007554558687843382
Epoch:  480  	Training Loss: 0.0007763806497678161
 96%|█████████▌| 480/500 [05:42<00:06,  3.03it/s] 96%|█████████▋| 482/500 [05:48<00:21,  1.17s/it] 97%|█████████▋| 484/500 [05:48<00:13,  1.19it/s] 97%|█████████▋| 486/500 [05:48<00:08,  1.64it/s] 98%|█████████▊| 488/500 [05:49<00:05,  2.25it/s] 98%|█████████▊| 490/500 [05:49<00:03,  3.02it/s] 98%|█████████▊| 492/500 [05:55<00:09,  1.16s/it] 99%|█████████▉| 494/500 [05:55<00:05,  1.20it/s] 99%|█████████▉| 496/500 [05:55<00:02,  1.65it/s]100%|█████████▉| 498/500 [05:55<00:00,  2.25it/s]100%|██████████| 500/500 [05:55<00:00,  3.02it/s]100%|██████████| 500/500 [05:55<00:00,  1.40it/s]
Test Loss:  0.0009454021346755326
Valid Loss:  0.0007542626117356122
Epoch:  481  	Training Loss: 0.0007750978693366051
Test Loss:  0.0009437247063033283
Valid Loss:  0.0007531127193942666
Epoch:  482  	Training Loss: 0.0007738240528851748
Test Loss:  0.0009423589799553156
Valid Loss:  0.0007527060806751251
Epoch:  483  	Training Loss: 0.0007731694495305419
Test Loss:  0.0009411660139448941
Valid Loss:  0.0007522358791902661
Epoch:  484  	Training Loss: 0.0007725264295004308
Test Loss:  0.0009399977861903608
Valid Loss:  0.0007517655030824244
Epoch:  485  	Training Loss: 0.0007718883571214974
Test Loss:  0.0009388401522301137
Valid Loss:  0.0007512997835874557
Epoch:  486  	Training Loss: 0.0007712552323937416
Test Loss:  0.0009376954403705895
Valid Loss:  0.0007508376729674637
Epoch:  487  	Training Loss: 0.0007706281030550599
Test Loss:  0.0009365633013658226
Valid Loss:  0.000750390870962292
Epoch:  488  	Training Loss: 0.0007700091227889061
Test Loss:  0.0009354419307783246
Valid Loss:  0.0007499579805880785
Epoch:  489  	Training Loss: 0.0007693959050811827
Test Loss:  0.0009343303390778601
Valid Loss:  0.0007495284080505371
Epoch:  490  	Training Loss: 0.0007687875768169761
Test Loss:  0.000933227245695889
Valid Loss:  0.000749116123188287
Epoch:  491  	Training Loss: 0.0007681853603571653
Test Loss:  0.0009321132674813271
Valid Loss:  0.0007487448747269809
Epoch:  492  	Training Loss: 0.0007676042150706053
Test Loss:  0.0009310817695222795
Valid Loss:  0.0007478122133761644
Epoch:  493  	Training Loss: 0.0007663177093490958
Test Loss:  0.0009300847304984927
Valid Loss:  0.0007467782124876976
Epoch:  494  	Training Loss: 0.0007650549523532391
Test Loss:  0.0009290527086704969
Valid Loss:  0.0007457160390913486
Epoch:  495  	Training Loss: 0.0007638189708814025
Test Loss:  0.0009279065998271108
Valid Loss:  0.0007446297677233815
Epoch:  496  	Training Loss: 0.0007626139558851719
Test Loss:  0.0009267125278711319
Valid Loss:  0.0007435590378008783
Epoch:  497  	Training Loss: 0.0007614232017658651
Test Loss:  0.0009254522155970335
Valid Loss:  0.000742488307878375
Epoch:  498  	Training Loss: 0.0007602455443702638
Test Loss:  0.0009241609368473291
Valid Loss:  0.0007414261344820261
Epoch:  499  	Training Loss: 0.0007590730092488229
Test Loss:  0.0009228250710293651
Valid Loss:  0.0007403586059808731
Epoch:  500  	Training Loss: 0.0007579069351777434
Test Loss:  0.0009214759338647127
Valid Loss:  0.0007392998086288571
seed is  7
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 15.94it/s]  1%|          | 4/500 [00:00<00:30, 16.02it/s]  1%|          | 6/500 [00:00<00:30, 16.23it/s]  2%|▏         | 8/500 [00:00<00:30, 16.35it/s]  2%|▏         | 10/500 [00:00<00:29, 16.48it/s]  2%|▏         | 12/500 [00:00<00:29, 16.54it/s]  3%|▎         | 14/500 [00:00<00:29, 16.55it/s]  3%|▎         | 16/500 [00:00<00:29, 16.45it/s]  4%|▎         | 18/500 [00:01<00:29, 16.41it/s]  4%|▍         | 20/500 [00:01<00:29, 16.47it/s]  4%|▍         | 22/500 [00:01<00:28, 16.52it/s]  5%|▍         | 24/500 [00:01<00:28, 16.53it/s]  5%|▌         | 26/500 [00:01<00:28, 16.61it/s]  6%|▌         | 28/500 [00:01<00:28, 16.68it/s]  6%|▌         | 30/500 [00:01<00:28, 16.72it/s]  6%|▋         | 32/500 [00:01<00:27, 16.72it/s]  7%|▋         | 34/500 [00:02<00:28, 16.48it/s]  7%|▋         | 36/500 [00:02<00:28, 16.37it/s]  8%|▊         | 38/500 [00:02<00:28, 16.40it/s]  8%|▊         | 40/500 [00:02<00:28, 16.32it/s]  8%|▊         | 42/500 [00:02<00:28, 16.10it/s]  9%|▉         | 44/500 [00:02<00:27, 16.31it/s]  9%|▉         | 46/500 [00:02<00:27, 16.49it/s] 10%|▉         | 48/500 [00:02<00:27, 16.55it/s] 10%|█         | 50/500 [00:03<00:27, 16.57it/s] 10%|█         | 52/500 [00:03<00:27, 16.56it/s] 11%|█         | 54/500 [00:03<00:27, 16.46it/s] 11%|█         | 56/500 [00:03<00:26, 16.52it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.44it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.47it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.47it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.54it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.57it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.60it/s] 14%|█▍        | 70/500 [00:04<00:25, 16.63it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.68it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.74it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.82it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.80it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.77it/s] 16%|█▋        | 82/500 [00:04<00:24, 16.76it/s] 17%|█▋        | 84/500 [00:05<00:24, 16.76it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.78it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.58it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.54it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.59it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.48it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.52it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.53it/s] 20%|██        | 100/500 [00:06<00:24, 16.55it/s] 20%|██        | 102/500 [00:06<00:24, 16.57it/s] 21%|██        | 104/500 [00:06<00:23, 16.60it/s] 21%|██        | 106/500 [00:06<00:23, 16.44it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.45it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.55it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.61it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.63it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.63it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.55it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.44it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.45it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.46it/s]Epoch:  1  	Training Loss: 0.25013217329978943
Test Loss:  5758.9658203125
Valid Loss:  5707.8740234375
Epoch:  2  	Training Loss: 5723.263671875
Test Loss:  1.724881543500923e+17
Valid Loss:  1.7333738964359578e+17
Epoch:  3  	Training Loss: 1.731532214459433e+17
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.46it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.55it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.66it/s] 26%|██▋       | 132/500 [00:07<00:21, 16.76it/s] 27%|██▋       | 134/500 [00:08<00:21, 16.69it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.60it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.27it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.24it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.36it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.31it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.31it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.47it/s] 30%|███       | 150/500 [00:09<00:21, 16.49it/s] 30%|███       | 152/500 [00:09<00:21, 16.41it/s] 31%|███       | 154/500 [00:09<00:21, 16.41it/s] 31%|███       | 156/500 [00:09<00:21, 16.29it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.37it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.46it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.56it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.66it/s] 33%|███▎      | 166/500 [00:10<00:19, 16.71it/s] 34%|███▎      | 168/500 [00:10<00:19, 16.71it/s] 34%|███▍      | 170/500 [00:10<00:19, 16.57it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.60it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.57it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.56it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.64it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.72it/s] 36%|███▋      | 182/500 [00:11<00:18, 16.75it/s] 37%|███▋      | 184/500 [00:11<00:18, 16.78it/s] 37%|███▋      | 186/500 [00:11<00:18, 16.79it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.78it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.77it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.69it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.73it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.76it/s] 40%|███▉      | 198/500 [00:11<00:18, 16.77it/s] 40%|████      | 200/500 [00:12<00:17, 16.77it/s] 40%|████      | 202/500 [00:12<00:17, 16.71it/s] 41%|████      | 204/500 [00:12<00:17, 16.72it/s] 41%|████      | 206/500 [00:12<00:17, 16.63it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.60it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.61it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.68it/s] 43%|████▎     | 214/500 [00:12<00:17, 16.74it/s] 43%|████▎     | 216/500 [00:13<00:16, 16.82it/s] 44%|████▎     | 218/500 [00:13<00:16, 16.81it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.83it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.67it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.58it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.56it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.59it/s] 46%|████▌     | 230/500 [00:13<00:16, 16.49it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.42it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.49it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.55it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.65it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.66it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.66it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.65it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.69it/s] 50%|████▉     | 248/500 [00:14<00:15, 16.55it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.47it/s] 50%|█████     | 252/500 [00:15<00:15, 16.52it/s] 51%|█████     | 254/500 [00:15<00:14, 16.47it/s] 51%|█████     | 256/500 [00:15<00:14, 16.52it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.62it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.67it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.68it/s] 53%|█████▎    | 264/500 [00:15<00:14, 16.73it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.68it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.25it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.35it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.45it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.41it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.47it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.53it/s] 56%|█████▌    | 280/500 [00:16<00:13, 16.59it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.55it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.55it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.50it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.46it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.56it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.62it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.68it/s] 59%|█████▉    | 296/500 [00:17<00:12, 16.54it/s] 60%|█████▉    | 298/500 [00:17<00:12, 16.63it/s] 60%|██████    | 300/500 [00:18<00:11, 16.71it/s] 60%|██████    | 302/500 [00:18<00:11, 16.62it/s] 61%|██████    | 304/500 [00:18<00:11, 16.62it/s] 61%|██████    | 306/500 [00:18<00:11, 16.51it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.60it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.61it/s] 62%|██████▏   | 312/500 [00:18<00:11, 16.46it/s] 63%|██████▎   | 314/500 [00:18<00:11, 16.41it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.49it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.45it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.44it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.49it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.53it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.56it/s] 66%|██████▌   | 328/500 [00:19<00:10, 16.62it/s] 66%|██████▌   | 330/500 [00:19<00:10, 16.43it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.23it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.15it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.35it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.30it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.45it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.51it/s] 69%|██████▉   | 344/500 [00:20<00:09, 16.55it/s] 69%|██████▉   | 346/500 [00:20<00:09, 16.61it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.57it/s] 70%|███████   | 350/500 [00:21<00:09, 16.53it/s] 70%|███████   | 352/500 [00:21<00:09, 16.36it/s] 71%|███████   | 354/500 [00:21<00:08, 16.39it/s] 71%|███████   | 356/500 [00:21<00:08, 16.39it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.49it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.55it/s] 72%|███████▏  | 362/500 [00:21<00:08, 16.64it/s] 73%|███████▎  | 364/500 [00:21<00:08, 16.51it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.51it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.48it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.45it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.54it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.56it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.59it/s] 76%|███████▌  | 378/500 [00:22<00:07, 16.52it/s] 76%|███████▌  | 380/500 [00:22<00:07, 16.40it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.48it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.46it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.45it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.48it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.45it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.53it/s] 79%|███████▉  | 394/500 [00:23<00:06, 16.62it/s] 79%|███████▉  | 396/500 [00:23<00:06, 16.43it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.37it/s] 80%|████████  | 400/500 [00:24<00:06, 16.36it/s] 80%|████████  | 402/500 [00:24<00:05, 16.46it/s] 81%|████████  | 404/500 [00:24<00:05, 16.49it/s] 81%|████████  | 406/500 [00:24<00:05, 16.53it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.56it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.59it/s] 82%|████████▏ | 412/500 [00:24<00:05, 16.60it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.60it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.55it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.53it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.31it/s] 84%|████████▍ | 422/500 [00:25<00:04, 15.86it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.12it/s] 85%|████████▌ | 426/500 [00:25<00:04, 16.28it/s] 86%|████████▌ | 428/500 [00:25<00:04, 16.42it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.45it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.50it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.60it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.65it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.62it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.63it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.66it/s] 89%|████████▉ | 444/500 [00:26<00:03, 16.57it/s] 89%|████████▉ | 446/500 [00:26<00:03, 16.43it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.45it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.39it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.39it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.31it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.45it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.46it/s] 92%|█████████▏| 460/500 [00:27<00:02, 16.51it/s] 92%|█████████▏| 462/500 [00:27<00:02, 16.27it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.28it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.43it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.51it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.50it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.55it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.59it/s] 95%|█████████▌| 476/500 [00:28<00:01, 16.59it/s] 96%|█████████▌| 478/500 [00:28<00:01, 16.58it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.44it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.34it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.44it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.60it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.57it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.60it/s] 98%|█████████▊| 492/500 [00:29<00:00, 16.52it/s] 99%|█████████▉| 494/500 [00:29<00:00, 16.58it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.64it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.52it/s]100%|██████████| 500/500 [00:30<00:00, 16.60it/s]100%|██████████| 500/500 [00:30<00:00, 16.53it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  7
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:10,  6.15s/it]  1%|          | 3/500 [00:06<13:39,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:27,  1.18s/it]  5%|▍         | 23/500 [00:19<06:43,  1.18it/s]  5%|▌         | 25/500 [00:19<04:49,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.64it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<09:00,  1.18s/it]  9%|▊         | 43/500 [00:33<06:26,  1.18it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:33<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:42,  1.16s/it] 11%|█         | 53/500 [00:40<06:13,  1.20it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.26it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.03it/s] 12%|█▏        | 61/500 [00:46<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:08,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:53<08:19,  1.16s/it] 15%|█▍        | 73/500 [00:53<05:57,  1.20it/s]Epoch:  1  	Training Loss: 0.25013217329978943
Test Loss:  6.192636489868164
Valid Loss:  6.312033176422119
Epoch:  2  	Training Loss: 6.274936199188232
Test Loss:  0.2831079363822937
Valid Loss:  0.261173278093338
Epoch:  3  	Training Loss: 0.27072104811668396
Test Loss:  0.2828184962272644
Valid Loss:  0.2608979344367981
Epoch:  4  	Training Loss: 0.2704401910305023
Test Loss:  0.28252941370010376
Valid Loss:  0.26062291860580444
Epoch:  5  	Training Loss: 0.27015963196754456
Test Loss:  0.28224068880081177
Valid Loss:  0.26034823060035706
Epoch:  6  	Training Loss: 0.26987946033477783
Test Loss:  0.2819523513317108
Valid Loss:  0.2600739002227783
Epoch:  7  	Training Loss: 0.2695996165275574
Test Loss:  0.2816910147666931
Valid Loss:  0.259819358587265
Epoch:  8  	Training Loss: 0.2693409323692322
Test Loss:  0.2816663384437561
Valid Loss:  0.2597910463809967
Epoch:  9  	Training Loss: 0.26931512355804443
Test Loss:  0.2816663384437561
Valid Loss:  0.2597910463809967
Epoch:  10  	Training Loss: 0.26931512355804443
Test Loss:  0.2816663086414337
Valid Loss:  0.2597910165786743
Epoch:  11  	Training Loss: 0.26931512355804443
Test Loss:  0.28166627883911133
Valid Loss:  0.25979098677635193
Epoch:  12  	Training Loss: 0.26931509375572205
Test Loss:  0.28166618943214417
Valid Loss:  0.25979092717170715
Epoch:  13  	Training Loss: 0.2693150043487549
Test Loss:  0.281666100025177
Valid Loss:  0.25979083776474
Epoch:  14  	Training Loss: 0.2693149447441101
Test Loss:  0.28166601061820984
Valid Loss:  0.2597907781600952
Epoch:  15  	Training Loss: 0.26931485533714294
Test Loss:  0.2816659212112427
Valid Loss:  0.25979068875312805
Epoch:  16  	Training Loss: 0.2693147659301758
Test Loss:  0.2816658616065979
Valid Loss:  0.2597906291484833
Epoch:  17  	Training Loss: 0.269314706325531
Test Loss:  0.28166577219963074
Valid Loss:  0.2597905397415161
Epoch:  18  	Training Loss: 0.26931461691856384
Test Loss:  0.2816656827926636
Valid Loss:  0.25979048013687134
Epoch:  19  	Training Loss: 0.2693145275115967
Test Loss:  0.2816655933856964
Valid Loss:  0.25979042053222656
Epoch:  20  	Training Loss: 0.2693144381046295
Test Loss:  0.28166550397872925
Valid Loss:  0.259790301322937
Epoch:  21  	Training Loss: 0.26931437849998474
Test Loss:  0.2816654443740845
Valid Loss:  0.25979024171829224
Epoch:  22  	Training Loss: 0.2693142890930176
Test Loss:  0.2816653251647949
Valid Loss:  0.25979018211364746
Epoch:  23  	Training Loss: 0.2693142294883728
Test Loss:  0.28166526556015015
Valid Loss:  0.2597900927066803
Epoch:  24  	Training Loss: 0.26931411027908325
Test Loss:  0.2816651463508606
Valid Loss:  0.25979000329971313
Epoch:  25  	Training Loss: 0.2693140506744385
Test Loss:  0.2816650867462158
Valid Loss:  0.25978994369506836
Epoch:  26  	Training Loss: 0.2693139910697937
Test Loss:  0.28166499733924866
Valid Loss:  0.2597898542881012
Epoch:  27  	Training Loss: 0.26931390166282654
Test Loss:  0.2816649079322815
Valid Loss:  0.2597897946834564
Epoch:  28  	Training Loss: 0.2693138122558594
Test Loss:  0.28166481852531433
Valid Loss:  0.25978970527648926
Epoch:  29  	Training Loss: 0.2693137228488922
Test Loss:  0.28166472911834717
Valid Loss:  0.2597896456718445
Epoch:  30  	Training Loss: 0.26931366324424744
Test Loss:  0.28166463971138
Valid Loss:  0.2597895562648773
Epoch:  31  	Training Loss: 0.2693135738372803
Test Loss:  0.28166458010673523
Valid Loss:  0.25978949666023254
Epoch:  32  	Training Loss: 0.2693135142326355
Test Loss:  0.28166449069976807
Valid Loss:  0.2597894072532654
Epoch:  33  	Training Loss: 0.26931342482566833
Test Loss:  0.2816644012928009
Valid Loss:  0.2597893476486206
Epoch:  34  	Training Loss: 0.26931333541870117
Test Loss:  0.28166431188583374
Valid Loss:  0.25978928804397583
Epoch:  35  	Training Loss: 0.2693132758140564
Test Loss:  0.2816642224788666
Valid Loss:  0.2597891688346863
Epoch:  36  	Training Loss: 0.2693132162094116
Test Loss:  0.2816641330718994
Valid Loss:  0.2597891092300415
Epoch:  37  	Training Loss: 0.26931309700012207
Test Loss:  0.28166401386260986
Valid Loss:  0.25978901982307434
Epoch:  38  	Training Loss: 0.2693130075931549
Test Loss:  0.2816639542579651
Valid Loss:  0.25978896021842957
Epoch:  39  	Training Loss: 0.2693129777908325
Test Loss:  0.2816638946533203
Valid Loss:  0.2597889006137848
Epoch:  40  	Training Loss: 0.26931285858154297
Test Loss:  0.28166377544403076
Valid Loss:  0.2597888112068176
Epoch:  41  	Training Loss: 0.2693127989768982
Test Loss:  0.281663715839386
Valid Loss:  0.25978875160217285
Epoch:  42  	Training Loss: 0.2693127393722534
Test Loss:  0.28166359663009644
Valid Loss:  0.2597886621952057
Epoch:  43  	Training Loss: 0.26931262016296387
Test Loss:  0.28166353702545166
Valid Loss:  0.2597886025905609
Epoch:  44  	Training Loss: 0.2693125605583191
Test Loss:  0.2816634476184845
Valid Loss:  0.25978851318359375
Epoch:  45  	Training Loss: 0.26931244134902954
Test Loss:  0.28166335821151733
Valid Loss:  0.2597884237766266
Epoch:  46  	Training Loss: 0.26931241154670715
Test Loss:  0.28166329860687256
Valid Loss:  0.2597883641719818
Epoch:  47  	Training Loss: 0.26931232213974
Test Loss:  0.281663179397583
Valid Loss:  0.25978827476501465
Epoch:  48  	Training Loss: 0.2693122625350952
Test Loss:  0.28166311979293823
Valid Loss:  0.2597882151603699
Epoch:  49  	Training Loss: 0.26931214332580566
Test Loss:  0.2816630005836487
Valid Loss:  0.2597881257534027
Epoch:  50  	Training Loss: 0.2693120837211609
Test Loss:  0.2816629111766815
Valid Loss:  0.25978806614875793
Epoch:  51  	Training Loss: 0.2693120241165161
Test Loss:  0.28166282176971436
Valid Loss:  0.25978797674179077
Epoch:  52  	Training Loss: 0.26931193470954895
Test Loss:  0.2816627621650696
Valid Loss:  0.259787917137146
Epoch:  53  	Training Loss: 0.2693118453025818
Test Loss:  0.2816626727581024
Valid Loss:  0.25978782773017883
Epoch:  54  	Training Loss: 0.269311785697937
Test Loss:  0.28166258335113525
Valid Loss:  0.25978773832321167
Epoch:  55  	Training Loss: 0.26931166648864746
Test Loss:  0.2816624939441681
Valid Loss:  0.2597876787185669
Epoch:  56  	Training Loss: 0.2693116068840027
Test Loss:  0.2816624045372009
Valid Loss:  0.2597876191139221
Epoch:  57  	Training Loss: 0.2693115472793579
Test Loss:  0.28166231513023376
Valid Loss:  0.25978749990463257
Epoch:  58  	Training Loss: 0.26931142807006836
Test Loss:  0.2816622257232666
Valid Loss:  0.2597874701023102
Epoch:  59  	Training Loss: 0.2693113684654236
Test Loss:  0.28166213631629944
Valid Loss:  0.2597874104976654
Epoch:  60  	Training Loss: 0.2693113088607788
Test Loss:  0.28166207671165466
Valid Loss:  0.25978732109069824
Epoch:  61  	Training Loss: 0.26931121945381165
Test Loss:  0.2816619873046875
Valid Loss:  0.2597872316837311
Epoch:  62  	Training Loss: 0.2693111300468445
Test Loss:  0.28166189789772034
Valid Loss:  0.2597871422767639
Epoch:  63  	Training Loss: 0.2693110704421997
Test Loss:  0.2816618084907532
Valid Loss:  0.25978708267211914
Epoch:  64  	Training Loss: 0.26931098103523254
Test Loss:  0.281661719083786
Valid Loss:  0.25978702306747437
Epoch:  65  	Training Loss: 0.2693108916282654
Test Loss:  0.28166162967681885
Valid Loss:  0.2597869038581848
Epoch:  66  	Training Loss: 0.2693108320236206
Test Loss:  0.2816615402698517
Valid Loss:  0.25978684425354004
Epoch:  67  	Training Loss: 0.26931071281433105
Test Loss:  0.2816614508628845
Valid Loss:  0.25978678464889526
Epoch:  68  	Training Loss: 0.2693106532096863
Test Loss:  0.28166139125823975
Valid Loss:  0.2597867250442505
Epoch:  69  	Training Loss: 0.2693105638027191
Test Loss:  0.2816612720489502
Valid Loss:  0.25978660583496094
Epoch:  70  	Training Loss: 0.26931050419807434
Test Loss:  0.2816612124443054
Valid Loss:  0.25978654623031616
Epoch:  71  	Training Loss: 0.2693104147911072
Test Loss:  0.28166112303733826
Valid Loss:  0.259786456823349
Epoch:  72  	Training Loss: 0.26931032538414
Test Loss:  0.2816610336303711
Valid Loss:  0.2597863972187042
Epoch:  73  	Training Loss: 0.26931026577949524
Test Loss:  0.28166094422340393
Valid Loss:  0.25978630781173706
Epoch:  74  	Training Loss: 0.2693101763725281
Test Loss:  0.28166085481643677
Valid Loss:   15%|█▌        | 75/500 [00:53<04:16,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.26it/s] 16%|█▌        | 79/500 [00:54<02:18,  3.03it/s] 16%|█▌        | 81/500 [01:00<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:00<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:00<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:07<07:52,  1.16s/it] 19%|█▊        | 93/500 [01:07<05:37,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:03,  1.67it/s] 19%|█▉        | 97/500 [01:07<02:57,  2.27it/s] 20%|█▉        | 99/500 [01:07<02:11,  3.06it/s] 20%|██        | 101/500 [01:13<07:42,  1.16s/it] 21%|██        | 103/500 [01:13<05:30,  1.20it/s] 21%|██        | 105/500 [01:14<03:57,  1.66it/s] 21%|██▏       | 107/500 [01:14<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:20<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:20<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:20<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:21<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:27<07:20,  1.16s/it] 25%|██▍       | 123/500 [01:27<05:14,  1.20it/s] 25%|██▌       | 125/500 [01:27<03:46,  1.66it/s] 25%|██▌       | 127/500 [01:27<02:45,  2.26it/s] 26%|██▌       | 129/500 [01:27<02:02,  3.04it/s] 26%|██▌       | 131/500 [01:34<07:07,  1.16s/it] 27%|██▋       | 133/500 [01:34<05:05,  1.20it/s] 27%|██▋       | 135/500 [01:34<03:39,  1.66it/s] 27%|██▋       | 137/500 [01:34<02:40,  2.27it/s] 28%|██▊       | 139/500 [01:34<01:58,  3.05it/s] 28%|██▊       | 141/500 [01:40<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:41<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:41<02:36,  2.25it/s]0.2597862482070923
Epoch:  75  	Training Loss: 0.2693101167678833
Test Loss:  0.2816607654094696
Valid Loss:  0.2597861886024475
Epoch:  76  	Training Loss: 0.26930999755859375
Test Loss:  0.28166067600250244
Valid Loss:  0.25978612899780273
Epoch:  77  	Training Loss: 0.269309937953949
Test Loss:  0.2816605865955353
Valid Loss:  0.2597860097885132
Epoch:  78  	Training Loss: 0.2693098783493042
Test Loss:  0.2816604971885681
Valid Loss:  0.2597859501838684
Epoch:  79  	Training Loss: 0.26930978894233704
Test Loss:  0.28166043758392334
Valid Loss:  0.25978589057922363
Epoch:  80  	Training Loss: 0.2693096995353699
Test Loss:  0.2816603183746338
Valid Loss:  0.25978580117225647
Epoch:  81  	Training Loss: 0.2693096399307251
Test Loss:  0.281660258769989
Valid Loss:  0.2597857117652893
Epoch:  82  	Training Loss: 0.26930955052375793
Test Loss:  0.28166016936302185
Valid Loss:  0.25978565216064453
Epoch:  83  	Training Loss: 0.26930946111679077
Test Loss:  0.2816600799560547
Valid Loss:  0.25978559255599976
Epoch:  84  	Training Loss: 0.269309401512146
Test Loss:  0.2816599905490875
Valid Loss:  0.259785532951355
Epoch:  85  	Training Loss: 0.2693093419075012
Test Loss:  0.28165990114212036
Valid Loss:  0.2597854435443878
Epoch:  86  	Training Loss: 0.26930922269821167
Test Loss:  0.2816598117351532
Valid Loss:  0.25978535413742065
Epoch:  87  	Training Loss: 0.2693091332912445
Test Loss:  0.28165972232818604
Valid Loss:  0.2597852647304535
Epoch:  88  	Training Loss: 0.2693091034889221
Test Loss:  0.28165966272354126
Valid Loss:  0.25978517532348633
Epoch:  89  	Training Loss: 0.26930901408195496
Test Loss:  0.2816595435142517
Valid Loss:  0.25978511571884155
Epoch:  90  	Training Loss: 0.2693089246749878
Test Loss:  0.28165948390960693
Valid Loss:  0.2597850561141968
Epoch:  91  	Training Loss: 0.26930883526802063
Test Loss:  0.28165939450263977
Valid Loss:  0.2597849667072296
Epoch:  92  	Training Loss: 0.26930874586105347
Test Loss:  0.2816593050956726
Valid Loss:  0.25978490710258484
Epoch:  93  	Training Loss: 0.2693086862564087
Test Loss:  0.28165921568870544
Valid Loss:  0.2597848176956177
Epoch:  94  	Training Loss: 0.26930859684944153
Test Loss:  0.2816591262817383
Valid Loss:  0.2597847580909729
Epoch:  95  	Training Loss: 0.26930853724479675
Test Loss:  0.2816590368747711
Valid Loss:  0.25978466868400574
Epoch:  96  	Training Loss: 0.2693084478378296
Test Loss:  0.28165894746780396
Valid Loss:  0.25978460907936096
Epoch:  97  	Training Loss: 0.26930832862854004
Test Loss:  0.2816588878631592
Valid Loss:  0.2597845196723938
Epoch:  98  	Training Loss: 0.26930826902389526
Test Loss:  0.28165876865386963
Valid Loss:  0.259784460067749
Epoch:  99  	Training Loss: 0.2693082094192505
Test Loss:  0.28165870904922485
Valid Loss:  0.25978437066078186
Epoch:  100  	Training Loss: 0.2693081498146057
Test Loss:  0.2816586196422577
Valid Loss:  0.2597843110561371
Epoch:  101  	Training Loss: 0.26930803060531616
Test Loss:  0.2816585302352905
Valid Loss:  0.2597842216491699
Epoch:  102  	Training Loss: 0.2693079710006714
Test Loss:  0.28165844082832336
Valid Loss:  0.25978416204452515
Epoch:  103  	Training Loss: 0.2693078815937042
Test Loss:  0.2816583514213562
Valid Loss:  0.25978410243988037
Epoch:  104  	Training Loss: 0.26930779218673706
Test Loss:  0.28165823221206665
Valid Loss:  0.2597839832305908
Epoch:  105  	Training Loss: 0.2693077325820923
Test Loss:  0.2816581726074219
Valid Loss:  0.25978392362594604
Epoch:  106  	Training Loss: 0.2693076729774475
Test Loss:  0.2816580832004547
Valid Loss:  0.25978386402130127
Epoch:  107  	Training Loss: 0.26930758357048035
Test Loss:  0.28165799379348755
Valid Loss:  0.2597837746143341
Epoch:  108  	Training Loss: 0.2693074941635132
Test Loss:  0.2816579341888428
Valid Loss:  0.25978368520736694
Epoch:  109  	Training Loss: 0.269307404756546
Test Loss:  0.2816578149795532
Valid Loss:  0.25978362560272217
Epoch:  110  	Training Loss: 0.26930731534957886
Test Loss:  0.28165775537490845
Valid Loss:  0.2597835659980774
Epoch:  111  	Training Loss: 0.2693072557449341
Test Loss:  0.2816576659679413
Valid Loss:  0.25978347659111023
Epoch:  112  	Training Loss: 0.2693071961402893
Test Loss:  0.2816575765609741
Valid Loss:  0.25978338718414307
Epoch:  113  	Training Loss: 0.26930707693099976
Test Loss:  0.28165748715400696
Valid Loss:  0.2597833275794983
Epoch:  114  	Training Loss: 0.269307017326355
Test Loss:  0.2816573977470398
Valid Loss:  0.25978323817253113
Epoch:  115  	Training Loss: 0.2693069577217102
Test Loss:  0.281657338142395
Valid Loss:  0.25978317856788635
Epoch:  116  	Training Loss: 0.26930683851242065
Test Loss:  0.28165721893310547
Valid Loss:  0.2597830891609192
Epoch:  117  	Training Loss: 0.2693067789077759
Test Loss:  0.2816571593284607
Valid Loss:  0.2597830295562744
Epoch:  118  	Training Loss: 0.2693066895008087
Test Loss:  0.28165704011917114
Valid Loss:  0.25978294014930725
Epoch:  119  	Training Loss: 0.26930662989616394
Test Loss:  0.28165698051452637
Valid Loss:  0.2597828805446625
Epoch:  120  	Training Loss: 0.2693065404891968
Test Loss:  0.2816569209098816
Valid Loss:  0.2597827911376953
Epoch:  121  	Training Loss: 0.2693064510822296
Test Loss:  0.28165680170059204
Valid Loss:  0.25978273153305054
Epoch:  122  	Training Loss: 0.26930636167526245
Test Loss:  0.2816567122936249
Valid Loss:  0.2597826421260834
Epoch:  123  	Training Loss: 0.2693063020706177
Test Loss:  0.2816566228866577
Valid Loss:  0.2597825825214386
Epoch:  124  	Training Loss: 0.2693062126636505
Test Loss:  0.28165653347969055
Valid Loss:  0.25978249311447144
Epoch:  125  	Training Loss: 0.26930615305900574
Test Loss:  0.2816564440727234
Valid Loss:  0.25978243350982666
Epoch:  126  	Training Loss: 0.2693060636520386
Test Loss:  0.2816563844680786
Valid Loss:  0.2597823441028595
Epoch:  127  	Training Loss: 0.2693059742450714
Test Loss:  0.28165626525878906
Valid Loss:  0.25978225469589233
Epoch:  128  	Training Loss: 0.26930591464042664
Test Loss:  0.2816562056541443
Valid Loss:  0.25978219509124756
Epoch:  129  	Training Loss: 0.2693058252334595
Test Loss:  0.2816561162471771
Valid Loss:  0.2597821354866028
Epoch:  130  	Training Loss: 0.2693057656288147
Test Loss:  0.28165602684020996
Valid Loss:  0.2597820460796356
Epoch:  131  	Training Loss: 0.26930567622184753
Test Loss:  0.2816559374332428
Valid Loss:  0.25978195667266846
Epoch:  132  	Training Loss: 0.26930558681488037
Test Loss:  0.28165584802627563
Valid Loss:  0.2597818970680237
Epoch:  133  	Training Loss: 0.2693055272102356
Test Loss:  0.28165578842163086
Valid Loss:  0.2597818374633789
Epoch:  134  	Training Loss: 0.26930540800094604
Test Loss:  0.2816556692123413
Valid Loss:  0.25978174805641174
Epoch:  135  	Training Loss: 0.26930534839630127
Test Loss:  0.28165560960769653
Valid Loss:  0.25978168845176697
Epoch:  136  	Training Loss: 0.2693052589893341
Test Loss:  0.28165552020072937
Valid Loss:  0.2597815990447998
Epoch:  137  	Training Loss: 0.26930516958236694
Test Loss:  0.2816554307937622
Valid Loss:  0.25978153944015503
Epoch:  138  	Training Loss: 0.26930510997772217
Test Loss:  0.28165531158447266
Valid Loss:  0.2597814202308655
Epoch:  139  	Training Loss: 0.2693050503730774
Test Loss:  0.2816552519798279
Valid Loss:  0.2597813606262207
Epoch:  140  	Training Loss: 0.26930496096611023
Test Loss:  0.2816551625728607
Valid Loss:  0.2597813010215759
Epoch:  141  	Training Loss: 0.26930487155914307
Test Loss:  0.28165507316589355
Valid Loss:  0.25978121161460876
Epoch:  142  	Training Loss: 0.2693048119544983
Test Loss:  0.2816550135612488
Valid Loss:  0.2597811222076416
Epoch:  143  	Training Loss: 0.2693047523498535
Test Loss:  0.28165489435195923
Valid Loss:  0.2597810626029968
Epoch:  144  	Training Loss: 0.26930463314056396
Test Loss:  0.28165483474731445
Valid Loss:  0.25978100299835205
Epoch:  145  	Training Loss: 0.2693045735359192
Test Loss:  0.2816547155380249
Valid Loss:  0.2597809433937073
Epoch:  146  	Training Loss: 0.26930445432662964
Test Loss:  0.2816546559333801
Valid Loss:  0.2597808241844177
Epoch:  147  	Training Loss: 0.26930442452430725
Test Loss:  0.28165456652641296
Valid Loss:  0.25978076457977295
 30%|██▉       | 149/500 [01:41<01:56,  3.02it/s] 30%|███       | 151/500 [01:47<06:47,  1.17s/it] 31%|███       | 153/500 [01:47<04:50,  1.19it/s] 31%|███       | 155/500 [01:47<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:48<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:54<06:36,  1.17s/it] 33%|███▎      | 163/500 [01:54<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:54<03:23,  1.65it/s] 33%|███▎      | 167/500 [01:54<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:01<06:20,  1.16s/it] 35%|███▍      | 173/500 [02:01<04:32,  1.20it/s] 35%|███▌      | 175/500 [02:01<03:15,  1.66it/s] 35%|███▌      | 177/500 [02:01<02:22,  2.26it/s] 36%|███▌      | 179/500 [02:01<01:45,  3.04it/s] 36%|███▌      | 181/500 [02:07<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:08<03:11,  1.65it/s] 37%|███▋      | 187/500 [02:08<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:08<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:14<06:00,  1.17s/it] 39%|███▊      | 193/500 [02:14<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:15<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:15<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:15<01:39,  3.03it/s] 40%|████      | 201/500 [02:21<05:52,  1.18s/it] 41%|████      | 203/500 [02:21<04:11,  1.18it/s] 41%|████      | 205/500 [02:21<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:21<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:28<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:28<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:28<02:53,  1.65it/s] 43%|████▎     | 217/500 [02:28<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:28<01:33,  3.02it/s]Epoch:  148  	Training Loss: 0.2693043351173401
Test Loss:  0.2816544771194458
Valid Loss:  0.2597807049751282
Epoch:  149  	Training Loss: 0.2693042457103729
Test Loss:  0.281654417514801
Valid Loss:  0.259780615568161
Epoch:  150  	Training Loss: 0.26930418610572815
Test Loss:  0.2816542983055115
Valid Loss:  0.25978055596351624
Epoch:  151  	Training Loss: 0.269304096698761
Test Loss:  0.2816542088985443
Valid Loss:  0.2597804665565491
Epoch:  152  	Training Loss: 0.2693040072917938
Test Loss:  0.28165411949157715
Valid Loss:  0.2597803771495819
Epoch:  153  	Training Loss: 0.26930391788482666
Test Loss:  0.28165403008461
Valid Loss:  0.25978031754493713
Epoch:  154  	Training Loss: 0.2693038582801819
Test Loss:  0.2816539704799652
Valid Loss:  0.25978022813796997
Epoch:  155  	Training Loss: 0.2693037688732147
Test Loss:  0.28165388107299805
Valid Loss:  0.2597801685333252
Epoch:  156  	Training Loss: 0.26930367946624756
Test Loss:  0.2816537916660309
Valid Loss:  0.2597801089286804
Epoch:  157  	Training Loss: 0.2693036198616028
Test Loss:  0.2816537022590637
Valid Loss:  0.25977998971939087
Epoch:  158  	Training Loss: 0.2693035304546356
Test Loss:  0.28165358304977417
Valid Loss:  0.2597799301147461
Epoch:  159  	Training Loss: 0.26930344104766846
Test Loss:  0.2816535234451294
Valid Loss:  0.2597798705101013
Epoch:  160  	Training Loss: 0.2693033814430237
Test Loss:  0.28165343403816223
Valid Loss:  0.25977978110313416
Epoch:  161  	Training Loss: 0.26930326223373413
Test Loss:  0.28165334463119507
Valid Loss:  0.2597797214984894
Epoch:  162  	Training Loss: 0.26930323243141174
Test Loss:  0.2816532850265503
Valid Loss:  0.2597796320915222
Epoch:  163  	Training Loss: 0.2693031430244446
Test Loss:  0.28165316581726074
Valid Loss:  0.25977957248687744
Epoch:  164  	Training Loss: 0.2693030536174774
Test Loss:  0.28165310621261597
Valid Loss:  0.2597794830799103
Epoch:  165  	Training Loss: 0.26930299401283264
Test Loss:  0.2816529870033264
Valid Loss:  0.2597793936729431
Epoch:  166  	Training Loss: 0.2693029046058655
Test Loss:  0.28165292739868164
Valid Loss:  0.25977933406829834
Epoch:  167  	Training Loss: 0.2693028151988983
Test Loss:  0.2816528081893921
Valid Loss:  0.25977927446365356
Epoch:  168  	Training Loss: 0.26930272579193115
Test Loss:  0.2816527485847473
Valid Loss:  0.2597791850566864
Epoch:  169  	Training Loss: 0.2693026661872864
Test Loss:  0.28165265917778015
Valid Loss:  0.25977909564971924
Epoch:  170  	Training Loss: 0.2693026065826416
Test Loss:  0.281652569770813
Valid Loss:  0.25977903604507446
Epoch:  171  	Training Loss: 0.26930251717567444
Test Loss:  0.2816525101661682
Valid Loss:  0.2597789764404297
Epoch:  172  	Training Loss: 0.2693024277687073
Test Loss:  0.28165239095687866
Valid Loss:  0.25977885723114014
Epoch:  173  	Training Loss: 0.2693023681640625
Test Loss:  0.2816523313522339
Valid Loss:  0.25977879762649536
Epoch:  174  	Training Loss: 0.26930227875709534
Test Loss:  0.28165221214294434
Valid Loss:  0.2597787380218506
Epoch:  175  	Training Loss: 0.2693021893501282
Test Loss:  0.28165215253829956
Valid Loss:  0.2597786784172058
Epoch:  176  	Training Loss: 0.269302099943161
Test Loss:  0.2816520631313324
Valid Loss:  0.25977858901023865
Epoch:  177  	Training Loss: 0.26930201053619385
Test Loss:  0.28165197372436523
Valid Loss:  0.2597784996032715
Epoch:  178  	Training Loss: 0.2693019509315491
Test Loss:  0.28165191411972046
Valid Loss:  0.2597784399986267
Epoch:  179  	Training Loss: 0.2693018913269043
Test Loss:  0.2816517949104309
Valid Loss:  0.25977835059165955
Epoch:  180  	Training Loss: 0.26930177211761475
Test Loss:  0.28165170550346375
Valid Loss:  0.25977829098701477
Epoch:  181  	Training Loss: 0.26930171251296997
Test Loss:  0.2816516160964966
Valid Loss:  0.2597782015800476
Epoch:  182  	Training Loss: 0.2693016529083252
Test Loss:  0.2816515564918518
Valid Loss:  0.25977811217308044
Epoch:  183  	Training Loss: 0.26930156350135803
Test Loss:  0.28165143728256226
Valid Loss:  0.25977808237075806
Epoch:  184  	Training Loss: 0.26930147409439087
Test Loss:  0.2816513776779175
Valid Loss:  0.2597779929637909
Epoch:  185  	Training Loss: 0.2693014144897461
Test Loss:  0.28165125846862793
Valid Loss:  0.25977790355682373
Epoch:  186  	Training Loss: 0.26930129528045654
Test Loss:  0.28165119886398315
Valid Loss:  0.25977784395217896
Epoch:  187  	Training Loss: 0.26930123567581177
Test Loss:  0.281651109457016
Valid Loss:  0.2597777843475342
Epoch:  188  	Training Loss: 0.269301176071167
Test Loss:  0.28165102005004883
Valid Loss:  0.259777694940567
Epoch:  189  	Training Loss: 0.26930105686187744
Test Loss:  0.28165093064308167
Valid Loss:  0.25977760553359985
Epoch:  190  	Training Loss: 0.26930099725723267
Test Loss:  0.2816508412361145
Valid Loss:  0.2597775459289551
Epoch:  191  	Training Loss: 0.2693009078502655
Test Loss:  0.2816507816314697
Valid Loss:  0.2597774565219879
Epoch:  192  	Training Loss: 0.26930081844329834
Test Loss:  0.2816506624221802
Valid Loss:  0.25977736711502075
Epoch:  193  	Training Loss: 0.26930075883865356
Test Loss:  0.2816506028175354
Valid Loss:  0.259777307510376
Epoch:  194  	Training Loss: 0.2693006992340088
Test Loss:  0.2816505432128906
Valid Loss:  0.2597772181034088
Epoch:  195  	Training Loss: 0.2693006098270416
Test Loss:  0.2816504240036011
Valid Loss:  0.2597771883010864
Epoch:  196  	Training Loss: 0.26930052042007446
Test Loss:  0.2816503345966339
Valid Loss:  0.2597770690917969
Epoch:  197  	Training Loss: 0.2693004608154297
Test Loss:  0.28165024518966675
Valid Loss:  0.2597770094871521
Epoch:  198  	Training Loss: 0.2693004012107849
Test Loss:  0.2816501259803772
Valid Loss:  0.25977692008018494
Epoch:  199  	Training Loss: 0.26930028200149536
Test Loss:  0.2816500663757324
Valid Loss:  0.2597768306732178
Epoch:  200  	Training Loss: 0.2693002223968506
Test Loss:  0.28165000677108765
Valid Loss:  0.259776771068573
Epoch:  201  	Training Loss: 0.2693001329898834
Test Loss:  0.2816498875617981
Valid Loss:  0.2597767114639282
Epoch:  202  	Training Loss: 0.26930004358291626
Test Loss:  0.2816498279571533
Valid Loss:  0.25977662205696106
Epoch:  203  	Training Loss: 0.2692999839782715
Test Loss:  0.28164973855018616
Valid Loss:  0.2597765326499939
Epoch:  204  	Training Loss: 0.26929986476898193
Test Loss:  0.2816496193408966
Valid Loss:  0.2597764730453491
Epoch:  205  	Training Loss: 0.26929980516433716
Test Loss:  0.28164955973625183
Valid Loss:  0.25977641344070435
Epoch:  206  	Training Loss: 0.2692997455596924
Test Loss:  0.28164947032928467
Valid Loss:  0.2597763240337372
Epoch:  207  	Training Loss: 0.2692996561527252
Test Loss:  0.2816493809223175
Valid Loss:  0.2597762644290924
Epoch:  208  	Training Loss: 0.26929956674575806
Test Loss:  0.28164929151535034
Valid Loss:  0.25977617502212524
Epoch:  209  	Training Loss: 0.2692994773387909
Test Loss:  0.2816492021083832
Valid Loss:  0.2597760856151581
Epoch:  210  	Training Loss: 0.2692994177341461
Test Loss:  0.281649112701416
Valid Loss:  0.2597760260105133
Epoch:  211  	Training Loss: 0.26929932832717896
Test Loss:  0.28164905309677124
Valid Loss:  0.25977593660354614
Epoch:  212  	Training Loss: 0.2692992389202118
Test Loss:  0.2816489338874817
Valid Loss:  0.25977587699890137
Epoch:  213  	Training Loss: 0.269299179315567
Test Loss:  0.2816488444805145
Valid Loss:  0.2597758173942566
Epoch:  214  	Training Loss: 0.26929908990859985
Test Loss:  0.28164878487586975
Valid Loss:  0.25977572798728943
Epoch:  215  	Training Loss: 0.2692990303039551
Test Loss:  0.2816486954689026
Valid Loss:  0.25977566838264465
Epoch:  216  	Training Loss: 0.2692989408969879
Test Loss:  0.2816486060619354
Valid Loss:  0.2597755789756775
Epoch:  217  	Training Loss: 0.26929885149002075
Test Loss:  0.28164851665496826
Valid Loss:  0.2597754895687103
Epoch:  218  	Training Loss: 0.269298791885376
Test Loss:  0.2816484570503235
Valid Loss:  0.25977542996406555
Epoch:  219  	Training Loss: 0.2692987024784088
Test Loss:  0.28164833784103394
Valid Loss:  0.2597753405570984
Epoch:  220  	Training Loss: 0.26929861307144165
Test Loss:  0.28164827823638916
Valid Loss:  0.2597752809524536
 44%|████▍     | 221/500 [02:35<05:24,  1.16s/it] 45%|████▍     | 223/500 [02:35<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:35<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:35<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:35<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:41<05:13,  1.17s/it] 47%|████▋     | 233/500 [02:42<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:42<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:42<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:42<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:48<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:48<03:34,  1.20it/s] 49%|████▉     | 245/500 [02:48<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:49<01:52,  2.26it/s] 50%|████▉     | 249/500 [02:49<01:22,  3.03it/s] 50%|█████     | 251/500 [02:55<04:51,  1.17s/it] 51%|█████     | 253/500 [02:55<03:27,  1.19it/s] 51%|█████     | 255/500 [02:55<02:28,  1.64it/s] 51%|█████▏    | 257/500 [02:55<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:55<01:19,  3.01it/s] 52%|█████▏    | 261/500 [03:02<04:35,  1.15s/it] 53%|█████▎    | 263/500 [03:02<03:16,  1.21it/s] 53%|█████▎    | 265/500 [03:02<02:20,  1.67it/s] 53%|█████▎    | 267/500 [03:02<01:42,  2.28it/s] 54%|█████▍    | 269/500 [03:02<01:15,  3.06it/s] 54%|█████▍    | 271/500 [03:08<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:09<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:09<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:09<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:09<01:12,  3.04it/s] 56%|█████▌    | 281/500 [03:15<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:15<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:15<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:16<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:16<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:22<04:01,  1.16s/it]Epoch:  221  	Training Loss: 0.2692985534667969
Test Loss:  0.2816481590270996
Valid Loss:  0.25977519154548645
Epoch:  222  	Training Loss: 0.2692984640598297
Test Loss:  0.28164809942245483
Valid Loss:  0.2597751319408417
Epoch:  223  	Training Loss: 0.26929837465286255
Test Loss:  0.28164801001548767
Valid Loss:  0.2597750425338745
Epoch:  224  	Training Loss: 0.2692983150482178
Test Loss:  0.2816479206085205
Valid Loss:  0.25977495312690735
Epoch:  225  	Training Loss: 0.2692981958389282
Test Loss:  0.28164783120155334
Valid Loss:  0.25977492332458496
Epoch:  226  	Training Loss: 0.26929813623428345
Test Loss:  0.2816477417945862
Valid Loss:  0.2597748041152954
Epoch:  227  	Training Loss: 0.26929807662963867
Test Loss:  0.281647652387619
Valid Loss:  0.25977474451065063
Epoch:  228  	Training Loss: 0.2692980170249939
Test Loss:  0.28164756298065186
Valid Loss:  0.25977465510368347
Epoch:  229  	Training Loss: 0.26929792761802673
Test Loss:  0.2816474735736847
Valid Loss:  0.2597745954990387
Epoch:  230  	Training Loss: 0.26929783821105957
Test Loss:  0.28164738416671753
Valid Loss:  0.25977450609207153
Epoch:  231  	Training Loss: 0.2692977488040924
Test Loss:  0.28164732456207275
Valid Loss:  0.25977444648742676
Epoch:  232  	Training Loss: 0.26929765939712524
Test Loss:  0.2816472053527832
Valid Loss:  0.259774386882782
Epoch:  233  	Training Loss: 0.26929759979248047
Test Loss:  0.2816471457481384
Valid Loss:  0.2597742974758148
Epoch:  234  	Training Loss: 0.2692975401878357
Test Loss:  0.28164705634117126
Valid Loss:  0.25977420806884766
Epoch:  235  	Training Loss: 0.26929742097854614
Test Loss:  0.2816469669342041
Valid Loss:  0.2597741484642029
Epoch:  236  	Training Loss: 0.269297331571579
Test Loss:  0.28164687752723694
Valid Loss:  0.2597740590572357
Epoch:  237  	Training Loss: 0.2692972719669342
Test Loss:  0.2816467881202698
Valid Loss:  0.25977399945259094
Epoch:  238  	Training Loss: 0.26929718255996704
Test Loss:  0.281646728515625
Valid Loss:  0.2597739100456238
Epoch:  239  	Training Loss: 0.26929712295532227
Test Loss:  0.28164660930633545
Valid Loss:  0.259773850440979
Epoch:  240  	Training Loss: 0.2692970335483551
Test Loss:  0.2816465497016907
Valid Loss:  0.25977376103401184
Epoch:  241  	Training Loss: 0.26929694414138794
Test Loss:  0.2816464602947235
Valid Loss:  0.2597736716270447
Epoch:  242  	Training Loss: 0.26929688453674316
Test Loss:  0.28164637088775635
Valid Loss:  0.2597736120223999
Epoch:  243  	Training Loss: 0.269296795129776
Test Loss:  0.2816462516784668
Valid Loss:  0.2597735524177551
Epoch:  244  	Training Loss: 0.26929670572280884
Test Loss:  0.281646192073822
Valid Loss:  0.25977346301078796
Epoch:  245  	Training Loss: 0.26929664611816406
Test Loss:  0.28164610266685486
Valid Loss:  0.2597734034061432
Epoch:  246  	Training Loss: 0.2692965865135193
Test Loss:  0.2816460132598877
Valid Loss:  0.259773313999176
Epoch:  247  	Training Loss: 0.26929646730422974
Test Loss:  0.2816459536552429
Valid Loss:  0.25977325439453125
Epoch:  248  	Training Loss: 0.26929640769958496
Test Loss:  0.28164583444595337
Valid Loss:  0.2597731947898865
Epoch:  249  	Training Loss: 0.2692963480949402
Test Loss:  0.2816457748413086
Valid Loss:  0.2597731053829193
Epoch:  250  	Training Loss: 0.269296258687973
Test Loss:  0.28164568543434143
Valid Loss:  0.25977301597595215
Epoch:  251  	Training Loss: 0.26929616928100586
Test Loss:  0.28164559602737427
Valid Loss:  0.2597729563713074
Epoch:  252  	Training Loss: 0.2692961096763611
Test Loss:  0.2816455066204071
Valid Loss:  0.2597728967666626
Epoch:  253  	Training Loss: 0.26929599046707153
Test Loss:  0.28164541721343994
Valid Loss:  0.25977280735969543
Epoch:  254  	Training Loss: 0.26929593086242676
Test Loss:  0.2816453278064728
Valid Loss:  0.25977271795272827
Epoch:  255  	Training Loss: 0.2692958414554596
Test Loss:  0.2816452383995056
Valid Loss:  0.2597726285457611
Epoch:  256  	Training Loss: 0.26929575204849243
Test Loss:  0.28164514899253845
Valid Loss:  0.25977256894111633
Epoch:  257  	Training Loss: 0.26929569244384766
Test Loss:  0.2816450595855713
Valid Loss:  0.25977247953414917
Epoch:  258  	Training Loss: 0.2692956328392029
Test Loss:  0.2816449999809265
Valid Loss:  0.2597724199295044
Epoch:  259  	Training Loss: 0.26929551362991333
Test Loss:  0.28164491057395935
Valid Loss:  0.25977233052253723
Epoch:  260  	Training Loss: 0.26929545402526855
Test Loss:  0.2816448211669922
Valid Loss:  0.25977227091789246
Epoch:  261  	Training Loss: 0.2692953646183014
Test Loss:  0.281644731760025
Valid Loss:  0.2597721815109253
Epoch:  262  	Training Loss: 0.26929527521133423
Test Loss:  0.28164464235305786
Valid Loss:  0.2597721219062805
Epoch:  263  	Training Loss: 0.26929521560668945
Test Loss:  0.2816445231437683
Valid Loss:  0.25977206230163574
Epoch:  264  	Training Loss: 0.2692951560020447
Test Loss:  0.28164446353912354
Valid Loss:  0.2597719430923462
Epoch:  265  	Training Loss: 0.2692950367927551
Test Loss:  0.28164437413215637
Valid Loss:  0.2597718834877014
Epoch:  266  	Training Loss: 0.26929497718811035
Test Loss:  0.2816442847251892
Valid Loss:  0.25977182388305664
Epoch:  267  	Training Loss: 0.2692949175834656
Test Loss:  0.28164422512054443
Valid Loss:  0.2597717344760895
Epoch:  268  	Training Loss: 0.2692948281764984
Test Loss:  0.2816441059112549
Valid Loss:  0.2597716748714447
Epoch:  269  	Training Loss: 0.26929473876953125
Test Loss:  0.2816440463066101
Valid Loss:  0.25977158546447754
Epoch:  270  	Training Loss: 0.2692946791648865
Test Loss:  0.28164395689964294
Valid Loss:  0.25977152585983276
Epoch:  271  	Training Loss: 0.2692945599555969
Test Loss:  0.2816438674926758
Valid Loss:  0.259771466255188
Epoch:  272  	Training Loss: 0.26929450035095215
Test Loss:  0.2816437780857086
Valid Loss:  0.2597713768482208
Epoch:  273  	Training Loss: 0.2692944407463074
Test Loss:  0.28164368867874146
Valid Loss:  0.25977128744125366
Epoch:  274  	Training Loss: 0.2692943513393402
Test Loss:  0.2816435992717743
Valid Loss:  0.2597712278366089
Epoch:  275  	Training Loss: 0.26929426193237305
Test Loss:  0.28164350986480713
Valid Loss:  0.2597711682319641
Epoch:  276  	Training Loss: 0.26929420232772827
Test Loss:  0.28164342045783997
Valid Loss:  0.25977107882499695
Epoch:  277  	Training Loss: 0.2692941129207611
Test Loss:  0.2816433310508728
Valid Loss:  0.2597709894180298
Epoch:  278  	Training Loss: 0.26929402351379395
Test Loss:  0.281643271446228
Valid Loss:  0.259770929813385
Epoch:  279  	Training Loss: 0.26929396390914917
Test Loss:  0.28164318203926086
Valid Loss:  0.25977084040641785
Epoch:  280  	Training Loss: 0.269293874502182
Test Loss:  0.2816430926322937
Valid Loss:  0.2597707509994507
Epoch:  281  	Training Loss: 0.26929378509521484
Test Loss:  0.28164297342300415
Valid Loss:  0.2597706913948059
Epoch:  282  	Training Loss: 0.26929372549057007
Test Loss:  0.2816429138183594
Valid Loss:  0.25977060198783875
Epoch:  283  	Training Loss: 0.2692936360836029
Test Loss:  0.2816428542137146
Valid Loss:  0.25977054238319397
Epoch:  284  	Training Loss: 0.26929354667663574
Test Loss:  0.28164273500442505
Valid Loss:  0.2597704529762268
Epoch:  285  	Training Loss: 0.26929348707199097
Test Loss:  0.2816426753997803
Valid Loss:  0.25977039337158203
Epoch:  286  	Training Loss: 0.2692933976650238
Test Loss:  0.2816425859928131
Valid Loss:  0.25977030396461487
Epoch:  287  	Training Loss: 0.26929330825805664
Test Loss:  0.28164249658584595
Valid Loss:  0.2597702443599701
Epoch:  288  	Training Loss: 0.26929324865341187
Test Loss:  0.2816423773765564
Valid Loss:  0.25977015495300293
Epoch:  289  	Training Loss: 0.2692931592464447
Test Loss:  0.2816423177719116
Valid Loss:  0.25977009534835815
Epoch:  290  	Training Loss: 0.2692930996417999
Test Loss:  0.28164222836494446
Valid Loss:  0.2597700357437134
Epoch:  291  	Training Loss: 0.26929301023483276
Test Loss:  0.2816421389579773
Valid Loss:  0.25976991653442383
Epoch:  292  	Training Loss: 0.269292950630188
Test Loss:  0.2816420793533325
Valid Loss:  0.25976985692977905
Epoch:  293  	Training Loss: 0.26929283142089844
Test Loss:  0.28164196014404297
Valid Loss:  0.2597697973251343 59%|█████▊    | 293/500 [03:22<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:22<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:22<01:29,  2.26it/s] 60%|█████▉    | 299/500 [03:22<01:06,  3.04it/s] 60%|██████    | 301/500 [03:29<03:52,  1.17s/it] 61%|██████    | 303/500 [03:29<02:45,  1.19it/s] 61%|██████    | 305/500 [03:29<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:29<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:29<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:35<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:36<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:36<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:36<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:36<00:59,  3.03it/s] 64%|██████▍   | 321/500 [03:42<03:28,  1.17s/it] 65%|██████▍   | 323/500 [03:42<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:42<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:43<01:16,  2.25it/s] 66%|██████▌   | 329/500 [03:43<00:56,  3.03it/s] 66%|██████▌   | 331/500 [03:49<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:49<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:49<01:40,  1.65it/s] 67%|██████▋   | 337/500 [03:49<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:50<00:53,  3.01it/s] 68%|██████▊   | 341/500 [03:56<03:05,  1.16s/it] 69%|██████▊   | 343/500 [03:56<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:56<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:56<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:56<00:50,  3.02it/s] 70%|███████   | 351/500 [04:03<02:54,  1.17s/it] 71%|███████   | 353/500 [04:03<02:03,  1.19it/s] 71%|███████   | 355/500 [04:03<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:03<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:03<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:09<02:41,  1.16s/it] 73%|███████▎  | 363/500 [04:09<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:10<01:21,  1.66it/s]
Epoch:  294  	Training Loss: 0.26929277181625366
Test Loss:  0.2816419005393982
Valid Loss:  0.2597697377204895
Epoch:  295  	Training Loss: 0.2692926526069641
Test Loss:  0.28164178133010864
Valid Loss:  0.25976961851119995
Epoch:  296  	Training Loss: 0.26929259300231934
Test Loss:  0.28164172172546387
Valid Loss:  0.2597695589065552
Epoch:  297  	Training Loss: 0.26929253339767456
Test Loss:  0.2816416323184967
Valid Loss:  0.2597694993019104
Epoch:  298  	Training Loss: 0.2692924439907074
Test Loss:  0.28164154291152954
Valid Loss:  0.2597694396972656
Epoch:  299  	Training Loss: 0.26929235458374023
Test Loss:  0.2816414535045624
Valid Loss:  0.2597693204879761
Epoch:  300  	Training Loss: 0.26929229497909546
Test Loss:  0.2816413342952728
Valid Loss:  0.2597692608833313
Epoch:  301  	Training Loss: 0.2692922055721283
Test Loss:  0.28164127469062805
Valid Loss:  0.2597692012786865
Epoch:  302  	Training Loss: 0.26929211616516113
Test Loss:  0.2816411852836609
Valid Loss:  0.25976911187171936
Epoch:  303  	Training Loss: 0.26929205656051636
Test Loss:  0.2816410958766937
Valid Loss:  0.2597690224647522
Epoch:  304  	Training Loss: 0.2692919671535492
Test Loss:  0.28164103627204895
Valid Loss:  0.2597689628601074
Epoch:  305  	Training Loss: 0.26929187774658203
Test Loss:  0.2816409468650818
Valid Loss:  0.25976890325546265
Epoch:  306  	Training Loss: 0.26929181814193726
Test Loss:  0.2816408574581146
Valid Loss:  0.2597687840461731
Epoch:  307  	Training Loss: 0.2692917287349701
Test Loss:  0.28164076805114746
Valid Loss:  0.2597687244415283
Epoch:  308  	Training Loss: 0.26929163932800293
Test Loss:  0.2816406488418579
Valid Loss:  0.25976866483688354
Epoch:  309  	Training Loss: 0.26929157972335815
Test Loss:  0.28164058923721313
Valid Loss:  0.2597685754299164
Epoch:  310  	Training Loss: 0.269291490316391
Test Loss:  0.28164049983024597
Valid Loss:  0.2597685158252716
Epoch:  311  	Training Loss: 0.26929140090942383
Test Loss:  0.2816404104232788
Valid Loss:  0.25976842641830444
Epoch:  312  	Training Loss: 0.26929134130477905
Test Loss:  0.28164035081863403
Valid Loss:  0.25976836681365967
Epoch:  313  	Training Loss: 0.2692912817001343
Test Loss:  0.2816402316093445
Valid Loss:  0.2597682774066925
Epoch:  314  	Training Loss: 0.2692911922931671
Test Loss:  0.2816401720046997
Valid Loss:  0.25976818799972534
Epoch:  315  	Training Loss: 0.26929110288619995
Test Loss:  0.28164005279541016
Valid Loss:  0.25976812839508057
Epoch:  316  	Training Loss: 0.2692910432815552
Test Loss:  0.2816399931907654
Valid Loss:  0.2597680389881134
Epoch:  317  	Training Loss: 0.269290953874588
Test Loss:  0.2816399037837982
Valid Loss:  0.25976797938346863
Epoch:  318  	Training Loss: 0.26929086446762085
Test Loss:  0.28163981437683105
Valid Loss:  0.25976788997650146
Epoch:  319  	Training Loss: 0.2692908048629761
Test Loss:  0.2816397249698639
Valid Loss:  0.2597678303718567
Epoch:  320  	Training Loss: 0.2692906856536865
Test Loss:  0.28163963556289673
Valid Loss:  0.2597677409648895
Epoch:  321  	Training Loss: 0.26929062604904175
Test Loss:  0.28163957595825195
Valid Loss:  0.25976768136024475
Epoch:  322  	Training Loss: 0.2692905366420746
Test Loss:  0.2816394567489624
Valid Loss:  0.2597675919532776
Epoch:  323  	Training Loss: 0.2692904770374298
Test Loss:  0.2816393971443176
Valid Loss:  0.2597675323486328
Epoch:  324  	Training Loss: 0.26929038763046265
Test Loss:  0.28163930773735046
Valid Loss:  0.25976744294166565
Epoch:  325  	Training Loss: 0.26929032802581787
Test Loss:  0.2816391885280609
Valid Loss:  0.2597673833370209
Epoch:  326  	Training Loss: 0.2692902386188507
Test Loss:  0.28163909912109375
Valid Loss:  0.2597672939300537
Epoch:  327  	Training Loss: 0.26929014921188354
Test Loss:  0.281639039516449
Valid Loss:  0.25976723432540894
Epoch:  328  	Training Loss: 0.26929008960723877
Test Loss:  0.2816389799118042
Valid Loss:  0.25976717472076416
Epoch:  329  	Training Loss: 0.2692899703979492
Test Loss:  0.28163886070251465
Valid Loss:  0.259767085313797
Epoch:  330  	Training Loss: 0.26928991079330444
Test Loss:  0.2816387414932251
Valid Loss:  0.25976699590682983
Epoch:  331  	Training Loss: 0.26928985118865967
Test Loss:  0.2816386818885803
Valid Loss:  0.25976693630218506
Epoch:  332  	Training Loss: 0.2692897319793701
Test Loss:  0.28163862228393555
Valid Loss:  0.2597668468952179
Epoch:  333  	Training Loss: 0.26928967237472534
Test Loss:  0.281638503074646
Valid Loss:  0.25976675748825073
Epoch:  334  	Training Loss: 0.26928961277008057
Test Loss:  0.2816384434700012
Valid Loss:  0.25976669788360596
Epoch:  335  	Training Loss: 0.2692895233631134
Test Loss:  0.28163835406303406
Valid Loss:  0.2597666382789612
Epoch:  336  	Training Loss: 0.26928943395614624
Test Loss:  0.2816382646560669
Valid Loss:  0.259766548871994
Epoch:  337  	Training Loss: 0.26928937435150146
Test Loss:  0.28163817524909973
Valid Loss:  0.25976645946502686
Epoch:  338  	Training Loss: 0.2692892849445343
Test Loss:  0.28163808584213257
Valid Loss:  0.2597663998603821
Epoch:  339  	Training Loss: 0.26928919553756714
Test Loss:  0.2816380262374878
Valid Loss:  0.2597663402557373
Epoch:  340  	Training Loss: 0.2692891061306
Test Loss:  0.28163790702819824
Valid Loss:  0.25976625084877014
Epoch:  341  	Training Loss: 0.2692890465259552
Test Loss:  0.28163784742355347
Valid Loss:  0.259766161441803
Epoch:  342  	Training Loss: 0.26928895711898804
Test Loss:  0.2816377580165863
Valid Loss:  0.2597661018371582
Epoch:  343  	Training Loss: 0.26928889751434326
Test Loss:  0.28163766860961914
Valid Loss:  0.25976601243019104
Epoch:  344  	Training Loss: 0.2692888081073761
Test Loss:  0.281637579202652
Valid Loss:  0.25976595282554626
Epoch:  345  	Training Loss: 0.26928871870040894
Test Loss:  0.2816374897956848
Valid Loss:  0.2597658634185791
Epoch:  346  	Training Loss: 0.26928865909576416
Test Loss:  0.28163740038871765
Valid Loss:  0.2597658038139343
Epoch:  347  	Training Loss: 0.2692885994911194
Test Loss:  0.2816373109817505
Valid Loss:  0.25976571440696716
Epoch:  348  	Training Loss: 0.26928848028182983
Test Loss:  0.2816372215747833
Valid Loss:  0.2597656548023224
Epoch:  349  	Training Loss: 0.26928842067718506
Test Loss:  0.28163713216781616
Valid Loss:  0.2597655653953552
Epoch:  350  	Training Loss: 0.2692883312702179
Test Loss:  0.281637042760849
Valid Loss:  0.25976550579071045
Epoch:  351  	Training Loss: 0.26928824186325073
Test Loss:  0.28163695335388184
Valid Loss:  0.2597654461860657
Epoch:  352  	Training Loss: 0.26928818225860596
Test Loss:  0.28163689374923706
Valid Loss:  0.2597653567790985
Epoch:  353  	Training Loss: 0.2692880928516388
Test Loss:  0.2816368043422699
Valid Loss:  0.25976529717445374
Epoch:  354  	Training Loss: 0.269288033246994
Test Loss:  0.28163671493530273
Valid Loss:  0.2597652077674866
Epoch:  355  	Training Loss: 0.26928794384002686
Test Loss:  0.28163662552833557
Valid Loss:  0.2597651481628418
Epoch:  356  	Training Loss: 0.2692878544330597
Test Loss:  0.2816365361213684
Valid Loss:  0.25976502895355225
Epoch:  357  	Training Loss: 0.26928776502609253
Test Loss:  0.28163647651672363
Valid Loss:  0.25976496934890747
Epoch:  358  	Training Loss: 0.26928767561912537
Test Loss:  0.2816363573074341
Valid Loss:  0.2597649097442627
Epoch:  359  	Training Loss: 0.269287645816803
Test Loss:  0.2816362679004669
Valid Loss:  0.25976482033729553
Epoch:  360  	Training Loss: 0.2692875266075134
Test Loss:  0.28163620829582214
Valid Loss:  0.25976473093032837
Epoch:  361  	Training Loss: 0.26928746700286865
Test Loss:  0.281636118888855
Valid Loss:  0.2597646713256836
Epoch:  362  	Training Loss: 0.2692873775959015
Test Loss:  0.28163599967956543
Valid Loss:  0.2597646117210388
Epoch:  363  	Training Loss: 0.2692873179912567
Test Loss:  0.28163594007492065
Valid Loss:  0.25976455211639404
Epoch:  364  	Training Loss: 0.26928722858428955
Test Loss:  0.2816358208656311
Valid Loss:  0.2597644329071045
Epoch:  365  	Training Loss: 0.2692871391773224
Test Loss:  0.28163576126098633
Valid Loss:  0.2597643733024597
Epoch:  366  	Training Loss: 0.2692870497703552
Test Loss:  0.28163570165634155
Valid Loss:   73%|███████▎  | 367/500 [04:10<00:58,  2.26it/s] 74%|███████▍  | 369/500 [04:10<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:16<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:16<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:16<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:17<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:17<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:23<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:23<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:23<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:23<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:24<00:36,  3.00it/s] 78%|███████▊  | 391/500 [04:30<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:30<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:30<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:30<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:30<00:33,  3.03it/s] 80%|████████  | 401/500 [04:36<01:54,  1.16s/it] 81%|████████  | 403/500 [04:37<01:20,  1.20it/s] 81%|████████  | 405/500 [04:37<00:57,  1.67it/s] 81%|████████▏ | 407/500 [04:37<00:40,  2.28it/s] 82%|████████▏ | 409/500 [04:37<00:29,  3.06it/s] 82%|████████▏ | 411/500 [04:43<01:42,  1.16s/it] 83%|████████▎ | 413/500 [04:43<01:12,  1.20it/s] 83%|████████▎ | 415/500 [04:43<00:51,  1.66it/s] 83%|████████▎ | 417/500 [04:44<00:36,  2.27it/s] 84%|████████▍ | 419/500 [04:44<00:26,  3.05it/s] 84%|████████▍ | 421/500 [04:50<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:50<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:50<00:45,  1.66it/s] 85%|████████▌ | 427/500 [04:50<00:32,  2.27it/s] 86%|████████▌ | 429/500 [04:50<00:23,  3.05it/s] 86%|████████▌ | 431/500 [04:57<01:19,  1.16s/it] 87%|████████▋ | 433/500 [04:57<00:55,  1.20it/s] 87%|████████▋ | 435/500 [04:57<00:39,  1.66it/s] 87%|████████▋ | 437/500 [04:57<00:27,  2.27it/s]0.25976431369781494
Epoch:  367  	Training Loss: 0.26928699016571045
Test Loss:  0.281635582447052
Valid Loss:  0.2597642242908478
Epoch:  368  	Training Loss: 0.2692868709564209
Test Loss:  0.2816355228424072
Valid Loss:  0.2597641348838806
Epoch:  369  	Training Loss: 0.2692868113517761
Test Loss:  0.2816354036331177
Valid Loss:  0.25976407527923584
Epoch:  370  	Training Loss: 0.26928675174713135
Test Loss:  0.2816353440284729
Valid Loss:  0.2597639858722687
Epoch:  371  	Training Loss: 0.2692866921424866
Test Loss:  0.28163525462150574
Valid Loss:  0.2597639262676239
Epoch:  372  	Training Loss: 0.269286572933197
Test Loss:  0.2816351652145386
Valid Loss:  0.25976383686065674
Epoch:  373  	Training Loss: 0.26928651332855225
Test Loss:  0.281635046005249
Valid Loss:  0.25976377725601196
Epoch:  374  	Training Loss: 0.2692864239215851
Test Loss:  0.28163498640060425
Valid Loss:  0.2597636878490448
Epoch:  375  	Training Loss: 0.2692863345146179
Test Loss:  0.2816348969936371
Valid Loss:  0.25976359844207764
Epoch:  376  	Training Loss: 0.26928627490997314
Test Loss:  0.2816348075866699
Valid Loss:  0.25976353883743286
Epoch:  377  	Training Loss: 0.26928621530532837
Test Loss:  0.28163471817970276
Valid Loss:  0.2597634792327881
Epoch:  378  	Training Loss: 0.2692860960960388
Test Loss:  0.2816346287727356
Valid Loss:  0.25976336002349854
Epoch:  379  	Training Loss: 0.26928603649139404
Test Loss:  0.28163453936576843
Valid Loss:  0.25976330041885376
Epoch:  380  	Training Loss: 0.26928597688674927
Test Loss:  0.28163444995880127
Valid Loss:  0.259763240814209
Epoch:  381  	Training Loss: 0.2692858874797821
Test Loss:  0.2816343903541565
Valid Loss:  0.2597631812095642
Epoch:  382  	Training Loss: 0.26928579807281494
Test Loss:  0.28163427114486694
Valid Loss:  0.25976306200027466
Epoch:  383  	Training Loss: 0.26928573846817017
Test Loss:  0.28163421154022217
Valid Loss:  0.25976303219795227
Epoch:  384  	Training Loss: 0.2692856192588806
Test Loss:  0.281634122133255
Valid Loss:  0.2597629427909851
Epoch:  385  	Training Loss: 0.26928555965423584
Test Loss:  0.28163403272628784
Valid Loss:  0.25976285338401794
Epoch:  386  	Training Loss: 0.26928550004959106
Test Loss:  0.28163397312164307
Valid Loss:  0.25976279377937317
Epoch:  387  	Training Loss: 0.2692853808403015
Test Loss:  0.2816338837146759
Valid Loss:  0.259762704372406
Epoch:  388  	Training Loss: 0.26928532123565674
Test Loss:  0.28163379430770874
Valid Loss:  0.25976264476776123
Epoch:  389  	Training Loss: 0.26928526163101196
Test Loss:  0.2816337049007416
Valid Loss:  0.25976255536079407
Epoch:  390  	Training Loss: 0.2692851424217224
Test Loss:  0.2816336154937744
Valid Loss:  0.2597624957561493
Epoch:  391  	Training Loss: 0.26928508281707764
Test Loss:  0.28163352608680725
Valid Loss:  0.25976240634918213
Epoch:  392  	Training Loss: 0.2692849934101105
Test Loss:  0.2816334366798401
Valid Loss:  0.25976234674453735
Epoch:  393  	Training Loss: 0.2692849040031433
Test Loss:  0.2816333472728729
Valid Loss:  0.2597622573375702
Epoch:  394  	Training Loss: 0.26928484439849854
Test Loss:  0.28163325786590576
Valid Loss:  0.2597621977329254
Epoch:  395  	Training Loss: 0.26928478479385376
Test Loss:  0.281633198261261
Valid Loss:  0.25976210832595825
Epoch:  396  	Training Loss: 0.2692846953868866
Test Loss:  0.28163307905197144
Valid Loss:  0.2597620487213135
Epoch:  397  	Training Loss: 0.26928460597991943
Test Loss:  0.2816329896450043
Valid Loss:  0.2597619891166687
Epoch:  398  	Training Loss: 0.26928454637527466
Test Loss:  0.2816329300403595
Valid Loss:  0.25976189970970154
Epoch:  399  	Training Loss: 0.2692844569683075
Test Loss:  0.28163284063339233
Valid Loss:  0.2597618103027344
Epoch:  400  	Training Loss: 0.26928436756134033
Test Loss:  0.2816327214241028
Valid Loss:  0.2597617506980896
Epoch:  401  	Training Loss: 0.26928430795669556
Test Loss:  0.281632661819458
Valid Loss:  0.25976166129112244
Epoch:  402  	Training Loss: 0.2692842185497284
Test Loss:  0.28163257241249084
Valid Loss:  0.2597615718841553
Epoch:  403  	Training Loss: 0.26928412914276123
Test Loss:  0.2816324830055237
Valid Loss:  0.2597615122795105
Epoch:  404  	Training Loss: 0.26928406953811646
Test Loss:  0.28163236379623413
Valid Loss:  0.2597614526748657
Epoch:  405  	Training Loss: 0.2692839801311493
Test Loss:  0.28163230419158936
Valid Loss:  0.25976136326789856
Epoch:  406  	Training Loss: 0.26928389072418213
Test Loss:  0.2816322147846222
Valid Loss:  0.2597612738609314
Epoch:  407  	Training Loss: 0.26928383111953735
Test Loss:  0.28163212537765503
Valid Loss:  0.2597612142562866
Epoch:  408  	Training Loss: 0.2692837417125702
Test Loss:  0.28163206577301025
Valid Loss:  0.25976115465164185
Epoch:  409  	Training Loss: 0.269283652305603
Test Loss:  0.2816319465637207
Valid Loss:  0.2597610354423523
Epoch:  410  	Training Loss: 0.26928356289863586
Test Loss:  0.28163185715675354
Valid Loss:  0.2597609758377075
Epoch:  411  	Training Loss: 0.2692835032939911
Test Loss:  0.28163179755210876
Valid Loss:  0.25976091623306274
Epoch:  412  	Training Loss: 0.2692834138870239
Test Loss:  0.2816317081451416
Valid Loss:  0.25976085662841797
Epoch:  413  	Training Loss: 0.26928335428237915
Test Loss:  0.28163161873817444
Valid Loss:  0.2597607374191284
Epoch:  414  	Training Loss: 0.269283264875412
Test Loss:  0.2816315293312073
Valid Loss:  0.25976067781448364
Epoch:  415  	Training Loss: 0.2692831754684448
Test Loss:  0.2816314399242401
Valid Loss:  0.25976061820983887
Epoch:  416  	Training Loss: 0.26928311586380005
Test Loss:  0.28163135051727295
Valid Loss:  0.2597605288028717
Epoch:  417  	Training Loss: 0.2692829966545105
Test Loss:  0.2816312909126282
Valid Loss:  0.25976046919822693
Epoch:  418  	Training Loss: 0.2692829668521881
Test Loss:  0.281631201505661
Valid Loss:  0.25976037979125977
Epoch:  419  	Training Loss: 0.26928287744522095
Test Loss:  0.28163111209869385
Valid Loss:  0.259760320186615
Epoch:  420  	Training Loss: 0.2692827582359314
Test Loss:  0.2816310226917267
Valid Loss:  0.2597602307796478
Epoch:  421  	Training Loss: 0.2692826986312866
Test Loss:  0.28163090348243713
Valid Loss:  0.25976014137268066
Epoch:  422  	Training Loss: 0.26928263902664185
Test Loss:  0.28163084387779236
Valid Loss:  0.2597600817680359
Epoch:  423  	Training Loss: 0.2692825198173523
Test Loss:  0.2816307544708252
Valid Loss:  0.2597600221633911
Epoch:  424  	Training Loss: 0.2692824602127075
Test Loss:  0.2816306948661804
Valid Loss:  0.25975993275642395
Epoch:  425  	Training Loss: 0.26928240060806274
Test Loss:  0.28163057565689087
Valid Loss:  0.2597598433494568
Epoch:  426  	Training Loss: 0.2692823112010956
Test Loss:  0.2816305160522461
Valid Loss:  0.259759783744812
Epoch:  427  	Training Loss: 0.2692822515964508
Test Loss:  0.28163042664527893
Valid Loss:  0.25975969433784485
Epoch:  428  	Training Loss: 0.26928216218948364
Test Loss:  0.28163033723831177
Valid Loss:  0.2597596347332001
Epoch:  429  	Training Loss: 0.2692820429801941
Test Loss:  0.2816302180290222
Valid Loss:  0.2597595453262329
Epoch:  430  	Training Loss: 0.2692820131778717
Test Loss:  0.28163015842437744
Valid Loss:  0.25975948572158813
Epoch:  431  	Training Loss: 0.26928192377090454
Test Loss:  0.2816300690174103
Valid Loss:  0.25975939631462097
Epoch:  432  	Training Loss: 0.2692818343639374
Test Loss:  0.2816299796104431
Valid Loss:  0.2597593367099762
Epoch:  433  	Training Loss: 0.2692817449569702
Test Loss:  0.28162992000579834
Valid Loss:  0.25975924730300903
Epoch:  434  	Training Loss: 0.26928168535232544
Test Loss:  0.2816298007965088
Valid Loss:  0.25975918769836426
Epoch:  435  	Training Loss: 0.26928162574768066
Test Loss:  0.281629741191864
Valid Loss:  0.2597591280937195
Epoch:  436  	Training Loss: 0.2692815065383911
Test Loss:  0.28162962198257446
Valid Loss:  0.2597590386867523
Epoch:  437  	Training Loss: 0.26928144693374634
Test Loss:  0.2816295623779297
Valid Loss:  0.25975894927978516
Epoch:  438  	Training Loss: 0.2692813575267792
Test Loss:  0.2816294729709625
Valid Loss:  0.2597588896751404
Epoch:  439  	Training Loss: 0.269281268119812
Test Loss:  0.28162938356399536
Valid Loss:   88%|████████▊ | 439/500 [04:57<00:19,  3.05it/s] 88%|████████▊ | 441/500 [05:03<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:03<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:04<00:33,  1.66it/s] 89%|████████▉ | 447/500 [05:04<00:23,  2.27it/s] 90%|████████▉ | 449/500 [05:04<00:16,  3.05it/s] 90%|█████████ | 451/500 [05:10<00:56,  1.15s/it] 91%|█████████ | 453/500 [05:10<00:38,  1.21it/s] 91%|█████████ | 455/500 [05:10<00:26,  1.67it/s] 91%|█████████▏| 457/500 [05:10<00:18,  2.28it/s] 92%|█████████▏| 459/500 [05:11<00:13,  3.04it/s] 92%|█████████▏| 461/500 [05:17<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:17<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:17<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:17<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:17<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:24<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:24<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:24<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:24<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:24<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:30<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:31<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:31<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:31<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:31<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:37<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:37<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:37<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:38<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:38<00:00,  3.02it/s]100%|██████████| 500/500 [05:38<00:00,  1.48it/s]
0.2597588002681732
Epoch:  440  	Training Loss: 0.26928120851516724
Test Loss:  0.2816292941570282
Valid Loss:  0.25975874066352844
Epoch:  441  	Training Loss: 0.2692811191082001
Test Loss:  0.28162920475006104
Valid Loss:  0.2597586512565613
Epoch:  442  	Training Loss: 0.2692810595035553
Test Loss:  0.2816290855407715
Valid Loss:  0.2597585916519165
Epoch:  443  	Training Loss: 0.26928097009658813
Test Loss:  0.2816290259361267
Valid Loss:  0.25975853204727173
Epoch:  444  	Training Loss: 0.26928088068962097
Test Loss:  0.28162896633148193
Valid Loss:  0.25975844264030457
Epoch:  445  	Training Loss: 0.2692807912826538
Test Loss:  0.2816288471221924
Valid Loss:  0.2597583532333374
Epoch:  446  	Training Loss: 0.26928073167800903
Test Loss:  0.2816287875175476
Valid Loss:  0.25975826382637024
Epoch:  447  	Training Loss: 0.26928067207336426
Test Loss:  0.28162866830825806
Valid Loss:  0.25975820422172546
Epoch:  448  	Training Loss: 0.2692805528640747
Test Loss:  0.2816286087036133
Valid Loss:  0.2597581446170807
Epoch:  449  	Training Loss: 0.26928049325942993
Test Loss:  0.2816285192966461
Valid Loss:  0.2597580552101135
Epoch:  450  	Training Loss: 0.26928043365478516
Test Loss:  0.28162842988967896
Valid Loss:  0.25975799560546875
Epoch:  451  	Training Loss: 0.2692803144454956
Test Loss:  0.2816283702850342
Valid Loss:  0.2597579061985016
Epoch:  452  	Training Loss: 0.26928025484085083
Test Loss:  0.28162825107574463
Valid Loss:  0.2597578167915344
Epoch:  453  	Training Loss: 0.26928019523620605
Test Loss:  0.28162819147109985
Valid Loss:  0.25975775718688965
Epoch:  454  	Training Loss: 0.2692800760269165
Test Loss:  0.2816280722618103
Valid Loss:  0.2597576975822449
Epoch:  455  	Training Loss: 0.26928001642227173
Test Loss:  0.2816280126571655
Valid Loss:  0.2597576081752777
Epoch:  456  	Training Loss: 0.26927995681762695
Test Loss:  0.281627893447876
Valid Loss:  0.25975751876831055
Epoch:  457  	Training Loss: 0.2692798674106598
Test Loss:  0.2816278338432312
Valid Loss:  0.25975745916366577
Epoch:  458  	Training Loss: 0.2692797780036926
Test Loss:  0.28162774443626404
Valid Loss:  0.259757399559021
Epoch:  459  	Training Loss: 0.26927971839904785
Test Loss:  0.2816276550292969
Valid Loss:  0.25975731015205383
Epoch:  460  	Training Loss: 0.2692795991897583
Test Loss:  0.2816275656223297
Valid Loss:  0.25975722074508667
Epoch:  461  	Training Loss: 0.2692795395851135
Test Loss:  0.28162747621536255
Valid Loss:  0.2597571611404419
Epoch:  462  	Training Loss: 0.26927947998046875
Test Loss:  0.2816274166107178
Valid Loss:  0.25975707173347473
Epoch:  463  	Training Loss: 0.2692793905735016
Test Loss:  0.2816273272037506
Valid Loss:  0.25975701212882996
Epoch:  464  	Training Loss: 0.2692793011665344
Test Loss:  0.28162720799446106
Valid Loss:  0.2597569227218628
Epoch:  465  	Training Loss: 0.26927924156188965
Test Loss:  0.2816271185874939
Valid Loss:  0.259756863117218
Epoch:  466  	Training Loss: 0.2692791521549225
Test Loss:  0.2816270589828491
Valid Loss:  0.25975677371025085
Epoch:  467  	Training Loss: 0.2692790627479553
Test Loss:  0.28162696957588196
Valid Loss:  0.2597567141056061
Epoch:  468  	Training Loss: 0.26927900314331055
Test Loss:  0.2816268801689148
Valid Loss:  0.2597566246986389
Epoch:  469  	Training Loss: 0.2692789137363434
Test Loss:  0.28162679076194763
Valid Loss:  0.25975656509399414
Epoch:  470  	Training Loss: 0.2692788243293762
Test Loss:  0.28162670135498047
Valid Loss:  0.25975650548934937
Epoch:  471  	Training Loss: 0.26927873492240906
Test Loss:  0.2816266417503357
Valid Loss:  0.2597563862800598
Epoch:  472  	Training Loss: 0.2692786753177643
Test Loss:  0.28162652254104614
Valid Loss:  0.2597563564777374
Epoch:  473  	Training Loss: 0.2692785859107971
Test Loss:  0.28162646293640137
Valid Loss:  0.25975626707077026
Epoch:  474  	Training Loss: 0.26927852630615234
Test Loss:  0.2816263735294342
Valid Loss:  0.2597561776638031
Epoch:  475  	Training Loss: 0.2692784368991852
Test Loss:  0.28162628412246704
Valid Loss:  0.25975608825683594
Epoch:  476  	Training Loss: 0.269278347492218
Test Loss:  0.2816261649131775
Valid Loss:  0.25975602865219116
Epoch:  477  	Training Loss: 0.26927828788757324
Test Loss:  0.2816261053085327
Valid Loss:  0.259755939245224
Epoch:  478  	Training Loss: 0.2692781686782837
Test Loss:  0.28162601590156555
Valid Loss:  0.25975584983825684
Epoch:  479  	Training Loss: 0.2692781090736389
Test Loss:  0.2816259264945984
Valid Loss:  0.25975579023361206
Epoch:  480  	Training Loss: 0.26927804946899414
Test Loss:  0.2816258668899536
Valid Loss:  0.2597557306289673
Epoch:  481  	Training Loss: 0.269277960062027
Test Loss:  0.28162574768066406
Valid Loss:  0.2597556710243225
Epoch:  482  	Training Loss: 0.2692778706550598
Test Loss:  0.2816256880760193
Valid Loss:  0.25975555181503296
Epoch:  483  	Training Loss: 0.26927781105041504
Test Loss:  0.2816255986690521
Valid Loss:  0.2597554922103882
Epoch:  484  	Training Loss: 0.2692777216434479
Test Loss:  0.28162550926208496
Valid Loss:  0.2597554326057434
Epoch:  485  	Training Loss: 0.2692776620388031
Test Loss:  0.2816254496574402
Valid Loss:  0.25975534319877625
Epoch:  486  	Training Loss: 0.26927757263183594
Test Loss:  0.28162533044815063
Valid Loss:  0.2597552537918091
Epoch:  487  	Training Loss: 0.2692774832248688
Test Loss:  0.28162527084350586
Valid Loss:  0.2597551941871643
Epoch:  488  	Training Loss: 0.269277423620224
Test Loss:  0.2816251516342163
Valid Loss:  0.25975513458251953
Epoch:  489  	Training Loss: 0.26927733421325684
Test Loss:  0.28162506222724915
Valid Loss:  0.25975504517555237
Epoch:  490  	Training Loss: 0.2692772448062897
Test Loss:  0.281624972820282
Valid Loss:  0.2597549557685852
Epoch:  491  	Training Loss: 0.2692771852016449
Test Loss:  0.2816249132156372
Valid Loss:  0.25975489616394043
Epoch:  492  	Training Loss: 0.26927709579467773
Test Loss:  0.28162479400634766
Valid Loss:  0.25975483655929565
Epoch:  493  	Training Loss: 0.26927703619003296
Test Loss:  0.2816247344017029
Valid Loss:  0.2597547173500061
Epoch:  494  	Training Loss: 0.2692769467830658
Test Loss:  0.2816246747970581
Valid Loss:  0.25975465774536133
Epoch:  495  	Training Loss: 0.26927685737609863
Test Loss:  0.28162455558776855
Valid Loss:  0.25975459814071655
Epoch:  496  	Training Loss: 0.26927679777145386
Test Loss:  0.2816244661808014
Valid Loss:  0.2597545385360718
Epoch:  497  	Training Loss: 0.2692767083644867
Test Loss:  0.28162437677383423
Valid Loss:  0.2597544491291046
Epoch:  498  	Training Loss: 0.26927661895751953
Test Loss:  0.28162431716918945
Valid Loss:  0.25975435972213745
Epoch:  499  	Training Loss: 0.26927655935287476
Test Loss:  0.2816241979598999
Valid Loss:  0.2597543001174927
Epoch:  500  	Training Loss: 0.2692764699459076
Test Loss:  0.2816241383552551
Valid Loss:  0.2597542107105255
seed is  7
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:37,  6.21s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:41,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:42,  2.97it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:37,  3.00it/s]  6%|▌         | 31/500 [00:26<09:11,  1.18s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:33,  3.01it/s]  8%|▊         | 41/500 [00:39<15:53,  2.08s/it]  9%|▊         | 43/500 [00:39<11:14,  1.48s/it]  9%|▉         | 45/500 [00:39<07:58,  1.05s/it]  9%|▉         | 47/500 [00:39<05:42,  1.32it/s] 10%|▉         | 49/500 [00:39<04:07,  1.83it/s] 10%|█         | 51/500 [00:46<09:53,  1.32s/it] 11%|█         | 53/500 [00:46<07:02,  1.06it/s] 11%|█         | 55/500 [00:46<05:03,  1.47it/s] 11%|█▏        | 57/500 [00:46<03:39,  2.02it/s] 12%|█▏        | 59/500 [00:46<02:41,  2.73it/s] 12%|█▏        | 61/500 [00:52<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:53<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:53<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:53<03:14,  2.23it/s]Epoch:  1  	Training Loss: 0.25013217329978943
Test Loss:  0.5271627306938171
Valid Loss:  0.5884592533111572
Epoch:  2  	Training Loss: 0.5688604116439819
Test Loss:  0.5383542776107788
Valid Loss:  0.47279542684555054
Epoch:  3  	Training Loss: 0.49766790866851807
Test Loss:  0.21327754855155945
Valid Loss:  0.24168628454208374
Epoch:  4  	Training Loss: 0.23285409808158875
Test Loss:  0.07139647752046585
Valid Loss:  0.06264719367027283
Epoch:  5  	Training Loss: 0.06740236282348633
Test Loss:  0.023567456752061844
Valid Loss:  0.03016316518187523
Epoch:  6  	Training Loss: 0.028875267133116722
Test Loss:  0.015013700351119041
Valid Loss:  0.016590513288974762
Epoch:  7  	Training Loss: 0.017150210216641426
Test Loss:  0.009200108237564564
Valid Loss:  0.011831492185592651
Epoch:  8  	Training Loss: 0.011745152994990349
Test Loss:  0.006615505553781986
Valid Loss:  0.008388832211494446
Epoch:  9  	Training Loss: 0.008528424426913261
Test Loss:  0.004798542708158493
Valid Loss:  0.006356198340654373
Epoch:  10  	Training Loss: 0.006429864093661308
Test Loss:  0.0036964258179068565
Valid Loss:  0.004918472841382027
Epoch:  11  	Training Loss: 0.00502221193164587
Test Loss:  0.0029916875064373016
Valid Loss:  0.003970269579440355
Epoch:  12  	Training Loss: 0.004070039838552475
Test Loss:  0.0025224629789590836
Valid Loss:  0.0032691829837858677
Epoch:  13  	Training Loss: 0.0033927476033568382
Test Loss:  0.002273851539939642
Valid Loss:  0.0028519395273178816
Epoch:  14  	Training Loss: 0.0029643657617270947
Test Loss:  0.002124001272022724
Valid Loss:  0.0025607880670577288
Epoch:  15  	Training Loss: 0.002678914461284876
Test Loss:  0.0020579108968377113
Valid Loss:  0.0023708061780780554
Epoch:  16  	Training Loss: 0.002487813588231802
Test Loss:  0.002024688757956028
Valid Loss:  0.002240542322397232
Epoch:  17  	Training Loss: 0.0023593674413859844
Test Loss:  0.0020232750102877617
Valid Loss:  0.0021538548171520233
Epoch:  18  	Training Loss: 0.0022732424549758434
Test Loss:  0.0020319493487477303
Valid Loss:  0.0020951698534190655
Epoch:  19  	Training Loss: 0.0022155409678816795
Test Loss:  0.0020502388942986727
Valid Loss:  0.0020557872485369444
Epoch:  20  	Training Loss: 0.0021768808364868164
Test Loss:  0.0020699307788163424
Valid Loss:  0.00202919146977365
Epoch:  21  	Training Loss: 0.0021509798243641853
Test Loss:  0.0020908452570438385
Valid Loss:  0.0020112565252929926
Epoch:  22  	Training Loss: 0.002133624628186226
Test Loss:  0.0020779171027243137
Valid Loss:  0.0019626948051154613
Epoch:  23  	Training Loss: 0.002082743449136615
Test Loss:  0.002074737101793289
Valid Loss:  0.001928824814967811
Epoch:  24  	Training Loss: 0.0020488700829446316
Test Loss:  0.0020794770680367947
Valid Loss:  0.0019134888425469398
Epoch:  25  	Training Loss: 0.0020333717111498117
Test Loss:  0.0020844456739723682
Valid Loss:  0.0019021545303985476
Epoch:  26  	Training Loss: 0.0020215106196701527
Test Loss:  0.0020866068080067635
Valid Loss:  0.001892965054139495
Epoch:  27  	Training Loss: 0.002011844888329506
Test Loss:  0.002087719738483429
Valid Loss:  0.001884683733806014
Epoch:  28  	Training Loss: 0.0020034010522067547
Test Loss:  0.0020871185697615147
Valid Loss:  0.001876811496913433
Epoch:  29  	Training Loss: 0.0019949455745518208
Test Loss:  0.002084629377350211
Valid Loss:  0.0018690793076530099
Epoch:  30  	Training Loss: 0.001986254006624222
Test Loss:  0.0020799969788640738
Valid Loss:  0.0018611244158819318
Epoch:  31  	Training Loss: 0.0019769356586039066
Test Loss:  0.0020736046135425568
Valid Loss:  0.0018517335411161184
Epoch:  32  	Training Loss: 0.0019672573544085026
Test Loss:  0.0020751096308231354
Valid Loss:  0.0018510736990720034
Epoch:  33  	Training Loss: 0.001966023351997137
Test Loss:  0.0021103229373693466
Valid Loss:  0.001850000349804759
Epoch:  34  	Training Loss: 0.0019670601468533278
Test Loss:  0.002078510355204344
Valid Loss:  0.0018614011351019144
Epoch:  35  	Training Loss: 0.0019745975732803345
Test Loss:  0.0022101071663200855
Valid Loss:  0.0018850539345294237
Epoch:  36  	Training Loss: 0.002006411086767912
Test Loss:  0.0021515239495784044
Valid Loss:  0.0020300811156630516
Epoch:  37  	Training Loss: 0.002134117763489485
Test Loss:  0.0030527946073561907
Valid Loss:  0.0025245426222682
Epoch:  38  	Training Loss: 0.0026603483129292727
Test Loss:  0.004296617116779089
Valid Loss:  0.004629937000572681
Epoch:  39  	Training Loss: 0.0046899765729904175
Test Loss:  0.012635916471481323
Valid Loss:  0.011514553800225258
Epoch:  40  	Training Loss: 0.011670835316181183
Test Loss:  0.03434164077043533
Valid Loss:  0.03664691001176834
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.036438364535570145
Test Loss:  0.00404663709923625
Valid Loss:  0.0038274016696959734
Epoch:  42  	Training Loss: 0.003912429790943861
Test Loss:  0.00226187938824296
Valid Loss:  0.0020085154101252556
Epoch:  43  	Training Loss: 0.0021214380394667387
Test Loss:  0.0020671766251325607
Valid Loss:  0.0018417862011119723
Epoch:  44  	Training Loss: 0.0019544067326933146
Test Loss:  0.0020314946305006742
Valid Loss:  0.00182399433106184
Epoch:  45  	Training Loss: 0.001933861756697297
Test Loss:  0.002006620867177844
Valid Loss:  0.0018109086668118834
Epoch:  46  	Training Loss: 0.0019183964468538761
Test Loss:  0.001987360417842865
Valid Loss:  0.00180183001793921
Epoch:  47  	Training Loss: 0.0019075433956459165
Test Loss:  0.001975218765437603
Valid Loss:  0.0017963886493816972
Epoch:  48  	Training Loss: 0.001900652889162302
Test Loss:  0.001967434538528323
Valid Loss:  0.0017929573077708483
Epoch:  49  	Training Loss: 0.0018963678739964962
Test Loss:  0.001962436828762293
Valid Loss:  0.0017909128218889236
Epoch:  50  	Training Loss: 0.0018937462009489536
Test Loss:  0.0019595299381762743
Valid Loss:  0.0017896568169817328
Epoch:  51  	Training Loss: 0.0018920574802905321
Test Loss:  0.001958113396540284
Valid Loss:  0.0017886109417304397
Epoch:  52  	Training Loss: 0.001890894491225481
Test Loss:  0.0019657500088214874
Valid Loss:  0.001778561738319695
Epoch:  53  	Training Loss: 0.0018820313271135092
Test Loss:  0.0019630573224276304
Valid Loss:  0.001775092096067965
Epoch:  54  	Training Loss: 0.0018783393315970898
Test Loss:  0.001966421725228429
Valid Loss:  0.001772457966580987
Epoch:  55  	Training Loss: 0.001875981455668807
Test Loss:  0.0019698594696819782
Valid Loss:  0.0017705191858112812
Epoch:  56  	Training Loss: 0.0018741792300716043
Test Loss:  0.0019730753265321255
Valid Loss:  0.0017689099768176675
Epoch:  57  	Training Loss: 0.0018725863192230463
Test Loss:  0.00197602272965014
Valid Loss:  0.001767501118592918
Epoch:  58  	Training Loss: 0.001871170592494309
Test Loss:  0.0019788697827607393
Valid Loss:  0.0017663637408986688
Epoch:  59  	Training Loss: 0.0018700589425861835
Test Loss:  0.0019815664272755384
Valid Loss:  0.0017653253162279725
Epoch:  60  	Training Loss: 0.0018690562574192882
Test Loss:  0.0019841291941702366
Valid Loss:  0.0017643463797867298
Epoch:  61  	Training Loss: 0.0018681525252759457
Test Loss:  0.001986490562558174
Valid Loss:  0.0017634732648730278
Epoch:  62  	Training Loss: 0.0018673773156479
Test Loss:  0.0019779533613473177
Valid Loss:  0.0017450969899073243
Epoch:  63  	Training Loss: 0.0018489761278033257
Test Loss:  0.0019688790198415518
Valid Loss:  0.001733108190819621
Epoch:  64  	Training Loss: 0.0018368331948295236
Test Loss:  0.001960660796612501
Valid Loss:  0.0017239103326573968
Epoch:  65  	Training Loss: 0.001826529623940587
Test Loss:  0.0019526163814589381
Valid Loss:  0.0017160680145025253
Epoch:  66  	Training Loss: 0.0018177642486989498
Test Loss:  0.0019448009552434087
Valid Loss:  0.0017087848391383886
Epoch:  67  	Training Loss: 0.0018098675645887852
Test Loss:  0.001937230583280325
Valid Loss:  0.0017015887424349785
Epoch:  68  	Training Loss: 0.0018023608718067408
Test Loss:  0.0019293095683678985
Valid Loss:  0.0016946257092058659
Epoch:  69  	Training Loss: 0.001795089920051396
Test Loss:  0.0019219513051211834
Valid Loss:   14%|█▍        | 69/500 [00:53<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:59<08:17,  1.16s/it] 15%|█▍        | 73/500 [00:59<05:55,  1.20it/s] 15%|█▌        | 75/500 [00:59<04:15,  1.66it/s] 15%|█▌        | 77/500 [01:00<03:06,  2.27it/s] 16%|█▌        | 79/500 [01:00<02:17,  3.05it/s] 16%|█▌        | 81/500 [01:06<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:06<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:06<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:06<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:06<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:13<07:57,  1.17s/it] 19%|█▊        | 93/500 [01:13<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:13<04:06,  1.65it/s] 19%|█▉        | 97/500 [01:13<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:13<02:13,  3.01it/s] 20%|██        | 101/500 [01:19<07:47,  1.17s/it] 21%|██        | 103/500 [01:20<05:33,  1.19it/s] 21%|██        | 105/500 [01:20<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:20<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:20<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:26<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:26<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:27<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:27<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:27<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:33<07:19,  1.16s/it] 25%|██▍       | 123/500 [01:33<05:13,  1.20it/s] 25%|██▌       | 125/500 [01:33<03:46,  1.66it/s] 25%|██▌       | 127/500 [01:33<02:44,  2.27it/s] 26%|██▌       | 129/500 [01:34<02:01,  3.05it/s] 26%|██▌       | 131/500 [01:40<07:08,  1.16s/it] 27%|██▋       | 133/500 [01:40<05:06,  1.20it/s] 27%|██▋       | 135/500 [01:40<03:40,  1.66it/s] 27%|██▋       | 137/500 [01:40<02:40,  2.26it/s]0.0016877002781257033
Epoch:  70  	Training Loss: 0.0017881137318909168
Test Loss:  0.0019144776742905378
Valid Loss:  0.0016813355032354593
Epoch:  71  	Training Loss: 0.0017815196188166738
Test Loss:  0.0019075837917625904
Valid Loss:  0.0016748683992773294
Epoch:  72  	Training Loss: 0.001774930744431913
Test Loss:  0.001905545825138688
Valid Loss:  0.0016736385878175497
Epoch:  73  	Training Loss: 0.0017733690328896046
Test Loss:  0.0019056446617469192
Valid Loss:  0.0016725037712603807
Epoch:  74  	Training Loss: 0.0017722677439451218
Test Loss:  0.0019064764492213726
Valid Loss:  0.0016716421814635396
Epoch:  75  	Training Loss: 0.0017715634312480688
Test Loss:  0.0019074350129812956
Valid Loss:  0.0016711554490029812
Epoch:  76  	Training Loss: 0.001771124079823494
Test Loss:  0.0019084957893937826
Valid Loss:  0.0016708786133676767
Epoch:  77  	Training Loss: 0.001770863076671958
Test Loss:  0.0019094902090728283
Valid Loss:  0.0016706970054656267
Epoch:  78  	Training Loss: 0.001770691480487585
Test Loss:  0.0019104278180748224
Valid Loss:  0.001670587109401822
Epoch:  79  	Training Loss: 0.0017706068465486169
Test Loss:  0.0019113104790449142
Valid Loss:  0.001670504454523325
Epoch:  80  	Training Loss: 0.0017705410718917847
Test Loss:  0.0019121445948258042
Valid Loss:  0.0016704360023140907
Epoch:  81  	Training Loss: 0.0017704940401017666
Test Loss:  0.0019129402935504913
Valid Loss:  0.001670381985604763
Epoch:  82  	Training Loss: 0.0017704598139971495
Test Loss:  0.0019047767855226994
Valid Loss:  0.0016567286802455783
Epoch:  83  	Training Loss: 0.0017543237190693617
Test Loss:  0.0018998925806954503
Valid Loss:  0.0016477042809128761
Epoch:  84  	Training Loss: 0.0017448142170906067
Test Loss:  0.0018920348957180977
Valid Loss:  0.0016412429977208376
Epoch:  85  	Training Loss: 0.0017369997221976519
Test Loss:  0.0018838685937225819
Valid Loss:  0.0016350047662854195
Epoch:  86  	Training Loss: 0.0017303965287283063
Test Loss:  0.0018740963423624635
Valid Loss:  0.001629080274142325
Epoch:  87  	Training Loss: 0.0017238417640328407
Test Loss:  0.001864647027105093
Valid Loss:  0.0016230267938226461
Epoch:  88  	Training Loss: 0.0017172328662127256
Test Loss:  0.0018552809488028288
Valid Loss:  0.0016169305890798569
Epoch:  89  	Training Loss: 0.0017106849700212479
Test Loss:  0.0018459780840203166
Valid Loss:  0.001611047307960689
Epoch:  90  	Training Loss: 0.00170430657453835
Test Loss:  0.0018374585779383779
Valid Loss:  0.0016055728774517775
Epoch:  91  	Training Loss: 0.001698372419923544
Test Loss:  0.0018294138135388494
Valid Loss:  0.0016002662014216185
Epoch:  92  	Training Loss: 0.0016926371026784182
Test Loss:  0.0018214824376627803
Valid Loss:  0.0015881129074841738
Epoch:  93  	Training Loss: 0.0016806544736027718
Test Loss:  0.0018156152218580246
Valid Loss:  0.0015785031719133258
Epoch:  94  	Training Loss: 0.0016713648801669478
Test Loss:  0.0018114668782800436
Valid Loss:  0.0015711546875536442
Epoch:  95  	Training Loss: 0.00166406761854887
Test Loss:  0.0018078167922794819
Valid Loss:  0.001564376289024949
Epoch:  96  	Training Loss: 0.0016571530140936375
Test Loss:  0.0018045050092041492
Valid Loss:  0.0015581082552671432
Epoch:  97  	Training Loss: 0.0016506616957485676
Test Loss:  0.00180147890932858
Valid Loss:  0.0015523380134254694
Epoch:  98  	Training Loss: 0.0016446392983198166
Test Loss:  0.0017990199849009514
Valid Loss:  0.0015470373909920454
Epoch:  99  	Training Loss: 0.0016393294790759683
Test Loss:  0.0017968977335840464
Valid Loss:  0.001541877631098032
Epoch:  100  	Training Loss: 0.0016344372415915132
Test Loss:  0.0017950270557776093
Valid Loss:  0.0015371977351605892
Epoch:  101  	Training Loss: 0.0016301549039781094
Test Loss:  0.001793127041310072
Valid Loss:  0.001532930415123701
Epoch:  102  	Training Loss: 0.0016262701246887445
Test Loss:  0.0017842843662947416
Valid Loss:  0.0015229651471599936
Epoch:  103  	Training Loss: 0.0016154702752828598
Test Loss:  0.0017731536645442247
Valid Loss:  0.0015135181602090597
Epoch:  104  	Training Loss: 0.0016050490085035563
Test Loss:  0.0017624174943193793
Valid Loss:  0.0015043095918372273
Epoch:  105  	Training Loss: 0.00159489456564188
Test Loss:  0.0017514440696686506
Valid Loss:  0.001495651202276349
Epoch:  106  	Training Loss: 0.0015853432705625892
Test Loss:  0.0017404984682798386
Valid Loss:  0.0014873099280521274
Epoch:  107  	Training Loss: 0.0015761740505695343
Test Loss:  0.001729466370306909
Valid Loss:  0.0014790595741942525
Epoch:  108  	Training Loss: 0.0015671094879508018
Test Loss:  0.0017185801407322288
Valid Loss:  0.0014712449628859758
Epoch:  109  	Training Loss: 0.001558300107717514
Test Loss:  0.001708208117634058
Valid Loss:  0.0014636586420238018
Epoch:  110  	Training Loss: 0.0015500804875046015
Test Loss:  0.001698493491858244
Valid Loss:  0.001456600846722722
Epoch:  111  	Training Loss: 0.0015425875317305326
Test Loss:  0.001689254422672093
Valid Loss:  0.0014500918332487345
Epoch:  112  	Training Loss: 0.0015355090145021677
Test Loss:  0.0016856736037880182
Valid Loss:  0.00145016610622406
Epoch:  113  	Training Loss: 0.0015353329945355654
Test Loss:  0.0016849169041961432
Valid Loss:  0.001450009411200881
Epoch:  114  	Training Loss: 0.0015351923648267984
Test Loss:  0.0016837494913488626
Valid Loss:  0.0014499167446047068
Epoch:  115  	Training Loss: 0.0015350569738075137
Test Loss:  0.001682839123532176
Valid Loss:  0.0014498131349682808
Epoch:  116  	Training Loss: 0.0015349248424172401
Test Loss:  0.0016820146702229977
Valid Loss:  0.0014497145311906934
Epoch:  117  	Training Loss: 0.0015347986482083797
Test Loss:  0.0016812939429655671
Valid Loss:  0.0014496163930743933
Epoch:  118  	Training Loss: 0.001534674083814025
Test Loss:  0.0016806477215141058
Valid Loss:  0.0014495152281597257
Epoch:  119  	Training Loss: 0.0015345545252785087
Test Loss:  0.0016800627345219254
Valid Loss:  0.0014494166243821383
Epoch:  120  	Training Loss: 0.0015344368293881416
Test Loss:  0.0016795448027551174
Valid Loss:  0.0014493169728666544
Epoch:  121  	Training Loss: 0.0015343206468969584
Test Loss:  0.0016790854278951883
Valid Loss:  0.0014492152258753777
Epoch:  122  	Training Loss: 0.0015342039987444878
Test Loss:  0.0016722255386412144
Valid Loss:  0.0014406585833057761
Epoch:  123  	Training Loss: 0.001525247935205698
Test Loss:  0.0016628862358629704
Valid Loss:  0.001433510915376246
Epoch:  124  	Training Loss: 0.00151713821105659
Test Loss:  0.0016558920033276081
Valid Loss:  0.001427077455446124
Epoch:  125  	Training Loss: 0.0015103075420483947
Test Loss:  0.0016485078958794475
Valid Loss:  0.0014212625101208687
Epoch:  126  	Training Loss: 0.001504040090367198
Test Loss:  0.0016415688442066312
Valid Loss:  0.001415756531059742
Epoch:  127  	Training Loss: 0.001498043304309249
Test Loss:  0.0016345386393368244
Valid Loss:  0.001410819822922349
Epoch:  128  	Training Loss: 0.0014927922748029232
Test Loss:  0.0016281052958220243
Valid Loss:  0.001406771712936461
Epoch:  129  	Training Loss: 0.001488458481617272
Test Loss:  0.0016222518170252442
Valid Loss:  0.0014030447928234935
Epoch:  130  	Training Loss: 0.0014847081620246172
Test Loss:  0.0016172828618437052
Valid Loss:  0.0013997950591146946
Epoch:  131  	Training Loss: 0.0014813726302236319
Test Loss:  0.001612756634131074
Valid Loss:  0.001396986423060298
Epoch:  132  	Training Loss: 0.001478117541410029
Test Loss:  0.0016102606896311045
Valid Loss:  0.0013957768678665161
Epoch:  133  	Training Loss: 0.0014770980924367905
Test Loss:  0.00160855776630342
Valid Loss:  0.0013947722036391497
Epoch:  134  	Training Loss: 0.0014763690996915102
Test Loss:  0.0016071646241471171
Valid Loss:  0.0013938683550804853
Epoch:  135  	Training Loss: 0.001475742319598794
Test Loss:  0.0016058767214417458
Valid Loss:  0.0013929763808846474
Epoch:  136  	Training Loss: 0.0014751334674656391
Test Loss:  0.0016047090757638216
Valid Loss:  0.0013921450590714812
Epoch:  137  	Training Loss: 0.0014745817752555013
Test Loss:  0.0016036491142585874
Valid Loss:  0.0013913200236856937
Epoch:  138  	Training Loss: 0.0014740347396582365
Test Loss:  0.0016026884550228715
 28%|██▊       | 139/500 [01:40<01:58,  3.04it/s] 28%|██▊       | 141/500 [01:46<06:56,  1.16s/it] 29%|██▊       | 143/500 [01:47<04:57,  1.20it/s] 29%|██▉       | 145/500 [01:47<03:33,  1.66it/s] 29%|██▉       | 147/500 [01:47<02:35,  2.27it/s] 30%|██▉       | 149/500 [01:47<01:56,  3.03it/s] 30%|███       | 151/500 [01:53<06:48,  1.17s/it] 31%|███       | 153/500 [01:53<04:51,  1.19it/s] 31%|███       | 155/500 [01:54<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:54<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:54<01:52,  3.02it/s] 32%|███▏      | 161/500 [02:00<06:34,  1.16s/it] 33%|███▎      | 163/500 [02:00<04:42,  1.19it/s] 33%|███▎      | 165/500 [02:00<03:23,  1.65it/s] 33%|███▎      | 167/500 [02:00<02:27,  2.25it/s] 34%|███▍      | 169/500 [02:01<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:07<06:24,  1.17s/it] 35%|███▍      | 173/500 [02:07<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:07<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:07<02:23,  2.24it/s] 36%|███▌      | 179/500 [02:07<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:14<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:14<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:14<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:14<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:14<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:21<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:21<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:21<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:21<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:21<01:40,  3.00it/s] 40%|████      | 201/500 [02:27<05:56,  1.19s/it] 41%|████      | 203/500 [02:28<04:14,  1.17it/s] 41%|████      | 205/500 [02:28<03:02,  1.62it/s]Valid Loss:  0.0013905547093600035
Epoch:  139  	Training Loss: 0.001473554177209735
Test Loss:  0.0016018118476495147
Valid Loss:  0.001389797660522163
Epoch:  140  	Training Loss: 0.0014730844413861632
Test Loss:  0.0016009972896426916
Valid Loss:  0.0013890484115108848
Epoch:  141  	Training Loss: 0.00147261843085289
Test Loss:  0.0016002338379621506
Valid Loss:  0.0013883060310035944
Epoch:  142  	Training Loss: 0.001472157659009099
Test Loss:  0.0015986422076821327
Valid Loss:  0.0013867360539734364
Epoch:  143  	Training Loss: 0.0014706262154504657
Test Loss:  0.0015954464906826615
Valid Loss:  0.0013855573488399386
Epoch:  144  	Training Loss: 0.0014693536795675755
Test Loss:  0.001593155786395073
Valid Loss:  0.0013844106579199433
Epoch:  145  	Training Loss: 0.001468157977797091
Test Loss:  0.001590920495800674
Valid Loss:  0.0013833411503583193
Epoch:  146  	Training Loss: 0.001466994872316718
Test Loss:  0.0015888689085841179
Valid Loss:  0.0013822810724377632
Epoch:  147  	Training Loss: 0.0014659165171906352
Test Loss:  0.0015869529452174902
Valid Loss:  0.0013813290279358625
Epoch:  148  	Training Loss: 0.00146495399530977
Test Loss:  0.0015853531658649445
Valid Loss:  0.0013804653426632285
Epoch:  149  	Training Loss: 0.0014641165034845471
Test Loss:  0.0015839342959225178
Valid Loss:  0.0013796032872051
Epoch:  150  	Training Loss: 0.0014632944948971272
Test Loss:  0.0015825489535927773
Valid Loss:  0.0013789176009595394
Epoch:  151  	Training Loss: 0.0014625126495957375
Test Loss:  0.0015812809579074383
Valid Loss:  0.0013783214380964637
Epoch:  152  	Training Loss: 0.0014618183486163616
Test Loss:  0.0015814848011359572
Valid Loss:  0.00137720862403512
Epoch:  153  	Training Loss: 0.0014605872565880418
Test Loss:  0.0015811632620170712
Valid Loss:  0.0013761511072516441
Epoch:  154  	Training Loss: 0.0014595143729820848
Test Loss:  0.0015805440489202738
Valid Loss:  0.001375327236019075
Epoch:  155  	Training Loss: 0.001458819955587387
Test Loss:  0.0015799419488757849
Valid Loss:  0.001374997547827661
Epoch:  156  	Training Loss: 0.0014583449810743332
Test Loss:  0.001579466974362731
Valid Loss:  0.0013746640179306269
Epoch:  157  	Training Loss: 0.0014579116832464933
Test Loss:  0.0015788559103384614
Valid Loss:  0.0013744556345045567
Epoch:  158  	Training Loss: 0.0014576846733689308
Test Loss:  0.0015784235438331962
Valid Loss:  0.0013742337469011545
Epoch:  159  	Training Loss: 0.0014575100503861904
Test Loss:  0.0015778739470988512
Valid Loss:  0.0013741394504904747
Epoch:  160  	Training Loss: 0.0014574418310075998
Test Loss:  0.0015775279607623816
Valid Loss:  0.001374032231979072
Epoch:  161  	Training Loss: 0.0014573759399354458
Test Loss:  0.0015772716142237186
Valid Loss:  0.0013739168643951416
Epoch:  162  	Training Loss: 0.00145731121301651
Test Loss:  0.0015759055968374014
Valid Loss:  0.0013726591132581234
Epoch:  163  	Training Loss: 0.0014558791881427169
Test Loss:  0.0015756667125970125
Valid Loss:  0.0013715490931645036
Epoch:  164  	Training Loss: 0.0014547444880008698
Test Loss:  0.0015752522740513086
Valid Loss:  0.0013706493191421032
Epoch:  165  	Training Loss: 0.0014537733513861895
Test Loss:  0.001574695692397654
Valid Loss:  0.0013698746915906668
Epoch:  166  	Training Loss: 0.0014528585597872734
Test Loss:  0.0015741281677037477
Valid Loss:  0.0013692231150344014
Epoch:  167  	Training Loss: 0.001452121650800109
Test Loss:  0.0015734926564618945
Valid Loss:  0.0013686431339010596
Epoch:  168  	Training Loss: 0.001451528980396688
Test Loss:  0.001572795445099473
Valid Loss:  0.001368099357932806
Epoch:  169  	Training Loss: 0.0014509630855172873
Test Loss:  0.0015721344389021397
Valid Loss:  0.001367576653137803
Epoch:  170  	Training Loss: 0.0014504622668027878
Test Loss:  0.0015714324545115232
Valid Loss:  0.0013670638436451554
Epoch:  171  	Training Loss: 0.0014499732060357928
Test Loss:  0.0015707853017374873
Valid Loss:  0.001366566983051598
Epoch:  172  	Training Loss: 0.0014495204668492079
Test Loss:  0.001570333493873477
Valid Loss:  0.0013655361253768206
Epoch:  173  	Training Loss: 0.0014486636500805616
Test Loss:  0.0015695872716605663
Valid Loss:  0.0013646450825035572
Epoch:  174  	Training Loss: 0.0014478948432952166
Test Loss:  0.0015688223065808415
Valid Loss:  0.001363788964226842
Epoch:  175  	Training Loss: 0.0014471891336143017
Test Loss:  0.0015680983196943998
Valid Loss:  0.0013630097964778543
Epoch:  176  	Training Loss: 0.0014465549029409885
Test Loss:  0.0015674184542149305
Valid Loss:  0.001362263923510909
Epoch:  177  	Training Loss: 0.0014459590893238783
Test Loss:  0.001566772349178791
Valid Loss:  0.0013615592615678906
Epoch:  178  	Training Loss: 0.0014454040210694075
Test Loss:  0.0015661780489608645
Valid Loss:  0.0013608764857053757
Epoch:  179  	Training Loss: 0.0014448774745687842
Test Loss:  0.001565604005008936
Valid Loss:  0.0013602162944152951
Epoch:  180  	Training Loss: 0.001444371184334159
Test Loss:  0.0015650687273591757
Valid Loss:  0.001359586021862924
Epoch:  181  	Training Loss: 0.0014438980724662542
Test Loss:  0.0015647202963009477
Valid Loss:  0.0013589694863185287
Epoch:  182  	Training Loss: 0.0014434533659368753
Test Loss:  0.001562983845360577
Valid Loss:  0.0013577284989878535
Epoch:  183  	Training Loss: 0.0014424842083826661
Test Loss:  0.0015618822071701288
Valid Loss:  0.0013565978733822703
Epoch:  184  	Training Loss: 0.0014416677877306938
Test Loss:  0.0015610047848895192
Valid Loss:  0.0013557156780734658
Epoch:  185  	Training Loss: 0.0014410385629162192
Test Loss:  0.0015603142092004418
Valid Loss:  0.0013550142757594585
Epoch:  186  	Training Loss: 0.0014405704569071531
Test Loss:  0.0015597282908856869
Valid Loss:  0.0013543753884732723
Epoch:  187  	Training Loss: 0.0014401255175471306
Test Loss:  0.001559188007377088
Valid Loss:  0.0013537872582674026
Epoch:  188  	Training Loss: 0.0014397018821910024
Test Loss:  0.0015587154775857925
Valid Loss:  0.001353339059278369
Epoch:  189  	Training Loss: 0.00143931875936687
Test Loss:  0.0015583073254674673
Valid Loss:  0.0013529215939342976
Epoch:  190  	Training Loss: 0.001438973587937653
Test Loss:  0.001557933515869081
Valid Loss:  0.0013525285758078098
Epoch:  191  	Training Loss: 0.0014386307448148727
Test Loss:  0.0015576181467622519
Valid Loss:  0.0013521730434149504
Epoch:  192  	Training Loss: 0.0014383322559297085
Test Loss:  0.0015543923946097493
Valid Loss:  0.001344906399026513
Epoch:  193  	Training Loss: 0.001425823662430048
Test Loss:  0.0015561787877231836
Valid Loss:  0.0013405162608250976
Epoch:  194  	Training Loss: 0.0014197856653481722
Test Loss:  0.001558688236400485
Valid Loss:  0.0013377515133470297
Epoch:  195  	Training Loss: 0.0014169288333505392
Test Loss:  0.0015598747413605452
Valid Loss:  0.0013358539436012506
Epoch:  196  	Training Loss: 0.0014149644412100315
Test Loss:  0.0015598528552800417
Valid Loss:  0.0013346077175810933
Epoch:  197  	Training Loss: 0.0014136170502752066
Test Loss:  0.0015589026734232903
Valid Loss:  0.001333751017227769
Epoch:  198  	Training Loss: 0.0014124775771051645
Test Loss:  0.0015575983561575413
Valid Loss:  0.0013331440277397633
Epoch:  199  	Training Loss: 0.001411384902894497
Test Loss:  0.0015559839084744453
Valid Loss:  0.0013326770858839154
Epoch:  200  	Training Loss: 0.0014106167946010828
Test Loss:  0.0015539689920842648
Valid Loss:  0.0013323172461241484
Epoch:  201  	Training Loss: 0.001410051598213613
Test Loss:  0.0015515389386564493
Valid Loss:  0.0013318625278770924
Epoch:  202  	Training Loss: 0.0014096086379140615
Test Loss:  0.001549456501379609
Valid Loss:  0.001330775674432516
Epoch:  203  	Training Loss: 0.0014089742908254266
Test Loss:  0.0015431300271302462
Valid Loss:  0.0013304408639669418
Epoch:  204  	Training Loss: 0.0014085047878324986
Test Loss:  0.0015402525896206498
Valid Loss:  0.0013299175770953298
Epoch:  205  	Training Loss: 0.0014081543777137995
Test Loss:  0.001536650350317359
Valid Loss:  0.0013296075630933046
Epoch:  206  	Training Loss: 0.0014078706735745072
Test Loss:  0.0015342524275183678
Valid Loss:  0.0013292584335431457
Epoch:  207  	Training Loss: 0.0014076337683945894 41%|████▏     | 207/500 [02:28<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:28<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:34<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:34<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:35<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:35<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:35<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:41<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:41<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:41<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:42<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:42<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:48<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:48<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:48<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:48<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:48<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:55<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:55<03:34,  1.20it/s] 49%|████▉     | 245/500 [02:55<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:55<01:52,  2.26it/s] 50%|████▉     | 249/500 [02:55<01:22,  3.03it/s] 50%|█████     | 251/500 [03:01<04:47,  1.16s/it] 51%|█████     | 253/500 [03:02<03:24,  1.21it/s] 51%|█████     | 255/500 [03:02<02:27,  1.67it/s] 51%|█████▏    | 257/500 [03:02<01:46,  2.28it/s] 52%|█████▏    | 259/500 [03:02<01:18,  3.06it/s] 52%|█████▏    | 261/500 [03:08<04:38,  1.16s/it] 53%|█████▎    | 263/500 [03:08<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:08<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:09<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:09<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:15<04:24,  1.16s/it] 55%|█████▍    | 273/500 [03:15<03:08,  1.21it/s] 55%|█████▌    | 275/500 [03:15<02:15,  1.67it/s]
Test Loss:  0.0015319254016503692
Valid Loss:  0.0013289760099723935
Epoch:  208  	Training Loss: 0.001407428877428174
Test Loss:  0.0015301341190934181
Valid Loss:  0.0013286956818774343
Epoch:  209  	Training Loss: 0.0014072476187720895
Test Loss:  0.0015285428380593657
Valid Loss:  0.001328436192125082
Epoch:  210  	Training Loss: 0.0014070819597691298
Test Loss:  0.001527239102870226
Valid Loss:  0.0013281800784170628
Epoch:  211  	Training Loss: 0.0014069253811612725
Test Loss:  0.001526111038401723
Valid Loss:  0.001327931648120284
Epoch:  212  	Training Loss: 0.0014067778829485178
Test Loss:  0.001525877509266138
Valid Loss:  0.0013266282621771097
Epoch:  213  	Training Loss: 0.0014053520280867815
Test Loss:  0.001526008127257228
Valid Loss:  0.0013255465310066938
Epoch:  214  	Training Loss: 0.001404282171279192
Test Loss:  0.001526090083643794
Valid Loss:  0.0013247167225927114
Epoch:  215  	Training Loss: 0.0014035069616511464
Test Loss:  0.0015260317595675588
Valid Loss:  0.0013239578111097217
Epoch:  216  	Training Loss: 0.0014028180157765746
Test Loss:  0.0015258886851370335
Valid Loss:  0.001323354197666049
Epoch:  217  	Training Loss: 0.0014022048562765121
Test Loss:  0.0015257411869242787
Valid Loss:  0.00132289610337466
Epoch:  218  	Training Loss: 0.001401698449626565
Test Loss:  0.001525533851236105
Valid Loss:  0.0013224309077486396
Epoch:  219  	Training Loss: 0.0014013077598065138
Test Loss:  0.0015252307057380676
Valid Loss:  0.0013220250839367509
Epoch:  220  	Training Loss: 0.0014009771402925253
Test Loss:  0.0015249352436512709
Valid Loss:  0.001321673858910799
Epoch:  221  	Training Loss: 0.0014006978599354625
Test Loss:  0.0015246500261127949
Valid Loss:  0.0013213944621384144
Epoch:  222  	Training Loss: 0.001400453387759626
Test Loss:  0.0015184092335402966
Valid Loss:  0.00131368322763592
Epoch:  223  	Training Loss: 0.001390778343193233
Test Loss:  0.0015154890716075897
Valid Loss:  0.0013069796841591597
Epoch:  224  	Training Loss: 0.0013830410316586494
Test Loss:  0.0015089239459484816
Valid Loss:  0.001302002347074449
Epoch:  225  	Training Loss: 0.0013772917445749044
Test Loss:  0.0015071600209921598
Valid Loss:  0.001297604525461793
Epoch:  226  	Training Loss: 0.0013730183709412813
Test Loss:  0.0015004448359832168
Valid Loss:  0.0012941958848387003
Epoch:  227  	Training Loss: 0.001369217410683632
Test Loss:  0.0014995194505900145
Valid Loss:  0.0012904974864795804
Epoch:  228  	Training Loss: 0.0013656727969646454
Test Loss:  0.00149272452108562
Valid Loss:  0.0012880442664027214
Epoch:  229  	Training Loss: 0.0013626744039356709
Test Loss:  0.0014923973940312862
Valid Loss:  0.001285045174881816
Epoch:  230  	Training Loss: 0.001359818154014647
Test Loss:  0.0014857029309496284
Valid Loss:  0.0012834416702389717
Epoch:  231  	Training Loss: 0.001357473200187087
Test Loss:  0.0014868408907204866
Valid Loss:  0.0012810132466256618
Epoch:  232  	Training Loss: 0.0013553311582654715
Test Loss:  0.001481890445575118
Valid Loss:  0.00127948890440166
Epoch:  233  	Training Loss: 0.0013531139120459557
Test Loss:  0.0014826523838564754
Valid Loss:  0.0012772122863680124
Epoch:  234  	Training Loss: 0.001351059414446354
Test Loss:  0.0014792419970035553
Valid Loss:  0.0012757552322000265
Epoch:  235  	Training Loss: 0.001349086407572031
Test Loss:  0.0014785442035645247
Valid Loss:  0.0012739157536998391
Epoch:  236  	Training Loss: 0.0013471462298184633
Test Loss:  0.0014759685145691037
Valid Loss:  0.0012724539265036583
Epoch:  237  	Training Loss: 0.0013453123392537236
Test Loss:  0.0014743771171197295
Valid Loss:  0.0012707847636193037
Epoch:  238  	Training Loss: 0.0013435670407488942
Test Loss:  0.0014718385646119714
Valid Loss:  0.001269279746338725
Epoch:  239  	Training Loss: 0.0013418733142316341
Test Loss:  0.0014699345920234919
Valid Loss:  0.0012676980113610625
Epoch:  240  	Training Loss: 0.0013401965843513608
Test Loss:  0.0014677325962111354
Valid Loss:  0.0012661789078265429
Epoch:  241  	Training Loss: 0.001338543719612062
Test Loss:  0.0014657825231552124
Valid Loss:  0.0012646435061469674
Epoch:  242  	Training Loss: 0.0013369069201871753
Test Loss:  0.0014630577061325312
Valid Loss:  0.0012634306913241744
Epoch:  243  	Training Loss: 0.00133563915733248
Test Loss:  0.0014607803896069527
Valid Loss:  0.0012622401118278503
Epoch:  244  	Training Loss: 0.001334433676674962
Test Loss:  0.001458815997466445
Valid Loss:  0.0012611767742782831
Epoch:  245  	Training Loss: 0.001333428081125021
Test Loss:  0.0014570305356755853
Valid Loss:  0.0012601283378899097
Epoch:  246  	Training Loss: 0.0013324498431757092
Test Loss:  0.0014554241206496954
Valid Loss:  0.0012591469567269087
Epoch:  247  	Training Loss: 0.0013315703254193068
Test Loss:  0.0014539484400302172
Valid Loss:  0.0012581825722008944
Epoch:  248  	Training Loss: 0.0013307395856827497
Test Loss:  0.0014526911545544863
Valid Loss:  0.0012572731357067823
Epoch:  249  	Training Loss: 0.0013299959246069193
Test Loss:  0.0014517062809318304
Valid Loss:  0.0012565189972519875
Epoch:  250  	Training Loss: 0.0013294618111103773
Test Loss:  0.001450857613235712
Valid Loss:  0.0012558132875710726
Epoch:  251  	Training Loss: 0.001329005346633494
Test Loss:  0.001450125128030777
Valid Loss:  0.0012551615945994854
Epoch:  252  	Training Loss: 0.0013286089524626732
Test Loss:  0.0014499931130558252
Valid Loss:  0.00125408754684031
Epoch:  253  	Training Loss: 0.0013274491066113114
Test Loss:  0.0014509002212435007
Valid Loss:  0.00125298579223454
Epoch:  254  	Training Loss: 0.0013264644658192992
Test Loss:  0.0014506590086966753
Valid Loss:  0.0012520949821919203
Epoch:  255  	Training Loss: 0.0013257433893159032
Test Loss:  0.001450350508093834
Valid Loss:  0.0012512409593909979
Epoch:  256  	Training Loss: 0.0013250879710540175
Test Loss:  0.0014496998628601432
Valid Loss:  0.0012504938058555126
Epoch:  257  	Training Loss: 0.0013244972797110677
Test Loss:  0.0014490950852632523
Valid Loss:  0.0012497864663600922
Epoch:  258  	Training Loss: 0.0013239769032225013
Test Loss:  0.0014482265105471015
Valid Loss:  0.0012491720262914896
Epoch:  259  	Training Loss: 0.001323480624705553
Test Loss:  0.0014475377975031734
Valid Loss:  0.001248607411980629
Epoch:  260  	Training Loss: 0.0013230233453214169
Test Loss:  0.001446767128072679
Valid Loss:  0.0012480514124035835
Epoch:  261  	Training Loss: 0.0013226049486547709
Test Loss:  0.0014459668891504407
Valid Loss:  0.0012475275434553623
Epoch:  262  	Training Loss: 0.0013222189154475927
Test Loss:  0.0014454610645771027
Valid Loss:  0.0012469030916690826
Epoch:  263  	Training Loss: 0.0013217845698818564
Test Loss:  0.0014448449946939945
Valid Loss:  0.001246283994987607
Epoch:  264  	Training Loss: 0.0013213740894570947
Test Loss:  0.0014442065730690956
Valid Loss:  0.0012456958647817373
Epoch:  265  	Training Loss: 0.0013209893368184566
Test Loss:  0.001443605637177825
Valid Loss:  0.0012450977228581905
Epoch:  266  	Training Loss: 0.0013206176226958632
Test Loss:  0.0014429488219320774
Valid Loss:  0.0012445070315152407
Epoch:  267  	Training Loss: 0.001320267328992486
Test Loss:  0.001442338339984417
Valid Loss:  0.0012439735000953078
Epoch:  268  	Training Loss: 0.0013199583627283573
Test Loss:  0.0014417758211493492
Valid Loss:  0.0012435370590537786
Epoch:  269  	Training Loss: 0.001319690141826868
Test Loss:  0.0014412213349714875
Valid Loss:  0.0012431270442903042
Epoch:  270  	Training Loss: 0.0013194382190704346
Test Loss:  0.0014407148119062185
Valid Loss:  0.0012427427573129535
Epoch:  271  	Training Loss: 0.0013192121405154467
Test Loss:  0.0014402359956875443
Valid Loss:  0.0012424001470208168
Epoch:  272  	Training Loss: 0.0013190065510571003
Test Loss:  0.0014359171036630869
Valid Loss:  0.0012353186029940844
Epoch:  273  	Training Loss: 0.0013070733984932303
Test Loss:  0.0014373300364241004
Valid Loss:  0.0012285782722756267
Epoch:  274  	Training Loss: 0.0012982075568288565
Test Loss:  0.0014320301124826074
Valid Loss:  0.001224201638251543
Epoch:  275  	Training Loss: 0.0012926666531711817
Test Loss:  0.0014299913309514523
Valid Loss:  0.0012197993928566575
 55%|█████▌    | 277/500 [03:15<01:38,  2.27it/s] 56%|█████▌    | 279/500 [03:15<01:12,  3.06it/s] 56%|█████▌    | 281/500 [03:22<04:13,  1.16s/it] 57%|█████▋    | 283/500 [03:22<03:00,  1.20it/s] 57%|█████▋    | 285/500 [03:22<02:09,  1.66it/s] 57%|█████▋    | 287/500 [03:22<01:33,  2.27it/s] 58%|█████▊    | 289/500 [03:22<01:08,  3.06it/s] 58%|█████▊    | 291/500 [03:28<04:01,  1.16s/it] 59%|█████▊    | 293/500 [03:28<02:51,  1.20it/s] 59%|█████▉    | 295/500 [03:29<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:29<01:29,  2.27it/s] 60%|█████▉    | 299/500 [03:29<01:05,  3.05it/s] 60%|██████    | 301/500 [03:35<03:51,  1.17s/it] 61%|██████    | 303/500 [03:35<02:45,  1.19it/s] 61%|██████    | 305/500 [03:35<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:35<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:36<01:02,  3.03it/s] 62%|██████▏   | 311/500 [03:42<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:42<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:42<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:42<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:42<01:00,  3.00it/s] 64%|██████▍   | 321/500 [03:49<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:49<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:49<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:49<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:49<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:56<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:56<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:56<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:56<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:56<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:02<03:08,  1.18s/it] 69%|██████▊   | 343/500 [04:03<02:13,  1.18it/s]Epoch:  276  	Training Loss: 0.0012880866415798664
Test Loss:  0.001425263937562704
Valid Loss:  0.0012160588521510363
Epoch:  277  	Training Loss: 0.0012840721756219864
Test Loss:  0.0014224509941413999
Valid Loss:  0.0012127438094466925
Epoch:  278  	Training Loss: 0.0012808011379092932
Test Loss:  0.0014184736646711826
Valid Loss:  0.0012101620668545365
Epoch:  279  	Training Loss: 0.00127800100017339
Test Loss:  0.0014146029716357589
Valid Loss:  0.0012076770653948188
Epoch:  280  	Training Loss: 0.001275399001315236
Test Loss:  0.0014107669703662395
Valid Loss:  0.0012056471314281225
Epoch:  281  	Training Loss: 0.0012729230802506208
Test Loss:  0.0014074271311983466
Valid Loss:  0.0012037049746140838
Epoch:  282  	Training Loss: 0.001270583481527865
Test Loss:  0.0014064264250919223
Valid Loss:  0.0012029886711388826
Epoch:  283  	Training Loss: 0.0012693251483142376
Test Loss:  0.001404695911332965
Valid Loss:  0.0012024687603116035
Epoch:  284  	Training Loss: 0.0012684192042797804
Test Loss:  0.0014027967117726803
Valid Loss:  0.0012021174188703299
Epoch:  285  	Training Loss: 0.0012676655314862728
Test Loss:  0.0014007961144670844
Valid Loss:  0.0012018438428640366
Epoch:  286  	Training Loss: 0.0012671174481511116
Test Loss:  0.0013985966797918081
Valid Loss:  0.0012014860985800624
Epoch:  287  	Training Loss: 0.0012666898546740413
Test Loss:  0.0013962298398837447
Valid Loss:  0.0012012493098154664
Epoch:  288  	Training Loss: 0.0012662984663620591
Test Loss:  0.0013942497316747904
Valid Loss:  0.0012010072823613882
Epoch:  289  	Training Loss: 0.0012659254716709256
Test Loss:  0.001392432488501072
Valid Loss:  0.0012007963377982378
Epoch:  290  	Training Loss: 0.0012655805330723524
Test Loss:  0.001390789169818163
Valid Loss:  0.0012006200850009918
Epoch:  291  	Training Loss: 0.0012652750592678785
Test Loss:  0.001389155164361
Valid Loss:  0.0012003853917121887
Epoch:  292  	Training Loss: 0.0012650331482291222
Test Loss:  0.0013849770184606314
Valid Loss:  0.0011960428673774004
Epoch:  293  	Training Loss: 0.0012610285775735974
Test Loss:  0.0013804321642965078
Valid Loss:  0.0011922754347324371
Epoch:  294  	Training Loss: 0.0012576042208820581
Test Loss:  0.0013765967451035976
Valid Loss:  0.0011892925249412656
Epoch:  295  	Training Loss: 0.0012548810336738825
Test Loss:  0.0013733222149312496
Valid Loss:  0.0011868171859532595
Epoch:  296  	Training Loss: 0.0012526062782853842
Test Loss:  0.0013703114818781614
Valid Loss:  0.0011844855034723878
Epoch:  297  	Training Loss: 0.0012503709876909852
Test Loss:  0.0013674783986061811
Valid Loss:  0.0011821966618299484
Epoch:  298  	Training Loss: 0.0012481845915317535
Test Loss:  0.001364898169413209
Valid Loss:  0.00118025834672153
Epoch:  299  	Training Loss: 0.0012461667647585273
Test Loss:  0.0013624888379126787
Valid Loss:  0.00117838429287076
Epoch:  300  	Training Loss: 0.001244181185029447
Test Loss:  0.0013602544786408544
Valid Loss:  0.0011765987146645784
Epoch:  301  	Training Loss: 0.0012423412408679724
Test Loss:  0.001358149223960936
Valid Loss:  0.001174835953861475
Epoch:  302  	Training Loss: 0.0012405186425894499
Test Loss:  0.0013573704054579139
Valid Loss:  0.0011735552689060569
Epoch:  303  	Training Loss: 0.0012388990726321936
Test Loss:  0.0013572367606684566
Valid Loss:  0.0011721354676410556
Epoch:  304  	Training Loss: 0.001237362390384078
Test Loss:  0.0013567170826718211
Valid Loss:  0.0011707186931744218
Epoch:  305  	Training Loss: 0.0012358480598777533
Test Loss:  0.0013560049701482058
Valid Loss:  0.0011693333508446813
Epoch:  306  	Training Loss: 0.0012343410635367036
Test Loss:  0.0013551968149840832
Valid Loss:  0.0011679561575874686
Epoch:  307  	Training Loss: 0.0012328492011874914
Test Loss:  0.0013543001841753721
Valid Loss:  0.0011665968922898173
Epoch:  308  	Training Loss: 0.0012313809711486101
Test Loss:  0.0013533623423427343
Valid Loss:  0.0011652680113911629
Epoch:  309  	Training Loss: 0.0012299332302063704
Test Loss:  0.0013523412635549903
Valid Loss:  0.0011639184085652232
Epoch:  310  	Training Loss: 0.0012285001575946808
Test Loss:  0.0013512626755982637
Valid Loss:  0.0011626146733760834
Epoch:  311  	Training Loss: 0.0012270731385797262
Test Loss:  0.0013499006163328886
Valid Loss:  0.0011612814851105213
Epoch:  312  	Training Loss: 0.0012256568297743797
Test Loss:  0.00134936161339283
Valid Loss:  0.0011612102389335632
Epoch:  313  	Training Loss: 0.0012256248155608773
Test Loss:  0.0013485618401318789
Valid Loss:  0.0011612067464739084
Epoch:  314  	Training Loss: 0.0012256009504199028
Test Loss:  0.00134786288253963
Valid Loss:  0.0011611999943852425
Epoch:  315  	Training Loss: 0.0012255804613232613
Test Loss:  0.0013472163118422031
Valid Loss:  0.0011611983645707369
Epoch:  316  	Training Loss: 0.0012255635811015964
Test Loss:  0.0013466286472976208
Valid Loss:  0.001161190215498209
Epoch:  317  	Training Loss: 0.0012255508918315172
Test Loss:  0.001346084289252758
Valid Loss:  0.0011611925438046455
Epoch:  318  	Training Loss: 0.00122553831897676
Test Loss:  0.001345617463812232
Valid Loss:  0.0011611968511715531
Epoch:  319  	Training Loss: 0.0012255300534889102
Test Loss:  0.0013451887061819434
Valid Loss:  0.0011611920781433582
Epoch:  320  	Training Loss: 0.001225522719323635
Test Loss:  0.0013447916135191917
Valid Loss:  0.0011612002272158861
Epoch:  321  	Training Loss: 0.0012255150359123945
Test Loss:  0.001344445743598044
Valid Loss:  0.0011611978989094496
Epoch:  322  	Training Loss: 0.0012255089823156595
Test Loss:  0.0013443059287965298
Valid Loss:  0.001160700456239283
Epoch:  323  	Training Loss: 0.0012247716076672077
Test Loss:  0.001344301737844944
Valid Loss:  0.0011603047605603933
Epoch:  324  	Training Loss: 0.0012241329532116652
Test Loss:  0.00134407845325768
Valid Loss:  0.0011599477147683501
Epoch:  325  	Training Loss: 0.0012236477341502905
Test Loss:  0.0013436509761959314
Valid Loss:  0.00115959532558918
Epoch:  326  	Training Loss: 0.0012232291046530008
Test Loss:  0.001343115814961493
Valid Loss:  0.0011592961382120848
Epoch:  327  	Training Loss: 0.001222848193719983
Test Loss:  0.0013426048681139946
Valid Loss:  0.0011590144131332636
Epoch:  328  	Training Loss: 0.001222475664690137
Test Loss:  0.0013420863542705774
Valid Loss:  0.0011587397893890738
Epoch:  329  	Training Loss: 0.0012221334036439657
Test Loss:  0.0013417841400951147
Valid Loss:  0.0011584633029997349
Epoch:  330  	Training Loss: 0.0012218570336699486
Test Loss:  0.0013410055544227362
Valid Loss:  0.0011582570150494576
Epoch:  331  	Training Loss: 0.001221580896526575
Test Loss:  0.001340408343821764
Valid Loss:  0.0011580578284338117
Epoch:  332  	Training Loss: 0.0012213066220283508
Test Loss:  0.0013396479189395905
Valid Loss:  0.001157947350293398
Epoch:  333  	Training Loss: 0.0012211825232952833
Test Loss:  0.0013390628155320883
Valid Loss:  0.0011578324483707547
Epoch:  334  	Training Loss: 0.001221068436279893
Test Loss:  0.0013385338243097067
Valid Loss:  0.0011577168479561806
Epoch:  335  	Training Loss: 0.001220959471538663
Test Loss:  0.0013380424352362752
Valid Loss:  0.001157614984549582
Epoch:  336  	Training Loss: 0.0012208519037812948
Test Loss:  0.001337619498372078
Valid Loss:  0.0011575256939977407
Epoch:  337  	Training Loss: 0.0012207487598061562
Test Loss:  0.0013372321845963597
Valid Loss:  0.001157436752691865
Epoch:  338  	Training Loss: 0.0012206503888592124
Test Loss:  0.0013368590734899044
Valid Loss:  0.001157357357442379
Epoch:  339  	Training Loss: 0.0012205522507429123
Test Loss:  0.00133654591627419
Valid Loss:  0.0011572723742574453
Epoch:  340  	Training Loss: 0.0012204548111185431
Test Loss:  0.0013362474273890257
Valid Loss:  0.0011571920476853848
Epoch:  341  	Training Loss: 0.001220357371494174
Test Loss:  0.0013359596487134695
Valid Loss:  0.001157126622274518
Epoch:  342  	Training Loss: 0.0012202637735754251
Test Loss:  0.0013350544031709433
Valid Loss:  0.0011554142693057656
Epoch:  343  	Training Loss: 0.0012186113744974136
Test Loss:  0.0013338394928723574
Valid Loss:  0.0011538243852555752
Epoch:  344  	Training Loss: 0.001217020209878683
Test Loss:  0.0013328480999916792
 69%|██████▉   | 345/500 [04:03<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:03<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:03<00:50,  3.00it/s] 70%|███████   | 351/500 [04:09<02:53,  1.16s/it] 71%|███████   | 353/500 [04:09<02:03,  1.19it/s] 71%|███████   | 355/500 [04:09<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:10<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:10<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:16<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:16<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:16<01:22,  1.65it/s] 73%|███████▎  | 367/500 [04:16<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:16<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:23<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:23<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:23<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:23<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:23<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:30<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:30<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:30<01:09,  1.64it/s] 77%|███████▋  | 387/500 [04:30<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:30<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:36<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:36<01:28,  1.20it/s] 79%|███████▉  | 395/500 [04:36<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:37<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:37<00:33,  3.04it/s] 80%|████████  | 401/500 [04:43<01:55,  1.16s/it] 81%|████████  | 403/500 [04:43<01:21,  1.20it/s] 81%|████████  | 405/500 [04:43<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:43<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:44<00:30,  3.03it/s] 82%|████████▏ | 411/500 [04:50<01:44,  1.17s/it]Valid Loss:  0.0011523254215717316
Epoch:  345  	Training Loss: 0.0012154963333159685
Test Loss:  0.0013319308636710048
Valid Loss:  0.0011508185416460037
Epoch:  346  	Training Loss: 0.001213982468470931
Test Loss:  0.001330954022705555
Valid Loss:  0.001149338437244296
Epoch:  347  	Training Loss: 0.0012124828062951565
Test Loss:  0.0013300231657922268
Valid Loss:  0.0011479200329631567
Epoch:  348  	Training Loss: 0.0012110298266634345
Test Loss:  0.0013291740324348211
Valid Loss:  0.001146545633673668
Epoch:  349  	Training Loss: 0.0012096192222088575
Test Loss:  0.0013283730950206518
Valid Loss:  0.0011452247854322195
Epoch:  350  	Training Loss: 0.0012082378380000591
Test Loss:  0.0013275609817355871
Valid Loss:  0.0011439002119004726
Epoch:  351  	Training Loss: 0.001206864952109754
Test Loss:  0.0013266857713460922
Valid Loss:  0.0011425818083807826
Epoch:  352  	Training Loss: 0.0012055017286911607
Test Loss:  0.0013261598069220781
Valid Loss:  0.0011410998413339257
Epoch:  353  	Training Loss: 0.0012035435065627098
Test Loss:  0.0013274418888613582
Valid Loss:  0.0011396030895411968
Epoch:  354  	Training Loss: 0.0012019237037748098
Test Loss:  0.00132827612105757
Valid Loss:  0.0011385567486286163
Epoch:  355  	Training Loss: 0.0012005747994408011
Test Loss:  0.0013284955639392138
Valid Loss:  0.0011377031914889812
Epoch:  356  	Training Loss: 0.0011994149535894394
Test Loss:  0.00132825318723917
Valid Loss:  0.001136917620897293
Epoch:  357  	Training Loss: 0.0011982888681814075
Test Loss:  0.0013277535326778889
Valid Loss:  0.001136403065174818
Epoch:  358  	Training Loss: 0.0011972504435107112
Test Loss:  0.0013268394395709038
Valid Loss:  0.0011358584742993116
Epoch:  359  	Training Loss: 0.001196528086438775
Test Loss:  0.0013255337253212929
Valid Loss:  0.001135490252636373
Epoch:  360  	Training Loss: 0.0011958318063989282
Test Loss:  0.0013241709675639868
Valid Loss:  0.001135172788053751
Epoch:  361  	Training Loss: 0.0011952642817050219
Test Loss:  0.001322634518146515
Valid Loss:  0.0011348009575158358
Epoch:  362  	Training Loss: 0.0011948059545829892
Test Loss:  0.0013219297397881746
Valid Loss:  0.0011339383199810982
Epoch:  363  	Training Loss: 0.0011943308636546135
Test Loss:  0.0013169283047318459
Valid Loss:  0.0011338773183524609
Epoch:  364  	Training Loss: 0.0011939628748223186
Test Loss:  0.0013157427310943604
Valid Loss:  0.0011334024602547288
Epoch:  365  	Training Loss: 0.0011936582159250975
Test Loss:  0.0013127889251336455
Valid Loss:  0.0011332688154652715
Epoch:  366  	Training Loss: 0.0011933891801163554
Test Loss:  0.0013116487534716725
Valid Loss:  0.00113296031486243
Epoch:  367  	Training Loss: 0.001193148666061461
Test Loss:  0.0013098070630803704
Valid Loss:  0.001132800243794918
Epoch:  368  	Training Loss: 0.001192923984490335
Test Loss:  0.0013088468695059419
Valid Loss:  0.0011325583327561617
Epoch:  369  	Training Loss: 0.0011927090818062425
Test Loss:  0.001307640690356493
Valid Loss:  0.0011323823127895594
Epoch:  370  	Training Loss: 0.0011925013968721032
Test Loss:  0.0013068789849057794
Valid Loss:  0.0011321681085973978
Epoch:  371  	Training Loss: 0.0011922994162887335
Test Loss:  0.0013060537166893482
Valid Loss:  0.001131986966356635
Epoch:  372  	Training Loss: 0.0011921030236408114
Test Loss:  0.0013054517330601811
Valid Loss:  0.001131845056079328
Epoch:  373  	Training Loss: 0.0011919322423636913
Test Loss:  0.0013050333363935351
Valid Loss:  0.0011316941818222404
Epoch:  374  	Training Loss: 0.001191772404126823
Test Loss:  0.0013045999221503735
Valid Loss:  0.0011315597221255302
Epoch:  375  	Training Loss: 0.0011916214134544134
Test Loss:  0.0013043025974184275
Valid Loss:  0.0011314160656183958
Epoch:  376  	Training Loss: 0.0011914719361811876
Test Loss:  0.0013039757031947374
Valid Loss:  0.0011312896385788918
Epoch:  377  	Training Loss: 0.001191335148178041
Test Loss:  0.0013037570752203465
Valid Loss:  0.0011311531998217106
Epoch:  378  	Training Loss: 0.0011912030167877674
Test Loss:  0.0013034960720688105
Valid Loss:  0.001131032477132976
Epoch:  379  	Training Loss: 0.0011910793837159872
Test Loss:  0.0013033307623118162
Valid Loss:  0.0011309122201055288
Epoch:  380  	Training Loss: 0.00119095912668854
Test Loss:  0.001303117605857551
Valid Loss:  0.001130802440457046
Epoch:  381  	Training Loss: 0.0011908425949513912
Test Loss:  0.0013029883848503232
Valid Loss:  0.0011306828819215298
Epoch:  382  	Training Loss: 0.001190726994536817
Test Loss:  0.0013029011897742748
Valid Loss:  0.0011306223459541798
Epoch:  383  	Training Loss: 0.0011906202416867018
Test Loss:  0.0013029073597863317
Valid Loss:  0.0011305452790111303
Epoch:  384  	Training Loss: 0.0011905200080946088
Test Loss:  0.0013028653338551521
Valid Loss:  0.0011304676299914718
Epoch:  385  	Training Loss: 0.0011904240818694234
Test Loss:  0.0013027919922024012
Valid Loss:  0.0011303909122943878
Epoch:  386  	Training Loss: 0.001190328155644238
Test Loss:  0.0013027102686464787
Valid Loss:  0.0011303143110126257
Epoch:  387  	Training Loss: 0.001190233277156949
Test Loss:  0.001302623888477683
Valid Loss:  0.001130247488617897
Epoch:  388  	Training Loss: 0.001190138515084982
Test Loss:  0.0013025302905589342
Valid Loss:  0.001130184275098145
Epoch:  389  	Training Loss: 0.0011900453828275204
Test Loss:  0.0013024304062128067
Valid Loss:  0.0011301229242235422
Epoch:  390  	Training Loss: 0.0011899636592715979
Test Loss:  0.0013023146893829107
Valid Loss:  0.0011300607584416866
Epoch:  391  	Training Loss: 0.001189884846098721
Test Loss:  0.0013021915219724178
Valid Loss:  0.0011300032492727041
Epoch:  392  	Training Loss: 0.0011898103402927518
Test Loss:  0.001302211545407772
Valid Loss:  0.0011299352627247572
Epoch:  393  	Training Loss: 0.0011894102208316326
Test Loss:  0.0013024162035435438
Valid Loss:  0.00112984050065279
Epoch:  394  	Training Loss: 0.0011891735484823585
Test Loss:  0.0013026499655097723
Valid Loss:  0.0011297324672341347
Epoch:  395  	Training Loss: 0.001188971451483667
Test Loss:  0.0013028834946453571
Valid Loss:  0.0011296237353235483
Epoch:  396  	Training Loss: 0.0011887822765856981
Test Loss:  0.0013030950212851167
Valid Loss:  0.0011295394506305456
Epoch:  397  	Training Loss: 0.0011886234860867262
Test Loss:  0.001303276396356523
Valid Loss:  0.0011294608702883124
Epoch:  398  	Training Loss: 0.0011884670238941908
Test Loss:  0.0013034231960773468
Valid Loss:  0.0011293870629742742
Epoch:  399  	Training Loss: 0.0011883170809596777
Test Loss:  0.001303517259657383
Valid Loss:  0.0011293060379102826
Epoch:  400  	Training Loss: 0.001188201131299138
Test Loss:  0.0013035371666774154
Valid Loss:  0.0011292228009551764
Epoch:  401  	Training Loss: 0.001188097521662712
Test Loss:  0.0013035038718953729
Valid Loss:  0.0011291506234556437
Epoch:  402  	Training Loss: 0.0011879988014698029
Test Loss:  0.0013035282026976347
Valid Loss:  0.0011290318798273802
Epoch:  403  	Training Loss: 0.0011879418743774295
Test Loss:  0.0013030155096203089
Valid Loss:  0.0011289818212389946
Epoch:  404  	Training Loss: 0.0011878956574946642
Test Loss:  0.0013024454237893224
Valid Loss:  0.0011289560934528708
Epoch:  405  	Training Loss: 0.0011878509540110826
Test Loss:  0.0013019139878451824
Valid Loss:  0.001128935138694942
Epoch:  406  	Training Loss: 0.0011878138175234199
Test Loss:  0.0013014236465096474
Valid Loss:  0.001128918956965208
Epoch:  407  	Training Loss: 0.0011877866927534342
Test Loss:  0.0013009728863835335
Valid Loss:  0.0011289103422313929
Epoch:  408  	Training Loss: 0.0011877631768584251
Test Loss:  0.0013005631044507027
Valid Loss:  0.0011289030080661178
Epoch:  409  	Training Loss: 0.001187746413052082
Test Loss:  0.001300182775594294
Valid Loss:  0.0011288982350379229
Epoch:  410  	Training Loss: 0.0011877358192577958
Test Loss:  0.001299836440011859
Valid Loss:  0.001128892763517797
Epoch:  411  	Training Loss: 0.0011877254582941532
Test Loss:  0.0012995199067518115
Valid Loss:  0.0011288911337032914
Epoch:  412  	Training Loss: 0.001187715446576476
Test Loss:  0.0012996017467230558
Valid Loss:  0.0011286884546279907
Epoch:  413  	Training Loss: 0.001187510322779417
 83%|████████▎ | 413/500 [04:50<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:50<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:50<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:50<00:26,  3.03it/s] 84%|████████▍ | 421/500 [04:57<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:57<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:57<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:57<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:57<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:04<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:04<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:04<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:04<00:28,  2.18it/s] 88%|████████▊ | 439/500 [05:04<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:10<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:10<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:11<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:11<00:23,  2.26it/s] 90%|████████▉ | 449/500 [05:11<00:16,  3.03it/s] 90%|█████████ | 451/500 [05:17<00:56,  1.16s/it] 91%|█████████ | 453/500 [05:17<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:17<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.26it/s] 92%|█████████▏| 459/500 [05:18<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:24<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:24<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:24<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:24<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:24<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:31<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:31<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:31<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:31<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.16s/it]Test Loss:  0.001299394411034882
Valid Loss:  0.0011285740183666348
Epoch:  414  	Training Loss: 0.0011873072944581509
Test Loss:  0.0012993081472814083
Valid Loss:  0.0011284372303634882
Epoch:  415  	Training Loss: 0.001187122194096446
Test Loss:  0.0012991225812584162
Valid Loss:  0.0011283073108643293
Epoch:  416  	Training Loss: 0.0011869538575410843
Test Loss:  0.001298910123296082
Valid Loss:  0.0011281818151474
Epoch:  417  	Training Loss: 0.0011867909925058484
Test Loss:  0.0012987093068659306
Valid Loss:  0.0011280623730272055
Epoch:  418  	Training Loss: 0.0011866349959746003
Test Loss:  0.0012985006906092167
Valid Loss:  0.0011279492173343897
Epoch:  419  	Training Loss: 0.0011864795815199614
Test Loss:  0.0012982883490622044
Valid Loss:  0.001127838622778654
Epoch:  420  	Training Loss: 0.001186325098387897
Test Loss:  0.001298070652410388
Valid Loss:  0.001127729774452746
Epoch:  421  	Training Loss: 0.001186169683933258
Test Loss:  0.001297852024435997
Valid Loss:  0.0011276204604655504
Epoch:  422  	Training Loss: 0.0011860155500471592
Test Loss:  0.0012966851936653256
Valid Loss:  0.0011258649174124002
Epoch:  423  	Training Loss: 0.0011844559339806437
Test Loss:  0.0012951320968568325
Valid Loss:  0.0011242845794185996
Epoch:  424  	Training Loss: 0.0011829487048089504
Test Loss:  0.0012938554864376783
Valid Loss:  0.001122817164286971
Epoch:  425  	Training Loss: 0.001181565341539681
Test Loss:  0.0012926056515425444
Valid Loss:  0.0011214613914489746
Epoch:  426  	Training Loss: 0.0011802864028140903
Test Loss:  0.0012914459221065044
Valid Loss:  0.0011201042216271162
Epoch:  427  	Training Loss: 0.001179049490019679
Test Loss:  0.0012903835158795118
Valid Loss:  0.00111892179120332
Epoch:  428  	Training Loss: 0.001178026432171464
Test Loss:  0.001289419480599463
Valid Loss:  0.0011178776621818542
Epoch:  429  	Training Loss: 0.0011770593700930476
Test Loss:  0.001288480474613607
Valid Loss:  0.0011168367927893996
Epoch:  430  	Training Loss: 0.001176149700768292
Test Loss:  0.0012876499677076936
Valid Loss:  0.001115922350436449
Epoch:  431  	Training Loss: 0.001175380777567625
Test Loss:  0.0012868662597611547
Valid Loss:  0.0011151160579174757
Epoch:  432  	Training Loss: 0.0011746140662580729
Test Loss:  0.00128638104069978
Valid Loss:  0.0011139661073684692
Epoch:  433  	Training Loss: 0.0011732527054846287
Test Loss:  0.0012862483272328973
Valid Loss:  0.0011127656325697899
Epoch:  434  	Training Loss: 0.001171917887404561
Test Loss:  0.0012860745191574097
Valid Loss:  0.0011115935631096363
Epoch:  435  	Training Loss: 0.0011705991346389055
Test Loss:  0.0012858028057962656
Valid Loss:  0.0011104571167379618
Epoch:  436  	Training Loss: 0.0011692921398207545
Test Loss:  0.0012854313245043159
Valid Loss:  0.0011093257926404476
Epoch:  437  	Training Loss: 0.0011680044699460268
Test Loss:  0.0012849671766161919
Valid Loss:  0.0011082007549703121
Epoch:  438  	Training Loss: 0.0011667297221720219
Test Loss:  0.0012844172306358814
Valid Loss:  0.001107087591663003
Epoch:  439  	Training Loss: 0.0011654715053737164
Test Loss:  0.0012836959213018417
Valid Loss:  0.00110591237898916
Epoch:  440  	Training Loss: 0.0011642295867204666
Test Loss:  0.001282840734347701
Valid Loss:  0.0011047529987990856
Epoch:  441  	Training Loss: 0.001162996282801032
Test Loss:  0.001281931297853589
Valid Loss:  0.0011036014184355736
Epoch:  442  	Training Loss: 0.0011617648415267467
Test Loss:  0.0012813596986234188
Valid Loss:  0.0011033884948119521
Epoch:  443  	Training Loss: 0.0011616002302616835
Test Loss:  0.0012801147531718016
Valid Loss:  0.001103314571082592
Epoch:  444  	Training Loss: 0.001161453197710216
Test Loss:  0.0012793517671525478
Valid Loss:  0.0011031918693333864
Epoch:  445  	Training Loss: 0.0011613257229328156
Test Loss:  0.0012785110156983137
Valid Loss:  0.001103098038583994
Epoch:  446  	Training Loss: 0.0011612027883529663
Test Loss:  0.0012778309173882008
Valid Loss:  0.0011029941961169243
Epoch:  447  	Training Loss: 0.0011610814835876226
Test Loss:  0.001277186325751245
Valid Loss:  0.0011028989683836699
Epoch:  448  	Training Loss: 0.001160963554866612
Test Loss:  0.0012766227591782808
Valid Loss:  0.001102800015360117
Epoch:  449  	Training Loss: 0.0011608477216213942
Test Loss:  0.0012761097168549895
Valid Loss:  0.0011027036234736443
Epoch:  450  	Training Loss: 0.0011607331689447165
Test Loss:  0.001275650574825704
Valid Loss:  0.0011026097927242517
Epoch:  451  	Training Loss: 0.0011606247862800956
Test Loss:  0.001275232876650989
Valid Loss:  0.0011025161948055029
Epoch:  452  	Training Loss: 0.0011605176841840148
Test Loss:  0.0012729866430163383
Valid Loss:  0.0010991154704242945
Epoch:  453  	Training Loss: 0.001157599501311779
Test Loss:  0.0012702567037194967
Valid Loss:  0.001096628257073462
Epoch:  454  	Training Loss: 0.0011552412761375308
Test Loss:  0.0012682736851274967
Valid Loss:  0.0010941823711618781
Epoch:  455  	Training Loss: 0.0011531758354976773
Test Loss:  0.0012661798391491175
Valid Loss:  0.0010922159999608994
Epoch:  456  	Training Loss: 0.0011512902565300465
Test Loss:  0.0012643705122172832
Valid Loss:  0.001090231817215681
Epoch:  457  	Training Loss: 0.0011494336649775505
Test Loss:  0.00126251473557204
Valid Loss:  0.0010883018840104342
Epoch:  458  	Training Loss: 0.0011476166546344757
Test Loss:  0.0012608433607965708
Valid Loss:  0.0010866487864404917
Epoch:  459  	Training Loss: 0.0011459353845566511
Test Loss:  0.0012592184357345104
Valid Loss:  0.0010850663529708982
Epoch:  460  	Training Loss: 0.0011442728573456407
Test Loss:  0.0012576477602124214
Valid Loss:  0.0010835016146302223
Epoch:  461  	Training Loss: 0.0011426778510212898
Test Loss:  0.001256187679246068
Valid Loss:  0.0010820133611559868
Epoch:  462  	Training Loss: 0.001141174929216504
Test Loss:  0.0012550550745800138
Valid Loss:  0.0010804897174239159
Epoch:  463  	Training Loss: 0.0011398443020880222
Test Loss:  0.001254018396139145
Valid Loss:  0.001079159788787365
Epoch:  464  	Training Loss: 0.0011386515107005835
Test Loss:  0.001253013382665813
Valid Loss:  0.0010779540752992034
Epoch:  465  	Training Loss: 0.0011375173926353455
Test Loss:  0.001252035261131823
Valid Loss:  0.0010767898056656122
Epoch:  466  	Training Loss: 0.0011364463716745377
Test Loss:  0.0012511040549725294
Valid Loss:  0.0010757350828498602
Epoch:  467  	Training Loss: 0.0011354639427736402
Test Loss:  0.001250213012099266
Valid Loss:  0.0010747375199571252
Epoch:  468  	Training Loss: 0.0011345476377755404
Test Loss:  0.0012493340764194727
Valid Loss:  0.0010737706907093525
Epoch:  469  	Training Loss: 0.0011336351744830608
Test Loss:  0.0012484590988606215
Valid Loss:  0.0010728127090260386
Epoch:  470  	Training Loss: 0.001132749137468636
Test Loss:  0.0012476155534386635
Valid Loss:  0.0010719989659264684
Epoch:  471  	Training Loss: 0.001131906290538609
Test Loss:  0.0012467855121940374
Valid Loss:  0.001071218866854906
Epoch:  472  	Training Loss: 0.0011310786940157413
Test Loss:  0.001247377134859562
Valid Loss:  0.0010705799795687199
Epoch:  473  	Training Loss: 0.0011304637882858515
Test Loss:  0.0012472729431465268
Valid Loss:  0.001070020953193307
Epoch:  474  	Training Loss: 0.0011298584286123514
Test Loss:  0.0012474874965846539
Valid Loss:  0.0010694409720599651
Epoch:  475  	Training Loss: 0.0011292988201603293
Test Loss:  0.001247383072040975
Valid Loss:  0.0010688952170312405
Epoch:  476  	Training Loss: 0.001128742122091353
Test Loss:  0.0012473773676902056
Valid Loss:  0.0010683354921638966
Epoch:  477  	Training Loss: 0.0011281897313892841
Test Loss:  0.0012472128728404641
Valid Loss:  0.0010677902027964592
Epoch:  478  	Training Loss: 0.0011276387376710773
Test Loss:  0.0012470735237002373
Valid Loss:  0.0010672396747395396
Epoch:  479  	Training Loss: 0.0011270908871665597
Test Loss:  0.001246853731572628
Valid Loss:  0.001066771917976439
Epoch:  480  	Training Loss: 0.0011265455977991223
Test Loss:  0.0012466319603845477
Valid Loss:  0.0010663153370842338
Epoch:  481  	Training Loss: 0.0011260199826210737
Test Loss:  0.0012464120518416166
Valid Loss:  0.0010658993851393461
 97%|█████████▋| 483/500 [05:38<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:38<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:38<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:38<00:03,  3.03it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:44<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:45<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:45<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:45<00:00,  3.01it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
Epoch:  482  	Training Loss: 0.0011255796998739243
Test Loss:  0.0012462842278182507
Valid Loss:  0.0010658100945875049
Epoch:  483  	Training Loss: 0.0011254862183704972
Test Loss:  0.0012462185695767403
Valid Loss:  0.0010657093953341246
Epoch:  484  	Training Loss: 0.001125394250266254
Test Loss:  0.0012461611768230796
Valid Loss:  0.0010656106751412153
Epoch:  485  	Training Loss: 0.0011253063566982746
Test Loss:  0.0012461079750210047
Valid Loss:  0.0010655104415491223
Epoch:  486  	Training Loss: 0.0011252197436988354
Test Loss:  0.0012460548896342516
Valid Loss:  0.0010654107900336385
Epoch:  487  	Training Loss: 0.0011251327814534307
Test Loss:  0.0012460033176466823
Valid Loss:  0.0010653107892721891
Epoch:  488  	Training Loss: 0.0011250479146838188
Test Loss:  0.0012459615245461464
Valid Loss:  0.0010652142809703946
Epoch:  489  	Training Loss: 0.0011249647941440344
Test Loss:  0.0012459218269214034
Valid Loss:  0.001065127900801599
Epoch:  490  	Training Loss: 0.0011248920345678926
Test Loss:  0.0012458874844014645
Valid Loss:  0.0010650460608303547
Epoch:  491  	Training Loss: 0.0011248206719756126
Test Loss:  0.0012458486016839743
Valid Loss:  0.0010649629402905703
Epoch:  492  	Training Loss: 0.001124749076552689
Test Loss:  0.001246053958311677
Valid Loss:  0.0010648673633113503
Epoch:  493  	Training Loss: 0.0011246544308960438
Test Loss:  0.0012462267186492682
Valid Loss:  0.0010647769086062908
Epoch:  494  	Training Loss: 0.0011245603673160076
Test Loss:  0.001246374100446701
Valid Loss:  0.001064687268808484
Epoch:  495  	Training Loss: 0.0011244678171351552
Test Loss:  0.0012465014588087797
Valid Loss:  0.0010646029841154814
Epoch:  496  	Training Loss: 0.0011243749177083373
Test Loss:  0.0012466087937355042
Valid Loss:  0.0010645221918821335
Epoch:  497  	Training Loss: 0.0011242826003581285
Test Loss:  0.0012466959888115525
Valid Loss:  0.001064440468326211
Epoch:  498  	Training Loss: 0.0011241931933909655
Test Loss:  0.0012467646738514304
Valid Loss:  0.0010643588611856103
Epoch:  499  	Training Loss: 0.0011241041356697679
Test Loss:  0.0012468170607462525
Valid Loss:  0.0010642791166901588
Epoch:  500  	Training Loss: 0.0011240162421017885
Test Loss:  0.0012468576896935701
Valid Loss:  0.0010641985572874546
seed is  8
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 15.03it/s]  1%|          | 4/500 [00:00<00:31, 15.76it/s]  1%|          | 6/500 [00:00<00:31, 15.65it/s]  2%|▏         | 8/500 [00:00<00:30, 16.03it/s]  2%|▏         | 10/500 [00:00<00:30, 16.25it/s]  2%|▏         | 12/500 [00:00<00:29, 16.37it/s]  3%|▎         | 14/500 [00:00<00:29, 16.42it/s]  3%|▎         | 16/500 [00:00<00:29, 16.31it/s]  4%|▎         | 18/500 [00:01<00:30, 15.69it/s]  4%|▍         | 20/500 [00:01<00:30, 15.93it/s]  4%|▍         | 22/500 [00:01<00:30, 15.88it/s]  5%|▍         | 24/500 [00:01<00:29, 16.04it/s]  5%|▌         | 26/500 [00:01<00:29, 16.02it/s]  6%|▌         | 28/500 [00:01<00:29, 16.17it/s]  6%|▌         | 30/500 [00:01<00:28, 16.29it/s]  6%|▋         | 32/500 [00:01<00:28, 16.38it/s]  7%|▋         | 34/500 [00:02<00:28, 16.44it/s]  7%|▋         | 36/500 [00:02<00:28, 16.53it/s]  8%|▊         | 38/500 [00:02<00:27, 16.58it/s]  8%|▊         | 40/500 [00:02<00:27, 16.61it/s]  8%|▊         | 42/500 [00:02<00:27, 16.43it/s]  9%|▉         | 44/500 [00:02<00:28, 16.17it/s]  9%|▉         | 46/500 [00:02<00:28, 16.15it/s] 10%|▉         | 48/500 [00:02<00:28, 15.97it/s] 10%|█         | 50/500 [00:03<00:27, 16.13it/s] 10%|█         | 52/500 [00:03<00:27, 16.26it/s] 11%|█         | 54/500 [00:03<00:27, 16.14it/s] 11%|█         | 56/500 [00:03<00:27, 16.31it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.39it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.51it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.47it/s] 13%|█▎        | 64/500 [00:03<00:27, 16.05it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.92it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.05it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.20it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.06it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.90it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.92it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.08it/s] 16%|█▌        | 80/500 [00:04<00:26, 15.91it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.67it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.66it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.62it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.78it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.02it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.14it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.29it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.27it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.29it/s] 20%|██        | 100/500 [00:06<00:24, 16.28it/s] 20%|██        | 102/500 [00:06<00:24, 15.95it/s] 21%|██        | 104/500 [00:06<00:24, 16.02it/s] 21%|██        | 106/500 [00:06<00:24, 15.92it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.10it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.14it/s] 22%|██▏       | 112/500 [00:06<00:24, 16.10it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.22it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.37it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.43it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.00it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.15it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.26it/s]Epoch:  1  	Training Loss: 0.029097314924001694
Test Loss:  33.620582580566406
Valid Loss:  33.905059814453125
Epoch:  2  	Training Loss: 33.808807373046875
Test Loss:  98316208.0
Valid Loss:  97573920.0
Epoch:  3  	Training Loss: 97833848.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
 25%|██▌       | 126/500 [00:07<00:22, 16.36it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.38it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.27it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.26it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.24it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.23it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.42it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.51it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.57it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.64it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.64it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.66it/s] 30%|███       | 150/500 [00:09<00:21, 16.65it/s] 30%|███       | 152/500 [00:09<00:20, 16.65it/s] 31%|███       | 154/500 [00:09<00:20, 16.67it/s] 31%|███       | 156/500 [00:09<00:21, 16.31it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.01it/s] 32%|███▏      | 160/500 [00:09<00:21, 15.99it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.18it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.27it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.09it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.09it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.08it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.10it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.03it/s] 35%|███▌      | 176/500 [00:10<00:20, 16.14it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.18it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.95it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.78it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.35it/s] 37%|███▋      | 186/500 [00:11<00:20, 15.57it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.68it/s] 38%|███▊      | 190/500 [00:11<00:19, 15.76it/s] 38%|███▊      | 192/500 [00:11<00:19, 15.76it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.66it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.84it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.04it/s] 40%|████      | 200/500 [00:12<00:18, 15.88it/s] 40%|████      | 202/500 [00:12<00:18, 16.09it/s] 41%|████      | 204/500 [00:12<00:18, 16.06it/s] 41%|████      | 206/500 [00:12<00:18, 15.94it/s] 42%|████▏     | 208/500 [00:12<00:18, 16.11it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.19it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.33it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.43it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.48it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.53it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.60it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.61it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.47it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.51it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.42it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.22it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.34it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.47it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.54it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.56it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.57it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.63it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.59it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.59it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.45it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:15<00:15, 16.45it/s] 50%|█████     | 252/500 [00:15<00:15, 16.52it/s] 51%|█████     | 254/500 [00:15<00:14, 16.53it/s] 51%|█████     | 256/500 [00:15<00:14, 16.42it/s] 52%|█████▏    | 258/500 [00:15<00:15, 16.10it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.29it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.27it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.22it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.14it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.11it/s] 54%|█████▍    | 270/500 [00:16<00:14, 15.78it/s] 54%|█████▍    | 272/500 [00:16<00:14, 15.96it/s] 55%|█████▍    | 274/500 [00:16<00:14, 16.12it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.20it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.34it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.23it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.36it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.32it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.33it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.43it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.52it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.41it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.47it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.41it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.22it/s] 60%|██████    | 300/500 [00:18<00:12, 16.13it/s] 60%|██████    | 302/500 [00:18<00:13, 14.98it/s] 61%|██████    | 304/500 [00:18<00:12, 15.27it/s] 61%|██████    | 306/500 [00:18<00:12, 15.47it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.72it/s] 62%|██████▏   | 310/500 [00:19<00:11, 15.96it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.07it/s] 63%|██████▎   | 314/500 [00:19<00:11, 15.60it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.72it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.97it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.11it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.23it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.12it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.11it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.34it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.36it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.32it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.26it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.27it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.28it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.31it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.23it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.25it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.03it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.24it/s] 70%|███████   | 350/500 [00:21<00:09, 16.36it/s] 70%|███████   | 352/500 [00:21<00:09, 16.42it/s] 71%|███████   | 354/500 [00:21<00:08, 16.48it/s] 71%|███████   | 356/500 [00:21<00:08, 16.50it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.53it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.46it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.39it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.29it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.06it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.25it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.30it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.39it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.07it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.03it/s] 76%|███████▌  | 378/500 [00:23<00:07, 15.87it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.03it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.20it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.33it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.38it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.19it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.21it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.07it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.01it/s] 79%|███████▉  | 396/500 [00:24<00:06, 15.68it/s] 80%|███████▉  | 398/500 [00:24<00:06, 15.18it/s] 80%|████████  | 400/500 [00:24<00:06, 15.53it/s] 80%|████████  | 402/500 [00:24<00:06, 15.58it/s] 81%|████████  | 404/500 [00:24<00:06, 15.68it/s] 81%|████████  | 406/500 [00:25<00:05, 15.89it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.53it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.72it/s] 82%|████████▏ | 412/500 [00:25<00:05, 15.65it/s] 83%|████████▎ | 414/500 [00:25<00:05, 15.94it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.08it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.28it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.40it/s] 84%|████████▍ | 422/500 [00:26<00:05, 15.21it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.46it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.61it/s] 86%|████████▌ | 428/500 [00:26<00:04, 15.92it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.14it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.25it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.25it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.32it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.40it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.38it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.21it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.35it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.45it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.49it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.54it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.55it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.57it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.56it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.55it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.48it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.53it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.40it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.33it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.34it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.17it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.23it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.35it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.46it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.53it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.57it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.61it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.42it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.07it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.12it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.10it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.87it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.76it/s] 99%|█████████▉| 496/500 [00:30<00:00, 15.87it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:30<00:00, 16.08it/s]100%|██████████| 500/500 [00:30<00:00, 16.25it/s]100%|██████████| 500/500 [00:30<00:00, 16.17it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  8
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:15,  6.16s/it]  1%|          | 3/500 [00:06<13:37,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:12<10:40,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:40,  3.01it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:19<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.64it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:55,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:28,  3.03it/s] 10%|█         | 51/500 [00:40<08:43,  1.17s/it] 11%|█         | 53/500 [00:40<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.25it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:46<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:46<06:05,  1.20it/s] 13%|█▎        | 65/500 [00:47<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.03it/s] 14%|█▍        | 71/500 [00:53<08:14,  1.15s/it]Epoch:  1  	Training Loss: 0.029097316786646843
Test Loss:  0.38160449266433716
Valid Loss:  0.37334614992141724
Epoch:  2  	Training Loss: 0.37432798743247986
Test Loss:  1.5333385467529297
Valid Loss:  1.5353156328201294
Epoch:  3  	Training Loss: 1.5400562286376953
Test Loss:  0.023935990408062935
Valid Loss:  0.02928529679775238
Epoch:  4  	Training Loss: 0.02934037521481514
Test Loss:  0.023919817060232162
Valid Loss:  0.029268264770507812
Epoch:  5  	Training Loss: 0.029323065653443336
Test Loss:  0.023903656750917435
Valid Loss:  0.029251253232359886
Epoch:  6  	Training Loss: 0.02930576726794243
Test Loss:  0.023887507617473602
Valid Loss:  0.02923424169421196
Epoch:  7  	Training Loss: 0.029288481920957565
Test Loss:  0.02387138083577156
Valid Loss:  0.029217252507805824
Epoch:  8  	Training Loss: 0.029271209612488747
Test Loss:  0.02385525591671467
Valid Loss:  0.029200270771980286
Epoch:  9  	Training Loss: 0.029253952205181122
Test Loss:  0.023839157074689865
Valid Loss:  0.02918330207467079
Epoch:  10  	Training Loss: 0.029236704111099243
Test Loss:  0.02382306382060051
Valid Loss:  0.029166340827941895
Epoch:  11  	Training Loss: 0.02921946719288826
Test Loss:  0.023806989192962646
Valid Loss:  0.029149392619729042
Epoch:  12  	Training Loss: 0.02920224890112877
Test Loss:  0.02376249060034752
Valid Loss:  0.029106445610523224
Epoch:  13  	Training Loss: 0.029156990349292755
Test Loss:  0.023718170821666718
Valid Loss:  0.029063623398542404
Epoch:  14  	Training Loss: 0.02911188267171383
Test Loss:  0.02367403544485569
Valid Loss:  0.029020924121141434
Epoch:  15  	Training Loss: 0.02906692959368229
Test Loss:  0.02363007143139839
Valid Loss:  0.028978347778320312
Epoch:  16  	Training Loss: 0.02902211621403694
Test Loss:  0.023586291819810867
Valid Loss:  0.02893589809536934
Epoch:  17  	Training Loss: 0.028977451846003532
Test Loss:  0.023542683571577072
Valid Loss:  0.028893567621707916
Epoch:  18  	Training Loss: 0.028932930901646614
Test Loss:  0.023499246686697006
Valid Loss:  0.02885136567056179
Epoch:  19  	Training Loss: 0.028888555243611336
Test Loss:  0.023455986753106117
Valid Loss:  0.02880926989018917
Epoch:  20  	Training Loss: 0.02884431928396225
Test Loss:  0.02341289445757866
Valid Loss:  0.028767302632331848
Epoch:  21  	Training Loss: 0.028800223022699356
Test Loss:  0.02336997166275978
Valid Loss:  0.02872544899582863
Epoch:  22  	Training Loss: 0.028756270185112953
Test Loss:  0.02332821674644947
Valid Loss:  0.02868485637009144
Epoch:  23  	Training Loss: 0.02871358022093773
Test Loss:  0.02328662946820259
Valid Loss:  0.028644375503063202
Epoch:  24  	Training Loss: 0.0286710225045681
Test Loss:  0.023245198652148247
Valid Loss:  0.02860400639474392
Epoch:  25  	Training Loss: 0.028628598898649216
Test Loss:  0.023203931748867035
Valid Loss:  0.02856374904513359
Epoch:  26  	Training Loss: 0.028586305677890778
Test Loss:  0.02316281944513321
Valid Loss:  0.028523597866296768
Epoch:  27  	Training Loss: 0.028544146567583084
Test Loss:  0.023121865466237068
Valid Loss:  0.028484387323260307
Epoch:  28  	Training Loss: 0.028502948582172394
Test Loss:  0.023082513362169266
Valid Loss:  0.02844785526394844
Epoch:  29  	Training Loss: 0.02846398577094078
Test Loss:  0.02304385043680668
Valid Loss:  0.028412213549017906
Epoch:  30  	Training Loss: 0.02842579036951065
Test Loss:  0.023005597293376923
Valid Loss:  0.028377162292599678
Epoch:  31  	Training Loss: 0.02838798798620701
Test Loss:  0.022967558354139328
Valid Loss:  0.02834235318005085
Epoch:  32  	Training Loss: 0.028350427746772766
Test Loss:  0.02293315902352333
Valid Loss:  0.028310323134064674
Epoch:  33  	Training Loss: 0.02831611968576908
Test Loss:  0.022898957133293152
Valid Loss:  0.02827838808298111
Epoch:  34  	Training Loss: 0.02828194387257099
Test Loss:  0.022864922881126404
Valid Loss:  0.0282465647906065
Epoch:  35  	Training Loss: 0.0282478928565979
Test Loss:  0.022831059992313385
Valid Loss:  0.028214843943715096
Epoch:  36  	Training Loss: 0.028213970363140106
Test Loss:  0.022797338664531708
Valid Loss:  0.028183218091726303
Epoch:  37  	Training Loss: 0.028180167078971863
Test Loss:  0.022763751447200775
Valid Loss:  0.028152000159025192
Epoch:  38  	Training Loss: 0.028146587312221527
Test Loss:  0.022730495780706406
Valid Loss:  0.028122033923864365
Epoch:  39  	Training Loss: 0.028114091604948044
Test Loss:  0.022697942331433296
Valid Loss:  0.028093300759792328
Epoch:  40  	Training Loss: 0.028083007782697678
Test Loss:  0.022665875032544136
Valid Loss:  0.02806585095822811
Epoch:  41  	Training Loss: 0.028052914887666702
Test Loss:  0.02263428270816803
Valid Loss:  0.028038987889885902
Epoch:  42  	Training Loss: 0.028023727238178253
Test Loss:  0.02260858379304409
Valid Loss:  0.028016965836286545
Epoch:  43  	Training Loss: 0.02800031006336212
Test Loss:  0.02258312702178955
Valid Loss:  0.027995754033327103
Epoch:  44  	Training Loss: 0.027977261692285538
Test Loss:  0.022557906806468964
Valid Loss:  0.027975156903266907
Epoch:  45  	Training Loss: 0.027954591438174248
Test Loss:  0.022532952949404716
Valid Loss:  0.027954988181591034
Epoch:  46  	Training Loss: 0.02793213166296482
Test Loss:  0.022508569061756134
Valid Loss:  0.027934908866882324
Epoch:  47  	Training Loss: 0.027909837663173676
Test Loss:  0.02248452603816986
Valid Loss:  0.027915026992559433
Epoch:  48  	Training Loss: 0.02788776159286499
Test Loss:  0.022460825741291046
Valid Loss:  0.027895618230104446
Epoch:  49  	Training Loss: 0.027865808457136154
Test Loss:  0.022437334060668945
Valid Loss:  0.02787642553448677
Epoch:  50  	Training Loss: 0.027844224125146866
Test Loss:  0.02241404354572296
Valid Loss:  0.027857527136802673
Epoch:  51  	Training Loss: 0.02782295271754265
Test Loss:  0.02239089086651802
Valid Loss:  0.02783871255815029
Epoch:  52  	Training Loss: 0.027801809832453728
Test Loss:  0.022367537021636963
Valid Loss:  0.027819760143756866
Epoch:  53  	Training Loss: 0.02778058499097824
Test Loss:  0.022344395518302917
Valid Loss:  0.027801187708973885
Epoch:  54  	Training Loss: 0.02775956317782402
Test Loss:  0.022321388125419617
Valid Loss:  0.027782833203673363
Epoch:  55  	Training Loss: 0.027738720178604126
Test Loss:  0.022298522293567657
Valid Loss:  0.02776458114385605
Epoch:  56  	Training Loss: 0.027718007564544678
Test Loss:  0.022275839000940323
Valid Loss:  0.027746494859457016
Epoch:  57  	Training Loss: 0.027697496116161346
Test Loss:  0.022253328934311867
Valid Loss:  0.027728572487831116
Epoch:  58  	Training Loss: 0.027677131816744804
Test Loss:  0.022230876609683037
Valid Loss:  0.027710799127817154
Epoch:  59  	Training Loss: 0.027656860649585724
Test Loss:  0.022208571434020996
Valid Loss:  0.02769320085644722
Epoch:  60  	Training Loss: 0.027636684477329254
Test Loss:  0.02218637615442276
Valid Loss:  0.027675841003656387
Epoch:  61  	Training Loss: 0.027616608887910843
Test Loss:  0.02216428704559803
Valid Loss:  0.02765856310725212
Epoch:  62  	Training Loss: 0.027596626430749893
Test Loss:  0.022143114358186722
Valid Loss:  0.027641991153359413
Epoch:  63  	Training Loss: 0.027577470988035202
Test Loss:  0.022122029215097427
Valid Loss:  0.027625491842627525
Epoch:  64  	Training Loss: 0.027558397501707077
Test Loss:  0.022101040929555893
Valid Loss:  0.027609070762991905
Epoch:  65  	Training Loss: 0.027539409697055817
Test Loss:  0.02208014205098152
Valid Loss:  0.027592718601226807
Epoch:  66  	Training Loss: 0.027520501986145973
Test Loss:  0.022059326991438866
Valid Loss:  0.027576439082622528
Epoch:  67  	Training Loss: 0.027501674368977547
Test Loss:  0.022038603201508522
Valid Loss:  0.02756023034453392
Epoch:  68  	Training Loss: 0.027482936158776283
Test Loss:  0.02201804146170616
Valid Loss:  0.027544120326638222
Epoch:  69  	Training Loss: 0.027464348822832108
Test Loss:  0.02199755795300007
Valid Loss:  0.027528084814548492
Epoch:  70  	Training Loss: 0.02744584158062935
Test Loss:  0.021977169439196587
Valid Loss:  0.027512121945619583
Epoch:  71  	Training Loss: 0.027427416294813156
Test Loss:  0.02195686846971512
Valid Loss:  0.027496229857206345
 15%|█▍        | 73/500 [00:53<05:53,  1.21it/s] 15%|█▌        | 75/500 [00:53<04:15,  1.67it/s] 15%|█▌        | 77/500 [00:53<03:06,  2.27it/s] 16%|█▌        | 79/500 [00:54<02:17,  3.06it/s] 16%|█▌        | 81/500 [01:00<08:04,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:45,  1.21it/s] 17%|█▋        | 85/500 [01:00<04:08,  1.67it/s] 17%|█▋        | 87/500 [01:00<03:01,  2.27it/s] 18%|█▊        | 89/500 [01:00<02:14,  3.06it/s] 18%|█▊        | 91/500 [01:06<07:56,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:40,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:07<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:07<02:12,  3.03it/s] 20%|██        | 101/500 [01:13<07:47,  1.17s/it] 21%|██        | 103/500 [01:13<05:33,  1.19it/s] 21%|██        | 105/500 [01:14<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:14<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:14<02:08,  3.03it/s] 22%|██▏       | 111/500 [01:20<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:20<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:20<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:20<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:27<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:27<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:27<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:27<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:27<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:34<07:09,  1.16s/it] 27%|██▋       | 133/500 [01:34<05:06,  1.20it/s] 27%|██▋       | 135/500 [01:34<03:40,  1.65it/s] 27%|██▋       | 137/500 [01:34<02:40,  2.26it/s] 28%|██▊       | 139/500 [01:34<01:59,  3.03it/s] 28%|██▊       | 141/500 [01:40<06:57,  1.16s/it]Epoch:  72  	Training Loss: 0.02740907296538353
Test Loss:  0.02193748950958252
Valid Loss:  0.02748103439807892
Epoch:  73  	Training Loss: 0.027391556650400162
Test Loss:  0.02191818878054619
Valid Loss:  0.027465946972370148
Epoch:  74  	Training Loss: 0.027374111115932465
Test Loss:  0.021898958832025528
Valid Loss:  0.02745102532207966
Epoch:  75  	Training Loss: 0.027356738224625587
Test Loss:  0.021879808977246284
Valid Loss:  0.027436165139079094
Epoch:  76  	Training Loss: 0.027339443564414978
Test Loss:  0.02186080440878868
Valid Loss:  0.02742137387394905
Epoch:  77  	Training Loss: 0.027322284877300262
Test Loss:  0.021841976791620255
Valid Loss:  0.027406664565205574
Epoch:  78  	Training Loss: 0.02730526775121689
Test Loss:  0.02182329259812832
Valid Loss:  0.027392031624913216
Epoch:  79  	Training Loss: 0.027288343757390976
Test Loss:  0.021804694086313248
Valid Loss:  0.027377456426620483
Epoch:  80  	Training Loss: 0.027271494269371033
Test Loss:  0.021786168217658997
Valid Loss:  0.027362950146198273
Epoch:  81  	Training Loss: 0.02725471556186676
Test Loss:  0.021767718717455864
Valid Loss:  0.027348505333065987
Epoch:  82  	Training Loss: 0.027238015085458755
Test Loss:  0.02175011858344078
Valid Loss:  0.02733473852276802
Epoch:  83  	Training Loss: 0.02722209319472313
Test Loss:  0.02173258736729622
Valid Loss:  0.027321025729179382
Epoch:  84  	Training Loss: 0.027206234633922577
Test Loss:  0.021715205162763596
Valid Loss:  0.027307379990816116
Epoch:  85  	Training Loss: 0.02719048224389553
Test Loss:  0.021697886288166046
Valid Loss:  0.027293790131807327
Epoch:  86  	Training Loss: 0.02717478945851326
Test Loss:  0.02168063074350357
Valid Loss:  0.027280256152153015
Epoch:  87  	Training Loss: 0.027159161865711212
Test Loss:  0.021663449704647064
Valid Loss:  0.02726677432656288
Epoch:  88  	Training Loss: 0.027143599465489388
Test Loss:  0.021646328270435333
Valid Loss:  0.027253350242972374
Epoch:  89  	Training Loss: 0.027128098532557487
Test Loss:  0.021629275754094124
Valid Loss:  0.027239982038736343
Epoch:  90  	Training Loss: 0.027112659066915512
Test Loss:  0.021612290292978287
Valid Loss:  0.027226664125919342
Epoch:  91  	Training Loss: 0.02709728479385376
Test Loss:  0.021595362573862076
Valid Loss:  0.027213405817747116
Epoch:  92  	Training Loss: 0.027081968262791634
Test Loss:  0.021579213440418243
Valid Loss:  0.027200743556022644
Epoch:  93  	Training Loss: 0.02706734649837017
Test Loss:  0.021563123911619186
Valid Loss:  0.02718813717365265
Epoch:  94  	Training Loss: 0.027052780613303185
Test Loss:  0.021547095850110054
Valid Loss:  0.027175575494766235
Epoch:  95  	Training Loss: 0.027038268744945526
Test Loss:  0.02153111808001995
Valid Loss:  0.027163058519363403
Epoch:  96  	Training Loss: 0.027023814618587494
Test Loss:  0.021515216678380966
Valid Loss:  0.0271505918353796
Epoch:  97  	Training Loss: 0.02700941450893879
Test Loss:  0.02149943821132183
Valid Loss:  0.02713816985487938
Epoch:  98  	Training Loss: 0.026995066553354263
Test Loss:  0.02148371934890747
Valid Loss:  0.02712579071521759
Epoch:  99  	Training Loss: 0.02698078751564026
Test Loss:  0.021468110382556915
Valid Loss:  0.027113480493426323
Epoch:  100  	Training Loss: 0.026966582983732224
Test Loss:  0.021452562883496284
Valid Loss:  0.027101214975118637
Epoch:  101  	Training Loss: 0.026952432468533516
Test Loss:  0.021437067538499832
Valid Loss:  0.027088992297649384
Epoch:  102  	Training Loss: 0.026938337832689285
Test Loss:  0.021422123536467552
Valid Loss:  0.027077194303274155
Epoch:  103  	Training Loss: 0.0269247367978096
Test Loss:  0.021407227963209152
Valid Loss:  0.02706543356180191
Epoch:  104  	Training Loss: 0.026911186054348946
Test Loss:  0.02139239013195038
Valid Loss:  0.027053721249103546
Epoch:  105  	Training Loss: 0.02689768187701702
Test Loss:  0.021377598866820335
Valid Loss:  0.027042042464017868
Epoch:  106  	Training Loss: 0.026884227991104126
Test Loss:  0.021362856030464172
Valid Loss:  0.02703041210770607
Epoch:  107  	Training Loss: 0.026870818808674812
Test Loss:  0.021348167210817337
Valid Loss:  0.027018819004297256
Epoch:  108  	Training Loss: 0.02685745805501938
Test Loss:  0.021333524957299232
Valid Loss:  0.027007265016436577
Epoch:  109  	Training Loss: 0.026844145730137825
Test Loss:  0.021318934857845306
Valid Loss:  0.026995748281478882
Epoch:  110  	Training Loss: 0.026830878108739853
Test Loss:  0.02130439318716526
Valid Loss:  0.026984278112649918
Epoch:  111  	Training Loss: 0.02681766077876091
Test Loss:  0.021289974451065063
Valid Loss:  0.026972845196723938
Epoch:  112  	Training Loss: 0.02680448815226555
Test Loss:  0.021276133134961128
Valid Loss:  0.026961859315633774
Epoch:  113  	Training Loss: 0.02679181843996048
Test Loss:  0.021262340247631073
Valid Loss:  0.026950903236865997
Epoch:  114  	Training Loss: 0.02677919715642929
Test Loss:  0.021248631179332733
Valid Loss:  0.026940006762742996
Epoch:  115  	Training Loss: 0.026766648516058922
Test Loss:  0.021234963089227676
Valid Loss:  0.02692914754152298
Epoch:  116  	Training Loss: 0.026754144579172134
Test Loss:  0.021221347153186798
Valid Loss:  0.02691832184791565
Epoch:  117  	Training Loss: 0.02674167975783348
Test Loss:  0.021207768470048904
Valid Loss:  0.026907529681921005
Epoch:  118  	Training Loss: 0.02672925963997841
Test Loss:  0.021194245666265488
Valid Loss:  0.026896780356764793
Epoch:  119  	Training Loss: 0.02671687677502632
Test Loss:  0.021180758252739906
Valid Loss:  0.02688606269657612
Epoch:  120  	Training Loss: 0.02670455351471901
Test Loss:  0.021167360246181488
Valid Loss:  0.02687540091574192
Epoch:  121  	Training Loss: 0.026692286133766174
Test Loss:  0.021154001355171204
Valid Loss:  0.02686477079987526
Epoch:  122  	Training Loss: 0.026680056005716324
Test Loss:  0.021141059696674347
Valid Loss:  0.026854442432522774
Epoch:  123  	Training Loss: 0.02666819468140602
Test Loss:  0.021128155291080475
Valid Loss:  0.026844147592782974
Epoch:  124  	Training Loss: 0.026656368747353554
Test Loss:  0.021115299314260483
Valid Loss:  0.02683388441801071
Epoch:  125  	Training Loss: 0.02664458565413952
Test Loss:  0.021102484315633774
Valid Loss:  0.026823654770851135
Epoch:  126  	Training Loss: 0.026632843539118767
Test Loss:  0.02108972705900669
Valid Loss:  0.026813475415110588
Epoch:  127  	Training Loss: 0.02662113681435585
Test Loss:  0.02107701450586319
Valid Loss:  0.026803329586982727
Epoch:  128  	Training Loss: 0.026609469205141068
Test Loss:  0.02106434479355812
Valid Loss:  0.0267932191491127
Epoch:  129  	Training Loss: 0.02659784071147442
Test Loss:  0.021051716059446335
Valid Loss:  0.026783136650919914
Epoch:  130  	Training Loss: 0.026586253196001053
Test Loss:  0.021039124578237534
Valid Loss:  0.026773089542984962
Epoch:  131  	Training Loss: 0.02657470293343067
Test Loss:  0.021026574075222015
Valid Loss:  0.0267630722373724
Epoch:  132  	Training Loss: 0.026563189923763275
Test Loss:  0.02101433090865612
Valid Loss:  0.02675328217446804
Epoch:  133  	Training Loss: 0.026551954448223114
Test Loss:  0.02100212685763836
Valid Loss:  0.026743527501821518
Epoch:  134  	Training Loss: 0.02654075250029564
Test Loss:  0.020989952608942986
Valid Loss:  0.026733793318271637
Epoch:  135  	Training Loss: 0.026529585942626
Test Loss:  0.020977821201086044
Valid Loss:  0.026724092662334442
Epoch:  136  	Training Loss: 0.026518451049923897
Test Loss:  0.02096571959555149
Valid Loss:  0.026714418083429337
Epoch:  137  	Training Loss: 0.02650734968483448
Test Loss:  0.020953651517629623
Valid Loss:  0.02670476585626602
Epoch:  138  	Training Loss: 0.0264962837100029
Test Loss:  0.02094162628054619
Valid Loss:  0.026695139706134796
Epoch:  139  	Training Loss: 0.0264852587133646
Test Loss:  0.020929668098688126
Valid Loss:  0.026685576885938644
Epoch:  140  	Training Loss: 0.02647428587079048
Test Loss:  0.020917780697345734
Valid Loss:  0.026676056906580925
Epoch:  141  	Training Loss: 0.026463348418474197
Test Loss:  0.02090592309832573
Valid Loss:  0.026666564866900444
Epoch:  142  	Training Loss: 0.02645244263112545
Test Loss:  0.0208943709731102
Valid Loss:   29%|██▊       | 143/500 [01:40<04:58,  1.20it/s] 29%|██▉       | 145/500 [01:41<03:34,  1.66it/s] 29%|██▉       | 147/500 [01:41<02:36,  2.26it/s] 30%|██▉       | 149/500 [01:41<01:55,  3.04it/s] 30%|███       | 151/500 [01:47<06:45,  1.16s/it] 31%|███       | 153/500 [01:47<04:50,  1.20it/s] 31%|███       | 155/500 [01:47<03:28,  1.65it/s] 31%|███▏      | 157/500 [01:47<02:32,  2.26it/s] 32%|███▏      | 159/500 [01:48<01:52,  3.03it/s] 32%|███▏      | 161/500 [01:54<06:39,  1.18s/it] 33%|███▎      | 163/500 [01:54<04:45,  1.18it/s] 33%|███▎      | 165/500 [01:54<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:54<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:54<01:49,  3.01it/s] 34%|███▍      | 171/500 [02:01<06:21,  1.16s/it] 35%|███▍      | 173/500 [02:01<04:32,  1.20it/s] 35%|███▌      | 175/500 [02:01<03:15,  1.66it/s] 35%|███▌      | 177/500 [02:01<02:22,  2.27it/s] 36%|███▌      | 179/500 [02:01<01:45,  3.05it/s] 36%|███▌      | 181/500 [02:07<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:08<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:08<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:08<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:14<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:14<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:15<03:05,  1.65it/s] 39%|███▉      | 197/500 [02:15<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:15<01:39,  3.02it/s] 40%|████      | 201/500 [02:21<05:51,  1.18s/it] 41%|████      | 203/500 [02:21<04:10,  1.18it/s] 41%|████      | 205/500 [02:21<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:21<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:22<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:28<05:39,  1.18s/it]0.026657313108444214
Epoch:  143  	Training Loss: 0.026441816240549088
Test Loss:  0.020882850512862206
Valid Loss:  0.026648079976439476
Epoch:  144  	Training Loss: 0.026431221514940262
Test Loss:  0.020871367305517197
Valid Loss:  0.026638880372047424
Epoch:  145  	Training Loss: 0.026420660316944122
Test Loss:  0.020859917625784874
Valid Loss:  0.026629699394106865
Epoch:  146  	Training Loss: 0.026410125195980072
Test Loss:  0.02084849774837494
Valid Loss:  0.026620548218488693
Epoch:  147  	Training Loss: 0.026399627327919006
Test Loss:  0.02083711512386799
Valid Loss:  0.02661142125725746
Epoch:  148  	Training Loss: 0.02638915739953518
Test Loss:  0.020825758576393127
Valid Loss:  0.02660231478512287
Epoch:  149  	Training Loss: 0.026378720998764038
Test Loss:  0.0208144374191761
Valid Loss:  0.02659323811531067
Epoch:  150  	Training Loss: 0.026368312537670135
Test Loss:  0.020803149789571762
Valid Loss:  0.026584187522530556
Epoch:  151  	Training Loss: 0.026357941329479218
Test Loss:  0.020791981369256973
Valid Loss:  0.02657521702349186
Epoch:  152  	Training Loss: 0.026347635313868523
Test Loss:  0.020781036466360092
Valid Loss:  0.026566414162516594
Epoch:  153  	Training Loss: 0.026337528601288795
Test Loss:  0.0207701213657856
Valid Loss:  0.02655762992799282
Epoch:  154  	Training Loss: 0.026327449828386307
Test Loss:  0.02075923979282379
Valid Loss:  0.026548875495791435
Epoch:  155  	Training Loss: 0.026317400857806206
Test Loss:  0.020748388022184372
Valid Loss:  0.02654014714062214
Epoch:  156  	Training Loss: 0.02630738541483879
Test Loss:  0.02073756605386734
Valid Loss:  0.026531442999839783
Epoch:  157  	Training Loss: 0.026297401636838913
Test Loss:  0.020726775750517845
Valid Loss:  0.02652275376021862
Epoch:  158  	Training Loss: 0.026287443935871124
Test Loss:  0.020716015249490738
Valid Loss:  0.026514094322919846
Epoch:  159  	Training Loss: 0.026277516037225723
Test Loss:  0.02070528268814087
Valid Loss:  0.02650545723736286
Epoch:  160  	Training Loss: 0.026267623528838158
Test Loss:  0.020694587379693985
Valid Loss:  0.026496844366192818
Epoch:  161  	Training Loss: 0.026257755234837532
Test Loss:  0.02068391442298889
Valid Loss:  0.026488253846764565
Epoch:  162  	Training Loss: 0.026247914880514145
Test Loss:  0.020673517137765884
Valid Loss:  0.026479870080947876
Epoch:  163  	Training Loss: 0.026238296180963516
Test Loss:  0.020663142204284668
Valid Loss:  0.02647150680422783
Epoch:  164  	Training Loss: 0.026228703558444977
Test Loss:  0.020652800798416138
Valid Loss:  0.02646317332983017
Epoch:  165  	Training Loss: 0.026219144463539124
Test Loss:  0.020642485469579697
Valid Loss:  0.026454854756593704
Epoch:  166  	Training Loss: 0.02620960772037506
Test Loss:  0.020632203668355942
Valid Loss:  0.026446551084518433
Epoch:  167  	Training Loss: 0.026200098916888237
Test Loss:  0.020621944218873978
Valid Loss:  0.026438280940055847
Epoch:  168  	Training Loss: 0.026190616190433502
Test Loss:  0.020611710846424103
Valid Loss:  0.026430029422044754
Epoch:  169  	Training Loss: 0.026181165128946304
Test Loss:  0.020601511001586914
Valid Loss:  0.026421790942549706
Epoch:  170  	Training Loss: 0.026171738281846046
Test Loss:  0.020591337233781815
Valid Loss:  0.026413580402731895
Epoch:  171  	Training Loss: 0.026162337511777878
Test Loss:  0.020581185817718506
Valid Loss:  0.026405390352010727
Epoch:  172  	Training Loss: 0.026152964681386948
Test Loss:  0.020571202039718628
Valid Loss:  0.026397312059998512
Epoch:  173  	Training Loss: 0.026143738999962807
Test Loss:  0.02056124620139599
Valid Loss:  0.026389265432953835
Epoch:  174  	Training Loss: 0.026134539395570755
Test Loss:  0.020551318302750587
Valid Loss:  0.026381226256489754
Epoch:  175  	Training Loss: 0.026125362142920494
Test Loss:  0.020541414618492126
Valid Loss:  0.02637321501970291
Epoch:  176  	Training Loss: 0.02611621655523777
Test Loss:  0.020531535148620605
Valid Loss:  0.026365220546722412
Epoch:  177  	Training Loss: 0.02610708773136139
Test Loss:  0.020521681755781174
Valid Loss:  0.026357240974903107
Epoch:  178  	Training Loss: 0.026097988709807396
Test Loss:  0.02051185443997383
Valid Loss:  0.02634928561747074
Epoch:  179  	Training Loss: 0.026088912039995193
Test Loss:  0.02050204947590828
Valid Loss:  0.02634134516119957
Epoch:  180  	Training Loss: 0.02607986144721508
Test Loss:  0.02049226686358452
Valid Loss:  0.02633342519402504
Epoch:  181  	Training Loss: 0.026070833206176758
Test Loss:  0.020482514053583145
Valid Loss:  0.02632552571594715
Epoch:  182  	Training Loss: 0.026061829179525375
Test Loss:  0.020472940057516098
Valid Loss:  0.026317786425352097
Epoch:  183  	Training Loss: 0.02605300396680832
Test Loss:  0.020463386550545692
Valid Loss:  0.026310071349143982
Epoch:  184  	Training Loss: 0.026044201105833054
Test Loss:  0.020453859120607376
Valid Loss:  0.02630237117409706
Epoch:  185  	Training Loss: 0.02603542059659958
Test Loss:  0.02044435776770115
Valid Loss:  0.02629469335079193
Epoch:  186  	Training Loss: 0.026026666164398193
Test Loss:  0.020434871315956116
Valid Loss:  0.026287026703357697
Epoch:  187  	Training Loss: 0.0260179303586483
Test Loss:  0.02042541280388832
Valid Loss:  0.026279374957084656
Epoch:  188  	Training Loss: 0.026009220629930496
Test Loss:  0.020415980368852615
Valid Loss:  0.026271749287843704
Epoch:  189  	Training Loss: 0.026000533252954483
Test Loss:  0.020406566560268402
Valid Loss:  0.026264134794473648
Epoch:  190  	Training Loss: 0.02599186822772026
Test Loss:  0.020397178828716278
Valid Loss:  0.026256538927555084
Epoch:  191  	Training Loss: 0.02598322369158268
Test Loss:  0.020387809723615646
Valid Loss:  0.02624896541237831
Epoch:  192  	Training Loss: 0.02597460150718689
Test Loss:  0.02037857472896576
Valid Loss:  0.026241464540362358
Epoch:  193  	Training Loss: 0.025966081768274307
Test Loss:  0.020369360223412514
Valid Loss:  0.026233984157443047
Epoch:  194  	Training Loss: 0.025957584381103516
Test Loss:  0.020360171794891357
Valid Loss:  0.02622651681303978
Epoch:  195  	Training Loss: 0.02594911679625511
Test Loss:  0.02035105600953102
Valid Loss:  0.02621910348534584
Epoch:  196  	Training Loss: 0.025940682739019394
Test Loss:  0.02034197747707367
Valid Loss:  0.026211708784103394
Epoch:  197  	Training Loss: 0.025932271033525467
Test Loss:  0.020332930609583855
Valid Loss:  0.026204321533441544
Epoch:  198  	Training Loss: 0.025923877954483032
Test Loss:  0.020323939621448517
Valid Loss:  0.02619699388742447
Epoch:  199  	Training Loss: 0.025915518403053284
Test Loss:  0.02031496912240982
Valid Loss:  0.026189669966697693
Epoch:  200  	Training Loss: 0.02590717002749443
Test Loss:  0.020306020975112915
Valid Loss:  0.026182377710938454
Epoch:  201  	Training Loss: 0.025898853316903114
Test Loss:  0.02029709331691265
Valid Loss:  0.026175085455179214
Epoch:  202  	Training Loss: 0.02589055523276329
Test Loss:  0.02028827555477619
Valid Loss:  0.02616788260638714
Epoch:  203  	Training Loss: 0.02588234283030033
Test Loss:  0.020279470831155777
Valid Loss:  0.026160690933465958
Epoch:  204  	Training Loss: 0.025874154642224312
Test Loss:  0.020270690321922302
Valid Loss:  0.02615351788699627
Epoch:  205  	Training Loss: 0.025865986943244934
Test Loss:  0.02026192843914032
Valid Loss:  0.026146357879042625
Epoch:  206  	Training Loss: 0.0258578360080719
Test Loss:  0.020253192633390427
Valid Loss:  0.026139218360185623
Epoch:  207  	Training Loss: 0.025849709287285805
Test Loss:  0.020244475454092026
Valid Loss:  0.026132088154554367
Epoch:  208  	Training Loss: 0.0258416049182415
Test Loss:  0.020235782489180565
Valid Loss:  0.026124978438019753
Epoch:  209  	Training Loss: 0.02583351917564869
Test Loss:  0.020227104425430298
Valid Loss:  0.026117876172065735
Epoch:  210  	Training Loss: 0.02582544833421707
Test Loss:  0.02021845057606697
Valid Loss:  0.02611079439520836
Epoch:  211  	Training Loss: 0.025817403569817543
Test Loss:  0.020209817215800285
Valid Loss:  0.026103731244802475
Epoch:  212  	Training Loss: 0.025809377431869507
Test Loss:  0.020201247185468674
Valid Loss:  0.026096699759364128
Epoch:  213  	Training Loss: 0.0258013978600502
 43%|████▎     | 213/500 [02:28<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:28<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:28<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:28<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:35<05:25,  1.17s/it] 45%|████▍     | 223/500 [02:35<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:35<02:46,  1.66it/s] 45%|████▌     | 227/500 [02:35<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:35<01:28,  3.05it/s] 46%|████▌     | 231/500 [02:42<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:42<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:42<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:42<01:58,  2.23it/s] 48%|████▊     | 239/500 [02:42<01:27,  2.99it/s] 48%|████▊     | 241/500 [02:48<05:02,  1.17s/it] 49%|████▊     | 243/500 [02:48<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:49<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:49<01:52,  2.25it/s] 50%|████▉     | 249/500 [02:49<01:22,  3.04it/s] 50%|█████     | 251/500 [02:55<04:50,  1.17s/it] 51%|█████     | 253/500 [02:55<03:26,  1.19it/s] 51%|█████     | 255/500 [02:55<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:55<01:47,  2.25it/s] 52%|█████▏    | 259/500 [02:56<01:19,  3.03it/s] 52%|█████▏    | 261/500 [03:02<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:02<03:18,  1.20it/s] 53%|█████▎    | 265/500 [03:02<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:02<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:02<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:08<04:24,  1.16s/it] 55%|█████▍    | 273/500 [03:09<03:08,  1.20it/s] 55%|█████▌    | 275/500 [03:09<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:09<01:38,  2.27it/s] 56%|█████▌    | 279/500 [03:09<01:12,  3.06it/s] 56%|█████▌    | 281/500 [03:15<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:15<03:01,  1.19it/s]Test Loss:  0.020192693918943405
Valid Loss:  0.026089686900377274
Epoch:  214  	Training Loss: 0.025793440639972687
Test Loss:  0.020184161141514778
Valid Loss:  0.026082687079906464
Epoch:  215  	Training Loss: 0.025785496458411217
Test Loss:  0.020175646990537643
Valid Loss:  0.026075702160596848
Epoch:  216  	Training Loss: 0.025777574628591537
Test Loss:  0.02016715332865715
Valid Loss:  0.026068732142448425
Epoch:  217  	Training Loss: 0.0257696695625782
Test Loss:  0.02015867829322815
Valid Loss:  0.0260617733001709
Epoch:  218  	Training Loss: 0.025761786848306656
Test Loss:  0.02015022560954094
Valid Loss:  0.026054827496409416
Epoch:  219  	Training Loss: 0.025753919035196304
Test Loss:  0.020141787827014923
Valid Loss:  0.026047898456454277
Epoch:  220  	Training Loss: 0.025746073573827744
Test Loss:  0.02013337053358555
Valid Loss:  0.02604098431766033
Epoch:  221  	Training Loss: 0.025738243013620377
Test Loss:  0.020124973729252815
Valid Loss:  0.026034079492092133
Epoch:  222  	Training Loss: 0.02573043294250965
Test Loss:  0.020116697996854782
Valid Loss:  0.02602727711200714
Epoch:  223  	Training Loss: 0.025722727179527283
Test Loss:  0.020108435302972794
Valid Loss:  0.026020491495728493
Epoch:  224  	Training Loss: 0.025715041905641556
Test Loss:  0.020100196823477745
Valid Loss:  0.02601371705532074
Epoch:  225  	Training Loss: 0.02570737525820732
Test Loss:  0.02009197697043419
Valid Loss:  0.02600695565342903
Epoch:  226  	Training Loss: 0.02569972351193428
Test Loss:  0.020083773881196976
Valid Loss:  0.026000214740633965
Epoch:  227  	Training Loss: 0.02569209411740303
Test Loss:  0.020075593143701553
Valid Loss:  0.025993481278419495
Epoch:  228  	Training Loss: 0.025684479624032974
Test Loss:  0.020067423582077026
Valid Loss:  0.025986751541495323
Epoch:  229  	Training Loss: 0.02567688189446926
Test Loss:  0.02005927264690399
Valid Loss:  0.02598004974424839
Epoch:  230  	Training Loss: 0.02566930465400219
Test Loss:  0.020051144063472748
Valid Loss:  0.025973357260227203
Epoch:  231  	Training Loss: 0.025661742314696312
Test Loss:  0.020043030381202698
Valid Loss:  0.025966674089431763
Epoch:  232  	Training Loss: 0.025654198601841927
Test Loss:  0.020035026594996452
Valid Loss:  0.025960076600313187
Epoch:  233  	Training Loss: 0.025646742433309555
Test Loss:  0.020027033984661102
Valid Loss:  0.025953490287065506
Epoch:  234  	Training Loss: 0.025639303028583527
Test Loss:  0.02001906745135784
Valid Loss:  0.02594691887497902
Epoch:  235  	Training Loss: 0.02563188225030899
Test Loss:  0.020011117681860924
Valid Loss:  0.025940366089344025
Epoch:  236  	Training Loss: 0.025624480098485947
Test Loss:  0.02000318467617035
Valid Loss:  0.025933820754289627
Epoch:  237  	Training Loss: 0.025617092847824097
Test Loss:  0.019995268434286118
Valid Loss:  0.025927282869815826
Epoch:  238  	Training Loss: 0.02560972049832344
Test Loss:  0.01998738758265972
Valid Loss:  0.025920763611793518
Epoch:  239  	Training Loss: 0.025602372363209724
Test Loss:  0.019979555159807205
Valid Loss:  0.025914285331964493
Epoch:  240  	Training Loss: 0.02559504844248295
Test Loss:  0.01997174136340618
Valid Loss:  0.02590782567858696
Epoch:  241  	Training Loss: 0.025587745010852814
Test Loss:  0.019963938742876053
Valid Loss:  0.025901373475790024
Epoch:  242  	Training Loss: 0.025580456480383873
Test Loss:  0.019956272095441818
Valid Loss:  0.02589501440525055
Epoch:  243  	Training Loss: 0.025573261082172394
Test Loss:  0.019948624074459076
Valid Loss:  0.025888662785291672
Epoch:  244  	Training Loss: 0.025566086173057556
Test Loss:  0.019940992817282677
Valid Loss:  0.025882327929139137
Epoch:  245  	Training Loss: 0.025558926165103912
Test Loss:  0.01993338204920292
Valid Loss:  0.02587600238621235
Epoch:  246  	Training Loss: 0.025551779195666313
Test Loss:  0.019925788044929504
Valid Loss:  0.025869689881801605
Epoch:  247  	Training Loss: 0.025544650852680206
Test Loss:  0.019918212667107582
Valid Loss:  0.025863390415906906
Epoch:  248  	Training Loss: 0.025537539273500443
Test Loss:  0.019910652190446854
Valid Loss:  0.0258571058511734
Epoch:  249  	Training Loss: 0.025530442595481873
Test Loss:  0.019903108477592468
Valid Loss:  0.025850828737020493
Epoch:  250  	Training Loss: 0.025523364543914795
Test Loss:  0.019895583391189575
Valid Loss:  0.025844566524028778
Epoch:  251  	Training Loss: 0.02551630139350891
Test Loss:  0.019888076931238174
Valid Loss:  0.02583831548690796
Epoch:  252  	Training Loss: 0.02550925314426422
Test Loss:  0.019880877807736397
Valid Loss:  0.025832295417785645
Epoch:  253  	Training Loss: 0.02550247497856617
Test Loss:  0.01987369917333126
Valid Loss:  0.025826288387179375
Epoch:  254  	Training Loss: 0.025495707988739014
Test Loss:  0.01986653544008732
Valid Loss:  0.02582029066979885
Epoch:  255  	Training Loss: 0.0254889614880085
Test Loss:  0.01985938847064972
Valid Loss:  0.025814302265644073
Epoch:  256  	Training Loss: 0.02548222430050373
Test Loss:  0.01985226385295391
Valid Loss:  0.02580833248794079
Epoch:  257  	Training Loss: 0.025475505739450455
Test Loss:  0.01984516903758049
Valid Loss:  0.025802364572882652
Epoch:  258  	Training Loss: 0.025468800216913223
Test Loss:  0.01983809284865856
Valid Loss:  0.02579641155898571
Epoch:  259  	Training Loss: 0.025462111458182335
Test Loss:  0.019831031560897827
Valid Loss:  0.025790469720959663
Epoch:  260  	Training Loss: 0.025455433875322342
Test Loss:  0.019823983311653137
Valid Loss:  0.025784537196159363
Epoch:  261  	Training Loss: 0.025448773056268692
Test Loss:  0.01981695368885994
Valid Loss:  0.025778621435165405
Epoch:  262  	Training Loss: 0.025442125275731087
Test Loss:  0.01981046423316002
Valid Loss:  0.02577310800552368
Epoch:  263  	Training Loss: 0.02543596923351288
Test Loss:  0.019803989678621292
Valid Loss:  0.025767609477043152
Epoch:  264  	Training Loss: 0.025429824367165565
Test Loss:  0.01979752443730831
Valid Loss:  0.02576211467385292
Epoch:  265  	Training Loss: 0.025423690676689148
Test Loss:  0.019791068509221077
Valid Loss:  0.025756629183888435
Epoch:  266  	Training Loss: 0.025417566299438477
Test Loss:  0.019784627482295036
Valid Loss:  0.025751156732439995
Epoch:  267  	Training Loss: 0.025411456823349
Test Loss:  0.01977820321917534
Valid Loss:  0.025745684280991554
Epoch:  268  	Training Loss: 0.025405358523130417
Test Loss:  0.019771786406636238
Valid Loss:  0.02574022114276886
Epoch:  269  	Training Loss: 0.02539926767349243
Test Loss:  0.01976538449525833
Valid Loss:  0.02573477476835251
Epoch:  270  	Training Loss: 0.025393187999725342
Test Loss:  0.019758984446525574
Valid Loss:  0.025729328393936157
Epoch:  271  	Training Loss: 0.025387119501829147
Test Loss:  0.019752610474824905
Valid Loss:  0.025723885744810104
Epoch:  272  	Training Loss: 0.02538106217980385
Test Loss:  0.019746877253055573
Valid Loss:  0.025718964636325836
Epoch:  273  	Training Loss: 0.025375600904226303
Test Loss:  0.019741147756576538
Valid Loss:  0.025714047253131866
Epoch:  274  	Training Loss: 0.025370150804519653
Test Loss:  0.01973543129861355
Valid Loss:  0.025709129869937897
Epoch:  275  	Training Loss: 0.0253647081553936
Test Loss:  0.019729724153876305
Valid Loss:  0.025704221799969673
Epoch:  276  	Training Loss: 0.025359271094202995
Test Loss:  0.01972402259707451
Valid Loss:  0.025699319317936897
Epoch:  277  	Training Loss: 0.025353845208883286
Test Loss:  0.019718334078788757
Valid Loss:  0.025694428011775017
Epoch:  278  	Training Loss: 0.025348426774144173
Test Loss:  0.01971265859901905
Valid Loss:  0.025689538568258286
Epoch:  279  	Training Loss: 0.025343017652630806
Test Loss:  0.019706983119249344
Valid Loss:  0.025684650987386703
Epoch:  280  	Training Loss: 0.025337614119052887
Test Loss:  0.019701318815350533
Valid Loss:  0.025679774582386017
Epoch:  281  	Training Loss: 0.025332221761345863
Test Loss:  0.019695669412612915
Valid Loss:  0.02567489817738533
Epoch:  282  	Training Loss: 0.025326836854219437
Test Loss:  0.01969049498438835
Valid Loss:  0.025670386850833893
Epoch:  283  	Training Loss: 0.025321878492832184
Test Loss:  0.019685331732034683
Valid Loss:  0.02566591091454029
 57%|█████▋    | 285/500 [03:16<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:16<01:34,  2.26it/s] 58%|█████▊    | 289/500 [03:16<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:22<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:22<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:22<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:23<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:23<01:07,  2.99it/s] 60%|██████    | 301/500 [03:29<03:55,  1.19s/it] 61%|██████    | 303/500 [03:29<02:47,  1.17it/s] 61%|██████    | 305/500 [03:29<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:29<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:30<01:03,  2.98it/s] 62%|██████▏   | 311/500 [03:36<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:36<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:36<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:36<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:36<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:43<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:43<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:43<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:43<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:43<00:56,  3.00it/s] 66%|██████▌   | 331/500 [03:49<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:50<02:19,  1.19it/s] 67%|██████▋   | 335/500 [03:50<01:40,  1.65it/s] 67%|██████▋   | 337/500 [03:50<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:50<00:53,  3.03it/s] 68%|██████▊   | 341/500 [03:56<03:06,  1.17s/it] 69%|██████▊   | 343/500 [03:56<02:12,  1.19it/s] 69%|██████▉   | 345/500 [03:56<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:57<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:57<00:50,  3.01it/s] 70%|███████   | 351/500 [04:03<02:53,  1.17s/it] 71%|███████   | 353/500 [04:03<02:03,  1.19it/s]Epoch:  284  	Training Loss: 0.025316938757896423
Test Loss:  0.01968017965555191
Valid Loss:  0.025661436840891838
Epoch:  285  	Training Loss: 0.02531200274825096
Test Loss:  0.019675038754940033
Valid Loss:  0.025656968355178833
Epoch:  286  	Training Loss: 0.025307074189186096
Test Loss:  0.019669899716973305
Valid Loss:  0.025652503594756126
Epoch:  287  	Training Loss: 0.025302153080701828
Test Loss:  0.019664768129587173
Valid Loss:  0.025648046284914017
Epoch:  288  	Training Loss: 0.025297237560153008
Test Loss:  0.01965964585542679
Valid Loss:  0.025643587112426758
Epoch:  289  	Training Loss: 0.025292325764894485
Test Loss:  0.0196545347571373
Valid Loss:  0.025639139115810394
Epoch:  290  	Training Loss: 0.02528742514550686
Test Loss:  0.01964942365884781
Valid Loss:  0.02563469111919403
Epoch:  291  	Training Loss: 0.02528253197669983
Test Loss:  0.019644320011138916
Valid Loss:  0.025630252435803413
Epoch:  292  	Training Loss: 0.02527764067053795
Test Loss:  0.0196395106613636
Valid Loss:  0.0256260484457016
Epoch:  293  	Training Loss: 0.025273021310567856
Test Loss:  0.019634712487459183
Valid Loss:  0.025621861219406128
Epoch:  294  	Training Loss: 0.02526841126382351
Test Loss:  0.019629912450909615
Valid Loss:  0.02561767026782036
Epoch:  295  	Training Loss: 0.02526380494236946
Test Loss:  0.019625123590230942
Valid Loss:  0.025613486766815186
Epoch:  296  	Training Loss: 0.02525920607149601
Test Loss:  0.01962035335600376
Valid Loss:  0.02560933493077755
Epoch:  297  	Training Loss: 0.025254618376493454
Test Loss:  0.01961558684706688
Valid Loss:  0.02560518868267536
Epoch:  298  	Training Loss: 0.025250039994716644
Test Loss:  0.019610822200775146
Valid Loss:  0.025601042434573174
Epoch:  299  	Training Loss: 0.025245465338230133
Test Loss:  0.019606079906225204
Valid Loss:  0.025596939027309418
Epoch:  300  	Training Loss: 0.025240901857614517
Test Loss:  0.019601348787546158
Valid Loss:  0.025592869147658348
Epoch:  301  	Training Loss: 0.025236347690224648
Test Loss:  0.019596628844738007
Valid Loss:  0.025588801130652428
Epoch:  302  	Training Loss: 0.025231804698705673
Test Loss:  0.019592054188251495
Valid Loss:  0.025584839284420013
Epoch:  303  	Training Loss: 0.0252273790538311
Test Loss:  0.019587483257055283
Valid Loss:  0.0255808774381876
Epoch:  304  	Training Loss: 0.025222957134246826
Test Loss:  0.019582923501729965
Valid Loss:  0.025576921179890633
Epoch:  305  	Training Loss: 0.025218546390533447
Test Loss:  0.019578367471694946
Valid Loss:  0.025572974234819412
Epoch:  306  	Training Loss: 0.025214141234755516
Test Loss:  0.019573820754885674
Valid Loss:  0.02556902915239334
Epoch:  307  	Training Loss: 0.025209739804267883
Test Loss:  0.0195692740380764
Valid Loss:  0.02556508034467697
Epoch:  308  	Training Loss: 0.025205345824360847
Test Loss:  0.019564738497138023
Valid Loss:  0.025561146438121796
Epoch:  309  	Training Loss: 0.02520095556974411
Test Loss:  0.019560206681489944
Valid Loss:  0.02555720880627632
Epoch:  310  	Training Loss: 0.02519657276570797
Test Loss:  0.01955568417906761
Valid Loss:  0.025553282350301743
Epoch:  311  	Training Loss: 0.025192193686962128
Test Loss:  0.019551165401935577
Valid Loss:  0.025549355894327164
Epoch:  312  	Training Loss: 0.025187823921442032
Test Loss:  0.019546708092093468
Valid Loss:  0.025545479729771614
Epoch:  313  	Training Loss: 0.025183510035276413
Test Loss:  0.019542254507541656
Valid Loss:  0.02554161287844181
Epoch:  314  	Training Loss: 0.025179199874401093
Test Loss:  0.019537806510925293
Valid Loss:  0.02553774043917656
Epoch:  315  	Training Loss: 0.02517489716410637
Test Loss:  0.019533365964889526
Valid Loss:  0.025533877313137054
Epoch:  316  	Training Loss: 0.025170598179101944
Test Loss:  0.019528929144144058
Valid Loss:  0.02553001418709755
Epoch:  317  	Training Loss: 0.025166302919387817
Test Loss:  0.01952449604868889
Valid Loss:  0.02552615851163864
Epoch:  318  	Training Loss: 0.025162016972899437
Test Loss:  0.019520077854394913
Valid Loss:  0.025522306561470032
Epoch:  319  	Training Loss: 0.025157738476991653
Test Loss:  0.019515659660100937
Valid Loss:  0.02551845833659172
Epoch:  320  	Training Loss: 0.02515346184372902
Test Loss:  0.019511239603161812
Valid Loss:  0.02551461011171341
Epoch:  321  	Training Loss: 0.025149187073111534
Test Loss:  0.01950683817267418
Valid Loss:  0.025510765612125397
Epoch:  322  	Training Loss: 0.025144919753074646
Test Loss:  0.01950250193476677
Valid Loss:  0.025506993755698204
Epoch:  323  	Training Loss: 0.025140728801488876
Test Loss:  0.019498169422149658
Valid Loss:  0.02550322748720646
Epoch:  324  	Training Loss: 0.025136535987257957
Test Loss:  0.019493846222758293
Valid Loss:  0.025499463081359863
Epoch:  325  	Training Loss: 0.025132352486252785
Test Loss:  0.019489524886012077
Valid Loss:  0.025495707988739014
Epoch:  326  	Training Loss: 0.02512817457318306
Test Loss:  0.01948521099984646
Valid Loss:  0.025491952896118164
Epoch:  327  	Training Loss: 0.025124000385403633
Test Loss:  0.019480904564261436
Valid Loss:  0.025488197803497314
Epoch:  328  	Training Loss: 0.025119829922914505
Test Loss:  0.019476599991321564
Valid Loss:  0.025484450161457062
Epoch:  329  	Training Loss: 0.025115665048360825
Test Loss:  0.019472304731607437
Valid Loss:  0.02548070251941681
Epoch:  330  	Training Loss: 0.025111505761742592
Test Loss:  0.01946800760924816
Valid Loss:  0.025476962327957153
Epoch:  331  	Training Loss: 0.025107353925704956
Test Loss:  0.01946372352540493
Valid Loss:  0.025473223999142647
Epoch:  332  	Training Loss: 0.02510320208966732
Test Loss:  0.019459497183561325
Valid Loss:  0.025469526648521423
Epoch:  333  	Training Loss: 0.025099102407693863
Test Loss:  0.01945527456700802
Valid Loss:  0.02546583116054535
Epoch:  334  	Training Loss: 0.025095010176301003
Test Loss:  0.019451070576906204
Valid Loss:  0.025462165474891663
Epoch:  335  	Training Loss: 0.02509091980755329
Test Loss:  0.019446872174739838
Valid Loss:  0.025458497926592827
Epoch:  336  	Training Loss: 0.025086835026741028
Test Loss:  0.019442681223154068
Valid Loss:  0.025454839691519737
Epoch:  337  	Training Loss: 0.025082755833864212
Test Loss:  0.019438486546278
Valid Loss:  0.025451187044382095
Epoch:  338  	Training Loss: 0.025078684091567993
Test Loss:  0.01943429559469223
Valid Loss:  0.025447512045502663
Epoch:  339  	Training Loss: 0.025074616074562073
Test Loss:  0.019430115818977356
Valid Loss:  0.02544386312365532
Epoch:  340  	Training Loss: 0.02507055178284645
Test Loss:  0.01942594349384308
Valid Loss:  0.025440217927098274
Epoch:  341  	Training Loss: 0.02506648749113083
Test Loss:  0.01942177303135395
Valid Loss:  0.02543657086789608
Epoch:  342  	Training Loss: 0.025062434375286102
Test Loss:  0.019417688250541687
Valid Loss:  0.0254330076277256
Epoch:  343  	Training Loss: 0.025058461353182793
Test Loss:  0.019413607195019722
Valid Loss:  0.02542944625020027
Epoch:  344  	Training Loss: 0.02505449578166008
Test Loss:  0.019409533590078354
Valid Loss:  0.02542588859796524
Epoch:  345  	Training Loss: 0.025050532072782516
Test Loss:  0.019405458122491837
Valid Loss:  0.02542233094573021
Epoch:  346  	Training Loss: 0.02504657581448555
Test Loss:  0.019401395693421364
Valid Loss:  0.025418780744075775
Epoch:  347  	Training Loss: 0.025042623281478882
Test Loss:  0.01939733512699604
Valid Loss:  0.02541523054242134
Epoch:  348  	Training Loss: 0.025038670748472214
Test Loss:  0.019393276423215866
Valid Loss:  0.025411687791347504
Epoch:  349  	Training Loss: 0.02503472939133644
Test Loss:  0.019389230757951736
Valid Loss:  0.025408145040273666
Epoch:  350  	Training Loss: 0.02503078803420067
Test Loss:  0.01938518136739731
Valid Loss:  0.025404607877135277
Epoch:  351  	Training Loss: 0.025026854127645493
Test Loss:  0.019381139427423477
Valid Loss:  0.025401072576642036
Epoch:  352  	Training Loss: 0.025022925809025764
Test Loss:  0.019377101212739944
Valid Loss:  0.02539752796292305
Epoch:  353  	Training Loss: 0.02501899003982544
Test Loss:  0.019373059272766113
Valid Loss:  0.02539398893713951
Epoch:  354  	Training Loss: 0.025015059858560562
Test Loss:  0.019369032233953476 71%|███████   | 355/500 [04:03<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:03<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:04<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:10<02:41,  1.16s/it] 73%|███████▎  | 363/500 [04:10<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:10<01:21,  1.66it/s] 73%|███████▎  | 367/500 [04:10<00:58,  2.26it/s] 74%|███████▍  | 369/500 [04:10<00:43,  3.04it/s] 74%|███████▍  | 371/500 [04:17<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:17<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:17<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:17<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:17<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:23<02:17,  1.15s/it] 77%|███████▋  | 383/500 [04:23<01:37,  1.21it/s] 77%|███████▋  | 385/500 [04:24<01:09,  1.66it/s] 77%|███████▋  | 387/500 [04:24<00:49,  2.26it/s] 78%|███████▊  | 389/500 [04:24<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:30<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:30<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:30<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:31<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:31<00:33,  2.99it/s] 80%|████████  | 401/500 [04:37<01:56,  1.18s/it] 81%|████████  | 403/500 [04:37<01:22,  1.18it/s] 81%|████████  | 405/500 [04:37<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:37<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:38<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:44<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:44<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:44<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:44<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:44<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:51<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:51<01:04,  1.20it/s]
Valid Loss:  0.025390449911355972
Epoch:  355  	Training Loss: 0.025011137127876282
Test Loss:  0.01936500146985054
Valid Loss:  0.02538692206144333
Epoch:  356  	Training Loss: 0.025007214397192
Test Loss:  0.019360976293683052
Valid Loss:  0.02538338303565979
Epoch:  357  	Training Loss: 0.02500329539179802
Test Loss:  0.01935695856809616
Valid Loss:  0.025379857048392296
Epoch:  358  	Training Loss: 0.024999380111694336
Test Loss:  0.01935294084250927
Valid Loss:  0.025376329198479652
Epoch:  359  	Training Loss: 0.0249954704195261
Test Loss:  0.019348928704857826
Valid Loss:  0.025372806936502457
Epoch:  360  	Training Loss: 0.024991564452648163
Test Loss:  0.01934492588043213
Valid Loss:  0.02536928653717041
Epoch:  361  	Training Loss: 0.024987664073705673
Test Loss:  0.019340921193361282
Valid Loss:  0.025365768000483513
Epoch:  362  	Training Loss: 0.024983765557408333
Test Loss:  0.019337011501193047
Valid Loss:  0.025362327694892883
Epoch:  363  	Training Loss: 0.024979952722787857
Test Loss:  0.01933310367166996
Valid Loss:  0.025358885526657104
Epoch:  364  	Training Loss: 0.024976147338747978
Test Loss:  0.01932920143008232
Valid Loss:  0.02535545639693737
Epoch:  365  	Training Loss: 0.0249723419547081
Test Loss:  0.01932530663907528
Valid Loss:  0.025352023541927338
Epoch:  366  	Training Loss: 0.024968545883893967
Test Loss:  0.019321411848068237
Valid Loss:  0.025348592549562454
Epoch:  367  	Training Loss: 0.024964751675724983
Test Loss:  0.019317522644996643
Valid Loss:  0.02534516714513302
Epoch:  368  	Training Loss: 0.024960961192846298
Test Loss:  0.019313639029860497
Valid Loss:  0.02534174546599388
Epoch:  369  	Training Loss: 0.024957172572612762
Test Loss:  0.01930975914001465
Valid Loss:  0.025338325649499893
Epoch:  370  	Training Loss: 0.024953389540314674
Test Loss:  0.019305884838104248
Valid Loss:  0.025334907695651054
Epoch:  371  	Training Loss: 0.024949612095952034
Test Loss:  0.019302010536193848
Valid Loss:  0.025331486016511917
Epoch:  372  	Training Loss: 0.024945836514234543
Test Loss:  0.019298193976283073
Valid Loss:  0.025328125804662704
Epoch:  373  	Training Loss: 0.024942118674516678
Test Loss:  0.019294388592243195
Valid Loss:  0.02532476931810379
Epoch:  374  	Training Loss: 0.02493840456008911
Test Loss:  0.019290588796138763
Valid Loss:  0.025321416556835175
Epoch:  375  	Training Loss: 0.02493470162153244
Test Loss:  0.019286789000034332
Valid Loss:  0.02531806193292141
Epoch:  376  	Training Loss: 0.02493099495768547
Test Loss:  0.0192829929292202
Valid Loss:  0.025314707309007645
Epoch:  377  	Training Loss: 0.0249272920191288
Test Loss:  0.019279202446341515
Valid Loss:  0.025311365723609924
Epoch:  378  	Training Loss: 0.024923594668507576
Test Loss:  0.019275417551398277
Valid Loss:  0.025308016687631607
Epoch:  379  	Training Loss: 0.02491990104317665
Test Loss:  0.019271638244390488
Valid Loss:  0.025304673239588737
Epoch:  380  	Training Loss: 0.024916213005781174
Test Loss:  0.01926785707473755
Valid Loss:  0.025301337242126465
Epoch:  381  	Training Loss: 0.024912528693675995
Test Loss:  0.019264081493020058
Valid Loss:  0.025297995656728745
Epoch:  382  	Training Loss: 0.024908846244215965
Test Loss:  0.019260350614786148
Valid Loss:  0.025294698774814606
Epoch:  383  	Training Loss: 0.024905206635594368
Test Loss:  0.019256627187132835
Valid Loss:  0.02529139816761017
Epoch:  384  	Training Loss: 0.02490156702697277
Test Loss:  0.019252903759479523
Valid Loss:  0.025288105010986328
Epoch:  385  	Training Loss: 0.02489793486893177
Test Loss:  0.019249189645051956
Valid Loss:  0.02528480999171734
Epoch:  386  	Training Loss: 0.02489430457353592
Test Loss:  0.019245468080043793
Valid Loss:  0.025281518697738647
Epoch:  387  	Training Loss: 0.024890676140785217
Test Loss:  0.019241761416196823
Valid Loss:  0.025278227403759956
Epoch:  388  	Training Loss: 0.024887051433324814
Test Loss:  0.019238052889704704
Valid Loss:  0.025274943560361862
Epoch:  389  	Training Loss: 0.024883432313799858
Test Loss:  0.019234349951148033
Valid Loss:  0.02527165599167347
Epoch:  390  	Training Loss: 0.0248798169195652
Test Loss:  0.019230656325817108
Valid Loss:  0.025268377736210823
Epoch:  391  	Training Loss: 0.02487620711326599
Test Loss:  0.019226960837841034
Valid Loss:  0.025265097618103027
Epoch:  392  	Training Loss: 0.02487259916961193
Test Loss:  0.019223298877477646
Valid Loss:  0.02526184730231762
Epoch:  393  	Training Loss: 0.024869021028280258
Test Loss:  0.019219642505049706
Valid Loss:  0.02525859698653221
Epoch:  394  	Training Loss: 0.024865444749593735
Test Loss:  0.019215991720557213
Valid Loss:  0.025255346670746803
Epoch:  395  	Training Loss: 0.02486187219619751
Test Loss:  0.01921233721077442
Valid Loss:  0.025252100080251694
Epoch:  396  	Training Loss: 0.024858303368091583
Test Loss:  0.019208692014217377
Valid Loss:  0.025248857215046883
Epoch:  397  	Training Loss: 0.024854741990566254
Test Loss:  0.019205056130886078
Valid Loss:  0.02524561434984207
Epoch:  398  	Training Loss: 0.024851176887750626
Test Loss:  0.01920141652226448
Valid Loss:  0.025242380797863007
Epoch:  399  	Training Loss: 0.024847619235515594
Test Loss:  0.019197778776288033
Valid Loss:  0.02523915469646454
Epoch:  400  	Training Loss: 0.024844063445925713
Test Loss:  0.01919415220618248
Valid Loss:  0.02523592859506607
Epoch:  401  	Training Loss: 0.024840515106916428
Test Loss:  0.019190525636076927
Valid Loss:  0.025232704356312752
Epoch:  402  	Training Loss: 0.024836968630552292
Test Loss:  0.01918696239590645
Valid Loss:  0.02522953785955906
Epoch:  403  	Training Loss: 0.02483348175883293
Test Loss:  0.01918340101838112
Valid Loss:  0.02522636577486992
Epoch:  404  	Training Loss: 0.024829993024468422
Test Loss:  0.019179848954081535
Valid Loss:  0.025223203003406525
Epoch:  405  	Training Loss: 0.02482651174068451
Test Loss:  0.019176296889781952
Valid Loss:  0.02522004209458828
Epoch:  406  	Training Loss: 0.024823036044836044
Test Loss:  0.019172750413417816
Valid Loss:  0.025216879323124886
Epoch:  407  	Training Loss: 0.02481955848634243
Test Loss:  0.01916920393705368
Valid Loss:  0.02521372027695179
Epoch:  408  	Training Loss: 0.024816086515784264
Test Loss:  0.019165663048624992
Valid Loss:  0.025210566818714142
Epoch:  409  	Training Loss: 0.024812620133161545
Test Loss:  0.019162127748131752
Valid Loss:  0.025207411497831345
Epoch:  410  	Training Loss: 0.024809155613183975
Test Loss:  0.019158601760864258
Valid Loss:  0.025204282253980637
Epoch:  411  	Training Loss: 0.024805696681141853
Test Loss:  0.019155088812112808
Valid Loss:  0.02520114928483963
Epoch:  412  	Training Loss: 0.02480223961174488
Test Loss:  0.019151655957102776
Valid Loss:  0.025198103860020638
Epoch:  413  	Training Loss: 0.024798866361379623
Test Loss:  0.019148224964737892
Valid Loss:  0.025195062160491943
Epoch:  414  	Training Loss: 0.024795502424240112
Test Loss:  0.019144795835018158
Valid Loss:  0.0251920223236084
Epoch:  415  	Training Loss: 0.024792134761810303
Test Loss:  0.01914137229323387
Valid Loss:  0.025188978761434555
Epoch:  416  	Training Loss: 0.02478877454996109
Test Loss:  0.019137954339385033
Valid Loss:  0.025185944512486458
Epoch:  417  	Training Loss: 0.024785418063402176
Test Loss:  0.019134540110826492
Valid Loss:  0.02518291026353836
Epoch:  418  	Training Loss: 0.02478206343948841
Test Loss:  0.0191311277449131
Valid Loss:  0.025179876014590263
Epoch:  419  	Training Loss: 0.024778712540864944
Test Loss:  0.01912771910429001
Valid Loss:  0.025176847353577614
Epoch:  420  	Training Loss: 0.024775361642241478
Test Loss:  0.019124312326312065
Valid Loss:  0.025173818692564964
Epoch:  421  	Training Loss: 0.02477201819419861
Test Loss:  0.01912091113626957
Valid Loss:  0.025170791894197464
Epoch:  422  	Training Loss: 0.024768680334091187
Test Loss:  0.019117552787065506
Valid Loss:  0.025167807936668396
Epoch:  423  	Training Loss: 0.02476537972688675
Test Loss:  0.01911420002579689
Valid Loss:  0.025164827704429626
Epoch:  424  	Training Loss: 0.02476208657026291
Test Loss:  0.019110850989818573
Valid Loss:  0.025161847472190857
 85%|████████▌ | 425/500 [04:51<00:45,  1.66it/s] 85%|████████▌ | 427/500 [04:51<00:32,  2.26it/s] 86%|████████▌ | 429/500 [04:51<00:23,  3.04it/s] 86%|████████▌ | 431/500 [04:57<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:57<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:58<00:39,  1.65it/s] 87%|████████▋ | 437/500 [04:58<00:28,  2.25it/s] 88%|████████▊ | 439/500 [04:58<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:04<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:04<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:04<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:05<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:05<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:11<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:11<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:11<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:11<00:19,  2.26it/s] 92%|█████████▏| 459/500 [05:11<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:18<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:18<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:18<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:18<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:18<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:24<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:25<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:25<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:25<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:25<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:31<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:31<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:31<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:32<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:32<00:03,  3.03it/s] 98%|█████████▊| 491/500 [05:38<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:38<00:05,  1.18it/s]Epoch:  425  	Training Loss: 0.024758795276284218
Test Loss:  0.019107503816485405
Valid Loss:  0.025158867239952087
Epoch:  426  	Training Loss: 0.024755507707595825
Test Loss:  0.019104160368442535
Valid Loss:  0.02515588328242302
Epoch:  427  	Training Loss: 0.024752220138907433
Test Loss:  0.019100818783044815
Valid Loss:  0.025152914226055145
Epoch:  428  	Training Loss: 0.02474893629550934
Test Loss:  0.019097480922937393
Valid Loss:  0.025149939581751823
Epoch:  429  	Training Loss: 0.02474565990269184
Test Loss:  0.019094150513410568
Valid Loss:  0.0251469686627388
Epoch:  430  	Training Loss: 0.024742381647229195
Test Loss:  0.019090820103883743
Valid Loss:  0.025143999606370926
Epoch:  431  	Training Loss: 0.024739108979701996
Test Loss:  0.01908748596906662
Valid Loss:  0.025141030550003052
Epoch:  432  	Training Loss: 0.024735838174819946
Test Loss:  0.019084159284830093
Valid Loss:  0.02513805404305458
Epoch:  433  	Training Loss: 0.0247325599193573
Test Loss:  0.019080840051174164
Valid Loss:  0.02513507381081581
Epoch:  434  	Training Loss: 0.02472928911447525
Test Loss:  0.019077524542808533
Valid Loss:  0.025132106617093086
Epoch:  435  	Training Loss: 0.02472601644694805
Test Loss:  0.019074203446507454
Valid Loss:  0.025129130110144615
Epoch:  436  	Training Loss: 0.02472274750471115
Test Loss:  0.019070889800786972
Valid Loss:  0.02512616105377674
Epoch:  437  	Training Loss: 0.0247194841504097
Test Loss:  0.019067581743001938
Valid Loss:  0.025123193860054016
Epoch:  438  	Training Loss: 0.024716222658753395
Test Loss:  0.019064271822571754
Valid Loss:  0.025120234116911888
Epoch:  439  	Training Loss: 0.02471296489238739
Test Loss:  0.019060973078012466
Valid Loss:  0.02511727064847946
Epoch:  440  	Training Loss: 0.024709712713956833
Test Loss:  0.019057676196098328
Valid Loss:  0.025114309042692184
Epoch:  441  	Training Loss: 0.024706460535526276
Test Loss:  0.01905437372624874
Valid Loss:  0.025111354887485504
Epoch:  442  	Training Loss: 0.02470320835709572
Test Loss:  0.01905113086104393
Valid Loss:  0.025108449161052704
Epoch:  443  	Training Loss: 0.024700015783309937
Test Loss:  0.019047893583774567
Valid Loss:  0.025105543434619904
Epoch:  444  	Training Loss: 0.024696826934814453
Test Loss:  0.019044674932956696
Valid Loss:  0.02510266937315464
Epoch:  445  	Training Loss: 0.024693641811609268
Test Loss:  0.019041456282138824
Valid Loss:  0.025099799036979675
Epoch:  446  	Training Loss: 0.02469046413898468
Test Loss:  0.01903824508190155
Valid Loss:  0.02509692683815956
Epoch:  447  	Training Loss: 0.02468728832900524
Test Loss:  0.019035035744309425
Valid Loss:  0.025094054639339447
Epoch:  448  	Training Loss: 0.024684114381670952
Test Loss:  0.01903182454407215
Valid Loss:  0.02509118616580963
Epoch:  449  	Training Loss: 0.02468094229698181
Test Loss:  0.019028618931770325
Valid Loss:  0.025088321417570114
Epoch:  450  	Training Loss: 0.02467777393758297
Test Loss:  0.019025422632694244
Valid Loss:  0.025085458531975746
Epoch:  451  	Training Loss: 0.024674609303474426
Test Loss:  0.019022220745682716
Valid Loss:  0.02508259005844593
Epoch:  452  	Training Loss: 0.02467145025730133
Test Loss:  0.01901906728744507
Valid Loss:  0.025079775601625443
Epoch:  453  	Training Loss: 0.024668332189321518
Test Loss:  0.019015919417142868
Valid Loss:  0.025076955556869507
Epoch:  454  	Training Loss: 0.024665212258696556
Test Loss:  0.01901276782155037
Valid Loss:  0.02507413923740387
Epoch:  455  	Training Loss: 0.02466210350394249
Test Loss:  0.019009625539183617
Valid Loss:  0.02507132850587368
Epoch:  456  	Training Loss: 0.024658992886543274
Test Loss:  0.019006486982107162
Valid Loss:  0.025068510323762894
Epoch:  457  	Training Loss: 0.024655889719724655
Test Loss:  0.01900334656238556
Valid Loss:  0.025065701454877853
Epoch:  458  	Training Loss: 0.024652784690260887
Test Loss:  0.019000209867954254
Valid Loss:  0.025062894448637962
Epoch:  459  	Training Loss: 0.02464968152344227
Test Loss:  0.018997076898813248
Valid Loss:  0.02506008744239807
Epoch:  460  	Training Loss: 0.024646585807204247
Test Loss:  0.01899394951760769
Valid Loss:  0.02505728043615818
Epoch:  461  	Training Loss: 0.024643491953611374
Test Loss:  0.01899082213640213
Valid Loss:  0.025054477155208588
Epoch:  462  	Training Loss: 0.02464039996266365
Test Loss:  0.01898772269487381
Valid Loss:  0.025051701813936234
Epoch:  463  	Training Loss: 0.024637330323457718
Test Loss:  0.018984626978635788
Valid Loss:  0.02504892647266388
Epoch:  464  	Training Loss: 0.02463427186012268
Test Loss:  0.018981527537107468
Valid Loss:  0.025046154856681824
Epoch:  465  	Training Loss: 0.024631213396787643
Test Loss:  0.018978439271450043
Valid Loss:  0.025043386965990067
Epoch:  466  	Training Loss: 0.024628158658742905
Test Loss:  0.01897534914314747
Valid Loss:  0.02504061535000801
Epoch:  467  	Training Loss: 0.024625103920698166
Test Loss:  0.018972264602780342
Valid Loss:  0.0250378530472517
Epoch:  468  	Training Loss: 0.024622056633234024
Test Loss:  0.018969181925058365
Valid Loss:  0.025035085156559944
Epoch:  469  	Training Loss: 0.024619005620479584
Test Loss:  0.018966101109981537
Valid Loss:  0.025032320991158485
Epoch:  470  	Training Loss: 0.02461596205830574
Test Loss:  0.018963024020195007
Valid Loss:  0.025029562413692474
Epoch:  471  	Training Loss: 0.024612918496131897
Test Loss:  0.018959954380989075
Valid Loss:  0.025026801973581314
Epoch:  472  	Training Loss: 0.02460988238453865
Test Loss:  0.01895693875849247
Valid Loss:  0.025024089962244034
Epoch:  473  	Training Loss: 0.024606898427009583
Test Loss:  0.018953924998641014
Valid Loss:  0.0250213835388422
Epoch:  474  	Training Loss: 0.02460392192006111
Test Loss:  0.018950916826725006
Valid Loss:  0.025018680840730667
Epoch:  475  	Training Loss: 0.02460094541311264
Test Loss:  0.018947914242744446
Valid Loss:  0.02501598373055458
Epoch:  476  	Training Loss: 0.02459797076880932
Test Loss:  0.018944911658763885
Valid Loss:  0.025013282895088196
Epoch:  477  	Training Loss: 0.024595001712441444
Test Loss:  0.018941914662718773
Valid Loss:  0.02501058578491211
Epoch:  478  	Training Loss: 0.02459203451871872
Test Loss:  0.01893891766667366
Valid Loss:  0.025007890537381172
Epoch:  479  	Training Loss: 0.02458907477557659
Test Loss:  0.018935926258563995
Valid Loss:  0.025005202740430832
Epoch:  480  	Training Loss: 0.024586115032434464
Test Loss:  0.01893293671309948
Valid Loss:  0.025002507492899895
Epoch:  481  	Training Loss: 0.024583151564002037
Test Loss:  0.018929950892925262
Valid Loss:  0.024999819695949554
Epoch:  482  	Training Loss: 0.024580199271440506
Test Loss:  0.018926966935396194
Valid Loss:  0.02499714493751526
Epoch:  483  	Training Loss: 0.024577254429459572
Test Loss:  0.018923990428447723
Valid Loss:  0.024994466453790665
Epoch:  484  	Training Loss: 0.024574311450123787
Test Loss:  0.01892101764678955
Valid Loss:  0.02499179169535637
Epoch:  485  	Training Loss: 0.02457137033343315
Test Loss:  0.018918044865131378
Valid Loss:  0.02498912252485752
Epoch:  486  	Training Loss: 0.024568434804677963
Test Loss:  0.018915079534053802
Valid Loss:  0.024986455217003822
Epoch:  487  	Training Loss: 0.024565501138567924
Test Loss:  0.018912114202976227
Valid Loss:  0.024983787909150124
Epoch:  488  	Training Loss: 0.024562571197748184
Test Loss:  0.01890914887189865
Valid Loss:  0.024981118738651276
Epoch:  489  	Training Loss: 0.024559643119573593
Test Loss:  0.018906190991401672
Valid Loss:  0.024978458881378174
Epoch:  490  	Training Loss: 0.0245567187666893
Test Loss:  0.018903233110904694
Valid Loss:  0.024975797161459923
Epoch:  491  	Training Loss: 0.024553794413805008
Test Loss:  0.018900278955698013
Valid Loss:  0.02497313916683197
Epoch:  492  	Training Loss: 0.024550873786211014
Test Loss:  0.01889733225107193
Valid Loss:  0.024970488622784615
Epoch:  493  	Training Loss: 0.024547960609197617
Test Loss:  0.018894389271736145
Valid Loss:  0.024967841804027557
Epoch:  494  	Training Loss: 0.024545054882764816
Test Loss:  0.01889144815504551
Valid Loss:  0.024965189397335052
Epoch:  495  	Training Loss: 0.024542147293686867
Test Loss:   99%|█████████▉| 495/500 [05:38<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:38<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:39<00:00,  3.00it/s]100%|██████████| 500/500 [05:39<00:00,  1.47it/s]
0.018888508901000023
Valid Loss:  0.024962546303868294
Epoch:  496  	Training Loss: 0.024539243429899216
Test Loss:  0.018885571509599686
Valid Loss:  0.024959903210401535
Epoch:  497  	Training Loss: 0.024536341428756714
Test Loss:  0.018882637843489647
Valid Loss:  0.024957260116934776
Epoch:  498  	Training Loss: 0.02453344129025936
Test Loss:  0.018879706040024757
Valid Loss:  0.024954620748758316
Epoch:  499  	Training Loss: 0.024530544877052307
Test Loss:  0.018876779824495316
Valid Loss:  0.024951979517936707
Epoch:  500  	Training Loss: 0.024527650326490402
Test Loss:  0.018873851746320724
Valid Loss:  0.024949338287115097
seed is  8
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:15,  6.28s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:40,  1.31s/it]  3%|▎         | 13/500 [00:13<07:16,  1.11it/s]  3%|▎         | 15/500 [00:13<05:04,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:19<09:42,  1.22s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:32<16:27,  2.11s/it]  7%|▋         | 33/500 [00:33<11:37,  1.49s/it]  7%|▋         | 35/500 [00:33<08:14,  1.06s/it]  7%|▋         | 37/500 [00:33<05:53,  1.31it/s]  8%|▊         | 39/500 [00:33<04:15,  1.80it/s]  8%|▊         | 41/500 [00:39<10:08,  1.33s/it]  9%|▊         | 43/500 [00:39<07:13,  1.05it/s]  9%|▉         | 45/500 [00:39<05:11,  1.46it/s]  9%|▉         | 47/500 [00:40<03:45,  2.01it/s] 10%|▉         | 49/500 [00:40<02:46,  2.71it/s] 10%|█         | 51/500 [00:46<08:56,  1.19s/it] 11%|█         | 53/500 [00:46<06:23,  1.17it/s] 11%|█         | 55/500 [00:46<04:35,  1.61it/s] 11%|█▏        | 57/500 [00:46<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:47<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:53<08:40,  1.19s/it] 13%|█▎        | 63/500 [00:53<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:53<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:53<03:14,  2.22it/s]Epoch:  1  	Training Loss: 0.029097316786646843
Test Loss:  0.03826422989368439
Valid Loss:  0.04748933017253876
Epoch:  2  	Training Loss: 0.04540974646806717
Test Loss:  0.06267797946929932
Valid Loss:  0.059810105711221695
Epoch:  3  	Training Loss: 0.06265553832054138
Test Loss:  0.018521534278988838
Valid Loss:  0.023675762116909027
Epoch:  4  	Training Loss: 0.022794615477323532
Test Loss:  0.017396125942468643
Valid Loss:  0.022428030148148537
Epoch:  5  	Training Loss: 0.021657614037394524
Test Loss:  0.016494575887918472
Valid Loss:  0.021403899416327477
Epoch:  6  	Training Loss: 0.020727159455418587
Test Loss:  0.015727531164884567
Valid Loss:  0.020527072250843048
Epoch:  7  	Training Loss: 0.01993800327181816
Test Loss:  0.015084306709468365
Valid Loss:  0.019770823419094086
Epoch:  8  	Training Loss: 0.019264187663793564
Test Loss:  0.01455939095467329
Valid Loss:  0.019149281084537506
Epoch:  9  	Training Loss: 0.018703745678067207
Test Loss:  0.014186043292284012
Valid Loss:  0.018682051450014114
Epoch:  10  	Training Loss: 0.01828964427113533
Test Loss:  0.013892820104956627
Valid Loss:  0.018314005807042122
Epoch:  11  	Training Loss: 0.017941821366548538
Test Loss:  0.013614948838949203
Valid Loss:  0.01796022802591324
Epoch:  12  	Training Loss: 0.017611108720302582
Test Loss:  0.010368948802351952
Valid Loss:  0.013298297300934792
Epoch:  13  	Training Loss: 0.013630712404847145
Test Loss:  0.007953326217830181
Valid Loss:  0.01076558232307434
Epoch:  14  	Training Loss: 0.010708315297961235
Test Loss:  0.006558074615895748
Valid Loss:  0.008933022618293762
Epoch:  15  	Training Loss: 0.009072590619325638
Test Loss:  0.005775614641606808
Valid Loss:  0.00777650810778141
Epoch:  16  	Training Loss: 0.007854157127439976
Test Loss:  0.004996619187295437
Valid Loss:  0.00681929849088192
Epoch:  17  	Training Loss: 0.006949675269424915
Test Loss:  0.004625336267054081
Valid Loss:  0.006093010306358337
Epoch:  18  	Training Loss: 0.006217055022716522
Test Loss:  0.004137431271374226
Valid Loss:  0.005505809560418129
Epoch:  19  	Training Loss: 0.00564119266346097
Test Loss:  0.003962384071201086
Valid Loss:  0.005033554974943399
Epoch:  20  	Training Loss: 0.005182063672691584
Test Loss:  0.0036641028709709644
Valid Loss:  0.004667041823267937
Epoch:  21  	Training Loss: 0.004816954955458641
Test Loss:  0.0035895160399377346
Valid Loss:  0.004357624799013138
Epoch:  22  	Training Loss: 0.0045214807614684105
Test Loss:  0.0026578987017273903
Valid Loss:  0.002933796960860491
Epoch:  23  	Training Loss: 0.0030464567244052887
Test Loss:  0.00215007271617651
Valid Loss:  0.0021422426216304302
Epoch:  24  	Training Loss: 0.0022401660680770874
Test Loss:  0.002369907218962908
Valid Loss:  0.002272645942866802
Epoch:  25  	Training Loss: 0.002285523572936654
Test Loss:  0.0026148040778934956
Valid Loss:  0.0026569487527012825
Epoch:  26  	Training Loss: 0.0027538021095097065
Test Loss:  0.003941699862480164
Valid Loss:  0.00402055075392127
Epoch:  27  	Training Loss: 0.003915487788617611
Test Loss:  0.006583682727068663
Valid Loss:  0.007445668801665306
Epoch:  28  	Training Loss: 0.007495098747313023
Test Loss:  0.002963695675134659
Valid Loss:  0.0030157777946442366
Epoch:  29  	Training Loss: 0.002989836037158966
Test Loss:  0.0034939199686050415
Valid Loss:  0.0037648077122867107
Epoch:  30  	Training Loss: 0.0038432003930211067
Test Loss:  0.004283880814909935
Valid Loss:  0.004410990048199892
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.004230843391269445
Test Loss:  0.002496740547940135
Valid Loss:  0.001827550120651722
Epoch:  32  	Training Loss: 0.0018786992877721786
Test Loss:  0.002278416883200407
Valid Loss:  0.0016988938441500068
Epoch:  33  	Training Loss: 0.0017603756859898567
Test Loss:  0.0021302197128534317
Valid Loss:  0.0016396923456341028
Epoch:  34  	Training Loss: 0.0016930758720263839
Test Loss:  0.0020320105832070112
Valid Loss:  0.0016034096479415894
Epoch:  35  	Training Loss: 0.0016578908544033766
Test Loss:  0.0019728958141058683
Valid Loss:  0.001587284030392766
Epoch:  36  	Training Loss: 0.0016357218846678734
Test Loss:  0.001935924286954105
Valid Loss:  0.0015706559643149376
Epoch:  37  	Training Loss: 0.0016195561038330197
Test Loss:  0.0019057514145970345
Valid Loss:  0.0015582502819597721
Epoch:  38  	Training Loss: 0.0016055530868470669
Test Loss:  0.0018814501818269491
Valid Loss:  0.0015462348237633705
Epoch:  39  	Training Loss: 0.0015927668428048491
Test Loss:  0.001860709977336228
Valid Loss:  0.0015353942289948463
Epoch:  40  	Training Loss: 0.0015808406751602888
Test Loss:  0.0018425077432766557
Valid Loss:  0.0015247322153300047
Epoch:  41  	Training Loss: 0.001569559914059937
Test Loss:  0.0018256355542689562
Valid Loss:  0.0015144592616707087
Epoch:  42  	Training Loss: 0.0015585829969495535
Test Loss:  0.0018125477945432067
Valid Loss:  0.0014877708163112402
Epoch:  43  	Training Loss: 0.001535082352347672
Test Loss:  0.0017990473425015807
Valid Loss:  0.0014696614816784859
Epoch:  44  	Training Loss: 0.0015169561374932528
Test Loss:  0.0017915705684572458
Valid Loss:  0.0014582894509658217
Epoch:  45  	Training Loss: 0.0015056950505822897
Test Loss:  0.0017861885717138648
Valid Loss:  0.0014506734441965818
Epoch:  46  	Training Loss: 0.0014976749662309885
Test Loss:  0.0017806603573262691
Valid Loss:  0.0014441893436014652
Epoch:  47  	Training Loss: 0.0014915124047547579
Test Loss:  0.0017753040883690119
Valid Loss:  0.0014379307394847274
Epoch:  48  	Training Loss: 0.0014861838426440954
Test Loss:  0.0017698322189971805
Valid Loss:  0.0014319000765681267
Epoch:  49  	Training Loss: 0.0014813931193202734
Test Loss:  0.0017643612809479237
Valid Loss:  0.0014260020107030869
Epoch:  50  	Training Loss: 0.0014767738757655025
Test Loss:  0.0017591235227882862
Valid Loss:  0.00142027682159096
Epoch:  51  	Training Loss: 0.0014723220374435186
Test Loss:  0.0017541649285703897
Valid Loss:  0.0014148210175335407
Epoch:  52  	Training Loss: 0.0014680842868983746
Test Loss:  0.0017122733406722546
Valid Loss:  0.0013769783545285463
Epoch:  53  	Training Loss: 0.0014313277788460255
Test Loss:  0.0016767987981438637
Valid Loss:  0.001348656602203846
Epoch:  54  	Training Loss: 0.0014036550419405103
Test Loss:  0.0016480791382491589
Valid Loss:  0.0013248680625110865
Epoch:  55  	Training Loss: 0.0013818598818033934
Test Loss:  0.0016239945543929935
Valid Loss:  0.0013040830381214619
Epoch:  56  	Training Loss: 0.001363176852464676
Test Loss:  0.0016036913730204105
Valid Loss:  0.0012869196943938732
Epoch:  57  	Training Loss: 0.0013476934982463717
Test Loss:  0.0015863950829952955
Valid Loss:  0.001271759974770248
Epoch:  58  	Training Loss: 0.0013345174957066774
Test Loss:  0.0015717134810984135
Valid Loss:  0.0012593562714755535
Epoch:  59  	Training Loss: 0.00132389971986413
Test Loss:  0.001559342839755118
Valid Loss:  0.0012491028755903244
Epoch:  60  	Training Loss: 0.001314923050813377
Test Loss:  0.0015483886236324906
Valid Loss:  0.0012396335368975997
Epoch:  61  	Training Loss: 0.0013063985388725996
Test Loss:  0.0015384138096123934
Valid Loss:  0.0012306633871048689
Epoch:  62  	Training Loss: 0.0012983465567231178
Test Loss:  0.0015245879767462611
Valid Loss:  0.0012086379574611783
Epoch:  63  	Training Loss: 0.0012637111358344555
Test Loss:  0.0015197989996522665
Valid Loss:  0.0011898857774212956
Epoch:  64  	Training Loss: 0.0012431084178388119
Test Loss:  0.0015125982463359833
Valid Loss:  0.0011747864773496985
Epoch:  65  	Training Loss: 0.0012251230655238032
Test Loss:  0.0015034868847578764
Valid Loss:  0.0011606860207393765
Epoch:  66  	Training Loss: 0.0012087990762665868
Test Loss:  0.0014922990230843425
Valid Loss:  0.0011468713637441397
Epoch:  67  	Training Loss: 0.0011938310926780105
Test Loss:  0.001480849809013307
Valid Loss:  0.0011339862830936909
Epoch:  68  	Training Loss: 0.0011799857020378113
Test Loss:  0.0014683941844850779
Valid Loss:  0.001121003064326942
Epoch:  69  	Training Loss: 0.0011668981751427054
Test Loss:  0.0014561022398993373
Valid Loss:   14%|█▍        | 69/500 [00:53<02:24,  2.99it/s] 14%|█▍        | 71/500 [01:00<08:27,  1.18s/it] 15%|█▍        | 73/500 [01:00<06:02,  1.18it/s] 15%|█▌        | 75/500 [01:00<04:20,  1.63it/s] 15%|█▌        | 77/500 [01:00<03:10,  2.22it/s] 16%|█▌        | 79/500 [01:00<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:06<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:07<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:07<04:12,  1.65it/s] 17%|█▋        | 87/500 [01:07<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:07<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:13<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:13<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:14<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:14<02:13,  3.00it/s] 20%|██        | 101/500 [01:20<07:45,  1.17s/it] 21%|██        | 103/500 [01:20<05:32,  1.20it/s] 21%|██        | 105/500 [01:20<03:58,  1.65it/s] 21%|██▏       | 107/500 [01:20<02:53,  2.26it/s] 22%|██▏       | 109/500 [01:21<02:08,  3.04it/s] 22%|██▏       | 111/500 [01:27<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:27<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:27<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:27<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:27<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:34<07:23,  1.17s/it] 25%|██▍       | 123/500 [01:34<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:34<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:34<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:34<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:41<07:20,  1.20s/it] 27%|██▋       | 133/500 [01:41<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:41<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:41<02:44,  2.21it/s]0.0011087777093052864
Epoch:  70  	Training Loss: 0.0011541667627170682
Test Loss:  0.0014439435908570886
Valid Loss:  0.0010968876304104924
Epoch:  71  	Training Loss: 0.0011417585192248225
Test Loss:  0.0014319649199023843
Valid Loss:  0.0010855195578187704
Epoch:  72  	Training Loss: 0.0011297330493107438
Test Loss:  0.001428279560059309
Valid Loss:  0.0010742949089035392
Epoch:  73  	Training Loss: 0.0011197139974683523
Test Loss:  0.0014177595730870962
Valid Loss:  0.001068287412635982
Epoch:  74  	Training Loss: 0.00111050670966506
Test Loss:  0.001410650322213769
Valid Loss:  0.0010590553283691406
Epoch:  75  	Training Loss: 0.0011017387732863426
Test Loss:  0.001400151289999485
Valid Loss:  0.001052508014254272
Epoch:  76  	Training Loss: 0.0010932162404060364
Test Loss:  0.001391689176671207
Valid Loss:  0.0010441873455420136
Epoch:  77  	Training Loss: 0.0010849693790078163
Test Loss:  0.0013814318226650357
Valid Loss:  0.0010373240802437067
Epoch:  78  	Training Loss: 0.001076892833225429
Test Loss:  0.001372369471937418
Valid Loss:  0.0010296003893017769
Epoch:  79  	Training Loss: 0.0010689792688935995
Test Loss:  0.0013625051360577345
Valid Loss:  0.001022673211991787
Epoch:  80  	Training Loss: 0.0010611906182020903
Test Loss:  0.001353334984742105
Valid Loss:  0.0010153441689908504
Epoch:  81  	Training Loss: 0.001053546671755612
Test Loss:  0.0013434482971206307
Valid Loss:  0.0010083257220685482
Epoch:  82  	Training Loss: 0.0010461031924933195
Test Loss:  0.0013233936624601483
Valid Loss:  0.0010064643574878573
Epoch:  83  	Training Loss: 0.0010412979172542691
Test Loss:  0.0013137832283973694
Valid Loss:  0.0010051927529275417
Epoch:  84  	Training Loss: 0.0010391343384981155
Test Loss:  0.0013078944757580757
Valid Loss:  0.0010037370957434177
Epoch:  85  	Training Loss: 0.001037398586049676
Test Loss:  0.00130385160446167
Valid Loss:  0.001002294011414051
Epoch:  86  	Training Loss: 0.0010358263971284032
Test Loss:  0.0013007428497076035
Valid Loss:  0.0010009144898504019
Epoch:  87  	Training Loss: 0.0010343313915655017
Test Loss:  0.001298191724345088
Valid Loss:  0.0009995505679398775
Epoch:  88  	Training Loss: 0.0010328780626878142
Test Loss:  0.0012959769228473306
Valid Loss:  0.0009981842013075948
Epoch:  89  	Training Loss: 0.00103143067099154
Test Loss:  0.0012939644511789083
Valid Loss:  0.0009968390222638845
Epoch:  90  	Training Loss: 0.0010299889836460352
Test Loss:  0.001292088651098311
Valid Loss:  0.0009955125860869884
Epoch:  91  	Training Loss: 0.0010285710450261831
Test Loss:  0.001290318788960576
Valid Loss:  0.00099420256447047
Epoch:  92  	Training Loss: 0.0010271728970110416
Test Loss:  0.0012893863022327423
Valid Loss:  0.0009895018301904202
Epoch:  93  	Training Loss: 0.0010241472627967596
Test Loss:  0.0012877915287390351
Valid Loss:  0.0009870901703834534
Epoch:  94  	Training Loss: 0.0010226609883829951
Test Loss:  0.001285558333620429
Valid Loss:  0.0009855704847723246
Epoch:  95  	Training Loss: 0.0010216725058853626
Test Loss:  0.0012829587794840336
Valid Loss:  0.0009844547603279352
Epoch:  96  	Training Loss: 0.0010208755265921354
Test Loss:  0.0012801939155906439
Valid Loss:  0.0009835390374064445
Epoch:  97  	Training Loss: 0.0010201630648225546
Test Loss:  0.001277396222576499
Valid Loss:  0.0009827370522543788
Epoch:  98  	Training Loss: 0.001019505551084876
Test Loss:  0.0012746371794492006
Valid Loss:  0.0009820089908316731
Epoch:  99  	Training Loss: 0.0010188951855525374
Test Loss:  0.0012719716178253293
Valid Loss:  0.0009813520591706038
Epoch:  100  	Training Loss: 0.0010183367412537336
Test Loss:  0.0012694005854427814
Valid Loss:  0.0009807359892874956
Epoch:  101  	Training Loss: 0.0010178135707974434
Test Loss:  0.001266957726329565
Valid Loss:  0.0009801550768315792
Epoch:  102  	Training Loss: 0.0010173252085223794
Test Loss:  0.0012655409518629313
Valid Loss:  0.0009746443829499185
Epoch:  103  	Training Loss: 0.0010079219937324524
Test Loss:  0.0012628164840862155
Valid Loss:  0.0009650164865888655
Epoch:  104  	Training Loss: 0.000999595271423459
Test Loss:  0.0012575213331729174
Valid Loss:  0.0009591266280040145
Epoch:  105  	Training Loss: 0.0009917725110426545
Test Loss:  0.0012514041736721992
Valid Loss:  0.0009513720870018005
Epoch:  106  	Training Loss: 0.0009842129657045007
Test Loss:  0.0012444776948541403
Valid Loss:  0.0009450822835788131
Epoch:  107  	Training Loss: 0.0009768743766471744
Test Loss:  0.001236932585015893
Valid Loss:  0.0009380317060276866
Epoch:  108  	Training Loss: 0.0009697323548607528
Test Loss:  0.0012287007411941886
Valid Loss:  0.0009316648356616497
Epoch:  109  	Training Loss: 0.0009629008127376437
Test Loss:  0.0012203793739899993
Valid Loss:  0.0009252193267457187
Epoch:  110  	Training Loss: 0.0009561971528455615
Test Loss:  0.0012121828040108085
Valid Loss:  0.0009192075813189149
Epoch:  111  	Training Loss: 0.0009495534468442202
Test Loss:  0.0012041288428008556
Valid Loss:  0.0009131417027674615
Epoch:  112  	Training Loss: 0.000942969461902976
Test Loss:  0.0011950513580814004
Valid Loss:  0.0009098043665289879
Epoch:  113  	Training Loss: 0.000938407436478883
Test Loss:  0.001190805691294372
Valid Loss:  0.0009081343887373805
Epoch:  114  	Training Loss: 0.0009363942663185298
Test Loss:  0.001186918467283249
Valid Loss:  0.0009063640609383583
Epoch:  115  	Training Loss: 0.0009344713180325925
Test Loss:  0.0011833137832581997
Valid Loss:  0.0009045923361554742
Epoch:  116  	Training Loss: 0.0009325713035650551
Test Loss:  0.0011799217900261283
Valid Loss:  0.0009028327185660601
Epoch:  117  	Training Loss: 0.0009306934662163258
Test Loss:  0.0011767034884542227
Valid Loss:  0.0009011090733110905
Epoch:  118  	Training Loss: 0.0009288627188652754
Test Loss:  0.0011736222077161074
Valid Loss:  0.000899415637832135
Epoch:  119  	Training Loss: 0.0009270579321309924
Test Loss:  0.001170627074316144
Valid Loss:  0.0008977607358247042
Epoch:  120  	Training Loss: 0.0009252993040718138
Test Loss:  0.0011676597641780972
Valid Loss:  0.0008961285930126905
Epoch:  121  	Training Loss: 0.0009236031910404563
Test Loss:  0.0011647671926766634
Valid Loss:  0.0008945526788011193
Epoch:  122  	Training Loss: 0.0009219726198352873
Test Loss:  0.0011559748090803623
Valid Loss:  0.0008827098645269871
Epoch:  123  	Training Loss: 0.0009129259269684553
Test Loss:  0.0011444081319496036
Valid Loss:  0.0008757808245718479
Epoch:  124  	Training Loss: 0.0009058380965143442
Test Loss:  0.0011346592800691724
Valid Loss:  0.0008690670365467668
Epoch:  125  	Training Loss: 0.0008992724469862878
Test Loss:  0.0011256902944296598
Valid Loss:  0.0008628899231553078
Epoch:  126  	Training Loss: 0.0008932527853175998
Test Loss:  0.001117589185014367
Valid Loss:  0.0008572902879677713
Epoch:  127  	Training Loss: 0.0008876843494363129
Test Loss:  0.0011102226562798023
Valid Loss:  0.0008520110277459025
Epoch:  128  	Training Loss: 0.0008825904806144536
Test Loss:  0.0011036294745281339
Valid Loss:  0.0008471611654385924
Epoch:  129  	Training Loss: 0.0008778923656791449
Test Loss:  0.0010976649355143309
Valid Loss:  0.0008425552514381707
Epoch:  130  	Training Loss: 0.0008734897128306329
Test Loss:  0.001092138816602528
Valid Loss:  0.0008381465449929237
Epoch:  131  	Training Loss: 0.0008692652336321771
Test Loss:  0.0010869810357689857
Valid Loss:  0.0008339842897839844
Epoch:  132  	Training Loss: 0.0008652193937450647
Test Loss:  0.0010751071386039257
Valid Loss:  0.0008022567490115762
Epoch:  133  	Training Loss: 0.0008321938803419471
Test Loss:  0.0010685465531423688
Valid Loss:  0.0007823886116966605
Epoch:  134  	Training Loss: 0.0008124274318106472
Test Loss:  0.0010608801385387778
Valid Loss:  0.0007679195259697735
Epoch:  135  	Training Loss: 0.0007966368575580418
Test Loss:  0.0010530593572184443
Valid Loss:  0.0007565678679384291
Epoch:  136  	Training Loss: 0.0007844333304092288
Test Loss:  0.0010451660491526127
Valid Loss:  0.0007478272309526801
Epoch:  137  	Training Loss: 0.00077518739271909
Test Loss:  0.0010372528340667486
Valid Loss:  0.0007403944618999958
Epoch:  138  	Training Loss: 0.0007672334322705865
Test Loss:   28%|██▊       | 139/500 [01:41<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:47<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:48<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:48<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:48<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:48<01:56,  3.02it/s] 30%|███       | 151/500 [01:54<06:47,  1.17s/it] 31%|███       | 153/500 [01:54<04:50,  1.20it/s] 31%|███       | 155/500 [01:54<03:28,  1.66it/s] 31%|███▏      | 157/500 [01:55<02:32,  2.26it/s] 32%|███▏      | 159/500 [01:55<01:52,  3.03it/s] 32%|███▏      | 161/500 [02:01<06:39,  1.18s/it] 33%|███▎      | 163/500 [02:01<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:01<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:01<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:02<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:08<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:08<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:08<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:08<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:08<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:14<06:09,  1.16s/it] 37%|███▋      | 183/500 [02:15<04:23,  1.20it/s] 37%|███▋      | 185/500 [02:15<03:09,  1.66it/s] 37%|███▋      | 187/500 [02:15<02:18,  2.26it/s] 38%|███▊      | 189/500 [02:15<01:42,  3.03it/s] 38%|███▊      | 191/500 [02:21<06:00,  1.17s/it] 39%|███▊      | 193/500 [02:21<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:22<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:22<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:22<01:39,  3.01it/s] 40%|████      | 201/500 [02:28<05:53,  1.18s/it] 41%|████      | 203/500 [02:28<04:12,  1.18it/s] 41%|████      | 205/500 [02:28<03:01,  1.62it/s]0.001029199338518083
Valid Loss:  0.0007341922027990222
Epoch:  139  	Training Loss: 0.0007600898970849812
Test Loss:  0.0010213475907221437
Valid Loss:  0.0007283135782927275
Epoch:  140  	Training Loss: 0.0007535299519076943
Test Loss:  0.0010135479969903827
Valid Loss:  0.0007229980546981096
Epoch:  141  	Training Loss: 0.0007476439932361245
Test Loss:  0.0010058337356895208
Valid Loss:  0.0007183825364336371
Epoch:  142  	Training Loss: 0.0007423146162182093
Test Loss:  0.0009982719784602523
Valid Loss:  0.0007146659190766513
Epoch:  143  	Training Loss: 0.0007378264563158154
Test Loss:  0.000990398577414453
Valid Loss:  0.0007118405192159116
Epoch:  144  	Training Loss: 0.0007335069822147489
Test Loss:  0.0009834427619352937
Valid Loss:  0.0007083747768774629
Epoch:  145  	Training Loss: 0.0007293759845197201
Test Loss:  0.0009761093533597887
Valid Loss:  0.0007058159681037068
Epoch:  146  	Training Loss: 0.0007254618685692549
Test Loss:  0.0009695223998278379
Valid Loss:  0.0007026243256404996
Epoch:  147  	Training Loss: 0.0007218059035949409
Test Loss:  0.0009624970844015479
Valid Loss:  0.0007002834463492036
Epoch:  148  	Training Loss: 0.0007184517453424633
Test Loss:  0.0009561738697811961
Valid Loss:  0.0006974858697503805
Epoch:  149  	Training Loss: 0.0007152617909014225
Test Loss:  0.0009497646242380142
Valid Loss:  0.0006955118151381612
Epoch:  150  	Training Loss: 0.0007122025126591325
Test Loss:  0.0009441192960366607
Valid Loss:  0.0006929157534614205
Epoch:  151  	Training Loss: 0.0007092541200108826
Test Loss:  0.0009383248980157077
Valid Loss:  0.0006911401869729161
Epoch:  152  	Training Loss: 0.0007064343080855906
Test Loss:  0.0009324830025434494
Valid Loss:  0.00068358686985448
Epoch:  153  	Training Loss: 0.0007008445099927485
Test Loss:  0.0009263238753192127
Valid Loss:  0.0006786629091948271
Epoch:  154  	Training Loss: 0.0006958000594750047
Test Loss:  0.000920870341360569
Valid Loss:  0.0006734280032105744
Epoch:  155  	Training Loss: 0.000691004388500005
Test Loss:  0.0009156272863037884
Valid Loss:  0.0006685853004455566
Epoch:  156  	Training Loss: 0.0006863954477012157
Test Loss:  0.0009106458746828139
Valid Loss:  0.0006638934137299657
Epoch:  157  	Training Loss: 0.0006819505360908806
Test Loss:  0.0009059022413566709
Valid Loss:  0.0006594298174604774
Epoch:  158  	Training Loss: 0.0006777031812816858
Test Loss:  0.0009014059323817492
Valid Loss:  0.0006551526021212339
Epoch:  159  	Training Loss: 0.0006736379582434893
Test Loss:  0.0008971213828772306
Valid Loss:  0.0006510501261800528
Epoch:  160  	Training Loss: 0.0006696940981782973
Test Loss:  0.0008929853793233633
Valid Loss:  0.0006470873486250639
Epoch:  161  	Training Loss: 0.0006659846985712647
Test Loss:  0.000888972484972328
Valid Loss:  0.0006433743401430547
Epoch:  162  	Training Loss: 0.0006624669767916203
Test Loss:  0.0008860230445861816
Valid Loss:  0.0006402741419151425
Epoch:  163  	Training Loss: 0.0006554904393851757
Test Loss:  0.0008814487373456359
Valid Loss:  0.0006306269206106663
Epoch:  164  	Training Loss: 0.0006489281659014523
Test Loss:  0.0008756325696595013
Valid Loss:  0.0006284111877903342
Epoch:  165  	Training Loss: 0.000642589177004993
Test Loss:  0.0008691890398040414
Valid Loss:  0.0006186270620673895
Epoch:  166  	Training Loss: 0.0006363904103636742
Test Loss:  0.0008624272304587066
Valid Loss:  0.0006170489359647036
Epoch:  167  	Training Loss: 0.0006303032278083265
Test Loss:  0.0008554037776775658
Valid Loss:  0.000606988905929029
Epoch:  168  	Training Loss: 0.000624308711849153
Test Loss:  0.0008484619902446866
Valid Loss:  0.0006060504820197821
Epoch:  169  	Training Loss: 0.0006184183293953538
Test Loss:  0.0008412933675572276
Valid Loss:  0.0005956755485385656
Epoch:  170  	Training Loss: 0.0006126118823885918
Test Loss:  0.0008344364468939602
Valid Loss:  0.0005953901563771069
Epoch:  171  	Training Loss: 0.0006068988004699349
Test Loss:  0.0008272862178273499
Valid Loss:  0.0005846869898959994
Epoch:  172  	Training Loss: 0.000601276638917625
Test Loss:  0.0008126185857690871
Valid Loss:  0.0005847103893756866
Epoch:  173  	Training Loss: 0.0005948171019554138
Test Loss:  0.0008057215600274503
Valid Loss:  0.000577602768316865
Epoch:  174  	Training Loss: 0.0005902682896703482
Test Loss:  0.0007988458964973688
Valid Loss:  0.0005749124684371054
Epoch:  175  	Training Loss: 0.0005860933451913297
Test Loss:  0.0007926207617856562
Valid Loss:  0.0005668432568199933
Epoch:  176  	Training Loss: 0.0005790242576040328
Test Loss:  0.0007813547272235155
Valid Loss:  0.0005489815375767648
Epoch:  177  	Training Loss: 0.0005626210477203131
Test Loss:  0.0007675141096115112
Valid Loss:  0.0005327019607648253
Epoch:  178  	Training Loss: 0.0005459084059111774
Test Loss:  0.0007536673219874501
Valid Loss:  0.0005248263478279114
Epoch:  179  	Training Loss: 0.0005365770775824785
Test Loss:  0.0007418880704790354
Valid Loss:  0.0005184473702684045
Epoch:  180  	Training Loss: 0.0005294332513585687
Test Loss:  0.0007315353723242879
Valid Loss:  0.0005133416852913797
Epoch:  181  	Training Loss: 0.0005234488053247333
Test Loss:  0.0007223309949040413
Valid Loss:  0.0005085882730782032
Epoch:  182  	Training Loss: 0.0005180484731681645
Test Loss:  0.0007179260137490928
Valid Loss:  0.0005010057357139885
Epoch:  183  	Training Loss: 0.0005136380204930902
Test Loss:  0.0007132524624466896
Valid Loss:  0.0004990576417185366
Epoch:  184  	Training Loss: 0.0005095506785437465
Test Loss:  0.000708984094671905
Valid Loss:  0.0004937879857607186
Epoch:  185  	Training Loss: 0.0005056453519500792
Test Loss:  0.0007045008824206889
Valid Loss:  0.0004909335402771831
Epoch:  186  	Training Loss: 0.000501832808367908
Test Loss:  0.0007002390339039266
Valid Loss:  0.0004866547242272645
Epoch:  187  	Training Loss: 0.000498103559948504
Test Loss:  0.000695927650667727
Valid Loss:  0.00048345254617743194
Epoch:  188  	Training Loss: 0.0004944432876072824
Test Loss:  0.0006916826823726296
Valid Loss:  0.0004796374123543501
Epoch:  189  	Training Loss: 0.0004908386617898941
Test Loss:  0.0006874380051158369
Valid Loss:  0.00047632731730118394
Epoch:  190  	Training Loss: 0.0004872771096415818
Test Loss:  0.0006833081133663654
Valid Loss:  0.0004727864288724959
Epoch:  191  	Training Loss: 0.00048374710604548454
Test Loss:  0.0006791981868445873
Valid Loss:  0.0004694558447226882
Epoch:  192  	Training Loss: 0.00048025883734226227
Test Loss:  0.0006719375960528851
Valid Loss:  0.00046822361764498055
Epoch:  193  	Training Loss: 0.00047835768782533705
Test Loss:  0.0006670269067399204
Valid Loss:  0.0004669165937229991
Epoch:  194  	Training Loss: 0.0004768640792462975
Test Loss:  0.0006632172735407948
Valid Loss:  0.0004655705997720361
Epoch:  195  	Training Loss: 0.0004755087720695883
Test Loss:  0.0006600207416340709
Valid Loss:  0.0004642406420316547
Epoch:  196  	Training Loss: 0.0004742234305012971
Test Loss:  0.0006572222919203341
Valid Loss:  0.00046294560888782144
Epoch:  197  	Training Loss: 0.0004729856736958027
Test Loss:  0.0006547115044668317
Valid Loss:  0.0004616884980350733
Epoch:  198  	Training Loss: 0.00047177827218547463
Test Loss:  0.0006523923948407173
Valid Loss:  0.0004604424466378987
Epoch:  199  	Training Loss: 0.000470608239993453
Test Loss:  0.000650225963909179
Valid Loss:  0.00045923501602374017
Epoch:  200  	Training Loss: 0.00046946160728111863
Test Loss:  0.0006481969612650573
Valid Loss:  0.00045805558329448104
Epoch:  201  	Training Loss: 0.0004683316801674664
Test Loss:  0.0006462902529165149
Valid Loss:  0.0004569002194330096
Epoch:  202  	Training Loss: 0.00046721944818273187
Test Loss:  0.0006460810545831919
Valid Loss:  0.00045356358168646693
Epoch:  203  	Training Loss: 0.0004636768135242164
Test Loss:  0.0006455226102843881
Valid Loss:  0.00045038043754175305
Epoch:  204  	Training Loss: 0.0004604336281772703
Test Loss:  0.0006447024643421173
Valid Loss:  0.000447403232101351
Epoch:  205  	Training Loss: 0.00045742676593363285
Test Loss:  0.0006436521071009338
Valid Loss:  0.00044457073090597987
Epoch:  206  	Training Loss: 0.00045458920067176223
Test Loss:  0.0006423828890547156
Valid Loss:  41%|████▏     | 207/500 [02:29<02:12,  2.22it/s] 42%|████▏     | 209/500 [02:29<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:35<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:35<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:35<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:35<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:36<01:34,  2.99it/s] 44%|████▍     | 221/500 [02:42<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:42<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:42<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:42<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:42<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:48<05:12,  1.16s/it] 47%|████▋     | 233/500 [02:49<03:43,  1.20it/s] 47%|████▋     | 235/500 [02:49<02:40,  1.66it/s] 47%|████▋     | 237/500 [02:49<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:49<01:25,  3.04it/s] 48%|████▊     | 241/500 [02:55<05:00,  1.16s/it] 49%|████▊     | 243/500 [02:55<03:34,  1.20it/s] 49%|████▉     | 245/500 [02:55<02:33,  1.66it/s] 49%|████▉     | 247/500 [02:56<01:51,  2.27it/s] 50%|████▉     | 249/500 [02:56<01:22,  3.04it/s] 50%|█████     | 251/500 [03:02<04:48,  1.16s/it] 51%|█████     | 253/500 [03:02<03:26,  1.20it/s] 51%|█████     | 255/500 [03:02<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:02<01:47,  2.26it/s] 52%|█████▏    | 259/500 [03:02<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:09<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:09<03:18,  1.19it/s] 53%|█████▎    | 265/500 [03:09<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:09<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:09<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:16<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:16<03:11,  1.19it/s] 0.0004418373282533139
Epoch:  207  	Training Loss: 0.0004518735804595053
Test Loss:  0.0006409299094229937
Valid Loss:  0.0004391907714307308
Epoch:  208  	Training Loss: 0.00044925749534741044
Test Loss:  0.0006393240764737129
Valid Loss:  0.0004366151406429708
Epoch:  209  	Training Loss: 0.0004467229009605944
Test Loss:  0.0006375847151502967
Valid Loss:  0.00043408284545876086
Epoch:  210  	Training Loss: 0.00044424913357943296
Test Loss:  0.0006357342936098576
Valid Loss:  0.00043145971721969545
Epoch:  211  	Training Loss: 0.0004417269374243915
Test Loss:  0.000633787945844233
Valid Loss:  0.0004282847512513399
Epoch:  212  	Training Loss: 0.0004387644585222006
Test Loss:  0.000626663095317781
Valid Loss:  0.00042335718171671033
Epoch:  213  	Training Loss: 0.00043418662971816957
Test Loss:  0.0006191078573465347
Valid Loss:  0.0004168713930994272
Epoch:  214  	Training Loss: 0.00042792310705408454
Test Loss:  0.0006115743308328092
Valid Loss:  0.0004104606923647225
Epoch:  215  	Training Loss: 0.0004214839718770236
Test Loss:  0.0006050192750990391
Valid Loss:  0.0004056604811921716
Epoch:  216  	Training Loss: 0.00041631865315139294
Test Loss:  0.0005993854138068855
Valid Loss:  0.0004022287903353572
Epoch:  217  	Training Loss: 0.0004126009007450193
Test Loss:  0.0005943774594925344
Valid Loss:  0.0003995547886006534
Epoch:  218  	Training Loss: 0.0004096419143024832
Test Loss:  0.0005898788222111762
Valid Loss:  0.0003971649275626987
Epoch:  219  	Training Loss: 0.0004068804264534265
Test Loss:  0.0005855544004589319
Valid Loss:  0.0003948742523789406
Epoch:  220  	Training Loss: 0.00040423456812277436
Test Loss:  0.0005813253810629249
Valid Loss:  0.0003917968715541065
Epoch:  221  	Training Loss: 0.0004009930999018252
Test Loss:  0.000575931859202683
Valid Loss:  0.00038509859587065876
Epoch:  222  	Training Loss: 0.00039500242564827204
Test Loss:  0.0005695518339052796
Valid Loss:  0.0003845791216008365
Epoch:  223  	Training Loss: 0.0003915756242349744
Test Loss:  0.0005635686102323234
Valid Loss:  0.00038071261951699853
Epoch:  224  	Training Loss: 0.0003887411439791322
Test Loss:  0.0005591007648035884
Valid Loss:  0.00037896708818152547
Epoch:  225  	Training Loss: 0.00038610168849118054
Test Loss:  0.000554724014364183
Valid Loss:  0.00037645158590748906
Epoch:  226  	Training Loss: 0.0003835564129985869
Test Loss:  0.0005509486654773355
Valid Loss:  0.00037442854954861104
Epoch:  227  	Training Loss: 0.00038111163303256035
Test Loss:  0.0005473053315654397
Valid Loss:  0.0003722594992723316
Epoch:  228  	Training Loss: 0.0003787014284171164
Test Loss:  0.0005438652005977929
Valid Loss:  0.00037022997275926173
Epoch:  229  	Training Loss: 0.0003763358690775931
Test Loss:  0.0005405626725405455
Valid Loss:  0.00036818982334807515
Epoch:  230  	Training Loss: 0.0003740310203284025
Test Loss:  0.00053729786304757
Valid Loss:  0.0003661851806100458
Epoch:  231  	Training Loss: 0.0003717566723935306
Test Loss:  0.0005341205396689475
Valid Loss:  0.0003642116498667747
Epoch:  232  	Training Loss: 0.00036952606751583517
Test Loss:  0.0005280557670630515
Valid Loss:  0.0003611803404055536
Epoch:  233  	Training Loss: 0.00036659016041085124
Test Loss:  0.0005230249953456223
Valid Loss:  0.0003586994716897607
Epoch:  234  	Training Loss: 0.0003638220368884504
Test Loss:  0.0005189098883420229
Valid Loss:  0.0003559977049008012
Epoch:  235  	Training Loss: 0.0003611069405451417
Test Loss:  0.0005149387288838625
Valid Loss:  0.000353534851456061
Epoch:  236  	Training Loss: 0.000358429504558444
Test Loss:  0.0005112674552947283
Valid Loss:  0.0003509828238748014
Epoch:  237  	Training Loss: 0.0003557824238669127
Test Loss:  0.0005076031666249037
Valid Loss:  0.00034854290424846113
Epoch:  238  	Training Loss: 0.0003531628171913326
Test Loss:  0.0005040713003836572
Valid Loss:  0.0003460781299509108
Epoch:  239  	Training Loss: 0.0003505647473502904
Test Loss:  0.0005005539860576391
Valid Loss:  0.00034365913597866893
Epoch:  240  	Training Loss: 0.0003479975857771933
Test Loss:  0.0004970788140781224
Valid Loss:  0.00034125265665352345
Epoch:  241  	Training Loss: 0.0003454579273238778
Test Loss:  0.000493628263939172
Valid Loss:  0.000338875746820122
Epoch:  242  	Training Loss: 0.00034293957287445664
Test Loss:  0.0004906125250272453
Valid Loss:  0.00033572810934856534
Epoch:  243  	Training Loss: 0.0003404052695259452
Test Loss:  0.00048703461652621627
Valid Loss:  0.0003338231472298503
Epoch:  244  	Training Loss: 0.0003379870031494647
Test Loss:  0.00048385115223936737
Valid Loss:  0.000331520801410079
Epoch:  245  	Training Loss: 0.0003356081433594227
Test Loss:  0.0004806733631994575
Valid Loss:  0.0003294252965133637
Epoch:  246  	Training Loss: 0.0003332521882839501
Test Loss:  0.00047752654063515365
Valid Loss:  0.0003272749308962375
Epoch:  247  	Training Loss: 0.00033093683305196464
Test Loss:  0.0004743640893138945
Valid Loss:  0.00032516344799660146
Epoch:  248  	Training Loss: 0.0003286225546617061
Test Loss:  0.0004712250083684921
Valid Loss:  0.0003230473375879228
Epoch:  249  	Training Loss: 0.0003263402031734586
Test Loss:  0.00046817463589832187
Valid Loss:  0.00032094359630718827
Epoch:  250  	Training Loss: 0.00032409754930995405
Test Loss:  0.00046513526467606425
Valid Loss:  0.00031887981458567083
Epoch:  251  	Training Loss: 0.000321895262459293
Test Loss:  0.0004622054984793067
Valid Loss:  0.0003168679540976882
Epoch:  252  	Training Loss: 0.0003197664045728743
Test Loss:  0.00046062900219112635
Valid Loss:  0.00031618887442164123
Epoch:  253  	Training Loss: 0.000319247308652848
Test Loss:  0.00045915384544059634
Valid Loss:  0.0003155554586555809
Epoch:  254  	Training Loss: 0.00031876834691502154
Test Loss:  0.00045777129707857966
Valid Loss:  0.000314961071126163
Epoch:  255  	Training Loss: 0.00031832524109631777
Test Loss:  0.00045647696242667735
Valid Loss:  0.00031440367456525564
Epoch:  256  	Training Loss: 0.0003179151681251824
Test Loss:  0.0004552628379315138
Valid Loss:  0.00031388047500513494
Epoch:  257  	Training Loss: 0.00031753507209941745
Test Loss:  0.0004541251983027905
Valid Loss:  0.000313389056827873
Epoch:  258  	Training Loss: 0.00031718218815512955
Test Loss:  0.0004530361038632691
Valid Loss:  0.0003129253163933754
Epoch:  259  	Training Loss: 0.00031685433350503445
Test Loss:  0.0004520057118497789
Valid Loss:  0.00031248817685991526
Epoch:  260  	Training Loss: 0.00031654880149289966
Test Loss:  0.00045103850425221026
Valid Loss:  0.0003120749315712601
Epoch:  261  	Training Loss: 0.00031626434065401554
Test Loss:  0.00045012772898189723
Valid Loss:  0.0003116837178822607
Epoch:  262  	Training Loss: 0.000315998651785776
Test Loss:  0.0004478363844100386
Valid Loss:  0.0003110049874521792
Epoch:  263  	Training Loss: 0.00031551532447338104
Test Loss:  0.0004459755145944655
Valid Loss:  0.0003104724455624819
Epoch:  264  	Training Loss: 0.0003151379060000181
Test Loss:  0.000444507400970906
Valid Loss:  0.0003099952591583133
Epoch:  265  	Training Loss: 0.0003148322575725615
Test Loss:  0.0004433246795088053
Valid Loss:  0.00030957756098359823
Epoch:  266  	Training Loss: 0.00031457451405003667
Test Loss:  0.00044238066766411066
Valid Loss:  0.000309203052893281
Epoch:  267  	Training Loss: 0.0003143515787087381
Test Loss:  0.00044164655264467
Valid Loss:  0.00030886050080880523
Epoch:  268  	Training Loss: 0.0003141565539408475
Test Loss:  0.00044106008135713637
Valid Loss:  0.00030854635406285524
Epoch:  269  	Training Loss: 0.0003139815526083112
Test Loss:  0.0004405916843097657
Valid Loss:  0.00030825420981273055
Epoch:  270  	Training Loss: 0.0003138227330055088
Test Loss:  0.00044022133806720376
Valid Loss:  0.00030797923682257533
Epoch:  271  	Training Loss: 0.0003136760205961764
Test Loss:  0.0004399276804178953
Valid Loss:  0.0003077166620641947
Epoch:  272  	Training Loss: 0.0003135385341010988
Test Loss:  0.00044167134910821915
Valid Loss:  0.0003058136790059507
Epoch:  273  	Training Loss: 0.00030927208717912436
Test Loss:  0.0004428290412761271
Valid Loss:  0.00030354881891980767
Epoch:  274  	Training Loss: 0.00030690967105329037
Test Loss:   55%|█████▌    | 275/500 [03:16<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:16<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:16<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:22<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:22<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:23<02:10,  1.64it/s] 57%|█████▋    | 287/500 [03:23<01:34,  2.24it/s] 58%|█████▊    | 289/500 [03:23<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:29<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:29<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:29<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:30<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:30<01:06,  3.02it/s] 60%|██████    | 301/500 [03:36<03:54,  1.18s/it] 61%|██████    | 303/500 [03:36<02:46,  1.18it/s] 61%|██████    | 305/500 [03:36<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:36<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:37<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:43<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:43<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:43<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:43<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:43<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:50<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:50<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:50<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:50<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:50<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:56<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:57<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:57<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:57<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:57<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:03<03:07,  1.18s/it]0.0004423682112246752
Valid Loss:  0.0003019346622750163
Epoch:  275  	Training Loss: 0.0003050403902307153
Test Loss:  0.000441152835264802
Valid Loss:  0.0003003785095643252
Epoch:  276  	Training Loss: 0.0003034364781342447
Test Loss:  0.00043949438259005547
Valid Loss:  0.0002988611231558025
Epoch:  277  	Training Loss: 0.0003019085852429271
Test Loss:  0.00043768362957052886
Valid Loss:  0.0002973920200020075
Epoch:  278  	Training Loss: 0.0003004299942404032
Test Loss:  0.0004357244761195034
Valid Loss:  0.0002959728008136153
Epoch:  279  	Training Loss: 0.0002990110369864851
Test Loss:  0.0004337692225817591
Valid Loss:  0.0002945897285826504
Epoch:  280  	Training Loss: 0.0002976147807203233
Test Loss:  0.0004318334686104208
Valid Loss:  0.0002932333736680448
Epoch:  281  	Training Loss: 0.00029624311719089746
Test Loss:  0.0004298959975130856
Valid Loss:  0.0002918735845014453
Epoch:  282  	Training Loss: 0.00029487378196790814
Test Loss:  0.0004278993874322623
Valid Loss:  0.00028582505183294415
Epoch:  283  	Training Loss: 0.0002908088790718466
Test Loss:  0.0004241176648065448
Valid Loss:  0.0002853561018127948
Epoch:  284  	Training Loss: 0.0002876628714147955
Test Loss:  0.00042096333345398307
Valid Loss:  0.00028031558031216264
Epoch:  285  	Training Loss: 0.00028491768171079457
Test Loss:  0.0004166371072642505
Valid Loss:  0.0002802726230584085
Epoch:  286  	Training Loss: 0.00028235488571226597
Test Loss:  0.00041303387843072414
Valid Loss:  0.0002758408954832703
Epoch:  287  	Training Loss: 0.0002799366775434464
Test Loss:  0.00040883137262426317
Valid Loss:  0.0002757590846158564
Epoch:  288  	Training Loss: 0.00027759780641645193
Test Loss:  0.0004052718577440828
Valid Loss:  0.0002717043680604547
Epoch:  289  	Training Loss: 0.00027531301020644605
Test Loss:  0.000401346362195909
Valid Loss:  0.0002714325091801584
Epoch:  290  	Training Loss: 0.00027307806885801256
Test Loss:  0.000397882133256644
Valid Loss:  0.00026768725365400314
Epoch:  291  	Training Loss: 0.0002708677784539759
Test Loss:  0.00039428233867511153
Valid Loss:  0.00026731379330158234
Epoch:  292  	Training Loss: 0.00026870123110711575
Test Loss:  0.0003936653956770897
Valid Loss:  0.00026627734769135714
Epoch:  293  	Training Loss: 0.0002680117904674262
Test Loss:  0.00039361818926408887
Valid Loss:  0.00026589271146804094
Epoch:  294  	Training Loss: 0.0002673987182788551
Test Loss:  0.000393238733522594
Valid Loss:  0.00026536668883636594
Epoch:  295  	Training Loss: 0.0002668239758349955
Test Loss:  0.0003928156802430749
Valid Loss:  0.0002649141533765942
Epoch:  296  	Training Loss: 0.00026627452461980283
Test Loss:  0.000392288580769673
Valid Loss:  0.00026445998810231686
Epoch:  297  	Training Loss: 0.00026574250659905374
Test Loss:  0.000391687557566911
Valid Loss:  0.00026401987997815013
Epoch:  298  	Training Loss: 0.0002652226248756051
Test Loss:  0.0003910306841135025
Valid Loss:  0.00026358553441241384
Epoch:  299  	Training Loss: 0.00026471202727407217
Test Loss:  0.000390330096706748
Valid Loss:  0.00026315698050893843
Epoch:  300  	Training Loss: 0.0002642074250616133
Test Loss:  0.00038959167432039976
Valid Loss:  0.0002627288631629199
Epoch:  301  	Training Loss: 0.0002637055004015565
Test Loss:  0.0003888218489009887
Valid Loss:  0.00026230266666971147
Epoch:  302  	Training Loss: 0.0002632084651850164
Test Loss:  0.000384465791285038
Valid Loss:  0.00026094570057466626
Epoch:  303  	Training Loss: 0.0002618761791381985
Test Loss:  0.0003808910842053592
Valid Loss:  0.00025970477145165205
Epoch:  304  	Training Loss: 0.00026076598442159593
Test Loss:  0.0003778632380999625
Valid Loss:  0.0002586232149042189
Epoch:  305  	Training Loss: 0.0002598061691969633
Test Loss:  0.000375272094970569
Valid Loss:  0.00025766820181161165
Epoch:  306  	Training Loss: 0.00025894533609971404
Test Loss:  0.0003730157040990889
Valid Loss:  0.00025679561076685786
Epoch:  307  	Training Loss: 0.0002581571170594543
Test Loss:  0.00037101563066244125
Valid Loss:  0.0002559712156653404
Epoch:  308  	Training Loss: 0.0002574039972387254
Test Loss:  0.00036923063453286886
Valid Loss:  0.0002551719080656767
Epoch:  309  	Training Loss: 0.00025668361922726035
Test Loss:  0.0003676185442600399
Valid Loss:  0.0002543899172451347
Epoch:  310  	Training Loss: 0.00025596568593755364
Test Loss:  0.00036614976124837995
Valid Loss:  0.00025363039458170533
Epoch:  311  	Training Loss: 0.000255265214946121
Test Loss:  0.0003647997509688139
Valid Loss:  0.0002528910990804434
Epoch:  312  	Training Loss: 0.0002545754541642964
Test Loss:  0.0003643122618086636
Valid Loss:  0.00025241082767024636
Epoch:  313  	Training Loss: 0.00025423162151128054
Test Loss:  0.00036382704274728894
Valid Loss:  0.00025200180243700743
Epoch:  314  	Training Loss: 0.00025389972142875195
Test Loss:  0.0003633487212937325
Valid Loss:  0.00025163718964904547
Epoch:  315  	Training Loss: 0.0002535746025387198
Test Loss:  0.00036287069087848067
Valid Loss:  0.000251285033300519
Epoch:  316  	Training Loss: 0.00025325806927867234
Test Loss:  0.0003623932716436684
Valid Loss:  0.00025093965814448893
Epoch:  317  	Training Loss: 0.0002529495395720005
Test Loss:  0.0003619192575570196
Valid Loss:  0.0002506008022464812
Epoch:  318  	Training Loss: 0.00025265561998821795
Test Loss:  0.00036145036574453115
Valid Loss:  0.0002502646530047059
Epoch:  319  	Training Loss: 0.0002523808798287064
Test Loss:  0.0003609991690609604
Valid Loss:  0.00024994206614792347
Epoch:  320  	Training Loss: 0.0002521089627407491
Test Loss:  0.00036055862437933683
Valid Loss:  0.0002496263477951288
Epoch:  321  	Training Loss: 0.0002518417895771563
Test Loss:  0.0003601183125283569
Valid Loss:  0.00024931240477599204
Epoch:  322  	Training Loss: 0.0002515837550163269
Test Loss:  0.0003603596705943346
Valid Loss:  0.0002494000073056668
Epoch:  323  	Training Loss: 0.0002510033664293587
Test Loss:  0.0003603339719120413
Valid Loss:  0.00024912331718951464
Epoch:  324  	Training Loss: 0.0002505301090423018
Test Loss:  0.0003602775977924466
Valid Loss:  0.00024889226187951863
Epoch:  325  	Training Loss: 0.00025004075723700225
Test Loss:  0.00036005734000355005
Valid Loss:  0.0002486253506503999
Epoch:  326  	Training Loss: 0.0002495876979082823
Test Loss:  0.0003596749738790095
Valid Loss:  0.00024837188539095223
Epoch:  327  	Training Loss: 0.00024915963876992464
Test Loss:  0.0003591806162148714
Valid Loss:  0.00024812924675643444
Epoch:  328  	Training Loss: 0.0002487496822141111
Test Loss:  0.00035861675860360265
Valid Loss:  0.00024789522285573184
Epoch:  329  	Training Loss: 0.00024835378280840814
Test Loss:  0.0003579994081519544
Valid Loss:  0.00024766710703261197
Epoch:  330  	Training Loss: 0.00024796841898933053
Test Loss:  0.0003573392750695348
Valid Loss:  0.0002474436187185347
Epoch:  331  	Training Loss: 0.0002475921646691859
Test Loss:  0.000356648291926831
Valid Loss:  0.0002472240012139082
Epoch:  332  	Training Loss: 0.00024722403031773865
Test Loss:  0.0003552712150849402
Valid Loss:  0.00024658592883497477
Epoch:  333  	Training Loss: 0.0002461677067913115
Test Loss:  0.0003537838929332793
Valid Loss:  0.0002455035864841193
Epoch:  334  	Training Loss: 0.00024513606331311166
Test Loss:  0.00035227712942287326
Valid Loss:  0.0002446096623316407
Epoch:  335  	Training Loss: 0.00024412130005657673
Test Loss:  0.0003507415531203151
Valid Loss:  0.00024365699209738523
Epoch:  336  	Training Loss: 0.0002431199827697128
Test Loss:  0.00034920391044579446
Valid Loss:  0.00024274094903375953
Epoch:  337  	Training Loss: 0.00024212947755586356
Test Loss:  0.0003476673737168312
Valid Loss:  0.00024182317429222167
Epoch:  338  	Training Loss: 0.0002411504538031295
Test Loss:  0.00034613447496667504
Valid Loss:  0.00024091664818115532
Epoch:  339  	Training Loss: 0.00024018427939154208
Test Loss:  0.0003445979382377118
Valid Loss:  0.00024001998826861382
Epoch:  340  	Training Loss: 0.00023922868422232568
Test Loss:  0.0003430477518122643
Valid Loss:  0.00023912990582175553
Epoch:  341  	Training Loss: 0.00023828595294617116
Test Loss:  0.0003415160463191569
Valid Loss:  0.00023822925868444145
 69%|██████▊   | 343/500 [04:03<02:12,  1.18it/s] 69%|██████▉   | 345/500 [04:04<01:34,  1.63it/s] 69%|██████▉   | 347/500 [04:04<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:04<00:50,  3.01it/s] 70%|███████   | 351/500 [04:10<02:57,  1.19s/it] 71%|███████   | 353/500 [04:10<02:05,  1.17it/s] 71%|███████   | 355/500 [04:11<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:11<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:11<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:17<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:17<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:17<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:17<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:18<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:24<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:24<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:24<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:24<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:24<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:31<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:31<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:31<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:31<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:31<00:36,  3.00it/s] 78%|███████▊  | 391/500 [04:38<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:38<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:38<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:38<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:38<00:33,  2.99it/s] 80%|████████  | 401/500 [04:44<01:56,  1.18s/it] 81%|████████  | 403/500 [04:45<01:22,  1.18it/s] 81%|████████  | 405/500 [04:45<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:45<00:41,  2.23it/s]Epoch:  342  	Training Loss: 0.00023733937996439636
Test Loss:  0.00034130766289308667
Valid Loss:  0.00023774526198394597
Epoch:  343  	Training Loss: 0.0002365834079682827
Test Loss:  0.0003405457246117294
Valid Loss:  0.00023690288071520627
Epoch:  344  	Training Loss: 0.00023586844326928258
Test Loss:  0.0003397908294573426
Valid Loss:  0.00023607828188687563
Epoch:  345  	Training Loss: 0.0002351630391785875
Test Loss:  0.000338954123435542
Valid Loss:  0.0002352128503844142
Epoch:  346  	Training Loss: 0.00023445238184649497
Test Loss:  0.00033818191150203347
Valid Loss:  0.00023440108634531498
Epoch:  347  	Training Loss: 0.0002337470359634608
Test Loss:  0.0003373236977495253
Valid Loss:  0.00023354531731456518
Epoch:  348  	Training Loss: 0.00023303840134758502
Test Loss:  0.0003365396405570209
Valid Loss:  0.00023274487466551363
Epoch:  349  	Training Loss: 0.00023234079708345234
Test Loss:  0.00033576684654690325
Valid Loss:  0.0002319558261660859
Epoch:  350  	Training Loss: 0.00023165380116552114
Test Loss:  0.00033500452991575
Valid Loss:  0.00023117873934097588
Epoch:  351  	Training Loss: 0.00023097687517292798
Test Loss:  0.0003342507407069206
Valid Loss:  0.00023041256645228714
Epoch:  352  	Training Loss: 0.0002303099463460967
Test Loss:  0.00033272389555349946
Valid Loss:  0.00022837425058241934
Epoch:  353  	Training Loss: 0.00022945081582292914
Test Loss:  0.0003319286915939301
Valid Loss:  0.0002277443854836747
Epoch:  354  	Training Loss: 0.0002288412651978433
Test Loss:  0.00033110613003373146
Valid Loss:  0.00022701027046423405
Epoch:  355  	Training Loss: 0.00022824955522082746
Test Loss:  0.0003303149715065956
Valid Loss:  0.00022630645253229886
Epoch:  356  	Training Loss: 0.0002276686718687415
Test Loss:  0.0003295382484793663
Valid Loss:  0.00022561094374395907
Epoch:  357  	Training Loss: 0.00022710426128469408
Test Loss:  0.00032878213096410036
Valid Loss:  0.00022493049618788064
Epoch:  358  	Training Loss: 0.0002265575749333948
Test Loss:  0.00032803553040139377
Valid Loss:  0.00022426039504352957
Epoch:  359  	Training Loss: 0.00022603280376642942
Test Loss:  0.0003273227484896779
Valid Loss:  0.0002236185100628063
Epoch:  360  	Training Loss: 0.00022551791334990412
Test Loss:  0.0003266312414780259
Valid Loss:  0.00022299482952803373
Epoch:  361  	Training Loss: 0.0002250112738693133
Test Loss:  0.0003259565564803779
Valid Loss:  0.00022238075325731188
Epoch:  362  	Training Loss: 0.00022451406402979046
Test Loss:  0.00032540681422688067
Valid Loss:  0.00022236882068682462
Epoch:  363  	Training Loss: 0.00022351305233314633
Test Loss:  0.0003240258083678782
Valid Loss:  0.0002208123478339985
Epoch:  364  	Training Loss: 0.00022254297800827771
Test Loss:  0.00032306244247592986
Valid Loss:  0.00022066046949476004
Epoch:  365  	Training Loss: 0.00022160109074320644
Test Loss:  0.0003214918833691627
Valid Loss:  0.00021929274953436106
Epoch:  366  	Training Loss: 0.0002206783537985757
Test Loss:  0.0003203091910108924
Valid Loss:  0.0002190280647482723
Epoch:  367  	Training Loss: 0.0002197738504037261
Test Loss:  0.00031868269434198737
Valid Loss:  0.00021780873066745698
Epoch:  368  	Training Loss: 0.0002188861253671348
Test Loss:  0.0003174020675942302
Valid Loss:  0.00021743265097029507
Epoch:  369  	Training Loss: 0.00021801763796247542
Test Loss:  0.0003157625033054501
Valid Loss:  0.00021630048286169767
Epoch:  370  	Training Loss: 0.00021716741321142763
Test Loss:  0.0003144492511637509
Valid Loss:  0.00021585647482424974
Epoch:  371  	Training Loss: 0.00021633008145727217
Test Loss:  0.00031285517616197467
Valid Loss:  0.00021481109433807433
Epoch:  372  	Training Loss: 0.00021550426026806235
Test Loss:  0.0003121222252957523
Valid Loss:  0.0002143770398106426
Epoch:  373  	Training Loss: 0.00021506205666810274
Test Loss:  0.00031140289502218366
Valid Loss:  0.0002139389980584383
Epoch:  374  	Training Loss: 0.0002146227052435279
Test Loss:  0.0003107002703472972
Valid Loss:  0.00021350393944885582
Epoch:  375  	Training Loss: 0.0002141865697922185
Test Loss:  0.0003099971800111234
Valid Loss:  0.00021306666894815862
Epoch:  376  	Training Loss: 0.0002137538540409878
Test Loss:  0.0003093007835559547
Valid Loss:  0.00021263095550239086
Epoch:  377  	Training Loss: 0.00021332656615413725
Test Loss:  0.0003086213837377727
Valid Loss:  0.0002121778961736709
Epoch:  378  	Training Loss: 0.0002129021449945867
Test Loss:  0.00030795513885095716
Valid Loss:  0.00021172224660404027
Epoch:  379  	Training Loss: 0.00021247983386274427
Test Loss:  0.0003072994586545974
Valid Loss:  0.00021126909996382892
Epoch:  380  	Training Loss: 0.00021205998200457543
Test Loss:  0.00030665419762954116
Valid Loss:  0.00021081628801766783
Epoch:  381  	Training Loss: 0.0002116360847139731
Test Loss:  0.0003060203162021935
Valid Loss:  0.00021029410709161311
Epoch:  382  	Training Loss: 0.00021115978597663343
Test Loss:  0.00030244182562455535
Valid Loss:  0.00020476528152357787
Epoch:  383  	Training Loss: 0.00020681106252595782
Test Loss:  0.000299761479254812
Valid Loss:  0.00020166681497357786
Epoch:  384  	Training Loss: 0.00020374951418489218
Test Loss:  0.0002974538365378976
Valid Loss:  0.00020020140800625086
Epoch:  385  	Training Loss: 0.00020194053649902344
Test Loss:  0.0002953929943032563
Valid Loss:  0.0001991261524381116
Epoch:  386  	Training Loss: 0.00020074228814337403
Test Loss:  0.00029343325877562165
Valid Loss:  0.00019831815734505653
Epoch:  387  	Training Loss: 0.00019986108236480504
Test Loss:  0.00029165169689804316
Valid Loss:  0.00019761937437579036
Epoch:  388  	Training Loss: 0.00019912965944968164
Test Loss:  0.0002900524123106152
Valid Loss:  0.00019695915398187935
Epoch:  389  	Training Loss: 0.0001984832779271528
Test Loss:  0.00028861084138043225
Valid Loss:  0.0001963177346624434
Epoch:  390  	Training Loss: 0.00019786834309343249
Test Loss:  0.00028731615748256445
Valid Loss:  0.00019570253789424896
Epoch:  391  	Training Loss: 0.000197291694348678
Test Loss:  0.0002861354732885957
Valid Loss:  0.00019512022845447063
Epoch:  392  	Training Loss: 0.00019674416398629546
Test Loss:  0.0002853230107575655
Valid Loss:  0.00019459867326077074
Epoch:  393  	Training Loss: 0.00019647556473501027
Test Loss:  0.0002845867711585015
Valid Loss:  0.00019426504150032997
Epoch:  394  	Training Loss: 0.0001962655078386888
Test Loss:  0.00028390143415890634
Valid Loss:  0.00019402298494242132
Epoch:  395  	Training Loss: 0.00019608266302384436
Test Loss:  0.0002832430473063141
Valid Loss:  0.0001938245550263673
Epoch:  396  	Training Loss: 0.00019591610180214047
Test Loss:  0.00028261353145353496
Valid Loss:  0.0001936600892804563
Epoch:  397  	Training Loss: 0.00019576356862671673
Test Loss:  0.00028200240922160447
Valid Loss:  0.00019351228547748178
Epoch:  398  	Training Loss: 0.00019562686793506145
Test Loss:  0.00028140906943008304
Valid Loss:  0.00019337769481353462
Epoch:  399  	Training Loss: 0.00019550391880329698
Test Loss:  0.0002808398858178407
Valid Loss:  0.0001932568266056478
Epoch:  400  	Training Loss: 0.00019539089407771826
Test Loss:  0.00028030300745740533
Valid Loss:  0.0001931487931869924
Epoch:  401  	Training Loss: 0.00019528521806932986
Test Loss:  0.00027980117010883987
Valid Loss:  0.00019304938905406743
Epoch:  402  	Training Loss: 0.00019518611952662468
Test Loss:  0.0002808060380630195
Valid Loss:  0.00019274723308626562
Epoch:  403  	Training Loss: 0.00019432255066931248
Test Loss:  0.00028012506663799286
Valid Loss:  0.0001909099955810234
Epoch:  404  	Training Loss: 0.0001929968420881778
Test Loss:  0.0002791734877973795
Valid Loss:  0.00018868950428441167
Epoch:  405  	Training Loss: 0.00019116923795081675
Test Loss:  0.00027852720813825727
Valid Loss:  0.00018711363372858614
Epoch:  406  	Training Loss: 0.00018968942458741367
Test Loss:  0.0002778212947305292
Valid Loss:  0.00018632672436069697
Epoch:  407  	Training Loss: 0.00018881246796809137
Test Loss:  0.00027701957151293755
Valid Loss:  0.00018590909894555807
Epoch:  408  	Training Loss: 0.00018822646234184504
Test Loss:  0.0002761218056548387
Valid Loss:  0.00018549064407125115
 82%|████████▏ | 409/500 [04:45<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:51<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:51<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:52<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:52<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:58<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:58<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:58<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:58<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:59<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:05<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:05<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:05<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:05<00:27,  2.25it/s] 88%|████████▊ | 439/500 [05:05<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:12<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:12<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:12<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:12<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:12<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:19<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:19<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:19<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:19<00:13,  2.93it/s] 92%|█████████▏| 461/500 [05:25<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:25<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:26<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:26<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:32<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:32<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:32<00:15,  1.64it/s]Epoch:  409  	Training Loss: 0.00018776807701215148
Test Loss:  0.0002752290165517479
Valid Loss:  0.00018515874398872256
Epoch:  410  	Training Loss: 0.00018738512881100178
Test Loss:  0.0002743855002336204
Valid Loss:  0.00018484637257643044
Epoch:  411  	Training Loss: 0.00018703468958847225
Test Loss:  0.0002735862508416176
Valid Loss:  0.00018455719691701233
Epoch:  412  	Training Loss: 0.00018670572899281979
Test Loss:  0.00027226938982494175
Valid Loss:  0.0001840565528254956
Epoch:  413  	Training Loss: 0.00018632152932696044
Test Loss:  0.00027104784385301173
Valid Loss:  0.00018369336612522602
Epoch:  414  	Training Loss: 0.00018597746384330094
Test Loss:  0.0002699198084883392
Valid Loss:  0.00018338306108489633
Epoch:  415  	Training Loss: 0.00018565823847893625
Test Loss:  0.0002688769600354135
Valid Loss:  0.0001831050030887127
Epoch:  416  	Training Loss: 0.00018535929848439991
Test Loss:  0.0002679098688531667
Valid Loss:  0.0001828492822824046
Epoch:  417  	Training Loss: 0.00018507693312130868
Test Loss:  0.00026701134629547596
Valid Loss:  0.0001826081715989858
Epoch:  418  	Training Loss: 0.0001848087558755651
Test Loss:  0.0002661847975105047
Valid Loss:  0.0001823761558625847
Epoch:  419  	Training Loss: 0.00018455290410201997
Test Loss:  0.00026541680563241243
Valid Loss:  0.0001821541809476912
Epoch:  420  	Training Loss: 0.00018431163334753364
Test Loss:  0.000264698697719723
Valid Loss:  0.00018194230506196618
Epoch:  421  	Training Loss: 0.0001840818440541625
Test Loss:  0.00026401999639347196
Valid Loss:  0.0001817377342376858
Epoch:  422  	Training Loss: 0.00018386630108579993
Test Loss:  0.0002632189425639808
Valid Loss:  0.00018107323558069766
Epoch:  423  	Training Loss: 0.00018331859610043466
Test Loss:  0.0002624114858917892
Valid Loss:  0.0001806204381864518
Epoch:  424  	Training Loss: 0.00018278088828083128
Test Loss:  0.00026161150890402496
Valid Loss:  0.00018015134264715016
Epoch:  425  	Training Loss: 0.0001822472841013223
Test Loss:  0.00026082052499987185
Valid Loss:  0.00017969435430131853
Epoch:  426  	Training Loss: 0.00018173216085415334
Test Loss:  0.0002600421430543065
Valid Loss:  0.0001792553230188787
Epoch:  427  	Training Loss: 0.0001812565024010837
Test Loss:  0.000259270949754864
Valid Loss:  0.00017884167027659714
Epoch:  428  	Training Loss: 0.00018080364679917693
Test Loss:  0.00025855074636638165
Valid Loss:  0.00017845738329924643
Epoch:  429  	Training Loss: 0.00018037531117442995
Test Loss:  0.00025785010075196624
Valid Loss:  0.0001781041210051626
Epoch:  430  	Training Loss: 0.00017998501425608993
Test Loss:  0.00025717326207086444
Valid Loss:  0.0001777789875632152
Epoch:  431  	Training Loss: 0.0001796294527594
Test Loss:  0.00025650160387158394
Valid Loss:  0.00017746404046192765
Epoch:  432  	Training Loss: 0.00017929414752870798
Test Loss:  0.00025568247656337917
Valid Loss:  0.00017722713528200984
Epoch:  433  	Training Loss: 0.00017833971651270986
Test Loss:  0.00025450787506997585
Valid Loss:  0.00017640214355196804
Epoch:  434  	Training Loss: 0.00017752559506334364
Test Loss:  0.0002533654624130577
Valid Loss:  0.00017559361003804952
Epoch:  435  	Training Loss: 0.0001767245412338525
Test Loss:  0.0002522287832107395
Valid Loss:  0.00017478500376455486
Epoch:  436  	Training Loss: 0.00017593125812709332
Test Loss:  0.00025116282631643116
Valid Loss:  0.00017399730859324336
Epoch:  437  	Training Loss: 0.00017513663624413311
Test Loss:  0.0002500816190149635
Valid Loss:  0.0001732035307213664
Epoch:  438  	Training Loss: 0.00017434176697861403
Test Loss:  0.00024909147759899497
Valid Loss:  0.00017243724141735584
Epoch:  439  	Training Loss: 0.00017351687711197883
Test Loss:  0.000248042430030182
Valid Loss:  0.0001716323458822444
Epoch:  440  	Training Loss: 0.00017269820091314614
Test Loss:  0.0002470437320880592
Valid Loss:  0.00017085159197449684
Epoch:  441  	Training Loss: 0.0001718770945444703
Test Loss:  0.00024599855532869697
Valid Loss:  0.0001700480788713321
Epoch:  442  	Training Loss: 0.0001710575306788087
Test Loss:  0.00024512503296136856
Valid Loss:  0.0001692953082965687
Epoch:  443  	Training Loss: 0.00017020049563143402
Test Loss:  0.0002439083473291248
Valid Loss:  0.0001681786379776895
Epoch:  444  	Training Loss: 0.00016917572065722197
Test Loss:  0.00024257367476820946
Valid Loss:  0.00016673438949510455
Epoch:  445  	Training Loss: 0.0001679121342021972
Test Loss:  0.00024110839876811951
Valid Loss:  0.00016518979100510478
Epoch:  446  	Training Loss: 0.0001665051531745121
Test Loss:  0.0002396660711383447
Valid Loss:  0.00016373404650948942
Epoch:  447  	Training Loss: 0.00016517298354301602
Test Loss:  0.0002383516839472577
Valid Loss:  0.0001624773140065372
Epoch:  448  	Training Loss: 0.00016401452012360096
Test Loss:  0.00023715161660220474
Valid Loss:  0.0001615122746443376
Epoch:  449  	Training Loss: 0.0001630737679079175
Test Loss:  0.00023600179702043533
Valid Loss:  0.00016073125880211592
Epoch:  450  	Training Loss: 0.00016229203902184963
Test Loss:  0.00023492837499361485
Valid Loss:  0.00016008310194592923
Epoch:  451  	Training Loss: 0.0001616169756744057
Test Loss:  0.00023395835887640715
Valid Loss:  0.00015949933731462806
Epoch:  452  	Training Loss: 0.00016099917411338538
Test Loss:  0.00023179508571047336
Valid Loss:  0.00015815423103049397
Epoch:  453  	Training Loss: 0.0001600246032467112
Test Loss:  0.00023027174756862223
Valid Loss:  0.00015752846957184374
Epoch:  454  	Training Loss: 0.0001590713218320161
Test Loss:  0.00022874164278618991
Valid Loss:  0.00015652779256924987
Epoch:  455  	Training Loss: 0.00015814971993677318
Test Loss:  0.00022747449111193419
Valid Loss:  0.00015573060954920948
Epoch:  456  	Training Loss: 0.00015725272533018142
Test Loss:  0.00022621452808380127
Valid Loss:  0.00015483856259379536
Epoch:  457  	Training Loss: 0.00015636815805919468
Test Loss:  0.00022508722031489015
Valid Loss:  0.00015402931603603065
Epoch:  458  	Training Loss: 0.00015549015370197594
Test Loss:  0.00022393823019228876
Valid Loss:  0.00015317703946493566
Epoch:  459  	Training Loss: 0.00015463042655028403
Test Loss:  0.00022277308744378388
Valid Loss:  0.0001523505779914558
Epoch:  460  	Training Loss: 0.00015377774252556264
Test Loss:  0.0002216549328295514
Valid Loss:  0.00015155455912463367
Epoch:  461  	Training Loss: 0.00015294407785404474
Test Loss:  0.00022055961017031223
Valid Loss:  0.00015077109856065363
Epoch:  462  	Training Loss: 0.00015212314610835165
Test Loss:  0.00022010429529473186
Valid Loss:  0.00015020277351140976
Epoch:  463  	Training Loss: 0.00015137027367018163
Test Loss:  0.00021918048150837421
Valid Loss:  0.00014938792446628213
Epoch:  464  	Training Loss: 0.00015066328342072666
Test Loss:  0.00021817667584400624
Valid Loss:  0.00014878231741022319
Epoch:  465  	Training Loss: 0.00014997208199929446
Test Loss:  0.00021712084708269686
Valid Loss:  0.0001480878854636103
Epoch:  466  	Training Loss: 0.0001492983428761363
Test Loss:  0.00021595005819108337
Valid Loss:  0.00014749594265595078
Epoch:  467  	Training Loss: 0.00014864090189803392
Test Loss:  0.00021486716286744922
Valid Loss:  0.00014686159556731582
Epoch:  468  	Training Loss: 0.00014799552445765585
Test Loss:  0.00021383502462413162
Valid Loss:  0.00014626745542045683
Epoch:  469  	Training Loss: 0.0001473611337132752
Test Loss:  0.0002128265768988058
Valid Loss:  0.00014568156620953232
Epoch:  470  	Training Loss: 0.00014673738041892648
Test Loss:  0.0002118378470186144
Valid Loss:  0.00014511308108922094
Epoch:  471  	Training Loss: 0.00014612358063459396
Test Loss:  0.00021086214110255241
Valid Loss:  0.00014454835036303848
Epoch:  472  	Training Loss: 0.00014551571803167462
Test Loss:  0.00021045937319286168
Valid Loss:  0.00014352139260154217
Epoch:  473  	Training Loss: 0.00014500234101433307
Test Loss:  0.00020998556283302605
Valid Loss:  0.00014346023090183735
Epoch:  474  	Training Loss: 0.00014451579772867262
Test Loss:  0.0002093735383823514
Valid Loss:  0.0001428035757271573
Epoch:  475  	Training Loss: 0.00014405208639800549
Test Loss:  0.00020871189190074801
Valid Loss:  0.00014255983114708215
 95%|█████████▌| 477/500 [05:33<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:33<00:06,  3.00it/s] 96%|█████████▌| 481/500 [05:39<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:39<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:39<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:40<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:46<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:46<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:46<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:46<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:46<00:00,  3.01it/s]100%|██████████| 500/500 [05:46<00:00,  1.44it/s]
Epoch:  476  	Training Loss: 0.00014360326167661697
Test Loss:  0.000207993492949754
Valid Loss:  0.00014207157073542476
Epoch:  477  	Training Loss: 0.00014316587476059794
Test Loss:  0.00020725192734971642
Valid Loss:  0.0001417592284269631
Epoch:  478  	Training Loss: 0.00014273854321800172
Test Loss:  0.00020649450016207993
Valid Loss:  0.0001413458667229861
Epoch:  479  	Training Loss: 0.00014231620298232883
Test Loss:  0.00020577135728672147
Valid Loss:  0.00014102138811722398
Epoch:  480  	Training Loss: 0.0001418923056917265
Test Loss:  0.00020503264386206865
Valid Loss:  0.0001406310184393078
Epoch:  481  	Training Loss: 0.00014147665933705866
Test Loss:  0.00020429276628419757
Valid Loss:  0.00014029358862899244
Epoch:  482  	Training Loss: 0.00014106821618042886
Test Loss:  0.00020338839385658503
Valid Loss:  0.00013993552420288324
Epoch:  483  	Training Loss: 0.00014061917318031192
Test Loss:  0.0002025388239417225
Valid Loss:  0.00013952888548374176
Epoch:  484  	Training Loss: 0.0001401838380843401
Test Loss:  0.00020178314298391342
Valid Loss:  0.0001391978730680421
Epoch:  485  	Training Loss: 0.00013975314504932612
Test Loss:  0.0002009814779739827
Valid Loss:  0.0001387882512062788
Epoch:  486  	Training Loss: 0.00013932387810200453
Test Loss:  0.0002002598048420623
Valid Loss:  0.00013846464571543038
Epoch:  487  	Training Loss: 0.0001389043463859707
Test Loss:  0.00019954006711486727
Valid Loss:  0.00013808702351525426
Epoch:  488  	Training Loss: 0.0001384935894748196
Test Loss:  0.00019886270456481725
Valid Loss:  0.0001377615553792566
Epoch:  489  	Training Loss: 0.00013809071970172226
Test Loss:  0.0001981916429940611
Valid Loss:  0.00013740277790930122
Epoch:  490  	Training Loss: 0.00013769495126325637
Test Loss:  0.00019754318054765463
Valid Loss:  0.00013707918697036803
Epoch:  491  	Training Loss: 0.00013730718637816608
Test Loss:  0.0001968910510186106
Valid Loss:  0.00013673094508703798
Epoch:  492  	Training Loss: 0.00013692470383830369
Test Loss:  0.00019367309869267046
Valid Loss:  0.00013595548807643354
Epoch:  493  	Training Loss: 0.0001359927118755877
Test Loss:  0.0001916155160870403
Valid Loss:  0.00013517437037080526
Epoch:  494  	Training Loss: 0.00013525575923267752
Test Loss:  0.00019011416588909924
Valid Loss:  0.00013451471750158817
Epoch:  495  	Training Loss: 0.00013459427282214165
Test Loss:  0.00018892640946432948
Valid Loss:  0.00013386100181378424
Epoch:  496  	Training Loss: 0.00013396622671280056
Test Loss:  0.00018791091861203313
Valid Loss:  0.0001332371321041137
Epoch:  497  	Training Loss: 0.00013335651601664722
Test Loss:  0.0001869893167167902
Valid Loss:  0.00013263030268717557
Epoch:  498  	Training Loss: 0.00013275575474835932
Test Loss:  0.00018613059364724904
Valid Loss:  0.0001320327282883227
Epoch:  499  	Training Loss: 0.0001321667805314064
Test Loss:  0.00018530679517425597
Valid Loss:  0.00013143783144187182
Epoch:  500  	Training Loss: 0.00013158883666619658
Test Loss:  0.00018449996423441917
Valid Loss:  0.00013085661339573562
seed is  9
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.30it/s]  1%|          | 4/500 [00:00<00:30, 16.01it/s]  1%|          | 6/500 [00:00<00:30, 16.26it/s]  2%|▏         | 8/500 [00:00<00:30, 16.39it/s]  2%|▏         | 10/500 [00:00<00:29, 16.47it/s]  2%|▏         | 12/500 [00:00<00:29, 16.57it/s]  3%|▎         | 14/500 [00:00<00:29, 16.54it/s]  3%|▎         | 16/500 [00:00<00:29, 16.55it/s]  4%|▎         | 18/500 [00:01<00:29, 16.60it/s]  4%|▍         | 20/500 [00:01<00:28, 16.64it/s]  4%|▍         | 22/500 [00:01<00:28, 16.59it/s]  5%|▍         | 24/500 [00:01<00:28, 16.57it/s]  5%|▌         | 26/500 [00:01<00:28, 16.49it/s]  6%|▌         | 28/500 [00:01<00:28, 16.48it/s]  6%|▌         | 30/500 [00:01<00:28, 16.45it/s]  6%|▋         | 32/500 [00:01<00:28, 16.38it/s]  7%|▋         | 34/500 [00:02<00:28, 16.42it/s]  7%|▋         | 36/500 [00:02<00:28, 16.46it/s]  8%|▊         | 38/500 [00:02<00:28, 16.42it/s]  8%|▊         | 40/500 [00:02<00:27, 16.48it/s]  8%|▊         | 42/500 [00:02<00:28, 15.97it/s]  9%|▉         | 44/500 [00:02<00:28, 15.98it/s]  9%|▉         | 46/500 [00:02<00:28, 16.10it/s] 10%|▉         | 48/500 [00:02<00:27, 16.20it/s] 10%|█         | 50/500 [00:03<00:27, 16.34it/s] 10%|█         | 52/500 [00:03<00:27, 16.25it/s] 11%|█         | 54/500 [00:03<00:27, 16.21it/s] 11%|█         | 56/500 [00:03<00:28, 15.64it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.78it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.54it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.70it/s] 13%|█▎        | 64/500 [00:03<00:27, 15.88it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.78it/s] 14%|█▎        | 68/500 [00:04<00:28, 15.35it/s] 14%|█▍        | 70/500 [00:04<00:29, 14.79it/s] 14%|█▍        | 72/500 [00:04<00:28, 15.06it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.61it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.91it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.07it/s] 16%|█▌        | 80/500 [00:04<00:26, 15.90it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.14it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.18it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.88it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.00it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.11it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.28it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.44it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.45it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.49it/s] 20%|██        | 100/500 [00:06<00:24, 16.54it/s] 20%|██        | 102/500 [00:06<00:24, 16.55it/s] 21%|██        | 104/500 [00:06<00:24, 16.23it/s] 21%|██        | 106/500 [00:06<00:24, 16.39it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.47it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.52it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.58it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.61it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.61it/s] 24%|██▎       | 118/500 [00:07<00:22, 16.62it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.68it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.69it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.67it/s]Epoch:  1  	Training Loss: 0.0821116492152214
Test Loss:  1794.533203125
Valid Loss:  1795.115478515625
Epoch:  2  	Training Loss: 1794.875244140625
Test Loss:  653951854706688.0
Valid Loss:  656432265428992.0
Epoch:  3  	Training Loss: 655951765962752.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.69it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.73it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.67it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.66it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.48it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.57it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.61it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.65it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.67it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.64it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.50it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.30it/s] 30%|███       | 150/500 [00:09<00:21, 16.37it/s] 30%|███       | 152/500 [00:09<00:21, 16.45it/s] 31%|███       | 154/500 [00:09<00:21, 16.34it/s] 31%|███       | 156/500 [00:09<00:21, 16.23it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.03it/s] 32%|███▏      | 160/500 [00:09<00:21, 16.04it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.28it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.32it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.29it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.22it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.01it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.06it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.10it/s] 35%|███▌      | 176/500 [00:10<00:20, 15.90it/s] 36%|███▌      | 178/500 [00:10<00:20, 15.67it/s] 36%|███▌      | 180/500 [00:11<00:21, 15.14it/s] 36%|███▋      | 182/500 [00:11<00:21, 14.84it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.28it/s] 37%|███▋      | 186/500 [00:11<00:20, 15.46it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.78it/s] 38%|███▊      | 190/500 [00:11<00:19, 15.78it/s] 38%|███▊      | 192/500 [00:11<00:19, 15.84it/s] 39%|███▉      | 194/500 [00:11<00:19, 16.03it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.05it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.15it/s] 40%|████      | 200/500 [00:12<00:18, 16.07it/s] 40%|████      | 202/500 [00:12<00:18, 16.04it/s] 41%|████      | 204/500 [00:12<00:18, 16.29it/s] 41%|████      | 206/500 [00:12<00:17, 16.37it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.31it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.47it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.56it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.61it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.68it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.42it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.25it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.38it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.41it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.44it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.50it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.56it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.58it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.44it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.50it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.15it/s] 48%|████▊     | 240/500 [00:14<00:16, 16.24it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.26it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.38it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.46it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.48it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.52it/s] 50%|█████     | 252/500 [00:15<00:15, 16.35it/s] 51%|█████     | 254/500 [00:15<00:15, 16.36it/s] 51%|█████     | 256/500 [00:15<00:15, 16.17it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.26it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.39it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.37it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.36it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.08it/s] 54%|█████▎    | 268/500 [00:16<00:14, 15.93it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.04it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.00it/s] 55%|█████▍    | 274/500 [00:16<00:14, 16.01it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.91it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.04it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.46it/s] 56%|█████▋    | 282/500 [00:17<00:14, 15.51it/s] 57%|█████▋    | 284/500 [00:17<00:13, 15.46it/s] 57%|█████▋    | 286/500 [00:17<00:13, 15.71it/s] 58%|█████▊    | 288/500 [00:17<00:13, 15.81it/s] 58%|█████▊    | 290/500 [00:17<00:13, 15.65it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.62it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.85it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.03it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.12it/s] 60%|██████    | 300/500 [00:18<00:12, 16.24it/s] 60%|██████    | 302/500 [00:18<00:12, 16.34it/s] 61%|██████    | 304/500 [00:18<00:11, 16.43it/s] 61%|██████    | 306/500 [00:18<00:11, 16.34it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.41it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.48it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.54it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.32it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.38it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.41it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.45it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.47it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.49it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.52it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.51it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.00it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.19it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.06it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.08it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.23it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.32it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.30it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.17it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.10it/s] 70%|██████▉   | 348/500 [00:21<00:09, 15.97it/s] 70%|███████   | 350/500 [00:21<00:09, 16.08it/s] 70%|███████   | 352/500 [00:21<00:09, 15.99it/s] 71%|███████   | 354/500 [00:21<00:09, 16.07it/s] 71%|███████   | 356/500 [00:21<00:08, 16.02it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.15it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.30it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.00it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.93it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.93it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.98it/s] 74%|███████▍  | 370/500 [00:22<00:08, 15.88it/s] 74%|███████▍  | 372/500 [00:22<00:08, 15.19it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:08, 15.58it/s] 75%|███████▌  | 376/500 [00:23<00:07, 15.88it/s] 76%|███████▌  | 378/500 [00:23<00:07, 15.98it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.22it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.03it/s] 77%|███████▋  | 384/500 [00:23<00:07, 15.87it/s] 77%|███████▋  | 386/500 [00:23<00:07, 15.95it/s] 78%|███████▊  | 388/500 [00:23<00:07, 15.95it/s] 78%|███████▊  | 390/500 [00:24<00:06, 15.96it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.16it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.29it/s] 79%|███████▉  | 396/500 [00:24<00:06, 15.84it/s] 80%|███████▉  | 398/500 [00:24<00:06, 15.95it/s] 80%|████████  | 400/500 [00:24<00:06, 16.17it/s] 80%|████████  | 402/500 [00:24<00:06, 16.13it/s] 81%|████████  | 404/500 [00:24<00:05, 16.28it/s] 81%|████████  | 406/500 [00:25<00:05, 16.18it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.22it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.27it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.40it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.45it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.43it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.47it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.48it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.49it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.51it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.51it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.52it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.47it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.31it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.33it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.38it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.44it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.46it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.48it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.53it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.45it/s] 90%|████████▉ | 448/500 [00:27<00:03, 15.99it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.10it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.22it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.38it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.50it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.37it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.22it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.25it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.32it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.28it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.28it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.18it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.25it/s] 95%|█████████▍| 474/500 [00:29<00:01, 15.95it/s] 95%|█████████▌| 476/500 [00:29<00:01, 15.72it/s] 96%|█████████▌| 478/500 [00:29<00:01, 15.78it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.01it/s] 96%|█████████▋| 482/500 [00:29<00:01, 15.77it/s] 97%|█████████▋| 484/500 [00:29<00:01, 15.54it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.68it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.90it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.10it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.13it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.87it/s] 99%|█████████▉| 496/500 [00:30<00:00, 15.81it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 15.86it/s]100%|██████████| 500/500 [00:30<00:00, 16.04it/s]100%|██████████| 500/500 [00:30<00:00, 16.18it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  9
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:12,  6.16s/it]  1%|          | 3/500 [00:06<13:38,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:12<10:39,  1.31s/it]  3%|▎         | 13/500 [00:13<07:16,  1.12it/s]  3%|▎         | 15/500 [00:19<13:03,  1.61s/it]  3%|▎         | 17/500 [00:19<09:05,  1.13s/it]  4%|▍         | 19/500 [00:19<06:24,  1.25it/s]  4%|▍         | 21/500 [00:31<19:26,  2.43s/it]  5%|▍         | 23/500 [00:31<13:37,  1.71s/it]  5%|▌         | 25/500 [00:38<16:53,  2.13s/it]  5%|▌         | 27/500 [00:38<11:53,  1.51s/it]  6%|▌         | 29/500 [00:38<08:26,  1.08s/it]  6%|▌         | 31/500 [00:50<20:34,  2.63s/it]  7%|▋         | 33/500 [00:51<14:29,  1.86s/it]  7%|▋         | 35/500 [00:57<17:20,  2.24s/it]  7%|▋         | 37/500 [00:57<12:14,  1.59s/it]  8%|▊         | 39/500 [00:57<08:40,  1.13s/it]  8%|▊         | 41/500 [01:09<20:10,  2.64s/it]  9%|▊         | 43/500 [01:10<14:13,  1.87s/it]  9%|▉         | 45/500 [01:16<16:56,  2.23s/it]  9%|▉         | 47/500 [01:16<11:57,  1.58s/it] 10%|▉         | 49/500 [01:16<08:29,  1.13s/it] 10%|█         | 51/500 [01:28<19:42,  2.63s/it] 11%|█         | 53/500 [01:28<13:53,  1.86s/it] 11%|█         | 55/500 [01:35<16:34,  2.23s/it] 11%|█▏        | 57/500 [01:35<11:42,  1.58s/it] 12%|█▏        | 59/500 [01:35<08:17,  1.13s/it] 12%|█▏        | 61/500 [01:47<19:19,  2.64s/it] 13%|█▎        | 63/500 [01:47<13:36,  1.87s/it]Epoch:  1  	Training Loss: 0.0821116492152214
Test Loss:  35.830352783203125
Valid Loss:  35.39064407348633
Epoch:  2  	Training Loss: 35.55016326904297
Test Loss:  23.271671295166016
Valid Loss:  23.41382598876953
Epoch:  3  	Training Loss: 23.406448364257812
Test Loss:  0.07753258943557739
Valid Loss:  0.06868624687194824
Epoch:  4  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  5  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  6  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  7  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  8  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  9  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  10  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  11  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  12  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  13  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  14  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  15  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  17  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868624687194824
Epoch:  18  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  19  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  20  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  22  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  23  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  24  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  25  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  27  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  28  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  29  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  30  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  32  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  33  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  34  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  35  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  37  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  38  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  39  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  40  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  42  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  43  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  44  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  45  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  47  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  48  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  49  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  50  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  52  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  53  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  54  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  55  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  57  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  58  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  59  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  60  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  62  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  63  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
 13%|█▎        | 65/500 [01:54<16:13,  2.24s/it] 13%|█▎        | 67/500 [01:54<11:27,  1.59s/it] 14%|█▍        | 69/500 [01:54<08:08,  1.13s/it] 14%|█▍        | 69/500 [02:04<08:08,  1.13s/it] 14%|█▍        | 71/500 [02:06<18:58,  2.65s/it] 15%|█▍        | 73/500 [02:06<13:22,  1.88s/it] 15%|█▌        | 75/500 [02:13<16:05,  2.27s/it] 15%|█▌        | 77/500 [02:13<11:21,  1.61s/it] 16%|█▌        | 79/500 [02:13<08:05,  1.15s/it] 16%|█▌        | 79/500 [02:24<08:05,  1.15s/it] 16%|█▌        | 81/500 [02:26<18:47,  2.69s/it] 17%|█▋        | 83/500 [02:26<13:14,  1.90s/it] 17%|█▋        | 85/500 [02:32<15:49,  2.29s/it] 17%|█▋        | 87/500 [02:32<11:09,  1.62s/it] 18%|█▊        | 89/500 [02:32<07:54,  1.15s/it] 18%|█▊        | 89/500 [02:44<07:54,  1.15s/it] 18%|█▊        | 91/500 [02:45<18:13,  2.67s/it] 19%|█▊        | 93/500 [02:45<12:50,  1.89s/it] 19%|█▉        | 95/500 [02:51<15:16,  2.26s/it] 19%|█▉        | 97/500 [02:51<10:46,  1.60s/it] 20%|█▉        | 99/500 [02:51<07:38,  1.14s/it] 20%|██        | 101/500 [03:04<17:34,  2.64s/it] 21%|██        | 103/500 [03:04<12:22,  1.87s/it] 21%|██        | 105/500 [03:10<14:47,  2.25s/it] 21%|██▏       | 107/500 [03:10<10:27,  1.60s/it] 22%|██▏       | 109/500 [03:10<07:24,  1.14s/it] 22%|██▏       | 111/500 [03:23<17:18,  2.67s/it] 23%|██▎       | 113/500 [03:23<12:11,  1.89s/it] 23%|██▎       | 115/500 [03:29<14:31,  2.26s/it] 23%|██▎       | 117/500 [03:29<10:14,  1.61s/it] 24%|██▍       | 119/500 [03:30<07:15,  1.14s/it] 24%|██▍       | 121/500 [03:42<16:48,  2.66s/it] 25%|██▍       | 123/500 [03:42<11:50,  1.89s/it]Epoch:  64  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  65  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  67  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  68  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  69  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  70  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  72  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  73  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  74  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  75  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  77  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  78  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  79  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  80  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  82  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  83  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  84  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  85  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  87  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  88  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  89  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  90  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  92  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  93  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  94  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  95  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  97  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  98  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  99  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  100  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  102  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  103  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  104  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  105  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  107  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  108  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  109  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  110  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  112  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  113  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  114  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  115  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  117  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  118  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  119  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  120  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  122  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  123  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  124  	Training Loss: 0.0733054131269455
Test Loss:   25%|██▌       | 125/500 [03:48<14:05,  2.25s/it] 25%|██▌       | 127/500 [03:49<09:56,  1.60s/it] 26%|██▌       | 129/500 [03:49<07:02,  1.14s/it] 26%|██▌       | 131/500 [04:01<16:17,  2.65s/it] 27%|██▋       | 133/500 [04:01<11:28,  1.88s/it] 27%|██▋       | 135/500 [04:08<13:47,  2.27s/it] 27%|██▋       | 137/500 [04:08<09:43,  1.61s/it] 28%|██▊       | 139/500 [04:08<06:53,  1.15s/it] 28%|██▊       | 141/500 [04:20<15:56,  2.66s/it] 29%|██▊       | 143/500 [04:20<11:13,  1.89s/it] 29%|██▉       | 145/500 [04:27<13:21,  2.26s/it] 29%|██▉       | 147/500 [04:27<09:25,  1.60s/it] 30%|██▉       | 149/500 [04:27<06:41,  1.14s/it] 30%|███       | 151/500 [04:39<15:37,  2.69s/it] 31%|███       | 153/500 [04:40<10:59,  1.90s/it] 31%|███       | 155/500 [04:46<13:07,  2.28s/it] 31%|███▏      | 157/500 [04:46<09:15,  1.62s/it] 32%|███▏      | 159/500 [04:46<06:33,  1.15s/it] 32%|███▏      | 161/500 [04:59<15:07,  2.68s/it] 33%|███▎      | 163/500 [04:59<10:38,  1.89s/it] 33%|███▎      | 165/500 [05:05<12:41,  2.27s/it] 33%|███▎      | 167/500 [05:05<08:56,  1.61s/it] 34%|███▍      | 169/500 [05:05<06:19,  1.15s/it] 34%|███▍      | 171/500 [05:18<14:40,  2.68s/it] 35%|███▍      | 173/500 [05:18<10:19,  1.89s/it] 35%|███▌      | 175/500 [05:24<12:18,  2.27s/it] 35%|███▌      | 177/500 [05:24<08:40,  1.61s/it] 36%|███▌      | 179/500 [05:25<06:08,  1.15s/it] 36%|███▌      | 181/500 [05:37<14:06,  2.65s/it] 37%|███▋      | 183/500 [05:37<09:55,  1.88s/it]0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  125  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  127  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  128  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  129  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  130  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  132  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  133  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  134  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  135  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  137  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  138  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  139  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  140  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  142  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  143  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  144  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  145  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  147  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  148  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  149  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  150  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  152  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  153  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  154  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  155  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  157  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  158  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  159  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  160  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  162  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  163  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  164  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  165  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  167  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  168  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  169  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  170  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  172  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  173  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  174  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  175  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  177  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  178  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  179  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  180  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868624687194824
Epoch:  182  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  183  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  184  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:   37%|███▋      | 185/500 [05:43<11:50,  2.26s/it] 37%|███▋      | 187/500 [05:43<08:21,  1.60s/it] 38%|███▊      | 189/500 [05:44<05:54,  1.14s/it] 38%|███▊      | 189/500 [05:54<05:54,  1.14s/it] 38%|███▊      | 191/500 [05:56<13:45,  2.67s/it] 39%|███▊      | 193/500 [05:56<09:40,  1.89s/it] 39%|███▉      | 195/500 [06:02<11:26,  2.25s/it] 39%|███▉      | 197/500 [06:03<08:03,  1.60s/it] 40%|███▉      | 199/500 [06:03<05:42,  1.14s/it] 40%|███▉      | 199/500 [06:14<05:42,  1.14s/it] 40%|████      | 201/500 [06:15<13:10,  2.64s/it] 41%|████      | 203/500 [06:15<09:16,  1.87s/it] 41%|████      | 205/500 [06:21<11:04,  2.25s/it] 41%|████▏     | 207/500 [06:22<07:48,  1.60s/it] 42%|████▏     | 209/500 [06:22<05:30,  1.14s/it] 42%|████▏     | 211/500 [06:34<12:49,  2.66s/it] 43%|████▎     | 213/500 [06:34<09:02,  1.89s/it] 43%|████▎     | 215/500 [06:41<10:47,  2.27s/it] 43%|████▎     | 217/500 [06:41<07:35,  1.61s/it] 44%|████▍     | 219/500 [06:41<05:22,  1.15s/it] 44%|████▍     | 221/500 [06:54<12:36,  2.71s/it] 45%|████▍     | 223/500 [06:54<08:51,  1.92s/it] 45%|████▌     | 225/500 [07:00<10:34,  2.31s/it] 45%|████▌     | 227/500 [07:00<07:26,  1.64s/it] 46%|████▌     | 229/500 [07:00<05:15,  1.16s/it] 46%|████▌     | 231/500 [07:13<12:03,  2.69s/it] 47%|████▋     | 233/500 [07:13<08:28,  1.90s/it] 47%|████▋     | 235/500 [07:19<10:02,  2.27s/it] 47%|████▋     | 237/500 [07:20<07:04,  1.61s/it] 48%|████▊     | 239/500 [07:20<05:00,  1.15s/it] 48%|████▊     | 241/500 [07:32<11:37,  2.69s/it] 49%|████▊     | 243/500 [07:32<08:10,  1.91s/it]0.06868623942136765
Epoch:  185  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  187  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  188  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  189  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  190  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  192  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  193  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  194  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  195  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  197  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  198  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  199  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  200  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  202  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  203  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  204  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  205  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  207  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  208  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  209  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  210  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  212  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  213  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  214  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  215  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  217  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  218  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  219  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  220  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  222  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  223  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  224  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868624687194824
Epoch:  225  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  227  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  228  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  229  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  230  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  232  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  233  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  234  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  235  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  237  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  238  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  239  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  240  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  242  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  243  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  244  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
 49%|████▉     | 245/500 [07:39<09:43,  2.29s/it] 49%|████▉     | 247/500 [07:39<06:50,  1.62s/it] 50%|████▉     | 249/500 [07:39<04:49,  1.15s/it] 50%|█████     | 251/500 [07:52<11:12,  2.70s/it] 51%|█████     | 253/500 [07:52<07:52,  1.91s/it] 51%|█████     | 255/500 [07:58<09:15,  2.27s/it] 51%|█████▏    | 257/500 [07:58<06:30,  1.61s/it] 52%|█████▏    | 259/500 [07:58<04:37,  1.15s/it] 52%|█████▏    | 261/500 [08:11<10:40,  2.68s/it] 53%|█████▎    | 263/500 [08:11<07:29,  1.90s/it] 53%|█████▎    | 265/500 [08:17<08:54,  2.28s/it] 53%|█████▎    | 267/500 [08:17<06:16,  1.62s/it] 54%|█████▍    | 269/500 [08:18<04:25,  1.15s/it] 54%|█████▍    | 271/500 [08:30<10:10,  2.67s/it] 55%|█████▍    | 273/500 [08:30<07:08,  1.89s/it] 55%|█████▌    | 275/500 [08:36<08:29,  2.27s/it] 55%|█████▌    | 277/500 [08:36<05:58,  1.61s/it] 56%|█████▌    | 279/500 [08:37<04:13,  1.15s/it] 56%|█████▌    | 281/500 [08:49<09:46,  2.68s/it] 57%|█████▋    | 283/500 [08:49<06:51,  1.90s/it] 57%|█████▋    | 285/500 [08:56<08:10,  2.28s/it] 57%|█████▋    | 287/500 [08:56<05:44,  1.62s/it] 58%|█████▊    | 289/500 [08:56<04:03,  1.15s/it] 58%|█████▊    | 291/500 [09:08<09:20,  2.68s/it] 59%|█████▊    | 293/500 [09:09<06:32,  1.90s/it] 59%|█████▉    | 295/500 [09:15<07:42,  2.26s/it] 59%|█████▉    | 297/500 [09:15<05:24,  1.60s/it] 60%|█████▉    | 299/500 [09:15<03:49,  1.14s/it] 60%|██████    | 301/500 [09:27<08:45,  2.64s/it] 61%|██████    | 303/500 [09:27<06:08,  1.87s/it]Epoch:  245  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  247  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  248  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  249  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  250  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  252  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  253  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  254  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  255  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  257  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  258  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  259  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  260  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  262  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  263  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  264  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  265  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  267  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  268  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  269  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  270  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  272  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  273  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  274  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  275  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  277  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  278  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  279  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  280  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  282  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  283  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  284  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  285  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  287  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  288  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  289  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  290  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  292  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  293  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  294  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  295  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  297  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  298  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  299  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  300  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  302  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  303  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  304  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
 61%|██████    | 305/500 [09:34<07:21,  2.26s/it] 61%|██████▏   | 307/500 [09:34<05:09,  1.61s/it] 62%|██████▏   | 309/500 [09:34<03:38,  1.14s/it] 62%|██████▏   | 309/500 [09:44<03:38,  1.14s/it] 62%|██████▏   | 311/500 [09:47<08:23,  2.66s/it] 63%|██████▎   | 313/500 [09:47<05:52,  1.89s/it] 63%|██████▎   | 315/500 [09:53<07:00,  2.27s/it] 63%|██████▎   | 317/500 [09:53<04:54,  1.61s/it] 64%|██████▍   | 319/500 [09:53<03:27,  1.15s/it] 64%|██████▍   | 319/500 [10:04<03:27,  1.15s/it] 64%|██████▍   | 321/500 [10:06<07:55,  2.66s/it] 65%|██████▍   | 323/500 [10:06<05:33,  1.88s/it] 65%|██████▌   | 325/500 [10:12<06:33,  2.25s/it] 65%|██████▌   | 327/500 [10:12<04:36,  1.60s/it] 66%|██████▌   | 329/500 [10:12<03:14,  1.14s/it] 66%|██████▌   | 329/500 [10:24<03:14,  1.14s/it] 66%|██████▌   | 331/500 [10:25<07:26,  2.64s/it] 67%|██████▋   | 333/500 [10:25<05:12,  1.87s/it] 67%|██████▋   | 335/500 [10:31<06:11,  2.25s/it] 67%|██████▋   | 337/500 [10:31<04:20,  1.60s/it] 68%|██████▊   | 339/500 [10:31<03:03,  1.14s/it] 68%|██████▊   | 341/500 [10:44<07:06,  2.68s/it] 69%|██████▊   | 343/500 [10:44<04:58,  1.90s/it] 69%|██████▉   | 345/500 [10:50<05:57,  2.31s/it] 69%|██████▉   | 347/500 [10:51<04:10,  1.64s/it] 70%|██████▉   | 349/500 [10:51<02:55,  1.16s/it] 70%|███████   | 351/500 [11:03<06:41,  2.70s/it] 71%|███████   | 353/500 [11:03<04:40,  1.91s/it] 71%|███████   | 355/500 [11:10<05:30,  2.28s/it] 71%|███████▏  | 357/500 [11:10<03:51,  1.62s/it] 72%|███████▏  | 359/500 [11:10<02:42,  1.15s/it] 72%|███████▏  | 361/500 [11:22<06:12,  2.68s/it] 73%|███████▎  | 363/500 [11:23<04:20,  1.90s/it]Epoch:  305  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  307  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  308  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  309  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  310  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  312  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  313  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  314  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  315  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  317  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  318  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  319  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868624687194824
Epoch:  320  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  322  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  323  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  324  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  325  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  327  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  328  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  329  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  330  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  332  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  333  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  334  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  335  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  337  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  338  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  339  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  340  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  342  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  343  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  344  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  345  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  347  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  348  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  349  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  350  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  352  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  353  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  354  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  355  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  357  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  358  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  359  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  360  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  362  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  363  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  364  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
 73%|███████▎  | 365/500 [11:29<05:06,  2.27s/it] 73%|███████▎  | 367/500 [11:29<03:33,  1.61s/it] 74%|███████▍  | 369/500 [11:29<02:30,  1.15s/it] 74%|███████▍  | 371/500 [11:42<05:44,  2.67s/it] 75%|███████▍  | 373/500 [11:42<04:00,  1.89s/it] 75%|███████▌  | 375/500 [11:48<04:41,  2.25s/it] 75%|███████▌  | 377/500 [11:48<03:16,  1.60s/it] 76%|███████▌  | 379/500 [11:48<02:17,  1.14s/it] 76%|███████▌  | 381/500 [12:01<05:15,  2.65s/it] 77%|███████▋  | 383/500 [12:01<03:39,  1.88s/it] 77%|███████▋  | 385/500 [12:07<04:18,  2.25s/it] 77%|███████▋  | 387/500 [12:07<03:00,  1.60s/it] 78%|███████▊  | 389/500 [12:07<02:06,  1.14s/it] 78%|███████▊  | 391/500 [12:20<04:52,  2.68s/it] 79%|███████▊  | 393/500 [12:20<03:23,  1.90s/it] 79%|███████▉  | 395/500 [12:26<03:57,  2.26s/it] 79%|███████▉  | 397/500 [12:26<02:45,  1.61s/it] 80%|███████▉  | 399/500 [12:26<01:55,  1.14s/it] 80%|████████  | 401/500 [12:39<04:23,  2.67s/it] 81%|████████  | 403/500 [12:39<03:03,  1.89s/it] 81%|████████  | 405/500 [12:45<03:34,  2.26s/it] 81%|████████▏ | 407/500 [12:45<02:28,  1.60s/it] 82%|████████▏ | 409/500 [12:46<01:43,  1.14s/it] 82%|████████▏ | 411/500 [12:58<03:57,  2.67s/it] 83%|████████▎ | 413/500 [12:58<02:44,  1.89s/it] 83%|████████▎ | 415/500 [13:04<03:11,  2.26s/it] 83%|████████▎ | 417/500 [13:05<02:12,  1.60s/it] 84%|████████▍ | 419/500 [13:05<01:32,  1.14s/it] 84%|████████▍ | 421/500 [13:17<03:31,  2.67s/it] 85%|████████▍ | 423/500 [13:17<02:25,  1.89s/it]Epoch:  365  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  367  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  368  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  369  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  370  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  372  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  373  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  374  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  375  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  377  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  378  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  379  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  380  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  382  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  383  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  384  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  385  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  387  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  388  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  389  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  390  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  392  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  393  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  394  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  395  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0733054056763649
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  397  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  398  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  399  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  400  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  402  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  403  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  404  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  405  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  407  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623197078705
Epoch:  408  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  409  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  410  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  412  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  413  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868624687194824
Epoch:  414  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  415  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  417  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  418  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  419  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  420  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  422  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  423  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  424  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
 85%|████████▌ | 425/500 [13:24<02:50,  2.28s/it] 85%|████████▌ | 427/500 [13:24<01:57,  1.61s/it] 86%|████████▌ | 429/500 [13:24<01:21,  1.15s/it] 86%|████████▌ | 429/500 [13:34<01:21,  1.15s/it] 86%|████████▌ | 431/500 [13:36<03:04,  2.67s/it] 87%|████████▋ | 433/500 [13:36<02:06,  1.89s/it] 87%|████████▋ | 435/500 [13:43<02:27,  2.28s/it] 87%|████████▋ | 437/500 [13:43<01:41,  1.61s/it] 88%|████████▊ | 439/500 [13:43<01:10,  1.15s/it] 88%|████████▊ | 439/500 [13:54<01:10,  1.15s/it] 88%|████████▊ | 441/500 [13:55<02:36,  2.65s/it] 89%|████████▊ | 443/500 [13:56<01:47,  1.88s/it] 89%|████████▉ | 445/500 [14:02<02:03,  2.24s/it] 89%|████████▉ | 447/500 [14:02<01:24,  1.59s/it] 90%|████████▉ | 449/500 [14:02<00:57,  1.13s/it] 90%|████████▉ | 449/500 [14:14<00:57,  1.13s/it] 90%|█████████ | 451/500 [14:15<02:11,  2.68s/it] 91%|█████████ | 453/500 [14:15<01:29,  1.90s/it] 91%|█████████ | 455/500 [14:21<01:42,  2.27s/it] 91%|█████████▏| 457/500 [14:21<01:09,  1.61s/it] 92%|█████████▏| 459/500 [14:21<00:47,  1.15s/it] 92%|█████████▏| 461/500 [14:34<01:45,  2.70s/it] 93%|█████████▎| 463/500 [14:34<01:10,  1.92s/it] 93%|█████████▎| 465/500 [14:40<01:20,  2.29s/it] 93%|█████████▎| 467/500 [14:41<00:53,  1.62s/it] 94%|█████████▍| 469/500 [14:41<00:35,  1.15s/it] 94%|█████████▍| 471/500 [14:53<01:17,  2.67s/it] 95%|█████████▍| 473/500 [14:53<00:51,  1.89s/it] 95%|█████████▌| 475/500 [15:00<00:57,  2.28s/it] 95%|█████████▌| 477/500 [15:00<00:37,  1.62s/it] 96%|█████████▌| 479/500 [15:00<00:24,  1.15s/it] 96%|█████████▌| 481/500 [15:13<00:51,  2.69s/it] 97%|█████████▋| 483/500 [15:13<00:32,  1.91s/it]Epoch:  425  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  427  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  428  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  429  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  430  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  432  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  433  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  434  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  435  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  437  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  438  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  439  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  440  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  442  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  443  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  444  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  445  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  447  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  448  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  449  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  450  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  452  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  453  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  454  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  455  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  457  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  458  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  459  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  460  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  462  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  463  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  464  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  465  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  467  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  468  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  469  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868624687194824
Epoch:  470  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  472  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  473  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  474  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  475  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  477  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  478  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  479  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  480  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  482  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  483  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  484  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
 97%|█████████▋| 485/500 [15:19<00:34,  2.30s/it] 97%|█████████▋| 487/500 [15:19<00:21,  1.63s/it] 98%|█████████▊| 489/500 [15:19<00:12,  1.17s/it] 98%|█████████▊| 491/500 [15:32<00:24,  2.71s/it] 99%|█████████▊| 493/500 [15:32<00:13,  1.92s/it] 99%|█████████▉| 495/500 [15:39<00:11,  2.30s/it] 99%|█████████▉| 497/500 [15:39<00:04,  1.63s/it]100%|█████████▉| 499/500 [15:39<00:01,  1.16s/it]100%|██████████| 500/500 [15:45<00:00,  1.89s/it]
Epoch:  485  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  487  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  488  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  489  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  490  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325670838356
Valid Loss:  0.06868623942136765
Epoch:  492  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623197078705
Epoch:  493  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  494  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  495  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868624687194824
Epoch:  497  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  498  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  499  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
Epoch:  500  	Training Loss: 0.0733054131269455
Test Loss:  0.0775325745344162
Valid Loss:  0.06868623942136765
**************************************************learning rate decay**************************************************
seed is  9
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:07,  6.27s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:57,  1.35s/it]  3%|▎         | 13/500 [00:13<07:28,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.95it/s]  4%|▍         | 21/500 [00:20<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:32<16:28,  2.11s/it]  7%|▋         | 33/500 [00:33<11:37,  1.49s/it]  7%|▋         | 35/500 [00:33<08:14,  1.06s/it]  7%|▋         | 37/500 [00:33<05:53,  1.31it/s]  8%|▊         | 39/500 [00:33<04:15,  1.81it/s]  8%|▊         | 41/500 [00:39<10:11,  1.33s/it]  9%|▊         | 43/500 [00:39<07:16,  1.05it/s]  9%|▉         | 45/500 [00:40<05:13,  1.45it/s]  9%|▉         | 47/500 [00:40<03:48,  1.98it/s] 10%|▉         | 49/500 [00:40<02:49,  2.66it/s] 10%|█         | 51/500 [00:46<08:58,  1.20s/it] 11%|█         | 53/500 [00:46<06:24,  1.16it/s] 11%|█         | 55/500 [00:46<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:47<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:47<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:53<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:53<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:53<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:53<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:53<02:23,  2.99it/s]Epoch:  1  	Training Loss: 0.0821116492152214
Test Loss:  2.867428779602051
Valid Loss:  2.7888331413269043
Epoch:  2  	Training Loss: 2.8111732006073
Test Loss:  81.16368865966797
Valid Loss:  82.2894058227539
Epoch:  3  	Training Loss: 81.97283172607422
Test Loss:  0.9306679964065552
Valid Loss:  0.9627660512924194
Epoch:  4  	Training Loss: 0.9572679996490479
Test Loss:  0.9232446551322937
Valid Loss:  0.9547704458236694
Epoch:  5  	Training Loss: 0.950026273727417
Test Loss:  0.9185194969177246
Valid Loss:  0.9493013620376587
Epoch:  6  	Training Loss: 0.9454654455184937
Test Loss:  0.9148126244544983
Valid Loss:  0.9452539682388306
Epoch:  7  	Training Loss: 0.9418694972991943
Test Loss:  0.9117438793182373
Valid Loss:  0.9424296021461487
Epoch:  8  	Training Loss: 0.9392556548118591
Test Loss:  0.9092090129852295
Valid Loss:  0.9402484893798828
Epoch:  9  	Training Loss: 0.9371058940887451
Test Loss:  0.907058835029602
Valid Loss:  0.938346803188324
Epoch:  10  	Training Loss: 0.9351855516433716
Test Loss:  0.9052075147628784
Valid Loss:  0.9367436170578003
Epoch:  11  	Training Loss: 0.9335606098175049
Test Loss:  0.9036135673522949
Valid Loss:  0.9354617595672607
Epoch:  12  	Training Loss: 0.9321516752243042
Test Loss:  0.13783985376358032
Valid Loss:  0.16392084956169128
Epoch:  13  	Training Loss: 0.161497101187706
Test Loss:  0.06724138557910919
Valid Loss:  0.08680010586977005
Epoch:  14  	Training Loss: 0.0860191285610199
Test Loss:  0.03740911930799484
Valid Loss:  0.053313806653022766
Epoch:  15  	Training Loss: 0.05299803242087364
Test Loss:  0.02476852759718895
Valid Loss:  0.038549065589904785
Epoch:  16  	Training Loss: 0.038329679518938065
Test Loss:  0.019449513405561447
Valid Loss:  0.03190554678440094
Epoch:  17  	Training Loss: 0.031680889427661896
Test Loss:  0.017197763547301292
Valid Loss:  0.028812497854232788
Epoch:  18  	Training Loss: 0.028551548719406128
Test Loss:  0.016224201768636703
Valid Loss:  0.027281248942017555
Epoch:  19  	Training Loss: 0.02698083594441414
Test Loss:  0.015774128958582878
Valid Loss:  0.026443827897310257
Epoch:  20  	Training Loss: 0.026105239987373352
Test Loss:  0.015527663752436638
Valid Loss:  0.025916650891304016
Epoch:  21  	Training Loss: 0.0255441777408123
Test Loss:  0.015356731601059437
Valid Loss:  0.025530409067869186
Epoch:  22  	Training Loss: 0.025130093097686768
Test Loss:  0.00910474918782711
Valid Loss:  0.012209094129502773
Epoch:  23  	Training Loss: 0.011382673867046833
Test Loss:  0.012623865157365799
Valid Loss:  0.014745962806046009
Epoch:  24  	Training Loss: 0.014654992148280144
Test Loss:  0.07235850393772125
Valid Loss:  0.07846596837043762
Epoch:  25  	Training Loss: 0.07525614649057388
Test Loss:  0.21571142971515656
Valid Loss:  0.20905929803848267
Epoch:  26  	Training Loss: 0.21237841248512268
Test Loss:  0.27060627937316895
Valid Loss:  0.26016733050346375
Epoch:  27  	Training Loss: 0.2649797201156616
Test Loss:  0.04885492101311684
Valid Loss:  0.05338585004210472
Epoch:  28  	Training Loss: 0.05190186947584152
Test Loss:  0.015673041343688965
Valid Loss:  0.01144135370850563
Epoch:  29  	Training Loss: 0.011595138348639011
Test Loss:  0.011173147708177567
Valid Loss:  0.01006403286010027
Epoch:  30  	Training Loss: 0.009544342756271362
Test Loss:  0.010463286191225052
Valid Loss:  0.008230885490775108
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.008309133350849152
Test Loss:  0.00954916886985302
Valid Loss:  0.007767468690872192
Epoch:  32  	Training Loss: 0.007735089398920536
Test Loss:  0.008960255421698093
Valid Loss:  0.007542327046394348
Epoch:  33  	Training Loss: 0.007432297803461552
Test Loss:  0.008574854582548141
Valid Loss:  0.007267047185450792
Epoch:  34  	Training Loss: 0.0071893963031470776
Test Loss:  0.00821185763925314
Valid Loss:  0.0070801894180476665
Epoch:  35  	Training Loss: 0.006990834139287472
Test Loss:  0.00793058704584837
Valid Loss:  0.006903976202011108
Epoch:  36  	Training Loss: 0.00682583125308156
Test Loss:  0.007665881887078285
Valid Loss:  0.006767242215573788
Epoch:  37  	Training Loss: 0.006684263702481985
Test Loss:  0.007444753311574459
Valid Loss:  0.006633427459746599
Epoch:  38  	Training Loss: 0.006556352600455284
Test Loss:  0.007232283242046833
Valid Loss:  0.006533022504299879
Epoch:  39  	Training Loss: 0.006448227912187576
Test Loss:  0.007061045616865158
Valid Loss:  0.006434373091906309
Epoch:  40  	Training Loss: 0.006352876778692007
Test Loss:  0.006888154894113541
Valid Loss:  0.006358643993735313
Epoch:  41  	Training Loss: 0.0062697334215044975
Test Loss:  0.006751511245965958
Valid Loss:  0.006283759139478207
Epoch:  42  	Training Loss: 0.006199914962053299
Test Loss:  0.006740440148860216
Valid Loss:  0.006206489633768797
Epoch:  43  	Training Loss: 0.006132074166089296
Test Loss:  0.006732673849910498
Valid Loss:  0.006133198272436857
Epoch:  44  	Training Loss: 0.006068119779229164
Test Loss:  0.006730332504957914
Valid Loss:  0.006069742608815432
Epoch:  45  	Training Loss: 0.006012211553752422
Test Loss:  0.00672615971416235
Valid Loss:  0.0060140714049339294
Epoch:  46  	Training Loss: 0.005962611176073551
Test Loss:  0.006724056787788868
Valid Loss:  0.0059659443795681
Epoch:  47  	Training Loss: 0.005915550515055656
Test Loss:  0.006719079799950123
Valid Loss:  0.005917834118008614
Epoch:  48  	Training Loss: 0.005867892410606146
Test Loss:  0.006714465096592903
Valid Loss:  0.005870594643056393
Epoch:  49  	Training Loss: 0.005818156059831381
Test Loss:  0.006713190581649542
Valid Loss:  0.005827976390719414
Epoch:  50  	Training Loss: 0.005769453942775726
Test Loss:  0.006713507696986198
Valid Loss:  0.005791741423308849
Epoch:  51  	Training Loss: 0.005728548392653465
Test Loss:  0.00671099778264761
Valid Loss:  0.005759451538324356
Epoch:  52  	Training Loss: 0.0056920126080513
Test Loss:  0.0064683761447668076
Valid Loss:  0.005658783484250307
Epoch:  53  	Training Loss: 0.005573316477239132
Test Loss:  0.006275742780417204
Valid Loss:  0.0055653732270002365
Epoch:  54  	Training Loss: 0.005476629361510277
Test Loss:  0.006108696572482586
Valid Loss:  0.005480377934873104
Epoch:  55  	Training Loss: 0.0053924438543617725
Test Loss:  0.005960036069154739
Valid Loss:  0.005405412521213293
Epoch:  56  	Training Loss: 0.005320315714925528
Test Loss:  0.0058265142142772675
Valid Loss:  0.0053403014317154884
Epoch:  57  	Training Loss: 0.005258448421955109
Test Loss:  0.005706164054572582
Valid Loss:  0.0052841948345303535
Epoch:  58  	Training Loss: 0.005205145105719566
Test Loss:  0.005597425624728203
Valid Loss:  0.005234714597463608
Epoch:  59  	Training Loss: 0.005158538930118084
Test Loss:  0.0054990071803331375
Valid Loss:  0.005191098898649216
Epoch:  60  	Training Loss: 0.005117867141962051
Test Loss:  0.005409829318523407
Valid Loss:  0.005152993835508823
Epoch:  61  	Training Loss: 0.005082373972982168
Test Loss:  0.00532892532646656
Valid Loss:  0.005120185203850269
Epoch:  62  	Training Loss: 0.0050512258894741535
Test Loss:  0.005420842207968235
Valid Loss:  0.005116095766425133
Epoch:  63  	Training Loss: 0.004935792181640863
Test Loss:  0.005130299832671881
Valid Loss:  0.004907643422484398
Epoch:  64  	Training Loss: 0.004866796545684338
Test Loss:  0.0052119772881269455
Valid Loss:  0.004980386234819889
Epoch:  65  	Training Loss: 0.004820984788239002
Test Loss:  0.004949326626956463
Valid Loss:  0.004804193042218685
Epoch:  66  	Training Loss: 0.004764612764120102
Test Loss:  0.004995536059141159
Valid Loss:  0.004855572246015072
Epoch:  67  	Training Loss: 0.004720686934888363
Test Loss:  0.004817478358745575
Valid Loss:  0.004737187176942825
Epoch:  68  	Training Loss: 0.004692210350185633
Test Loss:  0.00484361732378602
Valid Loss:  0.0047799102030694485
Epoch:  69  	Training Loss: 0.004659321159124374
Test Loss:  0.004725322593003511
Valid Loss:  0.004694904200732708
Epoch:  70  	Training Loss: 0.004633054602891207
Test Loss:  0.00471743056550622
Valid Loss:  0.0047182608395814896
Epoch:  71  	Training Loss: 0.00461359741166234
Test Loss:   14%|█▍        | 71/500 [01:00<08:29,  1.19s/it] 15%|█▍        | 73/500 [01:00<06:03,  1.18it/s] 15%|█▌        | 75/500 [01:00<04:21,  1.63it/s] 15%|█▌        | 77/500 [01:00<03:10,  2.22it/s] 16%|█▌        | 79/500 [01:00<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:07<08:14,  1.18s/it] 17%|█▋        | 83/500 [01:07<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:07<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:07<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:07<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:14<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:14<05:43,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:14<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:14<02:13,  3.00it/s] 20%|██        | 101/500 [01:20<07:54,  1.19s/it] 21%|██        | 103/500 [01:21<05:38,  1.17it/s] 21%|██        | 105/500 [01:21<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:21<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:21<02:13,  2.92it/s] 22%|██▏       | 111/500 [01:28<07:55,  1.22s/it] 23%|██▎       | 113/500 [01:28<05:38,  1.14it/s] 23%|██▎       | 115/500 [01:28<04:03,  1.58it/s] 23%|██▎       | 117/500 [01:28<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:28<02:10,  2.92it/s] 24%|██▍       | 121/500 [01:34<07:35,  1.20s/it] 25%|██▍       | 123/500 [01:35<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:35<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:35<02:51,  2.17it/s] 26%|██▌       | 129/500 [01:35<02:08,  2.89it/s] 26%|██▌       | 131/500 [01:41<07:22,  1.20s/it] 27%|██▋       | 133/500 [01:42<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:42<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:42<02:46,  2.18it/s] 28%|██▊       | 139/500 [01:42<02:03,  2.93it/s]0.004648437723517418
Valid Loss:  0.004675835371017456
Epoch:  72  	Training Loss: 0.004596102051436901
Test Loss:  0.004560597240924835
Valid Loss:  0.004512051586061716
Epoch:  73  	Training Loss: 0.004427528008818626
Test Loss:  0.004498448222875595
Valid Loss:  0.004385672509670258
Epoch:  74  	Training Loss: 0.0042965528555214405
Test Loss:  0.004474959336221218
Valid Loss:  0.00427454337477684
Epoch:  75  	Training Loss: 0.004182402975857258
Test Loss:  0.00442830566316843
Valid Loss:  0.00414523808285594
Epoch:  76  	Training Loss: 0.004064125008881092
Test Loss:  0.004416459705680609
Valid Loss:  0.004050710238516331
Epoch:  77  	Training Loss: 0.003962184302508831
Test Loss:  0.004374328535050154
Valid Loss:  0.00392336118966341
Epoch:  78  	Training Loss: 0.0038597355596721172
Test Loss:  0.004375144839286804
Valid Loss:  0.0038011425640434027
Epoch:  79  	Training Loss: 0.003745592664927244
Test Loss:  0.0043249791488051414
Valid Loss:  0.003731716889888048
Epoch:  80  	Training Loss: 0.00367179699242115
Test Loss:  0.004338356666266918
Valid Loss:  0.003642960451543331
Epoch:  81  	Training Loss: 0.003606676124036312
Test Loss:  0.004303223453462124
Valid Loss:  0.0035754891578108072
Epoch:  82  	Training Loss: 0.0035428209230303764
Test Loss:  0.004108752124011517
Valid Loss:  0.0034352396614849567
Epoch:  83  	Training Loss: 0.0033949215430766344
Test Loss:  0.003945029340684414
Valid Loss:  0.0032966332510113716
Epoch:  84  	Training Loss: 0.003264441154897213
Test Loss:  0.003793887095525861
Valid Loss:  0.003163894172757864
Epoch:  85  	Training Loss: 0.003140421584248543
Test Loss:  0.003647126257419586
Valid Loss:  0.003036880400031805
Epoch:  86  	Training Loss: 0.0030206888914108276
Test Loss:  0.003505520522594452
Valid Loss:  0.002915720921009779
Epoch:  87  	Training Loss: 0.002906234236434102
Test Loss:  0.0033704270608723164
Valid Loss:  0.002797942841425538
Epoch:  88  	Training Loss: 0.0027956082485616207
Test Loss:  0.003242436796426773
Valid Loss:  0.0026801989879459143
Epoch:  89  	Training Loss: 0.0026865359395742416
Test Loss:  0.0031210598535835743
Valid Loss:  0.0025658560916781425
Epoch:  90  	Training Loss: 0.002579584252089262
Test Loss:  0.003006589598953724
Valid Loss:  0.0024574610870331526
Epoch:  91  	Training Loss: 0.002478073351085186
Test Loss:  0.0028961291536688805
Valid Loss:  0.0023556258529424667
Epoch:  92  	Training Loss: 0.002382674254477024
Test Loss:  0.0027999519370496273
Valid Loss:  0.002250473480671644
Epoch:  93  	Training Loss: 0.0023125307634472847
Test Loss:  0.002783837029710412
Valid Loss:  0.002186327241361141
Epoch:  94  	Training Loss: 0.0022475067526102066
Test Loss:  0.0027405794244259596
Valid Loss:  0.002118108794093132
Epoch:  95  	Training Loss: 0.0021942437160760164
Test Loss:  0.0027175783179700375
Valid Loss:  0.002066629007458687
Epoch:  96  	Training Loss: 0.002147748600691557
Test Loss:  0.002691020490601659
Valid Loss:  0.002018590923398733
Epoch:  97  	Training Loss: 0.002106714528053999
Test Loss:  0.0026715630665421486
Valid Loss:  0.001976566156372428
Epoch:  98  	Training Loss: 0.002069758251309395
Test Loss:  0.0026513608172535896
Valid Loss:  0.0019382457248866558
Epoch:  99  	Training Loss: 0.002036375692114234
Test Loss:  0.002632453804835677
Valid Loss:  0.0019037580350413918
Epoch:  100  	Training Loss: 0.0020057871006429195
Test Loss:  0.002614914905279875
Valid Loss:  0.00187205639667809
Epoch:  101  	Training Loss: 0.001977769425138831
Test Loss:  0.00259833293966949
Valid Loss:  0.0018431053031235933
Epoch:  102  	Training Loss: 0.0019518814515322447
Test Loss:  0.002600963693112135
Valid Loss:  0.00183891283813864
Epoch:  103  	Training Loss: 0.0019490518607199192
Test Loss:  0.002599007450044155
Valid Loss:  0.0018360583344474435
Epoch:  104  	Training Loss: 0.0019464509095996618
Test Loss:  0.0025977359618991613
Valid Loss:  0.0018331077881157398
Epoch:  105  	Training Loss: 0.0019439320312812924
Test Loss:  0.002596360631287098
Valid Loss:  0.0018301366362720728
Epoch:  106  	Training Loss: 0.0019414338748902082
Test Loss:  0.0025950311683118343
Valid Loss:  0.0018270681612193584
Epoch:  107  	Training Loss: 0.0019388848450034857
Test Loss:  0.0025937838945537806
Valid Loss:  0.0018240459030494094
Epoch:  108  	Training Loss: 0.0019363720202818513
Test Loss:  0.0025925347581505775
Valid Loss:  0.0018210418056696653
Epoch:  109  	Training Loss: 0.0019338621059432626
Test Loss:  0.002591328229755163
Valid Loss:  0.0018181591294705868
Epoch:  110  	Training Loss: 0.0019314817618578672
Test Loss:  0.002590146381407976
Valid Loss:  0.0018156066071242094
Epoch:  111  	Training Loss: 0.0019292882643640041
Test Loss:  0.0025893538258969784
Valid Loss:  0.0018137632869184017
Epoch:  112  	Training Loss: 0.0019276655511930585
Test Loss:  0.002270034048706293
Valid Loss:  0.0016868526581674814
Epoch:  113  	Training Loss: 0.001781695056706667
Test Loss:  0.0021542031317949295
Valid Loss:  0.0016471981070935726
Epoch:  114  	Training Loss: 0.0017371923895552754
Test Loss:  0.00209953379817307
Valid Loss:  0.0016212938353419304
Epoch:  115  	Training Loss: 0.0017104673897847533
Test Loss:  0.002066197106614709
Valid Loss:  0.0015980147290974855
Epoch:  116  	Training Loss: 0.0016877239104360342
Test Loss:  0.0020412912126630545
Valid Loss:  0.0015759114176034927
Epoch:  117  	Training Loss: 0.0016664417926222086
Test Loss:  0.0020202654413878918
Valid Loss:  0.0015550742391496897
Epoch:  118  	Training Loss: 0.001646112184971571
Test Loss:  0.0020007221028208733
Valid Loss:  0.0015350393950939178
Epoch:  119  	Training Loss: 0.0016267573228105903
Test Loss:  0.0019815159030258656
Valid Loss:  0.0015158455353230238
Epoch:  120  	Training Loss: 0.001608248334378004
Test Loss:  0.001963584218174219
Valid Loss:  0.0014977806713432074
Epoch:  121  	Training Loss: 0.0015906179323792458
Test Loss:  0.0019462814088910818
Valid Loss:  0.001480383099988103
Epoch:  122  	Training Loss: 0.001573665183968842
Test Loss:  0.0019076071912422776
Valid Loss:  0.001371094724163413
Epoch:  123  	Training Loss: 0.0014747275272384286
Test Loss:  0.001857267809100449
Valid Loss:  0.0013258580584079027
Epoch:  124  	Training Loss: 0.0014297631569206715
Test Loss:  0.0018124062335118651
Valid Loss:  0.001290226704441011
Epoch:  125  	Training Loss: 0.001393426675349474
Test Loss:  0.001774175325408578
Valid Loss:  0.001260765129700303
Epoch:  126  	Training Loss: 0.0013630595058202744
Test Loss:  0.0017380209174007177
Valid Loss:  0.0012349553871899843
Epoch:  127  	Training Loss: 0.0013358115684241056
Test Loss:  0.0017041964456439018
Valid Loss:  0.001211795024573803
Epoch:  128  	Training Loss: 0.001310854684561491
Test Loss:  0.0016720108687877655
Valid Loss:  0.0011915570357814431
Epoch:  129  	Training Loss: 0.0012886009644716978
Test Loss:  0.0016406786162406206
Valid Loss:  0.0011733537539839745
Epoch:  130  	Training Loss: 0.0012687556445598602
Test Loss:  0.0016126586124300957
Valid Loss:  0.0011581714497879148
Epoch:  131  	Training Loss: 0.0012507028877735138
Test Loss:  0.0015867350157350302
Valid Loss:  0.0011442285031080246
Epoch:  132  	Training Loss: 0.0012341056717559695
Test Loss:  0.0015579832252115011
Valid Loss:  0.0011340423952788115
Epoch:  133  	Training Loss: 0.0012234582100063562
Test Loss:  0.001535399816930294
Valid Loss:  0.0011261829640716314
Epoch:  134  	Training Loss: 0.001215215539559722
Test Loss:  0.0015169524122029543
Valid Loss:  0.0011194780236110091
Epoch:  135  	Training Loss: 0.0012083012843504548
Test Loss:  0.0015015725512057543
Valid Loss:  0.001113323145546019
Epoch:  136  	Training Loss: 0.0012020791182294488
Test Loss:  0.0014882911927998066
Valid Loss:  0.001107810065150261
Epoch:  137  	Training Loss: 0.0011964822188019753
Test Loss:  0.0014766226522624493
Valid Loss:  0.001102928537875414
Epoch:  138  	Training Loss: 0.001191433286294341
Test Loss:  0.001466237474232912
Valid Loss:  0.0010986208217218518
Epoch:  139  	Training Loss: 0.0011867524590343237
Test Loss:  0.0014568532351404428
Valid Loss:  0.0010946632828563452
Epoch:  140  	Training Loss: 0.0011824178509414196
Test Loss:  0.0014482345432043076
Valid Loss:   28%|██▊       | 141/500 [01:48<07:13,  1.21s/it] 29%|██▊       | 143/500 [01:49<05:09,  1.16it/s] 29%|██▉       | 145/500 [01:49<03:42,  1.60it/s] 29%|██▉       | 147/500 [01:49<02:41,  2.18it/s] 30%|██▉       | 149/500 [01:49<01:59,  2.94it/s] 30%|███       | 151/500 [01:55<06:50,  1.18s/it] 31%|███       | 153/500 [01:55<04:52,  1.19it/s] 31%|███       | 155/500 [01:55<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:56<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:56<01:54,  2.98it/s] 32%|███▏      | 161/500 [02:02<06:38,  1.18s/it] 33%|███▎      | 163/500 [02:02<04:44,  1.18it/s] 33%|███▎      | 165/500 [02:02<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:02<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:03<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:09<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:09<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:09<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:09<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:09<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:16<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:16<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:16<03:15,  1.62it/s] 37%|███▋      | 187/500 [02:16<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:16<01:46,  2.91it/s] 38%|███▊      | 191/500 [02:23<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:23<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:23<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:23<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:23<01:41,  2.97it/s] 40%|████      | 201/500 [02:29<05:49,  1.17s/it] 41%|████      | 203/500 [02:30<04:09,  1.19it/s] 41%|████      | 205/500 [02:30<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:30<02:10,  2.25it/s]0.0010910455603152514
Epoch:  141  	Training Loss: 0.0011784271337091923
Test Loss:  0.001440259162336588
Valid Loss:  0.001087756478227675
Epoch:  142  	Training Loss: 0.0011746950913220644
Test Loss:  0.0014419639483094215
Valid Loss:  0.0010756630217656493
Epoch:  143  	Training Loss: 0.0011622566962614655
Test Loss:  0.0014180295402184129
Valid Loss:  0.0010685615707188845
Epoch:  144  	Training Loss: 0.0011541348649188876
Test Loss:  0.0014062371337786317
Valid Loss:  0.0010622043628245592
Epoch:  145  	Training Loss: 0.0011472899932414293
Test Loss:  0.0013925747480243444
Valid Loss:  0.0010568045545369387
Epoch:  146  	Training Loss: 0.0011414330219849944
Test Loss:  0.0013814219273626804
Valid Loss:  0.0010521524818614125
Epoch:  147  	Training Loss: 0.001136583974584937
Test Loss:  0.0013710390776395798
Valid Loss:  0.0010479422053322196
Epoch:  148  	Training Loss: 0.0011322631035000086
Test Loss:  0.00136187591124326
Valid Loss:  0.0010443497449159622
Epoch:  149  	Training Loss: 0.0011287101078778505
Test Loss:  0.0013535746838897467
Valid Loss:  0.0010410624090582132
Epoch:  150  	Training Loss: 0.0011254956480115652
Test Loss:  0.001346157630905509
Valid Loss:  0.00103864970151335
Epoch:  151  	Training Loss: 0.0011226756032556295
Test Loss:  0.0013394653797149658
Valid Loss:  0.0010368051007390022
Epoch:  152  	Training Loss: 0.0011203688336536288
Test Loss:  0.0012989549431949854
Valid Loss:  0.000977551331743598
Epoch:  153  	Training Loss: 0.0010574329644441605
Test Loss:  0.00130549562163651
Valid Loss:  0.0009492092067375779
Epoch:  154  	Training Loss: 0.0010257209651172161
Test Loss:  0.0012789133470505476
Valid Loss:  0.0009358098031952977
Epoch:  155  	Training Loss: 0.0010042480425909162
Test Loss:  0.0012624496594071388
Valid Loss:  0.0009190806886181235
Epoch:  156  	Training Loss: 0.000986141967587173
Test Loss:  0.0012337206862866879
Valid Loss:  0.0009077077847905457
Epoch:  157  	Training Loss: 0.0009692382300272584
Test Loss:  0.0012162092607468367
Valid Loss:  0.0008936804952099919
Epoch:  158  	Training Loss: 0.0009535639546811581
Test Loss:  0.0011924670543521643
Valid Loss:  0.0008824077667668462
Epoch:  159  	Training Loss: 0.0009392903884872794
Test Loss:  0.00117335538379848
Valid Loss:  0.0008675409480929375
Epoch:  160  	Training Loss: 0.0009242523228749633
Test Loss:  0.0011667469516396523
Valid Loss:  0.0008557615801692009
Epoch:  161  	Training Loss: 0.0009103225311264396
Test Loss:  0.0011437027715146542
Valid Loss:  0.0008455522474832833
Epoch:  162  	Training Loss: 0.0008994773961603642
Test Loss:  0.0011460661189630628
Valid Loss:  0.0008399258367717266
Epoch:  163  	Training Loss: 0.000894606695510447
Test Loss:  0.0011206211056560278
Valid Loss:  0.0008373804157599807
Epoch:  164  	Training Loss: 0.0008909563766792417
Test Loss:  0.0011204960756003857
Valid Loss:  0.000833929399959743
Epoch:  165  	Training Loss: 0.0008878387161530554
Test Loss:  0.0011022782418876886
Valid Loss:  0.0008320918423123658
Epoch:  166  	Training Loss: 0.0008854955667629838
Test Loss:  0.00110152259003371
Valid Loss:  0.0008301246562041342
Epoch:  167  	Training Loss: 0.0008835969492793083
Test Loss:  0.0010870394762605429
Valid Loss:  0.0008289690595120192
Epoch:  168  	Training Loss: 0.0008821256342343986
Test Loss:  0.0010873570572584867
Valid Loss:  0.000827641342766583
Epoch:  169  	Training Loss: 0.0008808418060652912
Test Loss:  0.0010745751205831766
Valid Loss:  0.0008269999525509775
Epoch:  170  	Training Loss: 0.0008800116484053433
Test Loss:  0.0010766872437670827
Valid Loss:  0.0008259278256446123
Epoch:  171  	Training Loss: 0.0008790380088612437
Test Loss:  0.0010648914612829685
Valid Loss:  0.0008254599524661899
Epoch:  172  	Training Loss: 0.0008783555240370333
Test Loss:  0.00105845439247787
Valid Loss:  0.0008036429062485695
Epoch:  173  	Training Loss: 0.0008563376031816006
Test Loss:  0.001044191070832312
Valid Loss:  0.0007958667119964957
Epoch:  174  	Training Loss: 0.0008457024814561009
Test Loss:  0.0010337027488276362
Valid Loss:  0.0007920689531601965
Epoch:  175  	Training Loss: 0.0008412252063862979
Test Loss:  0.0010267719626426697
Valid Loss:  0.0007902607321739197
Epoch:  176  	Training Loss: 0.0008386608678847551
Test Loss:  0.0010208883322775364
Valid Loss:  0.000789557583630085
Epoch:  177  	Training Loss: 0.0008373804157599807
Test Loss:  0.0010153809562325478
Valid Loss:  0.0007890901761129498
Epoch:  178  	Training Loss: 0.0008366038673557341
Test Loss:  0.0010112528689205647
Valid Loss:  0.0007886799285188317
Epoch:  179  	Training Loss: 0.000836007937323302
Test Loss:  0.0010074663441628218
Valid Loss:  0.0007883359212428331
Epoch:  180  	Training Loss: 0.000835543847642839
Test Loss:  0.0010042258072644472
Valid Loss:  0.0007880489574745297
Epoch:  181  	Training Loss: 0.0008351714932359755
Test Loss:  0.001001519849523902
Valid Loss:  0.0007878139731474221
Epoch:  182  	Training Loss: 0.000834869162645191
Test Loss:  0.0010060505010187626
Valid Loss:  0.0007798327133059502
Epoch:  183  	Training Loss: 0.0008245656499639153
Test Loss:  0.001008837716653943
Valid Loss:  0.0007734267273917794
Epoch:  184  	Training Loss: 0.0008187408093363047
Test Loss:  0.0010124769760295749
Valid Loss:  0.0007708672201260924
Epoch:  185  	Training Loss: 0.000815821229480207
Test Loss:  0.0010119008366018534
Valid Loss:  0.0007685670279897749
Epoch:  186  	Training Loss: 0.0008136330870911479
Test Loss:  0.0010119624203070998
Valid Loss:  0.0007670599152334034
Epoch:  187  	Training Loss: 0.0008119465783238411
Test Loss:  0.0010097554186359048
Valid Loss:  0.0007656450034119189
Epoch:  188  	Training Loss: 0.0008103379514068365
Test Loss:  0.0010091789299622178
Valid Loss:  0.000764625146985054
Epoch:  189  	Training Loss: 0.0008089077891781926
Test Loss:  0.0010059601627290249
Valid Loss:  0.0007635364308953285
Epoch:  190  	Training Loss: 0.0008075564983300865
Test Loss:  0.0010044088121503592
Valid Loss:  0.0007625812431797385
Epoch:  191  	Training Loss: 0.0008062610868364573
Test Loss:  0.001001197611913085
Valid Loss:  0.0007616463117301464
Epoch:  192  	Training Loss: 0.0008049877360463142
Test Loss:  0.0009829672053456306
Valid Loss:  0.0007564367260783911
Epoch:  193  	Training Loss: 0.0007994382176548243
Test Loss:  0.0009730241727083921
Valid Loss:  0.0007532091694884002
Epoch:  194  	Training Loss: 0.0007967186393216252
Test Loss:  0.0009646181133575737
Valid Loss:  0.0007513799937441945
Epoch:  195  	Training Loss: 0.0007950773579068482
Test Loss:  0.00095889758085832
Valid Loss:  0.0007501862710341811
Epoch:  196  	Training Loss: 0.0007940275827422738
Test Loss:  0.0009537673322483897
Valid Loss:  0.00074931257404387
Epoch:  197  	Training Loss: 0.0007932290900498629
Test Loss:  0.0009497033897787333
Valid Loss:  0.0007486294489353895
Epoch:  198  	Training Loss: 0.0007926251273602247
Test Loss:  0.0009462542366236448
Valid Loss:  0.0007481015054509044
Epoch:  199  	Training Loss: 0.0007921585347503424
Test Loss:  0.0009432846563868225
Valid Loss:  0.0007476647733710706
Epoch:  200  	Training Loss: 0.0007917918264865875
Test Loss:  0.0009409302147105336
Valid Loss:  0.0007473474834114313
Epoch:  201  	Training Loss: 0.0007915057940408587
Test Loss:  0.0009388873586431146
Valid Loss:  0.0007472045836038888
Epoch:  202  	Training Loss: 0.0007912727305665612
Test Loss:  0.0009402782307006419
Valid Loss:  0.0007387197692878544
Epoch:  203  	Training Loss: 0.0007809674716554582
Test Loss:  0.0009367960738018155
Valid Loss:  0.0007377678994089365
Epoch:  204  	Training Loss: 0.0007789708906784654
Test Loss:  0.0009325995342805982
Valid Loss:  0.0007371364627033472
Epoch:  205  	Training Loss: 0.0007776054553687572
Test Loss:  0.0009297633660025895
Valid Loss:  0.0007366890786215663
Epoch:  206  	Training Loss: 0.0007764942711219192
Test Loss:  0.0009278365760110319
Valid Loss:  0.0007363538024947047
Epoch:  207  	Training Loss: 0.0007755965925753117
Test Loss:  0.0009262611856684089
Valid Loss:  0.0007360816234722733
Epoch:  208  	Training Loss: 0.0007748545613139868
Test Loss:  0.0009252401068806648
Valid Loss:  0.0007358578150160611
 42%|████▏     | 209/500 [02:30<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:36<05:42,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:37<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:37<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:37<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:43<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:43<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:43<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:44<02:03,  2.22it/s] 46%|████▌     | 229/500 [02:44<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:50<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:50<03:43,  1.20it/s] 47%|████▋     | 235/500 [02:50<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:50<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:50<01:25,  3.04it/s] 48%|████▊     | 241/500 [02:57<05:08,  1.19s/it] 49%|████▊     | 243/500 [02:57<03:40,  1.17it/s] 49%|████▉     | 245/500 [02:57<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:57<01:55,  2.18it/s] 50%|████▉     | 249/500 [02:57<01:25,  2.92it/s] 50%|█████     | 251/500 [03:04<04:58,  1.20s/it] 51%|█████     | 253/500 [03:04<03:31,  1.17it/s] 51%|█████     | 255/500 [03:04<02:31,  1.61it/s] 51%|█████▏    | 257/500 [03:04<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:04<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:11<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:11<03:21,  1.17it/s] 53%|█████▎    | 265/500 [03:11<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:11<01:45,  2.22it/s] 54%|█████▍    | 269/500 [03:11<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:18<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:18<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:18<02:18,  1.63it/s]Epoch:  209  	Training Loss: 0.0007742706802673638
Test Loss:  0.0009245350956916809
Valid Loss:  0.0007356996648013592
Epoch:  210  	Training Loss: 0.0007739061838947237
Test Loss:  0.0009242765954695642
Valid Loss:  0.0007355616544373333
Epoch:  211  	Training Loss: 0.0007736060069873929
Test Loss:  0.0009240295039489865
Valid Loss:  0.0007354420376941562
Epoch:  212  	Training Loss: 0.000773355015553534
Test Loss:  0.0009256010525859892
Valid Loss:  0.0007351750391535461
Epoch:  213  	Training Loss: 0.0007731481455266476
Test Loss:  0.0009250954026356339
Valid Loss:  0.0007350362720899284
Epoch:  214  	Training Loss: 0.000772955478169024
Test Loss:  0.0009245615801773965
Valid Loss:  0.0007349072257056832
Epoch:  215  	Training Loss: 0.0007727866759523749
Test Loss:  0.0009256393532268703
Valid Loss:  0.0007347350474447012
Epoch:  216  	Training Loss: 0.0007726875483058393
Test Loss:  0.0009247354464605451
Valid Loss:  0.0007346381898969412
Epoch:  217  	Training Loss: 0.0007725598989054561
Test Loss:  0.0009255565237253904
Valid Loss:  0.0007345048361457884
Epoch:  218  	Training Loss: 0.0007724781753495336
Test Loss:  0.0009245200781151652
Valid Loss:  0.0007344259065575898
Epoch:  219  	Training Loss: 0.0007723810849711299
Test Loss:  0.000925128348171711
Valid Loss:  0.0007343116449192166
Epoch:  220  	Training Loss: 0.0007722842274233699
Test Loss:  0.0009255784098058939
Valid Loss:  0.000734219211153686
Epoch:  221  	Training Loss: 0.0007722197915427387
Test Loss:  0.0009243743843398988
Valid Loss:  0.0007342445896938443
Epoch:  222  	Training Loss: 0.000772167812101543
Test Loss:  0.0009231669828295708
Valid Loss:  0.0007273206720128655
Epoch:  223  	Training Loss: 0.0007609879830852151
Test Loss:  0.0009246462723240256
Valid Loss:  0.0007275516400113702
Epoch:  224  	Training Loss: 0.0007582709076814353
Test Loss:  0.0009264711989089847
Valid Loss:  0.0007281290600076318
Epoch:  225  	Training Loss: 0.0007573777693323791
Test Loss:  0.0009274488547816873
Valid Loss:  0.0007282637525349855
Epoch:  226  	Training Loss: 0.0007572746835649014
Test Loss:  0.0009280944941565394
Valid Loss:  0.0007282994920387864
Epoch:  227  	Training Loss: 0.0007572215399704874
Test Loss:  0.000928623485378921
Valid Loss:  0.0007283284794539213
Epoch:  228  	Training Loss: 0.0007571891183033586
Test Loss:  0.0009288801811635494
Valid Loss:  0.0007282661972567439
Epoch:  229  	Training Loss: 0.0007571687456220388
Test Loss:  0.0009292805334553123
Valid Loss:  0.0007283005397766829
Epoch:  230  	Training Loss: 0.0007571482565253973
Test Loss:  0.0009294339688494802
Valid Loss:  0.0007282408187165856
Epoch:  231  	Training Loss: 0.0007571295136585832
Test Loss:  0.0009295446216128767
Valid Loss:  0.000728197512216866
Epoch:  232  	Training Loss: 0.000757116184104234
Test Loss:  0.0009267915738746524
Valid Loss:  0.0007120781810954213
Epoch:  233  	Training Loss: 0.0007450229022651911
Test Loss:  0.0009168359683826566
Valid Loss:  0.0007064031669870019
Epoch:  234  	Training Loss: 0.0007386774523183703
Test Loss:  0.0009100701427087188
Valid Loss:  0.0007009728578850627
Epoch:  235  	Training Loss: 0.0007331756060011685
Test Loss:  0.000903588836081326
Valid Loss:  0.0006960413884371519
Epoch:  236  	Training Loss: 0.0007281992002390325
Test Loss:  0.0008975471719168127
Valid Loss:  0.0006918939761817455
Epoch:  237  	Training Loss: 0.000723701436072588
Test Loss:  0.0008925037691369653
Valid Loss:  0.0006883193273097277
Epoch:  238  	Training Loss: 0.0007200581021606922
Test Loss:  0.0008880825480446219
Valid Loss:  0.0006849764613434672
Epoch:  239  	Training Loss: 0.0007167033618316054
Test Loss:  0.0008839275105856359
Valid Loss:  0.0006817525718361139
Epoch:  240  	Training Loss: 0.0007134850602596998
Test Loss:  0.0008803668897598982
Valid Loss:  0.0006786584854125977
Epoch:  241  	Training Loss: 0.000710510415956378
Test Loss:  0.0008771202410571277
Valid Loss:  0.0006759500247426331
Epoch:  242  	Training Loss: 0.0007079938659444451
Test Loss:  0.0008685888606123626
Valid Loss:  0.0006684637046419084
Epoch:  243  	Training Loss: 0.0006977580487728119
Test Loss:  0.0008624773472547531
Valid Loss:  0.000665904488414526
Epoch:  244  	Training Loss: 0.0006945313652977347
Test Loss:  0.0008578583365306258
Valid Loss:  0.0006642857915721834
Epoch:  245  	Training Loss: 0.0006925438647158444
Test Loss:  0.0008531133644282818
Valid Loss:  0.0006627598195336759
Epoch:  246  	Training Loss: 0.0006908717332407832
Test Loss:  0.0008491183398291469
Valid Loss:  0.0006615265738219023
Epoch:  247  	Training Loss: 0.000689439126290381
Test Loss:  0.0008462398545816541
Valid Loss:  0.0006604387890547514
Epoch:  248  	Training Loss: 0.0006882396410219371
Test Loss:  0.0008436535717919469
Valid Loss:  0.0006593806901946664
Epoch:  249  	Training Loss: 0.0006870890501886606
Test Loss:  0.00084157835226506
Valid Loss:  0.0006583789363503456
Epoch:  250  	Training Loss: 0.0006860733265057206
Test Loss:  0.0008387771085835993
Valid Loss:  0.0006572662387043238
Epoch:  251  	Training Loss: 0.0006851038197055459
Test Loss:  0.0008371908916160464
Valid Loss:  0.0006563547067344189
Epoch:  252  	Training Loss: 0.000684209750033915
Test Loss:  0.0008394505130127072
Valid Loss:  0.0006422855658456683
Epoch:  253  	Training Loss: 0.0006730940658599138
Test Loss:  0.0008296314626932144
Valid Loss:  0.0006370615446940064
Epoch:  254  	Training Loss: 0.0006660079816356301
Test Loss:  0.0008272380800917745
Valid Loss:  0.0006303251720964909
Epoch:  255  	Training Loss: 0.0006598429754376411
Test Loss:  0.0008212963002733886
Valid Loss:  0.0006251388695091009
Epoch:  256  	Training Loss: 0.0006542847258970141
Test Loss:  0.0008168742060661316
Valid Loss:  0.000619749363977462
Epoch:  257  	Training Loss: 0.0006489376537501812
Test Loss:  0.0008119578124023974
Valid Loss:  0.0006148450775071979
Epoch:  258  	Training Loss: 0.0006440186407417059
Test Loss:  0.0008074130164459348
Valid Loss:  0.0006100600585341454
Epoch:  259  	Training Loss: 0.0006391977658495307
Test Loss:  0.0008027675794437528
Valid Loss:  0.0006054082768969238
Epoch:  260  	Training Loss: 0.0006345500587485731
Test Loss:  0.0007982498500496149
Valid Loss:  0.0006009478820487857
Epoch:  261  	Training Loss: 0.0006300713866949081
Test Loss:  0.0007939160568639636
Valid Loss:  0.0005965762538835406
Epoch:  262  	Training Loss: 0.0006257074419409037
Test Loss:  0.0007847861270420253
Valid Loss:  0.0005944335134699941
Epoch:  263  	Training Loss: 0.000623348169028759
Test Loss:  0.0007794490084052086
Valid Loss:  0.0005923181306570768
Epoch:  264  	Training Loss: 0.0006213244632817805
Test Loss:  0.0007739217835478485
Valid Loss:  0.0005906785372644663
Epoch:  265  	Training Loss: 0.0006195672322064638
Test Loss:  0.0007699804264120758
Valid Loss:  0.0005892182234674692
Epoch:  266  	Training Loss: 0.0006180329946801066
Test Loss:  0.0007663574069738388
Valid Loss:  0.0005879466189071536
Epoch:  267  	Training Loss: 0.0006166674429550767
Test Loss:  0.0007634753128513694
Valid Loss:  0.0005867613363079727
Epoch:  268  	Training Loss: 0.000615377037320286
Test Loss:  0.0007608619634993374
Valid Loss:  0.0005857564974576235
Epoch:  269  	Training Loss: 0.0006142068887129426
Test Loss:  0.000758783018682152
Valid Loss:  0.0005848644068464637
Epoch:  270  	Training Loss: 0.0006132208509370685
Test Loss:  0.0007570833549834788
Valid Loss:  0.0005840520607307553
Epoch:  271  	Training Loss: 0.0006122934282757342
Test Loss:  0.0007555593620054424
Valid Loss:  0.0005832744645886123
Epoch:  272  	Training Loss: 0.0006114106508903205
Test Loss:  0.0007555625052191317
Valid Loss:  0.0005832257447764277
Epoch:  273  	Training Loss: 0.0006113998824730515
Test Loss:  0.0007552612805739045
Valid Loss:  0.0005832368042320013
Epoch:  274  	Training Loss: 0.0006113934796303511
Test Loss:  0.0007550339214503765
Valid Loss:  0.0005832377355545759
Epoch:  275  	Training Loss: 0.0006113870185799897
Test Loss:  0.0007548065041191876
Valid Loss:  0.0005832400056533515
Epoch:  276  	Training Loss: 0.0006113817798905075
Test Loss:  0.0007545924745500088
Valid Loss:  0.0005832427414134145
Epoch:  277  	Training Loss: 0.0006113769486546516
 55%|█████▌    | 277/500 [03:18<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:18<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:24<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:25<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:25<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:25<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:25<01:11,  2.97it/s] 58%|█████▊    | 291/500 [03:31<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:32<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:32<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:32<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:32<01:07,  2.99it/s] 60%|██████    | 301/500 [03:38<03:56,  1.19s/it] 61%|██████    | 303/500 [03:38<02:47,  1.17it/s] 61%|██████    | 305/500 [03:39<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:39<01:27,  2.22it/s] 62%|██████▏   | 309/500 [03:39<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:45<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:45<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:45<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:46<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:46<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:52<03:32,  1.18s/it] 65%|██████▍   | 323/500 [03:52<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:52<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:52<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:53<00:57,  2.96it/s] 66%|██████▌   | 331/500 [03:59<03:18,  1.18s/it] 67%|██████▋   | 333/500 [03:59<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:59<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:59<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:59<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:06<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:06<02:12,  1.19it/s]Test Loss:  0.0007543902029283345
Valid Loss:  0.0005832458846271038
Epoch:  278  	Training Loss: 0.0006113725830800831
Test Loss:  0.0007541969534941018
Valid Loss:  0.0005832489114254713
Epoch:  279  	Training Loss: 0.0006113681592978537
Test Loss:  0.0007540135411545634
Valid Loss:  0.0005832519382238388
Epoch:  280  	Training Loss: 0.0006113650742918253
Test Loss:  0.0007538401987403631
Valid Loss:  0.0005832550814375281
Epoch:  281  	Training Loss: 0.0006113611161708832
Test Loss:  0.000753674830775708
Valid Loss:  0.0005832566530443728
Epoch:  282  	Training Loss: 0.0006113586714491248
Test Loss:  0.0007552284514531493
Valid Loss:  0.00057929044123739
Epoch:  283  	Training Loss: 0.0006072134710848331
Test Loss:  0.0007549081929028034
Valid Loss:  0.0005772399017587304
Epoch:  284  	Training Loss: 0.0006048784125596285
Test Loss:  0.0007542631938122213
Valid Loss:  0.0005760978674516082
Epoch:  285  	Training Loss: 0.0006031754892319441
Test Loss:  0.0007529329741373658
Valid Loss:  0.0005756818572990596
Epoch:  286  	Training Loss: 0.0006024158792570233
Test Loss:  0.0007517007179558277
Valid Loss:  0.0005754681769758463
Epoch:  287  	Training Loss: 0.000601937819737941
Test Loss:  0.000750631676055491
Valid Loss:  0.0005752560682594776
Epoch:  288  	Training Loss: 0.000601556443143636
Test Loss:  0.0007494763704016805
Valid Loss:  0.0005750611308030784
Epoch:  289  	Training Loss: 0.0006012748926877975
Test Loss:  0.0007483757799491286
Valid Loss:  0.0005748674157075584
Epoch:  290  	Training Loss: 0.0006010386859998107
Test Loss:  0.0007472943980246782
Valid Loss:  0.0005747016984969378
Epoch:  291  	Training Loss: 0.0006008237251080573
Test Loss:  0.000746225705370307
Valid Loss:  0.0005745486705563962
Epoch:  292  	Training Loss: 0.0006006258772686124
Test Loss:  0.0007465130765922368
Valid Loss:  0.0005743150250054896
Epoch:  293  	Training Loss: 0.000600451254285872
Test Loss:  0.0007462140638381243
Valid Loss:  0.0005742008215747774
Epoch:  294  	Training Loss: 0.0006003060843795538
Test Loss:  0.0007459413027390838
Valid Loss:  0.0005740534979850054
Epoch:  295  	Training Loss: 0.0006001620786264539
Test Loss:  0.000745681463740766
Valid Loss:  0.0005739051848649979
Epoch:  296  	Training Loss: 0.0006000217981636524
Test Loss:  0.0007454328006133437
Valid Loss:  0.0005737638566643
Epoch:  297  	Training Loss: 0.000599892227910459
Test Loss:  0.000745279248803854
Valid Loss:  0.0005736490129493177
Epoch:  298  	Training Loss: 0.0005997638218104839
Test Loss:  0.0007449977565556765
Valid Loss:  0.0005735366139560938
Epoch:  299  	Training Loss: 0.0005996389081701636
Test Loss:  0.000744757242500782
Valid Loss:  0.0005734168225899339
Epoch:  300  	Training Loss: 0.0005995145766064525
Test Loss:  0.0007445155642926693
Valid Loss:  0.0005732995341531932
Epoch:  301  	Training Loss: 0.0005993910599499941
Test Loss:  0.0007442769128829241
Valid Loss:  0.0005731841665692627
Epoch:  302  	Training Loss: 0.0005992699880152941
Test Loss:  0.0007442650385200977
Valid Loss:  0.0005731625133194029
Epoch:  303  	Training Loss: 0.0005992341320961714
Test Loss:  0.000744271615985781
Valid Loss:  0.0005731375422328711
Epoch:  304  	Training Loss: 0.0005992003716528416
Test Loss:  0.0007442741189152002
Valid Loss:  0.0005731142591685057
Epoch:  305  	Training Loss: 0.0005991681246086955
Test Loss:  0.0007442774949595332
Valid Loss:  0.0005730913253501058
Epoch:  306  	Training Loss: 0.0005991370417177677
Test Loss:  0.0007442806381732225
Valid Loss:  0.0005730676930397749
Epoch:  307  	Training Loss: 0.0005991082289256155
Test Loss:  0.0007442875066772103
Valid Loss:  0.0005730469711124897
Epoch:  308  	Training Loss: 0.0005990815698169172
Test Loss:  0.0007442922797054052
Valid Loss:  0.0005730255506932735
Epoch:  309  	Training Loss: 0.000599055492784828
Test Loss:  0.0007442975766025484
Valid Loss:  0.0005730047123506665
Epoch:  310  	Training Loss: 0.0005990296485833824
Test Loss:  0.0007443042704835534
Valid Loss:  0.0005729829426854849
Epoch:  311  	Training Loss: 0.0005990049103274941
Test Loss:  0.0007443095091730356
Valid Loss:  0.0005729625700041652
Epoch:  312  	Training Loss: 0.0005989802302792668
Test Loss:  0.0007436966407112777
Valid Loss:  0.0005729724653065205
Epoch:  313  	Training Loss: 0.0005989460041746497
Test Loss:  0.0007431745762005448
Valid Loss:  0.000572972756344825
Epoch:  314  	Training Loss: 0.0005989170167595148
Test Loss:  0.0007427126402035356
Valid Loss:  0.000572968740016222
Epoch:  315  	Training Loss: 0.0005988904740661383
Test Loss:  0.0007422869675792754
Valid Loss:  0.0005729623371735215
Epoch:  316  	Training Loss: 0.00059886573581025
Test Loss:  0.0007418902823701501
Valid Loss:  0.00057295395527035
Epoch:  317  	Training Loss: 0.0005988426855765283
Test Loss:  0.0007415128638967872
Valid Loss:  0.0005729454569518566
Epoch:  318  	Training Loss: 0.0005988214397802949
Test Loss:  0.0007411518017761409
Valid Loss:  0.0005729384138248861
Epoch:  319  	Training Loss: 0.0005988015909679234
Test Loss:  0.0007408061064779758
Valid Loss:  0.0005729306722059846
Epoch:  320  	Training Loss: 0.0005987825570628047
Test Loss:  0.0007404743228107691
Valid Loss:  0.0005729240365326405
Epoch:  321  	Training Loss: 0.0005987654440104961
Test Loss:  0.0007401537732221186
Valid Loss:  0.0005729186232201755
Epoch:  322  	Training Loss: 0.0005987491458654404
Test Loss:  0.0007376765715889633
Valid Loss:  0.0005714994622394443
Epoch:  323  	Training Loss: 0.0005976079264655709
Test Loss:  0.0007353178225457668
Valid Loss:  0.0005702399648725986
Epoch:  324  	Training Loss: 0.0005966191529296339
Test Loss:  0.0007336229318752885
Valid Loss:  0.0005691919941455126
Epoch:  325  	Training Loss: 0.0005958801484666765
Test Loss:  0.000732195214368403
Valid Loss:  0.000568193499930203
Epoch:  326  	Training Loss: 0.0005952223436906934
Test Loss:  0.0007310124346986413
Valid Loss:  0.000567290117032826
Epoch:  327  	Training Loss: 0.0005946618039160967
Test Loss:  0.0007300641736947
Valid Loss:  0.0005664677009917796
Epoch:  328  	Training Loss: 0.0005941722774878144
Test Loss:  0.0007292961236089468
Valid Loss:  0.0005657225847244263
Epoch:  329  	Training Loss: 0.0005937519599683583
Test Loss:  0.0007286614272743464
Valid Loss:  0.000564996269531548
Epoch:  330  	Training Loss: 0.0005933491047471762
Test Loss:  0.000728109385818243
Valid Loss:  0.0005642921896651387
Epoch:  331  	Training Loss: 0.0005929602775722742
Test Loss:  0.0007276448304764926
Valid Loss:  0.0005636073183268309
Epoch:  332  	Training Loss: 0.0005925861187279224
Test Loss:  0.0007275911048054695
Valid Loss:  0.0005556893302127719
Epoch:  333  	Training Loss: 0.0005783093511126935
Test Loss:  0.0007331681554205716
Valid Loss:  0.0005474730860441923
Epoch:  334  	Training Loss: 0.0005714381695725024
Test Loss:  0.0007323210593312979
Valid Loss:  0.0005454738275147974
Epoch:  335  	Training Loss: 0.0005671248654834926
Test Loss:  0.0007336819544434547
Valid Loss:  0.0005416212370619178
Epoch:  336  	Training Loss: 0.0005640753661282361
Test Loss:  0.000731694046407938
Valid Loss:  0.0005402344395406544
Epoch:  337  	Training Loss: 0.0005614489782601595
Test Loss:  0.0007306718034669757
Valid Loss:  0.0005376209155656397
Epoch:  338  	Training Loss: 0.0005590686341747642
Test Loss:  0.0007281119469553232
Valid Loss:  0.0005361416842788458
Epoch:  339  	Training Loss: 0.0005569956265389919
Test Loss:  0.0007253827061504126
Valid Loss:  0.0005341836949810386
Epoch:  340  	Training Loss: 0.0005552447400987148
Test Loss:  0.0007218676037155092
Valid Loss:  0.0005329640698619187
Epoch:  341  	Training Loss: 0.000553628895431757
Test Loss:  0.0007188247400335968
Valid Loss:  0.0005315425805747509
Epoch:  342  	Training Loss: 0.0005520599661394954
Test Loss:  0.0007134148618206382
Valid Loss:  0.0005287964595481753
Epoch:  343  	Training Loss: 0.0005496543599292636
Test Loss:  0.0007082182564772666
Valid Loss:  0.0005268901586532593
Epoch:  344  	Training Loss: 0.0005477777449414134
Test Loss:  0.0007038464536890388
Valid Loss:  0.0005252270493656397
Epoch:  345  	Training Loss: 0.0005461600958369672
Test Loss:  0.000699835829436779
Valid Loss:   69%|██████▉   | 345/500 [04:06<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:06<01:09,  2.22it/s] 70%|██████▉   | 349/500 [04:06<00:50,  2.98it/s] 70%|███████   | 351/500 [04:12<02:55,  1.18s/it] 71%|███████   | 353/500 [04:13<02:04,  1.18it/s] 71%|███████   | 355/500 [04:13<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:13<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:13<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:19<02:40,  1.16s/it] 73%|███████▎  | 363/500 [04:19<01:53,  1.20it/s] 73%|███████▎  | 365/500 [04:19<01:21,  1.66it/s] 73%|███████▎  | 367/500 [04:20<00:58,  2.27it/s] 74%|███████▍  | 369/500 [04:20<00:42,  3.06it/s] 74%|███████▍  | 371/500 [04:26<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:26<01:46,  1.20it/s] 75%|███████▌  | 375/500 [04:26<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:26<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:26<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:33<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:33<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:33<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:33<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:33<00:36,  3.03it/s] 78%|███████▊  | 391/500 [04:39<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:40<01:28,  1.20it/s] 79%|███████▉  | 395/500 [04:40<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:40<00:45,  2.27it/s] 80%|███████▉  | 399/500 [04:40<00:33,  3.04it/s] 80%|████████  | 401/500 [04:46<01:55,  1.16s/it] 81%|████████  | 403/500 [04:46<01:20,  1.20it/s] 81%|████████  | 405/500 [04:46<00:57,  1.66it/s] 81%|████████▏ | 407/500 [04:47<00:41,  2.26it/s] 82%|████████▏ | 409/500 [04:47<00:30,  3.03it/s] 82%|████████▏ | 411/500 [04:53<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:53<01:12,  1.19it/s]0.0005237343721091747
Epoch:  346  	Training Loss: 0.0005446893628686666
Test Loss:  0.0006962296320125461
Valid Loss:  0.0005223857006058097
Epoch:  347  	Training Loss: 0.0005433649057522416
Test Loss:  0.0006928724469617009
Valid Loss:  0.0005211567040532827
Epoch:  348  	Training Loss: 0.0005421800306066871
Test Loss:  0.0006899143918417394
Valid Loss:  0.0005199969746172428
Epoch:  349  	Training Loss: 0.0005411023739725351
Test Loss:  0.0006870989454910159
Valid Loss:  0.0005189975490793586
Epoch:  350  	Training Loss: 0.0005402134265750647
Test Loss:  0.0006846541655249894
Valid Loss:  0.0005180625012144446
Epoch:  351  	Training Loss: 0.0005394269246608019
Test Loss:  0.0006824149168096483
Valid Loss:  0.0005172137171030045
Epoch:  352  	Training Loss: 0.0005387318669818342
Test Loss:  0.000685172388330102
Valid Loss:  0.0005164376925677061
Epoch:  353  	Training Loss: 0.0005345180979929864
Test Loss:  0.000684675294905901
Valid Loss:  0.000515891530085355
Epoch:  354  	Training Loss: 0.0005340150673873723
Test Loss:  0.0006843075389042497
Valid Loss:  0.0005155251710675657
Epoch:  355  	Training Loss: 0.0005335874739103019
Test Loss:  0.0006839361740276217
Valid Loss:  0.0005152077646926045
Epoch:  356  	Training Loss: 0.0005331783322617412
Test Loss:  0.0006837882101535797
Valid Loss:  0.0005149870412424207
Epoch:  357  	Training Loss: 0.0005327858962118626
Test Loss:  0.0006832374492660165
Valid Loss:  0.0005146411713212729
Epoch:  358  	Training Loss: 0.0005324658704921603
Test Loss:  0.0006828275509178638
Valid Loss:  0.0005143657326698303
Epoch:  359  	Training Loss: 0.0005321492208167911
Test Loss:  0.0006824084557592869
Valid Loss:  0.0005140946013852954
Epoch:  360  	Training Loss: 0.0005318342591635883
Test Loss:  0.0006819702102802694
Valid Loss:  0.0005138259148225188
Epoch:  361  	Training Loss: 0.0005315206944942474
Test Loss:  0.0006815182860009372
Valid Loss:  0.0005135590326972306
Epoch:  362  	Training Loss: 0.000531209516339004
Test Loss:  0.0006808391772210598
Valid Loss:  0.0005112932994961739
Epoch:  363  	Training Loss: 0.000529709504917264
Test Loss:  0.0006797442329116166
Valid Loss:  0.0005104490555822849
Epoch:  364  	Training Loss: 0.0005285913357511163
Test Loss:  0.0006784084253013134
Valid Loss:  0.0005095021915622056
Epoch:  365  	Training Loss: 0.0005275915027596056
Test Loss:  0.0006770670879632235
Valid Loss:  0.0005086753517389297
Epoch:  366  	Training Loss: 0.0005266311345621943
Test Loss:  0.0006756354123353958
Valid Loss:  0.0005078638787381351
Epoch:  367  	Training Loss: 0.0005256951553747058
Test Loss:  0.0006742565310560167
Valid Loss:  0.0005070763290859759
Epoch:  368  	Training Loss: 0.0005247843218967319
Test Loss:  0.0006727933650836349
Valid Loss:  0.0005064514698460698
Epoch:  369  	Training Loss: 0.0005238947924226522
Test Loss:  0.0006710637826472521
Valid Loss:  0.0005057830130681396
Epoch:  370  	Training Loss: 0.0005230867536738515
Test Loss:  0.0006693840259686112
Valid Loss:  0.0005052159540355206
Epoch:  371  	Training Loss: 0.000522301415912807
Test Loss:  0.0006679725483991206
Valid Loss:  0.0005046623409725726
Epoch:  372  	Training Loss: 0.0005215315613895655
Test Loss:  0.0006673490279354155
Valid Loss:  0.0005041625699959695
Epoch:  373  	Training Loss: 0.0005205055349506438
Test Loss:  0.0006662842934019864
Valid Loss:  0.0005032704793848097
Epoch:  374  	Training Loss: 0.0005195504636503756
Test Loss:  0.0006651130970567465
Valid Loss:  0.000502540438901633
Epoch:  375  	Training Loss: 0.0005186958587728441
Test Loss:  0.0006633909652009606
Valid Loss:  0.0005018248339183629
Epoch:  376  	Training Loss: 0.0005179359577596188
Test Loss:  0.0006619184277951717
Valid Loss:  0.0005012924084439874
Epoch:  377  	Training Loss: 0.000517193169798702
Test Loss:  0.0006604245863854885
Valid Loss:  0.0005007351282984018
Epoch:  378  	Training Loss: 0.0005164650501683354
Test Loss:  0.0006589451804757118
Valid Loss:  0.0005002017132937908
Epoch:  379  	Training Loss: 0.0005157515988685191
Test Loss:  0.0006574764265678823
Valid Loss:  0.0004996741190552711
Epoch:  380  	Training Loss: 0.0005150515935383737
Test Loss:  0.0006560212932527065
Valid Loss:  0.0004991585738025606
Epoch:  381  	Training Loss: 0.000514367304276675
Test Loss:  0.0006544902571476996
Valid Loss:  0.0004986367421224713
Epoch:  382  	Training Loss: 0.0005137181142345071
Test Loss:  0.000637615448795259
Valid Loss:  0.0004917077021673322
Epoch:  383  	Training Loss: 0.0005069364560768008
Test Loss:  0.0006264057010412216
Valid Loss:  0.00048761957441456616
Epoch:  384  	Training Loss: 0.0005030615720897913
Test Loss:  0.0006181051721796393
Valid Loss:  0.00048506574239581823
Epoch:  385  	Training Loss: 0.0005005741841159761
Test Loss:  0.0006121362093836069
Valid Loss:  0.0004832749255001545
Epoch:  386  	Training Loss: 0.0004988424479961395
Test Loss:  0.0006074272678233683
Valid Loss:  0.00048194147530011833
Epoch:  387  	Training Loss: 0.0004975252668373287
Test Loss:  0.0006038433639332652
Valid Loss:  0.00048084670561365783
Epoch:  388  	Training Loss: 0.0004964976105839014
Test Loss:  0.0006010993965901434
Valid Loss:  0.00047997600631788373
Epoch:  389  	Training Loss: 0.0004956756019964814
Test Loss:  0.0005991799989715219
Valid Loss:  0.0004792730323970318
Epoch:  390  	Training Loss: 0.0004950440488755703
Test Loss:  0.0005977953551337123
Valid Loss:  0.0004786619101651013
Epoch:  391  	Training Loss: 0.0004945059772580862
Test Loss:  0.0005966653698123991
Valid Loss:  0.0004780933086294681
Epoch:  392  	Training Loss: 0.0004940076032653451
Test Loss:  0.000597436330281198
Valid Loss:  0.00047503632958978415
Epoch:  393  	Training Loss: 0.0004904718953184783
Test Loss:  0.000598583952523768
Valid Loss:  0.0004721017030533403
Epoch:  394  	Training Loss: 0.0004874568257946521
Test Loss:  0.0005989124765619636
Valid Loss:  0.0004696567775681615
Epoch:  395  	Training Loss: 0.0004847236559726298
Test Loss:  0.0005990940262563527
Valid Loss:  0.0004673025105148554
Epoch:  396  	Training Loss: 0.00048219121526926756
Test Loss:  0.0005988636985421181
Valid Loss:  0.00046517018927261233
Epoch:  397  	Training Loss: 0.0004798012669198215
Test Loss:  0.0005982405273243785
Valid Loss:  0.00046300896792672575
Epoch:  398  	Training Loss: 0.00047754828119650483
Test Loss:  0.000597289064899087
Valid Loss:  0.0004609607276506722
Epoch:  399  	Training Loss: 0.0004753552784677595
Test Loss:  0.0005961429560557008
Valid Loss:  0.00045886987936683
Epoch:  400  	Training Loss: 0.00047320121666416526
Test Loss:  0.0005947906756773591
Valid Loss:  0.0004568487056531012
Epoch:  401  	Training Loss: 0.00047107526916079223
Test Loss:  0.000593370757997036
Valid Loss:  0.0004548240394797176
Epoch:  402  	Training Loss: 0.00046897208085283637
Test Loss:  0.0005931900814175606
Valid Loss:  0.0004493537126109004
Epoch:  403  	Training Loss: 0.0004629544564522803
Test Loss:  0.000591466436162591
Valid Loss:  0.00044434680603444576
Epoch:  404  	Training Loss: 0.00045787746785208583
Test Loss:  0.000588144815992564
Valid Loss:  0.0004401111218612641
Epoch:  405  	Training Loss: 0.00045311072608456016
Test Loss:  0.0005851234309375286
Valid Loss:  0.00043518783058971167
Epoch:  406  	Training Loss: 0.00044854998122900724
Test Loss:  0.0005802634987048805
Valid Loss:  0.00043203396489843726
Epoch:  407  	Training Loss: 0.000444196310127154
Test Loss:  0.0005783827509731054
Valid Loss:  0.0004266029573045671
Epoch:  408  	Training Loss: 0.00044030387653037906
Test Loss:  0.0005723641952499747
Valid Loss:  0.00042730214772745967
Epoch:  409  	Training Loss: 0.00043765633017756045
Test Loss:  0.0005783720989711583
Valid Loss:  0.0004231097118463367
Epoch:  410  	Training Loss: 0.0004386278160382062
Test Loss:  0.0005798169877380133
Valid Loss:  0.0004457044997252524
Epoch:  411  	Training Loss: 0.000450725230621174
Test Loss:  0.0006400453858077526
Valid Loss:  0.00047661096323281527
Epoch:  412  	Training Loss: 0.0004967193235643208
Test Loss:  0.0005210504168644547
Valid Loss:  0.00041191268246620893
Epoch:  413  	Training Loss: 0.0004249416524544358
Test Loss:  0.0005204437766224146
Valid Loss:  0.0004116743803024292
 83%|████████▎ | 415/500 [04:59<02:10,  1.53s/it] 83%|████████▎ | 417/500 [05:00<01:30,  1.10s/it] 84%|████████▍ | 419/500 [05:00<01:03,  1.27it/s] 84%|████████▍ | 421/500 [05:06<01:57,  1.48s/it] 85%|████████▍ | 423/500 [05:06<01:21,  1.06s/it] 85%|████████▌ | 425/500 [05:06<00:56,  1.32it/s] 85%|████████▌ | 427/500 [05:06<00:40,  1.82it/s] 86%|████████▌ | 429/500 [05:06<00:28,  2.47it/s] 86%|████████▌ | 431/500 [05:13<01:24,  1.22s/it] 87%|████████▋ | 433/500 [05:13<00:58,  1.14it/s] 87%|████████▋ | 435/500 [05:13<00:41,  1.58it/s] 87%|████████▋ | 437/500 [05:13<00:29,  2.16it/s] 88%|████████▊ | 439/500 [05:13<00:21,  2.90it/s] 88%|████████▊ | 441/500 [05:19<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:19<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:20<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:20<00:23,  2.26it/s] 90%|████████▉ | 449/500 [05:20<00:16,  3.03it/s] 90%|█████████ | 451/500 [05:26<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:26<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:26<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:27<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:27<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:33<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:33<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:33<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:33<00:14,  2.26it/s] 94%|█████████▍| 469/500 [05:33<00:10,  3.04it/s] 94%|█████████▍| 471/500 [05:40<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:40<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:40<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:40<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:40<00:06,  3.01it/s]Epoch:  414  	Training Loss: 0.00042446263250894845
Test Loss:  0.0005218589212745428
Valid Loss:  0.00041138753294944763
Epoch:  415  	Training Loss: 0.00042418797966092825
Test Loss:  0.0005231214454397559
Valid Loss:  0.0004111418384127319
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.000423964491346851
Test Loss:  0.0005231683608144522
Valid Loss:  0.00041009639971889555
Epoch:  417  	Training Loss: 0.00042301660869270563
Test Loss:  0.000523055496159941
Valid Loss:  0.0004090973234269768
Epoch:  418  	Training Loss: 0.0004220945993438363
Test Loss:  0.0005228967638686299
Valid Loss:  0.00040812543011270463
Epoch:  419  	Training Loss: 0.0004211945924907923
Test Loss:  0.0005227377405390143
Valid Loss:  0.0004071768489666283
Epoch:  420  	Training Loss: 0.00042031664634123445
Test Loss:  0.0005225582281127572
Valid Loss:  0.000406250124797225
Epoch:  421  	Training Loss: 0.0004194604989606887
Test Loss:  0.0005223644548095763
Valid Loss:  0.00040537159657105803
Epoch:  422  	Training Loss: 0.0004186254518572241
Test Loss:  0.0005214543780311942
Valid Loss:  0.00040420563891530037
Epoch:  423  	Training Loss: 0.0004175608919467777
Test Loss:  0.0005205731722526252
Valid Loss:  0.0004031268472317606
Epoch:  424  	Training Loss: 0.00041660756687633693
Test Loss:  0.0005197465652599931
Valid Loss:  0.0004021555942017585
Epoch:  425  	Training Loss: 0.0004157795920036733
Test Loss:  0.0005189685616642237
Valid Loss:  0.0004012850986327976
Epoch:  426  	Training Loss: 0.0004150386084802449
Test Loss:  0.0005182287422940135
Valid Loss:  0.00040048020309768617
Epoch:  427  	Training Loss: 0.00041433595470152795
Test Loss:  0.000517505977768451
Valid Loss:  0.0003997146850451827
Epoch:  428  	Training Loss: 0.0004136677016504109
Test Loss:  0.0005167988128960133
Valid Loss:  0.00039898432441987097
Epoch:  429  	Training Loss: 0.00041303716716356575
Test Loss:  0.000516166677698493
Valid Loss:  0.0003983014030382037
Epoch:  430  	Training Loss: 0.00041245229658670723
Test Loss:  0.0005155527614988387
Valid Loss:  0.00039764776010997593
Epoch:  431  	Training Loss: 0.00041189277544617653
Test Loss:  0.0005149539792910218
Valid Loss:  0.00039701967034488916
Epoch:  432  	Training Loss: 0.00041135645005851984
Test Loss:  0.0005140673601999879
Valid Loss:  0.0003917350259143859
Epoch:  433  	Training Loss: 0.000404771592002362
Test Loss:  0.0005167067283764482
Valid Loss:  0.0003895162371918559
Epoch:  434  	Training Loss: 0.00040211298619396985
Test Loss:  0.0005190010997466743
Valid Loss:  0.0003882321179844439
Epoch:  435  	Training Loss: 0.00040052158874459565
Test Loss:  0.0005205590859986842
Valid Loss:  0.00038730952655896544
Epoch:  436  	Training Loss: 0.00039939285488799214
Test Loss:  0.0005214388947933912
Valid Loss:  0.0003865804465021938
Epoch:  437  	Training Loss: 0.0003985005314461887
Test Loss:  0.0005218044389039278
Valid Loss:  0.0003859669086523354
Epoch:  438  	Training Loss: 0.0003977466549258679
Test Loss:  0.0005216873250901699
Valid Loss:  0.0003854128299281001
Epoch:  439  	Training Loss: 0.0003970946418121457
Test Loss:  0.0005212938413023949
Valid Loss:  0.00038489041617140174
Epoch:  440  	Training Loss: 0.0003964736533816904
Test Loss:  0.0005207364447414875
Valid Loss:  0.00038438645424321294
Epoch:  441  	Training Loss: 0.00039588173967786133
Test Loss:  0.000520004250574857
Valid Loss:  0.00038389567635022104
Epoch:  442  	Training Loss: 0.0003953056293539703
Test Loss:  0.0005205059424042702
Valid Loss:  0.0003828036424238235
Epoch:  443  	Training Loss: 0.0003948030062019825
Test Loss:  0.0005205731140449643
Valid Loss:  0.0003826861793641001
Epoch:  444  	Training Loss: 0.0003947564691770822
Test Loss:  0.00052054034313187
Valid Loss:  0.000382636149879545
Epoch:  445  	Training Loss: 0.00039471726631745696
Test Loss:  0.0005204966873861849
Valid Loss:  0.0003825952298939228
Epoch:  446  	Training Loss: 0.0003946801007259637
Test Loss:  0.0005204557674005628
Valid Loss:  0.00038255585241131485
Epoch:  447  	Training Loss: 0.00039464252768084407
Test Loss:  0.0005204137996770442
Valid Loss:  0.00038251554360613227
Epoch:  448  	Training Loss: 0.0003946051874663681
Test Loss:  0.0005203725886531174
Valid Loss:  0.00038247572956606746
Epoch:  449  	Training Loss: 0.0003945678472518921
Test Loss:  0.0005203310865908861
Valid Loss:  0.0003824352170340717
Epoch:  450  	Training Loss: 0.0003945307107642293
Test Loss:  0.0005202902248129249
Valid Loss:  0.0003823951701633632
Epoch:  451  	Training Loss: 0.00039449339965358377
Test Loss:  0.0005202492466196418
Valid Loss:  0.00038235567626543343
Epoch:  452  	Training Loss: 0.0003944563795812428
Test Loss:  0.0005182488239370286
Valid Loss:  0.00038214345113374293
Epoch:  453  	Training Loss: 0.000393566966522485
Test Loss:  0.000517366745043546
Valid Loss:  0.000382254394935444
Epoch:  454  	Training Loss: 0.000393217516830191
Test Loss:  0.0005168647621758282
Valid Loss:  0.00038231705548241735
Epoch:  455  	Training Loss: 0.0003930478123947978
Test Loss:  0.0005165472975932062
Valid Loss:  0.0003823271254077554
Epoch:  456  	Training Loss: 0.00039291661232709885
Test Loss:  0.0005163096357136965
Valid Loss:  0.0003822992439381778
Epoch:  457  	Training Loss: 0.00039279641350731254
Test Loss:  0.0005161035805940628
Valid Loss:  0.00038224755553528666
Epoch:  458  	Training Loss: 0.0003926806675735861
Test Loss:  0.00051590905059129
Valid Loss:  0.00038218341069296
Epoch:  459  	Training Loss: 0.0003925666678696871
Test Loss:  0.0005157158011570573
Valid Loss:  0.0003821112331934273
Epoch:  460  	Training Loss: 0.00039245307561941445
Test Loss:  0.0005155187100172043
Valid Loss:  0.00038203486474230886
Epoch:  461  	Training Loss: 0.00039234006544575095
Test Loss:  0.0005153180682100356
Valid Loss:  0.00038195663364604115
Epoch:  462  	Training Loss: 0.0003922273754142225
Test Loss:  0.0005150788347236812
Valid Loss:  0.000381642603315413
Epoch:  463  	Training Loss: 0.00039201148319989443
Test Loss:  0.0005146950716152787
Valid Loss:  0.000381390011170879
Epoch:  464  	Training Loss: 0.0003918283327948302
Test Loss:  0.0005142149748280644
Valid Loss:  0.00038117915391921997
Epoch:  465  	Training Loss: 0.00039166619535535574
Test Loss:  0.0005136709078215063
Valid Loss:  0.0003809977788478136
Epoch:  466  	Training Loss: 0.0003915192501153797
Test Loss:  0.0005130867939442396
Valid Loss:  0.00038083893014118075
Epoch:  467  	Training Loss: 0.00039138467400334775
Test Loss:  0.0005124824238009751
Valid Loss:  0.000380698184017092
Epoch:  468  	Training Loss: 0.0003912601387128234
Test Loss:  0.0005118700210005045
Valid Loss:  0.00038057059282436967
Epoch:  469  	Training Loss: 0.000391143694287166
Test Loss:  0.0005112580256536603
Valid Loss:  0.0003804553998634219
Epoch:  470  	Training Loss: 0.00039103548624552786
Test Loss:  0.0005106540047563612
Valid Loss:  0.0003803494037128985
Epoch:  471  	Training Loss: 0.00039093405939638615
Test Loss:  0.0005100616253912449
Valid Loss:  0.00038025231333449483
Epoch:  472  	Training Loss: 0.00039083935553207994
Test Loss:  0.0005092290812171996
Valid Loss:  0.0003802916035056114
Epoch:  473  	Training Loss: 0.00039079863927327096
Test Loss:  0.0005086424644105136
Valid Loss:  0.00038032548036426306
Epoch:  474  	Training Loss: 0.0003907734644599259
Test Loss:  0.0005082245916128159
Valid Loss:  0.0003803516738116741
Epoch:  475  	Training Loss: 0.0003907542850356549
Test Loss:  0.0005079185357317328
Valid Loss:  0.000380370911443606
Epoch:  476  	Training Loss: 0.0003907390928361565
Test Loss:  0.000507691758684814
Valid Loss:  0.00038038549246266484
Epoch:  477  	Training Loss: 0.0003907264326699078
Test Loss:  0.0005075180088169873
Valid Loss:  0.00038039576611481607
Epoch:  478  	Training Loss: 0.0003907159552909434
Test Loss:  0.0005073528736829758
Valid Loss:  0.00038040627259761095
Epoch:  479  	Training Loss: 0.0003907085629180074
Test Loss:  0.0005072288913652301
Valid Loss:  0.0003804126172326505
Epoch:  480  	Training Loss: 0.0003907029749825597
Test Loss:  0.0005071055493317544
Valid Loss:   96%|█████████▌| 481/500 [05:47<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:47<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:47<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:47<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:47<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:53<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:54<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:54<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:54<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:54<00:00,  3.01it/s]100%|██████████| 500/500 [05:54<00:00,  1.41it/s]
0.00038042018422856927
Epoch:  481  	Training Loss: 0.0003906987840309739
Test Loss:  0.0005070189363323152
Valid Loss:  0.0003804248117376119
Epoch:  482  	Training Loss: 0.0003906949423253536
Test Loss:  0.0005073971697129309
Valid Loss:  0.00037940696347504854
Epoch:  483  	Training Loss: 0.00039022855344228446
Test Loss:  0.0005068609025329351
Valid Loss:  0.0003793005598708987
Epoch:  484  	Training Loss: 0.0003901593736372888
Test Loss:  0.0005062785348854959
Valid Loss:  0.0003792505303863436
Epoch:  485  	Training Loss: 0.00039010285399854183
Test Loss:  0.0005057132220827043
Valid Loss:  0.00037921243347227573
Epoch:  486  	Training Loss: 0.0003900531155522913
Test Loss:  0.0005052078631706536
Valid Loss:  0.00037917806184850633
Epoch:  487  	Training Loss: 0.0003900076844729483
Test Loss:  0.0005047197337262332
Valid Loss:  0.000379151024390012
Epoch:  488  	Training Loss: 0.00038996542571112514
Test Loss:  0.000504255120176822
Valid Loss:  0.0003791258786804974
Epoch:  489  	Training Loss: 0.0003899268922396004
Test Loss:  0.0005037838127464056
Valid Loss:  0.00037910486571490765
Epoch:  490  	Training Loss: 0.00038989080348983407
Test Loss:  0.0005033721681684256
Valid Loss:  0.00037908274680376053
Epoch:  491  	Training Loss: 0.0003898577415384352
Test Loss:  0.0005029444582760334
Valid Loss:  0.000379066274035722
Epoch:  492  	Training Loss: 0.000389826949685812
Test Loss:  0.0005023839185014367
Valid Loss:  0.00037901446921750903
Epoch:  493  	Training Loss: 0.00038975058123469353
Test Loss:  0.0005018787924200296
Valid Loss:  0.0003789555048570037
Epoch:  494  	Training Loss: 0.0003896776761393994
Test Loss:  0.0005014074849896133
Valid Loss:  0.00037889648228883743
Epoch:  495  	Training Loss: 0.0003896076523233205
Test Loss:  0.0005009615560993552
Valid Loss:  0.0003788387402892113
Epoch:  496  	Training Loss: 0.00038954082992859185
Test Loss:  0.0005005380953662097
Valid Loss:  0.00037878204602748156
Epoch:  497  	Training Loss: 0.00038947598659433424
Test Loss:  0.0005001345998607576
Valid Loss:  0.0003787269815802574
Epoch:  498  	Training Loss: 0.00038941350067034364
Test Loss:  0.0004997506039217114
Valid Loss:  0.0003786739835049957
Epoch:  499  	Training Loss: 0.00038935348857194185
Test Loss:  0.0004993833717890084
Valid Loss:  0.00037862255703657866
Epoch:  500  	Training Loss: 0.00038929490256123245
Test Loss:  0.0004990334855392575
Valid Loss:  0.000378571217879653
seed is  10
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.50it/s]  1%|          | 4/500 [00:00<00:31, 15.76it/s]  1%|          | 6/500 [00:00<00:30, 16.16it/s]  2%|▏         | 8/500 [00:00<00:30, 16.26it/s]  2%|▏         | 10/500 [00:00<00:29, 16.34it/s]  2%|▏         | 12/500 [00:00<00:30, 16.24it/s]  3%|▎         | 14/500 [00:00<00:29, 16.31it/s]  3%|▎         | 16/500 [00:00<00:30, 15.94it/s]  4%|▎         | 18/500 [00:01<00:30, 16.03it/s]  4%|▍         | 20/500 [00:01<00:29, 16.23it/s]  4%|▍         | 22/500 [00:01<00:29, 16.26it/s]  5%|▍         | 24/500 [00:01<00:29, 16.36it/s]  5%|▌         | 26/500 [00:01<00:28, 16.42it/s]  6%|▌         | 28/500 [00:01<00:28, 16.35it/s]  6%|▌         | 30/500 [00:01<00:29, 15.95it/s]  6%|▋         | 32/500 [00:01<00:28, 16.15it/s]  7%|▋         | 34/500 [00:02<00:28, 16.11it/s]  7%|▋         | 36/500 [00:02<00:28, 16.07it/s]  8%|▊         | 38/500 [00:02<00:28, 16.16it/s]  8%|▊         | 40/500 [00:02<00:28, 16.28it/s]  8%|▊         | 42/500 [00:02<00:29, 15.77it/s]  9%|▉         | 44/500 [00:02<00:28, 16.11it/s]  9%|▉         | 46/500 [00:02<00:27, 16.32it/s] 10%|▉         | 48/500 [00:02<00:27, 16.41it/s] 10%|█         | 50/500 [00:03<00:27, 16.49it/s] 10%|█         | 52/500 [00:03<00:27, 16.24it/s] 11%|█         | 54/500 [00:03<00:28, 15.90it/s] 11%|█         | 56/500 [00:03<00:27, 16.05it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.05it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.12it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.14it/s] 13%|█▎        | 64/500 [00:03<00:27, 16.09it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.93it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.99it/s] 14%|█▍        | 70/500 [00:04<00:26, 15.99it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.84it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.82it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.92it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.14it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.31it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.41it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.48it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.47it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.98it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.97it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.09it/s] 19%|█▉        | 94/500 [00:05<00:25, 16.19it/s] 19%|█▉        | 96/500 [00:05<00:25, 16.12it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.20it/s] 20%|██        | 100/500 [00:06<00:24, 16.22it/s] 20%|██        | 102/500 [00:06<00:24, 16.07it/s] 21%|██        | 104/500 [00:06<00:24, 16.20it/s] 21%|██        | 106/500 [00:06<00:24, 16.24it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.93it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.09it/s] 22%|██▏       | 112/500 [00:06<00:24, 15.72it/s] 23%|██▎       | 114/500 [00:07<00:24, 16.04it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.94it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.12it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.28it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.40it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.39it/s]Epoch:  1  	Training Loss: 0.06297262012958527
Test Loss:  556.0709838867188
Valid Loss:  558.523681640625
Epoch:  2  	Training Loss: 557.6104736328125
Test Loss:  1153384054784.0
Valid Loss:  1156222812160.0
Epoch:  3  	Training Loss: 1155909156864.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.25it/s] 26%|██▌       | 128/500 [00:07<00:23, 16.15it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.33it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.39it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.50it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.50it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.53it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.45it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.51it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.56it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.61it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.66it/s] 30%|███       | 150/500 [00:09<00:21, 16.50it/s] 30%|███       | 152/500 [00:09<00:20, 16.62it/s] 31%|███       | 154/500 [00:09<00:20, 16.63it/s] 31%|███       | 156/500 [00:09<00:21, 16.29it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.37it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.26it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.27it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.30it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.35it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.28it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.36it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.39it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.36it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.38it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.23it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.29it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.41it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.13it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.28it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.41it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.44it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.42it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.31it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.27it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.18it/s] 40%|████      | 200/500 [00:12<00:18, 16.14it/s] 40%|████      | 202/500 [00:12<00:18, 16.29it/s] 41%|████      | 204/500 [00:12<00:18, 16.40it/s] 41%|████      | 206/500 [00:12<00:18, 16.32it/s] 42%|████▏     | 208/500 [00:12<00:18, 16.20it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.17it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.24it/s] 43%|████▎     | 214/500 [00:13<00:17, 15.98it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.94it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.84it/s] 44%|████▍     | 220/500 [00:13<00:17, 15.83it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.06it/s] 45%|████▍     | 224/500 [00:13<00:17, 15.73it/s] 45%|████▌     | 226/500 [00:13<00:17, 15.97it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.15it/s] 46%|████▌     | 230/500 [00:14<00:16, 15.91it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.13it/s] 47%|████▋     | 234/500 [00:14<00:17, 15.06it/s] 47%|████▋     | 236/500 [00:14<00:17, 14.92it/s] 48%|████▊     | 238/500 [00:14<00:17, 15.16it/s] 48%|████▊     | 240/500 [00:14<00:16, 15.49it/s] 48%|████▊     | 242/500 [00:14<00:16, 15.83it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.04it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.08it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.11it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.22it/s] 50%|█████     | 252/500 [00:15<00:15, 16.35it/s] 51%|█████     | 254/500 [00:15<00:15, 16.30it/s] 51%|█████     | 256/500 [00:15<00:15, 15.77it/s] 52%|█████▏    | 258/500 [00:15<00:15, 15.20it/s] 52%|█████▏    | 260/500 [00:16<00:17, 14.06it/s] 52%|█████▏    | 262/500 [00:16<00:16, 14.17it/s] 53%|█████▎    | 264/500 [00:16<00:15, 14.80it/s] 53%|█████▎    | 266/500 [00:16<00:15, 15.16it/s] 54%|█████▎    | 268/500 [00:16<00:15, 15.20it/s] 54%|█████▍    | 270/500 [00:16<00:14, 15.59it/s] 54%|█████▍    | 272/500 [00:16<00:14, 15.74it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.91it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.90it/s] 56%|█████▌    | 278/500 [00:17<00:13, 15.98it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.09it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.06it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.09it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.07it/s] 58%|█████▊    | 288/500 [00:17<00:13, 16.20it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.34it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.44it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.36it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.27it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.14it/s] 60%|██████    | 300/500 [00:18<00:12, 16.25it/s] 60%|██████    | 302/500 [00:18<00:12, 16.35it/s] 61%|██████    | 304/500 [00:18<00:12, 16.29it/s] 61%|██████    | 306/500 [00:19<00:11, 16.28it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.27it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.39it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.39it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.36it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.24it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.07it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.07it/s] 64%|██████▍   | 322/500 [00:19<00:11, 16.00it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.05it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.04it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.10it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.85it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.10it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.06it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.20it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.25it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.30it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.29it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.10it/s] 69%|██████▉   | 346/500 [00:21<00:09, 15.99it/s] 70%|██████▉   | 348/500 [00:21<00:09, 15.93it/s] 70%|███████   | 350/500 [00:21<00:09, 16.08it/s] 70%|███████   | 352/500 [00:21<00:09, 16.11it/s] 71%|███████   | 354/500 [00:21<00:08, 16.32it/s] 71%|███████   | 356/500 [00:22<00:08, 16.07it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.11it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.98it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.07it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.97it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.07it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.71it/s] 74%|███████▍  | 370/500 [00:22<00:08, 16.01it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.15it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.27it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.23it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.19it/s] 76%|███████▌  | 380/500 [00:23<00:07, 15.88it/s] 76%|███████▋  | 382/500 [00:23<00:07, 15.97it/s] 77%|███████▋  | 384/500 [00:23<00:07, 15.88it/s] 77%|███████▋  | 386/500 [00:23<00:07, 16.05it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.12it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.15it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.24it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.24it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.30it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.31it/s] 80%|████████  | 400/500 [00:24<00:06, 16.27it/s] 80%|████████  | 402/500 [00:24<00:06, 16.11it/s] 81%|████████  | 404/500 [00:25<00:06, 15.99it/s] 81%|████████  | 406/500 [00:25<00:06, 14.68it/s] 82%|████████▏ | 408/500 [00:25<00:06, 14.55it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.11it/s] 82%|████████▏ | 412/500 [00:25<00:05, 15.53it/s] 83%|████████▎ | 414/500 [00:25<00:05, 15.31it/s] 83%|████████▎ | 416/500 [00:25<00:05, 15.50it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.56it/s] 84%|████████▍ | 420/500 [00:26<00:05, 15.80it/s] 84%|████████▍ | 422/500 [00:26<00:04, 15.93it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.11it/s] 85%|████████▌ | 426/500 [00:26<00:05, 14.65it/s] 86%|████████▌ | 428/500 [00:26<00:04, 14.62it/s] 86%|████████▌ | 430/500 [00:26<00:04, 15.16it/s] 86%|████████▋ | 432/500 [00:26<00:04, 15.49it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.62it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.89it/s] 88%|████████▊ | 438/500 [00:27<00:03, 15.96it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.19it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.36it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.47it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.48it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.51it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.16it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.03it/s] 91%|█████████ | 454/500 [00:28<00:02, 15.90it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.04it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.15it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.26it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.41it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.37it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.44it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.54it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.51it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.08it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.24it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.31it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.39it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.02it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.15it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.18it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.03it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.37it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.33it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.76it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.99it/s] 99%|█████████▉| 496/500 [00:30<00:00, 15.97it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.96it/s]100%|██████████| 500/500 [00:31<00:00, 15.97it/s]100%|██████████| 500/500 [00:31<00:00, 16.04it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  10
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:16,  6.28s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:09,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.65it/s]  7%|▋         | 37/500 [00:27<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:33<06:26,  1.18it/s]  9%|▉         | 45/500 [00:33<04:38,  1.64it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:50,  1.18s/it] 11%|█         | 53/500 [00:40<06:19,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:47<08:36,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:54<08:22,  1.17s/it]Epoch:  1  	Training Loss: 0.06297262012958527
Test Loss:  12.96938705444336
Valid Loss:  12.826584815979004
Epoch:  2  	Training Loss: 12.874403953552246
Test Loss:  0.08029870688915253
Valid Loss:  0.07241552323102951
Epoch:  3  	Training Loss: 0.07714177668094635
Test Loss:  0.079278364777565
Valid Loss:  0.0715198665857315
Epoch:  4  	Training Loss: 0.07619713246822357
Test Loss:  0.07827242463827133
Valid Loss:  0.07063711434602737
Epoch:  5  	Training Loss: 0.07526594400405884
Test Loss:  0.077280692756176
Valid Loss:  0.06976711750030518
Epoch:  6  	Training Loss: 0.07434801012277603
Test Loss:  0.07630296051502228
Valid Loss:  0.0689096748828888
Epoch:  7  	Training Loss: 0.07344317436218262
Test Loss:  0.07533903419971466
Valid Loss:  0.0680646151304245
Epoch:  8  	Training Loss: 0.07255122065544128
Test Loss:  0.07438874244689941
Valid Loss:  0.06723175942897797
Epoch:  9  	Training Loss: 0.07167200744152069
Test Loss:  0.07345188409090042
Valid Loss:  0.06641095876693726
Epoch:  10  	Training Loss: 0.07080534100532532
Test Loss:  0.07252828776836395
Valid Loss:  0.06560203433036804
Epoch:  11  	Training Loss: 0.06995105743408203
Test Loss:  0.07161775231361389
Valid Loss:  0.0648048147559166
Epoch:  12  	Training Loss: 0.06910897046327591
Test Loss:  0.07076863944530487
Valid Loss:  0.0640590488910675
Epoch:  13  	Training Loss: 0.06832240521907806
Test Loss:  0.06993921846151352
Valid Loss:  0.06332842260599136
Epoch:  14  	Training Loss: 0.06755176931619644
Test Loss:  0.0691857635974884
Valid Loss:  0.06265970319509506
Epoch:  15  	Training Loss: 0.06684719026088715
Test Loss:  0.0684884712100029
Valid Loss:  0.06204517185688019
Epoch:  16  	Training Loss: 0.06619830429553986
Test Loss:  0.06803443282842636
Valid Loss:  0.06162421405315399
Epoch:  17  	Training Loss: 0.06575851887464523
Test Loss:  0.06775808334350586
Valid Loss:  0.06138010323047638
Epoch:  18  	Training Loss: 0.06550276279449463
Test Loss:  0.06748666614294052
Valid Loss:  0.061139944940805435
Epoch:  19  	Training Loss: 0.06525196135044098
Test Loss:  0.06721807271242142
Valid Loss:  0.06090262904763222
Epoch:  20  	Training Loss: 0.06500402837991714
Test Loss:  0.06697937101125717
Valid Loss:  0.06068498641252518
Epoch:  21  	Training Loss: 0.0647764652967453
Test Loss:  0.06692318618297577
Valid Loss:  0.0606246255338192
Epoch:  22  	Training Loss: 0.06471508741378784
Test Loss:  0.06691354513168335
Valid Loss:  0.06061333417892456
Epoch:  23  	Training Loss: 0.0647055134177208
Test Loss:  0.06690753996372223
Valid Loss:  0.06060793250799179
Epoch:  24  	Training Loss: 0.06470076739788055
Test Loss:  0.06690369546413422
Valid Loss:  0.06060384213924408
Epoch:  25  	Training Loss: 0.06469787657260895
Test Loss:  0.0669010654091835
Valid Loss:  0.06060090288519859
Epoch:  26  	Training Loss: 0.06469623744487762
Test Loss:  0.06689869612455368
Valid Loss:  0.060598380863666534
Epoch:  27  	Training Loss: 0.06469488888978958
Test Loss:  0.06689691543579102
Valid Loss:  0.060596831142902374
Epoch:  28  	Training Loss: 0.06469403207302094
Test Loss:  0.06689570844173431
Valid Loss:  0.06059575080871582
Epoch:  29  	Training Loss: 0.06469342112541199
Test Loss:  0.06689474731683731
Valid Loss:  0.06059487536549568
Epoch:  30  	Training Loss: 0.06469293683767319
Test Loss:  0.06689390540122986
Valid Loss:  0.06059413403272629
Epoch:  31  	Training Loss: 0.06469248980283737
Test Loss:  0.06689313799142838
Valid Loss:  0.060593463480472565
Epoch:  32  	Training Loss: 0.06469208002090454
Test Loss:  0.06689238548278809
Valid Loss:  0.06059281527996063
Epoch:  33  	Training Loss: 0.0646916851401329
Test Loss:  0.06689172238111496
Valid Loss:  0.06059227138757706
Epoch:  34  	Training Loss: 0.06469134241342545
Test Loss:  0.06689120829105377
Valid Loss:  0.060591790825128555
Epoch:  35  	Training Loss: 0.06469102203845978
Test Loss:  0.06689071655273438
Valid Loss:  0.060591354966163635
Epoch:  36  	Training Loss: 0.06469069421291351
Test Loss:  0.06689022481441498
Valid Loss:  0.0605909638106823
Epoch:  37  	Training Loss: 0.06469038128852844
Test Loss:  0.06688977777957916
Valid Loss:  0.06059061735868454
Epoch:  38  	Training Loss: 0.06469009816646576
Test Loss:  0.06688942760229111
Valid Loss:  0.06059029698371887
Epoch:  39  	Training Loss: 0.06468983739614487
Test Loss:  0.06688907742500305
Valid Loss:  0.06058996915817261
Epoch:  40  	Training Loss: 0.06468957662582397
Test Loss:  0.06688878685235977
Valid Loss:  0.06058967113494873
Epoch:  41  	Training Loss: 0.06468933820724487
Test Loss:  0.06688853353261948
Valid Loss:  0.06058940291404724
Epoch:  42  	Training Loss: 0.06468909978866577
Test Loss:  0.06688832491636276
Valid Loss:  0.060589175671339035
Epoch:  43  	Training Loss: 0.06468887627124786
Test Loss:  0.06688811630010605
Valid Loss:  0.06058894097805023
Epoch:  44  	Training Loss: 0.06468865275382996
Test Loss:  0.06688792258501053
Valid Loss:  0.06058872491121292
Epoch:  45  	Training Loss: 0.06468843668699265
Test Loss:  0.06688781082630157
Valid Loss:  0.060588520020246506
Epoch:  46  	Training Loss: 0.06468822807073593
Test Loss:  0.06688772886991501
Valid Loss:  0.06058831512928009
Epoch:  47  	Training Loss: 0.06468802690505981
Test Loss:  0.06688766181468964
Valid Loss:  0.060588110238313675
Epoch:  48  	Training Loss: 0.0646878033876419
Test Loss:  0.06688754260540009
Valid Loss:  0.06058790162205696
Epoch:  49  	Training Loss: 0.06468760222196579
Test Loss:  0.06688746809959412
Valid Loss:  0.060587696731090546
Epoch:  50  	Training Loss: 0.06468740105628967
Test Loss:  0.06688737869262695
Valid Loss:  0.06058749556541443
Epoch:  51  	Training Loss: 0.06468719244003296
Test Loss:  0.06688729673624039
Valid Loss:  0.060587286949157715
Epoch:  52  	Training Loss: 0.06468697637319565
Test Loss:  0.06688722968101501
Valid Loss:  0.060587093234062195
Epoch:  53  	Training Loss: 0.06468679010868073
Test Loss:  0.06688719242811203
Valid Loss:  0.06058690696954727
Epoch:  54  	Training Loss: 0.0646865963935852
Test Loss:  0.06688714772462845
Valid Loss:  0.06058672070503235
Epoch:  55  	Training Loss: 0.06468640267848969
Test Loss:  0.06688705086708069
Valid Loss:  0.06058653071522713
Epoch:  56  	Training Loss: 0.06468620896339417
Test Loss:  0.06688704341650009
Valid Loss:  0.060586344450712204
Epoch:  57  	Training Loss: 0.06468602269887924
Test Loss:  0.06688696891069412
Valid Loss:  0.060586147010326385
Epoch:  58  	Training Loss: 0.06468582898378372
Test Loss:  0.06688689440488815
Valid Loss:  0.060585953295230865
Epoch:  59  	Training Loss: 0.0646856352686882
Test Loss:  0.06688683480024338
Valid Loss:  0.06058576703071594
Epoch:  60  	Training Loss: 0.06468544155359268
Test Loss:  0.06688682734966278
Valid Loss:  0.06058558076620102
Epoch:  61  	Training Loss: 0.06468525528907776
Test Loss:  0.06688673794269562
Valid Loss:  0.0605853870511055
Epoch:  62  	Training Loss: 0.06468506157398224
Test Loss:  0.06688665598630905
Valid Loss:  0.06058517470955849
Epoch:  63  	Training Loss: 0.06468485295772552
Test Loss:  0.06688659638166428
Valid Loss:  0.06058497354388237
Epoch:  64  	Training Loss: 0.06468464434146881
Test Loss:  0.06688655912876129
Valid Loss:  0.060584768652915955
Epoch:  65  	Training Loss: 0.0646844357252121
Test Loss:  0.06688643246889114
Valid Loss:  0.06058456003665924
Epoch:  66  	Training Loss: 0.06468422710895538
Test Loss:  0.06688636541366577
Valid Loss:  0.06058435142040253
Epoch:  67  	Training Loss: 0.06468401104211807
Test Loss:  0.0668862983584404
Valid Loss:  0.06058414280414581
Epoch:  68  	Training Loss: 0.06468380242586136
Test Loss:  0.06688622385263443
Valid Loss:  0.0605839341878891
Epoch:  69  	Training Loss: 0.06468358635902405
Test Loss:  0.06688614189624786
Valid Loss:  0.060583725571632385
Epoch:  70  	Training Loss: 0.06468337774276733
Test Loss:  0.06688608229160309
Valid Loss:  0.06058352068066597
Epoch:  71  	Training Loss: 0.06468316912651062
Test Loss:  0.06688600778579712
Valid Loss:  0.060583312064409256
Epoch:  72  	Training Loss: 0.0646829605102539
Test Loss:  0.06688591837882996
Valid Loss:  0.06058311089873314
Epoch:  73  	Training Loss: 0.06468275189399719
Test Loss:   15%|█▍        | 73/500 [00:54<05:59,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:07<08:00,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:43,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:46,  1.17s/it] 21%|██        | 103/500 [01:14<05:33,  1.19it/s] 21%|██        | 105/500 [01:14<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:14<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:21<07:32,  1.16s/it] 23%|██▎       | 113/500 [01:21<05:23,  1.20it/s] 23%|██▎       | 115/500 [01:21<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:21<02:49,  2.26it/s] 24%|██▍       | 119/500 [01:21<02:05,  3.02it/s] 24%|██▍       | 121/500 [01:27<07:21,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:15,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:34<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:34<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:43,  2.23it/s] 28%|██▊       | 139/500 [01:35<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:41<07:03,  1.18s/it] 29%|██▊       | 143/500 [01:41<05:02,  1.18it/s]0.06688585877418518
Valid Loss:  0.060582906007766724
Epoch:  74  	Training Loss: 0.06468255072832108
Test Loss:  0.06688578426837921
Valid Loss:  0.060582712292671204
Epoch:  75  	Training Loss: 0.06468234956264496
Test Loss:  0.06688574701547623
Valid Loss:  0.06058250367641449
Epoch:  76  	Training Loss: 0.06468214094638824
Test Loss:  0.06688565015792847
Valid Loss:  0.06058230251073837
Epoch:  77  	Training Loss: 0.06468193978071213
Test Loss:  0.0668855831027031
Valid Loss:  0.060582101345062256
Epoch:  78  	Training Loss: 0.06468173861503601
Test Loss:  0.06688553094863892
Valid Loss:  0.06058190390467644
Epoch:  79  	Training Loss: 0.0646815299987793
Test Loss:  0.06688547134399414
Valid Loss:  0.06058170646429062
Epoch:  80  	Training Loss: 0.06468132138252258
Test Loss:  0.06688535958528519
Valid Loss:  0.060581501573324203
Epoch:  81  	Training Loss: 0.06468112766742706
Test Loss:  0.06688529998064041
Valid Loss:  0.060581304132938385
Epoch:  82  	Training Loss: 0.06468091905117035
Test Loss:  0.06688524782657623
Valid Loss:  0.06058110296726227
Epoch:  83  	Training Loss: 0.06468071043491364
Test Loss:  0.06688518822193146
Valid Loss:  0.06058089807629585
Epoch:  84  	Training Loss: 0.06468051671981812
Test Loss:  0.0668850690126419
Valid Loss:  0.06058068573474884
Epoch:  85  	Training Loss: 0.0646803006529808
Test Loss:  0.06688502430915833
Valid Loss:  0.06058048456907272
Epoch:  86  	Training Loss: 0.06468009948730469
Test Loss:  0.06688496470451355
Valid Loss:  0.0605802908539772
Epoch:  87  	Training Loss: 0.06467989087104797
Test Loss:  0.06688490509986877
Valid Loss:  0.06058008596301079
Epoch:  88  	Training Loss: 0.06467969715595245
Test Loss:  0.06688480079174042
Valid Loss:  0.06057988107204437
Epoch:  89  	Training Loss: 0.06467948853969574
Test Loss:  0.06688474863767624
Valid Loss:  0.060579679906368256
Epoch:  90  	Training Loss: 0.06467927992343903
Test Loss:  0.06688465923070908
Valid Loss:  0.06057947129011154
Epoch:  91  	Training Loss: 0.06467907875776291
Test Loss:  0.06688462197780609
Valid Loss:  0.06057927384972572
Epoch:  92  	Training Loss: 0.0646788701415062
Test Loss:  0.06688454747200012
Valid Loss:  0.06057906150817871
Epoch:  93  	Training Loss: 0.06467865407466888
Test Loss:  0.06688442081212997
Valid Loss:  0.0605788379907608
Epoch:  94  	Training Loss: 0.06467843055725098
Test Loss:  0.0668843537569046
Valid Loss:  0.06057862192392349
Epoch:  95  	Training Loss: 0.06467821449041367
Test Loss:  0.06688426434993744
Valid Loss:  0.06057840958237648
Epoch:  96  	Training Loss: 0.06467799842357635
Test Loss:  0.06688417494297028
Valid Loss:  0.06057818979024887
Epoch:  97  	Training Loss: 0.06467777490615845
Test Loss:  0.0668841078877449
Valid Loss:  0.06057798117399216
Epoch:  98  	Training Loss: 0.06467755138874054
Test Loss:  0.06688402593135834
Valid Loss:  0.060577765107154846
Epoch:  99  	Training Loss: 0.06467733532190323
Test Loss:  0.06688393652439117
Valid Loss:  0.06057754531502724
Epoch:  100  	Training Loss: 0.06467711925506592
Test Loss:  0.06688383221626282
Valid Loss:  0.060577329248189926
Epoch:  101  	Training Loss: 0.06467689573764801
Test Loss:  0.06688375771045685
Valid Loss:  0.060577116906642914
Epoch:  102  	Training Loss: 0.0646766796708107
Test Loss:  0.06688369810581207
Valid Loss:  0.0605769157409668
Epoch:  103  	Training Loss: 0.06467647850513458
Test Loss:  0.0668836385011673
Valid Loss:  0.06057671830058098
Epoch:  104  	Training Loss: 0.06467627733945847
Test Loss:  0.06688356399536133
Valid Loss:  0.06057651340961456
Epoch:  105  	Training Loss: 0.06467607617378235
Test Loss:  0.06688348948955536
Valid Loss:  0.06057631969451904
Epoch:  106  	Training Loss: 0.06467587500810623
Test Loss:  0.0668834000825882
Valid Loss:  0.060576118528842926
Epoch:  107  	Training Loss: 0.06467567384243011
Test Loss:  0.06688336282968521
Valid Loss:  0.06057591736316681
Epoch:  108  	Training Loss: 0.064675472676754
Test Loss:  0.06688328832387924
Valid Loss:  0.06057571992278099
Epoch:  109  	Training Loss: 0.06467527151107788
Test Loss:  0.06688323616981506
Valid Loss:  0.06057552993297577
Epoch:  110  	Training Loss: 0.06467507034540176
Test Loss:  0.06688316911458969
Valid Loss:  0.06057532876729965
Epoch:  111  	Training Loss: 0.06467486917972565
Test Loss:  0.06688307970762253
Valid Loss:  0.06057512015104294
Epoch:  112  	Training Loss: 0.06467466056346893
Test Loss:  0.06688301265239716
Valid Loss:  0.06057492643594742
Epoch:  113  	Training Loss: 0.06467446684837341
Test Loss:  0.06688295304775238
Valid Loss:  0.0605747289955616
Epoch:  114  	Training Loss: 0.0646742731332779
Test Loss:  0.0668829008936882
Valid Loss:  0.06057453900575638
Epoch:  115  	Training Loss: 0.06467407196760178
Test Loss:  0.06688284873962402
Valid Loss:  0.06057434156537056
Epoch:  116  	Training Loss: 0.06467387080192566
Test Loss:  0.06688280403614044
Valid Loss:  0.06057415157556534
Epoch:  117  	Training Loss: 0.06467367708683014
Test Loss:  0.06688274443149567
Valid Loss:  0.06057395786046982
Epoch:  118  	Training Loss: 0.06467348337173462
Test Loss:  0.06688269227743149
Valid Loss:  0.0605737641453743
Epoch:  119  	Training Loss: 0.0646732896566391
Test Loss:  0.06688256561756134
Valid Loss:  0.06057355925440788
Epoch:  120  	Training Loss: 0.06467309594154358
Test Loss:  0.06688253581523895
Valid Loss:  0.06057336926460266
Epoch:  121  	Training Loss: 0.06467288732528687
Test Loss:  0.06688244640827179
Valid Loss:  0.060573168098926544
Epoch:  122  	Training Loss: 0.06467269361019135
Test Loss:  0.0668824166059494
Valid Loss:  0.06057298183441162
Epoch:  123  	Training Loss: 0.06467249244451523
Test Loss:  0.06688234210014343
Valid Loss:  0.060572780668735504
Epoch:  124  	Training Loss: 0.06467229872941971
Test Loss:  0.06688231229782104
Valid Loss:  0.06057259067893028
Epoch:  125  	Training Loss: 0.06467209756374359
Test Loss:  0.06688222289085388
Valid Loss:  0.060572393238544464
Epoch:  126  	Training Loss: 0.06467190384864807
Test Loss:  0.0668821632862091
Valid Loss:  0.060572199523448944
Epoch:  127  	Training Loss: 0.06467171013355255
Test Loss:  0.06688211858272552
Valid Loss:  0.060572005808353424
Epoch:  128  	Training Loss: 0.06467150896787643
Test Loss:  0.06688204407691956
Valid Loss:  0.060571812093257904
Epoch:  129  	Training Loss: 0.06467131525278091
Test Loss:  0.06688199937343597
Valid Loss:  0.060571618378162384
Epoch:  130  	Training Loss: 0.0646711140871048
Test Loss:  0.06688189506530762
Valid Loss:  0.06057141348719597
Epoch:  131  	Training Loss: 0.06467092037200928
Test Loss:  0.06688184291124344
Valid Loss:  0.06057122349739075
Epoch:  132  	Training Loss: 0.06467071920633316
Test Loss:  0.06688176095485687
Valid Loss:  0.06057101488113403
Epoch:  133  	Training Loss: 0.06467051804065704
Test Loss:  0.0668817013502121
Valid Loss:  0.060570813715457916
Epoch:  134  	Training Loss: 0.06467030942440033
Test Loss:  0.06688163429498672
Valid Loss:  0.0605706125497818
Epoch:  135  	Training Loss: 0.06467010080814362
Test Loss:  0.06688155233860016
Valid Loss:  0.060570407658815384
Epoch:  136  	Training Loss: 0.0646698921918869
Test Loss:  0.06688149273395538
Valid Loss:  0.06057020276784897
Epoch:  137  	Training Loss: 0.06466968357563019
Test Loss:  0.06688140332698822
Valid Loss:  0.06057000160217285
Epoch:  138  	Training Loss: 0.06466948240995407
Test Loss:  0.06688135862350464
Valid Loss:  0.060569796711206436
Epoch:  139  	Training Loss: 0.06466926634311676
Test Loss:  0.06688126176595688
Valid Loss:  0.06056959554553032
Epoch:  140  	Training Loss: 0.06466906517744064
Test Loss:  0.0668812096118927
Valid Loss:  0.060569390654563904
Epoch:  141  	Training Loss: 0.06466885656118393
Test Loss:  0.06688112020492554
Valid Loss:  0.06056918203830719
Epoch:  142  	Training Loss: 0.06466865539550781
Test Loss:  0.06688106060028076
Valid Loss:  0.06056898087263107
Epoch:  143  	Training Loss: 0.0646684467792511
Test Loss:  0.0668809786438942
Valid Loss:  0.06056877598166466
Epoch:  144  	Training Loss: 0.06466823816299438
Test Loss:  0.06688092648983002
Valid Loss:  0.06056857109069824
Epoch:  145  	Training Loss: 0.06466802954673767
Test Loss:   29%|██▉       | 145/500 [01:41<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:42<01:58,  2.97it/s] 30%|███       | 151/500 [01:48<06:56,  1.19s/it] 31%|███       | 153/500 [01:48<04:57,  1.17it/s] 31%|███       | 155/500 [01:48<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:48<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:49<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:55<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.18it/s] 33%|███▎      | 165/500 [01:55<03:24,  1.63it/s] 33%|███▎      | 167/500 [01:55<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:55<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:02<06:24,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:17,  1.65it/s] 35%|███▌      | 177/500 [02:02<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:08<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:15<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:15<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:16<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.01it/s] 40%|████      | 201/500 [02:22<05:58,  1.20s/it] 41%|████      | 203/500 [02:22<04:14,  1.17it/s] 41%|████      | 205/500 [02:22<03:02,  1.61it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.97it/s] 42%|████▏     | 211/500 [02:29<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:29<02:54,  1.63it/s]0.06688083708286285
Valid Loss:  0.060568369925022125
Epoch:  146  	Training Loss: 0.06466782838106155
Test Loss:  0.06688078492879868
Valid Loss:  0.06056817248463631
Epoch:  147  	Training Loss: 0.06466762721538544
Test Loss:  0.06688068807125092
Valid Loss:  0.06056796759366989
Epoch:  148  	Training Loss: 0.06466741859912872
Test Loss:  0.06688064336776733
Valid Loss:  0.060567766427993774
Epoch:  149  	Training Loss: 0.06466720998287201
Test Loss:  0.06688055396080017
Valid Loss:  0.06056756153702736
Epoch:  150  	Training Loss: 0.0646670013666153
Test Loss:  0.0668804943561554
Valid Loss:  0.060567356646060944
Epoch:  151  	Training Loss: 0.06466680765151978
Test Loss:  0.06688041985034943
Valid Loss:  0.06056715175509453
Epoch:  152  	Training Loss: 0.06466659903526306
Test Loss:  0.06688036024570465
Valid Loss:  0.06056695431470871
Epoch:  153  	Training Loss: 0.06466639786958694
Test Loss:  0.06688028573989868
Valid Loss:  0.06056676059961319
Epoch:  154  	Training Loss: 0.06466619670391083
Test Loss:  0.0668802261352539
Valid Loss:  0.06056655943393707
Epoch:  155  	Training Loss: 0.06466599553823471
Test Loss:  0.06688015162944794
Valid Loss:  0.060566361993551254
Epoch:  156  	Training Loss: 0.0646657943725586
Test Loss:  0.06688009202480316
Valid Loss:  0.060566164553165436
Epoch:  157  	Training Loss: 0.06466560065746307
Test Loss:  0.06688003242015839
Valid Loss:  0.060565970838069916
Epoch:  158  	Training Loss: 0.06466539949178696
Test Loss:  0.06687995791435242
Valid Loss:  0.0605657696723938
Epoch:  159  	Training Loss: 0.06466519087553024
Test Loss:  0.06687989830970764
Valid Loss:  0.06056557223200798
Epoch:  160  	Training Loss: 0.06466498970985413
Test Loss:  0.06687982380390167
Valid Loss:  0.06056537479162216
Epoch:  161  	Training Loss: 0.0646647959947586
Test Loss:  0.0668797641992569
Valid Loss:  0.06056518107652664
Epoch:  162  	Training Loss: 0.06466459482908249
Test Loss:  0.06687971204519272
Valid Loss:  0.060565002262592316
Epoch:  163  	Training Loss: 0.06466441601514816
Test Loss:  0.06687966734170914
Valid Loss:  0.060564830899238586
Epoch:  164  	Training Loss: 0.06466424465179443
Test Loss:  0.06687963008880615
Valid Loss:  0.06056465208530426
Epoch:  165  	Training Loss: 0.06466406583786011
Test Loss:  0.06687958538532257
Valid Loss:  0.06056447699666023
Epoch:  166  	Training Loss: 0.06466388702392578
Test Loss:  0.06687956303358078
Valid Loss:  0.0605643056333065
Epoch:  167  	Training Loss: 0.06466371566057205
Test Loss:  0.0668795108795166
Valid Loss:  0.06056412309408188
Epoch:  168  	Training Loss: 0.06466354429721832
Test Loss:  0.06687948107719421
Valid Loss:  0.06056395173072815
Epoch:  169  	Training Loss: 0.064663365483284
Test Loss:  0.06687942147254944
Valid Loss:  0.060563765466213226
Epoch:  170  	Training Loss: 0.06466317921876907
Test Loss:  0.06687937676906586
Valid Loss:  0.0605635941028595
Epoch:  171  	Training Loss: 0.06466300785541534
Test Loss:  0.06687933206558228
Valid Loss:  0.06056341528892517
Epoch:  172  	Training Loss: 0.06466282904148102
Test Loss:  0.0668792650103569
Valid Loss:  0.06056322157382965
Epoch:  173  	Training Loss: 0.0646626204252243
Test Loss:  0.06687921285629272
Valid Loss:  0.06056302785873413
Epoch:  174  	Training Loss: 0.06466242671012878
Test Loss:  0.06687913089990616
Valid Loss:  0.060562826693058014
Epoch:  175  	Training Loss: 0.06466223299503326
Test Loss:  0.06687907129526138
Valid Loss:  0.060562632977962494
Epoch:  176  	Training Loss: 0.06466203182935715
Test Loss:  0.06687897443771362
Valid Loss:  0.06056243181228638
Epoch:  177  	Training Loss: 0.06466183066368103
Test Loss:  0.06687893718481064
Valid Loss:  0.06056223809719086
Epoch:  178  	Training Loss: 0.06466162949800491
Test Loss:  0.06687884032726288
Valid Loss:  0.06056203320622444
Epoch:  179  	Training Loss: 0.0646614283323288
Test Loss:  0.0668787807226181
Valid Loss:  0.06056184321641922
Epoch:  180  	Training Loss: 0.06466123461723328
Test Loss:  0.06687872111797333
Valid Loss:  0.0605616420507431
Epoch:  181  	Training Loss: 0.06466103345155716
Test Loss:  0.06687863171100616
Valid Loss:  0.060561444610357285
Epoch:  182  	Training Loss: 0.06466083228588104
Test Loss:  0.0668785572052002
Valid Loss:  0.06056123971939087
Epoch:  183  	Training Loss: 0.06466062366962433
Test Loss:  0.06687848269939423
Valid Loss:  0.060561034828424454
Epoch:  184  	Training Loss: 0.06466041505336761
Test Loss:  0.06687840074300766
Valid Loss:  0.06056082993745804
Epoch:  185  	Training Loss: 0.0646602064371109
Test Loss:  0.06687832623720169
Valid Loss:  0.06056061387062073
Epoch:  186  	Training Loss: 0.06465999782085419
Test Loss:  0.06687823683023453
Valid Loss:  0.06056040897965431
Epoch:  187  	Training Loss: 0.06465978175401688
Test Loss:  0.06687816977500916
Valid Loss:  0.0605602040886879
Epoch:  188  	Training Loss: 0.06465956568717957
Test Loss:  0.06687808036804199
Valid Loss:  0.06055999919772148
Epoch:  189  	Training Loss: 0.06465936452150345
Test Loss:  0.06687799096107483
Valid Loss:  0.06055978313088417
Epoch:  190  	Training Loss: 0.06465914845466614
Test Loss:  0.06687791645526886
Valid Loss:  0.06055957078933716
Epoch:  191  	Training Loss: 0.06465893983840942
Test Loss:  0.0668778270483017
Valid Loss:  0.06055937707424164
Epoch:  192  	Training Loss: 0.0646587386727333
Test Loss:  0.06687776744365692
Valid Loss:  0.06055917218327522
Epoch:  193  	Training Loss: 0.06465853750705719
Test Loss:  0.06687769293785095
Valid Loss:  0.0605589784681797
Epoch:  194  	Training Loss: 0.06465832889080048
Test Loss:  0.06687760353088379
Valid Loss:  0.06055876985192299
Epoch:  195  	Training Loss: 0.06465812772512436
Test Loss:  0.06687755137681961
Valid Loss:  0.06055857986211777
Epoch:  196  	Training Loss: 0.06465793401002884
Test Loss:  0.06687748432159424
Valid Loss:  0.06055837869644165
Epoch:  197  	Training Loss: 0.06465773284435272
Test Loss:  0.06687739491462708
Valid Loss:  0.06055817753076553
Epoch:  198  	Training Loss: 0.06465752422809601
Test Loss:  0.0668773427605629
Valid Loss:  0.06055798381567001
Epoch:  199  	Training Loss: 0.06465733051300049
Test Loss:  0.06687726080417633
Valid Loss:  0.0605577789247036
Epoch:  200  	Training Loss: 0.06465712934732437
Test Loss:  0.06687718629837036
Valid Loss:  0.06055757775902748
Epoch:  201  	Training Loss: 0.06465692818164825
Test Loss:  0.06687711924314499
Valid Loss:  0.06055738031864166
Epoch:  202  	Training Loss: 0.06465671956539154
Test Loss:  0.06687704473733902
Valid Loss:  0.060557182878255844
Epoch:  203  	Training Loss: 0.06465652585029602
Test Loss:  0.06687697023153305
Valid Loss:  0.06055697798728943
Epoch:  204  	Training Loss: 0.0646563172340393
Test Loss:  0.06687688827514648
Valid Loss:  0.06055678054690361
Epoch:  205  	Training Loss: 0.06465611606836319
Test Loss:  0.06687682867050171
Valid Loss:  0.060556575655937195
Epoch:  206  	Training Loss: 0.06465590745210648
Test Loss:  0.06687673926353455
Valid Loss:  0.06055637449026108
Epoch:  207  	Training Loss: 0.06465570628643036
Test Loss:  0.06687666475772858
Valid Loss:  0.06055617332458496
Epoch:  208  	Training Loss: 0.06465550512075424
Test Loss:  0.0668765977025032
Valid Loss:  0.06055597588419914
Epoch:  209  	Training Loss: 0.06465530395507812
Test Loss:  0.06687650829553604
Valid Loss:  0.06055577099323273
Epoch:  210  	Training Loss: 0.06465510278940201
Test Loss:  0.06687644869089127
Valid Loss:  0.06055557727813721
Epoch:  211  	Training Loss: 0.06465490162372589
Test Loss:  0.0668763592839241
Valid Loss:  0.06055537983775139
Epoch:  212  	Training Loss: 0.06465470790863037
Test Loss:  0.06687627732753754
Valid Loss:  0.060555171221494675
Epoch:  213  	Training Loss: 0.06465449929237366
Test Loss:  0.06687621027231216
Valid Loss:  0.06055497005581856
Epoch:  214  	Training Loss: 0.06465429067611694
Test Loss:  0.06687614321708679
Valid Loss:  0.06055476516485214
Epoch:  215  	Training Loss: 0.06465408205986023
Test Loss:  0.06687603890895844
Valid Loss:  0.06055456027388573
Epoch:  216  	Training Loss: 0.06465388834476471
Test Loss:  0.06687597930431366
Valid Loss:  0.06055436283349991
Epoch:  217  	Training Loss: 0.06465368717908859
 43%|████▎     | 217/500 [02:29<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:30<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:36<05:30,  1.19s/it] 45%|████▍     | 223/500 [02:36<03:55,  1.17it/s] 45%|████▌     | 225/500 [02:36<02:49,  1.63it/s] 45%|████▌     | 227/500 [02:36<02:03,  2.22it/s] 46%|████▌     | 229/500 [02:36<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:43<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:43<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.65it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:50<05:04,  1.17s/it] 49%|████▊     | 243/500 [02:50<03:36,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:50<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.02it/s] 50%|█████     | 251/500 [02:56<04:52,  1.18s/it] 51%|█████     | 253/500 [02:56<03:28,  1.19it/s] 51%|█████     | 255/500 [02:57<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:03<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:03<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:03<02:22,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:10<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:10<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:10<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:10<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:11<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:17<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:17<03:04,  1.17it/s] 57%|█████▋    | 285/500 [03:17<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:17<01:35,  2.22it/s]Test Loss:  0.06687591224908829
Valid Loss:  0.06055416166782379
Epoch:  218  	Training Loss: 0.06465347856283188
Test Loss:  0.06687584519386292
Valid Loss:  0.060553960502147675
Epoch:  219  	Training Loss: 0.06465326994657516
Test Loss:  0.06687574088573456
Valid Loss:  0.06055375561118126
Epoch:  220  	Training Loss: 0.06465306878089905
Test Loss:  0.06687568128108978
Valid Loss:  0.06055355817079544
Epoch:  221  	Training Loss: 0.06465286761522293
Test Loss:  0.06687560677528381
Valid Loss:  0.06055334955453873
Epoch:  222  	Training Loss: 0.06465265899896622
Test Loss:  0.06687552481889725
Valid Loss:  0.06055315211415291
Epoch:  223  	Training Loss: 0.0646524578332901
Test Loss:  0.06687544286251068
Valid Loss:  0.06055295467376709
Epoch:  224  	Training Loss: 0.06465226411819458
Test Loss:  0.06687537580728531
Valid Loss:  0.060552749782800674
Epoch:  225  	Training Loss: 0.06465205550193787
Test Loss:  0.06687530130147934
Valid Loss:  0.060552552342414856
Epoch:  226  	Training Loss: 0.06465186178684235
Test Loss:  0.06687521934509277
Valid Loss:  0.06055235117673874
Epoch:  227  	Training Loss: 0.06465165317058563
Test Loss:  0.06687513738870621
Valid Loss:  0.06055215373635292
Epoch:  228  	Training Loss: 0.06465145200490952
Test Loss:  0.06687507033348083
Valid Loss:  0.060551948845386505
Epoch:  229  	Training Loss: 0.0646512508392334
Test Loss:  0.06687500327825546
Valid Loss:  0.06055175140500069
Epoch:  230  	Training Loss: 0.06465104967355728
Test Loss:  0.0668749064207077
Valid Loss:  0.06055154651403427
Epoch:  231  	Training Loss: 0.06465084850788116
Test Loss:  0.06687482446432114
Valid Loss:  0.06055135279893875
Epoch:  232  	Training Loss: 0.06465064734220505
Test Loss:  0.06687476485967636
Valid Loss:  0.06055115535855293
Epoch:  233  	Training Loss: 0.06465045362710953
Test Loss:  0.0668746829032898
Valid Loss:  0.060550957918167114
Epoch:  234  	Training Loss: 0.06465025246143341
Test Loss:  0.06687460839748383
Valid Loss:  0.060550760477781296
Epoch:  235  	Training Loss: 0.0646500438451767
Test Loss:  0.06687454134225845
Valid Loss:  0.06055056303739548
Epoch:  236  	Training Loss: 0.06464985013008118
Test Loss:  0.06687447428703308
Valid Loss:  0.06055036932229996
Epoch:  237  	Training Loss: 0.06464965641498566
Test Loss:  0.0668744221329689
Valid Loss:  0.06055017560720444
Epoch:  238  	Training Loss: 0.06464946269989014
Test Loss:  0.06687432527542114
Valid Loss:  0.06054998189210892
Epoch:  239  	Training Loss: 0.06464926898479462
Test Loss:  0.06687425822019577
Valid Loss:  0.0605497881770134
Epoch:  240  	Training Loss: 0.0646490678191185
Test Loss:  0.0668741911649704
Valid Loss:  0.06054959446191788
Epoch:  241  	Training Loss: 0.06464887410402298
Test Loss:  0.06687411665916443
Valid Loss:  0.06054940074682236
Epoch:  242  	Training Loss: 0.06464868038892746
Test Loss:  0.06687403470277786
Valid Loss:  0.06054919958114624
Epoch:  243  	Training Loss: 0.06464847922325134
Test Loss:  0.06687397509813309
Valid Loss:  0.06054900214076042
Epoch:  244  	Training Loss: 0.06464828550815582
Test Loss:  0.06687390804290771
Valid Loss:  0.0605488084256649
Epoch:  245  	Training Loss: 0.0646480843424797
Test Loss:  0.06687382608652115
Valid Loss:  0.06054861098527908
Epoch:  246  	Training Loss: 0.06464789062738419
Test Loss:  0.06687373667955399
Valid Loss:  0.060548409819602966
Epoch:  247  	Training Loss: 0.06464768201112747
Test Loss:  0.06687367707490921
Valid Loss:  0.06054820865392685
Epoch:  248  	Training Loss: 0.06464748829603195
Test Loss:  0.06687359511852264
Valid Loss:  0.06054801493883133
Epoch:  249  	Training Loss: 0.06464729458093643
Test Loss:  0.06687353551387787
Valid Loss:  0.06054782122373581
Epoch:  250  	Training Loss: 0.06464709341526031
Test Loss:  0.0668734684586525
Valid Loss:  0.06054762750864029
Epoch:  251  	Training Loss: 0.0646468997001648
Test Loss:  0.06687337160110474
Valid Loss:  0.06054742634296417
Epoch:  252  	Training Loss: 0.06464669853448868
Test Loss:  0.06687332689762115
Valid Loss:  0.060547247529029846
Epoch:  253  	Training Loss: 0.06464651226997375
Test Loss:  0.06687327474355698
Valid Loss:  0.06054706126451492
Epoch:  254  	Training Loss: 0.06464632600545883
Test Loss:  0.0668732076883316
Valid Loss:  0.060546875
Epoch:  255  	Training Loss: 0.06464613974094391
Test Loss:  0.06687316298484802
Valid Loss:  0.06054669991135597
Epoch:  256  	Training Loss: 0.06464596092700958
Test Loss:  0.06687310338020325
Valid Loss:  0.06054650992155075
Epoch:  257  	Training Loss: 0.06464578211307526
Test Loss:  0.06687303632497787
Valid Loss:  0.06054632365703583
Epoch:  258  	Training Loss: 0.06464558839797974
Test Loss:  0.0668729841709137
Valid Loss:  0.060546137392520905
Epoch:  259  	Training Loss: 0.06464540958404541
Test Loss:  0.06687293201684952
Valid Loss:  0.06054595857858658
Epoch:  260  	Training Loss: 0.06464523077011108
Test Loss:  0.06687288731336594
Valid Loss:  0.06054578721523285
Epoch:  261  	Training Loss: 0.06464504450559616
Test Loss:  0.06687282025814056
Valid Loss:  0.06054559722542763
Epoch:  262  	Training Loss: 0.06464485824108124
Test Loss:  0.0668727308511734
Valid Loss:  0.060545388609170914
Epoch:  263  	Training Loss: 0.06464465707540512
Test Loss:  0.06687265634536743
Valid Loss:  0.0605451799929142
Epoch:  264  	Training Loss: 0.06464444845914841
Test Loss:  0.06687256693840027
Valid Loss:  0.060544975101947784
Epoch:  265  	Training Loss: 0.0646442398428917
Test Loss:  0.0668724998831749
Valid Loss:  0.06054477021098137
Epoch:  266  	Training Loss: 0.06464403122663498
Test Loss:  0.06687241792678833
Valid Loss:  0.06054457277059555
Epoch:  267  	Training Loss: 0.06464382261037827
Test Loss:  0.06687232851982117
Valid Loss:  0.06054436415433884
Epoch:  268  	Training Loss: 0.06464362144470215
Test Loss:  0.06687223166227341
Valid Loss:  0.060544151812791824
Epoch:  269  	Training Loss: 0.06464341282844543
Test Loss:  0.06687216460704803
Valid Loss:  0.06054394692182541
Epoch:  270  	Training Loss: 0.06464320421218872
Test Loss:  0.06687207520008087
Valid Loss:  0.060543742030858994
Epoch:  271  	Training Loss: 0.064642995595932
Test Loss:  0.0668719932436943
Valid Loss:  0.06054353713989258
Epoch:  272  	Training Loss: 0.06464278697967529
Test Loss:  0.06687195599079132
Valid Loss:  0.06054334342479706
Epoch:  273  	Training Loss: 0.06464259326457977
Test Loss:  0.06687187403440475
Valid Loss:  0.06054314970970154
Epoch:  274  	Training Loss: 0.06464239954948425
Test Loss:  0.06687178462743759
Valid Loss:  0.06054295226931572
Epoch:  275  	Training Loss: 0.06464220583438873
Test Loss:  0.06687171012163162
Valid Loss:  0.0605427622795105
Epoch:  276  	Training Loss: 0.06464199721813202
Test Loss:  0.06687166541814804
Valid Loss:  0.060542572289705276
Epoch:  277  	Training Loss: 0.0646418109536171
Test Loss:  0.06687159836292267
Valid Loss:  0.060542382299900055
Epoch:  278  	Training Loss: 0.06464161723852158
Test Loss:  0.0668715238571167
Valid Loss:  0.060542184859514236
Epoch:  279  	Training Loss: 0.06464142352342606
Test Loss:  0.06687148660421371
Valid Loss:  0.060541994869709015
Epoch:  280  	Training Loss: 0.06464122980833054
Test Loss:  0.06687141954898834
Valid Loss:  0.060541801154613495
Epoch:  281  	Training Loss: 0.06464102864265442
Test Loss:  0.06687133759260178
Valid Loss:  0.060541607439517975
Epoch:  282  	Training Loss: 0.0646408423781395
Test Loss:  0.0668712630867958
Valid Loss:  0.060541409999132156
Epoch:  283  	Training Loss: 0.06464064121246338
Test Loss:  0.06687118858098984
Valid Loss:  0.06054120510816574
Epoch:  284  	Training Loss: 0.06464042514562607
Test Loss:  0.06687109172344208
Valid Loss:  0.06054099649190903
Epoch:  285  	Training Loss: 0.06464022397994995
Test Loss:  0.06687101721763611
Valid Loss:  0.06054079160094261
Epoch:  286  	Training Loss: 0.06464001536369324
Test Loss:  0.06687095761299133
Valid Loss:  0.060540586709976196
Epoch:  287  	Training Loss: 0.06463980674743652
Test Loss:  0.06687086820602417
Valid Loss:  0.06054037809371948
Epoch:  288  	Training Loss: 0.06463959813117981
Test Loss:  0.0668707937002182
Valid Loss:  0.06054018437862396
Epoch:  289  	Training Loss: 0.0646393895149231
 58%|█████▊    | 289/500 [03:17<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:24<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.03it/s] 60%|██████    | 301/500 [03:30<03:49,  1.15s/it] 61%|██████    | 303/500 [03:30<02:43,  1.21it/s] 61%|██████    | 305/500 [03:31<01:57,  1.67it/s] 61%|██████▏   | 307/500 [03:31<01:24,  2.27it/s] 62%|██████▏   | 309/500 [03:31<01:02,  3.06it/s] 62%|██████▏   | 311/500 [03:37<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:37<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:37<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.26it/s] 64%|██████▍   | 319/500 [03:38<00:59,  3.03it/s] 64%|██████▍   | 321/500 [03:44<03:28,  1.16s/it] 65%|██████▍   | 323/500 [03:44<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:44<01:45,  1.66it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.25it/s] 66%|██████▌   | 329/500 [03:44<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:51<03:18,  1.18s/it] 67%|██████▋   | 333/500 [03:51<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:51<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:51<00:53,  3.01it/s] 68%|██████▊   | 341/500 [03:58<03:09,  1.19s/it] 69%|██████▊   | 343/500 [03:58<02:14,  1.17it/s] 69%|██████▉   | 345/500 [03:58<01:35,  1.62it/s] 69%|██████▉   | 347/500 [03:58<01:09,  2.19it/s] 70%|██████▉   | 349/500 [03:58<00:51,  2.93it/s] 70%|███████   | 351/500 [04:05<03:00,  1.21s/it] 71%|███████   | 353/500 [04:05<02:08,  1.15it/s] 71%|███████   | 355/500 [04:05<01:31,  1.59it/s] 71%|███████▏  | 357/500 [04:05<01:05,  2.17it/s] 72%|███████▏  | 359/500 [04:05<00:48,  2.93it/s]Test Loss:  0.06687071919441223
Valid Loss:  0.06053997948765755
Epoch:  290  	Training Loss: 0.06463918089866638
Test Loss:  0.06687064468860626
Valid Loss:  0.06053977087140083
Epoch:  291  	Training Loss: 0.06463897228240967
Test Loss:  0.0668705552816391
Valid Loss:  0.06053956598043442
Epoch:  292  	Training Loss: 0.06463877111673355
Test Loss:  0.06687050312757492
Valid Loss:  0.06053939089179039
Epoch:  293  	Training Loss: 0.06463859230279922
Test Loss:  0.06687045097351074
Valid Loss:  0.060539208352565765
Epoch:  294  	Training Loss: 0.0646384060382843
Test Loss:  0.06687039881944656
Valid Loss:  0.06053902581334114
Epoch:  295  	Training Loss: 0.06463821977376938
Test Loss:  0.06687035411596298
Valid Loss:  0.06053885444998741
Epoch:  296  	Training Loss: 0.06463804841041565
Test Loss:  0.0668703019618988
Valid Loss:  0.06053866818547249
Epoch:  297  	Training Loss: 0.06463786959648132
Test Loss:  0.06687024235725403
Valid Loss:  0.060538485646247864
Epoch:  298  	Training Loss: 0.0646376758813858
Test Loss:  0.06687019765377045
Valid Loss:  0.060538314282894135
Epoch:  299  	Training Loss: 0.06463750451803207
Test Loss:  0.06687015295028687
Valid Loss:  0.06053813174366951
Epoch:  300  	Training Loss: 0.06463731825351715
Test Loss:  0.06687009334564209
Valid Loss:  0.060537949204444885
Epoch:  301  	Training Loss: 0.06463713943958282
Test Loss:  0.06687004864215851
Valid Loss:  0.06053777039051056
Epoch:  302  	Training Loss: 0.0646369606256485
Test Loss:  0.06686998903751373
Valid Loss:  0.06053757667541504
Epoch:  303  	Training Loss: 0.06463675945997238
Test Loss:  0.06686992943286896
Valid Loss:  0.06053738668560982
Epoch:  304  	Training Loss: 0.06463656574487686
Test Loss:  0.0668698325753212
Valid Loss:  0.0605371817946434
Epoch:  305  	Training Loss: 0.06463636457920074
Test Loss:  0.06686976552009583
Valid Loss:  0.06053699180483818
Epoch:  306  	Training Loss: 0.06463617086410522
Test Loss:  0.06686972081661224
Valid Loss:  0.06053680181503296
Epoch:  307  	Training Loss: 0.0646359771490097
Test Loss:  0.06686963140964508
Valid Loss:  0.06053660809993744
Epoch:  308  	Training Loss: 0.06463578343391418
Test Loss:  0.06686956435441971
Valid Loss:  0.06053641438484192
Epoch:  309  	Training Loss: 0.06463558971881866
Test Loss:  0.06686950474977493
Valid Loss:  0.060536228120326996
Epoch:  310  	Training Loss: 0.06463538855314255
Test Loss:  0.06686943024396896
Valid Loss:  0.06053603067994118
Epoch:  311  	Training Loss: 0.06463520228862762
Test Loss:  0.06686938554048538
Valid Loss:  0.060535844415426254
Epoch:  312  	Training Loss: 0.06463500112295151
Test Loss:  0.06686929613351822
Valid Loss:  0.06053563207387924
Epoch:  313  	Training Loss: 0.06463479995727539
Test Loss:  0.06686922162771225
Valid Loss:  0.06053543835878372
Epoch:  314  	Training Loss: 0.06463459879159927
Test Loss:  0.06686916202306747
Valid Loss:  0.0605352409183979
Epoch:  315  	Training Loss: 0.06463439762592316
Test Loss:  0.06686906516551971
Valid Loss:  0.060535039752721786
Epoch:  316  	Training Loss: 0.06463418900966644
Test Loss:  0.06686902046203613
Valid Loss:  0.060534846037626266
Epoch:  317  	Training Loss: 0.06463399529457092
Test Loss:  0.06686894595623016
Valid Loss:  0.06053464859724045
Epoch:  318  	Training Loss: 0.0646338015794754
Test Loss:  0.066868856549263
Valid Loss:  0.06053444370627403
Epoch:  319  	Training Loss: 0.06463359296321869
Test Loss:  0.06686880439519882
Valid Loss:  0.06053425371646881
Epoch:  320  	Training Loss: 0.06463339179754257
Test Loss:  0.06686872988939285
Valid Loss:  0.060534052550792694
Epoch:  321  	Training Loss: 0.06463319063186646
Test Loss:  0.06686864793300629
Valid Loss:  0.060533855110406876
Epoch:  322  	Training Loss: 0.06463299691677094
Test Loss:  0.06686857342720032
Valid Loss:  0.06053365021944046
Epoch:  323  	Training Loss: 0.06463278830051422
Test Loss:  0.06686851382255554
Valid Loss:  0.06053345650434494
Epoch:  324  	Training Loss: 0.0646325871348381
Test Loss:  0.06686842441558838
Valid Loss:  0.06053325533866882
Epoch:  325  	Training Loss: 0.06463238596916199
Test Loss:  0.06686834990978241
Valid Loss:  0.060533054172992706
Epoch:  326  	Training Loss: 0.06463217735290527
Test Loss:  0.06686829030513763
Valid Loss:  0.060532860457897186
Epoch:  327  	Training Loss: 0.06463198363780975
Test Loss:  0.06686820089817047
Valid Loss:  0.06053265929222107
Epoch:  328  	Training Loss: 0.06463178247213364
Test Loss:  0.0668681412935257
Valid Loss:  0.06053246185183525
Epoch:  329  	Training Loss: 0.06463158875703812
Test Loss:  0.06686806678771973
Valid Loss:  0.06053226813673973
Epoch:  330  	Training Loss: 0.0646313726902008
Test Loss:  0.06686799228191376
Valid Loss:  0.060532066971063614
Epoch:  331  	Training Loss: 0.06463117897510529
Test Loss:  0.06686791777610779
Valid Loss:  0.060531869530677795
Epoch:  332  	Training Loss: 0.06463098526000977
Test Loss:  0.0668678730726242
Valid Loss:  0.060531679540872574
Epoch:  333  	Training Loss: 0.06463078409433365
Test Loss:  0.06686779856681824
Valid Loss:  0.060531485825777054
Epoch:  334  	Training Loss: 0.06463059037923813
Test Loss:  0.06686772406101227
Valid Loss:  0.06053130328655243
Epoch:  335  	Training Loss: 0.0646304041147232
Test Loss:  0.06686767935752869
Valid Loss:  0.060531117022037506
Epoch:  336  	Training Loss: 0.06463021785020828
Test Loss:  0.06686759740114212
Valid Loss:  0.060530927032232285
Epoch:  337  	Training Loss: 0.06463003158569336
Test Loss:  0.06686754524707794
Valid Loss:  0.06053074449300766
Epoch:  338  	Training Loss: 0.06462983787059784
Test Loss:  0.06686748564243317
Valid Loss:  0.06053055077791214
Epoch:  339  	Training Loss: 0.06462964415550232
Test Loss:  0.0668674185872078
Valid Loss:  0.06053036451339722
Epoch:  340  	Training Loss: 0.064629465341568
Test Loss:  0.06686735153198242
Valid Loss:  0.0605301707983017
Epoch:  341  	Training Loss: 0.06462927162647247
Test Loss:  0.06686730682849884
Valid Loss:  0.06052999570965767
Epoch:  342  	Training Loss: 0.06462907791137695
Test Loss:  0.06686724722385406
Valid Loss:  0.060529813170433044
Epoch:  343  	Training Loss: 0.06462890654802322
Test Loss:  0.06686721742153168
Valid Loss:  0.060529645532369614
Epoch:  344  	Training Loss: 0.0646287351846695
Test Loss:  0.0668671652674675
Valid Loss:  0.06052947789430618
Epoch:  345  	Training Loss: 0.06462856382131577
Test Loss:  0.06686712056398392
Valid Loss:  0.06052929908037186
Epoch:  346  	Training Loss: 0.06462839245796204
Test Loss:  0.06686706840991974
Valid Loss:  0.06052912771701813
Epoch:  347  	Training Loss: 0.06462821364402771
Test Loss:  0.06686703115701675
Valid Loss:  0.0605289526283741
Epoch:  348  	Training Loss: 0.06462803483009338
Test Loss:  0.06686697155237198
Valid Loss:  0.06052878499031067
Epoch:  349  	Training Loss: 0.06462787091732025
Test Loss:  0.066866934299469
Valid Loss:  0.06052861362695694
Epoch:  350  	Training Loss: 0.06462769210338593
Test Loss:  0.06686688959598541
Valid Loss:  0.060528434813022614
Epoch:  351  	Training Loss: 0.0646275207400322
Test Loss:  0.06686685234308243
Valid Loss:  0.06052826717495918
Epoch:  352  	Training Loss: 0.06462734937667847
Test Loss:  0.06686677038669586
Valid Loss:  0.060528069734573364
Epoch:  353  	Training Loss: 0.06462714821100235
Test Loss:  0.06686672568321228
Valid Loss:  0.06052789092063904
Epoch:  354  	Training Loss: 0.06462696194648743
Test Loss:  0.06686665862798691
Valid Loss:  0.06052769720554352
Epoch:  355  	Training Loss: 0.0646267682313919
Test Loss:  0.06686657667160034
Valid Loss:  0.060527503490448
Epoch:  356  	Training Loss: 0.06462657451629639
Test Loss:  0.06686650961637497
Valid Loss:  0.060527313500642776
Epoch:  357  	Training Loss: 0.06462638825178146
Test Loss:  0.06686646491289139
Valid Loss:  0.06052713096141815
Epoch:  358  	Training Loss: 0.06462620198726654
Test Loss:  0.06686637550592422
Valid Loss:  0.06052693352103233
Epoch:  359  	Training Loss: 0.06462600827217102
Test Loss:  0.06686632335186005
Valid Loss:  0.06052674353122711
Epoch:  360  	Training Loss: 0.0646258145570755
Test Loss:  0.06686625629663467
Valid Loss:  0.06052655726671219
 72%|███████▏  | 361/500 [04:12<02:47,  1.20s/it] 73%|███████▎  | 363/500 [04:12<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:12<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:12<01:01,  2.18it/s] 74%|███████▍  | 369/500 [04:12<00:44,  2.94it/s] 74%|███████▍  | 371/500 [04:19<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:19<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:19<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:19<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:19<00:41,  2.95it/s] 76%|███████▌  | 381/500 [04:25<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:26<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:26<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:26<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:32<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:32<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:33<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.03it/s] 80%|████████  | 401/500 [04:39<01:56,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:39<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:40<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:46<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:46<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:53<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.01it/s] 86%|████████▌ | 431/500 [04:59<01:21,  1.18s/it]Epoch:  361  	Training Loss: 0.06462562084197998
Test Loss:  0.0668661817908287
Valid Loss:  0.06052635982632637
Epoch:  362  	Training Loss: 0.06462543457746506
Test Loss:  0.06686610728502274
Valid Loss:  0.060526177287101746
Epoch:  363  	Training Loss: 0.06462523341178894
Test Loss:  0.06686604768037796
Valid Loss:  0.06052597612142563
Epoch:  364  	Training Loss: 0.06462503969669342
Test Loss:  0.06686598062515259
Valid Loss:  0.060525789856910706
Epoch:  365  	Training Loss: 0.0646248385310173
Test Loss:  0.06686590611934662
Valid Loss:  0.06052559241652489
Epoch:  366  	Training Loss: 0.06462464481592178
Test Loss:  0.06686584651470184
Valid Loss:  0.060525402426719666
Epoch:  367  	Training Loss: 0.06462445110082626
Test Loss:  0.06686575710773468
Valid Loss:  0.06052520498633385
Epoch:  368  	Training Loss: 0.06462425738573074
Test Loss:  0.0668656975030899
Valid Loss:  0.06052501127123833
Epoch:  369  	Training Loss: 0.06462406367063522
Test Loss:  0.06686562299728394
Valid Loss:  0.060524821281433105
Epoch:  370  	Training Loss: 0.0646238625049591
Test Loss:  0.06686554849147797
Valid Loss:  0.06052462384104729
Epoch:  371  	Training Loss: 0.06462366878986359
Test Loss:  0.06686548888683319
Valid Loss:  0.060524433851242065
Epoch:  372  	Training Loss: 0.06462347507476807
Test Loss:  0.06686542183160782
Valid Loss:  0.06052424758672714
Epoch:  373  	Training Loss: 0.06462328135967255
Test Loss:  0.06686536222696304
Valid Loss:  0.060524050146341324
Epoch:  374  	Training Loss: 0.06462308764457703
Test Loss:  0.06686526536941528
Valid Loss:  0.0605238601565361
Epoch:  375  	Training Loss: 0.0646228939294815
Test Loss:  0.0668652206659317
Valid Loss:  0.06052366644144058
Epoch:  376  	Training Loss: 0.06462270021438599
Test Loss:  0.06686514616012573
Valid Loss:  0.06052347272634506
Epoch:  377  	Training Loss: 0.06462250649929047
Test Loss:  0.06686507165431976
Valid Loss:  0.06052327901124954
Epoch:  378  	Training Loss: 0.06462231278419495
Test Loss:  0.06686501204967499
Valid Loss:  0.06052308902144432
Epoch:  379  	Training Loss: 0.06462211161851883
Test Loss:  0.06686493754386902
Valid Loss:  0.0605228915810585
Epoch:  380  	Training Loss: 0.06462191790342331
Test Loss:  0.06686486303806305
Valid Loss:  0.06052270531654358
Epoch:  381  	Training Loss: 0.06462172418832779
Test Loss:  0.06686478853225708
Valid Loss:  0.06052250787615776
Epoch:  382  	Training Loss: 0.06462153792381287
Test Loss:  0.0668647289276123
Valid Loss:  0.06052231416106224
Epoch:  383  	Training Loss: 0.06462133675813675
Test Loss:  0.06686465442180634
Valid Loss:  0.06052212044596672
Epoch:  384  	Training Loss: 0.06462113559246063
Test Loss:  0.06686457991600037
Valid Loss:  0.0605219304561615
Epoch:  385  	Training Loss: 0.06462094932794571
Test Loss:  0.06686452031135559
Valid Loss:  0.06052174046635628
Epoch:  386  	Training Loss: 0.06462075561285019
Test Loss:  0.06686443090438843
Valid Loss:  0.06052154302597046
Epoch:  387  	Training Loss: 0.06462055444717407
Test Loss:  0.06686437129974365
Valid Loss:  0.06052134931087494
Epoch:  388  	Training Loss: 0.06462036073207855
Test Loss:  0.06686431169509888
Valid Loss:  0.06052115559577942
Epoch:  389  	Training Loss: 0.06462016701698303
Test Loss:  0.06686423718929291
Valid Loss:  0.0605209618806839
Epoch:  390  	Training Loss: 0.06461997330188751
Test Loss:  0.06686415523290634
Valid Loss:  0.06052077189087868
Epoch:  391  	Training Loss: 0.0646197721362114
Test Loss:  0.06686407327651978
Valid Loss:  0.06052057445049286
Epoch:  392  	Training Loss: 0.06461957842111588
Test Loss:  0.066864013671875
Valid Loss:  0.06052038446068764
Epoch:  393  	Training Loss: 0.06461938470602036
Test Loss:  0.06686394661664963
Valid Loss:  0.060520198196172714
Epoch:  394  	Training Loss: 0.06461919844150543
Test Loss:  0.06686386466026306
Valid Loss:  0.0605199970304966
Epoch:  395  	Training Loss: 0.06461899727582932
Test Loss:  0.06686380505561829
Valid Loss:  0.060519807040691376
Epoch:  396  	Training Loss: 0.0646188035607338
Test Loss:  0.06686373054981232
Valid Loss:  0.060519613325595856
Epoch:  397  	Training Loss: 0.06461861729621887
Test Loss:  0.06686365604400635
Valid Loss:  0.060519419610500336
Epoch:  398  	Training Loss: 0.06461840867996216
Test Loss:  0.06686358898878098
Valid Loss:  0.06051922217011452
Epoch:  399  	Training Loss: 0.06461821496486664
Test Loss:  0.066863514482975
Valid Loss:  0.060519032180309296
Epoch:  400  	Training Loss: 0.06461802124977112
Test Loss:  0.06686343997716904
Valid Loss:  0.060518842190504074
Epoch:  401  	Training Loss: 0.0646178275346756
Test Loss:  0.06686337292194366
Valid Loss:  0.060518644750118256
Epoch:  402  	Training Loss: 0.06461763381958008
Test Loss:  0.06686332076787949
Valid Loss:  0.060518454760313034
Epoch:  403  	Training Loss: 0.06461744010448456
Test Loss:  0.06686322391033173
Valid Loss:  0.06051826477050781
Epoch:  404  	Training Loss: 0.06461724638938904
Test Loss:  0.06686316430568695
Valid Loss:  0.06051807850599289
Epoch:  405  	Training Loss: 0.06461705267429352
Test Loss:  0.06686311215162277
Valid Loss:  0.06051788851618767
Epoch:  406  	Training Loss: 0.0646168664097786
Test Loss:  0.06686301529407501
Valid Loss:  0.06051769480109215
Epoch:  407  	Training Loss: 0.06461667269468307
Test Loss:  0.06686296314001083
Valid Loss:  0.060517504811286926
Epoch:  408  	Training Loss: 0.06461647897958755
Test Loss:  0.06686290353536606
Valid Loss:  0.060517318546772
Epoch:  409  	Training Loss: 0.06461629271507263
Test Loss:  0.0668628066778183
Valid Loss:  0.06051712483167648
Epoch:  410  	Training Loss: 0.06461609899997711
Test Loss:  0.06686275452375412
Valid Loss:  0.06051693856716156
Epoch:  411  	Training Loss: 0.06461590528488159
Test Loss:  0.06686268746852875
Valid Loss:  0.06051674485206604
Epoch:  412  	Training Loss: 0.06461571156978607
Test Loss:  0.06686259806156158
Valid Loss:  0.06051655486226082
Epoch:  413  	Training Loss: 0.06461552530527115
Test Loss:  0.066862553358078
Valid Loss:  0.060516372323036194
Epoch:  414  	Training Loss: 0.06461533904075623
Test Loss:  0.06686249375343323
Valid Loss:  0.06051618605852127
Epoch:  415  	Training Loss: 0.0646151527762413
Test Loss:  0.06686240434646606
Valid Loss:  0.060516003519296646
Epoch:  416  	Training Loss: 0.06461496651172638
Test Loss:  0.06686235219240189
Valid Loss:  0.060515813529491425
Epoch:  417  	Training Loss: 0.06461477279663086
Test Loss:  0.06686230003833771
Valid Loss:  0.0605156272649765
Epoch:  418  	Training Loss: 0.06461459398269653
Test Loss:  0.06686224043369293
Valid Loss:  0.06051544472575188
Epoch:  419  	Training Loss: 0.06461440026760101
Test Loss:  0.06686215102672577
Valid Loss:  0.060515254735946655
Epoch:  420  	Training Loss: 0.06461422145366669
Test Loss:  0.06686209887266159
Valid Loss:  0.060515064746141434
Epoch:  421  	Training Loss: 0.06461402773857117
Test Loss:  0.06686203926801682
Valid Loss:  0.06051487848162651
Epoch:  422  	Training Loss: 0.06461383402347565
Test Loss:  0.06686194241046906
Valid Loss:  0.06051468476653099
Epoch:  423  	Training Loss: 0.06461364030838013
Test Loss:  0.06686188280582428
Valid Loss:  0.06051449850201607
Epoch:  424  	Training Loss: 0.0646134540438652
Test Loss:  0.0668618232011795
Valid Loss:  0.060514308512210846
Epoch:  425  	Training Loss: 0.06461326032876968
Test Loss:  0.06686174869537354
Valid Loss:  0.06051412224769592
Epoch:  426  	Training Loss: 0.06461306661367416
Test Loss:  0.06686166673898697
Valid Loss:  0.0605139285326004
Epoch:  427  	Training Loss: 0.06461286544799805
Test Loss:  0.0668616071343422
Valid Loss:  0.06051373481750488
Epoch:  428  	Training Loss: 0.06461268663406372
Test Loss:  0.06686155498027802
Valid Loss:  0.06051354855298996
Epoch:  429  	Training Loss: 0.0646124929189682
Test Loss:  0.06686145067214966
Valid Loss:  0.06051335483789444
Epoch:  430  	Training Loss: 0.06461229920387268
Test Loss:  0.06686139106750488
Valid Loss:  0.06051316484808922
Epoch:  431  	Training Loss: 0.06461211293935776
Test Loss:  0.06686133146286011
Valid Loss:  0.060512978583574295
Epoch:  432  	Training Loss: 0.06461191922426224
Test Loss:  0.06686125695705414
Valid Loss:   87%|████████▋ | 433/500 [05:00<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:07<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:13<00:58,  1.18s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:14<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:21<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:27<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:34<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:34<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.20it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.26it/s]100%|█████████▉| 499/500 [05:41<00:00,  2.99it/s]100%|██████████| 500/500 [05:41<00:00,  1.46it/s]
0.060512788593769073
Epoch:  433  	Training Loss: 0.06461173295974731
Test Loss:  0.06686118990182877
Valid Loss:  0.06051260605454445
Epoch:  434  	Training Loss: 0.06461154669523239
Test Loss:  0.06686113774776459
Valid Loss:  0.060512423515319824
Epoch:  435  	Training Loss: 0.06461136043071747
Test Loss:  0.06686106324195862
Valid Loss:  0.0605122372508049
Epoch:  436  	Training Loss: 0.06461117416620255
Test Loss:  0.06686100363731384
Valid Loss:  0.060512054711580276
Epoch:  437  	Training Loss: 0.06461098045110703
Test Loss:  0.06686094403266907
Valid Loss:  0.06051187217235565
Epoch:  438  	Training Loss: 0.0646108016371727
Test Loss:  0.0668608695268631
Valid Loss:  0.06051167845726013
Epoch:  439  	Training Loss: 0.06461062282323837
Test Loss:  0.06686081737279892
Valid Loss:  0.060511503368616104
Epoch:  440  	Training Loss: 0.06461043655872345
Test Loss:  0.06686075776815414
Valid Loss:  0.060511309653520584
Epoch:  441  	Training Loss: 0.06461024284362793
Test Loss:  0.06686070561408997
Valid Loss:  0.060511134564876556
Epoch:  442  	Training Loss: 0.064610056579113
Test Loss:  0.0668606087565422
Valid Loss:  0.060510944575071335
Epoch:  443  	Training Loss: 0.06460987031459808
Test Loss:  0.06686054170131683
Valid Loss:  0.060510747134685516
Epoch:  444  	Training Loss: 0.06460967659950256
Test Loss:  0.06686048209667206
Valid Loss:  0.06051056087017059
Epoch:  445  	Training Loss: 0.06460948288440704
Test Loss:  0.06686040759086609
Valid Loss:  0.06051037088036537
Epoch:  446  	Training Loss: 0.06460930407047272
Test Loss:  0.06686033308506012
Valid Loss:  0.06051017716526985
Epoch:  447  	Training Loss: 0.0646091029047966
Test Loss:  0.06686027348041534
Valid Loss:  0.06050999090075493
Epoch:  448  	Training Loss: 0.06460890918970108
Test Loss:  0.06686019152402878
Valid Loss:  0.06050979718565941
Epoch:  449  	Training Loss: 0.06460872292518616
Test Loss:  0.0668601244688034
Valid Loss:  0.06050960719585419
Epoch:  450  	Training Loss: 0.06460852921009064
Test Loss:  0.06686006486415863
Valid Loss:  0.06050941348075867
Epoch:  451  	Training Loss: 0.06460833549499512
Test Loss:  0.06685999035835266
Valid Loss:  0.060509223490953445
Epoch:  452  	Training Loss: 0.0646081417798996
Test Loss:  0.06685992330312729
Valid Loss:  0.06050904095172882
Epoch:  453  	Training Loss: 0.06460796296596527
Test Loss:  0.06685987859964371
Valid Loss:  0.06050886586308479
Epoch:  454  	Training Loss: 0.06460778415203094
Test Loss:  0.06685982644557953
Valid Loss:  0.06050868332386017
Epoch:  455  	Training Loss: 0.06460759788751602
Test Loss:  0.06685975939035416
Valid Loss:  0.060508497059345245
Epoch:  456  	Training Loss: 0.0646074116230011
Test Loss:  0.06685970723628998
Valid Loss:  0.06050831824541092
Epoch:  457  	Training Loss: 0.06460723280906677
Test Loss:  0.0668596476316452
Valid Loss:  0.06050814688205719
Epoch:  458  	Training Loss: 0.06460705399513245
Test Loss:  0.06685958057641983
Valid Loss:  0.06050796061754227
Epoch:  459  	Training Loss: 0.06460686773061752
Test Loss:  0.06685953587293625
Valid Loss:  0.06050778180360794
Epoch:  460  	Training Loss: 0.0646066963672638
Test Loss:  0.06685948371887207
Valid Loss:  0.06050760671496391
Epoch:  461  	Training Loss: 0.06460650265216827
Test Loss:  0.06685943901538849
Valid Loss:  0.06050742417573929
Epoch:  462  	Training Loss: 0.06460632383823395
Test Loss:  0.06685936450958252
Valid Loss:  0.06050723046064377
Epoch:  463  	Training Loss: 0.06460613012313843
Test Loss:  0.06685928255319595
Valid Loss:  0.060507044196128845
Epoch:  464  	Training Loss: 0.0646059513092041
Test Loss:  0.06685921549797058
Valid Loss:  0.060506854206323624
Epoch:  465  	Training Loss: 0.06460575014352798
Test Loss:  0.06685914099216461
Valid Loss:  0.060506660491228104
Epoch:  466  	Training Loss: 0.06460554897785187
Test Loss:  0.06685908138751984
Valid Loss:  0.06050647050142288
Epoch:  467  	Training Loss: 0.06460537016391754
Test Loss:  0.06685903668403625
Valid Loss:  0.06050628796219826
Epoch:  468  	Training Loss: 0.06460516899824142
Test Loss:  0.06685896962881088
Valid Loss:  0.060506097972393036
Epoch:  469  	Training Loss: 0.0646049827337265
Test Loss:  0.06685887277126312
Valid Loss:  0.060505904257297516
Epoch:  470  	Training Loss: 0.06460478901863098
Test Loss:  0.06685881316661835
Valid Loss:  0.060505710542201996
Epoch:  471  	Training Loss: 0.06460459530353546
Test Loss:  0.06685873866081238
Valid Loss:  0.060505516827106476
Epoch:  472  	Training Loss: 0.06460439413785934
Test Loss:  0.06685866415500641
Valid Loss:  0.06050533056259155
Epoch:  473  	Training Loss: 0.06460420787334442
Test Loss:  0.06685860455036163
Valid Loss:  0.06050514057278633
Epoch:  474  	Training Loss: 0.0646040141582489
Test Loss:  0.06685854494571686
Valid Loss:  0.06050495058298111
Epoch:  475  	Training Loss: 0.06460382044315338
Test Loss:  0.06685848534107208
Valid Loss:  0.06050475686788559
Epoch:  476  	Training Loss: 0.06460361927747726
Test Loss:  0.06685839593410492
Valid Loss:  0.06050456315279007
Epoch:  477  	Training Loss: 0.06460343301296234
Test Loss:  0.06685831397771835
Valid Loss:  0.06050436943769455
Epoch:  478  	Training Loss: 0.06460323929786682
Test Loss:  0.06685826182365417
Valid Loss:  0.06050417572259903
Epoch:  479  	Training Loss: 0.0646030381321907
Test Loss:  0.06685817241668701
Valid Loss:  0.06050398200750351
Epoch:  480  	Training Loss: 0.06460285186767578
Test Loss:  0.06685811281204224
Valid Loss:  0.060503795742988586
Epoch:  481  	Training Loss: 0.06460265070199966
Test Loss:  0.06685805320739746
Valid Loss:  0.060503605753183365
Epoch:  482  	Training Loss: 0.06460244953632355
Test Loss:  0.06685799360275269
Valid Loss:  0.06050341576337814
Epoch:  483  	Training Loss: 0.06460227072238922
Test Loss:  0.06685793399810791
Valid Loss:  0.060503240674734116
Epoch:  484  	Training Loss: 0.0646020919084549
Test Loss:  0.06685787439346313
Valid Loss:  0.06050305813550949
Epoch:  485  	Training Loss: 0.06460191309452057
Test Loss:  0.06685782968997955
Valid Loss:  0.060502879321575165
Epoch:  486  	Training Loss: 0.06460172683000565
Test Loss:  0.06685776263475418
Valid Loss:  0.06050270050764084
Epoch:  487  	Training Loss: 0.06460154056549072
Test Loss:  0.06685769557952881
Valid Loss:  0.060502514243125916
Epoch:  488  	Training Loss: 0.0646013543009758
Test Loss:  0.06685763597488403
Valid Loss:  0.06050233542919159
Epoch:  489  	Training Loss: 0.06460117548704147
Test Loss:  0.06685758382081985
Valid Loss:  0.06050215661525726
Epoch:  490  	Training Loss: 0.06460098922252655
Test Loss:  0.06685753166675568
Valid Loss:  0.06050197780132294
Epoch:  491  	Training Loss: 0.06460081040859222
Test Loss:  0.06685745716094971
Valid Loss:  0.060501787811517715
Epoch:  492  	Training Loss: 0.0646006241440773
Test Loss:  0.06685738265514374
Valid Loss:  0.0605015829205513
Epoch:  493  	Training Loss: 0.06460040807723999
Test Loss:  0.06685730814933777
Valid Loss:  0.060501374304294586
Epoch:  494  	Training Loss: 0.06460020691156387
Test Loss:  0.0668572187423706
Valid Loss:  0.06050117313861847
Epoch:  495  	Training Loss: 0.06459999829530716
Test Loss:  0.06685711443424225
Valid Loss:  0.06050095707178116
Epoch:  496  	Training Loss: 0.06459978222846985
Test Loss:  0.06685703247785568
Valid Loss:  0.06050075590610504
Epoch:  497  	Training Loss: 0.06459957361221313
Test Loss:  0.06685696542263031
Valid Loss:  0.060500554740428925
Epoch:  498  	Training Loss: 0.06459936499595642
Test Loss:  0.06685687601566315
Valid Loss:  0.06050035357475281
Epoch:  499  	Training Loss: 0.0645991638302803
Test Loss:  0.06685678660869598
Valid Loss:  0.060500141233205795
Epoch:  500  	Training Loss: 0.06459896266460419
Test Loss:  0.06685668230056763
Valid Loss:  0.06049993634223938
seed is  10
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:10,  6.15s/it]  1%|          | 3/500 [00:06<13:39,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:12<10:48,  1.33s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:26<12:12,  1.54s/it]  5%|▌         | 27/500 [00:26<08:38,  1.10s/it]  6%|▌         | 29/500 [00:26<06:10,  1.27it/s]  6%|▌         | 31/500 [00:32<11:54,  1.52s/it]  7%|▋         | 33/500 [00:33<08:27,  1.09s/it]  7%|▋         | 35/500 [00:33<06:02,  1.28it/s]  7%|▋         | 37/500 [00:33<04:21,  1.77it/s]  8%|▊         | 39/500 [00:33<03:11,  2.41it/s]  8%|▊         | 41/500 [00:39<09:29,  1.24s/it]  9%|▊         | 43/500 [00:39<06:46,  1.12it/s]  9%|▉         | 45/500 [00:40<04:52,  1.56it/s]  9%|▉         | 47/500 [00:40<03:33,  2.12it/s] 10%|▉         | 49/500 [00:40<02:37,  2.86it/s] 10%|█         | 51/500 [00:46<08:56,  1.20s/it] 11%|█         | 53/500 [00:46<06:23,  1.17it/s] 11%|█         | 55/500 [00:46<04:35,  1.61it/s] 11%|█▏        | 57/500 [00:47<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:47<02:28,  2.96it/s] 12%|█▏        | 61/500 [00:53<08:33,  1.17s/it] 13%|█▎        | 63/500 [00:53<06:07,  1.19it/s] 13%|█▎        | 65/500 [00:53<04:24,  1.65it/s] 13%|█▎        | 67/500 [00:53<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:54<02:22,  3.02it/s]Epoch:  1  	Training Loss: 0.06297262012958527
Test Loss:  0.5382051467895508
Valid Loss:  0.595208466053009
Epoch:  2  	Training Loss: 0.5771125555038452
Test Loss:  0.6284158229827881
Valid Loss:  0.5132294297218323
Epoch:  3  	Training Loss: 0.5531991720199585
Test Loss:  0.24900555610656738
Valid Loss:  0.2942599356174469
Epoch:  4  	Training Loss: 0.28008490800857544
Test Loss:  0.17917218804359436
Valid Loss:  0.21323999762535095
Epoch:  5  	Training Loss: 0.20315203070640564
Test Loss:  0.10440757125616074
Valid Loss:  0.12734967470169067
Epoch:  6  	Training Loss: 0.12099650502204895
Test Loss:  0.06537467986345291
Valid Loss:  0.08109381049871445
Epoch:  7  	Training Loss: 0.077228844165802
Test Loss:  0.04642412066459656
Valid Loss:  0.05749806761741638
Epoch:  8  	Training Loss: 0.05524240434169769
Test Loss:  0.03701446205377579
Valid Loss:  0.0450630784034729
Epoch:  9  	Training Loss: 0.04385504871606827
Test Loss:  0.032089948654174805
Valid Loss:  0.03815605863928795
Epoch:  10  	Training Loss: 0.03763166069984436
Test Loss:  0.02924906462430954
Valid Loss:  0.03400462865829468
Epoch:  11  	Training Loss: 0.03392506390810013
Test Loss:  0.02736292965710163
Valid Loss:  0.03124711848795414
Epoch:  12  	Training Loss: 0.03145796060562134
Test Loss:  0.020809609442949295
Valid Loss:  0.023622898384928703
Epoch:  13  	Training Loss: 0.024180538952350616
Test Loss:  0.014615613967180252
Valid Loss:  0.018571430817246437
Epoch:  14  	Training Loss: 0.01856323331594467
Test Loss:  0.013460366055369377
Valid Loss:  0.017109382897615433
Epoch:  15  	Training Loss: 0.016792407259345055
Test Loss:  0.015006082132458687
Valid Loss:  0.018321245908737183
Epoch:  16  	Training Loss: 0.01857697032392025
Test Loss:  0.011423075571656227
Valid Loss:  0.01467655599117279
Epoch:  17  	Training Loss: 0.014536132104694843
Test Loss:  0.010291412472724915
Valid Loss:  0.013642309233546257
Epoch:  18  	Training Loss: 0.013668311759829521
Test Loss:  0.010889305733144283
Valid Loss:  0.01381679903715849
Epoch:  19  	Training Loss: 0.013546397909522057
Test Loss:  0.013374770060181618
Valid Loss:  0.01614486798644066
Epoch:  20  	Training Loss: 0.01666877418756485
Test Loss:  0.010619351640343666
Valid Loss:  0.012871233746409416
Epoch:  21  	Training Loss: 0.012788173742592335
Test Loss:  0.011270883493125439
Valid Loss:  0.014070426113903522
Epoch:  22  	Training Loss: 0.01454661414027214
Test Loss:  0.004688155837357044
Valid Loss:  0.006247323006391525
Epoch:  23  	Training Loss: 0.006378797814249992
Test Loss:  0.003170907497406006
Valid Loss:  0.003891606582328677
Epoch:  24  	Training Loss: 0.004085445310920477
Test Loss:  0.015329252928495407
Valid Loss:  0.01593548059463501
Epoch:  25  	Training Loss: 0.01572955772280693
Test Loss:  0.1300995945930481
Valid Loss:  0.13014401495456696
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.13227105140686035
Test Loss:  0.010580676607787609
Valid Loss:  0.011796535924077034
Epoch:  27  	Training Loss: 0.012446396052837372
Test Loss:  0.009269479662179947
Valid Loss:  0.01085512526333332
Epoch:  28  	Training Loss: 0.011287507601082325
Test Loss:  0.008699632249772549
Valid Loss:  0.010294212028384209
Epoch:  29  	Training Loss: 0.010687122121453285
Test Loss:  0.008316184394061565
Valid Loss:  0.009885923936963081
Epoch:  30  	Training Loss: 0.010266739875078201
Test Loss:  0.00802021473646164
Valid Loss:  0.00956543069332838
Epoch:  31  	Training Loss: 0.009931914508342743
Test Loss:  0.007761809043586254
Valid Loss:  0.009282183833420277
Epoch:  32  	Training Loss: 0.009640468284487724
Test Loss:  0.0037751994095742702
Valid Loss:  0.004752202890813351
Epoch:  33  	Training Loss: 0.004885256290435791
Test Loss:  0.00225408049300313
Valid Loss:  0.002797125605866313
Epoch:  34  	Training Loss: 0.002909487346187234
Test Loss:  0.001998043619096279
Valid Loss:  0.0023409498389810324
Epoch:  35  	Training Loss: 0.0024323840625584126
Test Loss:  0.0019651781767606735
Valid Loss:  0.0021569307427853346
Epoch:  36  	Training Loss: 0.0022542367223650217
Test Loss:  0.00198760605417192
Valid Loss:  0.0020773655269294977
Epoch:  37  	Training Loss: 0.002175147645175457
Test Loss:  0.0020074681378901005
Valid Loss:  0.002030626405030489
Epoch:  38  	Training Loss: 0.0021307531278580427
Test Loss:  0.0020229886285960674
Valid Loss:  0.0020003006793558598
Epoch:  39  	Training Loss: 0.002100193640217185
Test Loss:  0.002030517440289259
Valid Loss:  0.0019767978228628635
Epoch:  40  	Training Loss: 0.0020761974155902863
Test Loss:  0.002033389639109373
Valid Loss:  0.001956947147846222
Epoch:  41  	Training Loss: 0.0020555327646434307
Test Loss:  0.0020325202494859695
Valid Loss:  0.001939959591254592
Epoch:  42  	Training Loss: 0.002036991761997342
Test Loss:  0.002039000391960144
Valid Loss:  0.0019251685589551926
Epoch:  43  	Training Loss: 0.0020222908351570368
Test Loss:  0.00204633641988039
Valid Loss:  0.0019140795338898897
Epoch:  44  	Training Loss: 0.0020110670011490583
Test Loss:  0.0020533017814159393
Valid Loss:  0.0019047941314056516
Epoch:  45  	Training Loss: 0.002001578686758876
Test Loss:  0.00205968227237463
Valid Loss:  0.0018968661315739155
Epoch:  46  	Training Loss: 0.0019934221636503935
Test Loss:  0.0020655617117881775
Valid Loss:  0.0018900202121585608
Epoch:  47  	Training Loss: 0.0019863899797201157
Test Loss:  0.0020711082033813
Valid Loss:  0.0018840085249394178
Epoch:  48  	Training Loss: 0.001980227418243885
Test Loss:  0.0020763096399605274
Valid Loss:  0.0018787612207233906
Epoch:  49  	Training Loss: 0.001974910032004118
Test Loss:  0.002081210259348154
Valid Loss:  0.0018740760860964656
Epoch:  50  	Training Loss: 0.001970179844647646
Test Loss:  0.0020856307819485664
Valid Loss:  0.0018699278589338064
Epoch:  51  	Training Loss: 0.0019659209065139294
Test Loss:  0.0020896175410598516
Valid Loss:  0.0018661962822079659
Epoch:  52  	Training Loss: 0.001962039154022932
Test Loss:  0.0019899862818419933
Valid Loss:  0.0016779478173702955
Epoch:  53  	Training Loss: 0.0017770299455150962
Test Loss:  0.001924297772347927
Valid Loss:  0.0015140974428504705
Epoch:  54  	Training Loss: 0.001611221581697464
Test Loss:  0.0018540727905929089
Valid Loss:  0.0013896389864385128
Epoch:  55  	Training Loss: 0.0014831647276878357
Test Loss:  0.0018083404283970594
Valid Loss:  0.0012968385126441717
Epoch:  56  	Training Loss: 0.0013895895099267364
Test Loss:  0.001767399488016963
Valid Loss:  0.001234665047377348
Epoch:  57  	Training Loss: 0.0013243999565020204
Test Loss:  0.0017320571932941675
Valid Loss:  0.0011872777249664068
Epoch:  58  	Training Loss: 0.0012761617545038462
Test Loss:  0.0016963710077106953
Valid Loss:  0.0011509655741974711
Epoch:  59  	Training Loss: 0.0012392094358801842
Test Loss:  0.0016635009087622166
Valid Loss:  0.001121187349781394
Epoch:  60  	Training Loss: 0.0012084981426596642
Test Loss:  0.001631096238270402
Valid Loss:  0.0010970919393002987
Epoch:  61  	Training Loss: 0.0011820255313068628
Test Loss:  0.0016000207979232073
Valid Loss:  0.0010758353164419532
Epoch:  62  	Training Loss: 0.0011579424608498812
Test Loss:  0.001315753092058003
Valid Loss:  0.0009067530045285821
Epoch:  63  	Training Loss: 0.0009717004140838981
Test Loss:  0.0011323238722980022
Valid Loss:  0.0007885246304795146
Epoch:  64  	Training Loss: 0.0008420847589150071
Test Loss:  0.0010043911170214415
Valid Loss:  0.0007010690169408917
Epoch:  65  	Training Loss: 0.0007462865323759615
Test Loss:  0.0009055466507561505
Valid Loss:  0.0006365705048665404
Epoch:  66  	Training Loss: 0.000674079405143857
Test Loss:  0.0008317201281897724
Valid Loss:  0.0005884503480046988
Epoch:  67  	Training Loss: 0.0006201266660355031
Test Loss:  0.0007714258972555399
Valid Loss:  0.0005494671640917659
Epoch:  68  	Training Loss: 0.0005763451335951686
Test Loss:  0.0007199679384939373
Valid Loss:  0.0005181410815566778
Epoch:  69  	Training Loss: 0.0005408936413004994
Test Loss:  0.0006801409181207418
Valid Loss:  0.0004942185478284955
Epoch:  70  	Training Loss: 0.0005147326737642288
Test Loss:   14%|█▍        | 71/500 [01:00<08:33,  1.20s/it] 14%|█▍        | 72/500 [01:00<07:09,  1.00s/it] 15%|█▍        | 74/500 [01:00<04:56,  1.44it/s] 15%|█▌        | 76/500 [01:00<03:32,  2.00it/s] 16%|█▌        | 78/500 [01:01<02:35,  2.71it/s] 16%|█▌        | 80/500 [01:01<01:57,  3.56it/s] 16%|█▋        | 82/500 [01:07<08:10,  1.17s/it] 17%|█▋        | 84/500 [01:07<05:47,  1.20it/s] 17%|█▋        | 86/500 [01:07<04:08,  1.66it/s] 18%|█▊        | 88/500 [01:07<03:01,  2.27it/s] 18%|█▊        | 90/500 [01:08<02:14,  3.06it/s] 18%|█▊        | 92/500 [01:14<07:59,  1.17s/it] 19%|█▉        | 94/500 [01:14<05:41,  1.19it/s] 19%|█▉        | 96/500 [01:14<04:05,  1.65it/s] 20%|█▉        | 98/500 [01:14<02:59,  2.24it/s] 20%|██        | 100/500 [01:14<02:12,  3.02it/s] 20%|██        | 102/500 [01:21<08:04,  1.22s/it] 21%|██        | 104/500 [01:21<05:45,  1.15it/s] 21%|██        | 106/500 [01:21<04:07,  1.59it/s] 22%|██▏       | 108/500 [01:21<03:00,  2.18it/s] 22%|██▏       | 110/500 [01:22<02:12,  2.93it/s] 22%|██▏       | 112/500 [01:28<07:41,  1.19s/it] 23%|██▎       | 114/500 [01:28<05:28,  1.17it/s] 23%|██▎       | 116/500 [01:28<03:56,  1.62it/s] 24%|██▎       | 118/500 [01:28<02:52,  2.22it/s] 24%|██▍       | 120/500 [01:28<02:08,  2.95it/s] 24%|██▍       | 122/500 [01:35<07:34,  1.20s/it] 25%|██▍       | 124/500 [01:35<05:23,  1.16it/s] 25%|██▌       | 126/500 [01:35<03:52,  1.61it/s] 26%|██▌       | 128/500 [01:35<02:49,  2.20it/s] 26%|██▌       | 130/500 [01:42<07:55,  1.29s/it] 26%|██▌       | 131/500 [01:48<13:18,  2.16s/it] 27%|██▋       | 133/500 [01:48<08:56,  1.46s/it] 27%|██▋       | 135/500 [01:48<06:08,  1.01s/it]0.0006487069185823202
Valid Loss:  0.00047427319805137813
Epoch:  71  	Training Loss: 0.0004948492278344929
Test Loss:  0.0006233793683350086
Valid Loss:  0.0004589641175698489
Epoch:  72  	Training Loss: 0.00047806487418711185
Test Loss:  0.0006061763851903379
Valid Loss:  0.0004499986534938216
Epoch:  73  	Training Loss: 0.0004681801365222782
Test Loss:  0.000594013137742877
Valid Loss:  0.0004422127385623753
Epoch:  74  	Training Loss: 0.0004600485262926668
Test Loss:  0.0005825498374179006
Valid Loss:  0.0004347573849372566
Epoch:  75  	Training Loss: 0.00045282189967110753
Test Loss:  0.0005729588447138667
Valid Loss:  0.0004286353359930217
Epoch:  76  	Training Loss: 0.00044703116873279214
Test Loss:  0.0005643179174512625
Valid Loss:  0.0004244367592036724
Epoch:  77  	Training Loss: 0.0004421776975505054
Test Loss:  0.0005572974332608283
Valid Loss:  0.00042037872481159866
Epoch:  78  	Training Loss: 0.0004374875279609114
Test Loss:  0.000550472701434046
Valid Loss:  0.00041645028977654874
Epoch:  79  	Training Loss: 0.00043371960055083036
Test Loss:  0.000546386931091547
Valid Loss:  0.0004138094955123961
Epoch:  80  	Training Loss: 0.000431374239269644
Test Loss:  0.000543154776096344
Valid Loss:  0.00041234405944123864
Epoch:  81  	Training Loss: 0.00042950728675350547
Test Loss:  0.0005398869980126619
Valid Loss:  0.00041091354796662927
Epoch:  82  	Training Loss: 0.0004278932756278664
Test Loss:  0.0005342941731214523
Valid Loss:  0.0004045572713948786
Epoch:  83  	Training Loss: 0.00042040017433464527
Test Loss:  0.0005316089373081923
Valid Loss:  0.00039922562427818775
Epoch:  84  	Training Loss: 0.0004144267295487225
Test Loss:  0.0005291776033118367
Valid Loss:  0.0003946241922676563
Epoch:  85  	Training Loss: 0.0004095574840903282
Test Loss:  0.0005266611115075648
Valid Loss:  0.0003904533514287323
Epoch:  86  	Training Loss: 0.00040523812640458345
Test Loss:  0.0005243119085207582
Valid Loss:  0.000386748812161386
Epoch:  87  	Training Loss: 0.0004014599253423512
Test Loss:  0.0005219480954110622
Valid Loss:  0.0003833028022199869
Epoch:  88  	Training Loss: 0.00039788614958524704
Test Loss:  0.0005197006976231933
Valid Loss:  0.00038000490167178214
Epoch:  89  	Training Loss: 0.0003945929929614067
Test Loss:  0.0005174671532586217
Valid Loss:  0.0003772293566726148
Epoch:  90  	Training Loss: 0.00039180368185043335
Test Loss:  0.0005153288948349655
Valid Loss:  0.0003747024165932089
Epoch:  91  	Training Loss: 0.00038920820225030184
Test Loss:  0.0005133615923114121
Valid Loss:  0.00037231328315101564
Epoch:  92  	Training Loss: 0.00038675396353937685
Test Loss:  0.0005065894220024347
Valid Loss:  0.0003577674797270447
Epoch:  93  	Training Loss: 0.00037011358654126525
Test Loss:  0.0005033559282310307
Valid Loss:  0.00034669312299229205
Epoch:  94  	Training Loss: 0.0003582116332836449
Test Loss:  0.0004975751508027315
Valid Loss:  0.00033831651671789587
Epoch:  95  	Training Loss: 0.0003486653440631926
Test Loss:  0.0004921199288219213
Valid Loss:  0.00033085051109082997
Epoch:  96  	Training Loss: 0.0003404801245778799
Test Loss:  0.00048580835573375225
Valid Loss:  0.00032446146360598505
Epoch:  97  	Training Loss: 0.00033332593739032745
Test Loss:  0.00047936581540852785
Valid Loss:  0.0003184897359460592
Epoch:  98  	Training Loss: 0.0003270086017437279
Test Loss:  0.0004728406493086368
Valid Loss:  0.00031332235084846616
Epoch:  99  	Training Loss: 0.0003212465962860733
Test Loss:  0.0004665978194680065
Valid Loss:  0.00030859094113111496
Epoch:  100  	Training Loss: 0.00031613855389878154
Test Loss:  0.00046063485206104815
Valid Loss:  0.0003042573225684464
Epoch:  101  	Training Loss: 0.00031137210316956043
Test Loss:  0.0004549880395643413
Valid Loss:  0.00030020478880032897
Epoch:  102  	Training Loss: 0.0003069273952860385
Test Loss:  0.00044962443644180894
Valid Loss:  0.00029910512967035174
Epoch:  103  	Training Loss: 0.0003056525602005422
Test Loss:  0.0004452839493751526
Valid Loss:  0.00029818969778716564
Epoch:  104  	Training Loss: 0.0003046398051083088
Test Loss:  0.0004415410221554339
Valid Loss:  0.000297460617730394
Epoch:  105  	Training Loss: 0.00030382536351680756
Test Loss:  0.000438290269812569
Valid Loss:  0.0002968789776787162
Epoch:  106  	Training Loss: 0.0003031655214726925
Test Loss:  0.0004354565462563187
Valid Loss:  0.00029641034780070186
Epoch:  107  	Training Loss: 0.00030262567452155054
Test Loss:  0.00043297692900523543
Valid Loss:  0.00029602990252897143
Epoch:  108  	Training Loss: 0.0003021793090738356
Test Loss:  0.00043079929309897125
Valid Loss:  0.0002957183460239321
Epoch:  109  	Training Loss: 0.00030180608155205846
Test Loss:  0.00042888044845312834
Valid Loss:  0.0002954587689600885
Epoch:  110  	Training Loss: 0.00030148981022648513
Test Loss:  0.00042718378244899213
Valid Loss:  0.0002952399954665452
Epoch:  111  	Training Loss: 0.00030121742747724056
Test Loss:  0.00042567774653434753
Valid Loss:  0.0002950530033558607
Epoch:  112  	Training Loss: 0.0003009798820130527
Test Loss:  0.0004198631504550576
Valid Loss:  0.00029302528128027916
Epoch:  113  	Training Loss: 0.000299343082588166
Test Loss:  0.0004161347751505673
Valid Loss:  0.0002918766695074737
Epoch:  114  	Training Loss: 0.00029858737252652645
Test Loss:  0.0004127435095142573
Valid Loss:  0.0002907465095631778
Epoch:  115  	Training Loss: 0.00029785477090626955
Test Loss:  0.00041008161497302353
Valid Loss:  0.000289647578028962
Epoch:  116  	Training Loss: 0.0002971431822516024
Test Loss:  0.0004075200413353741
Valid Loss:  0.0002885731519199908
Epoch:  117  	Training Loss: 0.0002964493469335139
Test Loss:  0.00040505046490579844
Valid Loss:  0.0002875220961868763
Epoch:  118  	Training Loss: 0.0002957698015961796
Test Loss:  0.0004026670358143747
Valid Loss:  0.0002864923153538257
Epoch:  119  	Training Loss: 0.00029510559397749603
Test Loss:  0.0004003604408353567
Valid Loss:  0.00028548319824039936
Epoch:  120  	Training Loss: 0.00029445457039400935
Test Loss:  0.00039879512041807175
Valid Loss:  0.0002844966948032379
Epoch:  121  	Training Loss: 0.0002938152174465358
Test Loss:  0.0003973957500420511
Valid Loss:  0.0002835367922671139
Epoch:  122  	Training Loss: 0.0002931902417913079
Test Loss:  0.00040045278728939593
Valid Loss:  0.00028290541376918554
Epoch:  123  	Training Loss: 0.000289403076749295
Test Loss:  0.0004025772796012461
Valid Loss:  0.00027948219212703407
Epoch:  124  	Training Loss: 0.0002884232671931386
Test Loss:  0.00040154997259378433
Valid Loss:  0.0002902732521761209
Epoch:  125  	Training Loss: 0.00029139657272025943
Test Loss:  0.00041842894279398024
Valid Loss:  0.00029406658723019063
Epoch:  126  	Training Loss: 0.00030545960180461407
Test Loss:  0.0004551392630673945
Valid Loss:  0.00036689863190986216
Epoch:  127  	Training Loss: 0.00035268926876597106
Test Loss:  0.0006082748877815902
Valid Loss:  0.00048639412852935493
Epoch:  128  	Training Loss: 0.0005013204063288867
Test Loss:  0.0010092819575220346
Valid Loss:  0.0010194757487624884
Epoch:  129  	Training Loss: 0.0009410387137904763
Test Loss:  0.0024000266566872597
Valid Loss:  0.0023593069054186344
Epoch:  130  	Training Loss: 0.002326748799532652
Test Loss:  0.005967774894088507
Valid Loss:  0.0064568351954221725
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.00612308643758297
Test Loss:  0.0004544816620182246
Valid Loss:  0.00045374539331533015
Epoch:  132  	Training Loss: 0.0004057138576172292
Test Loss:  0.0003043286851607263
Valid Loss:  0.00028921879129484296
Epoch:  133  	Training Loss: 0.00026394915767014027
Test Loss:  0.00028629921143874526
Valid Loss:  0.0002698758034966886
Epoch:  134  	Training Loss: 0.0002506148593965918
Test Loss:  0.00028331542853266
Valid Loss:  0.00026663707103580236
Epoch:  135  	Training Loss: 0.00024924182798713446
Test Loss:  0.0002827462740242481
Valid Loss:  0.00026587455067783594
Epoch:  136  	Training Loss: 0.0002490895567461848
Test Loss:  0.00028274068608880043
Valid Loss:  0.0002656606084201485
Epoch:  137  	Training Loss: 0.00024906883481889963
Test Loss:   27%|██▋       | 137/500 [01:48<04:17,  1.41it/s] 28%|██▊       | 139/500 [01:48<03:03,  1.96it/s] 28%|██▊       | 141/500 [01:55<08:00,  1.34s/it] 29%|██▊       | 143/500 [01:55<05:39,  1.05it/s] 29%|██▉       | 145/500 [01:55<04:01,  1.47it/s] 29%|██▉       | 147/500 [01:55<02:54,  2.02it/s] 30%|██▉       | 149/500 [01:55<02:09,  2.71it/s] 30%|███       | 151/500 [02:02<07:11,  1.24s/it] 31%|███       | 153/500 [02:02<05:07,  1.13it/s] 31%|███       | 155/500 [02:02<03:40,  1.56it/s] 31%|███▏      | 157/500 [02:02<02:40,  2.14it/s] 32%|███▏      | 159/500 [02:02<01:57,  2.89it/s] 32%|███▏      | 161/500 [02:09<06:51,  1.21s/it] 33%|███▎      | 163/500 [02:09<04:53,  1.15it/s] 33%|███▎      | 165/500 [02:09<03:30,  1.59it/s] 33%|███▎      | 167/500 [02:09<02:33,  2.17it/s] 34%|███▍      | 169/500 [02:09<01:53,  2.92it/s] 34%|███▍      | 171/500 [02:16<06:35,  1.20s/it] 35%|███▍      | 173/500 [02:16<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:16<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:16<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:16<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:23<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:23<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:23<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:23<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:23<01:44,  2.99it/s] 38%|███▊      | 191/500 [02:30<06:06,  1.19s/it] 39%|███▊      | 193/500 [02:30<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:30<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:30<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:30<01:40,  2.99it/s] 40%|████      | 201/500 [02:36<05:54,  1.19s/it] 41%|████      | 203/500 [02:37<04:12,  1.17it/s]0.0002828572760336101
Valid Loss:  0.00026558656827546656
Epoch:  138  	Training Loss: 0.0002490617916919291
Test Loss:  0.0002829980803653598
Valid Loss:  0.0002655567368492484
Epoch:  139  	Training Loss: 0.00024905745522119105
Test Loss:  0.00028313466464169323
Valid Loss:  0.00026554224314168096
Epoch:  140  	Training Loss: 0.0002490543411113322
Test Loss:  0.00028325908351689577
Valid Loss:  0.0002655333955772221
Epoch:  141  	Training Loss: 0.0002490518381819129
Test Loss:  0.0002833702601492405
Valid Loss:  0.0002655275457073003
Epoch:  142  	Training Loss: 0.00024904991732910275
Test Loss:  0.00028346027829684317
Valid Loss:  0.0002651035611052066
Epoch:  143  	Training Loss: 0.0002487263409420848
Test Loss:  0.0002835188643075526
Valid Loss:  0.0002648449444677681
Epoch:  144  	Training Loss: 0.00024844141444191337
Test Loss:  0.00028356496477499604
Valid Loss:  0.00026463932590559125
Epoch:  145  	Training Loss: 0.00024821306578814983
Test Loss:  0.00028360538999550045
Valid Loss:  0.0002644380438141525
Epoch:  146  	Training Loss: 0.0002479971444699913
Test Loss:  0.00028363725868985057
Valid Loss:  0.0002642744220793247
Epoch:  147  	Training Loss: 0.00024784740526229143
Test Loss:  0.00028366560582071543
Valid Loss:  0.0002641135943122208
Epoch:  148  	Training Loss: 0.0002476986846886575
Test Loss:  0.00028365853358991444
Valid Loss:  0.000263943278696388
Epoch:  149  	Training Loss: 0.0002475510991644114
Test Loss:  0.00028368952916935086
Valid Loss:  0.00026379560586065054
Epoch:  150  	Training Loss: 0.00024740459048189223
Test Loss:  0.0002837039646692574
Valid Loss:  0.0002636394347064197
Epoch:  151  	Training Loss: 0.00024727429263293743
Test Loss:  0.00028371333610266447
Valid Loss:  0.00026351987617090344
Epoch:  152  	Training Loss: 0.0002471902989782393
Test Loss:  0.00028082585777156055
Valid Loss:  0.0002492051280569285
Epoch:  153  	Training Loss: 0.0002392639871686697
Test Loss:  0.0002759970084298402
Valid Loss:  0.00024620810290798545
Epoch:  154  	Training Loss: 0.00023446085106115788
Test Loss:  0.0002738448092713952
Valid Loss:  0.00024228809343185276
Epoch:  155  	Training Loss: 0.00023130528279580176
Test Loss:  0.0002722918288782239
Valid Loss:  0.00024005425802897662
Epoch:  156  	Training Loss: 0.0002287318930029869
Test Loss:  0.00027114973636344075
Valid Loss:  0.00023848067212384194
Epoch:  157  	Training Loss: 0.00022678378445561975
Test Loss:  0.00027009527548216283
Valid Loss:  0.00023797071480657905
Epoch:  158  	Training Loss: 0.00022564921528100967
Test Loss:  0.00026949995663017035
Valid Loss:  0.00023696990683674812
Epoch:  159  	Training Loss: 0.0002248761593364179
Test Loss:  0.0002689691900741309
Valid Loss:  0.00023684321786276996
Epoch:  160  	Training Loss: 0.00022435476421378553
Test Loss:  0.00026865984546020627
Valid Loss:  0.00023654790129512548
Epoch:  161  	Training Loss: 0.00022399728186428547
Test Loss:  0.000268427946139127
Valid Loss:  0.00023644516477361321
Epoch:  162  	Training Loss: 0.00022372062085196376
Test Loss:  0.000268029049038887
Valid Loss:  0.00023611815413460135
Epoch:  163  	Training Loss: 0.00022337188420351595
Test Loss:  0.0002676366420928389
Valid Loss:  0.00023579181288369
Epoch:  164  	Training Loss: 0.00022302631987258792
Test Loss:  0.00026724894996732473
Valid Loss:  0.00023546584998257458
Epoch:  165  	Training Loss: 0.00022268766770139337
Test Loss:  0.0002668809611350298
Valid Loss:  0.000235151092056185
Epoch:  166  	Training Loss: 0.00022236151562537998
Test Loss:  0.0002665316278580576
Valid Loss:  0.00023484720441047102
Epoch:  167  	Training Loss: 0.00022205087589100003
Test Loss:  0.0002661864855326712
Valid Loss:  0.00023454210895579308
Epoch:  168  	Training Loss: 0.00022174218611326069
Test Loss:  0.000265846261754632
Valid Loss:  0.00023423715902026743
Epoch:  169  	Training Loss: 0.0002214359410572797
Test Loss:  0.000265509937889874
Valid Loss:  0.00023393280571326613
Epoch:  170  	Training Loss: 0.00022113497834652662
Test Loss:  0.00026519130915403366
Valid Loss:  0.00023363929358310997
Epoch:  171  	Training Loss: 0.00022084491502027959
Test Loss:  0.00026487684226594865
Valid Loss:  0.00023334615980274975
Epoch:  172  	Training Loss: 0.00022055921726860106
Test Loss:  0.00026462579262442887
Valid Loss:  0.0002331747964490205
Epoch:  173  	Training Loss: 0.00022036618611309677
Test Loss:  0.0002643870539031923
Valid Loss:  0.00023295046412386
Epoch:  174  	Training Loss: 0.00022019734024070203
Test Loss:  0.00026428024284541607
Valid Loss:  0.00023281527683138847
Epoch:  175  	Training Loss: 0.00022011803230270743
Test Loss:  0.0002641728497110307
Valid Loss:  0.00023279321612790227
Epoch:  176  	Training Loss: 0.00022003974299877882
Test Loss:  0.0002640647580847144
Valid Loss:  0.00023276195861399174
Epoch:  177  	Training Loss: 0.00021996228315401822
Test Loss:  0.00026395448367111385
Valid Loss:  0.000232724953093566
Epoch:  178  	Training Loss: 0.00021988485241308808
Test Loss:  0.00026384272496216
Valid Loss:  0.00023268559016287327
Epoch:  179  	Training Loss: 0.00021980798919685185
Test Loss:  0.0002637293073348701
Valid Loss:  0.0002326430840184912
Epoch:  180  	Training Loss: 0.00021973140246700495
Test Loss:  0.0002636145509313792
Valid Loss:  0.00023260041780304164
Epoch:  181  	Training Loss: 0.00021965487394481897
Test Loss:  0.00026349982363171875
Valid Loss:  0.00023255693668033928
Epoch:  182  	Training Loss: 0.00021957872377242893
Test Loss:  0.00026273075491189957
Valid Loss:  0.0002314861776540056
Epoch:  183  	Training Loss: 0.00021879107225686312
Test Loss:  0.00026198342675343156
Valid Loss:  0.00023052141477819532
Epoch:  184  	Training Loss: 0.0002180249139200896
Test Loss:  0.00026126360171474516
Valid Loss:  0.00022960349451750517
Epoch:  185  	Training Loss: 0.00021727412240579724
Test Loss:  0.0002605719491839409
Valid Loss:  0.00022871146211400628
Epoch:  186  	Training Loss: 0.00021653846488334239
Test Loss:  0.00025990826543420553
Valid Loss:  0.00022783858003094792
Epoch:  187  	Training Loss: 0.00021581703913398087
Test Loss:  0.00025927176466211677
Valid Loss:  0.00022698224347550422
Epoch:  188  	Training Loss: 0.0002151094377040863
Test Loss:  0.0002586607006378472
Valid Loss:  0.00022614045883528888
Epoch:  189  	Training Loss: 0.00021441563148982823
Test Loss:  0.00025807530619204044
Valid Loss:  0.00022531597642228007
Epoch:  190  	Training Loss: 0.0002137361152563244
Test Loss:  0.0002575127873569727
Valid Loss:  0.00022450565302278847
Epoch:  191  	Training Loss: 0.00021306853159330785
Test Loss:  0.0002569701464381069
Valid Loss:  0.00022370810620486736
Epoch:  192  	Training Loss: 0.000212413418921642
Test Loss:  0.0002563527086749673
Valid Loss:  0.00022167153656482697
Epoch:  193  	Training Loss: 0.00021115429990459234
Test Loss:  0.0002558720880188048
Valid Loss:  0.00022106347023509443
Epoch:  194  	Training Loss: 0.00021000854030717164
Test Loss:  0.0002551793586462736
Valid Loss:  0.0002193660184275359
Epoch:  195  	Training Loss: 0.00020887752179987729
Test Loss:  0.0002546088071539998
Valid Loss:  0.00021860553533770144
Epoch:  196  	Training Loss: 0.00020778097677975893
Test Loss:  0.00025390484370291233
Valid Loss:  0.00021720677614212036
Epoch:  197  	Training Loss: 0.00020673003746196628
Test Loss:  0.00025327689945697784
Valid Loss:  0.00021630313131026924
Epoch:  198  	Training Loss: 0.00020570038759615272
Test Loss:  0.00025261202245019376
Valid Loss:  0.00021518627181649208
Epoch:  199  	Training Loss: 0.00020469751325435936
Test Loss:  0.0002519498229958117
Valid Loss:  0.00021410040790215135
Epoch:  200  	Training Loss: 0.00020371473510749638
Test Loss:  0.0002512806677259505
Valid Loss:  0.00021303114772308618
Epoch:  201  	Training Loss: 0.00020275218412280083
Test Loss:  0.00025063371867872775
Valid Loss:  0.00021198767353780568
Epoch:  202  	Training Loss: 0.00020181084983050823
Test Loss:  0.00024978333385661244
Valid Loss:  0.00021126196952536702
Epoch:  203  	Training Loss: 0.00020128348842263222
Test Loss:  0.0002489793114364147
Valid Loss:  0.0002106221509166062
Epoch:  204  	Training Loss: 0.0002007684379350394
Test Loss:  0.0002482343406882137
Valid Loss:   41%|████      | 205/500 [02:37<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:37<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:37<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:43<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:44<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:44<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:44<02:07,  2.21it/s] 44%|████▍     | 219/500 [02:44<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:50<05:34,  1.20s/it] 45%|████▍     | 223/500 [02:50<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:51<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:51<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:51<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:57<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:57<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:58<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:58<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:58<01:27,  2.97it/s] 48%|████▊     | 241/500 [03:04<05:11,  1.20s/it] 49%|████▊     | 243/500 [03:04<03:42,  1.16it/s] 49%|████▉     | 245/500 [03:05<02:39,  1.60it/s] 49%|████▉     | 247/500 [03:05<01:55,  2.19it/s] 50%|████▉     | 249/500 [03:05<01:24,  2.95it/s] 50%|█████     | 251/500 [03:11<04:57,  1.20s/it] 51%|█████     | 253/500 [03:11<03:31,  1.17it/s] 51%|█████     | 255/500 [03:11<02:31,  1.61it/s] 51%|█████▏    | 257/500 [03:12<01:50,  2.21it/s] 52%|█████▏    | 259/500 [03:12<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:18<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:18<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:18<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:18<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:19<01:18,  2.93it/s] 54%|█████▍    | 271/500 [03:25<04:29,  1.18s/it]0.00020998997206334025
Epoch:  205  	Training Loss: 0.0002002647379413247
Test Loss:  0.00024754140758886933
Valid Loss:  0.00020937388762831688
Epoch:  206  	Training Loss: 0.00019977285410277545
Test Loss:  0.00024689571000635624
Valid Loss:  0.00020877202041447163
Epoch:  207  	Training Loss: 0.0001992917968891561
Test Loss:  0.000246291805524379
Valid Loss:  0.00020818470511585474
Epoch:  208  	Training Loss: 0.0001988210715353489
Test Loss:  0.0002457243390381336
Valid Loss:  0.00020760878396686167
Epoch:  209  	Training Loss: 0.000198359542991966
Test Loss:  0.0002451924083288759
Valid Loss:  0.00020704438793472946
Epoch:  210  	Training Loss: 0.00019790658552665263
Test Loss:  0.0002446900471113622
Valid Loss:  0.0002064912987407297
Epoch:  211  	Training Loss: 0.00019746192265301943
Test Loss:  0.0002442394325044006
Valid Loss:  0.00020594852685462683
Epoch:  212  	Training Loss: 0.00019702542340382934
Test Loss:  0.00024499630671925843
Valid Loss:  0.0002060664992313832
Epoch:  213  	Training Loss: 0.00019659196550492197
Test Loss:  0.00024544523330405354
Valid Loss:  0.0002059348189504817
Epoch:  214  	Training Loss: 0.00019629736198112369
Test Loss:  0.00024572532856836915
Valid Loss:  0.0002057162782875821
Epoch:  215  	Training Loss: 0.00019603472901508212
Test Loss:  0.00024590129032731056
Valid Loss:  0.00020547877647913992
Epoch:  216  	Training Loss: 0.0001957908971235156
Test Loss:  0.0002459967799950391
Valid Loss:  0.00020523893181234598
Epoch:  217  	Training Loss: 0.0001955564075615257
Test Loss:  0.0002460278628859669
Valid Loss:  0.0002050172770395875
Epoch:  218  	Training Loss: 0.00019532867008820176
Test Loss:  0.00024600737378932536
Valid Loss:  0.000204799507628195
Epoch:  219  	Training Loss: 0.00019510550191625953
Test Loss:  0.0002459450624883175
Valid Loss:  0.0002045856963377446
Epoch:  220  	Training Loss: 0.00019488595717120916
Test Loss:  0.0002458475064486265
Valid Loss:  0.0002043752756435424
Epoch:  221  	Training Loss: 0.00019466973026283085
Test Loss:  0.0002457230584695935
Valid Loss:  0.00020416711049620062
Epoch:  222  	Training Loss: 0.00019445535144768655
Test Loss:  0.000244551949435845
Valid Loss:  0.00020285705977585167
Epoch:  223  	Training Loss: 0.00019365722255315632
Test Loss:  0.00024346340796910226
Valid Loss:  0.00020189765200484544
Epoch:  224  	Training Loss: 0.00019292085198685527
Test Loss:  0.00024244084488600492
Valid Loss:  0.0002010234456975013
Epoch:  225  	Training Loss: 0.00019220990361645818
Test Loss:  0.00024149357341229916
Valid Loss:  0.000200194917852059
Epoch:  226  	Training Loss: 0.00019152654567733407
Test Loss:  0.00024060541181825101
Valid Loss:  0.0001993993646465242
Epoch:  227  	Training Loss: 0.00019086155225522816
Test Loss:  0.00023976901138667017
Valid Loss:  0.00019862224871758372
Epoch:  228  	Training Loss: 0.00019021281332243234
Test Loss:  0.0002389790752204135
Valid Loss:  0.00019786015036515892
Epoch:  229  	Training Loss: 0.00018958204600494355
Test Loss:  0.00023825635435059667
Valid Loss:  0.0001971208257600665
Epoch:  230  	Training Loss: 0.00018897218978963792
Test Loss:  0.0002375855401623994
Valid Loss:  0.0001963992544915527
Epoch:  231  	Training Loss: 0.0001883789082057774
Test Loss:  0.00023694895207881927
Valid Loss:  0.0001956892665475607
Epoch:  232  	Training Loss: 0.00018779764650389552
Test Loss:  0.0002369723515585065
Valid Loss:  0.00019567905110307038
Epoch:  233  	Training Loss: 0.0001877739414339885
Test Loss:  0.00023698799486737698
Valid Loss:  0.00019565498223528266
Epoch:  234  	Training Loss: 0.00018775041098706424
Test Loss:  0.00023700078600086272
Valid Loss:  0.00019565047114156187
Epoch:  235  	Training Loss: 0.00018772727344185114
Test Loss:  0.00023701085592620075
Valid Loss:  0.00019564411195460707
Epoch:  236  	Training Loss: 0.00018771443865261972
Test Loss:  0.00023709741071797907
Valid Loss:  0.00019579232321120799
Epoch:  237  	Training Loss: 0.00018769869348034263
Test Loss:  0.00023714618873782456
Valid Loss:  0.00019575054466258734
Epoch:  238  	Training Loss: 0.0001876870810519904
Test Loss:  0.00023719831369817257
Valid Loss:  0.0001957532949745655
Epoch:  239  	Training Loss: 0.0001876757014542818
Test Loss:  0.0002372431627009064
Valid Loss:  0.00019574598991312087
Epoch:  240  	Training Loss: 0.000187664816621691
Test Loss:  0.0002372838498558849
Valid Loss:  0.00019574105681385845
Epoch:  241  	Training Loss: 0.0001876545138657093
Test Loss:  0.0002373201714362949
Valid Loss:  0.00019573577446863055
Epoch:  242  	Training Loss: 0.0001876438909675926
Test Loss:  0.0002373805473325774
Valid Loss:  0.0001956443884409964
Epoch:  243  	Training Loss: 0.00018749700393527746
Test Loss:  0.00023744176723994315
Valid Loss:  0.00019554290338419378
Epoch:  244  	Training Loss: 0.00018735555931925774
Test Loss:  0.00023748588864691556
Valid Loss:  0.0001954406179720536
Epoch:  245  	Training Loss: 0.00018722184177022427
Test Loss:  0.00023750757100060582
Valid Loss:  0.00019533681916072965
Epoch:  246  	Training Loss: 0.000187091194675304
Test Loss:  0.0002375089388806373
Valid Loss:  0.00019523216178640723
Epoch:  247  	Training Loss: 0.00018696280312724411
Test Loss:  0.00023748958483338356
Valid Loss:  0.00019512655853759497
Epoch:  248  	Training Loss: 0.00018683663802221417
Test Loss:  0.00023745301587041467
Valid Loss:  0.0001950206351466477
Epoch:  249  	Training Loss: 0.00018671198631636798
Test Loss:  0.00023740199685562402
Valid Loss:  0.00019491423154249787
Epoch:  250  	Training Loss: 0.00018658919725567102
Test Loss:  0.00023733556736260653
Valid Loss:  0.00019480788614600897
Epoch:  251  	Training Loss: 0.00018646742682904005
Test Loss:  0.00023725790379103273
Valid Loss:  0.00019470159895718098
Epoch:  252  	Training Loss: 0.00018634699517861009
Test Loss:  0.00023723591584712267
Valid Loss:  0.000194667954929173
Epoch:  253  	Training Loss: 0.00018632608407642692
Test Loss:  0.00023720585159026086
Valid Loss:  0.00019464243086986244
Epoch:  254  	Training Loss: 0.00018630512931849808
Test Loss:  0.0002371712471358478
Valid Loss:  0.0001946223492268473
Epoch:  255  	Training Loss: 0.0001862847711890936
Test Loss:  0.0002371340524405241
Valid Loss:  0.00019460570183582604
Epoch:  256  	Training Loss: 0.00018626434030011296
Test Loss:  0.0002370951697230339
Valid Loss:  0.00019459007307887077
Epoch:  257  	Training Loss: 0.00018624422955326736
Test Loss:  0.00023705539933871478
Valid Loss:  0.00019457591406535357
Epoch:  258  	Training Loss: 0.00018622423522174358
Test Loss:  0.0002370145230088383
Valid Loss:  0.0001945624389918521
Epoch:  259  	Training Loss: 0.0001862040371634066
Test Loss:  0.0002369733847444877
Valid Loss:  0.00019454862922430038
Epoch:  260  	Training Loss: 0.0001861841301433742
Test Loss:  0.0002369316207477823
Valid Loss:  0.00019453585264272988
Epoch:  261  	Training Loss: 0.00018616420857142657
Test Loss:  0.00023688990040682256
Valid Loss:  0.00019452279957477003
Epoch:  262  	Training Loss: 0.0001861442142399028
Test Loss:  0.00023609799973201007
Valid Loss:  0.00019310033530928195
Epoch:  263  	Training Loss: 0.0001849604886956513
Test Loss:  0.00023538946697954088
Valid Loss:  0.00019177742069587111
Epoch:  264  	Training Loss: 0.00018382890266366303
Test Loss:  0.0002347298141103238
Valid Loss:  0.00019052416610065848
Epoch:  265  	Training Loss: 0.00018274583271704614
Test Loss:  0.00023410293215420097
Valid Loss:  0.00018932900275103748
Epoch:  266  	Training Loss: 0.0001817099255276844
Test Loss:  0.00023349415278062224
Valid Loss:  0.00018818021635524929
Epoch:  267  	Training Loss: 0.00018071629165206105
Test Loss:  0.0002329003473278135
Valid Loss:  0.0001870729902293533
Epoch:  268  	Training Loss: 0.00017976228264160454
Test Loss:  0.00023231867817230523
Valid Loss:  0.00018600282783154398
Epoch:  269  	Training Loss: 0.00017884356202557683
Test Loss:  0.00023174738453235477
Valid Loss:  0.00018496395205147564
Epoch:  270  	Training Loss: 0.0001779574522515759
Test Loss:  0.00023118779063224792
Valid Loss:  0.0001839571341406554
Epoch:  271  	Training Loss: 0.00017710201791487634
Test Loss:  0.00023063889238983393
Valid Loss:  0.00018298078794032335
 55%|█████▍    | 273/500 [03:25<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:25<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:25<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:25<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:32<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:32<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:32<02:13,  1.62it/s] 57%|█████▋    | 287/500 [03:32<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:32<01:11,  2.97it/s] 58%|█████▊    | 291/500 [03:39<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:39<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:39<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:39<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:39<01:07,  2.98it/s] 60%|██████    | 301/500 [03:46<04:02,  1.22s/it] 61%|██████    | 303/500 [03:46<02:52,  1.14it/s] 61%|██████    | 305/500 [03:46<02:02,  1.59it/s] 61%|██████▏   | 307/500 [03:46<01:28,  2.17it/s] 62%|██████▏   | 309/500 [03:46<01:05,  2.93it/s] 62%|██████▏   | 311/500 [03:53<03:47,  1.21s/it] 63%|██████▎   | 313/500 [03:53<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:53<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:53<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:53<01:01,  2.95it/s] 64%|██████▍   | 321/500 [04:00<03:34,  1.20s/it] 65%|██████▍   | 323/500 [04:00<02:32,  1.16it/s] 65%|██████▌   | 325/500 [04:00<01:48,  1.61it/s] 65%|██████▌   | 327/500 [04:00<01:18,  2.20it/s] 66%|██████▌   | 329/500 [04:00<00:57,  2.95it/s] 66%|██████▌   | 331/500 [04:07<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:07<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:07<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:07<01:13,  2.22it/s]Epoch:  272  	Training Loss: 0.0001762763422448188
Test Loss:  0.00022983647068031132
Valid Loss:  0.00018256953626405448
Epoch:  273  	Training Loss: 0.0001758671714924276
Test Loss:  0.00022911952692084014
Valid Loss:  0.00018212686700280756
Epoch:  274  	Training Loss: 0.00017547524475958198
Test Loss:  0.00022846419597044587
Valid Loss:  0.00018167005327995867
Epoch:  275  	Training Loss: 0.00017509519238956273
Test Loss:  0.00022785679902881384
Valid Loss:  0.00018121102766599506
Epoch:  276  	Training Loss: 0.00017472481704317033
Test Loss:  0.00022728911426384002
Valid Loss:  0.00018075430125463754
Epoch:  277  	Training Loss: 0.00017436272173654288
Test Loss:  0.00022675454965792596
Valid Loss:  0.0001803034101612866
Epoch:  278  	Training Loss: 0.00017400769866071641
Test Loss:  0.00022624694975093007
Valid Loss:  0.0001798553130356595
Epoch:  279  	Training Loss: 0.00017365458188578486
Test Loss:  0.00022576672199647874
Valid Loss:  0.0001794137933757156
Epoch:  280  	Training Loss: 0.00017330842092633247
Test Loss:  0.0002253101411042735
Valid Loss:  0.0001789797970559448
Epoch:  281  	Training Loss: 0.00017296794976573437
Test Loss:  0.0002248755336040631
Valid Loss:  0.000178552174475044
Epoch:  282  	Training Loss: 0.00017263325571548194
Test Loss:  0.00022528477711603045
Valid Loss:  0.00017872465832624584
Epoch:  283  	Training Loss: 0.0001724622561596334
Test Loss:  0.00022558256750926375
Valid Loss:  0.00017877278150990605
Epoch:  284  	Training Loss: 0.00017234381812158972
Test Loss:  0.00022578859352506697
Valid Loss:  0.00017875805497169495
Epoch:  285  	Training Loss: 0.0001722427550703287
Test Loss:  0.0002259238826809451
Valid Loss:  0.00017871624731924385
Epoch:  286  	Training Loss: 0.0001721504668239504
Test Loss:  0.00022600340889766812
Valid Loss:  0.00017866284179035574
Epoch:  287  	Training Loss: 0.00017206216580234468
Test Loss:  0.000226053933147341
Valid Loss:  0.00017861236119642854
Epoch:  288  	Training Loss: 0.00017197603301610798
Test Loss:  0.0002260655746795237
Valid Loss:  0.0001785556523827836
Epoch:  289  	Training Loss: 0.0001718930434435606
Test Loss:  0.0002260445326101035
Valid Loss:  0.0001784971245797351
Epoch:  290  	Training Loss: 0.00017181193106807768
Test Loss:  0.0002259981702081859
Valid Loss:  0.00017843788373284042
Epoch:  291  	Training Loss: 0.0001717327395454049
Test Loss:  0.00022592997993342578
Valid Loss:  0.00017837935592979193
Epoch:  292  	Training Loss: 0.0001716547558316961
Test Loss:  0.00022572011221200228
Valid Loss:  0.0001782446342986077
Epoch:  293  	Training Loss: 0.00017152362852357328
Test Loss:  0.00022550566063728184
Valid Loss:  0.0001781250030035153
Epoch:  294  	Training Loss: 0.00017139417468570173
Test Loss:  0.00022528739646077156
Valid Loss:  0.00017801145440898836
Epoch:  295  	Training Loss: 0.00017126584134530276
Test Loss:  0.00022506661480292678
Valid Loss:  0.00017790183483157307
Epoch:  296  	Training Loss: 0.00017113928333856165
Test Loss:  0.0002248436794616282
Valid Loss:  0.0001777940196916461
Epoch:  297  	Training Loss: 0.00017101402045227587
Test Loss:  0.00022462059860117733
Valid Loss:  0.0001776874269125983
Epoch:  298  	Training Loss: 0.0001708900381345302
Test Loss:  0.0002244043571408838
Valid Loss:  0.00017758172180037946
Epoch:  299  	Training Loss: 0.00017076745280064642
Test Loss:  0.00022418811568059027
Valid Loss:  0.00017747751553542912
Epoch:  300  	Training Loss: 0.00017064600251615047
Test Loss:  0.00022397175780497491
Valid Loss:  0.00017737381858751178
Epoch:  301  	Training Loss: 0.0001705259783193469
Test Loss:  0.00022375595290213823
Valid Loss:  0.0001772706164047122
Epoch:  302  	Training Loss: 0.00017040708917193115
Test Loss:  0.00022353926033247262
Valid Loss:  0.00017697070143185556
Epoch:  303  	Training Loss: 0.00017034418124239892
Test Loss:  0.00022348023776430637
Valid Loss:  0.00017699737509246916
Epoch:  304  	Training Loss: 0.00017029109585564584
Test Loss:  0.00022337297559715807
Valid Loss:  0.00017695924907457083
Epoch:  305  	Training Loss: 0.00017023991676978767
Test Loss:  0.00022326257021632046
Valid Loss:  0.0001769347582012415
Epoch:  306  	Training Loss: 0.000170189916389063
Test Loss:  0.00022314059606287628
Valid Loss:  0.000176921472302638
Epoch:  307  	Training Loss: 0.00017014099285006523
Test Loss:  0.00022301278659142554
Valid Loss:  0.0001769107475411147
Epoch:  308  	Training Loss: 0.00017009308794513345
Test Loss:  0.0002228777448181063
Valid Loss:  0.0001769012596923858
Epoch:  309  	Training Loss: 0.00017004628898575902
Test Loss:  0.0002227383229183033
Valid Loss:  0.00017689159722067416
Epoch:  310  	Training Loss: 0.0001700003631412983
Test Loss:  0.00022259580146055669
Valid Loss:  0.0001768818765413016
Epoch:  311  	Training Loss: 0.00016995437908917665
Test Loss:  0.00022247196466196328
Valid Loss:  0.00017688263324089348
Epoch:  312  	Training Loss: 0.0001699067943263799
Test Loss:  0.00022220965183805674
Valid Loss:  0.00017641599697526544
Epoch:  313  	Training Loss: 0.00016943852824624628
Test Loss:  0.00022186804562807083
Valid Loss:  0.00017586417379789054
Epoch:  314  	Training Loss: 0.00016897040768526495
Test Loss:  0.00022151773737277836
Valid Loss:  0.0001753279793774709
Epoch:  315  	Training Loss: 0.00016850841348059475
Test Loss:  0.00022115375031717122
Valid Loss:  0.00017479622329119593
Epoch:  316  	Training Loss: 0.00016805215273052454
Test Loss:  0.00022077867470216006
Valid Loss:  0.00017427021521143615
Epoch:  317  	Training Loss: 0.00016760145081207156
Test Loss:  0.00022039581381250173
Valid Loss:  0.0001737504790071398
Epoch:  318  	Training Loss: 0.00016715613310225308
Test Loss:  0.00022000596800353378
Valid Loss:  0.00017323557403869927
Epoch:  319  	Training Loss: 0.00016671587945893407
Test Loss:  0.00021961012680549175
Valid Loss:  0.0001727261405903846
Epoch:  320  	Training Loss: 0.0001662807771936059
Test Loss:  0.00021920882863923907
Valid Loss:  0.0001722209999570623
Epoch:  321  	Training Loss: 0.00016585076809860766
Test Loss:  0.00021880443091504276
Valid Loss:  0.0001717211853247136
Epoch:  322  	Training Loss: 0.00016542575031053275
Test Loss:  0.0002187269419664517
Valid Loss:  0.00017164391465485096
Epoch:  323  	Training Loss: 0.0001653932995395735
Test Loss:  0.00021866968018002808
Valid Loss:  0.00017160770948976278
Epoch:  324  	Training Loss: 0.0001653623767197132
Test Loss:  0.00021861790446564555
Valid Loss:  0.0001715858088573441
Epoch:  325  	Training Loss: 0.00016533196321688592
Test Loss:  0.00021856780222151428
Valid Loss:  0.000171568724908866
Epoch:  326  	Training Loss: 0.00016530169523321092
Test Loss:  0.00021851655037607998
Valid Loss:  0.00017155299428850412
Epoch:  327  	Training Loss: 0.00016527171828784049
Test Loss:  0.00021846519666723907
Valid Loss:  0.00017153668159153312
Epoch:  328  	Training Loss: 0.00016524165403097868
Test Loss:  0.00021841234411112964
Valid Loss:  0.00017152019427157938
Epoch:  329  	Training Loss: 0.00016521193902008235
Test Loss:  0.0002183588221669197
Valid Loss:  0.00017150372150354087
Epoch:  330  	Training Loss: 0.00016518229676876217
Test Loss:  0.00021830441255588084
Valid Loss:  0.00017148774350062013
Epoch:  331  	Training Loss: 0.000165152974659577
Test Loss:  0.00021824834402650595
Valid Loss:  0.0001714720856398344
Epoch:  332  	Training Loss: 0.00016512389993295074
Test Loss:  0.00021767534781247377
Valid Loss:  0.00017163093434646726
Epoch:  333  	Training Loss: 0.00016491618589498103
Test Loss:  0.00021719388314522803
Valid Loss:  0.0001714258105494082
Epoch:  334  	Training Loss: 0.00016473379218950868
Test Loss:  0.00021675697644241154
Valid Loss:  0.0001712455414235592
Epoch:  335  	Training Loss: 0.00016455454169772565
Test Loss:  0.00021635719167534262
Valid Loss:  0.0001710655924398452
Epoch:  336  	Training Loss: 0.00016437713929917663
Test Loss:  0.0002159850555472076
Valid Loss:  0.00017088628374040127
Epoch:  337  	Training Loss: 0.00016420168685726821
Test Loss:  0.00021563202608376741
Valid Loss:  0.0001707068586256355
Epoch:  338  	Training Loss: 0.00016402835899498314
Test Loss:  0.00021529686637222767
Valid Loss:  0.00017053076589945704
 68%|██████▊   | 339/500 [04:07<00:53,  2.98it/s] 68%|██████▊   | 341/500 [04:13<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:14<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:14<01:34,  1.63it/s] 69%|██████▉   | 347/500 [04:14<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:14<00:50,  3.00it/s] 70%|███████   | 351/500 [04:20<02:54,  1.17s/it] 71%|███████   | 353/500 [04:20<02:03,  1.19it/s] 71%|███████   | 355/500 [04:20<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:21<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:21<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:27<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:27<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:27<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:27<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:28<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:34<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:34<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:34<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:34<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:34<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:41<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:41<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:41<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:41<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:41<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:47<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:48<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:48<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:48<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:48<00:33,  3.01it/s] 80%|████████  | 401/500 [04:54<01:55,  1.17s/it] 81%|████████  | 403/500 [04:54<01:21,  1.19it/s] 81%|████████  | 405/500 [04:55<00:57,  1.65it/s]Epoch:  339  	Training Loss: 0.00016385639901272953
Test Loss:  0.00021497681154869497
Valid Loss:  0.00017035497876349837
Epoch:  340  	Training Loss: 0.00016368513752240688
Test Loss:  0.0002146667247870937
Valid Loss:  0.00017017993377521634
Epoch:  341  	Training Loss: 0.00016351448721252382
Test Loss:  0.00021436488896142691
Valid Loss:  0.00017000490333884954
Epoch:  342  	Training Loss: 0.00016334386600647122
Test Loss:  0.00021422766440082341
Valid Loss:  0.0001698892010608688
Epoch:  343  	Training Loss: 0.00016332155792042613
Test Loss:  0.0002140984870493412
Valid Loss:  0.0001698164560366422
Epoch:  344  	Training Loss: 0.00016330479411408305
Test Loss:  0.00021397523232735693
Valid Loss:  0.00016976917686406523
Epoch:  345  	Training Loss: 0.00016329032951034606
Test Loss:  0.0002138554264092818
Valid Loss:  0.0001697369443718344
Epoch:  346  	Training Loss: 0.00016327676712535322
Test Loss:  0.00021373922936618328
Valid Loss:  0.00016971440345514566
Epoch:  347  	Training Loss: 0.00016326394688803703
Test Loss:  0.00021362659754231572
Valid Loss:  0.00016969721764326096
Epoch:  348  	Training Loss: 0.00016325147589668632
Test Loss:  0.0002135174290742725
Valid Loss:  0.00016968429554253817
Epoch:  349  	Training Loss: 0.0001632395142223686
Test Loss:  0.00021341131650842726
Valid Loss:  0.0001696734398137778
Epoch:  350  	Training Loss: 0.000163227814482525
Test Loss:  0.00021330795425456017
Valid Loss:  0.00016966371913440526
Epoch:  351  	Training Loss: 0.00016321611474268138
Test Loss:  0.0002132080844603479
Valid Loss:  0.00016965545364655554
Epoch:  352  	Training Loss: 0.00016320479335263371
Test Loss:  0.00021340689272619784
Valid Loss:  0.00016976919141598046
Epoch:  353  	Training Loss: 0.00016313367814291269
Test Loss:  0.00021353823831304908
Valid Loss:  0.00016984756803140044
Epoch:  354  	Training Loss: 0.00016308017075061798
Test Loss:  0.00021361859398894012
Valid Loss:  0.00016989588038995862
Epoch:  355  	Training Loss: 0.00016303623851854354
Test Loss:  0.00021366108558140695
Valid Loss:  0.00016992061864584684
Epoch:  356  	Training Loss: 0.00016299649723805487
Test Loss:  0.00021367688896134496
Valid Loss:  0.00016992847668007016
Epoch:  357  	Training Loss: 0.00016295909881591797
Test Loss:  0.00021367376029957086
Valid Loss:  0.00016992373275570571
Epoch:  358  	Training Loss: 0.00016292337386403233
Test Loss:  0.0002136569528374821
Valid Loss:  0.00016990916628856212
Epoch:  359  	Training Loss: 0.00016288782353512943
Test Loss:  0.00021363096311688423
Valid Loss:  0.0001698876585578546
Epoch:  360  	Training Loss: 0.0001628526661079377
Test Loss:  0.0002135986287612468
Valid Loss:  0.000169860984897241
Epoch:  361  	Training Loss: 0.000162818148965016
Test Loss:  0.00021356213255785406
Valid Loss:  0.00016983086243271828
Epoch:  362  	Training Loss: 0.0001627834135433659
Test Loss:  0.00021314225159585476
Valid Loss:  0.0001694087841315195
Epoch:  363  	Training Loss: 0.00016264771693386137
Test Loss:  0.0002126244071405381
Valid Loss:  0.0001692288788035512
Epoch:  364  	Training Loss: 0.0001625430304557085
Test Loss:  0.0002121252764482051
Valid Loss:  0.0001691044308245182
Epoch:  365  	Training Loss: 0.00016244681319221854
Test Loss:  0.00021166780788917094
Valid Loss:  0.00016899763431865722
Epoch:  366  	Training Loss: 0.00016235643124673516
Test Loss:  0.0002112525689881295
Valid Loss:  0.00016889914695639163
Epoch:  367  	Training Loss: 0.00016227092419285327
Test Loss:  0.00021087622735649347
Valid Loss:  0.00016880582552403212
Epoch:  368  	Training Loss: 0.00016218938981182873
Test Loss:  0.00021053481032140553
Valid Loss:  0.00016871692787390202
Epoch:  369  	Training Loss: 0.00016211096954066306
Test Loss:  0.0002102223807014525
Valid Loss:  0.00016863219207152724
Epoch:  370  	Training Loss: 0.00016203508130274713
Test Loss:  0.00020993780344724655
Valid Loss:  0.00016855062858667225
Epoch:  371  	Training Loss: 0.00016196137585211545
Test Loss:  0.00020967720774933696
Valid Loss:  0.00016847137885633856
Epoch:  372  	Training Loss: 0.00016188918380066752
Test Loss:  0.0002096173702739179
Valid Loss:  0.00016841807519085705
Epoch:  373  	Training Loss: 0.0001618267851881683
Test Loss:  0.00020955603395123035
Valid Loss:  0.000168364291312173
Epoch:  374  	Training Loss: 0.00016176438657566905
Test Loss:  0.00020949458121322095
Valid Loss:  0.00016831034736242145
Epoch:  375  	Training Loss: 0.00016170240996871144
Test Loss:  0.00020943213894497603
Valid Loss:  0.0001682561996858567
Epoch:  376  	Training Loss: 0.00016164089902304113
Test Loss:  0.00020937007502652705
Valid Loss:  0.0001682015135884285
Epoch:  377  	Training Loss: 0.00016157954814843833
Test Loss:  0.00020930831669829786
Valid Loss:  0.0001681491849012673
Epoch:  378  	Training Loss: 0.00016152096213772893
Test Loss:  0.00020924655837006867
Valid Loss:  0.0001680963032413274
Epoch:  379  	Training Loss: 0.00016146240523084998
Test Loss:  0.00020918401423841715
Valid Loss:  0.00016804333426989615
Epoch:  380  	Training Loss: 0.00016140428488142788
Test Loss:  0.00020912110630888492
Valid Loss:  0.00016798998694866896
Epoch:  381  	Training Loss: 0.00016134614998009056
Test Loss:  0.00020905745623167604
Valid Loss:  0.0001679375272942707
Epoch:  382  	Training Loss: 0.00016128855349961668
Test Loss:  0.00020893797045573592
Valid Loss:  0.00016782330931164324
Epoch:  383  	Training Loss: 0.00016121142834890634
Test Loss:  0.00020882065291516483
Valid Loss:  0.0001677148975431919
Epoch:  384  	Training Loss: 0.00016113452147692442
Test Loss:  0.0002087050670525059
Valid Loss:  0.00016760986181907356
Epoch:  385  	Training Loss: 0.00016105815302580595
Test Loss:  0.0002085912856273353
Valid Loss:  0.00016750807117205113
Epoch:  386  	Training Loss: 0.0001609817409189418
Test Loss:  0.00020847951236646622
Valid Loss:  0.00016740814317017794
Epoch:  387  	Training Loss: 0.00016090627468656749
Test Loss:  0.00020837041665799916
Valid Loss:  0.0001673096267040819
Epoch:  388  	Training Loss: 0.0001608308230061084
Test Loss:  0.00020826308173127472
Valid Loss:  0.00016721220163162798
Epoch:  389  	Training Loss: 0.0001607552112545818
Test Loss:  0.0002081549318972975
Valid Loss:  0.0001671149511821568
Epoch:  390  	Training Loss: 0.00016067890101112425
Test Loss:  0.0002080483827739954
Valid Loss:  0.00016701800632290542
Epoch:  391  	Training Loss: 0.0001606025907676667
Test Loss:  0.00020794308511540294
Valid Loss:  0.00016692183271516114
Epoch:  392  	Training Loss: 0.0001605267752893269
Test Loss:  0.00020825534011237323
Valid Loss:  0.00016707778559066355
Epoch:  393  	Training Loss: 0.00016046369273681194
Test Loss:  0.00020849038264714181
Valid Loss:  0.00016717555990908295
Epoch:  394  	Training Loss: 0.0001604239660082385
Test Loss:  0.0002086644381051883
Valid Loss:  0.000167232530657202
Epoch:  395  	Training Loss: 0.0001603944692760706
Test Loss:  0.00020879320800304413
Valid Loss:  0.00016726308967918158
Epoch:  396  	Training Loss: 0.00016036967281252146
Test Loss:  0.00020888893050141633
Valid Loss:  0.00016727737965993583
Epoch:  397  	Training Loss: 0.00016034765576478094
Test Loss:  0.00020895875059068203
Valid Loss:  0.00016728094487916678
Epoch:  398  	Training Loss: 0.00016032684652600437
Test Loss:  0.00020900882373098284
Valid Loss:  0.0001672783400863409
Epoch:  399  	Training Loss: 0.00016030723054427654
Test Loss:  0.00020904226403217763
Valid Loss:  0.00016727231559343636
Epoch:  400  	Training Loss: 0.00016028829850256443
Test Loss:  0.000209062869544141
Valid Loss:  0.00016726403555367142
Epoch:  401  	Training Loss: 0.00016027039964683354
Test Loss:  0.00020907296857330948
Valid Loss:  0.00016725523164495826
Epoch:  402  	Training Loss: 0.00016025229706428945
Test Loss:  0.00020892491738777608
Valid Loss:  0.00016712106298655272
Epoch:  403  	Training Loss: 0.0001602088159415871
Test Loss:  0.00020876989583484828
Valid Loss:  0.00016702331777196378
Epoch:  404  	Training Loss: 0.00016016984591260552
Test Loss:  0.00020861317170783877
Valid Loss:  0.000166948331752792
Epoch:  405  	Training Loss: 0.00016013314598239958
Test Loss:  0.0002084576990455389
Valid Loss:  0.00016688715550117195
 81%|████████▏ | 407/500 [04:55<00:41,  2.26it/s] 82%|████████▏ | 409/500 [04:55<00:30,  3.03it/s] 82%|████████▏ | 411/500 [05:01<01:43,  1.17s/it] 83%|████████▎ | 413/500 [05:01<01:13,  1.19it/s] 83%|████████▎ | 415/500 [05:01<00:51,  1.65it/s] 83%|████████▎ | 417/500 [05:01<00:36,  2.25it/s] 84%|████████▍ | 419/500 [05:02<00:26,  3.03it/s] 84%|████████▍ | 421/500 [05:08<01:32,  1.18s/it] 85%|████████▍ | 423/500 [05:08<01:04,  1.19it/s] 85%|████████▌ | 425/500 [05:08<00:45,  1.64it/s] 85%|████████▌ | 427/500 [05:08<00:32,  2.24it/s] 86%|████████▌ | 429/500 [05:08<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:15<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:15<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:15<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:15<00:28,  2.25it/s] 88%|████████▊ | 439/500 [05:15<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:22<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:22<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:22<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:22<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:22<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:28<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:28<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:29<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:29<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:29<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:35<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:35<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:35<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:36<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:36<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:42<00:33,  1.16s/it]Epoch:  406  	Training Loss: 0.00016009731916710734
Test Loss:  0.00020830592256970704
Valid Loss:  0.0001668347103986889
Epoch:  407  	Training Loss: 0.00016006290388759226
Test Loss:  0.00020815717289224267
Valid Loss:  0.00016678762040100992
Epoch:  408  	Training Loss: 0.00016002854681573808
Test Loss:  0.00020801372011192143
Valid Loss:  0.00016674434300512075
Epoch:  409  	Training Loss: 0.00015999488823581487
Test Loss:  0.00020787559333257377
Valid Loss:  0.0001667034812271595
Epoch:  410  	Training Loss: 0.00015996178262867033
Test Loss:  0.00020774235599674284
Valid Loss:  0.0001666647440288216
Epoch:  411  	Training Loss: 0.00015992909902706742
Test Loss:  0.0002076139353448525
Valid Loss:  0.0001666263851802796
Epoch:  412  	Training Loss: 0.00015989647363312542
Test Loss:  0.00020752777345478535
Valid Loss:  0.00016647521988488734
Epoch:  413  	Training Loss: 0.00015985175559762865
Test Loss:  0.0002074890653602779
Valid Loss:  0.00016641007096040994
Epoch:  414  	Training Loss: 0.00015981044271029532
Test Loss:  0.00020745908841490746
Valid Loss:  0.00016636296641081572
Epoch:  415  	Training Loss: 0.00015976920258253813
Test Loss:  0.00020743106142617762
Valid Loss:  0.00016631896141916513
Epoch:  416  	Training Loss: 0.0001597282534930855
Test Loss:  0.00020740208856295794
Valid Loss:  0.0001662758586462587
Epoch:  417  	Training Loss: 0.00015968680963851511
Test Loss:  0.00020737355225719512
Valid Loss:  0.00016623278497718275
Epoch:  418  	Training Loss: 0.00015964600606821477
Test Loss:  0.00020734421559609473
Valid Loss:  0.00016619008965790272
Epoch:  419  	Training Loss: 0.0001596049260115251
Test Loss:  0.00020731452968902886
Valid Loss:  0.00016614721971563995
Epoch:  420  	Training Loss: 0.00015956413699313998
Test Loss:  0.000207284843781963
Valid Loss:  0.000166104466188699
Epoch:  421  	Training Loss: 0.00015952333342283964
Test Loss:  0.00020725384820252657
Valid Loss:  0.00016606165445409715
Epoch:  422  	Training Loss: 0.00015948255895636976
Test Loss:  0.00020697589206974953
Valid Loss:  0.00016606776625849307
Epoch:  423  	Training Loss: 0.00015941585297696292
Test Loss:  0.00020675624546129256
Valid Loss:  0.0001660558336880058
Epoch:  424  	Training Loss: 0.0001593547931406647
Test Loss:  0.00020657922141253948
Valid Loss:  0.00016603103722445667
Epoch:  425  	Training Loss: 0.00015929786604829133
Test Loss:  0.00020643103925976902
Valid Loss:  0.00016599599621258676
Epoch:  426  	Training Loss: 0.0001592420449014753
Test Loss:  0.00020630379731301218
Valid Loss:  0.00016595401393715292
Epoch:  427  	Training Loss: 0.00015918692224659026
Test Loss:  0.00020619101996999234
Valid Loss:  0.00016590645827818662
Epoch:  428  	Training Loss: 0.0001591322652529925
Test Loss:  0.000206088661798276
Valid Loss:  0.00016585506091360003
Epoch:  429  	Training Loss: 0.00015907794295344502
Test Loss:  0.00020599440904334188
Valid Loss:  0.00016580085502937436
Epoch:  430  	Training Loss: 0.0001590252504684031
Test Loss:  0.00020590730127878487
Valid Loss:  0.00016574724577367306
Epoch:  431  	Training Loss: 0.00015897341654635966
Test Loss:  0.00020582388970069587
Valid Loss:  0.00016569157014600933
Epoch:  432  	Training Loss: 0.00015892210649326444
Test Loss:  0.00020571416825987399
Valid Loss:  0.00016557585331611335
Epoch:  433  	Training Loss: 0.00015889687347225845
Test Loss:  0.00020559453696478158
Valid Loss:  0.00016551805310882628
Epoch:  434  	Training Loss: 0.00015887533663772047
Test Loss:  0.0002054755896097049
Valid Loss:  0.00016548209532629699
Epoch:  435  	Training Loss: 0.000158854469191283
Test Loss:  0.00020536049851216376
Valid Loss:  0.00016545520338695496
Epoch:  436  	Training Loss: 0.00015883406740613282
Test Loss:  0.00020525127183645964
Valid Loss:  0.00016543128003831953
Epoch:  437  	Training Loss: 0.00015881413128226995
Test Loss:  0.0002051482442766428
Valid Loss:  0.000165409262990579
Epoch:  438  	Training Loss: 0.00015879413695074618
Test Loss:  0.0002050501643680036
Valid Loss:  0.00016538813360966742
Epoch:  439  	Training Loss: 0.00015877452096901834
Test Loss:  0.00020495764329098165
Valid Loss:  0.00016536752809770405
Epoch:  440  	Training Loss: 0.00015875518147367984
Test Loss:  0.0002048704627668485
Valid Loss:  0.0001653472863836214
Epoch:  441  	Training Loss: 0.00015873595839366317
Test Loss:  0.00020478788064792752
Valid Loss:  0.00016532736481167376
Epoch:  442  	Training Loss: 0.00015871660434640944
Test Loss:  0.00020504611893557012
Valid Loss:  0.0001654504449106753
Epoch:  443  	Training Loss: 0.00015864305896684527
Test Loss:  0.00020519275858532637
Valid Loss:  0.00016542934463359416
Epoch:  444  	Training Loss: 0.00015858214464969933
Test Loss:  0.00020527729066088796
Valid Loss:  0.0001654048974160105
Epoch:  445  	Training Loss: 0.00015852654178161174
Test Loss:  0.00020531428162939847
Valid Loss:  0.0001653802755754441
Epoch:  446  	Training Loss: 0.00015847370377741754
Test Loss:  0.0002053130738204345
Valid Loss:  0.0001653567305766046
Epoch:  447  	Training Loss: 0.00015842283028177917
Test Loss:  0.00020530739857349545
Valid Loss:  0.0001653448271099478
Epoch:  448  	Training Loss: 0.0001583700650371611
Test Loss:  0.0002052683848887682
Valid Loss:  0.00016532228619325906
Epoch:  449  	Training Loss: 0.00015831936616450548
Test Loss:  0.0002052083727903664
Valid Loss:  0.00016529914864804596
Epoch:  450  	Training Loss: 0.00015826952585484833
Test Loss:  0.00020512928313110024
Valid Loss:  0.00016527617117390037
Epoch:  451  	Training Loss: 0.0001582209806656465
Test Loss:  0.00020503744599409401
Valid Loss:  0.00016525288810953498
Epoch:  452  	Training Loss: 0.00015817304665688425
Test Loss:  0.0002048737951554358
Valid Loss:  0.00016502424841746688
Epoch:  453  	Training Loss: 0.00015813755453564227
Test Loss:  0.00020481928368099034
Valid Loss:  0.00016501075879205018
Epoch:  454  	Training Loss: 0.00015810891636647284
Test Loss:  0.00020475976634770632
Valid Loss:  0.000164983473950997
Epoch:  455  	Training Loss: 0.00015808036550879478
Test Loss:  0.00020470054005272686
Valid Loss:  0.00016495733871124685
Epoch:  456  	Training Loss: 0.00015805162547621876
Test Loss:  0.0002046418667305261
Valid Loss:  0.00016493105795234442
Epoch:  457  	Training Loss: 0.00015802306006662548
Test Loss:  0.00020458362996578217
Valid Loss:  0.00016490543202962726
Epoch:  458  	Training Loss: 0.00015799448010511696
Test Loss:  0.0002045256260316819
Valid Loss:  0.00016487899119965732
Epoch:  459  	Training Loss: 0.00015796620573382825
Test Loss:  0.0002044682769337669
Valid Loss:  0.00016485310334246606
Epoch:  460  	Training Loss: 0.00015793737838976085
Test Loss:  0.00020441089873202145
Valid Loss:  0.00016482692444697022
Epoch:  461  	Training Loss: 0.00015790911857038736
Test Loss:  0.00020435400074347854
Valid Loss:  0.0001648007455514744
Epoch:  462  	Training Loss: 0.00015788045129738748
Test Loss:  0.00020444199617486447
Valid Loss:  0.00016490195412188768
Epoch:  463  	Training Loss: 0.00015783200797159225
Test Loss:  0.0002044119028141722
Valid Loss:  0.00016484505613334477
Epoch:  464  	Training Loss: 0.0001577868388267234
Test Loss:  0.00020439137006178498
Valid Loss:  0.0001648324978305027
Epoch:  465  	Training Loss: 0.00015774319763295352
Test Loss:  0.0002043495187535882
Valid Loss:  0.00016480848717037588
Epoch:  466  	Training Loss: 0.0001577002985868603
Test Loss:  0.00020429727737791836
Valid Loss:  0.00016478676116093993
Epoch:  467  	Training Loss: 0.0001576579816173762
Test Loss:  0.00020423431124072522
Valid Loss:  0.00016476483142469078
Epoch:  468  	Training Loss: 0.0001576164795551449
Test Loss:  0.00020416354527696967
Valid Loss:  0.00016474277072120458
Epoch:  469  	Training Loss: 0.00015757561777718365
Test Loss:  0.00020408570708241314
Valid Loss:  0.00016472063725814223
Epoch:  470  	Training Loss: 0.00015753507614135742
Test Loss:  0.00020400146604515612
Valid Loss:  0.00016469851834699512
Epoch:  471  	Training Loss: 0.0001574950001668185
Test Loss:  0.00020391331054270267
Valid Loss:  0.00016467605018988252
Epoch:  472  	Training Loss: 0.00015745517157483846
Test Loss:  0.0002042176784016192
Valid Loss:  0.00016488890105392784
 95%|█████████▍| 473/500 [05:42<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:42<00:15,  1.66it/s] 95%|█████████▌| 477/500 [05:42<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:42<00:06,  3.04it/s] 96%|█████████▌| 481/500 [05:49<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:49<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:49<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:49<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:49<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:56<00:10,  1.19s/it] 98%|█████████▊| 492/500 [05:56<00:08,  1.01s/it] 99%|█████████▉| 494/500 [05:56<00:04,  1.45it/s] 99%|█████████▉| 496/500 [05:56<00:01,  2.05it/s]100%|█████████▉| 498/500 [05:56<00:00,  2.81it/s]100%|██████████| 500/500 [05:56<00:00,  3.76it/s]100%|██████████| 500/500 [05:56<00:00,  1.40it/s]
Epoch:  473  	Training Loss: 0.00015735655324533582
Test Loss:  0.0002043919375864789
Valid Loss:  0.00016498661716468632
Epoch:  474  	Training Loss: 0.00015729706501588225
Test Loss:  0.00020448473514989018
Valid Loss:  0.00016501624486409128
Epoch:  475  	Training Loss: 0.00015724786499049515
Test Loss:  0.00020453018078114837
Valid Loss:  0.00016500988567713648
Epoch:  476  	Training Loss: 0.0001572024484630674
Test Loss:  0.000204545067390427
Valid Loss:  0.0001649847545195371
Epoch:  477  	Training Loss: 0.0001571577158756554
Test Loss:  0.00020454166224226356
Valid Loss:  0.00016495150339324027
Epoch:  478  	Training Loss: 0.00015711388550698757
Test Loss:  0.00020452517492230982
Valid Loss:  0.00016491337737534195
Epoch:  479  	Training Loss: 0.0001570703461766243
Test Loss:  0.00020449853036552668
Valid Loss:  0.00016487411630805582
Epoch:  480  	Training Loss: 0.00015702733071520925
Test Loss:  0.00020446418784558773
Valid Loss:  0.00016483372019138187
Epoch:  481  	Training Loss: 0.00015698440256528556
Test Loss:  0.00020442654204089195
Valid Loss:  0.00016479460464324802
Epoch:  482  	Training Loss: 0.00015694140165578574
Test Loss:  0.00020348740508779883
Valid Loss:  0.00016381127352360636
Epoch:  483  	Training Loss: 0.00015648048429284245
Test Loss:  0.0002027254377026111
Valid Loss:  0.00016344762116204947
Epoch:  484  	Training Loss: 0.00015604562941007316
Test Loss:  0.00020203503663651645
Valid Loss:  0.00016289856284856796
Epoch:  485  	Training Loss: 0.00015562075714115053
Test Loss:  0.0002014141937252134
Valid Loss:  0.0001624239084776491
Epoch:  486  	Training Loss: 0.00015520268061663955
Test Loss:  0.00020083965500816703
Valid Loss:  0.00016193423653021455
Epoch:  487  	Training Loss: 0.0001547908177599311
Test Loss:  0.0002003015688387677
Valid Loss:  0.00016145885456353426
Epoch:  488  	Training Loss: 0.00015438116679433733
Test Loss:  0.00019978632917627692
Valid Loss:  0.0001609778410056606
Epoch:  489  	Training Loss: 0.00015397058450616896
Test Loss:  0.0001992927718674764
Valid Loss:  0.0001605037832632661
Epoch:  490  	Training Loss: 0.00015356510994024575
Test Loss:  0.0001988160947803408
Valid Loss:  0.0001600344548933208
Epoch:  491  	Training Loss: 0.0001531642919871956
Test Loss:  0.00019835335842799395
Valid Loss:  0.0001595708599779755
Epoch:  492  	Training Loss: 0.00015276885824277997
Test Loss:  0.0001984261762117967
Valid Loss:  0.0001595490175532177
Epoch:  493  	Training Loss: 0.00015271574375219643
Test Loss:  0.00019847374642267823
Valid Loss:  0.0001595144422026351
Epoch:  494  	Training Loss: 0.0001526646374259144
Test Loss:  0.0001985043491004035
Valid Loss:  0.00015947141218930483
Epoch:  495  	Training Loss: 0.00015261443331837654
Test Loss:  0.00019852345576509833
Valid Loss:  0.00015942227037157863
Epoch:  496  	Training Loss: 0.00015256498591043055
Test Loss:  0.00019853404955938458
Valid Loss:  0.00015937005809973925
Epoch:  497  	Training Loss: 0.00015251671720761806
Test Loss:  0.00019853966659866273
Valid Loss:  0.00015931646339595318
Epoch:  498  	Training Loss: 0.0001524703111499548
Test Loss:  0.00019854280981235206
Valid Loss:  0.00015926329069770873
Epoch:  499  	Training Loss: 0.00015242607332766056
Test Loss:  0.00019854199490509927
Valid Loss:  0.0001592087501194328
Epoch:  500  	Training Loss: 0.00015238241758197546
Test Loss:  0.00019853870617225766
Valid Loss:  0.0001591542677488178
seed is  11
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.13it/s]  1%|          | 4/500 [00:00<00:30, 16.53it/s]  1%|          | 6/500 [00:00<00:29, 16.66it/s]  2%|▏         | 8/500 [00:00<00:29, 16.65it/s]  2%|▏         | 10/500 [00:00<00:29, 16.75it/s]  2%|▏         | 12/500 [00:00<00:29, 16.66it/s]  3%|▎         | 14/500 [00:00<00:29, 16.65it/s]  3%|▎         | 16/500 [00:00<00:29, 16.61it/s]  4%|▎         | 18/500 [00:01<00:29, 16.54it/s]  4%|▍         | 20/500 [00:01<00:29, 16.48it/s]  4%|▍         | 22/500 [00:01<00:28, 16.55it/s]  5%|▍         | 24/500 [00:01<00:28, 16.60it/s]  5%|▌         | 26/500 [00:01<00:28, 16.52it/s]  6%|▌         | 28/500 [00:01<00:28, 16.50it/s]  6%|▌         | 30/500 [00:01<00:28, 16.61it/s]  6%|▋         | 32/500 [00:01<00:28, 16.56it/s]  7%|▋         | 34/500 [00:02<00:28, 16.48it/s]  7%|▋         | 36/500 [00:02<00:28, 16.53it/s]  8%|▊         | 38/500 [00:02<00:28, 16.45it/s]  8%|▊         | 40/500 [00:02<00:28, 16.37it/s]  8%|▊         | 42/500 [00:02<00:27, 16.45it/s]  9%|▉         | 44/500 [00:02<00:27, 16.53it/s]  9%|▉         | 46/500 [00:02<00:27, 16.49it/s] 10%|▉         | 48/500 [00:02<00:27, 16.43it/s] 10%|█         | 50/500 [00:03<00:27, 16.46it/s] 10%|█         | 52/500 [00:03<00:27, 16.54it/s] 11%|█         | 54/500 [00:03<00:27, 16.43it/s] 11%|█         | 56/500 [00:03<00:27, 16.43it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.46it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.53it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.56it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.59it/s] 13%|█▎        | 66/500 [00:03<00:26, 16.48it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.50it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.51it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.51it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.53it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.51it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.56it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.58it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.60it/s] 17%|█▋        | 84/500 [00:05<00:24, 16.65it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.49it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.42it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.50it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.50it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.41it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.41it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.41it/s] 20%|██        | 100/500 [00:06<00:24, 16.38it/s] 20%|██        | 102/500 [00:06<00:24, 16.28it/s] 21%|██        | 104/500 [00:06<00:24, 16.28it/s] 21%|██        | 106/500 [00:06<00:24, 16.29it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.43it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.45it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.43it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.37it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.35it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.44it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.56it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.46it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.49it/s]Epoch:  1  	Training Loss: 0.031122222542762756
Test Loss:  115.29090118408203
Valid Loss:  115.68614196777344
Epoch:  2  	Training Loss: 115.55762481689453
Test Loss:  1338066304.0
Valid Loss:  1330588928.0
Epoch:  3  	Training Loss: 1332957440.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.55it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.62it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.60it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.40it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.35it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.32it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.29it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.42it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.53it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.57it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.55it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.29it/s] 30%|███       | 150/500 [00:09<00:21, 16.25it/s] 30%|███       | 152/500 [00:09<00:21, 16.21it/s] 31%|███       | 154/500 [00:09<00:21, 16.26it/s] 31%|███       | 156/500 [00:09<00:21, 16.37it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.45it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.54it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.58it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.61it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.63it/s] 34%|███▎      | 168/500 [00:10<00:19, 16.66it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.32it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.37it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.41it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.45it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.47it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.49it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.50it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.41it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.45it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.48it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.54it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.52it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.60it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.52it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.43it/s] 40%|████      | 200/500 [00:12<00:18, 16.42it/s] 40%|████      | 202/500 [00:12<00:18, 16.47it/s] 41%|████      | 204/500 [00:12<00:17, 16.52it/s] 41%|████      | 206/500 [00:12<00:17, 16.49it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.32it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.41it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.50it/s] 43%|████▎     | 214/500 [00:12<00:17, 16.59it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.62it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.57it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.56it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.64it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.38it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.36it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.22it/s] 46%|████▌     | 230/500 [00:13<00:16, 15.98it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.19it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.22it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.26it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.36it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.48it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.49it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.38it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.24it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.25it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.32it/s] 50%|█████     | 252/500 [00:15<00:15, 16.41it/s] 51%|█████     | 254/500 [00:15<00:14, 16.45it/s] 51%|█████     | 256/500 [00:15<00:14, 16.46it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.52it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.43it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.43it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.32it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.33it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.39it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.32it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.26it/s] 55%|█████▍    | 274/500 [00:16<00:14, 15.83it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.03it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.22it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.39it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.53it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.55it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.55it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.35it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.38it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.51it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.53it/s] 59%|█████▉    | 296/500 [00:17<00:12, 16.44it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.35it/s] 60%|██████    | 300/500 [00:18<00:12, 16.39it/s] 60%|██████    | 302/500 [00:18<00:12, 16.44it/s] 61%|██████    | 304/500 [00:18<00:11, 16.50it/s] 61%|██████    | 306/500 [00:18<00:11, 16.52it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.58it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.46it/s] 62%|██████▏   | 312/500 [00:18<00:11, 16.40it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.47it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.55it/s] 64%|██████▎   | 318/500 [00:19<00:10, 16.57it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.50it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.53it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.53it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.58it/s] 66%|██████▌   | 328/500 [00:19<00:10, 16.48it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.39it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.20it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.32it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.44it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.40it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.35it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.15it/s] 69%|██████▉   | 344/500 [00:20<00:09, 16.20it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.26it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.26it/s] 70%|███████   | 350/500 [00:21<00:09, 16.37it/s] 70%|███████   | 352/500 [00:21<00:08, 16.51it/s] 71%|███████   | 354/500 [00:21<00:08, 16.38it/s] 71%|███████   | 356/500 [00:21<00:08, 16.37it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.13it/s] 72%|███████▏  | 360/500 [00:21<00:09, 14.63it/s] 72%|███████▏  | 362/500 [00:22<00:09, 14.43it/s] 73%|███████▎  | 364/500 [00:22<00:09, 14.76it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.24it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.63it/s] 74%|███████▍  | 370/500 [00:22<00:08, 15.91it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.01it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.16it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.20it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.17it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.27it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.42it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.50it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.55it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.64it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.69it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.70it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.71it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.59it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.62it/s] 80%|████████  | 400/500 [00:24<00:06, 16.64it/s] 80%|████████  | 402/500 [00:24<00:05, 16.65it/s] 81%|████████  | 404/500 [00:24<00:05, 16.68it/s] 81%|████████  | 406/500 [00:24<00:05, 16.69it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.69it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.70it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.67it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.66it/s] 83%|████████▎ | 416/500 [00:25<00:05, 15.62it/s] 84%|████████▎ | 418/500 [00:25<00:05, 14.50it/s] 84%|████████▍ | 420/500 [00:25<00:05, 14.62it/s] 84%|████████▍ | 422/500 [00:25<00:05, 15.17it/s] 85%|████████▍ | 424/500 [00:25<00:04, 15.30it/s] 85%|████████▌ | 426/500 [00:26<00:05, 14.30it/s] 86%|████████▌ | 428/500 [00:26<00:04, 14.70it/s] 86%|████████▌ | 430/500 [00:26<00:04, 14.83it/s] 86%|████████▋ | 432/500 [00:26<00:04, 15.19it/s] 87%|████████▋ | 434/500 [00:26<00:04, 15.37it/s] 87%|████████▋ | 436/500 [00:26<00:04, 15.69it/s] 88%|████████▊ | 438/500 [00:26<00:03, 15.87it/s] 88%|████████▊ | 440/500 [00:26<00:03, 15.62it/s] 88%|████████▊ | 442/500 [00:27<00:03, 14.51it/s] 89%|████████▉ | 444/500 [00:27<00:03, 14.56it/s] 89%|████████▉ | 446/500 [00:27<00:03, 14.98it/s] 90%|████████▉ | 448/500 [00:27<00:03, 15.32it/s] 90%|█████████ | 450/500 [00:27<00:03, 15.56it/s] 90%|█████████ | 452/500 [00:27<00:03, 15.86it/s] 91%|█████████ | 454/500 [00:27<00:02, 15.98it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.09it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.21it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.32it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.23it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.39it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.43it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.34it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.24it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.39it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.41it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.42it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.33it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.36it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.38it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.45it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.43it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.33it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.15it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.29it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.27it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.45it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.51it/s]100%|██████████| 500/500 [00:30<00:00, 16.62it/s]100%|██████████| 500/500 [00:30<00:00, 16.29it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  11
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:59,  6.25s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:11,  1.18s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:55,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:20,  2.26it/s] 10%|▉         | 49/500 [00:34<02:28,  3.03it/s] 10%|█         | 51/500 [00:40<08:46,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.25it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.02it/s] 12%|█▏        | 61/500 [00:47<08:31,  1.16s/it] 13%|█▎        | 63/500 [00:47<06:05,  1.20it/s] 13%|█▎        | 65/500 [00:47<04:22,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:11,  2.26it/s] 14%|█▍        | 69/500 [00:47<02:21,  3.04it/s] 14%|█▍        | 71/500 [00:53<08:20,  1.17s/it]Epoch:  1  	Training Loss: 0.031122224405407906
Test Loss:  1.1387546062469482
Valid Loss:  1.1121814250946045
Epoch:  2  	Training Loss: 1.1184024810791016
Test Loss:  0.9223171472549438
Valid Loss:  0.8954640626907349
Epoch:  3  	Training Loss: 0.908943772315979
Test Loss:  0.03836306184530258
Valid Loss:  0.03597065061330795
Epoch:  4  	Training Loss: 0.03853911906480789
Test Loss:  0.032782331109046936
Valid Loss:  0.0311496090143919
Epoch:  5  	Training Loss: 0.03333457559347153
Test Loss:  0.03256215527653694
Valid Loss:  0.030706195160746574
Epoch:  6  	Training Loss: 0.0329100675880909
Test Loss:  0.0318572111427784
Valid Loss:  0.029691893607378006
Epoch:  7  	Training Loss: 0.03185151517391205
Test Loss:  0.031730107963085175
Valid Loss:  0.029384981840848923
Epoch:  8  	Training Loss: 0.03145883232355118
Test Loss:  0.0316413938999176
Valid Loss:  0.029281681403517723
Epoch:  9  	Training Loss: 0.031349580734968185
Test Loss:  0.031583577394485474
Valid Loss:  0.02919711172580719
Epoch:  10  	Training Loss: 0.031255029141902924
Test Loss:  0.031559549272060394
Valid Loss:  0.02911774441599846
Epoch:  11  	Training Loss: 0.03116939403116703
Test Loss:  0.031491249799728394
Valid Loss:  0.029042920097708702
Epoch:  12  	Training Loss: 0.031086677685379982
Test Loss:  0.03145977854728699
Valid Loss:  0.02897137962281704
Epoch:  13  	Training Loss: 0.03100697323679924
Test Loss:  0.03142225369811058
Valid Loss:  0.028904113918542862
Epoch:  14  	Training Loss: 0.030932694673538208
Test Loss:  0.03138064220547676
Valid Loss:  0.028838591650128365
Epoch:  15  	Training Loss: 0.030860943719744682
Test Loss:  0.031341344118118286
Valid Loss:  0.028774145990610123
Epoch:  16  	Training Loss: 0.030791986733675003
Test Loss:  0.031312622129917145
Valid Loss:  0.02871568128466606
Epoch:  17  	Training Loss: 0.030726775527000427
Test Loss:  0.03128069266676903
Valid Loss:  0.028657900169491768
Epoch:  18  	Training Loss: 0.030664490535855293
Test Loss:  0.03124677762389183
Valid Loss:  0.028600377961993217
Epoch:  19  	Training Loss: 0.03060406818985939
Test Loss:  0.031216364353895187
Valid Loss:  0.02854585275053978
Epoch:  20  	Training Loss: 0.03054620884358883
Test Loss:  0.031185265630483627
Valid Loss:  0.028492074459791183
Epoch:  21  	Training Loss: 0.030490385368466377
Test Loss:  0.0311588104814291
Valid Loss:  0.028442129492759705
Epoch:  22  	Training Loss: 0.03043690323829651
Test Loss:  0.031131230294704437
Valid Loss:  0.028391588479280472
Epoch:  23  	Training Loss: 0.030385475605726242
Test Loss:  0.03111862577497959
Valid Loss:  0.02835434302687645
Epoch:  24  	Training Loss: 0.030337989330291748
Test Loss:  0.031085047870874405
Valid Loss:  0.028299305588006973
Epoch:  25  	Training Loss: 0.030291318893432617
Test Loss:  0.031073762103915215
Valid Loss:  0.028266066685318947
Epoch:  26  	Training Loss: 0.03024630807340145
Test Loss:  0.03105243854224682
Valid Loss:  0.02822365239262581
Epoch:  27  	Training Loss: 0.03020409308373928
Test Loss:  0.031034983694553375
Valid Loss:  0.028185829520225525
Epoch:  28  	Training Loss: 0.030163688585162163
Test Loss:  0.031014839187264442
Valid Loss:  0.028145821765065193
Epoch:  29  	Training Loss: 0.03012501262128353
Test Loss:  0.03099888376891613
Valid Loss:  0.02811071276664734
Epoch:  30  	Training Loss: 0.030087795108556747
Test Loss:  0.030984770506620407
Valid Loss:  0.028078164905309677
Epoch:  31  	Training Loss: 0.030052296817302704
Test Loss:  0.03096875734627247
Valid Loss:  0.028044186532497406
Epoch:  32  	Training Loss: 0.030018193647265434
Test Loss:  0.03095029667019844
Valid Loss:  0.028008032590150833
Epoch:  33  	Training Loss: 0.029984954744577408
Test Loss:  0.030930325388908386
Valid Loss:  0.02797059901058674
Epoch:  34  	Training Loss: 0.029952242970466614
Test Loss:  0.03090955875813961
Valid Loss:  0.02793256938457489
Epoch:  35  	Training Loss: 0.02992040291428566
Test Loss:  0.0308946892619133
Valid Loss:  0.027901150286197662
Epoch:  36  	Training Loss: 0.02988974004983902
Test Loss:  0.030877431854605675
Valid Loss:  0.027867542579770088
Epoch:  37  	Training Loss: 0.02985973283648491
Test Loss:  0.03085874766111374
Valid Loss:  0.027832696214318275
Epoch:  38  	Training Loss: 0.02983018010854721
Test Loss:  0.03083929792046547
Valid Loss:  0.02779725193977356
Epoch:  39  	Training Loss: 0.02980131283402443
Test Loss:  0.030825790017843246
Valid Loss:  0.027768418192863464
Epoch:  40  	Training Loss: 0.029773540794849396
Test Loss:  0.03080987185239792
Valid Loss:  0.02773732878267765
Epoch:  41  	Training Loss: 0.02974635362625122
Test Loss:  0.030792519450187683
Valid Loss:  0.02770494669675827
Epoch:  42  	Training Loss: 0.029719561338424683
Test Loss:  0.0307743139564991
Valid Loss:  0.027671879157423973
Epoch:  43  	Training Loss: 0.02969306707382202
Test Loss:  0.03075568377971649
Valid Loss:  0.027638528496026993
Epoch:  44  	Training Loss: 0.029666872695088387
Test Loss:  0.0307368915528059
Valid Loss:  0.02760518155992031
Epoch:  45  	Training Loss: 0.02964097447693348
Test Loss:  0.030718060210347176
Valid Loss:  0.02757195755839348
Epoch:  46  	Training Loss: 0.029615353792905807
Test Loss:  0.03069928288459778
Valid Loss:  0.02753894403576851
Epoch:  47  	Training Loss: 0.029590465128421783
Test Loss:  0.030686546117067337
Valid Loss:  0.027512583881616592
Epoch:  48  	Training Loss: 0.029566340148448944
Test Loss:  0.03067648783326149
Valid Loss:  0.027489488944411278
Epoch:  49  	Training Loss: 0.029543064534664154
Test Loss:  0.030664997175335884
Valid Loss:  0.02746579423546791
Epoch:  50  	Training Loss: 0.029520520940423012
Test Loss:  0.030651303008198738
Valid Loss:  0.02744060941040516
Epoch:  51  	Training Loss: 0.029498495161533356
Test Loss:  0.03064250573515892
Valid Loss:  0.027419928461313248
Epoch:  52  	Training Loss: 0.029477283358573914
Test Loss:  0.030630819499492645
Valid Loss:  0.02739710919559002
Epoch:  53  	Training Loss: 0.02945666015148163
Test Loss:  0.03061731904745102
Valid Loss:  0.027372967451810837
Epoch:  54  	Training Loss: 0.029436614364385605
Test Loss:  0.03060910664498806
Valid Loss:  0.02735370770096779
Epoch:  55  	Training Loss: 0.02941715717315674
Test Loss:  0.030598074197769165
Valid Loss:  0.027332285419106483
Epoch:  56  	Training Loss: 0.029398180544376373
Test Loss:  0.03058525174856186
Valid Loss:  0.027309490367770195
Epoch:  57  	Training Loss: 0.02937961369752884
Test Loss:  0.030577853322029114
Valid Loss:  0.02729175239801407
Epoch:  58  	Training Loss: 0.029361683875322342
Test Loss:  0.030567599460482597
Valid Loss:  0.027272503823041916
Epoch:  59  	Training Loss: 0.029344182461500168
Test Loss:  0.030555542558431625
Valid Loss:  0.027253279462456703
Epoch:  60  	Training Loss: 0.02932695299386978
Test Loss:  0.030542388558387756
Valid Loss:  0.027233902364969254
Epoch:  61  	Training Loss: 0.02931022085249424
Test Loss:  0.030535154044628143
Valid Loss:  0.027217891067266464
Epoch:  62  	Training Loss: 0.02929392270743847
Test Loss:  0.030525289475917816
Valid Loss:  0.027200771495699883
Epoch:  63  	Training Loss: 0.029277989640831947
Test Loss:  0.030513770878314972
Valid Loss:  0.027182959020137787
Epoch:  64  	Training Loss: 0.029262280091643333
Test Loss:  0.030502278357744217
Valid Loss:  0.0271647609770298
Epoch:  65  	Training Loss: 0.029246751219034195
Test Loss:  0.030490612611174583
Valid Loss:  0.027147114276885986
Epoch:  66  	Training Loss: 0.029231373220682144
Test Loss:  0.030478674918413162
Valid Loss:  0.02713017910718918
Epoch:  67  	Training Loss: 0.029216738417744637
Test Loss:  0.030477330088615417
Valid Loss:  0.027118418365716934
Epoch:  68  	Training Loss: 0.029202235862612724
Test Loss:  0.03047240898013115
Valid Loss:  0.027105411514639854
Epoch:  69  	Training Loss: 0.029188435524702072
Test Loss:  0.03046511299908161
Valid Loss:  0.02709151804447174
Epoch:  70  	Training Loss: 0.029174989089369774
Test Loss:  0.030456291511654854
Valid Loss:  0.027077043429017067
Epoch:  71  	Training Loss: 0.02916175127029419
Test Loss:  0.030446544289588928
Valid Loss:  0.02706223353743553
Epoch:  72  	Training Loss: 0.029148656874895096
Test Loss:   15%|█▍        | 73/500 [00:53<05:58,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:18,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.25it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:12,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:00<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<08:05,  1.19s/it] 19%|█▊        | 93/500 [01:07<05:46,  1.17it/s] 19%|█▉        | 95/500 [01:07<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:07<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.97it/s] 20%|██        | 101/500 [01:14<07:52,  1.18s/it] 21%|██        | 103/500 [01:14<05:37,  1.18it/s] 21%|██        | 105/500 [01:14<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:14<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:14<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:21<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:28<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:35<07:22,  1.20s/it] 27%|██▋       | 133/500 [01:35<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:35<03:47,  1.61it/s] 27%|██▋       | 137/500 [01:35<02:45,  2.20it/s] 28%|██▊       | 139/500 [01:35<02:02,  2.96it/s] 28%|██▊       | 141/500 [01:41<07:05,  1.19s/it]0.0304361991584301
Valid Loss:  0.02704722061753273
Epoch:  73  	Training Loss: 0.029135679826140404
Test Loss:  0.030425522476434708
Valid Loss:  0.027032146230340004
Epoch:  74  	Training Loss: 0.029122821986675262
Test Loss:  0.03041466698050499
Valid Loss:  0.02701706252992153
Epoch:  75  	Training Loss: 0.02911006659269333
Test Loss:  0.030403725802898407
Valid Loss:  0.02700202912092209
Epoch:  76  	Training Loss: 0.029097523540258408
Test Loss:  0.03039693832397461
Valid Loss:  0.02698928490281105
Epoch:  77  	Training Loss: 0.029085392132401466
Test Loss:  0.03038994036614895
Valid Loss:  0.02697661519050598
Epoch:  78  	Training Loss: 0.029073506593704224
Test Loss:  0.03038283810019493
Valid Loss:  0.02696407213807106
Epoch:  79  	Training Loss: 0.029061932116746902
Test Loss:  0.030377553775906563
Valid Loss:  0.026952700689435005
Epoch:  80  	Training Loss: 0.029050642624497414
Test Loss:  0.030371733009815216
Valid Loss:  0.02694123052060604
Epoch:  81  	Training Loss: 0.029039625078439713
Test Loss:  0.03036436252295971
Valid Loss:  0.026929054409265518
Epoch:  82  	Training Loss: 0.02902878262102604
Test Loss:  0.03035607747733593
Valid Loss:  0.02691650390625
Epoch:  83  	Training Loss: 0.02901824191212654
Test Loss:  0.030352704226970673
Valid Loss:  0.026906883344054222
Epoch:  84  	Training Loss: 0.02900800108909607
Test Loss:  0.03034714050590992
Valid Loss:  0.02689618617296219
Epoch:  85  	Training Loss: 0.028998009860515594
Test Loss:  0.030340135097503662
Valid Loss:  0.026884786784648895
Epoch:  86  	Training Loss: 0.02898816019296646
Test Loss:  0.030332228168845177
Valid Loss:  0.026872966438531876
Epoch:  87  	Training Loss: 0.02897842787206173
Test Loss:  0.03032374009490013
Valid Loss:  0.026860883459448814
Epoch:  88  	Training Loss: 0.028968777507543564
Test Loss:  0.03031489998102188
Valid Loss:  0.026848657056689262
Epoch:  89  	Training Loss: 0.028959201648831367
Test Loss:  0.030305854976177216
Valid Loss:  0.02683638036251068
Epoch:  90  	Training Loss: 0.028949696570634842
Test Loss:  0.030296703800559044
Valid Loss:  0.0268249548971653
Epoch:  91  	Training Loss: 0.02894025482237339
Test Loss:  0.030287517234683037
Valid Loss:  0.026813741773366928
Epoch:  92  	Training Loss: 0.02893088571727276
Test Loss:  0.030278954654932022
Valid Loss:  0.02680259943008423
Epoch:  93  	Training Loss: 0.02892160974442959
Test Loss:  0.030270835384726524
Valid Loss:  0.026791520416736603
Epoch:  94  	Training Loss: 0.028912443667650223
Test Loss:  0.030267106369137764
Valid Loss:  0.026782769709825516
Epoch:  95  	Training Loss: 0.028903620317578316
Test Loss:  0.03026197850704193
Valid Loss:  0.02677343413233757
Epoch:  96  	Training Loss: 0.02889496460556984
Test Loss:  0.03025592304766178
Valid Loss:  0.02676371857523918
Epoch:  97  	Training Loss: 0.028886407613754272
Test Loss:  0.030249282717704773
Valid Loss:  0.02675376832485199
Epoch:  98  	Training Loss: 0.028877930715680122
Test Loss:  0.03024226985871792
Valid Loss:  0.026743682101368904
Epoch:  99  	Training Loss: 0.0288695115596056
Test Loss:  0.0302350465208292
Valid Loss:  0.02673354372382164
Epoch:  100  	Training Loss: 0.028861165046691895
Test Loss:  0.03022770769894123
Valid Loss:  0.02672339603304863
Epoch:  101  	Training Loss: 0.028852881863713264
Test Loss:  0.03022029623389244
Valid Loss:  0.026713263243436813
Epoch:  102  	Training Loss: 0.028844650834798813
Test Loss:  0.03021288476884365
Valid Loss:  0.026703180745244026
Epoch:  103  	Training Loss: 0.028836501762270927
Test Loss:  0.03020547330379486
Valid Loss:  0.02669314295053482
Epoch:  104  	Training Loss: 0.028828401118516922
Test Loss:  0.030198074877262115
Valid Loss:  0.026683157309889793
Epoch:  105  	Training Loss: 0.028820358216762543
Test Loss:  0.030190711840987206
Valid Loss:  0.02667323499917984
Epoch:  106  	Training Loss: 0.028812367469072342
Test Loss:  0.030183374881744385
Valid Loss:  0.026663368567824364
Epoch:  107  	Training Loss: 0.02880442515015602
Test Loss:  0.030176077038049698
Valid Loss:  0.02665356732904911
Epoch:  108  	Training Loss: 0.028796538710594177
Test Loss:  0.03016882762312889
Valid Loss:  0.026643827557563782
Epoch:  109  	Training Loss: 0.02878870628774166
Test Loss:  0.030161619186401367
Valid Loss:  0.026634154841303825
Epoch:  110  	Training Loss: 0.028780922293663025
Test Loss:  0.030154459178447723
Valid Loss:  0.026624543592333794
Epoch:  111  	Training Loss: 0.028773192316293716
Test Loss:  0.030147336423397064
Valid Loss:  0.02661551535129547
Epoch:  112  	Training Loss: 0.028765538707375526
Test Loss:  0.030143219977617264
Valid Loss:  0.02660788968205452
Epoch:  113  	Training Loss: 0.028758108615875244
Test Loss:  0.030139021575450897
Valid Loss:  0.02660033479332924
Epoch:  114  	Training Loss: 0.028750833123922348
Test Loss:  0.030133919790387154
Valid Loss:  0.026592543348670006
Epoch:  115  	Training Loss: 0.028743647038936615
Test Loss:  0.030128251761198044
Valid Loss:  0.026584604755043983
Epoch:  116  	Training Loss: 0.028736520558595657
Test Loss:  0.030122216790914536
Valid Loss:  0.026576587930321693
Epoch:  117  	Training Loss: 0.028729453682899475
Test Loss:  0.03011595830321312
Valid Loss:  0.026568546891212463
Epoch:  118  	Training Loss: 0.028722429648041725
Test Loss:  0.030109558254480362
Valid Loss:  0.02656049095094204
Epoch:  119  	Training Loss: 0.028715450316667557
Test Loss:  0.03010309487581253
Valid Loss:  0.02655245177447796
Epoch:  120  	Training Loss: 0.02870851568877697
Test Loss:  0.030096597969532013
Valid Loss:  0.026544436812400818
Epoch:  121  	Training Loss: 0.028701623901724815
Test Loss:  0.030090097337961197
Valid Loss:  0.02653646282851696
Epoch:  122  	Training Loss: 0.028694884851574898
Test Loss:  0.030087199062108994
Valid Loss:  0.02652990259230137
Epoch:  123  	Training Loss: 0.028688225895166397
Test Loss:  0.030083119869232178
Valid Loss:  0.026522984728217125
Epoch:  124  	Training Loss: 0.02868168242275715
Test Loss:  0.03007826767861843
Valid Loss:  0.026515835896134377
Epoch:  125  	Training Loss: 0.02867520973086357
Test Loss:  0.030072910711169243
Valid Loss:  0.02650853991508484
Epoch:  126  	Training Loss: 0.02866879105567932
Test Loss:  0.03006758540868759
Valid Loss:  0.026501156389713287
Epoch:  127  	Training Loss: 0.028662415221333504
Test Loss:  0.030062271282076836
Valid Loss:  0.026493724435567856
Epoch:  128  	Training Loss: 0.02865607850253582
Test Loss:  0.030056849122047424
Valid Loss:  0.026486288756132126
Epoch:  129  	Training Loss: 0.028649773448705673
Test Loss:  0.03005167841911316
Valid Loss:  0.02647886425256729
Epoch:  130  	Training Loss: 0.02864350937306881
Test Loss:  0.030046788975596428
Valid Loss:  0.026471465826034546
Epoch:  131  	Training Loss: 0.02863728255033493
Test Loss:  0.0300418920814991
Valid Loss:  0.02646409347653389
Epoch:  132  	Training Loss: 0.028631089255213737
Test Loss:  0.030037079006433487
Valid Loss:  0.02645682357251644
Epoch:  133  	Training Loss: 0.028625009581446648
Test Loss:  0.030032286420464516
Valid Loss:  0.026449590921401978
Epoch:  134  	Training Loss: 0.02861896902322769
Test Loss:  0.030027516186237335
Valid Loss:  0.026442397385835648
Epoch:  135  	Training Loss: 0.028612960129976273
Test Loss:  0.030022770166397095
Valid Loss:  0.0264352485537529
Epoch:  136  	Training Loss: 0.028606994077563286
Test Loss:  0.03001805767416954
Valid Loss:  0.02642815001308918
Epoch:  137  	Training Loss: 0.028601069003343582
Test Loss:  0.03001335635781288
Valid Loss:  0.026421088725328445
Epoch:  138  	Training Loss: 0.028595171868801117
Test Loss:  0.03000868670642376
Valid Loss:  0.026414066553115845
Epoch:  139  	Training Loss: 0.028589310124516487
Test Loss:  0.030004052445292473
Valid Loss:  0.02640719711780548
Epoch:  140  	Training Loss: 0.02858348935842514
Test Loss:  0.029999451711773872
Valid Loss:  0.026400785893201828
Epoch:  141  	Training Loss: 0.028577808290719986
Test Loss:  0.029997076839208603
Valid Loss:  0.02639528177678585
Epoch:  142  	Training Loss: 0.028572220355272293
Test Loss:  0.029994066804647446
Valid Loss:  0.026389645412564278
Epoch:  143  	Training Loss: 0.02856677770614624
Test Loss:   29%|██▊       | 143/500 [01:42<05:03,  1.17it/s] 29%|██▉       | 145/500 [01:42<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.22it/s] 30%|██▉       | 149/500 [01:42<01:57,  2.99it/s] 30%|███       | 151/500 [01:48<06:48,  1.17s/it] 31%|███       | 153/500 [01:48<04:51,  1.19it/s] 31%|███       | 155/500 [01:48<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:49<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:49<01:52,  3.03it/s] 32%|███▏      | 161/500 [01:55<06:44,  1.19s/it] 33%|███▎      | 163/500 [01:55<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:55<03:27,  1.62it/s] 33%|███▎      | 167/500 [01:56<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:56<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:02<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:02<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:02<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:02<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.98it/s] 36%|███▌      | 181/500 [02:09<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:16<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.00it/s] 40%|████      | 201/500 [02:22<05:51,  1.18s/it] 41%|████      | 203/500 [02:23<04:10,  1.18it/s] 41%|████      | 205/500 [02:23<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:23<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:23<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:29<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:02,  1.18it/s]0.029990598559379578
Valid Loss:  0.026383889839053154
Epoch:  144  	Training Loss: 0.028561390936374664
Test Loss:  0.02998683787882328
Valid Loss:  0.02637806162238121
Epoch:  145  	Training Loss: 0.028556043282151222
Test Loss:  0.02998289093375206
Valid Loss:  0.026372196152806282
Epoch:  146  	Training Loss: 0.028550732880830765
Test Loss:  0.029978817328810692
Valid Loss:  0.02636631391942501
Epoch:  147  	Training Loss: 0.028545450419187546
Test Loss:  0.029974685981869698
Valid Loss:  0.02636043354868889
Epoch:  148  	Training Loss: 0.02854020893573761
Test Loss:  0.029970509931445122
Valid Loss:  0.026354573667049408
Epoch:  149  	Training Loss: 0.028534995391964912
Test Loss:  0.029966315254569054
Valid Loss:  0.02634872868657112
Epoch:  150  	Training Loss: 0.028529811650514603
Test Loss:  0.029962120577692986
Valid Loss:  0.026342909783124924
Epoch:  151  	Training Loss: 0.02852465584874153
Test Loss:  0.029957933351397514
Valid Loss:  0.026337118819355965
Epoch:  152  	Training Loss: 0.028519531711935997
Test Loss:  0.02995375171303749
Valid Loss:  0.026331350207328796
Epoch:  153  	Training Loss: 0.028514429926872253
Test Loss:  0.029949581250548363
Valid Loss:  0.026325616985559464
Epoch:  154  	Training Loss: 0.028509359806776047
Test Loss:  0.029945436865091324
Valid Loss:  0.026319917291402817
Epoch:  155  	Training Loss: 0.02850431576371193
Test Loss:  0.02994130551815033
Valid Loss:  0.026314251124858856
Epoch:  156  	Training Loss: 0.0284993015229702
Test Loss:  0.029937200248241425
Valid Loss:  0.026308611035346985
Epoch:  157  	Training Loss: 0.02849431149661541
Test Loss:  0.02993312105536461
Valid Loss:  0.02630300633609295
Epoch:  158  	Training Loss: 0.028489353135228157
Test Loss:  0.029929058626294136
Valid Loss:  0.0262974314391613
Epoch:  159  	Training Loss: 0.028484420850872993
Test Loss:  0.029925018548965454
Valid Loss:  0.026291891932487488
Epoch:  160  	Training Loss: 0.02847951650619507
Test Loss:  0.029920995235443115
Valid Loss:  0.026286378502845764
Epoch:  161  	Training Loss: 0.028474710881710052
Test Loss:  0.029918529093265533
Valid Loss:  0.02628154307603836
Epoch:  162  	Training Loss: 0.028469979763031006
Test Loss:  0.02991603873670101
Valid Loss:  0.02627674862742424
Epoch:  163  	Training Loss: 0.028465334326028824
Test Loss:  0.029913103207945824
Valid Loss:  0.026271827518939972
Epoch:  164  	Training Loss: 0.02846074104309082
Test Loss:  0.02990986406803131
Valid Loss:  0.026266813278198242
Epoch:  165  	Training Loss: 0.028456183150410652
Test Loss:  0.029906433075666428
Valid Loss:  0.026261746883392334
Epoch:  166  	Training Loss: 0.028451651334762573
Test Loss:  0.0299028679728508
Valid Loss:  0.02625664323568344
Epoch:  167  	Training Loss: 0.028447145596146584
Test Loss:  0.029899241402745247
Valid Loss:  0.026251543313264847
Epoch:  168  	Training Loss: 0.028442667797207832
Test Loss:  0.029895566403865814
Valid Loss:  0.02624644711613655
Epoch:  169  	Training Loss: 0.02843821421265602
Test Loss:  0.02989187277853489
Valid Loss:  0.026241356506943703
Epoch:  170  	Training Loss: 0.028433782979846
Test Loss:  0.029888169839978218
Valid Loss:  0.026236291974782944
Epoch:  171  	Training Loss: 0.02842937782406807
Test Loss:  0.029884472489356995
Valid Loss:  0.02623124234378338
Epoch:  172  	Training Loss: 0.02842499502003193
Test Loss:  0.02988065965473652
Valid Loss:  0.02622613124549389
Epoch:  173  	Training Loss: 0.028420528396964073
Test Loss:  0.029876872897148132
Valid Loss:  0.026221370324492455
Epoch:  174  	Training Loss: 0.028416089713573456
Test Loss:  0.029873091727495193
Valid Loss:  0.026216663420200348
Epoch:  175  	Training Loss: 0.02841167151927948
Test Loss:  0.029869327321648598
Valid Loss:  0.026212042197585106
Epoch:  176  	Training Loss: 0.028407277539372444
Test Loss:  0.029865583404898643
Valid Loss:  0.02620772272348404
Epoch:  177  	Training Loss: 0.0284029059112072
Test Loss:  0.029861852526664734
Valid Loss:  0.026203449815511703
Epoch:  178  	Training Loss: 0.028398558497428894
Test Loss:  0.029858142137527466
Valid Loss:  0.02619919553399086
Epoch:  179  	Training Loss: 0.02839423343539238
Test Loss:  0.02985445037484169
Valid Loss:  0.026194978505373
Epoch:  180  	Training Loss: 0.028389936313033104
Test Loss:  0.029850780963897705
Valid Loss:  0.02619077078998089
Epoch:  181  	Training Loss: 0.02838565595448017
Test Loss:  0.029847126454114914
Valid Loss:  0.026186587288975716
Epoch:  182  	Training Loss: 0.02838139981031418
Test Loss:  0.029843587428331375
Valid Loss:  0.026182517409324646
Epoch:  183  	Training Loss: 0.028377264738082886
Test Loss:  0.02984006702899933
Valid Loss:  0.02617846429347992
Epoch:  184  	Training Loss: 0.028373152017593384
Test Loss:  0.029836565256118774
Valid Loss:  0.02617444470524788
Epoch:  185  	Training Loss: 0.028369057923555374
Test Loss:  0.029833078384399414
Valid Loss:  0.026170434430241585
Epoch:  186  	Training Loss: 0.028364989906549454
Test Loss:  0.029829613864421844
Valid Loss:  0.026166453957557678
Epoch:  187  	Training Loss: 0.028360942378640175
Test Loss:  0.029826167970895767
Valid Loss:  0.026162490248680115
Epoch:  188  	Training Loss: 0.028356917202472687
Test Loss:  0.029822738841176033
Valid Loss:  0.02615855447947979
Epoch:  189  	Training Loss: 0.028352972120046616
Test Loss:  0.029820596799254417
Valid Loss:  0.02615470066666603
Epoch:  190  	Training Loss: 0.028349071741104126
Test Loss:  0.029818441718816757
Valid Loss:  0.02615090273320675
Epoch:  191  	Training Loss: 0.028345230966806412
Test Loss:  0.029815908521413803
Valid Loss:  0.026147127151489258
Epoch:  192  	Training Loss: 0.02834143117070198
Test Loss:  0.029813110828399658
Valid Loss:  0.026143355295062065
Epoch:  193  	Training Loss: 0.028337683528661728
Test Loss:  0.029811827465891838
Valid Loss:  0.026139752939343452
Epoch:  194  	Training Loss: 0.02833397686481476
Test Loss:  0.029809914529323578
Valid Loss:  0.026136167347431183
Epoch:  195  	Training Loss: 0.028330348432064056
Test Loss:  0.029807578772306442
Valid Loss:  0.026132578030228615
Epoch:  196  	Training Loss: 0.028326760977506638
Test Loss:  0.029804956167936325
Valid Loss:  0.02612898498773575
Epoch:  197  	Training Loss: 0.028323207050561905
Test Loss:  0.029802147299051285
Valid Loss:  0.026125401258468628
Epoch:  198  	Training Loss: 0.028319664299488068
Test Loss:  0.029799215495586395
Valid Loss:  0.02612181566655636
Epoch:  199  	Training Loss: 0.02831614390015602
Test Loss:  0.02979620173573494
Valid Loss:  0.026118244975805283
Epoch:  200  	Training Loss: 0.028312696143984795
Test Loss:  0.029794836416840553
Valid Loss:  0.026114918291568756
Epoch:  201  	Training Loss: 0.028309281915426254
Test Loss:  0.029792917892336845
Valid Loss:  0.026111576706171036
Epoch:  202  	Training Loss: 0.02830592356622219
Test Loss:  0.029790695756673813
Valid Loss:  0.02610827051103115
Epoch:  203  	Training Loss: 0.028302662074565887
Test Loss:  0.029788237065076828
Valid Loss:  0.026104949414730072
Epoch:  204  	Training Loss: 0.028299422934651375
Test Loss:  0.029785796999931335
Valid Loss:  0.026101626455783844
Epoch:  205  	Training Loss: 0.028296200558543205
Test Loss:  0.02978326380252838
Valid Loss:  0.026098310947418213
Epoch:  206  	Training Loss: 0.02829299494624138
Test Loss:  0.02978067472577095
Valid Loss:  0.026094995439052582
Epoch:  207  	Training Loss: 0.0282897986471653
Test Loss:  0.029778048396110535
Valid Loss:  0.026091687381267548
Epoch:  208  	Training Loss: 0.02828662469983101
Test Loss:  0.02977539785206318
Valid Loss:  0.02608839049935341
Epoch:  209  	Training Loss: 0.028283461928367615
Test Loss:  0.029772745445370674
Valid Loss:  0.026085101068019867
Epoch:  210  	Training Loss: 0.028280310332775116
Test Loss:  0.02977008931338787
Valid Loss:  0.026081835851073265
Epoch:  211  	Training Loss: 0.028277182951569557
Test Loss:  0.02976742573082447
Valid Loss:  0.02607857435941696
Epoch:  212  	Training Loss: 0.028274059295654297
Test Loss:  0.02976469323039055
Valid Loss:  0.02607525885105133
Epoch:  213  	Training Loss: 0.02827087789773941
Test Loss:  0.02976197376847267
Valid Loss:  0.026071958243846893
 43%|████▎     | 215/500 [02:30<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:36<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.22it/s] 46%|████▌     | 229/500 [02:37<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:43<05:24,  1.21s/it] 47%|████▋     | 233/500 [02:43<03:51,  1.15it/s] 47%|████▋     | 235/500 [02:43<02:46,  1.60it/s] 47%|████▋     | 237/500 [02:44<02:00,  2.18it/s] 48%|████▊     | 239/500 [02:44<01:28,  2.93it/s] 48%|████▊     | 241/500 [02:50<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:24,  2.97it/s] 50%|█████     | 251/500 [02:57<04:51,  1.17s/it] 51%|█████     | 253/500 [02:57<03:27,  1.19it/s] 51%|█████     | 255/500 [02:57<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:04<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:18,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:04<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:11<04:33,  1.19s/it] 55%|█████▍    | 273/500 [03:11<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:11<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:11<01:41,  2.21it/s] 56%|█████▌    | 279/500 [03:11<01:14,  2.97it/s] 56%|█████▌    | 281/500 [03:17<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:18<03:05,  1.17it/s]Epoch:  214  	Training Loss: 0.028267711400985718
Test Loss:  0.029759254306554794
Valid Loss:  0.0260686706751585
Epoch:  215  	Training Loss: 0.02826455980539322
Test Loss:  0.02975654974579811
Valid Loss:  0.02606539987027645
Epoch:  216  	Training Loss: 0.028261424973607063
Test Loss:  0.029753856360912323
Valid Loss:  0.026062143966555595
Epoch:  217  	Training Loss: 0.028258297592401505
Test Loss:  0.029751189053058624
Valid Loss:  0.026058904826641083
Epoch:  218  	Training Loss: 0.028255190700292587
Test Loss:  0.029748734086751938
Valid Loss:  0.026055680587887764
Epoch:  219  	Training Loss: 0.028252093121409416
Test Loss:  0.02974631078541279
Valid Loss:  0.02605246938765049
Epoch:  220  	Training Loss: 0.02824900858104229
Test Loss:  0.029743894934654236
Valid Loss:  0.02604927122592926
Epoch:  221  	Training Loss: 0.028245942667126656
Test Loss:  0.029741518199443817
Valid Loss:  0.026046089828014374
Epoch:  222  	Training Loss: 0.028242886066436768
Test Loss:  0.02973940223455429
Valid Loss:  0.026042984798550606
Epoch:  223  	Training Loss: 0.028239913284778595
Test Loss:  0.029737316071987152
Valid Loss:  0.026039889082312584
Epoch:  224  	Training Loss: 0.02823694795370102
Test Loss:  0.02973523549735546
Valid Loss:  0.026036810129880905
Epoch:  225  	Training Loss: 0.028233997523784637
Test Loss:  0.029733160510659218
Valid Loss:  0.02603391371667385
Epoch:  226  	Training Loss: 0.028231101110577583
Test Loss:  0.029731839895248413
Valid Loss:  0.026031101122498512
Epoch:  227  	Training Loss: 0.028228238224983215
Test Loss:  0.029730305075645447
Valid Loss:  0.026028329506516457
Epoch:  228  	Training Loss: 0.028225412592291832
Test Loss:  0.029728621244430542
Valid Loss:  0.026025570929050446
Epoch:  229  	Training Loss: 0.028222616761922836
Test Loss:  0.02972683496773243
Valid Loss:  0.026022840291261673
Epoch:  230  	Training Loss: 0.028219837695360184
Test Loss:  0.029724974185228348
Valid Loss:  0.0260201133787632
Epoch:  231  	Training Loss: 0.028217066079378128
Test Loss:  0.029723074287176132
Valid Loss:  0.02601740136742592
Epoch:  232  	Training Loss: 0.028214313089847565
Test Loss:  0.029721083119511604
Valid Loss:  0.026014648377895355
Epoch:  233  	Training Loss: 0.02821151167154312
Test Loss:  0.029719090089201927
Valid Loss:  0.026011908426880836
Epoch:  234  	Training Loss: 0.02820872887969017
Test Loss:  0.02971707470715046
Valid Loss:  0.026009175926446915
Epoch:  235  	Training Loss: 0.028205953538417816
Test Loss:  0.02971505932509899
Valid Loss:  0.026006462052464485
Epoch:  236  	Training Loss: 0.028203193098306656
Test Loss:  0.029713042080402374
Valid Loss:  0.026003751903772354
Epoch:  237  	Training Loss: 0.028200441971421242
Test Loss:  0.029711034148931503
Valid Loss:  0.026001058518886566
Epoch:  238  	Training Loss: 0.028197702020406723
Test Loss:  0.029709026217460632
Valid Loss:  0.025998378172516823
Epoch:  239  	Training Loss: 0.028194978833198547
Test Loss:  0.02970702573657036
Valid Loss:  0.025995712727308273
Epoch:  240  	Training Loss: 0.028192270547151566
Test Loss:  0.029705027118325233
Valid Loss:  0.025993049144744873
Epoch:  241  	Training Loss: 0.028189564123749733
Test Loss:  0.029703034088015556
Valid Loss:  0.025990400463342667
Epoch:  242  	Training Loss: 0.028186872601509094
Test Loss:  0.029701057821512222
Valid Loss:  0.025987770408391953
Epoch:  243  	Training Loss: 0.0281841978430748
Test Loss:  0.02969907596707344
Valid Loss:  0.025985144078731537
Epoch:  244  	Training Loss: 0.02818153239786625
Test Loss:  0.02969711646437645
Valid Loss:  0.025982536375522614
Epoch:  245  	Training Loss: 0.028178906068205833
Test Loss:  0.02969571202993393
Valid Loss:  0.025979990139603615
Epoch:  246  	Training Loss: 0.028176311403512955
Test Loss:  0.02969430759549141
Valid Loss:  0.025977469980716705
Epoch:  247  	Training Loss: 0.028173748403787613
Test Loss:  0.029693473130464554
Valid Loss:  0.02597505785524845
Epoch:  248  	Training Loss: 0.028171241283416748
Test Loss:  0.029691576957702637
Valid Loss:  0.025972537696361542
Epoch:  249  	Training Loss: 0.02816873788833618
Test Loss:  0.029690423980355263
Valid Loss:  0.02597014233469963
Epoch:  250  	Training Loss: 0.0281662717461586
Test Loss:  0.02968905121088028
Valid Loss:  0.02596774697303772
Epoch:  251  	Training Loss: 0.028163844719529152
Test Loss:  0.029687514528632164
Valid Loss:  0.025965336710214615
Epoch:  252  	Training Loss: 0.0281614288687706
Test Loss:  0.029685907065868378
Valid Loss:  0.02596295066177845
Epoch:  253  	Training Loss: 0.028159048408269882
Test Loss:  0.029684223234653473
Valid Loss:  0.025960564613342285
Epoch:  254  	Training Loss: 0.02815668098628521
Test Loss:  0.029682498425245285
Valid Loss:  0.025958184152841568
Epoch:  255  	Training Loss: 0.028154324740171432
Test Loss:  0.02968074195086956
Valid Loss:  0.02595580369234085
Epoch:  256  	Training Loss: 0.0281519815325737
Test Loss:  0.029678961262106895
Valid Loss:  0.02595343440771103
Epoch:  257  	Training Loss: 0.028149645775556564
Test Loss:  0.029677169397473335
Valid Loss:  0.025951072573661804
Epoch:  258  	Training Loss: 0.028147317469120026
Test Loss:  0.029675383120775223
Valid Loss:  0.025948718190193176
Epoch:  259  	Training Loss: 0.02814500406384468
Test Loss:  0.029673587530851364
Valid Loss:  0.025946371257305145
Epoch:  260  	Training Loss: 0.028142698109149933
Test Loss:  0.029671791940927505
Valid Loss:  0.02594403550028801
Epoch:  261  	Training Loss: 0.02814040519297123
Test Loss:  0.029670003801584244
Valid Loss:  0.025941703468561172
Epoch:  262  	Training Loss: 0.028138119727373123
Test Loss:  0.02966815046966076
Valid Loss:  0.0259393397718668
Epoch:  263  	Training Loss: 0.028135789558291435
Test Loss:  0.02966630645096302
Valid Loss:  0.025936979800462723
Epoch:  264  	Training Loss: 0.028133470565080643
Test Loss:  0.02966446802020073
Valid Loss:  0.025934631004929543
Epoch:  265  	Training Loss: 0.028131159022450447
Test Loss:  0.029662635177373886
Valid Loss:  0.025932295247912407
Epoch:  266  	Training Loss: 0.028128858655691147
Test Loss:  0.029660813510417938
Valid Loss:  0.02592996135354042
Epoch:  267  	Training Loss: 0.028126563876867294
Test Loss:  0.029658988118171692
Valid Loss:  0.025927633047103882
Epoch:  268  	Training Loss: 0.02812427654862404
Test Loss:  0.02965717576444149
Valid Loss:  0.025925323367118835
Epoch:  269  	Training Loss: 0.02812200039625168
Test Loss:  0.029655368998646736
Valid Loss:  0.025923023000359535
Epoch:  270  	Training Loss: 0.028119737282395363
Test Loss:  0.02965357154607773
Valid Loss:  0.02592073380947113
Epoch:  271  	Training Loss: 0.028117477893829346
Test Loss:  0.029651779681444168
Valid Loss:  0.025918448343873024
Epoch:  272  	Training Loss: 0.028115231543779373
Test Loss:  0.029650017619132996
Valid Loss:  0.025916198268532753
Epoch:  273  	Training Loss: 0.028113020583987236
Test Loss:  0.029648274183273315
Valid Loss:  0.025913964956998825
Epoch:  274  	Training Loss: 0.028110820800065994
Test Loss:  0.029646530747413635
Valid Loss:  0.025911731645464897
Epoch:  275  	Training Loss: 0.02810862846672535
Test Loss:  0.029644789174199104
Valid Loss:  0.025909511372447014
Epoch:  276  	Training Loss: 0.0281064435839653
Test Loss:  0.02964305877685547
Valid Loss:  0.025907304137945175
Epoch:  277  	Training Loss: 0.028104268014431
Test Loss:  0.029641330242156982
Valid Loss:  0.025905104354023933
Epoch:  278  	Training Loss: 0.028102099895477295
Test Loss:  0.029639611020684242
Valid Loss:  0.02590290457010269
Epoch:  279  	Training Loss: 0.028099939227104187
Test Loss:  0.0296378955245018
Valid Loss:  0.025900721549987793
Epoch:  280  	Training Loss: 0.02809779904782772
Test Loss:  0.029636692255735397
Valid Loss:  0.025898650288581848
Epoch:  281  	Training Loss: 0.028095683082938194
Test Loss:  0.029635492712259293
Valid Loss:  0.025896601378917694
Epoch:  282  	Training Loss: 0.028093598783016205
Test Loss:  0.029634103178977966
Valid Loss:  0.025894496589899063
Epoch:  283  	Training Loss: 0.028091490268707275
Test Loss:  0.02963262051343918
Valid Loss:  0.025892386212944984
Epoch:  284  	Training Loss: 0.02808939293026924
Test Loss:   57%|█████▋    | 285/500 [03:18<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:18<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:18<01:10,  2.97it/s] 58%|█████▊    | 291/500 [03:24<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:24<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:25<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:25<01:07,  2.98it/s] 60%|██████    | 301/500 [03:31<03:55,  1.18s/it] 61%|██████    | 303/500 [03:31<02:47,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:32<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:38<03:39,  1.16s/it] 63%|██████▎   | 313/500 [03:38<02:36,  1.20it/s] 63%|██████▎   | 315/500 [03:38<01:51,  1.65it/s] 63%|██████▎   | 317/500 [03:38<01:20,  2.26it/s] 64%|██████▍   | 319/500 [03:38<00:59,  3.04it/s] 64%|██████▍   | 321/500 [03:45<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:45<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:45<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:45<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:45<00:57,  3.00it/s] 66%|██████▌   | 331/500 [03:52<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:52<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:52<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:52<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:52<00:53,  3.02it/s] 68%|██████▊   | 341/500 [03:58<03:06,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:59<01:34,  1.65it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.25it/s] 70%|██████▉   | 349/500 [03:59<00:49,  3.02it/s] 70%|███████   | 351/500 [04:05<02:55,  1.18s/it] 71%|███████   | 353/500 [04:05<02:04,  1.18it/s]0.02963106706738472
Valid Loss:  0.025890272110700607
Epoch:  285  	Training Loss: 0.028087308630347252
Test Loss:  0.029629476368427277
Valid Loss:  0.02588815614581108
Epoch:  286  	Training Loss: 0.028085235506296158
Test Loss:  0.02962794154882431
Valid Loss:  0.025886040180921555
Epoch:  287  	Training Loss: 0.02808316797018051
Test Loss:  0.02962641417980194
Valid Loss:  0.025883931666612625
Epoch:  288  	Training Loss: 0.028081107884645462
Test Loss:  0.029624883085489273
Valid Loss:  0.025881826877593994
Epoch:  289  	Training Loss: 0.02807905711233616
Test Loss:  0.029623346403241158
Valid Loss:  0.025879818946123123
Epoch:  290  	Training Loss: 0.028077013790607452
Test Loss:  0.02962181344628334
Valid Loss:  0.025877851992845535
Epoch:  291  	Training Loss: 0.028074974194169044
Test Loss:  0.02962026745080948
Valid Loss:  0.025875892490148544
Epoch:  292  	Training Loss: 0.028072945773601532
Test Loss:  0.0296187587082386
Valid Loss:  0.025873957201838493
Epoch:  293  	Training Loss: 0.028070947155356407
Test Loss:  0.029617248103022575
Valid Loss:  0.025872034952044487
Epoch:  294  	Training Loss: 0.028068970888853073
Test Loss:  0.029616232961416245
Valid Loss:  0.025870129466056824
Epoch:  295  	Training Loss: 0.02806701511144638
Test Loss:  0.029615074396133423
Valid Loss:  0.025868244469165802
Epoch:  296  	Training Loss: 0.028065085411071777
Test Loss:  0.029613817110657692
Valid Loss:  0.025866365060210228
Epoch:  297  	Training Loss: 0.02806316502392292
Test Loss:  0.029612498357892036
Valid Loss:  0.025864504277706146
Epoch:  298  	Training Loss: 0.028061263263225555
Test Loss:  0.0296111311763525
Valid Loss:  0.025862645357847214
Epoch:  299  	Training Loss: 0.02805936709046364
Test Loss:  0.029609737917780876
Valid Loss:  0.025860795751214027
Epoch:  300  	Training Loss: 0.028057478368282318
Test Loss:  0.029608331620693207
Valid Loss:  0.025858953595161438
Epoch:  301  	Training Loss: 0.028055604547262192
Test Loss:  0.029606906697154045
Valid Loss:  0.025857120752334595
Epoch:  302  	Training Loss: 0.028053734451532364
Test Loss:  0.029605459421873093
Valid Loss:  0.025855273008346558
Epoch:  303  	Training Loss: 0.028051849454641342
Test Loss:  0.029604008421301842
Valid Loss:  0.025853432714939117
Epoch:  304  	Training Loss: 0.028049971908330917
Test Loss:  0.029602553695440292
Valid Loss:  0.025851596146821976
Epoch:  305  	Training Loss: 0.02804810367524624
Test Loss:  0.029601112008094788
Valid Loss:  0.025849778205156326
Epoch:  306  	Training Loss: 0.028046242892742157
Test Loss:  0.029599659144878387
Valid Loss:  0.02584795467555523
Epoch:  307  	Training Loss: 0.028044387698173523
Test Loss:  0.029598217457532883
Valid Loss:  0.025846144184470177
Epoch:  308  	Training Loss: 0.028042541816830635
Test Loss:  0.02959677018225193
Valid Loss:  0.025844335556030273
Epoch:  309  	Training Loss: 0.028040699660778046
Test Loss:  0.029595335945487022
Valid Loss:  0.025842532515525818
Epoch:  310  	Training Loss: 0.028038864955306053
Test Loss:  0.02959389239549637
Valid Loss:  0.02584073506295681
Epoch:  311  	Training Loss: 0.02803703024983406
Test Loss:  0.02959246188402176
Valid Loss:  0.025838950648903847
Epoch:  312  	Training Loss: 0.028035225346684456
Test Loss:  0.029591543599963188
Valid Loss:  0.025837251916527748
Epoch:  313  	Training Loss: 0.02803347259759903
Test Loss:  0.02959049865603447
Valid Loss:  0.025835556909441948
Epoch:  314  	Training Loss: 0.028031740337610245
Test Loss:  0.029589351266622543
Valid Loss:  0.025833865627646446
Epoch:  315  	Training Loss: 0.028030019253492355
Test Loss:  0.029588153585791588
Valid Loss:  0.02583218179643154
Epoch:  316  	Training Loss: 0.02802831307053566
Test Loss:  0.029586900025606155
Valid Loss:  0.025830494239926338
Epoch:  317  	Training Loss: 0.028026612475514412
Test Loss:  0.029585620388388634
Valid Loss:  0.02582881599664688
Epoch:  318  	Training Loss: 0.028024917468428612
Test Loss:  0.029584312811493874
Valid Loss:  0.025827139616012573
Epoch:  319  	Training Loss: 0.02802322804927826
Test Loss:  0.029582997784018517
Valid Loss:  0.025825466960668564
Epoch:  320  	Training Loss: 0.028021542355418205
Test Loss:  0.029581675305962563
Valid Loss:  0.02582380175590515
Epoch:  321  	Training Loss: 0.028019864112138748
Test Loss:  0.02958034910261631
Valid Loss:  0.025822138413786888
Epoch:  322  	Training Loss: 0.02801818773150444
Test Loss:  0.029578950256109238
Valid Loss:  0.025820424780249596
Epoch:  323  	Training Loss: 0.028016461059451103
Test Loss:  0.029577556997537613
Valid Loss:  0.0258187148720026
Epoch:  324  	Training Loss: 0.028014736250042915
Test Loss:  0.029576163738965988
Valid Loss:  0.025817008689045906
Epoch:  325  	Training Loss: 0.028013020753860474
Test Loss:  0.029574770480394363
Valid Loss:  0.025815308094024658
Epoch:  326  	Training Loss: 0.028011305257678032
Test Loss:  0.029573386535048485
Valid Loss:  0.025813618674874306
Epoch:  327  	Training Loss: 0.028009600937366486
Test Loss:  0.029571998864412308
Valid Loss:  0.025811929255723953
Epoch:  328  	Training Loss: 0.02800789847970009
Test Loss:  0.02957060933113098
Valid Loss:  0.02581024542450905
Epoch:  329  	Training Loss: 0.02800619974732399
Test Loss:  0.02956923097372055
Valid Loss:  0.025808565318584442
Epoch:  330  	Training Loss: 0.02800450660288334
Test Loss:  0.02956785075366497
Valid Loss:  0.025806888937950134
Epoch:  331  	Training Loss: 0.028002815321087837
Test Loss:  0.02956647053360939
Valid Loss:  0.025805220007896423
Epoch:  332  	Training Loss: 0.028001131489872932
Test Loss:  0.029565175995230675
Valid Loss:  0.025803621858358383
Epoch:  333  	Training Loss: 0.027999527752399445
Test Loss:  0.02956387773156166
Valid Loss:  0.02580203302204609
Epoch:  334  	Training Loss: 0.027997924014925957
Test Loss:  0.02956259250640869
Valid Loss:  0.025800444185733795
Epoch:  335  	Training Loss: 0.027996327728033066
Test Loss:  0.029561297968029976
Valid Loss:  0.02579886093735695
Epoch:  336  	Training Loss: 0.027994738891720772
Test Loss:  0.029560018330812454
Valid Loss:  0.0257972814142704
Epoch:  337  	Training Loss: 0.027993150055408478
Test Loss:  0.029558725655078888
Valid Loss:  0.0257957112044096
Epoch:  338  	Training Loss: 0.02799156680703163
Test Loss:  0.029557447880506516
Valid Loss:  0.025794142857193947
Epoch:  339  	Training Loss: 0.027989987283945084
Test Loss:  0.029556170105934143
Valid Loss:  0.025792576372623444
Epoch:  340  	Training Loss: 0.027988415211439133
Test Loss:  0.02955489605665207
Valid Loss:  0.025791015475988388
Epoch:  341  	Training Loss: 0.027986843138933182
Test Loss:  0.029553622007369995
Valid Loss:  0.02578945830464363
Epoch:  342  	Training Loss: 0.027985282242298126
Test Loss:  0.029552318155765533
Valid Loss:  0.025787875056266785
Epoch:  343  	Training Loss: 0.027983684092760086
Test Loss:  0.02955101802945137
Valid Loss:  0.025786299258470535
Epoch:  344  	Training Loss: 0.027982095256447792
Test Loss:  0.029549716040492058
Valid Loss:  0.025784727185964584
Epoch:  345  	Training Loss: 0.027980506420135498
Test Loss:  0.029548417776823044
Valid Loss:  0.025783155113458633
Epoch:  346  	Training Loss: 0.02797892317175865
Test Loss:  0.029547126963734627
Valid Loss:  0.02578158490359783
Epoch:  347  	Training Loss: 0.027977345511317253
Test Loss:  0.02954614907503128
Valid Loss:  0.025780070573091507
Epoch:  348  	Training Loss: 0.027975784614682198
Test Loss:  0.029544856399297714
Valid Loss:  0.02577851712703705
Epoch:  349  	Training Loss: 0.027974238619208336
Test Loss:  0.02954389899969101
Valid Loss:  0.025777021422982216
Epoch:  350  	Training Loss: 0.02797270193696022
Test Loss:  0.029542844742536545
Valid Loss:  0.025775521993637085
Epoch:  351  	Training Loss: 0.0279711727052927
Test Loss:  0.029541727155447006
Valid Loss:  0.025774020701646805
Epoch:  352  	Training Loss: 0.02796965278685093
Test Loss:  0.02954058349132538
Valid Loss:  0.02577253431081772
Epoch:  353  	Training Loss: 0.0279681533575058
Test Loss:  0.029539406299591064
Valid Loss:  0.02577104978263378
Epoch:  354  	Training Loss: 0.027966663241386414
Test Loss:  0.02953820303082466
Valid Loss:  0.025769557803869247
 71%|███████   | 355/500 [04:05<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:06<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:06<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:12<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:12<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:12<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:13<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:19<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:19<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:19<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:19<00:56,  2.20it/s] 76%|███████▌  | 379/500 [04:20<00:41,  2.95it/s] 76%|███████▌  | 381/500 [04:26<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:26<01:37,  1.19it/s] 77%|███████▋  | 385/500 [04:26<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.26it/s] 78%|███████▊  | 389/500 [04:26<00:36,  3.03it/s] 78%|███████▊  | 391/500 [04:32<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:33<01:29,  1.20it/s] 79%|███████▉  | 395/500 [04:33<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.27it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.00it/s] 80%|████████  | 401/500 [04:39<01:54,  1.16s/it] 81%|████████  | 403/500 [04:39<01:20,  1.20it/s] 81%|████████  | 405/500 [04:39<00:57,  1.66it/s] 81%|████████▏ | 407/500 [04:40<00:40,  2.27it/s] 82%|████████▏ | 409/500 [04:40<00:29,  3.05it/s] 82%|████████▏ | 411/500 [04:46<01:43,  1.16s/it] 83%|████████▎ | 413/500 [04:46<01:12,  1.20it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.66it/s] 83%|████████▎ | 417/500 [04:46<00:36,  2.27it/s] 84%|████████▍ | 419/500 [04:46<00:26,  3.05it/s] 84%|████████▍ | 421/500 [04:53<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.20it/s]Epoch:  355  	Training Loss: 0.02796517126262188
Test Loss:  0.02953699603676796
Valid Loss:  0.025768067687749863
Epoch:  356  	Training Loss: 0.027963683009147644
Test Loss:  0.029535770416259766
Valid Loss:  0.025766585022211075
Epoch:  357  	Training Loss: 0.027962200343608856
Test Loss:  0.029534542933106422
Valid Loss:  0.025765102356672287
Epoch:  358  	Training Loss: 0.027960723266005516
Test Loss:  0.029533321037888527
Valid Loss:  0.025763627141714096
Epoch:  359  	Training Loss: 0.027959253638982773
Test Loss:  0.029532087966799736
Valid Loss:  0.025762151926755905
Epoch:  360  	Training Loss: 0.02795778587460518
Test Loss:  0.029530858621001244
Valid Loss:  0.025760680437088013
Epoch:  361  	Training Loss: 0.027956314384937286
Test Loss:  0.029529627412557602
Valid Loss:  0.02575920894742012
Epoch:  362  	Training Loss: 0.02795485407114029
Test Loss:  0.02952839806675911
Valid Loss:  0.025757741183042526
Epoch:  363  	Training Loss: 0.027953393757343292
Test Loss:  0.029527172446250916
Valid Loss:  0.02575628273189068
Epoch:  364  	Training Loss: 0.027951933443546295
Test Loss:  0.029525943100452423
Valid Loss:  0.02575482241809368
Epoch:  365  	Training Loss: 0.027950478717684746
Test Loss:  0.02952471747994423
Valid Loss:  0.025753363966941833
Epoch:  366  	Training Loss: 0.027949027717113495
Test Loss:  0.029523489996790886
Valid Loss:  0.025751907378435135
Epoch:  367  	Training Loss: 0.027947578579187393
Test Loss:  0.02952226623892784
Valid Loss:  0.025750458240509033
Epoch:  368  	Training Loss: 0.02794613316655159
Test Loss:  0.029521038755774498
Valid Loss:  0.02574901282787323
Epoch:  369  	Training Loss: 0.027944687753915787
Test Loss:  0.02951981872320175
Valid Loss:  0.02574756368994713
Epoch:  370  	Training Loss: 0.027943246066570282
Test Loss:  0.029518600553274155
Valid Loss:  0.025746123865246773
Epoch:  371  	Training Loss: 0.027941808104515076
Test Loss:  0.02951737865805626
Valid Loss:  0.02574467845261097
Epoch:  372  	Training Loss: 0.02794037014245987
Test Loss:  0.029516197741031647
Valid Loss:  0.0257432758808136
Epoch:  373  	Training Loss: 0.0279389675706625
Test Loss:  0.029515013098716736
Valid Loss:  0.025741873309016228
Epoch:  374  	Training Loss: 0.02793758362531662
Test Loss:  0.029514137655496597
Valid Loss:  0.02574053965508938
Epoch:  375  	Training Loss: 0.02793620526790619
Test Loss:  0.029513267800211906
Valid Loss:  0.025739219039678574
Epoch:  376  	Training Loss: 0.027934841811656952
Test Loss:  0.029512304812669754
Valid Loss:  0.025737881660461426
Epoch:  377  	Training Loss: 0.027933485805988312
Test Loss:  0.029511289671063423
Valid Loss:  0.02573654241859913
Epoch:  378  	Training Loss: 0.02793213538825512
Test Loss:  0.02951022982597351
Valid Loss:  0.025735197588801384
Epoch:  379  	Training Loss: 0.027930792421102524
Test Loss:  0.02950914576649666
Valid Loss:  0.02573385089635849
Epoch:  380  	Training Loss: 0.027929453179240227
Test Loss:  0.029508035629987717
Valid Loss:  0.025732506066560745
Epoch:  381  	Training Loss: 0.02792811393737793
Test Loss:  0.02950691059231758
Valid Loss:  0.025731151923537254
Epoch:  382  	Training Loss: 0.027926776558160782
Test Loss:  0.02950577810406685
Valid Loss:  0.025729801505804062
Epoch:  383  	Training Loss: 0.027925442904233932
Test Loss:  0.02950463630259037
Valid Loss:  0.02572845108807087
Epoch:  384  	Training Loss: 0.027924109250307083
Test Loss:  0.029503490775823593
Valid Loss:  0.025727100670337677
Epoch:  385  	Training Loss: 0.027922777459025383
Test Loss:  0.029502347111701965
Valid Loss:  0.02572575956583023
Epoch:  386  	Training Loss: 0.02792144939303398
Test Loss:  0.02950119972229004
Valid Loss:  0.025724414736032486
Epoch:  387  	Training Loss: 0.027920126914978027
Test Loss:  0.02950005605816841
Valid Loss:  0.025723077356815338
Epoch:  388  	Training Loss: 0.027918806299567223
Test Loss:  0.02949892170727253
Valid Loss:  0.025721751153469086
Epoch:  389  	Training Loss: 0.027917496860027313
Test Loss:  0.02949777990579605
Valid Loss:  0.025720417499542236
Epoch:  390  	Training Loss: 0.027916185557842255
Test Loss:  0.029496638104319572
Valid Loss:  0.025719087570905685
Epoch:  391  	Training Loss: 0.027914876118302345
Test Loss:  0.029495500028133392
Valid Loss:  0.02571776881814003
Epoch:  392  	Training Loss: 0.027913570404052734
Test Loss:  0.02949432283639908
Valid Loss:  0.02571640908718109
Epoch:  393  	Training Loss: 0.027912229299545288
Test Loss:  0.029493149369955063
Valid Loss:  0.0257150586694479
Epoch:  394  	Training Loss: 0.02791089564561844
Test Loss:  0.029491985216736794
Valid Loss:  0.025713711977005005
Epoch:  395  	Training Loss: 0.02790956012904644
Test Loss:  0.029490813612937927
Valid Loss:  0.02571236342191696
Epoch:  396  	Training Loss: 0.02790823206305504
Test Loss:  0.029489651322364807
Valid Loss:  0.025711020454764366
Epoch:  397  	Training Loss: 0.027906905859708786
Test Loss:  0.02948848530650139
Valid Loss:  0.02570968307554722
Epoch:  398  	Training Loss: 0.027905579656362534
Test Loss:  0.029487324878573418
Valid Loss:  0.02570834942162037
Epoch:  399  	Training Loss: 0.02790425904095173
Test Loss:  0.029486164450645447
Valid Loss:  0.025707019492983818
Epoch:  400  	Training Loss: 0.027902940288186073
Test Loss:  0.029485009610652924
Valid Loss:  0.025705687701702118
Epoch:  401  	Training Loss: 0.027901628986001015
Test Loss:  0.02948385290801525
Valid Loss:  0.025704365223646164
Epoch:  402  	Training Loss: 0.027900317683815956
Test Loss:  0.02948271855711937
Valid Loss:  0.025703057646751404
Epoch:  403  	Training Loss: 0.027899030596017838
Test Loss:  0.029481612145900726
Valid Loss:  0.02570175752043724
Epoch:  404  	Training Loss: 0.02789774164557457
Test Loss:  0.029480542987585068
Valid Loss:  0.025700457394123077
Epoch:  405  	Training Loss: 0.0278964601457119
Test Loss:  0.029479477554559708
Valid Loss:  0.025699160993099213
Epoch:  406  	Training Loss: 0.02789517678320408
Test Loss:  0.02947840839624405
Valid Loss:  0.025697868317365646
Epoch:  407  	Training Loss: 0.027893897145986557
Test Loss:  0.029477348551154137
Valid Loss:  0.025696581229567528
Epoch:  408  	Training Loss: 0.027892619371414185
Test Loss:  0.02947627753019333
Valid Loss:  0.02569529414176941
Epoch:  409  	Training Loss: 0.02789134532213211
Test Loss:  0.029475221410393715
Valid Loss:  0.02569401264190674
Epoch:  410  	Training Loss: 0.027890074998140335
Test Loss:  0.029474161565303802
Valid Loss:  0.02569272555410862
Epoch:  411  	Training Loss: 0.027888808399438858
Test Loss:  0.02947309985756874
Valid Loss:  0.025691451504826546
Epoch:  412  	Training Loss: 0.02788754180073738
Test Loss:  0.02947188913822174
Valid Loss:  0.02569003775715828
Epoch:  413  	Training Loss: 0.027886129915714264
Test Loss:  0.02947067841887474
Valid Loss:  0.02568862773478031
Epoch:  414  	Training Loss: 0.027884723618626595
Test Loss:  0.02946947142481804
Valid Loss:  0.025687221437692642
Epoch:  415  	Training Loss: 0.027883317321538925
Test Loss:  0.029468266293406487
Valid Loss:  0.02568582072854042
Epoch:  416  	Training Loss: 0.027881914749741554
Test Loss:  0.029467061161994934
Valid Loss:  0.0256844200193882
Epoch:  417  	Training Loss: 0.027880515903234482
Test Loss:  0.02946586161851883
Valid Loss:  0.02568301558494568
Epoch:  418  	Training Loss: 0.02787911891937256
Test Loss:  0.029464663937687874
Valid Loss:  0.025681622326374054
Epoch:  419  	Training Loss: 0.027877725660800934
Test Loss:  0.02946346625685692
Valid Loss:  0.02568022906780243
Epoch:  420  	Training Loss: 0.02787633240222931
Test Loss:  0.029462266713380814
Valid Loss:  0.025678839534521103
Epoch:  421  	Training Loss: 0.027874942868947983
Test Loss:  0.029461070895195007
Valid Loss:  0.025677450001239777
Epoch:  422  	Training Loss: 0.027873553335666656
Test Loss:  0.029460011050105095
Valid Loss:  0.025676188990473747
Epoch:  423  	Training Loss: 0.027872297912836075
Test Loss:  0.029458941891789436
Valid Loss:  0.025674916803836823
Epoch:  424  	Training Loss: 0.027871035039424896
Test Loss:  0.029457885771989822
Valid Loss:  0.025673655793070793
Epoch:  425  	Training Loss: 0.027869783341884613
Test Loss:  0.029456831514835358
 85%|████████▌ | 425/500 [04:53<00:45,  1.66it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.27it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.05it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.16s/it] 87%|████████▋ | 433/500 [04:59<00:55,  1.20it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.66it/s] 87%|████████▋ | 437/500 [05:00<00:27,  2.26it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.03it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:07<00:16,  3.00it/s] 90%|█████████ | 451/500 [05:13<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:14<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:27<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.04it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.26it/s] 98%|█████████▊| 489/500 [05:34<00:03,  3.04it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.65it/s]Valid Loss:  0.025672398507595062
Epoch:  426  	Training Loss: 0.02786853164434433
Test Loss:  0.029455777257680893
Valid Loss:  0.02567114308476448
Epoch:  427  	Training Loss: 0.027867283672094345
Test Loss:  0.02945472113788128
Valid Loss:  0.025669891387224197
Epoch:  428  	Training Loss: 0.02786603942513466
Test Loss:  0.02945367619395256
Valid Loss:  0.025668643414974213
Epoch:  429  	Training Loss: 0.02786479890346527
Test Loss:  0.029452625662088394
Valid Loss:  0.025667395442724228
Epoch:  430  	Training Loss: 0.027863558381795883
Test Loss:  0.029451582580804825
Valid Loss:  0.02566615305840969
Epoch:  431  	Training Loss: 0.027862321585416794
Test Loss:  0.02945052832365036
Valid Loss:  0.025664906948804855
Epoch:  432  	Training Loss: 0.027861084789037704
Test Loss:  0.029449500143527985
Valid Loss:  0.025663673877716064
Epoch:  433  	Training Loss: 0.02785985916852951
Test Loss:  0.02944847010076046
Valid Loss:  0.02566244639456272
Epoch:  434  	Training Loss: 0.027858637273311615
Test Loss:  0.029447440057992935
Valid Loss:  0.025661222636699677
Epoch:  435  	Training Loss: 0.027857419103384018
Test Loss:  0.02944641187787056
Valid Loss:  0.025659997016191483
Epoch:  436  	Training Loss: 0.02785620279610157
Test Loss:  0.029445389285683632
Valid Loss:  0.025658775120973587
Epoch:  437  	Training Loss: 0.02785499207675457
Test Loss:  0.029444364830851555
Valid Loss:  0.02565755881369114
Epoch:  438  	Training Loss: 0.02785377949476242
Test Loss:  0.029443342238664627
Valid Loss:  0.02565634809434414
Epoch:  439  	Training Loss: 0.027852576225996017
Test Loss:  0.029442323371767998
Valid Loss:  0.02565513551235199
Epoch:  440  	Training Loss: 0.027851372957229614
Test Loss:  0.02944130450487137
Valid Loss:  0.025653932243585587
Epoch:  441  	Training Loss: 0.02785017155110836
Test Loss:  0.029440291225910187
Valid Loss:  0.025652728974819183
Epoch:  442  	Training Loss: 0.027848977595567703
Test Loss:  0.029439285397529602
Valid Loss:  0.025651536881923676
Epoch:  443  	Training Loss: 0.02784779667854309
Test Loss:  0.029438456520438194
Valid Loss:  0.02565040811896324
Epoch:  444  	Training Loss: 0.027846626937389374
Test Loss:  0.029437633231282234
Valid Loss:  0.025649286806583405
Epoch:  445  	Training Loss: 0.027845468372106552
Test Loss:  0.029436767101287842
Valid Loss:  0.02564815618097782
Epoch:  446  	Training Loss: 0.027844315394759178
Test Loss:  0.029435863718390465
Valid Loss:  0.02564701996743679
Epoch:  447  	Training Loss: 0.027843168005347252
Test Loss:  0.029434939846396446
Valid Loss:  0.02564588002860546
Epoch:  448  	Training Loss: 0.027842018753290176
Test Loss:  0.02943398989737034
Valid Loss:  0.025644730776548386
Epoch:  449  	Training Loss: 0.02784087508916855
Test Loss:  0.029433032497763634
Valid Loss:  0.02564358338713646
Epoch:  450  	Training Loss: 0.02783973515033722
Test Loss:  0.02943206951022148
Valid Loss:  0.025642434135079384
Epoch:  451  	Training Loss: 0.027838600799441338
Test Loss:  0.02943110093474388
Valid Loss:  0.025641288608312607
Epoch:  452  	Training Loss: 0.027837468311190605
Test Loss:  0.029430147260427475
Valid Loss:  0.025640156120061874
Epoch:  453  	Training Loss: 0.027836348861455917
Test Loss:  0.02942918799817562
Valid Loss:  0.02563902735710144
Epoch:  454  	Training Loss: 0.02783523127436638
Test Loss:  0.029428228735923767
Valid Loss:  0.025637898594141006
Epoch:  455  	Training Loss: 0.02783411741256714
Test Loss:  0.029427269473671913
Valid Loss:  0.02563677355647087
Epoch:  456  	Training Loss: 0.027833011001348495
Test Loss:  0.02942631021142006
Valid Loss:  0.025635648518800735
Epoch:  457  	Training Loss: 0.027831900864839554
Test Loss:  0.029425349086523056
Valid Loss:  0.0256345234811306
Epoch:  458  	Training Loss: 0.02783079259097576
Test Loss:  0.02942439541220665
Valid Loss:  0.02563340589404106
Epoch:  459  	Training Loss: 0.027829688042402267
Test Loss:  0.029423438012599945
Valid Loss:  0.025632284581661224
Epoch:  460  	Training Loss: 0.027828583493828773
Test Loss:  0.029422476887702942
Valid Loss:  0.025631168857216835
Epoch:  461  	Training Loss: 0.027827482670545578
Test Loss:  0.029421526938676834
Valid Loss:  0.025630053132772446
Epoch:  462  	Training Loss: 0.027826383709907532
Test Loss:  0.029420558363199234
Valid Loss:  0.02562893182039261
Epoch:  463  	Training Loss: 0.02782527543604374
Test Loss:  0.029419593513011932
Valid Loss:  0.02562781423330307
Epoch:  464  	Training Loss: 0.027824170887470245
Test Loss:  0.02941863052546978
Valid Loss:  0.025626692920923233
Epoch:  465  	Training Loss: 0.027823064476251602
Test Loss:  0.029417669400572777
Valid Loss:  0.025625579059123993
Epoch:  466  	Training Loss: 0.027821969240903854
Test Loss:  0.029416924342513084
Valid Loss:  0.02562454529106617
Epoch:  467  	Training Loss: 0.027820874005556107
Test Loss:  0.029416115954518318
Valid Loss:  0.025623491033911705
Epoch:  468  	Training Loss: 0.027819788083434105
Test Loss:  0.029415268450975418
Valid Loss:  0.025622429326176643
Epoch:  469  	Training Loss: 0.0278187058866024
Test Loss:  0.02941438928246498
Valid Loss:  0.025621358305215836
Epoch:  470  	Training Loss: 0.027817627415060997
Test Loss:  0.029413489624857903
Valid Loss:  0.02562028169631958
Epoch:  471  	Training Loss: 0.02781655080616474
Test Loss:  0.02941257506608963
Valid Loss:  0.025619203224778175
Epoch:  472  	Training Loss: 0.027815476059913635
Test Loss:  0.029411623254418373
Valid Loss:  0.02561809867620468
Epoch:  473  	Training Loss: 0.027814384549856186
Test Loss:  0.029410671442747116
Valid Loss:  0.025616995990276337
Epoch:  474  	Training Loss: 0.027813289314508438
Test Loss:  0.029409712180495262
Valid Loss:  0.025615893304347992
Epoch:  475  	Training Loss: 0.027812203392386436
Test Loss:  0.02940874546766281
Valid Loss:  0.025614790618419647
Epoch:  476  	Training Loss: 0.027811115607619286
Test Loss:  0.02940778248012066
Valid Loss:  0.025613687932491302
Epoch:  477  	Training Loss: 0.027810027822852135
Test Loss:  0.029406815767288208
Valid Loss:  0.025612585246562958
Epoch:  478  	Training Loss: 0.02780894562602043
Test Loss:  0.029405852779746056
Valid Loss:  0.02561149001121521
Epoch:  479  	Training Loss: 0.02780786156654358
Test Loss:  0.029404886066913605
Valid Loss:  0.025610391050577164
Epoch:  480  	Training Loss: 0.027806781232357025
Test Loss:  0.029403915628790855
Valid Loss:  0.025609295815229416
Epoch:  481  	Training Loss: 0.02780570089817047
Test Loss:  0.029402954503893852
Valid Loss:  0.025608202442526817
Epoch:  482  	Training Loss: 0.027804620563983917
Test Loss:  0.02940204367041588
Valid Loss:  0.0256071574985981
Epoch:  483  	Training Loss: 0.027803603559732437
Test Loss:  0.029401136562228203
Valid Loss:  0.025606120005249977
Epoch:  484  	Training Loss: 0.02780258283019066
Test Loss:  0.029400229454040527
Valid Loss:  0.025605084374547005
Epoch:  485  	Training Loss: 0.027801567688584328
Test Loss:  0.02939932979643345
Valid Loss:  0.02560405433177948
Epoch:  486  	Training Loss: 0.027800556272268295
Test Loss:  0.02939843013882637
Valid Loss:  0.025603024289011955
Epoch:  487  	Training Loss: 0.027799546718597412
Test Loss:  0.029397524893283844
Valid Loss:  0.02560199424624443
Epoch:  488  	Training Loss: 0.02779853716492653
Test Loss:  0.029396625235676765
Valid Loss:  0.025600969791412354
Epoch:  489  	Training Loss: 0.027797529473900795
Test Loss:  0.029395723715424538
Valid Loss:  0.025599941611289978
Epoch:  490  	Training Loss: 0.02779652178287506
Test Loss:  0.029394829645752907
Valid Loss:  0.0255989171564579
Epoch:  491  	Training Loss: 0.027795515954494476
Test Loss:  0.02939392812550068
Valid Loss:  0.025597896426916122
Epoch:  492  	Training Loss: 0.02779451571404934
Test Loss:  0.02939300239086151
Valid Loss:  0.025596849620342255
Epoch:  493  	Training Loss: 0.027793478220701218
Test Loss:  0.029392078518867493
Valid Loss:  0.025595806539058685
Epoch:  494  	Training Loss: 0.02779245376586914
Test Loss:  0.029391156509518623
Valid Loss:  0.025594759732484818
Epoch:  495  	Training Loss: 0.027791423723101616
Test Loss:  0.029390227049589157
Valid Loss:  0.025593716651201248
 99%|█████████▉| 497/500 [05:41<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:41<00:00,  3.02it/s]100%|██████████| 500/500 [05:41<00:00,  1.47it/s]
Epoch:  496  	Training Loss: 0.02779039740562439
Test Loss:  0.029389306902885437
Valid Loss:  0.02559267356991768
Epoch:  497  	Training Loss: 0.027789369225502014
Test Loss:  0.02938838303089142
Valid Loss:  0.025591634213924408
Epoch:  498  	Training Loss: 0.027788346633315086
Test Loss:  0.0293874628841877
Valid Loss:  0.025590598583221436
Epoch:  499  	Training Loss: 0.02778732031583786
Test Loss:  0.02938654087483883
Valid Loss:  0.025589559227228165
Epoch:  500  	Training Loss: 0.02778629958629608
Test Loss:  0.02938561886548996
Valid Loss:  0.025588523596525192
seed is  11
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:48,  6.23s/it]  1%|          | 3/500 [00:06<13:47,  1.67s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.22it/s]  4%|▍         | 19/500 [00:13<02:39,  3.02it/s]  4%|▍         | 21/500 [00:19<09:30,  1.19s/it]  5%|▍         | 23/500 [00:19<06:45,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.64it/s]  5%|▌         | 27/500 [00:20<03:33,  2.21it/s]  6%|▌         | 29/500 [00:20<02:37,  2.98it/s]  6%|▌         | 31/500 [00:26<09:09,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.64it/s]  7%|▋         | 37/500 [00:26<03:26,  2.25it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:39<15:56,  2.08s/it]  9%|▊         | 43/500 [00:39<11:16,  1.48s/it]  9%|▉         | 45/500 [00:39<08:00,  1.06s/it]  9%|▉         | 47/500 [00:39<05:43,  1.32it/s] 10%|▉         | 49/500 [00:39<04:07,  1.82it/s] 10%|█         | 51/500 [00:46<09:50,  1.31s/it] 11%|█         | 53/500 [00:46<07:00,  1.06it/s] 11%|█         | 55/500 [00:46<05:02,  1.47it/s] 11%|█▏        | 57/500 [00:46<03:39,  2.02it/s] 12%|█▏        | 59/500 [00:46<02:41,  2.73it/s] 12%|█▏        | 61/500 [00:53<08:47,  1.20s/it] 13%|█▎        | 63/500 [00:53<06:16,  1.16it/s] 13%|█▎        | 65/500 [00:53<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:53<03:17,  2.19it/s]Epoch:  1  	Training Loss: 0.031122224405407906
Test Loss:  0.10110418498516083
Valid Loss:  0.10942572355270386
Epoch:  2  	Training Loss: 0.10678650438785553
Test Loss:  0.04110608994960785
Valid Loss:  0.03855055943131447
Epoch:  3  	Training Loss: 0.041322432458400726
Test Loss:  0.017775852233171463
Valid Loss:  0.02324940264225006
Epoch:  4  	Training Loss: 0.022335484623908997
Test Loss:  0.006930803880095482
Valid Loss:  0.008485933765769005
Epoch:  5  	Training Loss: 0.008869358338415623
Test Loss:  0.0037384263705462217
Valid Loss:  0.005404785741120577
Epoch:  6  	Training Loss: 0.005471883341670036
Test Loss:  0.0029695210978388786
Valid Loss:  0.004129697103053331
Epoch:  7  	Training Loss: 0.00430076289921999
Test Loss:  0.002597338519990444
Valid Loss:  0.0036888746544718742
Epoch:  8  	Training Loss: 0.0037942761555314064
Test Loss:  0.0024143082555383444
Valid Loss:  0.0033358470536768436
Epoch:  9  	Training Loss: 0.003472234820947051
Test Loss:  0.0022566253319382668
Valid Loss:  0.003131780307739973
Epoch:  10  	Training Loss: 0.0032398817129433155
Test Loss:  0.0021407105959951878
Valid Loss:  0.002929028356447816
Epoch:  11  	Training Loss: 0.003037605667486787
Test Loss:  0.0020316545851528645
Valid Loss:  0.00275786267593503
Epoch:  12  	Training Loss: 0.002855905331671238
Test Loss:  0.0018648433033376932
Valid Loss:  0.0022667930461466312
Epoch:  13  	Training Loss: 0.002338474616408348
Test Loss:  0.0018035091925412416
Valid Loss:  0.0020407703705132008
Epoch:  14  	Training Loss: 0.0020985198207199574
Test Loss:  0.0017339494079351425
Valid Loss:  0.0019056005403399467
Epoch:  15  	Training Loss: 0.0019292373908683658
Test Loss:  0.0017143263248726726
Valid Loss:  0.0017610443755984306
Epoch:  16  	Training Loss: 0.0017823928501456976
Test Loss:  0.0016351336380466819
Valid Loss:  0.001642464892938733
Epoch:  17  	Training Loss: 0.0016497350297868252
Test Loss:  0.0015725031262263656
Valid Loss:  0.0014952602796256542
Epoch:  18  	Training Loss: 0.0015116361901164055
Test Loss:  0.0014786169631406665
Valid Loss:  0.0013760520378127694
Epoch:  19  	Training Loss: 0.0013902431819587946
Test Loss:  0.0014417466009035707
Valid Loss:  0.0012897475389763713
Epoch:  20  	Training Loss: 0.0013157210778445005
Test Loss:  0.0014029296580702066
Valid Loss:  0.00126068782992661
Epoch:  21  	Training Loss: 0.0012846228200942278
Test Loss:  0.0013845652574673295
Valid Loss:  0.0012356298975646496
Epoch:  22  	Training Loss: 0.0012620275374501944
Test Loss:  0.0013533238088712096
Valid Loss:  0.0011740485206246376
Epoch:  23  	Training Loss: 0.0012043386232107878
Test Loss:  0.0013364475453272462
Valid Loss:  0.0011451451573520899
Epoch:  24  	Training Loss: 0.0011776976753026247
Test Loss:  0.0013112404849380255
Valid Loss:  0.0011281953193247318
Epoch:  25  	Training Loss: 0.0011595813557505608
Test Loss:  0.0013005497166886926
Valid Loss:  0.0011086971499025822
Epoch:  26  	Training Loss: 0.0011428847210481763
Test Loss:  0.001278694486245513
Valid Loss:  0.0010959948413074017
Epoch:  27  	Training Loss: 0.0011280542239546776
Test Loss:  0.0012719817459583282
Valid Loss:  0.00107885105535388
Epoch:  28  	Training Loss: 0.0011143680894747376
Test Loss:  0.0012500343145802617
Valid Loss:  0.0010695941746234894
Epoch:  29  	Training Loss: 0.001102191861718893
Test Loss:  0.0012496532872319221
Valid Loss:  0.0010530296713113785
Epoch:  30  	Training Loss: 0.0010900518391281366
Test Loss:  0.0012216827599331737
Valid Loss:  0.0010398334125056863
Epoch:  31  	Training Loss: 0.001073246356099844
Test Loss:  0.001221753191202879
Valid Loss:  0.001013395143672824
Epoch:  32  	Training Loss: 0.0010502910008653998
Test Loss:  0.0011640824377536774
Valid Loss:  0.0009776621591299772
Epoch:  33  	Training Loss: 0.0010061354842036963
Test Loss:  0.0011578539852052927
Valid Loss:  0.0009676490444689989
Epoch:  34  	Training Loss: 0.001004477497190237
Test Loss:  0.0011904231505468488
Valid Loss:  0.0010738004930317402
Epoch:  35  	Training Loss: 0.001090731006115675
Test Loss:  0.002089462010189891
Valid Loss:  0.0017453203909099102
Epoch:  36  	Training Loss: 0.0018137902952730656
Test Loss:  0.004595511592924595
Valid Loss:  0.004909743554890156
Epoch:  37  	Training Loss: 0.004826158285140991
Test Loss:  0.006784080062061548
Valid Loss:  0.006330424919724464
Epoch:  38  	Training Loss: 0.006401786580681801
Test Loss:  0.007769682910293341
Valid Loss:  0.008279029279947281
Epoch:  39  	Training Loss: 0.008225140161812305
Test Loss:  0.006383037194609642
Valid Loss:  0.005859937518835068
Epoch:  40  	Training Loss: 0.005938740912824869
Test Loss:  0.005482793785631657
Valid Loss:  0.005793954711407423
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.005823439918458462
Test Loss:  0.0014647922944277525
Valid Loss:  0.0013282473664730787
Epoch:  42  	Training Loss: 0.001386844553053379
Test Loss:  0.001462125568650663
Valid Loss:  0.001222715014591813
Epoch:  43  	Training Loss: 0.0012842309661209583
Test Loss:  0.0014174291864037514
Valid Loss:  0.0011734056752175093
Epoch:  44  	Training Loss: 0.001229151850566268
Test Loss:  0.0013820971362292767
Valid Loss:  0.0011286684311926365
Epoch:  45  	Training Loss: 0.0011817882768809795
Test Loss:  0.0013363466132432222
Valid Loss:  0.0010826587677001953
Epoch:  46  	Training Loss: 0.001133643789216876
Test Loss:  0.0012846197932958603
Valid Loss:  0.0010363231413066387
Epoch:  47  	Training Loss: 0.0010845183860510588
Test Loss:  0.0012295118067413568
Valid Loss:  0.000991289271041751
Epoch:  48  	Training Loss: 0.0010356387356296182
Test Loss:  0.0011829647701233625
Valid Loss:  0.0009555118740536273
Epoch:  49  	Training Loss: 0.0009961612522602081
Test Loss:  0.0011553718941286206
Valid Loss:  0.0009339560056105256
Epoch:  50  	Training Loss: 0.0009732982143759727
Test Loss:  0.001147126080468297
Valid Loss:  0.0009244164102710783
Epoch:  51  	Training Loss: 0.0009632642613723874
Test Loss:  0.0011471959296613932
Valid Loss:  0.0009209419367834926
Epoch:  52  	Training Loss: 0.0009595579467713833
Test Loss:  0.0011454117484390736
Valid Loss:  0.0009155123843811452
Epoch:  53  	Training Loss: 0.0009551728144288063
Test Loss:  0.001138283871114254
Valid Loss:  0.000913277268409729
Epoch:  54  	Training Loss: 0.0009515794226899743
Test Loss:  0.0011352242436259985
Valid Loss:  0.000910145347006619
Epoch:  55  	Training Loss: 0.0009484238107688725
Test Loss:  0.0011302074417471886
Valid Loss:  0.0009083313634619117
Epoch:  56  	Training Loss: 0.0009457943961024284
Test Loss:  0.001126528368331492
Valid Loss:  0.0009065775666385889
Epoch:  57  	Training Loss: 0.0009435884421691298
Test Loss:  0.0011226676870137453
Valid Loss:  0.0009053052635863423
Epoch:  58  	Training Loss: 0.0009418126428499818
Test Loss:  0.0011192526435479522
Valid Loss:  0.0009041196899488568
Epoch:  59  	Training Loss: 0.0009403271251358092
Test Loss:  0.0011159098939970136
Valid Loss:  0.0009031828958541155
Epoch:  60  	Training Loss: 0.0009390877094119787
Test Loss:  0.0011132308281958103
Valid Loss:  0.0009023993043228984
Epoch:  61  	Training Loss: 0.0009381050476804376
Test Loss:  0.0011108794715255499
Valid Loss:  0.0009017600095830858
Epoch:  62  	Training Loss: 0.0009373051580041647
Test Loss:  0.0011058237869292498
Valid Loss:  0.0008996123215183616
Epoch:  63  	Training Loss: 0.0009349426254630089
Test Loss:  0.0011014981428161263
Valid Loss:  0.0008974750526249409
Epoch:  64  	Training Loss: 0.0009327325387857854
Test Loss:  0.0010971503797918558
Valid Loss:  0.0008953767828643322
Epoch:  65  	Training Loss: 0.000930562790017575
Test Loss:  0.001092413323931396
Valid Loss:  0.0008931514457799494
Epoch:  66  	Training Loss: 0.0009283695835620165
Test Loss:  0.0010878462344408035
Valid Loss:  0.000890927913133055
Epoch:  67  	Training Loss: 0.0009260810911655426
Test Loss:  0.0010822067270055413
Valid Loss:  0.0008882420952431858
Epoch:  68  	Training Loss: 0.0009233445161953568
Test Loss:  0.0010715716052800417
Valid Loss:  0.0008820827933959663
Epoch:  69  	Training Loss: 0.0009166763629764318
Test Loss:   14%|█▍        | 69/500 [00:53<02:25,  2.96it/s] 14%|█▍        | 71/500 [00:59<08:28,  1.18s/it] 15%|█▍        | 73/500 [01:00<06:03,  1.18it/s] 15%|█▌        | 75/500 [01:00<04:21,  1.63it/s] 15%|█▌        | 77/500 [01:00<03:10,  2.22it/s] 16%|█▌        | 79/500 [01:00<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:06<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:06<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:07<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:07<03:07,  2.21it/s] 18%|█▊        | 89/500 [01:07<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:13<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:13<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:13<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:13<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:14<02:15,  2.96it/s] 20%|██        | 101/500 [01:20<07:58,  1.20s/it] 21%|██        | 103/500 [01:20<05:41,  1.16it/s] 21%|██        | 105/500 [01:20<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:20<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.96it/s] 22%|██▏       | 111/500 [01:27<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:27<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:27<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:27<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:27<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:34<07:37,  1.21s/it] 25%|██▍       | 123/500 [01:34<05:26,  1.16it/s] 25%|██▌       | 125/500 [01:34<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:34<02:51,  2.17it/s] 26%|██▌       | 129/500 [01:34<02:07,  2.92it/s] 26%|██▌       | 131/500 [01:41<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:41<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:41<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:41<02:44,  2.21it/s]0.001071406528353691
Valid Loss:  0.0008805713732726872
Epoch:  70  	Training Loss: 0.0009153544087894261
Test Loss:  0.0010705876629799604
Valid Loss:  0.0008793020388111472
Epoch:  71  	Training Loss: 0.0009141131304204464
Test Loss:  0.0010695650707930326
Valid Loss:  0.0008781110518611968
Epoch:  72  	Training Loss: 0.0009128990350291133
Test Loss:  0.0010706757893785834
Valid Loss:  0.0008756897877901793
Epoch:  73  	Training Loss: 0.0009094264241866767
Test Loss:  0.001075157430022955
Valid Loss:  0.0008725443040020764
Epoch:  74  	Training Loss: 0.0009067667415365577
Test Loss:  0.0010738976998254657
Valid Loss:  0.0008711755508556962
Epoch:  75  	Training Loss: 0.0009048316860571504
Test Loss:  0.001075197011232376
Valid Loss:  0.0008692901465110481
Epoch:  76  	Training Loss: 0.0009030360961332917
Test Loss:  0.001073078834451735
Valid Loss:  0.000868304050527513
Epoch:  77  	Training Loss: 0.0009013431263156235
Test Loss:  0.0010729540372267365
Valid Loss:  0.0008666872163303196
Epoch:  78  	Training Loss: 0.0008997261174954474
Test Loss:  0.0010704410960897803
Valid Loss:  0.000865722366143018
Epoch:  79  	Training Loss: 0.0008981649880297482
Test Loss:  0.001069457153789699
Valid Loss:  0.0008642763714306056
Epoch:  80  	Training Loss: 0.0008966508321464062
Test Loss:  0.0010668141767382622
Valid Loss:  0.0008633130346424878
Epoch:  81  	Training Loss: 0.0008952227071858943
Test Loss:  0.0010652646888047457
Valid Loss:  0.0008620216394774616
Epoch:  82  	Training Loss: 0.0008939169347286224
Test Loss:  0.0010386814828962088
Valid Loss:  0.000837164930999279
Epoch:  83  	Training Loss: 0.0008682459592819214
Test Loss:  0.0010208794847130775
Valid Loss:  0.0008177631534636021
Epoch:  84  	Training Loss: 0.0008483059355057776
Test Loss:  0.0010099709033966064
Valid Loss:  0.0008036972722038627
Epoch:  85  	Training Loss: 0.0008341620559804142
Test Loss:  0.001000505406409502
Valid Loss:  0.0007927999831736088
Epoch:  86  	Training Loss: 0.0008232704130932689
Test Loss:  0.000992817454971373
Valid Loss:  0.0007846379885450006
Epoch:  87  	Training Loss: 0.0008144340245053172
Test Loss:  0.0009848835179582238
Valid Loss:  0.0007780134910717607
Epoch:  88  	Training Loss: 0.000806629890576005
Test Loss:  0.0009781182743608952
Valid Loss:  0.0007722447044216096
Epoch:  89  	Training Loss: 0.0007997559732757509
Test Loss:  0.0009710212470963597
Valid Loss:  0.0007681962451897562
Epoch:  90  	Training Loss: 0.0007941877702251077
Test Loss:  0.0009643586236052215
Valid Loss:  0.0007644480792805552
Epoch:  91  	Training Loss: 0.0007892051944509149
Test Loss:  0.0009575615986250341
Valid Loss:  0.0007609015447087586
Epoch:  92  	Training Loss: 0.0007845086511224508
Test Loss:  0.0009401580318808556
Valid Loss:  0.0007269415655173361
Epoch:  93  	Training Loss: 0.0007529176073148847
Test Loss:  0.0009123000781983137
Valid Loss:  0.000705778191331774
Epoch:  94  	Training Loss: 0.0007335635018534958
Test Loss:  0.0008956043748185039
Valid Loss:  0.0007027997053228319
Epoch:  95  	Training Loss: 0.0007293361704796553
Test Loss:  0.000888969749212265
Valid Loss:  0.0007024686201475561
Epoch:  96  	Training Loss: 0.0007286069449037313
Test Loss:  0.0008859609952196479
Valid Loss:  0.0007025762461125851
Epoch:  97  	Training Loss: 0.0007284745806828141
Test Loss:  0.0008851286256685853
Valid Loss:  0.0007025147788226604
Epoch:  98  	Training Loss: 0.0007284367457032204
Test Loss:  0.0008838261710479856
Valid Loss:  0.0007026187377050519
Epoch:  99  	Training Loss: 0.0007284211460500956
Test Loss:  0.0008835095795802772
Valid Loss:  0.0007025895174592733
Epoch:  100  	Training Loss: 0.0007284148596227169
Test Loss:  0.0008831338491290808
Valid Loss:  0.0007025874801911414
Epoch:  101  	Training Loss: 0.0007284106104634702
Test Loss:  0.0008827178389765322
Valid Loss:  0.0007025967934168875
Epoch:  102  	Training Loss: 0.0007284076418727636
Test Loss:  0.0008787621627561748
Valid Loss:  0.0006919316947460175
Epoch:  103  	Training Loss: 0.0007174826459959149
Test Loss:  0.0008744155056774616
Valid Loss:  0.0006802905118092895
Epoch:  104  	Training Loss: 0.0007058057235553861
Test Loss:  0.0008687725057825446
Valid Loss:  0.0006687759305350482
Epoch:  105  	Training Loss: 0.0006942249601706862
Test Loss:  0.000862621353007853
Valid Loss:  0.000657697266433388
Epoch:  106  	Training Loss: 0.0006832400104030967
Test Loss:  0.0008566813776269555
Valid Loss:  0.0006479290896095335
Epoch:  107  	Training Loss: 0.0006734667113050818
Test Loss:  0.0008509785402566195
Valid Loss:  0.0006397668039426208
Epoch:  108  	Training Loss: 0.0006650937139056623
Test Loss:  0.0008457085350528359
Valid Loss:  0.000632721814326942
Epoch:  109  	Training Loss: 0.0006581538473255932
Test Loss:  0.000841211061924696
Valid Loss:  0.0006269734585657716
Epoch:  110  	Training Loss: 0.0006526014767587185
Test Loss:  0.0008368517737835646
Valid Loss:  0.0006224457756616175
Epoch:  111  	Training Loss: 0.0006477835704572499
Test Loss:  0.0008326908573508263
Valid Loss:  0.0006184211233630776
Epoch:  112  	Training Loss: 0.0006433021044358611
Test Loss:  0.0008320498745888472
Valid Loss:  0.0006173597648739815
Epoch:  113  	Training Loss: 0.0006427751504816115
Test Loss:  0.0008300032932311296
Valid Loss:  0.0006171599961817265
Epoch:  114  	Training Loss: 0.0006424461025744677
Test Loss:  0.0008282840135507286
Valid Loss:  0.0006168856634758413
Epoch:  115  	Training Loss: 0.0006421431316994131
Test Loss:  0.0008265972719527781
Valid Loss:  0.0006166429375298321
Epoch:  116  	Training Loss: 0.000641860649921
Test Loss:  0.0008249834645539522
Valid Loss:  0.000616415636613965
Epoch:  117  	Training Loss: 0.0006415968528017402
Test Loss:  0.0008234354900196195
Valid Loss:  0.0006162051577121019
Epoch:  118  	Training Loss: 0.0006413506343960762
Test Loss:  0.0008219480514526367
Valid Loss:  0.0006160082994028926
Epoch:  119  	Training Loss: 0.0006411207723431289
Test Loss:  0.0008205369231291115
Valid Loss:  0.000615824363194406
Epoch:  120  	Training Loss: 0.0006409049965441227
Test Loss:  0.0008191845845431089
Valid Loss:  0.0006156531162559986
Epoch:  121  	Training Loss: 0.0006407038890756667
Test Loss:  0.0008178841089829803
Valid Loss:  0.0006154935108497739
Epoch:  122  	Training Loss: 0.0006405161693692207
Test Loss:  0.0008139974670484662
Valid Loss:  0.0006077715661376715
Epoch:  123  	Training Loss: 0.000629320100415498
Test Loss:  0.0008126760949380696
Valid Loss:  0.0006029679789207876
Epoch:  124  	Training Loss: 0.0006251868908293545
Test Loss:  0.0008085887529887259
Valid Loss:  0.0006006441544741392
Epoch:  125  	Training Loss: 0.0006223708624020219
Test Loss:  0.000804633367806673
Valid Loss:  0.0005981642752885818
Epoch:  126  	Training Loss: 0.000619826721958816
Test Loss:  0.0008004474802874029
Valid Loss:  0.0005961662391200662
Epoch:  127  	Training Loss: 0.0006174339214339852
Test Loss:  0.0007962738163769245
Valid Loss:  0.0005942460265941918
Epoch:  128  	Training Loss: 0.0006152444984763861
Test Loss:  0.0007919129566289485
Valid Loss:  0.0005923727294430137
Epoch:  129  	Training Loss: 0.0006131593836471438
Test Loss:  0.000787610886618495
Valid Loss:  0.0005906032747589052
Epoch:  130  	Training Loss: 0.0006111916154623032
Test Loss:  0.0007836967124603689
Valid Loss:  0.0005889837630093098
Epoch:  131  	Training Loss: 0.0006092959665693343
Test Loss:  0.0007800571620464325
Valid Loss:  0.0005873252521269023
Epoch:  132  	Training Loss: 0.0006074425764381886
Test Loss:  0.0007762694731354713
Valid Loss:  0.0005842030514031649
Epoch:  133  	Training Loss: 0.000604049360845238
Test Loss:  0.0007732731173746288
Valid Loss:  0.000581864733248949
Epoch:  134  	Training Loss: 0.0006014651153236628
Test Loss:  0.0007703785668127239
Valid Loss:  0.0005796565092168748
Epoch:  135  	Training Loss: 0.0005990207428112626
Test Loss:  0.000767745659686625
Valid Loss:  0.0005776912439614534
Epoch:  136  	Training Loss: 0.0005968575133010745
Test Loss:  0.0007652553031221032
Valid Loss:  0.0005757653270848095
Epoch:  137  	Training Loss: 0.0005948094185441732
Test Loss:  0.0007628924795426428
Valid Loss:  0.0005739170010201633
 28%|██▊       | 139/500 [01:41<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:48<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:48<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:48<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:48<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:48<01:56,  3.01it/s] 30%|███       | 151/500 [01:54<06:53,  1.19s/it] 31%|███       | 153/500 [01:55<04:55,  1.17it/s] 31%|███       | 155/500 [01:55<03:32,  1.63it/s] 31%|███▏      | 157/500 [01:55<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:55<01:54,  2.98it/s] 32%|███▏      | 161/500 [02:01<06:40,  1.18s/it] 33%|███▎      | 163/500 [02:01<04:46,  1.18it/s] 33%|███▎      | 165/500 [02:02<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:02<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:02<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:08<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:08<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:08<03:18,  1.63it/s] 35%|███▌      | 177/500 [02:09<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:09<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:15<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:15<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:15<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:15<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:16<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:22<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:22<04:21,  1.18it/s] 39%|███▉      | 195/500 [02:22<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:22<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:22<01:40,  2.99it/s] 40%|████      | 201/500 [02:29<05:53,  1.18s/it] 41%|████      | 203/500 [02:29<04:11,  1.18it/s] 41%|████      | 205/500 [02:29<03:00,  1.63it/s]Epoch:  138  	Training Loss: 0.0005929272156208754
Test Loss:  0.0007607426960021257
Valid Loss:  0.0005723510985262692
Epoch:  139  	Training Loss: 0.000591323128901422
Test Loss:  0.0007585872663185
Valid Loss:  0.0005708069656975567
Epoch:  140  	Training Loss: 0.0005898158997297287
Test Loss:  0.0007564750267192721
Valid Loss:  0.000569355848710984
Epoch:  141  	Training Loss: 0.0005883881822228432
Test Loss:  0.0007543697720393538
Valid Loss:  0.0005679123569279909
Epoch:  142  	Training Loss: 0.0005869819433428347
Test Loss:  0.0007535015465691686
Valid Loss:  0.0005653090192936361
Epoch:  143  	Training Loss: 0.0005846747662872076
Test Loss:  0.0007507838308811188
Valid Loss:  0.0005627661594189703
Epoch:  144  	Training Loss: 0.0005815772456116974
Test Loss:  0.0007488969713449478
Valid Loss:  0.0005601711454801261
Epoch:  145  	Training Loss: 0.0005790917202830315
Test Loss:  0.0007467153482139111
Valid Loss:  0.000559830863494426
Epoch:  146  	Training Loss: 0.0005780941573902965
Test Loss:  0.0007451826822943985
Valid Loss:  0.000558947678655386
Epoch:  147  	Training Loss: 0.000577135942876339
Test Loss:  0.0007432273705489933
Valid Loss:  0.0005585448234342039
Epoch:  148  	Training Loss: 0.0005762019427493215
Test Loss:  0.0007415368454530835
Valid Loss:  0.0005578650161623955
Epoch:  149  	Training Loss: 0.0005753092700615525
Test Loss:  0.0007395974243991077
Valid Loss:  0.000557278806809336
Epoch:  150  	Training Loss: 0.0005743823712691665
Test Loss:  0.0007362212054431438
Valid Loss:  0.0005517826648429036
Epoch:  151  	Training Loss: 0.0005692298291251063
Test Loss:  0.0007358264410868287
Valid Loss:  0.0005500089609995484
Epoch:  152  	Training Loss: 0.0005662554758600891
Test Loss:  0.0007168673910200596
Valid Loss:  0.0005433328915387392
Epoch:  153  	Training Loss: 0.0005586588522419333
Test Loss:  0.000707783387042582
Valid Loss:  0.0005383174866437912
Epoch:  154  	Training Loss: 0.0005540078273043036
Test Loss:  0.0007010082481428981
Valid Loss:  0.0005343251395970583
Epoch:  155  	Training Loss: 0.0005501548293977976
Test Loss:  0.0006954969139769673
Valid Loss:  0.0005306548555381596
Epoch:  156  	Training Loss: 0.0005465459544211626
Test Loss:  0.0006911256932653487
Valid Loss:  0.000527330266777426
Epoch:  157  	Training Loss: 0.0005431355675682425
Test Loss:  0.0006873314850963652
Valid Loss:  0.0005234595737420022
Epoch:  158  	Training Loss: 0.0005393011379055679
Test Loss:  0.0006820293492637575
Valid Loss:  0.0005164861213415861
Epoch:  159  	Training Loss: 0.0005325289675965905
Test Loss:  0.0006765412981621921
Valid Loss:  0.0005100109265185893
Epoch:  160  	Training Loss: 0.0005257385782897472
Test Loss:  0.0006719386437907815
Valid Loss:  0.0005064475699327886
Epoch:  161  	Training Loss: 0.0005213817348703742
Test Loss:  0.000667861255351454
Valid Loss:  0.0005032450426369905
Epoch:  162  	Training Loss: 0.0005179293802939355
Test Loss:  0.0006659921491518617
Valid Loss:  0.0004982808604836464
Epoch:  163  	Training Loss: 0.0005123536102473736
Test Loss:  0.0006632235599681735
Valid Loss:  0.0004955204203724861
Epoch:  164  	Training Loss: 0.0005083814612589777
Test Loss:  0.0006600325577892363
Valid Loss:  0.0004927399568259716
Epoch:  165  	Training Loss: 0.0005051211337558925
Test Loss:  0.0006562218186445534
Valid Loss:  0.0004904490779154003
Epoch:  166  	Training Loss: 0.000502362847328186
Test Loss:  0.00065267039462924
Valid Loss:  0.00048787955893203616
Epoch:  167  	Training Loss: 0.0004998665535822511
Test Loss:  0.0006487664068117738
Valid Loss:  0.0004858280881308019
Epoch:  168  	Training Loss: 0.000497493427246809
Test Loss:  0.0006455174880102277
Valid Loss:  0.0004834296414628625
Epoch:  169  	Training Loss: 0.0004952311282977462
Test Loss:  0.0006418328848667443
Valid Loss:  0.0004815409192815423
Epoch:  170  	Training Loss: 0.0004930684808641672
Test Loss:  0.0006387034663930535
Valid Loss:  0.0004793346452061087
Epoch:  171  	Training Loss: 0.0004909605486318469
Test Loss:  0.0006352858035825193
Valid Loss:  0.000477575056720525
Epoch:  172  	Training Loss: 0.000488900812342763
Test Loss:  0.0006325293215923011
Valid Loss:  0.0004766317433677614
Epoch:  173  	Training Loss: 0.0004874435253441334
Test Loss:  0.000629748567007482
Valid Loss:  0.00047574861673638225
Epoch:  174  	Training Loss: 0.0004862641799263656
Test Loss:  0.0006270162994042039
Valid Loss:  0.0004750108637381345
Epoch:  175  	Training Loss: 0.00048522025463171303
Test Loss:  0.0006243448005989194
Valid Loss:  0.0004743029421661049
Epoch:  176  	Training Loss: 0.0004842995840590447
Test Loss:  0.0006218026974238455
Valid Loss:  0.00047374929999932647
Epoch:  177  	Training Loss: 0.00048343578237108886
Test Loss:  0.0006194716552272439
Valid Loss:  0.0004731909721158445
Epoch:  178  	Training Loss: 0.00048265582881867886
Test Loss:  0.0006171045824885368
Valid Loss:  0.0004727944906335324
Epoch:  179  	Training Loss: 0.0004819785535801202
Test Loss:  0.0006150350673124194
Valid Loss:  0.0004723456222563982
Epoch:  180  	Training Loss: 0.00048136606346815825
Test Loss:  0.0006129301618784666
Valid Loss:  0.00047200804692693055
Epoch:  181  	Training Loss: 0.0004808248486369848
Test Loss:  0.0006111121037974954
Valid Loss:  0.0004716513503808528
Epoch:  182  	Training Loss: 0.0004803134361281991
Test Loss:  0.0006102532497607172
Valid Loss:  0.0004670237540267408
Epoch:  183  	Training Loss: 0.0004754103720188141
Test Loss:  0.0006060355808585882
Valid Loss:  0.0004656524979509413
Epoch:  184  	Training Loss: 0.00047300587175413966
Test Loss:  0.0006041586166247725
Valid Loss:  0.0004630707553587854
Epoch:  185  	Training Loss: 0.0004709014610853046
Test Loss:  0.000600390019826591
Valid Loss:  0.00046171745634637773
Epoch:  186  	Training Loss: 0.0004689731285907328
Test Loss:  0.0005978457047604024
Valid Loss:  0.000459658564068377
Epoch:  187  	Training Loss: 0.0004671867936849594
Test Loss:  0.0005944964359514415
Valid Loss:  0.00045819414663128555
Epoch:  188  	Training Loss: 0.00046547444071620703
Test Loss:  0.000591953459661454
Valid Loss:  0.00045635312562808394
Epoch:  189  	Training Loss: 0.0004638065001927316
Test Loss:  0.0005891068722121418
Valid Loss:  0.000454832857940346
Epoch:  190  	Training Loss: 0.00046217479393817484
Test Loss:  0.0005867110448889434
Valid Loss:  0.00045312842121347785
Epoch:  191  	Training Loss: 0.00046057376312091947
Test Loss:  0.0005842117825523019
Valid Loss:  0.0004515908658504486
Epoch:  192  	Training Loss: 0.0004589985474012792
Test Loss:  0.0005833272007293999
Valid Loss:  0.0004501485964283347
Epoch:  193  	Training Loss: 0.0004569516167975962
Test Loss:  0.0005823401152156293
Valid Loss:  0.00044873805018141866
Epoch:  194  	Training Loss: 0.0004550134763121605
Test Loss:  0.0005813105963170528
Valid Loss:  0.0004473495646379888
Epoch:  195  	Training Loss: 0.0004531934973783791
Test Loss:  0.0005801637307740748
Valid Loss:  0.0004459998453967273
Epoch:  196  	Training Loss: 0.00045144816976971924
Test Loss:  0.0005790424766018987
Valid Loss:  0.00044466284452937543
Epoch:  197  	Training Loss: 0.0004498144844546914
Test Loss:  0.0005777932237833738
Valid Loss:  0.00044336795690469444
Epoch:  198  	Training Loss: 0.00044837387395091355
Test Loss:  0.0005765313399024308
Valid Loss:  0.00044210650958120823
Epoch:  199  	Training Loss: 0.0004470476706046611
Test Loss:  0.0005752136930823326
Valid Loss:  0.00044089125003665686
Epoch:  200  	Training Loss: 0.00044576742220669985
Test Loss:  0.0005738232284784317
Valid Loss:  0.00043970177648589015
Epoch:  201  	Training Loss: 0.00044452943257056177
Test Loss:  0.0005724922521039844
Valid Loss:  0.0004385227512102574
Epoch:  202  	Training Loss: 0.0004433024732861668
Test Loss:  0.000568314571864903
Valid Loss:  0.0004355800920166075
Epoch:  203  	Training Loss: 0.0004398526798468083
Test Loss:  0.000564957270398736
Valid Loss:  0.00043269299203529954
Epoch:  204  	Training Loss: 0.0004367405781522393
Test Loss:  0.0005618080613203347
Valid Loss:  0.0004301034496165812
Epoch:  205  	Training Loss: 0.0004338507424108684
Test Loss:  0.0005587548366747797
Valid Loss:  0.00042770718573592603
 41%|████▏     | 207/500 [02:29<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:29<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:36<05:42,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:36<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:36<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:36<01:34,  2.99it/s] 44%|████▍     | 221/500 [02:42<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:43<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:43<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:43<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:43<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:49<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:49<03:45,  1.19it/s] 47%|████▋     | 235/500 [02:49<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:50<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:50<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:56<05:06,  1.19s/it] 49%|████▊     | 243/500 [02:56<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:56<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:56<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:57<01:24,  2.98it/s] 50%|█████     | 251/500 [03:03<04:54,  1.18s/it] 51%|█████     | 253/500 [03:03<03:29,  1.18it/s] 51%|█████     | 255/500 [03:03<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:03<01:48,  2.23it/s] 52%|█████▏    | 259/500 [03:03<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:10<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:10<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:10<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:10<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:10<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:17<04:31,  1.18s/it]Epoch:  206  	Training Loss: 0.00043125057709403336
Test Loss:  0.0005557583644986153
Valid Loss:  0.0004256001557223499
Epoch:  207  	Training Loss: 0.00042884721187874675
Test Loss:  0.000552782672457397
Valid Loss:  0.00042370802839286625
Epoch:  208  	Training Loss: 0.00042663951171562076
Test Loss:  0.0005498501705005765
Valid Loss:  0.00042193473200313747
Epoch:  209  	Training Loss: 0.00042460800614207983
Test Loss:  0.0005470617907121778
Valid Loss:  0.00042021129047498107
Epoch:  210  	Training Loss: 0.00042265531374141574
Test Loss:  0.0005444036796689034
Valid Loss:  0.000418531009927392
Epoch:  211  	Training Loss: 0.0004207609163131565
Test Loss:  0.0005418427754193544
Valid Loss:  0.00041688952478580177
Epoch:  212  	Training Loss: 0.00041895045433193445
Test Loss:  0.000539260683581233
Valid Loss:  0.00041403304203413427
Epoch:  213  	Training Loss: 0.00041591335320845246
Test Loss:  0.0005366778350435197
Valid Loss:  0.0004113710019737482
Epoch:  214  	Training Loss: 0.00041309307562187314
Test Loss:  0.0005342183285392821
Valid Loss:  0.00040896545397117734
Epoch:  215  	Training Loss: 0.0004105998668819666
Test Loss:  0.0005318312905728817
Valid Loss:  0.0004067955887876451
Epoch:  216  	Training Loss: 0.0004083969397470355
Test Loss:  0.0005294873844832182
Valid Loss:  0.00040477613219991326
Epoch:  217  	Training Loss: 0.00040636007906869054
Test Loss:  0.0005271742702461779
Valid Loss:  0.00040284194983541965
Epoch:  218  	Training Loss: 0.0004043856752105057
Test Loss:  0.0005248872330412269
Valid Loss:  0.00040093075949698687
Epoch:  219  	Training Loss: 0.000402455945732072
Test Loss:  0.0005226988578215241
Valid Loss:  0.000399098003981635
Epoch:  220  	Training Loss: 0.0004005894297733903
Test Loss:  0.0005205883062444627
Valid Loss:  0.00039732971345074475
Epoch:  221  	Training Loss: 0.000398781499825418
Test Loss:  0.0005185304908081889
Valid Loss:  0.00039560155710205436
Epoch:  222  	Training Loss: 0.00039701838977634907
Test Loss:  0.0005176051054149866
Valid Loss:  0.0003952067927457392
Epoch:  223  	Training Loss: 0.0003967077936977148
Test Loss:  0.0005166870541870594
Valid Loss:  0.0003948519879486412
Epoch:  224  	Training Loss: 0.000396412011468783
Test Loss:  0.0005158074200153351
Valid Loss:  0.000394522154238075
Epoch:  225  	Training Loss: 0.0003961272013839334
Test Loss:  0.0005149618373252451
Valid Loss:  0.0003942091134376824
Epoch:  226  	Training Loss: 0.0003958576708100736
Test Loss:  0.0005141585716046393
Valid Loss:  0.0003939177840948105
Epoch:  227  	Training Loss: 0.00039560499135404825
Test Loss:  0.0005133940139785409
Valid Loss:  0.0003936351276934147
Epoch:  228  	Training Loss: 0.0003953604609705508
Test Loss:  0.0005126641481183469
Valid Loss:  0.00039335948531515896
Epoch:  229  	Training Loss: 0.00039512309012934566
Test Loss:  0.0005119698471389711
Valid Loss:  0.0003930918173864484
Epoch:  230  	Training Loss: 0.00039489177288487554
Test Loss:  0.0005113083170726895
Valid Loss:  0.00039282976649701595
Epoch:  231  	Training Loss: 0.00039466971065849066
Test Loss:  0.0005106828175485134
Valid Loss:  0.0003925776691175997
Epoch:  232  	Training Loss: 0.0003944571362808347
Test Loss:  0.0005106996395625174
Valid Loss:  0.00039178234874270856
Epoch:  233  	Training Loss: 0.00039165810449048877
Test Loss:  0.0005108250770717859
Valid Loss:  0.00038948969449847937
Epoch:  234  	Training Loss: 0.00038970488822087646
Test Loss:  0.0005082897841930389
Valid Loss:  0.00038883188972249627
Epoch:  235  	Training Loss: 0.0003881119191646576
Test Loss:  0.000506738550029695
Valid Loss:  0.00038692489033564925
Epoch:  236  	Training Loss: 0.0003866131301037967
Test Loss:  0.0005039273528382182
Valid Loss:  0.0003861943259835243
Epoch:  237  	Training Loss: 0.00038520287489518523
Test Loss:  0.0005021216347813606
Valid Loss:  0.00038453246816061437
Epoch:  238  	Training Loss: 0.0003838208212982863
Test Loss:  0.0004995630588382483
Valid Loss:  0.0003837697731796652
Epoch:  239  	Training Loss: 0.0003824612940661609
Test Loss:  0.0004977601347491145
Valid Loss:  0.00038226673495955765
Epoch:  240  	Training Loss: 0.00038115319330245256
Test Loss:  0.0004952388699166477
Valid Loss:  0.0003814946976490319
Epoch:  241  	Training Loss: 0.00037992786383256316
Test Loss:  0.0004933062009513378
Valid Loss:  0.0003801390412263572
Epoch:  242  	Training Loss: 0.00037877331487834454
Test Loss:  0.0004919596249237657
Valid Loss:  0.00037842983147129416
Epoch:  243  	Training Loss: 0.00037664291448891163
Test Loss:  0.0004904278321191669
Valid Loss:  0.0003769984468817711
Epoch:  244  	Training Loss: 0.00037488347152248025
Test Loss:  0.0004888619878329337
Valid Loss:  0.0003756412770599127
Epoch:  245  	Training Loss: 0.00037328945472836494
Test Loss:  0.0004872347053606063
Valid Loss:  0.0003743332054000348
Epoch:  246  	Training Loss: 0.0003718197694979608
Test Loss:  0.0004855850129388273
Valid Loss:  0.00037302839336916804
Epoch:  247  	Training Loss: 0.0003703976108226925
Test Loss:  0.0004839174507651478
Valid Loss:  0.00037174392491579056
Epoch:  248  	Training Loss: 0.0003690219309646636
Test Loss:  0.0004823051276616752
Valid Loss:  0.0003704967675730586
Epoch:  249  	Training Loss: 0.0003676952328532934
Test Loss:  0.0004807132063433528
Valid Loss:  0.0003692719619721174
Epoch:  250  	Training Loss: 0.0003664016257971525
Test Loss:  0.00047917620395310223
Valid Loss:  0.0003680725349113345
Epoch:  251  	Training Loss: 0.00036515307147055864
Test Loss:  0.00047764505143277347
Valid Loss:  0.0003668776771519333
Epoch:  252  	Training Loss: 0.0003639287897385657
Test Loss:  0.00047302397433668375
Valid Loss:  0.0003641355433501303
Epoch:  253  	Training Loss: 0.0003614703891798854
Test Loss:  0.0004691723152063787
Valid Loss:  0.00036199972964823246
Epoch:  254  	Training Loss: 0.00035939717781729996
Test Loss:  0.0004660273261833936
Valid Loss:  0.0003599300398491323
Epoch:  255  	Training Loss: 0.0003574998991098255
Test Loss:  0.0004631980264093727
Valid Loss:  0.00035799224860966206
Epoch:  256  	Training Loss: 0.00035570445470511913
Test Loss:  0.0004606645670719445
Valid Loss:  0.00035612983629107475
Epoch:  257  	Training Loss: 0.0003539987956173718
Test Loss:  0.0004583446425385773
Valid Loss:  0.0003543465572874993
Epoch:  258  	Training Loss: 0.0003523679915815592
Test Loss:  0.0004561954992823303
Valid Loss:  0.0003526071086525917
Epoch:  259  	Training Loss: 0.0003507855872157961
Test Loss:  0.00045416608918458223
Valid Loss:  0.0003509078233037144
Epoch:  260  	Training Loss: 0.0003492500400170684
Test Loss:  0.00045226927613839507
Valid Loss:  0.00034927649539895356
Epoch:  261  	Training Loss: 0.00034776824759319425
Test Loss:  0.00045044798753224313
Valid Loss:  0.00034772721119225025
Epoch:  262  	Training Loss: 0.0003463469329290092
Test Loss:  0.0004493463784456253
Valid Loss:  0.00034624553518369794
Epoch:  263  	Training Loss: 0.00034493737621232867
Test Loss:  0.0004479937197174877
Valid Loss:  0.000345103646395728
Epoch:  264  	Training Loss: 0.0003435633843764663
Test Loss:  0.00044669461203739047
Valid Loss:  0.00034372665686532855
Epoch:  265  	Training Loss: 0.00034221046371385455
Test Loss:  0.0004452380526345223
Valid Loss:  0.0003425511240493506
Epoch:  266  	Training Loss: 0.0003408703487366438
Test Loss:  0.00044381129555404186
Valid Loss:  0.00034123461227864027
Epoch:  267  	Training Loss: 0.0003395414096303284
Test Loss:  0.00044231326319277287
Valid Loss:  0.0003400401910766959
Epoch:  268  	Training Loss: 0.00033823237754404545
Test Loss:  0.0004408487002365291
Valid Loss:  0.000338775513228029
Epoch:  269  	Training Loss: 0.0003369476762600243
Test Loss:  0.0004393431590870023
Valid Loss:  0.0003375893575139344
Epoch:  270  	Training Loss: 0.00033568328944966197
Test Loss:  0.00043785476009361446
Valid Loss:  0.00033636807347647846
Epoch:  271  	Training Loss: 0.0003344429424032569
Test Loss:  0.00043634301982820034
Valid Loss:  0.00033520147553645074
Epoch:  272  	Training Loss: 0.00033322503441013396
Test Loss:  0.00043628981802612543
Valid Loss:  0.00033381563844159245
Epoch:  273  	Training Loss: 0.00033130907104350626
Test Loss:  0.00043559298501349986 55%|█████▍    | 273/500 [03:17<03:13,  1.18it/s] 55%|█████▌    | 275/500 [03:17<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:17<01:40,  2.23it/s] 56%|█████▌    | 279/500 [03:17<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:23<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:24<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:24<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:24<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:24<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:30<04:07,  1.19s/it] 59%|█████▊    | 293/500 [03:30<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:31<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:31<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:31<01:08,  2.95it/s] 60%|██████    | 301/500 [03:37<03:55,  1.18s/it] 61%|██████    | 303/500 [03:37<02:47,  1.18it/s] 61%|██████    | 305/500 [03:37<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:38<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:38<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:44<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:44<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:44<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:44<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:45<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:51<03:35,  1.20s/it] 65%|██████▍   | 323/500 [03:51<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:51<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:51<01:18,  2.19it/s] 66%|██████▌   | 329/500 [03:52<00:57,  2.95it/s] 66%|██████▌   | 331/500 [03:58<03:25,  1.21s/it] 67%|██████▋   | 333/500 [03:58<02:25,  1.15it/s] 67%|██████▋   | 335/500 [03:58<01:43,  1.59it/s] 67%|██████▋   | 337/500 [03:58<01:14,  2.18it/s] 68%|██████▊   | 339/500 [03:59<00:54,  2.94it/s]
Valid Loss:  0.0003319233364891261
Epoch:  274  	Training Loss: 0.00032953236950561404
Test Loss:  0.0004347704234533012
Valid Loss:  0.0003303703560959548
Epoch:  275  	Training Loss: 0.00032783960341475904
Test Loss:  0.0004336773417890072
Valid Loss:  0.00032872508745640516
Epoch:  276  	Training Loss: 0.00032621657010167837
Test Loss:  0.00043248647125437856
Valid Loss:  0.0003271796158514917
Epoch:  277  	Training Loss: 0.00032462304807268083
Test Loss:  0.00043117033783346415
Valid Loss:  0.0003256183990743011
Epoch:  278  	Training Loss: 0.00032305356580764055
Test Loss:  0.0004297971026971936
Valid Loss:  0.0003240957157686353
Epoch:  279  	Training Loss: 0.0003215133910998702
Test Loss:  0.0004283433663658798
Valid Loss:  0.00032257536076940596
Epoch:  280  	Training Loss: 0.00032000080682337284
Test Loss:  0.0004268178017809987
Valid Loss:  0.0003210801223758608
Epoch:  281  	Training Loss: 0.0003185130190104246
Test Loss:  0.00042529002530500293
Valid Loss:  0.00031961314380168915
Epoch:  282  	Training Loss: 0.00031704147113487124
Test Loss:  0.0004225692246109247
Valid Loss:  0.000318065081955865
Epoch:  283  	Training Loss: 0.0003158692270517349
Test Loss:  0.00041975732892751694
Valid Loss:  0.0003170703712385148
Epoch:  284  	Training Loss: 0.00031481002224609256
Test Loss:  0.0004174464556854218
Valid Loss:  0.00031592234154231846
Epoch:  285  	Training Loss: 0.0003138415631838143
Test Loss:  0.00041534198680892587
Valid Loss:  0.0003149484109599143
Epoch:  286  	Training Loss: 0.00031293858774006367
Test Loss:  0.00041348926606588066
Valid Loss:  0.00031398481223732233
Epoch:  287  	Training Loss: 0.0003120886685792357
Test Loss:  0.00041186227463185787
Valid Loss:  0.0003130852128379047
Epoch:  288  	Training Loss: 0.00031128741102293134
Test Loss:  0.0004103025421500206
Valid Loss:  0.00031224111444316804
Epoch:  289  	Training Loss: 0.0003105309442616999
Test Loss:  0.0004089423455297947
Valid Loss:  0.0003114095306955278
Epoch:  290  	Training Loss: 0.00030980989686213434
Test Loss:  0.00040772766806185246
Valid Loss:  0.00031061627669259906
Epoch:  291  	Training Loss: 0.0003091170219704509
Test Loss:  0.00040660309605300426
Valid Loss:  0.00030985201010480523
Epoch:  292  	Training Loss: 0.00030845036963000894
Test Loss:  0.00040670143789611757
Valid Loss:  0.0003098913875874132
Epoch:  293  	Training Loss: 0.00030775574850849807
Test Loss:  0.0004073492018505931
Valid Loss:  0.0003094515996053815
Epoch:  294  	Training Loss: 0.0003072225081268698
Test Loss:  0.0004073459713254124
Valid Loss:  0.00030921201687306166
Epoch:  295  	Training Loss: 0.0003067499492317438
Test Loss:  0.00040715967770665884
Valid Loss:  0.00030894161318428814
Epoch:  296  	Training Loss: 0.0003063080075662583
Test Loss:  0.0004067577247042209
Valid Loss:  0.0003086835495196283
Epoch:  297  	Training Loss: 0.0003058903384953737
Test Loss:  0.00040623685345053673
Valid Loss:  0.0003084298223257065
Epoch:  298  	Training Loss: 0.0003054800326935947
Test Loss:  0.00040563184302300215
Valid Loss:  0.0003081748727709055
Epoch:  299  	Training Loss: 0.000305081281112507
Test Loss:  0.00040494935819879174
Valid Loss:  0.0003079211455769837
Epoch:  300  	Training Loss: 0.00030469754710793495
Test Loss:  0.00040422272286377847
Valid Loss:  0.0003076718421652913
Epoch:  301  	Training Loss: 0.00030432664789259434
Test Loss:  0.0004034663434140384
Valid Loss:  0.00030742830131202936
Epoch:  302  	Training Loss: 0.00030397233786061406
Test Loss:  0.000401013414375484
Valid Loss:  0.0003057356516364962
Epoch:  303  	Training Loss: 0.00030274110031314194
Test Loss:  0.00039840792305767536
Valid Loss:  0.0003050255763810128
Epoch:  304  	Training Loss: 0.0003016006085090339
Test Loss:  0.0003967445227317512
Valid Loss:  0.0003035744302906096
Epoch:  305  	Training Loss: 0.00030053051887080073
Test Loss:  0.00039484657463617623
Valid Loss:  0.0003028655191883445
Epoch:  306  	Training Loss: 0.00029949622694402933
Test Loss:  0.0003935451968573034
Valid Loss:  0.0003015625406987965
Epoch:  307  	Training Loss: 0.00029849132988601923
Test Loss:  0.00039199271122924984
Valid Loss:  0.0003008209459949285
Epoch:  308  	Training Loss: 0.0002975004317704588
Test Loss:  0.0003908487851731479
Valid Loss:  0.0002996128750964999
Epoch:  309  	Training Loss: 0.00029652577359229326
Test Loss:  0.0003894958645105362
Valid Loss:  0.0002988438936881721
Epoch:  310  	Training Loss: 0.00029556150548160076
Test Loss:  0.0003884280158672482
Valid Loss:  0.00029770517721772194
Epoch:  311  	Training Loss: 0.00029460416408255696
Test Loss:  0.0003871890949085355
Valid Loss:  0.0002968971384689212
Epoch:  312  	Training Loss: 0.0002936583186965436
Test Loss:  0.00038583087734878063
Valid Loss:  0.0002957089454866946
Epoch:  313  	Training Loss: 0.0002928815083578229
Test Loss:  0.0003845666360575706
Valid Loss:  0.0002949791378341615
Epoch:  314  	Training Loss: 0.0002921575214713812
Test Loss:  0.0003834267845377326
Valid Loss:  0.00029412476578727365
Epoch:  315  	Training Loss: 0.0002914678188972175
Test Loss:  0.00038237799890339375
Valid Loss:  0.0002933661453425884
Epoch:  316  	Training Loss: 0.0002908158930949867
Test Loss:  0.00038141250843182206
Valid Loss:  0.0002926061279140413
Epoch:  317  	Training Loss: 0.00029018946224823594
Test Loss:  0.00038051800220273435
Valid Loss:  0.00029187326435931027
Epoch:  318  	Training Loss: 0.0002895830839406699
Test Loss:  0.00037968921242281795
Valid Loss:  0.0002911574556492269
Epoch:  319  	Training Loss: 0.0002889912575483322
Test Loss:  0.0003789153997786343
Valid Loss:  0.00029045113478787243
Epoch:  320  	Training Loss: 0.00028841441962867975
Test Loss:  0.00037819595308974385
Valid Loss:  0.0002897564845625311
Epoch:  321  	Training Loss: 0.0002878524246625602
Test Loss:  0.0003775267687160522
Valid Loss:  0.0002890777832362801
Epoch:  322  	Training Loss: 0.0002873046905733645
Test Loss:  0.00037722213892266154
Valid Loss:  0.00028900266624987125
Epoch:  323  	Training Loss: 0.0002871634205803275
Test Loss:  0.0003769576142076403
Valid Loss:  0.0002888113958761096
Epoch:  324  	Training Loss: 0.00028702273266389966
Test Loss:  0.00037669739685952663
Valid Loss:  0.0002886834554374218
Epoch:  325  	Training Loss: 0.00028688277234323323
Test Loss:  0.0003764598513953388
Valid Loss:  0.00028852024115622044
Epoch:  326  	Training Loss: 0.0002867432776838541
Test Loss:  0.0003762299311347306
Valid Loss:  0.00028837600257247686
Epoch:  327  	Training Loss: 0.00028660253155976534
Test Loss:  0.0003760147956199944
Valid Loss:  0.0002882204717025161
Epoch:  328  	Training Loss: 0.00028646207647398114
Test Loss:  0.0003758095554076135
Valid Loss:  0.00028807244962081313
Epoch:  329  	Training Loss: 0.00028632234898395836
Test Loss:  0.0003756142104975879
Valid Loss:  0.00028792026569135487
Epoch:  330  	Training Loss: 0.00028618378564715385
Test Loss:  0.0003754303907044232
Valid Loss:  0.000287771166767925
Epoch:  331  	Training Loss: 0.00028604641556739807
Test Loss:  0.00037525646621361375
Valid Loss:  0.00028762081637978554
Epoch:  332  	Training Loss: 0.000285910238744691
Test Loss:  0.0003746061702258885
Valid Loss:  0.00028669723542407155
Epoch:  333  	Training Loss: 0.00028427899815142155
Test Loss:  0.0003742108237929642
Valid Loss:  0.000285561487544328
Epoch:  334  	Training Loss: 0.00028296891832724214
Test Loss:  0.0003738458617590368
Valid Loss:  0.00028473633574321866
Epoch:  335  	Training Loss: 0.00028189457952976227
Test Loss:  0.00037340610288083553
Valid Loss:  0.00028394313994795084
Epoch:  336  	Training Loss: 0.0002809252473525703
Test Loss:  0.00037278883974067867
Valid Loss:  0.000283201748970896
Epoch:  337  	Training Loss: 0.0002800137735903263
Test Loss:  0.00037203659303486347
Valid Loss:  0.0002824640541803092
Epoch:  338  	Training Loss: 0.0002791302395053208
Test Loss:  0.00037113131838850677
Valid Loss:  0.0002817271160893142
Epoch:  339  	Training Loss: 0.00027825203142128885
Test Loss:  0.00037014350527897477
Valid Loss:  0.00028098191251046956
Epoch:  340  	Training Loss: 0.0002773927990347147
Test Loss:  0.00036907981848344207
Valid Loss:  0.00028024218045175076
 68%|██████▊   | 341/500 [04:05<03:10,  1.20s/it] 69%|██████▊   | 343/500 [04:05<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:05<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:05<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:05<00:50,  2.97it/s] 70%|███████   | 351/500 [04:12<02:55,  1.18s/it] 71%|███████   | 353/500 [04:12<02:04,  1.18it/s] 71%|███████   | 355/500 [04:12<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:12<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:12<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:18<02:41,  1.16s/it] 73%|███████▎  | 363/500 [04:19<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:19<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:19<00:58,  2.26it/s] 74%|███████▍  | 369/500 [04:19<00:43,  3.04it/s] 74%|███████▍  | 371/500 [04:25<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:25<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:26<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:26<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:26<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:32<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:32<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:32<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:33<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:33<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:39<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:39<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:39<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:39<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:40<00:33,  2.98it/s] 80%|████████  | 401/500 [04:46<01:57,  1.19s/it] 81%|████████  | 403/500 [04:46<01:22,  1.17it/s] 81%|████████  | 405/500 [04:46<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:46<00:41,  2.22it/s]Epoch:  341  	Training Loss: 0.00027655455050989985
Test Loss:  0.0003679674700833857
Valid Loss:  0.00027951132506132126
Epoch:  342  	Training Loss: 0.00027573786792345345
Test Loss:  0.00036659385659731925
Valid Loss:  0.0002779413480311632
Epoch:  343  	Training Loss: 0.00027446020976640284
Test Loss:  0.0003650132566690445
Valid Loss:  0.0002770675055216998
Epoch:  344  	Training Loss: 0.00027319768560118973
Test Loss:  0.00036358711076900363
Valid Loss:  0.0002756902249529958
Epoch:  345  	Training Loss: 0.0002719431067816913
Test Loss:  0.00036208078381605446
Valid Loss:  0.00027462825528346
Epoch:  346  	Training Loss: 0.000270679360255599
Test Loss:  0.00036061013815924525
Valid Loss:  0.0002733689616434276
Epoch:  347  	Training Loss: 0.0002694598224479705
Test Loss:  0.00035909184953197837
Valid Loss:  0.00027233303990215063
Epoch:  348  	Training Loss: 0.0002683326893020421
Test Loss:  0.0003575930022634566
Valid Loss:  0.00027124531334266067
Epoch:  349  	Training Loss: 0.0002672974660526961
Test Loss:  0.00035614706575870514
Valid Loss:  0.0002702654164750129
Epoch:  350  	Training Loss: 0.0002663064224179834
Test Loss:  0.00035470956936478615
Valid Loss:  0.0002692895650397986
Epoch:  351  	Training Loss: 0.00026535638608038425
Test Loss:  0.000353335082763806
Valid Loss:  0.0002683612983673811
Epoch:  352  	Training Loss: 0.0002644304186105728
Test Loss:  0.00035283860052004457
Valid Loss:  0.0002683345810510218
Epoch:  353  	Training Loss: 0.00026437913766130805
Test Loss:  0.00035241639125160873
Valid Loss:  0.0002682990743778646
Epoch:  354  	Training Loss: 0.0002643360639922321
Test Loss:  0.0003520309110172093
Valid Loss:  0.00026827192050404847
Epoch:  355  	Training Loss: 0.00026430515572428703
Test Loss:  0.000351679977029562
Valid Loss:  0.0002682472695596516
Epoch:  356  	Training Loss: 0.00026427977718412876
Test Loss:  0.0003513579140417278
Valid Loss:  0.00026823245570994914
Epoch:  357  	Training Loss: 0.00026425955002196133
Test Loss:  0.0003510662936605513
Valid Loss:  0.00026822168729268014
Epoch:  358  	Training Loss: 0.0002642443869262934
Test Loss:  0.0003507976944092661
Valid Loss:  0.00026821281062439084
Epoch:  359  	Training Loss: 0.00026423248345963657
Test Loss:  0.0003505574131850153
Valid Loss:  0.0002682032354641706
Epoch:  360  	Training Loss: 0.0002642219187691808
Test Loss:  0.00035034280153922737
Valid Loss:  0.00026819546474143863
Epoch:  361  	Training Loss: 0.00026421237271279097
Test Loss:  0.0003501520841382444
Valid Loss:  0.00026818705373443663
Epoch:  362  	Training Loss: 0.00026420358335599303
Test Loss:  0.0003497728321235627
Valid Loss:  0.0002674580318853259
Epoch:  363  	Training Loss: 0.00026328882086090744
Test Loss:  0.0003491851966828108
Valid Loss:  0.00026642350712791085
Epoch:  364  	Training Loss: 0.00026239047292619944
Test Loss:  0.00034863586188293993
Valid Loss:  0.00026573287323117256
Epoch:  365  	Training Loss: 0.0002615034463815391
Test Loss:  0.0003478999133221805
Valid Loss:  0.00026469677686691284
Epoch:  366  	Training Loss: 0.0002606281195767224
Test Loss:  0.0003472438547760248
Valid Loss:  0.00026404153322800994
Epoch:  367  	Training Loss: 0.0002597625716589391
Test Loss:  0.0003464103792794049
Valid Loss:  0.0002630032831802964
Epoch:  368  	Training Loss: 0.0002589071518741548
Test Loss:  0.00034568505361676216
Valid Loss:  0.00026237734709866345
Epoch:  369  	Training Loss: 0.0002580548753030598
Test Loss:  0.00034477037843316793
Valid Loss:  0.00026131750200875103
Epoch:  370  	Training Loss: 0.00025720353005453944
Test Loss:  0.00034399155993014574
Valid Loss:  0.000260705390246585
Epoch:  371  	Training Loss: 0.0002563597518019378
Test Loss:  0.000343026767950505
Valid Loss:  0.0002596185659058392
Epoch:  372  	Training Loss: 0.00025552170700393617
Test Loss:  0.0003421354340389371
Valid Loss:  0.00025872717378661036
Epoch:  373  	Training Loss: 0.00025462982011958957
Test Loss:  0.00034128245897591114
Valid Loss:  0.000257838168181479
Epoch:  374  	Training Loss: 0.0002537784166634083
Test Loss:  0.0003405229072086513
Valid Loss:  0.00025702311540953815
Epoch:  375  	Training Loss: 0.00025297130923718214
Test Loss:  0.0003397937398403883
Valid Loss:  0.0002562121953815222
Epoch:  376  	Training Loss: 0.00025219860253855586
Test Loss:  0.0003391099162399769
Valid Loss:  0.0002554438542574644
Epoch:  377  	Training Loss: 0.0002514661173336208
Test Loss:  0.0003384637529961765
Valid Loss:  0.00025467725936323404
Epoch:  378  	Training Loss: 0.0002507666067685932
Test Loss:  0.0003378402616363019
Valid Loss:  0.00025394311523996294
Epoch:  379  	Training Loss: 0.00025008455850183964
Test Loss:  0.0003372299834154546
Valid Loss:  0.0002532080397941172
Epoch:  380  	Training Loss: 0.0002494181680958718
Test Loss:  0.0003366304445080459
Valid Loss:  0.00025249808095395565
Epoch:  381  	Training Loss: 0.0002487636520527303
Test Loss:  0.00033606612123548985
Valid Loss:  0.000251797930104658
Epoch:  382  	Training Loss: 0.0002481207484379411
Test Loss:  0.00033512950176373124
Valid Loss:  0.00025139536592178047
Epoch:  383  	Training Loss: 0.00024778011720627546
Test Loss:  0.00033428461756557226
Valid Loss:  0.0002509883197490126
Epoch:  384  	Training Loss: 0.00024745723931118846
Test Loss:  0.0003335126384627074
Valid Loss:  0.00025059509789571166
Epoch:  385  	Training Loss: 0.0002471496118232608
Test Loss:  0.0003328035236336291
Valid Loss:  0.0002502145944163203
Epoch:  386  	Training Loss: 0.00024685519747436047
Test Loss:  0.0003321532276459038
Valid Loss:  0.0002498463145457208
Epoch:  387  	Training Loss: 0.00024657201720401645
Test Loss:  0.0003315553185530007
Valid Loss:  0.00024948871578089893
Epoch:  388  	Training Loss: 0.00024629899417050183
Test Loss:  0.00033100569271482527
Valid Loss:  0.00024913973174989223
Epoch:  389  	Training Loss: 0.000246035517193377
Test Loss:  0.00033050013007596135
Valid Loss:  0.00024880177807062864
Epoch:  390  	Training Loss: 0.0002457804512232542
Test Loss:  0.0003300336538814008
Valid Loss:  0.00024847034364938736
Epoch:  391  	Training Loss: 0.0002455327194184065
Test Loss:  0.0003296032955404371
Valid Loss:  0.0002481465635355562
Epoch:  392  	Training Loss: 0.0002452896151226014
Test Loss:  0.00033014066866599023
Valid Loss:  0.0002478805836290121
Epoch:  393  	Training Loss: 0.0002441680699121207
Test Loss:  0.00033019226975739
Valid Loss:  0.00024679276975803077
Epoch:  394  	Training Loss: 0.00024325688718818128
Test Loss:  0.0003299946547485888
Valid Loss:  0.0002465105499140918
Epoch:  395  	Training Loss: 0.00024243691586889327
Test Loss:  0.0003294828929938376
Valid Loss:  0.0002457338268868625
Epoch:  396  	Training Loss: 0.00024168250092770904
Test Loss:  0.00032886024564504623
Valid Loss:  0.00024537305580452085
Epoch:  397  	Training Loss: 0.00024097392451949418
Test Loss:  0.00032807461684569716
Valid Loss:  0.0002447360020596534
Epoch:  398  	Training Loss: 0.00024030019994825125
Test Loss:  0.0003272413450758904
Valid Loss:  0.0002443321864120662
Epoch:  399  	Training Loss: 0.00023965761647559702
Test Loss:  0.0003263023681938648
Valid Loss:  0.00024379082606174052
Epoch:  400  	Training Loss: 0.00023903892724774778
Test Loss:  0.00032532415934838355
Valid Loss:  0.00024337807553820312
Epoch:  401  	Training Loss: 0.0002384412509854883
Test Loss:  0.00032429961720481515
Valid Loss:  0.00024289346765726805
Epoch:  402  	Training Loss: 0.00023786102246958762
Test Loss:  0.00032256453414447606
Valid Loss:  0.00024221529019996524
Epoch:  403  	Training Loss: 0.00023716055147815496
Test Loss:  0.00032106362050399184
Valid Loss:  0.00024155122810043395
Epoch:  404  	Training Loss: 0.00023648975184187293
Test Loss:  0.0003197097685188055
Valid Loss:  0.00024091333034448326
Epoch:  405  	Training Loss: 0.0002358467609155923
Test Loss:  0.0003184697707183659
Valid Loss:  0.00024030049098655581
Epoch:  406  	Training Loss: 0.00023522585979662836
Test Loss:  0.00031733058858662844
Valid Loss:  0.00023970843176357448
Epoch:  407  	Training Loss: 0.00023463126854039729
Test Loss:  0.000316265388391912
Valid Loss:  0.00023913160839583725
Epoch:  408  	Training Loss: 0.00023405603133141994
Test Loss:  82%|████████▏ | 409/500 [04:46<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:53<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:53<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:53<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:53<00:36,  2.24it/s] 84%|████████▍ | 419/500 [04:53<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:59<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:00<01:04,  1.19it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.63it/s] 85%|████████▌ | 427/500 [05:00<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:00<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:06<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:07<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:07<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:07<00:20,  2.95it/s] 88%|████████▊ | 441/500 [05:13<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:13<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:14<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:14<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:14<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:20<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:20<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:21<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:27<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:27<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:40<01:00,  2.10s/it] 95%|█████████▍| 473/500 [05:40<00:40,  1.49s/it] 0.00031526616658084095
Valid Loss:  0.0002385656553087756
Epoch:  409  	Training Loss: 0.0002334929013159126
Test Loss:  0.0003143247158732265
Valid Loss:  0.0002380155783612281
Epoch:  410  	Training Loss: 0.00023293716367334127
Test Loss:  0.000313430093228817
Valid Loss:  0.00023746726219542325
Epoch:  411  	Training Loss: 0.00023239814618136734
Test Loss:  0.0003125760122202337
Valid Loss:  0.00023691586102358997
Epoch:  412  	Training Loss: 0.0002318680053576827
Test Loss:  0.00031120533822104335
Valid Loss:  0.0002366646658629179
Epoch:  413  	Training Loss: 0.00023103786224965006
Test Loss:  0.0003102252958342433
Valid Loss:  0.0002361718943575397
Epoch:  414  	Training Loss: 0.00023045920534059405
Test Loss:  0.00030918981065042317
Valid Loss:  0.00023592295474372804
Epoch:  415  	Training Loss: 0.00022993743186816573
Test Loss:  0.00030837731901556253
Valid Loss:  0.0002356292970944196
Epoch:  416  	Training Loss: 0.00022950518177822232
Test Loss:  0.00030757609056308866
Valid Loss:  0.00023541049449704587
Epoch:  417  	Training Loss: 0.00022910773986950517
Test Loss:  0.000306794885545969
Valid Loss:  0.00023518021043855697
Epoch:  418  	Training Loss: 0.00022874318528920412
Test Loss:  0.0003060023591388017
Valid Loss:  0.0002349599526496604
Epoch:  419  	Training Loss: 0.00022841338068246841
Test Loss:  0.00030521623557433486
Valid Loss:  0.00023474467161577195
Epoch:  420  	Training Loss: 0.00022810196969658136
Test Loss:  0.0003044483019039035
Valid Loss:  0.0002345368848182261
Epoch:  421  	Training Loss: 0.00022779533173888922
Test Loss:  0.00030372029868885875
Valid Loss:  0.00023432762827724218
Epoch:  422  	Training Loss: 0.00022748828632757068
Test Loss:  0.00030394806526601315
Valid Loss:  0.00023396837059408426
Epoch:  423  	Training Loss: 0.00022714024817105383
Test Loss:  0.0003042706521227956
Valid Loss:  0.00023377762408927083
Epoch:  424  	Training Loss: 0.00022682735288981348
Test Loss:  0.00030449757468886673
Valid Loss:  0.0002335486642550677
Epoch:  425  	Training Loss: 0.00022653714404441416
Test Loss:  0.0003046952770091593
Valid Loss:  0.00023335553123615682
Epoch:  426  	Training Loss: 0.00022627244470641017
Test Loss:  0.00030483677983283997
Valid Loss:  0.0002331721771042794
Epoch:  427  	Training Loss: 0.00022603070829063654
Test Loss:  0.0003049409424420446
Valid Loss:  0.0002330077695660293
Epoch:  428  	Training Loss: 0.00022580749646294862
Test Loss:  0.0003049995575565845
Valid Loss:  0.00023285439237952232
Epoch:  429  	Training Loss: 0.0002256029547424987
Test Loss:  0.0003050192608498037
Valid Loss:  0.00023271080863196403
Epoch:  430  	Training Loss: 0.00022541245562024415
Test Loss:  0.00030500144930556417
Valid Loss:  0.00023257544671650976
Epoch:  431  	Training Loss: 0.00022523650841321796
Test Loss:  0.00030494778184220195
Valid Loss:  0.00023244474141392857
Epoch:  432  	Training Loss: 0.0002250718098366633
Test Loss:  0.0003019713331013918
Valid Loss:  0.0002319783961866051
Epoch:  433  	Training Loss: 0.000224461909965612
Test Loss:  0.0002998319687321782
Valid Loss:  0.00023127582971937954
Epoch:  434  	Training Loss: 0.00022397071006707847
Test Loss:  0.0002979512501042336
Valid Loss:  0.00023097885423339903
Epoch:  435  	Training Loss: 0.00022355359396897256
Test Loss:  0.00029660179279744625
Valid Loss:  0.0002304257359355688
Epoch:  436  	Training Loss: 0.00022318444098345935
Test Loss:  0.00029534538043662906
Valid Loss:  0.00023019482614472508
Epoch:  437  	Training Loss: 0.00022285013983491808
Test Loss:  0.0002944601292256266
Valid Loss:  0.0002297184255439788
Epoch:  438  	Training Loss: 0.00022254785289987922
Test Loss:  0.000293595134280622
Valid Loss:  0.00022950657876208425
Epoch:  439  	Training Loss: 0.00022226393048185855
Test Loss:  0.00029298473964445293
Valid Loss:  0.00022907709353603423
Epoch:  440  	Training Loss: 0.00022199598606675863
Test Loss:  0.000292349373921752
Valid Loss:  0.0002288779942318797
Epoch:  441  	Training Loss: 0.00022173926117829978
Test Loss:  0.00029193441150709987
Valid Loss:  0.000228486635023728
Epoch:  442  	Training Loss: 0.00022149225696921349
Test Loss:  0.0002921279810834676
Valid Loss:  0.0002284510264871642
Epoch:  443  	Training Loss: 0.00022126565454527736
Test Loss:  0.0002922096464317292
Valid Loss:  0.00022821678430773318
Epoch:  444  	Training Loss: 0.00022104215167928487
Test Loss:  0.0002922603744082153
Valid Loss:  0.00022809661459177732
Epoch:  445  	Training Loss: 0.0002208143996540457
Test Loss:  0.00029224486206658185
Valid Loss:  0.00022791956143919379
Epoch:  446  	Training Loss: 0.00022059133334551007
Test Loss:  0.0002921762643381953
Valid Loss:  0.00022776801779400557
Epoch:  447  	Training Loss: 0.00022037746384739876
Test Loss:  0.00029206357430666685
Valid Loss:  0.0002276070008520037
Epoch:  448  	Training Loss: 0.00022016523871570826
Test Loss:  0.0002919197431765497
Valid Loss:  0.00022745529713574797
Epoch:  449  	Training Loss: 0.00021995189308654517
Test Loss:  0.00029173935763537884
Valid Loss:  0.00022730123600922525
Epoch:  450  	Training Loss: 0.0002197453723056242
Test Loss:  0.0002915252116508782
Valid Loss:  0.00022715673549100757
Epoch:  451  	Training Loss: 0.00021954585099592805
Test Loss:  0.00029127972084097564
Valid Loss:  0.00022701919078826904
Epoch:  452  	Training Loss: 0.0002193563850596547
Test Loss:  0.0002922862477134913
Valid Loss:  0.00022720781271345913
Epoch:  453  	Training Loss: 0.00021893903613090515
Test Loss:  0.00029263136093504727
Valid Loss:  0.00022710928169544786
Epoch:  454  	Training Loss: 0.00021868423209525645
Test Loss:  0.00029272958636283875
Valid Loss:  0.00022691597405355424
Epoch:  455  	Training Loss: 0.00021845378796570003
Test Loss:  0.0002926996094174683
Valid Loss:  0.00022669248573947698
Epoch:  456  	Training Loss: 0.00021823591669090092
Test Loss:  0.0002926200395449996
Valid Loss:  0.00022647369769401848
Epoch:  457  	Training Loss: 0.00021802556875627488
Test Loss:  0.0002924989094026387
Valid Loss:  0.00022626126883551478
Epoch:  458  	Training Loss: 0.0002178205322707072
Test Loss:  0.0002923541469499469
Valid Loss:  0.0002260634209960699
Epoch:  459  	Training Loss: 0.00021761818788945675
Test Loss:  0.0002921871782746166
Valid Loss:  0.00022586979321204126
Epoch:  460  	Training Loss: 0.00021741740056313574
Test Loss:  0.0002920011756941676
Valid Loss:  0.00022567782434634864
Epoch:  461  	Training Loss: 0.00021721806842833757
Test Loss:  0.00029179759440012276
Valid Loss:  0.00022548765991814435
Epoch:  462  	Training Loss: 0.0002170208317693323
Test Loss:  0.00028873494011349976
Valid Loss:  0.00022371963132172823
Epoch:  463  	Training Loss: 0.00021618120081257075
Test Loss:  0.0002862635301426053
Valid Loss:  0.00022434903075918555
Epoch:  464  	Training Loss: 0.00021553682745434344
Test Loss:  0.0002850223099812865
Valid Loss:  0.00022183282999321818
Epoch:  465  	Training Loss: 0.0002151195949409157
Test Loss:  0.0002838561194948852
Valid Loss:  0.00022495913435705006
Epoch:  466  	Training Loss: 0.00021513429237529635
Test Loss:  0.00028488202951848507
Valid Loss:  0.00022103275114204735
Epoch:  467  	Training Loss: 0.0002161331649404019
Test Loss:  0.00028694234788417816
Valid Loss:  0.00023197050904855132
Epoch:  468  	Training Loss: 0.00021948743960820138
Test Loss:  0.00029687152709811926
Valid Loss:  0.0002292794524691999
Epoch:  469  	Training Loss: 0.00022853477275930345
Test Loss:  0.0003173181030433625
Valid Loss:  0.00027056148974224925
Epoch:  470  	Training Loss: 0.00025135237956419587
Test Loss:  0.00037557806354016066
Valid Loss:  0.000298737024422735
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0003075437853112817
Test Loss:  0.0002934497606474906
Valid Loss:  0.00022645355784334242
Epoch:  472  	Training Loss: 0.00022564391838386655
Test Loss:  0.0002821040980052203
Valid Loss:  0.00021831730555277318
Epoch:  473  	Training Loss: 0.00021391315385699272
Test Loss:  0.0002798327477648854
Valid Loss:  0.00021746494167018682
Epoch:  474  	Training Loss: 0.00021139363525435328
Test Loss:  0.00027935064281336963
 95%|█████████▌| 475/500 [05:40<00:26,  1.06s/it] 95%|█████████▌| 477/500 [05:40<00:17,  1.31it/s] 96%|█████████▌| 479/500 [05:40<00:11,  1.80it/s] 96%|█████████▌| 481/500 [05:47<00:26,  1.37s/it] 97%|█████████▋| 483/500 [05:47<00:16,  1.02it/s] 97%|█████████▋| 485/500 [05:47<00:10,  1.42it/s] 97%|█████████▋| 487/500 [05:47<00:06,  1.95it/s] 98%|█████████▊| 489/500 [05:47<00:04,  2.64it/s] 98%|█████████▊| 491/500 [05:54<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:54<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:54<00:03,  1.58it/s] 99%|█████████▉| 497/500 [05:54<00:01,  2.17it/s]100%|█████████▉| 499/500 [05:54<00:00,  2.91it/s]100%|██████████| 500/500 [05:54<00:00,  1.41it/s]
Valid Loss:  0.0002175570116378367
Epoch:  475  	Training Loss: 0.00021071857190690935
Test Loss:  0.0002792098675854504
Valid Loss:  0.00021761239622719586
Epoch:  476  	Training Loss: 0.00021041760919615626
Test Loss:  0.0002791232254821807
Valid Loss:  0.00021755907800979912
Epoch:  477  	Training Loss: 0.00021019650739617646
Test Loss:  0.00027903279988095164
Valid Loss:  0.0002174390247091651
Epoch:  478  	Training Loss: 0.00020999263506382704
Test Loss:  0.00027892785146832466
Valid Loss:  0.00021728524006903172
Epoch:  479  	Training Loss: 0.0002097949618473649
Test Loss:  0.0002788057900033891
Valid Loss:  0.0002171170199289918
Epoch:  480  	Training Loss: 0.0002096013631671667
Test Loss:  0.0002786680415738374
Valid Loss:  0.0002169435756513849
Epoch:  481  	Training Loss: 0.0002094106748700142
Test Loss:  0.00027851766208186746
Valid Loss:  0.00021676698816008866
Epoch:  482  	Training Loss: 0.00020922112162224948
Test Loss:  0.0002783614327199757
Valid Loss:  0.00021659581398125738
Epoch:  483  	Training Loss: 0.00020887677965220064
Test Loss:  0.0002781565999612212
Valid Loss:  0.00021636152814608067
Epoch:  484  	Training Loss: 0.00020854754257015884
Test Loss:  0.0002779051137622446
Valid Loss:  0.00021609636314678937
Epoch:  485  	Training Loss: 0.00020822457736358047
Test Loss:  0.0002776223118416965
Valid Loss:  0.00021582093904726207
Epoch:  486  	Training Loss: 0.0002079075202345848
Test Loss:  0.00027730705915018916
Valid Loss:  0.00021554064005613327
Epoch:  487  	Training Loss: 0.00020759491599164903
Test Loss:  0.00027696395409293473
Valid Loss:  0.0002152581000700593
Epoch:  488  	Training Loss: 0.00020728431991301477
Test Loss:  0.0002766028046607971
Valid Loss:  0.000214973755646497
Epoch:  489  	Training Loss: 0.00020697532454505563
Test Loss:  0.00027621854678727686
Valid Loss:  0.0002146907791029662
Epoch:  490  	Training Loss: 0.00020666759519372135
Test Loss:  0.000275821250397712
Valid Loss:  0.00021440275304485112
Epoch:  491  	Training Loss: 0.00020635753753595054
Test Loss:  0.0002754206070676446
Valid Loss:  0.00021411919442471117
Epoch:  492  	Training Loss: 0.0002060500264633447
Test Loss:  0.0002751892025116831
Valid Loss:  0.00021379244572017342
Epoch:  493  	Training Loss: 0.00020589784253388643
Test Loss:  0.0002751034335233271
Valid Loss:  0.00021360430400818586
Epoch:  494  	Training Loss: 0.00020576571114361286
Test Loss:  0.000275074242381379
Valid Loss:  0.00021346777793951333
Epoch:  495  	Training Loss: 0.00020563584985211492
Test Loss:  0.0002750520361587405
Valid Loss:  0.00021334519260562956
Epoch:  496  	Training Loss: 0.0002055084187304601
Test Loss:  0.00027502834564074874
Valid Loss:  0.0002132283989340067
Epoch:  497  	Training Loss: 0.00020538289390970021
Test Loss:  0.0002750012499745935
Valid Loss:  0.00021311342425178736
Epoch:  498  	Training Loss: 0.00020525953732430935
Test Loss:  0.00027496760594658554
Valid Loss:  0.00021299978834576905
Epoch:  499  	Training Loss: 0.00020513801428023726
Test Loss:  0.0002749279956333339
Valid Loss:  0.00021288570133037865
Epoch:  500  	Training Loss: 0.00020501801918726414
Test Loss:  0.0002748846891336143
Valid Loss:  0.00021277301129885018
seed is  12
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.50it/s]  1%|          | 4/500 [00:00<00:29, 16.58it/s]  1%|          | 6/500 [00:00<00:29, 16.61it/s]  2%|▏         | 8/500 [00:00<00:29, 16.63it/s]  2%|▏         | 10/500 [00:00<00:29, 16.39it/s]  2%|▏         | 12/500 [00:00<00:29, 16.42it/s]  3%|▎         | 14/500 [00:00<00:29, 16.52it/s]  3%|▎         | 16/500 [00:00<00:29, 16.68it/s]  4%|▎         | 18/500 [00:01<00:28, 16.71it/s]  4%|▍         | 20/500 [00:01<00:28, 16.72it/s]  4%|▍         | 22/500 [00:01<00:28, 16.65it/s]  5%|▍         | 24/500 [00:01<00:28, 16.56it/s]  5%|▌         | 26/500 [00:01<00:28, 16.40it/s]  6%|▌         | 28/500 [00:01<00:28, 16.40it/s]  6%|▌         | 30/500 [00:01<00:28, 16.45it/s]  6%|▋         | 32/500 [00:01<00:28, 16.45it/s]  7%|▋         | 34/500 [00:02<00:28, 16.35it/s]  7%|▋         | 36/500 [00:02<00:28, 16.25it/s]  8%|▊         | 38/500 [00:02<00:28, 16.43it/s]  8%|▊         | 40/500 [00:02<00:27, 16.47it/s]  8%|▊         | 42/500 [00:02<00:27, 16.65it/s]  9%|▉         | 44/500 [00:02<00:27, 16.70it/s]  9%|▉         | 46/500 [00:02<00:27, 16.66it/s] 10%|▉         | 48/500 [00:02<00:26, 16.76it/s] 10%|█         | 50/500 [00:03<00:27, 16.58it/s] 10%|█         | 52/500 [00:03<00:27, 16.52it/s] 11%|█         | 54/500 [00:03<00:26, 16.60it/s] 11%|█         | 56/500 [00:03<00:27, 16.31it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.42it/s] 12%|█▏        | 60/500 [00:03<00:30, 14.40it/s] 12%|█▏        | 62/500 [00:03<00:31, 13.94it/s] 13%|█▎        | 64/500 [00:03<00:29, 14.72it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.30it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.52it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.88it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.16it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.34it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.40it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.36it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.57it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.63it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.55it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.59it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.60it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.70it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.70it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.44it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.44it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.14it/s] 20%|██        | 100/500 [00:06<00:24, 16.26it/s] 20%|██        | 102/500 [00:06<00:24, 16.41it/s] 21%|██        | 104/500 [00:06<00:24, 16.29it/s] 21%|██        | 106/500 [00:06<00:23, 16.44it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.51it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.48it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.56it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.29it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.17it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.39it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.56it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.61it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.74it/s]Epoch:  1  	Training Loss: 0.18247933685779572
Test Loss:  4896.92138671875
Valid Loss:  4972.63427734375
Epoch:  2  	Training Loss: 4949.95849609375
Test Loss:  2.279959680862126e+17
Valid Loss:  2.2897515191022387e+17
Epoch:  3  	Training Loss: 2.287769992990556e+17
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.74it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.77it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.73it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.64it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.62it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.56it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.63it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.69it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.61it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.33it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.37it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.51it/s] 30%|███       | 150/500 [00:09<00:21, 16.58it/s] 30%|███       | 152/500 [00:09<00:20, 16.62it/s] 31%|███       | 154/500 [00:09<00:20, 16.68it/s] 31%|███       | 156/500 [00:09<00:20, 16.66it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.47it/s] 32%|███▏      | 160/500 [00:09<00:22, 15.00it/s] 32%|███▏      | 162/500 [00:09<00:22, 14.77it/s] 33%|███▎      | 164/500 [00:10<00:22, 15.20it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.63it/s] 34%|███▎      | 168/500 [00:10<00:22, 14.86it/s] 34%|███▍      | 170/500 [00:10<00:21, 15.21it/s] 34%|███▍      | 172/500 [00:10<00:21, 15.53it/s] 35%|███▍      | 174/500 [00:10<00:20, 15.68it/s] 35%|███▌      | 176/500 [00:10<00:20, 16.02it/s] 36%|███▌      | 178/500 [00:10<00:21, 15.21it/s] 36%|███▌      | 180/500 [00:11<00:22, 14.09it/s] 36%|███▋      | 182/500 [00:11<00:23, 13.53it/s] 37%|███▋      | 184/500 [00:11<00:22, 13.94it/s] 37%|███▋      | 186/500 [00:11<00:21, 14.60it/s] 38%|███▊      | 188/500 [00:11<00:21, 14.51it/s] 38%|███▊      | 190/500 [00:11<00:22, 13.80it/s] 38%|███▊      | 192/500 [00:12<00:23, 13.29it/s] 39%|███▉      | 194/500 [00:12<00:23, 12.98it/s] 39%|███▉      | 196/500 [00:12<00:22, 13.74it/s] 40%|███▉      | 198/500 [00:12<00:20, 14.38it/s] 40%|████      | 200/500 [00:12<00:19, 15.00it/s] 40%|████      | 202/500 [00:12<00:19, 15.50it/s] 41%|████      | 204/500 [00:12<00:18, 15.68it/s] 41%|████      | 206/500 [00:12<00:18, 16.00it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.10it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.19it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.30it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.28it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.37it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.21it/s] 44%|████▍     | 220/500 [00:13<00:17, 15.76it/s] 44%|████▍     | 222/500 [00:13<00:18, 15.38it/s] 45%|████▍     | 224/500 [00:14<00:19, 14.26it/s] 45%|████▌     | 226/500 [00:14<00:18, 14.43it/s] 46%|████▌     | 228/500 [00:14<00:18, 15.06it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.57it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.81it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.02it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.13it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.21it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.41it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.53it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.57it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.60it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.52it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.52it/s] 50%|█████     | 252/500 [00:15<00:14, 16.63it/s] 51%|█████     | 254/500 [00:15<00:14, 16.62it/s] 51%|█████     | 256/500 [00:16<00:14, 16.63it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.67it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.69it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.62it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.69it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.58it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.50it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.57it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.56it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.60it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.99it/s] 56%|█████▌    | 278/500 [00:17<00:14, 14.92it/s] 56%|█████▌    | 280/500 [00:17<00:15, 14.25it/s] 56%|█████▋    | 282/500 [00:17<00:15, 13.76it/s] 57%|█████▋    | 284/500 [00:17<00:16, 13.49it/s] 57%|█████▋    | 286/500 [00:17<00:14, 14.29it/s] 58%|█████▊    | 288/500 [00:18<00:14, 14.84it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.35it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.69it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.07it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.02it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.26it/s] 60%|██████    | 300/500 [00:18<00:12, 16.30it/s] 60%|██████    | 302/500 [00:18<00:12, 16.46it/s] 61%|██████    | 304/500 [00:19<00:11, 16.50it/s] 61%|██████    | 306/500 [00:19<00:11, 16.60it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.58it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.60it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.60it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.46it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.39it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.41it/s] 64%|██████▍   | 320/500 [00:20<00:10, 16.52it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.64it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.65it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.33it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.31it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.40it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.34it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.44it/s] 67%|██████▋   | 336/500 [00:21<00:09, 16.55it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.45it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.55it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.49it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.66it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.66it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.53it/s] 70%|███████   | 350/500 [00:21<00:09, 16.56it/s] 70%|███████   | 352/500 [00:21<00:08, 16.67it/s] 71%|███████   | 354/500 [00:22<00:08, 16.71it/s] 71%|███████   | 356/500 [00:22<00:08, 16.75it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.75it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.81it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.80it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.72it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.57it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.49it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.18it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.15it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:08, 15.61it/s] 75%|███████▌  | 376/500 [00:23<00:07, 15.96it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.23it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.47it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.57it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.52it/s] 77%|███████▋  | 386/500 [00:24<00:06, 16.62it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.58it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.63it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.72it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.74it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.75it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.47it/s] 80%|████████  | 400/500 [00:24<00:06, 16.38it/s] 80%|████████  | 402/500 [00:25<00:06, 16.32it/s] 81%|████████  | 404/500 [00:25<00:05, 16.33it/s] 81%|████████  | 406/500 [00:25<00:05, 16.36it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.35it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.42it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.46it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.51it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.54it/s] 84%|████████▎ | 418/500 [00:26<00:04, 16.61it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.52it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.47it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.29it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.46it/s] 86%|████████▌ | 428/500 [00:26<00:04, 15.61it/s] 86%|████████▌ | 430/500 [00:26<00:04, 15.94it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.14it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.29it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.40it/s] 88%|████████▊ | 438/500 [00:27<00:04, 15.36it/s] 88%|████████▊ | 440/500 [00:27<00:03, 15.57it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.93it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.10it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.08it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.26it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.48it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.57it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.42it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.54it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.47it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.44it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.52it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.67it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.47it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.51it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.51it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.54it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.59it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.61it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.51it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.54it/s] 96%|█████████▋| 482/500 [00:29<00:01, 15.89it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.15it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.30it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.46it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.55it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.60it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.72it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.62it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.70it/s]100%|██████████| 500/500 [00:31<00:00, 16.59it/s]100%|██████████| 500/500 [00:31<00:00, 16.11it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  12
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:04,  6.14s/it]  1%|          | 3/500 [00:06<13:37,  1.64s/it]  1%|          | 5/500 [00:06<06:51,  1.20it/s]  1%|▏         | 7/500 [00:06<04:09,  1.97it/s]  2%|▏         | 9/500 [00:06<02:46,  2.94it/s]  2%|▏         | 11/500 [00:12<10:41,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.02it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:19<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:11,  1.18s/it]  7%|▋         | 33/500 [00:26<06:34,  1.18it/s]  7%|▋         | 35/500 [00:26<04:44,  1.64it/s]  7%|▋         | 37/500 [00:26<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:33<06:25,  1.18it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:33<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:44,  1.17s/it] 11%|█         | 53/500 [00:40<06:15,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:40<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:46<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:07,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:53<08:23,  1.17s/it] 15%|█▍        | 73/500 [00:53<06:00,  1.19it/s]Epoch:  1  	Training Loss: 0.1824793517589569
Test Loss:  7.981621742248535
Valid Loss:  8.087652206420898
Epoch:  2  	Training Loss: 8.055023193359375
Test Loss:  0.19232825934886932
Valid Loss:  0.1735028326511383
Epoch:  3  	Training Loss: 0.18186703324317932
Test Loss:  0.19219613075256348
Valid Loss:  0.17338168621063232
Epoch:  4  	Training Loss: 0.18174171447753906
Test Loss:  0.19206425547599792
Valid Loss:  0.17326074838638306
Epoch:  5  	Training Loss: 0.1816166341304779
Test Loss:  0.19195076823234558
Valid Loss:  0.17315174639225006
Epoch:  6  	Training Loss: 0.18150469660758972
Test Loss:  0.19189652800559998
Valid Loss:  0.17309734225273132
Epoch:  7  	Training Loss: 0.18144956231117249
Test Loss:  0.19185835123062134
Valid Loss:  0.17306187748908997
Epoch:  8  	Training Loss: 0.18141412734985352
Test Loss:  0.1918238401412964
Valid Loss:  0.17303118109703064
Epoch:  9  	Training Loss: 0.1813829243183136
Test Loss:  0.19179220497608185
Valid Loss:  0.17300328612327576
Epoch:  10  	Training Loss: 0.18135380744934082
Test Loss:  0.19176173210144043
Valid Loss:  0.17297670245170593
Epoch:  11  	Training Loss: 0.18132592737674713
Test Loss:  0.19173169136047363
Valid Loss:  0.17295074462890625
Epoch:  12  	Training Loss: 0.18129847943782806
Test Loss:  0.1917266845703125
Valid Loss:  0.17294630408287048
Epoch:  13  	Training Loss: 0.1812938004732132
Test Loss:  0.1917218565940857
Valid Loss:  0.1729419231414795
Epoch:  14  	Training Loss: 0.18128922581672668
Test Loss:  0.19171705842018127
Valid Loss:  0.17293764650821686
Epoch:  15  	Training Loss: 0.18128472566604614
Test Loss:  0.19171233475208282
Valid Loss:  0.1729333996772766
Epoch:  16  	Training Loss: 0.18128027021884918
Test Loss:  0.19170767068862915
Valid Loss:  0.17292913794517517
Epoch:  17  	Training Loss: 0.18127581477165222
Test Loss:  0.19170302152633667
Valid Loss:  0.17292490601539612
Epoch:  18  	Training Loss: 0.18127138912677765
Test Loss:  0.1916983723640442
Valid Loss:  0.17292070388793945
Epoch:  19  	Training Loss: 0.18126699328422546
Test Loss:  0.1916937381029129
Valid Loss:  0.1729164719581604
Epoch:  20  	Training Loss: 0.18126262724399567
Test Loss:  0.191689133644104
Valid Loss:  0.17291226983070374
Epoch:  21  	Training Loss: 0.18125826120376587
Test Loss:  0.1916845142841339
Valid Loss:  0.17290809750556946
Epoch:  22  	Training Loss: 0.18125393986701965
Test Loss:  0.19167941808700562
Valid Loss:  0.17290356755256653
Epoch:  23  	Training Loss: 0.18124918639659882
Test Loss:  0.19167430698871613
Valid Loss:  0.172899067401886
Epoch:  24  	Training Loss: 0.18124446272850037
Test Loss:  0.19166919589042664
Valid Loss:  0.17289455235004425
Epoch:  25  	Training Loss: 0.18123973906040192
Test Loss:  0.19166412949562073
Valid Loss:  0.1728900671005249
Epoch:  26  	Training Loss: 0.18123504519462585
Test Loss:  0.19165900349617004
Valid Loss:  0.17288556694984436
Epoch:  27  	Training Loss: 0.1812303215265274
Test Loss:  0.19165390729904175
Valid Loss:  0.1728810966014862
Epoch:  28  	Training Loss: 0.18122559785842896
Test Loss:  0.19164884090423584
Valid Loss:  0.17287661135196686
Epoch:  29  	Training Loss: 0.1812209039926529
Test Loss:  0.19164375960826874
Valid Loss:  0.1728721261024475
Epoch:  30  	Training Loss: 0.18121619522571564
Test Loss:  0.19163864850997925
Valid Loss:  0.17286765575408936
Epoch:  31  	Training Loss: 0.18121148645877838
Test Loss:  0.19163355231285095
Valid Loss:  0.1728631556034088
Epoch:  32  	Training Loss: 0.18120677769184113
Test Loss:  0.19162845611572266
Valid Loss:  0.17285868525505066
Epoch:  33  	Training Loss: 0.18120206892490387
Test Loss:  0.19162335991859436
Valid Loss:  0.17285418510437012
Epoch:  34  	Training Loss: 0.18119734525680542
Test Loss:  0.19161826372146606
Valid Loss:  0.17284971475601196
Epoch:  35  	Training Loss: 0.18119263648986816
Test Loss:  0.19161315262317657
Valid Loss:  0.17284521460533142
Epoch:  36  	Training Loss: 0.18118789792060852
Test Loss:  0.19160804152488708
Valid Loss:  0.17284072935581207
Epoch:  37  	Training Loss: 0.18118318915367126
Test Loss:  0.1916029155254364
Valid Loss:  0.17283624410629272
Epoch:  38  	Training Loss: 0.181178480386734
Test Loss:  0.1915978044271469
Valid Loss:  0.17283174395561218
Epoch:  39  	Training Loss: 0.18117375671863556
Test Loss:  0.19159269332885742
Valid Loss:  0.17282725870609283
Epoch:  40  	Training Loss: 0.1811690330505371
Test Loss:  0.19158758223056793
Valid Loss:  0.1728227585554123
Epoch:  41  	Training Loss: 0.18116432428359985
Test Loss:  0.19158247113227844
Valid Loss:  0.17281827330589294
Epoch:  42  	Training Loss: 0.1811596155166626
Test Loss:  0.19157738983631134
Valid Loss:  0.17281381785869598
Epoch:  43  	Training Loss: 0.18115490674972534
Test Loss:  0.19157229363918304
Valid Loss:  0.17280936241149902
Epoch:  44  	Training Loss: 0.18115022778511047
Test Loss:  0.19156721234321594
Valid Loss:  0.17280489206314087
Epoch:  45  	Training Loss: 0.18114551901817322
Test Loss:  0.19156211614608765
Valid Loss:  0.17280042171478271
Epoch:  46  	Training Loss: 0.18114084005355835
Test Loss:  0.19155704975128174
Valid Loss:  0.17279595136642456
Epoch:  47  	Training Loss: 0.1811361312866211
Test Loss:  0.19155195355415344
Valid Loss:  0.1727915108203888
Epoch:  48  	Training Loss: 0.18113145232200623
Test Loss:  0.19154685735702515
Valid Loss:  0.17278702557086945
Epoch:  49  	Training Loss: 0.18112677335739136
Test Loss:  0.19154179096221924
Valid Loss:  0.1727825552225113
Epoch:  50  	Training Loss: 0.1811220645904541
Test Loss:  0.19153669476509094
Valid Loss:  0.17277808487415314
Epoch:  51  	Training Loss: 0.18111737072467804
Test Loss:  0.19153159856796265
Valid Loss:  0.17277362942695618
Epoch:  52  	Training Loss: 0.18111267685890198
Test Loss:  0.19152653217315674
Valid Loss:  0.1727691888809204
Epoch:  53  	Training Loss: 0.1811079978942871
Test Loss:  0.19152146577835083
Valid Loss:  0.17276471853256226
Epoch:  54  	Training Loss: 0.18110331892967224
Test Loss:  0.19151636958122253
Valid Loss:  0.1727602630853653
Epoch:  55  	Training Loss: 0.18109863996505737
Test Loss:  0.19151130318641663
Valid Loss:  0.17275580763816833
Epoch:  56  	Training Loss: 0.1810939460992813
Test Loss:  0.19150623679161072
Valid Loss:  0.17275136709213257
Epoch:  57  	Training Loss: 0.18108928203582764
Test Loss:  0.1915011703968048
Valid Loss:  0.17274689674377441
Epoch:  58  	Training Loss: 0.18108458817005157
Test Loss:  0.1914960741996765
Valid Loss:  0.17274245619773865
Epoch:  59  	Training Loss: 0.1810799241065979
Test Loss:  0.1914910078048706
Valid Loss:  0.1727379858493805
Epoch:  60  	Training Loss: 0.18107523024082184
Test Loss:  0.1914859414100647
Valid Loss:  0.17273354530334473
Epoch:  61  	Training Loss: 0.18107053637504578
Test Loss:  0.1914808750152588
Valid Loss:  0.17272908985614777
Epoch:  62  	Training Loss: 0.1810658574104309
Test Loss:  0.19147582352161407
Valid Loss:  0.1727246642112732
Epoch:  63  	Training Loss: 0.18106120824813843
Test Loss:  0.19147077202796936
Valid Loss:  0.17272022366523743
Epoch:  64  	Training Loss: 0.18105655908584595
Test Loss:  0.19146572053432465
Valid Loss:  0.17271581292152405
Epoch:  65  	Training Loss: 0.18105190992355347
Test Loss:  0.19146068394184113
Valid Loss:  0.17271138727664948
Epoch:  66  	Training Loss: 0.181047260761261
Test Loss:  0.1914556473493576
Valid Loss:  0.1727069467306137
Epoch:  67  	Training Loss: 0.1810425966978073
Test Loss:  0.1914505958557129
Valid Loss:  0.17270252108573914
Epoch:  68  	Training Loss: 0.18103794753551483
Test Loss:  0.19144555926322937
Valid Loss:  0.17269808053970337
Epoch:  69  	Training Loss: 0.18103329837322235
Test Loss:  0.19144052267074585
Valid Loss:  0.17269368469715118
Epoch:  70  	Training Loss: 0.18102864921092987
Test Loss:  0.19143547117710114
Valid Loss:  0.17268922924995422
Epoch:  71  	Training Loss: 0.1810240000486374
Test Loss:  0.19143043458461761
Valid Loss:  0.17268481850624084
Epoch:  72  	Training Loss: 0.18101933598518372
Test Loss:  0.1914254128932953
Valid Loss:  0.17268040776252747
Epoch:  73  	Training Loss: 0.18101468682289124
Test Loss:  0.19142037630081177
Valid Loss:  0.1726759970188141
 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:00<08:11,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:17,  3.00it/s] 18%|█▊        | 91/500 [01:07<08:08,  1.19s/it] 19%|█▊        | 93/500 [01:07<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:07<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:07<03:03,  2.19it/s] 20%|█▉        | 99/500 [01:08<02:16,  2.93it/s] 20%|██        | 101/500 [01:14<07:57,  1.20s/it] 21%|██        | 103/500 [01:14<05:41,  1.16it/s] 21%|██        | 105/500 [01:14<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:14<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:15<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:21<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:21<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:28<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:28<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:35<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:41<06:57,  1.16s/it] 29%|██▊       | 143/500 [01:41<04:58,  1.20it/s] 29%|██▉       | 145/500 [01:42<03:34,  1.65it/s]Epoch:  74  	Training Loss: 0.18101006746292114
Test Loss:  0.19141533970832825
Valid Loss:  0.1726715862751007
Epoch:  75  	Training Loss: 0.18100541830062866
Test Loss:  0.19141030311584473
Valid Loss:  0.17266716063022614
Epoch:  76  	Training Loss: 0.18100078403949738
Test Loss:  0.1914052814245224
Valid Loss:  0.17266274988651276
Epoch:  77  	Training Loss: 0.1809961497783661
Test Loss:  0.19140025973320007
Valid Loss:  0.17265833914279938
Epoch:  78  	Training Loss: 0.1809915006160736
Test Loss:  0.19139522314071655
Valid Loss:  0.1726539134979248
Epoch:  79  	Training Loss: 0.18098685145378113
Test Loss:  0.19139020144939423
Valid Loss:  0.17264950275421143
Epoch:  80  	Training Loss: 0.18098220229148865
Test Loss:  0.1913851797580719
Valid Loss:  0.17264509201049805
Epoch:  81  	Training Loss: 0.18097758293151855
Test Loss:  0.19138014316558838
Valid Loss:  0.17264066636562347
Epoch:  82  	Training Loss: 0.18097294867038727
Test Loss:  0.19137513637542725
Valid Loss:  0.1726362705230713
Epoch:  83  	Training Loss: 0.18096832931041718
Test Loss:  0.1913701295852661
Valid Loss:  0.1726318895816803
Epoch:  84  	Training Loss: 0.18096372485160828
Test Loss:  0.19136512279510498
Valid Loss:  0.1726275086402893
Epoch:  85  	Training Loss: 0.18095910549163818
Test Loss:  0.19136013090610504
Valid Loss:  0.17262309789657593
Epoch:  86  	Training Loss: 0.1809544861316681
Test Loss:  0.1913551241159439
Valid Loss:  0.17261871695518494
Epoch:  87  	Training Loss: 0.180949866771698
Test Loss:  0.19135013222694397
Valid Loss:  0.17261430621147156
Epoch:  88  	Training Loss: 0.1809452474117279
Test Loss:  0.19134512543678284
Valid Loss:  0.17260992527008057
Epoch:  89  	Training Loss: 0.1809406280517578
Test Loss:  0.1913401186466217
Valid Loss:  0.17260554432868958
Epoch:  90  	Training Loss: 0.18093600869178772
Test Loss:  0.19133511185646057
Valid Loss:  0.1726011484861374
Epoch:  91  	Training Loss: 0.18093140423297882
Test Loss:  0.19133011996746063
Valid Loss:  0.1725967526435852
Epoch:  92  	Training Loss: 0.18092679977416992
Test Loss:  0.1913251429796219
Valid Loss:  0.1725923866033554
Epoch:  93  	Training Loss: 0.18092219531536102
Test Loss:  0.19132016599178314
Valid Loss:  0.1725880205631256
Epoch:  94  	Training Loss: 0.18091760575771332
Test Loss:  0.1913151890039444
Valid Loss:  0.17258363962173462
Epoch:  95  	Training Loss: 0.1809130162000656
Test Loss:  0.19131019711494446
Valid Loss:  0.17257928848266602
Epoch:  96  	Training Loss: 0.1809084117412567
Test Loss:  0.1913052350282669
Valid Loss:  0.17257490754127502
Epoch:  97  	Training Loss: 0.180903822183609
Test Loss:  0.19130024313926697
Valid Loss:  0.17257054150104523
Epoch:  98  	Training Loss: 0.1808992326259613
Test Loss:  0.19129526615142822
Valid Loss:  0.17256616055965424
Epoch:  99  	Training Loss: 0.1808946430683136
Test Loss:  0.19129028916358948
Valid Loss:  0.17256179451942444
Epoch:  100  	Training Loss: 0.1808900386095047
Test Loss:  0.19128532707691193
Valid Loss:  0.17255741357803345
Epoch:  101  	Training Loss: 0.180885449051857
Test Loss:  0.19128035008907318
Valid Loss:  0.17255304753780365
Epoch:  102  	Training Loss: 0.1808808594942093
Test Loss:  0.19127540290355682
Valid Loss:  0.17254871129989624
Epoch:  103  	Training Loss: 0.18087631464004517
Test Loss:  0.19127047061920166
Valid Loss:  0.17254438996315002
Epoch:  104  	Training Loss: 0.18087175488471985
Test Loss:  0.1912655234336853
Valid Loss:  0.17254003882408142
Epoch:  105  	Training Loss: 0.18086719512939453
Test Loss:  0.19126059114933014
Valid Loss:  0.172535702586174
Epoch:  106  	Training Loss: 0.1808626353740692
Test Loss:  0.19125564396381378
Valid Loss:  0.1725313663482666
Epoch:  107  	Training Loss: 0.1808580756187439
Test Loss:  0.19125071167945862
Valid Loss:  0.172527015209198
Epoch:  108  	Training Loss: 0.18085351586341858
Test Loss:  0.19124576449394226
Valid Loss:  0.17252269387245178
Epoch:  109  	Training Loss: 0.18084894120693207
Test Loss:  0.1912408322095871
Valid Loss:  0.17251834273338318
Epoch:  110  	Training Loss: 0.18084438145160675
Test Loss:  0.19123588502407074
Valid Loss:  0.17251402139663696
Epoch:  111  	Training Loss: 0.18083983659744263
Test Loss:  0.19123095273971558
Valid Loss:  0.17250967025756836
Epoch:  112  	Training Loss: 0.1808352768421173
Test Loss:  0.1912260353565216
Valid Loss:  0.17250534892082214
Epoch:  113  	Training Loss: 0.18083074688911438
Test Loss:  0.19122111797332764
Valid Loss:  0.17250104248523712
Epoch:  114  	Training Loss: 0.18082620203495026
Test Loss:  0.19121620059013367
Valid Loss:  0.1724967360496521
Epoch:  115  	Training Loss: 0.18082165718078613
Test Loss:  0.1912112981081009
Valid Loss:  0.17249241471290588
Epoch:  116  	Training Loss: 0.1808171272277832
Test Loss:  0.19120636582374573
Valid Loss:  0.17248809337615967
Epoch:  117  	Training Loss: 0.18081261217594147
Test Loss:  0.19120146334171295
Valid Loss:  0.17248377203941345
Epoch:  118  	Training Loss: 0.18080806732177734
Test Loss:  0.19119654595851898
Valid Loss:  0.17247946560382843
Epoch:  119  	Training Loss: 0.18080353736877441
Test Loss:  0.1911916434764862
Valid Loss:  0.1724751591682434
Epoch:  120  	Training Loss: 0.18079900741577148
Test Loss:  0.19118672609329224
Valid Loss:  0.1724708527326584
Epoch:  121  	Training Loss: 0.18079447746276855
Test Loss:  0.19118182361125946
Valid Loss:  0.17246653139591217
Epoch:  122  	Training Loss: 0.18078994750976562
Test Loss:  0.19117692112922668
Valid Loss:  0.17246222496032715
Epoch:  123  	Training Loss: 0.1807854175567627
Test Loss:  0.1911720335483551
Valid Loss:  0.17245793342590332
Epoch:  124  	Training Loss: 0.18078091740608215
Test Loss:  0.19116714596748352
Valid Loss:  0.1724536418914795
Epoch:  125  	Training Loss: 0.18077640235424042
Test Loss:  0.19116225838661194
Valid Loss:  0.17244933545589447
Epoch:  126  	Training Loss: 0.18077188730239868
Test Loss:  0.19115735590457916
Valid Loss:  0.17244504392147064
Epoch:  127  	Training Loss: 0.18076735734939575
Test Loss:  0.19115246832370758
Valid Loss:  0.17244073748588562
Epoch:  128  	Training Loss: 0.1807628571987152
Test Loss:  0.1911475658416748
Valid Loss:  0.17243646085262299
Epoch:  129  	Training Loss: 0.18075832724571228
Test Loss:  0.19114267826080322
Valid Loss:  0.17243215441703796
Epoch:  130  	Training Loss: 0.18075381219387054
Test Loss:  0.19113779067993164
Valid Loss:  0.17242786288261414
Epoch:  131  	Training Loss: 0.1807492971420288
Test Loss:  0.19113290309906006
Valid Loss:  0.1724235564470291
Epoch:  132  	Training Loss: 0.18074478209018707
Test Loss:  0.19112803041934967
Valid Loss:  0.17241927981376648
Epoch:  133  	Training Loss: 0.18074028193950653
Test Loss:  0.19112315773963928
Valid Loss:  0.17241501808166504
Epoch:  134  	Training Loss: 0.18073579668998718
Test Loss:  0.1911182850599289
Valid Loss:  0.1724107265472412
Epoch:  135  	Training Loss: 0.18073129653930664
Test Loss:  0.1911134123802185
Valid Loss:  0.17240643501281738
Epoch:  136  	Training Loss: 0.1807268112897873
Test Loss:  0.1911085546016693
Valid Loss:  0.17240217328071594
Epoch:  137  	Training Loss: 0.18072231113910675
Test Loss:  0.19110366702079773
Valid Loss:  0.17239788174629211
Epoch:  138  	Training Loss: 0.18071779608726501
Test Loss:  0.19109879434108734
Valid Loss:  0.1723935902118683
Epoch:  139  	Training Loss: 0.18071331083774567
Test Loss:  0.19109392166137695
Valid Loss:  0.17238934338092804
Epoch:  140  	Training Loss: 0.18070882558822632
Test Loss:  0.19108906388282776
Valid Loss:  0.1723850518465042
Epoch:  141  	Training Loss: 0.18070432543754578
Test Loss:  0.19108419120311737
Valid Loss:  0.17238077521324158
Epoch:  142  	Training Loss: 0.18069982528686523
Test Loss:  0.19107934832572937
Valid Loss:  0.17237652838230133
Epoch:  143  	Training Loss: 0.18069536983966827
Test Loss:  0.19107449054718018
Valid Loss:  0.1723722666501999
Epoch:  144  	Training Loss: 0.18069088459014893
Test Loss:  0.19106966257095337
Valid Loss:  0.17236800491809845
Epoch:  145  	Training Loss: 0.18068642914295197
Test Loss:  0.19106483459472656
Valid Loss:  0.1723637580871582
Epoch:  146  	Training Loss: 0.18068194389343262
Test Loss:   29%|██▉       | 147/500 [01:42<02:36,  2.26it/s] 30%|██▉       | 149/500 [01:42<01:55,  3.04it/s] 30%|███       | 151/500 [01:48<06:49,  1.17s/it] 31%|███       | 153/500 [01:48<04:52,  1.19it/s] 31%|███       | 155/500 [01:48<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:48<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:49<01:52,  3.02it/s] 32%|███▏      | 161/500 [01:55<06:34,  1.16s/it] 33%|███▎      | 163/500 [01:55<04:41,  1.20it/s] 33%|███▎      | 165/500 [01:55<03:22,  1.65it/s] 33%|███▎      | 167/500 [01:55<02:27,  2.26it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:02<06:26,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:08<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:27,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:15<06:00,  1.17s/it] 39%|███▊      | 193/500 [02:15<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:16<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:14,  2.24it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.02it/s] 40%|████      | 201/500 [02:22<05:55,  1.19s/it] 41%|████      | 203/500 [02:22<04:13,  1.17it/s] 41%|████      | 205/500 [02:22<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.22it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.97it/s] 42%|████▏     | 211/500 [02:29<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:29<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:29<02:07,  2.22it/s]0.19105997681617737
Valid Loss:  0.17235951125621796
Epoch:  147  	Training Loss: 0.18067747354507446
Test Loss:  0.19105513393878937
Valid Loss:  0.17235524952411652
Epoch:  148  	Training Loss: 0.1806730031967163
Test Loss:  0.19105029106140137
Valid Loss:  0.17235100269317627
Epoch:  149  	Training Loss: 0.18066853284835815
Test Loss:  0.19104546308517456
Valid Loss:  0.17234674096107483
Epoch:  150  	Training Loss: 0.1806640625
Test Loss:  0.19104060530662537
Valid Loss:  0.1723424792289734
Epoch:  151  	Training Loss: 0.18065959215164185
Test Loss:  0.19103576242923737
Valid Loss:  0.17233823239803314
Epoch:  152  	Training Loss: 0.18065513670444489
Test Loss:  0.19103094935417175
Valid Loss:  0.1723339855670929
Epoch:  153  	Training Loss: 0.18065068125724792
Test Loss:  0.19102612137794495
Valid Loss:  0.17232975363731384
Epoch:  154  	Training Loss: 0.18064622581005096
Test Loss:  0.19102129340171814
Valid Loss:  0.1723255217075348
Epoch:  155  	Training Loss: 0.180641770362854
Test Loss:  0.19101648032665253
Valid Loss:  0.17232128977775574
Epoch:  156  	Training Loss: 0.18063732981681824
Test Loss:  0.19101166725158691
Valid Loss:  0.1723170280456543
Epoch:  157  	Training Loss: 0.18063285946846008
Test Loss:  0.1910068392753601
Valid Loss:  0.17231281101703644
Epoch:  158  	Training Loss: 0.18062841892242432
Test Loss:  0.1910020112991333
Valid Loss:  0.1723085641860962
Epoch:  159  	Training Loss: 0.18062397837638855
Test Loss:  0.1909971982240677
Valid Loss:  0.17230433225631714
Epoch:  160  	Training Loss: 0.1806195229291916
Test Loss:  0.19099238514900208
Valid Loss:  0.17230011522769928
Epoch:  161  	Training Loss: 0.18061506748199463
Test Loss:  0.19098755717277527
Valid Loss:  0.17229586839675903
Epoch:  162  	Training Loss: 0.18061062693595886
Test Loss:  0.19098277390003204
Valid Loss:  0.17229166626930237
Epoch:  163  	Training Loss: 0.18060621619224548
Test Loss:  0.1909780204296112
Valid Loss:  0.1722874790430069
Epoch:  164  	Training Loss: 0.1806018203496933
Test Loss:  0.19097325205802917
Valid Loss:  0.17228329181671143
Epoch:  165  	Training Loss: 0.1805974245071411
Test Loss:  0.19096848368644714
Valid Loss:  0.17227910459041595
Epoch:  166  	Training Loss: 0.18059301376342773
Test Loss:  0.1909637153148651
Valid Loss:  0.17227491736412048
Epoch:  167  	Training Loss: 0.18058860301971436
Test Loss:  0.19095894694328308
Valid Loss:  0.172270730137825
Epoch:  168  	Training Loss: 0.18058420717716217
Test Loss:  0.19095417857170105
Valid Loss:  0.17226654291152954
Epoch:  169  	Training Loss: 0.18057981133460999
Test Loss:  0.19094941020011902
Valid Loss:  0.17226234078407288
Epoch:  170  	Training Loss: 0.1805754154920578
Test Loss:  0.19094465672969818
Valid Loss:  0.1722581684589386
Epoch:  171  	Training Loss: 0.18057100474834442
Test Loss:  0.19093988835811615
Valid Loss:  0.17225396633148193
Epoch:  172  	Training Loss: 0.18056660890579224
Test Loss:  0.1909351348876953
Valid Loss:  0.17224979400634766
Epoch:  173  	Training Loss: 0.18056221306324005
Test Loss:  0.19093038141727448
Valid Loss:  0.17224563658237457
Epoch:  174  	Training Loss: 0.18055783212184906
Test Loss:  0.19092562794685364
Valid Loss:  0.1722414493560791
Epoch:  175  	Training Loss: 0.18055343627929688
Test Loss:  0.1909208595752716
Valid Loss:  0.17223727703094482
Epoch:  176  	Training Loss: 0.18054905533790588
Test Loss:  0.19091610610485077
Valid Loss:  0.17223310470581055
Epoch:  177  	Training Loss: 0.1805446743965149
Test Loss:  0.19091135263442993
Valid Loss:  0.17222893238067627
Epoch:  178  	Training Loss: 0.1805402934551239
Test Loss:  0.1909066140651703
Valid Loss:  0.172224760055542
Epoch:  179  	Training Loss: 0.18053589761257172
Test Loss:  0.19090187549591064
Valid Loss:  0.17222055792808533
Epoch:  180  	Training Loss: 0.18053151667118073
Test Loss:  0.1908971071243286
Valid Loss:  0.17221638560295105
Epoch:  181  	Training Loss: 0.18052712082862854
Test Loss:  0.19089235365390778
Valid Loss:  0.17221222817897797
Epoch:  182  	Training Loss: 0.18052273988723755
Test Loss:  0.19088762998580933
Valid Loss:  0.17220807075500488
Epoch:  183  	Training Loss: 0.18051838874816895
Test Loss:  0.19088293612003326
Valid Loss:  0.172203928232193
Epoch:  184  	Training Loss: 0.18051403760910034
Test Loss:  0.19087821245193481
Valid Loss:  0.1721998006105423
Epoch:  185  	Training Loss: 0.18050968647003174
Test Loss:  0.19087353348731995
Valid Loss:  0.1721956431865692
Epoch:  186  	Training Loss: 0.18050533533096313
Test Loss:  0.1908687949180603
Valid Loss:  0.17219151556491852
Epoch:  187  	Training Loss: 0.18050098419189453
Test Loss:  0.19086408615112305
Valid Loss:  0.17218737304210663
Epoch:  188  	Training Loss: 0.18049663305282593
Test Loss:  0.1908593773841858
Valid Loss:  0.17218324542045593
Epoch:  189  	Training Loss: 0.18049228191375732
Test Loss:  0.19085465371608734
Valid Loss:  0.17217907309532166
Epoch:  190  	Training Loss: 0.18048793077468872
Test Loss:  0.19084995985031128
Valid Loss:  0.17217493057250977
Epoch:  191  	Training Loss: 0.18048357963562012
Test Loss:  0.19084522128105164
Valid Loss:  0.17217080295085907
Epoch:  192  	Training Loss: 0.1804792284965515
Test Loss:  0.19084055721759796
Valid Loss:  0.17216670513153076
Epoch:  193  	Training Loss: 0.1804749071598053
Test Loss:  0.1908358931541443
Valid Loss:  0.17216259241104126
Epoch:  194  	Training Loss: 0.18047058582305908
Test Loss:  0.19083121418952942
Valid Loss:  0.17215847969055176
Epoch:  195  	Training Loss: 0.18046627938747406
Test Loss:  0.19082653522491455
Valid Loss:  0.17215436697006226
Epoch:  196  	Training Loss: 0.18046195805072784
Test Loss:  0.19082185626029968
Valid Loss:  0.17215026915073395
Epoch:  197  	Training Loss: 0.18045765161514282
Test Loss:  0.1908172070980072
Valid Loss:  0.17214617133140564
Epoch:  198  	Training Loss: 0.1804533302783966
Test Loss:  0.19081252813339233
Valid Loss:  0.17214204370975494
Epoch:  199  	Training Loss: 0.18044902384281158
Test Loss:  0.19080784916877747
Valid Loss:  0.17213794589042664
Epoch:  200  	Training Loss: 0.18044470250606537
Test Loss:  0.1908031702041626
Valid Loss:  0.17213383316993713
Epoch:  201  	Training Loss: 0.18044039607048035
Test Loss:  0.19079849123954773
Valid Loss:  0.17212972044944763
Epoch:  202  	Training Loss: 0.18043605983257294
Test Loss:  0.19079384207725525
Valid Loss:  0.1721256524324417
Epoch:  203  	Training Loss: 0.1804317831993103
Test Loss:  0.19078920781612396
Valid Loss:  0.1721215695142746
Epoch:  204  	Training Loss: 0.18042749166488647
Test Loss:  0.19078457355499268
Valid Loss:  0.17211748659610748
Epoch:  205  	Training Loss: 0.18042321503162384
Test Loss:  0.1907799243927002
Valid Loss:  0.17211341857910156
Epoch:  206  	Training Loss: 0.1804189234972
Test Loss:  0.19077527523040771
Valid Loss:  0.17210933566093445
Epoch:  207  	Training Loss: 0.18041464686393738
Test Loss:  0.19077062606811523
Valid Loss:  0.17210525274276733
Epoch:  208  	Training Loss: 0.18041035532951355
Test Loss:  0.19076600670814514
Valid Loss:  0.17210116982460022
Epoch:  209  	Training Loss: 0.18040607869625092
Test Loss:  0.19076134264469147
Valid Loss:  0.1720970869064331
Epoch:  210  	Training Loss: 0.1804017871618271
Test Loss:  0.19075670838356018
Valid Loss:  0.172093003988266
Epoch:  211  	Training Loss: 0.18039749562740326
Test Loss:  0.1907520741224289
Valid Loss:  0.17208892107009888
Epoch:  212  	Training Loss: 0.18039321899414062
Test Loss:  0.1907474398612976
Valid Loss:  0.17208486795425415
Epoch:  213  	Training Loss: 0.18038895726203918
Test Loss:  0.1907428354024887
Valid Loss:  0.17208081483840942
Epoch:  214  	Training Loss: 0.18038469552993774
Test Loss:  0.19073820114135742
Valid Loss:  0.1720767319202423
Epoch:  215  	Training Loss: 0.18038040399551392
Test Loss:  0.19073358178138733
Valid Loss:  0.17207267880439758
Epoch:  216  	Training Loss: 0.18037614226341248
Test Loss:  0.19072896242141724
Valid Loss:  0.17206861078739166
Epoch:  217  	Training Loss: 0.18037188053131104
Test Loss:  0.19072434306144714
Valid Loss:  0.17206454277038574
Epoch:  218  	Training Loss: 0.1803676187992096
Test Loss:  0.19071972370147705
Valid Loss:   44%|████▍     | 219/500 [02:30<01:34,  2.99it/s] 44%|████▍     | 221/500 [02:36<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:36<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:43<05:13,  1.16s/it] 47%|████▋     | 233/500 [02:43<03:43,  1.20it/s] 47%|████▋     | 235/500 [02:43<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:43<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:43<01:25,  3.04it/s] 48%|████▊     | 241/500 [02:49<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:49<03:34,  1.20it/s] 49%|████▉     | 245/500 [02:50<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:50<01:51,  2.26it/s] 50%|████▉     | 249/500 [02:50<01:22,  3.04it/s] 50%|█████     | 251/500 [02:56<04:50,  1.17s/it] 51%|█████     | 253/500 [02:56<03:26,  1.19it/s] 51%|█████     | 255/500 [02:56<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:56<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:03<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:03<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:03<02:23,  1.63it/s] 53%|█████▎    | 267/500 [03:03<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:03<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:10<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:10<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:10<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:10<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:10<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:17<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:17<01:09,  3.02it/s]0.17206048965454102
Epoch:  219  	Training Loss: 0.18036334216594696
Test Loss:  0.19071510434150696
Valid Loss:  0.1720564365386963
Epoch:  220  	Training Loss: 0.18035908043384552
Test Loss:  0.19071048498153687
Valid Loss:  0.17205235362052917
Epoch:  221  	Training Loss: 0.18035480380058289
Test Loss:  0.19070585072040558
Valid Loss:  0.17204830050468445
Epoch:  222  	Training Loss: 0.18035054206848145
Test Loss:  0.19070126116275787
Valid Loss:  0.17204426229000092
Epoch:  223  	Training Loss: 0.18034628033638
Test Loss:  0.19069667160511017
Valid Loss:  0.17204022407531738
Epoch:  224  	Training Loss: 0.18034204840660095
Test Loss:  0.19069206714630127
Valid Loss:  0.17203617095947266
Epoch:  225  	Training Loss: 0.1803377866744995
Test Loss:  0.19068746268749237
Valid Loss:  0.17203211784362793
Epoch:  226  	Training Loss: 0.18033355474472046
Test Loss:  0.19068285822868347
Valid Loss:  0.1720280796289444
Epoch:  227  	Training Loss: 0.1803293079137802
Test Loss:  0.19067826867103577
Valid Loss:  0.17202404141426086
Epoch:  228  	Training Loss: 0.18032506108283997
Test Loss:  0.19067367911338806
Valid Loss:  0.17202000319957733
Epoch:  229  	Training Loss: 0.18032081425189972
Test Loss:  0.19066907465457916
Valid Loss:  0.1720159649848938
Epoch:  230  	Training Loss: 0.18031656742095947
Test Loss:  0.19066447019577026
Valid Loss:  0.17201191186904907
Epoch:  231  	Training Loss: 0.18031232059001923
Test Loss:  0.19065988063812256
Valid Loss:  0.17200787365436554
Epoch:  232  	Training Loss: 0.18030807375907898
Test Loss:  0.19065530598163605
Valid Loss:  0.1720038652420044
Epoch:  233  	Training Loss: 0.18030385673046112
Test Loss:  0.19065076112747192
Valid Loss:  0.17199982702732086
Epoch:  234  	Training Loss: 0.18029963970184326
Test Loss:  0.19064617156982422
Valid Loss:  0.17199581861495972
Epoch:  235  	Training Loss: 0.1802954077720642
Test Loss:  0.1906415969133377
Valid Loss:  0.17199179530143738
Epoch:  236  	Training Loss: 0.18029117584228516
Test Loss:  0.1906370222568512
Valid Loss:  0.17198777198791504
Epoch:  237  	Training Loss: 0.1802869588136673
Test Loss:  0.19063246250152588
Valid Loss:  0.1719837486743927
Epoch:  238  	Training Loss: 0.18028274178504944
Test Loss:  0.19062788784503937
Valid Loss:  0.17197972536087036
Epoch:  239  	Training Loss: 0.18027850985527039
Test Loss:  0.19062331318855286
Valid Loss:  0.17197570204734802
Epoch:  240  	Training Loss: 0.18027429282665253
Test Loss:  0.19061875343322754
Valid Loss:  0.17197167873382568
Epoch:  241  	Training Loss: 0.18027007579803467
Test Loss:  0.19061417877674103
Valid Loss:  0.17196765542030334
Epoch:  242  	Training Loss: 0.18026584386825562
Test Loss:  0.1906096339225769
Valid Loss:  0.1719636768102646
Epoch:  243  	Training Loss: 0.18026165664196014
Test Loss:  0.19060511887073517
Valid Loss:  0.17195969820022583
Epoch:  244  	Training Loss: 0.18025748431682587
Test Loss:  0.19060060381889343
Valid Loss:  0.17195571959018707
Epoch:  245  	Training Loss: 0.1802532970905304
Test Loss:  0.1905960738658905
Valid Loss:  0.17195174098014832
Epoch:  246  	Training Loss: 0.18024912476539612
Test Loss:  0.19059155881404877
Valid Loss:  0.17194776237010956
Epoch:  247  	Training Loss: 0.18024493753910065
Test Loss:  0.19058701395988464
Valid Loss:  0.1719437837600708
Epoch:  248  	Training Loss: 0.18024076521396637
Test Loss:  0.1905824989080429
Valid Loss:  0.17193980515003204
Epoch:  249  	Training Loss: 0.1802365779876709
Test Loss:  0.19057798385620117
Valid Loss:  0.1719358116388321
Epoch:  250  	Training Loss: 0.18023239076137543
Test Loss:  0.19057343900203705
Valid Loss:  0.17193183302879333
Epoch:  251  	Training Loss: 0.18022821843624115
Test Loss:  0.1905689239501953
Valid Loss:  0.17192785441875458
Epoch:  252  	Training Loss: 0.18022403120994568
Test Loss:  0.19056440889835358
Valid Loss:  0.17192387580871582
Epoch:  253  	Training Loss: 0.1802198588848114
Test Loss:  0.19055989384651184
Valid Loss:  0.17191991209983826
Epoch:  254  	Training Loss: 0.1802157163619995
Test Loss:  0.1905553936958313
Valid Loss:  0.1719159483909607
Epoch:  255  	Training Loss: 0.18021154403686523
Test Loss:  0.19055089354515076
Valid Loss:  0.17191198468208313
Epoch:  256  	Training Loss: 0.18020737171173096
Test Loss:  0.19054639339447021
Valid Loss:  0.17190800607204437
Epoch:  257  	Training Loss: 0.18020319938659668
Test Loss:  0.19054187834262848
Valid Loss:  0.171904057264328
Epoch:  258  	Training Loss: 0.1801990568637848
Test Loss:  0.19053736329078674
Valid Loss:  0.17190009355545044
Epoch:  259  	Training Loss: 0.1801948845386505
Test Loss:  0.190532848238945
Valid Loss:  0.17189611494541168
Epoch:  260  	Training Loss: 0.18019071221351624
Test Loss:  0.19052834808826447
Valid Loss:  0.17189213633537292
Epoch:  261  	Training Loss: 0.18018655478954315
Test Loss:  0.19052384793758392
Valid Loss:  0.17188818752765656
Epoch:  262  	Training Loss: 0.18018238246440887
Test Loss:  0.19051936268806458
Valid Loss:  0.17188423871994019
Epoch:  263  	Training Loss: 0.18017825484275818
Test Loss:  0.19051489233970642
Valid Loss:  0.171880304813385
Epoch:  264  	Training Loss: 0.1801741123199463
Test Loss:  0.19051042199134827
Valid Loss:  0.17187635600566864
Epoch:  265  	Training Loss: 0.1801699697971344
Test Loss:  0.19050592184066772
Valid Loss:  0.17187242209911346
Epoch:  266  	Training Loss: 0.1801658421754837
Test Loss:  0.19050145149230957
Valid Loss:  0.1718684732913971
Epoch:  267  	Training Loss: 0.18016169965267181
Test Loss:  0.19049698114395142
Valid Loss:  0.17186453938484192
Epoch:  268  	Training Loss: 0.18015757203102112
Test Loss:  0.19049251079559326
Valid Loss:  0.17186060547828674
Epoch:  269  	Training Loss: 0.18015342950820923
Test Loss:  0.19048801064491272
Valid Loss:  0.17185665667057037
Epoch:  270  	Training Loss: 0.18014928698539734
Test Loss:  0.19048354029655457
Valid Loss:  0.1718527227640152
Epoch:  271  	Training Loss: 0.18014514446258545
Test Loss:  0.1904790699481964
Valid Loss:  0.17184877395629883
Epoch:  272  	Training Loss: 0.18014100193977356
Test Loss:  0.19047462940216064
Valid Loss:  0.17184486985206604
Epoch:  273  	Training Loss: 0.18013691902160645
Test Loss:  0.19047017395496368
Valid Loss:  0.17184095084667206
Epoch:  274  	Training Loss: 0.18013280630111694
Test Loss:  0.1904657483100891
Valid Loss:  0.17183706164360046
Epoch:  275  	Training Loss: 0.18012869358062744
Test Loss:  0.19046129286289215
Valid Loss:  0.17183315753936768
Epoch:  276  	Training Loss: 0.18012459576129913
Test Loss:  0.19045686721801758
Valid Loss:  0.1718292534351349
Epoch:  277  	Training Loss: 0.18012049794197083
Test Loss:  0.1904524266719818
Valid Loss:  0.1718253195285797
Epoch:  278  	Training Loss: 0.18011638522148132
Test Loss:  0.19044798612594604
Valid Loss:  0.17182143032550812
Epoch:  279  	Training Loss: 0.18011228740215302
Test Loss:  0.19044354557991028
Valid Loss:  0.17181751132011414
Epoch:  280  	Training Loss: 0.1801081746816635
Test Loss:  0.1904391050338745
Valid Loss:  0.17181360721588135
Epoch:  281  	Training Loss: 0.1801040768623352
Test Loss:  0.19043466448783875
Valid Loss:  0.17180970311164856
Epoch:  282  	Training Loss: 0.1800999641418457
Test Loss:  0.19043026864528656
Valid Loss:  0.17180582880973816
Epoch:  283  	Training Loss: 0.18009589612483978
Test Loss:  0.19042587280273438
Valid Loss:  0.17180193960666656
Epoch:  284  	Training Loss: 0.18009184300899506
Test Loss:  0.190421462059021
Valid Loss:  0.17179808020591736
Epoch:  285  	Training Loss: 0.18008777499198914
Test Loss:  0.19041708111763
Valid Loss:  0.17179419100284576
Epoch:  286  	Training Loss: 0.18008370697498322
Test Loss:  0.19041264057159424
Valid Loss:  0.17179033160209656
Epoch:  287  	Training Loss: 0.1800796389579773
Test Loss:  0.19040825963020325
Valid Loss:  0.17178645730018616
Epoch:  288  	Training Loss: 0.18007557094097137
Test Loss:  0.19040386378765106
Valid Loss:  0.17178256809711456
Epoch:  289  	Training Loss: 0.18007150292396545
Test Loss:  0.19039946794509888
Valid Loss:  0.17177870869636536
Epoch:  290  	Training Loss: 0.18006742000579834
Test Loss:  0.1903950572013855
Valid Loss:  0.17177483439445496
 58%|█████▊    | 291/500 [03:23<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:24<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:24<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:24<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:24<01:07,  2.98it/s] 60%|██████    | 301/500 [03:30<03:55,  1.18s/it] 61%|██████    | 303/500 [03:30<02:47,  1.17it/s] 61%|██████    | 305/500 [03:31<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:31<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:37<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:37<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:38<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:38<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:38<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:44<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:44<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:44<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:45<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:51<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:51<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:51<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:51<00:53,  3.01it/s] 68%|██████▊   | 341/500 [03:58<03:09,  1.19s/it] 69%|██████▊   | 343/500 [03:58<02:14,  1.17it/s] 69%|██████▉   | 345/500 [03:58<01:35,  1.62it/s] 69%|██████▉   | 347/500 [03:58<01:09,  2.22it/s] 70%|██████▉   | 349/500 [03:58<00:50,  2.98it/s] 70%|███████   | 351/500 [04:05<02:54,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:11<02:44,  1.19s/it]Epoch:  291  	Training Loss: 0.1800633668899536
Test Loss:  0.1903906613588333
Valid Loss:  0.17177096009254456
Epoch:  292  	Training Loss: 0.1800593137741089
Test Loss:  0.19038629531860352
Valid Loss:  0.17176711559295654
Epoch:  293  	Training Loss: 0.18005526065826416
Test Loss:  0.19038191437721252
Valid Loss:  0.17176327109336853
Epoch:  294  	Training Loss: 0.18005123734474182
Test Loss:  0.19037756323814392
Valid Loss:  0.17175939679145813
Epoch:  295  	Training Loss: 0.1800471842288971
Test Loss:  0.19037318229675293
Valid Loss:  0.1717555820941925
Epoch:  296  	Training Loss: 0.18004314601421356
Test Loss:  0.19036883115768433
Valid Loss:  0.1717517226934433
Epoch:  297  	Training Loss: 0.18003910779953003
Test Loss:  0.19036445021629333
Valid Loss:  0.1717478632926941
Epoch:  298  	Training Loss: 0.1800350695848465
Test Loss:  0.19036006927490234
Valid Loss:  0.17174403369426727
Epoch:  299  	Training Loss: 0.18003103137016296
Test Loss:  0.19035570323467255
Valid Loss:  0.17174017429351807
Epoch:  300  	Training Loss: 0.18002699315547943
Test Loss:  0.19035133719444275
Valid Loss:  0.17173632979393005
Epoch:  301  	Training Loss: 0.1800229549407959
Test Loss:  0.19034697115421295
Valid Loss:  0.17173248529434204
Epoch:  302  	Training Loss: 0.18001893162727356
Test Loss:  0.19034260511398315
Valid Loss:  0.17172867059707642
Epoch:  303  	Training Loss: 0.18001490831375122
Test Loss:  0.19033825397491455
Valid Loss:  0.1717248260974884
Epoch:  304  	Training Loss: 0.1800108700990677
Test Loss:  0.19033390283584595
Valid Loss:  0.17172099649906158
Epoch:  305  	Training Loss: 0.18000686168670654
Test Loss:  0.19032958149909973
Valid Loss:  0.17171716690063477
Epoch:  306  	Training Loss: 0.1800028383731842
Test Loss:  0.19032521545886993
Valid Loss:  0.17171333730220795
Epoch:  307  	Training Loss: 0.17999881505966187
Test Loss:  0.19032086431980133
Valid Loss:  0.17170950770378113
Epoch:  308  	Training Loss: 0.17999479174613953
Test Loss:  0.19031652808189392
Valid Loss:  0.17170566320419312
Epoch:  309  	Training Loss: 0.1799907684326172
Test Loss:  0.19031217694282532
Valid Loss:  0.1717018485069275
Epoch:  310  	Training Loss: 0.17998674511909485
Test Loss:  0.1903078258037567
Valid Loss:  0.17169800400733948
Epoch:  311  	Training Loss: 0.1799827218055725
Test Loss:  0.1903034746646881
Valid Loss:  0.17169418931007385
Epoch:  312  	Training Loss: 0.17997869849205017
Test Loss:  0.1902991533279419
Valid Loss:  0.17169037461280823
Epoch:  313  	Training Loss: 0.17997470498085022
Test Loss:  0.19029486179351807
Valid Loss:  0.171686589717865
Epoch:  314  	Training Loss: 0.17997071146965027
Test Loss:  0.19029054045677185
Valid Loss:  0.17168277502059937
Epoch:  315  	Training Loss: 0.1799667477607727
Test Loss:  0.19028621912002563
Valid Loss:  0.17167899012565613
Epoch:  316  	Training Loss: 0.17996275424957275
Test Loss:  0.19028189778327942
Valid Loss:  0.1716751903295517
Epoch:  317  	Training Loss: 0.1799587607383728
Test Loss:  0.1902776062488556
Valid Loss:  0.17167139053344727
Epoch:  318  	Training Loss: 0.17995478212833405
Test Loss:  0.19027328491210938
Valid Loss:  0.17166757583618164
Epoch:  319  	Training Loss: 0.1799508035182953
Test Loss:  0.19026896357536316
Valid Loss:  0.1716637909412384
Epoch:  320  	Training Loss: 0.17994681000709534
Test Loss:  0.19026467204093933
Valid Loss:  0.17166000604629517
Epoch:  321  	Training Loss: 0.17994281649589539
Test Loss:  0.19026035070419312
Valid Loss:  0.17165619134902954
Epoch:  322  	Training Loss: 0.17993882298469543
Test Loss:  0.19025607407093048
Valid Loss:  0.1716524362564087
Epoch:  323  	Training Loss: 0.17993488907814026
Test Loss:  0.19025179743766785
Valid Loss:  0.17164866626262665
Epoch:  324  	Training Loss: 0.1799309402704239
Test Loss:  0.1902475357055664
Valid Loss:  0.1716448962688446
Epoch:  325  	Training Loss: 0.17992699146270752
Test Loss:  0.19024324417114258
Valid Loss:  0.17164114117622375
Epoch:  326  	Training Loss: 0.17992302775382996
Test Loss:  0.19023898243904114
Valid Loss:  0.1716373860836029
Epoch:  327  	Training Loss: 0.1799190789461136
Test Loss:  0.1902347207069397
Valid Loss:  0.17163361608982086
Epoch:  328  	Training Loss: 0.17991513013839722
Test Loss:  0.19023045897483826
Valid Loss:  0.1716298609972
Epoch:  329  	Training Loss: 0.17991119623184204
Test Loss:  0.19022618234157562
Valid Loss:  0.17162609100341797
Epoch:  330  	Training Loss: 0.17990723252296448
Test Loss:  0.190221905708313
Valid Loss:  0.17162233591079712
Epoch:  331  	Training Loss: 0.1799032986164093
Test Loss:  0.19021764397621155
Valid Loss:  0.17161856591701508
Epoch:  332  	Training Loss: 0.17989933490753174
Test Loss:  0.1902133971452713
Valid Loss:  0.17161482572555542
Epoch:  333  	Training Loss: 0.17989541590213776
Test Loss:  0.19020915031433105
Valid Loss:  0.17161110043525696
Epoch:  334  	Training Loss: 0.17989149689674377
Test Loss:  0.190204918384552
Valid Loss:  0.1716073751449585
Epoch:  335  	Training Loss: 0.1798875778913498
Test Loss:  0.19020068645477295
Valid Loss:  0.17160364985466003
Epoch:  336  	Training Loss: 0.179883673787117
Test Loss:  0.1901964545249939
Valid Loss:  0.17159990966320038
Epoch:  337  	Training Loss: 0.17987975478172302
Test Loss:  0.19019222259521484
Valid Loss:  0.17159616947174072
Epoch:  338  	Training Loss: 0.17987583577632904
Test Loss:  0.1901879906654358
Valid Loss:  0.17159244418144226
Epoch:  339  	Training Loss: 0.17987191677093506
Test Loss:  0.19018375873565674
Valid Loss:  0.1715887188911438
Epoch:  340  	Training Loss: 0.17986799776554108
Test Loss:  0.1901795119047165
Valid Loss:  0.17158497869968414
Epoch:  341  	Training Loss: 0.1798640787601471
Test Loss:  0.19017526507377625
Valid Loss:  0.1715812385082245
Epoch:  342  	Training Loss: 0.1798601746559143
Test Loss:  0.19017107784748077
Valid Loss:  0.1715775430202484
Epoch:  343  	Training Loss: 0.17985627055168152
Test Loss:  0.1901668757200241
Valid Loss:  0.17157384753227234
Epoch:  344  	Training Loss: 0.17985239624977112
Test Loss:  0.19016268849372864
Valid Loss:  0.17157015204429626
Epoch:  345  	Training Loss: 0.17984850704669952
Test Loss:  0.19015848636627197
Valid Loss:  0.171566441655159
Epoch:  346  	Training Loss: 0.17984463274478912
Test Loss:  0.1901542842388153
Valid Loss:  0.17156274616718292
Epoch:  347  	Training Loss: 0.17984074354171753
Test Loss:  0.19015009701251984
Valid Loss:  0.17155906558036804
Epoch:  348  	Training Loss: 0.17983686923980713
Test Loss:  0.19014589488506317
Valid Loss:  0.17155534029006958
Epoch:  349  	Training Loss: 0.17983299493789673
Test Loss:  0.1901416778564453
Valid Loss:  0.1715516448020935
Epoch:  350  	Training Loss: 0.17982910573482513
Test Loss:  0.19013749063014984
Valid Loss:  0.17154794931411743
Epoch:  351  	Training Loss: 0.17982521653175354
Test Loss:  0.19013328850269318
Valid Loss:  0.17154425382614136
Epoch:  352  	Training Loss: 0.17982134222984314
Test Loss:  0.1901291310787201
Valid Loss:  0.17154058814048767
Epoch:  353  	Training Loss: 0.17981746792793274
Test Loss:  0.19012495875358582
Valid Loss:  0.1715369075536728
Epoch:  354  	Training Loss: 0.17981363832950592
Test Loss:  0.19012078642845154
Valid Loss:  0.1715332418680191
Epoch:  355  	Training Loss: 0.1798097789287567
Test Loss:  0.19011661410331726
Valid Loss:  0.17152956128120422
Epoch:  356  	Training Loss: 0.1798059344291687
Test Loss:  0.19011247158050537
Valid Loss:  0.17152589559555054
Epoch:  357  	Training Loss: 0.1798020899295807
Test Loss:  0.1901082992553711
Valid Loss:  0.17152222990989685
Epoch:  358  	Training Loss: 0.1797982156276703
Test Loss:  0.19010412693023682
Valid Loss:  0.17151856422424316
Epoch:  359  	Training Loss: 0.17979437112808228
Test Loss:  0.19009996950626373
Valid Loss:  0.17151489853858948
Epoch:  360  	Training Loss: 0.17979052662849426
Test Loss:  0.19009578227996826
Valid Loss:  0.1715112030506134
Epoch:  361  	Training Loss: 0.17978665232658386
Test Loss:  0.19009160995483398
Valid Loss:  0.17150753736495972
Epoch:  362  	Training Loss: 0.17978280782699585
Test Loss:  0.1900874823331833
Valid Loss:  0.17150387167930603
Epoch:  363  	Training Loss: 0.17977897822856903
 73%|███████▎  | 363/500 [04:12<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:12<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:12<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:18<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:18<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:19<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:19<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:25<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:25<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:26<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:26<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:26<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:32<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:32<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:33<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:33<00:33,  2.99it/s] 80%|████████  | 401/500 [04:39<01:56,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:39<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:46<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:46<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:46<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:53<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.66it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.03it/s] 86%|████████▌ | 431/500 [04:59<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:00<00:56,  1.18it/s]Test Loss:  0.1900833547115326
Valid Loss:  0.17150023579597473
Epoch:  364  	Training Loss: 0.1797751486301422
Test Loss:  0.1900792121887207
Valid Loss:  0.17149659991264343
Epoch:  365  	Training Loss: 0.1797713339328766
Test Loss:  0.1900750696659088
Valid Loss:  0.17149293422698975
Epoch:  366  	Training Loss: 0.17976748943328857
Test Loss:  0.19007094204425812
Valid Loss:  0.17148929834365845
Epoch:  367  	Training Loss: 0.17976367473602295
Test Loss:  0.19006679952144623
Valid Loss:  0.17148564755916595
Epoch:  368  	Training Loss: 0.17975984513759613
Test Loss:  0.19006265699863434
Valid Loss:  0.17148199677467346
Epoch:  369  	Training Loss: 0.1797560155391693
Test Loss:  0.19005852937698364
Valid Loss:  0.17147836089134216
Epoch:  370  	Training Loss: 0.1797521710395813
Test Loss:  0.19005438685417175
Valid Loss:  0.17147471010684967
Epoch:  371  	Training Loss: 0.17974835634231567
Test Loss:  0.19005024433135986
Valid Loss:  0.17147105932235718
Epoch:  372  	Training Loss: 0.17974454164505005
Test Loss:  0.19004614651203156
Valid Loss:  0.17146743834018707
Epoch:  373  	Training Loss: 0.17974072694778442
Test Loss:  0.19004201889038086
Valid Loss:  0.17146381735801697
Epoch:  374  	Training Loss: 0.1797369420528412
Test Loss:  0.19003793597221375
Valid Loss:  0.17146021127700806
Epoch:  375  	Training Loss: 0.17973312735557556
Test Loss:  0.19003382325172424
Valid Loss:  0.17145657539367676
Epoch:  376  	Training Loss: 0.17972934246063232
Test Loss:  0.19002971053123474
Valid Loss:  0.17145296931266785
Epoch:  377  	Training Loss: 0.1797255277633667
Test Loss:  0.19002561271190643
Valid Loss:  0.17144933342933655
Epoch:  378  	Training Loss: 0.17972174286842346
Test Loss:  0.19002151489257812
Valid Loss:  0.17144572734832764
Epoch:  379  	Training Loss: 0.17971794307231903
Test Loss:  0.19001740217208862
Valid Loss:  0.17144212126731873
Epoch:  380  	Training Loss: 0.1797141581773758
Test Loss:  0.19001330435276031
Valid Loss:  0.17143848538398743
Epoch:  381  	Training Loss: 0.17971034348011017
Test Loss:  0.190009206533432
Valid Loss:  0.17143487930297852
Epoch:  382  	Training Loss: 0.17970655858516693
Test Loss:  0.1900051385164261
Valid Loss:  0.1714312732219696
Epoch:  383  	Training Loss: 0.1797027885913849
Test Loss:  0.19000107049942017
Valid Loss:  0.17142769694328308
Epoch:  384  	Training Loss: 0.17969903349876404
Test Loss:  0.18999698758125305
Valid Loss:  0.17142410576343536
Epoch:  385  	Training Loss: 0.179695263504982
Test Loss:  0.18999293446540833
Valid Loss:  0.17142052948474884
Epoch:  386  	Training Loss: 0.17969149351119995
Test Loss:  0.1899888515472412
Valid Loss:  0.17141693830490112
Epoch:  387  	Training Loss: 0.1796877384185791
Test Loss:  0.1899847835302353
Valid Loss:  0.1714133322238922
Epoch:  388  	Training Loss: 0.17968398332595825
Test Loss:  0.18998071551322937
Valid Loss:  0.1714097559452057
Epoch:  389  	Training Loss: 0.17968019843101501
Test Loss:  0.18997666239738464
Valid Loss:  0.17140617966651917
Epoch:  390  	Training Loss: 0.17967642843723297
Test Loss:  0.18997257947921753
Valid Loss:  0.17140258848667145
Epoch:  391  	Training Loss: 0.17967268824577332
Test Loss:  0.1899685263633728
Valid Loss:  0.17139899730682373
Epoch:  392  	Training Loss: 0.17966891825199127
Test Loss:  0.18996447324752808
Valid Loss:  0.1713954210281372
Epoch:  393  	Training Loss: 0.17966517806053162
Test Loss:  0.18996044993400574
Valid Loss:  0.17139187455177307
Epoch:  394  	Training Loss: 0.17966145277023315
Test Loss:  0.1899564117193222
Valid Loss:  0.17138831317424774
Epoch:  395  	Training Loss: 0.1796576976776123
Test Loss:  0.18995237350463867
Valid Loss:  0.1713847517967224
Epoch:  396  	Training Loss: 0.17965397238731384
Test Loss:  0.18994833528995514
Valid Loss:  0.17138119041919708
Epoch:  397  	Training Loss: 0.17965024709701538
Test Loss:  0.1899443119764328
Valid Loss:  0.17137762904167175
Epoch:  398  	Training Loss: 0.17964650690555573
Test Loss:  0.18994025886058807
Valid Loss:  0.17137406766414642
Epoch:  399  	Training Loss: 0.17964276671409607
Test Loss:  0.18993623554706573
Valid Loss:  0.1713705062866211
Epoch:  400  	Training Loss: 0.1796390265226364
Test Loss:  0.1899321973323822
Valid Loss:  0.17136694490909576
Epoch:  401  	Training Loss: 0.17963530123233795
Test Loss:  0.18992814421653748
Valid Loss:  0.17136338353157043
Epoch:  402  	Training Loss: 0.1796315610408783
Test Loss:  0.18992415070533752
Valid Loss:  0.1713598370552063
Epoch:  403  	Training Loss: 0.17962785065174103
Test Loss:  0.18992012739181519
Valid Loss:  0.17135632038116455
Epoch:  404  	Training Loss: 0.17962414026260376
Test Loss:  0.18991613388061523
Valid Loss:  0.17135277390480042
Epoch:  405  	Training Loss: 0.1796204298734665
Test Loss:  0.1899121105670929
Valid Loss:  0.17134925723075867
Epoch:  406  	Training Loss: 0.17961671948432922
Test Loss:  0.18990811705589294
Valid Loss:  0.17134571075439453
Epoch:  407  	Training Loss: 0.17961302399635315
Test Loss:  0.189904123544693
Valid Loss:  0.1713421791791916
Epoch:  408  	Training Loss: 0.1796092987060547
Test Loss:  0.18990010023117065
Valid Loss:  0.17133863270282745
Epoch:  409  	Training Loss: 0.1796056032180786
Test Loss:  0.1898960918188095
Valid Loss:  0.1713351011276245
Epoch:  410  	Training Loss: 0.17960187792778015
Test Loss:  0.18989209830760956
Valid Loss:  0.17133155465126038
Epoch:  411  	Training Loss: 0.17959816753864288
Test Loss:  0.1898880898952484
Valid Loss:  0.17132802307605743
Epoch:  412  	Training Loss: 0.17959445714950562
Test Loss:  0.18988409638404846
Valid Loss:  0.17132452130317688
Epoch:  413  	Training Loss: 0.17959079146385193
Test Loss:  0.1898801326751709
Valid Loss:  0.17132101953029633
Epoch:  414  	Training Loss: 0.17958711087703705
Test Loss:  0.18987615406513214
Valid Loss:  0.17131751775741577
Epoch:  415  	Training Loss: 0.17958343029022217
Test Loss:  0.18987219035625458
Valid Loss:  0.17131400108337402
Epoch:  416  	Training Loss: 0.1795797497034073
Test Loss:  0.18986821174621582
Valid Loss:  0.17131049931049347
Epoch:  417  	Training Loss: 0.1795760691165924
Test Loss:  0.18986424803733826
Valid Loss:  0.17130699753761292
Epoch:  418  	Training Loss: 0.17957240343093872
Test Loss:  0.1898602545261383
Valid Loss:  0.17130348086357117
Epoch:  419  	Training Loss: 0.17956872284412384
Test Loss:  0.18985629081726074
Valid Loss:  0.1712999790906906
Epoch:  420  	Training Loss: 0.17956504225730896
Test Loss:  0.18985231220722198
Valid Loss:  0.17129647731781006
Epoch:  421  	Training Loss: 0.17956136167049408
Test Loss:  0.18984833359718323
Valid Loss:  0.1712929606437683
Epoch:  422  	Training Loss: 0.1795576810836792
Test Loss:  0.18984439969062805
Valid Loss:  0.17128948867321014
Epoch:  423  	Training Loss: 0.1795540452003479
Test Loss:  0.1898404359817505
Valid Loss:  0.17128601670265198
Epoch:  424  	Training Loss: 0.1795503795146942
Test Loss:  0.1898365020751953
Valid Loss:  0.17128252983093262
Epoch:  425  	Training Loss: 0.17954672873020172
Test Loss:  0.18983256816864014
Valid Loss:  0.17127904295921326
Epoch:  426  	Training Loss: 0.17954307794570923
Test Loss:  0.18982861936092377
Valid Loss:  0.1712755560874939
Epoch:  427  	Training Loss: 0.17953941226005554
Test Loss:  0.1898246556520462
Valid Loss:  0.17127208411693573
Epoch:  428  	Training Loss: 0.17953577637672424
Test Loss:  0.18982073664665222
Valid Loss:  0.17126861214637756
Epoch:  429  	Training Loss: 0.17953211069107056
Test Loss:  0.18981678783893585
Valid Loss:  0.171265110373497
Epoch:  430  	Training Loss: 0.17952847480773926
Test Loss:  0.18981283903121948
Valid Loss:  0.17126163840293884
Epoch:  431  	Training Loss: 0.17952482402324677
Test Loss:  0.1898089051246643
Valid Loss:  0.17125815153121948
Epoch:  432  	Training Loss: 0.17952115833759308
Test Loss:  0.18980498611927032
Valid Loss:  0.1712547093629837
Epoch:  433  	Training Loss: 0.17951755225658417
Test Loss:  0.18980108201503754
Valid Loss:  0.17125125229358673
Epoch:  434  	Training Loss: 0.17951393127441406
Test Loss:  0.18979716300964355
Valid Loss:  0.17124781012535095
Epoch:  435  	Training Loss: 0.17951029539108276
Test Loss:  0.18979325890541077
Valid Loss:  87%|████████▋ | 435/500 [05:00<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:07<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:13<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:14<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:20<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:20<00:10,  2.99it/s] 94%|█████████▍| 471/500 [05:27<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:27<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:34<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:34<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:41<00:00,  3.01it/s]100%|██████████| 500/500 [05:41<00:00,  1.46it/s]
 0.17124435305595398
Epoch:  436  	Training Loss: 0.17950668931007385
Test Loss:  0.18978935480117798
Valid Loss:  0.171240895986557
Epoch:  437  	Training Loss: 0.17950306832790375
Test Loss:  0.1897854208946228
Valid Loss:  0.17123743891716003
Epoch:  438  	Training Loss: 0.17949944734573364
Test Loss:  0.1897815316915512
Valid Loss:  0.17123399674892426
Epoch:  439  	Training Loss: 0.17949582636356354
Test Loss:  0.18977761268615723
Valid Loss:  0.17123053967952728
Epoch:  440  	Training Loss: 0.17949220538139343
Test Loss:  0.18977370858192444
Valid Loss:  0.1712270975112915
Epoch:  441  	Training Loss: 0.17948858439922333
Test Loss:  0.18976977467536926
Valid Loss:  0.17122364044189453
Epoch:  442  	Training Loss: 0.17948496341705322
Test Loss:  0.18976590037345886
Valid Loss:  0.17122019827365875
Epoch:  443  	Training Loss: 0.1794813722372055
Test Loss:  0.18976204097270966
Valid Loss:  0.17121678590774536
Epoch:  444  	Training Loss: 0.1794777810573578
Test Loss:  0.18975815176963806
Valid Loss:  0.17121335864067078
Epoch:  445  	Training Loss: 0.17947418987751007
Test Loss:  0.18975429236888885
Valid Loss:  0.1712099313735962
Epoch:  446  	Training Loss: 0.17947059869766235
Test Loss:  0.18975038826465607
Valid Loss:  0.171206533908844
Epoch:  447  	Training Loss: 0.17946699261665344
Test Loss:  0.18974652886390686
Valid Loss:  0.17120309174060822
Epoch:  448  	Training Loss: 0.17946341633796692
Test Loss:  0.18974263966083527
Valid Loss:  0.17119967937469482
Epoch:  449  	Training Loss: 0.179459810256958
Test Loss:  0.18973876535892487
Valid Loss:  0.17119625210762024
Epoch:  450  	Training Loss: 0.17945623397827148
Test Loss:  0.18973489105701447
Valid Loss:  0.17119282484054565
Epoch:  451  	Training Loss: 0.17945265769958496
Test Loss:  0.18973100185394287
Valid Loss:  0.17118939757347107
Epoch:  452  	Training Loss: 0.17944905161857605
Test Loss:  0.18972717225551605
Valid Loss:  0.17118601500988007
Epoch:  453  	Training Loss: 0.17944550514221191
Test Loss:  0.18972334265708923
Valid Loss:  0.17118263244628906
Epoch:  454  	Training Loss: 0.17944195866584778
Test Loss:  0.18971949815750122
Valid Loss:  0.17117923498153687
Epoch:  455  	Training Loss: 0.17943839728832245
Test Loss:  0.1897156536579132
Valid Loss:  0.17117586731910706
Epoch:  456  	Training Loss: 0.17943483591079712
Test Loss:  0.18971183896064758
Valid Loss:  0.17117246985435486
Epoch:  457  	Training Loss: 0.17943128943443298
Test Loss:  0.18970799446105957
Valid Loss:  0.17116908729076385
Epoch:  458  	Training Loss: 0.17942774295806885
Test Loss:  0.18970416486263275
Valid Loss:  0.17116570472717285
Epoch:  459  	Training Loss: 0.1794241964817047
Test Loss:  0.18970033526420593
Valid Loss:  0.17116230726242065
Epoch:  460  	Training Loss: 0.17942065000534058
Test Loss:  0.18969649076461792
Valid Loss:  0.17115890979766846
Epoch:  461  	Training Loss: 0.17941708862781525
Test Loss:  0.1896926462650299
Valid Loss:  0.17115554213523865
Epoch:  462  	Training Loss: 0.1794135421514511
Test Loss:  0.18968884646892548
Valid Loss:  0.17115217447280884
Epoch:  463  	Training Loss: 0.17941002547740936
Test Loss:  0.18968504667282104
Valid Loss:  0.17114883661270142
Epoch:  464  	Training Loss: 0.17940649390220642
Test Loss:  0.1896812468767166
Valid Loss:  0.1711454540491104
Epoch:  465  	Training Loss: 0.17940297722816467
Test Loss:  0.18967744708061218
Valid Loss:  0.17114213109016418
Epoch:  466  	Training Loss: 0.17939946055412292
Test Loss:  0.18967363238334656
Valid Loss:  0.17113874852657318
Epoch:  467  	Training Loss: 0.17939592897891998
Test Loss:  0.18966983258724213
Valid Loss:  0.17113539576530457
Epoch:  468  	Training Loss: 0.17939241230487823
Test Loss:  0.1896660327911377
Valid Loss:  0.17113202810287476
Epoch:  469  	Training Loss: 0.1793888807296753
Test Loss:  0.18966223299503326
Valid Loss:  0.17112869024276733
Epoch:  470  	Training Loss: 0.17938537895679474
Test Loss:  0.18965843319892883
Valid Loss:  0.17112532258033752
Epoch:  471  	Training Loss: 0.1793818473815918
Test Loss:  0.1896546185016632
Valid Loss:  0.1711219698190689
Epoch:  472  	Training Loss: 0.17937833070755005
Test Loss:  0.18965083360671997
Valid Loss:  0.1711186170578003
Epoch:  473  	Training Loss: 0.1793748140335083
Test Loss:  0.18964703381061554
Valid Loss:  0.17111524939537048
Epoch:  474  	Training Loss: 0.17937129735946655
Test Loss:  0.1896432489156723
Valid Loss:  0.17111191153526306
Epoch:  475  	Training Loss: 0.1793677806854248
Test Loss:  0.18963944911956787
Valid Loss:  0.17110857367515564
Epoch:  476  	Training Loss: 0.17936427891254425
Test Loss:  0.18963566422462463
Valid Loss:  0.17110520601272583
Epoch:  477  	Training Loss: 0.1793607771396637
Test Loss:  0.1896318644285202
Valid Loss:  0.17110185325145721
Epoch:  478  	Training Loss: 0.17935726046562195
Test Loss:  0.18962806463241577
Valid Loss:  0.1710985004901886
Epoch:  479  	Training Loss: 0.1793537437915802
Test Loss:  0.18962427973747253
Valid Loss:  0.17109516263008118
Epoch:  480  	Training Loss: 0.17935022711753845
Test Loss:  0.1896204948425293
Valid Loss:  0.17109179496765137
Epoch:  481  	Training Loss: 0.1793467104434967
Test Loss:  0.18961668014526367
Valid Loss:  0.17108845710754395
Epoch:  482  	Training Loss: 0.17934319376945496
Test Loss:  0.1896129548549652
Valid Loss:  0.1710851490497589
Epoch:  483  	Training Loss: 0.1793397217988968
Test Loss:  0.18960918486118317
Valid Loss:  0.17108182609081268
Epoch:  484  	Training Loss: 0.17933624982833862
Test Loss:  0.18960542976856232
Valid Loss:  0.17107851803302765
Epoch:  485  	Training Loss: 0.17933276295661926
Test Loss:  0.18960168957710266
Valid Loss:  0.17107519507408142
Epoch:  486  	Training Loss: 0.1793293058872223
Test Loss:  0.1895979344844818
Valid Loss:  0.17107190191745758
Epoch:  487  	Training Loss: 0.17932581901550293
Test Loss:  0.18959417939186096
Valid Loss:  0.17106857895851135
Epoch:  488  	Training Loss: 0.17932233214378357
Test Loss:  0.1895904392004013
Valid Loss:  0.17106527090072632
Epoch:  489  	Training Loss: 0.1793188750743866
Test Loss:  0.18958668410778046
Valid Loss:  0.1710619330406189
Epoch:  490  	Training Loss: 0.17931538820266724
Test Loss:  0.1895829439163208
Valid Loss:  0.17105863988399506
Epoch:  491  	Training Loss: 0.17931193113327026
Test Loss:  0.18957918882369995
Valid Loss:  0.17105533182621002
Epoch:  492  	Training Loss: 0.1793084442615509
Test Loss:  0.1895754486322403
Valid Loss:  0.171052023768425
Epoch:  493  	Training Loss: 0.17930498719215393
Test Loss:  0.18957172334194183
Valid Loss:  0.17104871571063995
Epoch:  494  	Training Loss: 0.17930153012275696
Test Loss:  0.18956798315048218
Valid Loss:  0.1710454225540161
Epoch:  495  	Training Loss: 0.17929807305335999
Test Loss:  0.18956422805786133
Valid Loss:  0.17104211449623108
Epoch:  496  	Training Loss: 0.17929458618164062
Test Loss:  0.18956050276756287
Valid Loss:  0.17103880643844604
Epoch:  497  	Training Loss: 0.17929114401340485
Test Loss:  0.1895567774772644
Valid Loss:  0.171035498380661
Epoch:  498  	Training Loss: 0.17928767204284668
Test Loss:  0.18955303728580475
Valid Loss:  0.17103222012519836
Epoch:  499  	Training Loss: 0.1792842149734497
Test Loss:  0.1895492970943451
Valid Loss:  0.17102891206741333
Epoch:  500  	Training Loss: 0.17928075790405273
Test Loss:  0.18954555690288544
Valid Loss:  0.1710256040096283
seed is  12
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:45,  6.22s/it]  1%|          | 3/500 [00:06<13:47,  1.67s/it]  1%|          | 5/500 [00:06<06:57,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:26<12:13,  1.54s/it]  5%|▌         | 27/500 [00:26<08:39,  1.10s/it]  6%|▌         | 29/500 [00:26<06:10,  1.27it/s]  6%|▌         | 31/500 [00:32<11:43,  1.50s/it]  7%|▋         | 33/500 [00:33<08:19,  1.07s/it]  7%|▋         | 35/500 [00:33<05:56,  1.30it/s]  7%|▋         | 37/500 [00:33<04:17,  1.80it/s]  8%|▊         | 39/500 [00:33<03:08,  2.45it/s]  8%|▊         | 41/500 [00:39<09:19,  1.22s/it]  9%|▊         | 43/500 [00:39<06:38,  1.15it/s]  9%|▉         | 45/500 [00:39<04:46,  1.59it/s]  9%|▉         | 47/500 [00:40<03:28,  2.18it/s] 10%|▉         | 49/500 [00:40<02:33,  2.94it/s] 10%|█         | 51/500 [00:46<08:48,  1.18s/it] 11%|█         | 53/500 [00:46<06:18,  1.18it/s] 11%|█         | 55/500 [00:46<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:46<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:46<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:53<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:53<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:53<04:27,  1.62it/s] 13%|█▎        | 67/500 [00:53<03:16,  2.20it/s]Epoch:  1  	Training Loss: 0.1824793517589569
Test Loss:  0.07296013832092285
Valid Loss:  0.08964696526527405
Epoch:  2  	Training Loss: 0.08491315692663193
Test Loss:  0.09388691931962967
Valid Loss:  0.08347096294164658
Epoch:  3  	Training Loss: 0.08870990574359894
Test Loss:  0.05782688036561012
Valid Loss:  0.07020895928144455
Epoch:  4  	Training Loss: 0.06640726327896118
Test Loss:  0.02627827227115631
Valid Loss:  0.02427849918603897
Epoch:  5  	Training Loss: 0.026067692786455154
Test Loss:  0.01617029868066311
Valid Loss:  0.019680336117744446
Epoch:  6  	Training Loss: 0.01902986317873001
Test Loss:  0.012114867568016052
Valid Loss:  0.011903580278158188
Epoch:  7  	Training Loss: 0.012784373015165329
Test Loss:  0.008851169608533382
Valid Loss:  0.010479135438799858
Epoch:  8  	Training Loss: 0.010440494865179062
Test Loss:  0.007530373055487871
Valid Loss:  0.007747848518192768
Epoch:  9  	Training Loss: 0.008280578069388866
Test Loss:  0.005886917933821678
Valid Loss:  0.006841944996267557
Epoch:  10  	Training Loss: 0.00699985958635807
Test Loss:  0.005205101333558559
Valid Loss:  0.005675171501934528
Epoch:  11  	Training Loss: 0.006000827997922897
Test Loss:  0.004343857988715172
Valid Loss:  0.005047496408224106
Epoch:  12  	Training Loss: 0.005240040831267834
Test Loss:  0.0027673824224621058
Valid Loss:  0.0032468028366565704
Epoch:  13  	Training Loss: 0.0033994452096521854
Test Loss:  0.0019318986451253295
Valid Loss:  0.0022701346315443516
Epoch:  14  	Training Loss: 0.002430810360237956
Test Loss:  0.0014378384221345186
Valid Loss:  0.0018362365663051605
Epoch:  15  	Training Loss: 0.0018672687001526356
Test Loss:  0.0012077788123860955
Valid Loss:  0.0014242164324969053
Epoch:  16  	Training Loss: 0.0015239025233313441
Test Loss:  0.0010700137354433537
Valid Loss:  0.001309526851400733
Epoch:  17  	Training Loss: 0.001327111735008657
Test Loss:  0.0009102425538003445
Valid Loss:  0.0010630302131175995
Epoch:  18  	Training Loss: 0.0011245770147070289
Test Loss:  0.0008573513478040695
Valid Loss:  0.0009845371823757887
Epoch:  19  	Training Loss: 0.0010048681870102882
Test Loss:  0.000700145261362195
Valid Loss:  0.0008120754500851035
Epoch:  20  	Training Loss: 0.0008503131102770567
Test Loss:  0.000684295198880136
Valid Loss:  0.0007440446061082184
Epoch:  21  	Training Loss: 0.0007666934980079532
Test Loss:  0.0005491348565556109
Valid Loss:  0.0006281285313889384
Epoch:  22  	Training Loss: 0.0006530121900141239
Test Loss:  0.0012391902273520827
Valid Loss:  0.001171740936115384
Epoch:  23  	Training Loss: 0.0011984820012003183
Test Loss:  0.004318853374570608
Valid Loss:  0.0047943806275725365
Epoch:  24  	Training Loss: 0.004726485349237919
Test Loss:  0.020999373868107796
Valid Loss:  0.0211048386991024
Epoch:  25  	Training Loss: 0.021014504134655
Test Loss:  0.04532758146524429
Valid Loss:  0.04813925176858902
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.04721924662590027
Test Loss:  0.0027861478738486767
Valid Loss:  0.003132871352136135
Epoch:  27  	Training Loss: 0.0029920816887170076
Test Loss:  0.0007048618863336742
Valid Loss:  0.0007120731752365828
Epoch:  28  	Training Loss: 0.0007041300414130092
Test Loss:  0.0006874599494040012
Valid Loss:  0.0006696537602692842
Epoch:  29  	Training Loss: 0.0006719233933836222
Test Loss:  0.0006738798692822456
Valid Loss:  0.0006582568166777492
Epoch:  30  	Training Loss: 0.00066104915458709
Test Loss:  0.0006606437964364886
Valid Loss:  0.0006488102953881025
Epoch:  31  	Training Loss: 0.0006512528052553535
Test Loss:  0.0006482299650087953
Valid Loss:  0.0006404614541679621
Epoch:  32  	Training Loss: 0.000642386032268405
Test Loss:  0.0006330874748528004
Valid Loss:  0.0006243089446797967
Epoch:  33  	Training Loss: 0.0006259307847358286
Test Loss:  0.0006179030751809478
Valid Loss:  0.0006089344387874007
Epoch:  34  	Training Loss: 0.0006101123290136456
Test Loss:  0.000602841260842979
Valid Loss:  0.0005941784474998713
Epoch:  35  	Training Loss: 0.0005947832833044231
Test Loss:  0.0005880839307792485
Valid Loss:  0.0005799435311928391
Epoch:  36  	Training Loss: 0.0005799314239993691
Test Loss:  0.0005737595492973924
Valid Loss:  0.0005662048934027553
Epoch:  37  	Training Loss: 0.0005655032582581043
Test Loss:  0.0005598128773272038
Valid Loss:  0.0005527900066226721
Epoch:  38  	Training Loss: 0.0005513288779184222
Test Loss:  0.0005463451961986721
Valid Loss:  0.0005396673223003745
Epoch:  39  	Training Loss: 0.0005375251057557762
Test Loss:  0.0005333005683496594
Valid Loss:  0.0005269027315080166
Epoch:  40  	Training Loss: 0.0005241463659331203
Test Loss:  0.0005206345813348889
Valid Loss:  0.0005145191098563373
Epoch:  41  	Training Loss: 0.0005111671634949744
Test Loss:  0.0005088434554636478
Valid Loss:  0.0005028020823374391
Epoch:  42  	Training Loss: 0.0004988611326552927
Test Loss:  0.00047337485011667013
Valid Loss:  0.0004754103720188141
Epoch:  43  	Training Loss: 0.00047086901031434536
Test Loss:  0.0004463558434508741
Valid Loss:  0.0004519080393947661
Epoch:  44  	Training Loss: 0.0004487384867388755
Test Loss:  0.0004253827501088381
Valid Loss:  0.00043540235492400825
Epoch:  45  	Training Loss: 0.0004326279740780592
Test Loss:  0.0004093497118446976
Valid Loss:  0.0004240201669745147
Epoch:  46  	Training Loss: 0.00042089709313586354
Test Loss:  0.0003959837486036122
Valid Loss:  0.0004154886701144278
Epoch:  47  	Training Loss: 0.00041201867861673236
Test Loss:  0.00038500811206176877
Valid Loss:  0.0004086411790922284
Epoch:  48  	Training Loss: 0.00040476879803463817
Test Loss:  0.0003758052480407059
Valid Loss:  0.00040289724711328745
Epoch:  49  	Training Loss: 0.00039858694071881473
Test Loss:  0.0003680037916637957
Valid Loss:  0.0003982486668974161
Epoch:  50  	Training Loss: 0.0003934416745323688
Test Loss:  0.0003614829038269818
Valid Loss:  0.00039473787182942033
Epoch:  51  	Training Loss: 0.00038919056532904506
Test Loss:  0.0003557759046088904
Valid Loss:  0.0003917412250302732
Epoch:  52  	Training Loss: 0.0003855861141346395
Test Loss:  0.0003479651059024036
Valid Loss:  0.00038208955083973706
Epoch:  53  	Training Loss: 0.0003760237595997751
Test Loss:  0.0003403949667699635
Valid Loss:  0.0003720567037817091
Epoch:  54  	Training Loss: 0.0003660303773358464
Test Loss:  0.0003331436892040074
Valid Loss:  0.00036035486846230924
Epoch:  55  	Training Loss: 0.00035572037450037897
Test Loss:  0.00032644541352055967
Valid Loss:  0.00034882675390690565
Epoch:  56  	Training Loss: 0.0003459158760961145
Test Loss:  0.00031969964038580656
Valid Loss:  0.0003367548924870789
Epoch:  57  	Training Loss: 0.0003355437656864524
Test Loss:  0.00031245165155269206
Valid Loss:  0.0003249654546380043
Epoch:  58  	Training Loss: 0.00032501600799150765
Test Loss:  0.0003049595979973674
Valid Loss:  0.0003130537807010114
Epoch:  59  	Training Loss: 0.000313927186653018
Test Loss:  0.00029776006704196334
Valid Loss:  0.000301576335914433
Epoch:  60  	Training Loss: 0.0003028906648978591
Test Loss:  0.0002908423193730414
Valid Loss:  0.0002902598353102803
Epoch:  61  	Training Loss: 0.00029173673829063773
Test Loss:  0.0002838188665919006
Valid Loss:  0.0002795803302433342
Epoch:  62  	Training Loss: 0.0002812536258716136
Test Loss:  0.0002811755402944982
Valid Loss:  0.0002782112860586494
Epoch:  63  	Training Loss: 0.00027963952743448317
Test Loss:  0.00027881169808097184
Valid Loss:  0.00027676415629684925
Epoch:  64  	Training Loss: 0.000278134539257735
Test Loss:  0.00027657666942104697
Valid Loss:  0.00027526458143256605
Epoch:  65  	Training Loss: 0.0002766533871181309
Test Loss:  0.00027444990701042116
Valid Loss:  0.0002738085458986461
Epoch:  66  	Training Loss: 0.0002752401342149824
Test Loss:  0.0002724344376474619
Valid Loss:  0.0002723934012465179
Epoch:  67  	Training Loss: 0.0002738656767178327
Test Loss:  0.00027052531368099153
Valid Loss:  0.00027103960746899247
Epoch:  68  	Training Loss: 0.00027251295978203416
Test Loss:  0.00026856723707169294
Valid Loss:  0.0002696265873964876
 14%|█▍        | 69/500 [00:53<02:26,  2.95it/s] 14%|█▍        | 71/500 [01:00<08:30,  1.19s/it] 15%|█▍        | 73/500 [01:00<06:04,  1.17it/s] 15%|█▌        | 75/500 [01:00<04:22,  1.62it/s] 15%|█▌        | 77/500 [01:00<03:11,  2.21it/s] 16%|█▌        | 79/500 [01:00<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:07<08:12,  1.18s/it] 17%|█▋        | 83/500 [01:07<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:07<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:07<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:07<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:13<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:14<05:49,  1.16it/s] 19%|█▉        | 95/500 [01:14<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:14<03:03,  2.19it/s] 20%|█▉        | 99/500 [01:14<02:16,  2.94it/s] 20%|██        | 101/500 [01:21<08:03,  1.21s/it] 21%|██        | 103/500 [01:21<05:44,  1.15it/s] 21%|██        | 105/500 [01:21<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:21<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:21<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:27<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:27<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:28<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:28<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:28<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:34<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:34<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:34<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:35<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:35<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:41<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:41<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:41<03:45,  1.62it/s]Epoch:  69  	Training Loss: 0.00027105421759188175
Test Loss:  0.0002666110813152045
Valid Loss:  0.00026823009829968214
Epoch:  70  	Training Loss: 0.00026956258807331324
Test Loss:  0.00026460038498044014
Valid Loss:  0.00026675182743929327
Epoch:  71  	Training Loss: 0.0002679702010937035
Test Loss:  0.0002625926281325519
Valid Loss:  0.0002650219830684364
Epoch:  72  	Training Loss: 0.00026623185840435326
Test Loss:  0.0002547700423747301
Valid Loss:  0.00025487784296274185
Epoch:  73  	Training Loss: 0.00025619781808927655
Test Loss:  0.0002465242287144065
Valid Loss:  0.0002446707512717694
Epoch:  74  	Training Loss: 0.00024566520005464554
Test Loss:  0.0002379438083153218
Valid Loss:  0.00023432093439623713
Epoch:  75  	Training Loss: 0.00023500295355916023
Test Loss:  0.00022910136613063514
Valid Loss:  0.00022365048062056303
Epoch:  76  	Training Loss: 0.00022403545153792948
Test Loss:  0.00022454382269643247
Valid Loss:  0.00021587006631307304
Epoch:  77  	Training Loss: 0.0002161863521905616
Test Loss:  0.00021860362903680652
Valid Loss:  0.0002094413066515699
Epoch:  78  	Training Loss: 0.00020941408001817763
Test Loss:  0.00021350159659050405
Valid Loss:  0.00020350515842437744
Epoch:  79  	Training Loss: 0.0002033024502452463
Test Loss:  0.00020903529366478324
Valid Loss:  0.000198100067791529
Epoch:  80  	Training Loss: 0.00019782963499892503
Test Loss:  0.000205046366318129
Valid Loss:  0.0001931825972860679
Epoch:  81  	Training Loss: 0.00019290734780952334
Test Loss:  0.00020165099704172462
Valid Loss:  0.00018881485448218882
Epoch:  82  	Training Loss: 0.00018850105698220432
Test Loss:  0.00020101512200199068
Valid Loss:  0.00018855447706300765
Epoch:  83  	Training Loss: 0.00018815384828485548
Test Loss:  0.00020048397709615529
Valid Loss:  0.00018829747568815947
Epoch:  84  	Training Loss: 0.0001878356415545568
Test Loss:  0.0002000159292947501
Valid Loss:  0.0001880391064332798
Epoch:  85  	Training Loss: 0.00018753073527477682
Test Loss:  0.0001995851780520752
Valid Loss:  0.00018778516096062958
Epoch:  86  	Training Loss: 0.00018723533139564097
Test Loss:  0.0001991952449316159
Valid Loss:  0.00018753494077827781
Epoch:  87  	Training Loss: 0.00018694854225032032
Test Loss:  0.0001988409348996356
Valid Loss:  0.00018728990107774734
Epoch:  88  	Training Loss: 0.00018666811229195446
Test Loss:  0.00019852624973282218
Valid Loss:  0.00018705004185903817
Epoch:  89  	Training Loss: 0.00018639228073880076
Test Loss:  0.0001982367830350995
Valid Loss:  0.00018681219080463052
Epoch:  90  	Training Loss: 0.00018612049461808056
Test Loss:  0.0001979712105821818
Valid Loss:  0.00018657720647752285
Epoch:  91  	Training Loss: 0.000185853656148538
Test Loss:  0.00019772721861954778
Valid Loss:  0.00018634663138072938
Epoch:  92  	Training Loss: 0.00018559242016635835
Test Loss:  0.00019494273874443024
Valid Loss:  0.0001793500268831849
Epoch:  93  	Training Loss: 0.00017888942966237664
Test Loss:  0.0001915772445499897
Valid Loss:  0.0001732106611598283
Epoch:  94  	Training Loss: 0.0001728557690512389
Test Loss:  0.00018864244339056313
Valid Loss:  0.00016730543575249612
Epoch:  95  	Training Loss: 0.00016722423606552184
Test Loss:  0.00018537456344347447
Valid Loss:  0.00016154914919752628
Epoch:  96  	Training Loss: 0.00016172893811017275
Test Loss:  0.0001822825870476663
Valid Loss:  0.00015599915059283376
Epoch:  97  	Training Loss: 0.0001565314450999722
Test Loss:  0.0001789699017535895
Valid Loss:  0.00015092587273102254
Epoch:  98  	Training Loss: 0.00015169379184953868
Test Loss:  0.00017579522682353854
Valid Loss:  0.0001461635110899806
Epoch:  99  	Training Loss: 0.0001471552241127938
Test Loss:  0.00017261506582144648
Valid Loss:  0.00014169738278724253
Epoch:  100  	Training Loss: 0.00014286875375546515
Test Loss:  0.0001694119710009545
Valid Loss:  0.00013745091564487666
Epoch:  101  	Training Loss: 0.0001388606906402856
Test Loss:  0.00016624110867269337
Valid Loss:  0.00013351705274544656
Epoch:  102  	Training Loss: 0.00013504577509593219
Test Loss:  0.00016509732813574374
Valid Loss:  0.00013283753651194274
Epoch:  103  	Training Loss: 0.00013410563406068832
Test Loss:  0.00016404205234721303
Valid Loss:  0.00013219306129030883
Epoch:  104  	Training Loss: 0.00013322272570803761
Test Loss:  0.00016308040358126163
Valid Loss:  0.00013157943612895906
Epoch:  105  	Training Loss: 0.0001323899778071791
Test Loss:  0.00016218758537434042
Valid Loss:  0.00013100760406814516
Epoch:  106  	Training Loss: 0.0001316103443969041
Test Loss:  0.00016134936595335603
Valid Loss:  0.00013045809464529157
Epoch:  107  	Training Loss: 0.00013087625848129392
Test Loss:  0.0001605611469130963
Valid Loss:  0.00012992431584279984
Epoch:  108  	Training Loss: 0.00013018480967730284
Test Loss:  0.00015983321645762771
Valid Loss:  0.00012941968452651054
Epoch:  109  	Training Loss: 0.0001295862894039601
Test Loss:  0.0001591691398061812
Valid Loss:  0.000128949512145482
Epoch:  110  	Training Loss: 0.00012905284529551864
Test Loss:  0.00015854557568673044
Valid Loss:  0.0001285077742068097
Epoch:  111  	Training Loss: 0.00012855749810114503
Test Loss:  0.00015796010848134756
Valid Loss:  0.00012807754683308303
Epoch:  112  	Training Loss: 0.00012807882740162313
Test Loss:  0.0001576714712427929
Valid Loss:  0.00012723449617624283
Epoch:  113  	Training Loss: 0.00012721799430437386
Test Loss:  0.00015741368406452239
Valid Loss:  0.00012647452240344137
Epoch:  114  	Training Loss: 0.0001264262682525441
Test Loss:  0.000157210961333476
Valid Loss:  0.00012579766917042434
Epoch:  115  	Training Loss: 0.00012570001126732677
Test Loss:  0.00015701280790381134
Valid Loss:  0.00012521882308647037
Epoch:  116  	Training Loss: 0.00012505939230322838
Test Loss:  0.00015683224773965776
Valid Loss:  0.0001246936444658786
Epoch:  117  	Training Loss: 0.00012446127948351204
Test Loss:  0.00015667080879211426
Valid Loss:  0.00012419885024428368
Epoch:  118  	Training Loss: 0.00012389093171805143
Test Loss:  0.00015651134890504181
Valid Loss:  0.00012376863742247224
Epoch:  119  	Training Loss: 0.00012336307554505765
Test Loss:  0.00015632540453225374
Valid Loss:  0.0001233685325132683
Epoch:  120  	Training Loss: 0.0001229042245540768
Test Loss:  0.0001561250537633896
Valid Loss:  0.00012301445531193167
Epoch:  121  	Training Loss: 0.0001225004089064896
Test Loss:  0.00015590776456519961
Valid Loss:  0.00012276308552827686
Epoch:  122  	Training Loss: 0.00012215548485983163
Test Loss:  0.0001553343900013715
Valid Loss:  0.0001217376411659643
Epoch:  123  	Training Loss: 0.0001214303047163412
Test Loss:  0.0001543645339552313
Valid Loss:  0.00012109294766560197
Epoch:  124  	Training Loss: 0.00012081005843356252
Test Loss:  0.0001536157651571557
Valid Loss:  0.0001204292057082057
Epoch:  125  	Training Loss: 0.000120218624942936
Test Loss:  0.0001529100991319865
Valid Loss:  0.00011979920964222401
Epoch:  126  	Training Loss: 0.00011964983423240483
Test Loss:  0.00015227249241434038
Valid Loss:  0.0001191854098578915
Epoch:  127  	Training Loss: 0.00011910501052625477
Test Loss:  0.00015169552352745086
Valid Loss:  0.00011860007361974567
Epoch:  128  	Training Loss: 0.0001185871078632772
Test Loss:  0.0001511674781795591
Valid Loss:  0.00011803707457147539
Epoch:  129  	Training Loss: 0.00011809709394583479
Test Loss:  0.00015069212531670928
Valid Loss:  0.00011748923861887306
Epoch:  130  	Training Loss: 0.00011762772919610143
Test Loss:  0.0001502615778008476
Valid Loss:  0.0001169515453511849
Epoch:  131  	Training Loss: 0.00011717485176632181
Test Loss:  0.0001498580677434802
Valid Loss:  0.00011642285971902311
Epoch:  132  	Training Loss: 0.00011673104017972946
Test Loss:  0.0001473796583013609
Valid Loss:  0.0001131918397732079
Epoch:  133  	Training Loss: 0.00011338078184053302
Test Loss:  0.00014523003483191133
Valid Loss:  0.00011000830272678286
Epoch:  134  	Training Loss: 0.00011025846470147371
Test Loss:  0.00014314177678897977
Valid Loss:  0.00010703632142394781
Epoch:  135  	Training Loss: 0.00010734003444667906
Test Loss:  0.00014118239050731063
Valid Loss:  0.0001042522635543719
Epoch:  136  	Training Loss: 0.0001046258257701993
 27%|██▋       | 137/500 [01:41<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:42<02:01,  2.96it/s] 28%|██▊       | 141/500 [01:48<07:05,  1.19s/it] 29%|██▊       | 143/500 [01:48<05:03,  1.17it/s] 29%|██▉       | 145/500 [01:48<03:38,  1.62it/s] 29%|██▉       | 147/500 [01:48<02:38,  2.22it/s] 30%|██▉       | 149/500 [01:48<01:57,  2.99it/s] 30%|███       | 151/500 [01:55<06:50,  1.18s/it] 31%|███       | 153/500 [01:55<04:52,  1.19it/s] 31%|███       | 155/500 [01:55<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:55<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:55<01:52,  3.03it/s] 32%|███▏      | 161/500 [02:02<06:41,  1.18s/it] 33%|███▎      | 163/500 [02:02<04:46,  1.18it/s] 33%|███▎      | 165/500 [02:02<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:02<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:02<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:08<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:09<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:09<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:09<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:09<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:15<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:15<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:16<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:16<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:16<01:44,  2.99it/s] 38%|███▊      | 191/500 [02:22<06:03,  1.17s/it] 39%|███▊      | 193/500 [02:22<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:22<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:23<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:23<01:39,  3.01it/s] 40%|████      | 201/500 [02:29<05:52,  1.18s/it] 41%|████      | 203/500 [02:29<04:11,  1.18it/s]Test Loss:  0.00013934692833572626
Valid Loss:  0.00010168259177589789
Epoch:  137  	Training Loss: 0.00010211598419118673
Test Loss:  0.00013758771819993854
Valid Loss:  9.928845975082368e-05
Epoch:  138  	Training Loss: 9.976512228604406e-05
Test Loss:  0.00013593281619250774
Valid Loss:  9.706145647214726e-05
Epoch:  139  	Training Loss: 9.759204112924635e-05
Test Loss:  0.00013435908476822078
Valid Loss:  9.498887811787426e-05
Epoch:  140  	Training Loss: 9.557990415487438e-05
Test Loss:  0.0001328730140812695
Valid Loss:  9.306202264269814e-05
Epoch:  141  	Training Loss: 9.370734915137291e-05
Test Loss:  0.00013147038407623768
Valid Loss:  9.126841905526817e-05
Epoch:  142  	Training Loss: 9.196392784360796e-05
Test Loss:  0.00012985979265067726
Valid Loss:  8.978899859357625e-05
Epoch:  143  	Training Loss: 9.042331657838076e-05
Test Loss:  0.00012874550884589553
Valid Loss:  8.844592957757413e-05
Epoch:  144  	Training Loss: 8.912463090382516e-05
Test Loss:  0.00012823636643588543
Valid Loss:  8.769839769229293e-05
Epoch:  145  	Training Loss: 8.840642840368673e-05
Test Loss:  0.00012787329615093768
Valid Loss:  8.727199019631371e-05
Epoch:  146  	Training Loss: 8.792777953203768e-05
Test Loss:  0.00012746293214149773
Valid Loss:  8.701163460500538e-05
Epoch:  147  	Training Loss: 8.759601769270375e-05
Test Loss:  0.00012695082114078104
Valid Loss:  8.684057684149593e-05
Epoch:  148  	Training Loss: 8.737053576624021e-05
Test Loss:  0.00012642459478229284
Valid Loss:  8.670180977787822e-05
Epoch:  149  	Training Loss: 8.716547017684206e-05
Test Loss:  0.0001259133714484051
Valid Loss:  8.657942817080766e-05
Epoch:  150  	Training Loss: 8.698062447365373e-05
Test Loss:  0.00012542304466478527
Valid Loss:  8.646595233585685e-05
Epoch:  151  	Training Loss: 8.681738108862191e-05
Test Loss:  0.00012495210103224963
Valid Loss:  8.635277481516823e-05
Epoch:  152  	Training Loss: 8.668780355947092e-05
Test Loss:  0.00012395935482345521
Valid Loss:  8.52733792271465e-05
Epoch:  153  	Training Loss: 8.571991929784417e-05
Test Loss:  0.00012277814676053822
Valid Loss:  8.440300007350743e-05
Epoch:  154  	Training Loss: 8.485159196425229e-05
Test Loss:  0.00012165379303041846
Valid Loss:  8.360722858924419e-05
Epoch:  155  	Training Loss: 8.404390246141702e-05
Test Loss:  0.00012060711742378771
Valid Loss:  8.287160017061979e-05
Epoch:  156  	Training Loss: 8.327644900418818e-05
Test Loss:  0.00011963306315010414
Valid Loss:  8.216880087275058e-05
Epoch:  157  	Training Loss: 8.254741260316223e-05
Test Loss:  0.0001187202287837863
Valid Loss:  8.148854249157012e-05
Epoch:  158  	Training Loss: 8.184340549632907e-05
Test Loss:  0.0001178636375698261
Valid Loss:  8.08398617664352e-05
Epoch:  159  	Training Loss: 8.117435208987445e-05
Test Loss:  0.0001170535251731053
Valid Loss:  8.021465328056365e-05
Epoch:  160  	Training Loss: 8.053655619733036e-05
Test Loss:  0.00011628800712060183
Valid Loss:  7.960787479532883e-05
Epoch:  161  	Training Loss: 7.992092287167907e-05
Test Loss:  0.00011556378740351647
Valid Loss:  7.901874778326601e-05
Epoch:  162  	Training Loss: 7.932352309580892e-05
Test Loss:  0.00011538667604327202
Valid Loss:  7.901408389443532e-05
Epoch:  163  	Training Loss: 7.912334694992751e-05
Test Loss:  0.00011532469216035679
Valid Loss:  7.898805779404938e-05
Epoch:  164  	Training Loss: 7.898835610831156e-05
Test Loss:  0.00011527646711328998
Valid Loss:  7.894291775301099e-05
Epoch:  165  	Training Loss: 7.889681728556752e-05
Test Loss:  0.00011519223335199058
Valid Loss:  7.888508844189346e-05
Epoch:  166  	Training Loss: 7.883568468969315e-05
Test Loss:  0.0001150810276158154
Valid Loss:  7.883397483965382e-05
Epoch:  167  	Training Loss: 7.878003088990226e-05
Test Loss:  0.00011495214130263776
Valid Loss:  7.878775068093091e-05
Epoch:  168  	Training Loss: 7.872941205278039e-05
Test Loss:  0.00011481747787911445
Valid Loss:  7.874624861869961e-05
Epoch:  169  	Training Loss: 7.867939712014049e-05
Test Loss:  0.00011467687727417797
Valid Loss:  7.870585250202566e-05
Epoch:  170  	Training Loss: 7.863479549996555e-05
Test Loss:  0.00011453298793639988
Valid Loss:  7.866756641305983e-05
Epoch:  171  	Training Loss: 7.859279867261648e-05
Test Loss:  0.00011438903311500326
Valid Loss:  7.863187784096226e-05
Epoch:  172  	Training Loss: 7.855198055040091e-05
Test Loss:  0.0001137078070314601
Valid Loss:  7.739246939308941e-05
Epoch:  173  	Training Loss: 7.747199560981244e-05
Test Loss:  0.00011285417713224888
Valid Loss:  7.630180334672332e-05
Epoch:  174  	Training Loss: 7.646230369573459e-05
Test Loss:  0.00011199997970834374
Valid Loss:  7.526492117904127e-05
Epoch:  175  	Training Loss: 7.550876762252301e-05
Test Loss:  0.00011113655637018383
Valid Loss:  7.430220284732059e-05
Epoch:  176  	Training Loss: 7.461122004315257e-05
Test Loss:  0.00011030731548089534
Valid Loss:  7.337160059250891e-05
Epoch:  177  	Training Loss: 7.375647692242637e-05
Test Loss:  0.0001094859471777454
Valid Loss:  7.248397741932422e-05
Epoch:  178  	Training Loss: 7.294198439922184e-05
Test Loss:  0.00010867749369936064
Valid Loss:  7.163669943111017e-05
Epoch:  179  	Training Loss: 7.21623218851164e-05
Test Loss:  0.00010787776409415528
Valid Loss:  7.082096271915361e-05
Epoch:  180  	Training Loss: 7.141346577554941e-05
Test Loss:  0.00010708559420891106
Valid Loss:  7.0036796387285e-05
Epoch:  181  	Training Loss: 7.069297862472013e-05
Test Loss:  0.00010630060569383204
Valid Loss:  6.928294897079468e-05
Epoch:  182  	Training Loss: 6.999840843491256e-05
Test Loss:  0.00010617623047437519
Valid Loss:  6.884413596708328e-05
Epoch:  183  	Training Loss: 6.969311652937904e-05
Test Loss:  0.00010594850027700886
Valid Loss:  6.855432729935274e-05
Epoch:  184  	Training Loss: 6.944603228475899e-05
Test Loss:  0.00010568269499344751
Valid Loss:  6.83045363985002e-05
Epoch:  185  	Training Loss: 6.921278691152111e-05
Test Loss:  0.00010541355732129887
Valid Loss:  6.806744204368442e-05
Epoch:  186  	Training Loss: 6.898579886183143e-05
Test Loss:  0.00010514854511711746
Valid Loss:  6.783827120671049e-05
Epoch:  187  	Training Loss: 6.876578845549375e-05
Test Loss:  0.00010488704720046371
Valid Loss:  6.761768599972129e-05
Epoch:  188  	Training Loss: 6.855348328826949e-05
Test Loss:  0.00010463461512699723
Valid Loss:  6.740199751220644e-05
Epoch:  189  	Training Loss: 6.834616215201095e-05
Test Loss:  0.0001043883603415452
Valid Loss:  6.7192166170571e-05
Epoch:  190  	Training Loss: 6.814370135543868e-05
Test Loss:  0.00010414926509838551
Valid Loss:  6.699400546494871e-05
Epoch:  191  	Training Loss: 6.794584624003619e-05
Test Loss:  0.00010391598334535956
Valid Loss:  6.679989746771753e-05
Epoch:  192  	Training Loss: 6.775247311452404e-05
Test Loss:  0.00010283285519108176
Valid Loss:  6.673636380583048e-05
Epoch:  193  	Training Loss: 6.7502012825571e-05
Test Loss:  0.00010226966696791351
Valid Loss:  6.653122545685619e-05
Epoch:  194  	Training Loss: 6.729357119183987e-05
Test Loss:  0.00010169076267629862
Valid Loss:  6.639187631662935e-05
Epoch:  195  	Training Loss: 6.71016241540201e-05
Test Loss:  0.00010122299863724038
Valid Loss:  6.623772060265765e-05
Epoch:  196  	Training Loss: 6.691974704153836e-05
Test Loss:  0.00010079841740662232
Valid Loss:  6.609128467971459e-05
Epoch:  197  	Training Loss: 6.674805626971647e-05
Test Loss:  0.00010041266796179116
Valid Loss:  6.594964361283928e-05
Epoch:  198  	Training Loss: 6.658193160546944e-05
Test Loss:  0.00010008171375375241
Valid Loss:  6.580963963642716e-05
Epoch:  199  	Training Loss: 6.64200633764267e-05
Test Loss:  9.977201261790469e-05
Valid Loss:  6.567219679709524e-05
Epoch:  200  	Training Loss: 6.62614475004375e-05
Test Loss:  9.948144725058228e-05
Valid Loss:  6.553758430527523e-05
Epoch:  201  	Training Loss: 6.61064259475097e-05
Test Loss:  9.919880540110171e-05
Valid Loss:  6.540635513374582e-05
Epoch:  202  	Training Loss: 6.595766171813011e-05
Test Loss:  9.90490079857409e-05
Valid Loss:  6.512648542411625e-05
Epoch:  203  	Training Loss: 6.570159894181415e-05
Test Loss:  9.88340107141994e-05
Valid Loss:  6.49087960482575e-05
 41%|████      | 205/500 [02:29<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:29<02:11,  2.24it/s] 42%|████▏     | 209/500 [02:30<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:36<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:02,  1.19it/s] 43%|████▎     | 215/500 [02:36<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:36<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:36<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:43<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:43<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:43<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:43<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:43<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:49<05:13,  1.17s/it] 47%|████▋     | 233/500 [02:49<03:42,  1.20it/s] 47%|████▋     | 235/500 [02:50<02:39,  1.66it/s] 47%|████▋     | 237/500 [02:50<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:50<01:25,  3.04it/s] 48%|████▊     | 241/500 [02:56<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:56<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:56<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:57<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:57<01:23,  3.02it/s] 50%|█████     | 251/500 [03:03<04:51,  1.17s/it] 51%|█████     | 253/500 [03:03<03:27,  1.19it/s] 51%|█████     | 255/500 [03:03<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:03<01:47,  2.26it/s] 52%|█████▏    | 259/500 [03:03<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:10<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:10<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:10<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:10<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:10<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:17<04:28,  1.17s/it]Epoch:  204  	Training Loss: 6.546039367094636e-05
Test Loss:  9.86153245321475e-05
Valid Loss:  6.468327774200588e-05
Epoch:  205  	Training Loss: 6.523133924929425e-05
Test Loss:  9.836500248638913e-05
Valid Loss:  6.447901978390291e-05
Epoch:  206  	Training Loss: 6.500750896520913e-05
Test Loss:  9.811253403313458e-05
Valid Loss:  6.427449989132583e-05
Epoch:  207  	Training Loss: 6.478856084868312e-05
Test Loss:  9.785243310034275e-05
Valid Loss:  6.407481123460457e-05
Epoch:  208  	Training Loss: 6.457528797909617e-05
Test Loss:  9.758722444530576e-05
Valid Loss:  6.387812027242035e-05
Epoch:  209  	Training Loss: 6.43669773126021e-05
Test Loss:  9.731807222124189e-05
Valid Loss:  6.36869081063196e-05
Epoch:  210  	Training Loss: 6.416394171537831e-05
Test Loss:  9.704833064461127e-05
Valid Loss:  6.350364128593355e-05
Epoch:  211  	Training Loss: 6.396857497747988e-05
Test Loss:  9.678075730334967e-05
Valid Loss:  6.331848271656781e-05
Epoch:  212  	Training Loss: 6.377664976753294e-05
Test Loss:  9.652269363868982e-05
Valid Loss:  6.284481059992686e-05
Epoch:  213  	Training Loss: 6.329270399874076e-05
Test Loss:  9.628575935494155e-05
Valid Loss:  6.238337664399296e-05
Epoch:  214  	Training Loss: 6.285890412982553e-05
Test Loss:  9.605183731764555e-05
Valid Loss:  6.194598972797394e-05
Epoch:  215  	Training Loss: 6.245750410016626e-05
Test Loss:  9.581756603438407e-05
Valid Loss:  6.153625145088881e-05
Epoch:  216  	Training Loss: 6.208400736795738e-05
Test Loss:  9.558112651575357e-05
Valid Loss:  6.115326686995104e-05
Epoch:  217  	Training Loss: 6.173678411869332e-05
Test Loss:  9.533831325825304e-05
Valid Loss:  6.0803220549132675e-05
Epoch:  218  	Training Loss: 6.141485937405378e-05
Test Loss:  9.509622759651393e-05
Valid Loss:  6.047138958820142e-05
Epoch:  219  	Training Loss: 6.111247057560831e-05
Test Loss:  9.485542977927253e-05
Valid Loss:  6.015887265675701e-05
Epoch:  220  	Training Loss: 6.082947220420465e-05
Test Loss:  9.461552690481767e-05
Valid Loss:  5.9862857597181574e-05
Epoch:  221  	Training Loss: 6.0563335864571854e-05
Test Loss:  9.437660628464073e-05
Valid Loss:  5.958135079708882e-05
Epoch:  222  	Training Loss: 6.031220982549712e-05
Test Loss:  9.355507791042328e-05
Valid Loss:  5.9316011174814776e-05
Epoch:  223  	Training Loss: 6.006819603499025e-05
Test Loss:  9.280308586312458e-05
Valid Loss:  5.915121073485352e-05
Epoch:  224  	Training Loss: 5.986456744722091e-05
Test Loss:  9.223056258633733e-05
Valid Loss:  5.897862502024509e-05
Epoch:  225  	Training Loss: 5.968533514533192e-05
Test Loss:  9.173658327199519e-05
Valid Loss:  5.88283764955122e-05
Epoch:  226  	Training Loss: 5.9521222283365205e-05
Test Loss:  9.141538612311706e-05
Valid Loss:  5.8674824686022475e-05
Epoch:  227  	Training Loss: 5.937649984844029e-05
Test Loss:  9.11100723897107e-05
Valid Loss:  5.854084884049371e-05
Epoch:  228  	Training Loss: 5.923559365328401e-05
Test Loss:  9.084642806556076e-05
Valid Loss:  5.8404853916727006e-05
Epoch:  229  	Training Loss: 5.9097415942233056e-05
Test Loss:  9.06695204321295e-05
Valid Loss:  5.826453707413748e-05
Epoch:  230  	Training Loss: 5.896366201341152e-05
Test Loss:  9.033840615302324e-05
Valid Loss:  5.816252814838663e-05
Epoch:  231  	Training Loss: 5.883214544155635e-05
Test Loss:  9.023452003020793e-05
Valid Loss:  5.799605423817411e-05
Epoch:  232  	Training Loss: 5.8701167290564626e-05
Test Loss:  9.007765038404614e-05
Valid Loss:  5.771492578787729e-05
Epoch:  233  	Training Loss: 5.838649667566642e-05
Test Loss:  8.994177915155888e-05
Valid Loss:  5.745621820096858e-05
Epoch:  234  	Training Loss: 5.8125915529672056e-05
Test Loss:  8.98110811249353e-05
Valid Loss:  5.72123535675928e-05
Epoch:  235  	Training Loss: 5.7895013014785945e-05
Test Loss:  8.967454050434753e-05
Valid Loss:  5.697748565580696e-05
Epoch:  236  	Training Loss: 5.768254050053656e-05
Test Loss:  8.95333505468443e-05
Valid Loss:  5.675138527294621e-05
Epoch:  237  	Training Loss: 5.748311377828941e-05
Test Loss:  8.938850078266114e-05
Valid Loss:  5.653608968714252e-05
Epoch:  238  	Training Loss: 5.7295583246741444e-05
Test Loss:  8.923973655328155e-05
Valid Loss:  5.633087857859209e-05
Epoch:  239  	Training Loss: 5.711931953555904e-05
Test Loss:  8.908746531233191e-05
Valid Loss:  5.613524990621954e-05
Epoch:  240  	Training Loss: 5.695216168533079e-05
Test Loss:  8.893318590708077e-05
Valid Loss:  5.594812682829797e-05
Epoch:  241  	Training Loss: 5.679280002368614e-05
Test Loss:  8.877839718479663e-05
Valid Loss:  5.577001138590276e-05
Epoch:  242  	Training Loss: 5.6640470575075597e-05
Test Loss:  8.845367119647563e-05
Valid Loss:  5.55909973627422e-05
Epoch:  243  	Training Loss: 5.652076652040705e-05
Test Loss:  8.805646211840212e-05
Valid Loss:  5.5491393140982836e-05
Epoch:  244  	Training Loss: 5.642628821078688e-05
Test Loss:  8.7673295638524e-05
Valid Loss:  5.541623613680713e-05
Epoch:  245  	Training Loss: 5.6347213103435934e-05
Test Loss:  8.731406705919653e-05
Valid Loss:  5.536363096325658e-05
Epoch:  246  	Training Loss: 5.628149665426463e-05
Test Loss:  8.7004154920578e-05
Valid Loss:  5.531308124773204e-05
Epoch:  247  	Training Loss: 5.6224234867841005e-05
Test Loss:  8.672673720866442e-05
Valid Loss:  5.5266405979637057e-05
Epoch:  248  	Training Loss: 5.617351416731253e-05
Test Loss:  8.647689537610859e-05
Valid Loss:  5.522465653484687e-05
Epoch:  249  	Training Loss: 5.612886161543429e-05
Test Loss:  8.625097689218819e-05
Valid Loss:  5.518793477676809e-05
Epoch:  250  	Training Loss: 5.608910578303039e-05
Test Loss:  8.604580943938345e-05
Valid Loss:  5.5154603614937514e-05
Epoch:  251  	Training Loss: 5.6053511798381805e-05
Test Loss:  8.585992327425629e-05
Valid Loss:  5.512424831977114e-05
Epoch:  252  	Training Loss: 5.602159581030719e-05
Test Loss:  8.574149251217023e-05
Valid Loss:  5.5037431593518704e-05
Epoch:  253  	Training Loss: 5.591229273704812e-05
Test Loss:  8.56599144754e-05
Valid Loss:  5.4914391512284055e-05
Epoch:  254  	Training Loss: 5.5802956921979785e-05
Test Loss:  8.554333180654794e-05
Valid Loss:  5.481485277414322e-05
Epoch:  255  	Training Loss: 5.5692315072519705e-05
Test Loss:  8.544129377696663e-05
Valid Loss:  5.469961615744978e-05
Epoch:  256  	Training Loss: 5.5582524510100484e-05
Test Loss:  8.531998173566535e-05
Valid Loss:  5.4596475820289925e-05
Epoch:  257  	Training Loss: 5.547365435631946e-05
Test Loss:  8.520205301465467e-05
Valid Loss:  5.448763840831816e-05
Epoch:  258  	Training Loss: 5.536551907425746e-05
Test Loss:  8.50744909257628e-05
Valid Loss:  5.438343941932544e-05
Epoch:  259  	Training Loss: 5.5257827625609934e-05
Test Loss:  8.494681969750673e-05
Valid Loss:  5.4277821618597955e-05
Epoch:  260  	Training Loss: 5.51513148820959e-05
Test Loss:  8.482141129206866e-05
Valid Loss:  5.41722220077645e-05
Epoch:  261  	Training Loss: 5.504515138454735e-05
Test Loss:  8.468324085697532e-05
Valid Loss:  5.407149001257494e-05
Epoch:  262  	Training Loss: 5.493938078870997e-05
Test Loss:  8.459598029730842e-05
Valid Loss:  5.398148641688749e-05
Epoch:  263  	Training Loss: 5.483917993842624e-05
Test Loss:  8.452017209492624e-05
Valid Loss:  5.38720705662854e-05
Epoch:  264  	Training Loss: 5.474034696817398e-05
Test Loss:  8.441926911473274e-05
Valid Loss:  5.377700654207729e-05
Epoch:  265  	Training Loss: 5.464282367029227e-05
Test Loss:  8.431974129052833e-05
Valid Loss:  5.36748266313225e-05
Epoch:  266  	Training Loss: 5.4546526371268556e-05
Test Loss:  8.42059962451458e-05
Valid Loss:  5.357959526008926e-05
Epoch:  267  	Training Loss: 5.4450658353744075e-05
Test Loss:  8.409004658460617e-05
Valid Loss:  5.348146805772558e-05
Epoch:  268  	Training Loss: 5.4355616157408804e-05
Test Loss:  8.396692282985896e-05
Valid Loss:  5.338621122064069e-05
Epoch:  269  	Training Loss: 5.426114148576744e-05
Test Loss:  8.384065586142242e-05
Valid Loss:  5.3290223149815574e-05
Epoch:  270  	Training Loss: 5.416699423221871e-05
Test Loss:  8.371011062990874e-05
Valid Loss:  5.3196316002868116e-05
Epoch:  271  	Training Loss: 5.407369462773204e-05
Test Loss:  8.357792103197426e-05
Valid Loss:  5.3102085075806826e-05
 55%|█████▍    | 273/500 [03:17<03:11,  1.19it/s] 55%|█████▌    | 275/500 [03:17<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:17<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:17<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:23<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:23<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:24<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:24<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:24<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:30<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:30<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:30<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:31<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:31<01:06,  3.00it/s] 60%|██████    | 301/500 [03:37<03:54,  1.18s/it] 61%|██████    | 303/500 [03:37<02:46,  1.18it/s] 61%|██████    | 305/500 [03:37<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:37<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:38<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:44<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:44<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:44<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:44<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:44<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:51<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:51<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:51<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:51<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:51<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:57<03:15,  1.16s/it] 67%|██████▋   | 333/500 [03:58<02:18,  1.20it/s] 67%|██████▋   | 335/500 [03:58<01:39,  1.67it/s] 67%|██████▋   | 337/500 [03:58<01:11,  2.28it/s]Epoch:  272  	Training Loss: 5.398050416260958e-05
Test Loss:  8.338858606293797e-05
Valid Loss:  5.291007619234733e-05
Epoch:  273  	Training Loss: 5.379959475249052e-05
Test Loss:  8.321295899804682e-05
Valid Loss:  5.271909321891144e-05
Epoch:  274  	Training Loss: 5.3627602028427646e-05
Test Loss:  8.303727372549474e-05
Valid Loss:  5.253627386991866e-05
Epoch:  275  	Training Loss: 5.3463358199223876e-05
Test Loss:  8.285987132694572e-05
Valid Loss:  5.236170909483917e-05
Epoch:  276  	Training Loss: 5.330736166797578e-05
Test Loss:  8.26817995402962e-05
Valid Loss:  5.219452577875927e-05
Epoch:  277  	Training Loss: 5.3157702495809644e-05
Test Loss:  8.250301470980048e-05
Valid Loss:  5.203466571401805e-05
Epoch:  278  	Training Loss: 5.301402052282356e-05
Test Loss:  8.232370601035655e-05
Valid Loss:  5.1882045227102935e-05
Epoch:  279  	Training Loss: 5.287740350468084e-05
Test Loss:  8.214436093112454e-05
Valid Loss:  5.173488170839846e-05
Epoch:  280  	Training Loss: 5.274565774016082e-05
Test Loss:  8.19655106170103e-05
Valid Loss:  5.1593837270047516e-05
Epoch:  281  	Training Loss: 5.261848491500132e-05
Test Loss:  8.17876061773859e-05
Valid Loss:  5.1457565859891474e-05
Epoch:  282  	Training Loss: 5.2495699492283165e-05
Test Loss:  8.174571848940104e-05
Valid Loss:  5.143889575265348e-05
Epoch:  283  	Training Loss: 5.2424336900003254e-05
Test Loss:  8.169894863385707e-05
Valid Loss:  5.139865243108943e-05
Epoch:  284  	Training Loss: 5.236754077486694e-05
Test Loss:  8.164569590007886e-05
Valid Loss:  5.134771345183253e-05
Epoch:  285  	Training Loss: 5.231289105722681e-05
Test Loss:  8.158532727975398e-05
Valid Loss:  5.129176133777946e-05
Epoch:  286  	Training Loss: 5.2257990319048986e-05
Test Loss:  8.152327791322023e-05
Valid Loss:  5.1235092541901395e-05
Epoch:  287  	Training Loss: 5.2203300583641976e-05
Test Loss:  8.145962783601135e-05
Valid Loss:  5.117849650559947e-05
Epoch:  288  	Training Loss: 5.2148774557281286e-05
Test Loss:  8.139632700476795e-05
Valid Loss:  5.1123184675816447e-05
Epoch:  289  	Training Loss: 5.209333903621882e-05
Test Loss:  8.132932998705655e-05
Valid Loss:  5.106655589770526e-05
Epoch:  290  	Training Loss: 5.203788532526232e-05
Test Loss:  8.126129250740632e-05
Valid Loss:  5.101088390802033e-05
Epoch:  291  	Training Loss: 5.198288636165671e-05
Test Loss:  8.119167614495382e-05
Valid Loss:  5.095502274343744e-05
Epoch:  292  	Training Loss: 5.1928254833910614e-05
Test Loss:  8.116212848108262e-05
Valid Loss:  5.068285463494249e-05
Epoch:  293  	Training Loss: 5.1775004976661876e-05
Test Loss:  8.096075907815248e-05
Valid Loss:  5.057105954620056e-05
Epoch:  294  	Training Loss: 5.1633141993079334e-05
Test Loss:  8.082149724941701e-05
Valid Loss:  5.040474206907675e-05
Epoch:  295  	Training Loss: 5.1496179366949946e-05
Test Loss:  8.064649591688067e-05
Valid Loss:  5.026689177611843e-05
Epoch:  296  	Training Loss: 5.1361959776841104e-05
Test Loss:  8.04769661044702e-05
Valid Loss:  5.0122365792049095e-05
Epoch:  297  	Training Loss: 5.123055598232895e-05
Test Loss:  8.029805758269504e-05
Valid Loss:  4.998572694603354e-05
Epoch:  298  	Training Loss: 5.1101684221066535e-05
Test Loss:  8.011903992155567e-05
Valid Loss:  4.985107807442546e-05
Epoch:  299  	Training Loss: 5.097506436868571e-05
Test Loss:  7.993651524884626e-05
Valid Loss:  4.971985617885366e-05
Epoch:  300  	Training Loss: 5.085087104816921e-05
Test Loss:  7.975215703481808e-05
Valid Loss:  4.959055513609201e-05
Epoch:  301  	Training Loss: 5.0728915084619075e-05
Test Loss:  7.956616900628433e-05
Valid Loss:  4.946359695168212e-05
Epoch:  302  	Training Loss: 5.0608752644620836e-05
Test Loss:  7.898971671238542e-05
Valid Loss:  4.9340491386828944e-05
Epoch:  303  	Training Loss: 5.044095451012254e-05
Test Loss:  7.856914453441277e-05
Valid Loss:  4.91960090585053e-05
Epoch:  304  	Training Loss: 5.028679879615083e-05
Test Loss:  7.820244354661554e-05
Valid Loss:  4.905501918983646e-05
Epoch:  305  	Training Loss: 5.013973350287415e-05
Test Loss:  7.786955393385142e-05
Valid Loss:  4.89183803438209e-05
Epoch:  306  	Training Loss: 4.9998277972918004e-05
Test Loss:  7.756351988064125e-05
Valid Loss:  4.8787427658680826e-05
Epoch:  307  	Training Loss: 4.9864043830893934e-05
Test Loss:  7.728094351477921e-05
Valid Loss:  4.865891969529912e-05
Epoch:  308  	Training Loss: 4.973378963768482e-05
Test Loss:  7.701628055656329e-05
Valid Loss:  4.8533645895076916e-05
Epoch:  309  	Training Loss: 4.9607006076257676e-05
Test Loss:  7.676618406549096e-05
Valid Loss:  4.841126065002754e-05
Epoch:  310  	Training Loss: 4.9483656766824424e-05
Test Loss:  7.652891508769244e-05
Valid Loss:  4.829154204344377e-05
Epoch:  311  	Training Loss: 4.9363858124706894e-05
Test Loss:  7.630173058714718e-05
Valid Loss:  4.817446824745275e-05
Epoch:  312  	Training Loss: 4.9246897106058896e-05
Test Loss:  7.637689122930169e-05
Valid Loss:  4.804948912351392e-05
Epoch:  313  	Training Loss: 4.912411532131955e-05
Test Loss:  7.643872231710702e-05
Valid Loss:  4.79244117741473e-05
Epoch:  314  	Training Loss: 4.9011701776180416e-05
Test Loss:  7.648137398064137e-05
Valid Loss:  4.7810899559408426e-05
Epoch:  315  	Training Loss: 4.8908856115303934e-05
Test Loss:  7.650793850189075e-05
Valid Loss:  4.770774830831215e-05
Epoch:  316  	Training Loss: 4.881192580796778e-05
Test Loss:  7.651948544662446e-05
Valid Loss:  4.761237505590543e-05
Epoch:  317  	Training Loss: 4.871952478424646e-05
Test Loss:  7.651918713236228e-05
Valid Loss:  4.7522094973828644e-05
Epoch:  318  	Training Loss: 4.8630139644956216e-05
Test Loss:  7.65074510127306e-05
Valid Loss:  4.7434779844479635e-05
Epoch:  319  	Training Loss: 4.854385042563081e-05
Test Loss:  7.648405153304338e-05
Valid Loss:  4.7350869863294065e-05
Epoch:  320  	Training Loss: 4.845984585699625e-05
Test Loss:  7.645203731954098e-05
Valid Loss:  4.726983024738729e-05
Epoch:  321  	Training Loss: 4.837783853872679e-05
Test Loss:  7.641123374924064e-05
Valid Loss:  4.7190929763019085e-05
Epoch:  322  	Training Loss: 4.8297337343683466e-05
Test Loss:  7.601708057336509e-05
Valid Loss:  4.708734923042357e-05
Epoch:  323  	Training Loss: 4.818072193302214e-05
Test Loss:  7.567421562271193e-05
Valid Loss:  4.698297561844811e-05
Epoch:  324  	Training Loss: 4.807248478755355e-05
Test Loss:  7.536134944530204e-05
Valid Loss:  4.688381886808202e-05
Epoch:  325  	Training Loss: 4.7970839659683406e-05
Test Loss:  7.507410191465169e-05
Valid Loss:  4.678913683164865e-05
Epoch:  326  	Training Loss: 4.78748042951338e-05
Test Loss:  7.480816566385329e-05
Valid Loss:  4.669891495723277e-05
Epoch:  327  	Training Loss: 4.778348375111818e-05
Test Loss:  7.456161984009668e-05
Valid Loss:  4.6611814468633384e-05
Epoch:  328  	Training Loss: 4.76963359687943e-05
Test Loss:  7.433182327076793e-05
Valid Loss:  4.65285120299086e-05
Epoch:  329  	Training Loss: 4.7612884372938424e-05
Test Loss:  7.411598926410079e-05
Valid Loss:  4.644753425964154e-05
Epoch:  330  	Training Loss: 4.753230678034015e-05
Test Loss:  7.391282269963995e-05
Valid Loss:  4.636876474251039e-05
Epoch:  331  	Training Loss: 4.7454494051635265e-05
Test Loss:  7.37210939405486e-05
Valid Loss:  4.629266186384484e-05
Epoch:  332  	Training Loss: 4.7379104216815904e-05
Test Loss:  7.374122651526704e-05
Valid Loss:  4.6217290218919516e-05
Epoch:  333  	Training Loss: 4.730712316813879e-05
Test Loss:  7.37622904125601e-05
Valid Loss:  4.614180215867236e-05
Epoch:  334  	Training Loss: 4.723830352304503e-05
Test Loss:  7.378093141596764e-05
Valid Loss:  4.6068835217738524e-05
Epoch:  335  	Training Loss: 4.717237607110292e-05
Test Loss:  7.379642920568585e-05
Valid Loss:  4.599868043442257e-05
Epoch:  336  	Training Loss: 4.7109144361456856e-05
Test Loss:  7.380885654129088e-05
Valid Loss:  4.593099220073782e-05
Epoch:  337  	Training Loss: 4.7048302803887054e-05
Test Loss:  7.381840259768069e-05
Valid Loss:  4.586585419019684e-05
Epoch:  338  	Training Loss: 4.698941484093666e-05
Test Loss:  7.382532930932939e-05
Valid Loss:  4.580253880703822e-05
Epoch:  339  	Training Loss: 4.693233495345339e-05
Test Loss:  7.382912008324638e-05
Valid Loss:   68%|██████▊   | 339/500 [03:58<00:52,  3.06it/s] 68%|██████▊   | 341/500 [04:04<03:05,  1.16s/it] 69%|██████▊   | 343/500 [04:04<02:11,  1.20it/s] 69%|██████▉   | 345/500 [04:04<01:33,  1.65it/s] 69%|██████▉   | 347/500 [04:05<01:07,  2.26it/s] 70%|██████▉   | 349/500 [04:05<00:49,  3.04it/s] 70%|███████   | 351/500 [04:11<02:53,  1.16s/it] 71%|███████   | 353/500 [04:11<02:02,  1.20it/s] 71%|███████   | 355/500 [04:11<01:27,  1.66it/s] 71%|███████▏  | 357/500 [04:11<01:03,  2.27it/s] 72%|███████▏  | 359/500 [04:11<00:46,  3.05it/s] 72%|███████▏  | 361/500 [04:18<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:18<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:18<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:18<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:18<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:25<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:25<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:25<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.24it/s] 76%|███████▌  | 379/500 [04:25<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:31<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:32<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:32<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:32<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:38<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:38<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:39<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:39<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:39<00:33,  3.00it/s] 80%|████████  | 401/500 [04:45<01:57,  1.19s/it] 81%|████████  | 403/500 [04:45<01:22,  1.18it/s] 81%|████████  | 405/500 [04:45<00:58,  1.63it/s]4.574140621116385e-05
Epoch:  340  	Training Loss: 4.6877190470695496e-05
Test Loss:  7.383072806987911e-05
Valid Loss:  4.568197255139239e-05
Epoch:  341  	Training Loss: 4.682359576690942e-05
Test Loss:  7.38291782909073e-05
Valid Loss:  4.562402318697423e-05
Epoch:  342  	Training Loss: 4.677145625464618e-05
Test Loss:  7.350962550844997e-05
Valid Loss:  4.55721965408884e-05
Epoch:  343  	Training Loss: 4.66708152089268e-05
Test Loss:  7.327293860726058e-05
Valid Loss:  4.550101584754884e-05
Epoch:  344  	Training Loss: 4.657746831071563e-05
Test Loss:  7.306659972527996e-05
Valid Loss:  4.5424319978337735e-05
Epoch:  345  	Training Loss: 4.648750109481625e-05
Test Loss:  7.287639891728759e-05
Valid Loss:  4.5348515413934365e-05
Epoch:  346  	Training Loss: 4.640031329472549e-05
Test Loss:  7.269895286299288e-05
Valid Loss:  4.527252895059064e-05
Epoch:  347  	Training Loss: 4.631451884051785e-05
Test Loss:  7.253234798554331e-05
Valid Loss:  4.51966880063992e-05
Epoch:  348  	Training Loss: 4.6229535655584186e-05
Test Loss:  7.237365934997797e-05
Valid Loss:  4.5121578295947984e-05
Epoch:  349  	Training Loss: 4.6145876694936305e-05
Test Loss:  7.222119893413037e-05
Valid Loss:  4.5048247557133436e-05
Epoch:  350  	Training Loss: 4.6065106289461255e-05
Test Loss:  7.207566522993147e-05
Valid Loss:  4.497470217756927e-05
Epoch:  351  	Training Loss: 4.598520172294229e-05
Test Loss:  7.193569035734981e-05
Valid Loss:  4.490182618610561e-05
Epoch:  352  	Training Loss: 4.590563185047358e-05
Test Loss:  7.187042501755059e-05
Valid Loss:  4.476878893910907e-05
Epoch:  353  	Training Loss: 4.583591362461448e-05
Test Loss:  7.157841173466295e-05
Valid Loss:  4.476404865272343e-05
Epoch:  354  	Training Loss: 4.576802166411653e-05
Test Loss:  7.148661825340241e-05
Valid Loss:  4.4660821004072204e-05
Epoch:  355  	Training Loss: 4.570092278299853e-05
Test Loss:  7.125988486222923e-05
Valid Loss:  4.4634449295699596e-05
Epoch:  356  	Training Loss: 4.563527909340337e-05
Test Loss:  7.115250627975911e-05
Valid Loss:  4.4549800804816186e-05
Epoch:  357  	Training Loss: 4.557070496957749e-05
Test Loss:  7.096327317412943e-05
Valid Loss:  4.451197310118005e-05
Epoch:  358  	Training Loss: 4.550738958641887e-05
Test Loss:  7.084864773787558e-05
Valid Loss:  4.443835496203974e-05
Epoch:  359  	Training Loss: 4.54448745585978e-05
Test Loss:  7.068400009302422e-05
Valid Loss:  4.4393564166966826e-05
Epoch:  360  	Training Loss: 4.538321809377521e-05
Test Loss:  7.056514004943892e-05
Valid Loss:  4.43250683019869e-05
Epoch:  361  	Training Loss: 4.5321921788854524e-05
Test Loss:  7.041911885607988e-05
Valid Loss:  4.427317253430374e-05
Epoch:  362  	Training Loss: 4.526054908637889e-05
Test Loss:  7.027574611129239e-05
Valid Loss:  4.421376434038393e-05
Epoch:  363  	Training Loss: 4.5178443542681634e-05
Test Loss:  7.017211464699358e-05
Valid Loss:  4.413976421346888e-05
Epoch:  364  	Training Loss: 4.509853170020506e-05
Test Loss:  7.007146632531658e-05
Valid Loss:  4.406459629535675e-05
Epoch:  365  	Training Loss: 4.502051160670817e-05
Test Loss:  6.996899173827842e-05
Valid Loss:  4.399190947879106e-05
Epoch:  366  	Training Loss: 4.494448148761876e-05
Test Loss:  6.986811058595777e-05
Valid Loss:  4.3919535528402776e-05
Epoch:  367  	Training Loss: 4.4869182602269575e-05
Test Loss:  6.976607983233407e-05
Valid Loss:  4.3847619963344187e-05
Epoch:  368  	Training Loss: 4.479441849980503e-05
Test Loss:  6.966387445572764e-05
Valid Loss:  4.3776482925750315e-05
Epoch:  369  	Training Loss: 4.472047294257209e-05
Test Loss:  6.956169818295166e-05
Valid Loss:  4.370584792923182e-05
Epoch:  370  	Training Loss: 4.4647124013863504e-05
Test Loss:  6.945940549485385e-05
Valid Loss:  4.363603511592373e-05
Epoch:  371  	Training Loss: 4.457448812900111e-05
Test Loss:  6.935666897334158e-05
Valid Loss:  4.356676072347909e-05
Epoch:  372  	Training Loss: 4.450355118024163e-05
Test Loss:  6.936764839338139e-05
Valid Loss:  4.349813025328331e-05
Epoch:  373  	Training Loss: 4.446897219168022e-05
Test Loss:  6.933226541150361e-05
Valid Loss:  4.346474088379182e-05
Epoch:  374  	Training Loss: 4.443929356057197e-05
Test Loss:  6.929303344804794e-05
Valid Loss:  4.3434160033939406e-05
Epoch:  375  	Training Loss: 4.4409840484149754e-05
Test Loss:  6.925203342689201e-05
Valid Loss:  4.3403990275692195e-05
Epoch:  376  	Training Loss: 4.4380569306667894e-05
Test Loss:  6.921128806425259e-05
Valid Loss:  4.337394784670323e-05
Epoch:  377  	Training Loss: 4.435140726855025e-05
Test Loss:  6.917017162777483e-05
Valid Loss:  4.334403638495132e-05
Epoch:  378  	Training Loss: 4.432224886841141e-05
Test Loss:  6.912856042617932e-05
Valid Loss:  4.331388117861934e-05
Epoch:  379  	Training Loss: 4.429329783306457e-05
Test Loss:  6.908639625180513e-05
Valid Loss:  4.328475915826857e-05
Epoch:  380  	Training Loss: 4.426443774718791e-05
Test Loss:  6.904420297360048e-05
Valid Loss:  4.325513873482123e-05
Epoch:  381  	Training Loss: 4.4235988752916455e-05
Test Loss:  6.900166772538796e-05
Valid Loss:  4.322530367062427e-05
Epoch:  382  	Training Loss: 4.4207394239492714e-05
Test Loss:  6.879841384943575e-05
Valid Loss:  4.3181629735045135e-05
Epoch:  383  	Training Loss: 4.409496978041716e-05
Test Loss:  6.873610254842788e-05
Valid Loss:  4.3048996303696185e-05
Epoch:  384  	Training Loss: 4.3991189158987254e-05
Test Loss:  6.860066787339747e-05
Valid Loss:  4.2958206904586405e-05
Epoch:  385  	Training Loss: 4.388973684399389e-05
Test Loss:  6.847774784546345e-05
Valid Loss:  4.285402246750891e-05
Epoch:  386  	Training Loss: 4.378947051009163e-05
Test Loss:  6.833810766693205e-05
Valid Loss:  4.2757324990816414e-05
Epoch:  387  	Training Loss: 4.369007729110308e-05
Test Loss:  6.819720147177577e-05
Valid Loss:  4.265923780621961e-05
Epoch:  388  	Training Loss: 4.359126978670247e-05
Test Loss:  6.805335578974336e-05
Valid Loss:  4.256371903466061e-05
Epoch:  389  	Training Loss: 4.349249502411112e-05
Test Loss:  6.790859333705157e-05
Valid Loss:  4.246766184223816e-05
Epoch:  390  	Training Loss: 4.3393931264290586e-05
Test Loss:  6.776268128305674e-05
Valid Loss:  4.237228858983144e-05
Epoch:  391  	Training Loss: 4.329478906583972e-05
Test Loss:  6.761756958439946e-05
Valid Loss:  4.2276391468476504e-05
Epoch:  392  	Training Loss: 4.319695653975941e-05
Test Loss:  6.760135875083506e-05
Valid Loss:  4.2181160097243264e-05
Epoch:  393  	Training Loss: 4.3119573092553765e-05
Test Loss:  6.755655340384692e-05
Valid Loss:  4.210164479445666e-05
Epoch:  394  	Training Loss: 4.304532922105864e-05
Test Loss:  6.750580359948799e-05
Valid Loss:  4.202377749606967e-05
Epoch:  395  	Training Loss: 4.297306441003457e-05
Test Loss:  6.744642450939864e-05
Valid Loss:  4.194896973785944e-05
Epoch:  396  	Training Loss: 4.290266224415973e-05
Test Loss:  6.73797185299918e-05
Valid Loss:  4.187610829831101e-05
Epoch:  397  	Training Loss: 4.2833642510231584e-05
Test Loss:  6.730724999215454e-05
Valid Loss:  4.180486939731054e-05
Epoch:  398  	Training Loss: 4.276583786122501e-05
Test Loss:  6.722910620737821e-05
Valid Loss:  4.1732622776180506e-05
Epoch:  399  	Training Loss: 4.2699033656390384e-05
Test Loss:  6.71460511512123e-05
Valid Loss:  4.166193320997991e-05
Epoch:  400  	Training Loss: 4.2633284465409815e-05
Test Loss:  6.705915438942611e-05
Valid Loss:  4.15927788708359e-05
Epoch:  401  	Training Loss: 4.256815373082645e-05
Test Loss:  6.696903437841684e-05
Valid Loss:  4.152491601416841e-05
Epoch:  402  	Training Loss: 4.2503852455411106e-05
Test Loss:  6.68604188831523e-05
Valid Loss:  4.146696301177144e-05
Epoch:  403  	Training Loss: 4.244332012603991e-05
Test Loss:  6.675801705569029e-05
Valid Loss:  4.140778037253767e-05
Epoch:  404  	Training Loss: 4.2383617255836725e-05
Test Loss:  6.665945693384856e-05
Valid Loss:  4.134789196541533e-05
Epoch:  405  	Training Loss: 4.232429273542948e-05
Test Loss:  6.656399636995047e-05
Valid Loss:  4.128754517296329e-05
Epoch:  406  	Training Loss: 4.226533928886056e-05
Test Loss:  6.647204281762242e-05
Valid Loss:  4.1227132896892726e-05
Epoch:  407  	Training Loss: 4.2206953366985545e-05
Test Loss:  6.638173363171518e-05
Valid Loss:   81%|████████▏ | 407/500 [04:46<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:52<01:45,  1.19s/it] 83%|████████▎ | 413/500 [04:52<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:52<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.98it/s] 84%|████████▍ | 421/500 [04:59<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:59<00:46,  1.60it/s] 85%|████████▌ | 427/500 [04:59<00:33,  2.17it/s] 86%|████████▌ | 429/500 [05:00<00:24,  2.91it/s] 86%|████████▌ | 431/500 [05:06<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:06<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:06<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:06<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:06<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:13<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:13<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:13<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:13<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:13<00:16,  3.00it/s] 90%|█████████ | 451/500 [05:20<00:58,  1.18s/it] 91%|█████████ | 453/500 [05:20<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:20<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:26<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:27<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.66it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.26it/s] 94%|█████████▍| 469/500 [05:27<00:10,  3.05it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:33<00:22,  1.18it/s]4.1166691516991705e-05
Epoch:  408  	Training Loss: 4.214834189042449e-05
Test Loss:  6.629345443798229e-05
Valid Loss:  4.1106071876129135e-05
Epoch:  409  	Training Loss: 4.209026519674808e-05
Test Loss:  6.620790372835472e-05
Valid Loss:  4.10460343118757e-05
Epoch:  410  	Training Loss: 4.2032428609672934e-05
Test Loss:  6.612354627577588e-05
Valid Loss:  4.0986036765389144e-05
Epoch:  411  	Training Loss: 4.19751631852705e-05
Test Loss:  6.604093505302444e-05
Valid Loss:  4.092629751539789e-05
Epoch:  412  	Training Loss: 4.191866537439637e-05
Test Loss:  6.579735781997442e-05
Valid Loss:  4.0837541746441275e-05
Epoch:  413  	Training Loss: 4.1837985918391496e-05
Test Loss:  6.55316689517349e-05
Valid Loss:  4.07732259191107e-05
Epoch:  414  	Training Loss: 4.176219954388216e-05
Test Loss:  6.53085153317079e-05
Valid Loss:  4.0704846469452605e-05
Epoch:  415  	Training Loss: 4.168992745690048e-05
Test Loss:  6.510298408102244e-05
Valid Loss:  4.063896994921379e-05
Epoch:  416  	Training Loss: 4.1620143747422844e-05
Test Loss:  6.491650128737092e-05
Valid Loss:  4.0573413571109995e-05
Epoch:  417  	Training Loss: 4.1552142647560686e-05
Test Loss:  6.47448468953371e-05
Valid Loss:  4.050822462886572e-05
Epoch:  418  	Training Loss: 4.148568768869154e-05
Test Loss:  6.458497227868065e-05
Valid Loss:  4.0443581383442506e-05
Epoch:  419  	Training Loss: 4.14200549130328e-05
Test Loss:  6.443570600822568e-05
Valid Loss:  4.0379451093031093e-05
Epoch:  420  	Training Loss: 4.135574272368103e-05
Test Loss:  6.429514905903488e-05
Valid Loss:  4.031537537230179e-05
Epoch:  421  	Training Loss: 4.12920635426417e-05
Test Loss:  6.416163523681462e-05
Valid Loss:  4.0251507016364485e-05
Epoch:  422  	Training Loss: 4.1228984628105536e-05
Test Loss:  6.39657155261375e-05
Valid Loss:  4.020141568616964e-05
Epoch:  423  	Training Loss: 4.1163577407132834e-05
Test Loss:  6.382942956406623e-05
Valid Loss:  4.013556463178247e-05
Epoch:  424  	Training Loss: 4.109783185413107e-05
Test Loss:  6.369510083459318e-05
Valid Loss:  4.007162351626903e-05
Epoch:  425  	Training Loss: 4.103262472199276e-05
Test Loss:  6.356964149745181e-05
Valid Loss:  4.000732587883249e-05
Epoch:  426  	Training Loss: 4.096630436833948e-05
Test Loss:  6.345259316731244e-05
Valid Loss:  3.994181315647438e-05
Epoch:  427  	Training Loss: 4.09007552661933e-05
Test Loss:  6.336527439998463e-05
Valid Loss:  3.987435047747567e-05
Epoch:  428  	Training Loss: 4.083638123120181e-05
Test Loss:  6.324028072413057e-05
Valid Loss:  3.981272311648354e-05
Epoch:  429  	Training Loss: 4.0772130887489766e-05
Test Loss:  6.315785140031949e-05
Valid Loss:  3.9745304093230516e-05
Epoch:  430  	Training Loss: 4.070808063261211e-05
Test Loss:  6.303467671386898e-05
Valid Loss:  3.9685084630036727e-05
Epoch:  431  	Training Loss: 4.0645132685313e-05
Test Loss:  6.295403727563098e-05
Valid Loss:  3.9618014852749184e-05
Epoch:  432  	Training Loss: 4.0581846405984834e-05
Test Loss:  6.291591125773266e-05
Valid Loss:  3.9544960600323975e-05
Epoch:  433  	Training Loss: 4.049017297802493e-05
Test Loss:  6.287006544880569e-05
Valid Loss:  3.9451166230719537e-05
Epoch:  434  	Training Loss: 4.04083875764627e-05
Test Loss:  6.281607056735083e-05
Valid Loss:  3.9365644624922425e-05
Epoch:  435  	Training Loss: 4.033008008264005e-05
Test Loss:  6.273372855503112e-05
Valid Loss:  3.9286649553105235e-05
Epoch:  436  	Training Loss: 4.0255996282212436e-05
Test Loss:  6.260682130232453e-05
Valid Loss:  3.9213096897583455e-05
Epoch:  437  	Training Loss: 4.0183469536714256e-05
Test Loss:  6.250781007111073e-05
Valid Loss:  3.913653927156702e-05
Epoch:  438  	Training Loss: 4.011253622593358e-05
Test Loss:  6.239460344659165e-05
Valid Loss:  3.906580968759954e-05
Epoch:  439  	Training Loss: 4.0043007174972445e-05
Test Loss:  6.227604171726853e-05
Valid Loss:  3.899574949173257e-05
Epoch:  440  	Training Loss: 3.997492240159772e-05
Test Loss:  6.215411121957004e-05
Valid Loss:  3.8927704736124724e-05
Epoch:  441  	Training Loss: 3.9908096368890256e-05
Test Loss:  6.202983058756217e-05
Valid Loss:  3.886099875671789e-05
Epoch:  442  	Training Loss: 3.984233990195207e-05
Test Loss:  6.203226803336293e-05
Valid Loss:  3.8780308386776596e-05
Epoch:  443  	Training Loss: 3.9784998079994693e-05
Test Loss:  6.198409391799942e-05
Valid Loss:  3.871639637509361e-05
Epoch:  444  	Training Loss: 3.9729682612232864e-05
Test Loss:  6.196080357767642e-05
Valid Loss:  3.865213511744514e-05
Epoch:  445  	Training Loss: 3.9675254811299965e-05
Test Loss:  6.193121953401715e-05
Valid Loss:  3.859112621285021e-05
Epoch:  446  	Training Loss: 3.9621601899852976e-05
Test Loss:  6.189760460983962e-05
Valid Loss:  3.853430462186225e-05
Epoch:  447  	Training Loss: 3.956873115384951e-05
Test Loss:  6.186110113048926e-05
Valid Loss:  3.8478494388982654e-05
Epoch:  448  	Training Loss: 3.9516402466688305e-05
Test Loss:  6.182061042636633e-05
Valid Loss:  3.8425067032221705e-05
Epoch:  449  	Training Loss: 3.9466074667871e-05
Test Loss:  6.177869363455102e-05
Valid Loss:  3.83717124350369e-05
Epoch:  450  	Training Loss: 3.941597242373973e-05
Test Loss:  6.17353362031281e-05
Valid Loss:  3.8318339647958055e-05
Epoch:  451  	Training Loss: 3.93662485294044e-05
Test Loss:  6.169013795442879e-05
Valid Loss:  3.826549800578505e-05
Epoch:  452  	Training Loss: 3.931710671167821e-05
Test Loss:  6.157462485134602e-05
Valid Loss:  3.8234931707847863e-05
Epoch:  453  	Training Loss: 3.9277103496715426e-05
Test Loss:  6.147080421214923e-05
Valid Loss:  3.8201244024094194e-05
Epoch:  454  	Training Loss: 3.92383590224199e-05
Test Loss:  6.137463788036257e-05
Valid Loss:  3.81670834030956e-05
Epoch:  455  	Training Loss: 3.920064045814797e-05
Test Loss:  6.128297536633909e-05
Valid Loss:  3.813207149505615e-05
Epoch:  456  	Training Loss: 3.9163634937722236e-05
Test Loss:  6.119530007708818e-05
Valid Loss:  3.809757618000731e-05
Epoch:  457  	Training Loss: 3.9126935007516295e-05
Test Loss:  6.110940739745274e-05
Valid Loss:  3.806322274613194e-05
Epoch:  458  	Training Loss: 3.9091282815206796e-05
Test Loss:  6.102653424022719e-05
Valid Loss:  3.8029254938010126e-05
Epoch:  459  	Training Loss: 3.905611811205745e-05
Test Loss:  6.094515265431255e-05
Valid Loss:  3.799588739639148e-05
Epoch:  460  	Training Loss: 3.902150638168678e-05
Test Loss:  6.086528082960285e-05
Valid Loss:  3.796278906520456e-05
Epoch:  461  	Training Loss: 3.898745126207359e-05
Test Loss:  6.0787373513448983e-05
Valid Loss:  3.7930560210952535e-05
Epoch:  462  	Training Loss: 3.895416739396751e-05
Test Loss:  6.059800580260344e-05
Valid Loss:  3.789926995523274e-05
Epoch:  463  	Training Loss: 3.8899306673556566e-05
Test Loss:  6.0470003518275917e-05
Valid Loss:  3.785602530115284e-05
Epoch:  464  	Training Loss: 3.884722536895424e-05
Test Loss:  6.0363818192854524e-05
Valid Loss:  3.780892802751623e-05
Epoch:  465  	Training Loss: 3.879520227201283e-05
Test Loss:  6.02665422775317e-05
Valid Loss:  3.776238736463711e-05
Epoch:  466  	Training Loss: 3.874490357702598e-05
Test Loss:  6.017717532813549e-05
Valid Loss:  3.7715057260356843e-05
Epoch:  467  	Training Loss: 3.8695012335665524e-05
Test Loss:  6.0092221247032285e-05
Valid Loss:  3.7668134609702975e-05
Epoch:  468  	Training Loss: 3.8645637687295675e-05
Test Loss:  6.001043948344886e-05
Valid Loss:  3.762100823223591e-05
Epoch:  469  	Training Loss: 3.8596703234361485e-05
Test Loss:  5.993151353322901e-05
Valid Loss:  3.757418744498864e-05
Epoch:  470  	Training Loss: 3.8548067095689476e-05
Test Loss:  5.985474126646295e-05
Valid Loss:  3.7528094253502786e-05
Epoch:  471  	Training Loss: 3.8500056689372286e-05
Test Loss:  5.9779758885269985e-05
Valid Loss:  3.748209564946592e-05
Epoch:  472  	Training Loss: 3.845234459731728e-05
Test Loss:  5.9749687352450565e-05
Valid Loss:  3.745707363123074e-05
Epoch:  473  	Training Loss: 3.842464502668008e-05
Test Loss:  5.9717000112868845e-05
Valid Loss:  3.742969056474976e-05
Epoch:  474  	Training Loss: 3.839762939605862e-05
Test Loss:  5.96827594563365e-05
Valid Loss:  3.7401667213998735e-05
Epoch:  475  	Training Loss: 3.8370602851500735e-05
Test Loss:  5.9645150031428784e-05
 95%|█████████▌| 475/500 [05:34<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:34<00:06,  3.00it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:41<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:47<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:47<00:00,  3.02it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Valid Loss:  3.7373822124209255e-05
Epoch:  476  	Training Loss: 3.834402741631493e-05
Test Loss:  5.96062745898962e-05
Valid Loss:  3.734564234036952e-05
Epoch:  477  	Training Loss: 3.831752110272646e-05
Test Loss:  5.9565631090663373e-05
Valid Loss:  3.731811011675745e-05
Epoch:  478  	Training Loss: 3.829116394626908e-05
Test Loss:  5.952375795459375e-05
Valid Loss:  3.729071613634005e-05
Epoch:  479  	Training Loss: 3.826514875981957e-05
Test Loss:  5.948092439211905e-05
Valid Loss:  3.726384602487087e-05
Epoch:  480  	Training Loss: 3.8239082641666755e-05
Test Loss:  5.9436872106743976e-05
Valid Loss:  3.72368776879739e-05
Epoch:  481  	Training Loss: 3.821305654128082e-05
Test Loss:  5.939382390351966e-05
Valid Loss:  3.721048415172845e-05
Epoch:  482  	Training Loss: 3.818709228653461e-05
Test Loss:  5.94864395679906e-05
Valid Loss:  3.7077184970257804e-05
Epoch:  483  	Training Loss: 3.812798604485579e-05
Test Loss:  5.9426478401292115e-05
Valid Loss:  3.705428389366716e-05
Epoch:  484  	Training Loss: 3.807585744652897e-05
Test Loss:  5.943890573689714e-05
Valid Loss:  3.6983616155339405e-05
Epoch:  485  	Training Loss: 3.802617720793933e-05
Test Loss:  5.94096454733517e-05
Valid Loss:  3.693946928251535e-05
Epoch:  486  	Training Loss: 3.797782483161427e-05
Test Loss:  5.939535913057625e-05
Valid Loss:  3.688447759486735e-05
Epoch:  487  	Training Loss: 3.793036739807576e-05
Test Loss:  5.936769230174832e-05
Valid Loss:  3.683651448227465e-05
Epoch:  488  	Training Loss: 3.7883801269344985e-05
Test Loss:  5.9342317399568856e-05
Valid Loss:  3.678665962070227e-05
Epoch:  489  	Training Loss: 3.783780994126573e-05
Test Loss:  5.9310947108315304e-05
Valid Loss:  3.673883475130424e-05
Epoch:  490  	Training Loss: 3.779157850658521e-05
Test Loss:  5.927958773099817e-05
Valid Loss:  3.66911590390373e-05
Epoch:  491  	Training Loss: 3.774479409912601e-05
Test Loss:  5.9247700846754014e-05
Valid Loss:  3.664249743451364e-05
Epoch:  492  	Training Loss: 3.7698391679441556e-05
Test Loss:  5.912473352509551e-05
Valid Loss:  3.6618665035348386e-05
Epoch:  493  	Training Loss: 3.766355075640604e-05
Test Loss:  5.901288386667147e-05
Valid Loss:  3.659495268948376e-05
Epoch:  494  	Training Loss: 3.7630932638421655e-05
Test Loss:  5.8914149121847004e-05
Valid Loss:  3.6567740608006716e-05
Epoch:  495  	Training Loss: 3.759926767088473e-05
Test Loss:  5.882245022803545e-05
Valid Loss:  3.653990279417485e-05
Epoch:  496  	Training Loss: 3.756806836463511e-05
Test Loss:  5.873647751286626e-05
Valid Loss:  3.6511090002022684e-05
Epoch:  497  	Training Loss: 3.7537240132223815e-05
Test Loss:  5.865530692972243e-05
Valid Loss:  3.6482641007751226e-05
Epoch:  498  	Training Loss: 3.750669566215947e-05
Test Loss:  5.857738869963214e-05
Valid Loss:  3.645411561592482e-05
Epoch:  499  	Training Loss: 3.747651135199703e-05
Test Loss:  5.850321031175554e-05
Valid Loss:  3.642546653281897e-05
Epoch:  500  	Training Loss: 3.744666537386365e-05
Test Loss:  5.8432138757780194e-05
Valid Loss:  3.6396719224285334e-05
seed is  13
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.53it/s]  1%|          | 4/500 [00:00<00:29, 16.71it/s]  1%|          | 6/500 [00:00<00:30, 16.46it/s]  2%|▏         | 8/500 [00:00<00:30, 16.38it/s]  2%|▏         | 10/500 [00:00<00:29, 16.38it/s]  2%|▏         | 12/500 [00:00<00:29, 16.51it/s]  3%|▎         | 14/500 [00:00<00:29, 16.61it/s]  3%|▎         | 16/500 [00:00<00:29, 16.58it/s]  4%|▎         | 18/500 [00:01<00:29, 16.50it/s]  4%|▍         | 20/500 [00:01<00:28, 16.58it/s]  4%|▍         | 22/500 [00:01<00:28, 16.68it/s]  5%|▍         | 24/500 [00:01<00:28, 16.76it/s]  5%|▌         | 26/500 [00:01<00:28, 16.74it/s]  6%|▌         | 28/500 [00:01<00:28, 16.71it/s]  6%|▌         | 30/500 [00:01<00:28, 16.70it/s]  6%|▋         | 32/500 [00:01<00:28, 16.63it/s]  7%|▋         | 34/500 [00:02<00:28, 16.49it/s]  7%|▋         | 36/500 [00:02<00:28, 16.37it/s]  8%|▊         | 38/500 [00:02<00:28, 16.28it/s]  8%|▊         | 40/500 [00:02<00:28, 16.10it/s]  8%|▊         | 42/500 [00:02<00:28, 16.02it/s]  9%|▉         | 44/500 [00:02<00:28, 16.23it/s]  9%|▉         | 46/500 [00:02<00:27, 16.40it/s] 10%|▉         | 48/500 [00:02<00:27, 16.54it/s] 10%|█         | 50/500 [00:03<00:27, 16.61it/s] 10%|█         | 52/500 [00:03<00:27, 16.59it/s] 11%|█         | 54/500 [00:03<00:26, 16.56it/s] 11%|█         | 56/500 [00:03<00:27, 16.34it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.31it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.43it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.38it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.31it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.37it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.37it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.46it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.37it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.19it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.13it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.33it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.45it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.55it/s] 17%|█▋        | 84/500 [00:05<00:24, 16.65it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.73it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.66it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.53it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.63it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.70it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.75it/s] 20%|█▉        | 98/500 [00:05<00:23, 16.79it/s] 20%|██        | 100/500 [00:06<00:23, 16.81it/s] 20%|██        | 102/500 [00:06<00:23, 16.75it/s] 21%|██        | 104/500 [00:06<00:23, 16.60it/s] 21%|██        | 106/500 [00:06<00:23, 16.64it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.65it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.71it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.75it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.71it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.64it/s] 24%|██▎       | 118/500 [00:07<00:22, 16.62it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.66it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.38it/s] 25%|██▍       | 124/500 [00:07<00:23, 15.79it/s]Epoch:  1  	Training Loss: 0.049283869564533234
Test Loss:  250.4004364013672
Valid Loss:  251.0305633544922
Epoch:  2  	Training Loss: 250.8092041015625
Test Loss:  7630594048.0
Valid Loss:  7605669376.0
Epoch:  3  	Training Loss: 7616010240.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:25, 14.92it/s] 26%|██▌       | 128/500 [00:07<00:24, 15.38it/s] 26%|██▌       | 130/500 [00:07<00:23, 15.78it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.90it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.16it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.31it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.43it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.37it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.39it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.36it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.40it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.48it/s] 30%|███       | 150/500 [00:09<00:21, 16.40it/s] 30%|███       | 152/500 [00:09<00:21, 16.46it/s] 31%|███       | 154/500 [00:09<00:20, 16.49it/s] 31%|███       | 156/500 [00:09<00:20, 16.57it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.64it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.60it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.50it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.60it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.14it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.14it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.15it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.25it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.34it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.45it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.52it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.61it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.69it/s] 37%|███▋      | 184/500 [00:11<00:18, 16.74it/s] 37%|███▋      | 186/500 [00:11<00:18, 16.78it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.65it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.61it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.45it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.48it/s] 39%|███▉      | 196/500 [00:11<00:19, 15.77it/s] 40%|███▉      | 198/500 [00:12<00:18, 15.98it/s] 40%|████      | 200/500 [00:12<00:18, 16.13it/s] 40%|████      | 202/500 [00:12<00:19, 15.30it/s] 41%|████      | 204/500 [00:12<00:20, 14.41it/s] 41%|████      | 206/500 [00:12<00:19, 15.01it/s] 42%|████▏     | 208/500 [00:12<00:18, 15.46it/s] 42%|████▏     | 210/500 [00:12<00:18, 15.82it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.02it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.04it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.08it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.03it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.10it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.21it/s] 45%|████▍     | 224/500 [00:13<00:17, 16.22it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.26it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.33it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.30it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.20it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.30it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.05it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.27it/s] 48%|████▊     | 240/500 [00:14<00:16, 16.08it/s] 48%|████▊     | 242/500 [00:14<00:16, 16.07it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.30it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.38it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.38it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.06it/s] 50%|█████     | 252/500 [00:15<00:15, 16.08it/s] 51%|█████     | 254/500 [00:15<00:15, 16.32it/s] 51%|█████     | 256/500 [00:15<00:14, 16.37it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.36it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.07it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.15it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.19it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.89it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.11it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.19it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.28it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.39it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.53it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.60it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.48it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.39it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.44it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.54it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.65it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.64it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.73it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.77it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.73it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.69it/s] 60%|██████    | 300/500 [00:18<00:12, 15.39it/s] 60%|██████    | 302/500 [00:18<00:12, 15.74it/s] 61%|██████    | 304/500 [00:18<00:12, 15.84it/s] 61%|██████    | 306/500 [00:18<00:12, 16.09it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.32it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.25it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.29it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.30it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.36it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.44it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.51it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.57it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.54it/s] 65%|██████▌   | 326/500 [00:19<00:11, 15.65it/s] 66%|██████▌   | 328/500 [00:20<00:10, 15.89it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.09it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.18it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.24it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.43it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.40it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.50it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.41it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.43it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.31it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.32it/s] 70%|███████   | 350/500 [00:21<00:09, 16.33it/s] 70%|███████   | 352/500 [00:21<00:09, 16.36it/s] 71%|███████   | 354/500 [00:21<00:08, 16.51it/s] 71%|███████   | 356/500 [00:21<00:08, 16.60it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.49it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.62it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.49it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.57it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.62it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.65it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.68it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.55it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.44it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.23it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.20it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.33it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.44it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.45it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.34it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.35it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.39it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.51it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.61it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.60it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.57it/s] 80%|████████  | 400/500 [00:24<00:06, 16.58it/s] 80%|████████  | 402/500 [00:24<00:05, 16.63it/s] 81%|████████  | 404/500 [00:24<00:05, 16.65it/s] 81%|████████  | 406/500 [00:24<00:05, 16.63it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.67it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.59it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.52it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.53it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.41it/s] 84%|████████▎ | 418/500 [00:25<00:05, 14.83it/s] 84%|████████▍ | 420/500 [00:25<00:05, 14.88it/s] 84%|████████▍ | 422/500 [00:25<00:05, 15.41it/s] 85%|████████▍ | 424/500 [00:25<00:04, 15.80it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.93it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.14it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.34it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.48it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.48it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.46it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.45it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.52it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.49it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.57it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.63it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.65it/s] 90%|█████████ | 450/500 [00:27<00:02, 16.68it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.58it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.58it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.51it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.39it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.36it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.29it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.42it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.54it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.58it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.69it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.71it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.69it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.68it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.70it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.72it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.52it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.48it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.39it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.22it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.28it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.36it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.46it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.57it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.64it/s]100%|██████████| 500/500 [00:30<00:00, 16.65it/s]100%|██████████| 500/500 [00:30<00:00, 16.35it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  13
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:29,  6.19s/it]  1%|          | 3/500 [00:06<13:43,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:28,  1.21s/it]  7%|▋         | 33/500 [00:27<06:45,  1.15it/s]  7%|▋         | 35/500 [00:27<04:51,  1.60it/s]  7%|▋         | 37/500 [00:27<03:32,  2.18it/s]  8%|▊         | 39/500 [00:27<02:37,  2.93it/s]  8%|▊         | 41/500 [00:33<09:05,  1.19s/it]  9%|▊         | 43/500 [00:33<06:29,  1.17it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:28,  2.17it/s] 10%|▉         | 49/500 [00:34<02:36,  2.89it/s] 10%|█         | 51/500 [00:40<08:56,  1.19s/it] 11%|█         | 53/500 [00:40<06:23,  1.17it/s] 11%|█         | 55/500 [00:41<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:29,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.97it/s] 14%|█▍        | 71/500 [00:54<08:33,  1.20s/it]Epoch:  1  	Training Loss: 0.049283869564533234
Test Loss:  162.59910583496094
Valid Loss:  154.91061401367188
Epoch:  2  	Training Loss: 157.44992065429688
Test Loss:  7903.7802734375
Valid Loss:  7926.326171875
Epoch:  3  	Training Loss: 7927.775390625
Test Loss:  132.50897216796875
Valid Loss:  133.80886840820312
Epoch:  4  	Training Loss: 133.50100708007812
Test Loss:  0.06459231674671173
Valid Loss:  0.08269773423671722
Epoch:  5  	Training Loss: 0.07872740179300308
Test Loss:  0.06434998661279678
Valid Loss:  0.08242650330066681
Epoch:  6  	Training Loss: 0.07847537100315094
Test Loss:  0.06411653757095337
Valid Loss:  0.08216382563114166
Epoch:  7  	Training Loss: 0.0782317966222763
Test Loss:  0.06389157474040985
Valid Loss:  0.08190938085317612
Epoch:  8  	Training Loss: 0.07799632847309113
Test Loss:  0.06367480754852295
Valid Loss:  0.0816628634929657
Epoch:  9  	Training Loss: 0.07776866108179092
Test Loss:  0.06346587091684341
Valid Loss:  0.08142395317554474
Epoch:  10  	Training Loss: 0.07754848897457123
Test Loss:  0.06326448917388916
Valid Loss:  0.08119241893291473
Epoch:  11  	Training Loss: 0.07733555138111115
Test Loss:  0.06307032704353333
Valid Loss:  0.0809679627418518
Epoch:  12  	Training Loss: 0.0771295428276062
Test Loss:  0.06294669210910797
Valid Loss:  0.08081969618797302
Epoch:  13  	Training Loss: 0.07699158042669296
Test Loss:  0.06282410025596619
Valid Loss:  0.0806725025177002
Epoch:  14  	Training Loss: 0.07685466855764389
Test Loss:  0.0627024918794632
Valid Loss:  0.08052632212638855
Epoch:  15  	Training Loss: 0.07671874016523361
Test Loss:  0.0625818520784378
Valid Loss:  0.08038118481636047
Epoch:  16  	Training Loss: 0.07658380270004272
Test Loss:  0.06246219575405121
Valid Loss:  0.08023703098297119
Epoch:  17  	Training Loss: 0.07644985616207123
Test Loss:  0.062343500554561615
Valid Loss:  0.08009390532970428
Epoch:  18  	Training Loss: 0.07631688565015793
Test Loss:  0.06222577393054962
Valid Loss:  0.07995178550481796
Epoch:  19  	Training Loss: 0.07618487626314163
Test Loss:  0.062108978629112244
Valid Loss:  0.07981061935424805
Epoch:  20  	Training Loss: 0.07605382800102234
Test Loss:  0.06199311837553978
Valid Loss:  0.07967045903205872
Epoch:  21  	Training Loss: 0.07592372596263885
Test Loss:  0.061878181993961334
Valid Loss:  0.0795312449336052
Epoch:  22  	Training Loss: 0.07579454779624939
Test Loss:  0.06176434084773064
Valid Loss:  0.07939320802688599
Epoch:  23  	Training Loss: 0.07566650211811066
Test Loss:  0.06165139004588127
Valid Loss:  0.07925610989332199
Epoch:  24  	Training Loss: 0.07553936541080475
Test Loss:  0.06153932958841324
Valid Loss:  0.07911994308233261
Epoch:  25  	Training Loss: 0.07541313022375107
Test Loss:  0.061428144574165344
Valid Loss:  0.07898470759391785
Epoch:  26  	Training Loss: 0.07528778910636902
Test Loss:  0.06131783127784729
Valid Loss:  0.07885038107633591
Epoch:  27  	Training Loss: 0.0751633271574974
Test Loss:  0.06120838224887848
Valid Loss:  0.0787169486284256
Epoch:  28  	Training Loss: 0.07503974437713623
Test Loss:  0.06109977141022682
Valid Loss:  0.07858443260192871
Epoch:  29  	Training Loss: 0.0749170184135437
Test Loss:  0.060992006212472916
Valid Loss:  0.07845278084278107
Epoch:  30  	Training Loss: 0.07479514926671982
Test Loss:  0.06088506802916527
Valid Loss:  0.07832200825214386
Epoch:  31  	Training Loss: 0.07467412948608398
Test Loss:  0.06077894568443298
Valid Loss:  0.07819210737943649
Epoch:  32  	Training Loss: 0.074553944170475
Test Loss:  0.06067383289337158
Valid Loss:  0.07806329429149628
Epoch:  33  	Training Loss: 0.0744348019361496
Test Loss:  0.06056951731443405
Valid Loss:  0.07793533802032471
Epoch:  34  	Training Loss: 0.07431647181510925
Test Loss:  0.060465991497039795
Valid Loss:  0.07780821621417999
Epoch:  35  	Training Loss: 0.07419894635677338
Test Loss:  0.06036324054002762
Valid Loss:  0.07768191397190094
Epoch:  36  	Training Loss: 0.07408223301172256
Test Loss:  0.06026126444339752
Valid Loss:  0.07755643129348755
Epoch:  37  	Training Loss: 0.07396629452705383
Test Loss:  0.06016004830598831
Valid Loss:  0.07743176817893982
Epoch:  38  	Training Loss: 0.07385113835334778
Test Loss:  0.06005959212779999
Valid Loss:  0.07730790972709656
Epoch:  39  	Training Loss: 0.0737367570400238
Test Loss:  0.059959881007671356
Valid Loss:  0.07718484103679657
Epoch:  40  	Training Loss: 0.07362315058708191
Test Loss:  0.05986091122031212
Valid Loss:  0.07706256210803986
Epoch:  41  	Training Loss: 0.07351028919219971
Test Loss:  0.05976265296339989
Valid Loss:  0.07694105803966522
Epoch:  42  	Training Loss: 0.0733981728553772
Test Loss:  0.059665240347385406
Valid Loss:  0.07682046294212341
Epoch:  43  	Training Loss: 0.07328692078590393
Test Loss:  0.05956852808594704
Valid Loss:  0.0767006129026413
Epoch:  44  	Training Loss: 0.07317640632390976
Test Loss:  0.05947251617908478
Valid Loss:  0.07658152282238007
Epoch:  45  	Training Loss: 0.0730666071176529
Test Loss:  0.05937720090150833
Valid Loss:  0.07646318525075912
Epoch:  46  	Training Loss: 0.07295751571655273
Test Loss:  0.0592825710773468
Valid Loss:  0.07634557783603668
Epoch:  47  	Training Loss: 0.07284913957118988
Test Loss:  0.05918861925601959
Valid Loss:  0.07622870802879333
Epoch:  48  	Training Loss: 0.07274145632982254
Test Loss:  0.05909533053636551
Valid Loss:  0.0761125385761261
Epoch:  49  	Training Loss: 0.07263445854187012
Test Loss:  0.05900272727012634
Valid Loss:  0.07599710673093796
Epoch:  50  	Training Loss: 0.0725281685590744
Test Loss:  0.05891076475381851
Valid Loss:  0.07588239014148712
Epoch:  51  	Training Loss: 0.07242254912853241
Test Loss:  0.05881946533918381
Valid Loss:  0.0757683664560318
Epoch:  52  	Training Loss: 0.07231760025024414
Test Loss:  0.058728981763124466
Valid Loss:  0.0756552666425705
Epoch:  53  	Training Loss: 0.07221352308988571
Test Loss:  0.05863911658525467
Valid Loss:  0.07554285228252411
Epoch:  54  	Training Loss: 0.07211010158061981
Test Loss:  0.058549895882606506
Valid Loss:  0.07543110847473145
Epoch:  55  	Training Loss: 0.07200732827186584
Test Loss:  0.05846128612756729
Valid Loss:  0.0753200575709343
Epoch:  56  	Training Loss: 0.07190518081188202
Test Loss:  0.058373287320137024
Valid Loss:  0.07520963996648788
Epoch:  57  	Training Loss: 0.07180368155241013
Test Loss:  0.05828588455915451
Valid Loss:  0.0750998929142952
Epoch:  58  	Training Loss: 0.07170280814170837
Test Loss:  0.05819908529520035
Valid Loss:  0.07499079406261444
Epoch:  59  	Training Loss: 0.07160255312919617
Test Loss:  0.05811287835240364
Valid Loss:  0.07488235086202621
Epoch:  60  	Training Loss: 0.0715029165148735
Test Loss:  0.058027252554893494
Valid Loss:  0.07477452605962753
Epoch:  61  	Training Loss: 0.0714038833975792
Test Loss:  0.05794220417737961
Valid Loss:  0.07466734945774078
Epoch:  62  	Training Loss: 0.07130544632673264
Test Loss:  0.05785787105560303
Valid Loss:  0.0745609700679779
Epoch:  63  	Training Loss: 0.07120778411626816
Test Loss:  0.057774100452661514
Valid Loss:  0.07445520907640457
Epoch:  64  	Training Loss: 0.07111069560050964
Test Loss:  0.05769089236855507
Valid Loss:  0.07435005903244019
Epoch:  65  	Training Loss: 0.07101419568061829
Test Loss:  0.0576082207262516
Valid Loss:  0.07424552738666534
Epoch:  66  	Training Loss: 0.0709182620048523
Test Loss:  0.05752609670162201
Valid Loss:  0.07414157688617706
Epoch:  67  	Training Loss: 0.07082290202379227
Test Loss:  0.05744451284408569
Valid Loss:  0.07403822988271713
Epoch:  68  	Training Loss: 0.0707281082868576
Test Loss:  0.05736346170306206
Valid Loss:  0.07393545657396317
Epoch:  69  	Training Loss: 0.07063385844230652
Test Loss:  0.057282935827970505
Valid Loss:  0.07383327186107635
Epoch:  70  	Training Loss: 0.0705401748418808
Test Loss:  0.05720292776823044
Valid Loss:  0.07373165339231491
Epoch:  71  	Training Loss: 0.07044702023267746
Test Loss:  0.05712343752384186
Valid Loss:  0.07363062351942062
Epoch:  72  	Training Loss: 0.0703544169664383
Test Loss:  0.05704457312822342
Valid Loss:  0.07353029400110245
Epoch:  73  	Training Loss: 0.07026248425245285
Test Loss:  0.05696621537208557
Valid Loss:   15%|█▍        | 73/500 [00:54<06:06,  1.16it/s] 15%|█▌        | 75/500 [00:54<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:54<03:11,  2.20it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:01<08:14,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.22it/s] 18%|█▊        | 89/500 [01:01<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:08<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:03,  2.19it/s] 20%|█▉        | 99/500 [01:08<02:18,  2.89it/s] 20%|██        | 101/500 [01:15<07:59,  1.20s/it] 21%|██        | 103/500 [01:15<05:42,  1.16it/s] 21%|██        | 105/500 [01:15<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:15<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:15<02:13,  2.94it/s] 22%|██▏       | 111/500 [01:22<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:22<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:22<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:28<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:29<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:29<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:35<07:13,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:36<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:36<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:36<02:00,  2.98it/s] 28%|██▊       | 141/500 [01:42<07:05,  1.19s/it] 29%|██▊       | 143/500 [01:42<05:03,  1.18it/s]0.07343053072690964
Epoch:  74  	Training Loss: 0.07017108052968979
Test Loss:  0.05688835307955742
Valid Loss:  0.073331318795681
Epoch:  75  	Training Loss: 0.07008019089698792
Test Loss:  0.05681097134947777
Valid Loss:  0.07323263585567474
Epoch:  76  	Training Loss: 0.06998983025550842
Test Loss:  0.056734077632427216
Valid Loss:  0.07313451170921326
Epoch:  77  	Training Loss: 0.06989997625350952
Test Loss:  0.05665767565369606
Valid Loss:  0.07303692400455475
Epoch:  78  	Training Loss: 0.06981062889099121
Test Loss:  0.056581735610961914
Valid Loss:  0.07293985784053802
Epoch:  79  	Training Loss: 0.0697217732667923
Test Loss:  0.056506264954805374
Valid Loss:  0.07284331321716309
Epoch:  80  	Training Loss: 0.06963341683149338
Test Loss:  0.056431256234645844
Valid Loss:  0.07274729758501053
Epoch:  81  	Training Loss: 0.06954554468393326
Test Loss:  0.05635671317577362
Valid Loss:  0.07265177369117737
Epoch:  82  	Training Loss: 0.06945816427469254
Test Loss:  0.05628274753689766
Valid Loss:  0.07255695760250092
Epoch:  83  	Training Loss: 0.06937141716480255
Test Loss:  0.05620922893285751
Valid Loss:  0.07246261835098267
Epoch:  84  	Training Loss: 0.06928513944149017
Test Loss:  0.05613615736365318
Valid Loss:  0.07236878573894501
Epoch:  85  	Training Loss: 0.069199338555336
Test Loss:  0.056063517928123474
Valid Loss:  0.07227545231580734
Epoch:  86  	Training Loss: 0.06911398470401764
Test Loss:  0.05599131062626839
Valid Loss:  0.07218259572982788
Epoch:  87  	Training Loss: 0.06902910768985748
Test Loss:  0.05591953545808792
Valid Loss:  0.07209023833274841
Epoch:  88  	Training Loss: 0.06894467771053314
Test Loss:  0.05584817752242088
Valid Loss:  0.07199835032224655
Epoch:  89  	Training Loss: 0.06886069476604462
Test Loss:  0.05577723681926727
Valid Loss:  0.0719069242477417
Epoch:  90  	Training Loss: 0.0687771588563919
Test Loss:  0.05570671707391739
Valid Loss:  0.07181598246097565
Epoch:  91  	Training Loss: 0.06869406253099442
Test Loss:  0.05563659593462944
Valid Loss:  0.07172549515962601
Epoch:  92  	Training Loss: 0.06861139833927155
Test Loss:  0.055566996335983276
Valid Loss:  0.07163562625646591
Epoch:  93  	Training Loss: 0.06852930784225464
Test Loss:  0.055497799068689346
Valid Loss:  0.07154619693756104
Epoch:  94  	Training Loss: 0.06844763457775116
Test Loss:  0.055428989231586456
Valid Loss:  0.07145722210407257
Epoch:  95  	Training Loss: 0.06836637854576111
Test Loss:  0.055360566824674606
Valid Loss:  0.07136868685483932
Epoch:  96  	Training Loss: 0.06828554719686508
Test Loss:  0.055292535573244095
Valid Loss:  0.0712805986404419
Epoch:  97  	Training Loss: 0.06820512562990189
Test Loss:  0.05522488057613373
Valid Loss:  0.07119295001029968
Epoch:  98  	Training Loss: 0.06812511384487152
Test Loss:  0.055157601833343506
Valid Loss:  0.0711057260632515
Epoch:  99  	Training Loss: 0.06804549694061279
Test Loss:  0.05509069934487343
Valid Loss:  0.07101892679929733
Epoch:  100  	Training Loss: 0.0679662823677063
Test Loss:  0.0550241693854332
Valid Loss:  0.07093256711959839
Epoch:  101  	Training Loss: 0.06788748502731323
Test Loss:  0.05495801568031311
Valid Loss:  0.07084663212299347
Epoch:  102  	Training Loss: 0.0678090751171112
Test Loss:  0.054892268031835556
Valid Loss:  0.07076118886470795
Epoch:  103  	Training Loss: 0.06773111969232559
Test Loss:  0.054826878011226654
Valid Loss:  0.07067615538835526
Epoch:  104  	Training Loss: 0.06765355169773102
Test Loss:  0.054761841893196106
Valid Loss:  0.0705915242433548
Epoch:  105  	Training Loss: 0.06757635623216629
Test Loss:  0.05469715595245361
Valid Loss:  0.07050730288028717
Epoch:  106  	Training Loss: 0.067499540746212
Test Loss:  0.05463281646370888
Valid Loss:  0.07042346894741058
Epoch:  107  	Training Loss: 0.06742309778928757
Test Loss:  0.054568812251091
Valid Loss:  0.07034005224704742
Epoch:  108  	Training Loss: 0.06734701991081238
Test Loss:  0.05450515076518059
Valid Loss:  0.07025700807571411
Epoch:  109  	Training Loss: 0.06727130711078644
Test Loss:  0.05444180965423584
Valid Loss:  0.07017435878515244
Epoch:  110  	Training Loss: 0.06719595193862915
Test Loss:  0.054378803819417953
Valid Loss:  0.0700920969247818
Epoch:  111  	Training Loss: 0.06712095439434052
Test Loss:  0.05431612208485603
Valid Loss:  0.0700102150440216
Epoch:  112  	Training Loss: 0.06704631447792053
Test Loss:  0.05425389111042023
Valid Loss:  0.0699288547039032
Epoch:  113  	Training Loss: 0.06697216629981995
Test Loss:  0.05419197678565979
Valid Loss:  0.06984788179397583
Epoch:  114  	Training Loss: 0.06689836829900742
Test Loss:  0.054130371659994125
Valid Loss:  0.06976726651191711
Epoch:  115  	Training Loss: 0.06682491302490234
Test Loss:  0.05406908318400383
Valid Loss:  0.06968703120946884
Epoch:  116  	Training Loss: 0.06675179302692413
Test Loss:  0.05400810018181801
Valid Loss:  0.06960715353488922
Epoch:  117  	Training Loss: 0.06667900830507278
Test Loss:  0.053947415202856064
Valid Loss:  0.06952762603759766
Epoch:  118  	Training Loss: 0.0666065588593483
Test Loss:  0.05388704687356949
Valid Loss:  0.06944847106933594
Epoch:  119  	Training Loss: 0.06653442978858948
Test Loss:  0.053826965391635895
Valid Loss:  0.06936965882778168
Epoch:  120  	Training Loss: 0.06646264344453812
Test Loss:  0.05376717448234558
Valid Loss:  0.06929118931293488
Epoch:  121  	Training Loss: 0.06639116257429123
Test Loss:  0.053707681596279144
Valid Loss:  0.06921306252479553
Epoch:  122  	Training Loss: 0.06632000207901001
Test Loss:  0.05364856868982315
Valid Loss:  0.06913541257381439
Epoch:  123  	Training Loss: 0.06624928116798401
Test Loss:  0.053589750081300735
Valid Loss:  0.06905810534954071
Epoch:  124  	Training Loss: 0.06617885828018188
Test Loss:  0.05353120341897011
Valid Loss:  0.0689811259508133
Epoch:  125  	Training Loss: 0.06610875576734543
Test Loss:  0.05347292870283127
Valid Loss:  0.06890447437763214
Epoch:  126  	Training Loss: 0.06603895127773285
Test Loss:  0.05341494083404541
Valid Loss:  0.06882815062999725
Epoch:  127  	Training Loss: 0.06596945226192474
Test Loss:  0.05335722118616104
Valid Loss:  0.06875216215848923
Epoch:  128  	Training Loss: 0.06590025871992111
Test Loss:  0.05329977348446846
Valid Loss:  0.06867649406194687
Epoch:  129  	Training Loss: 0.06583135575056076
Test Loss:  0.053242579102516174
Valid Loss:  0.06860114634037018
Epoch:  130  	Training Loss: 0.06576275825500488
Test Loss:  0.05318566411733627
Valid Loss:  0.06852610409259796
Epoch:  131  	Training Loss: 0.06569443643093109
Test Loss:  0.05312900245189667
Valid Loss:  0.06845138967037201
Epoch:  132  	Training Loss: 0.06562641263008118
Test Loss:  0.053072694689035416
Valid Loss:  0.06837710738182068
Epoch:  133  	Training Loss: 0.0655587837100029
Test Loss:  0.05301665514707565
Valid Loss:  0.06830313056707382
Epoch:  134  	Training Loss: 0.0654914528131485
Test Loss:  0.05296086147427559
Valid Loss:  0.06822946667671204
Epoch:  135  	Training Loss: 0.06542438268661499
Test Loss:  0.05290531367063522
Valid Loss:  0.06815610826015472
Epoch:  136  	Training Loss: 0.06535761058330536
Test Loss:  0.052850011736154556
Valid Loss:  0.06808304786682129
Epoch:  137  	Training Loss: 0.06529109179973602
Test Loss:  0.05279495567083359
Valid Loss:  0.06801027059555054
Epoch:  138  	Training Loss: 0.06522485613822937
Test Loss:  0.05274013802409172
Valid Loss:  0.06793779134750366
Epoch:  139  	Training Loss: 0.06515888124704361
Test Loss:  0.052685558795928955
Valid Loss:  0.06786561012268066
Epoch:  140  	Training Loss: 0.06509317457675934
Test Loss:  0.05263121426105499
Valid Loss:  0.06779371201992035
Epoch:  141  	Training Loss: 0.06502772867679596
Test Loss:  0.05257710814476013
Valid Loss:  0.06772209703922272
Epoch:  142  	Training Loss: 0.06496255099773407
Test Loss:  0.05252332240343094
Valid Loss:  0.06765089929103851
Epoch:  143  	Training Loss: 0.06489774584770203
Test Loss:  0.052469782531261444
Valid Loss:  0.0675799697637558
Epoch:  144  	Training Loss: 0.06483319401741028
Test Loss:  0.05241645127534866
Valid Loss:  0.06750933080911636
Epoch:  145  	Training Loss: 0.06476889550685883
Test Loss:  0.05236335098743439
Valid Loss:   29%|██▉       | 145/500 [01:42<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:43<02:38,  2.22it/s] 30%|██▉       | 149/500 [01:43<01:57,  2.98it/s] 30%|███       | 151/500 [01:49<06:54,  1.19s/it] 31%|███       | 153/500 [01:49<04:55,  1.17it/s] 31%|███       | 155/500 [01:49<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:49<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:50<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:56<06:34,  1.17s/it] 33%|███▎      | 163/500 [01:56<04:42,  1.20it/s] 33%|███▎      | 165/500 [01:56<03:22,  1.65it/s] 33%|███▎      | 167/500 [01:56<02:27,  2.26it/s] 34%|███▍      | 169/500 [01:56<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:03<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:03<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:03<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:03<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:10<06:21,  1.20s/it] 37%|███▋      | 183/500 [02:10<04:32,  1.17it/s] 37%|███▋      | 185/500 [02:10<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:10<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:10<01:44,  2.96it/s] 38%|███▊      | 191/500 [02:17<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:17<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:17<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:17<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:17<01:41,  2.96it/s] 40%|████      | 201/500 [02:23<05:49,  1.17s/it] 41%|████      | 203/500 [02:23<04:09,  1.19it/s] 41%|████      | 205/500 [02:24<02:59,  1.65it/s] 41%|████▏     | 207/500 [02:24<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:24<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:30<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:30<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:53,  1.64it/s]0.06743896007537842
Epoch:  146  	Training Loss: 0.06470485031604767
Test Loss:  0.05231046676635742
Valid Loss:  0.06736886501312256
Epoch:  147  	Training Loss: 0.06464105099439621
Test Loss:  0.05225779861211777
Valid Loss:  0.06729903817176819
Epoch:  148  	Training Loss: 0.06457749009132385
Test Loss:  0.05220535397529602
Valid Loss:  0.06722947210073471
Epoch:  149  	Training Loss: 0.0645141750574112
Test Loss:  0.052153121680021286
Valid Loss:  0.06716018915176392
Epoch:  150  	Training Loss: 0.06445110589265823
Test Loss:  0.05210109427571297
Valid Loss:  0.06709113717079163
Epoch:  151  	Training Loss: 0.06438827514648438
Test Loss:  0.05204927921295166
Valid Loss:  0.06702236086130142
Epoch:  152  	Training Loss: 0.06432566791772842
Test Loss:  0.05199773609638214
Valid Loss:  0.06695393472909927
Epoch:  153  	Training Loss: 0.06426340341567993
Test Loss:  0.05194640904664993
Valid Loss:  0.06688578426837921
Epoch:  154  	Training Loss: 0.06420134752988815
Test Loss:  0.05189528316259384
Valid Loss:  0.06681785732507706
Epoch:  155  	Training Loss: 0.06413953751325607
Test Loss:  0.05184435471892357
Valid Loss:  0.06675019860267639
Epoch:  156  	Training Loss: 0.0640779435634613
Test Loss:  0.05179362744092941
Valid Loss:  0.06668277829885483
Epoch:  157  	Training Loss: 0.06401658058166504
Test Loss:  0.051743097603321075
Valid Loss:  0.06661560386419296
Epoch:  158  	Training Loss: 0.06395544111728668
Test Loss:  0.051692746579647064
Valid Loss:  0.0665486752986908
Epoch:  159  	Training Loss: 0.06389451026916504
Test Loss:  0.05164260044693947
Valid Loss:  0.06648199260234833
Epoch:  160  	Training Loss: 0.0638338029384613
Test Loss:  0.051592640578746796
Valid Loss:  0.06641553342342377
Epoch:  161  	Training Loss: 0.06377330422401428
Test Loss:  0.051542870700359344
Valid Loss:  0.0663493275642395
Epoch:  162  	Training Loss: 0.06371302902698517
Test Loss:  0.05149336904287338
Valid Loss:  0.0662834644317627
Epoch:  163  	Training Loss: 0.06365308165550232
Test Loss:  0.05144406110048294
Valid Loss:  0.06621783971786499
Epoch:  164  	Training Loss: 0.06359334290027618
Test Loss:  0.051394931972026825
Valid Loss:  0.06615243852138519
Epoch:  165  	Training Loss: 0.06353379786014557
Test Loss:  0.05134597793221474
Valid Loss:  0.0660872682929039
Epoch:  166  	Training Loss: 0.06347446143627167
Test Loss:  0.05129719153046608
Valid Loss:  0.06602232903242111
Epoch:  167  	Training Loss: 0.06341533362865448
Test Loss:  0.05124859884381294
Valid Loss:  0.06595760583877563
Epoch:  168  	Training Loss: 0.06335639953613281
Test Loss:  0.05120016634464264
Valid Loss:  0.06589309871196747
Epoch:  169  	Training Loss: 0.06329766660928726
Test Loss:  0.05115191638469696
Valid Loss:  0.0658288225531578
Epoch:  170  	Training Loss: 0.06323912739753723
Test Loss:  0.05110382288694382
Valid Loss:  0.06576475501060486
Epoch:  171  	Training Loss: 0.06318078935146332
Test Loss:  0.0510559119284153
Valid Loss:  0.06570090353488922
Epoch:  172  	Training Loss: 0.06312264502048492
Test Loss:  0.051008254289627075
Valid Loss:  0.06563739478588104
Epoch:  173  	Training Loss: 0.063064806163311
Test Loss:  0.050960756838321686
Valid Loss:  0.06557409465312958
Epoch:  174  	Training Loss: 0.06300715357065201
Test Loss:  0.05091342329978943
Valid Loss:  0.06551100313663483
Epoch:  175  	Training Loss: 0.06294968724250793
Test Loss:  0.0508662573993206
Valid Loss:  0.06544812768697739
Epoch:  176  	Training Loss: 0.06289241462945938
Test Loss:  0.050819236785173416
Valid Loss:  0.06538544595241547
Epoch:  177  	Training Loss: 0.06283532083034515
Test Loss:  0.05077238753437996
Valid Loss:  0.06532298028469086
Epoch:  178  	Training Loss: 0.06277841329574585
Test Loss:  0.05072569102048874
Valid Loss:  0.06526070088148117
Epoch:  179  	Training Loss: 0.06272168457508087
Test Loss:  0.05067914351820946
Valid Loss:  0.06519864499568939
Epoch:  180  	Training Loss: 0.06266513466835022
Test Loss:  0.050632771104574203
Valid Loss:  0.06513678282499313
Epoch:  181  	Training Loss: 0.06260877847671509
Test Loss:  0.050586529076099396
Valid Loss:  0.0650751143693924
Epoch:  182  	Training Loss: 0.06255258619785309
Test Loss:  0.05054052174091339
Valid Loss:  0.06501375138759613
Epoch:  183  	Training Loss: 0.06249665841460228
Test Loss:  0.050494659692049026
Valid Loss:  0.06495256721973419
Epoch:  184  	Training Loss: 0.0624409094452858
Test Loss:  0.0504489466547966
Valid Loss:  0.06489159166812897
Epoch:  185  	Training Loss: 0.062385328114032745
Test Loss:  0.050403375178575516
Valid Loss:  0.06483079493045807
Epoch:  186  	Training Loss: 0.06232992187142372
Test Loss:  0.05035794526338577
Valid Loss:  0.0647701844573021
Epoch:  187  	Training Loss: 0.06227467581629753
Test Loss:  0.05031266063451767
Valid Loss:  0.06470976769924164
Epoch:  188  	Training Loss: 0.06221960484981537
Test Loss:  0.05026751011610031
Valid Loss:  0.0646495372056961
Epoch:  189  	Training Loss: 0.062164682894945145
Test Loss:  0.050222501158714294
Valid Loss:  0.0645894706249237
Epoch:  190  	Training Loss: 0.06210992485284805
Test Loss:  0.05017763003706932
Valid Loss:  0.06452960520982742
Epoch:  191  	Training Loss: 0.06205534189939499
Test Loss:  0.05013289675116539
Valid Loss:  0.06446990370750427
Epoch:  192  	Training Loss: 0.06200091168284416
Test Loss:  0.05008838698267937
Valid Loss:  0.0644105076789856
Epoch:  193  	Training Loss: 0.061946749687194824
Test Loss:  0.05004400759935379
Valid Loss:  0.06435129046440125
Epoch:  194  	Training Loss: 0.06189274042844772
Test Loss:  0.04999975115060806
Valid Loss:  0.06429225206375122
Epoch:  195  	Training Loss: 0.06183888763189316
Test Loss:  0.04995563626289368
Valid Loss:  0.06423337757587433
Epoch:  196  	Training Loss: 0.06178519129753113
Test Loss:  0.04991164058446884
Valid Loss:  0.06417467445135117
Epoch:  197  	Training Loss: 0.06173163652420044
Test Loss:  0.04986778646707535
Valid Loss:  0.06411615014076233
Epoch:  198  	Training Loss: 0.061678241938352585
Test Loss:  0.049824051558971405
Valid Loss:  0.06405779719352722
Epoch:  199  	Training Loss: 0.06162500008940697
Test Loss:  0.04978043586015701
Valid Loss:  0.06399960070848465
Epoch:  200  	Training Loss: 0.06157190352678299
Test Loss:  0.04973694682121277
Valid Loss:  0.063941590487957
Epoch:  201  	Training Loss: 0.06151895597577095
Test Loss:  0.04969358816742897
Valid Loss:  0.06388372927904129
Epoch:  202  	Training Loss: 0.06146615371108055
Test Loss:  0.04965044558048248
Valid Loss:  0.06382615864276886
Epoch:  203  	Training Loss: 0.061413612216711044
Test Loss:  0.04960741102695465
Valid Loss:  0.06376875936985016
Epoch:  204  	Training Loss: 0.06136120855808258
Test Loss:  0.049564510583877563
Valid Loss:  0.06371151655912399
Epoch:  205  	Training Loss: 0.061308957636356354
Test Loss:  0.04952172562479973
Valid Loss:  0.06365443766117096
Epoch:  206  	Training Loss: 0.061256855726242065
Test Loss:  0.04947906360030174
Valid Loss:  0.06359753012657166
Epoch:  207  	Training Loss: 0.06120488792657852
Test Loss:  0.049436502158641815
Valid Loss:  0.0635407567024231
Epoch:  208  	Training Loss: 0.06115305423736572
Test Loss:  0.04939405992627144
Valid Loss:  0.06348414719104767
Epoch:  209  	Training Loss: 0.06110134720802307
Test Loss:  0.04935172572731972
Valid Loss:  0.06342770159244537
Epoch:  210  	Training Loss: 0.06104979291558266
Test Loss:  0.04930951073765755
Valid Loss:  0.06337140500545502
Epoch:  211  	Training Loss: 0.06099836528301239
Test Loss:  0.04926740378141403
Valid Loss:  0.063315249979496
Epoch:  212  	Training Loss: 0.06094706058502197
Test Loss:  0.049225494265556335
Valid Loss:  0.06325936317443848
Epoch:  213  	Training Loss: 0.06089601293206215
Test Loss:  0.049183689057826996
Valid Loss:  0.06320364773273468
Epoch:  214  	Training Loss: 0.060845088213682175
Test Loss:  0.04914200305938721
Valid Loss:  0.06314805150032043
Epoch:  215  	Training Loss: 0.060794293880462646
Test Loss:  0.04910041391849518
Valid Loss:  0.06309262663125992
Epoch:  216  	Training Loss: 0.06074362248182297
Test Loss:  0.049058929085731506
Valid Loss:  0.06303733587265015
Epoch:  217  	Training Loss: 0.06069308891892433
Test Loss:   43%|████▎     | 217/500 [02:31<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:31<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:37<05:23,  1.16s/it] 45%|████▍     | 223/500 [02:37<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:37<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:37<01:29,  3.01it/s] 46%|████▌     | 231/500 [02:44<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:44<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:44<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:44<01:58,  2.23it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:51<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:51<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:51<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:51<01:55,  2.20it/s] 50%|████▉     | 249/500 [02:51<01:25,  2.95it/s] 50%|█████     | 251/500 [02:58<04:54,  1.18s/it] 51%|█████     | 253/500 [02:58<03:29,  1.18it/s] 51%|█████     | 255/500 [02:58<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:58<01:49,  2.23it/s] 52%|█████▏    | 259/500 [02:58<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:04<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:05<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:05<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:05<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:05<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:11<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:11<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:11<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:12<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:12<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:18<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:18<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:18<02:13,  1.62it/s] 57%|█████▋    | 287/500 [03:18<01:36,  2.21it/s]0.04901755228638649
Valid Loss:  0.06298218667507172
Epoch:  218  	Training Loss: 0.060642682015895844
Test Loss:  0.04897627606987953
Valid Loss:  0.06292717158794403
Epoch:  219  	Training Loss: 0.06059238687157631
Test Loss:  0.04893510788679123
Valid Loss:  0.06287232041358948
Epoch:  220  	Training Loss: 0.06054222956299782
Test Loss:  0.04889403283596039
Valid Loss:  0.06281760334968567
Epoch:  221  	Training Loss: 0.06049218773841858
Test Loss:  0.048853062093257904
Valid Loss:  0.0627630203962326
Epoch:  222  	Training Loss: 0.06044226884841919
Test Loss:  0.048812270164489746
Valid Loss:  0.06270867586135864
Epoch:  223  	Training Loss: 0.06039256229996681
Test Loss:  0.04877156764268875
Valid Loss:  0.06265447288751602
Epoch:  224  	Training Loss: 0.06034297123551369
Test Loss:  0.048730961978435516
Valid Loss:  0.06260038912296295
Epoch:  225  	Training Loss: 0.06029350683093071
Test Loss:  0.04869046062231064
Valid Loss:  0.06254646182060242
Epoch:  226  	Training Loss: 0.06024415045976639
Test Loss:  0.04865004122257233
Valid Loss:  0.06249265745282173
Epoch:  227  	Training Loss: 0.060194920748472214
Test Loss:  0.04860972613096237
Valid Loss:  0.06243898719549179
Epoch:  228  	Training Loss: 0.06014580279588699
Test Loss:  0.04856950789690018
Valid Loss:  0.06238545477390289
Epoch:  229  	Training Loss: 0.06009679660201073
Test Loss:  0.048529379069805145
Valid Loss:  0.062332041561603546
Epoch:  230  	Training Loss: 0.06004790961742401
Test Loss:  0.04848933964967728
Valid Loss:  0.06227877736091614
Epoch:  231  	Training Loss: 0.05999913811683655
Test Loss:  0.04844938963651657
Valid Loss:  0.06222562864422798
Epoch:  232  	Training Loss: 0.05995047092437744
Test Loss:  0.04840961843729019
Valid Loss:  0.062172722071409225
Epoch:  233  	Training Loss: 0.059902019798755646
Test Loss:  0.048369936645030975
Valid Loss:  0.06211993843317032
Epoch:  234  	Training Loss: 0.059853680431842804
Test Loss:  0.048330340534448624
Valid Loss:  0.062067292630672455
Epoch:  235  	Training Loss: 0.05980544537305832
Test Loss:  0.04829083010554314
Valid Loss:  0.06201476231217384
Epoch:  236  	Training Loss: 0.05975732207298279
Test Loss:  0.04825140908360481
Valid Loss:  0.06196235492825508
Epoch:  237  	Training Loss: 0.05970931053161621
Test Loss:  0.048212070018053055
Valid Loss:  0.06191007047891617
Epoch:  238  	Training Loss: 0.05966140329837799
Test Loss:  0.04817282408475876
Valid Loss:  0.0618579164147377
Epoch:  239  	Training Loss: 0.05961359664797783
Test Loss:  0.04813366010785103
Valid Loss:  0.06180587410926819
Epoch:  240  	Training Loss: 0.05956590175628662
Test Loss:  0.048094578087329865
Valid Loss:  0.061753954738378525
Epoch:  241  	Training Loss: 0.05951830744743347
Test Loss:  0.04805557802319527
Valid Loss:  0.06170216202735901
Epoch:  242  	Training Loss: 0.05947081372141838
Test Loss:  0.048016734421253204
Valid Loss:  0.0616505891084671
Epoch:  243  	Training Loss: 0.05942352116107941
Test Loss:  0.047977980226278305
Valid Loss:  0.06159914284944534
Epoch:  244  	Training Loss: 0.05937633663415909
Test Loss:  0.047939300537109375
Valid Loss:  0.061547793447971344
Epoch:  245  	Training Loss: 0.05932924151420593
Test Loss:  0.047900713980197906
Valid Loss:  0.06149657070636749
Epoch:  246  	Training Loss: 0.059282250702381134
Test Loss:  0.04786219075322151
Valid Loss:  0.061445459723472595
Epoch:  247  	Training Loss: 0.059235360473394394
Test Loss:  0.04782375320792198
Valid Loss:  0.06139446049928665
Epoch:  248  	Training Loss: 0.059188567101955414
Test Loss:  0.04778539016842842
Valid Loss:  0.06134358048439026
Epoch:  249  	Training Loss: 0.059141866862773895
Test Loss:  0.04774710536003113
Valid Loss:  0.06129280850291252
Epoch:  250  	Training Loss: 0.059095270931720734
Test Loss:  0.0477088987827301
Valid Loss:  0.061242155730724335
Epoch:  251  	Training Loss: 0.05904877185821533
Test Loss:  0.04767075926065445
Valid Loss:  0.06119160354137421
Epoch:  252  	Training Loss: 0.059002358466386795
Test Loss:  0.04763277620077133
Valid Loss:  0.061141256242990494
Epoch:  253  	Training Loss: 0.05895613133907318
Test Loss:  0.04759486764669418
Valid Loss:  0.061091016978025436
Epoch:  254  	Training Loss: 0.05890999734401703
Test Loss:  0.04755702242255211
Valid Loss:  0.061040885746479034
Epoch:  255  	Training Loss: 0.05886395275592804
Test Loss:  0.0475192591547966
Valid Loss:  0.060990869998931885
Epoch:  256  	Training Loss: 0.05881800502538681
Test Loss:  0.04748156666755676
Valid Loss:  0.0609409473836422
Epoch:  257  	Training Loss: 0.05877213925123215
Test Loss:  0.0474439412355423
Valid Loss:  0.06089113652706146
Epoch:  258  	Training Loss: 0.05872637405991554
Test Loss:  0.0474063865840435
Valid Loss:  0.060841433703899384
Epoch:  259  	Training Loss: 0.0586806982755661
Test Loss:  0.04736889898777008
Valid Loss:  0.06079183146357536
Epoch:  260  	Training Loss: 0.058635108172893524
Test Loss:  0.04733148217201233
Valid Loss:  0.06074233725667
Epoch:  261  	Training Loss: 0.05858960375189781
Test Loss:  0.04729413986206055
Valid Loss:  0.060692936182022095
Epoch:  262  	Training Loss: 0.058544185012578964
Test Loss:  0.0472569577395916
Valid Loss:  0.060643769800662994
Epoch:  263  	Training Loss: 0.05849897861480713
Test Loss:  0.04721985012292862
Valid Loss:  0.06059470772743225
Epoch:  264  	Training Loss: 0.05845385044813156
Test Loss:  0.047182805836200714
Valid Loss:  0.06054573878645897
Epoch:  265  	Training Loss: 0.058408815413713455
Test Loss:  0.047145817428827286
Valid Loss:  0.06049686670303345
Epoch:  266  	Training Loss: 0.05836385488510132
Test Loss:  0.04710889980196953
Valid Loss:  0.06044809892773628
Epoch:  267  	Training Loss: 0.058318983763456345
Test Loss:  0.04707205295562744
Valid Loss:  0.06039942428469658
Epoch:  268  	Training Loss: 0.058274202048778534
Test Loss:  0.04703525826334953
Valid Loss:  0.060350850224494934
Epoch:  269  	Training Loss: 0.058229491114616394
Test Loss:  0.04699854552745819
Valid Loss:  0.060302361845970154
Epoch:  270  	Training Loss: 0.05818486586213112
Test Loss:  0.04696188122034073
Valid Loss:  0.06025397777557373
Epoch:  271  	Training Loss: 0.05814032256603241
Test Loss:  0.04692528024315834
Valid Loss:  0.06020569056272507
Epoch:  272  	Training Loss: 0.05809586122632027
Test Loss:  0.04688882827758789
Valid Loss:  0.06015760824084282
Epoch:  273  	Training Loss: 0.05805157870054245
Test Loss:  0.04685243219137192
Valid Loss:  0.06010960787534714
Epoch:  274  	Training Loss: 0.0580073744058609
Test Loss:  0.04681609943509102
Valid Loss:  0.06006171554327011
Epoch:  275  	Training Loss: 0.05796324461698532
Test Loss:  0.04677983373403549
Valid Loss:  0.060013897716999054
Epoch:  276  	Training Loss: 0.057919204235076904
Test Loss:  0.04674362391233444
Valid Loss:  0.05996618792414665
Epoch:  277  	Training Loss: 0.05787523835897446
Test Loss:  0.046707477420568466
Valid Loss:  0.05991855263710022
Epoch:  278  	Training Loss: 0.05783134698867798
Test Loss:  0.04667137935757637
Valid Loss:  0.059871021658182144
Epoch:  279  	Training Loss: 0.05778753012418747
Test Loss:  0.04663534834980965
Valid Loss:  0.05982358008623123
Epoch:  280  	Training Loss: 0.05774379521608353
Test Loss:  0.0465993769466877
Valid Loss:  0.059776224195957184
Epoch:  281  	Training Loss: 0.057700127363204956
Test Loss:  0.04656346142292023
Valid Loss:  0.0597289502620697
Epoch:  282  	Training Loss: 0.05765654146671295
Test Loss:  0.0465276762843132
Valid Loss:  0.05968187749385834
Epoch:  283  	Training Loss: 0.057613126933574677
Test Loss:  0.04649195075035095
Valid Loss:  0.05963488668203354
Epoch:  284  	Training Loss: 0.057569779455661774
Test Loss:  0.04645627737045288
Valid Loss:  0.05958797037601471
Epoch:  285  	Training Loss: 0.05752650648355484
Test Loss:  0.04642067104578018
Valid Loss:  0.05954115092754364
Epoch:  286  	Training Loss: 0.05748330429196358
Test Loss:  0.04638510197401047
Valid Loss:  0.05949440225958824
Epoch:  287  	Training Loss: 0.05744016543030739
Test Loss:  0.04634959623217583
Valid Loss:  0.0594477578997612
Epoch:  288  	Training Loss: 0.057397112250328064
Test Loss:  0.046314142644405365
Valid Loss:  0.059401191771030426
 58%|█████▊    | 289/500 [03:19<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:25<04:05,  1.18s/it] 59%|█████▊    | 293/500 [03:25<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:25<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:25<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:25<01:06,  3.01it/s] 60%|██████    | 301/500 [03:32<03:52,  1.17s/it] 61%|██████    | 303/500 [03:32<02:45,  1.19it/s] 61%|██████    | 305/500 [03:32<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:32<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:32<01:03,  3.03it/s] 62%|██████▏   | 311/500 [03:38<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:39<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:39<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:39<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:39<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:45<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:45<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:46<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:46<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:46<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:52<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:52<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:52<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:52<01:12,  2.23it/s] 68%|██████▊   | 339/500 [03:53<00:53,  3.00it/s] 68%|██████▊   | 341/500 [03:59<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:59<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:59<01:33,  1.65it/s] 69%|██████▉   | 347/500 [03:59<01:07,  2.25it/s] 70%|██████▉   | 349/500 [03:59<00:49,  3.03it/s] 70%|███████   | 351/500 [04:06<02:54,  1.17s/it] 71%|███████   | 353/500 [04:06<02:03,  1.19it/s] 71%|███████   | 355/500 [04:06<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:06<00:46,  3.02it/s]Epoch:  289  	Training Loss: 0.057354122400283813
Test Loss:  0.04627875238656998
Valid Loss:  0.05935471132397652
Epoch:  290  	Training Loss: 0.05731120705604553
Test Loss:  0.04624341055750847
Valid Loss:  0.05930831655859947
Epoch:  291  	Training Loss: 0.05726836249232292
Test Loss:  0.04620812088251114
Valid Loss:  0.0592619925737381
Epoch:  292  	Training Loss: 0.05722559243440628
Test Loss:  0.04617295786738396
Valid Loss:  0.059215858578681946
Epoch:  293  	Training Loss: 0.05718298256397247
Test Loss:  0.04613785445690155
Valid Loss:  0.05916980654001236
Epoch:  294  	Training Loss: 0.05714043974876404
Test Loss:  0.04610280320048332
Valid Loss:  0.05912383273243904
Epoch:  295  	Training Loss: 0.05709796026349068
Test Loss:  0.046067796647548676
Valid Loss:  0.05907793715596199
Epoch:  296  	Training Loss: 0.05705554783344269
Test Loss:  0.04603284224867821
Valid Loss:  0.059032127261161804
Epoch:  297  	Training Loss: 0.05701320990920067
Test Loss:  0.045997943729162216
Valid Loss:  0.05898639187216759
Epoch:  298  	Training Loss: 0.05697093531489372
Test Loss:  0.045963093638420105
Valid Loss:  0.058940738439559937
Epoch:  299  	Training Loss: 0.05692873150110245
Test Loss:  0.045928288251161575
Valid Loss:  0.05889516323804855
Epoch:  300  	Training Loss: 0.05688658729195595
Test Loss:  0.045893535017967224
Valid Loss:  0.05884965509176254
Epoch:  301  	Training Loss: 0.05684451013803482
Test Loss:  0.04585883021354675
Valid Loss:  0.0588042289018631
Epoch:  302  	Training Loss: 0.05680249631404877
Test Loss:  0.04582427442073822
Valid Loss:  0.058759018778800964
Epoch:  303  	Training Loss: 0.05676066130399704
Test Loss:  0.04578976333141327
Valid Loss:  0.0587138757109642
Epoch:  304  	Training Loss: 0.05671890079975128
Test Loss:  0.0457552969455719
Valid Loss:  0.05866881459951401
Epoch:  305  	Training Loss: 0.0566771999001503
Test Loss:  0.04572088271379471
Valid Loss:  0.058623816817998886
Epoch:  306  	Training Loss: 0.05663555860519409
Test Loss:  0.0456865131855011
Valid Loss:  0.05857890099287033
Epoch:  307  	Training Loss: 0.05659398064017296
Test Loss:  0.04565219581127167
Valid Loss:  0.058534055948257446
Epoch:  308  	Training Loss: 0.0565524697303772
Test Loss:  0.04561792314052582
Valid Loss:  0.05848928540945053
Epoch:  309  	Training Loss: 0.05651101469993591
Test Loss:  0.04558369144797325
Valid Loss:  0.058444589376449585
Epoch:  310  	Training Loss: 0.056469619274139404
Test Loss:  0.04554951190948486
Valid Loss:  0.05839996412396431
Epoch:  311  	Training Loss: 0.05642829090356827
Test Loss:  0.04551537334918976
Valid Loss:  0.058355413377285004
Epoch:  312  	Training Loss: 0.05638702213764191
Test Loss:  0.04548133909702301
Valid Loss:  0.058311015367507935
Epoch:  313  	Training Loss: 0.05634588748216629
Test Loss:  0.04544735699892044
Valid Loss:  0.058266688138246536
Epoch:  314  	Training Loss: 0.05630480870604515
Test Loss:  0.045413415879011154
Valid Loss:  0.05822243168950081
Epoch:  315  	Training Loss: 0.056263796985149384
Test Loss:  0.04537951573729515
Valid Loss:  0.05817825347185135
Epoch:  316  	Training Loss: 0.05622284114360809
Test Loss:  0.045345667749643326
Valid Loss:  0.058134131133556366
Epoch:  317  	Training Loss: 0.05618194490671158
Test Loss:  0.045311857014894485
Valid Loss:  0.05809009075164795
Epoch:  318  	Training Loss: 0.05614110082387924
Test Loss:  0.04527808725833893
Valid Loss:  0.05804610997438431
Epoch:  319  	Training Loss: 0.05610031634569168
Test Loss:  0.04524436220526695
Valid Loss:  0.05800219625234604
Epoch:  320  	Training Loss: 0.056059595197439194
Test Loss:  0.045210689306259155
Valid Loss:  0.05795835703611374
Epoch:  321  	Training Loss: 0.05601892247796059
Test Loss:  0.045177046209573746
Valid Loss:  0.057914577424526215
Epoch:  322  	Training Loss: 0.05597831308841705
Test Loss:  0.04514353722333908
Valid Loss:  0.05787099525332451
Epoch:  323  	Training Loss: 0.05593787133693695
Test Loss:  0.0451100617647171
Valid Loss:  0.05782746896147728
Epoch:  324  	Training Loss: 0.05589747428894043
Test Loss:  0.0450766384601593
Valid Loss:  0.057784005999565125
Epoch:  325  	Training Loss: 0.055857136845588684
Test Loss:  0.045043252408504486
Valid Loss:  0.05774062126874924
Epoch:  326  	Training Loss: 0.05581685155630112
Test Loss:  0.045009903609752655
Valid Loss:  0.05769728869199753
Epoch:  327  	Training Loss: 0.05577663332223892
Test Loss:  0.044976599514484406
Valid Loss:  0.057654038071632385
Epoch:  328  	Training Loss: 0.05573645606637001
Test Loss:  0.04494333639740944
Valid Loss:  0.05761083960533142
Epoch:  329  	Training Loss: 0.055696338415145874
Test Loss:  0.04491011053323746
Valid Loss:  0.05756770446896553
Epoch:  330  	Training Loss: 0.055656276643276215
Test Loss:  0.04487692564725876
Valid Loss:  0.05752463638782501
Epoch:  331  	Training Loss: 0.055616267025470734
Test Loss:  0.044843778014183044
Valid Loss:  0.05748163163661957
Epoch:  332  	Training Loss: 0.05557630583643913
Test Loss:  0.04481074959039688
Valid Loss:  0.05743880197405815
Epoch:  333  	Training Loss: 0.05553650110960007
Test Loss:  0.0447777695953846
Valid Loss:  0.05739603191614151
Epoch:  334  	Training Loss: 0.05549674853682518
Test Loss:  0.044744823127985
Valid Loss:  0.05735332518815994
Epoch:  335  	Training Loss: 0.05545705556869507
Test Loss:  0.044711917638778687
Valid Loss:  0.057310689240694046
Epoch:  336  	Training Loss: 0.05541740357875824
Test Loss:  0.04467904567718506
Valid Loss:  0.05726810544729233
Epoch:  337  	Training Loss: 0.055377811193466187
Test Loss:  0.044646210968494415
Valid Loss:  0.057225584983825684
Epoch:  338  	Training Loss: 0.055338263511657715
Test Loss:  0.044613417237997055
Valid Loss:  0.057183124125003815
Epoch:  339  	Training Loss: 0.05529877170920372
Test Loss:  0.04458066076040268
Valid Loss:  0.05714073032140732
Epoch:  340  	Training Loss: 0.055259332060813904
Test Loss:  0.04454794526100159
Valid Loss:  0.0570983849465847
Epoch:  341  	Training Loss: 0.05521994084119797
Test Loss:  0.04451526701450348
Valid Loss:  0.057056114077568054
Epoch:  342  	Training Loss: 0.05518060177564621
Test Loss:  0.04448269307613373
Valid Loss:  0.05701401084661484
Epoch:  343  	Training Loss: 0.05514140427112579
Test Loss:  0.044450171291828156
Valid Loss:  0.0569719597697258
Epoch:  344  	Training Loss: 0.05510226637125015
Test Loss:  0.04441767558455467
Valid Loss:  0.05692996457219124
Epoch:  345  	Training Loss: 0.05506317317485809
Test Loss:  0.044385217130184174
Valid Loss:  0.05688803270459175
Epoch:  346  	Training Loss: 0.055024128407239914
Test Loss:  0.04435279965400696
Valid Loss:  0.05684616416692734
Epoch:  347  	Training Loss: 0.05498513579368591
Test Loss:  0.04432041943073273
Valid Loss:  0.056804344058036804
Epoch:  348  	Training Loss: 0.054946184158325195
Test Loss:  0.044288065284490585
Valid Loss:  0.056762587279081345
Epoch:  349  	Training Loss: 0.05490728095173836
Test Loss:  0.04425574839115143
Valid Loss:  0.056720882654190063
Epoch:  350  	Training Loss: 0.0548684298992157
Test Loss:  0.044223468750715256
Valid Loss:  0.05667923390865326
Epoch:  351  	Training Loss: 0.05482962727546692
Test Loss:  0.04419122263789177
Valid Loss:  0.05663764476776123
Epoch:  352  	Training Loss: 0.05479086562991142
Test Loss:  0.04415908455848694
Valid Loss:  0.05659621208906174
Epoch:  353  	Training Loss: 0.05475224554538727
Test Loss:  0.044126980006694794
Valid Loss:  0.05655483156442642
Epoch:  354  	Training Loss: 0.054713670164346695
Test Loss:  0.044094912707805634
Valid Loss:  0.056513503193855286
Epoch:  355  	Training Loss: 0.0546751394867897
Test Loss:  0.04406287521123886
Valid Loss:  0.056472230702638626
Epoch:  356  	Training Loss: 0.05463665723800659
Test Loss:  0.04403087496757507
Valid Loss:  0.05643101781606674
Epoch:  357  	Training Loss: 0.05459821969270706
Test Loss:  0.043998900800943375
Valid Loss:  0.056389860808849335
Epoch:  358  	Training Loss: 0.05455983057618141
Test Loss:  0.04396697133779526
Valid Loss:  0.056348755955696106
Epoch:  359  	Training Loss: 0.054521478712558746
Test Loss:  0.04393506795167923
Valid Loss:  0.056307703256607056
Epoch:  360  	Training Loss: 0.05448317900300026
 72%|███████▏  | 361/500 [04:12<02:43,  1.17s/it] 73%|███████▎  | 363/500 [04:13<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:13<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:13<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:19<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:19<01:48,  1.18it/s] 75%|███████▌  | 375/500 [04:20<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:20<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:20<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:26<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:26<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:27<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:27<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:27<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:33<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:33<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:33<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:33<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:34<00:33,  2.98it/s] 80%|████████  | 401/500 [04:40<01:57,  1.18s/it] 81%|████████  | 403/500 [04:40<01:22,  1.18it/s] 81%|████████  | 405/500 [04:40<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:41<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:47<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:47<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:47<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:47<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:47<00:27,  2.97it/s] 84%|████████▍ | 421/500 [04:54<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:54<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:54<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:54<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:54<00:23,  3.00it/s]Test Loss:  0.043903201818466187
Valid Loss:  0.05626671016216278
Epoch:  361  	Training Loss: 0.05444492772221565
Test Loss:  0.04387136548757553
Valid Loss:  0.05622576177120209
Epoch:  362  	Training Loss: 0.05440671369433403
Test Loss:  0.04383964464068413
Valid Loss:  0.05618499219417572
Epoch:  363  	Training Loss: 0.05436865612864494
Test Loss:  0.04380796104669571
Valid Loss:  0.05614428222179413
Epoch:  364  	Training Loss: 0.05433064326643944
Test Loss:  0.04377630725502968
Valid Loss:  0.05610361695289612
Epoch:  365  	Training Loss: 0.05429267883300781
Test Loss:  0.04374469071626663
Valid Loss:  0.056063007563352585
Epoch:  366  	Training Loss: 0.05425474792718887
Test Loss:  0.043713100254535675
Valid Loss:  0.05602244287729263
Epoch:  367  	Training Loss: 0.05421687290072441
Test Loss:  0.043681550770998
Valid Loss:  0.05598193407058716
Epoch:  368  	Training Loss: 0.054179027676582336
Test Loss:  0.04365001991391182
Valid Loss:  0.05594148114323616
Epoch:  369  	Training Loss: 0.05414123088121414
Test Loss:  0.04361852630972862
Valid Loss:  0.05590106546878815
Epoch:  370  	Training Loss: 0.05410347878932953
Test Loss:  0.04358706623315811
Valid Loss:  0.05586071312427521
Epoch:  371  	Training Loss: 0.0540657676756382
Test Loss:  0.04355563595890999
Valid Loss:  0.05582040920853615
Epoch:  372  	Training Loss: 0.054028093814849854
Test Loss:  0.04352429881691933
Valid Loss:  0.05578024685382843
Epoch:  373  	Training Loss: 0.053990550339221954
Test Loss:  0.04349299520254135
Valid Loss:  0.05574013665318489
Epoch:  374  	Training Loss: 0.05395304784178734
Test Loss:  0.043461717665195465
Valid Loss:  0.05570007115602493
Epoch:  375  	Training Loss: 0.053915586322546005
Test Loss:  0.043430473655462265
Valid Loss:  0.055660050362348557
Epoch:  376  	Training Loss: 0.053878165781497955
Test Loss:  0.04339926689863205
Valid Loss:  0.055620089173316956
Epoch:  377  	Training Loss: 0.05384078621864319
Test Loss:  0.043368082493543625
Valid Loss:  0.055580176413059235
Epoch:  378  	Training Loss: 0.053803443908691406
Test Loss:  0.043336931616067886
Valid Loss:  0.055540312081575394
Epoch:  379  	Training Loss: 0.053766150027513504
Test Loss:  0.04330580681562424
Valid Loss:  0.055500492453575134
Epoch:  380  	Training Loss: 0.053728893399238586
Test Loss:  0.04327470809221268
Valid Loss:  0.055460721254348755
Epoch:  381  	Training Loss: 0.05369167774915695
Test Loss:  0.0432436466217041
Valid Loss:  0.05542099475860596
Epoch:  382  	Training Loss: 0.0536545068025589
Test Loss:  0.04321270436048508
Valid Loss:  0.055381450802087784
Epoch:  383  	Training Loss: 0.05361747369170189
Test Loss:  0.04318178445100784
Valid Loss:  0.055341936647892
Epoch:  384  	Training Loss: 0.05358048900961876
Test Loss:  0.043150894343853
Valid Loss:  0.05530247837305069
Epoch:  385  	Training Loss: 0.053543537855148315
Test Loss:  0.04312003031373024
Valid Loss:  0.05526307225227356
Epoch:  386  	Training Loss: 0.053506627678871155
Test Loss:  0.04308919981122017
Valid Loss:  0.055223703384399414
Epoch:  387  	Training Loss: 0.053469762206077576
Test Loss:  0.043058399111032486
Valid Loss:  0.05518438294529915
Epoch:  388  	Training Loss: 0.05343293398618698
Test Loss:  0.04302762448787689
Valid Loss:  0.055145107209682465
Epoch:  389  	Training Loss: 0.05339613929390907
Test Loss:  0.04299687594175339
Valid Loss:  0.05510587990283966
Epoch:  390  	Training Loss: 0.05335938557982445
Test Loss:  0.04296615719795227
Valid Loss:  0.055066704750061035
Epoch:  391  	Training Loss: 0.053322672843933105
Test Loss:  0.04293546825647354
Valid Loss:  0.055027566850185394
Epoch:  392  	Training Loss: 0.05328599363565445
Test Loss:  0.04290488362312317
Valid Loss:  0.054988596588373184
Epoch:  393  	Training Loss: 0.05324946343898773
Test Loss:  0.04287433624267578
Valid Loss:  0.05494966357946396
Epoch:  394  	Training Loss: 0.0532129630446434
Test Loss:  0.042843807488679886
Valid Loss:  0.05491077899932861
Epoch:  395  	Training Loss: 0.05317649990320206
Test Loss:  0.04281331226229668
Valid Loss:  0.054871946573257446
Epoch:  396  	Training Loss: 0.05314008146524429
Test Loss:  0.04278284311294556
Valid Loss:  0.05483314394950867
Epoch:  397  	Training Loss: 0.053103700280189514
Test Loss:  0.04275239631533623
Valid Loss:  0.05479438975453377
Epoch:  398  	Training Loss: 0.053067345172166824
Test Loss:  0.04272197559475899
Valid Loss:  0.05475568026304245
Epoch:  399  	Training Loss: 0.053031034767627716
Test Loss:  0.042691588401794434
Valid Loss:  0.054717015475034714
Epoch:  400  	Training Loss: 0.052994754165410995
Test Loss:  0.04266121983528137
Valid Loss:  0.05467839539051056
Epoch:  401  	Training Loss: 0.052958518266677856
Test Loss:  0.042630888521671295
Valid Loss:  0.054639823734760284
Epoch:  402  	Training Loss: 0.0529223196208477
Test Loss:  0.04260064661502838
Valid Loss:  0.054601382464170456
Epoch:  403  	Training Loss: 0.0528862327337265
Test Loss:  0.04257043078541756
Valid Loss:  0.05456298962235451
Epoch:  404  	Training Loss: 0.05285019427537918
Test Loss:  0.04254024475812912
Valid Loss:  0.054524634033441544
Epoch:  405  	Training Loss: 0.05281418561935425
Test Loss:  0.04251008480787277
Valid Loss:  0.05448632314801216
Epoch:  406  	Training Loss: 0.052778210490942
Test Loss:  0.042479947209358215
Valid Loss:  0.05444805324077606
Epoch:  407  	Training Loss: 0.05274227261543274
Test Loss:  0.04244983196258545
Valid Loss:  0.054409828037023544
Epoch:  408  	Training Loss: 0.05270636826753616
Test Loss:  0.04241974651813507
Valid Loss:  0.05437164008617401
Epoch:  409  	Training Loss: 0.05267050117254257
Test Loss:  0.04238969087600708
Valid Loss:  0.05433349311351776
Epoch:  410  	Training Loss: 0.05263466387987137
Test Loss:  0.04235966131091118
Valid Loss:  0.05429539829492569
Epoch:  411  	Training Loss: 0.052598871290683746
Test Loss:  0.04232965037226677
Valid Loss:  0.0542573407292366
Epoch:  412  	Training Loss: 0.05256311222910881
Test Loss:  0.04229975491762161
Valid Loss:  0.05421944707632065
Epoch:  413  	Training Loss: 0.05252748727798462
Test Loss:  0.04226988926529884
Valid Loss:  0.054181575775146484
Epoch:  414  	Training Loss: 0.05249190330505371
Test Loss:  0.04224003851413727
Valid Loss:  0.054143764078617096
Epoch:  415  	Training Loss: 0.05245635285973549
Test Loss:  0.04221022129058838
Valid Loss:  0.054105985909700394
Epoch:  416  	Training Loss: 0.05242083966732025
Test Loss:  0.042180418968200684
Valid Loss:  0.05406825244426727
Epoch:  417  	Training Loss: 0.0523853525519371
Test Loss:  0.042150650173425674
Valid Loss:  0.05403055250644684
Epoch:  418  	Training Loss: 0.05234989896416664
Test Loss:  0.04212091118097305
Valid Loss:  0.053992897272109985
Epoch:  419  	Training Loss: 0.05231448635458946
Test Loss:  0.04209118336439133
Valid Loss:  0.05395527929067612
Epoch:  420  	Training Loss: 0.05227910354733467
Test Loss:  0.042061492800712585
Valid Loss:  0.05391770601272583
Epoch:  421  	Training Loss: 0.052243754267692566
Test Loss:  0.04203181341290474
Valid Loss:  0.05388016998767853
Epoch:  422  	Training Loss: 0.052208442240953445
Test Loss:  0.04200225695967674
Valid Loss:  0.05384279787540436
Epoch:  423  	Training Loss: 0.05217326432466507
Test Loss:  0.041972722858190536
Valid Loss:  0.053805455565452576
Epoch:  424  	Training Loss: 0.05213812738656998
Test Loss:  0.04194321110844612
Valid Loss:  0.05376816540956497
Epoch:  425  	Training Loss: 0.05210302025079727
Test Loss:  0.0419137217104435
Valid Loss:  0.053730905055999756
Epoch:  426  	Training Loss: 0.052067942917346954
Test Loss:  0.04188425838947296
Valid Loss:  0.053693681955337524
Epoch:  427  	Training Loss: 0.05203290656208992
Test Loss:  0.04185481742024422
Valid Loss:  0.053656503558158875
Epoch:  428  	Training Loss: 0.051997896283864975
Test Loss:  0.04182540625333786
Valid Loss:  0.053619351238012314
Epoch:  429  	Training Loss: 0.051962919533252716
Test Loss:  0.041796013712882996
Valid Loss:  0.05358225852251053
Epoch:  430  	Training Loss: 0.05192798003554344
Test Loss:  0.04176664352416992
Valid Loss:  0.05354519188404083
Epoch:  431  	Training Loss: 0.05189306661486626
Test Loss:  0.041737303137779236
Valid Loss:   86%|████████▌ | 431/500 [05:00<01:20,  1.16s/it] 87%|████████▋ | 433/500 [05:01<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:01<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:01<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:01<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:07<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.16it/s] 89%|████████▉ | 445/500 [05:08<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:08<00:24,  2.20it/s] 90%|████████▉ | 449/500 [05:08<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:14<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:14<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:15<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:21<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:21<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:22<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:28<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:28<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:28<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:28<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:35<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:35<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:35<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:35<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:35<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:42<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:42<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:42<00:00,  3.03it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
0.05350816994905472
Epoch:  432  	Training Loss: 0.051858190447092056
Test Loss:  0.04170805960893631
Valid Loss:  0.053471289575099945
Epoch:  433  	Training Loss: 0.051823437213897705
Test Loss:  0.041678834706544876
Valid Loss:  0.05343443155288696
Epoch:  434  	Training Loss: 0.05178871005773544
Test Loss:  0.04164963960647583
Valid Loss:  0.05339762195944786
Epoch:  435  	Training Loss: 0.051754023879766464
Test Loss:  0.04162045568227768
Valid Loss:  0.053360842168331146
Epoch:  436  	Training Loss: 0.051719360053539276
Test Loss:  0.04159130901098251
Valid Loss:  0.053324103355407715
Epoch:  437  	Training Loss: 0.05168473348021507
Test Loss:  0.04156217724084854
Valid Loss:  0.053287409245967865
Epoch:  438  	Training Loss: 0.05165012925863266
Test Loss:  0.04153307154774666
Valid Loss:  0.0532507449388504
Epoch:  439  	Training Loss: 0.05161556601524353
Test Loss:  0.041503988206386566
Valid Loss:  0.05321411043405533
Epoch:  440  	Training Loss: 0.05158102884888649
Test Loss:  0.041474927216768265
Valid Loss:  0.05317751318216324
Epoch:  441  	Training Loss: 0.05154652148485184
Test Loss:  0.041445888578891754
Valid Loss:  0.053140971809625626
Epoch:  442  	Training Loss: 0.05151205509901047
Test Loss:  0.0414169505238533
Valid Loss:  0.05310456454753876
Epoch:  443  	Training Loss: 0.05147770792245865
Test Loss:  0.04138803854584694
Valid Loss:  0.053068190813064575
Epoch:  444  	Training Loss: 0.051443394273519516
Test Loss:  0.04135914891958237
Valid Loss:  0.053031858056783676
Epoch:  445  	Training Loss: 0.05140911415219307
Test Loss:  0.041330285370349884
Valid Loss:  0.05299555882811546
Epoch:  446  	Training Loss: 0.05137486010789871
Test Loss:  0.04130144417285919
Valid Loss:  0.052959296852350235
Epoch:  447  	Training Loss: 0.05134063959121704
Test Loss:  0.041272617876529694
Valid Loss:  0.05292306840419769
Epoch:  448  	Training Loss: 0.05130644887685776
Test Loss:  0.04124381020665169
Valid Loss:  0.05288686603307724
Epoch:  449  	Training Loss: 0.051272276788949966
Test Loss:  0.04121503233909607
Valid Loss:  0.05285071209073067
Epoch:  450  	Training Loss: 0.05123814940452576
Test Loss:  0.04118628054857254
Valid Loss:  0.05281459540128708
Epoch:  451  	Training Loss: 0.051204048097133636
Test Loss:  0.041157543659210205
Valid Loss:  0.05277851223945618
Epoch:  452  	Training Loss: 0.051169976592063904
Test Loss:  0.04112892597913742
Valid Loss:  0.052742574363946915
Epoch:  453  	Training Loss: 0.051136039197444916
Test Loss:  0.04110031574964523
Valid Loss:  0.05270667374134064
Epoch:  454  	Training Loss: 0.05110213905572891
Test Loss:  0.04107173532247543
Valid Loss:  0.05267081409692764
Epoch:  455  	Training Loss: 0.0510682538151741
Test Loss:  0.041043173521757126
Valid Loss:  0.05263498052954674
Epoch:  456  	Training Loss: 0.05103441700339317
Test Loss:  0.04101463779807091
Valid Loss:  0.05259918421506882
Epoch:  457  	Training Loss: 0.05100059509277344
Test Loss:  0.04098612070083618
Valid Loss:  0.05256342887878418
Epoch:  458  	Training Loss: 0.05096680670976639
Test Loss:  0.040957625955343246
Valid Loss:  0.05252770334482193
Epoch:  459  	Training Loss: 0.050933048129081726
Test Loss:  0.0409291535615921
Valid Loss:  0.052492011338472366
Epoch:  460  	Training Loss: 0.050899311900138855
Test Loss:  0.04090069979429245
Valid Loss:  0.05245634913444519
Epoch:  461  	Training Loss: 0.05086561292409897
Test Loss:  0.040872275829315186
Valid Loss:  0.0524207279086113
Epoch:  462  	Training Loss: 0.05083194747567177
Test Loss:  0.040843941271305084
Valid Loss:  0.05238524079322815
Epoch:  463  	Training Loss: 0.05079839378595352
Test Loss:  0.040815625339746475
Valid Loss:  0.052349794656038284
Epoch:  464  	Training Loss: 0.05076486989855766
Test Loss:  0.04078733175992966
Valid Loss:  0.05231437087059021
Epoch:  465  	Training Loss: 0.05073137208819389
Test Loss:  0.040759067982435226
Valid Loss:  0.05227898433804512
Epoch:  466  	Training Loss: 0.05069790780544281
Test Loss:  0.04073081910610199
Valid Loss:  0.05224362388253212
Epoch:  467  	Training Loss: 0.05066446587443352
Test Loss:  0.040702588856220245
Valid Loss:  0.052208300679922104
Epoch:  468  	Training Loss: 0.05063105374574661
Test Loss:  0.04067438095808029
Valid Loss:  0.05217301473021507
Epoch:  469  	Training Loss: 0.050597675144672394
Test Loss:  0.04064619541168213
Valid Loss:  0.05213776230812073
Epoch:  470  	Training Loss: 0.050564318895339966
Test Loss:  0.040618035942316055
Valid Loss:  0.05210254341363907
Epoch:  471  	Training Loss: 0.050530996173620224
Test Loss:  0.040589891374111176
Valid Loss:  0.0520673543214798
Epoch:  472  	Training Loss: 0.05049770325422287
Test Loss:  0.040561847388744354
Valid Loss:  0.05203229933977127
Epoch:  473  	Training Loss: 0.050464529544115067
Test Loss:  0.040533825755119324
Valid Loss:  0.051997289061546326
Epoch:  474  	Training Loss: 0.05043138563632965
Test Loss:  0.040505822747945786
Valid Loss:  0.05196230113506317
Epoch:  475  	Training Loss: 0.050398267805576324
Test Loss:  0.04047784209251404
Valid Loss:  0.051927350461483
Epoch:  476  	Training Loss: 0.050365179777145386
Test Loss:  0.04044988006353378
Valid Loss:  0.05189242959022522
Epoch:  477  	Training Loss: 0.05033211410045624
Test Loss:  0.04042194038629532
Valid Loss:  0.051857542246580124
Epoch:  478  	Training Loss: 0.050299081951379776
Test Loss:  0.040394026786088943
Valid Loss:  0.051822684705257416
Epoch:  479  	Training Loss: 0.0502660758793354
Test Loss:  0.04036612808704376
Valid Loss:  0.05178786814212799
Epoch:  480  	Training Loss: 0.05023309215903282
Test Loss:  0.04033824801445007
Valid Loss:  0.05175306648015976
Epoch:  481  	Training Loss: 0.050200145691633224
Test Loss:  0.040310390293598175
Valid Loss:  0.05171830579638481
Epoch:  482  	Training Loss: 0.05016721412539482
Test Loss:  0.04028262943029404
Valid Loss:  0.051683686673641205
Epoch:  483  	Training Loss: 0.050134409219026566
Test Loss:  0.04025489091873169
Valid Loss:  0.05164908617734909
Epoch:  484  	Training Loss: 0.0501016303896904
Test Loss:  0.040227167308330536
Valid Loss:  0.05161452665925026
Epoch:  485  	Training Loss: 0.05006888136267662
Test Loss:  0.04019947350025177
Valid Loss:  0.051580000668764114
Epoch:  486  	Training Loss: 0.05003616213798523
Test Loss:  0.0401717945933342
Valid Loss:  0.05154550075531006
Epoch:  487  	Training Loss: 0.05000346899032593
Test Loss:  0.04014413431286812
Valid Loss:  0.05151103436946869
Epoch:  488  	Training Loss: 0.04997079819440842
Test Loss:  0.04011649638414383
Valid Loss:  0.05147659033536911
Epoch:  489  	Training Loss: 0.049938153475522995
Test Loss:  0.04008887708187103
Valid Loss:  0.05144219100475311
Epoch:  490  	Training Loss: 0.04990553855895996
Test Loss:  0.04006127640604973
Valid Loss:  0.051407814025878906
Epoch:  491  	Training Loss: 0.049872949719429016
Test Loss:  0.04003370180726051
Valid Loss:  0.05137346684932709
Epoch:  492  	Training Loss: 0.04984038323163986
Test Loss:  0.04000622779130936
Valid Loss:  0.051339272409677505
Epoch:  493  	Training Loss: 0.049807947129011154
Test Loss:  0.039978768676519394
Valid Loss:  0.05130510777235031
Epoch:  494  	Training Loss: 0.049775540828704834
Test Loss:  0.03995133936405182
Valid Loss:  0.05127096176147461
Epoch:  495  	Training Loss: 0.0497431606054306
Test Loss:  0.03992392122745514
Valid Loss:  0.05123685300350189
Epoch:  496  	Training Loss: 0.04971080645918846
Test Loss:  0.03989652544260025
Valid Loss:  0.05120277404785156
Epoch:  497  	Training Loss: 0.04967847466468811
Test Loss:  0.03986915200948715
Valid Loss:  0.05116873234510422
Epoch:  498  	Training Loss: 0.04964616894721985
Test Loss:  0.039841797202825546
Valid Loss:  0.05113471299409866
Epoch:  499  	Training Loss: 0.049613893032073975
Test Loss:  0.039814457297325134
Valid Loss:  0.0511007234454155
Epoch:  500  	Training Loss: 0.04958163946866989
Test Loss:  0.03978714346885681
Valid Loss:  0.05106675624847412
seed is  13
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:55,  6.24s/it]  1%|          | 3/500 [00:06<13:50,  1.67s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:56,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:37,  3.00it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:27<04:42,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:59,  1.17s/it]  9%|▊         | 43/500 [00:33<06:24,  1.19it/s]  9%|▉         | 45/500 [00:39<11:30,  1.52s/it]  9%|▉         | 47/500 [00:40<08:10,  1.08s/it] 10%|▉         | 49/500 [00:40<05:51,  1.28it/s] 10%|█         | 51/500 [00:46<11:10,  1.49s/it] 11%|█         | 53/500 [00:46<07:56,  1.07s/it] 11%|█         | 55/500 [00:46<05:40,  1.31it/s] 11%|█▏        | 57/500 [00:46<04:06,  1.80it/s] 12%|█▏        | 59/500 [00:47<03:00,  2.44it/s] 12%|█▏        | 61/500 [00:53<08:55,  1.22s/it] 13%|█▎        | 63/500 [00:53<06:22,  1.14it/s] 13%|█▎        | 65/500 [00:53<04:34,  1.58it/s] 13%|█▎        | 67/500 [00:53<03:20,  2.16it/s] 14%|█▍        | 69/500 [00:53<02:28,  2.91it/s] 14%|█▍        | 71/500 [01:00<08:27,  1.18s/it]Epoch:  1  	Training Loss: 0.049283869564533234
Test Loss:  3.361536979675293
Valid Loss:  3.28423810005188
Epoch:  2  	Training Loss: 3.3046202659606934
Test Loss:  892.205322265625
Valid Loss:  906.001220703125
Epoch:  3  	Training Loss: 902.6614379882812
Test Loss:  0.11979684978723526
Valid Loss:  0.14688462018966675
Epoch:  4  	Training Loss: 0.13937625288963318
Test Loss:  1.4491071701049805
Valid Loss:  1.422328233718872
Epoch:  5  	Training Loss: 1.4378730058670044
Test Loss:  1.5593438148498535
Valid Loss:  1.6199253797531128
Epoch:  6  	Training Loss: 1.5986695289611816
Test Loss:  1.5593100786209106
Valid Loss:  1.619889736175537
Epoch:  7  	Training Loss: 1.5986344814300537
Test Loss:  1.5592764616012573
Valid Loss:  1.6198539733886719
Epoch:  8  	Training Loss: 1.5985994338989258
Test Loss:  1.5592427253723145
Valid Loss:  1.6198179721832275
Epoch:  9  	Training Loss: 1.5985643863677979
Test Loss:  1.5592089891433716
Valid Loss:  1.6197820901870728
Epoch:  10  	Training Loss: 1.5985294580459595
Test Loss:  1.5591751337051392
Valid Loss:  1.619746208190918
Epoch:  11  	Training Loss: 1.5984944105148315
Test Loss:  1.5591410398483276
Valid Loss:  1.6197103261947632
Epoch:  12  	Training Loss: 1.598459243774414
Test Loss:  88.39717102050781
Valid Loss:  88.76699829101562
Epoch:  13  	Training Loss: 88.70262145996094
Test Loss:  0.47045841813087463
Valid Loss:  0.5701509118080139
Epoch:  14  	Training Loss: 0.548743486404419
Test Loss:  0.4650340676307678
Valid Loss:  0.5638084411621094
Epoch:  15  	Training Loss: 0.542671799659729
Test Loss:  0.4594353139400482
Valid Loss:  0.557772696018219
Epoch:  16  	Training Loss: 0.5365874767303467
Test Loss:  0.45352572202682495
Valid Loss:  0.5517688989639282
Epoch:  17  	Training Loss: 0.5303978323936462
Test Loss:  0.44780898094177246
Valid Loss:  0.5459498167037964
Epoch:  18  	Training Loss: 0.5244143009185791
Test Loss:  0.44228920340538025
Valid Loss:  0.540314793586731
Epoch:  19  	Training Loss: 0.5186610221862793
Test Loss:  0.4369824230670929
Valid Loss:  0.5349249243736267
Epoch:  20  	Training Loss: 0.5131078958511353
Test Loss:  0.4318159222602844
Valid Loss:  0.5297101140022278
Epoch:  21  	Training Loss: 0.5077284574508667
Test Loss:  0.42674720287323
Valid Loss:  0.5245735049247742
Epoch:  22  	Training Loss: 0.502479076385498
Test Loss:  45.41947937011719
Valid Loss:  46.396202087402344
Epoch:  23  	Training Loss: 46.09074401855469
Test Loss:  0.10892599076032639
Valid Loss:  0.15480902791023254
Epoch:  24  	Training Loss: 0.14681482315063477
Test Loss:  0.10891769826412201
Valid Loss:  0.15477615594863892
Epoch:  25  	Training Loss: 0.14678403735160828
Test Loss:  0.10888926684856415
Valid Loss:  0.15469437837600708
Epoch:  26  	Training Loss: 0.1467159539461136
Test Loss:  0.10880692303180695
Valid Loss:  0.15456601977348328
Epoch:  27  	Training Loss: 0.1465800404548645
Test Loss:  0.10865221917629242
Valid Loss:  0.15436527132987976
Epoch:  28  	Training Loss: 0.14637738466262817
Test Loss:  0.10839292407035828
Valid Loss:  0.15403074026107788
Epoch:  29  	Training Loss: 0.1460573673248291
Test Loss:  0.1080249473452568
Valid Loss:  0.15356341004371643
Epoch:  30  	Training Loss: 0.14563027024269104
Test Loss:  0.10759977251291275
Valid Loss:  0.1530241221189499
Epoch:  31  	Training Loss: 0.14512580633163452
Test Loss:  0.10714076459407806
Valid Loss:  0.1524355113506317
Epoch:  32  	Training Loss: 0.14456918835639954
Test Loss:  0.09960481524467468
Valid Loss:  0.14441043138504028
Epoch:  33  	Training Loss: 0.13671986758708954
Test Loss:  0.09656314551830292
Valid Loss:  0.14108094573020935
Epoch:  34  	Training Loss: 0.13345816731452942
Test Loss:  0.09406496584415436
Valid Loss:  0.13827642798423767
Epoch:  35  	Training Loss: 0.13072843849658966
Test Loss:  0.09202259033918381
Valid Loss:  0.1358984410762787
Epoch:  36  	Training Loss: 0.1284250020980835
Test Loss:  0.09037123620510101
Valid Loss:  0.13386525213718414
Epoch:  37  	Training Loss: 0.12646137177944183
Test Loss:  0.0890321135520935
Valid Loss:  0.13211172819137573
Epoch:  38  	Training Loss: 0.12477502226829529
Test Loss:  0.08790887892246246
Valid Loss:  0.13057570159435272
Epoch:  39  	Training Loss: 0.12331487238407135
Test Loss:  0.08695493638515472
Valid Loss:  0.12921762466430664
Epoch:  40  	Training Loss: 0.12203185260295868
Test Loss:  0.08613325655460358
Valid Loss:  0.12800663709640503
Epoch:  41  	Training Loss: 0.12089000642299652
Test Loss:  0.08541563898324966
Valid Loss:  0.12691722810268402
Epoch:  42  	Training Loss: 0.11986308544874191
Test Loss:  0.770237386226654
Valid Loss:  0.7536163330078125
Epoch:  43  	Training Loss: 0.7620919942855835
Test Loss:  0.025353770703077316
Valid Loss:  0.028351133689284325
Epoch:  44  	Training Loss: 0.029338516294956207
Test Loss:  0.02522376924753189
Valid Loss:  0.028286349028348923
Epoch:  45  	Training Loss: 0.029255248606204987
Test Loss:  0.025124438107013702
Valid Loss:  0.028235435485839844
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.029194019734859467
Test Loss:  0.02283484861254692
Valid Loss:  0.02482370287179947
Epoch:  47  	Training Loss: 0.025650277733802795
Test Loss:  0.019133150577545166
Valid Loss:  0.019587770104408264
Epoch:  48  	Training Loss: 0.020375575870275497
Test Loss:  0.0165744386613369
Valid Loss:  0.015856558457016945
Epoch:  49  	Training Loss: 0.016834253445267677
Test Loss:  0.016382522881031036
Valid Loss:  0.015400877222418785
Epoch:  50  	Training Loss: 0.01643229089677334
Test Loss:  0.016350869089365005
Valid Loss:  0.015151896513998508
Epoch:  51  	Training Loss: 0.016182206571102142
Test Loss:  0.016288133338093758
Valid Loss:  0.014892577193677425
Epoch:  52  	Training Loss: 0.015955403447151184
Test Loss:  0.011282986029982567
Valid Loss:  0.011507111601531506
Epoch:  53  	Training Loss: 0.011871487833559513
Test Loss:  0.010985108092427254
Valid Loss:  0.010195484384894371
Epoch:  54  	Training Loss: 0.010923555120825768
Test Loss:  0.01064746268093586
Valid Loss:  0.009095707908272743
Epoch:  55  	Training Loss: 0.010122468695044518
Test Loss:  0.009965356439352036
Valid Loss:  0.008096141740679741
Epoch:  56  	Training Loss: 0.009112656116485596
Test Loss:  0.009306761436164379
Valid Loss:  0.0073394267819821835
Epoch:  57  	Training Loss: 0.008080406114459038
Test Loss:  0.008576126769185066
Valid Loss:  0.006872747093439102
Epoch:  58  	Training Loss: 0.007302143611013889
Test Loss:  0.008035034872591496
Valid Loss:  0.006684719584882259
Epoch:  59  	Training Loss: 0.006875911727547646
Test Loss:  0.007627855055034161
Valid Loss:  0.0064729489386081696
Epoch:  60  	Training Loss: 0.0064834244549274445
Test Loss:  0.007226085290312767
Valid Loss:  0.006318203639239073
Epoch:  61  	Training Loss: 0.006172084715217352
Test Loss:  0.006927252747118473
Valid Loss:  0.006276403553783894
Epoch:  62  	Training Loss: 0.005979666952043772
Test Loss:  0.005552995949983597
Valid Loss:  0.005597930867224932
Epoch:  63  	Training Loss: 0.004841400310397148
Test Loss:  0.0044563026167452335
Valid Loss:  0.004890747833997011
Epoch:  64  	Training Loss: 0.004387323744595051
Test Loss:  0.00466940738260746
Valid Loss:  0.004939725622534752
Epoch:  65  	Training Loss: 0.004354290664196014
Test Loss:  0.004576897248625755
Valid Loss:  0.004824159201234579
Epoch:  66  	Training Loss: 0.004308231640607119
Test Loss:  0.004650759045034647
Valid Loss:  0.004820715170353651
Epoch:  67  	Training Loss: 0.00428391620516777
Test Loss:  0.004608946852385998
Valid Loss:  0.004760428331792355
Epoch:  68  	Training Loss: 0.004253465682268143
Test Loss:  0.004637676291167736
Valid Loss:  0.004752530716359615
Epoch:  69  	Training Loss: 0.004224455915391445
Test Loss:  0.0045934272930026054
Valid Loss:  0.00469962228089571
Epoch:  70  	Training Loss: 0.004184773191809654
Test Loss:  0.004600473679602146
Valid Loss:  0.00468450877815485
Epoch:  71  	Training Loss: 0.00413911510258913
Test Loss:  0.004553024657070637
Valid Loss:  0.004626821726560593
Epoch:  72  	Training Loss: 0.004093273542821407
Test Loss:   15%|█▍        | 73/500 [01:00<06:02,  1.18it/s] 15%|█▌        | 75/500 [01:00<04:20,  1.63it/s] 15%|█▌        | 77/500 [01:00<03:09,  2.23it/s] 16%|█▌        | 79/500 [01:00<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:06<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:06<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:07<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:07<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:07<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:13<07:57,  1.17s/it] 19%|█▊        | 93/500 [01:13<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:13<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:13<02:58,  2.25it/s] 20%|█▉        | 99/500 [01:14<02:12,  3.03it/s] 20%|██        | 101/500 [01:20<07:44,  1.16s/it] 21%|██        | 103/500 [01:20<05:31,  1.20it/s] 21%|██        | 105/500 [01:20<03:58,  1.65it/s] 21%|██▏       | 107/500 [01:20<02:53,  2.26it/s] 22%|██▏       | 109/500 [01:20<02:08,  3.04it/s] 22%|██▏       | 109/500 [01:31<02:08,  3.04it/s] 22%|██▏       | 111/500 [01:33<13:32,  2.09s/it] 23%|██▎       | 113/500 [01:33<09:33,  1.48s/it] 23%|██▎       | 115/500 [01:33<06:46,  1.06s/it] 23%|██▎       | 117/500 [01:33<04:50,  1.32it/s] 24%|██▍       | 119/500 [01:33<03:29,  1.82it/s] 24%|██▍       | 121/500 [01:40<08:20,  1.32s/it] 25%|██▍       | 123/500 [01:40<05:56,  1.06it/s] 25%|██▌       | 125/500 [01:40<04:15,  1.47it/s] 25%|██▌       | 127/500 [01:40<03:05,  2.02it/s] 26%|██▌       | 129/500 [01:40<02:16,  2.73it/s] 26%|██▌       | 131/500 [01:46<07:23,  1.20s/it] 27%|██▋       | 133/500 [01:46<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:47<03:47,  1.61it/s] 27%|██▋       | 137/500 [01:47<02:45,  2.20it/s] 28%|██▊       | 139/500 [01:47<02:01,  2.96it/s]0.00398055836558342
Valid Loss:  0.0041894083842635155
Epoch:  73  	Training Loss: 0.0035576189402490854
Test Loss:  0.003758923150599003
Valid Loss:  0.004007341340184212
Epoch:  74  	Training Loss: 0.003341429168358445
Test Loss:  0.0036457234527915716
Valid Loss:  0.003904166165739298
Epoch:  75  	Training Loss: 0.0032316367141902447
Test Loss:  0.003572330344468355
Valid Loss:  0.0038221694994717836
Epoch:  76  	Training Loss: 0.003155626356601715
Test Loss:  0.003519318765029311
Valid Loss:  0.00375385326333344
Epoch:  77  	Training Loss: 0.0030970685184001923
Test Loss:  0.0034768343903124332
Valid Loss:  0.0036937412805855274
Epoch:  78  	Training Loss: 0.0030500665307044983
Test Loss:  0.003442431101575494
Valid Loss:  0.0036469106562435627
Epoch:  79  	Training Loss: 0.003013474401086569
Test Loss:  0.0034119258634746075
Valid Loss:  0.0036150780506432056
Epoch:  80  	Training Loss: 0.002983629936352372
Test Loss:  0.0033931536599993706
Valid Loss:  0.003584120888262987
Epoch:  81  	Training Loss: 0.002960626967251301
Test Loss:  0.0033688426483422518
Valid Loss:  0.0035640636924654245
Epoch:  82  	Training Loss: 0.0029403911903500557
Test Loss:  0.003355464432388544
Valid Loss:  0.003525766311213374
Epoch:  83  	Training Loss: 0.0029015468899160624
Test Loss:  0.0033501810394227505
Valid Loss:  0.0035040145739912987
Epoch:  84  	Training Loss: 0.0028801686130464077
Test Loss:  0.0033495633397251368
Valid Loss:  0.003495619399473071
Epoch:  85  	Training Loss: 0.002868498908355832
Test Loss:  0.003348576370626688
Valid Loss:  0.003491184674203396
Epoch:  86  	Training Loss: 0.002863492351025343
Test Loss:  0.00334762642160058
Valid Loss:  0.00348803773522377
Epoch:  87  	Training Loss: 0.0028605267871171236
Test Loss:  0.0033467125613242388
Valid Loss:  0.0034855534322559834
Epoch:  88  	Training Loss: 0.002858135849237442
Test Loss:  0.003345825709402561
Valid Loss:  0.003483653999865055
Epoch:  89  	Training Loss: 0.0028561356011778116
Test Loss:  0.0033449754118919373
Valid Loss:  0.003481901716440916
Epoch:  90  	Training Loss: 0.00285435002297163
Test Loss:  0.00334415421821177
Valid Loss:  0.0034802837762981653
Epoch:  91  	Training Loss: 0.0028527528047561646
Test Loss:  0.0033433581702411175
Valid Loss:  0.0034787615295499563
Epoch:  92  	Training Loss: 0.0028512426652014256
Test Loss:  0.0025744992308318615
Valid Loss:  0.002802876755595207
Epoch:  93  	Training Loss: 0.0023448988795280457
Test Loss:  0.00237080967053771
Valid Loss:  0.0025886581279337406
Epoch:  94  	Training Loss: 0.0021584557835012674
Test Loss:  0.0022147363051772118
Valid Loss:  0.0024243826046586037
Epoch:  95  	Training Loss: 0.0020276536233723164
Test Loss:  0.002120452467352152
Valid Loss:  0.0023341141641139984
Epoch:  96  	Training Loss: 0.0019594235345721245
Test Loss:  0.0020642976742237806
Valid Loss:  0.0022684428840875626
Epoch:  97  	Training Loss: 0.0019120043143630028
Test Loss:  0.00202201004140079
Valid Loss:  0.0022171535529196262
Epoch:  98  	Training Loss: 0.0018773374613374472
Test Loss:  0.0019953076262027025
Valid Loss:  0.0021746547427028418
Epoch:  99  	Training Loss: 0.0018492215313017368
Test Loss:  0.0019762571901082993
Valid Loss:  0.0021377005614340305
Epoch:  100  	Training Loss: 0.001825972693040967
Test Loss:  0.0019503775984048843
Valid Loss:  0.0021094733383506536
Epoch:  101  	Training Loss: 0.0018074377439916134
Test Loss:  0.0019348934292793274
Valid Loss:  0.0020864021498709917
Epoch:  102  	Training Loss: 0.0017918142257258296
Test Loss:  0.0017603980377316475
Valid Loss:  0.0019787754863500595
Epoch:  103  	Training Loss: 0.0017706284997984767
Test Loss:  0.0021718298085033894
Valid Loss:  0.002172218170017004
Epoch:  104  	Training Loss: 0.0018307508435100317
Test Loss:  0.0018539831507951021
Valid Loss:  0.0021699825301766396
Epoch:  105  	Training Loss: 0.0021144566126167774
Test Loss:  0.003367241472005844
Valid Loss:  0.003243494313210249
Epoch:  106  	Training Loss: 0.0027176346629858017
Test Loss:  0.002312498865649104
Valid Loss:  0.0026368326507508755
Epoch:  107  	Training Loss: 0.002622963162139058
Test Loss:  0.002250509802252054
Valid Loss:  0.002489102305844426
Epoch:  108  	Training Loss: 0.002491886494681239
Test Loss:  0.002226437907665968
Valid Loss:  0.0024130085948854685
Epoch:  109  	Training Loss: 0.0024241479113698006
Test Loss:  0.002204079646617174
Valid Loss:  0.002368195913732052
Epoch:  110  	Training Loss: 0.002382235135883093
Test Loss:  0.0021842592395842075
Valid Loss:  0.0023353425785899162
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0023494369816035032
Test Loss:  0.002181926742196083
Valid Loss:  0.0023313157726079226
Epoch:  112  	Training Loss: 0.0023459112271666527
Test Loss:  0.001997739775106311
Valid Loss:  0.002091999165713787
Epoch:  113  	Training Loss: 0.0019923322834074497
Test Loss:  0.0019924973603338003
Valid Loss:  0.002088540233671665
Epoch:  114  	Training Loss: 0.0019742900040000677
Test Loss:  0.001976244617253542
Valid Loss:  0.002080586040392518
Epoch:  115  	Training Loss: 0.001964772352948785
Test Loss:  0.001968180062249303
Valid Loss:  0.0020788698457181454
Epoch:  116  	Training Loss: 0.0019603241235017776
Test Loss:  0.0019629322923719883
Valid Loss:  0.002076943637803197
Epoch:  117  	Training Loss: 0.0019582733511924744
Test Loss:  0.001959634944796562
Valid Loss:  0.002075855853036046
Epoch:  118  	Training Loss: 0.001956544816493988
Test Loss:  0.001957143424078822
Valid Loss:  0.002075173193588853
Epoch:  119  	Training Loss: 0.0019548828713595867
Test Loss:  0.001953638158738613
Valid Loss:  0.002072869101539254
Epoch:  120  	Training Loss: 0.0019532907754182816
Test Loss:  0.0019522004295140505
Valid Loss:  0.0020728646777570248
Epoch:  121  	Training Loss: 0.0019517280161380768
Test Loss:  0.0019504425581544638
Valid Loss:  0.0020725023932754993
Epoch:  122  	Training Loss: 0.001950215664692223
Test Loss:  0.0019435909343883395
Valid Loss:  0.0020644343458116055
Epoch:  123  	Training Loss: 0.001930464175529778
Test Loss:  0.0019425047794356942
Valid Loss:  0.002062893472611904
Epoch:  124  	Training Loss: 0.0019223985727876425
Test Loss:  0.0019441343611106277
Valid Loss:  0.002063504420220852
Epoch:  125  	Training Loss: 0.001918817637488246
Test Loss:  0.0019459942122921348
Valid Loss:  0.0020640261936932802
Epoch:  126  	Training Loss: 0.0019167166901752353
Test Loss:  0.001946594682522118
Valid Loss:  0.0020638657733798027
Epoch:  127  	Training Loss: 0.001915787230245769
Test Loss:  0.001947205513715744
Valid Loss:  0.00206352723762393
Epoch:  128  	Training Loss: 0.001915148925036192
Test Loss:  0.0019477747846394777
Valid Loss:  0.002063294406980276
Epoch:  129  	Training Loss: 0.0019145559053868055
Test Loss:  0.0019478746689856052
Valid Loss:  0.002062888815999031
Epoch:  130  	Training Loss: 0.001914014108479023
Test Loss:  0.001947955577634275
Valid Loss:  0.0020624827593564987
Epoch:  131  	Training Loss: 0.0019134816247969866
Test Loss:  0.001948019489645958
Valid Loss:  0.002062077634036541
Epoch:  132  	Training Loss: 0.001912960084155202
Test Loss:  0.0018174967262893915
Valid Loss:  0.0019373283721506596
Epoch:  133  	Training Loss: 0.0017617081757634878
Test Loss:  0.001733466750010848
Valid Loss:  0.0018539049196988344
Epoch:  134  	Training Loss: 0.001657605404034257
Test Loss:  0.0016804265324026346
Valid Loss:  0.0017984907608479261
Epoch:  135  	Training Loss: 0.0015859378036111593
Test Loss:  0.0016478800680488348
Valid Loss:  0.0017619977006688714
Epoch:  136  	Training Loss: 0.001536583062261343
Test Loss:  0.001628751982934773
Valid Loss:  0.00173823325894773
Epoch:  137  	Training Loss: 0.0015025788452476263
Test Loss:  0.0016182861290872097
Valid Loss:  0.00172298529651016
Epoch:  138  	Training Loss: 0.0014791355933994055
Test Loss:  0.001613310188986361
Valid Loss:  0.0017133989604189992
Epoch:  139  	Training Loss: 0.001462958287447691
Test Loss:  0.0016117229824885726
Valid Loss:  0.0017075433861464262
Epoch:  140  	Training Loss: 0.0014517795061692595
Test Loss:  0.0016121419612318277
Valid Loss:   28%|██▊       | 141/500 [01:53<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:53<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:53<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:53<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:54<01:56,  3.02it/s] 30%|███       | 151/500 [02:00<06:51,  1.18s/it] 31%|███       | 153/500 [02:00<04:53,  1.18it/s] 31%|███       | 155/500 [02:00<03:31,  1.63it/s] 31%|███▏      | 157/500 [02:00<02:33,  2.23it/s] 32%|███▏      | 159/500 [02:00<01:53,  3.01it/s] 32%|███▏      | 161/500 [02:07<06:36,  1.17s/it] 33%|███▎      | 163/500 [02:07<04:43,  1.19it/s] 33%|███▎      | 165/500 [02:07<03:23,  1.64it/s] 33%|███▎      | 167/500 [02:07<02:28,  2.25it/s] 34%|███▍      | 169/500 [02:07<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:14<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:14<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:14<03:17,  1.65it/s] 35%|███▌      | 177/500 [02:14<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:14<01:46,  3.03it/s] 36%|███▌      | 181/500 [02:20<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:20<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:21<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:21<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:21<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:27<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:27<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:27<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:28<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:28<01:40,  3.01it/s] 40%|████      | 201/500 [02:34<05:50,  1.17s/it] 41%|████      | 203/500 [02:34<04:10,  1.19it/s] 41%|████      | 205/500 [02:34<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:34<02:10,  2.24it/s]0.0017041144892573357
Epoch:  141  	Training Loss: 0.0014440397499129176
Test Loss:  0.0016136731719598174
Valid Loss:  0.0017022460233420134
Epoch:  142  	Training Loss: 0.0014386654365807772
Test Loss:  0.0016127405688166618
Valid Loss:  0.0017020421801134944
Epoch:  143  	Training Loss: 0.0014382576337084174
Test Loss:  0.0016118788626044989
Valid Loss:  0.0017018631333485246
Epoch:  144  	Training Loss: 0.0014378924388438463
Test Loss:  0.001611234387382865
Valid Loss:  0.0017017049249261618
Epoch:  145  	Training Loss: 0.0014375657774508
Test Loss:  0.0016109156422317028
Valid Loss:  0.0017015656922012568
Epoch:  146  	Training Loss: 0.0014372719451785088
Test Loss:  0.0016106206458061934
Valid Loss:  0.0017014392651617527
Epoch:  147  	Training Loss: 0.0014370371354743838
Test Loss:  0.0016104206442832947
Valid Loss:  0.0017013183096423745
Epoch:  148  	Training Loss: 0.0014369215350598097
Test Loss:  0.0016102285590022802
Valid Loss:  0.0017011999152600765
Epoch:  149  	Training Loss: 0.0014368118718266487
Test Loss:  0.0016100427601486444
Valid Loss:  0.0017010847805067897
Epoch:  150  	Training Loss: 0.0014367061667144299
Test Loss:  0.001609863480553031
Valid Loss:  0.0017009701114147902
Epoch:  151  	Training Loss: 0.0014366256073117256
Test Loss:  0.0016097574261948466
Valid Loss:  0.0017008442664518952
Epoch:  152  	Training Loss: 0.0014365490060299635
Test Loss:  0.0015460881404578686
Valid Loss:  0.001646293792873621
Epoch:  153  	Training Loss: 0.0014096079394221306
Test Loss:  0.0015179612673819065
Valid Loss:  0.0016221111873164773
Epoch:  154  	Training Loss: 0.0014003408141434193
Test Loss:  0.0015033677918836474
Valid Loss:  0.0016090844292193651
Epoch:  155  	Training Loss: 0.0013953647576272488
Test Loss:  0.0014944400172680616
Valid Loss:  0.0016008990351110697
Epoch:  156  	Training Loss: 0.0013920015189796686
Test Loss:  0.0014882044633850455
Valid Loss:  0.001595041947439313
Epoch:  157  	Training Loss: 0.0013893528375774622
Test Loss:  0.0014834573958069086
Valid Loss:  0.00159055320546031
Epoch:  158  	Training Loss: 0.0013871692353859544
Test Loss:  0.0014796231407672167
Valid Loss:  0.001586372614838183
Epoch:  159  	Training Loss: 0.001385331153869629
Test Loss:  0.0014764033257961273
Valid Loss:  0.0015826798044145107
Epoch:  160  	Training Loss: 0.00138376175891608
Test Loss:  0.0014736331067979336
Valid Loss:  0.0015795300714671612
Epoch:  161  	Training Loss: 0.0013824047055095434
Test Loss:  0.0014712621923536062
Valid Loss:  0.001576811890117824
Epoch:  162  	Training Loss: 0.0013812201796099544
Test Loss:  0.0014705300563946366
Valid Loss:  0.0015748555306345224
Epoch:  163  	Training Loss: 0.0013804235495626926
Test Loss:  0.0014699234161525965
Valid Loss:  0.001573822577483952
Epoch:  164  	Training Loss: 0.0013798008440062404
Test Loss:  0.0014694125857204199
Valid Loss:  0.0015734466724097729
Epoch:  165  	Training Loss: 0.0013793010730296373
Test Loss:  0.0014689782401546836
Valid Loss:  0.0015731595922261477
Epoch:  166  	Training Loss: 0.0013788895448669791
Test Loss:  0.0014686058275401592
Valid Loss:  0.00157293607480824
Epoch:  167  	Training Loss: 0.001378617133013904
Test Loss:  0.0014683946501463652
Valid Loss:  0.0015728108119219542
Epoch:  168  	Training Loss: 0.0013785301707684994
Test Loss:  0.0014683024492114782
Valid Loss:  0.001572757144458592
Epoch:  169  	Training Loss: 0.0013785029295831919
Test Loss:  0.0014682188630104065
Valid Loss:  0.0015727091813459992
Epoch:  170  	Training Loss: 0.0013784782495349646
Test Loss:  0.001468144590035081
Valid Loss:  0.001572666224092245
Epoch:  171  	Training Loss: 0.0013784560142084956
Test Loss:  0.001468077301979065
Valid Loss:  0.0015726250130683184
Epoch:  172  	Training Loss: 0.001378435641527176
Test Loss:  0.001343694981187582
Valid Loss:  0.0014443115796893835
Epoch:  173  	Training Loss: 0.0012744389241561294
Test Loss:  0.0013008706737309694
Valid Loss:  0.0013944152742624283
Epoch:  174  	Training Loss: 0.0012217131443321705
Test Loss:  0.0012728802394121885
Valid Loss:  0.0013601225800812244
Epoch:  175  	Training Loss: 0.0011863373219966888
Test Loss:  0.0012540773022919893
Valid Loss:  0.0013368716463446617
Epoch:  176  	Training Loss: 0.0011612626258283854
Test Loss:  0.0012384477304294705
Valid Loss:  0.0013175872154533863
Epoch:  177  	Training Loss: 0.001141754211857915
Test Loss:  0.001224250765517354
Valid Loss:  0.00130176090169698
Epoch:  178  	Training Loss: 0.0011253055417910218
Test Loss:  0.001209385460242629
Valid Loss:  0.0012866506585851312
Epoch:  179  	Training Loss: 0.0011102822609245777
Test Loss:  0.0011949040926992893
Valid Loss:  0.0012719875667244196
Epoch:  180  	Training Loss: 0.0010968238348141313
Test Loss:  0.0011811091098934412
Valid Loss:  0.0012581071350723505
Epoch:  181  	Training Loss: 0.0010842644842341542
Test Loss:  0.001168038696050644
Valid Loss:  0.0012453481322154403
Epoch:  182  	Training Loss: 0.0010725674219429493
Test Loss:  0.001167467562481761
Valid Loss:  0.0012442152947187424
Epoch:  183  	Training Loss: 0.0010716388933360577
Test Loss:  0.0011669122613966465
Valid Loss:  0.001243110280483961
Epoch:  184  	Training Loss: 0.0010707374894991517
Test Loss:  0.001166373142041266
Valid Loss:  0.0012420322746038437
Epoch:  185  	Training Loss: 0.0010698623955249786
Test Loss:  0.0011658812873065472
Valid Loss:  0.0012409808114171028
Epoch:  186  	Training Loss: 0.0010690123308449984
Test Loss:  0.0011654819827526808
Valid Loss:  0.0012399564730003476
Epoch:  187  	Training Loss: 0.0010681867133826017
Test Loss:  0.001165097812190652
Valid Loss:  0.0012389562325552106
Epoch:  188  	Training Loss: 0.0010673848446458578
Test Loss:  0.001164723769761622
Valid Loss:  0.001237979857251048
Epoch:  189  	Training Loss: 0.0010666062589734793
Test Loss:  0.0011643626494333148
Valid Loss:  0.0012370258336886764
Epoch:  190  	Training Loss: 0.0010658488608896732
Test Loss:  0.0011640129378065467
Valid Loss:  0.0012360961409285665
Epoch:  191  	Training Loss: 0.001065113814547658
Test Loss:  0.0011636742856353521
Valid Loss:  0.0012351882178336382
Epoch:  192  	Training Loss: 0.0010643992573022842
Test Loss:  0.001165579305961728
Valid Loss:  0.0012353032361716032
Epoch:  193  	Training Loss: 0.0010642448905855417
Test Loss:  0.0011671368265524507
Valid Loss:  0.0012354040518403053
Epoch:  194  	Training Loss: 0.001064131734892726
Test Loss:  0.001168314483948052
Valid Loss:  0.0012354750651866198
Epoch:  195  	Training Loss: 0.0010640497785061598
Test Loss:  0.0011691520921885967
Valid Loss:  0.0012355154613032937
Epoch:  196  	Training Loss: 0.0010639878455549479
Test Loss:  0.001169834053143859
Valid Loss:  0.0012355395592749119
Epoch:  197  	Training Loss: 0.0010639334795996547
Test Loss:  0.0011703402269631624
Valid Loss:  0.0012355452636256814
Epoch:  198  	Training Loss: 0.0010638854000717402
Test Loss:  0.0011707120575010777
Valid Loss:  0.0012355344370007515
Epoch:  199  	Training Loss: 0.001063839765265584
Test Loss:  0.0011709246318787336
Valid Loss:  0.001235505216754973
Epoch:  200  	Training Loss: 0.0010637965751811862
Test Loss:  0.0011711312690749764
Valid Loss:  0.001235474948771298
Epoch:  201  	Training Loss: 0.0010637540835887194
Test Loss:  0.0011712759733200073
Valid Loss:  0.001235435949638486
Epoch:  202  	Training Loss: 0.0010637120576575398
Test Loss:  0.0011698019225150347
Valid Loss:  0.0012339818058535457
Epoch:  203  	Training Loss: 0.0010624502319842577
Test Loss:  0.0011683470802381635
Valid Loss:  0.001232548849657178
Epoch:  204  	Training Loss: 0.0010612087789922953
Test Loss:  0.0011669110972434282
Valid Loss:  0.0012311364989727736
Epoch:  205  	Training Loss: 0.001059986650943756
Test Loss:  0.0011654938571155071
Valid Loss:  0.0012297466164454818
Epoch:  206  	Training Loss: 0.0010587655706331134
Test Loss:  0.001164028886705637
Valid Loss:  0.001228349283337593
Epoch:  207  	Training Loss: 0.00105752469971776
Test Loss:  0.0011625830084085464
Valid Loss:  0.0012269713915884495
Epoch:  208  	Training Loss: 0.001056293142028153
Test Loss:  0.0011610903311520815
Valid Loss:  0.0012255923356860876
Epoch:  209  	Training Loss: 0.0010550371371209621
Test Loss:  42%|████▏     | 209/500 [02:34<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:41<05:36,  1.16s/it] 43%|████▎     | 213/500 [02:41<04:00,  1.20it/s] 43%|████▎     | 215/500 [02:41<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:41<02:05,  2.26it/s] 44%|████▍     | 219/500 [02:41<01:32,  3.03it/s] 44%|████▍     | 221/500 [02:48<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:48<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:48<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:48<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:48<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:54<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:55<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:55<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:55<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:55<01:28,  2.94it/s] 48%|████▊     | 241/500 [03:01<05:06,  1.18s/it] 49%|████▊     | 243/500 [03:01<03:38,  1.18it/s] 49%|████▉     | 245/500 [03:02<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:02<01:53,  2.23it/s] 50%|████▉     | 249/500 [03:02<01:23,  3.00it/s] 50%|█████     | 251/500 [03:08<04:50,  1.17s/it] 51%|█████     | 253/500 [03:08<03:27,  1.19it/s] 51%|█████     | 255/500 [03:08<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:08<01:48,  2.25it/s] 52%|█████▏    | 259/500 [03:09<01:19,  3.01it/s] 52%|█████▏    | 261/500 [03:15<04:37,  1.16s/it] 53%|█████▎    | 263/500 [03:15<03:18,  1.20it/s] 53%|█████▎    | 265/500 [03:15<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:15<01:42,  2.26it/s] 54%|█████▍    | 269/500 [03:15<01:15,  3.05it/s] 54%|█████▍    | 271/500 [03:22<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:22<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:22<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:22<01:40,  2.22it/s] 0.0011596170952543616
Valid Loss:  0.0012242342345416546
Epoch:  210  	Training Loss: 0.0010538001079112291
Test Loss:  0.001158163184300065
Valid Loss:  0.0012228949926793575
Epoch:  211  	Training Loss: 0.0010525851976126432
Test Loss:  0.0011567289475351572
Valid Loss:  0.0012215828755870461
Epoch:  212  	Training Loss: 0.001051396015100181
Test Loss:  0.0011565971653908491
Valid Loss:  0.0012215040624141693
Epoch:  213  	Training Loss: 0.0010513507295399904
Test Loss:  0.0011564679443836212
Valid Loss:  0.0012214266462251544
Epoch:  214  	Training Loss: 0.0010513057932257652
Test Loss:  0.0011563471052795649
Valid Loss:  0.00122135691344738
Epoch:  215  	Training Loss: 0.0010512606240808964
Test Loss:  0.0011562311556190252
Valid Loss:  0.0012212889268994331
Epoch:  216  	Training Loss: 0.0010512156877666712
Test Loss:  0.0011561207938939333
Valid Loss:  0.0012212207075208426
Epoch:  217  	Training Loss: 0.0010511709842830896
Test Loss:  0.0011560115963220596
Valid Loss:  0.0012211519060656428
Epoch:  218  	Training Loss: 0.0010511266300454736
Test Loss:  0.0011559020495042205
Valid Loss:  0.0012210847344249487
Epoch:  219  	Training Loss: 0.0010510822758078575
Test Loss:  0.0011557930847629905
Valid Loss:  0.0012210163986310363
Epoch:  220  	Training Loss: 0.0010510380379855633
Test Loss:  0.0011556840036064386
Valid Loss:  0.0012209491105750203
Epoch:  221  	Training Loss: 0.0010509936837479472
Test Loss:  0.0011555757373571396
Valid Loss:  0.0012208811240270734
Epoch:  222  	Training Loss: 0.0010509500280022621
Test Loss:  0.0011471431935206056
Valid Loss:  0.0012135307770222425
Epoch:  223  	Training Loss: 0.0010373942786827683
Test Loss:  0.0011413719039410353
Valid Loss:  0.001208787551149726
Epoch:  224  	Training Loss: 0.001027443795464933
Test Loss:  0.0011380314826965332
Valid Loss:  0.0012064110487699509
Epoch:  225  	Training Loss: 0.0010209770407527685
Test Loss:  0.001137277577072382
Valid Loss:  0.001206822693347931
Epoch:  226  	Training Loss: 0.0010170298628509045
Test Loss:  0.0011375858448445797
Valid Loss:  0.001207483932375908
Epoch:  227  	Training Loss: 0.0010146081913262606
Test Loss:  0.0011379902716726065
Valid Loss:  0.0012080802116543055
Epoch:  228  	Training Loss: 0.0010130760492756963
Test Loss:  0.0011383906239643693
Valid Loss:  0.001208743778988719
Epoch:  229  	Training Loss: 0.001012020860798657
Test Loss:  0.001138713676482439
Valid Loss:  0.0012094846460968256
Epoch:  230  	Training Loss: 0.001011260086670518
Test Loss:  0.0011390398722141981
Valid Loss:  0.0012103633489459753
Epoch:  231  	Training Loss: 0.001010649255476892
Test Loss:  0.0011394445318728685
Valid Loss:  0.0012110440293326974
Epoch:  232  	Training Loss: 0.0010102967498824
Test Loss:  0.001064513809978962
Valid Loss:  0.0011411374434828758
Epoch:  233  	Training Loss: 0.00097745715174824
Test Loss:  0.001053673680871725
Valid Loss:  0.0011240157764405012
Epoch:  234  	Training Loss: 0.0009712120518088341
Test Loss:  0.001051911385729909
Valid Loss:  0.0011147786863148212
Epoch:  235  	Training Loss: 0.0009676500339992344
Test Loss:  0.0010513687739148736
Valid Loss:  0.0011084284633398056
Epoch:  236  	Training Loss: 0.0009653051383793354
Test Loss:  0.0010502961231395602
Valid Loss:  0.0011023764964193106
Epoch:  237  	Training Loss: 0.0009635178139433265
Test Loss:  0.0010491985594853759
Valid Loss:  0.0010973053285852075
Epoch:  238  	Training Loss: 0.000962107558734715
Test Loss:  0.0010482027428224683
Valid Loss:  0.0010931065771728754
Epoch:  239  	Training Loss: 0.000960996956564486
Test Loss:  0.0010480042546987534
Valid Loss:  0.0010901866480708122
Epoch:  240  	Training Loss: 0.0009601469500921667
Test Loss:  0.0010474021546542645
Valid Loss:  0.0010874769650399685
Epoch:  241  	Training Loss: 0.0009594359435141087
Test Loss:  0.0010467169340699911
Valid Loss:  0.0010850619291886687
Epoch:  242  	Training Loss: 0.0009588432149030268
Test Loss:  0.0010463212383911014
Valid Loss:  0.001082980539649725
Epoch:  243  	Training Loss: 0.0009577638702467084
Test Loss:  0.0010454438161104918
Valid Loss:  0.0010809514205902815
Epoch:  244  	Training Loss: 0.00095676927594468
Test Loss:  0.0010443467181175947
Valid Loss:  0.001079019857570529
Epoch:  245  	Training Loss: 0.000955827534198761
Test Loss:  0.0010431702248752117
Valid Loss:  0.0010771984234452248
Epoch:  246  	Training Loss: 0.0009549182141199708
Test Loss:  0.0010419730097055435
Valid Loss:  0.0010754956165328622
Epoch:  247  	Training Loss: 0.000954035553149879
Test Loss:  0.001040783477947116
Valid Loss:  0.001073914929293096
Epoch:  248  	Training Loss: 0.0009531793184578419
Test Loss:  0.0010396204888820648
Valid Loss:  0.0010724363382905722
Epoch:  249  	Training Loss: 0.0009523539338260889
Test Loss:  0.001038484275341034
Valid Loss:  0.0010710398200899363
Epoch:  250  	Training Loss: 0.0009515467099845409
Test Loss:  0.0010373760014772415
Valid Loss:  0.0010697157122194767
Epoch:  251  	Training Loss: 0.0009507622453384101
Test Loss:  0.0010363011388108134
Valid Loss:  0.0010684970766305923
Epoch:  252  	Training Loss: 0.0009500058367848396
Test Loss:  0.0010372515534982085
Valid Loss:  0.0010681760031729937
Epoch:  253  	Training Loss: 0.0009494087425991893
Test Loss:  0.001038060523569584
Valid Loss:  0.00106786098331213
Epoch:  254  	Training Loss: 0.0009488816722296178
Test Loss:  0.0010387469083070755
Valid Loss:  0.0010675480589270592
Epoch:  255  	Training Loss: 0.0009484089096076787
Test Loss:  0.0010393272386863828
Valid Loss:  0.0010672351345419884
Epoch:  256  	Training Loss: 0.0009479798609390855
Test Loss:  0.0010398165322840214
Valid Loss:  0.0010669216280803084
Epoch:  257  	Training Loss: 0.0009476051200181246
Test Loss:  0.0010400444734841585
Valid Loss:  0.0010666619054973125
Epoch:  258  	Training Loss: 0.0009472611709497869
Test Loss:  0.0010402289917692542
Valid Loss:  0.0010664085857570171
Epoch:  259  	Training Loss: 0.0009469588403590024
Test Loss:  0.0010405952343717217
Valid Loss:  0.001066112658008933
Epoch:  260  	Training Loss: 0.0009466956835240126
Test Loss:  0.001040677772834897
Valid Loss:  0.0010658751707524061
Epoch:  261  	Training Loss: 0.0009464477188885212
Test Loss:  0.0010407346999272704
Valid Loss:  0.0010656416416168213
Epoch:  262  	Training Loss: 0.0009462180314585567
Test Loss:  0.001033116364851594
Valid Loss:  0.0010577291250228882
Epoch:  263  	Training Loss: 0.0009353162022307515
Test Loss:  0.001024870085529983
Valid Loss:  0.0010490983258932829
Epoch:  264  	Training Loss: 0.0009252214804291725
Test Loss:  0.001016354886814952
Valid Loss:  0.0010399946477264166
Epoch:  265  	Training Loss: 0.0009153992286883295
Test Loss:  0.0010070912539958954
Valid Loss:  0.0010305538307875395
Epoch:  266  	Training Loss: 0.0009060307638719678
Test Loss:  0.0009977346053346992
Valid Loss:  0.0010208800667896867
Epoch:  267  	Training Loss: 0.0008970481576398015
Test Loss:  0.0009883823804557323
Valid Loss:  0.0010110489092767239
Epoch:  268  	Training Loss: 0.0008883432019501925
Test Loss:  0.000979181844741106
Valid Loss:  0.0010013813152909279
Epoch:  269  	Training Loss: 0.0008798753842711449
Test Loss:  0.0009700885275378823
Valid Loss:  0.000991721753962338
Epoch:  270  	Training Loss: 0.0008716743323020637
Test Loss:  0.0009611360728740692
Valid Loss:  0.0009821046842262149
Epoch:  271  	Training Loss: 0.000863638473674655
Test Loss:  0.0009522768668830395
Valid Loss:  0.0009723606635816395
Epoch:  272  	Training Loss: 0.0008557136752642691
Test Loss:  0.000941024161875248
Valid Loss:  0.0009615016751922667
Epoch:  273  	Training Loss: 0.0008440451347269118
Test Loss:  0.0009300985839217901
Valid Loss:  0.0009513274999335408
Epoch:  274  	Training Loss: 0.0008339716587215662
Test Loss:  0.0009213163866661489
Valid Loss:  0.0009431112557649612
Epoch:  275  	Training Loss: 0.0008256281726062298
Test Loss:  0.0009140459587797523
Valid Loss:  0.000935932737775147
Epoch:  276  	Training Loss: 0.0008186373161152005
Test Loss:  0.000907609355635941
Valid Loss:  0.0009292252361774445
Epoch:  277  	Training Loss: 0.0008128491463139653
Test Loss:  0.0009017797419801354
Valid Loss:  0.0009234448662027717
 56%|█████▌    | 279/500 [03:22<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:29<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:29<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:29<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:29<01:36,  2.22it/s] 58%|█████▊    | 289/500 [03:29<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:36<04:11,  1.20s/it] 59%|█████▊    | 293/500 [03:36<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:36<02:07,  1.60it/s] 59%|█████▉    | 297/500 [03:36<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:36<01:09,  2.91it/s] 60%|██████    | 301/500 [03:43<03:57,  1.19s/it] 61%|██████    | 303/500 [03:43<02:48,  1.17it/s] 61%|██████    | 305/500 [03:43<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:43<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:43<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:50<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:50<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:50<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:50<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:50<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:56<03:35,  1.20s/it] 65%|██████▍   | 323/500 [03:57<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:57<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:57<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:57<00:57,  2.96it/s] 66%|██████▌   | 331/500 [04:03<03:18,  1.18s/it] 67%|██████▋   | 333/500 [04:03<02:21,  1.18it/s] 67%|██████▋   | 335/500 [04:04<01:40,  1.64it/s] 67%|██████▋   | 337/500 [04:04<01:12,  2.23it/s] 68%|██████▊   | 339/500 [04:04<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:10<03:08,  1.18s/it] 69%|██████▊   | 343/500 [04:10<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:10<01:35,  1.63it/s]Epoch:  278  	Training Loss: 0.0008080773986876011
Test Loss:  0.0008966104942373931
Valid Loss:  0.0009186470997519791
Epoch:  279  	Training Loss: 0.0008037689840421081
Test Loss:  0.0008925580768845975
Valid Loss:  0.0009144417708739638
Epoch:  280  	Training Loss: 0.0008001849055290222
Test Loss:  0.0008890742319636047
Valid Loss:  0.0009104422642849386
Epoch:  281  	Training Loss: 0.000796802225522697
Test Loss:  0.0008860964444465935
Valid Loss:  0.000906722154468298
Epoch:  282  	Training Loss: 0.0007935737958177924
Test Loss:  0.0008496320806443691
Valid Loss:  0.000877067563124001
Epoch:  283  	Training Loss: 0.000780825037509203
Test Loss:  0.000836369872558862
Valid Loss:  0.0008657017606310546
Epoch:  284  	Training Loss: 0.0007768425275571644
Test Loss:  0.0008309931145049632
Valid Loss:  0.0008602316374890506
Epoch:  285  	Training Loss: 0.0007746007759124041
Test Loss:  0.0008285609656013548
Valid Loss:  0.0008569800411351025
Epoch:  286  	Training Loss: 0.0007729604840278625
Test Loss:  0.0008272695122286677
Valid Loss:  0.0008546501048840582
Epoch:  287  	Training Loss: 0.0007718227570876479
Test Loss:  0.0008254600688815117
Valid Loss:  0.0008527177851647139
Epoch:  288  	Training Loss: 0.0007710359641350806
Test Loss:  0.0008242290932685137
Valid Loss:  0.000851232442073524
Epoch:  289  	Training Loss: 0.0007703324081376195
Test Loss:  0.0008232513209804893
Valid Loss:  0.000850062700919807
Epoch:  290  	Training Loss: 0.0007697233813814819
Test Loss:  0.0008219016017392278
Valid Loss:  0.00084906374104321
Epoch:  291  	Training Loss: 0.0007691459031775594
Test Loss:  0.0008207938517443836
Valid Loss:  0.0008482455159537494
Epoch:  292  	Training Loss: 0.0007685914169996977
Test Loss:  0.0008132173679769039
Valid Loss:  0.0008392082527279854
Epoch:  293  	Training Loss: 0.0007542366511188447
Test Loss:  0.0008071371121332049
Valid Loss:  0.0008321096538566053
Epoch:  294  	Training Loss: 0.000742926262319088
Test Loss:  0.0008008986478671432
Valid Loss:  0.0008260108879767358
Epoch:  295  	Training Loss: 0.0007336046546697617
Test Loss:  0.0007951756124384701
Valid Loss:  0.0008207073551602662
Epoch:  296  	Training Loss: 0.0007255709497258067
Test Loss:  0.0007893908768892288
Valid Loss:  0.000815853476524353
Epoch:  297  	Training Loss: 0.0007183154812082648
Test Loss:  0.0007834661519154906
Valid Loss:  0.0008112530340440571
Epoch:  298  	Training Loss: 0.000711509957909584
Test Loss:  0.000777465698774904
Valid Loss:  0.0008068947936408222
Epoch:  299  	Training Loss: 0.0007051558350212872
Test Loss:  0.000771500519476831
Valid Loss:  0.0008027558214962482
Epoch:  300  	Training Loss: 0.0006991993868723512
Test Loss:  0.0007656159577891231
Valid Loss:  0.0007988203433342278
Epoch:  301  	Training Loss: 0.0006936255958862603
Test Loss:  0.0007598550291731954
Valid Loss:  0.0007950824219733477
Epoch:  302  	Training Loss: 0.0006883668247610331
Test Loss:  0.000761351257096976
Valid Loss:  0.0007944432436488569
Epoch:  303  	Training Loss: 0.0006879043648950756
Test Loss:  0.0007624549325555563
Valid Loss:  0.0007939843344502151
Epoch:  304  	Training Loss: 0.0006875908002257347
Test Loss:  0.0007632734486833215
Valid Loss:  0.0007936401525512338
Epoch:  305  	Training Loss: 0.0006873683305457234
Test Loss:  0.0007638683309778571
Valid Loss:  0.000793354120105505
Epoch:  306  	Training Loss: 0.0006871851510368288
Test Loss:  0.0007642992422915995
Valid Loss:  0.0007931047002784908
Epoch:  307  	Training Loss: 0.0006870235083624721
Test Loss:  0.0007646104204468429
Valid Loss:  0.0007928801933303475
Epoch:  308  	Training Loss: 0.0006868757773190737
Test Loss:  0.0007648334139958024
Valid Loss:  0.0007926755351945758
Epoch:  309  	Training Loss: 0.000686740328092128
Test Loss:  0.0007649644976481795
Valid Loss:  0.0007924969540908933
Epoch:  310  	Training Loss: 0.0006866184994578362
Test Loss:  0.000765022705309093
Valid Loss:  0.0007923298981040716
Epoch:  311  	Training Loss: 0.0006865020259283483
Test Loss:  0.0007650263141840696
Valid Loss:  0.0007921726210042834
Epoch:  312  	Training Loss: 0.0006863891612738371
Test Loss:  0.0007549043511971831
Valid Loss:  0.0007846839725971222
Epoch:  313  	Training Loss: 0.0006838903063908219
Test Loss:  0.0007495182217098773
Valid Loss:  0.0007805484929122031
Epoch:  314  	Training Loss: 0.000682580575812608
Test Loss:  0.0007454885635524988
Valid Loss:  0.000777785899117589
Epoch:  315  	Training Loss: 0.0006816411623731256
Test Loss:  0.0007427609525620937
Valid Loss:  0.0007758996216580272
Epoch:  316  	Training Loss: 0.0006808372563682497
Test Loss:  0.0007413018611259758
Valid Loss:  0.0007745997863821685
Epoch:  317  	Training Loss: 0.0006800660630688071
Test Loss:  0.0007394448621198535
Valid Loss:  0.0007733704405836761
Epoch:  318  	Training Loss: 0.0006793307256884873
Test Loss:  0.0007379621965810657
Valid Loss:  0.0007723580347374082
Epoch:  319  	Training Loss: 0.0006786035373806953
Test Loss:  0.0007365582277998328
Valid Loss:  0.0007714255480095744
Epoch:  320  	Training Loss: 0.000677854404784739
Test Loss:  0.0007352579268626869
Valid Loss:  0.0007705619209446013
Epoch:  321  	Training Loss: 0.0006771147600375116
Test Loss:  0.0007340193842537701
Valid Loss:  0.0007697395631112158
Epoch:  322  	Training Loss: 0.0006763834971934557
Test Loss:  0.0007199486717581749
Valid Loss:  0.0007588231819681823
Epoch:  323  	Training Loss: 0.0006726878345943987
Test Loss:  0.0007139042718335986
Valid Loss:  0.0007537734927609563
Epoch:  324  	Training Loss: 0.0006711864843964577
Test Loss:  0.0007108973222784698
Valid Loss:  0.0007508211419917643
Epoch:  325  	Training Loss: 0.0006701803067699075
Test Loss:  0.000709167099557817
Valid Loss:  0.0007487519178539515
Epoch:  326  	Training Loss: 0.0006693444447591901
Test Loss:  0.0007080194773152471
Valid Loss:  0.000747110228985548
Epoch:  327  	Training Loss: 0.0006686089909635484
Test Loss:  0.0007071666186675429
Valid Loss:  0.0007457095780409873
Epoch:  328  	Training Loss: 0.0006679536891169846
Test Loss:  0.000706477090716362
Valid Loss:  0.0007444681250490248
Epoch:  329  	Training Loss: 0.0006673684692941606
Test Loss:  0.0007058926858007908
Valid Loss:  0.0007433445425704122
Epoch:  330  	Training Loss: 0.000666845531668514
Test Loss:  0.0007053851732052863
Valid Loss:  0.0007423183415085077
Epoch:  331  	Training Loss: 0.0006663779495283961
Test Loss:  0.000704936683177948
Valid Loss:  0.0007413759012706578
Epoch:  332  	Training Loss: 0.0006659599021077156
Test Loss:  0.0007114902837201953
Valid Loss:  0.000739806389901787
Epoch:  333  	Training Loss: 0.0006607293034903705
Test Loss:  0.0007151502650231123
Valid Loss:  0.0007400219328701496
Epoch:  334  	Training Loss: 0.0006593218422494829
Test Loss:  0.0007164654089137912
Valid Loss:  0.0007401254260912538
Epoch:  335  	Training Loss: 0.0006587844691239297
Test Loss:  0.0007169900927692652
Valid Loss:  0.0007399640744552016
Epoch:  336  	Training Loss: 0.0006584564107470214
Test Loss:  0.0007171097095124424
Valid Loss:  0.0007396371802315116
Epoch:  337  	Training Loss: 0.0006581854540854692
Test Loss:  0.0007170223398134112
Valid Loss:  0.0007392511470243335
Epoch:  338  	Training Loss: 0.000657960947137326
Test Loss:  0.0007168182055465877
Valid Loss:  0.0007388555677607656
Epoch:  339  	Training Loss: 0.0006577637977898121
Test Loss:  0.0007165567949414253
Valid Loss:  0.0007384915952570736
Epoch:  340  	Training Loss: 0.000657582248095423
Test Loss:  0.0007160669192671776
Valid Loss:  0.0007381440373137593
Epoch:  341  	Training Loss: 0.0006574171711690724
Test Loss:  0.0007155168568715453
Valid Loss:  0.0007378063746728003
Epoch:  342  	Training Loss: 0.0006572589627467096
Test Loss:  0.0007147184805944562
Valid Loss:  0.0007371053798124194
Epoch:  343  	Training Loss: 0.0006569935358129442
Test Loss:  0.0007145105046220124
Valid Loss:  0.0007366134086623788
Epoch:  344  	Training Loss: 0.0006567695527337492
Test Loss:  0.0007142660906538367
Valid Loss:  0.0007361661992035806
Epoch:  345  	Training Loss: 0.000656582647934556
Test Loss:  0.0007139919907785952
Valid Loss:  0.0007357326103374362
Epoch:  346  	Training Loss: 0.0006564058712683618
Test Loss:  69%|██████▉   | 347/500 [04:11<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:11<00:50,  2.99it/s] 70%|███████   | 351/500 [04:17<02:55,  1.18s/it] 71%|███████   | 353/500 [04:17<02:04,  1.18it/s] 71%|███████   | 355/500 [04:17<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:17<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:17<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:24<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:24<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:24<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:24<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:24<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:31<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:31<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:31<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:31<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:31<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:38<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:38<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:38<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:38<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:38<00:37,  2.95it/s] 78%|███████▊  | 391/500 [04:45<02:10,  1.19s/it] 79%|███████▊  | 393/500 [04:45<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:45<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:45<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:45<00:34,  2.96it/s] 80%|████████  | 401/500 [04:51<01:56,  1.17s/it] 81%|████████  | 403/500 [04:51<01:21,  1.19it/s] 81%|████████  | 405/500 [04:52<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:52<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:52<00:30,  3.03it/s] 82%|████████▏ | 411/500 [04:58<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:58<01:13,  1.18it/s] 0.0007136927451938391
Valid Loss:  0.0007353101391345263
Epoch:  347  	Training Loss: 0.000656237592920661
Test Loss:  0.0007133773760870099
Valid Loss:  0.0007349012303166091
Epoch:  348  	Training Loss: 0.0006560757756233215
Test Loss:  0.0007130481535568833
Valid Loss:  0.0007345034973695874
Epoch:  349  	Training Loss: 0.0006559195462614298
Test Loss:  0.000712711364030838
Valid Loss:  0.0007341135060414672
Epoch:  350  	Training Loss: 0.0006557687884196639
Test Loss:  0.0007123686373233795
Valid Loss:  0.0007337314309552312
Epoch:  351  	Training Loss: 0.000655622105114162
Test Loss:  0.0007120185764506459
Valid Loss:  0.0007333571556955576
Epoch:  352  	Training Loss: 0.0006554797291755676
Test Loss:  0.0007105875411070883
Valid Loss:  0.0007324868347495794
Epoch:  353  	Training Loss: 0.0006546196527779102
Test Loss:  0.0007092684973031282
Valid Loss:  0.0007316813571378589
Epoch:  354  	Training Loss: 0.0006538137095049024
Test Loss:  0.0007080505019985139
Valid Loss:  0.0007309981156140566
Epoch:  355  	Training Loss: 0.0006530422251671553
Test Loss:  0.0007068684790283442
Valid Loss:  0.0007303508464246988
Epoch:  356  	Training Loss: 0.0006523049669340253
Test Loss:  0.0007057219045236707
Valid Loss:  0.0007297227857634425
Epoch:  357  	Training Loss: 0.0006515848217532039
Test Loss:  0.0007046053651720285
Valid Loss:  0.0007291121874004602
Epoch:  358  	Training Loss: 0.0006508806836791337
Test Loss:  0.0007035157177597284
Valid Loss:  0.000728515675291419
Epoch:  359  	Training Loss: 0.0006501899333670735
Test Loss:  0.0007024492369964719
Valid Loss:  0.000727931794244796
Epoch:  360  	Training Loss: 0.0006495119305327535
Test Loss:  0.0007014053408056498
Valid Loss:  0.000727359380107373
Epoch:  361  	Training Loss: 0.0006488474318757653
Test Loss:  0.0007003688951954246
Valid Loss:  0.0007268117624334991
Epoch:  362  	Training Loss: 0.0006482092430815101
Test Loss:  0.000677302828989923
Valid Loss:  0.0007075644098222256
Epoch:  363  	Training Loss: 0.0006440563010983169
Test Loss:  0.000675708579365164
Valid Loss:  0.0007058024639263749
Epoch:  364  	Training Loss: 0.0006438374985009432
Test Loss:  0.0006758077070116997
Valid Loss:  0.0007054747547954321
Epoch:  365  	Training Loss: 0.0006436667172238231
Test Loss:  0.0006761609110981226
Valid Loss:  0.0007053454755805433
Epoch:  366  	Training Loss: 0.0006435123505070806
Test Loss:  0.0006765204016119242
Valid Loss:  0.0007052405853755772
Epoch:  367  	Training Loss: 0.0006433725357055664
Test Loss:  0.0006768695893697441
Valid Loss:  0.0007051454158499837
Epoch:  368  	Training Loss: 0.0006432455847971141
Test Loss:  0.0006772064953111112
Valid Loss:  0.0007050581625662744
Epoch:  369  	Training Loss: 0.0006431752699427307
Test Loss:  0.0006770235486328602
Valid Loss:  0.000704855308867991
Epoch:  370  	Training Loss: 0.0006431454094126821
Test Loss:  0.000677059986628592
Valid Loss:  0.0007048259722068906
Epoch:  371  	Training Loss: 0.00064311851747334
Test Loss:  0.0006771170883439481
Valid Loss:  0.0007048154366202652
Epoch:  372  	Training Loss: 0.0006431025685742497
Test Loss:  0.0006793025531806052
Valid Loss:  0.0007036860915832222
Epoch:  373  	Training Loss: 0.0006414895178750157
Test Loss:  0.0006774849025532603
Valid Loss:  0.000700546195730567
Epoch:  374  	Training Loss: 0.0006400369456969202
Test Loss:  0.0006763674900867045
Valid Loss:  0.0006979337777011096
Epoch:  375  	Training Loss: 0.0006386726745404303
Test Loss:  0.0006751790642738342
Valid Loss:  0.0006953700794838369
Epoch:  376  	Training Loss: 0.0006373894866555929
Test Loss:  0.0006740973331034184
Valid Loss:  0.0006929556839168072
Epoch:  377  	Training Loss: 0.0006361822597682476
Test Loss:  0.0006730732857249677
Valid Loss:  0.0006906561320647597
Epoch:  378  	Training Loss: 0.0006350454641506076
Test Loss:  0.0006721117533743382
Valid Loss:  0.0006884669419378042
Epoch:  379  	Training Loss: 0.0006339745596051216
Test Loss:  0.0006712068570777774
Valid Loss:  0.0006863801972940564
Epoch:  380  	Training Loss: 0.0006329654715955257
Test Loss:  0.0006703542312607169
Valid Loss:  0.0006843911251053214
Epoch:  381  	Training Loss: 0.0006320139509625733
Test Loss:  0.0006695500342175364
Valid Loss:  0.0006824929150752723
Epoch:  382  	Training Loss: 0.0006311169127002358
Test Loss:  0.0006717235082760453
Valid Loss:  0.0006825088057667017
Epoch:  383  	Training Loss: 0.0006224652752280235
Test Loss:  0.0006730685126967728
Valid Loss:  0.0006827348261140287
Epoch:  384  	Training Loss: 0.000617723970208317
Test Loss:  0.0006739683449268341
Valid Loss:  0.0006831803475506604
Epoch:  385  	Training Loss: 0.0006150425761006773
Test Loss:  0.0006741727702319622
Valid Loss:  0.0006830350030213594
Epoch:  386  	Training Loss: 0.0006129930261522532
Test Loss:  0.0006741860415786505
Valid Loss:  0.0006827304023317993
Epoch:  387  	Training Loss: 0.0006115189753472805
Test Loss:  0.0006738955853506923
Valid Loss:  0.0006822700961492956
Epoch:  388  	Training Loss: 0.0006103054038248956
Test Loss:  0.0006735582137480378
Valid Loss:  0.000681665784213692
Epoch:  389  	Training Loss: 0.000609297479968518
Test Loss:  0.0006733695627190173
Valid Loss:  0.0006808903417550027
Epoch:  390  	Training Loss: 0.0006085792556405067
Test Loss:  0.000673209666274488
Valid Loss:  0.0006803342839702964
Epoch:  391  	Training Loss: 0.0006078914739191532
Test Loss:  0.0006730505265295506
Valid Loss:  0.000679799763020128
Epoch:  392  	Training Loss: 0.0006072897231206298
Test Loss:  0.0006725264829583466
Valid Loss:  0.0006796987727284431
Epoch:  393  	Training Loss: 0.0006072560790926218
Test Loss:  0.0006721592508256435
Valid Loss:  0.000679628923535347
Epoch:  394  	Training Loss: 0.0006072368123568594
Test Loss:  0.0006718989461660385
Valid Loss:  0.000679577759001404
Epoch:  395  	Training Loss: 0.0006072244141250849
Test Loss:  0.0006717096548527479
Valid Loss:  0.0006795383524149656
Epoch:  396  	Training Loss: 0.0006072150426916778
Test Loss:  0.0006715703057125211
Valid Loss:  0.0006795066874474287
Epoch:  397  	Training Loss: 0.0006072072428651154
Test Loss:  0.0006714772898703814
Valid Loss:  0.0006794796790927649
Epoch:  398  	Training Loss: 0.0006072001997381449
Test Loss:  0.0006714122137054801
Valid Loss:  0.0006794558139517903
Epoch:  399  	Training Loss: 0.0006071933312341571
Test Loss:  0.000671359826810658
Valid Loss:  0.0006794417276978493
Epoch:  400  	Training Loss: 0.000607186695560813
Test Loss:  0.0006713173352181911
Valid Loss:  0.000679436547216028
Epoch:  401  	Training Loss: 0.0006071801763027906
Test Loss:  0.000671280431561172
Valid Loss:  0.000679431133903563
Epoch:  402  	Training Loss: 0.0006071735988371074
Test Loss:  0.0006665828404948115
Valid Loss:  0.0006752879125997424
Epoch:  403  	Training Loss: 0.0006006946787238121
Test Loss:  0.0006624318775720894
Valid Loss:  0.0006717266514897346
Epoch:  404  	Training Loss: 0.0005949370679445565
Test Loss:  0.0006587525131180882
Valid Loss:  0.0006686403066851199
Epoch:  405  	Training Loss: 0.0005897906376048923
Test Loss:  0.0006554812425747514
Valid Loss:  0.0006659646169282496
Epoch:  406  	Training Loss: 0.0005851814639754593
Test Loss:  0.000652562826871872
Valid Loss:  0.0006636427133344114
Epoch:  407  	Training Loss: 0.0005810391739942133
Test Loss:  0.0006499519222415984
Valid Loss:  0.0006616277387365699
Epoch:  408  	Training Loss: 0.0005773108568973839
Test Loss:  0.0006475939881056547
Valid Loss:  0.0006598862819373608
Epoch:  409  	Training Loss: 0.0005739496555179358
Test Loss:  0.0006454532267525792
Valid Loss:  0.0006583626964129508
Epoch:  410  	Training Loss: 0.000570909003727138
Test Loss:  0.0006435016402974725
Valid Loss:  0.0006570265395566821
Epoch:  411  	Training Loss: 0.0005681490292772651
Test Loss:  0.0006417139084078372
Valid Loss:  0.0006558530731126666
Epoch:  412  	Training Loss: 0.0005656403372995555
Test Loss:  0.0005745025118812919
Valid Loss:  0.0006010935758240521
Epoch:  413  	Training Loss: 0.0005438533844426274
Test Loss:  0.0005767973489128053
Valid Loss:  0.0006011213990859687
Epoch:  414  	Training Loss: 0.0005422923713922501
Test Loss:  0.0005762968212366104
Valid Loss:  0.0005995759274810553
 83%|████████▎ | 415/500 [04:58<00:51,  1.63it/s] 83%|████████▎ | 417/500 [04:59<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:59<00:26,  3.01it/s] 84%|████████▍ | 421/500 [05:05<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:05<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:05<00:46,  1.63it/s] 85%|████████▌ | 427/500 [05:05<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:06<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:12<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:12<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:12<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:12<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:12<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:19<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:19<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:19<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:19<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:19<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:26<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:26<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:26<00:28,  1.61it/s] 91%|█████████▏| 457/500 [05:26<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:26<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:33<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:33<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:33<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:33<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:33<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:40<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:40<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:40<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:40<00:10,  2.20it/s] 96%|█████████▌| 479/500 [05:40<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:47<00:22,  1.19s/it]Epoch:  415  	Training Loss: 0.0005413417238742113
Test Loss:  0.0005764331435784698
Valid Loss:  0.0005986105534248054
Epoch:  416  	Training Loss: 0.0005406769923865795
Test Loss:  0.0005762458313256502
Valid Loss:  0.0005977695109322667
Epoch:  417  	Training Loss: 0.0005403447430580854
Test Loss:  0.0005759738269262016
Valid Loss:  0.0005971710197627544
Epoch:  418  	Training Loss: 0.0005400878144428134
Test Loss:  0.0005759645719081163
Valid Loss:  0.0005967605393379927
Epoch:  419  	Training Loss: 0.0005398504436016083
Test Loss:  0.0005758859333582222
Valid Loss:  0.0005963522708043456
Epoch:  420  	Training Loss: 0.0005396315245889127
Test Loss:  0.0005758219631388783
Valid Loss:  0.0005959849804639816
Epoch:  421  	Training Loss: 0.0005394328618422151
Test Loss:  0.0005753600271418691
Valid Loss:  0.0005955736851319671
Epoch:  422  	Training Loss: 0.0005392478778958321
Test Loss:  0.0005759551422670484
Valid Loss:  0.0005957860266789794
Epoch:  423  	Training Loss: 0.0005381077062338591
Test Loss:  0.0005759435007348657
Valid Loss:  0.0005955931264907122
Epoch:  424  	Training Loss: 0.0005372430314309895
Test Loss:  0.000575707876123488
Valid Loss:  0.0005952290957793593
Epoch:  425  	Training Loss: 0.0005365132237784564
Test Loss:  0.0005757620092481375
Valid Loss:  0.0005948282778263092
Epoch:  426  	Training Loss: 0.0005359153728932142
Test Loss:  0.0005755401798523962
Valid Loss:  0.0005943433498032391
Epoch:  427  	Training Loss: 0.0005355708999559283
Test Loss:  0.0005753625300712883
Valid Loss:  0.0005939233815297484
Epoch:  428  	Training Loss: 0.0005352944135665894
Test Loss:  0.0005753033910878003
Valid Loss:  0.0005935954977758229
Epoch:  429  	Training Loss: 0.0005350601859390736
Test Loss:  0.0005752112483605742
Valid Loss:  0.0005932917702011764
Epoch:  430  	Training Loss: 0.0005348672857508063
Test Loss:  0.0005751887802034616
Valid Loss:  0.0005930920015089214
Epoch:  431  	Training Loss: 0.0005346971447579563
Test Loss:  0.0005751072894781828
Valid Loss:  0.0005929374601691961
Epoch:  432  	Training Loss: 0.000534568855073303
Test Loss:  0.0005521599669009447
Valid Loss:  0.0005744919180870056
Epoch:  433  	Training Loss: 0.000522460148204118
Test Loss:  0.0005409799050539732
Valid Loss:  0.0005646003410220146
Epoch:  434  	Training Loss: 0.0005141458241268992
Test Loss:  0.0005326441023498774
Valid Loss:  0.0005571058136411011
Epoch:  435  	Training Loss: 0.000506764801684767
Test Loss:  0.0005249667447060347
Valid Loss:  0.0005502321291714907
Epoch:  436  	Training Loss: 0.0004999799421057105
Test Loss:  0.0005183722241781652
Valid Loss:  0.0005443497211672366
Epoch:  437  	Training Loss: 0.0004937411868013442
Test Loss:  0.0005120584974065423
Valid Loss:  0.000538900843821466
Epoch:  438  	Training Loss: 0.0004879858170170337
Test Loss:  0.0005063767894171178
Valid Loss:  0.0005337610491551459
Epoch:  439  	Training Loss: 0.00048267480451613665
Test Loss:  0.0005018850788474083
Valid Loss:  0.000529708806425333
Epoch:  440  	Training Loss: 0.0004778836446348578
Test Loss:  0.0004977565258741379
Valid Loss:  0.0005260736797936261
Epoch:  441  	Training Loss: 0.00047347680083476007
Test Loss:  0.0004935333272442222
Valid Loss:  0.0005223840707913041
Epoch:  442  	Training Loss: 0.0004693448427133262
Test Loss:  0.0004945626715198159
Valid Loss:  0.0005151609657332301
Epoch:  443  	Training Loss: 0.0004635958175640553
Test Loss:  0.0004949069116264582
Valid Loss:  0.0005116075626574457
Epoch:  444  	Training Loss: 0.0004611448966898024
Test Loss:  0.0004947960842400789
Valid Loss:  0.0005094344960525632
Epoch:  445  	Training Loss: 0.00045978702837601304
Test Loss:  0.0004946509725414217
Valid Loss:  0.0005079664988443255
Epoch:  446  	Training Loss: 0.00045895276707597077
Test Loss:  0.0004945506225340068
Valid Loss:  0.0005069294711574912
Epoch:  447  	Training Loss: 0.0004584137350320816
Test Loss:  0.0004941531806252897
Valid Loss:  0.0005060783005319536
Epoch:  448  	Training Loss: 0.0004579659434966743
Test Loss:  0.0004935268661938608
Valid Loss:  0.0005050166510045528
Epoch:  449  	Training Loss: 0.0004574735648930073
Test Loss:  0.000492726219817996
Valid Loss:  0.0005040332907810807
Epoch:  450  	Training Loss: 0.00045706037781201303
Test Loss:  0.000492248625960201
Valid Loss:  0.000503259536344558
Epoch:  451  	Training Loss: 0.0004567298456095159
Test Loss:  0.0004916521720588207
Valid Loss:  0.0005025248392485082
Epoch:  452  	Training Loss: 0.00045641936594620347
Test Loss:  0.000492783437948674
Valid Loss:  0.0005028835730627179
Epoch:  453  	Training Loss: 0.00045531406067311764
Test Loss:  0.0004937498597428203
Valid Loss:  0.0005032500484958291
Epoch:  454  	Training Loss: 0.00045447584125213325
Test Loss:  0.0004947927081957459
Valid Loss:  0.0005035626236349344
Epoch:  455  	Training Loss: 0.00045391934690997005
Test Loss:  0.0004956753691658378
Valid Loss:  0.0005039079114794731
Epoch:  456  	Training Loss: 0.000453478773124516
Test Loss:  0.0004964337567798793
Valid Loss:  0.0005042807897552848
Epoch:  457  	Training Loss: 0.00045309800771065056
Test Loss:  0.0004970289883203804
Valid Loss:  0.0005045818397775292
Epoch:  458  	Training Loss: 0.0004528110730461776
Test Loss:  0.0004975434858351946
Valid Loss:  0.0005048536695539951
Epoch:  459  	Training Loss: 0.00045255100121721625
Test Loss:  0.0004979908699169755
Valid Loss:  0.0005051002372056246
Epoch:  460  	Training Loss: 0.0004523131065070629
Test Loss:  0.000498382025398314
Valid Loss:  0.0005053248023614287
Epoch:  461  	Training Loss: 0.0004521091759670526
Test Loss:  0.0004986668936908245
Valid Loss:  0.0005054884823039174
Epoch:  462  	Training Loss: 0.00045194796985015273
Test Loss:  0.0004980037920176983
Valid Loss:  0.0005051505868323147
Epoch:  463  	Training Loss: 0.0004515977925620973
Test Loss:  0.0004973500035703182
Valid Loss:  0.000504817406181246
Epoch:  464  	Training Loss: 0.000451250554760918
Test Loss:  0.0004966799169778824
Valid Loss:  0.0005044787540100515
Epoch:  465  	Training Loss: 0.0004508797428570688
Test Loss:  0.0004959655925631523
Valid Loss:  0.000504136667586863
Epoch:  466  	Training Loss: 0.0004504956305027008
Test Loss:  0.0004952421877533197
Valid Loss:  0.0005037903320044279
Epoch:  467  	Training Loss: 0.00045009865425527096
Test Loss:  0.0004945297841913998
Valid Loss:  0.0005034490022808313
Epoch:  468  	Training Loss: 0.0004497072659432888
Test Loss:  0.000493826752062887
Valid Loss:  0.0005031112814322114
Epoch:  469  	Training Loss: 0.0004493210872169584
Test Loss:  0.0004931334406137466
Valid Loss:  0.0005027790321037173
Epoch:  470  	Training Loss: 0.00044894017628394067
Test Loss:  0.0004924494423903525
Valid Loss:  0.0005024503916501999
Epoch:  471  	Training Loss: 0.0004485644167289138
Test Loss:  0.0004917747573927045
Valid Loss:  0.0005021258257329464
Epoch:  472  	Training Loss: 0.000448193633928895
Test Loss:  0.00048727469402365386
Valid Loss:  0.0004977325443178415
Epoch:  473  	Training Loss: 0.00044665217865258455
Test Loss:  0.0004843522619921714
Valid Loss:  0.0004948963760398328
Epoch:  474  	Training Loss: 0.0004456191963981837
Test Loss:  0.00048236444126814604
Valid Loss:  0.0004929922288283706
Epoch:  475  	Training Loss: 0.00044483691453933716
Test Loss:  0.0004809413803741336
Valid Loss:  0.0004916265606880188
Epoch:  476  	Training Loss: 0.00044415704905986786
Test Loss:  0.00047987120342440903
Valid Loss:  0.0004905926180072129
Epoch:  477  	Training Loss: 0.00044352817349135876
Test Loss:  0.00047898414777591825
Valid Loss:  0.0004897702019661665
Epoch:  478  	Training Loss: 0.00044294900726526976
Test Loss:  0.0004778132715728134
Valid Loss:  0.0004889544798061252
Epoch:  479  	Training Loss: 0.00044241093564778566
Test Loss:  0.0004768123908434063
Valid Loss:  0.0004882860812358558
Epoch:  480  	Training Loss: 0.00044189213076606393
Test Loss:  0.00047592446208000183
Valid Loss:  0.0004877141327597201
Epoch:  481  	Training Loss: 0.0004413847054820508
Test Loss:  0.00047508988063782454
Valid Loss:  0.0004871947458013892
Epoch:  482  	Training Loss: 0.0004408684908412397
Test Loss:  0.00047472905134782195
Valid Loss:  0.00048689369577914476
 97%|█████████▋| 483/500 [05:47<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:47<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:47<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:47<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:53<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:53<00:05,  1.20it/s] 99%|█████████▉| 495/500 [05:54<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:54<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:54<00:00,  3.00it/s]100%|██████████| 500/500 [05:54<00:00,  1.41it/s]
Epoch:  483  	Training Loss: 0.00044048490235581994
Test Loss:  0.0004743149329442531
Valid Loss:  0.000486558536067605
Epoch:  484  	Training Loss: 0.000440110539784655
Test Loss:  0.0004738647839985788
Valid Loss:  0.0004861950292252004
Epoch:  485  	Training Loss: 0.0004397622251417488
Test Loss:  0.00047335089766420424
Valid Loss:  0.0004858030006289482
Epoch:  486  	Training Loss: 0.0004394428979139775
Test Loss:  0.0004724510363303125
Valid Loss:  0.00048530224012210965
Epoch:  487  	Training Loss: 0.0004391323891468346
Test Loss:  0.0004720271099358797
Valid Loss:  0.00048498620162718
Epoch:  488  	Training Loss: 0.00043882126919925213
Test Loss:  0.0004715866525657475
Valid Loss:  0.00048466084990650415
Epoch:  489  	Training Loss: 0.00043851544614881277
Test Loss:  0.00047113571781665087
Valid Loss:  0.0004843325586989522
Epoch:  490  	Training Loss: 0.0004382148617878556
Test Loss:  0.00047067931154742837
Valid Loss:  0.0004840028705075383
Epoch:  491  	Training Loss: 0.0004379191086627543
Test Loss:  0.0004702199948951602
Valid Loss:  0.0004836756270378828
Epoch:  492  	Training Loss: 0.0004376280994620174
Test Loss:  0.0004665798041969538
Valid Loss:  0.0004799733287654817
Epoch:  493  	Training Loss: 0.00043629464926198125
Test Loss:  0.00046444678446277976
Valid Loss:  0.00047747610369697213
Epoch:  494  	Training Loss: 0.00043521090992726386
Test Loss:  0.0004629622562788427
Valid Loss:  0.0004755072295665741
Epoch:  495  	Training Loss: 0.00043424201430752873
Test Loss:  0.00046179836499504745
Valid Loss:  0.000473805790534243
Epoch:  496  	Training Loss: 0.00043335885857231915
Test Loss:  0.0004608129383996129
Valid Loss:  0.0004722750745713711
Epoch:  497  	Training Loss: 0.0004325463087297976
Test Loss:  0.0004599352541845292
Valid Loss:  0.00047085905680432916
Epoch:  498  	Training Loss: 0.0004317947896197438
Test Loss:  0.0004591306787915528
Valid Loss:  0.00046953040873631835
Epoch:  499  	Training Loss: 0.0004310958320274949
Test Loss:  0.00045838282676413655
Valid Loss:  0.00046827367623336613
Epoch:  500  	Training Loss: 0.0004304434987716377
Test Loss:  0.0004576820938382298
Valid Loss:  0.0004670797206927091
seed is  14
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:34, 14.49it/s]  1%|          | 4/500 [00:00<00:37, 13.19it/s]  1%|          | 6/500 [00:00<00:38, 12.71it/s]  2%|▏         | 8/500 [00:00<00:38, 12.65it/s]  2%|▏         | 10/500 [00:00<00:36, 13.40it/s]  2%|▏         | 12/500 [00:00<00:34, 14.35it/s]  3%|▎         | 14/500 [00:00<00:32, 14.97it/s]  3%|▎         | 16/500 [00:01<00:31, 15.52it/s]  4%|▎         | 18/500 [00:01<00:30, 15.81it/s]  4%|▍         | 20/500 [00:01<00:30, 15.72it/s]  4%|▍         | 22/500 [00:01<00:31, 15.34it/s]  5%|▍         | 24/500 [00:01<00:30, 15.75it/s]  5%|▌         | 26/500 [00:01<00:29, 16.08it/s]  6%|▌         | 28/500 [00:01<00:28, 16.32it/s]  6%|▌         | 30/500 [00:01<00:28, 16.44it/s]  6%|▋         | 32/500 [00:02<00:28, 16.54it/s]  7%|▋         | 34/500 [00:02<00:28, 16.64it/s]  7%|▋         | 36/500 [00:02<00:27, 16.71it/s]  8%|▊         | 38/500 [00:02<00:27, 16.73it/s]  8%|▊         | 40/500 [00:02<00:27, 16.75it/s]  8%|▊         | 42/500 [00:02<00:27, 16.75it/s]  9%|▉         | 44/500 [00:02<00:27, 16.80it/s]  9%|▉         | 46/500 [00:02<00:27, 16.80it/s] 10%|▉         | 48/500 [00:03<00:27, 16.69it/s] 10%|█         | 50/500 [00:03<00:27, 16.59it/s] 10%|█         | 52/500 [00:03<00:26, 16.63it/s] 11%|█         | 54/500 [00:03<00:26, 16.62it/s] 11%|█         | 56/500 [00:03<00:26, 16.70it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.61it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.61it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.62it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.64it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.46it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.35it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.41it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.52it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.58it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.63it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.58it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.63it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.65it/s] 17%|█▋        | 84/500 [00:05<00:24, 16.70it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.59it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.51it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.63it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.58it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.58it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.66it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.70it/s] 20%|██        | 100/500 [00:06<00:23, 16.72it/s] 20%|██        | 102/500 [00:06<00:23, 16.76it/s] 21%|██        | 104/500 [00:06<00:23, 16.72it/s] 21%|██        | 106/500 [00:06<00:24, 16.39it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.46it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.40it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.51it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.57it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.62it/s] 24%|██▎       | 118/500 [00:07<00:22, 16.69it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.73it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.71it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.57it/s]Epoch:  1  	Training Loss: 0.26650020480155945
Test Loss:  4346.76171875
Valid Loss:  4349.58447265625
Epoch:  2  	Training Loss: 4348.087890625
Test Loss:  69819529428992.0
Valid Loss:  70104284921856.0
Epoch:  3  	Training Loss: 70048156745728.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.39it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.51it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.57it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.63it/s] 27%|██▋       | 134/500 [00:08<00:21, 16.66it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.67it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.68it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.70it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.70it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.70it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.74it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.74it/s] 30%|███       | 150/500 [00:09<00:20, 16.76it/s] 30%|███       | 152/500 [00:09<00:20, 16.79it/s] 31%|███       | 154/500 [00:09<00:20, 16.65it/s] 31%|███       | 156/500 [00:09<00:20, 16.57it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.67it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.67it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.65it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.50it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.62it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.57it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.44it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.08it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.14it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.30it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.42it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.54it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.57it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.59it/s] 37%|███▋      | 186/500 [00:11<00:18, 16.63it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.63it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.44it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.35it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.44it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.43it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.49it/s] 40%|████      | 200/500 [00:12<00:18, 16.54it/s] 40%|████      | 202/500 [00:12<00:17, 16.63it/s] 41%|████      | 204/500 [00:12<00:17, 16.75it/s] 41%|████      | 206/500 [00:12<00:17, 16.66it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.62it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.51it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.59it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.62it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.61it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.55it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.60it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.60it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.36it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.46it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.46it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.57it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.62it/s] 47%|████▋     | 234/500 [00:14<00:15, 16.66it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.71it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.74it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.73it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.78it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.80it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.80it/s] 50%|████▉     | 248/500 [00:15<00:14, 16.81it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:14, 16.81it/s] 50%|█████     | 252/500 [00:15<00:14, 16.81it/s] 51%|█████     | 254/500 [00:15<00:14, 16.77it/s] 51%|█████     | 256/500 [00:15<00:14, 16.79it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.76it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.74it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.73it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.65it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.40it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.40it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.36it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.51it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.54it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.58it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.30it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.21it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.27it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.26it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.29it/s] 58%|█████▊    | 288/500 [00:17<00:13, 16.26it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.23it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.16it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.25it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.27it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.11it/s] 60%|██████    | 300/500 [00:18<00:12, 16.25it/s] 60%|██████    | 302/500 [00:18<00:12, 15.34it/s] 61%|██████    | 304/500 [00:18<00:13, 14.91it/s] 61%|██████    | 306/500 [00:18<00:12, 15.38it/s] 62%|██████▏   | 308/500 [00:18<00:12, 15.13it/s] 62%|██████▏   | 310/500 [00:18<00:12, 15.54it/s] 62%|██████▏   | 312/500 [00:19<00:12, 14.94it/s] 63%|██████▎   | 314/500 [00:19<00:12, 15.24it/s] 63%|██████▎   | 316/500 [00:19<00:12, 15.07it/s] 64%|██████▎   | 318/500 [00:19<00:12, 14.70it/s] 64%|██████▍   | 320/500 [00:19<00:11, 15.23it/s] 64%|██████▍   | 322/500 [00:19<00:12, 14.68it/s] 65%|██████▍   | 324/500 [00:19<00:11, 14.69it/s] 65%|██████▌   | 326/500 [00:20<00:11, 15.28it/s] 66%|██████▌   | 328/500 [00:20<00:10, 15.74it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.09it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.31it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.28it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.36it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.34it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.47it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.55it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.58it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.58it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.61it/s] 70%|███████   | 350/500 [00:21<00:09, 16.63it/s] 70%|███████   | 352/500 [00:21<00:08, 16.49it/s] 71%|███████   | 354/500 [00:21<00:08, 16.51it/s] 71%|███████   | 356/500 [00:21<00:08, 16.63it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.69it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.52it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.58it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.61it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.64it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.64it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.66it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.68it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.68it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.45it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.37it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.46it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.46it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.31it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.31it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.41it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.44it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.51it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.53it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.49it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.42it/s] 80%|████████  | 400/500 [00:24<00:06, 16.48it/s] 80%|████████  | 402/500 [00:24<00:05, 16.34it/s] 81%|████████  | 404/500 [00:24<00:05, 16.23it/s] 81%|████████  | 406/500 [00:24<00:05, 16.34it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.39it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.47it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.23it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.07it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.23it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.34it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.30it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.35it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.15it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.23it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.37it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.49it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.60it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.64it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.62it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.67it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.58it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.64it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.66it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.81it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.85it/s] 90%|█████████ | 450/500 [00:27<00:02, 16.86it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.75it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.71it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.73it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.69it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.67it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.68it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.53it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.63it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.56it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.61it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.56it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.62it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.68it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.76it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.76it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.72it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.56it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.56it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.43it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.36it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.39it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.44it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.52it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.48it/s]100%|██████████| 500/500 [00:30<00:00, 16.38it/s]100%|██████████| 500/500 [00:30<00:00, 16.37it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  14
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:29,  6.31s/it]  1%|          | 3/500 [00:06<13:58,  1.69s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.98it/s]  6%|▌         | 31/500 [00:26<09:22,  1.20s/it]  7%|▋         | 33/500 [00:27<06:41,  1.16it/s]  7%|▋         | 35/500 [00:27<04:48,  1.61it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:37,  2.93it/s]  8%|▊         | 41/500 [00:33<09:10,  1.20s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.95it/s] 10%|█         | 51/500 [00:40<08:56,  1.20s/it] 11%|█         | 53/500 [00:40<06:24,  1.16it/s] 11%|█         | 55/500 [00:41<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.96it/s] 12%|█▏        | 61/500 [00:47<08:45,  1.20s/it] 13%|█▎        | 63/500 [00:47<06:15,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:48<03:16,  2.20it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.96it/s]Epoch:  1  	Training Loss: 0.26650020480155945
Test Loss:  0.026791201904416084
Valid Loss:  0.02538309618830681
Epoch:  2  	Training Loss: 0.02703273296356201
Test Loss:  0.016231771558523178
Valid Loss:  0.01803785189986229
Epoch:  3  	Training Loss: 0.01840652897953987
Test Loss:  0.013163636438548565
Valid Loss:  0.015021372586488724
Epoch:  4  	Training Loss: 0.015293785370886326
Test Loss:  0.010772114619612694
Valid Loss:  0.012530659325420856
Epoch:  5  	Training Loss: 0.01276693120598793
Test Loss:  0.008851926773786545
Valid Loss:  0.010502675548195839
Epoch:  6  	Training Loss: 0.010709632188081741
Test Loss:  0.007317754440009594
Valid Loss:  0.008869826793670654
Epoch:  7  	Training Loss: 0.009051432833075523
Test Loss:  0.006101381499320269
Valid Loss:  0.007565580774098635
Epoch:  8  	Training Loss: 0.007715616375207901
Test Loss:  0.0051390849985182285
Valid Loss:  0.006478770636022091
Epoch:  9  	Training Loss: 0.006622792221605778
Test Loss:  0.004366206005215645
Valid Loss:  0.005599827505648136
Epoch:  10  	Training Loss: 0.005728657823055983
Test Loss:  0.0037518080789595842
Valid Loss:  0.00487372325733304
Epoch:  11  	Training Loss: 0.004997452720999718
Test Loss:  0.0032623447477817535
Valid Loss:  0.00428412389010191
Epoch:  12  	Training Loss: 0.004400646314024925
Test Loss:  0.002875570673495531
Valid Loss:  0.0038008196279406548
Epoch:  13  	Training Loss: 0.003912219312041998
Test Loss:  0.0025708468165248632
Valid Loss:  0.0034065553918480873
Epoch:  14  	Training Loss: 0.003513844683766365
Test Loss:  0.002334124408662319
Valid Loss:  0.003086477518081665
Epoch:  15  	Training Loss: 0.0031899060122668743
Test Loss:  0.0021494373213499784
Valid Loss:  0.0028226743452250957
Epoch:  16  	Training Loss: 0.0029239552095532417
Test Loss:  0.002006229944527149
Valid Loss:  0.0026057763025164604
Epoch:  17  	Training Loss: 0.0027053882367908955
Test Loss:  0.0018959726439788938
Valid Loss:  0.002427351661026478
Epoch:  18  	Training Loss: 0.0025257188826799393
Test Loss:  0.0018124496564269066
Valid Loss:  0.0022807572968304157
Epoch:  19  	Training Loss: 0.0023779592011123896
Test Loss:  0.0017497783992439508
Valid Loss:  0.0021606336813420057
Epoch:  20  	Training Loss: 0.00225688680075109
Test Loss:  0.0017041524406522512
Valid Loss:  0.002062518149614334
Epoch:  21  	Training Loss: 0.002158238086849451
Test Loss:  0.0016718681436032057
Valid Loss:  0.001981914509087801
Epoch:  22  	Training Loss: 0.0020772237330675125
Test Loss:  0.0016496041789650917
Valid Loss:  0.001915414584800601
Epoch:  23  	Training Loss: 0.002010615076869726
Test Loss:  0.001635403954423964
Valid Loss:  0.0018604705110192299
Epoch:  24  	Training Loss: 0.001955626532435417
Test Loss:  0.001627402612939477
Valid Loss:  0.0018150113755837083
Epoch:  25  	Training Loss: 0.0019102022051811218
Test Loss:  0.0016237515956163406
Valid Loss:  0.0017773292493075132
Epoch:  26  	Training Loss: 0.0018726567504927516
Test Loss:  0.0016239599790424109
Valid Loss:  0.0017461227253079414
Epoch:  27  	Training Loss: 0.001841600751504302
Test Loss:  0.0016264142468571663
Valid Loss:  0.0017202409217134118
Epoch:  28  	Training Loss: 0.0018159407190978527
Test Loss:  0.0016312426887452602
Valid Loss:  0.0016987647395581007
Epoch:  29  	Training Loss: 0.0017946832813322544
Test Loss:  0.0016372182872146368
Valid Loss:  0.0016809245571494102
Epoch:  30  	Training Loss: 0.0017771036364138126
Test Loss:  0.001644117059186101
Valid Loss:  0.0016661073314025998
Epoch:  31  	Training Loss: 0.0017625510226935148
Test Loss:  0.0016517825424671173
Valid Loss:  0.0016537457704544067
Epoch:  32  	Training Loss: 0.0017504655988886952
Test Loss:  0.0016598040238022804
Valid Loss:  0.0016435511643067002
Epoch:  33  	Training Loss: 0.00174041953869164
Test Loss:  0.001667506294324994
Valid Loss:  0.0016350969672203064
Epoch:  34  	Training Loss: 0.0017321074847131968
Test Loss:  0.0016755920369178057
Valid Loss:  0.0016280764248222113
Epoch:  35  	Training Loss: 0.001725193578749895
Test Loss:  0.0016834336565807462
Valid Loss:  0.0016222074627876282
Epoch:  36  	Training Loss: 0.001719456515274942
Test Loss:  0.001690685166977346
Valid Loss:  0.001617327448911965
Epoch:  37  	Training Loss: 0.0017147097969427705
Test Loss:  0.001698048086836934
Valid Loss:  0.0016132388263940811
Epoch:  38  	Training Loss: 0.0017107526073232293
Test Loss:  0.0017050018068403006
Valid Loss:  0.0016098020132631063
Epoch:  39  	Training Loss: 0.0017074455972760916
Test Loss:  0.0017115771770477295
Valid Loss:  0.001606898964382708
Epoch:  40  	Training Loss: 0.0017046747962012887
Test Loss:  0.0017175639513880014
Valid Loss:  0.0016044751973822713
Epoch:  41  	Training Loss: 0.0017023724503815174
Test Loss:  0.0017232170794159174
Valid Loss:  0.0016024451470002532
Epoch:  42  	Training Loss: 0.0017004664987325668
Test Loss:  0.0017285561189055443
Valid Loss:  0.00160075759049505
Epoch:  43  	Training Loss: 0.001698892330750823
Test Loss:  0.0017335939919576049
Valid Loss:  0.0015993458218872547
Epoch:  44  	Training Loss: 0.0016975882463157177
Test Loss:  0.0017383224330842495
Valid Loss:  0.0015981604810804129
Epoch:  45  	Training Loss: 0.0016965069808065891
Test Loss:  0.0017427714774385095
Valid Loss:  0.001597149996086955
Epoch:  46  	Training Loss: 0.0016956073231995106
Test Loss:  0.0017467340221628547
Valid Loss:  0.001596344169229269
Epoch:  47  	Training Loss: 0.0016948673874139786
Test Loss:  0.0017506382428109646
Valid Loss:  0.0015956268180161715
Epoch:  48  	Training Loss: 0.0016942492220550776
Test Loss:  0.0017539960099384189
Valid Loss:  0.0015950808301568031
Epoch:  49  	Training Loss: 0.0016937353648245335
Test Loss:  0.0017573387594893575
Valid Loss:  0.0015946002677083015
Epoch:  50  	Training Loss: 0.0016933097504079342
Test Loss:  0.0017603954765945673
Valid Loss:  0.0015941864112392068
Epoch:  51  	Training Loss: 0.0016929551493376493
Test Loss:  0.0017631800146773458
Valid Loss:  0.0015938237775117159
Epoch:  52  	Training Loss: 0.0016926575917750597
Test Loss:  0.001765703083947301
Valid Loss:  0.001593506895005703
Epoch:  53  	Training Loss: 0.0016924039227887988
Test Loss:  0.0017680085729807615
Valid Loss:  0.001593225752003491
Epoch:  54  	Training Loss: 0.001692191930487752
Test Loss:  0.0017701006727293134
Valid Loss:  0.0015929758083075285
Epoch:  55  	Training Loss: 0.0016920107882469893
Test Loss:  0.0017720013856887817
Valid Loss:  0.0015927510103210807
Epoch:  56  	Training Loss: 0.0016918518813326955
Test Loss:  0.0017737210728228092
Valid Loss:  0.0015925447223708034
Epoch:  57  	Training Loss: 0.0016917164903134108
Test Loss:  0.0017752822022885084
Valid Loss:  0.0015923538012430072
Epoch:  58  	Training Loss: 0.0016915971646085382
Test Loss:  0.0017767027020454407
Valid Loss:  0.0015921834856271744
Epoch:  59  	Training Loss: 0.001691490993835032
Test Loss:  0.0017779857153072953
Valid Loss:  0.0015920154983177781
Epoch:  60  	Training Loss: 0.0016913990257307887
Test Loss:  0.0017791430000215769
Valid Loss:  0.0015918598510324955
Epoch:  61  	Training Loss: 0.001691314042545855
Test Loss:  0.0017801932990550995
Valid Loss:  0.0015917293494567275
Epoch:  62  	Training Loss: 0.0016912344144657254
Test Loss:  0.0017811453435570002
Valid Loss:  0.0015916448319330812
Epoch:  63  	Training Loss: 0.0016911652637645602
Test Loss:  0.0017820019274950027
Valid Loss:  0.001591577660292387
Epoch:  64  	Training Loss: 0.0016911050770431757
Test Loss:  0.001782572246156633
Valid Loss:  0.0015915357507765293
Epoch:  65  	Training Loss: 0.0016910519916564226
Test Loss:  0.0017835022881627083
Valid Loss:  0.0015914634568616748
Epoch:  66  	Training Loss: 0.0016910103149712086
Test Loss:  0.00178417912684381
Valid Loss:  0.001591415610164404
Epoch:  67  	Training Loss: 0.0016909660771489143
Test Loss:  0.0017847195267677307
Valid Loss:  0.0015913920942693949
Epoch:  68  	Training Loss: 0.0016909304540604353
Test Loss:  0.0017854685429483652
Valid Loss:  0.0015913486713543534
Epoch:  69  	Training Loss: 0.0016908964607864618
Test Loss:  0.0017860280349850655
Valid Loss:  0.001591309905052185
Epoch:  70  	Training Loss: 0.0016908689867705107
Test Loss:   14%|█▍        | 71/500 [00:54<08:36,  1.20s/it] 15%|█▍        | 73/500 [00:54<06:08,  1.16it/s] 15%|█▌        | 75/500 [00:55<04:25,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:13,  2.19it/s] 16%|█▌        | 79/500 [00:55<02:22,  2.95it/s] 16%|█▌        | 81/500 [01:01<08:15,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:54,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:02<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:02<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:08<08:04,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:46,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:09<02:13,  2.99it/s] 20%|██        | 101/500 [01:15<07:48,  1.17s/it] 21%|██        | 103/500 [01:15<05:34,  1.19it/s] 21%|██        | 105/500 [01:15<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:15<02:09,  3.01it/s] 22%|██▏       | 111/500 [01:22<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:22<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:22<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:22<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:28<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:36<03:43,  1.64it/s] 27%|██▋       | 137/500 [01:36<02:42,  2.24it/s]0.0017866137204691768
Valid Loss:  0.0015912700910121202
Epoch:  71  	Training Loss: 0.0016908389516174793
Test Loss:  0.0017869274597615004
Valid Loss:  0.0015912556555122137
Epoch:  72  	Training Loss: 0.0016908145043998957
Test Loss:  0.00178737030364573
Valid Loss:  0.001591228530742228
Epoch:  73  	Training Loss: 0.0016907888930290937
Test Loss:  0.0017878039507195354
Valid Loss:  0.001591197680681944
Epoch:  74  	Training Loss: 0.0016907663084566593
Test Loss:  0.0017882529646158218
Valid Loss:  0.0015911669470369816
Epoch:  75  	Training Loss: 0.0016907420940697193
Test Loss:  0.001788499765098095
Valid Loss:  0.0015911504160612822
Epoch:  76  	Training Loss: 0.0016907197423279285
Test Loss:  0.00178889324888587
Valid Loss:  0.0015911166556179523
Epoch:  77  	Training Loss: 0.001690699253231287
Test Loss:  0.0017890720628201962
Valid Loss:  0.0015911022201180458
Epoch:  78  	Training Loss: 0.0016906802775338292
Test Loss:  0.0017894338816404343
Valid Loss:  0.0015910705551505089
Epoch:  79  	Training Loss: 0.0016906608361750841
Test Loss:  0.0017894608899950981
Valid Loss:  0.0015910640358924866
Epoch:  80  	Training Loss: 0.0016906405799090862
Test Loss:  0.0017897090874612331
Valid Loss:  0.0015910384245216846
Epoch:  81  	Training Loss: 0.0016906228847801685
Test Loss:  0.0017898736987262964
Valid Loss:  0.0015910251531749964
Epoch:  82  	Training Loss: 0.0016906033270061016
Test Loss:  0.0017900519305840135
Valid Loss:  0.001591003267094493
Epoch:  83  	Training Loss: 0.0016905874945223331
Test Loss:  0.001790213049389422
Valid Loss:  0.0015909865032881498
Epoch:  84  	Training Loss: 0.0016905665397644043
Test Loss:  0.0017903638072311878
Valid Loss:  0.0015909692738205194
Epoch:  85  	Training Loss: 0.0016905481461435556
Test Loss:  0.0017904959386214614
Valid Loss:  0.001590945990756154
Epoch:  86  	Training Loss: 0.0016905306838452816
Test Loss:  0.0017906022258102894
Valid Loss:  0.0015909296926110983
Epoch:  87  	Training Loss: 0.0016905141528695822
Test Loss:  0.0017907151486724615
Valid Loss:  0.0015909094363451004
Epoch:  88  	Training Loss: 0.0016904959920793772
Test Loss:  0.0017908058362081647
Valid Loss:  0.001590894302353263
Epoch:  89  	Training Loss: 0.0016904774820432067
Test Loss:  0.0017908893059939146
Valid Loss:  0.0015908812638372183
Epoch:  90  	Training Loss: 0.0016904606018215418
Test Loss:  0.001791022252291441
Valid Loss:  0.0015908597270026803
Epoch:  91  	Training Loss: 0.0016904454678297043
Test Loss:  0.0017909742891788483
Valid Loss:  0.0015908475033938885
Epoch:  92  	Training Loss: 0.0016904270742088556
Test Loss:  0.001791038434021175
Valid Loss:  0.001590832369402051
Epoch:  93  	Training Loss: 0.0016904117073863745
Test Loss:  0.0017910896567627788
Valid Loss:  0.001590821659192443
Epoch:  94  	Training Loss: 0.001690393895842135
Test Loss:  0.0017911375034600496
Valid Loss:  0.0015907969791442156
Epoch:  95  	Training Loss: 0.0016903779469430447
Test Loss:  0.0017911854665726423
Valid Loss:  0.0015907872002571821
Epoch:  96  	Training Loss: 0.0016903607174754143
Test Loss:  0.0017912231851369143
Valid Loss:  0.0015907709021121264
Epoch:  97  	Training Loss: 0.0016903458163142204
Test Loss:  0.0017912450712174177
Valid Loss:  0.0015907571651041508
Epoch:  98  	Training Loss: 0.0016903301002457738
Test Loss:  0.0017912698676809669
Valid Loss:  0.0015907436609268188
Epoch:  99  	Training Loss: 0.0016903134528547525
Test Loss:  0.0017913010669872165
Valid Loss:  0.0015907229389995337
Epoch:  100  	Training Loss: 0.0016902971547096968
Test Loss:  0.0017913136398419738
Valid Loss:  0.0015907083870843053
Epoch:  101  	Training Loss: 0.0016902820207178593
Test Loss:  0.0017913402989506721
Valid Loss:  0.0015906936023384333
Epoch:  102  	Training Loss: 0.0016902661882340908
Test Loss:  0.001791347865946591
Valid Loss:  0.0015906842891126871
Epoch:  103  	Training Loss: 0.001690251985564828
Test Loss:  0.0017913577612489462
Valid Loss:  0.0015906670596450567
Epoch:  104  	Training Loss: 0.0016902363859117031
Test Loss:  0.0017913647461682558
Valid Loss:  0.001590654836036265
Epoch:  105  	Training Loss: 0.001690220320597291
Test Loss:  0.0017913724295794964
Valid Loss:  0.001590639352798462
Epoch:  106  	Training Loss: 0.0016902065835893154
Test Loss:  0.0017913770861923695
Valid Loss:  0.0015906263142824173
Epoch:  107  	Training Loss: 0.0016901892377063632
Test Loss:  0.001791380112990737
Valid Loss:  0.0015906142070889473
Epoch:  108  	Training Loss: 0.001690177246928215
Test Loss:  0.0017914528725668788
Valid Loss:  0.001590584870427847
Epoch:  109  	Training Loss: 0.0016901623457670212
Test Loss:  0.0017913284245878458
Valid Loss:  0.0015905823092907667
Epoch:  110  	Training Loss: 0.0016901441849768162
Test Loss:  0.001791332382708788
Valid Loss:  0.0015905681066215038
Epoch:  111  	Training Loss: 0.0016901298658922315
Test Loss:  0.0017913331976160407
Valid Loss:  0.0015905596083030105
Epoch:  112  	Training Loss: 0.0016901149647310376
Test Loss:  0.0017913352930918336
Valid Loss:  0.0015905441250652075
Epoch:  113  	Training Loss: 0.0016901001799851656
Test Loss:  0.0017913352930918336
Valid Loss:  0.0015905308537185192
Epoch:  114  	Training Loss: 0.0016900836490094662
Test Loss:  0.0017913347110152245
Valid Loss:  0.0015905213076621294
Epoch:  115  	Training Loss: 0.0016900717746466398
Test Loss:  0.001791331684216857
Valid Loss:  0.001590507454238832
Epoch:  116  	Training Loss: 0.001690057571977377
Test Loss:  0.001791326212696731
Valid Loss:  0.0015904941828921437
Epoch:  117  	Training Loss: 0.0016900412738323212
Test Loss:  0.0017913159681484103
Valid Loss:  0.0015904834726825356
Epoch:  118  	Training Loss: 0.0016900281189009547
Test Loss:  0.00179132423363626
Valid Loss:  0.0015904735773801804
Epoch:  119  	Training Loss: 0.0016900133341550827
Test Loss:  0.0017913151532411575
Valid Loss:  0.0015904553001746535
Epoch:  120  	Training Loss: 0.0016899991314858198
Test Loss:  0.0017913090996444225
Valid Loss:  0.0015904491301625967
Epoch:  121  	Training Loss: 0.0016899870242923498
Test Loss:  0.0017913011834025383
Valid Loss:  0.0015904336469247937
Epoch:  122  	Training Loss: 0.001689974102191627
Test Loss:  0.0017912968760356307
Valid Loss:  0.0015904223546385765
Epoch:  123  	Training Loss: 0.001689958618953824
Test Loss:  0.0017912923358380795
Valid Loss:  0.0015904135070741177
Epoch:  124  	Training Loss: 0.0016899468610063195
Test Loss:  0.0017912874463945627
Valid Loss:  0.0015903954626992345
Epoch:  125  	Training Loss: 0.0016899313777685165
Test Loss:  0.001791277201846242
Valid Loss:  0.001590388361364603
Epoch:  126  	Training Loss: 0.0016899181064218283
Test Loss:  0.0017912869807332754
Valid Loss:  0.0015903747407719493
Epoch:  127  	Training Loss: 0.0016899054171517491
Test Loss:  0.0017912524053826928
Valid Loss:  0.0015903610037639737
Epoch:  128  	Training Loss: 0.0016898901667445898
Test Loss:  0.0017912453040480614
Valid Loss:  0.001590354717336595
Epoch:  129  	Training Loss: 0.0016898770118132234
Test Loss:  0.0017912419280037284
Valid Loss:  0.0015903429593890905
Epoch:  130  	Training Loss: 0.0016898630419746041
Test Loss:  0.0017912329640239477
Valid Loss:  0.0015903266612440348
Epoch:  131  	Training Loss: 0.0016898494213819504
Test Loss:  0.0017912250477820635
Valid Loss:  0.0015903192106634378
Epoch:  132  	Training Loss: 0.0016898381290957332
Test Loss:  0.001791214570403099
Valid Loss:  0.0015903080347925425
Epoch:  133  	Training Loss: 0.0016898232279345393
Test Loss:  0.0017912082839757204
Valid Loss:  0.0015902930172160268
Epoch:  134  	Training Loss: 0.0016898110043257475
Test Loss:  0.001791201764717698
Valid Loss:  0.0015902809100225568
Epoch:  135  	Training Loss: 0.0016897970344871283
Test Loss:  0.0017911952454596758
Valid Loss:  0.0015902703162282705
Epoch:  136  	Training Loss: 0.0016897831810638309
Test Loss:  0.0017911854665726423
Valid Loss:  0.0015902601880952716
Epoch:  137  	Training Loss: 0.0016897710738703609
Test Loss:  0.0017911841860041022
Valid Loss:  0.0015902447048574686
Epoch:  138  	Training Loss: 0.0016897572204470634
Test Loss:  0.0017911740578711033
Valid Loss:  0.0015902337618172169
 28%|██▊       | 139/500 [01:36<02:00,  3.01it/s] 28%|██▊       | 141/500 [01:42<07:13,  1.21s/it] 29%|██▊       | 143/500 [01:42<05:09,  1.15it/s] 29%|██▉       | 145/500 [01:43<03:42,  1.59it/s] 29%|██▉       | 147/500 [01:43<02:42,  2.18it/s] 30%|██▉       | 149/500 [01:43<01:59,  2.93it/s] 30%|███       | 151/500 [01:49<06:51,  1.18s/it] 31%|███       | 153/500 [01:49<04:53,  1.18it/s] 31%|███       | 155/500 [01:49<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:50<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:50<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:56<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:45,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:57<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:03<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:03<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:03<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:03<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:03<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:10<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:10<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:10<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:10<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:16<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:17<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:17<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:17<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:17<01:39,  3.02it/s] 40%|████      | 201/500 [02:23<05:51,  1.18s/it] 41%|████      | 203/500 [02:23<04:10,  1.18it/s] 41%|████      | 205/500 [02:24<03:00,  1.64it/s]Epoch:  139  	Training Loss: 0.0016897418536245823
Test Loss:  0.001791162765584886
Valid Loss:  0.0015902246814221144
Epoch:  140  	Training Loss: 0.0016897282330319285
Test Loss:  0.001791155431419611
Valid Loss:  0.001590213505551219
Epoch:  141  	Training Loss: 0.0016897169407457113
Test Loss:  0.0017911475151777267
Valid Loss:  0.0015901984879747033
Epoch:  142  	Training Loss: 0.0016897020395845175
Test Loss:  0.0017911349423229694
Valid Loss:  0.0015901880105957389
Epoch:  143  	Training Loss: 0.0016896887682378292
Test Loss:  0.0017911279574036598
Valid Loss:  0.001590170431882143
Epoch:  144  	Training Loss: 0.0016896766610443592
Test Loss:  0.0017911181785166264
Valid Loss:  0.0015901615843176842
Epoch:  145  	Training Loss: 0.001689661992713809
Test Loss:  0.0017911179456859827
Valid Loss:  0.001590151572600007
Epoch:  146  	Training Loss: 0.0016896487213671207
Test Loss:  0.001791221322491765
Valid Loss:  0.0015901282895356417
Epoch:  147  	Training Loss: 0.0016896374290809035
Test Loss:  0.0017910001333802938
Valid Loss:  0.001590134110301733
Epoch:  148  	Training Loss: 0.0016896254383027554
Test Loss:  0.001791006070561707
Valid Loss:  0.0015901199076324701
Epoch:  149  	Training Loss: 0.001689614960923791
Test Loss:  0.0017910012975335121
Valid Loss:  0.001590108498930931
Epoch:  150  	Training Loss: 0.0016896009910851717
Test Loss:  0.0017909969901666045
Valid Loss:  0.0015900961589068174
Epoch:  151  	Training Loss: 0.0016895895823836327
Test Loss:  0.0017909930320456624
Valid Loss:  0.0015900880098342896
Epoch:  152  	Training Loss: 0.0016895774751901627
Test Loss:  0.001790995942428708
Valid Loss:  0.0015900707803666592
Epoch:  153  	Training Loss: 0.0016895639710128307
Test Loss:  0.0017909957095980644
Valid Loss:  0.0015900616999715567
Epoch:  154  	Training Loss: 0.0016895553562790155
Test Loss:  0.0017909931484609842
Valid Loss:  0.0015900483122095466
Epoch:  155  	Training Loss: 0.001689542317762971
Test Loss:  0.001790986629202962
Valid Loss:  0.0015900391153991222
Epoch:  156  	Training Loss: 0.0016895330045372248
Test Loss:  0.0017909849993884563
Valid Loss:  0.0015900286380201578
Epoch:  157  	Training Loss: 0.0016895206645131111
Test Loss:  0.0017909732414409518
Valid Loss:  0.0015900201397016644
Epoch:  158  	Training Loss: 0.001689508673734963
Test Loss:  0.0017909710295498371
Valid Loss:  0.0015900091966614127
Epoch:  159  	Training Loss: 0.0016894983127713203
Test Loss:  0.001790967071428895
Valid Loss:  0.0015900001162663102
Epoch:  160  	Training Loss: 0.0016894852742552757
Test Loss:  0.0017909654416143894
Valid Loss:  0.0015899898717179894
Epoch:  161  	Training Loss: 0.0016894766595214605
Test Loss:  0.0017909517046064138
Valid Loss:  0.0015899842837825418
Epoch:  162  	Training Loss: 0.0016894650179892778
Test Loss:  0.0017909465823322535
Valid Loss:  0.0015899736899882555
Epoch:  163  	Training Loss: 0.0016894529107958078
Test Loss:  0.001790940179489553
Valid Loss:  0.0015899650752544403
Epoch:  164  	Training Loss: 0.0016894422005861998
Test Loss:  0.0017909377347677946
Valid Loss:  0.0015899462159723043
Epoch:  165  	Training Loss: 0.0016894324216991663
Test Loss:  0.0017909304006025195
Valid Loss:  0.0015899422578513622
Epoch:  166  	Training Loss: 0.0016894207801669836
Test Loss:  0.0017909237649291754
Valid Loss:  0.0015899307327345014
Epoch:  167  	Training Loss: 0.0016894100699573755
Test Loss:  0.0017909164307639003
Valid Loss:  0.001589922932907939
Epoch:  168  	Training Loss: 0.0016893965657800436
Test Loss:  0.0017909096786752343
Valid Loss:  0.0015899140853434801
Epoch:  169  	Training Loss: 0.0016893886495381594
Test Loss:  0.0017909054877236485
Valid Loss:  0.00158989941701293
Epoch:  170  	Training Loss: 0.0016893763095140457
Test Loss:  0.001790895825251937
Valid Loss:  0.0015898924320936203
Epoch:  171  	Training Loss: 0.0016893654828891158
Test Loss:  0.00179088965523988
Valid Loss:  0.001589880557730794
Epoch:  172  	Training Loss: 0.0016893560532480478
Test Loss:  0.0017908790614455938
Valid Loss:  0.00158987776376307
Epoch:  173  	Training Loss: 0.001689345808699727
Test Loss:  0.0017908770823851228
Valid Loss:  0.0015898654237389565
Epoch:  174  	Training Loss: 0.0016893325373530388
Test Loss:  0.0017908671870827675
Valid Loss:  0.001589857041835785
Epoch:  175  	Training Loss: 0.00168932368978858
Test Loss:  0.0017908603185787797
Valid Loss:  0.001589847495779395
Epoch:  176  	Training Loss: 0.001689312281087041
Test Loss:  0.001790849957615137
Valid Loss:  0.0015898370184004307
Epoch:  177  	Training Loss: 0.0016893025022000074
Test Loss:  0.0017908443696796894
Valid Loss:  0.0015898285200819373
Epoch:  178  	Training Loss: 0.0016892917919903994
Test Loss:  0.0017908329609781504
Valid Loss:  0.0015898174606263638
Epoch:  179  	Training Loss: 0.0016892824787646532
Test Loss:  0.0017908293521031737
Valid Loss:  0.0015898076817393303
Epoch:  180  	Training Loss: 0.0016892728162929416
Test Loss:  0.001790820388123393
Valid Loss:  0.0015898001147434115
Epoch:  181  	Training Loss: 0.0016892623389139771
Test Loss:  0.0017908134032040834
Valid Loss:  0.0015897905686870217
Epoch:  182  	Training Loss: 0.0016892527928575873
Test Loss:  0.0017908092122524977
Valid Loss:  0.0015897838165983558
Epoch:  183  	Training Loss: 0.0016892419662326574
Test Loss:  0.0017908065347000957
Valid Loss:  0.001589775551110506
Epoch:  184  	Training Loss: 0.0016892347484827042
Test Loss:  0.0017907931469380856
Valid Loss:  0.0015897639095783234
Epoch:  185  	Training Loss: 0.0016892231069505215
Test Loss:  0.0017907910514622927
Valid Loss:  0.0015897615812718868
Epoch:  186  	Training Loss: 0.001689212047494948
Test Loss:  0.001790783368051052
Valid Loss:  0.0015897501725703478
Epoch:  187  	Training Loss: 0.0016892051789909601
Test Loss:  0.0017907782457768917
Valid Loss:  0.001589739928022027
Epoch:  188  	Training Loss: 0.0016891948180273175
Test Loss:  0.0017907690489664674
Valid Loss:  0.0015897287521511316
Epoch:  189  	Training Loss: 0.0016891853883862495
Test Loss:  0.001790762646123767
Valid Loss:  0.0015897229313850403
Epoch:  190  	Training Loss: 0.001689175609499216
Test Loss:  0.0017907621804624796
Valid Loss:  0.0015897135017439723
Epoch:  191  	Training Loss: 0.0016891665291041136
Test Loss:  0.001790749141946435
Valid Loss:  0.0015897070989012718
Epoch:  192  	Training Loss: 0.0016891562845557928
Test Loss:  0.0017907465808093548
Valid Loss:  0.0015896969707682729
Epoch:  193  	Training Loss: 0.0016891465056687593
Test Loss:  0.0017907407600432634
Valid Loss:  0.0015896891709417105
Epoch:  194  	Training Loss: 0.0016891402192413807
Test Loss:  0.0017907279543578625
Valid Loss:  0.0015896832337602973
Epoch:  195  	Training Loss: 0.0016891295090317726
Test Loss:  0.001790726324543357
Valid Loss:  0.0015896777622401714
Epoch:  196  	Training Loss: 0.0016891189152374864
Test Loss:  0.0017907217843458056
Valid Loss:  0.001589667983353138
Epoch:  197  	Training Loss: 0.001689113094471395
Test Loss:  0.0017907186411321163
Valid Loss:  0.0015896591357886791
Epoch:  198  	Training Loss: 0.0016891064587980509
Test Loss:  0.0017907093279063702
Valid Loss:  0.0015896474942564964
Epoch:  199  	Training Loss: 0.0016890967963263392
Test Loss:  0.0017907072324305773
Valid Loss:  0.0015896433033049107
Epoch:  200  	Training Loss: 0.0016890873666852713
Test Loss:  0.0017907037399709225
Valid Loss:  0.0015896360855549574
Epoch:  201  	Training Loss: 0.001689080148935318
Test Loss:  0.0017906969878822565
Valid Loss:  0.001589628285728395
Epoch:  202  	Training Loss: 0.0016890702536329627
Test Loss:  0.0017906911671161652
Valid Loss:  0.001589620253071189
Epoch:  203  	Training Loss: 0.0016890590777620673
Test Loss:  0.0017906875582411885
Valid Loss:  0.0015896155964583158
Epoch:  204  	Training Loss: 0.001689053839072585
Test Loss:  0.0017906827852129936
Valid Loss:  0.001589606748893857
Epoch:  205  	Training Loss: 0.001689043827354908
Test Loss:  0.0017906769644469023
Valid Loss:  0.0015896004624664783
Epoch:  206  	Training Loss: 0.0016890331171453
Test Loss:  0.0017906696302816272
Valid Loss:  0.0015895920805633068
Epoch:  207  	Training Loss: 0.0016890258993953466
Test Loss:  0.001790662994608283
 41%|████▏     | 207/500 [02:24<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:24<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:30<05:42,  1.18s/it] 43%|████▎     | 213/500 [02:30<04:04,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:55,  1.63it/s] 43%|████▎     | 217/500 [02:31<02:07,  2.23it/s] 44%|████▍     | 219/500 [02:31<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:37<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:37<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:37<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.24it/s] 46%|████▌     | 229/500 [02:38<01:30,  3.01it/s] 46%|████▌     | 231/500 [02:44<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:44<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:44<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:44<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:51<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:51<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:51<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:51<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.00it/s] 50%|█████     | 251/500 [02:57<04:54,  1.18s/it] 51%|█████     | 253/500 [02:58<03:29,  1.18it/s] 51%|█████     | 255/500 [02:58<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:58<01:49,  2.23it/s] 52%|█████▏    | 259/500 [02:58<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:04<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:05<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:05<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:05<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:11<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:11<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:12<02:19,  1.62it/s]Valid Loss:  0.00158958719111979
Epoch:  208  	Training Loss: 0.0016890177503228188
Test Loss:  0.0017906578723341227
Valid Loss:  0.0015895799733698368
Epoch:  209  	Training Loss: 0.0016890105325728655
Test Loss:  0.001790658920072019
Valid Loss:  0.0015895732212811708
Epoch:  210  	Training Loss: 0.0016890023835003376
Test Loss:  0.0017906571738421917
Valid Loss:  0.0015895664691925049
Epoch:  211  	Training Loss: 0.0016889956314116716
Test Loss:  0.0017906514694914222
Valid Loss:  0.0015895585529506207
Epoch:  212  	Training Loss: 0.001688987365923822
Test Loss:  0.0017906487919390202
Valid Loss:  0.0015895501710474491
Epoch:  213  	Training Loss: 0.0016889781691133976
Test Loss:  0.0017906418070197105
Valid Loss:  0.0015895436517894268
Epoch:  214  	Training Loss: 0.0016889717662706971
Test Loss:  0.0017906355205923319
Valid Loss:  0.001589534105733037
Epoch:  215  	Training Loss: 0.0016889641992747784
Test Loss:  0.0017906333087012172
Valid Loss:  0.001589532708749175
Epoch:  216  	Training Loss: 0.001688953721895814
Test Loss:  0.001790628070011735
Valid Loss:  0.001589522697031498
Epoch:  217  	Training Loss: 0.0016889438265934587
Test Loss:  0.0017906212015077472
Valid Loss:  0.0015895185060799122
Epoch:  218  	Training Loss: 0.0016889367252588272
Test Loss:  0.0017906130524352193
Valid Loss:  0.0015895059332251549
Epoch:  219  	Training Loss: 0.0016889306716620922
Test Loss:  0.0017906096763908863
Valid Loss:  0.0015895024407655
Epoch:  220  	Training Loss: 0.0016889222897589207
Test Loss:  0.001790607813745737
Valid Loss:  0.001589491032063961
Epoch:  221  	Training Loss: 0.0016889148391783237
Test Loss:  0.0017906028078868985
Valid Loss:  0.0015894894022494555
Epoch:  222  	Training Loss: 0.0016889073885977268
Test Loss:  0.0017905960557982326
Valid Loss:  0.0015894764801487327
Epoch:  223  	Training Loss: 0.0016888993559405208
Test Loss:  0.0017905927961692214
Valid Loss:  0.001589477644301951
Epoch:  224  	Training Loss: 0.0016888908576220274
Test Loss:  0.001790592446923256
Valid Loss:  0.0015894690295681357
Epoch:  225  	Training Loss: 0.0016888841055333614
Test Loss:  0.0017905808053910732
Valid Loss:  0.0015894611133262515
Epoch:  226  	Training Loss: 0.0016888780519366264
Test Loss:  0.0017905815038830042
Valid Loss:  0.0015894575044512749
Epoch:  227  	Training Loss: 0.001688868971541524
Test Loss:  0.0017905778950080276
Valid Loss:  0.0015894453972578049
Epoch:  228  	Training Loss: 0.0016888619866222143
Test Loss:  0.0017905754502862692
Valid Loss:  0.001589441206306219
Epoch:  229  	Training Loss: 0.0016888552345335484
Test Loss:  0.0017905703280121088
Valid Loss:  0.0015894320094957948
Epoch:  230  	Training Loss: 0.0016888477839529514
Test Loss:  0.0017905642744153738
Valid Loss:  0.0015894260723143816
Epoch:  231  	Training Loss: 0.0016888405662029982
Test Loss:  0.0017905589193105698
Valid Loss:  0.0015894188545644283
Epoch:  232  	Training Loss: 0.0016888320678845048
Test Loss:  0.0017905565910041332
Valid Loss:  0.0015894132666289806
Epoch:  233  	Training Loss: 0.0016888249665498734
Test Loss:  0.0017905535642057657
Valid Loss:  0.0015894066309556365
Epoch:  234  	Training Loss: 0.0016888193786144257
Test Loss:  0.0017905498389154673
Valid Loss:  0.0015894037205725908
Epoch:  235  	Training Loss: 0.001688811695203185
Test Loss:  0.0017905503045767546
Valid Loss:  0.0015893906820565462
Epoch:  236  	Training Loss: 0.0016888058744370937
Test Loss:  0.0017905480926856399
Valid Loss:  0.0015893896343186498
Epoch:  237  	Training Loss: 0.0016888005193322897
Test Loss:  0.0017905447166413069
Valid Loss:  0.0015893856761977077
Epoch:  238  	Training Loss: 0.001688793650828302
Test Loss:  0.0017905409913510084
Valid Loss:  0.001589379389770329
Epoch:  239  	Training Loss: 0.0016887886449694633
Test Loss:  0.0017905400600284338
Valid Loss:  0.0015893710078671575
Epoch:  240  	Training Loss: 0.001688782824203372
Test Loss:  0.0017905328422784805
Valid Loss:  0.0015893644886091352
Epoch:  241  	Training Loss: 0.0016887744423002005
Test Loss:  0.0017905307468026876
Valid Loss:  0.0015893594827502966
Epoch:  242  	Training Loss: 0.0016887680394575
Test Loss:  0.0017905256245285273
Valid Loss:  0.001589353196322918
Epoch:  243  	Training Loss: 0.001688762684352696
Test Loss:  0.001790522364899516
Valid Loss:  0.001589347142726183
Epoch:  244  	Training Loss: 0.0016887563979253173
Test Loss:  0.0017905229469761252
Valid Loss:  0.0015893399249762297
Epoch:  245  	Training Loss: 0.0016887499950826168
Test Loss:  0.0017905259737744927
Valid Loss:  0.001589329564012587
Epoch:  246  	Training Loss: 0.001688745804131031
Test Loss:  0.0017905186396092176
Valid Loss:  0.0015893274685367942
Epoch:  247  	Training Loss: 0.0016887399833649397
Test Loss:  0.001790517126210034
Valid Loss:  0.0015893183881416917
Epoch:  248  	Training Loss: 0.0016887328820303082
Test Loss:  0.0017905160784721375
Valid Loss:  0.0015893143136054277
Epoch:  249  	Training Loss: 0.0016887260135263205
Test Loss:  0.001790510257706046
Valid Loss:  0.0015893116360530257
Epoch:  250  	Training Loss: 0.0016887227538973093
Test Loss:  0.001790510374121368
Valid Loss:  0.0015893063973635435
Epoch:  251  	Training Loss: 0.001688715536147356
Test Loss:  0.0017905053682625294
Valid Loss:  0.001589300693012774
Epoch:  252  	Training Loss: 0.0016887113451957703
Test Loss:  0.0017905030399560928
Valid Loss:  0.0015892956871539354
Epoch:  253  	Training Loss: 0.001688705524429679
Test Loss:  0.0017905037384480238
Valid Loss:  0.0015892870724201202
Epoch:  254  	Training Loss: 0.001688699470832944
Test Loss:  0.001790500245988369
Valid Loss:  0.0015892800875008106
Epoch:  255  	Training Loss: 0.0016886916710063815
Test Loss:  0.0017905011773109436
Valid Loss:  0.0015892761293798685
Epoch:  256  	Training Loss: 0.001688686665147543
Test Loss:  0.0017904980340972543
Valid Loss:  0.001589273102581501
Epoch:  257  	Training Loss: 0.0016886824741959572
Test Loss:  0.0017904946580529213
Valid Loss:  0.001589268445968628
Epoch:  258  	Training Loss: 0.0016886757221072912
Test Loss:  0.0017904932610690594
Valid Loss:  0.001589262392371893
Epoch:  259  	Training Loss: 0.0016886729281395674
Test Loss:  0.0017904929118230939
Valid Loss:  0.0015892566880211234
Epoch:  260  	Training Loss: 0.0016886669909581542
Test Loss:  0.0017904859269037843
Valid Loss:  0.0015892514493316412
Epoch:  261  	Training Loss: 0.001688661752268672
Test Loss:  0.001790484064258635
Valid Loss:  0.0015892477240413427
Epoch:  262  	Training Loss: 0.001688653603196144
Test Loss:  0.0017904755659401417
Valid Loss:  0.0015892398077994585
Epoch:  263  	Training Loss: 0.0016886515077203512
Test Loss:  0.0017904734704643488
Valid Loss:  0.0015892352676019073
Epoch:  264  	Training Loss: 0.0016886454541236162
Test Loss:  0.001790473936125636
Valid Loss:  0.0015892311930656433
Epoch:  265  	Training Loss: 0.001688638818450272
Test Loss:  0.0017904717242345214
Valid Loss:  0.0015892311930656433
Epoch:  266  	Training Loss: 0.0016886329976841807
Test Loss:  0.001790472655557096
Valid Loss:  0.001589219900779426
Epoch:  267  	Training Loss: 0.0016886282246559858
Test Loss:  0.0017904690466821194
Valid Loss:  0.001589217223227024
Epoch:  268  	Training Loss: 0.0016886251978576183
Test Loss:  0.0017904671840369701
Valid Loss:  0.0015892130322754383
Epoch:  269  	Training Loss: 0.0016886192606762052
Test Loss:  0.0017904621781781316
Valid Loss:  0.0015892083756625652
Epoch:  270  	Training Loss: 0.0016886128578335047
Test Loss:  0.0017904581036418676
Valid Loss:  0.001589204533956945
Epoch:  271  	Training Loss: 0.0016886082012206316
Test Loss:  0.0017904608976095915
Valid Loss:  0.001589202438481152
Epoch:  272  	Training Loss: 0.001688605174422264
Test Loss:  0.0017904567066580057
Valid Loss:  0.0015891913790255785
Epoch:  273  	Training Loss: 0.0016885986551642418
Test Loss:  0.0017904553096741438
Valid Loss:  0.001589189050719142
Epoch:  274  	Training Loss: 0.001688594464212656
Test Loss:  0.001790453214198351
Valid Loss:  0.001589182298630476
Epoch:  275  	Training Loss: 0.001688589109107852
Test Loss:  0.0017904506530612707
Valid Loss:  0.0015891764778643847
Epoch:  276  	Training Loss: 0.0016885832883417606
 55%|█████▌    | 277/500 [03:12<01:40,  2.21it/s] 56%|█████▌    | 279/500 [03:12<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:18<04:23,  1.20s/it] 57%|█████▋    | 283/500 [03:18<03:07,  1.16it/s] 57%|█████▋    | 285/500 [03:18<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:19<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:19<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:25<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:25<02:56,  1.18it/s] 59%|█████▉    | 295/500 [03:25<02:06,  1.63it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:26<01:07,  2.98it/s] 60%|██████    | 301/500 [03:32<03:53,  1.17s/it] 61%|██████    | 303/500 [03:32<02:45,  1.19it/s] 61%|██████    | 305/500 [03:32<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:32<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:39<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:39<01:53,  1.62it/s] 63%|██████▎   | 317/500 [03:39<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:39<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:46<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:46<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:46<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:46<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:46<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:52<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:53<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:53<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:53<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:53<00:53,  3.00it/s] 68%|██████▊   | 341/500 [03:59<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:59<02:11,  1.19it/s]Test Loss:  0.0017904485575854778
Valid Loss:  0.0015891753137111664
Epoch:  277  	Training Loss: 0.0016885801451280713
Test Loss:  0.0017904478590935469
Valid Loss:  0.0015891690272837877
Epoch:  278  	Training Loss: 0.001688574906438589
Test Loss:  0.0017904445994645357
Valid Loss:  0.0015891632065176964
Epoch:  279  	Training Loss: 0.0016885686200112104
Test Loss:  0.0017904435517266393
Valid Loss:  0.0015891550574451685
Epoch:  280  	Training Loss: 0.0016885651275515556
Test Loss:  0.0017904388951137662
Valid Loss:  0.0015891541261225939
Epoch:  281  	Training Loss: 0.001688558142632246
Test Loss:  0.0017904418054968119
Valid Loss:  0.0015891469083726406
Epoch:  282  	Training Loss: 0.001688552787527442
Test Loss:  0.0017904373817145824
Valid Loss:  0.0015891409711912274
Epoch:  283  	Training Loss: 0.0016885502263903618
Test Loss:  0.0017904351698234677
Valid Loss:  0.001589136547408998
Epoch:  284  	Training Loss: 0.0016885451041162014
Test Loss:  0.0017904306296259165
Valid Loss:  0.001589133171364665
Epoch:  285  	Training Loss: 0.0016885384684428573
Test Loss:  0.0017904271371662617
Valid Loss:  0.0015891273505985737
Epoch:  286  	Training Loss: 0.0016885335789993405
Test Loss:  0.0017904281849041581
Valid Loss:  0.0015891236253082752
Epoch:  287  	Training Loss: 0.0016885293880477548
Test Loss:  0.0017904250416904688
Valid Loss:  0.0015891141956672072
Epoch:  288  	Training Loss: 0.0016885243821889162
Test Loss:  0.0017904225969687104
Valid Loss:  0.0015891108196228743
Epoch:  289  	Training Loss: 0.0016885212389752269
Test Loss:  0.0017904239939525723
Valid Loss:  0.0015891091898083687
Epoch:  290  	Training Loss: 0.0016885155346244574
Test Loss:  0.0017904234118759632
Valid Loss:  0.001589104300364852
Epoch:  291  	Training Loss: 0.001688511110842228
Test Loss:  0.0017904166597872972
Valid Loss:  0.0015891010407358408
Epoch:  292  	Training Loss: 0.0016885094810277224
Test Loss:  0.0017904149135574698
Valid Loss:  0.001589098945260048
Epoch:  293  	Training Loss: 0.0016885034274309874
Test Loss:  0.0017904116539284587
Valid Loss:  0.0015890924260020256
Epoch:  294  	Training Loss: 0.0016885008662939072
Test Loss:  0.0017904071137309074
Valid Loss:  0.0015890903305262327
Epoch:  295  	Training Loss: 0.0016884950455278158
Test Loss:  0.001790403388440609
Valid Loss:  0.0015890856739133596
Epoch:  296  	Training Loss: 0.0016884910874068737
Test Loss:  0.0017904054839164019
Valid Loss:  0.0015890770591795444
Epoch:  297  	Training Loss: 0.001688486197963357
Test Loss:  0.001790404785424471
Valid Loss:  0.0015890737995505333
Epoch:  298  	Training Loss: 0.0016884827055037022
Test Loss:  0.0017904038541018963
Valid Loss:  0.001589067978784442
Epoch:  299  	Training Loss: 0.001688478048890829
Test Loss:  0.0017904043197631836
Valid Loss:  0.0015890644863247871
Epoch:  300  	Training Loss: 0.0016884743236005306
Test Loss:  0.0017903978005051613
Valid Loss:  0.0015890607610344887
Epoch:  301  	Training Loss: 0.0016884711803868413
Test Loss:  0.001790390582755208
Valid Loss:  0.001589053077623248
Epoch:  302  	Training Loss: 0.0016884650103747845
Test Loss:  0.0017903849948197603
Valid Loss:  0.0015890521463006735
Epoch:  303  	Training Loss: 0.0016884610522538424
Test Loss:  0.0017903861589729786
Valid Loss:  0.0015890451613813639
Epoch:  304  	Training Loss: 0.001688455929979682
Test Loss:  0.0017903824336826801
Valid Loss:  0.0015890408540144563
Epoch:  305  	Training Loss: 0.0016884519718587399
Test Loss:  0.0017903812695294619
Valid Loss:  0.0015890353824943304
Epoch:  306  	Training Loss: 0.0016884490614756942
Test Loss:  0.0017903812695294619
Valid Loss:  0.0015890365466475487
Epoch:  307  	Training Loss: 0.0016884447541087866
Test Loss:  0.0017903819680213928
Valid Loss:  0.0015890265349298716
Epoch:  308  	Training Loss: 0.0016884407959878445
Test Loss:  0.0017903763800859451
Valid Loss:  0.0015890225768089294
Epoch:  309  	Training Loss: 0.0016884354408830404
Test Loss:  0.0017903810366988182
Valid Loss:  0.0015890159411355853
Epoch:  310  	Training Loss: 0.00168843031860888
Test Loss:  0.0017903719563037157
Valid Loss:  0.0015890172217041254
Epoch:  311  	Training Loss: 0.0016884275246411562
Test Loss:  0.0017903698608279228
Valid Loss:  0.0015890098875388503
Epoch:  312  	Training Loss: 0.0016884219367057085
Test Loss:  0.001790368463844061
Valid Loss:  0.0015890058130025864
Epoch:  313  	Training Loss: 0.001688417512923479
Test Loss:  0.001790367066860199
Valid Loss:  0.001588999992236495
Epoch:  314  	Training Loss: 0.0016884130891412497
Test Loss:  0.0017903686966747046
Valid Loss:  0.0015889941714704037
Epoch:  315  	Training Loss: 0.0016884105280041695
Test Loss:  0.0017903626430779696
Valid Loss:  0.0015889924252405763
Epoch:  316  	Training Loss: 0.0016884062206372619
Test Loss:  0.0017903631087392569
Valid Loss:  0.0015889883507043123
Epoch:  317  	Training Loss: 0.0016884010983631015
Test Loss:  0.0017903577536344528
Valid Loss:  0.001588984508998692
Epoch:  318  	Training Loss: 0.0016883986536413431
Test Loss:  0.0017903536790981889
Valid Loss:  0.001588981132954359
Epoch:  319  	Training Loss: 0.0016883923672139645
Test Loss:  0.0017903536790981889
Valid Loss:  0.0015889732167124748
Epoch:  320  	Training Loss: 0.0016883874777704477
Test Loss:  0.0017903498373925686
Valid Loss:  0.001588965649716556
Epoch:  321  	Training Loss: 0.0016883846838027239
Test Loss:  0.001790350303053856
Valid Loss:  0.0015889644855633378
Epoch:  322  	Training Loss: 0.0016883803764358163
Test Loss:  0.0017903505358844995
Valid Loss:  0.001588962273672223
Epoch:  323  	Training Loss: 0.0016883764183148742
Test Loss:  0.0017903451807796955
Valid Loss:  0.0015889585483819246
Epoch:  324  	Training Loss: 0.0016883721109479666
Test Loss:  0.0017903454136103392
Valid Loss:  0.0015889520291239023
Epoch:  325  	Training Loss: 0.0016883694333955646
Test Loss:  0.0017903437837958336
Valid Loss:  0.0015889450442045927
Epoch:  326  	Training Loss: 0.0016883646603673697
Test Loss:  0.001790344133041799
Valid Loss:  0.0015889444621279836
Epoch:  327  	Training Loss: 0.0016883607022464275
Test Loss:  0.0017903388943523169
Valid Loss:  0.0015889396890997887
Epoch:  328  	Training Loss: 0.0016883551143109798
Test Loss:  0.001790338079445064
Valid Loss:  0.0015889357309788465
Epoch:  329  	Training Loss: 0.001688355696387589
Test Loss:  0.001790336100384593
Valid Loss:  0.00158893340267241
Epoch:  330  	Training Loss: 0.0016883511561900377
Test Loss:  0.0017903343541547656
Valid Loss:  0.0015889313071966171
Epoch:  331  	Training Loss: 0.001688346965238452
Test Loss:  0.0017903337720781565
Valid Loss:  0.0015889275819063187
Epoch:  332  	Training Loss: 0.0016883424250409007
Test Loss:  0.0017903298139572144
Valid Loss:  0.0015889216447249055
Epoch:  333  	Training Loss: 0.0016883378848433495
Test Loss:  0.0017903298139572144
Valid Loss:  0.0015889143105596304
Epoch:  334  	Training Loss: 0.0016883357893675566
Test Loss:  0.0017903263214975595
Valid Loss:  0.0015889102360233665
Epoch:  335  	Training Loss: 0.0016883318312466145
Test Loss:  0.0017903210828080773
Valid Loss:  0.0015889056958258152
Epoch:  336  	Training Loss: 0.0016883292701095343
Test Loss:  0.0017903207335621119
Valid Loss:  0.0015889020869508386
Epoch:  337  	Training Loss: 0.001688324729911983
Test Loss:  0.0017903209663927555
Valid Loss:  0.0015888988273218274
Epoch:  338  	Training Loss: 0.001688320771791041
Test Loss:  0.0017903205007314682
Valid Loss:  0.001588897081092
Epoch:  339  	Training Loss: 0.0016883164644241333
Test Loss:  0.0017903124680742621
Valid Loss:  0.0015888906782492995
Epoch:  340  	Training Loss: 0.0016883143689483404
Test Loss:  0.001790316659025848
Valid Loss:  0.0015888877678662539
Epoch:  341  	Training Loss: 0.001688308548182249
Test Loss:  0.0017903158441185951
Valid Loss:  0.0015888845082372427
Epoch:  342  	Training Loss: 0.0016883044736459851
Test Loss:  0.0017903081607073545
Valid Loss:  0.0015888828784227371
Epoch:  343  	Training Loss: 0.001688302494585514
Test Loss:  0.001790311885997653
Valid Loss:  0.0015888758935034275
Epoch:  344  	Training Loss: 0.0016883001662790775
Test Loss:  0.0017903062980622053
Valid Loss:  0.001588874263688922
 69%|██████▉   | 345/500 [03:59<01:33,  1.65it/s] 69%|██████▉   | 347/500 [04:00<01:07,  2.26it/s] 70%|██████▉   | 349/500 [04:00<00:49,  3.03it/s] 70%|███████   | 351/500 [04:06<02:55,  1.18s/it] 71%|███████   | 353/500 [04:06<02:04,  1.18it/s] 71%|███████   | 355/500 [04:06<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:07<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:13<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:13<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:13<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:13<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:20<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:20<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:20<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:20<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:20<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:27<02:19,  1.18s/it] 77%|███████▋  | 383/500 [04:27<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:27<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:27<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:27<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:33<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:33<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:34<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:34<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:34<00:33,  3.03it/s] 80%|████████  | 401/500 [04:40<01:54,  1.16s/it] 81%|████████  | 403/500 [04:40<01:20,  1.20it/s] 81%|████████  | 405/500 [04:40<00:57,  1.66it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.26it/s] 82%|████████▏ | 409/500 [04:41<00:30,  3.03it/s] 82%|████████▏ | 411/500 [04:47<01:44,  1.17s/it]Epoch:  345  	Training Loss: 0.0016882946947589517
Test Loss:  0.0017903021071106195
Valid Loss:  0.0015888677444308996
Epoch:  346  	Training Loss: 0.001688291784375906
Test Loss:  0.0017903001280501485
Valid Loss:  0.0015888644848018885
Epoch:  347  	Training Loss: 0.0016882878262549639
Test Loss:  0.0017903002444654703
Valid Loss:  0.0015888625057414174
Epoch:  348  	Training Loss: 0.0016882852651178837
Test Loss:  0.0017902965191751719
Valid Loss:  0.0015888574998825788
Epoch:  349  	Training Loss: 0.0016882800264284015
Test Loss:  0.0017902991967275739
Valid Loss:  0.0015888568013906479
Epoch:  350  	Training Loss: 0.0016882761847227812
Test Loss:  0.0017902941908687353
Valid Loss:  0.0015888509806245565
Epoch:  351  	Training Loss: 0.0016882739728316665
Test Loss:  0.0017902934923768044
Valid Loss:  0.0015888474881649017
Epoch:  352  	Training Loss: 0.0016882712952792645
Test Loss:  0.0017902875551953912
Valid Loss:  0.0015888456255197525
Epoch:  353  	Training Loss: 0.0016882660565897822
Test Loss:  0.001790287671610713
Valid Loss:  0.0015888450434431434
Epoch:  354  	Training Loss: 0.0016882633790373802
Test Loss:  0.0017902841791510582
Valid Loss:  0.0015888343332335353
Epoch:  355  	Training Loss: 0.0016882609343156219
Test Loss:  0.0017902812687680125
Valid Loss:  0.0015888330526649952
Epoch:  356  	Training Loss: 0.0016882575582712889
Test Loss:  0.0017902771942317486
Valid Loss:  0.001588829793035984
Epoch:  357  	Training Loss: 0.0016882531344890594
Test Loss:  0.0017902806866914034
Valid Loss:  0.0015888250200077891
Epoch:  358  	Training Loss: 0.0016882503405213356
Test Loss:  0.0017902771942317486
Valid Loss:  0.0015888225752860308
Epoch:  359  	Training Loss: 0.0016882469644770026
Test Loss:  0.0017902759136632085
Valid Loss:  0.0015888211783021688
Epoch:  360  	Training Loss: 0.001688243355602026
Test Loss:  0.0017902730032801628
Valid Loss:  0.0015888165216892958
Epoch:  361  	Training Loss: 0.0016882410272955894
Test Loss:  0.0017902697436511517
Valid Loss:  0.0015888113994151354
Epoch:  362  	Training Loss: 0.0016882383497431874
Test Loss:  0.0017902700928971171
Valid Loss:  0.0015888061607256532
Epoch:  363  	Training Loss: 0.0016882338095456362
Test Loss:  0.0017902699764817953
Valid Loss:  0.001588806277140975
Epoch:  364  	Training Loss: 0.0016882296185940504
Test Loss:  0.0017902685794979334
Valid Loss:  0.0015887983608990908
Epoch:  365  	Training Loss: 0.0016882275231182575
Test Loss:  0.001790264854207635
Valid Loss:  0.0015887969639152288
Epoch:  366  	Training Loss: 0.0016882236814126372
Test Loss:  0.0017902562394738197
Valid Loss:  0.0015887939371168613
Epoch:  367  	Training Loss: 0.001688221120275557
Test Loss:  0.0017902536783367395
Valid Loss:  0.0015887917252257466
Epoch:  368  	Training Loss: 0.0016882165800780058
Test Loss:  0.0017902521649375558
Valid Loss:  0.0015887862537056208
Epoch:  369  	Training Loss: 0.0016882127383723855
Test Loss:  0.0017902542604133487
Valid Loss:  0.0015887825284153223
Epoch:  370  	Training Loss: 0.0016882087802514434
Test Loss:  0.001790251350030303
Valid Loss:  0.0015887776389718056
Epoch:  371  	Training Loss: 0.0016882062191143632
Test Loss:  0.0017902487888932228
Valid Loss:  0.0015887748450040817
Epoch:  372  	Training Loss: 0.0016882021445780993
Test Loss:  0.0017902482068166137
Valid Loss:  0.001588770654052496
Epoch:  373  	Training Loss: 0.0016881992341950536
Test Loss:  0.0017902454128488898
Valid Loss:  0.0015887675108388066
Epoch:  374  	Training Loss: 0.0016881965566426516
Test Loss:  0.0017902462277561426
Valid Loss:  0.0015887663466855884
Epoch:  375  	Training Loss: 0.0016881939955055714
Test Loss:  0.0017902407562360168
Valid Loss:  0.0015887629706412554
Epoch:  376  	Training Loss: 0.0016881907358765602
Test Loss:  0.0017902422696352005
Valid Loss:  0.0015887576155364513
Epoch:  377  	Training Loss: 0.001688187476247549
Test Loss:  0.0017902386607602239
Valid Loss:  0.0015887519111856818
Epoch:  378  	Training Loss: 0.0016881844494491816
Test Loss:  0.0017902362160384655
Valid Loss:  0.001588753191754222
Epoch:  379  	Training Loss: 0.001688178046606481
Test Loss:  0.0017902330728247762
Valid Loss:  0.0015887500485405326
Epoch:  380  	Training Loss: 0.0016881772316992283
Test Loss:  0.0017902330728247762
Valid Loss:  0.0015887455083429813
Epoch:  381  	Training Loss: 0.0016881750198081136
Test Loss:  0.0017902322579175234
Valid Loss:  0.00158873968757689
Epoch:  382  	Training Loss: 0.0016881711781024933
Test Loss:  0.001790232490748167
Valid Loss:  0.0015887402696534991
Epoch:  383  	Training Loss: 0.0016881683841347694
Test Loss:  0.0017902308609336615
Valid Loss:  0.0015887306071817875
Epoch:  384  	Training Loss: 0.0016881650080904365
Test Loss:  0.001790229114703834
Valid Loss:  0.001588729559443891
Epoch:  385  	Training Loss: 0.0016881634946912527
Test Loss:  0.0017902287654578686
Valid Loss:  0.0015887245535850525
Epoch:  386  	Training Loss: 0.001688160002231598
Test Loss:  0.001790227834135294
Valid Loss:  0.0015887238550931215
Epoch:  387  	Training Loss: 0.001688157208263874
Test Loss:  0.0017902252729982138
Valid Loss:  0.0015887191984802485
Epoch:  388  	Training Loss: 0.0016881548799574375
Test Loss:  0.0017902241088449955
Valid Loss:  0.0015887157060205936
Epoch:  389  	Training Loss: 0.0016881520859897137
Test Loss:  0.0017902189865708351
Valid Loss:  0.001588713494129479
Epoch:  390  	Training Loss: 0.0016881487099453807
Test Loss:  0.001790217007510364
Valid Loss:  0.0015887091867625713
Epoch:  391  	Training Loss: 0.0016881474293768406
Test Loss:  0.001790215028449893
Valid Loss:  0.001588707440532744
Epoch:  392  	Training Loss: 0.001688143820501864
Test Loss:  0.0017902120016515255
Valid Loss:  0.0015887039480730891
Epoch:  393  	Training Loss: 0.0016881410265341401
Test Loss:  0.0017902172403410077
Valid Loss:  0.0015886998735368252
Epoch:  394  	Training Loss: 0.001688139047473669
Test Loss:  0.0017902124673128128
Valid Loss:  0.0015886948676779866
Epoch:  395  	Training Loss: 0.001688138348981738
Test Loss:  0.00179021037183702
Valid Loss:  0.0015886961482465267
Epoch:  396  	Training Loss: 0.0016881339251995087
Test Loss:  0.001790208276361227
Valid Loss:  0.0015886934706941247
Epoch:  397  	Training Loss: 0.0016881313640624285
Test Loss:  0.0017902073450386524
Valid Loss:  0.0015886920737102628
Epoch:  398  	Training Loss: 0.001688129617832601
Test Loss:  0.001790203619748354
Valid Loss:  0.0015886888140812516
Epoch:  399  	Training Loss: 0.00168812763877213
Test Loss:  0.0017902033869177103
Valid Loss:  0.001588687184266746
Epoch:  400  	Training Loss: 0.0016881239134818316
Test Loss:  0.0017902051331475377
Valid Loss:  0.001588682527653873
Epoch:  401  	Training Loss: 0.0016881220508366823
Test Loss:  0.0017902053659781814
Valid Loss:  0.001588678453117609
Epoch:  402  	Training Loss: 0.0016881191404536366
Test Loss:  0.0017901987303048372
Valid Loss:  0.0015886779874563217
Epoch:  403  	Training Loss: 0.0016881177434697747
Test Loss:  0.0017901989631354809
Valid Loss:  0.001588671002537012
Epoch:  404  	Training Loss: 0.0016881127376109362
Test Loss:  0.0017901990795508027
Valid Loss:  0.0015886680921539664
Epoch:  405  	Training Loss: 0.0016881111077964306
Test Loss:  0.0017901903484016657
Valid Loss:  0.0015886707697063684
Epoch:  406  	Training Loss: 0.0016881085466593504
Test Loss:  0.001790192211046815
Valid Loss:  0.001588662387803197
Epoch:  407  	Training Loss: 0.0016881066840142012
Test Loss:  0.001790186041034758
Valid Loss:  0.0015886635519564152
Epoch:  408  	Training Loss: 0.001688102027401328
Test Loss:  0.0017901865066960454
Valid Loss:  0.0015886607579886913
Epoch:  409  	Training Loss: 0.0016881013289093971
Test Loss:  0.001790188136510551
Valid Loss:  0.001588654238730669
Epoch:  410  	Training Loss: 0.0016880964394658804
Test Loss:  0.0017901875544339418
Valid Loss:  0.001588653540238738
Epoch:  411  	Training Loss: 0.0016880963230505586
Test Loss:  0.0017901798710227013
Valid Loss:  0.0015886519104242325
Epoch:  412  	Training Loss: 0.0016880921320989728
Test Loss:  0.0017901756800711155
Valid Loss:  0.0015886470209807158
Epoch:  413  	Training Loss: 0.0016880887560546398
Test Loss:   83%|████████▎ | 413/500 [04:47<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:47<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:47<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:47<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:54<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:54<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:54<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:54<00:33,  2.20it/s] 86%|████████▌ | 429/500 [04:54<00:24,  2.91it/s] 86%|████████▌ | 431/500 [05:01<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:01<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:01<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:01<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:01<00:20,  2.95it/s] 88%|████████▊ | 441/500 [05:08<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:14<01:25,  1.55s/it] 89%|████████▉ | 447/500 [05:14<00:58,  1.11s/it] 90%|████████▉ | 449/500 [05:14<00:40,  1.26it/s] 90%|█████████ | 451/500 [05:21<01:13,  1.50s/it] 91%|█████████ | 453/500 [05:21<00:50,  1.07s/it] 91%|█████████ | 455/500 [05:21<00:34,  1.30it/s] 91%|█████████▏| 457/500 [05:21<00:23,  1.79it/s] 92%|█████████▏| 459/500 [05:21<00:16,  2.44it/s] 92%|█████████▏| 461/500 [05:27<00:47,  1.22s/it] 93%|█████████▎| 463/500 [05:28<00:32,  1.14it/s] 93%|█████████▎| 465/500 [05:28<00:22,  1.57it/s] 93%|█████████▎| 467/500 [05:28<00:15,  2.15it/s] 94%|█████████▍| 469/500 [05:28<00:10,  2.89it/s] 94%|█████████▍| 469/500 [05:40<00:10,  2.89it/s] 94%|█████████▍| 471/500 [05:41<01:01,  2.13s/it] 95%|█████████▍| 473/500 [05:41<00:40,  1.51s/it] 95%|█████████▌| 475/500 [05:41<00:26,  1.08s/it] 95%|█████████▌| 477/500 [05:41<00:17,  1.29it/s] 96%|█████████▌| 479/500 [05:41<00:11,  1.78it/s]0.0017901730025187135
Valid Loss:  0.001588643528521061
Epoch:  414  	Training Loss: 0.0016880863113328815
Test Loss:  0.001790174632333219
Valid Loss:  0.0015886439941823483
Epoch:  415  	Training Loss: 0.0016880831681191921
Test Loss:  0.0017901698593050241
Valid Loss:  0.0015886432956904173
Epoch:  416  	Training Loss: 0.0016880810726433992
Test Loss:  0.0017901710234582424
Valid Loss:  0.0015886388719081879
Epoch:  417  	Training Loss: 0.001688078511506319
Test Loss:  0.0017901714891195297
Valid Loss:  0.0015886349137872458
Epoch:  418  	Training Loss: 0.0016880768816918135
Test Loss:  0.0017901711398735642
Valid Loss:  0.0015886323526501656
Epoch:  419  	Training Loss: 0.0016880743205547333
Test Loss:  0.001790171954780817
Valid Loss:  0.0015886297915130854
Epoch:  420  	Training Loss: 0.0016880725743249059
Test Loss:  0.00179018615745008
Valid Loss:  0.0015886233886703849
Epoch:  421  	Training Loss: 0.0016880710609257221
Test Loss:  0.0017901507671922445
Valid Loss:  0.001588625367730856
Epoch:  422  	Training Loss: 0.0016880668699741364
Test Loss:  0.001790143782272935
Valid Loss:  0.001588624669238925
Epoch:  423  	Training Loss: 0.0016880647744983435
Test Loss:  0.0017901478568091989
Valid Loss:  0.0015886180335655808
Epoch:  424  	Training Loss: 0.0016880620969459414
Test Loss:  0.001790148438885808
Valid Loss:  0.0015886197797954082
Epoch:  425  	Training Loss: 0.0016880605835467577
Test Loss:  0.001790148438885808
Valid Loss:  0.001588622690178454
Epoch:  426  	Training Loss: 0.0016880566254258156
Test Loss:  0.001790146343410015
Valid Loss:  0.0015886141918599606
Epoch:  427  	Training Loss: 0.0016880538314580917
Test Loss:  0.0017901433166116476
Valid Loss:  0.0015886117471382022
Epoch:  428  	Training Loss: 0.0016880545299500227
Test Loss:  0.0017901414539664984
Valid Loss:  0.0015886130277067423
Epoch:  429  	Training Loss: 0.0016880517359822989
Test Loss:  0.0017901395913213491
Valid Loss:  0.0015886086039245129
Epoch:  430  	Training Loss: 0.001688049640506506
Test Loss:  0.0017901401733979583
Valid Loss:  0.0015886061592027545
Epoch:  431  	Training Loss: 0.0016880473122000694
Test Loss:  0.0017901427345350385
Valid Loss:  0.0015886025503277779
Epoch:  432  	Training Loss: 0.0016880461480468512
Test Loss:  0.0017901444807648659
Valid Loss:  0.001588599756360054
Epoch:  433  	Training Loss: 0.0016880452167242765
Test Loss:  0.0017901444807648659
Valid Loss:  0.0015885928878560662
Epoch:  434  	Training Loss: 0.0016880417242646217
Test Loss:  0.0017901454120874405
Valid Loss:  0.0015885934699326754
Epoch:  435  	Training Loss: 0.0016880400944501162
Test Loss:  0.0017901454120874405
Valid Loss:  0.001588592305779457
Epoch:  436  	Training Loss: 0.0016880386974662542
Test Loss:  0.0017901384271681309
Valid Loss:  0.0015885885804891586
Epoch:  437  	Training Loss: 0.0016880366019904613
Test Loss:  0.001790137030184269
Valid Loss:  0.0015885899774730206
Epoch:  438  	Training Loss: 0.0016880322946235538
Test Loss:  0.0017901351675391197
Valid Loss:  0.001588584971614182
Epoch:  439  	Training Loss: 0.0016880315961316228
Test Loss:  0.0017901314422488213
Valid Loss:  0.0015885821776464581
Epoch:  440  	Training Loss: 0.0016880282200872898
Test Loss:  0.0017901284154504538
Valid Loss:  0.0015885806642472744
Epoch:  441  	Training Loss: 0.001688025426119566
Test Loss:  0.001790135633200407
Valid Loss:  0.0015885790344327688
Epoch:  442  	Training Loss: 0.0016880248440429568
Test Loss:  0.0017901266692206264
Valid Loss:  0.0015885757748037577
Epoch:  443  	Training Loss: 0.0016880236798897386
Test Loss:  0.001790128997527063
Valid Loss:  0.0015885727480053902
Epoch:  444  	Training Loss: 0.0016880207695066929
Test Loss:  0.0017901232931762934
Valid Loss:  0.0015885718166828156
Epoch:  445  	Training Loss: 0.0016880207695066929
Test Loss:  0.0017901253886520863
Valid Loss:  0.0015885693719610572
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.001688017277047038
Test Loss:  0.0017901202663779259
Valid Loss:  0.0015885645989328623
Epoch:  447  	Training Loss: 0.0016880149487406015
Test Loss:  0.0017901191022247076
Valid Loss:  0.0015885643661022186
Epoch:  448  	Training Loss: 0.0016880147159099579
Test Loss:  0.00179011607542634
Valid Loss:  0.0015885647153481841
Epoch:  449  	Training Loss: 0.0016880135517567396
Test Loss:  0.0017901184037327766
Valid Loss:  0.001588564831763506
Epoch:  450  	Training Loss: 0.0016880120383575559
Test Loss:  0.0017901180544868112
Valid Loss:  0.0015885615721344948
Epoch:  451  	Training Loss: 0.0016880102921277285
Test Loss:  0.00179011607542634
Valid Loss:  0.0015885601751506329
Epoch:  452  	Training Loss: 0.0016880098264664412
Test Loss:  0.001790116191841662
Valid Loss:  0.0015885608736425638
Epoch:  453  	Training Loss: 0.001688007963821292
Test Loss:  0.0017901144456118345
Valid Loss:  0.0015885597094893456
Epoch:  454  	Training Loss: 0.0016880055190995336
Test Loss:  0.001790116890333593
Valid Loss:  0.0015885602915659547
Epoch:  455  	Training Loss: 0.0016880047041922808
Test Loss:  0.0017901129322126508
Valid Loss:  0.001588557381182909
Epoch:  456  	Training Loss: 0.0016880027251318097
Test Loss:  0.0017901102546602488
Valid Loss:  0.0015885562170296907
Epoch:  457  	Training Loss: 0.001688002492301166
Test Loss:  0.0017901147948578
Valid Loss:  0.001588552608154714
Epoch:  458  	Training Loss: 0.0016880023758858442
Test Loss:  0.0017901111859828234
Valid Loss:  0.0015885535394772887
Epoch:  459  	Training Loss: 0.0016880027251318097
Test Loss:  0.0017901115352287889
Valid Loss:  0.0015885517932474613
Epoch:  460  	Training Loss: 0.0016879987670108676
Test Loss:  0.0017901111859828234
Valid Loss:  0.001588551327586174
Epoch:  461  	Training Loss: 0.0016879986505955458
Test Loss:  0.0017901079263538122
Valid Loss:  0.0015885503962635994
Epoch:  462  	Training Loss: 0.001687997835688293
Test Loss:  0.0017901068786159158
Valid Loss:  0.001588546670973301
Epoch:  463  	Training Loss: 0.001687995158135891
Test Loss:  0.001790107460692525
Valid Loss:  0.0015885458560660481
Epoch:  464  	Training Loss: 0.00168799445964396
Test Loss:  0.0017901079263538122
Valid Loss:  0.0015885455068200827
Epoch:  465  	Training Loss: 0.0016879935283213854
Test Loss:  0.0017901058308780193
Valid Loss:  0.001588543877005577
Epoch:  466  	Training Loss: 0.0016879925969988108
Test Loss:  0.0017901072278618813
Valid Loss:  0.001588543993420899
Epoch:  467  	Training Loss: 0.0016879923641681671
Test Loss:  0.0017901052488014102
Valid Loss:  0.0015885431785136461
Epoch:  468  	Training Loss: 0.0016879925969988108
Test Loss:  0.00179010396823287
Valid Loss:  0.001588541897945106
Epoch:  469  	Training Loss: 0.0016879894537851214
Test Loss:  0.0017901031533256173
Valid Loss:  0.0015885414322838187
Epoch:  470  	Training Loss: 0.0016879895702004433
Test Loss:  0.001790104084648192
Valid Loss:  0.0015885408502072096
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0016879892209544778
Test Loss:  0.0017901022220030427
Valid Loss:  0.001588540617376566
Epoch:  472  	Training Loss: 0.0016879886388778687
Test Loss:  0.0017900981474667788
Valid Loss:  0.001588539220392704
Epoch:  473  	Training Loss: 0.0016879882896319032
Test Loss:  0.001790097914636135
Valid Loss:  0.0015885395696386695
Epoch:  474  	Training Loss: 0.001687987009063363
Test Loss:  0.0017900988459587097
Valid Loss:  0.0015885398024693131
Epoch:  475  	Training Loss: 0.0016879873583093286
Test Loss:  0.001790098613128066
Valid Loss:  0.0015885360771790147
Epoch:  476  	Training Loss: 0.0016879856120795012
Test Loss:  0.0017900962848216295
Valid Loss:  0.0015885403845459223
Epoch:  477  	Training Loss: 0.0016879859613254666
Test Loss:  0.0017900962848216295
Valid Loss:  0.0015885364264249802
Epoch:  478  	Training Loss: 0.0016879847971722484
Test Loss:  0.001790099311619997
Valid Loss:  0.0015885354951024055
Epoch:  479  	Training Loss: 0.0016879832837730646
Test Loss:  0.0017901016399264336
Valid Loss:  0.001588534447364509
 96%|█████████▌| 481/500 [05:53<00:42,  2.26s/it] 97%|█████████▋| 483/500 [05:54<00:27,  1.60s/it] 97%|█████████▋| 485/500 [05:54<00:17,  1.14s/it] 97%|█████████▋| 487/500 [05:54<00:10,  1.22it/s] 98%|█████████▊| 489/500 [05:54<00:06,  1.69it/s] 98%|█████████▊| 491/500 [06:06<00:20,  2.27s/it] 99%|█████████▊| 493/500 [06:07<00:11,  1.61s/it] 99%|█████████▉| 495/500 [06:07<00:05,  1.15s/it] 99%|█████████▉| 497/500 [06:07<00:02,  1.21it/s]100%|█████████▉| 499/500 [06:07<00:00,  1.67it/s]100%|██████████| 500/500 [06:13<00:00,  1.34it/s]
Epoch:  480  	Training Loss: 0.0016879842150956392
Test Loss:  0.0017901051323860884
Valid Loss:  0.0015885322354733944
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.00168798235245049
Test Loss:  0.0017901029204949737
Valid Loss:  0.0015885323518887162
Epoch:  482  	Training Loss: 0.001687981653958559
Test Loss:  0.0017901021055877209
Valid Loss:  0.001588531769812107
Epoch:  483  	Training Loss: 0.0016879815375432372
Test Loss:  0.0017901028040796518
Valid Loss:  0.0015885301399976015
Epoch:  484  	Training Loss: 0.0016879817703738809
Test Loss:  0.0017901025712490082
Valid Loss:  0.0015885313041508198
Epoch:  485  	Training Loss: 0.0016879818867892027
Test Loss:  0.0017901029204949737
Valid Loss:  0.0015885313041508198
Epoch:  486  	Training Loss: 0.0016879814211279154
Test Loss:  0.0017901015235111117
Valid Loss:  0.001588530489243567
Epoch:  487  	Training Loss: 0.00168798107188195
Test Loss:  0.0017901001265272498
Valid Loss:  0.001588529790751636
Epoch:  488  	Training Loss: 0.0016879800241440535
Test Loss:  0.001790100010111928
Valid Loss:  0.0015885315369814634
Epoch:  489  	Training Loss: 0.0016879800241440535
Test Loss:  0.0017901002429425716
Valid Loss:  0.0015885308384895325
Epoch:  490  	Training Loss: 0.0016879790928214788
Test Loss:  0.001790100708603859
Valid Loss:  0.0015885309549048543
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0016879787435755134
Test Loss:  0.001790101290680468
Valid Loss:  0.0015885294415056705
Epoch:  492  	Training Loss: 0.001687978277914226
Test Loss:  0.0017901016399264336
Valid Loss:  0.0015885296743363142
Epoch:  493  	Training Loss: 0.0016879783943295479
Test Loss:  0.0017901018727570772
Valid Loss:  0.0015885301399976015
Epoch:  494  	Training Loss: 0.001687978277914226
Test Loss:  0.0017901009414345026
Valid Loss:  0.0015885299071669579
Epoch:  495  	Training Loss: 0.0016879772301763296
Test Loss:  0.0017901002429425716
Valid Loss:  0.0015885294415056705
Epoch:  496  	Training Loss: 0.0016879773465916514
Test Loss:  0.0017901011742651463
Valid Loss:  0.0015885288594290614
Epoch:  497  	Training Loss: 0.0016879778122529387
Test Loss:  0.0017901011742651463
Valid Loss:  0.001588528510183096
Epoch:  498  	Training Loss: 0.0016879779286682606
Test Loss:  0.0017901011742651463
Valid Loss:  0.001588528510183096
Epoch:  499  	Training Loss: 0.0016879781614989042
Test Loss:  0.0017900994280353189
Valid Loss:  0.001588527811691165
Epoch:  500  	Training Loss: 0.001687977695837617
Test Loss:  0.0017901002429425716
Valid Loss:  0.001588528510183096
**************************************************learning rate decay**************************************************
seed is  14
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:32,  6.32s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.87it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:32,  1.19s/it]  5%|▍         | 23/500 [00:20<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:35,  3.02it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:36,  1.18it/s]  7%|▋         | 35/500 [00:27<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<08:55,  1.17s/it]  9%|▊         | 43/500 [00:33<06:22,  1.20it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:20,  2.26it/s] 10%|▉         | 49/500 [00:34<02:28,  3.04it/s] 10%|█         | 51/500 [00:40<08:52,  1.19s/it] 11%|█         | 53/500 [00:40<06:20,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:47<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.98it/s]Epoch:  1  	Training Loss: 0.26650020480155945
Test Loss:  0.1401931792497635
Valid Loss:  0.12618473172187805
Epoch:  2  	Training Loss: 0.13260839879512787
Test Loss:  0.10978981852531433
Valid Loss:  0.09791159629821777
Epoch:  3  	Training Loss: 0.10353843122720718
Test Loss:  0.08329248428344727
Valid Loss:  0.07342195510864258
Epoch:  4  	Training Loss: 0.07823535799980164
Test Loss:  0.06130623817443848
Valid Loss:  0.05370553582906723
Epoch:  5  	Training Loss: 0.0576409250497818
Test Loss:  0.04799738898873329
Valid Loss:  0.04227056726813316
Epoch:  6  	Training Loss: 0.04549106955528259
Test Loss:  0.03977258503437042
Valid Loss:  0.03555109351873398
Epoch:  7  	Training Loss: 0.038200169801712036
Test Loss:  0.0345369353890419
Valid Loss:  0.03150002658367157
Epoch:  8  	Training Loss: 0.03369937092065811
Test Loss:  0.031073227524757385
Valid Loss:  0.02896001748740673
Epoch:  9  	Training Loss: 0.030807243660092354
Test Loss:  0.028675470501184464
Valid Loss:  0.02728150598704815
Epoch:  10  	Training Loss: 0.02885775826871395
Test Loss:  0.026943884789943695
Valid Loss:  0.026106778532266617
Epoch:  11  	Training Loss: 0.02747580036520958
Test Loss:  0.025631386786699295
Valid Loss:  0.025223933160305023
Epoch:  12  	Training Loss: 0.026430675759911537
Test Loss:  0.02322571352124214
Valid Loss:  0.023134766146540642
Epoch:  13  	Training Loss: 0.024173513054847717
Test Loss:  0.020973598584532738
Valid Loss:  0.021234311163425446
Epoch:  14  	Training Loss: 0.022115424275398254
Test Loss:  0.019366290420293808
Valid Loss:  0.019892094656825066
Epoch:  15  	Training Loss: 0.02066855877637863
Test Loss:  0.018084019422531128
Valid Loss:  0.01882762461900711
Epoch:  16  	Training Loss: 0.019512701779603958
Test Loss:  0.01699618063867092
Valid Loss:  0.017912091687321663
Epoch:  17  	Training Loss: 0.01852373406291008
Test Loss:  0.01604379713535309
Valid Loss:  0.017088651657104492
Epoch:  18  	Training Loss: 0.017641505226492882
Test Loss:  0.015190771780908108
Valid Loss:  0.016336385160684586
Epoch:  19  	Training Loss: 0.01683954894542694
Test Loss:  0.014416486956179142
Valid Loss:  0.015631740912795067
Epoch:  20  	Training Loss: 0.01609613746404648
Test Loss:  0.013704827055335045
Valid Loss:  0.014966247603297234
Epoch:  21  	Training Loss: 0.01539920549839735
Test Loss:  0.013043602928519249
Valid Loss:  0.01433725468814373
Epoch:  22  	Training Loss: 0.014744115993380547
Test Loss:  0.012409920804202557
Valid Loss:  0.01376846432685852
Epoch:  23  	Training Loss: 0.014139696955680847
Test Loss:  0.011942033655941486
Valid Loss:  0.013338442891836166
Epoch:  24  	Training Loss: 0.013680893927812576
Test Loss:  0.011602507904171944
Valid Loss:  0.013026702217757702
Epoch:  25  	Training Loss: 0.013350158929824829
Test Loss:  0.011289430782198906
Valid Loss:  0.012739469297230244
Epoch:  26  	Training Loss: 0.013044420629739761
Test Loss:  0.010992703959345818
Valid Loss:  0.012463465332984924
Epoch:  27  	Training Loss: 0.012752814218401909
Test Loss:  0.010710082948207855
Valid Loss:  0.012198120355606079
Epoch:  28  	Training Loss: 0.012473265640437603
Test Loss:  0.010439946316182613
Valid Loss:  0.011941621080040932
Epoch:  29  	Training Loss: 0.012203852646052837
Test Loss:  0.010180998593568802
Valid Loss:  0.011693470180034637
Epoch:  30  	Training Loss: 0.011943826451897621
Test Loss:  0.009932037442922592
Valid Loss:  0.011452285572886467
Epoch:  31  	Training Loss: 0.011691845953464508
Test Loss:  0.009691646322607994
Valid Loss:  0.011217164807021618
Epoch:  32  	Training Loss: 0.011447091586887836
Test Loss:  0.009338493458926678
Valid Loss:  0.010878819040954113
Epoch:  33  	Training Loss: 0.011090964078903198
Test Loss:  0.009005378931760788
Valid Loss:  0.010553834959864616
Epoch:  34  	Training Loss: 0.010750935412943363
Test Loss:  0.008689941838383675
Valid Loss:  0.010241260752081871
Epoch:  35  	Training Loss: 0.010425395332276821
Test Loss:  0.008390400558710098
Valid Loss:  0.009940446354448795
Epoch:  36  	Training Loss: 0.010113315656781197
Test Loss:  0.008105448447167873
Valid Loss:  0.00965157151222229
Epoch:  37  	Training Loss: 0.009814765304327011
Test Loss:  0.007834086194634438
Valid Loss:  0.009374583140015602
Epoch:  38  	Training Loss: 0.009528848342597485
Test Loss:  0.007579082623124123
Valid Loss:  0.009121354669332504
Epoch:  39  	Training Loss: 0.009265863336622715
Test Loss:  0.007338627241551876
Valid Loss:  0.00888023804873228
Epoch:  40  	Training Loss: 0.009013830684125423
Test Loss:  0.007109995931386948
Valid Loss:  0.008647589012980461
Epoch:  41  	Training Loss: 0.008773407898843288
Test Loss:  0.006895022466778755
Valid Loss:  0.008426343090832233
Epoch:  42  	Training Loss: 0.008544599637389183
Test Loss:  0.006464743986725807
Valid Loss:  0.007952331565320492
Epoch:  43  	Training Loss: 0.00806656014174223
Test Loss:  0.006105818320065737
Valid Loss:  0.007559338118880987
Epoch:  44  	Training Loss: 0.007671227678656578
Test Loss:  0.005792343523353338
Valid Loss:  0.007216178812086582
Epoch:  45  	Training Loss: 0.007323817349970341
Test Loss:  0.005506325513124466
Valid Loss:  0.006900230422616005
Epoch:  46  	Training Loss: 0.007004243321716785
Test Loss:  0.005242284387350082
Valid Loss:  0.0066056689247488976
Epoch:  47  	Training Loss: 0.006706381216645241
Test Loss:  0.004996005445718765
Valid Loss:  0.0063281129114329815
Epoch:  48  	Training Loss: 0.006426060572266579
Test Loss:  0.0047660465352237225
Valid Loss:  0.006066212430596352
Epoch:  49  	Training Loss: 0.006161821540445089
Test Loss:  0.004551190882921219
Valid Loss:  0.0058190175332129
Epoch:  50  	Training Loss: 0.00591277563944459
Test Loss:  0.004350156523287296
Valid Loss:  0.00558554707095027
Epoch:  51  	Training Loss: 0.005677859764546156
Test Loss:  0.0041619595140218735
Valid Loss:  0.0053647905588150024
Epoch:  52  	Training Loss: 0.005455896258354187
Test Loss:  0.003946482203900814
Valid Loss:  0.005134200677275658
Epoch:  53  	Training Loss: 0.005213765427470207
Test Loss:  0.003783957567065954
Valid Loss:  0.004950741771608591
Epoch:  54  	Training Loss: 0.0050256275571882725
Test Loss:  0.0036441434640437365
Valid Loss:  0.004786707926541567
Epoch:  55  	Training Loss: 0.004858625121414661
Test Loss:  0.0035135350190103054
Valid Loss:  0.004630782175809145
Epoch:  56  	Training Loss: 0.00470061507076025
Test Loss:  0.003390977159142494
Valid Loss:  0.00448228232562542
Epoch:  57  	Training Loss: 0.004550711717456579
Test Loss:  0.00327578978613019
Valid Loss:  0.004340842831879854
Epoch:  58  	Training Loss: 0.004408313427120447
Test Loss:  0.003167353570461273
Valid Loss:  0.0042060138657689095
Epoch:  59  	Training Loss: 0.004272931255400181
Test Loss:  0.0030651711858808994
Valid Loss:  0.004077455028891563
Epoch:  60  	Training Loss: 0.004144119098782539
Test Loss:  0.002968689426779747
Valid Loss:  0.003954834304749966
Epoch:  61  	Training Loss: 0.004021525848656893
Test Loss:  0.0028776186518371105
Valid Loss:  0.003837869269773364
Epoch:  62  	Training Loss: 0.003904745914041996
Test Loss:  0.0027001588605344296
Valid Loss:  0.00358884921297431
Epoch:  63  	Training Loss: 0.0036708712577819824
Test Loss:  0.0025540683418512344
Valid Loss:  0.003393369261175394
Epoch:  64  	Training Loss: 0.0034831969533115625
Test Loss:  0.002426029182970524
Valid Loss:  0.0032217546831816435
Epoch:  65  	Training Loss: 0.003311984706670046
Test Loss:  0.0023112758062779903
Valid Loss:  0.003070905338972807
Epoch:  66  	Training Loss: 0.003164206864312291
Test Loss:  0.002217189408838749
Valid Loss:  0.0029447658453136683
Epoch:  67  	Training Loss: 0.0030385474674403667
Test Loss:  0.0021328823640942574
Valid Loss:  0.0028318623080849648
Epoch:  68  	Training Loss: 0.002926766639575362
Test Loss:  0.00206004292704165
Valid Loss:  0.002732430584728718
Epoch:  69  	Training Loss: 0.0028267414309084415
Test Loss:  0.00199511437676847
Valid Loss:  0.002642904408276081
Epoch:  70  	Training Loss: 0.002736522816121578
Test Loss:  0.001937352237291634
Valid Loss:  0.0025618327781558037
Epoch:  71  	Training Loss: 0.002653934061527252
Test Loss:  0.001884258585050702
Valid Loss:   14%|█▍        | 71/500 [00:54<08:33,  1.20s/it] 15%|█▍        | 73/500 [00:54<06:06,  1.16it/s] 15%|█▌        | 75/500 [00:54<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:54<03:12,  2.20it/s] 16%|█▌        | 79/500 [00:54<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:01<08:23,  1.20s/it] 17%|█▋        | 83/500 [01:01<06:02,  1.15it/s] 17%|█▋        | 85/500 [01:01<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:01<03:11,  2.16it/s] 18%|█▊        | 89/500 [01:01<02:21,  2.91it/s] 18%|█▊        | 91/500 [01:08<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:15<07:55,  1.19s/it] 21%|██        | 103/500 [01:15<05:39,  1.17it/s] 21%|██        | 105/500 [01:15<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:15<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:15<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:21<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:22<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:22<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:28<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.25it/s] 28%|██▊       | 139/500 [01:36<02:00,  3.01it/s]0.0024862883146852255
Epoch:  72  	Training Loss: 0.0025774510577321053
Test Loss:  0.0018499195575714111
Valid Loss:  0.0024259788915514946
Epoch:  73  	Training Loss: 0.0025223013944923878
Test Loss:  0.00181400659494102
Valid Loss:  0.0023621695581823587
Epoch:  74  	Training Loss: 0.002461901167407632
Test Loss:  0.0017673716647550464
Valid Loss:  0.0022913620341569185
Epoch:  75  	Training Loss: 0.00238912389613688
Test Loss:  0.0017117680981755257
Valid Loss:  0.0022148306015878916
Epoch:  76  	Training Loss: 0.002310647862032056
Test Loss:  0.0016515899915248156
Valid Loss:  0.0021314541809260845
Epoch:  77  	Training Loss: 0.002226833254098892
Test Loss:  0.001595046604052186
Valid Loss:  0.002052745781838894
Epoch:  78  	Training Loss: 0.0021467087790369987
Test Loss:  0.0015465803444385529
Valid Loss:  0.0019857115112245083
Epoch:  79  	Training Loss: 0.002075675642117858
Test Loss:  0.0015049848007038236
Valid Loss:  0.0019292953656986356
Epoch:  80  	Training Loss: 0.0020157042890787125
Test Loss:  0.0014708563685417175
Valid Loss:  0.0018799363169819117
Epoch:  81  	Training Loss: 0.001965269912034273
Test Loss:  0.0014410043368116021
Valid Loss:  0.0018375040963292122
Epoch:  82  	Training Loss: 0.0019209663150832057
Test Loss:  0.0014115707017481327
Valid Loss:  0.001789167057722807
Epoch:  83  	Training Loss: 0.0018707325216382742
Test Loss:  0.0013896194286644459
Valid Loss:  0.0017546587623655796
Epoch:  84  	Training Loss: 0.001833421178162098
Test Loss:  0.0013716317480430007
Valid Loss:  0.0017238510772585869
Epoch:  85  	Training Loss: 0.0018006941536441445
Test Loss:  0.0013560452498495579
Valid Loss:  0.0016954592429101467
Epoch:  86  	Training Loss: 0.0017709347885102034
Test Loss:  0.0013421670300886035
Valid Loss:  0.0016689177136868238
Epoch:  87  	Training Loss: 0.0017433777684345841
Test Loss:  0.0013296743854880333
Valid Loss:  0.001643957570195198
Epoch:  88  	Training Loss: 0.0017177306581288576
Test Loss:  0.0013182242400944233
Valid Loss:  0.0016204407438635826
Epoch:  89  	Training Loss: 0.0016936006722971797
Test Loss:  0.0013066756073385477
Valid Loss:  0.00159736059140414
Epoch:  90  	Training Loss: 0.0016703938599675894
Test Loss:  0.0012949174270033836
Valid Loss:  0.001575143774971366
Epoch:  91  	Training Loss: 0.0016479152254760265
Test Loss:  0.0012824726291000843
Valid Loss:  0.001552579808048904
Epoch:  92  	Training Loss: 0.0016248754691332579
Test Loss:  0.0012705913977697492
Valid Loss:  0.0015243020607158542
Epoch:  93  	Training Loss: 0.0015949526568874717
Test Loss:  0.0012590254191309214
Valid Loss:  0.0014991160714998841
Epoch:  94  	Training Loss: 0.0015686035621911287
Test Loss:  0.0012481615412980318
Valid Loss:  0.0014761135680601
Epoch:  95  	Training Loss: 0.001544593134894967
Test Loss:  0.001237683929502964
Valid Loss:  0.0014542428543791175
Epoch:  96  	Training Loss: 0.0015216809697449207
Test Loss:  0.001227936940267682
Valid Loss:  0.0014340865891426802
Epoch:  97  	Training Loss: 0.0015005080495029688
Test Loss:  0.0012178781908005476
Valid Loss:  0.0014144189190119505
Epoch:  98  	Training Loss: 0.0014800634235143661
Test Loss:  0.0012077682185918093
Valid Loss:  0.0013952413573861122
Epoch:  99  	Training Loss: 0.001460404833778739
Test Loss:  0.0011976244859397411
Valid Loss:  0.001376842032186687
Epoch:  100  	Training Loss: 0.0014413404278457165
Test Loss:  0.0011874742340296507
Valid Loss:  0.0013589076697826385
Epoch:  101  	Training Loss: 0.001422822242602706
Test Loss:  0.0011775459861382842
Valid Loss:  0.0013416663277894258
Epoch:  102  	Training Loss: 0.0014050127938389778
Test Loss:  0.0011696165893226862
Valid Loss:  0.001329863560386002
Epoch:  103  	Training Loss: 0.0013933354057371616
Test Loss:  0.0011635534465312958
Valid Loss:  0.0013195436913520098
Epoch:  104  	Training Loss: 0.0013829702511429787
Test Loss:  0.0011593529488891363
Valid Loss:  0.0013103806413710117
Epoch:  105  	Training Loss: 0.0013738186098635197
Test Loss:  0.0011560707353055477
Valid Loss:  0.001301741343922913
Epoch:  106  	Training Loss: 0.001365242525935173
Test Loss:  0.001153307966887951
Valid Loss:  0.0012935004197061062
Epoch:  107  	Training Loss: 0.001357060158625245
Test Loss:  0.0011508138850331306
Valid Loss:  0.0012856388930231333
Epoch:  108  	Training Loss: 0.001349199446849525
Test Loss:  0.0011485384311527014
Valid Loss:  0.0012780788820236921
Epoch:  109  	Training Loss: 0.0013416254660114646
Test Loss:  0.0011464685667306185
Valid Loss:  0.0012708012945950031
Epoch:  110  	Training Loss: 0.0013343491591513157
Test Loss:  0.0011445826385170221
Valid Loss:  0.0012638475745916367
Epoch:  111  	Training Loss: 0.0013273591175675392
Test Loss:  0.0011428161524236202
Valid Loss:  0.0012571306433528662
Epoch:  112  	Training Loss: 0.0013205930590629578
Test Loss:  0.0011393607128411531
Valid Loss:  0.0012490423396229744
Epoch:  113  	Training Loss: 0.0013125946279615164
Test Loss:  0.001136760227382183
Valid Loss:  0.001242215046659112
Epoch:  114  	Training Loss: 0.0013058158801868558
Test Loss:  0.001134504098445177
Valid Loss:  0.0012359623797237873
Epoch:  115  	Training Loss: 0.0012995320139452815
Test Loss:  0.0011323913931846619
Valid Loss:  0.0012300157686695457
Epoch:  116  	Training Loss: 0.0012935391860082746
Test Loss:  0.0011302733328193426
Valid Loss:  0.0012244419194757938
Epoch:  117  	Training Loss: 0.001287809107452631
Test Loss:  0.0011280151084065437
Valid Loss:  0.0012191772693768144
Epoch:  118  	Training Loss: 0.0012822295539081097
Test Loss:  0.001125810551457107
Valid Loss:  0.0012140582548454404
Epoch:  119  	Training Loss: 0.0012767920270562172
Test Loss:  0.0011237006401643157
Valid Loss:  0.0012090596137568355
Epoch:  120  	Training Loss: 0.0012715129414573312
Test Loss:  0.0011215617414563894
Valid Loss:  0.0012041798327118158
Epoch:  121  	Training Loss: 0.0012663474772125483
Test Loss:  0.0011194371618330479
Valid Loss:  0.0011993817752227187
Epoch:  122  	Training Loss: 0.0012612836435437202
Test Loss:  0.0011168329510837793
Valid Loss:  0.0011899559758603573
Epoch:  123  	Training Loss: 0.0012513964902609587
Test Loss:  0.0011153989471495152
Valid Loss:  0.0011824901448562741
Epoch:  124  	Training Loss: 0.0012432513758540154
Test Loss:  0.001114916754886508
Valid Loss:  0.0011762331705540419
Epoch:  125  	Training Loss: 0.0012366289738565683
Test Loss:  0.0011148476041853428
Valid Loss:  0.001170515432022512
Epoch:  126  	Training Loss: 0.0012306531425565481
Test Loss:  0.0011150251375511289
Valid Loss:  0.0011653788387775421
Epoch:  127  	Training Loss: 0.0012252256274223328
Test Loss:  0.0011152256047353148
Valid Loss:  0.0011604813626036048
Epoch:  128  	Training Loss: 0.0012201301287859678
Test Loss:  0.0011145640164613724
Valid Loss:  0.0011551741044968367
Epoch:  129  	Training Loss: 0.0012146556982770562
Test Loss:  0.001111059682443738
Valid Loss:  0.0011475910432636738
Epoch:  130  	Training Loss: 0.0012066392228007317
Test Loss:  0.0011049240129068494
Valid Loss:  0.0011374435853213072
Epoch:  131  	Training Loss: 0.0011958996765315533
Test Loss:  0.0010994614567607641
Valid Loss:  0.0011281888000667095
Epoch:  132  	Training Loss: 0.0011859992519021034
Test Loss:  0.001093842089176178
Valid Loss:  0.0011183511232957244
Epoch:  133  	Training Loss: 0.001176010468043387
Test Loss:  0.0010885538067668676
Valid Loss:  0.00110963499173522
Epoch:  134  	Training Loss: 0.0011671521933749318
Test Loss:  0.0010819497983902693
Valid Loss:  0.0010998414363712072
Epoch:  135  	Training Loss: 0.0011567834299057722
Test Loss:  0.0010744649916887283
Valid Loss:  0.0010893389116972685
Epoch:  136  	Training Loss: 0.0011457300279289484
Test Loss:  0.0010669489856809378
Valid Loss:  0.0010786522179841995
Epoch:  137  	Training Loss: 0.0011345043312758207
Test Loss:  0.0010602216934785247
Valid Loss:  0.001068735495209694
Epoch:  138  	Training Loss: 0.0011239846935495734
Test Loss:  0.0010550740407779813
Valid Loss:  0.0010601715184748173
Epoch:  139  	Training Loss: 0.001114957733079791
Test Loss:  0.0010512240696698427
Valid Loss:  0.0010532576125115156
Epoch:  140  	Training Loss: 0.0011071688495576382
Test Loss:  0.0010482469806447625
 28%|██▊       | 141/500 [01:42<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:42<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:42<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:42<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.01it/s] 30%|███       | 151/500 [01:49<06:50,  1.18s/it] 31%|███       | 153/500 [01:49<04:53,  1.18it/s] 31%|███       | 155/500 [01:49<03:31,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:56<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:56<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:56<03:23,  1.64it/s] 33%|███▎      | 167/500 [01:56<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:56<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:02<06:24,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:03<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:03<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:09<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:10<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:16<06:16,  1.22s/it] 39%|███▊      | 193/500 [02:16<04:28,  1.14it/s] 39%|███▉      | 195/500 [02:16<03:12,  1.58it/s] 39%|███▉      | 197/500 [02:17<02:19,  2.17it/s] 40%|███▉      | 199/500 [02:17<01:43,  2.92it/s] 40%|████      | 201/500 [02:23<05:54,  1.18s/it] 41%|████      | 203/500 [02:23<04:12,  1.17it/s] 41%|████      | 205/500 [02:23<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.22it/s]Valid Loss:  0.001047715311869979
Epoch:  141  	Training Loss: 0.0011004023253917694
Test Loss:  0.0010459879413247108
Valid Loss:  0.001043579657562077
Epoch:  142  	Training Loss: 0.0010950425639748573
Test Loss:  0.001043949043378234
Valid Loss:  0.0010366886854171753
Epoch:  143  	Training Loss: 0.001087430864572525
Test Loss:  0.0010428205132484436
Valid Loss:  0.0010307803750038147
Epoch:  144  	Training Loss: 0.0010812386171892285
Test Loss:  0.0010423099156469107
Valid Loss:  0.0010255143279209733
Epoch:  145  	Training Loss: 0.0010758264688774943
Test Loss:  0.0010420135222375393
Valid Loss:  0.0010207250015810132
Epoch:  146  	Training Loss: 0.001070904079824686
Test Loss:  0.0010416058357805014
Valid Loss:  0.001016324618831277
Epoch:  147  	Training Loss: 0.001066312426701188
Test Loss:  0.0010411584516987205
Valid Loss:  0.0010123170213773847
Epoch:  148  	Training Loss: 0.0010620173998177052
Test Loss:  0.0010407636873424053
Valid Loss:  0.0010086542461067438
Epoch:  149  	Training Loss: 0.0010580243542790413
Test Loss:  0.0010405873181298375
Valid Loss:  0.0010053501464426517
Epoch:  150  	Training Loss: 0.0010544124525040388
Test Loss:  0.0010402369080111384
Valid Loss:  0.001002212055027485
Epoch:  151  	Training Loss: 0.0010510541032999754
Test Loss:  0.0010398003505542874
Valid Loss:  0.000999172916635871
Epoch:  152  	Training Loss: 0.0010478351032361388
Test Loss:  0.0010392074473202229
Valid Loss:  0.0009966447250917554
Epoch:  153  	Training Loss: 0.0010452938731759787
Test Loss:  0.0010385895147919655
Valid Loss:  0.0009942315518856049
Epoch:  154  	Training Loss: 0.0010428333189338446
Test Loss:  0.0010379439918324351
Valid Loss:  0.0009919467847794294
Epoch:  155  	Training Loss: 0.0010404408676549792
Test Loss:  0.0010372539982199669
Valid Loss:  0.0009897281415760517
Epoch:  156  	Training Loss: 0.0010381012689322233
Test Loss:  0.0010365666821599007
Valid Loss:  0.0009875237010419369
Epoch:  157  	Training Loss: 0.001035815803334117
Test Loss:  0.0010359053267166018
Valid Loss:  0.0009853681549429893
Epoch:  158  	Training Loss: 0.0010335877304896712
Test Loss:  0.0010352644603699446
Valid Loss:  0.0009832419455051422
Epoch:  159  	Training Loss: 0.001031416468322277
Test Loss:  0.0010345809860154986
Valid Loss:  0.0009811442578211427
Epoch:  160  	Training Loss: 0.001029269304126501
Test Loss:  0.0010339205618947744
Valid Loss:  0.0009790617041289806
Epoch:  161  	Training Loss: 0.0010271478677168489
Test Loss:  0.0010332601377740502
Valid Loss:  0.0009770047618076205
Epoch:  162  	Training Loss: 0.0010250528575852513
Test Loss:  0.0010315144900232553
Valid Loss:  0.0009747538715600967
Epoch:  163  	Training Loss: 0.0010226602898910642
Test Loss:  0.0010300434660166502
Valid Loss:  0.0009728990262374282
Epoch:  164  	Training Loss: 0.0010205847211182117
Test Loss:  0.0010285780299454927
Valid Loss:  0.0009711328311823308
Epoch:  165  	Training Loss: 0.0010186447761952877
Test Loss:  0.0010272553190588951
Valid Loss:  0.0009695797925814986
Epoch:  166  	Training Loss: 0.0010169250890612602
Test Loss:  0.0010260395938530564
Valid Loss:  0.0009681032388471067
Epoch:  167  	Training Loss: 0.0010152995819225907
Test Loss:  0.0010250101331621408
Valid Loss:  0.0009667517151683569
Epoch:  168  	Training Loss: 0.001013810047879815
Test Loss:  0.001024189405143261
Valid Loss:  0.0009655032190494239
Epoch:  169  	Training Loss: 0.0010124079417437315
Test Loss:  0.0010234429500997066
Valid Loss:  0.0009643257362768054
Epoch:  170  	Training Loss: 0.0010110561270266771
Test Loss:  0.0010227782186120749
Valid Loss:  0.0009631722350604832
Epoch:  171  	Training Loss: 0.0010097448248416185
Test Loss:  0.0010222105775028467
Valid Loss:  0.0009620457421988249
Epoch:  172  	Training Loss: 0.0010084968525916338
Test Loss:  0.001019357005134225
Valid Loss:  0.0009578201570548117
Epoch:  173  	Training Loss: 0.001004092046059668
Test Loss:  0.0010168494191020727
Valid Loss:  0.0009536703582853079
Epoch:  174  	Training Loss: 0.0009997354354709387
Test Loss:  0.001015183748677373
Valid Loss:  0.0009500914602540433
Epoch:  175  	Training Loss: 0.0009960192255675793
Test Loss:  0.001014297129586339
Valid Loss:  0.0009473732789047062
Epoch:  176  	Training Loss: 0.0009930010419338942
Test Loss:  0.001013800734654069
Valid Loss:  0.0009453726815991104
Epoch:  177  	Training Loss: 0.0009905732003971934
Test Loss:  0.0010135285556316376
Valid Loss:  0.0009435784304514527
Epoch:  178  	Training Loss: 0.0009885549079626799
Test Loss:  0.0010134328622370958
Valid Loss:  0.0009419401176273823
Epoch:  179  	Training Loss: 0.0009868707275018096
Test Loss:  0.0010133718606084585
Valid Loss:  0.0009403800358995795
Epoch:  180  	Training Loss: 0.000985298422165215
Test Loss:  0.0010133084142580628
Valid Loss:  0.0009389349725097418
Epoch:  181  	Training Loss: 0.000983839388936758
Test Loss:  0.0010132298339158297
Valid Loss:  0.0009375568479299545
Epoch:  182  	Training Loss: 0.000982426106929779
Test Loss:  0.0010137732606381178
Valid Loss:  0.0009358729585073888
Epoch:  183  	Training Loss: 0.0009804138680920005
Test Loss:  0.0010138568468391895
Valid Loss:  0.0009353155619464815
Epoch:  184  	Training Loss: 0.0009797050151973963
Test Loss:  0.0010138211073353887
Valid Loss:  0.0009348620660603046
Epoch:  185  	Training Loss: 0.0009792086202651262
Test Loss:  0.0010138596408069134
Valid Loss:  0.0009344377904199064
Epoch:  186  	Training Loss: 0.0009787516901269555
Test Loss:  0.0010139402002096176
Valid Loss:  0.0009340396500192583
Epoch:  187  	Training Loss: 0.0009783220011740923
Test Loss:  0.001014047535136342
Valid Loss:  0.0009336798684671521
Epoch:  188  	Training Loss: 0.0009779572719708085
Test Loss:  0.0010141257662326097
Valid Loss:  0.0009333210182376206
Epoch:  189  	Training Loss: 0.0009776207152754068
Test Loss:  0.0010142328683286905
Valid Loss:  0.0009330085595138371
Epoch:  190  	Training Loss: 0.0009772948687896132
Test Loss:  0.001014317967928946
Valid Loss:  0.0009327179868705571
Epoch:  191  	Training Loss: 0.0009769846219569445
Test Loss:  0.0010144496336579323
Valid Loss:  0.0009324330021627247
Epoch:  192  	Training Loss: 0.0009766893927007914
Test Loss:  0.001014050329104066
Valid Loss:  0.0009309768211096525
Epoch:  193  	Training Loss: 0.0009751558536663651
Test Loss:  0.0010136314667761326
Valid Loss:  0.0009297170327045023
Epoch:  194  	Training Loss: 0.0009738398366607726
Test Loss:  0.0010132199386134744
Valid Loss:  0.0009286390268243849
Epoch:  195  	Training Loss: 0.0009726979187689722
Test Loss:  0.0010129089932888746
Valid Loss:  0.0009277333738282323
Epoch:  196  	Training Loss: 0.0009717195061966777
Test Loss:  0.00101264170370996
Valid Loss:  0.0009269280126318336
Epoch:  197  	Training Loss: 0.0009708190336823463
Test Loss:  0.0010123529937118292
Valid Loss:  0.000926170265302062
Epoch:  198  	Training Loss: 0.0009699745569378138
Test Loss:  0.0010121373925358057
Valid Loss:  0.0009254676988348365
Epoch:  199  	Training Loss: 0.0009692256571725011
Test Loss:  0.0010119129437953234
Valid Loss:  0.0009248449932783842
Epoch:  200  	Training Loss: 0.000968541600741446
Test Loss:  0.001011752407066524
Valid Loss:  0.0009242602391168475
Epoch:  201  	Training Loss: 0.0009679069044068456
Test Loss:  0.0010116053745150566
Valid Loss:  0.0009237141348421574
Epoch:  202  	Training Loss: 0.0009673322783783078
Test Loss:  0.0010068798437714577
Valid Loss:  0.000919257989153266
Epoch:  203  	Training Loss: 0.0009630976710468531
Test Loss:  0.0010021277703344822
Valid Loss:  0.0009154129074886441
Epoch:  204  	Training Loss: 0.000959248747676611
Test Loss:  0.000997413182631135
Valid Loss:  0.0009118770249187946
Epoch:  205  	Training Loss: 0.000955697731114924
Test Loss:  0.0009926831116899848
Valid Loss:  0.000908532296307385
Epoch:  206  	Training Loss: 0.0009522971813566983
Test Loss:  0.0009880249854177237
Valid Loss:  0.0009053339017555118
Epoch:  207  	Training Loss: 0.0009490257943980396
Test Loss:  0.0009834186639636755
Valid Loss:  0.0009022450540214777
Epoch:  208  	Training Loss: 0.0009458884596824646
Test Loss:  0.0009789479663595557
Valid Loss:  0.0008992964867502451
 42%|████▏     | 209/500 [02:24<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:30<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:30<04:08,  1.16it/s] 43%|████▎     | 215/500 [02:30<02:58,  1.60it/s] 43%|████▎     | 217/500 [02:30<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:31<01:35,  2.95it/s] 44%|████▍     | 221/500 [02:37<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:37<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:37<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.20it/s] 46%|████▌     | 229/500 [02:37<01:32,  2.92it/s] 46%|████▌     | 231/500 [02:44<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:44<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:44<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:51<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:51<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:51<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:51<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:51<01:24,  2.98it/s] 50%|█████     | 251/500 [02:57<04:49,  1.16s/it] 51%|█████     | 253/500 [02:58<03:26,  1.20it/s] 51%|█████     | 255/500 [02:58<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:58<01:47,  2.26it/s] 52%|█████▏    | 259/500 [02:58<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:04<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:05<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:05<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:11<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:11<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:11<02:16,  1.65it/s]Epoch:  209  	Training Loss: 0.0009429153287783265
Test Loss:  0.0009745960705913603
Valid Loss:  0.0008965678280219436
Epoch:  210  	Training Loss: 0.0009401150746271014
Test Loss:  0.0009703514515422285
Valid Loss:  0.0008939369581639767
Epoch:  211  	Training Loss: 0.0009373851353302598
Test Loss:  0.0009662267402745783
Valid Loss:  0.0008913885103538632
Epoch:  212  	Training Loss: 0.000934719224460423
Test Loss:  0.0009629580890759826
Valid Loss:  0.0008890717290341854
Epoch:  213  	Training Loss: 0.000932144233956933
Test Loss:  0.0009607488755136728
Valid Loss:  0.0008873260812833905
Epoch:  214  	Training Loss: 0.0009302552207373083
Test Loss:  0.0009592094575054944
Valid Loss:  0.000885870074853301
Epoch:  215  	Training Loss: 0.0009287572465837002
Test Loss:  0.0009580046171322465
Valid Loss:  0.0008845888078212738
Epoch:  216  	Training Loss: 0.0009274348267354071
Test Loss:  0.0009570944821462035
Valid Loss:  0.0008834388572722673
Epoch:  217  	Training Loss: 0.0009262880776077509
Test Loss:  0.0009564178762957454
Valid Loss:  0.0008824710384942591
Epoch:  218  	Training Loss: 0.0009253341122530401
Test Loss:  0.0009559759637340903
Valid Loss:  0.0008816326153464615
Epoch:  219  	Training Loss: 0.0009245146065950394
Test Loss:  0.0009556110017001629
Valid Loss:  0.0008808132261037827
Epoch:  220  	Training Loss: 0.0009237120393663645
Test Loss:  0.0009553179843351245
Valid Loss:  0.0008800233481451869
Epoch:  221  	Training Loss: 0.0009229278657585382
Test Loss:  0.000955090275965631
Valid Loss:  0.000879322353284806
Epoch:  222  	Training Loss: 0.0009222021326422691
Test Loss:  0.0009547002846375108
Valid Loss:  0.0008780769421719015
Epoch:  223  	Training Loss: 0.0009210399584844708
Test Loss:  0.0009543719934299588
Valid Loss:  0.0008769996929913759
Epoch:  224  	Training Loss: 0.0009200680069625378
Test Loss:  0.0009540080791339278
Valid Loss:  0.0008760438649915159
Epoch:  225  	Training Loss: 0.0009191494900733232
Test Loss:  0.0009536441648378968
Valid Loss:  0.0008751823334023356
Epoch:  226  	Training Loss: 0.0009182962239719927
Test Loss:  0.0009532792610116303
Valid Loss:  0.0008743539219722152
Epoch:  227  	Training Loss: 0.0009174792212434113
Test Loss:  0.0009529436938464642
Valid Loss:  0.0008735402952879667
Epoch:  228  	Training Loss: 0.0009166814852505922
Test Loss:  0.0009526113281026483
Valid Loss:  0.0008727344684302807
Epoch:  229  	Training Loss: 0.0009159001638181508
Test Loss:  0.0009522716281935573
Valid Loss:  0.0008719501784071326
Epoch:  230  	Training Loss: 0.000915142591111362
Test Loss:  0.0009519645245745778
Valid Loss:  0.0008711627451702952
Epoch:  231  	Training Loss: 0.0009143990464508533
Test Loss:  0.0009516528225503862
Valid Loss:  0.0008703974890522659
Epoch:  232  	Training Loss: 0.0009136551525443792
Test Loss:  0.0009491738164797425
Valid Loss:  0.0008688349626027048
Epoch:  233  	Training Loss: 0.0009120411705225706
Test Loss:  0.0009473981917835772
Valid Loss:  0.0008677269797772169
Epoch:  234  	Training Loss: 0.000910812639631331
Test Loss:  0.000945914420299232
Valid Loss:  0.0008667755755595863
Epoch:  235  	Training Loss: 0.0009097071597352624
Test Loss:  0.000944612780585885
Valid Loss:  0.0008659072918817401
Epoch:  236  	Training Loss: 0.0009087108774110675
Test Loss:  0.0009435919928364456
Valid Loss:  0.0008650823729112744
Epoch:  237  	Training Loss: 0.0009077967843040824
Test Loss:  0.0009426306933164597
Valid Loss:  0.0008642690954729915
Epoch:  238  	Training Loss: 0.0009069058578461409
Test Loss:  0.0009417866822332144
Valid Loss:  0.0008634622790850699
Epoch:  239  	Training Loss: 0.0009060563752427697
Test Loss:  0.0009410370839759707
Valid Loss:  0.0008626840426586568
Epoch:  240  	Training Loss: 0.0009052607929334044
Test Loss:  0.0009403614094480872
Valid Loss:  0.0008619435247965157
Epoch:  241  	Training Loss: 0.0009045120095834136
Test Loss:  0.0009397974354214966
Valid Loss:  0.0008612095844000578
Epoch:  242  	Training Loss: 0.000903785228729248
Test Loss:  0.0009352850029245019
Valid Loss:  0.0008511384367011487
Epoch:  243  	Training Loss: 0.0008926207665354013
Test Loss:  0.0009306704741902649
Valid Loss:  0.0008426976855844259
Epoch:  244  	Training Loss: 0.0008838127250783145
Test Loss:  0.0009256748599000275
Valid Loss:  0.0008351427968591452
Epoch:  245  	Training Loss: 0.0008758241892792284
Test Loss:  0.0009204347152262926
Valid Loss:  0.0008282620692625642
Epoch:  246  	Training Loss: 0.0008685062639415264
Test Loss:  0.0009151431731879711
Valid Loss:  0.0008218038128688931
Epoch:  247  	Training Loss: 0.000861533684656024
Test Loss:  0.0009099958697333932
Valid Loss:  0.0008156825206242502
Epoch:  248  	Training Loss: 0.0008550574420951307
Test Loss:  0.0009053426329046488
Valid Loss:  0.0008099869592115283
Epoch:  249  	Training Loss: 0.0008490117033943534
Test Loss:  0.0009010038338601589
Valid Loss:  0.0008048254530876875
Epoch:  250  	Training Loss: 0.0008431870373897254
Test Loss:  0.000896880344953388
Valid Loss:  0.0008000722154974937
Epoch:  251  	Training Loss: 0.0008376693003810942
Test Loss:  0.0008930738549679518
Valid Loss:  0.0007956050103530288
Epoch:  252  	Training Loss: 0.000832471763715148
Test Loss:  0.0008923858404159546
Valid Loss:  0.000794618739746511
Epoch:  253  	Training Loss: 0.0008315960876643658
Test Loss:  0.0008916606311686337
Valid Loss:  0.0007936455658636987
Epoch:  254  	Training Loss: 0.0008307411335408688
Test Loss:  0.0008910311153158545
Valid Loss:  0.00079279177589342
Epoch:  255  	Training Loss: 0.0008299011969938874
Test Loss:  0.0008903568377718329
Valid Loss:  0.0007919612107798457
Epoch:  256  	Training Loss: 0.0008290786063298583
Test Loss:  0.0008897389052435756
Valid Loss:  0.0007911479333415627
Epoch:  257  	Training Loss: 0.0008282875642180443
Test Loss:  0.000889049842953682
Valid Loss:  0.0007903450168669224
Epoch:  258  	Training Loss: 0.0008275093277916312
Test Loss:  0.000888453796505928
Valid Loss:  0.0007895827293395996
Epoch:  259  	Training Loss: 0.0008267603698186576
Test Loss:  0.0008878229418769479
Valid Loss:  0.0007888189284130931
Epoch:  260  	Training Loss: 0.0008260287577286363
Test Loss:  0.0008872980251908302
Valid Loss:  0.0007880771299824119
Epoch:  261  	Training Loss: 0.0008253161795437336
Test Loss:  0.0008867086144164205
Valid Loss:  0.000787333061452955
Epoch:  262  	Training Loss: 0.0008246137294918299
Test Loss:  0.0008863253751769662
Valid Loss:  0.0007869710680097342
Epoch:  263  	Training Loss: 0.000824164948426187
Test Loss:  0.0008860931266099215
Valid Loss:  0.0007866100640967488
Epoch:  264  	Training Loss: 0.000823743874207139
Test Loss:  0.0008859424269758165
Valid Loss:  0.0007862350321374834
Epoch:  265  	Training Loss: 0.000823327514808625
Test Loss:  0.0008858782239258289
Valid Loss:  0.0007858593598939478
Epoch:  266  	Training Loss: 0.0008229175582528114
Test Loss:  0.0008858654764480889
Valid Loss:  0.0007854895666241646
Epoch:  267  	Training Loss: 0.0008225323399528861
Test Loss:  0.0008858760120347142
Valid Loss:  0.0007851310074329376
Epoch:  268  	Training Loss: 0.0008221749449148774
Test Loss:  0.0008858994115144014
Valid Loss:  0.0007847790257073939
Epoch:  269  	Training Loss: 0.0008218300063163042
Test Loss:  0.0008859208319336176
Valid Loss:  0.000784429139457643
Epoch:  270  	Training Loss: 0.0008214860572479665
Test Loss:  0.0008859510417096317
Valid Loss:  0.0007840806501917541
Epoch:  271  	Training Loss: 0.0008211566600948572
Test Loss:  0.0008859746158123016
Valid Loss:  0.0007837350131012499
Epoch:  272  	Training Loss: 0.0008208287763409317
Test Loss:  0.0008811643347144127
Valid Loss:  0.0007777889259159565
Epoch:  273  	Training Loss: 0.0008142235456034541
Test Loss:  0.000876334379427135
Valid Loss:  0.0007726054172962904
Epoch:  274  	Training Loss: 0.0008083427674137056
Test Loss:  0.0008717613527551293
Valid Loss:  0.0007681492133997381
Epoch:  275  	Training Loss: 0.0008030148455873132
Test Loss:  0.0008680575992912054
Valid Loss:  0.0007642386481165886
Epoch:  276  	Training Loss: 0.0007983193499967456
Test Loss:  0.0008647280046716332
Valid Loss:  0.0007603889680467546
Epoch:  277  	Training Loss: 0.0007937576156109571
 55%|█████▌    | 277/500 [03:11<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:11<01:13,  3.03it/s] 56%|█████▌    | 281/500 [03:18<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:18<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:18<02:10,  1.64it/s] 57%|█████▋    | 287/500 [03:18<01:34,  2.24it/s] 58%|█████▊    | 289/500 [03:18<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:25<04:09,  1.19s/it] 59%|█████▊    | 293/500 [03:25<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:25<02:07,  1.60it/s] 59%|█████▉    | 297/500 [03:25<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:25<01:08,  2.94it/s] 60%|██████    | 301/500 [03:32<03:54,  1.18s/it] 61%|██████    | 303/500 [03:32<02:47,  1.18it/s] 61%|██████    | 305/500 [03:32<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:32<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:38<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:39<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:39<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:39<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:39<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:45<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:45<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:46<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:46<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:46<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:52<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:52<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:52<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:53<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:53<00:54,  2.93it/s] 68%|██████▊   | 341/500 [03:59<03:08,  1.19s/it] 69%|██████▊   | 343/500 [03:59<02:14,  1.17it/s]Test Loss:  0.0008614283287897706
Valid Loss:  0.0007567034335806966
Epoch:  278  	Training Loss: 0.0007894587470218539
Test Loss:  0.0008585326140746474
Valid Loss:  0.0007536483462899923
Epoch:  279  	Training Loss: 0.0007858772296458483
Test Loss:  0.0008558136178180575
Valid Loss:  0.0007507913978770375
Epoch:  280  	Training Loss: 0.0007825723150745034
Test Loss:  0.0008532706997357309
Valid Loss:  0.0007481041247956455
Epoch:  281  	Training Loss: 0.0007794752018526196
Test Loss:  0.0008510411716997623
Valid Loss:  0.0007458010804839432
Epoch:  282  	Training Loss: 0.0007766958442516625
Test Loss:  0.0008480825345031917
Valid Loss:  0.000743768410757184
Epoch:  283  	Training Loss: 0.0007747208583168685
Test Loss:  0.0008456505602225661
Valid Loss:  0.0007420281763188541
Epoch:  284  	Training Loss: 0.0007730838260613382
Test Loss:  0.0008437774376943707
Valid Loss:  0.0007405421929433942
Epoch:  285  	Training Loss: 0.000771697610616684
Test Loss:  0.0008420332451350987
Valid Loss:  0.0007391453837044537
Epoch:  286  	Training Loss: 0.0007703980663791299
Test Loss:  0.0008404769469052553
Valid Loss:  0.0007379071321338415
Epoch:  287  	Training Loss: 0.0007692441577091813
Test Loss:  0.0008390670991502702
Valid Loss:  0.0007367497310042381
Epoch:  288  	Training Loss: 0.0007681706920266151
Test Loss:  0.0008379828650504351
Valid Loss:  0.0007357122958637774
Epoch:  289  	Training Loss: 0.00076725531835109
Test Loss:  0.0008369545103050768
Valid Loss:  0.000734748609829694
Epoch:  290  	Training Loss: 0.0007663770811632276
Test Loss:  0.000836046936456114
Valid Loss:  0.0007338298601098359
Epoch:  291  	Training Loss: 0.0007655597291886806
Test Loss:  0.0008351971046067774
Valid Loss:  0.0007329299696721137
Epoch:  292  	Training Loss: 0.0007647628663107753
Test Loss:  0.0008352246950380504
Valid Loss:  0.0007318648276850581
Epoch:  293  	Training Loss: 0.0007636408554390073
Test Loss:  0.0008352461736649275
Valid Loss:  0.0007308302447199821
Epoch:  294  	Training Loss: 0.0007625553989782929
Test Loss:  0.0008352582808583975
Valid Loss:  0.0007298305863514543
Epoch:  295  	Training Loss: 0.0007615152280777693
Test Loss:  0.0008352561853826046
Valid Loss:  0.0007288571796379983
Epoch:  296  	Training Loss: 0.00076050846837461
Test Loss:  0.0008352119475603104
Valid Loss:  0.0007278991397470236
Epoch:  297  	Training Loss: 0.0007595416973344982
Test Loss:  0.0008351646829396486
Valid Loss:  0.0007269788766279817
Epoch:  298  	Training Loss: 0.0007585841231048107
Test Loss:  0.0008350694552063942
Valid Loss:  0.0007260462734848261
Epoch:  299  	Training Loss: 0.0007576399948447943
Test Loss:  0.0008349706185981631
Valid Loss:  0.0007251586648635566
Epoch:  300  	Training Loss: 0.0007567147258669138
Test Loss:  0.0008348345290869474
Valid Loss:  0.0007242844440042973
Epoch:  301  	Training Loss: 0.0007557997014373541
Test Loss:  0.000834678066894412
Valid Loss:  0.0007234124932438135
Epoch:  302  	Training Loss: 0.0007548951543867588
Test Loss:  0.0008344636298716068
Valid Loss:  0.0007224722066894174
Epoch:  303  	Training Loss: 0.0007538617355749011
Test Loss:  0.0008342023938894272
Valid Loss:  0.0007216335507109761
Epoch:  304  	Training Loss: 0.0007529410067945719
Test Loss:  0.0008339445339515805
Valid Loss:  0.0007208320312201977
Epoch:  305  	Training Loss: 0.0007521357038058341
Test Loss:  0.0008336593164131045
Valid Loss:  0.0007200741674751043
Epoch:  306  	Training Loss: 0.0007514352910220623
Test Loss:  0.0008333777077496052
Valid Loss:  0.0007193597848527133
Epoch:  307  	Training Loss: 0.000750807230360806
Test Loss:  0.000833120197057724
Valid Loss:  0.0007187109440565109
Epoch:  308  	Training Loss: 0.0007502552471123636
Test Loss:  0.0008328429539687932
Valid Loss:  0.0007180984830483794
Epoch:  309  	Training Loss: 0.0007497300393879414
Test Loss:  0.0008325448725372553
Valid Loss:  0.0007175689097493887
Epoch:  310  	Training Loss: 0.0007492175791412592
Test Loss:  0.0008322242647409439
Valid Loss:  0.000717063550837338
Epoch:  311  	Training Loss: 0.0007487180409952998
Test Loss:  0.0008318953332491219
Valid Loss:  0.000716572452802211
Epoch:  312  	Training Loss: 0.0007482240325771272
Test Loss:  0.0008309591794386506
Valid Loss:  0.0007146528223529458
Epoch:  313  	Training Loss: 0.0007456133607774973
Test Loss:  0.0008302588830702007
Valid Loss:  0.0007134064217098057
Epoch:  314  	Training Loss: 0.0007440568879246712
Test Loss:  0.000829914934001863
Valid Loss:  0.0007125305710360408
Epoch:  315  	Training Loss: 0.0007429344113916159
Test Loss:  0.0008296181913465261
Valid Loss:  0.0007118699140846729
Epoch:  316  	Training Loss: 0.0007421256741508842
Test Loss:  0.0008294177241623402
Valid Loss:  0.0007112587336450815
Epoch:  317  	Training Loss: 0.0007414690917357802
Test Loss:  0.0008292359998449683
Valid Loss:  0.0007108234567567706
Epoch:  318  	Training Loss: 0.0007410063408315182
Test Loss:  0.0008290464174933732
Valid Loss:  0.0007104184478521347
Epoch:  319  	Training Loss: 0.0007406015647575259
Test Loss:  0.0008288641110993922
Valid Loss:  0.0007100386428646743
Epoch:  320  	Training Loss: 0.0007402575574815273
Test Loss:  0.0008286018273793161
Valid Loss:  0.0007097138441167772
Epoch:  321  	Training Loss: 0.0007399405585601926
Test Loss:  0.0008283554343506694
Valid Loss:  0.0007094020838849247
Epoch:  322  	Training Loss: 0.0007396516157314181
Test Loss:  0.0008277638116851449
Valid Loss:  0.0007088647689670324
Epoch:  323  	Training Loss: 0.0007391547551378608
Test Loss:  0.000827204086817801
Valid Loss:  0.0007083786185830832
Epoch:  324  	Training Loss: 0.0007387020741589367
Test Loss:  0.0008266636286862195
Valid Loss:  0.0007079329807311296
Epoch:  325  	Training Loss: 0.0007382981129921973
Test Loss:  0.0008261895272880793
Valid Loss:  0.0007075481116771698
Epoch:  326  	Training Loss: 0.0007379439193755388
Test Loss:  0.0008257132139988244
Valid Loss:  0.0007071885629557073
Epoch:  327  	Training Loss: 0.0007376042194664478
Test Loss:  0.0008252441766671836
Valid Loss:  0.0007068453705869615
Epoch:  328  	Training Loss: 0.0007372783729806542
Test Loss:  0.0008247819496318698
Valid Loss:  0.0007065135287120938
Epoch:  329  	Training Loss: 0.0007369605009444058
Test Loss:  0.000824317685328424
Valid Loss:  0.000706200604327023
Epoch:  330  	Training Loss: 0.0007366533391177654
Test Loss:  0.0008239225717261434
Valid Loss:  0.0007059155032038689
Epoch:  331  	Training Loss: 0.0007363840704783797
Test Loss:  0.0008235261775553226
Valid Loss:  0.0007056336035020649
Epoch:  332  	Training Loss: 0.0007361165480688214
Test Loss:  0.0008228096412494779
Valid Loss:  0.0007050842978060246
Epoch:  333  	Training Loss: 0.0007356450660154223
Test Loss:  0.0008221432799473405
Valid Loss:  0.0007046743994578719
Epoch:  334  	Training Loss: 0.0007352752145379782
Test Loss:  0.0008214668487198651
Valid Loss:  0.0007043593795970082
Epoch:  335  	Training Loss: 0.0007349555962719023
Test Loss:  0.0008208004292100668
Valid Loss:  0.0007041303906589746
Epoch:  336  	Training Loss: 0.0007346489001065493
Test Loss:  0.0008201763266697526
Valid Loss:  0.0007039245683699846
Epoch:  337  	Training Loss: 0.0007343589677475393
Test Loss:  0.0008196017006412148
Valid Loss:  0.0007037314353510737
Epoch:  338  	Training Loss: 0.0007341073360294104
Test Loss:  0.000819084350951016
Valid Loss:  0.0007035641465336084
Epoch:  339  	Training Loss: 0.0007338915602304041
Test Loss:  0.0008186077466234565
Valid Loss:  0.0007034052978269756
Epoch:  340  	Training Loss: 0.0007336854469031096
Test Loss:  0.0008181596640497446
Valid Loss:  0.0007032549474388361
Epoch:  341  	Training Loss: 0.0007334846304729581
Test Loss:  0.0008177427807822824
Valid Loss:  0.0007031132699921727
Epoch:  342  	Training Loss: 0.0007332951063290238
Test Loss:  0.0008169306674972177
Valid Loss:  0.0007020143675617874
Epoch:  343  	Training Loss: 0.0007319800788536668
Test Loss:  0.0008162108715623617
Valid Loss:  0.0007009738474152982
Epoch:  344  	Training Loss: 0.0007308401400223374
Test Loss:  0.0008156246040016413
Valid Loss:  0.0006999924080446362
Epoch:  345  	Training Loss: 0.0007297832053154707
Test Loss:  0.0008151096990332007
Valid Loss:   69%|██████▉   | 345/500 [03:59<01:35,  1.62it/s] 69%|██████▉   | 347/500 [03:59<01:09,  2.22it/s] 70%|██████▉   | 349/500 [04:00<00:50,  2.98it/s] 70%|███████   | 351/500 [04:06<02:58,  1.20s/it] 71%|███████   | 353/500 [04:06<02:06,  1.16it/s] 71%|███████   | 355/500 [04:06<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:06<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:07<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:13<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:13<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:13<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:13<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:20<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:20<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:20<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:20<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:20<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:27<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:27<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:27<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:27<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:27<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:33<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:33<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:34<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:34<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:34<00:33,  3.01it/s] 80%|████████  | 401/500 [04:40<01:56,  1.18s/it] 81%|████████  | 403/500 [04:40<01:22,  1.18it/s] 81%|████████  | 405/500 [04:40<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:41<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:41<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:47<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:47<01:13,  1.19it/s]0.0006990362890064716
Epoch:  346  	Training Loss: 0.0007287702173925936
Test Loss:  0.0008146163308992982
Valid Loss:  0.0006981240003369749
Epoch:  347  	Training Loss: 0.0007278062985278666
Test Loss:  0.0008140986901707947
Valid Loss:  0.0006972524570301175
Epoch:  348  	Training Loss: 0.000726888538338244
Test Loss:  0.0008135696407407522
Valid Loss:  0.0006964163621887565
Epoch:  349  	Training Loss: 0.0007259919075295329
Test Loss:  0.0008130384376272559
Valid Loss:  0.0006955827120691538
Epoch:  350  	Training Loss: 0.0007251128554344177
Test Loss:  0.0008124832529574633
Valid Loss:  0.0006947526708245277
Epoch:  351  	Training Loss: 0.0007242434658110142
Test Loss:  0.0008118863916024566
Valid Loss:  0.0006939491140656173
Epoch:  352  	Training Loss: 0.0007233895594254136
Test Loss:  0.0008108871406875551
Valid Loss:  0.0006927680224180222
Epoch:  353  	Training Loss: 0.000721988151781261
Test Loss:  0.0008103255531750619
Valid Loss:  0.0006920426385477185
Epoch:  354  	Training Loss: 0.0007210149196907878
Test Loss:  0.000810140511021018
Valid Loss:  0.0006916976417414844
Epoch:  355  	Training Loss: 0.0007204391877166927
Test Loss:  0.0008101042476482689
Valid Loss:  0.0006914755795150995
Epoch:  356  	Training Loss: 0.0007200783584266901
Test Loss:  0.0008101575076580048
Valid Loss:  0.0006913413526490331
Epoch:  357  	Training Loss: 0.0007198605453595519
Test Loss:  0.0008102316060103476
Valid Loss:  0.0006912302924320102
Epoch:  358  	Training Loss: 0.000719659379683435
Test Loss:  0.0008103196159936488
Valid Loss:  0.0006911320379003882
Epoch:  359  	Training Loss: 0.0007194716017693281
Test Loss:  0.0008104182197712362
Valid Loss:  0.0006910517113283277
Epoch:  360  	Training Loss: 0.0007192977354861796
Test Loss:  0.0008105211891233921
Valid Loss:  0.0006910240626893938
Epoch:  361  	Training Loss: 0.0007191437180154026
Test Loss:  0.0008105864399112761
Valid Loss:  0.0006909637595526874
Epoch:  362  	Training Loss: 0.0007190133328549564
Test Loss:  0.0008080026600509882
Valid Loss:  0.000688663509208709
Epoch:  363  	Training Loss: 0.0007168127922341228
Test Loss:  0.0008057220256887376
Valid Loss:  0.0006866960320621729
Epoch:  364  	Training Loss: 0.0007149600423872471
Test Loss:  0.0008037792867980897
Valid Loss:  0.0006850020727142692
Epoch:  365  	Training Loss: 0.0007133103208616376
Test Loss:  0.0008019504602998495
Valid Loss:  0.0006834545056335628
Epoch:  366  	Training Loss: 0.0007117316126823425
Test Loss:  0.0008003099355846643
Valid Loss:  0.0006819789996370673
Epoch:  367  	Training Loss: 0.0007102340459823608
Test Loss:  0.0007988896104507148
Valid Loss:  0.0006805291632190347
Epoch:  368  	Training Loss: 0.0007087837439030409
Test Loss:  0.0007975733024068177
Valid Loss:  0.000679118325933814
Epoch:  369  	Training Loss: 0.0007074023596942425
Test Loss:  0.0007963287062011659
Valid Loss:  0.0006777668604627252
Epoch:  370  	Training Loss: 0.0007060751086100936
Test Loss:  0.000795169675257057
Valid Loss:  0.0006764407153241336
Epoch:  371  	Training Loss: 0.0007047805702313781
Test Loss:  0.0007941623334772885
Valid Loss:  0.0006751535693183541
Epoch:  372  	Training Loss: 0.0007035350427031517
Test Loss:  0.0007936506299301982
Valid Loss:  0.0006742129917256534
Epoch:  373  	Training Loss: 0.000702549354173243
Test Loss:  0.0007932235021144152
Valid Loss:  0.000673523114528507
Epoch:  374  	Training Loss: 0.0007018097676336765
Test Loss:  0.0007928627310320735
Valid Loss:  0.0006730213644914329
Epoch:  375  	Training Loss: 0.0007011776324361563
Test Loss:  0.0007925343816168606
Valid Loss:  0.0006725615239702165
Epoch:  376  	Training Loss: 0.0007006217492744327
Test Loss:  0.0007922517834231257
Valid Loss:  0.0006721332902088761
Epoch:  377  	Training Loss: 0.0007001119083724916
Test Loss:  0.0007920089410617948
Valid Loss:  0.0006717267679050565
Epoch:  378  	Training Loss: 0.000699673721101135
Test Loss:  0.0007918000919744372
Valid Loss:  0.000671355111990124
Epoch:  379  	Training Loss: 0.000699296360835433
Test Loss:  0.0007915748283267021
Valid Loss:  0.0006709956796839833
Epoch:  380  	Training Loss: 0.0006989323301240802
Test Loss:  0.0007913551526144147
Valid Loss:  0.0006706477724947035
Epoch:  381  	Training Loss: 0.0006985863437876105
Test Loss:  0.0007911298889666796
Valid Loss:  0.0006703066173940897
Epoch:  382  	Training Loss: 0.0006982486229389906
Test Loss:  0.000789832673035562
Valid Loss:  0.00066783232614398
Epoch:  383  	Training Loss: 0.0006956577417440712
Test Loss:  0.0007887700339779258
Valid Loss:  0.0006657706690020859
Epoch:  384  	Training Loss: 0.0006937840953469276
Test Loss:  0.000787767581641674
Valid Loss:  0.0006641292711719871
Epoch:  385  	Training Loss: 0.000692297238856554
Test Loss:  0.0007867631502449512
Valid Loss:  0.0006626924150623381
Epoch:  386  	Training Loss: 0.0006909834919497371
Test Loss:  0.000785776530392468
Valid Loss:  0.000661462836433202
Epoch:  387  	Training Loss: 0.0006898362189531326
Test Loss:  0.0007847838569432497
Valid Loss:  0.0006603051442652941
Epoch:  388  	Training Loss: 0.0006887526251375675
Test Loss:  0.0007838396122679114
Valid Loss:  0.0006592106656171381
Epoch:  389  	Training Loss: 0.0006877328269183636
Test Loss:  0.0007829202222637832
Valid Loss:  0.0006581349298357964
Epoch:  390  	Training Loss: 0.0006867511547170579
Test Loss:  0.0007820314494892955
Valid Loss:  0.0006571527337655425
Epoch:  391  	Training Loss: 0.0006858553388155997
Test Loss:  0.0007811685791239142
Valid Loss:  0.0006562275229953229
Epoch:  392  	Training Loss: 0.0006850293721072376
Test Loss:  0.0007802104810252786
Valid Loss:  0.0006555839208886027
Epoch:  393  	Training Loss: 0.0006843082373961806
Test Loss:  0.0007794552366249263
Valid Loss:  0.0006550730904564261
Epoch:  394  	Training Loss: 0.0006837521214038134
Test Loss:  0.0007788602961227298
Valid Loss:  0.0006546793156303465
Epoch:  395  	Training Loss: 0.0006833062507212162
Test Loss:  0.000778353656642139
Valid Loss:  0.0006543216295540333
Epoch:  396  	Training Loss: 0.0006828850018791854
Test Loss:  0.0007779326988384128
Valid Loss:  0.000654002302326262
Epoch:  397  	Training Loss: 0.0006824937299825251
Test Loss:  0.0007775877602398396
Valid Loss:  0.0006537088192999363
Epoch:  398  	Training Loss: 0.000682158162817359
Test Loss:  0.0007772795506753027
Valid Loss:  0.0006534110871143639
Epoch:  399  	Training Loss: 0.0006818402325734496
Test Loss:  0.0007769935764372349
Valid Loss:  0.0006531279650516808
Epoch:  400  	Training Loss: 0.0006815496017225087
Test Loss:  0.0007767161587253213
Valid Loss:  0.0006528472295030951
Epoch:  401  	Training Loss: 0.0006812706124037504
Test Loss:  0.0007764792535454035
Valid Loss:  0.0006525905337184668
Epoch:  402  	Training Loss: 0.0006810311460867524
Test Loss:  0.000775446358602494
Valid Loss:  0.0006508772494271398
Epoch:  403  	Training Loss: 0.0006789877079427242
Test Loss:  0.0007744321483187377
Valid Loss:  0.0006492254324257374
Epoch:  404  	Training Loss: 0.0006770654581487179
Test Loss:  0.0007735681720077991
Valid Loss:  0.0006476094713434577
Epoch:  405  	Training Loss: 0.0006752515328116715
Test Loss:  0.0007727486663497984
Valid Loss:  0.0006461329758167267
Epoch:  406  	Training Loss: 0.000673648901283741
Test Loss:  0.000771936378441751
Valid Loss:  0.0006447118939831853
Epoch:  407  	Training Loss: 0.000672147492878139
Test Loss:  0.0007711369544267654
Valid Loss:  0.0006433315575122833
Epoch:  408  	Training Loss: 0.000670717447064817
Test Loss:  0.0007703555165790021
Valid Loss:  0.0006420827703550458
Epoch:  409  	Training Loss: 0.0006693305913358927
Test Loss:  0.0007695772219449282
Valid Loss:  0.0006409002817235887
Epoch:  410  	Training Loss: 0.0006679861107841134
Test Loss:  0.0007687815232202411
Valid Loss:  0.0006397179677151144
Epoch:  411  	Training Loss: 0.0006666852859780192
Test Loss:  0.0007679795380681753
Valid Loss:  0.0006385643500834703
Epoch:  412  	Training Loss: 0.0006654562894254923
Test Loss:  0.0007676843088120222
Valid Loss:  0.0006370513001456857
Epoch:  413  	Training Loss: 0.000663936254568398
Test Loss:  0.0007670872146263719
Valid Loss:  0.0006359306862577796
 83%|████████▎ | 415/500 [04:47<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:47<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:48<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:54<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:54<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:54<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:54<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:54<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:01<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:01<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:01<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:01<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:01<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:07<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:08<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:08<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:08<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:14<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:15<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:15<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:15<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:21<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:22<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:22<00:10,  2.91it/s] 94%|█████████▍| 471/500 [05:28<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:28<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:29<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:35<00:22,  1.18s/it]Epoch:  414  	Training Loss: 0.0006628712872043252
Test Loss:  0.0007663475698791444
Valid Loss:  0.0006350070470944047
Epoch:  415  	Training Loss: 0.0006619652267545462
Test Loss:  0.000765549368225038
Valid Loss:  0.0006342088454402983
Epoch:  416  	Training Loss: 0.0006611230783164501
Test Loss:  0.000764645985327661
Valid Loss:  0.0006334945792332292
Epoch:  417  	Training Loss: 0.0006603645160794258
Test Loss:  0.0007636959198862314
Valid Loss:  0.0006327938172034919
Epoch:  418  	Training Loss: 0.0006596501916646957
Test Loss:  0.0007627576123923063
Valid Loss:  0.0006321107503026724
Epoch:  419  	Training Loss: 0.0006589670083485544
Test Loss:  0.000761845032684505
Valid Loss:  0.0006314428756013513
Epoch:  420  	Training Loss: 0.0006583287613466382
Test Loss:  0.0007609980530105531
Valid Loss:  0.0006308123702183366
Epoch:  421  	Training Loss: 0.0006577393505722284
Test Loss:  0.0007601401302963495
Valid Loss:  0.000630188500508666
Epoch:  422  	Training Loss: 0.0006571596604771912
Test Loss:  0.0007595383794978261
Valid Loss:  0.0006296024657785892
Epoch:  423  	Training Loss: 0.0006565548246726394
Test Loss:  0.0007589713204652071
Valid Loss:  0.0006290272576734424
Epoch:  424  	Training Loss: 0.0006559942848980427
Test Loss:  0.0007584223640151322
Valid Loss:  0.0006284991977736354
Epoch:  425  	Training Loss: 0.000655460637062788
Test Loss:  0.0007578959921374917
Valid Loss:  0.0006279811495915055
Epoch:  426  	Training Loss: 0.0006549475947394967
Test Loss:  0.000757380563300103
Valid Loss:  0.0006274796323850751
Epoch:  427  	Training Loss: 0.0006544665084220469
Test Loss:  0.0007568802684545517
Valid Loss:  0.0006269968580454588
Epoch:  428  	Training Loss: 0.0006540064932778478
Test Loss:  0.0007564020925201476
Valid Loss:  0.0006265370175242424
Epoch:  429  	Training Loss: 0.000653563067317009
Test Loss:  0.0007559333462268114
Valid Loss:  0.0006260813679546118
Epoch:  430  	Training Loss: 0.0006531257531605661
Test Loss:  0.0007554783951491117
Valid Loss:  0.0006256451597437263
Epoch:  431  	Training Loss: 0.0006527081714011729
Test Loss:  0.0007550329901278019
Valid Loss:  0.0006252153543755412
Epoch:  432  	Training Loss: 0.0006522958865389228
Test Loss:  0.0007544811815023422
Valid Loss:  0.0006241290830075741
Epoch:  433  	Training Loss: 0.0006509051891043782
Test Loss:  0.0007540977094322443
Valid Loss:  0.0006230414728634059
Epoch:  434  	Training Loss: 0.0006496516871266067
Test Loss:  0.0007537893834523857
Valid Loss:  0.0006219695787876844
Epoch:  435  	Training Loss: 0.0006485001649707556
Test Loss:  0.0007535270997323096
Valid Loss:  0.0006209340645000339
Epoch:  436  	Training Loss: 0.0006474421825259924
Test Loss:  0.0007532460149377584
Valid Loss:  0.0006199272465892136
Epoch:  437  	Training Loss: 0.0006464101606979966
Test Loss:  0.0007529669674113393
Valid Loss:  0.0006189409759826958
Epoch:  438  	Training Loss: 0.000645438558422029
Test Loss:  0.0007526053814217448
Valid Loss:  0.0006180288037285209
Epoch:  439  	Training Loss: 0.0006445445469580591
Test Loss:  0.0007521974039264023
Valid Loss:  0.000617154233623296
Epoch:  440  	Training Loss: 0.0006436750991269946
Test Loss:  0.0007517528720200062
Valid Loss:  0.0006163102807477117
Epoch:  441  	Training Loss: 0.0006428370252251625
Test Loss:  0.0007512699230574071
Valid Loss:  0.0006154939765110612
Epoch:  442  	Training Loss: 0.0006420298595912755
Test Loss:  0.0007511739386245608
Valid Loss:  0.0006150008412078023
Epoch:  443  	Training Loss: 0.0006415654206648469
Test Loss:  0.0007510663708671927
Valid Loss:  0.0006145698134787381
Epoch:  444  	Training Loss: 0.0006411205977201462
Test Loss:  0.0007509351125918329
Valid Loss:  0.0006141627673059702
Epoch:  445  	Training Loss: 0.0006407054024748504
Test Loss:  0.0007508022245019674
Valid Loss:  0.000613772077485919
Epoch:  446  	Training Loss: 0.0006403018487617373
Test Loss:  0.0007506556576117873
Valid Loss:  0.0006133947754278779
Epoch:  447  	Training Loss: 0.0006399179110303521
Test Loss:  0.000750511244405061
Valid Loss:  0.0006130646215751767
Epoch:  448  	Training Loss: 0.0006395494565367699
Test Loss:  0.0007503691595047712
Valid Loss:  0.0006127672968432307
Epoch:  449  	Training Loss: 0.0006392125505954027
Test Loss:  0.0007501880172640085
Valid Loss:  0.0006124770152382553
Epoch:  450  	Training Loss: 0.0006389098707586527
Test Loss:  0.0007499989005737007
Valid Loss:  0.000612191273830831
Epoch:  451  	Training Loss: 0.0006386099848896265
Test Loss:  0.0007497993065044284
Valid Loss:  0.000611937022767961
Epoch:  452  	Training Loss: 0.000638314988464117
Test Loss:  0.0007488918490707874
Valid Loss:  0.00061112578259781
Epoch:  453  	Training Loss: 0.0006370905321091413
Test Loss:  0.0007481465581804514
Valid Loss:  0.0006104466738179326
Epoch:  454  	Training Loss: 0.0006362880230881274
Test Loss:  0.0007474966696463525
Valid Loss:  0.0006098461453802884
Epoch:  455  	Training Loss: 0.0006357138627208769
Test Loss:  0.0007468556286767125
Valid Loss:  0.0006093358970247209
Epoch:  456  	Training Loss: 0.0006352212512865663
Test Loss:  0.0007462307694368064
Valid Loss:  0.0006088843801990151
Epoch:  457  	Training Loss: 0.0006347735179588199
Test Loss:  0.0007455662125721574
Valid Loss:  0.000608455971814692
Epoch:  458  	Training Loss: 0.000634340918622911
Test Loss:  0.0007449022959917784
Valid Loss:  0.0006080583552829921
Epoch:  459  	Training Loss: 0.0006339212413877249
Test Loss:  0.0007442058995366096
Valid Loss:  0.0006076857098378241
Epoch:  460  	Training Loss: 0.0006335453945212066
Test Loss:  0.0007435288280248642
Valid Loss:  0.0006073510739952326
Epoch:  461  	Training Loss: 0.0006332031916826963
Test Loss:  0.0007428043754771352
Valid Loss:  0.0006070261588320136
Epoch:  462  	Training Loss: 0.0006328635499812663
Test Loss:  0.0007419431349262595
Valid Loss:  0.0006042468594387174
Epoch:  463  	Training Loss: 0.0006298574735410511
Test Loss:  0.0007408246165141463
Valid Loss:  0.0006026893388479948
Epoch:  464  	Training Loss: 0.0006278434302657843
Test Loss:  0.0007395699503831565
Valid Loss:  0.0006013241363689303
Epoch:  465  	Training Loss: 0.0006262093083932996
Test Loss:  0.0007382257608696818
Valid Loss:  0.0006001502624712884
Epoch:  466  	Training Loss: 0.0006249329308047891
Test Loss:  0.0007369627128355205
Valid Loss:  0.000599061488173902
Epoch:  467  	Training Loss: 0.0006238078931346536
Test Loss:  0.0007358525763265789
Valid Loss:  0.000598051177803427
Epoch:  468  	Training Loss: 0.000622790539637208
Test Loss:  0.0007347009959630668
Valid Loss:  0.0005972102517262101
Epoch:  469  	Training Loss: 0.0006219111382961273
Test Loss:  0.0007335915579460561
Valid Loss:  0.0005964138545095921
Epoch:  470  	Training Loss: 0.0006210714345797896
Test Loss:  0.0007325354381464422
Valid Loss:  0.0005956611130386591
Epoch:  471  	Training Loss: 0.0006202835938893259
Test Loss:  0.0007315528346225619
Valid Loss:  0.0005949809565208852
Epoch:  472  	Training Loss: 0.0006195493042469025
Test Loss:  0.0007311946246773005
Valid Loss:  0.0005948193138465285
Epoch:  473  	Training Loss: 0.0006193615263327956
Test Loss:  0.0007308486965484917
Valid Loss:  0.0005946684977971017
Epoch:  474  	Training Loss: 0.0006191761349327862
Test Loss:  0.0007305167382583022
Valid Loss:  0.0005945170414634049
Epoch:  475  	Training Loss: 0.0006189922569319606
Test Loss:  0.000730207422748208
Valid Loss:  0.000594374374486506
Epoch:  476  	Training Loss: 0.0006188092520460486
Test Loss:  0.0007298878626897931
Valid Loss:  0.0005942292045801878
Epoch:  477  	Training Loss: 0.0006186403334140778
Test Loss:  0.0007295781979337335
Valid Loss:  0.000594087818171829
Epoch:  478  	Training Loss: 0.00061847735196352
Test Loss:  0.000729271792806685
Valid Loss:  0.0005939505062997341
Epoch:  479  	Training Loss: 0.0006183167570270598
Test Loss:  0.0007289658533409238
Valid Loss:  0.00059381069149822
Epoch:  480  	Training Loss: 0.0006181694334372878
Test Loss:  0.0007286595646291971
Valid Loss:  0.000593676115386188
Epoch:  481  	Training Loss: 0.0006180247291922569
Test Loss:  0.000728362356312573
Valid Loss:  0.0005935407243669033
Epoch:  482  	Training Loss: 0.0006178839248605072
Test Loss:   97%|█████████▋| 483/500 [05:35<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:35<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:35<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:36<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:42<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:42<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:42<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:42<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:42<00:00,  2.97it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
0.0007266351021826267
Valid Loss:  0.0005926587618887424
Epoch:  483  	Training Loss: 0.0006169086555019021
Test Loss:  0.0007251831702888012
Valid Loss:  0.0005918611423112452
Epoch:  484  	Training Loss: 0.0006160554476082325
Test Loss:  0.0007237890968099236
Valid Loss:  0.0005911510670557618
Epoch:  485  	Training Loss: 0.0006152947898954153
Test Loss:  0.0007224749424494803
Valid Loss:  0.0005904805148020387
Epoch:  486  	Training Loss: 0.0006145758670754731
Test Loss:  0.0007212369237095118
Valid Loss:  0.0005898472154513001
Epoch:  487  	Training Loss: 0.0006138950120657682
Test Loss:  0.0007200217805802822
Valid Loss:  0.0005892788176424801
Epoch:  488  	Training Loss: 0.0006132403505034745
Test Loss:  0.0007189504685811698
Valid Loss:  0.0005887690931558609
Epoch:  489  	Training Loss: 0.0006126813823357224
Test Loss:  0.0007179122185334563
Valid Loss:  0.0005882751429453492
Epoch:  490  	Training Loss: 0.0006121658952906728
Test Loss:  0.0007168923038989305
Valid Loss:  0.0005877935909666121
Epoch:  491  	Training Loss: 0.0006116617005318403
Test Loss:  0.0007159114466048777
Valid Loss:  0.0005873264744877815
Epoch:  492  	Training Loss: 0.0006111911498010159
Test Loss:  0.0007155463099479675
Valid Loss:  0.0005865518469363451
Epoch:  493  	Training Loss: 0.0006104657077230513
Test Loss:  0.0007151575409807265
Valid Loss:  0.0005858172080479562
Epoch:  494  	Training Loss: 0.0006097416044212878
Test Loss:  0.0007147522992454469
Valid Loss:  0.000585146714001894
Epoch:  495  	Training Loss: 0.0006090372335165739
Test Loss:  0.000714334542863071
Valid Loss:  0.000584492227062583
Epoch:  496  	Training Loss: 0.0006083521293476224
Test Loss:  0.0007139098597690463
Valid Loss:  0.0005838419892825186
Epoch:  497  	Training Loss: 0.0006076737772673368
Test Loss:  0.0007134782499633729
Valid Loss:  0.00058322015684098
Epoch:  498  	Training Loss: 0.0006069957162253559
Test Loss:  0.000713038956746459
Valid Loss:  0.0005826182314194739
Epoch:  499  	Training Loss: 0.0006063314503990114
Test Loss:  0.000712560722604394
Valid Loss:  0.0005820202641189098
Epoch:  500  	Training Loss: 0.0006057110731489956
Test Loss:  0.0007120685186237097
Valid Loss:  0.0005814425530843437
seed is  15
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.28it/s]  1%|          | 4/500 [00:00<00:29, 16.56it/s]  1%|          | 6/500 [00:00<00:30, 16.42it/s]  2%|▏         | 8/500 [00:00<00:30, 16.27it/s]  2%|▏         | 10/500 [00:00<00:29, 16.43it/s]  2%|▏         | 12/500 [00:00<00:29, 16.53it/s]  3%|▎         | 14/500 [00:00<00:29, 16.62it/s]  3%|▎         | 16/500 [00:00<00:29, 16.63it/s]  4%|▎         | 18/500 [00:01<00:28, 16.64it/s]  4%|▍         | 20/500 [00:01<00:29, 16.29it/s]  4%|▍         | 22/500 [00:01<00:29, 16.47it/s]  5%|▍         | 24/500 [00:01<00:28, 16.61it/s]  5%|▌         | 26/500 [00:01<00:28, 16.66it/s]  6%|▌         | 28/500 [00:01<00:28, 16.67it/s]  6%|▌         | 30/500 [00:01<00:28, 16.61it/s]  6%|▋         | 32/500 [00:01<00:28, 16.49it/s]  7%|▋         | 34/500 [00:02<00:28, 16.35it/s]  7%|▋         | 36/500 [00:02<00:28, 16.44it/s]  8%|▊         | 38/500 [00:02<00:28, 16.39it/s]  8%|▊         | 40/500 [00:02<00:27, 16.50it/s]  8%|▊         | 42/500 [00:02<00:28, 16.35it/s]  9%|▉         | 44/500 [00:02<00:30, 14.76it/s]  9%|▉         | 46/500 [00:02<00:31, 14.27it/s] 10%|▉         | 48/500 [00:03<00:33, 13.61it/s] 10%|█         | 50/500 [00:03<00:34, 13.20it/s] 10%|█         | 52/500 [00:03<00:31, 14.14it/s] 11%|█         | 54/500 [00:03<00:30, 14.80it/s] 11%|█         | 56/500 [00:03<00:28, 15.34it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.73it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.94it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.16it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.16it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.84it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.10it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.35it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.53it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.60it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.50it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.04it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.21it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.31it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.46it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.57it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.50it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.53it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.57it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.33it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.28it/s] 20%|█▉        | 98/500 [00:06<00:25, 16.07it/s] 20%|██        | 100/500 [00:06<00:24, 16.13it/s] 20%|██        | 102/500 [00:06<00:24, 16.33it/s] 21%|██        | 104/500 [00:06<00:24, 16.44it/s] 21%|██        | 106/500 [00:06<00:23, 16.55it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.56it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.54it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.59it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.26it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.35it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.48it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.50it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.57it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.58it/s]Epoch:  1  	Training Loss: 0.10619980096817017
Test Loss:  1855.269287109375
Valid Loss:  1851.546875
Epoch:  2  	Training Loss: 1852.6591796875
Test Loss:  61754306461696.0
Valid Loss:  62042119602176.0
Epoch:  3  	Training Loss: 61983072190464.0
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.61it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.65it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.75it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.71it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.50it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.51it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.52it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.45it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.46it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.57it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.65it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.70it/s] 30%|███       | 150/500 [00:09<00:20, 16.73it/s] 30%|███       | 152/500 [00:09<00:20, 16.75it/s] 31%|███       | 154/500 [00:09<00:20, 16.76it/s] 31%|███       | 156/500 [00:09<00:20, 16.77it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.75it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.60it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.61it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.60it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.24it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.32it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.20it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.36it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.43it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.36it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.32it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.44it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.51it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.07it/s] 37%|███▋      | 186/500 [00:11<00:22, 13.99it/s] 38%|███▊      | 188/500 [00:11<00:22, 13.80it/s] 38%|███▊      | 190/500 [00:11<00:21, 14.46it/s] 38%|███▊      | 192/500 [00:11<00:20, 14.98it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.44it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.79it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.06it/s] 40%|████      | 200/500 [00:12<00:18, 16.29it/s] 40%|████      | 202/500 [00:12<00:18, 16.42it/s] 41%|████      | 204/500 [00:12<00:17, 16.48it/s] 41%|████      | 206/500 [00:12<00:17, 16.54it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.40it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.34it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.42it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.51it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.34it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.38it/s] 44%|████▍     | 220/500 [00:13<00:17, 15.99it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.20it/s] 45%|████▍     | 224/500 [00:13<00:18, 15.30it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.51it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.73it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.02it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.27it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.43it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.54it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.60it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.67it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.60it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.66it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.65it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.65it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.66it/s] 50%|█████     | 252/500 [00:15<00:14, 16.71it/s] 51%|█████     | 254/500 [00:15<00:14, 16.75it/s] 51%|█████     | 256/500 [00:15<00:14, 16.70it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.66it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.65it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.64it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.70it/s] 53%|█████▎    | 266/500 [00:16<00:13, 16.75it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.12it/s] 54%|█████▍    | 270/500 [00:16<00:14, 15.84it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.01it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.24it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.39it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.71it/s] 56%|█████▌    | 280/500 [00:17<00:15, 14.33it/s] 56%|█████▋    | 282/500 [00:17<00:15, 13.65it/s] 57%|█████▋    | 284/500 [00:17<00:15, 13.81it/s] 57%|█████▋    | 286/500 [00:17<00:14, 14.45it/s] 58%|█████▊    | 288/500 [00:17<00:14, 15.08it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.58it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.94it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.18it/s] 59%|█████▉    | 296/500 [00:18<00:13, 15.54it/s] 60%|█████▉    | 298/500 [00:18<00:14, 14.26it/s] 60%|██████    | 300/500 [00:18<00:14, 13.76it/s] 60%|██████    | 302/500 [00:18<00:13, 14.50it/s] 61%|██████    | 304/500 [00:18<00:12, 15.09it/s] 61%|██████    | 306/500 [00:19<00:12, 15.54it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.91it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.14it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.32it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.32it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.27it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.27it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.26it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.31it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.43it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.52it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.57it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.39it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.52it/s] 67%|██████▋   | 334/500 [00:20<00:09, 16.61it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.68it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.59it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.68it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.53it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.56it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.58it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.58it/s] 70%|███████   | 350/500 [00:21<00:09, 16.56it/s] 70%|███████   | 352/500 [00:21<00:08, 16.48it/s] 71%|███████   | 354/500 [00:21<00:08, 16.50it/s] 71%|███████   | 356/500 [00:22<00:08, 16.33it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.17it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.20it/s] 72%|███████▏  | 362/500 [00:22<00:09, 15.33it/s] 73%|███████▎  | 364/500 [00:22<00:09, 15.00it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.48it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.65it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.81it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.01it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.06it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.17it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.26it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.38it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.53it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.50it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.53it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.57it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.39it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.45it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.23it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.34it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.44it/s] 80%|████████  | 400/500 [00:24<00:06, 16.60it/s] 80%|████████  | 402/500 [00:24<00:05, 16.70it/s] 81%|████████  | 404/500 [00:25<00:05, 16.70it/s] 81%|████████  | 406/500 [00:25<00:05, 16.75it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.74it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.75it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.62it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.42it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.56it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.63it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.71it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.76it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.67it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.71it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.62it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.39it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.52it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.39it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.44it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.50it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.56it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.39it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.36it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.50it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.57it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.65it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.52it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.55it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.61it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.53it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.59it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.64it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.71it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.66it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.65it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.68it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.58it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.61it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.61it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.59it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.70it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.59it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.69it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.75it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.70it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.56it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.56it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.64it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.71it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.73it/s]100%|██████████| 500/500 [00:30<00:00, 16.52it/s]100%|██████████| 500/500 [00:30<00:00, 16.21it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  15
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:09,  6.15s/it]  1%|          | 3/500 [00:06<13:38,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.94it/s]  2%|▏         | 11/500 [00:12<10:46,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  3.00it/s]  6%|▌         | 31/500 [00:26<09:13,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:26<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.24it/s]  8%|▊         | 39/500 [00:27<02:33,  3.01it/s]  8%|▊         | 41/500 [00:33<08:57,  1.17s/it]  9%|▊         | 43/500 [00:33<06:24,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:54,  1.19s/it] 11%|█         | 53/500 [00:40<06:21,  1.17it/s] 11%|█         | 55/500 [00:40<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:54<08:28,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s]Epoch:  1  	Training Loss: 0.10619980841875076
Test Loss:  338.01385498046875
Valid Loss:  335.11639404296875
Epoch:  2  	Training Loss: 336.33099365234375
Test Loss:  3.667888879776001
Valid Loss:  3.528315544128418
Epoch:  3  	Training Loss: 3.5819878578186035
Test Loss:  3.250056505203247
Valid Loss:  3.124650478363037
Epoch:  4  	Training Loss: 3.1730904579162598
Test Loss:  2.880037307739258
Valid Loss:  2.7673110961914062
Epoch:  5  	Training Loss: 2.8110580444335938
Test Loss:  2.5523321628570557
Valid Loss:  2.4509596824645996
Epoch:  6  	Training Loss: 2.490494728088379
Test Loss:  2.262079954147339
Valid Loss:  2.1708781719207764
Epoch:  7  	Training Loss: 2.2066307067871094
Test Loss:  2.0057246685028076
Valid Loss:  1.923311710357666
Epoch:  8  	Training Loss: 1.9557116031646729
Test Loss:  1.7797987461090088
Valid Loss:  1.7052016258239746
Epoch:  9  	Training Loss: 1.7346469163894653
Test Loss:  1.57979416847229
Valid Loss:  1.512249231338501
Epoch:  10  	Training Loss: 1.5390186309814453
Test Loss:  1.4025508165359497
Valid Loss:  1.3413453102111816
Epoch:  11  	Training Loss: 1.3657050132751465
Test Loss:  1.245375156402588
Valid Loss:  1.1898876428604126
Epoch:  12  	Training Loss: 1.2120726108551025
Test Loss:  1.1086361408233643
Valid Loss:  1.0586018562316895
Epoch:  13  	Training Loss: 1.0787416696548462
Test Loss:  0.9872502684593201
Valid Loss:  0.942092776298523
Epoch:  14  	Training Loss: 0.9604047536849976
Test Loss:  0.87965989112854
Valid Loss:  0.8389171361923218
Epoch:  15  	Training Loss: 0.8555826544761658
Test Loss:  0.783922553062439
Valid Loss:  0.747165322303772
Epoch:  16  	Training Loss: 0.7623294591903687
Test Loss:  0.6986935138702393
Valid Loss:  0.6655242443084717
Epoch:  17  	Training Loss: 0.6793298721313477
Test Loss:  0.6227967739105225
Valid Loss:  0.5928524732589722
Epoch:  18  	Training Loss: 0.605431854724884
Test Loss:  0.5552013516426086
Valid Loss:  0.528160810470581
Epoch:  19  	Training Loss: 0.5396329164505005
Test Loss:  0.49523550271987915
Valid Loss:  0.47068989276885986
Epoch:  20  	Training Loss: 0.4811604619026184
Test Loss:  0.46691006422042847
Valid Loss:  0.43953120708465576
Epoch:  21  	Training Loss: 0.45060640573501587
Test Loss:  0.45952773094177246
Valid Loss:  0.43171727657318115
Epoch:  22  	Training Loss: 0.4434107542037964
Test Loss:  0.455054372549057
Valid Loss:  0.4271247684955597
Epoch:  23  	Training Loss: 0.4388780891895294
Test Loss:  0.4516151249408722
Valid Loss:  0.4237891435623169
Epoch:  24  	Training Loss: 0.4354212284088135
Test Loss:  0.4485158324241638
Valid Loss:  0.42074263095855713
Epoch:  25  	Training Loss: 0.4322770833969116
Test Loss:  0.4455427825450897
Valid Loss:  0.4177452623844147
Epoch:  26  	Training Loss: 0.4292529225349426
Test Loss:  0.4426766633987427
Valid Loss:  0.414892315864563
Epoch:  27  	Training Loss: 0.4263872802257538
Test Loss:  0.4398450553417206
Valid Loss:  0.4121399521827698
Epoch:  28  	Training Loss: 0.42359697818756104
Test Loss:  0.43704843521118164
Valid Loss:  0.40943294763565063
Epoch:  29  	Training Loss: 0.42084312438964844
Test Loss:  0.4342663288116455
Valid Loss:  0.4067533612251282
Epoch:  30  	Training Loss: 0.4181175231933594
Test Loss:  0.43149858713150024
Valid Loss:  0.40409398078918457
Epoch:  31  	Training Loss: 0.41541457176208496
Test Loss:  0.4287450313568115
Valid Loss:  0.40145260095596313
Epoch:  32  	Training Loss: 0.41272851824760437
Test Loss:  0.42607372999191284
Valid Loss:  0.3988855481147766
Epoch:  33  	Training Loss: 0.41012442111968994
Test Loss:  0.4234192371368408
Valid Loss:  0.39633557200431824
Epoch:  34  	Training Loss: 0.4075384736061096
Test Loss:  0.4207817316055298
Valid Loss:  0.393804132938385
Epoch:  35  	Training Loss: 0.40497028827667236
Test Loss:  0.4181613326072693
Valid Loss:  0.3912903964519501
Epoch:  36  	Training Loss: 0.4024195075035095
Test Loss:  0.41555795073509216
Valid Loss:  0.38879579305648804
Epoch:  37  	Training Loss: 0.399885892868042
Test Loss:  0.4129717946052551
Valid Loss:  0.3863182067871094
Epoch:  38  	Training Loss: 0.39736881852149963
Test Loss:  0.4104023575782776
Valid Loss:  0.38385725021362305
Epoch:  39  	Training Loss: 0.3948681354522705
Test Loss:  0.4078495502471924
Valid Loss:  0.3814125657081604
Epoch:  40  	Training Loss: 0.39238378405570984
Test Loss:  0.4053128957748413
Valid Loss:  0.37898367643356323
Epoch:  41  	Training Loss: 0.3899156451225281
Test Loss:  0.4027925729751587
Valid Loss:  0.3765707015991211
Epoch:  42  	Training Loss: 0.3874637186527252
Test Loss:  0.4003221392631531
Valid Loss:  0.3742055296897888
Epoch:  43  	Training Loss: 0.38505983352661133
Test Loss:  0.39786937832832336
Valid Loss:  0.37185731530189514
Epoch:  44  	Training Loss: 0.3826727271080017
Test Loss:  0.39543381333351135
Valid Loss:  0.3695257008075714
Epoch:  45  	Training Loss: 0.38030245900154114
Test Loss:  0.3930149972438812
Valid Loss:  0.367210328578949
Epoch:  46  	Training Loss: 0.3779485821723938
Test Loss:  0.39061278104782104
Valid Loss:  0.36491113901138306
Epoch:  47  	Training Loss: 0.3756110668182373
Test Loss:  0.38822710514068604
Valid Loss:  0.3626279830932617
Epoch:  48  	Training Loss: 0.37328973412513733
Test Loss:  0.3858577013015747
Valid Loss:  0.36036133766174316
Epoch:  49  	Training Loss: 0.3709845542907715
Test Loss:  0.38350480794906616
Valid Loss:  0.35811078548431396
Epoch:  50  	Training Loss: 0.36869561672210693
Test Loss:  0.3811681866645813
Valid Loss:  0.3558759093284607
Epoch:  51  	Training Loss: 0.3664225935935974
Test Loss:  0.37884852290153503
Valid Loss:  0.3536566495895386
Epoch:  52  	Training Loss: 0.36416542530059814
Test Loss:  0.376507967710495
Valid Loss:  0.3514169156551361
Epoch:  53  	Training Loss: 0.36188727617263794
Test Loss:  0.3741834759712219
Valid Loss:  0.3491927981376648
Epoch:  54  	Training Loss: 0.35962504148483276
Test Loss:  0.3718750476837158
Valid Loss:  0.34698477387428284
Epoch:  55  	Training Loss: 0.35737860202789307
Test Loss:  0.36958250403404236
Valid Loss:  0.34479236602783203
Epoch:  56  	Training Loss: 0.3551478683948517
Test Loss:  0.3673057556152344
Valid Loss:  0.3426152467727661
Epoch:  57  	Training Loss: 0.3529326021671295
Test Loss:  0.3650445342063904
Valid Loss:  0.34045329689979553
Epoch:  58  	Training Loss: 0.3507326543331146
Test Loss:  0.362798810005188
Valid Loss:  0.33830639719963074
Epoch:  59  	Training Loss: 0.3485479950904846
Test Loss:  0.3605686128139496
Valid Loss:  0.33617454767227173
Epoch:  60  	Training Loss: 0.3463786542415619
Test Loss:  0.3583536148071289
Valid Loss:  0.33405792713165283
Epoch:  61  	Training Loss: 0.34422415494918823
Test Loss:  0.35615378618240356
Valid Loss:  0.331956684589386
Epoch:  62  	Training Loss: 0.3420846462249756
Test Loss:  0.3539639115333557
Valid Loss:  0.3298644721508026
Epoch:  63  	Training Loss: 0.3399544656276703
Test Loss:  0.3517884612083435
Valid Loss:  0.32778629660606384
Epoch:  64  	Training Loss: 0.3378385007381439
Test Loss:  0.34962764382362366
Valid Loss:  0.3257220983505249
Epoch:  65  	Training Loss: 0.335737019777298
Test Loss:  0.34748151898384094
Valid Loss:  0.323671817779541
Epoch:  66  	Training Loss: 0.33364957571029663
Test Loss:  0.34534937143325806
Valid Loss:  0.3216351866722107
Epoch:  67  	Training Loss: 0.3315759301185608
Test Loss:  0.3432316184043884
Valid Loss:  0.31961214542388916
Epoch:  68  	Training Loss: 0.3295159637928009
Test Loss:  0.34112802147865295
Valid Loss:  0.31760287284851074
Epoch:  69  	Training Loss: 0.32746967673301697
Test Loss:  0.3390384018421173
Valid Loss:  0.3156071603298187
Epoch:  70  	Training Loss: 0.32543715834617615
Test Loss:  0.33696240186691284
Valid Loss:  0.31362470984458923
Epoch:  71  	Training Loss: 0.3234179615974426
Test Loss:  0.3348999619483948
Valid Loss:  0.31165552139282227
Epoch:  72  	Training Loss: 0.3214123547077179
Test Loss:  0.33281660079956055
Valid Loss:  0.3096657991409302
Epoch:  73  	Training Loss: 0.31938600540161133
Test Loss:  0.33074676990509033
Valid Loss:  0.3076894283294678
Epoch:  74  	Training Loss: 0.3173730671405792
Test Loss:  0.32869064807891846
Valid Loss:  0.3057262897491455
 15%|█▌        | 75/500 [00:54<04:21,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:00<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.22it/s] 18%|█▊        | 89/500 [01:01<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:07<08:04,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:49,  1.18s/it] 21%|██        | 103/500 [01:14<05:35,  1.18it/s] 21%|██        | 105/500 [01:14<04:01,  1.63it/s] 21%|██▏       | 107/500 [01:15<02:55,  2.23it/s] 22%|██▏       | 109/500 [01:15<02:10,  3.01it/s] 22%|██▏       | 111/500 [01:21<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:21<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:21<02:56,  2.16it/s] 24%|██▍       | 119/500 [01:22<02:10,  2.91it/s] 24%|██▍       | 121/500 [01:28<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:28<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:28<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:18,  1.19s/it] 27%|██▋       | 133/500 [01:35<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:35<03:44,  1.62it/s] 27%|██▋       | 137/500 [01:35<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:35<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:42<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:04,  1.17it/s] 29%|██▉       | 145/500 [01:42<03:39,  1.62it/s]Epoch:  75  	Training Loss: 0.31537356972694397
Test Loss:  0.32664817571640015
Valid Loss:  0.3037763237953186
Epoch:  76  	Training Loss: 0.3133874535560608
Test Loss:  0.3246193826198578
Valid Loss:  0.30183976888656616
Epoch:  77  	Training Loss: 0.3114146590232849
Test Loss:  0.3226039707660675
Valid Loss:  0.29991626739501953
Epoch:  78  	Training Loss: 0.3094550371170044
Test Loss:  0.32060185074806213
Valid Loss:  0.2980056405067444
Epoch:  79  	Training Loss: 0.3075084686279297
Test Loss:  0.3186129033565521
Valid Loss:  0.2961078882217407
Epoch:  80  	Training Loss: 0.3055749535560608
Test Loss:  0.31663694977760315
Valid Loss:  0.29422274231910706
Epoch:  81  	Training Loss: 0.3036542534828186
Test Loss:  0.3146739602088928
Valid Loss:  0.29235029220581055
Epoch:  82  	Training Loss: 0.30174633860588074
Test Loss:  0.3127136826515198
Valid Loss:  0.2904801070690155
Epoch:  83  	Training Loss: 0.2998408079147339
Test Loss:  0.31076622009277344
Valid Loss:  0.28862264752388
Epoch:  84  	Training Loss: 0.2979481518268585
Test Loss:  0.3088316023349762
Valid Loss:  0.2867775559425354
Epoch:  85  	Training Loss: 0.296068012714386
Test Loss:  0.30690956115722656
Valid Loss:  0.28494471311569214
Epoch:  86  	Training Loss: 0.2942003011703491
Test Loss:  0.3050001859664917
Valid Loss:  0.283124178647995
Epoch:  87  	Training Loss: 0.2923450469970703
Test Loss:  0.30310332775115967
Valid Loss:  0.28131577372550964
Epoch:  88  	Training Loss: 0.29050213098526
Test Loss:  0.30121907591819763
Valid Loss:  0.2795194685459137
Epoch:  89  	Training Loss: 0.2886713147163391
Test Loss:  0.29934704303741455
Valid Loss:  0.27773505449295044
Epoch:  90  	Training Loss: 0.2868525981903076
Test Loss:  0.2974873185157776
Valid Loss:  0.27596259117126465
Epoch:  91  	Training Loss: 0.28504595160484314
Test Loss:  0.2956397533416748
Valid Loss:  0.2742019295692444
Epoch:  92  	Training Loss: 0.28325122594833374
Test Loss:  0.29379504919052124
Valid Loss:  0.2724439799785614
Epoch:  93  	Training Loss: 0.28145933151245117
Test Loss:  0.29196253418922424
Valid Loss:  0.27069783210754395
Epoch:  94  	Training Loss: 0.27967941761016846
Test Loss:  0.29014208912849426
Valid Loss:  0.2689635753631592
Epoch:  95  	Training Loss: 0.2779114842414856
Test Loss:  0.2883337140083313
Valid Loss:  0.26724088191986084
Epoch:  96  	Training Loss: 0.27615535259246826
Test Loss:  0.2865372896194458
Valid Loss:  0.2655298113822937
Epoch:  97  	Training Loss: 0.2744109630584717
Test Loss:  0.28475260734558105
Valid Loss:  0.2638302445411682
Epoch:  98  	Training Loss: 0.27267828583717346
Test Loss:  0.2829798460006714
Valid Loss:  0.2621423006057739
Epoch:  99  	Training Loss: 0.2709570825099945
Test Loss:  0.28121891617774963
Valid Loss:  0.2604658305644989
Epoch:  100  	Training Loss: 0.2692475914955139
Test Loss:  0.2794695496559143
Valid Loss:  0.2588005065917969
Epoch:  101  	Training Loss: 0.26754942536354065
Test Loss:  0.27773165702819824
Valid Loss:  0.2571464776992798
Epoch:  102  	Training Loss: 0.2658626437187195
Test Loss:  0.2760034203529358
Valid Loss:  0.25550177693367004
Epoch:  103  	Training Loss: 0.26418524980545044
Test Loss:  0.274286687374115
Valid Loss:  0.25386807322502136
Epoch:  104  	Training Loss: 0.26251906156539917
Test Loss:  0.2725811302661896
Valid Loss:  0.25224530696868896
Epoch:  105  	Training Loss: 0.2608639597892761
Test Loss:  0.2708868384361267
Valid Loss:  0.2506335377693176
Epoch:  106  	Training Loss: 0.2592199444770813
Test Loss:  0.26920372247695923
Valid Loss:  0.24903269112110138
Epoch:  107  	Training Loss: 0.25758689641952515
Test Loss:  0.26753175258636475
Valid Loss:  0.24744251370429993
Epoch:  108  	Training Loss: 0.2559647560119629
Test Loss:  0.26587074995040894
Valid Loss:  0.2458629608154297
Epoch:  109  	Training Loss: 0.25435346364974976
Test Loss:  0.26422062516212463
Valid Loss:  0.24429413676261902
Epoch:  110  	Training Loss: 0.2527529001235962
Test Loss:  0.26258134841918945
Valid Loss:  0.2427358329296112
Epoch:  111  	Training Loss: 0.25116297602653503
Test Loss:  0.26095283031463623
Valid Loss:  0.2411879003047943
Epoch:  112  	Training Loss: 0.24958361685276031
Test Loss:  0.2593477964401245
Valid Loss:  0.23966221511363983
Epoch:  113  	Training Loss: 0.24802696704864502
Test Loss:  0.25775325298309326
Valid Loss:  0.23814687132835388
Epoch:  114  	Training Loss: 0.24648067355155945
Test Loss:  0.25616931915283203
Valid Loss:  0.23664161562919617
Epoch:  115  	Training Loss: 0.24494478106498718
Test Loss:  0.2545958459377289
Valid Loss:  0.2351466864347458
Epoch:  116  	Training Loss: 0.2434191256761551
Test Loss:  0.25303277373313904
Valid Loss:  0.23366175591945648
Epoch:  117  	Training Loss: 0.24190369248390198
Test Loss:  0.25148001313209534
Valid Loss:  0.23218680918216705
Epoch:  118  	Training Loss: 0.24039840698242188
Test Loss:  0.2499375343322754
Valid Loss:  0.2307218313217163
Epoch:  119  	Training Loss: 0.23890313506126404
Test Loss:  0.24840515851974487
Valid Loss:  0.22926680743694305
Epoch:  120  	Training Loss: 0.23741792142391205
Test Loss:  0.24688300490379333
Valid Loss:  0.22782152891159058
Epoch:  121  	Training Loss: 0.23594260215759277
Test Loss:  0.24537083506584167
Valid Loss:  0.22638602554798126
Epoch:  122  	Training Loss: 0.2344772219657898
Test Loss:  0.24384896457195282
Valid Loss:  0.2249414622783661
Epoch:  123  	Training Loss: 0.2330024540424347
Test Loss:  0.24233703315258026
Valid Loss:  0.22350643575191498
Epoch:  124  	Training Loss: 0.23153740167617798
Test Loss:  0.240835040807724
Valid Loss:  0.2220810204744339
Epoch:  125  	Training Loss: 0.23008209466934204
Test Loss:  0.23934277892112732
Valid Loss:  0.2206650972366333
Epoch:  126  	Training Loss: 0.2286362200975418
Test Loss:  0.23786024749279022
Valid Loss:  0.21925848722457886
Epoch:  127  	Training Loss: 0.22719994187355042
Test Loss:  0.23638734221458435
Valid Loss:  0.2178613394498825
Epoch:  128  	Training Loss: 0.2257731854915619
Test Loss:  0.23492398858070374
Valid Loss:  0.21647338569164276
Epoch:  129  	Training Loss: 0.22435571253299713
Test Loss:  0.23346999287605286
Valid Loss:  0.21509462594985962
Epoch:  130  	Training Loss: 0.22294765710830688
Test Loss:  0.2320256233215332
Valid Loss:  0.21372506022453308
Epoch:  131  	Training Loss: 0.22154884040355682
Test Loss:  0.2305905520915985
Valid Loss:  0.21236471831798553
Epoch:  132  	Training Loss: 0.22015923261642456
Test Loss:  0.22921067476272583
Valid Loss:  0.21105676889419556
Epoch:  133  	Training Loss: 0.2188231199979782
Test Loss:  0.22784006595611572
Valid Loss:  0.20975781977176666
Epoch:  134  	Training Loss: 0.21749615669250488
Test Loss:  0.22647882997989655
Valid Loss:  0.20846793055534363
Epoch:  135  	Training Loss: 0.216178297996521
Test Loss:  0.22512677311897278
Valid Loss:  0.20718687772750854
Epoch:  136  	Training Loss: 0.21486946940422058
Test Loss:  0.22378388047218323
Valid Loss:  0.205914705991745
Epoch:  137  	Training Loss: 0.21356964111328125
Test Loss:  0.22244998812675476
Valid Loss:  0.20465126633644104
Epoch:  138  	Training Loss: 0.2122786045074463
Test Loss:  0.22112509608268738
Valid Loss:  0.20339658856391907
Epoch:  139  	Training Loss: 0.21099638938903809
Test Loss:  0.21980908513069153
Valid Loss:  0.20215046405792236
Epoch:  140  	Training Loss: 0.20972295105457306
Test Loss:  0.21850192546844482
Valid Loss:  0.20091281831264496
Epoch:  141  	Training Loss: 0.2084580808877945
Test Loss:  0.21720339357852936
Valid Loss:  0.19968368113040924
Epoch:  142  	Training Loss: 0.20720180869102478
Test Loss:  0.21585828065872192
Valid Loss:  0.19841070473194122
Epoch:  143  	Training Loss: 0.20590054988861084
Test Loss:  0.214521586894989
Valid Loss:  0.19714593887329102
Epoch:  144  	Training Loss: 0.20460760593414307
Test Loss:  0.2131934016942978
Valid Loss:  0.1958894431591034
Epoch:  145  	Training Loss: 0.20332306623458862
Test Loss:  0.21187365055084229
Valid Loss:  0.1946410834789276
Epoch:  146  	Training Loss: 0.202046737074852
Test Loss:  0.2105620950460434
Valid Loss:  0.19340071082115173
Epoch:  147  	Training Loss: 0.20077849924564362
Test Loss:  0.20925891399383545
Valid Loss:   29%|██▉       | 147/500 [01:42<02:39,  2.22it/s] 30%|██▉       | 149/500 [01:42<01:57,  2.98it/s] 30%|███       | 151/500 [01:49<06:59,  1.20s/it] 31%|███       | 153/500 [01:49<04:59,  1.16it/s] 31%|███       | 155/500 [01:49<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:49<02:36,  2.19it/s] 32%|███▏      | 159/500 [01:49<01:55,  2.95it/s] 32%|███▏      | 161/500 [01:56<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:30,  2.22it/s] 34%|███▍      | 169/500 [01:56<01:51,  2.98it/s] 34%|███▍      | 171/500 [02:02<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:03<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:03<03:21,  1.62it/s] 35%|███▌      | 177/500 [02:03<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.97it/s] 36%|███▌      | 181/500 [02:09<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:10<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:10<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:10<01:44,  2.99it/s] 38%|███▊      | 191/500 [02:16<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:16<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:17<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:17<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:17<01:41,  2.97it/s] 40%|████      | 201/500 [02:23<05:52,  1.18s/it] 41%|████      | 203/500 [02:23<04:11,  1.18it/s] 41%|████      | 205/500 [02:23<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:24<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:30<05:43,  1.19s/it] 43%|████▎     | 213/500 [02:30<04:04,  1.17it/s] 43%|████▎     | 215/500 [02:30<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:30<02:08,  2.21it/s] 44%|████▍     | 219/500 [02:31<01:34,  2.97it/s]0.19216835498809814
Epoch:  148  	Training Loss: 0.19951839745044708
Test Loss:  0.20796389877796173
Valid Loss:  0.19094400107860565
Epoch:  149  	Training Loss: 0.1982664167881012
Test Loss:  0.20667725801467896
Valid Loss:  0.18972770869731903
Epoch:  150  	Training Loss: 0.19702249765396118
Test Loss:  0.20539875328540802
Valid Loss:  0.1885192096233368
Epoch:  151  	Training Loss: 0.19578653573989868
Test Loss:  0.20412832498550415
Valid Loss:  0.1873185783624649
Epoch:  152  	Training Loss: 0.19455863535404205
Test Loss:  0.20285412669181824
Valid Loss:  0.18611431121826172
Epoch:  153  	Training Loss: 0.19332697987556458
Test Loss:  0.2015882432460785
Valid Loss:  0.1849181354045868
Epoch:  154  	Training Loss: 0.19210341572761536
Test Loss:  0.20033034682273865
Valid Loss:  0.18372973799705505
Epoch:  155  	Training Loss: 0.19088780879974365
Test Loss:  0.19908063113689423
Valid Loss:  0.18254917860031128
Epoch:  156  	Training Loss: 0.18968015909194946
Test Loss:  0.19783911108970642
Valid Loss:  0.18137651681900024
Epoch:  157  	Training Loss: 0.18848049640655518
Test Loss:  0.19660548865795135
Valid Loss:  0.18021173775196075
Epoch:  158  	Training Loss: 0.18728870153427124
Test Loss:  0.19537991285324097
Valid Loss:  0.17905452847480774
Epoch:  159  	Training Loss: 0.18610474467277527
Test Loss:  0.1941622495651245
Valid Loss:  0.1779051423072815
Epoch:  160  	Training Loss: 0.1849285513162613
Test Loss:  0.19295263290405273
Valid Loss:  0.1767633557319641
Epoch:  161  	Training Loss: 0.1837601363658905
Test Loss:  0.19175070524215698
Valid Loss:  0.1756291389465332
Epoch:  162  	Training Loss: 0.18259942531585693
Test Loss:  0.19050900638103485
Valid Loss:  0.17445707321166992
Epoch:  163  	Training Loss: 0.18140001595020294
Test Loss:  0.18927496671676636
Valid Loss:  0.17329241335391998
Epoch:  164  	Training Loss: 0.18020817637443542
Test Loss:  0.1880486011505127
Valid Loss:  0.17213524878025055
Epoch:  165  	Training Loss: 0.1790238320827484
Test Loss:  0.1868298202753067
Valid Loss:  0.17098554968833923
Epoch:  166  	Training Loss: 0.1778470277786255
Test Loss:  0.18561872839927673
Valid Loss:  0.1698431372642517
Epoch:  167  	Training Loss: 0.1766776740550995
Test Loss:  0.18441514670848846
Valid Loss:  0.16870799660682678
Epoch:  168  	Training Loss: 0.17551571130752563
Test Loss:  0.18321898579597473
Valid Loss:  0.16758021712303162
Epoch:  169  	Training Loss: 0.17436107993125916
Test Loss:  0.1820303201675415
Valid Loss:  0.1664595603942871
Epoch:  170  	Training Loss: 0.17321382462978363
Test Loss:  0.1808491200208664
Valid Loss:  0.16534626483917236
Epoch:  171  	Training Loss: 0.1720738559961319
Test Loss:  0.17967535555362701
Valid Loss:  0.16423997282981873
Epoch:  172  	Training Loss: 0.17094114422798157
Test Loss:  0.1785561740398407
Valid Loss:  0.163185715675354
Epoch:  173  	Training Loss: 0.1698613166809082
Test Loss:  0.17744413018226624
Valid Loss:  0.16213828325271606
Epoch:  174  	Training Loss: 0.1687886118888855
Test Loss:  0.17633941769599915
Valid Loss:  0.16109789907932281
Epoch:  175  	Training Loss: 0.16772301495075226
Test Loss:  0.17524176836013794
Valid Loss:  0.1600644886493683
Epoch:  176  	Training Loss: 0.16666436195373535
Test Loss:  0.17415133118629456
Valid Loss:  0.15903791785240173
Epoch:  177  	Training Loss: 0.16561272740364075
Test Loss:  0.1730678677558899
Valid Loss:  0.1580181121826172
Epoch:  178  	Training Loss: 0.16456793248653412
Test Loss:  0.17199137806892395
Valid Loss:  0.15700513124465942
Epoch:  179  	Training Loss: 0.16352997720241547
Test Loss:  0.17092178761959076
Valid Loss:  0.1559988260269165
Epoch:  180  	Training Loss: 0.16249892115592957
Test Loss:  0.16985923051834106
Valid Loss:  0.154999241232872
Epoch:  181  	Training Loss: 0.16147461533546448
Test Loss:  0.16880357265472412
Valid Loss:  0.15400636196136475
Epoch:  182  	Training Loss: 0.1604570895433426
Test Loss:  0.16776205599308014
Valid Loss:  0.1530270278453827
Epoch:  183  	Training Loss: 0.159453347325325
Test Loss:  0.16672736406326294
Valid Loss:  0.15205416083335876
Epoch:  184  	Training Loss: 0.1584562361240387
Test Loss:  0.16569945216178894
Valid Loss:  0.15108799934387207
Epoch:  185  	Training Loss: 0.1574658751487732
Test Loss:  0.1646784394979477
Valid Loss:  0.15012846887111664
Epoch:  186  	Training Loss: 0.15648213028907776
Test Loss:  0.1636640727519989
Valid Loss:  0.1491752564907074
Epoch:  187  	Training Loss: 0.15550497174263
Test Loss:  0.16265633702278137
Valid Loss:  0.14822854101657867
Epoch:  188  	Training Loss: 0.15453436970710754
Test Loss:  0.1616552770137787
Valid Loss:  0.1472882181406021
Epoch:  189  	Training Loss: 0.15357021987438202
Test Loss:  0.16066086292266846
Valid Loss:  0.14635425806045532
Epoch:  190  	Training Loss: 0.15261253714561462
Test Loss:  0.15967293083667755
Valid Loss:  0.14542658627033234
Epoch:  191  	Training Loss: 0.1516612470149994
Test Loss:  0.15869152545928955
Valid Loss:  0.14450523257255554
Epoch:  192  	Training Loss: 0.15071630477905273
Test Loss:  0.1576842963695526
Valid Loss:  0.1435597687959671
Epoch:  193  	Training Loss: 0.1497466266155243
Test Loss:  0.15668362379074097
Valid Loss:  0.14262069761753082
Epoch:  194  	Training Loss: 0.1487833857536316
Test Loss:  0.15568944811820984
Valid Loss:  0.14168784022331238
Epoch:  195  	Training Loss: 0.14782652258872986
Test Loss:  0.15470176935195923
Valid Loss:  0.14076119661331177
Epoch:  196  	Training Loss: 0.1468759924173355
Test Loss:  0.15372057259082794
Valid Loss:  0.13984078168869019
Epoch:  197  	Training Loss: 0.14593172073364258
Test Loss:  0.15274560451507568
Valid Loss:  0.13892647624015808
Epoch:  198  	Training Loss: 0.1449936330318451
Test Loss:  0.15177702903747559
Valid Loss:  0.138018399477005
Epoch:  199  	Training Loss: 0.1440618634223938
Test Loss:  0.1508149653673172
Valid Loss:  0.13711635768413544
Epoch:  200  	Training Loss: 0.14313629269599915
Test Loss:  0.1498589813709259
Valid Loss:  0.13622039556503296
Epoch:  201  	Training Loss: 0.14221680164337158
Test Loss:  0.1489093154668808
Valid Loss:  0.1353304088115692
Epoch:  202  	Training Loss: 0.1413034051656723
Test Loss:  0.14797179400920868
Valid Loss:  0.13445237278938293
Epoch:  203  	Training Loss: 0.14040210843086243
Test Loss:  0.14704060554504395
Valid Loss:  0.13358041644096375
Epoch:  204  	Training Loss: 0.13950693607330322
Test Loss:  0.14611557126045227
Valid Loss:  0.13271434605121613
Epoch:  205  	Training Loss: 0.1386178433895111
Test Loss:  0.14519678056240082
Valid Loss:  0.1318543553352356
Epoch:  206  	Training Loss: 0.1377347856760025
Test Loss:  0.1442839652299881
Valid Loss:  0.1310001015663147
Epoch:  207  	Training Loss: 0.13685762882232666
Test Loss:  0.14337724447250366
Valid Loss:  0.1301516741514206
Epoch:  208  	Training Loss: 0.13598641753196716
Test Loss:  0.14247657358646393
Valid Loss:  0.12930899858474731
Epoch:  209  	Training Loss: 0.13512103259563446
Test Loss:  0.14158186316490173
Valid Loss:  0.12847214937210083
Epoch:  210  	Training Loss: 0.13426154851913452
Test Loss:  0.1406930834054947
Valid Loss:  0.12764105200767517
Epoch:  211  	Training Loss: 0.133407860994339
Test Loss:  0.13981014490127563
Valid Loss:  0.1268155872821808
Epoch:  212  	Training Loss: 0.13255992531776428
Test Loss:  0.13899460434913635
Valid Loss:  0.12605319917201996
Epoch:  213  	Training Loss: 0.13177669048309326
Test Loss:  0.1381843388080597
Valid Loss:  0.1252959668636322
Epoch:  214  	Training Loss: 0.1309986412525177
Test Loss:  0.13737933337688446
Valid Loss:  0.12454371899366379
Epoch:  215  	Training Loss: 0.13022570312023163
Test Loss:  0.13657954335212708
Valid Loss:  0.1237964928150177
Epoch:  216  	Training Loss: 0.12945786118507385
Test Loss:  0.13578495383262634
Valid Loss:  0.12305427342653275
Epoch:  217  	Training Loss: 0.12869513034820557
Test Loss:  0.13499556481838226
Valid Loss:  0.12231696397066116
Epoch:  218  	Training Loss: 0.12793734669685364
Test Loss:  0.1342112272977829
Valid Loss:  0.12158457189798355
Epoch:  219  	Training Loss: 0.12718459963798523
Test Loss:  0.1334320306777954
Valid Loss:  0.12085706740617752
 44%|████▍     | 221/500 [02:37<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:37<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:37<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:37<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:44<05:19,  1.19s/it] 47%|████▋     | 233/500 [02:44<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:44<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:44<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:51<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:51<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:51<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:51<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.00it/s] 50%|█████     | 251/500 [02:57<04:49,  1.16s/it] 51%|█████     | 253/500 [02:57<03:26,  1.20it/s] 51%|█████     | 255/500 [02:58<02:28,  1.66it/s] 51%|█████▏    | 257/500 [02:58<01:47,  2.26it/s] 52%|█████▏    | 259/500 [02:58<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:04<04:42,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:04<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:05<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:05<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:11<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:11<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:11<02:19,  1.62it/s] 55%|█████▌    | 277/500 [03:12<01:40,  2.21it/s] 56%|█████▌    | 279/500 [03:12<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:18<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:18<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:18<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:18<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:19<01:10,  2.97it/s] 58%|█████▊    | 291/500 [03:25<04:08,  1.19s/it]Epoch:  220  	Training Loss: 0.12643679976463318
Test Loss:  0.13265785574913025
Valid Loss:  0.12013456970453262
Epoch:  221  	Training Loss: 0.12569405138492584
Test Loss:  0.13188879191875458
Valid Loss:  0.11941671371459961
Epoch:  222  	Training Loss: 0.12495610117912292
Test Loss:  0.13108527660369873
Valid Loss:  0.11866694688796997
Epoch:  223  	Training Loss: 0.12418529391288757
Test Loss:  0.13028723001480103
Valid Loss:  0.11792232096195221
Epoch:  224  	Training Loss: 0.12341973185539246
Test Loss:  0.1294945478439331
Valid Loss:  0.11718282103538513
Epoch:  225  	Training Loss: 0.12265938520431519
Test Loss:  0.12870702147483826
Valid Loss:  0.1164482831954956
Epoch:  226  	Training Loss: 0.12190410494804382
Test Loss:  0.1279248297214508
Valid Loss:  0.11571884155273438
Epoch:  227  	Training Loss: 0.12115401029586792
Test Loss:  0.12714770436286926
Valid Loss:  0.11499432474374771
Epoch:  228  	Training Loss: 0.12040894478559494
Test Loss:  0.12637585401535034
Valid Loss:  0.11427491903305054
Epoch:  229  	Training Loss: 0.11966899037361145
Test Loss:  0.1256091296672821
Valid Loss:  0.11356040835380554
Epoch:  230  	Training Loss: 0.11893399804830551
Test Loss:  0.12484757602214813
Valid Loss:  0.11285080015659332
Epoch:  231  	Training Loss: 0.11820406466722488
Test Loss:  0.12409111112356186
Valid Loss:  0.11214607954025269
Epoch:  232  	Training Loss: 0.11747905611991882
Test Loss:  0.12336624413728714
Valid Loss:  0.11147117614746094
Epoch:  233  	Training Loss: 0.11678457260131836
Test Loss:  0.12264615297317505
Valid Loss:  0.11080080270767212
Epoch:  234  	Training Loss: 0.11609473824501038
Test Loss:  0.1219308078289032
Valid Loss:  0.11013492941856384
Epoch:  235  	Training Loss: 0.1154094934463501
Test Loss:  0.12122015655040741
Valid Loss:  0.10947360098361969
Epoch:  236  	Training Loss: 0.11472887545824051
Test Loss:  0.12051420658826828
Valid Loss:  0.10881687700748444
Epoch:  237  	Training Loss: 0.11405287683010101
Test Loss:  0.11981303244829178
Valid Loss:  0.10816452652215958
Epoch:  238  	Training Loss: 0.11338144540786743
Test Loss:  0.11911644041538239
Valid Loss:  0.10751660168170929
Epoch:  239  	Training Loss: 0.11271446943283081
Test Loss:  0.11842440068721771
Valid Loss:  0.10687315464019775
Epoch:  240  	Training Loss: 0.11205199360847473
Test Loss:  0.11773698031902313
Valid Loss:  0.10623405128717422
Epoch:  241  	Training Loss: 0.11139395087957382
Test Loss:  0.11705408245325089
Valid Loss:  0.10559938848018646
Epoch:  242  	Training Loss: 0.11074034869670868
Test Loss:  0.11634396016597748
Valid Loss:  0.10493931174278259
Epoch:  243  	Training Loss: 0.11006073653697968
Test Loss:  0.11563856899738312
Valid Loss:  0.10428382456302643
Epoch:  244  	Training Loss: 0.1093856543302536
Test Loss:  0.11493787169456482
Valid Loss:  0.10363279283046722
Epoch:  245  	Training Loss: 0.10871515423059464
Test Loss:  0.11424174159765244
Valid Loss:  0.10298621654510498
Epoch:  246  	Training Loss: 0.1080491691827774
Test Loss:  0.11355029046535492
Valid Loss:  0.10234402120113373
Epoch:  247  	Training Loss: 0.1073877364397049
Test Loss:  0.1128634661436081
Valid Loss:  0.10170628875494003
Epoch:  248  	Training Loss: 0.10673069953918457
Test Loss:  0.11218122392892838
Valid Loss:  0.10107289254665375
Epoch:  249  	Training Loss: 0.10607817769050598
Test Loss:  0.1115034818649292
Valid Loss:  0.10044394433498383
Epoch:  250  	Training Loss: 0.10543010383844376
Test Loss:  0.11083021759986877
Valid Loss:  0.09981925785541534
Epoch:  251  	Training Loss: 0.10478638857603073
Test Loss:  0.11016134172677994
Valid Loss:  0.0991988405585289
Epoch:  252  	Training Loss: 0.10414701700210571
Test Loss:  0.1095268726348877
Valid Loss:  0.09861040115356445
Epoch:  253  	Training Loss: 0.10354052484035492
Test Loss:  0.10889655351638794
Valid Loss:  0.09802605211734772
Epoch:  254  	Training Loss: 0.10293818265199661
Test Loss:  0.10827046632766724
Valid Loss:  0.09744565188884735
Epoch:  255  	Training Loss: 0.10233989357948303
Test Loss:  0.1076485738158226
Valid Loss:  0.09686923027038574
Epoch:  256  	Training Loss: 0.10174566507339478
Test Loss:  0.10703077167272568
Valid Loss:  0.09629669785499573
Epoch:  257  	Training Loss: 0.10115541517734528
Test Loss:  0.10641706734895706
Valid Loss:  0.09572827816009521
Epoch:  258  	Training Loss: 0.10056919604539871
Test Loss:  0.10580739378929138
Valid Loss:  0.09516356885433197
Epoch:  259  	Training Loss: 0.0999869778752327
Test Loss:  0.10520172864198685
Valid Loss:  0.09460268914699554
Epoch:  260  	Training Loss: 0.0994085744023323
Test Loss:  0.10460013151168823
Valid Loss:  0.09404566138982773
Epoch:  261  	Training Loss: 0.0988340824842453
Test Loss:  0.1040024682879448
Valid Loss:  0.0934925526380539
Epoch:  262  	Training Loss: 0.0982634574174881
Test Loss:  0.10339269042015076
Valid Loss:  0.09292817115783691
Epoch:  263  	Training Loss: 0.09768131375312805
Test Loss:  0.10278689861297607
Valid Loss:  0.09236767143011093
Epoch:  264  	Training Loss: 0.09710310399532318
Test Loss:  0.10218524187803268
Valid Loss:  0.09181110560894012
Epoch:  265  	Training Loss: 0.09652887284755707
Test Loss:  0.10158746689558029
Valid Loss:  0.0912582278251648
Epoch:  266  	Training Loss: 0.09595847129821777
Test Loss:  0.10099375993013382
Valid Loss:  0.09070929139852524
Epoch:  267  	Training Loss: 0.09539192914962769
Test Loss:  0.10040394216775894
Valid Loss:  0.09016402065753937
Epoch:  268  	Training Loss: 0.0948292687535286
Test Loss:  0.099818155169487
Valid Loss:  0.0896226018667221
Epoch:  269  	Training Loss: 0.09427042305469513
Test Loss:  0.09923622012138367
Valid Loss:  0.08908487111330032
Epoch:  270  	Training Loss: 0.09371539950370789
Test Loss:  0.09865811467170715
Valid Loss:  0.08855083584785461
Epoch:  271  	Training Loss: 0.0931641086935997
Test Loss:  0.09808391332626343
Valid Loss:  0.08802049607038498
Epoch:  272  	Training Loss: 0.09261658787727356
Test Loss:  0.09752330183982849
Valid Loss:  0.08750289678573608
Epoch:  273  	Training Loss: 0.09208214282989502
Test Loss:  0.09696640074253082
Valid Loss:  0.08698883652687073
Epoch:  274  	Training Loss: 0.09155137836933136
Test Loss:  0.09641334414482117
Valid Loss:  0.08647830039262772
Epoch:  275  	Training Loss: 0.09102420508861542
Test Loss:  0.09586396813392639
Valid Loss:  0.08597144484519958
Epoch:  276  	Training Loss: 0.09050072729587555
Test Loss:  0.09531830251216888
Valid Loss:  0.08546807616949081
Epoch:  277  	Training Loss: 0.08998079597949982
Test Loss:  0.09477637708187103
Valid Loss:  0.08496825397014618
Epoch:  278  	Training Loss: 0.08946453779935837
Test Loss:  0.09423807263374329
Valid Loss:  0.08447189629077911
Epoch:  279  	Training Loss: 0.08895176649093628
Test Loss:  0.09370337426662445
Valid Loss:  0.08397901803255081
Epoch:  280  	Training Loss: 0.08844251930713654
Test Loss:  0.09317231178283691
Valid Loss:  0.08348940312862396
Epoch:  281  	Training Loss: 0.08793672919273376
Test Loss:  0.09264472126960754
Valid Loss:  0.08300334960222244
Epoch:  282  	Training Loss: 0.08743439614772797
Test Loss:  0.092130146920681
Valid Loss:  0.08252918720245361
Epoch:  283  	Training Loss: 0.08694440126419067
Test Loss:  0.09161905944347382
Valid Loss:  0.08205835521221161
Epoch:  284  	Training Loss: 0.08645769953727722
Test Loss:  0.09111122786998749
Valid Loss:  0.08159060776233673
Epoch:  285  	Training Loss: 0.08597423136234283
Test Loss:  0.09060676395893097
Valid Loss:  0.08112604916095734
Epoch:  286  	Training Loss: 0.08549394458532333
Test Loss:  0.09010559320449829
Valid Loss:  0.08066463470458984
Epoch:  287  	Training Loss: 0.08501696586608887
Test Loss:  0.0896076112985611
Valid Loss:  0.08020630478858948
Epoch:  288  	Training Loss: 0.08454306423664093
Test Loss:  0.08911293745040894
Valid Loss:  0.07975110411643982
Epoch:  289  	Training Loss: 0.08407235145568848
Test Loss:  0.08862143754959106
Valid Loss:  0.07929891347885132
Epoch:  290  	Training Loss: 0.08360471576452255
Test Loss:  0.08813323825597763
Valid Loss:  0.07884988188743591
Epoch:  291  	Training Loss: 0.08314024657011032
Test Loss:  0.0876481682062149
Valid Loss:  0.07840372622013092
 59%|█████▊    | 293/500 [03:25<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:25<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:25<01:07,  2.97it/s] 60%|██████    | 301/500 [03:32<03:52,  1.17s/it] 61%|██████    | 303/500 [03:32<02:46,  1.18it/s] 61%|██████    | 305/500 [03:32<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:32<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:32<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:38<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:39<02:36,  1.20it/s] 63%|██████▎   | 315/500 [03:39<01:51,  1.65it/s] 63%|██████▎   | 317/500 [03:39<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:39<00:59,  3.03it/s] 64%|██████▍   | 321/500 [03:45<03:27,  1.16s/it] 65%|██████▍   | 323/500 [03:45<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:45<01:45,  1.66it/s] 65%|██████▌   | 327/500 [03:46<01:16,  2.27it/s] 66%|██████▌   | 329/500 [03:46<00:56,  3.05it/s] 66%|██████▌   | 331/500 [03:52<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:52<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:52<01:42,  1.62it/s] 67%|██████▋   | 337/500 [03:52<01:14,  2.20it/s] 68%|██████▊   | 339/500 [03:53<00:54,  2.95it/s] 68%|██████▊   | 341/500 [03:59<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:59<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:59<01:34,  1.65it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.25it/s] 70%|██████▉   | 349/500 [03:59<00:50,  3.02it/s] 70%|███████   | 351/500 [04:06<02:53,  1.16s/it] 71%|███████   | 353/500 [04:06<02:02,  1.20it/s] 71%|███████   | 355/500 [04:06<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:06<00:46,  3.03it/s] 72%|███████▏  | 361/500 [04:12<02:43,  1.17s/it]Epoch:  292  	Training Loss: 0.08267883956432343
Test Loss:  0.08713957667350769
Valid Loss:  0.07793626934289932
Epoch:  293  	Training Loss: 0.0821952223777771
Test Loss:  0.08663445711135864
Valid Loss:  0.0774720162153244
Epoch:  294  	Training Loss: 0.08171495050191879
Test Loss:  0.08613260835409164
Valid Loss:  0.07701095938682556
Epoch:  295  	Training Loss: 0.08123793452978134
Test Loss:  0.08563409745693207
Valid Loss:  0.07655312120914459
Epoch:  296  	Training Loss: 0.08076414465904236
Test Loss:  0.08513887226581573
Valid Loss:  0.07609832286834717
Epoch:  297  	Training Loss: 0.08029350638389587
Test Loss:  0.0846470445394516
Valid Loss:  0.07564674317836761
Epoch:  298  	Training Loss: 0.07982612401247025
Test Loss:  0.08415834605693817
Valid Loss:  0.0751982033252716
Epoch:  299  	Training Loss: 0.07936182618141174
Test Loss:  0.08367294073104858
Valid Loss:  0.07475267350673676
Epoch:  300  	Training Loss: 0.07890071719884872
Test Loss:  0.0831906646490097
Valid Loss:  0.07431034743785858
Epoch:  301  	Training Loss: 0.07844269275665283
Test Loss:  0.08271166682243347
Valid Loss:  0.07387097179889679
Epoch:  302  	Training Loss: 0.07798780500888824
Test Loss:  0.0822468250989914
Valid Loss:  0.07344473153352737
Epoch:  303  	Training Loss: 0.07754643261432648
Test Loss:  0.08178495615720749
Valid Loss:  0.07302126288414001
Epoch:  304  	Training Loss: 0.07710795104503632
Test Loss:  0.08132612705230713
Valid Loss:  0.07260070741176605
Epoch:  305  	Training Loss: 0.07667240500450134
Test Loss:  0.0808701440691948
Valid Loss:  0.07218296080827713
Epoch:  306  	Training Loss: 0.07623964548110962
Test Loss:  0.08041712641716003
Valid Loss:  0.0717678964138031
Epoch:  307  	Training Loss: 0.07580970227718353
Test Loss:  0.07996708899736404
Valid Loss:  0.0713556706905365
Epoch:  308  	Training Loss: 0.07538272440433502
Test Loss:  0.07951989769935608
Valid Loss:  0.07094622403383255
Epoch:  309  	Training Loss: 0.07495846599340439
Test Loss:  0.07907550781965256
Valid Loss:  0.07053938508033752
Epoch:  310  	Training Loss: 0.07453693449497223
Test Loss:  0.07863400131464005
Valid Loss:  0.07013528048992157
Epoch:  311  	Training Loss: 0.07411816716194153
Test Loss:  0.07819526642560959
Valid Loss:  0.06973391771316528
Epoch:  312  	Training Loss: 0.07370214909315109
Test Loss:  0.07776058465242386
Valid Loss:  0.06933622062206268
Epoch:  313  	Training Loss: 0.07328997552394867
Test Loss:  0.07732877135276794
Valid Loss:  0.06894131004810333
Epoch:  314  	Training Loss: 0.0728805810213089
Test Loss:  0.07689981162548065
Valid Loss:  0.06854909658432007
Epoch:  315  	Training Loss: 0.07247398793697357
Test Loss:  0.0764736533164978
Valid Loss:  0.06815965473651886
Epoch:  316  	Training Loss: 0.07207009196281433
Test Loss:  0.07605040073394775
Valid Loss:  0.06777286529541016
Epoch:  317  	Training Loss: 0.07166896760463715
Test Loss:  0.07562988996505737
Valid Loss:  0.06738858669996262
Epoch:  318  	Training Loss: 0.07127055525779724
Test Loss:  0.07521216571331024
Valid Loss:  0.06700703501701355
Epoch:  319  	Training Loss: 0.07087478041648865
Test Loss:  0.07479710876941681
Valid Loss:  0.06662805378437042
Epoch:  320  	Training Loss: 0.07048161327838898
Test Loss:  0.07438471913337708
Valid Loss:  0.06625153124332428
Epoch:  321  	Training Loss: 0.07009103149175644
Test Loss:  0.07397496700286865
Valid Loss:  0.06587763875722885
Epoch:  322  	Training Loss: 0.06970305740833282
Test Loss:  0.07357196509838104
Valid Loss:  0.06550990045070648
Epoch:  323  	Training Loss: 0.06932152062654495
Test Loss:  0.07317152619361877
Valid Loss:  0.06514459103345871
Epoch:  324  	Training Loss: 0.06894247978925705
Test Loss:  0.07277362048625946
Valid Loss:  0.06478177011013031
Epoch:  325  	Training Loss: 0.06856588274240494
Test Loss:  0.07237829267978668
Valid Loss:  0.06442143023014069
Epoch:  326  	Training Loss: 0.0681917816400528
Test Loss:  0.07198561728000641
Valid Loss:  0.06406350433826447
Epoch:  327  	Training Loss: 0.06782025098800659
Test Loss:  0.07159543037414551
Valid Loss:  0.06370796263217926
Epoch:  328  	Training Loss: 0.0674511268734932
Test Loss:  0.07120776176452637
Valid Loss:  0.06335470080375671
Epoch:  329  	Training Loss: 0.067084401845932
Test Loss:  0.07082259654998779
Valid Loss:  0.06300393491983414
Epoch:  330  	Training Loss: 0.066720150411129
Test Loss:  0.07043984532356262
Valid Loss:  0.0626555010676384
Epoch:  331  	Training Loss: 0.06635823845863342
Test Loss:  0.07005956768989563
Valid Loss:  0.06230931729078293
Epoch:  332  	Training Loss: 0.06599865853786469
Test Loss:  0.0696803629398346
Valid Loss:  0.061964184045791626
Epoch:  333  	Training Loss: 0.0656401515007019
Test Loss:  0.06930370628833771
Valid Loss:  0.06162143871188164
Epoch:  334  	Training Loss: 0.06528410315513611
Test Loss:  0.06892937421798706
Valid Loss:  0.0612809918820858
Epoch:  335  	Training Loss: 0.06493034958839417
Test Loss:  0.06855767965316772
Valid Loss:  0.060942936688661575
Epoch:  336  	Training Loss: 0.0645790621638298
Test Loss:  0.06818830966949463
Valid Loss:  0.06060703843832016
Epoch:  337  	Training Loss: 0.0642300620675087
Test Loss:  0.06782125681638718
Valid Loss:  0.060273490846157074
Epoch:  338  	Training Loss: 0.06388336420059204
Test Loss:  0.06745660305023193
Valid Loss:  0.0599420964717865
Epoch:  339  	Training Loss: 0.06353886425495148
Test Loss:  0.0670943632721901
Valid Loss:  0.059612937271595
Epoch:  340  	Training Loss: 0.06319677084684372
Test Loss:  0.06673436611890793
Valid Loss:  0.05928604677319527
Epoch:  341  	Training Loss: 0.06285683810710907
Test Loss:  0.06637682020664215
Valid Loss:  0.05896131694316864
Epoch:  342  	Training Loss: 0.06251925230026245
Test Loss:  0.06600512564182281
Valid Loss:  0.05862385779619217
Epoch:  343  	Training Loss: 0.06216838210821152
Test Loss:  0.06563597172498703
Valid Loss:  0.05828876793384552
Epoch:  344  	Training Loss: 0.061819881200790405
Test Loss:  0.06526924669742584
Valid Loss:  0.05795599892735481
Epoch:  345  	Training Loss: 0.06147382780909538
Test Loss:  0.06490500271320343
Valid Loss:  0.05762554332613945
Epoch:  346  	Training Loss: 0.061130039393901825
Test Loss:  0.06454318761825562
Valid Loss:  0.05729731172323227
Epoch:  347  	Training Loss: 0.06078862398862839
Test Loss:  0.06418365240097046
Valid Loss:  0.05697135999798775
Epoch:  348  	Training Loss: 0.060449544340372086
Test Loss:  0.06382660567760468
Valid Loss:  0.056647688150405884
Epoch:  349  	Training Loss: 0.060112666338682175
Test Loss:  0.06347182393074036
Valid Loss:  0.056326188147068024
Epoch:  350  	Training Loss: 0.059778135269880295
Test Loss:  0.06311938166618347
Valid Loss:  0.05600687116384506
Epoch:  351  	Training Loss: 0.059445809572935104
Test Loss:  0.06276921182870865
Valid Loss:  0.05568975955247879
Epoch:  352  	Training Loss: 0.059115707874298096
Test Loss:  0.062418658286333084
Valid Loss:  0.05537232756614685
Epoch:  353  	Training Loss: 0.05878531187772751
Test Loss:  0.062070462852716446
Valid Loss:  0.05505713075399399
Epoch:  354  	Training Loss: 0.05845710635185242
Test Loss:  0.06172449514269829
Valid Loss:  0.05474407225847244
Epoch:  355  	Training Loss: 0.058131143450737
Test Loss:  0.06138089671730995
Valid Loss:  0.0544331818819046
Epoch:  356  	Training Loss: 0.05780741199851036
Test Loss:  0.06103963032364845
Valid Loss:  0.05412452667951584
Epoch:  357  	Training Loss: 0.05748593807220459
Test Loss:  0.06070057675242424
Valid Loss:  0.05381803214550018
Epoch:  358  	Training Loss: 0.057166650891304016
Test Loss:  0.06036384031176567
Valid Loss:  0.05351363122463226
Epoch:  359  	Training Loss: 0.05684952065348625
Test Loss:  0.0600292794406414
Valid Loss:  0.05321131646633148
Epoch:  360  	Training Loss: 0.05653458833694458
Test Loss:  0.05969700217247009
Valid Loss:  0.05291111394762993
Epoch:  361  	Training Loss: 0.05622173845767975
Test Loss:  0.05936688184738159
Valid Loss:  0.052612945437431335
Epoch:  362  	Training Loss: 0.05591101944446564
Test Loss:  0.05904611200094223
Valid Loss:  0.052323371171951294
Epoch:  363  	Training Loss: 0.05560920387506485
Test Loss:  0.058727461844682693
Valid Loss:   73%|███████▎  | 363/500 [04:13<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:13<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:13<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:19<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:19<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:20<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:20<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:20<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:26<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:26<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:26<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:27<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:33<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:33<01:29,  1.20it/s] 79%|███████▉  | 395/500 [04:33<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.03it/s] 80%|████████  | 401/500 [04:39<01:54,  1.15s/it] 81%|████████  | 403/500 [04:40<01:20,  1.21it/s] 81%|████████  | 405/500 [04:40<00:56,  1.67it/s] 81%|████████▏ | 407/500 [04:40<00:40,  2.28it/s] 82%|████████▏ | 409/500 [04:40<00:29,  3.05it/s] 82%|████████▏ | 411/500 [04:46<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:47<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:47<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:47<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:53<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:54<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:54<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:00<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:00<00:57,  1.17it/s]0.05203574523329735
Epoch:  364  	Training Loss: 0.05530940741300583
Test Loss:  0.058410823345184326
Valid Loss:  0.05175012722611427
Epoch:  365  	Training Loss: 0.05501158535480499
Test Loss:  0.05809628590941429
Valid Loss:  0.051466360688209534
Epoch:  366  	Training Loss: 0.05471576750278473
Test Loss:  0.05778375267982483
Valid Loss:  0.05118458718061447
Epoch:  367  	Training Loss: 0.054421886801719666
Test Loss:  0.057473331689834595
Valid Loss:  0.05090468376874924
Epoch:  368  	Training Loss: 0.054129987955093384
Test Loss:  0.05716491490602493
Valid Loss:  0.050626736134290695
Epoch:  369  	Training Loss: 0.05384008586406708
Test Loss:  0.05685853958129883
Valid Loss:  0.05035069212317467
Epoch:  370  	Training Loss: 0.053552087396383286
Test Loss:  0.05655414238572121
Valid Loss:  0.05007654055953026
Epoch:  371  	Training Loss: 0.053266048431396484
Test Loss:  0.05625173822045326
Valid Loss:  0.04980424791574478
Epoch:  372  	Training Loss: 0.0529819056391716
Test Loss:  0.055932216346263885
Valid Loss:  0.04951650649309158
Epoch:  373  	Training Loss: 0.05268172174692154
Test Loss:  0.05561491474509239
Valid Loss:  0.04923083633184433
Epoch:  374  	Training Loss: 0.052383601665496826
Test Loss:  0.055299803614616394
Valid Loss:  0.0489472821354866
Epoch:  375  	Training Loss: 0.05208764225244522
Test Loss:  0.054986871778964996
Valid Loss:  0.04866572469472885
Epoch:  376  	Training Loss: 0.05179383233189583
Test Loss:  0.05467599630355835
Valid Loss:  0.04838622361421585
Epoch:  377  	Training Loss: 0.05150199681520462
Test Loss:  0.05436743050813675
Valid Loss:  0.04810873419046402
Epoch:  378  	Training Loss: 0.05121225118637085
Test Loss:  0.05406085401773453
Valid Loss:  0.047833189368247986
Epoch:  379  	Training Loss: 0.050924502313137054
Test Loss:  0.05375633388757706
Valid Loss:  0.04755968973040581
Epoch:  380  	Training Loss: 0.05063886195421219
Test Loss:  0.05345410108566284
Valid Loss:  0.04728810489177704
Epoch:  381  	Training Loss: 0.050355199724435806
Test Loss:  0.05315382033586502
Valid Loss:  0.047018490731716156
Epoch:  382  	Training Loss: 0.05007360875606537
Test Loss:  0.052877359092235565
Valid Loss:  0.04677046835422516
Epoch:  383  	Training Loss: 0.04981440305709839
Test Loss:  0.05260264128446579
Valid Loss:  0.04652407020330429
Epoch:  384  	Training Loss: 0.04955685883760452
Test Loss:  0.05232970416545868
Valid Loss:  0.0462794229388237
Epoch:  385  	Training Loss: 0.04930104315280914
Test Loss:  0.05205855518579483
Valid Loss:  0.04603632166981697
Epoch:  386  	Training Loss: 0.049046941101551056
Test Loss:  0.05178920179605484
Valid Loss:  0.045794978737831116
Epoch:  387  	Training Loss: 0.04879457876086235
Test Loss:  0.05152150243520737
Valid Loss:  0.04555521905422211
Epoch:  388  	Training Loss: 0.04854381084442139
Test Loss:  0.05125557631254196
Valid Loss:  0.045316994190216064
Epoch:  389  	Training Loss: 0.04829475283622742
Test Loss:  0.05099139362573624
Valid Loss:  0.04508043825626373
Epoch:  390  	Training Loss: 0.0480472669005394
Test Loss:  0.050728827714920044
Valid Loss:  0.044845495373010635
Epoch:  391  	Training Loss: 0.04780155047774315
Test Loss:  0.050468020141124725
Valid Loss:  0.04461216926574707
Epoch:  392  	Training Loss: 0.04755739867687225
Test Loss:  0.0502123162150383
Valid Loss:  0.04438340663909912
Epoch:  393  	Training Loss: 0.0473179891705513
Test Loss:  0.04995814710855484
Valid Loss:  0.04415612667798996
Epoch:  394  	Training Loss: 0.04708012193441391
Test Loss:  0.04970570281147957
Valid Loss:  0.04393033683300018
Epoch:  395  	Training Loss: 0.04684383049607277
Test Loss:  0.049454741179943085
Valid Loss:  0.04370608925819397
Epoch:  396  	Training Loss: 0.04660911113023758
Test Loss:  0.049205489456653595
Valid Loss:  0.04348335415124893
Epoch:  397  	Training Loss: 0.04637591540813446
Test Loss:  0.048957791179418564
Valid Loss:  0.04326210170984268
Epoch:  398  	Training Loss: 0.046144209802150726
Test Loss:  0.04871167615056038
Valid Loss:  0.04304236173629761
Epoch:  399  	Training Loss: 0.04591407626867294
Test Loss:  0.04846715182065964
Valid Loss:  0.04282405599951744
Epoch:  400  	Training Loss: 0.045685458928346634
Test Loss:  0.04822418838739395
Valid Loss:  0.04260729253292084
Epoch:  401  	Training Loss: 0.04545837268233299
Test Loss:  0.047982845455408096
Valid Loss:  0.042391981929540634
Epoch:  402  	Training Loss: 0.045232828706502914
Test Loss:  0.04775675758719444
Valid Loss:  0.04219038039445877
Epoch:  403  	Training Loss: 0.045021627098321915
Test Loss:  0.0475320965051651
Valid Loss:  0.04199010878801346
Epoch:  404  	Training Loss: 0.0448116809129715
Test Loss:  0.047308821231126785
Valid Loss:  0.04179110750555992
Epoch:  405  	Training Loss: 0.044603075832128525
Test Loss:  0.04708687961101532
Valid Loss:  0.04159339517354965
Epoch:  406  	Training Loss: 0.044395871460437775
Test Loss:  0.046866342425346375
Valid Loss:  0.041396982967853546
Epoch:  407  	Training Loss: 0.0441899374127388
Test Loss:  0.04664723202586174
Valid Loss:  0.041201867163181305
Epoch:  408  	Training Loss: 0.04398529976606369
Test Loss:  0.04642932862043381
Valid Loss:  0.041007936000823975
Epoch:  409  	Training Loss: 0.04378193989396095
Test Loss:  0.04621279239654541
Valid Loss:  0.04081529378890991
Epoch:  410  	Training Loss: 0.04357987642288208
Test Loss:  0.04599759355187416
Valid Loss:  0.040623802691698074
Epoch:  411  	Training Loss: 0.0433790348470211
Test Loss:  0.04578371345996857
Valid Loss:  0.04043358564376831
Epoch:  412  	Training Loss: 0.043179482221603394
Test Loss:  0.04556554928421974
Valid Loss:  0.040239617228507996
Epoch:  413  	Training Loss: 0.042976006865501404
Test Loss:  0.045348748564720154
Valid Loss:  0.04004685953259468
Epoch:  414  	Training Loss: 0.042773716151714325
Test Loss:  0.04513319954276085
Valid Loss:  0.039855312556028366
Epoch:  415  	Training Loss: 0.04257276654243469
Test Loss:  0.044919148087501526
Valid Loss:  0.0396651029586792
Epoch:  416  	Training Loss: 0.042373109608888626
Test Loss:  0.04470633715391159
Valid Loss:  0.039476096630096436
Epoch:  417  	Training Loss: 0.04217471927404404
Test Loss:  0.04449488967657089
Valid Loss:  0.039288341999053955
Epoch:  418  	Training Loss: 0.04197763279080391
Test Loss:  0.04428480565547943
Valid Loss:  0.03910180926322937
Epoch:  419  	Training Loss: 0.041781820356845856
Test Loss:  0.04407592490315437
Valid Loss:  0.0389164499938488
Epoch:  420  	Training Loss: 0.04158719629049301
Test Loss:  0.04386843740940094
Valid Loss:  0.03873242437839508
Epoch:  421  	Training Loss: 0.04139389842748642
Test Loss:  0.04366236925125122
Valid Loss:  0.03854963183403015
Epoch:  422  	Training Loss: 0.0412018857896328
Test Loss:  0.043456487357616425
Valid Loss:  0.0383671335875988
Epoch:  423  	Training Loss: 0.04101024195551872
Test Loss:  0.04325197637081146
Valid Loss:  0.03818589821457863
Epoch:  424  	Training Loss: 0.04081978648900986
Test Loss:  0.043048836290836334
Valid Loss:  0.03800587356090546
Epoch:  425  	Training Loss: 0.040630631148815155
Test Loss:  0.042846906930208206
Valid Loss:  0.037826985120773315
Epoch:  426  	Training Loss: 0.04044267535209656
Test Loss:  0.04264617711305618
Valid Loss:  0.03764934837818146
Epoch:  427  	Training Loss: 0.04025588557124138
Test Loss:  0.04244671016931534
Valid Loss:  0.03747273609042168
Epoch:  428  	Training Loss: 0.040070317685604095
Test Loss:  0.042248524725437164
Valid Loss:  0.037297338247299194
Epoch:  429  	Training Loss: 0.03988592326641083
Test Loss:  0.04205155000090599
Valid Loss:  0.037123098969459534
Epoch:  430  	Training Loss: 0.03970271721482277
Test Loss:  0.041855793446302414
Valid Loss:  0.03695004805922508
Epoch:  431  	Training Loss: 0.039520714432001114
Test Loss:  0.04166129231452942
Valid Loss:  0.03677807003259659
Epoch:  432  	Training Loss: 0.03933984786272049
Test Loss:  0.04146081581711769
Valid Loss:  0.03660079836845398
Epoch:  433  	Training Loss: 0.039153434336185455
Test Loss:  0.041261620819568634
Valid Loss:  0.036424823105335236
Epoch:  434  	Training Loss: 0.03896826505661011
Test Loss:  0.04106369614601135
Valid Loss:  0.03624989464879036
 87%|████████▋ | 435/500 [05:00<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:01<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:07<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:07<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:07<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:07<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:14<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:14<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:14<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:21<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:21<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:27<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:28<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:28<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:34<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:35<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:41<00:00,  3.01it/s]100%|██████████| 500/500 [05:41<00:00,  1.46it/s]
Epoch:  435  	Training Loss: 0.038784272968769073
Test Loss:  0.04086700454354286
Valid Loss:  0.03607623651623726
Epoch:  436  	Training Loss: 0.03860151022672653
Test Loss:  0.040671639144420624
Valid Loss:  0.035903722047805786
Epoch:  437  	Training Loss: 0.0384199321269989
Test Loss:  0.04047735780477524
Valid Loss:  0.03573229908943176
Epoch:  438  	Training Loss: 0.038239508867263794
Test Loss:  0.04028446227312088
Valid Loss:  0.03556200861930847
Epoch:  439  	Training Loss: 0.03806029260158539
Test Loss:  0.040092699229717255
Valid Loss:  0.03539290279150009
Epoch:  440  	Training Loss: 0.037882257252931595
Test Loss:  0.03990224003791809
Valid Loss:  0.03522494435310364
Epoch:  441  	Training Loss: 0.03770538419485092
Test Loss:  0.03971292823553085
Valid Loss:  0.03505805879831314
Epoch:  442  	Training Loss: 0.037529654800891876
Test Loss:  0.039522700011730194
Valid Loss:  0.03489045053720474
Epoch:  443  	Training Loss: 0.037353090941905975
Test Loss:  0.03933370113372803
Valid Loss:  0.03472397103905678
Epoch:  444  	Training Loss: 0.0371776819229126
Test Loss:  0.039145879447460175
Valid Loss:  0.034558530896902084
Epoch:  445  	Training Loss: 0.03700344264507294
Test Loss:  0.038959305733442307
Valid Loss:  0.03439430892467499
Epoch:  446  	Training Loss: 0.036830343306064606
Test Loss:  0.03877387195825577
Valid Loss:  0.03423115238547325
Epoch:  447  	Training Loss: 0.03665837273001671
Test Loss:  0.03858962655067444
Valid Loss:  0.034069083631038666
Epoch:  448  	Training Loss: 0.036487556993961334
Test Loss:  0.03840663656592369
Valid Loss:  0.033908020704984665
Epoch:  449  	Training Loss: 0.0363178551197052
Test Loss:  0.038224734365940094
Valid Loss:  0.03374819830060005
Epoch:  450  	Training Loss: 0.036149248480796814
Test Loss:  0.0380440279841423
Valid Loss:  0.033589400351047516
Epoch:  451  	Training Loss: 0.03598175197839737
Test Loss:  0.03786446154117584
Valid Loss:  0.033431582152843475
Epoch:  452  	Training Loss: 0.03581536188721657
Test Loss:  0.03768841177225113
Valid Loss:  0.03327696770429611
Epoch:  453  	Training Loss: 0.0356522873044014
Test Loss:  0.03751341253519058
Valid Loss:  0.03312336653470993
Epoch:  454  	Training Loss: 0.03549022227525711
Test Loss:  0.037339530885219574
Valid Loss:  0.03297073394060135
Epoch:  455  	Training Loss: 0.03532920032739639
Test Loss:  0.037166744470596313
Valid Loss:  0.03281915560364723
Epoch:  456  	Training Loss: 0.03516925871372223
Test Loss:  0.03699503839015961
Valid Loss:  0.032668597996234894
Epoch:  457  	Training Loss: 0.03501033037900925
Test Loss:  0.03682442754507065
Valid Loss:  0.03251899033784866
Epoch:  458  	Training Loss: 0.034852392971515656
Test Loss:  0.03665489703416824
Valid Loss:  0.03237047791481018
Epoch:  459  	Training Loss: 0.03469555079936981
Test Loss:  0.03648645803332329
Valid Loss:  0.032222796231508255
Epoch:  460  	Training Loss: 0.03453967347741127
Test Loss:  0.03631901368498802
Valid Loss:  0.03207617998123169
Epoch:  461  	Training Loss: 0.0343848317861557
Test Loss:  0.036152638494968414
Valid Loss:  0.03193049132823944
Epoch:  462  	Training Loss: 0.03423096984624863
Test Loss:  0.035980403423309326
Valid Loss:  0.03177975118160248
Epoch:  463  	Training Loss: 0.034071698784828186
Test Loss:  0.03580927848815918
Valid Loss:  0.031629953533411026
Epoch:  464  	Training Loss: 0.03391347825527191
Test Loss:  0.035639211535453796
Valid Loss:  0.03148118406534195
Epoch:  465  	Training Loss: 0.03375626355409622
Test Loss:  0.03547028824687004
Valid Loss:  0.03133343160152435
Epoch:  466  	Training Loss: 0.03360012546181679
Test Loss:  0.035302359610795975
Valid Loss:  0.0311866644769907
Epoch:  467  	Training Loss: 0.033445026725530624
Test Loss:  0.03513558208942413
Valid Loss:  0.031040867790579796
Epoch:  468  	Training Loss: 0.03329089283943176
Test Loss:  0.03496984392404556
Valid Loss:  0.030896086245775223
Epoch:  469  	Training Loss: 0.03313782066106796
Test Loss:  0.03480520471930504
Valid Loss:  0.03075231797993183
Epoch:  470  	Training Loss: 0.03298576921224594
Test Loss:  0.03464161977171898
Valid Loss:  0.030609525740146637
Epoch:  471  	Training Loss: 0.03283470869064331
Test Loss:  0.03447908163070679
Valid Loss:  0.03046771138906479
Epoch:  472  	Training Loss: 0.032684747129678726
Test Loss:  0.03432361036539078
Valid Loss:  0.030332054942846298
Epoch:  473  	Training Loss: 0.032541222870349884
Test Loss:  0.0341690257191658
Valid Loss:  0.030197348445653915
Epoch:  474  	Training Loss: 0.032398633658885956
Test Loss:  0.034015510231256485
Valid Loss:  0.030063442885875702
Epoch:  475  	Training Loss: 0.03225702792406082
Test Loss:  0.0338628925383091
Valid Loss:  0.02993052825331688
Epoch:  476  	Training Loss: 0.03211625665426254
Test Loss:  0.03371117636561394
Valid Loss:  0.029798416420817375
Epoch:  477  	Training Loss: 0.03197638317942619
Test Loss:  0.03356041759252548
Valid Loss:  0.029667172580957413
Epoch:  478  	Training Loss: 0.03183741122484207
Test Loss:  0.03341067582368851
Valid Loss:  0.029536819085478783
Epoch:  479  	Training Loss: 0.03169935941696167
Test Loss:  0.033261850476264954
Valid Loss:  0.02940734662115574
Epoch:  480  	Training Loss: 0.03156217932701111
Test Loss:  0.03311390429735184
Valid Loss:  0.029278673231601715
Epoch:  481  	Training Loss: 0.03142588585615158
Test Loss:  0.03296691179275513
Valid Loss:  0.029150864109396935
Epoch:  482  	Training Loss: 0.031290486454963684
Test Loss:  0.03281371295452118
Valid Loss:  0.02901771478354931
Epoch:  483  	Training Loss: 0.031149376183748245
Test Loss:  0.032661572098731995
Valid Loss:  0.02888546511530876
Epoch:  484  	Training Loss: 0.031009238213300705
Test Loss:  0.03251031041145325
Valid Loss:  0.02875409461557865
Epoch:  485  	Training Loss: 0.030869996175169945
Test Loss:  0.032360076904296875
Valid Loss:  0.028623640537261963
Epoch:  486  	Training Loss: 0.03073166497051716
Test Loss:  0.032210737466812134
Valid Loss:  0.02849406935274601
Epoch:  487  	Training Loss: 0.030594265088438988
Test Loss:  0.03206247091293335
Valid Loss:  0.02836533635854721
Epoch:  488  	Training Loss: 0.030457783490419388
Test Loss:  0.031915098428726196
Valid Loss:  0.028237544000148773
Epoch:  489  	Training Loss: 0.030322225764393806
Test Loss:  0.03176863119006157
Valid Loss:  0.02811051905155182
Epoch:  490  	Training Loss: 0.030187547206878662
Test Loss:  0.03162315487861633
Valid Loss:  0.027984485030174255
Epoch:  491  	Training Loss: 0.03005373477935791
Test Loss:  0.03147859126329422
Valid Loss:  0.02785920538008213
Epoch:  492  	Training Loss: 0.02992081269621849
Test Loss:  0.0313398540019989
Valid Loss:  0.027739088982343674
Epoch:  493  	Training Loss: 0.029793303459882736
Test Loss:  0.03120194934308529
Valid Loss:  0.02761973813176155
Epoch:  494  	Training Loss: 0.02966657653450966
Test Loss:  0.031064890325069427
Valid Loss:  0.02750108391046524
Epoch:  495  	Training Loss: 0.0295406486839056
Test Loss:  0.030928688123822212
Valid Loss:  0.027383243665099144
Epoch:  496  	Training Loss: 0.029415497556328773
Test Loss:  0.030793331563472748
Valid Loss:  0.027266237884759903
Epoch:  497  	Training Loss: 0.029291193932294846
Test Loss:  0.030658796429634094
Valid Loss:  0.02714996412396431
Epoch:  498  	Training Loss: 0.029167689383029938
Test Loss:  0.03052520751953125
Valid Loss:  0.027034472674131393
Epoch:  499  	Training Loss: 0.029044965282082558
Test Loss:  0.030392378568649292
Valid Loss:  0.02691974677145481
Epoch:  500  	Training Loss: 0.02892303094267845
Test Loss:  0.03026038035750389
Valid Loss:  0.026805773377418518
seed is  15
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:42,  6.22s/it]  1%|          | 3/500 [00:06<13:47,  1.66s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<08:58,  1.17s/it]  9%|▊         | 43/500 [00:33<06:24,  1.19it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:34<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:47,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:18,  2.24it/s] 12%|█▏        | 59/500 [00:41<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:47<08:33,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:53<11:05,  1.53s/it] 13%|█▎        | 67/500 [00:53<07:52,  1.09s/it] 14%|█▍        | 69/500 [00:53<05:37,  1.28it/s] 14%|█▍        | 71/500 [01:00<10:38,  1.49s/it]Epoch:  1  	Training Loss: 0.10619980841875076
Test Loss:  48.23918151855469
Valid Loss:  46.83633804321289
Epoch:  2  	Training Loss: 47.30601501464844
Test Loss:  3112.31689453125
Valid Loss:  2999.7802734375
Epoch:  3  	Training Loss: 3038.3212890625
Test Loss:  5.898026943206787
Valid Loss:  5.980340003967285
Epoch:  4  	Training Loss: 5.998287200927734
Test Loss:  5.863013744354248
Valid Loss:  5.941289901733398
Epoch:  5  	Training Loss: 5.96044397354126
Test Loss:  5.828245639801025
Valid Loss:  5.902531623840332
Epoch:  6  	Training Loss: 5.922875881195068
Test Loss:  5.7937211990356445
Valid Loss:  5.864064693450928
Epoch:  7  	Training Loss: 5.88558292388916
Test Loss:  5.7594380378723145
Valid Loss:  5.8258867263793945
Epoch:  8  	Training Loss: 5.848562717437744
Test Loss:  5.725417613983154
Valid Loss:  5.788064956665039
Epoch:  9  	Training Loss: 5.81195068359375
Test Loss:  5.69189453125
Valid Loss:  5.750628471374512
Epoch:  10  	Training Loss: 5.775716304779053
Test Loss:  5.6586761474609375
Valid Loss:  5.713468551635742
Epoch:  11  	Training Loss: 5.739740371704102
Test Loss:  5.6256842613220215
Valid Loss:  5.676583290100098
Epoch:  12  	Training Loss: 5.704023361206055
Test Loss:  4.170709133148193
Valid Loss:  3.559107780456543
Epoch:  13  	Training Loss: 3.793107748031616
Test Loss:  0.3381209373474121
Valid Loss:  0.6033565998077393
Epoch:  14  	Training Loss: 0.5552415251731873
Test Loss:  0.24266251921653748
Valid Loss:  0.48097068071365356
Epoch:  15  	Training Loss: 0.4428565800189972
Test Loss:  0.22892670333385468
Valid Loss:  0.4734123647212982
Epoch:  16  	Training Loss: 0.43286076188087463
Test Loss:  0.22477790713310242
Valid Loss:  0.4656825363636017
Epoch:  17  	Training Loss: 0.42610275745391846
Test Loss:  0.21976950764656067
Valid Loss:  0.4586820602416992
Epoch:  18  	Training Loss: 0.4195130169391632
Test Loss:  0.21501217782497406
Valid Loss:  0.45166435837745667
Epoch:  19  	Training Loss: 0.41300126910209656
Test Loss:  0.21029038727283478
Valid Loss:  0.4447433352470398
Epoch:  20  	Training Loss: 0.4065651297569275
Test Loss:  0.20564152300357819
Valid Loss:  0.43789955973625183
Epoch:  21  	Training Loss: 0.40020519495010376
Test Loss:  0.20105943083763123
Valid Loss:  0.4311370551586151
Epoch:  22  	Training Loss: 0.3939216732978821
Test Loss:  16.117877960205078
Valid Loss:  16.466629028320312
Epoch:  23  	Training Loss: 16.374784469604492
Test Loss:  15.431455612182617
Valid Loss:  16.816097259521484
Epoch:  24  	Training Loss: 16.429515838623047
Test Loss:  0.22241711616516113
Valid Loss:  0.21809276938438416
Epoch:  25  	Training Loss: 0.22465820610523224
Test Loss:  0.22241662442684174
Valid Loss:  0.21809226274490356
Epoch:  26  	Training Loss: 0.22465768456459045
Test Loss:  0.22241614758968353
Valid Loss:  0.21809175610542297
Epoch:  27  	Training Loss: 0.22465716302394867
Test Loss:  0.22241562604904175
Valid Loss:  0.21809127926826477
Epoch:  28  	Training Loss: 0.22465667128562927
Test Loss:  0.22241514921188354
Valid Loss:  0.21809077262878418
Epoch:  29  	Training Loss: 0.2246561348438263
Test Loss:  0.22241465747356415
Valid Loss:  0.2180902361869812
Epoch:  30  	Training Loss: 0.2246556282043457
Test Loss:  0.22241421043872833
Valid Loss:  0.2180897444486618
Epoch:  31  	Training Loss: 0.22465510666370392
Test Loss:  0.22241368889808655
Valid Loss:  0.2180892825126648
Epoch:  32  	Training Loss: 0.22465458512306213
Test Loss:  0.12784771621227264
Valid Loss:  0.1335766315460205
Epoch:  33  	Training Loss: 0.13689148426055908
Test Loss:  0.09518074989318848
Valid Loss:  0.10298790782690048
Epoch:  34  	Training Loss: 0.10539354383945465
Test Loss:  0.08013825863599777
Valid Loss:  0.08552739024162292
Epoch:  35  	Training Loss: 0.08834969997406006
Test Loss:  0.07076165080070496
Valid Loss:  0.07916294038295746
Epoch:  36  	Training Loss: 0.08112610876560211
Test Loss:  0.06566134840250015
Valid Loss:  0.07230094820261002
Epoch:  37  	Training Loss: 0.07444926351308823
Test Loss:  0.05785471200942993
Valid Loss:  0.06734825670719147
Epoch:  38  	Training Loss: 0.06872166693210602
Test Loss:  0.05424734950065613
Valid Loss:  0.061728335916996
Epoch:  39  	Training Loss: 0.06335796415805817
Test Loss:  0.047716762870550156
Valid Loss:  0.05779993534088135
Epoch:  40  	Training Loss: 0.05876195430755615
Test Loss:  0.045316748321056366
Valid Loss:  0.05329110100865364
Epoch:  41  	Training Loss: 0.05452248826622963
Test Loss:  0.039738476276397705
Valid Loss:  0.050154268741607666
Epoch:  42  	Training Loss: 0.05080101639032364
Test Loss:  0.02346087247133255
Valid Loss:  0.03615056723356247
Epoch:  43  	Training Loss: 0.036132849752902985
Test Loss:  0.01623782142996788
Valid Loss:  0.02911446988582611
Epoch:  44  	Training Loss: 0.028699107468128204
Test Loss:  0.011572232469916344
Valid Loss:  0.022889353334903717
Epoch:  45  	Training Loss: 0.02260553650557995
Test Loss:  0.008771926164627075
Valid Loss:  0.018536653369665146
Epoch:  46  	Training Loss: 0.018525468185544014
Test Loss:  0.007095285691320896
Valid Loss:  0.015570778399705887
Epoch:  47  	Training Loss: 0.01579185016453266
Test Loss:  0.0061039552092552185
Valid Loss:  0.01356829609721899
Epoch:  48  	Training Loss: 0.013967678882181644
Test Loss:  0.0055147018283605576
Valid Loss:  0.01225072517991066
Epoch:  49  	Training Loss: 0.012761903926730156
Test Loss:  0.005159345455467701
Valid Loss:  0.011377193033695221
Epoch:  50  	Training Loss: 0.011956244707107544
Test Loss:  0.004939798265695572
Valid Loss:  0.010800414718687534
Epoch:  51  	Training Loss: 0.011414960958063602
Test Loss:  0.004821653012186289
Valid Loss:  0.010397698730230331
Epoch:  52  	Training Loss: 0.011040767654776573
Test Loss:  0.004530349746346474
Valid Loss:  0.010273866355419159
Epoch:  53  	Training Loss: 0.010852839797735214
Test Loss:  0.004293672274798155
Valid Loss:  0.010103685781359673
Epoch:  54  	Training Loss: 0.010621724650263786
Test Loss:  0.004300473257899284
Valid Loss:  0.010044449009001255
Epoch:  55  	Training Loss: 0.010530702769756317
Test Loss:  0.00433829240500927
Valid Loss:  0.010037601925432682
Epoch:  56  	Training Loss: 0.010520752519369125
Test Loss:  0.0043658120557665825
Valid Loss:  0.010030636563897133
Epoch:  57  	Training Loss: 0.010517642833292484
Test Loss:  0.004387937020510435
Valid Loss:  0.010022955946624279
Epoch:  58  	Training Loss: 0.010515376925468445
Test Loss:  0.0044074757024645805
Valid Loss:  0.010015501640737057
Epoch:  59  	Training Loss: 0.01051345095038414
Test Loss:  0.004425366409122944
Valid Loss:  0.010008584707975388
Epoch:  60  	Training Loss: 0.010511776432394981
Test Loss:  0.004441970493644476
Valid Loss:  0.010002217255532742
Epoch:  61  	Training Loss: 0.01051032543182373
Test Loss:  0.004457414615899324
Valid Loss:  0.009996413253247738
Epoch:  62  	Training Loss: 0.010509056970477104
Test Loss:  0.005121909081935883
Valid Loss:  0.009667349979281425
Epoch:  63  	Training Loss: 0.010454438626766205
Test Loss:  0.008046440780162811
Valid Loss:  0.015655238181352615
Epoch:  64  	Training Loss: 0.01529709342867136
Test Loss:  0.01081375777721405
Valid Loss:  0.01321425847709179
Epoch:  65  	Training Loss: 0.014771097339689732
Test Loss:  0.0063341716304421425
Valid Loss:  0.010746643878519535
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.011769442819058895
Test Loss:  0.004129866603761911
Valid Loss:  0.0097148846834898
Epoch:  67  	Training Loss: 0.01029586885124445
Test Loss:  0.003908972721546888
Valid Loss:  0.009779565036296844
Epoch:  68  	Training Loss: 0.01025878544896841
Test Loss:  0.003926645498722792
Valid Loss:  0.009767690673470497
Epoch:  69  	Training Loss: 0.010256113484501839
Test Loss:  0.003927208948880434
Valid Loss:  0.009765494614839554
Epoch:  70  	Training Loss: 0.010253706015646458
Test Loss:  0.0039293100126087666
Valid Loss:  0.009762532077729702
Epoch:  71  	Training Loss: 0.010251308791339397
Test Loss:  0.003931418992578983
Valid Loss:  0.009759915992617607
Epoch:  72  	Training Loss: 0.010248932987451553
Test Loss:  0.0040739462710917
 15%|█▍        | 73/500 [01:00<07:33,  1.06s/it] 15%|█▌        | 75/500 [01:00<05:24,  1.31it/s] 15%|█▌        | 77/500 [01:00<03:54,  1.80it/s] 16%|█▌        | 79/500 [01:00<02:51,  2.46it/s] 16%|█▌        | 81/500 [01:06<08:26,  1.21s/it] 17%|█▋        | 83/500 [01:07<06:01,  1.15it/s] 17%|█▋        | 85/500 [01:07<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:07<03:09,  2.18it/s] 18%|█▊        | 89/500 [01:07<02:19,  2.94it/s] 18%|█▊        | 91/500 [01:13<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:13<05:43,  1.19it/s] 19%|█▉        | 95/500 [01:13<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:14<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:14<02:13,  3.01it/s] 20%|██        | 101/500 [01:20<07:47,  1.17s/it] 21%|██        | 103/500 [01:20<05:34,  1.19it/s] 21%|██        | 105/500 [01:20<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:20<02:55,  2.25it/s] 22%|██▏       | 109/500 [01:20<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:27<07:33,  1.17s/it] 23%|██▎       | 113/500 [01:27<05:24,  1.19it/s] 23%|██▎       | 115/500 [01:27<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:27<02:49,  2.25it/s] 24%|██▍       | 119/500 [01:27<02:05,  3.03it/s] 24%|██▍       | 121/500 [01:40<13:20,  2.11s/it] 25%|██▍       | 123/500 [01:40<09:25,  1.50s/it] 25%|██▌       | 125/500 [01:40<06:41,  1.07s/it] 25%|██▌       | 127/500 [01:40<04:46,  1.30it/s] 26%|██▌       | 129/500 [01:40<03:26,  1.79it/s] 26%|██▌       | 131/500 [01:47<08:08,  1.32s/it] 27%|██▋       | 133/500 [01:47<05:48,  1.05it/s] 27%|██▋       | 135/500 [01:47<04:09,  1.46it/s] 27%|██▋       | 137/500 [01:47<03:01,  2.00it/s] 28%|██▊       | 139/500 [01:47<02:13,  2.71it/s] 28%|██▊       | 141/500 [01:53<07:09,  1.20s/it]Valid Loss:  0.00959763489663601
Epoch:  73  	Training Loss: 0.010160581208765507
Test Loss:  0.004182289354503155
Valid Loss:  0.009494401514530182
Epoch:  74  	Training Loss: 0.010106908157467842
Test Loss:  0.00426130834966898
Valid Loss:  0.009424895979464054
Epoch:  75  	Training Loss: 0.010070465505123138
Test Loss:  0.004318132530897856
Valid Loss:  0.009375438094139099
Epoch:  76  	Training Loss: 0.01004309393465519
Test Loss:  0.004359485115855932
Valid Loss:  0.00933840312063694
Epoch:  77  	Training Loss: 0.010020971298217773
Test Loss:  0.004390495829284191
Valid Loss:  0.009309440851211548
Epoch:  78  	Training Loss: 0.010002338327467442
Test Loss:  0.004414370749145746
Valid Loss:  0.009286163374781609
Epoch:  79  	Training Loss: 0.009986313991248608
Test Loss:  0.004433430731296539
Valid Loss:  0.00926700234413147
Epoch:  80  	Training Loss: 0.009972335770726204
Test Loss:  0.004449413623660803
Valid Loss:  0.009250903502106667
Epoch:  81  	Training Loss: 0.009960073977708817
Test Loss:  0.004463371820747852
Valid Loss:  0.00923713855445385
Epoch:  82  	Training Loss: 0.009949270635843277
Test Loss:  0.004403429571539164
Valid Loss:  0.008246852084994316
Epoch:  83  	Training Loss: 0.008993747644126415
Test Loss:  0.005254722665995359
Valid Loss:  0.0072403233498334885
Epoch:  84  	Training Loss: 0.008609507232904434
Test Loss:  0.00456470949575305
Valid Loss:  0.007436233572661877
Epoch:  85  	Training Loss: 0.008507509715855122
Test Loss:  0.00464891642332077
Valid Loss:  0.0072932462207973
Epoch:  86  	Training Loss: 0.00845378264784813
Test Loss:  0.004551437683403492
Valid Loss:  0.007282380945980549
Epoch:  87  	Training Loss: 0.008419698104262352
Test Loss:  0.004500401206314564
Valid Loss:  0.0072591290809214115
Epoch:  88  	Training Loss: 0.00839330069720745
Test Loss:  0.004440471529960632
Valid Loss:  0.00725197046995163
Epoch:  89  	Training Loss: 0.008372340351343155
Test Loss:  0.00438685342669487
Valid Loss:  0.007248327136039734
Epoch:  90  	Training Loss: 0.0083551574498415
Test Loss:  0.004368094727396965
Valid Loss:  0.007232817355543375
Epoch:  91  	Training Loss: 0.008340004831552505
Test Loss:  0.00432478915899992
Valid Loss:  0.007232103496789932
Epoch:  92  	Training Loss: 0.008326634764671326
Test Loss:  0.0043189553543925285
Valid Loss:  0.007228736765682697
Epoch:  93  	Training Loss: 0.008322246372699738
Test Loss:  0.004313210025429726
Valid Loss:  0.007225411012768745
Epoch:  94  	Training Loss: 0.008317935280501842
Test Loss:  0.004307543393224478
Valid Loss:  0.007222174201160669
Epoch:  95  	Training Loss: 0.008313694968819618
Test Loss:  0.004301948472857475
Valid Loss:  0.007218976505100727
Epoch:  96  	Training Loss: 0.008309522643685341
Test Loss:  0.004296435974538326
Valid Loss:  0.007215850055217743
Epoch:  97  	Training Loss: 0.008305417373776436
Test Loss:  0.004291007295250893
Valid Loss:  0.007212786935269833
Epoch:  98  	Training Loss: 0.008301321417093277
Test Loss:  0.004285536706447601
Valid Loss:  0.00720971217378974
Epoch:  99  	Training Loss: 0.00829717330634594
Test Loss:  0.004280140623450279
Valid Loss:  0.007206690032035112
Epoch:  100  	Training Loss: 0.00829310528934002
Test Loss:  0.004274815320968628
Valid Loss:  0.007203736342489719
Epoch:  101  	Training Loss: 0.00828908383846283
Test Loss:  0.004269565921276808
Valid Loss:  0.0072008236311376095
Epoch:  102  	Training Loss: 0.008285132236778736
Test Loss:  0.0042631980031728745
Valid Loss:  0.007198195438832045
Epoch:  103  	Training Loss: 0.008280804380774498
Test Loss:  0.004256945103406906
Valid Loss:  0.007195628248155117
Epoch:  104  	Training Loss: 0.008276557549834251
Test Loss:  0.004250811412930489
Valid Loss:  0.007193122524768114
Epoch:  105  	Training Loss: 0.008272400125861168
Test Loss:  0.004244792275130749
Valid Loss:  0.007190668489784002
Epoch:  106  	Training Loss: 0.008268322795629501
Test Loss:  0.004238882102072239
Valid Loss:  0.007188279181718826
Epoch:  107  	Training Loss: 0.00826432928442955
Test Loss:  0.004233078099787235
Valid Loss:  0.007185948081314564
Epoch:  108  	Training Loss: 0.008260407485067844
Test Loss:  0.004227382596582174
Valid Loss:  0.007183665409684181
Epoch:  109  	Training Loss: 0.008256562985479832
Test Loss:  0.0042217932641506195
Valid Loss:  0.007181438151746988
Epoch:  110  	Training Loss: 0.008252792060375214
Test Loss:  0.004216301254928112
Valid Loss:  0.007179266307502985
Epoch:  111  	Training Loss: 0.008249097503721714
Test Loss:  0.00421091029420495
Valid Loss:  0.007177147548645735
Epoch:  112  	Training Loss: 0.008245466277003288
Test Loss:  0.004148588050156832
Valid Loss:  0.007213246542960405
Epoch:  113  	Training Loss: 0.008217794820666313
Test Loss:  0.004430715925991535
Valid Loss:  0.007021627388894558
Epoch:  114  	Training Loss: 0.008206401020288467
Test Loss:  0.004253469407558441
Valid Loss:  0.007172987796366215
Epoch:  115  	Training Loss: 0.008206747472286224
Test Loss:  0.004576372914016247
Valid Loss:  0.00695692328736186
Epoch:  116  	Training Loss: 0.00821438804268837
Test Loss:  0.00426722364500165
Valid Loss:  0.007218886166810989
Epoch:  117  	Training Loss: 0.008228462189435959
Test Loss:  0.004710650071501732
Valid Loss:  0.006927105598151684
Epoch:  118  	Training Loss: 0.008249135687947273
Test Loss:  0.004256041720509529
Valid Loss:  0.007324837148189545
Epoch:  119  	Training Loss: 0.008279584348201752
Test Loss:  0.004900950938463211
Valid Loss:  0.006921493913978338
Epoch:  120  	Training Loss: 0.008325111120939255
Test Loss:  0.004241129383444786
Valid Loss:  0.007534356787800789
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.008393716998398304
Test Loss:  0.004167405888438225
Valid Loss:  0.007031576707959175
Epoch:  122  	Training Loss: 0.007894111797213554
Test Loss:  0.004173186607658863
Valid Loss:  0.0069581493735313416
Epoch:  123  	Training Loss: 0.007849824614822865
Test Loss:  0.004177520517259836
Valid Loss:  0.006880367640405893
Epoch:  124  	Training Loss: 0.0077936905436217785
Test Loss:  0.004179830197244883
Valid Loss:  0.006775846239179373
Epoch:  125  	Training Loss: 0.007711776997894049
Test Loss:  0.004181831143796444
Valid Loss:  0.006627749651670456
Epoch:  126  	Training Loss: 0.007572305854409933
Test Loss:  0.004156508482992649
Valid Loss:  0.006436321418732405
Epoch:  127  	Training Loss: 0.007401136681437492
Test Loss:  0.004125154111534357
Valid Loss:  0.006277844775468111
Epoch:  128  	Training Loss: 0.007241252809762955
Test Loss:  0.004114081151783466
Valid Loss:  0.0061777811497449875
Epoch:  129  	Training Loss: 0.007141613867133856
Test Loss:  0.004118708893656731
Valid Loss:  0.006115525960922241
Epoch:  130  	Training Loss: 0.007095200940966606
Test Loss:  0.004118962679058313
Valid Loss:  0.00607509957626462
Epoch:  131  	Training Loss: 0.007068370468914509
Test Loss:  0.004111987538635731
Valid Loss:  0.006045301910489798
Epoch:  132  	Training Loss: 0.0070494418032467365
Test Loss:  0.00409533828496933
Valid Loss:  0.006046463269740343
Epoch:  133  	Training Loss: 0.007044643629342318
Test Loss:  0.004079377744346857
Valid Loss:  0.006047611124813557
Epoch:  134  	Training Loss: 0.007039859890937805
Test Loss:  0.0040639955550432205
Valid Loss:  0.006048882380127907
Epoch:  135  	Training Loss: 0.007035235874354839
Test Loss:  0.0040504406206309795
Valid Loss:  0.00604977086186409
Epoch:  136  	Training Loss: 0.007030942942947149
Test Loss:  0.004038387443870306
Valid Loss:  0.006050244905054569
Epoch:  137  	Training Loss: 0.007026853505522013
Test Loss:  0.004027623683214188
Valid Loss:  0.006050340365618467
Epoch:  138  	Training Loss: 0.007022912614047527
Test Loss:  0.004017969593405724
Valid Loss:  0.006050080060958862
Epoch:  139  	Training Loss: 0.0070190876722335815
Test Loss:  0.004009333439171314
Valid Loss:  0.006049529183655977
Epoch:  140  	Training Loss: 0.007015431299805641
Test Loss:  0.00400150939822197
Valid Loss:  0.006048702634871006
Epoch:  141  	Training Loss: 0.007011836860328913
Test Loss:  0.003994395956397057
Valid Loss:  0.006047616712749004
 29%|██▊       | 143/500 [01:53<05:06,  1.17it/s] 29%|██▉       | 145/500 [01:54<03:40,  1.61it/s] 29%|██▉       | 147/500 [01:54<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:54<01:58,  2.97it/s] 30%|███       | 151/500 [02:00<06:49,  1.17s/it] 31%|███       | 153/500 [02:00<04:52,  1.19it/s] 31%|███       | 155/500 [02:00<03:30,  1.64it/s] 31%|███▏      | 157/500 [02:01<02:33,  2.24it/s] 32%|███▏      | 159/500 [02:01<01:53,  3.01it/s] 32%|███▏      | 161/500 [02:07<06:34,  1.16s/it] 33%|███▎      | 163/500 [02:07<04:41,  1.20it/s] 33%|███▎      | 165/500 [02:07<03:22,  1.65it/s] 33%|███▎      | 167/500 [02:07<02:27,  2.26it/s] 34%|███▍      | 169/500 [02:07<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:14<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:14<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:14<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:14<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:14<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:21<06:23,  1.20s/it] 37%|███▋      | 183/500 [02:21<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:21<03:17,  1.59it/s] 37%|███▋      | 187/500 [02:21<02:23,  2.18it/s] 38%|███▊      | 189/500 [02:21<01:46,  2.93it/s] 38%|███▊      | 191/500 [02:28<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:28<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:28<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:28<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:28<01:41,  2.98it/s] 40%|████      | 201/500 [02:34<05:51,  1.18s/it] 41%|████      | 203/500 [02:35<04:10,  1.18it/s] 41%|████      | 205/500 [02:35<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:35<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:35<01:36,  3.01it/s]Epoch:  142  	Training Loss: 0.007008292246609926
Test Loss:  0.0039893402718007565
Valid Loss:  0.006046961061656475
Epoch:  143  	Training Loss: 0.0070055462419986725
Test Loss:  0.00398466270416975
Valid Loss:  0.006046160124242306
Epoch:  144  	Training Loss: 0.007002812810242176
Test Loss:  0.003980318550020456
Valid Loss:  0.006045238580554724
Epoch:  145  	Training Loss: 0.007000145502388477
Test Loss:  0.003976251929998398
Valid Loss:  0.006044205278158188
Epoch:  146  	Training Loss: 0.006997483782470226
Test Loss:  0.003972428385168314
Valid Loss:  0.006043077912181616
Epoch:  147  	Training Loss: 0.006994838360697031
Test Loss:  0.003968813456594944
Valid Loss:  0.006041865795850754
Epoch:  148  	Training Loss: 0.006992201320827007
Test Loss:  0.003965379670262337
Valid Loss:  0.006040584295988083
Epoch:  149  	Training Loss: 0.006989573128521442
Test Loss:  0.003962112590670586
Valid Loss:  0.006039234343916178
Epoch:  150  	Training Loss: 0.0069869514554739
Test Loss:  0.0039589861407876015
Valid Loss:  0.006037825718522072
Epoch:  151  	Training Loss: 0.006984345149248838
Test Loss:  0.0039560371078550816
Valid Loss:  0.006036388222128153
Epoch:  152  	Training Loss: 0.006981813348829746
Test Loss:  0.003955290652811527
Valid Loss:  0.00603385828435421
Epoch:  153  	Training Loss: 0.006980344653129578
Test Loss:  0.003954533953219652
Valid Loss:  0.006031387951225042
Epoch:  154  	Training Loss: 0.006978895049542189
Test Loss:  0.003953767940402031
Valid Loss:  0.006028980016708374
Epoch:  155  	Training Loss: 0.0069774747826159
Test Loss:  0.003953000530600548
Valid Loss:  0.006026623770594597
Epoch:  156  	Training Loss: 0.006976079661399126
Test Loss:  0.003952221944928169
Valid Loss:  0.006024329923093319
Epoch:  157  	Training Loss: 0.006974705494940281
Test Loss:  0.003951434977352619
Valid Loss:  0.0060220761224627495
Epoch:  158  	Training Loss: 0.006973353214561939
Test Loss:  0.00395063916221261
Valid Loss:  0.006019871681928635
Epoch:  159  	Training Loss: 0.006972021423280239
Test Loss:  0.003949841484427452
Valid Loss:  0.00601772777736187
Epoch:  160  	Training Loss: 0.0069707101210951805
Test Loss:  0.0039490289054811
Valid Loss:  0.006015624850988388
Epoch:  161  	Training Loss: 0.0069694118574261665
Test Loss:  0.003948209807276726
Valid Loss:  0.006013575010001659
Epoch:  162  	Training Loss: 0.006968138739466667
Test Loss:  0.003963155206292868
Valid Loss:  0.005989717319607735
Epoch:  163  	Training Loss: 0.0069595747627317905
Test Loss:  0.003973246552050114
Valid Loss:  0.005973769351840019
Epoch:  164  	Training Loss: 0.00695477519184351
Test Loss:  0.003982864320278168
Valid Loss:  0.005958907306194305
Epoch:  165  	Training Loss: 0.006950756534934044
Test Loss:  0.003989970777183771
Valid Loss:  0.005947872530668974
Epoch:  166  	Training Loss: 0.0069482335820794106
Test Loss:  0.003996708430349827
Valid Loss:  0.005937553942203522
Epoch:  167  	Training Loss: 0.00694596953690052
Test Loss:  0.004003078676760197
Valid Loss:  0.005927904509007931
Epoch:  168  	Training Loss: 0.006943920161575079
Test Loss:  0.004009104333817959
Valid Loss:  0.005918873008340597
Epoch:  169  	Training Loss: 0.006942077539861202
Test Loss:  0.00401540519669652
Valid Loss:  0.005910427309572697
Epoch:  170  	Training Loss: 0.006940416991710663
Test Loss:  0.004022922366857529
Valid Loss:  0.005902501754462719
Epoch:  171  	Training Loss: 0.006938901264220476
Test Loss:  0.004031109623610973
Valid Loss:  0.005895086098462343
Epoch:  172  	Training Loss: 0.006937531288713217
Test Loss:  0.00393783301115036
Valid Loss:  0.005736218765377998
Epoch:  173  	Training Loss: 0.006661864463239908
Test Loss:  0.003822488011792302
Valid Loss:  0.005564287770539522
Epoch:  174  	Training Loss: 0.0064018829725682735
Test Loss:  0.003707297844812274
Valid Loss:  0.005413617007434368
Epoch:  175  	Training Loss: 0.006170200649648905
Test Loss:  0.003593414556235075
Valid Loss:  0.005287796258926392
Epoch:  176  	Training Loss: 0.0059610288590192795
Test Loss:  0.0034842367749661207
Valid Loss:  0.005179266911000013
Epoch:  177  	Training Loss: 0.005767364054918289
Test Loss:  0.0033821449615061283
Valid Loss:  0.005076940171420574
Epoch:  178  	Training Loss: 0.005570378620177507
Test Loss:  0.0032896995544433594
Valid Loss:  0.0049891397356987
Epoch:  179  	Training Loss: 0.005392066203057766
Test Loss:  0.0032014837488532066
Valid Loss:  0.004913653247058392
Epoch:  180  	Training Loss: 0.005228557623922825
Test Loss:  0.003119847271591425
Valid Loss:  0.004848605953156948
Epoch:  181  	Training Loss: 0.005079722963273525
Test Loss:  0.003047853708267212
Valid Loss:  0.004795800428837538
Epoch:  182  	Training Loss: 0.004945439286530018
Test Loss:  0.00294832163490355
Valid Loss:  0.004714964888989925
Epoch:  183  	Training Loss: 0.004800828639417887
Test Loss:  0.002863530535250902
Valid Loss:  0.0046549104154109955
Epoch:  184  	Training Loss: 0.004676289856433868
Test Loss:  0.002784620737656951
Valid Loss:  0.0045774830505251884
Epoch:  185  	Training Loss: 0.0045621804893016815
Test Loss:  0.0027099528815597296
Valid Loss:  0.004500718787312508
Epoch:  186  	Training Loss: 0.004456472583115101
Test Loss:  0.0026393041480332613
Valid Loss:  0.004408532753586769
Epoch:  187  	Training Loss: 0.0043589770793914795
Test Loss:  0.0025741029530763626
Valid Loss:  0.004323545843362808
Epoch:  188  	Training Loss: 0.004269217606633902
Test Loss:  0.0025140419602394104
Valid Loss:  0.00424523651599884
Epoch:  189  	Training Loss: 0.00418727844953537
Test Loss:  0.0024587451480329037
Valid Loss:  0.004173130262643099
Epoch:  190  	Training Loss: 0.004109170753508806
Test Loss:  0.0024093342944979668
Valid Loss:  0.004100433550775051
Epoch:  191  	Training Loss: 0.004026510752737522
Test Loss:  0.002365417778491974
Valid Loss:  0.004028329625725746
Epoch:  192  	Training Loss: 0.003939332440495491
Test Loss:  0.0021928949281573296
Valid Loss:  0.0039853909984230995
Epoch:  193  	Training Loss: 0.0038720108568668365
Test Loss:  0.002103371312841773
Valid Loss:  0.003972535952925682
Epoch:  194  	Training Loss: 0.0038462430238723755
Test Loss:  0.002054354641586542
Valid Loss:  0.003968195058405399
Epoch:  195  	Training Loss: 0.0038350119721144438
Test Loss:  0.00202552299015224
Valid Loss:  0.00396667281165719
Epoch:  196  	Training Loss: 0.003829240333288908
Test Loss:  0.002007818315178156
Valid Loss:  0.003966121934354305
Epoch:  197  	Training Loss: 0.0038257574196904898
Test Loss:  0.0020020073279738426
Valid Loss:  0.003964596427977085
Epoch:  198  	Training Loss: 0.003823322942480445
Test Loss:  0.001997157232835889
Valid Loss:  0.003963183611631393
Epoch:  199  	Training Loss: 0.003821146208792925
Test Loss:  0.001995022175833583
Valid Loss:  0.003961688838899136
Epoch:  200  	Training Loss: 0.0038193664513528347
Test Loss:  0.0019927588291466236
Valid Loss:  0.003960406873375177
Epoch:  201  	Training Loss: 0.0038177690003067255
Test Loss:  0.0019904738292098045
Valid Loss:  0.00395930977538228
Epoch:  202  	Training Loss: 0.003816321725025773
Test Loss:  0.001996845006942749
Valid Loss:  0.00395410880446434
Epoch:  203  	Training Loss: 0.0038115913048386574
Test Loss:  0.0020031826570630074
Valid Loss:  0.003949673846364021
Epoch:  204  	Training Loss: 0.0038064513355493546
Test Loss:  0.0020071701146662235
Valid Loss:  0.00394462700933218
Epoch:  205  	Training Loss: 0.003794280346482992
Test Loss:  0.0020075333304703236
Valid Loss:  0.0039019703399389982
Epoch:  206  	Training Loss: 0.0037501519545912743
Test Loss:  0.0020045677665621042
Valid Loss:  0.0038944673724472523
Epoch:  207  	Training Loss: 0.003744221292436123
Test Loss:  0.002001448068767786
Valid Loss:  0.003892258508130908
Epoch:  208  	Training Loss: 0.0037418389692902565
Test Loss:  0.00199717516079545
Valid Loss:  0.003890113439410925
Epoch:  209  	Training Loss: 0.0037395302206277847
Test Loss:  0.00199402729049325
Valid Loss:  0.003888046368956566
Epoch:  210  	Training Loss: 0.003737269900739193
Test Loss:  0.001989754382520914
Valid Loss:  0.0038860258646309376
Epoch:  211  	Training Loss: 0.003735039848834276
Test Loss:  0.0019855762366205454
Valid Loss:   42%|████▏     | 211/500 [02:41<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:41<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:41<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:42<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:42<01:32,  3.03it/s] 44%|████▍     | 221/500 [02:48<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:48<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:48<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:48<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:49<01:29,  3.01it/s] 46%|████▌     | 231/500 [02:55<05:12,  1.16s/it] 47%|████▋     | 233/500 [02:55<03:43,  1.20it/s] 47%|████▋     | 235/500 [02:55<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:55<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:55<01:26,  3.03it/s] 48%|████▊     | 241/500 [03:02<05:01,  1.17s/it] 49%|████▊     | 243/500 [03:02<03:34,  1.20it/s] 49%|████▉     | 245/500 [03:02<02:34,  1.65it/s] 49%|████▉     | 247/500 [03:02<01:51,  2.26it/s] 50%|████▉     | 249/500 [03:02<01:22,  3.04it/s] 50%|█████     | 251/500 [03:08<04:55,  1.19s/it] 51%|█████     | 253/500 [03:09<03:30,  1.17it/s] 51%|█████     | 255/500 [03:09<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:09<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:09<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:15<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:15<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:16<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:16<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:16<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:22<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:22<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:22<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:23<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:23<01:14,  2.99it/s]0.0038840528577566147
Epoch:  212  	Training Loss: 0.0037328428588807583
Test Loss:  0.001982947811484337
Valid Loss:  0.0038855834864079952
Epoch:  213  	Training Loss: 0.003731381380930543
Test Loss:  0.0019814451225101948
Valid Loss:  0.0038845306262373924
Epoch:  214  	Training Loss: 0.0037301178090274334
Test Loss:  0.0019799063447862864
Valid Loss:  0.0038835937157273293
Epoch:  215  	Training Loss: 0.003728858893737197
Test Loss:  0.0019783745519816875
Valid Loss:  0.003882653545588255
Epoch:  216  	Training Loss: 0.003727603703737259
Test Loss:  0.0019768462516367435
Valid Loss:  0.0038817129097878933
Epoch:  217  	Training Loss: 0.0037263473495841026
Test Loss:  0.0019753228407353163
Valid Loss:  0.003880781354382634
Epoch:  218  	Training Loss: 0.003725099842995405
Test Loss:  0.0019738012924790382
Valid Loss:  0.003879848401993513
Epoch:  219  	Training Loss: 0.003723850939422846
Test Loss:  0.001972287893295288
Valid Loss:  0.003878912655636668
Epoch:  220  	Training Loss: 0.003722607158124447
Test Loss:  0.0019707740284502506
Valid Loss:  0.0038779869209975004
Epoch:  221  	Training Loss: 0.0037213671021163464
Test Loss:  0.0019692673813551664
Valid Loss:  0.003877053502947092
Epoch:  222  	Training Loss: 0.0037201261147856712
Test Loss:  0.0019813126418739557
Valid Loss:  0.003800490638241172
Epoch:  223  	Training Loss: 0.003636439796537161
Test Loss:  0.001990607473999262
Valid Loss:  0.003740486688911915
Epoch:  224  	Training Loss: 0.003564687678590417
Test Loss:  0.0020010012667626143
Valid Loss:  0.0036827765870839357
Epoch:  225  	Training Loss: 0.0034981013741344213
Test Loss:  0.0020130753982812166
Valid Loss:  0.0036083355080336332
Epoch:  226  	Training Loss: 0.003432248020544648
Test Loss:  0.0020251621026545763
Valid Loss:  0.00354300276376307
Epoch:  227  	Training Loss: 0.0033747348934412003
Test Loss:  0.0020371894352138042
Valid Loss:  0.0034851846285164356
Epoch:  228  	Training Loss: 0.0033221938647329807
Test Loss:  0.002050994662567973
Valid Loss:  0.0034278768580406904
Epoch:  229  	Training Loss: 0.0032670279033482075
Test Loss:  0.002064581960439682
Valid Loss:  0.003377386834472418
Epoch:  230  	Training Loss: 0.003217443823814392
Test Loss:  0.0020801399368792772
Valid Loss:  0.003327298443764448
Epoch:  231  	Training Loss: 0.0031635104678571224
Test Loss:  0.002095462055876851
Valid Loss:  0.003283210564404726
Epoch:  232  	Training Loss: 0.0031154348980635405
Test Loss:  0.0020018834620714188
Valid Loss:  0.0032431024592369795
Epoch:  233  	Training Loss: 0.0030697104521095753
Test Loss:  0.001947376993484795
Valid Loss:  0.0032219896093010902
Epoch:  234  	Training Loss: 0.003047846257686615
Test Loss:  0.0019195552449673414
Valid Loss:  0.0032113795168697834
Epoch:  235  	Training Loss: 0.0030403053387999535
Test Loss:  0.0019056156743317842
Valid Loss:  0.0032049971632659435
Epoch:  236  	Training Loss: 0.003036743961274624
Test Loss:  0.0018944503972306848
Valid Loss:  0.0031995889730751514
Epoch:  237  	Training Loss: 0.0030343111138790846
Test Loss:  0.0018895709654316306
Valid Loss:  0.003195814322680235
Epoch:  238  	Training Loss: 0.003032718552276492
Test Loss:  0.0018891231156885624
Valid Loss:  0.003193426877260208
Epoch:  239  	Training Loss: 0.0030317013151943684
Test Loss:  0.0018881041323766112
Valid Loss:  0.003191249445080757
Epoch:  240  	Training Loss: 0.003030879655852914
Test Loss:  0.0018867513863369823
Valid Loss:  0.003189248964190483
Epoch:  241  	Training Loss: 0.0030302051454782486
Test Loss:  0.0018852174980565906
Valid Loss:  0.00318740401417017
Epoch:  242  	Training Loss: 0.003029637038707733
Test Loss:  0.0018753880867734551
Valid Loss:  0.003183194436132908
Epoch:  243  	Training Loss: 0.003026622347533703
Test Loss:  0.00186773925088346
Valid Loss:  0.0031796214170753956
Epoch:  244  	Training Loss: 0.003024072851985693
Test Loss:  0.0018680839566513896
Valid Loss:  0.003178433747962117
Epoch:  245  	Training Loss: 0.0030215049628168344
Test Loss:  0.0018593624699860811
Valid Loss:  0.0031748036853969097
Epoch:  246  	Training Loss: 0.003018914954736829
Test Loss:  0.0018518901197239757
Valid Loss:  0.0031715575605630875
Epoch:  247  	Training Loss: 0.003016476985067129
Test Loss:  0.0018452983349561691
Valid Loss:  0.003168602706864476
Epoch:  248  	Training Loss: 0.0030142520554363728
Test Loss:  0.0018464941531419754
Valid Loss:  0.003167901188135147
Epoch:  249  	Training Loss: 0.0030121058225631714
Test Loss:  0.0018385779112577438
Valid Loss:  0.0031647959258407354
Epoch:  250  	Training Loss: 0.0030099935829639435
Test Loss:  0.0018326323479413986
Valid Loss:  0.0031622101087123156
Epoch:  251  	Training Loss: 0.0030080501455813646
Test Loss:  0.0018272679299116135
Valid Loss:  0.003159820567816496
Epoch:  252  	Training Loss: 0.0030061881989240646
Test Loss:  0.0018444625893607736
Valid Loss:  0.0030959302093833685
Epoch:  253  	Training Loss: 0.0029408808331936598
Test Loss:  0.00186060625128448
Valid Loss:  0.0030404836870729923
Epoch:  254  	Training Loss: 0.0028838273137807846
Test Loss:  0.0018756480421870947
Valid Loss:  0.0029918402433395386
Epoch:  255  	Training Loss: 0.0028334828093647957
Test Loss:  0.0018901326693594456
Valid Loss:  0.002948699053376913
Epoch:  256  	Training Loss: 0.0027888379991054535
Test Loss:  0.0019042338244616985
Valid Loss:  0.0029105080757290125
Epoch:  257  	Training Loss: 0.0027461242862045765
Test Loss:  0.0019196970388293266
Valid Loss:  0.0028724928852170706
Epoch:  258  	Training Loss: 0.002701699733734131
Test Loss:  0.0019357395358383656
Valid Loss:  0.0028393720276653767
Epoch:  259  	Training Loss: 0.002659956458956003
Test Loss:  0.0019542714580893517
Valid Loss:  0.0028071878477931023
Epoch:  260  	Training Loss: 0.002615896752104163
Test Loss:  0.0019715665839612484
Valid Loss:  0.0027783173136413097
Epoch:  261  	Training Loss: 0.0025744333397597075
Test Loss:  0.0019906661473214626
Valid Loss:  0.002749837702140212
Epoch:  262  	Training Loss: 0.0025292844511568546
Test Loss:  0.001980127999559045
Valid Loss:  0.002745294477790594
Epoch:  263  	Training Loss: 0.002524781506508589
Test Loss:  0.001971539808437228
Valid Loss:  0.0027419000398367643
Epoch:  264  	Training Loss: 0.0025214157067239285
Test Loss:  0.0019644740968942642
Valid Loss:  0.0027393184136599302
Epoch:  265  	Training Loss: 0.0025188629515469074
Test Loss:  0.0019586014095693827
Valid Loss:  0.002737328177317977
Epoch:  266  	Training Loss: 0.0025168880820274353
Test Loss:  0.0019536768086254597
Valid Loss:  0.002735756104812026
Epoch:  267  	Training Loss: 0.0025153374299407005
Test Loss:  0.0019495075102895498
Valid Loss:  0.00273448065854609
Epoch:  268  	Training Loss: 0.0025140841025859118
Test Loss:  0.0019459426403045654
Valid Loss:  0.0027334268670529127
Epoch:  269  	Training Loss: 0.0025129723362624645
Test Loss:  0.001942258095368743
Valid Loss:  0.0027324128895998
Epoch:  270  	Training Loss: 0.00251190597191453
Test Loss:  0.0019390657544136047
Valid Loss:  0.002731537912040949
Epoch:  271  	Training Loss: 0.002511001657694578
Test Loss:  0.0019362682942301035
Valid Loss:  0.0027307758573442698
Epoch:  272  	Training Loss: 0.0025102151557803154
Test Loss:  0.001920376904308796
Valid Loss:  0.0026850509457290173
Epoch:  273  	Training Loss: 0.0024483799934387207
Test Loss:  0.0019087963737547398
Valid Loss:  0.002637662226334214
Epoch:  274  	Training Loss: 0.0023907837457954884
Test Loss:  0.0018998843152076006
Valid Loss:  0.0025816215202212334
Epoch:  275  	Training Loss: 0.002336618024855852
Test Loss:  0.0018939182627946138
Valid Loss:  0.002528744749724865
Epoch:  276  	Training Loss: 0.0022856236901134253
Test Loss:  0.0018748195143416524
Valid Loss:  0.002478791866451502
Epoch:  277  	Training Loss: 0.002237576525658369
Test Loss:  0.0018592135747894645
Valid Loss:  0.0024315763730555773
Epoch:  278  	Training Loss: 0.002192378044128418
Test Loss:  0.0018455561948940158
Valid Loss:  0.0023873811587691307
Epoch:  279  	Training Loss: 0.002149805426597595
Test Loss:  0.0018328225705772638
Valid Loss:  0.0023455191403627396
Epoch:  280  	Training Loss: 0.0021097976714372635
Test Loss:  0.0018215905874967575
 56%|█████▌    | 281/500 [03:29<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:29<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:29<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:29<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:29<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:36<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:36<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:36<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:36<01:32,  2.21it/s] 60%|█████▉    | 299/500 [03:36<01:07,  2.97it/s] 60%|██████    | 301/500 [03:43<03:52,  1.17s/it] 61%|██████    | 303/500 [03:43<02:45,  1.19it/s] 61%|██████    | 305/500 [03:43<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:43<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:43<01:03,  3.03it/s] 62%|██████▏   | 311/500 [03:56<06:37,  2.10s/it] 63%|██████▎   | 313/500 [03:56<04:39,  1.49s/it] 63%|██████▎   | 315/500 [03:56<03:17,  1.07s/it] 63%|██████▎   | 317/500 [03:56<02:20,  1.30it/s] 64%|██████▍   | 319/500 [03:56<01:41,  1.79it/s] 64%|██████▍   | 321/500 [04:03<04:01,  1.35s/it] 65%|██████▍   | 323/500 [04:03<02:51,  1.03it/s] 65%|██████▌   | 325/500 [04:03<02:01,  1.44it/s] 65%|██████▌   | 327/500 [04:03<01:27,  1.97it/s] 66%|██████▌   | 329/500 [04:03<01:04,  2.65it/s] 66%|██████▌   | 331/500 [04:10<03:28,  1.23s/it] 67%|██████▋   | 333/500 [04:10<02:27,  1.13it/s] 67%|██████▋   | 335/500 [04:10<01:45,  1.56it/s] 67%|██████▋   | 337/500 [04:10<01:16,  2.14it/s] 68%|██████▊   | 339/500 [04:10<00:55,  2.89it/s] 68%|██████▊   | 341/500 [04:17<03:11,  1.20s/it] 69%|██████▊   | 343/500 [04:17<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:17<01:36,  1.60it/s] 69%|██████▉   | 347/500 [04:17<01:09,  2.19it/s]Valid Loss:  0.0023062541149556637
Epoch:  281  	Training Loss: 0.0020724660716950893
Test Loss:  0.0018109297379851341
Valid Loss:  0.0022689728066325188
Epoch:  282  	Training Loss: 0.0020374308805912733
Test Loss:  0.0018182474886998534
Valid Loss:  0.0022445181384682655
Epoch:  283  	Training Loss: 0.0020110411569476128
Test Loss:  0.0018247361294925213
Valid Loss:  0.002222792012616992
Epoch:  284  	Training Loss: 0.0019875578582286835
Test Loss:  0.001830466790124774
Valid Loss:  0.0022033515851944685
Epoch:  285  	Training Loss: 0.001964377239346504
Test Loss:  0.0018369887256994843
Valid Loss:  0.002183712087571621
Epoch:  286  	Training Loss: 0.0019399919547140598
Test Loss:  0.001842902391217649
Valid Loss:  0.0021660947240889072
Epoch:  287  	Training Loss: 0.001917859772220254
Test Loss:  0.0018388591706752777
Valid Loss:  0.002150221262127161
Epoch:  288  	Training Loss: 0.0018976995488628745
Test Loss:  0.0018334182677790523
Valid Loss:  0.0021358616650104523
Epoch:  289  	Training Loss: 0.0018792538903653622
Test Loss:  0.0018278645584359765
Valid Loss:  0.0021228198893368244
Epoch:  290  	Training Loss: 0.0018623278010636568
Test Loss:  0.0018222585786134005
Valid Loss:  0.0021109499502927065
Epoch:  291  	Training Loss: 0.0018467609770596027
Test Loss:  0.001816642819903791
Valid Loss:  0.002100126352161169
Epoch:  292  	Training Loss: 0.001832408830523491
Test Loss:  0.0017877384088933468
Valid Loss:  0.0020755669102072716
Epoch:  293  	Training Loss: 0.0018160766921937466
Test Loss:  0.0017654448747634888
Valid Loss:  0.0020574412774294615
Epoch:  294  	Training Loss: 0.0018050175858661532
Test Loss:  0.001747993053868413
Valid Loss:  0.002043547574430704
Epoch:  295  	Training Loss: 0.0017972372006624937
Test Loss:  0.0017351864371448755
Valid Loss:  0.002032688818871975
Epoch:  296  	Training Loss: 0.0017916688229888678
Test Loss:  0.0017243141774088144
Valid Loss:  0.002023544628173113
Epoch:  297  	Training Loss: 0.001787504879757762
Test Loss:  0.001716256607323885
Valid Loss:  0.002016720362007618
Epoch:  298  	Training Loss: 0.0017848113784566522
Test Loss:  0.0017098607495427132
Valid Loss:  0.0020112255588173866
Epoch:  299  	Training Loss: 0.0017827310366556048
Test Loss:  0.0017049184534698725
Valid Loss:  0.0020068606827408075
Epoch:  300  	Training Loss: 0.0017812926089391112
Test Loss:  0.0017017638310790062
Valid Loss:  0.002003439236432314
Epoch:  301  	Training Loss: 0.0017801686190068722
Test Loss:  0.0016992617165669799
Valid Loss:  0.0020003076642751694
Epoch:  302  	Training Loss: 0.0017790442798286676
Test Loss:  0.001699260901659727
Valid Loss:  0.002000307198613882
Epoch:  303  	Training Loss: 0.001779044046998024
Test Loss:  0.001699263695627451
Valid Loss:  0.0020003062672913074
Epoch:  304  	Training Loss: 0.0017790442798286676
Test Loss:  0.0016992621822282672
Valid Loss:  0.002000307198613882
Epoch:  305  	Training Loss: 0.0017790434649214149
Test Loss:  0.0016992626478895545
Valid Loss:  0.002000304637476802
Epoch:  306  	Training Loss: 0.001779044046998024
Test Loss:  0.0016992621822282672
Valid Loss:  0.002000307198613882
Epoch:  307  	Training Loss: 0.0017790438141673803
Test Loss:  0.0016992625314742327
Valid Loss:  0.0020003048703074455
Epoch:  308  	Training Loss: 0.0017790431156754494
Test Loss:  0.0016992621822282672
Valid Loss:  0.002000303938984871
Epoch:  309  	Training Loss: 0.0017790429992601275
Test Loss:  0.0016992620658129454
Valid Loss:  0.0020003062672913074
Epoch:  310  	Training Loss: 0.0017790428828448057
Test Loss:  0.00169926299713552
Valid Loss:  0.002000305103138089
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.001779042067937553
Test Loss:  0.0016998338978737593
Valid Loss:  0.0020003297831863165
Epoch:  312  	Training Loss: 0.0017788480035960674
Test Loss:  0.0016979762585833669
Valid Loss:  0.0019987616688013077
Epoch:  313  	Training Loss: 0.0017784773372113705
Test Loss:  0.001696209073998034
Valid Loss:  0.001997274812310934
Epoch:  314  	Training Loss: 0.0017781390342861414
Test Loss:  0.0016945236129686236
Valid Loss:  0.001995878992602229
Epoch:  315  	Training Loss: 0.0017778829205781221
Test Loss:  0.0016934573650360107
Valid Loss:  0.001994847785681486
Epoch:  316  	Training Loss: 0.0017777085304260254
Test Loss:  0.001692452933639288
Valid Loss:  0.0019938666373491287
Epoch:  317  	Training Loss: 0.0017775529995560646
Test Loss:  0.0016914918087422848
Valid Loss:  0.0019929399713873863
Epoch:  318  	Training Loss: 0.0017774051520973444
Test Loss:  0.0016905749216675758
Valid Loss:  0.0019920524209737778
Epoch:  319  	Training Loss: 0.0017772726714611053
Test Loss:  0.0016896968008950353
Valid Loss:  0.0019912151619791985
Epoch:  320  	Training Loss: 0.001777147059328854
Test Loss:  0.001688856165856123
Valid Loss:  0.001990414224565029
Epoch:  321  	Training Loss: 0.001777032157406211
Test Loss:  0.0016880540642887354
Valid Loss:  0.001989657524973154
Epoch:  322  	Training Loss: 0.001776927150785923
Test Loss:  0.001644347095862031
Valid Loss:  0.001964376075193286
Epoch:  323  	Training Loss: 0.0017543097492307425
Test Loss:  0.0016158695798367262
Valid Loss:  0.0019453340210020542
Epoch:  324  	Training Loss: 0.0017360683996230364
Test Loss:  0.0015928952489048243
Valid Loss:  0.001928516197949648
Epoch:  325  	Training Loss: 0.0017192105296999216
Test Loss:  0.0015731953317299485
Valid Loss:  0.001913208863697946
Epoch:  326  	Training Loss: 0.0017034364864230156
Test Loss:  0.0015565380454063416
Valid Loss:  0.001899502007290721
Epoch:  327  	Training Loss: 0.0016886158846318722
Test Loss:  0.0015425062738358974
Valid Loss:  0.0018871017964556813
Epoch:  328  	Training Loss: 0.0016745023895055056
Test Loss:  0.0015297317877411842
Valid Loss:  0.0018753551412373781
Epoch:  329  	Training Loss: 0.001660953857935965
Test Loss:  0.0015181989874690771
Valid Loss:  0.0018618713365867734
Epoch:  330  	Training Loss: 0.0016460351180285215
Test Loss:  0.0015355662908405066
Valid Loss:  0.0018630718113854527
Epoch:  331  	Training Loss: 0.001632558647543192
Test Loss:  0.001492328941822052
Valid Loss:  0.0018377742962911725
Epoch:  332  	Training Loss: 0.0016145469853654504
Test Loss:  0.0014908828306943178
Valid Loss:  0.0018356629880145192
Epoch:  333  	Training Loss: 0.0016133928438648582
Test Loss:  0.001490183174610138
Valid Loss:  0.0018340605311095715
Epoch:  334  	Training Loss: 0.0016123875975608826
Test Loss:  0.001489478163421154
Valid Loss:  0.0018325024284422398
Epoch:  335  	Training Loss: 0.001611450221389532
Test Loss:  0.001488779205828905
Valid Loss:  0.0018309794832020998
Epoch:  336  	Training Loss: 0.0016105741960927844
Test Loss:  0.0014880861854180694
Valid Loss:  0.0018294950714334846
Epoch:  337  	Training Loss: 0.0016097547486424446
Test Loss:  0.001487404340878129
Valid Loss:  0.0018280535005033016
Epoch:  338  	Training Loss: 0.0016089902492240071
Test Loss:  0.0014867337886244059
Valid Loss:  0.00182665407191962
Epoch:  339  	Training Loss: 0.00160827930085361
Test Loss:  0.0014865882694721222
Valid Loss:  0.0018257882911711931
Epoch:  340  	Training Loss: 0.0016077032778412104
Test Loss:  0.0014864045660942793
Valid Loss:  0.0018249151762574911
Epoch:  341  	Training Loss: 0.0016071682330220938
Test Loss:  0.0014861839590594172
Valid Loss:  0.0018240476492792368
Epoch:  342  	Training Loss: 0.0016066741663962603
Test Loss:  0.0014860157389193773
Valid Loss:  0.0018239704659208655
Epoch:  343  	Training Loss: 0.001606535166501999
Test Loss:  0.0014858380891382694
Valid Loss:  0.0018238922348245978
Epoch:  344  	Training Loss: 0.0016063977964222431
Test Loss:  0.0014856619527563453
Valid Loss:  0.001823818776756525
Epoch:  345  	Training Loss: 0.0016062618233263493
Test Loss:  0.0014854853507131338
Valid Loss:  0.0018237396143376827
Epoch:  346  	Training Loss: 0.001606128877028823
Test Loss:  0.001485306303948164
Valid Loss:  0.0018236631294712424
Epoch:  347  	Training Loss: 0.0016059961635619402
Test Loss:  0.001485125278122723
Valid Loss:  0.0018235882744193077
Epoch:  348  	Training Loss: 0.0016058674082159996
 70%|██████▉   | 349/500 [04:17<00:51,  2.95it/s] 70%|███████   | 351/500 [04:23<02:56,  1.18s/it] 71%|███████   | 353/500 [04:24<02:04,  1.18it/s] 71%|███████   | 355/500 [04:24<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:24<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:24<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:30<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:30<01:54,  1.19it/s] 73%|███████▎  | 365/500 [04:30<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:31<00:58,  2.26it/s] 74%|███████▍  | 369/500 [04:31<00:43,  3.04it/s] 74%|███████▍  | 371/500 [04:37<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:37<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:37<01:16,  1.62it/s] 75%|███████▌  | 377/500 [04:37<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:38<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:44<02:22,  1.19s/it] 77%|███████▋  | 383/500 [04:44<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:44<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:44<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:45<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:51<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:51<01:31,  1.18it/s] 79%|███████▉  | 395/500 [04:51<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:51<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:51<00:33,  2.99it/s] 80%|████████  | 401/500 [04:58<01:55,  1.17s/it] 81%|████████  | 403/500 [04:58<01:21,  1.19it/s] 81%|████████  | 405/500 [04:58<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:58<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:58<00:30,  3.02it/s] 82%|████████▏ | 411/500 [05:04<01:44,  1.18s/it] 83%|████████▎ | 413/500 [05:05<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:05<00:51,  1.64it/s]Test Loss:  0.0014849408762529492
Valid Loss:  0.0018235170282423496
Epoch:  349  	Training Loss: 0.0016057412140071392
Test Loss:  0.0014847543789073825
Valid Loss:  0.001823442056775093
Epoch:  350  	Training Loss: 0.0016056140884757042
Test Loss:  0.0014845688128843904
Valid Loss:  0.0018233718583360314
Epoch:  351  	Training Loss: 0.0016054901061579585
Test Loss:  0.001484378706663847
Valid Loss:  0.0018233043374493718
Epoch:  352  	Training Loss: 0.0016053663566708565
Test Loss:  0.0014843465760350227
Valid Loss:  0.001823187107220292
Epoch:  353  	Training Loss: 0.0016051008133217692
Test Loss:  0.0014843185199424624
Valid Loss:  0.0018230814021080732
Epoch:  354  	Training Loss: 0.0016048444667831063
Test Loss:  0.001484285923652351
Valid Loss:  0.0018229768611490726
Epoch:  355  	Training Loss: 0.0016045968513935804
Test Loss:  0.0014842592645436525
Valid Loss:  0.0018228765111416578
Epoch:  356  	Training Loss: 0.0016043554060161114
Test Loss:  0.0014842324890196323
Valid Loss:  0.001822778256610036
Epoch:  357  	Training Loss: 0.0016041216440498829
Test Loss:  0.0014842075761407614
Valid Loss:  0.001822686055675149
Epoch:  358  	Training Loss: 0.0016038940520957112
Test Loss:  0.0014841845259070396
Valid Loss:  0.0018225960666313767
Epoch:  359  	Training Loss: 0.0016036730958148837
Test Loss:  0.0014841619413346052
Valid Loss:  0.001822509104385972
Epoch:  360  	Training Loss: 0.0016034587752074003
Test Loss:  0.001484138541854918
Valid Loss:  0.0018224261002615094
Epoch:  361  	Training Loss: 0.0016032503917813301
Test Loss:  0.0014841158408671618
Valid Loss:  0.0018223485676571727
Epoch:  362  	Training Loss: 0.0016030456172302365
Test Loss:  0.001486875582486391
Valid Loss:  0.001817433163523674
Epoch:  363  	Training Loss: 0.0015944079495966434
Test Loss:  0.0014865511329844594
Valid Loss:  0.0018111388199031353
Epoch:  364  	Training Loss: 0.0015863582957535982
Test Loss:  0.0014860425144433975
Valid Loss:  0.0018049718346446753
Epoch:  365  	Training Loss: 0.001578710856847465
Test Loss:  0.0014852837193757296
Valid Loss:  0.0017988434992730618
Epoch:  366  	Training Loss: 0.0015714658657088876
Test Loss:  0.0014853609027341008
Valid Loss:  0.001793903298676014
Epoch:  367  	Training Loss: 0.001564667676575482
Test Loss:  0.0014844723045825958
Valid Loss:  0.001788591267541051
Epoch:  368  	Training Loss: 0.0015582132618874311
Test Loss:  0.0014840150251984596
Valid Loss:  0.0017839466454461217
Epoch:  369  	Training Loss: 0.0015520991291850805
Test Loss:  0.0014834158355370164
Valid Loss:  0.0017793718725442886
Epoch:  370  	Training Loss: 0.001546288374811411
Test Loss:  0.0014821281656622887
Valid Loss:  0.0017744629876688123
Epoch:  371  	Training Loss: 0.0015406357124447823
Test Loss:  0.0014813810121268034
Valid Loss:  0.0017700521275401115
Epoch:  372  	Training Loss: 0.0015351896872743964
Test Loss:  0.0014791530556976795
Valid Loss:  0.0017625479958951473
Epoch:  373  	Training Loss: 0.0015297636855393648
Test Loss:  0.0014767893590033054
Valid Loss:  0.0017539368709549308
Epoch:  374  	Training Loss: 0.0015244698151946068
Test Loss:  0.0014743262436240911
Valid Loss:  0.0017453818581998348
Epoch:  375  	Training Loss: 0.001519296201877296
Test Loss:  0.001471781637519598
Valid Loss:  0.0017368965782225132
Epoch:  376  	Training Loss: 0.0015142611227929592
Test Loss:  0.0014694217825308442
Valid Loss:  0.001728792442008853
Epoch:  377  	Training Loss: 0.001509497407823801
Test Loss:  0.0014672285178676248
Valid Loss:  0.0017210477963089943
Epoch:  378  	Training Loss: 0.0015049950452521443
Test Loss:  0.0014657822903245687
Valid Loss:  0.001714246580377221
Epoch:  379  	Training Loss: 0.0015007563633844256
Test Loss:  0.001464140834286809
Valid Loss:  0.0017074088100343943
Epoch:  380  	Training Loss: 0.001496636774390936
Test Loss:  0.0014623376773670316
Valid Loss:  0.0017005567206069827
Epoch:  381  	Training Loss: 0.0014925834257155657
Test Loss:  0.0014604063471779227
Valid Loss:  0.0016930272104218602
Epoch:  382  	Training Loss: 0.0014872429892420769
Test Loss:  0.001461130566895008
Valid Loss:  0.0016920077614486217
Epoch:  383  	Training Loss: 0.0014841188676655293
Test Loss:  0.0014619659632444382
Valid Loss:  0.0016916858730837703
Epoch:  384  	Training Loss: 0.001482186489738524
Test Loss:  0.0014626727206632495
Valid Loss:  0.00169166992418468
Epoch:  385  	Training Loss: 0.001480931881815195
Test Loss:  0.0014631629455834627
Valid Loss:  0.001691747922450304
Epoch:  386  	Training Loss: 0.0014800612116232514
Test Loss:  0.0014634262770414352
Valid Loss:  0.0016918308101594448
Epoch:  387  	Training Loss: 0.001479409635066986
Test Loss:  0.0014634806429967284
Valid Loss:  0.0016918727196753025
Epoch:  388  	Training Loss: 0.0014788811095058918
Test Loss:  0.0014633511891588569
Valid Loss:  0.0016918608453124762
Epoch:  389  	Training Loss: 0.0014784233644604683
Test Loss:  0.0014630818041041493
Valid Loss:  0.0016917982138693333
Epoch:  390  	Training Loss: 0.001478009158745408
Test Loss:  0.0014626929769292474
Valid Loss:  0.0016916883178055286
Epoch:  391  	Training Loss: 0.0014776161406189203
Test Loss:  0.0014622181188315153
Valid Loss:  0.0016915410524234176
Epoch:  392  	Training Loss: 0.001477241050451994
Test Loss:  0.0014615985564887524
Valid Loss:  0.0016910264967009425
Epoch:  393  	Training Loss: 0.0014771902933716774
Test Loss:  0.0014610422076657414
Valid Loss:  0.0016905611846596003
Epoch:  394  	Training Loss: 0.0014771466376259923
Test Loss:  0.00146053871139884
Valid Loss:  0.0016901525668799877
Epoch:  395  	Training Loss: 0.0014771042624488473
Test Loss:  0.001460084575228393
Valid Loss:  0.0016897883033379912
Epoch:  396  	Training Loss: 0.0014770682901144028
Test Loss:  0.0014596725814044476
Valid Loss:  0.0016894610598683357
Epoch:  397  	Training Loss: 0.0014770310372114182
Test Loss:  0.001459300983697176
Valid Loss:  0.0016891706036403775
Epoch:  398  	Training Loss: 0.001476998906582594
Test Loss:  0.001458964659832418
Valid Loss:  0.0016889098333194852
Epoch:  399  	Training Loss: 0.0014769657282158732
Test Loss:  0.001458657905459404
Valid Loss:  0.0016886761877685785
Epoch:  400  	Training Loss: 0.0014769358094781637
Test Loss:  0.0014583736192435026
Valid Loss:  0.0016884636133909225
Epoch:  401  	Training Loss: 0.001476904610171914
Test Loss:  0.0014581186696887016
Valid Loss:  0.0016882787458598614
Epoch:  402  	Training Loss: 0.0014768759720027447
Test Loss:  0.0014564533485099673
Valid Loss:  0.0016873714048415422
Epoch:  403  	Training Loss: 0.001476379344239831
Test Loss:  0.001454817713238299
Valid Loss:  0.0016864845529198647
Epoch:  404  	Training Loss: 0.00147589563857764
Test Loss:  0.0014532152563333511
Valid Loss:  0.001685618539340794
Epoch:  405  	Training Loss: 0.0014754235744476318
Test Loss:  0.0014516450464725494
Valid Loss:  0.0016847731312736869
Epoch:  406  	Training Loss: 0.0014749637339264154
Test Loss:  0.0014501034747809172
Valid Loss:  0.0016839406453073025
Epoch:  407  	Training Loss: 0.00147452752571553
Test Loss:  0.0014486820437014103
Valid Loss:  0.0016832291148602962
Epoch:  408  	Training Loss: 0.001474128570407629
Test Loss:  0.0014473814517259598
Valid Loss:  0.0016826256178319454
Epoch:  409  	Training Loss: 0.0014737523160874844
Test Loss:  0.0014461020473390818
Valid Loss:  0.001682037254795432
Epoch:  410  	Training Loss: 0.0014733870048075914
Test Loss:  0.001444848719984293
Valid Loss:  0.001681458204984665
Epoch:  411  	Training Loss: 0.001473029376938939
Test Loss:  0.0014436180936172605
Valid Loss:  0.0016808948712423444
Epoch:  412  	Training Loss: 0.0014726795488968492
Test Loss:  0.0014442121610045433
Valid Loss:  0.0016806486528366804
Epoch:  413  	Training Loss: 0.0014720708131790161
Test Loss:  0.0014447907451540232
Valid Loss:  0.0016804557526484132
Epoch:  414  	Training Loss: 0.0014715295983478427
Test Loss:  0.0014453516341745853
Valid Loss:  0.0016803020844236016
Epoch:  415  	Training Loss: 0.0014710495015606284
Test Loss:  0.0014458929654210806
Valid Loss:  0.0016801791498437524
Epoch:  416  	Training Loss: 0.0014705582289025187
Test Loss:  0.0014465319691225886
Valid Loss:  0.001680075190961361
 83%|████████▎ | 417/500 [05:05<00:37,  2.24it/s] 84%|████████▍ | 419/500 [05:05<00:26,  3.01it/s] 84%|████████▍ | 421/500 [05:11<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:11<01:04,  1.19it/s] 85%|████████▌ | 425/500 [05:12<00:45,  1.65it/s] 85%|████████▌ | 427/500 [05:12<00:32,  2.25it/s] 86%|████████▌ | 429/500 [05:12<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:18<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:18<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:18<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:18<00:27,  2.25it/s] 88%|████████▊ | 439/500 [05:19<00:20,  3.03it/s] 88%|████████▊ | 441/500 [05:25<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:25<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:25<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:25<00:23,  2.26it/s] 90%|████████▉ | 449/500 [05:25<00:16,  3.04it/s] 90%|█████████ | 451/500 [05:32<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:32<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:32<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:32<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:32<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:39<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:39<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:39<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:39<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:39<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:45<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:46<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:46<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:46<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:46<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:52<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:52<00:14,  1.18it/s]Epoch:  417  	Training Loss: 0.001470035407692194
Test Loss:  0.001447147922590375
Valid Loss:  0.001680002547800541
Epoch:  418  	Training Loss: 0.0014695697464048862
Test Loss:  0.001447735819965601
Valid Loss:  0.001679785898886621
Epoch:  419  	Training Loss: 0.0014691527467221022
Test Loss:  0.0014482960104942322
Valid Loss:  0.0016794970724731684
Epoch:  420  	Training Loss: 0.001468779519200325
Test Loss:  0.0014488287270069122
Valid Loss:  0.00167924037668854
Epoch:  421  	Training Loss: 0.001468444592319429
Test Loss:  0.0014491081237792969
Valid Loss:  0.0016790104564279318
Epoch:  422  	Training Loss: 0.0014681450556963682
Test Loss:  0.0014494084753096104
Valid Loss:  0.0016730274073779583
Epoch:  423  	Training Loss: 0.0014625060139223933
Test Loss:  0.0014496587682515383
Valid Loss:  0.0016673763748258352
Epoch:  424  	Training Loss: 0.0014572199434041977
Test Loss:  0.0014498599339276552
Valid Loss:  0.0016620324458926916
Epoch:  425  	Training Loss: 0.0014522317796945572
Test Loss:  0.0014501111581921577
Valid Loss:  0.0016569581348448992
Epoch:  426  	Training Loss: 0.0014474756317213178
Test Loss:  0.0014503138372674584
Valid Loss:  0.0016521562356501818
Epoch:  427  	Training Loss: 0.0014430033043026924
Test Loss:  0.0014504672726616263
Valid Loss:  0.0016476016025990248
Epoch:  428  	Training Loss: 0.0014387920964509249
Test Loss:  0.0014505733270198107
Valid Loss:  0.0016432737465947866
Epoch:  429  	Training Loss: 0.0014348195400089025
Test Loss:  0.001450634328648448
Valid Loss:  0.0016391503158956766
Epoch:  430  	Training Loss: 0.0014310681726783514
Test Loss:  0.0014506557490676641
Valid Loss:  0.0016352225793525577
Epoch:  431  	Training Loss: 0.0014275165740400553
Test Loss:  0.0014506338629871607
Valid Loss:  0.0016314748208969831
Epoch:  432  	Training Loss: 0.001424148678779602
Test Loss:  0.0014499890385195613
Valid Loss:  0.0016312070656567812
Epoch:  433  	Training Loss: 0.001423936802893877
Test Loss:  0.0014493514318019152
Valid Loss:  0.0016309402417391539
Epoch:  434  	Training Loss: 0.0014237288851290941
Test Loss:  0.0014487216249108315
Valid Loss:  0.001630679122172296
Epoch:  435  	Training Loss: 0.0014235246926546097
Test Loss:  0.0014480985701084137
Valid Loss:  0.001630417420528829
Epoch:  436  	Training Loss: 0.0014233216643333435
Test Loss:  0.0014474857598543167
Valid Loss:  0.0016301628202199936
Epoch:  437  	Training Loss: 0.0014231230597943068
Test Loss:  0.0014468783047050238
Valid Loss:  0.0016299118287861347
Epoch:  438  	Training Loss: 0.0014229273656383157
Test Loss:  0.001446278765797615
Valid Loss:  0.0016296651447191834
Epoch:  439  	Training Loss: 0.0014227328356355429
Test Loss:  0.0014456865610554814
Valid Loss:  0.0016294220695272088
Epoch:  440  	Training Loss: 0.001422540401108563
Test Loss:  0.0014451013412326574
Valid Loss:  0.0016291794599965215
Epoch:  441  	Training Loss: 0.001422353321686387
Test Loss:  0.0014445234555751085
Valid Loss:  0.0016289395280182362
Epoch:  442  	Training Loss: 0.0014221675228327513
Test Loss:  0.0014424879336729646
Valid Loss:  0.0016269850311800838
Epoch:  443  	Training Loss: 0.0014215057017281651
Test Loss:  0.0014405215624719858
Valid Loss:  0.001625122968107462
Epoch:  444  	Training Loss: 0.001420884975232184
Test Loss:  0.00143861910328269
Valid Loss:  0.001623346470296383
Epoch:  445  	Training Loss: 0.0014203026657924056
Test Loss:  0.001436779391951859
Valid Loss:  0.0016216561198234558
Epoch:  446  	Training Loss: 0.00141976960003376
Test Loss:  0.0014352456200867891
Valid Loss:  0.0016203102422878146
Epoch:  447  	Training Loss: 0.0014193920651450753
Test Loss:  0.0014337570173665881
Valid Loss:  0.0016190208261832595
Epoch:  448  	Training Loss: 0.001419037813320756
Test Loss:  0.0014323123032227159
Valid Loss:  0.0016177850775420666
Epoch:  449  	Training Loss: 0.0014187013730406761
Test Loss:  0.0014309093821793795
Valid Loss:  0.001616599620319903
Epoch:  450  	Training Loss: 0.0014183791354298592
Test Loss:  0.0014295456930994987
Valid Loss:  0.0016154610784724355
Epoch:  451  	Training Loss: 0.0014180762227624655
Test Loss:  0.001428223797120154
Valid Loss:  0.0016143728280439973
Epoch:  452  	Training Loss: 0.001417788676917553
Test Loss:  0.001428048824891448
Valid Loss:  0.00161424046382308
Epoch:  453  	Training Loss: 0.001417647348716855
Test Loss:  0.0014278653543442488
Valid Loss:  0.001614109380170703
Epoch:  454  	Training Loss: 0.0014175118412822485
Test Loss:  0.0014276759466156363
Valid Loss:  0.0016139803919941187
Epoch:  455  	Training Loss: 0.001417377614416182
Test Loss:  0.0014274786226451397
Valid Loss:  0.001613852335140109
Epoch:  456  	Training Loss: 0.0014172475785017014
Test Loss:  0.00142727664206177
Valid Loss:  0.001613722532056272
Epoch:  457  	Training Loss: 0.0014171202201396227
Test Loss:  0.001427067443728447
Valid Loss:  0.00161359750200063
Epoch:  458  	Training Loss: 0.0014169944915920496
Test Loss:  0.0014268516097217798
Valid Loss:  0.0016134703764691949
Epoch:  459  	Training Loss: 0.0014168714405968785
Test Loss:  0.0014266318175941706
Valid Loss:  0.0016133449971675873
Epoch:  460  	Training Loss: 0.001416749320924282
Test Loss:  0.001426405506208539
Valid Loss:  0.001613219385035336
Epoch:  461  	Training Loss: 0.001416628248989582
Test Loss:  0.0014261780306696892
Valid Loss:  0.001613094937056303
Epoch:  462  	Training Loss: 0.0014165102038532495
Test Loss:  0.0014258013106882572
Valid Loss:  0.001612990628927946
Epoch:  463  	Training Loss: 0.0014164375606924295
Test Loss:  0.001425427501089871
Valid Loss:  0.001612887717783451
Epoch:  464  	Training Loss: 0.0014163689920678735
Test Loss:  0.0014250557869672775
Valid Loss:  0.0016127859707921743
Epoch:  465  	Training Loss: 0.0014163019368425012
Test Loss:  0.0014246831415221095
Valid Loss:  0.0016126874834299088
Epoch:  466  	Training Loss: 0.0014162359293550253
Test Loss:  0.001424314919859171
Valid Loss:  0.0016125901602208614
Epoch:  467  	Training Loss: 0.0014161705039441586
Test Loss:  0.0014239487936720252
Valid Loss:  0.001612490857951343
Epoch:  468  	Training Loss: 0.0014161095023155212
Test Loss:  0.0014235868584364653
Valid Loss:  0.001612396677955985
Epoch:  469  	Training Loss: 0.0014160473365336657
Test Loss:  0.0014232250396162271
Valid Loss:  0.0016123027307912707
Epoch:  470  	Training Loss: 0.0014159869169816375
Test Loss:  0.0014228636864572763
Valid Loss:  0.0016122092492878437
Epoch:  471  	Training Loss: 0.0014159270795062184
Test Loss:  0.0014225081540644169
Valid Loss:  0.0016121194930747151
Epoch:  472  	Training Loss: 0.0014158691046759486
Test Loss:  0.001413750578649342
Valid Loss:  0.0016095067840069532
Epoch:  473  	Training Loss: 0.0014138369588181376
Test Loss:  0.0014084447175264359
Valid Loss:  0.0016083077061921358
Epoch:  474  	Training Loss: 0.0014120745472609997
Test Loss:  0.0014027776196599007
Valid Loss:  0.0016068518161773682
Epoch:  475  	Training Loss: 0.001410505035892129
Test Loss:  0.0013984323013573885
Valid Loss:  0.001605873927474022
Epoch:  476  	Training Loss: 0.001409072196111083
Test Loss:  0.0013942079385742545
Valid Loss:  0.001604879042133689
Epoch:  477  	Training Loss: 0.0014077536761760712
Test Loss:  0.0013907402753829956
Valid Loss:  0.0016041406197473407
Epoch:  478  	Training Loss: 0.0014065117575228214
Test Loss:  0.001387797063216567
Valid Loss:  0.0016035304870456457
Epoch:  479  	Training Loss: 0.0014053264167159796
Test Loss:  0.0013851618859916925
Valid Loss:  0.0016029940452426672
Epoch:  480  	Training Loss: 0.001404192065820098
Test Loss:  0.0013827484799548984
Valid Loss:  0.00160251057241112
Epoch:  481  	Training Loss: 0.0014031033497303724
Test Loss:  0.00138048455119133
Valid Loss:  0.0016020608600229025
Epoch:  482  	Training Loss: 0.0014020551461726427
Test Loss:  0.0013803872279822826
Valid Loss:  0.0016019459581002593
Epoch:  483  	Training Loss: 0.0014019496738910675
Test Loss:  0.0013802906032651663
Valid Loss:  0.0016018305905163288
Epoch:  484  	Training Loss: 0.001401846413500607
Test Loss:  0.0013801930472254753
Valid Loss:  0.0016017159214243293
Epoch:  485  	Training Loss: 0.0014017409412190318
Test Loss:  0.0013800968881696463
Valid Loss:  97%|█████████▋| 485/500 [05:52<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:53<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:53<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:59<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:59<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:59<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:59<00:01,  2.24it/s]100%|█████████▉| 499/500 [06:00<00:00,  3.00it/s]100%|██████████| 500/500 [06:00<00:00,  1.39it/s]
 0.001601601019501686
Epoch:  486  	Training Loss: 0.0014016361674293876
Test Loss:  0.0013800016604363918
Valid Loss:  0.0016014818102121353
Epoch:  487  	Training Loss: 0.0014015324413776398
Test Loss:  0.0013799055013805628
Valid Loss:  0.001601371681317687
Epoch:  488  	Training Loss: 0.0014014297630637884
Test Loss:  0.001379809807986021
Valid Loss:  0.001601256662979722
Epoch:  489  	Training Loss: 0.0014013268519192934
Test Loss:  0.001379715627990663
Valid Loss:  0.0016011433908715844
Epoch:  490  	Training Loss: 0.001401222893036902
Test Loss:  0.0013796216808259487
Valid Loss:  0.0016010336112231016
Epoch:  491  	Training Loss: 0.0014011214952915907
Test Loss:  0.0013795276172459126
Valid Loss:  0.0016009153332561255
Epoch:  492  	Training Loss: 0.001401017769239843
Test Loss:  0.0013792110839858651
Valid Loss:  0.0015959974844008684
Epoch:  493  	Training Loss: 0.0013965608086436987
Test Loss:  0.0013788648648187518
Valid Loss:  0.0015911961672827601
Epoch:  494  	Training Loss: 0.001392250880599022
Test Loss:  0.0013784889597445726
Valid Loss:  0.0015865117311477661
Epoch:  495  	Training Loss: 0.0013880846090614796
Test Loss:  0.0013780887238681316
Valid Loss:  0.0015820101834833622
Epoch:  496  	Training Loss: 0.0013840524479746819
Test Loss:  0.001377665321342647
Valid Loss:  0.0015776705695316195
Epoch:  497  	Training Loss: 0.00138014554977417
Test Loss:  0.0013772251550108194
Valid Loss:  0.0015734357293695211
Epoch:  498  	Training Loss: 0.0013763585593551397
Test Loss:  0.0013767657801508904
Valid Loss:  0.0015692966990172863
Epoch:  499  	Training Loss: 0.001372684957459569
Test Loss:  0.001376294414512813
Valid Loss:  0.0015652573201805353
Epoch:  500  	Training Loss: 0.0013691185740754008
Test Loss:  0.0013758043060079217
Valid Loss:  0.0015613047871738672
seed is  16
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.18it/s]  1%|          | 4/500 [00:00<00:30, 16.52it/s]  1%|          | 6/500 [00:00<00:29, 16.60it/s]  2%|▏         | 8/500 [00:00<00:29, 16.65it/s]  2%|▏         | 10/500 [00:00<00:29, 16.65it/s]  2%|▏         | 12/500 [00:00<00:29, 16.72it/s]  3%|▎         | 14/500 [00:00<00:29, 16.72it/s]  3%|▎         | 16/500 [00:00<00:28, 16.74it/s]  4%|▎         | 18/500 [00:01<00:28, 16.64it/s]  4%|▍         | 20/500 [00:01<00:29, 16.54it/s]  4%|▍         | 22/500 [00:01<00:28, 16.59it/s]  5%|▍         | 24/500 [00:01<00:28, 16.43it/s]  5%|▌         | 26/500 [00:01<00:28, 16.42it/s]  6%|▌         | 28/500 [00:01<00:28, 16.31it/s]  6%|▌         | 30/500 [00:01<00:28, 16.49it/s]  6%|▋         | 32/500 [00:01<00:28, 16.58it/s]  7%|▋         | 34/500 [00:02<00:28, 16.62it/s]  7%|▋         | 36/500 [00:02<00:27, 16.60it/s]  8%|▊         | 38/500 [00:02<00:27, 16.55it/s]  8%|▊         | 40/500 [00:02<00:27, 16.58it/s]  8%|▊         | 42/500 [00:02<00:27, 16.58it/s]  9%|▉         | 44/500 [00:02<00:27, 16.62it/s]  9%|▉         | 46/500 [00:02<00:27, 16.60it/s] 10%|▉         | 48/500 [00:02<00:27, 16.62it/s] 10%|█         | 50/500 [00:03<00:27, 16.63it/s] 10%|█         | 52/500 [00:03<00:26, 16.62it/s] 11%|█         | 54/500 [00:03<00:26, 16.65it/s] 11%|█         | 56/500 [00:03<00:27, 16.03it/s] 12%|█▏        | 58/500 [00:03<00:30, 14.73it/s] 12%|█▏        | 60/500 [00:03<00:30, 14.28it/s] 12%|█▏        | 62/500 [00:03<00:29, 14.85it/s] 13%|█▎        | 64/500 [00:03<00:28, 15.25it/s] 13%|█▎        | 66/500 [00:04<00:30, 14.27it/s] 14%|█▎        | 68/500 [00:04<00:31, 13.72it/s] 14%|█▍        | 70/500 [00:04<00:32, 13.40it/s] 14%|█▍        | 72/500 [00:04<00:30, 14.23it/s] 15%|█▍        | 74/500 [00:04<00:28, 14.92it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.42it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.68it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.85it/s] 16%|█▋        | 82/500 [00:05<00:26, 16.06it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.98it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.10it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.23it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.42it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.55it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.64it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.66it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.60it/s] 20%|██        | 100/500 [00:06<00:23, 16.70it/s] 20%|██        | 102/500 [00:06<00:23, 16.73it/s] 21%|██        | 104/500 [00:06<00:23, 16.66it/s] 21%|██        | 106/500 [00:06<00:23, 16.67it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.74it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.65it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.63it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.11it/s] 23%|██▎       | 116/500 [00:07<00:26, 14.77it/s] 24%|██▎       | 118/500 [00:07<00:27, 13.98it/s] 24%|██▍       | 120/500 [00:07<00:26, 14.21it/s] 24%|██▍       | 122/500 [00:07<00:25, 14.86it/s] 25%|██▍       | 124/500 [00:07<00:24, 15.37it/s]Epoch:  1  	Training Loss: 0.5381231307983398
Test Loss:  5547.853515625
Valid Loss:  5533.8916015625
Epoch:  2  	Training Loss: 5540.6884765625
Test Loss:  6.462352104462746e+18
Valid Loss:  6.488808553250292e+18
Epoch:  3  	Training Loss: 6.483568280832311e+18
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 15.64it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.91it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.17it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.22it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.30it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.39it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.54it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.60it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.59it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.51it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.49it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.55it/s] 30%|███       | 150/500 [00:09<00:21, 16.46it/s] 30%|███       | 152/500 [00:09<00:21, 16.53it/s] 31%|███       | 154/500 [00:09<00:20, 16.57it/s] 31%|███       | 156/500 [00:09<00:20, 16.56it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.57it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.56it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.48it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.38it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.51it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.47it/s] 34%|███▍      | 170/500 [00:10<00:19, 16.55it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.14it/s] 35%|███▍      | 174/500 [00:10<00:22, 14.60it/s] 35%|███▌      | 176/500 [00:10<00:21, 15.16it/s] 36%|███▌      | 178/500 [00:11<00:21, 14.84it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.34it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.76it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.08it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.16it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.29it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.27it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.28it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.37it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.38it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.19it/s] 40%|████      | 200/500 [00:12<00:18, 16.29it/s] 40%|████      | 202/500 [00:12<00:18, 16.43it/s] 41%|████      | 204/500 [00:12<00:17, 16.51it/s] 41%|████      | 206/500 [00:12<00:17, 16.63it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.58it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.66it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.67it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.63it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.59it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.54it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.62it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.55it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.54it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.63it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.66it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.69it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.69it/s] 47%|████▋     | 234/500 [00:14<00:15, 16.68it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.64it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.50it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.41it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.44it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.46it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.52it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.56it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.55it/s] 50%|█████     | 252/500 [00:15<00:15, 16.51it/s] 51%|█████     | 254/500 [00:15<00:14, 16.55it/s] 51%|█████     | 256/500 [00:15<00:14, 16.49it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.35it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.37it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.44it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.50it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.54it/s] 54%|█████▎    | 268/500 [00:16<00:13, 16.60it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.47it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.42it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.38it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.39it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.28it/s] 56%|█████▌    | 280/500 [00:17<00:14, 14.78it/s] 56%|█████▋    | 282/500 [00:17<00:15, 14.06it/s] 57%|█████▋    | 284/500 [00:17<00:14, 14.73it/s] 57%|█████▋    | 286/500 [00:17<00:14, 14.41it/s] 58%|█████▊    | 288/500 [00:17<00:14, 14.74it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.27it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.69it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.00it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.23it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.19it/s] 60%|██████    | 300/500 [00:18<00:12, 16.08it/s] 60%|██████    | 302/500 [00:18<00:12, 16.07it/s] 61%|██████    | 304/500 [00:18<00:12, 16.19it/s] 61%|██████    | 306/500 [00:18<00:11, 16.34it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.43it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.35it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.32it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.38it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.35it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.42it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.10it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.21it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.21it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.38it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.38it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.14it/s] 66%|██████▋   | 332/500 [00:20<00:10, 15.83it/s] 67%|██████▋   | 334/500 [00:20<00:11, 14.71it/s] 67%|██████▋   | 336/500 [00:20<00:10, 15.22it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.51it/s] 68%|██████▊   | 340/500 [00:21<00:10, 14.69it/s] 68%|██████▊   | 342/500 [00:21<00:10, 14.67it/s] 69%|██████▉   | 344/500 [00:21<00:10, 15.26it/s] 69%|██████▉   | 346/500 [00:21<00:09, 15.57it/s] 70%|██████▉   | 348/500 [00:21<00:09, 15.77it/s] 70%|███████   | 350/500 [00:21<00:09, 15.97it/s] 70%|███████   | 352/500 [00:21<00:09, 16.20it/s] 71%|███████   | 354/500 [00:22<00:08, 16.33it/s] 71%|███████   | 356/500 [00:22<00:08, 16.43it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.49it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.42it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.54it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.59it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.44it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.35it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.29it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.35it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.43it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.55it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.63it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.68it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.65it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.41it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.44it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.50it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.59it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.52it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.40it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.45it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.00it/s] 80%|████████  | 400/500 [00:24<00:06, 15.47it/s] 80%|████████  | 402/500 [00:24<00:06, 15.79it/s] 81%|████████  | 404/500 [00:25<00:05, 16.07it/s] 81%|████████  | 406/500 [00:25<00:05, 16.29it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.42it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.36it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.32it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.37it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.43it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.48it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.47it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.51it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.55it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.51it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.59it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.49it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.50it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.50it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.52it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.53it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.51it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.43it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.43it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.52it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.58it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.57it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.41it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.53it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.59it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.61it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.47it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.34it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.35it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.37it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.38it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.38it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.32it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.32it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.43it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.49it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.51it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.50it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.53it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.44it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.44it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.60it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.63it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.62it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.60it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.56it/s]100%|██████████| 500/500 [00:30<00:00, 16.33it/s]100%|██████████| 500/500 [00:30<00:00, 16.18it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  16
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:36,  6.20s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:49,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:49,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:25,  1.21s/it]  7%|▋         | 33/500 [00:27<06:44,  1.15it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:36,  2.95it/s]  8%|▊         | 41/500 [00:33<09:04,  1.19s/it]  9%|▊         | 43/500 [00:33<06:29,  1.17it/s]  9%|▉         | 45/500 [00:34<04:39,  1.63it/s]  9%|▉         | 47/500 [00:34<03:23,  2.22it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:49,  1.18s/it] 11%|█         | 53/500 [00:40<06:18,  1.18it/s] 11%|█         | 55/500 [00:40<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:18,  2.24it/s] 12%|█▏        | 59/500 [00:41<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:47<08:37,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:54<08:23,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:59,  1.19it/s]Epoch:  1  	Training Loss: 0.5381231307983398
Test Loss:  167.5064239501953
Valid Loss:  167.70867919921875
Epoch:  2  	Training Loss: 167.7903594970703
Test Loss:  0.7010071277618408
Valid Loss:  0.6644811630249023
Epoch:  3  	Training Loss: 0.6790892481803894
Test Loss:  0.7009903192520142
Valid Loss:  0.664463996887207
Epoch:  4  	Training Loss: 0.6790744662284851
Test Loss:  0.700973391532898
Valid Loss:  0.6644461750984192
Epoch:  5  	Training Loss: 0.6790593862533569
Test Loss:  0.7009561061859131
Valid Loss:  0.6644270420074463
Epoch:  6  	Training Loss: 0.6790438890457153
Test Loss:  0.70093834400177
Valid Loss:  0.6644080281257629
Epoch:  7  	Training Loss: 0.6790282726287842
Test Loss:  0.700918436050415
Valid Loss:  0.66438889503479
Epoch:  8  	Training Loss: 0.679012656211853
Test Loss:  0.700897753238678
Valid Loss:  0.6643693447113037
Epoch:  9  	Training Loss: 0.6789963245391846
Test Loss:  0.7008770108222961
Valid Loss:  0.6643491387367249
Epoch:  10  	Training Loss: 0.678979754447937
Test Loss:  0.7008558511734009
Valid Loss:  0.6643275022506714
Epoch:  11  	Training Loss: 0.6789627075195312
Test Loss:  0.7008346319198608
Valid Loss:  0.6643058657646179
Epoch:  12  	Training Loss: 0.6789455413818359
Test Loss:  0.7007734775543213
Valid Loss:  0.664242148399353
Epoch:  13  	Training Loss: 0.6788915395736694
Test Loss:  0.7007083296775818
Valid Loss:  0.6641741394996643
Epoch:  14  	Training Loss: 0.678835928440094
Test Loss:  0.7006421089172363
Valid Loss:  0.6641045212745667
Epoch:  15  	Training Loss: 0.6787770986557007
Test Loss:  0.7005717754364014
Valid Loss:  0.6640299558639526
Epoch:  16  	Training Loss: 0.6787145137786865
Test Loss:  0.700495719909668
Valid Loss:  0.6639431715011597
Epoch:  17  	Training Loss: 0.6786460876464844
Test Loss:  0.7004159688949585
Valid Loss:  0.6638463735580444
Epoch:  18  	Training Loss: 0.678570568561554
Test Loss:  0.7003337144851685
Valid Loss:  0.6637463569641113
Epoch:  19  	Training Loss: 0.6784922480583191
Test Loss:  0.700251579284668
Valid Loss:  0.6636463403701782
Epoch:  20  	Training Loss: 0.678412675857544
Test Loss:  0.7001667618751526
Valid Loss:  0.663543164730072
Epoch:  21  	Training Loss: 0.678328812122345
Test Loss:  0.7000764608383179
Valid Loss:  0.6634366512298584
Epoch:  22  	Training Loss: 0.6782364845275879
Test Loss:  0.6999953389167786
Valid Loss:  0.6633437275886536
Epoch:  23  	Training Loss: 0.6781524419784546
Test Loss:  0.6999129056930542
Valid Loss:  0.6632494926452637
Epoch:  24  	Training Loss: 0.678065836429596
Test Loss:  0.6998237371444702
Valid Loss:  0.6631527543067932
Epoch:  25  	Training Loss: 0.6779752969741821
Test Loss:  0.6997312903404236
Valid Loss:  0.6630560755729675
Epoch:  26  	Training Loss: 0.677883505821228
Test Loss:  0.699631929397583
Valid Loss:  0.6629495620727539
Epoch:  27  	Training Loss: 0.6777827739715576
Test Loss:  0.6995326280593872
Valid Loss:  0.6628416776657104
Epoch:  28  	Training Loss: 0.6776809692382812
Test Loss:  0.6994320750236511
Valid Loss:  0.6627275347709656
Epoch:  29  	Training Loss: 0.6775762438774109
Test Loss:  0.69933021068573
Valid Loss:  0.6626074314117432
Epoch:  30  	Training Loss: 0.6774684190750122
Test Loss:  0.6992242336273193
Valid Loss:  0.6624754071235657
Epoch:  31  	Training Loss: 0.6773492097854614
Test Loss:  0.6991125345230103
Valid Loss:  0.6623313426971436
Epoch:  32  	Training Loss: 0.677217960357666
Test Loss:  0.6990156173706055
Valid Loss:  0.6622062921524048
Epoch:  33  	Training Loss: 0.6771024465560913
Test Loss:  0.6989166736602783
Valid Loss:  0.6620780229568481
Epoch:  34  	Training Loss: 0.67698073387146
Test Loss:  0.6988133788108826
Valid Loss:  0.6619406938552856
Epoch:  35  	Training Loss: 0.6768503189086914
Test Loss:  0.6986942291259766
Valid Loss:  0.661795973777771
Epoch:  36  	Training Loss: 0.6767064929008484
Test Loss:  0.6985654830932617
Valid Loss:  0.6616421341896057
Epoch:  37  	Training Loss: 0.6765539646148682
Test Loss:  0.6984232664108276
Valid Loss:  0.6614781022071838
Epoch:  38  	Training Loss: 0.6763910055160522
Test Loss:  0.6982734799385071
Valid Loss:  0.6613030433654785
Epoch:  39  	Training Loss: 0.6762187480926514
Test Loss:  0.6981168985366821
Valid Loss:  0.6611180901527405
Epoch:  40  	Training Loss: 0.6760320067405701
Test Loss:  0.6979444026947021
Valid Loss:  0.66092848777771
Epoch:  41  	Training Loss: 0.6758387088775635
Test Loss:  0.6977569460868835
Valid Loss:  0.6607203483581543
Epoch:  42  	Training Loss: 0.6756309270858765
Test Loss:  0.6975544691085815
Valid Loss:  0.6604936718940735
Epoch:  43  	Training Loss: 0.6754024028778076
Test Loss:  0.697334885597229
Valid Loss:  0.6602532267570496
Epoch:  44  	Training Loss: 0.6751603484153748
Test Loss:  0.6970870494842529
Valid Loss:  0.6599851846694946
Epoch:  45  	Training Loss: 0.6749014854431152
Test Loss:  0.6968245506286621
Valid Loss:  0.6596977710723877
Epoch:  46  	Training Loss: 0.6746219992637634
Test Loss:  0.69655841588974
Valid Loss:  0.6594018936157227
Epoch:  47  	Training Loss: 0.6743325591087341
Test Loss:  0.6962766051292419
Valid Loss:  0.6590980291366577
Epoch:  48  	Training Loss: 0.6740354299545288
Test Loss:  0.6959860324859619
Valid Loss:  0.6587804555892944
Epoch:  49  	Training Loss: 0.6737282276153564
Test Loss:  0.6956815719604492
Valid Loss:  0.6584481000900269
Epoch:  50  	Training Loss: 0.6733971834182739
Test Loss:  0.6953448057174683
Valid Loss:  0.6580901741981506
Epoch:  51  	Training Loss: 0.6730291843414307
Test Loss:  0.6949872970581055
Valid Loss:  0.657706618309021
Epoch:  52  	Training Loss: 0.67264723777771
Test Loss:  0.6945673227310181
Valid Loss:  0.6572444438934326
Epoch:  53  	Training Loss: 0.672188401222229
Test Loss:  0.6941194534301758
Valid Loss:  0.6567625999450684
Epoch:  54  	Training Loss: 0.6717029809951782
Test Loss:  0.6936215758323669
Valid Loss:  0.6562309265136719
Epoch:  55  	Training Loss: 0.6711759567260742
Test Loss:  0.6930974125862122
Valid Loss:  0.6556711196899414
Epoch:  56  	Training Loss: 0.6706127524375916
Test Loss:  0.6925004720687866
Valid Loss:  0.655066967010498
Epoch:  57  	Training Loss: 0.6700001955032349
Test Loss:  0.6918512582778931
Valid Loss:  0.6544264554977417
Epoch:  58  	Training Loss: 0.66934734582901
Test Loss:  0.6911386251449585
Valid Loss:  0.6537452340126038
Epoch:  59  	Training Loss: 0.6686529517173767
Test Loss:  0.6904146671295166
Valid Loss:  0.6530555486679077
Epoch:  60  	Training Loss: 0.6679505109786987
Test Loss:  0.689691424369812
Valid Loss:  0.6523665189743042
Epoch:  61  	Training Loss: 0.6672487854957581
Test Loss:  0.6889690160751343
Valid Loss:  0.6516782641410828
Epoch:  62  	Training Loss: 0.6665478348731995
Test Loss:  0.6881657838821411
Valid Loss:  0.6509333252906799
Epoch:  63  	Training Loss: 0.6657823324203491
Test Loss:  0.6873636245727539
Valid Loss:  0.6501893401145935
Epoch:  64  	Training Loss: 0.6650177240371704
Test Loss:  0.6865624189376831
Valid Loss:  0.6494461894035339
Epoch:  65  	Training Loss: 0.6642540693283081
Test Loss:  0.6857620477676392
Valid Loss:  0.6487038731575012
Epoch:  66  	Training Loss: 0.6634912490844727
Test Loss:  0.6849626302719116
Valid Loss:  0.6479624509811401
Epoch:  67  	Training Loss: 0.6627292633056641
Test Loss:  0.6841641664505005
Valid Loss:  0.6472219228744507
Epoch:  68  	Training Loss: 0.6619682312011719
Test Loss:  0.6833667755126953
Valid Loss:  0.6464821100234985
Epoch:  69  	Training Loss: 0.6612080931663513
Test Loss:  0.682570219039917
Valid Loss:  0.6457433700561523
Epoch:  70  	Training Loss: 0.6604488492012024
Test Loss:  0.6817746162414551
Valid Loss:  0.6450053453445435
Epoch:  71  	Training Loss: 0.6596904993057251
Test Loss:  0.6809799671173096
Valid Loss:  0.6442682147026062
Epoch:  72  	Training Loss: 0.6589329838752747
Test Loss:  0.6802447438240051
Valid Loss:  0.6435809135437012
Epoch:  73  	Training Loss: 0.6582285165786743
Test Loss:  0.6795103549957275
Valid Loss:  0.6428942084312439
Epoch:  74  	Training Loss: 0.657524824142456
Test Loss:  0.678776741027832
Valid Loss:  0.6422082781791687
Epoch:  75  	Training Loss: 0.6568217873573303
Test Loss:  0.678043782711029
Valid Loss:   15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:04,  1.16s/it] 17%|█▋        | 83/500 [01:01<05:46,  1.20it/s] 17%|█▋        | 85/500 [01:01<04:09,  1.66it/s] 17%|█▋        | 87/500 [01:01<03:01,  2.27it/s] 18%|█▊        | 89/500 [01:01<02:14,  3.05it/s] 18%|█▊        | 91/500 [01:07<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:06,  1.65it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:08<02:12,  3.03it/s] 20%|██        | 101/500 [01:14<08:02,  1.21s/it] 21%|██        | 103/500 [01:14<05:44,  1.15it/s] 21%|██        | 105/500 [01:15<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:15<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:15<02:14,  2.92it/s] 22%|██▏       | 111/500 [01:21<07:51,  1.21s/it] 23%|██▎       | 113/500 [01:21<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:22<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:22<02:56,  2.18it/s] 24%|██▍       | 119/500 [01:22<02:10,  2.92it/s] 24%|██▍       | 121/500 [01:28<07:35,  1.20s/it] 25%|██▍       | 123/500 [01:28<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:29<03:53,  1.60it/s] 25%|██▌       | 127/500 [01:29<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:29<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:35<07:29,  1.22s/it] 27%|██▋       | 133/500 [01:35<05:20,  1.15it/s] 27%|██▋       | 135/500 [01:36<03:50,  1.58it/s] 27%|██▋       | 137/500 [01:36<02:47,  2.16it/s] 28%|██▊       | 139/500 [01:36<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:42<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:42<05:06,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:40,  1.61it/s] 29%|██▉       | 147/500 [01:43<02:40,  2.21it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.96it/s]0.641523003578186
Epoch:  76  	Training Loss: 0.6561194658279419
Test Loss:  0.6773116588592529
Valid Loss:  0.6408385038375854
Epoch:  77  	Training Loss: 0.6554179191589355
Test Loss:  0.6765801906585693
Valid Loss:  0.6401546597480774
Epoch:  78  	Training Loss: 0.6547170877456665
Test Loss:  0.6758496165275574
Valid Loss:  0.6394715309143066
Epoch:  79  	Training Loss: 0.6540169715881348
Test Loss:  0.6751197576522827
Valid Loss:  0.6387890577316284
Epoch:  80  	Training Loss: 0.6533175706863403
Test Loss:  0.6743906736373901
Valid Loss:  0.6381073594093323
Epoch:  81  	Training Loss: 0.6526188850402832
Test Loss:  0.6736623644828796
Valid Loss:  0.6374263167381287
Epoch:  82  	Training Loss: 0.6519209146499634
Test Loss:  0.6729695200920105
Valid Loss:  0.6367753744125366
Epoch:  83  	Training Loss: 0.6512548923492432
Test Loss:  0.6722775101661682
Valid Loss:  0.6361249685287476
Epoch:  84  	Training Loss: 0.6505894660949707
Test Loss:  0.6715861558914185
Valid Loss:  0.6354753971099854
Epoch:  85  	Training Loss: 0.6499248147010803
Test Loss:  0.6708955764770508
Valid Loss:  0.6348264217376709
Epoch:  86  	Training Loss: 0.6492608189582825
Test Loss:  0.6702057123184204
Valid Loss:  0.6341780424118042
Epoch:  87  	Training Loss: 0.6485975384712219
Test Loss:  0.6695165634155273
Valid Loss:  0.6335304379463196
Epoch:  88  	Training Loss: 0.6479349136352539
Test Loss:  0.6688281297683716
Valid Loss:  0.6328834891319275
Epoch:  89  	Training Loss: 0.6472730040550232
Test Loss:  0.6681403517723083
Valid Loss:  0.6322372555732727
Epoch:  90  	Training Loss: 0.6466118097305298
Test Loss:  0.667453408241272
Valid Loss:  0.6315915584564209
Epoch:  91  	Training Loss: 0.6459512710571289
Test Loss:  0.6667670011520386
Valid Loss:  0.6309466361999512
Epoch:  92  	Training Loss: 0.6452913284301758
Test Loss:  0.666104793548584
Valid Loss:  0.6303223371505737
Epoch:  93  	Training Loss: 0.6446533203125
Test Loss:  0.6654431819915771
Valid Loss:  0.629698634147644
Epoch:  94  	Training Loss: 0.6440158486366272
Test Loss:  0.6647822260856628
Valid Loss:  0.6290755867958069
Epoch:  95  	Training Loss: 0.6433790922164917
Test Loss:  0.6641219258308411
Valid Loss:  0.6284531354904175
Epoch:  96  	Training Loss: 0.6427428722381592
Test Loss:  0.663462221622467
Valid Loss:  0.6278312802314758
Epoch:  97  	Training Loss: 0.6421072483062744
Test Loss:  0.6628032326698303
Valid Loss:  0.6272100210189819
Epoch:  98  	Training Loss: 0.6414722800254822
Test Loss:  0.6621448993682861
Valid Loss:  0.6265894174575806
Epoch:  99  	Training Loss: 0.6408380270004272
Test Loss:  0.6614872217178345
Valid Loss:  0.625969409942627
Epoch:  100  	Training Loss: 0.6402043104171753
Test Loss:  0.6608301401138306
Valid Loss:  0.6253499984741211
Epoch:  101  	Training Loss: 0.6395711898803711
Test Loss:  0.6601737141609192
Valid Loss:  0.624731183052063
Epoch:  102  	Training Loss: 0.6389387845993042
Test Loss:  0.65953528881073
Valid Loss:  0.6241281032562256
Epoch:  103  	Training Loss: 0.6383228302001953
Test Loss:  0.6588974595069885
Valid Loss:  0.6235256791114807
Epoch:  104  	Training Loss: 0.6377074718475342
Test Loss:  0.6582602262496948
Valid Loss:  0.6229238510131836
Epoch:  105  	Training Loss: 0.6370927095413208
Test Loss:  0.6576236486434937
Valid Loss:  0.6223224997520447
Epoch:  106  	Training Loss: 0.6364785432815552
Test Loss:  0.6569877862930298
Valid Loss:  0.6217218637466431
Epoch:  107  	Training Loss: 0.6358650922775269
Test Loss:  0.6563524007797241
Valid Loss:  0.6211217641830444
Epoch:  108  	Training Loss: 0.6352521181106567
Test Loss:  0.6557177305221558
Valid Loss:  0.6205222010612488
Epoch:  109  	Training Loss: 0.6346397399902344
Test Loss:  0.6550836563110352
Valid Loss:  0.6199232935905457
Epoch:  110  	Training Loss: 0.6340280175209045
Test Loss:  0.6544502973556519
Valid Loss:  0.6193249225616455
Epoch:  111  	Training Loss: 0.6334168910980225
Test Loss:  0.6538174152374268
Valid Loss:  0.6187272071838379
Epoch:  112  	Training Loss: 0.6328063011169434
Test Loss:  0.6531982421875
Valid Loss:  0.6181416511535645
Epoch:  113  	Training Loss: 0.632208526134491
Test Loss:  0.6525797843933105
Valid Loss:  0.6175566911697388
Epoch:  114  	Training Loss: 0.6316112875938416
Test Loss:  0.6519618630409241
Valid Loss:  0.6169722080230713
Epoch:  115  	Training Loss: 0.6310145854949951
Test Loss:  0.6513445377349854
Valid Loss:  0.6163883209228516
Epoch:  116  	Training Loss: 0.6304184794425964
Test Loss:  0.6507277488708496
Valid Loss:  0.6158050298690796
Epoch:  117  	Training Loss: 0.6298229694366455
Test Loss:  0.6501116156578064
Valid Loss:  0.6152222752571106
Epoch:  118  	Training Loss: 0.6292279958724976
Test Loss:  0.6494960784912109
Valid Loss:  0.6146400570869446
Epoch:  119  	Training Loss: 0.6286335587501526
Test Loss:  0.6488810777664185
Valid Loss:  0.6140583753585815
Epoch:  120  	Training Loss: 0.6280397176742554
Test Loss:  0.6482666730880737
Valid Loss:  0.613477349281311
Epoch:  121  	Training Loss: 0.6274464726448059
Test Loss:  0.6476528644561768
Valid Loss:  0.6128968000411987
Epoch:  122  	Training Loss: 0.6268537044525146
Test Loss:  0.6470491886138916
Valid Loss:  0.6123253107070923
Epoch:  123  	Training Loss: 0.6262704730033875
Test Loss:  0.6464461088180542
Valid Loss:  0.6117544174194336
Epoch:  124  	Training Loss: 0.6256877779960632
Test Loss:  0.6458435654640198
Valid Loss:  0.6111840009689331
Epoch:  125  	Training Loss: 0.625105619430542
Test Loss:  0.6452415585517883
Valid Loss:  0.6106141805648804
Epoch:  126  	Training Loss: 0.6245239973068237
Test Loss:  0.6446402072906494
Valid Loss:  0.6100448369979858
Epoch:  127  	Training Loss: 0.6239429116249084
Test Loss:  0.6440393924713135
Valid Loss:  0.6094760894775391
Epoch:  128  	Training Loss: 0.6233623623847961
Test Loss:  0.6434391140937805
Valid Loss:  0.6089078187942505
Epoch:  129  	Training Loss: 0.6227824091911316
Test Loss:  0.6428393721580505
Valid Loss:  0.6083401441574097
Epoch:  130  	Training Loss: 0.62220299243927
Test Loss:  0.6422402858734131
Valid Loss:  0.6077730655670166
Epoch:  131  	Training Loss: 0.621624231338501
Test Loss:  0.6416417956352234
Valid Loss:  0.6072064638137817
Epoch:  132  	Training Loss: 0.6210458278656006
Test Loss:  0.6410516500473022
Valid Loss:  0.6066474318504333
Epoch:  133  	Training Loss: 0.6204754114151001
Test Loss:  0.6404620409011841
Valid Loss:  0.6060889959335327
Epoch:  134  	Training Loss: 0.6199055910110474
Test Loss:  0.6398729681968689
Valid Loss:  0.6055309772491455
Epoch:  135  	Training Loss: 0.6193361282348633
Test Loss:  0.6392844915390015
Valid Loss:  0.604973554611206
Epoch:  136  	Training Loss: 0.618767261505127
Test Loss:  0.638696551322937
Valid Loss:  0.6044166088104248
Epoch:  137  	Training Loss: 0.6181989908218384
Test Loss:  0.6381091475486755
Valid Loss:  0.6038602590560913
Epoch:  138  	Training Loss: 0.617631196975708
Test Loss:  0.6375222206115723
Valid Loss:  0.6033042669296265
Epoch:  139  	Training Loss: 0.6170639395713806
Test Loss:  0.6369359493255615
Valid Loss:  0.6027489900588989
Epoch:  140  	Training Loss: 0.6164971590042114
Test Loss:  0.636350154876709
Valid Loss:  0.60219407081604
Epoch:  141  	Training Loss: 0.61593097448349
Test Loss:  0.6357649564743042
Valid Loss:  0.6016397476196289
Epoch:  142  	Training Loss: 0.6153653264045715
Test Loss:  0.6351863145828247
Valid Loss:  0.6010913848876953
Epoch:  143  	Training Loss: 0.6148058176040649
Test Loss:  0.634608268737793
Valid Loss:  0.6005434989929199
Epoch:  144  	Training Loss: 0.6142468452453613
Test Loss:  0.6340306997299194
Valid Loss:  0.5999962687492371
Epoch:  145  	Training Loss: 0.6136884689331055
Test Loss:  0.6334537267684937
Valid Loss:  0.5994493961334229
Epoch:  146  	Training Loss: 0.613130509853363
Test Loss:  0.6328772306442261
Valid Loss:  0.5989030599594116
Epoch:  147  	Training Loss: 0.6125731468200684
Test Loss:  0.6323012709617615
Valid Loss:  0.5983573198318481
Epoch:  148  	Training Loss: 0.6120162010192871
Test Loss:  0.6317257881164551
Valid Loss:  0.5978119373321533
Epoch:  149  	Training Loss: 0.6114598512649536
Test Loss:  0.6311509609222412
Valid Loss:  0.5972671508789062
 30%|███       | 151/500 [01:49<06:50,  1.18s/it] 31%|███       | 153/500 [01:49<04:53,  1.18it/s] 31%|███       | 155/500 [01:49<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:49<02:34,  2.23it/s] 32%|███▏      | 159/500 [01:50<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:56<06:45,  1.20s/it] 33%|███▎      | 163/500 [01:56<04:49,  1.16it/s] 33%|███▎      | 165/500 [01:56<03:27,  1.61it/s] 33%|███▎      | 167/500 [01:56<02:30,  2.21it/s] 34%|███▍      | 169/500 [01:57<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:03<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:03<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:03<03:21,  1.62it/s] 35%|███▌      | 177/500 [02:03<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.98it/s] 36%|███▌      | 181/500 [02:10<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:27,  1.18it/s] 37%|███▋      | 185/500 [02:10<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:17<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:17<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:17<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:17<02:16,  2.21it/s] 40%|███▉      | 199/500 [02:17<01:40,  2.98it/s] 40%|████      | 201/500 [02:23<05:51,  1.17s/it] 41%|████      | 203/500 [02:24<04:10,  1.19it/s] 41%|████      | 205/500 [02:24<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:24<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:24<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:30<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:30<04:02,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:31<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:31<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:37<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:37<03:55,  1.18it/s]Epoch:  150  	Training Loss: 0.6109039783477783
Test Loss:  0.6305765509605408
Valid Loss:  0.5967228412628174
Epoch:  151  	Training Loss: 0.6103485822677612
Test Loss:  0.6300027370452881
Valid Loss:  0.5961790680885315
Epoch:  152  	Training Loss: 0.6097937822341919
Test Loss:  0.6294341087341309
Valid Loss:  0.5956400036811829
Epoch:  153  	Training Loss: 0.6092437505722046
Test Loss:  0.6288659572601318
Valid Loss:  0.5951014161109924
Epoch:  154  	Training Loss: 0.608694314956665
Test Loss:  0.628298282623291
Valid Loss:  0.594563364982605
Epoch:  155  	Training Loss: 0.6081453561782837
Test Loss:  0.6277311444282532
Valid Loss:  0.594025731086731
Epoch:  156  	Training Loss: 0.6075968742370605
Test Loss:  0.6271646618843079
Valid Loss:  0.5934885740280151
Epoch:  157  	Training Loss: 0.6070489883422852
Test Loss:  0.6265985369682312
Valid Loss:  0.5929520130157471
Epoch:  158  	Training Loss: 0.6065014600753784
Test Loss:  0.6260330080986023
Valid Loss:  0.5924158692359924
Epoch:  159  	Training Loss: 0.6059545278549194
Test Loss:  0.6254679560661316
Valid Loss:  0.5918802618980408
Epoch:  160  	Training Loss: 0.6054080724716187
Test Loss:  0.6249034404754639
Valid Loss:  0.5913450717926025
Epoch:  161  	Training Loss: 0.6048620939254761
Test Loss:  0.6243394613265991
Valid Loss:  0.5908104181289673
Epoch:  162  	Training Loss: 0.6043166518211365
Test Loss:  0.6237790584564209
Valid Loss:  0.5902789831161499
Epoch:  163  	Training Loss: 0.6037745475769043
Test Loss:  0.6232191324234009
Valid Loss:  0.5897480249404907
Epoch:  164  	Training Loss: 0.6032329797744751
Test Loss:  0.6226598024368286
Valid Loss:  0.5892176628112793
Epoch:  165  	Training Loss: 0.6026918888092041
Test Loss:  0.6221009492874146
Valid Loss:  0.5886876583099365
Epoch:  166  	Training Loss: 0.6021512746810913
Test Loss:  0.6215425133705139
Valid Loss:  0.5881581902503967
Epoch:  167  	Training Loss: 0.6016111373901367
Test Loss:  0.620984673500061
Valid Loss:  0.5876291990280151
Epoch:  168  	Training Loss: 0.6010714769363403
Test Loss:  0.6204273104667664
Valid Loss:  0.5871006846427917
Epoch:  169  	Training Loss: 0.6005322933197021
Test Loss:  0.6198703646659851
Valid Loss:  0.5865726470947266
Epoch:  170  	Training Loss: 0.5999936461448669
Test Loss:  0.6193139553070068
Valid Loss:  0.5860450267791748
Epoch:  171  	Training Loss: 0.5994553565979004
Test Loss:  0.6187581419944763
Valid Loss:  0.5855178833007812
Epoch:  172  	Training Loss: 0.5989177227020264
Test Loss:  0.6182051301002502
Valid Loss:  0.5849933624267578
Epoch:  173  	Training Loss: 0.5983827114105225
Test Loss:  0.6176525354385376
Valid Loss:  0.584469199180603
Epoch:  174  	Training Loss: 0.5978480577468872
Test Loss:  0.6171004772186279
Valid Loss:  0.583945631980896
Epoch:  175  	Training Loss: 0.5973139405250549
Test Loss:  0.6165488958358765
Valid Loss:  0.5834224224090576
Epoch:  176  	Training Loss: 0.5967803001403809
Test Loss:  0.6159977912902832
Valid Loss:  0.5828996896743774
Epoch:  177  	Training Loss: 0.5962470769882202
Test Loss:  0.6154471635818481
Valid Loss:  0.5823773145675659
Epoch:  178  	Training Loss: 0.5957143306732178
Test Loss:  0.6148970127105713
Valid Loss:  0.5818555355072021
Epoch:  179  	Training Loss: 0.5951820611953735
Test Loss:  0.6143473386764526
Valid Loss:  0.5813341736793518
Epoch:  180  	Training Loss: 0.5946502089500427
Test Loss:  0.6137981414794922
Valid Loss:  0.5808132886886597
Epoch:  181  	Training Loss: 0.5941188931465149
Test Loss:  0.6132493615150452
Valid Loss:  0.5802927613258362
Epoch:  182  	Training Loss: 0.5935879945755005
Test Loss:  0.6127027273178101
Valid Loss:  0.5797741413116455
Epoch:  183  	Training Loss: 0.5930590033531189
Test Loss:  0.6121566295623779
Valid Loss:  0.5792559385299683
Epoch:  184  	Training Loss: 0.5925305485725403
Test Loss:  0.6116108894348145
Valid Loss:  0.578738272190094
Epoch:  185  	Training Loss: 0.5920024514198303
Test Loss:  0.611065685749054
Valid Loss:  0.5782210230827332
Epoch:  186  	Training Loss: 0.5914748907089233
Test Loss:  0.6105208992958069
Valid Loss:  0.5777041912078857
Epoch:  187  	Training Loss: 0.5909478068351746
Test Loss:  0.6099766492843628
Valid Loss:  0.5771878957748413
Epoch:  188  	Training Loss: 0.590421199798584
Test Loss:  0.6094329357147217
Valid Loss:  0.5766720175743103
Epoch:  189  	Training Loss: 0.5898950099945068
Test Loss:  0.6088896989822388
Valid Loss:  0.5761566162109375
Epoch:  190  	Training Loss: 0.5893692970275879
Test Loss:  0.6083468794822693
Valid Loss:  0.5756416320800781
Epoch:  191  	Training Loss: 0.5888440608978271
Test Loss:  0.6078045964241028
Valid Loss:  0.5751271843910217
Epoch:  192  	Training Loss: 0.5883193016052246
Test Loss:  0.6072630882263184
Valid Loss:  0.5746133327484131
Epoch:  193  	Training Loss: 0.5877953171730042
Test Loss:  0.6067221164703369
Valid Loss:  0.5741000175476074
Epoch:  194  	Training Loss: 0.5872718095779419
Test Loss:  0.6061816215515137
Valid Loss:  0.57358717918396
Epoch:  195  	Training Loss: 0.5867487192153931
Test Loss:  0.6056417226791382
Valid Loss:  0.5730747580528259
Epoch:  196  	Training Loss: 0.5862261056900024
Test Loss:  0.6051021814346313
Valid Loss:  0.5725628137588501
Epoch:  197  	Training Loss: 0.58570396900177
Test Loss:  0.6045631170272827
Valid Loss:  0.5720514059066772
Epoch:  198  	Training Loss: 0.5851823091506958
Test Loss:  0.6040245890617371
Valid Loss:  0.5715402960777283
Epoch:  199  	Training Loss: 0.5846611261367798
Test Loss:  0.6034865379333496
Valid Loss:  0.571029782295227
Epoch:  200  	Training Loss: 0.584140419960022
Test Loss:  0.6029489040374756
Valid Loss:  0.5705196857452393
Epoch:  201  	Training Loss: 0.5836201310157776
Test Loss:  0.6024118661880493
Valid Loss:  0.5700100064277649
Epoch:  202  	Training Loss: 0.5831003189086914
Test Loss:  0.6018753051757812
Valid Loss:  0.5695008039474487
Epoch:  203  	Training Loss: 0.5825810432434082
Test Loss:  0.6013392210006714
Valid Loss:  0.568992018699646
Epoch:  204  	Training Loss: 0.5820621848106384
Test Loss:  0.6008036732673645
Valid Loss:  0.5684837102890015
Epoch:  205  	Training Loss: 0.5815438032150269
Test Loss:  0.6002686023712158
Valid Loss:  0.5679758787155151
Epoch:  206  	Training Loss: 0.5810258388519287
Test Loss:  0.5997338891029358
Valid Loss:  0.5674684047698975
Epoch:  207  	Training Loss: 0.5805083513259888
Test Loss:  0.599199652671814
Valid Loss:  0.566961407661438
Epoch:  208  	Training Loss: 0.579991340637207
Test Loss:  0.5986659526824951
Valid Loss:  0.5664548873901367
Epoch:  209  	Training Loss: 0.579474687576294
Test Loss:  0.5981326699256897
Valid Loss:  0.5659487247467041
Epoch:  210  	Training Loss: 0.5789585113525391
Test Loss:  0.5975998640060425
Valid Loss:  0.5654430389404297
Epoch:  211  	Training Loss: 0.5784428119659424
Test Loss:  0.5970674753189087
Valid Loss:  0.5649378299713135
Epoch:  212  	Training Loss: 0.5779275894165039
Test Loss:  0.5965356826782227
Valid Loss:  0.5644329786300659
Epoch:  213  	Training Loss: 0.5774127244949341
Test Loss:  0.5960042476654053
Valid Loss:  0.5639285445213318
Epoch:  214  	Training Loss: 0.5768983364105225
Test Loss:  0.5954732894897461
Valid Loss:  0.5634245872497559
Epoch:  215  	Training Loss: 0.576384425163269
Test Loss:  0.5949428677558899
Valid Loss:  0.5629211664199829
Epoch:  216  	Training Loss: 0.5758709907531738
Test Loss:  0.5944129228591919
Valid Loss:  0.5624181032180786
Epoch:  217  	Training Loss: 0.5753579139709473
Test Loss:  0.5938833951950073
Valid Loss:  0.5619154572486877
Epoch:  218  	Training Loss: 0.5748453140258789
Test Loss:  0.593354344367981
Valid Loss:  0.5614133477210999
Epoch:  219  	Training Loss: 0.5743332505226135
Test Loss:  0.5928257703781128
Valid Loss:  0.5609116554260254
Epoch:  220  	Training Loss: 0.5738216042518616
Test Loss:  0.5922977924346924
Valid Loss:  0.5604103803634644
Epoch:  221  	Training Loss: 0.5733104944229126
Test Loss:  0.5917701125144958
Valid Loss:  0.5599096417427063
Epoch:  222  	Training Loss: 0.5727996826171875
Test Loss:  0.5912418365478516
Valid Loss:  0.5594081878662109
Epoch:  223  	Training Loss: 0.5722883343696594
Test Loss:  0.5907140970230103
Valid Loss:  0.558907151222229
 45%|████▌     | 225/500 [02:37<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:38<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:44<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:44<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:44<02:43,  1.63it/s] 47%|████▋     | 237/500 [02:44<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.99it/s] 48%|████▊     | 241/500 [02:51<05:09,  1.19s/it] 49%|████▊     | 243/500 [02:51<03:40,  1.17it/s] 49%|████▉     | 245/500 [02:51<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:51<01:54,  2.20it/s] 50%|████▉     | 249/500 [02:51<01:24,  2.96it/s] 50%|█████     | 251/500 [02:58<04:53,  1.18s/it] 51%|█████     | 253/500 [02:58<03:28,  1.18it/s] 51%|█████     | 255/500 [02:58<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:58<01:49,  2.23it/s] 52%|█████▏    | 259/500 [02:58<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:04<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:05<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:05<02:22,  1.64it/s] 53%|█████▎    | 267/500 [03:05<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:05<01:16,  3.00it/s] 54%|█████▍    | 271/500 [03:11<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:11<03:11,  1.19it/s] 55%|█████▌    | 275/500 [03:12<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:12<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:12<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:18<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:18<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:18<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:19<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:19<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:25<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:25<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:25<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.23it/s]Epoch:  224  	Training Loss: 0.5717774629592896
Test Loss:  0.5901867747306824
Valid Loss:  0.5584065318107605
Epoch:  225  	Training Loss: 0.5712669491767883
Test Loss:  0.5896600484848022
Valid Loss:  0.5579063892364502
Epoch:  226  	Training Loss: 0.5707569122314453
Test Loss:  0.589133620262146
Valid Loss:  0.5574067234992981
Epoch:  227  	Training Loss: 0.5702474117279053
Test Loss:  0.5886077284812927
Valid Loss:  0.5569074749946594
Epoch:  228  	Training Loss: 0.5697382688522339
Test Loss:  0.5880823135375977
Valid Loss:  0.556408703327179
Epoch:  229  	Training Loss: 0.5692296028137207
Test Loss:  0.587557315826416
Valid Loss:  0.5559103488922119
Epoch:  230  	Training Loss: 0.5687214136123657
Test Loss:  0.5870327949523926
Valid Loss:  0.5554124116897583
Epoch:  231  	Training Loss: 0.5682135820388794
Test Loss:  0.5865087509155273
Valid Loss:  0.5549148321151733
Epoch:  232  	Training Loss: 0.5677062273025513
Test Loss:  0.5859842300415039
Valid Loss:  0.5544168949127197
Epoch:  233  	Training Loss: 0.5671984553337097
Test Loss:  0.5854602456092834
Valid Loss:  0.5539193749427795
Epoch:  234  	Training Loss: 0.5666911602020264
Test Loss:  0.5849367380142212
Valid Loss:  0.5534223318099976
Epoch:  235  	Training Loss: 0.5661842226982117
Test Loss:  0.5844136476516724
Valid Loss:  0.552925705909729
Epoch:  236  	Training Loss: 0.5656778216362
Test Loss:  0.5838910937309265
Valid Loss:  0.5524294972419739
Epoch:  237  	Training Loss: 0.5651718378067017
Test Loss:  0.5833689570426941
Valid Loss:  0.551933765411377
Epoch:  238  	Training Loss: 0.5646663308143616
Test Loss:  0.5828473567962646
Valid Loss:  0.5514385104179382
Epoch:  239  	Training Loss: 0.5641612410545349
Test Loss:  0.5823261141777039
Valid Loss:  0.5509436130523682
Epoch:  240  	Training Loss: 0.5636566877365112
Test Loss:  0.581805408000946
Valid Loss:  0.5504492521286011
Epoch:  241  	Training Loss: 0.563152551651001
Test Loss:  0.5812851786613464
Valid Loss:  0.5499553680419922
Epoch:  242  	Training Loss: 0.5626488924026489
Test Loss:  0.5807639360427856
Valid Loss:  0.5494604110717773
Epoch:  243  	Training Loss: 0.5621442198753357
Test Loss:  0.5802432298660278
Valid Loss:  0.5489659309387207
Epoch:  244  	Training Loss: 0.5616399645805359
Test Loss:  0.5797230005264282
Valid Loss:  0.5484719276428223
Epoch:  245  	Training Loss: 0.5611362457275391
Test Loss:  0.5792031288146973
Valid Loss:  0.547978401184082
Epoch:  246  	Training Loss: 0.5606329441070557
Test Loss:  0.5786838531494141
Valid Loss:  0.5474852323532104
Epoch:  247  	Training Loss: 0.5601301193237305
Test Loss:  0.5781649351119995
Valid Loss:  0.5469925403594971
Epoch:  248  	Training Loss: 0.5596276521682739
Test Loss:  0.5776465535163879
Valid Loss:  0.5465002059936523
Epoch:  249  	Training Loss: 0.5591256618499756
Test Loss:  0.577128529548645
Valid Loss:  0.5460083484649658
Epoch:  250  	Training Loss: 0.5586241483688354
Test Loss:  0.5766110420227051
Valid Loss:  0.5455169677734375
Epoch:  251  	Training Loss: 0.5581231117248535
Test Loss:  0.5760940313339233
Valid Loss:  0.5450260639190674
Epoch:  252  	Training Loss: 0.5576224327087402
Test Loss:  0.5755755305290222
Valid Loss:  0.5445336103439331
Epoch:  253  	Training Loss: 0.5571203231811523
Test Loss:  0.5750574469566345
Valid Loss:  0.544041633605957
Epoch:  254  	Training Loss: 0.5566186904907227
Test Loss:  0.5745398998260498
Valid Loss:  0.5435501337051392
Epoch:  255  	Training Loss: 0.5561174750328064
Test Loss:  0.5740227699279785
Valid Loss:  0.5430590510368347
Epoch:  256  	Training Loss: 0.5556167960166931
Test Loss:  0.5735061168670654
Valid Loss:  0.5425684452056885
Epoch:  257  	Training Loss: 0.5551165342330933
Test Loss:  0.5729899406433105
Valid Loss:  0.5420782566070557
Epoch:  258  	Training Loss: 0.5546166896820068
Test Loss:  0.5724741816520691
Valid Loss:  0.5415884256362915
Epoch:  259  	Training Loss: 0.5541172623634338
Test Loss:  0.5719588994979858
Valid Loss:  0.5410991311073303
Epoch:  260  	Training Loss: 0.553618311882019
Test Loss:  0.5714441537857056
Valid Loss:  0.5406102538108826
Epoch:  261  	Training Loss: 0.5531197786331177
Test Loss:  0.570929765701294
Valid Loss:  0.5401217937469482
Epoch:  262  	Training Loss: 0.5526217222213745
Test Loss:  0.5704141855239868
Valid Loss:  0.5396320819854736
Epoch:  263  	Training Loss: 0.5521224141120911
Test Loss:  0.5698990225791931
Valid Loss:  0.5391428470611572
Epoch:  264  	Training Loss: 0.551623523235321
Test Loss:  0.5693843364715576
Valid Loss:  0.5386539697647095
Epoch:  265  	Training Loss: 0.5511250495910645
Test Loss:  0.5688700079917908
Valid Loss:  0.5381655693054199
Epoch:  266  	Training Loss: 0.5506269931793213
Test Loss:  0.5683562755584717
Valid Loss:  0.5376776456832886
Epoch:  267  	Training Loss: 0.5501295328140259
Test Loss:  0.567842960357666
Valid Loss:  0.5371900796890259
Epoch:  268  	Training Loss: 0.5496324300765991
Test Loss:  0.5673301219940186
Valid Loss:  0.5367031097412109
Epoch:  269  	Training Loss: 0.5491358041763306
Test Loss:  0.5668177604675293
Valid Loss:  0.5362164378166199
Epoch:  270  	Training Loss: 0.5486396551132202
Test Loss:  0.5663058757781982
Valid Loss:  0.535730242729187
Epoch:  271  	Training Loss: 0.5481439828872681
Test Loss:  0.5657944679260254
Valid Loss:  0.5352445840835571
Epoch:  272  	Training Loss: 0.5476486682891846
Test Loss:  0.5652819275856018
Valid Loss:  0.5347577929496765
Epoch:  273  	Training Loss: 0.5471522808074951
Test Loss:  0.5647697448730469
Valid Loss:  0.5342713594436646
Epoch:  274  	Training Loss: 0.5466563105583191
Test Loss:  0.5642581582069397
Valid Loss:  0.533785343170166
Epoch:  275  	Training Loss: 0.5461608171463013
Test Loss:  0.5637469291687012
Valid Loss:  0.5332998633384705
Epoch:  276  	Training Loss: 0.5456657409667969
Test Loss:  0.5632362365722656
Valid Loss:  0.5328147411346436
Epoch:  277  	Training Loss: 0.5451711416244507
Test Loss:  0.5627260208129883
Valid Loss:  0.5323302149772644
Epoch:  278  	Training Loss: 0.5446770191192627
Test Loss:  0.5622162818908691
Valid Loss:  0.5318460464477539
Epoch:  279  	Training Loss: 0.5441833734512329
Test Loss:  0.5617069602012634
Valid Loss:  0.5313622951507568
Epoch:  280  	Training Loss: 0.5436901450157166
Test Loss:  0.5611981749534607
Valid Loss:  0.530879020690918
Epoch:  281  	Training Loss: 0.5431973934173584
Test Loss:  0.5606898069381714
Valid Loss:  0.5303962826728821
Epoch:  282  	Training Loss: 0.5427050590515137
Test Loss:  0.5601795315742493
Valid Loss:  0.529911458492279
Epoch:  283  	Training Loss: 0.5422108173370361
Test Loss:  0.5596696138381958
Valid Loss:  0.529427170753479
Epoch:  284  	Training Loss: 0.5417170524597168
Test Loss:  0.5591602325439453
Valid Loss:  0.5289434194564819
Epoch:  285  	Training Loss: 0.5412237644195557
Test Loss:  0.5586513876914978
Valid Loss:  0.5284599661827087
Epoch:  286  	Training Loss: 0.5407308340072632
Test Loss:  0.5581430196762085
Valid Loss:  0.5279771089553833
Epoch:  287  	Training Loss: 0.5402384996414185
Test Loss:  0.5576350688934326
Valid Loss:  0.5274945497512817
Epoch:  288  	Training Loss: 0.5397465229034424
Test Loss:  0.5571275353431702
Valid Loss:  0.5270125865936279
Epoch:  289  	Training Loss: 0.5392550230026245
Test Loss:  0.5566205382347107
Valid Loss:  0.5265309810638428
Epoch:  290  	Training Loss: 0.5387639999389648
Test Loss:  0.5561140179634094
Valid Loss:  0.5260498523712158
Epoch:  291  	Training Loss: 0.5382733345031738
Test Loss:  0.5556079149246216
Valid Loss:  0.5255692005157471
Epoch:  292  	Training Loss: 0.5377832651138306
Test Loss:  0.5550999641418457
Valid Loss:  0.5250866413116455
Epoch:  293  	Training Loss: 0.5372913479804993
Test Loss:  0.5545924305915833
Valid Loss:  0.5246045589447021
Epoch:  294  	Training Loss: 0.5367997884750366
Test Loss:  0.5540854334831238
Valid Loss:  0.524122953414917
Epoch:  295  	Training Loss: 0.5363086462020874
Test Loss:  0.5535788536071777
Valid Loss:  0.52364182472229
Epoch:  296  	Training Loss: 0.5358180403709412
Test Loss:  0.5530726909637451
Valid Loss:  0.523160994052887
Epoch:  297  	Training Loss: 0.5353278517723083
Test Loss:  0.5525670647621155
Valid Loss:  0.5226807594299316
 60%|█████▉    | 299/500 [03:26<01:07,  2.97it/s] 60%|██████    | 301/500 [03:32<03:55,  1.18s/it] 61%|██████    | 303/500 [03:32<02:47,  1.17it/s] 61%|██████    | 305/500 [03:32<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:32<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:39<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:39<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:39<01:23,  2.18it/s] 64%|██████▍   | 319/500 [03:39<01:02,  2.91it/s] 64%|██████▍   | 321/500 [03:46<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:46<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:46<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:46<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:46<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:52<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:53<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:53<01:40,  1.65it/s] 67%|██████▋   | 337/500 [03:53<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:53<00:53,  3.03it/s] 68%|██████▊   | 341/500 [03:59<03:06,  1.18s/it] 69%|██████▊   | 343/500 [03:59<02:12,  1.19it/s] 69%|██████▉   | 345/500 [03:59<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:00<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:00<00:50,  3.01it/s] 70%|███████   | 351/500 [04:06<02:54,  1.17s/it] 71%|███████   | 353/500 [04:06<02:03,  1.19it/s] 71%|███████   | 355/500 [04:06<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:07<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:13<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:13<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:13<01:22,  1.65it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:13<00:43,  3.03it/s]Epoch:  298  	Training Loss: 0.5348381996154785
Test Loss:  0.552061915397644
Valid Loss:  0.5222008228302002
Epoch:  299  	Training Loss: 0.5343488454818726
Test Loss:  0.551557183265686
Valid Loss:  0.521721363067627
Epoch:  300  	Training Loss: 0.5338599681854248
Test Loss:  0.5510529279708862
Valid Loss:  0.5212424397468567
Epoch:  301  	Training Loss: 0.53337162733078
Test Loss:  0.5505490303039551
Valid Loss:  0.5207638740539551
Epoch:  302  	Training Loss: 0.5328836441040039
Test Loss:  0.5500437021255493
Valid Loss:  0.5202838182449341
Epoch:  303  	Training Loss: 0.5323941707611084
Test Loss:  0.5495387315750122
Valid Loss:  0.5198041200637817
Epoch:  304  	Training Loss: 0.5319050550460815
Test Loss:  0.5490342974662781
Valid Loss:  0.5193249583244324
Epoch:  305  	Training Loss: 0.5314165353775024
Test Loss:  0.5485302805900574
Valid Loss:  0.5188462138175964
Epoch:  306  	Training Loss: 0.5309283137321472
Test Loss:  0.5480268001556396
Valid Loss:  0.5183678865432739
Epoch:  307  	Training Loss: 0.530440628528595
Test Loss:  0.5475237369537354
Valid Loss:  0.5178900957107544
Epoch:  308  	Training Loss: 0.5299534201622009
Test Loss:  0.5470211505889893
Valid Loss:  0.5174126625061035
Epoch:  309  	Training Loss: 0.5294666886329651
Test Loss:  0.5465190410614014
Valid Loss:  0.5169357061386108
Epoch:  310  	Training Loss: 0.5289803743362427
Test Loss:  0.5460174083709717
Valid Loss:  0.5164592266082764
Epoch:  311  	Training Loss: 0.5284945368766785
Test Loss:  0.5455162525177002
Valid Loss:  0.5159832239151001
Epoch:  312  	Training Loss: 0.5280091166496277
Test Loss:  0.5450130701065063
Valid Loss:  0.5155051350593567
Epoch:  313  	Training Loss: 0.5275217294692993
Test Loss:  0.5445102453231812
Valid Loss:  0.5150274634361267
Epoch:  314  	Training Loss: 0.5270346403121948
Test Loss:  0.5440078973770142
Valid Loss:  0.5145503282546997
Epoch:  315  	Training Loss: 0.5265481472015381
Test Loss:  0.5435061454772949
Valid Loss:  0.5140736103057861
Epoch:  316  	Training Loss: 0.5260620713233948
Test Loss:  0.5430046916007996
Valid Loss:  0.5135972499847412
Epoch:  317  	Training Loss: 0.5255764126777649
Test Loss:  0.542503833770752
Valid Loss:  0.513121485710144
Epoch:  318  	Training Loss: 0.525091290473938
Test Loss:  0.5420033931732178
Valid Loss:  0.5126460790634155
Epoch:  319  	Training Loss: 0.5246065855026245
Test Loss:  0.5415034294128418
Valid Loss:  0.5121711492538452
Epoch:  320  	Training Loss: 0.5241222381591797
Test Loss:  0.541003942489624
Valid Loss:  0.5116966962814331
Epoch:  321  	Training Loss: 0.5236384868621826
Test Loss:  0.5405049324035645
Valid Loss:  0.5112226009368896
Epoch:  322  	Training Loss: 0.523155152797699
Test Loss:  0.5400040149688721
Valid Loss:  0.5107467174530029
Epoch:  323  	Training Loss: 0.5226699113845825
Test Loss:  0.5395035743713379
Valid Loss:  0.5102713108062744
Epoch:  324  	Training Loss: 0.522185206413269
Test Loss:  0.5390034914016724
Valid Loss:  0.5097962617874146
Epoch:  325  	Training Loss: 0.5217008590698242
Test Loss:  0.5385040044784546
Valid Loss:  0.5093216896057129
Epoch:  326  	Training Loss: 0.5212169289588928
Test Loss:  0.5380048155784607
Valid Loss:  0.5088475346565247
Epoch:  327  	Training Loss: 0.5207335352897644
Test Loss:  0.5375062823295593
Valid Loss:  0.5083739161491394
Epoch:  328  	Training Loss: 0.5202505588531494
Test Loss:  0.5370081663131714
Valid Loss:  0.5079007148742676
Epoch:  329  	Training Loss: 0.5197680592536926
Test Loss:  0.5365104675292969
Valid Loss:  0.5074279308319092
Epoch:  330  	Training Loss: 0.5192859768867493
Test Loss:  0.5360132455825806
Valid Loss:  0.5069555640220642
Epoch:  331  	Training Loss: 0.5188044309616089
Test Loss:  0.5355165004730225
Valid Loss:  0.5064836740493774
Epoch:  332  	Training Loss: 0.5183233022689819
Test Loss:  0.5350177884101868
Valid Loss:  0.5060099363327026
Epoch:  333  	Training Loss: 0.5178402066230774
Test Loss:  0.5345195531845093
Valid Loss:  0.5055365562438965
Epoch:  334  	Training Loss: 0.5173575282096863
Test Loss:  0.5340217351913452
Valid Loss:  0.5050636529922485
Epoch:  335  	Training Loss: 0.5168753862380981
Test Loss:  0.5335243940353394
Valid Loss:  0.5045912265777588
Epoch:  336  	Training Loss: 0.5163936614990234
Test Loss:  0.5330275893211365
Valid Loss:  0.5041192173957825
Epoch:  337  	Training Loss: 0.5159124135971069
Test Loss:  0.5325312614440918
Valid Loss:  0.5036476850509644
Epoch:  338  	Training Loss: 0.5154316425323486
Test Loss:  0.5320352911949158
Valid Loss:  0.5031765699386597
Epoch:  339  	Training Loss: 0.514951229095459
Test Loss:  0.5315398573875427
Valid Loss:  0.5027059316635132
Epoch:  340  	Training Loss: 0.5144713521003723
Test Loss:  0.5310449004173279
Valid Loss:  0.5022357106208801
Epoch:  341  	Training Loss: 0.5139919519424438
Test Loss:  0.5305503606796265
Valid Loss:  0.5017659664154053
Epoch:  342  	Training Loss: 0.513512909412384
Test Loss:  0.5300537347793579
Valid Loss:  0.5012941360473633
Epoch:  343  	Training Loss: 0.5130318999290466
Test Loss:  0.5295575857162476
Valid Loss:  0.5008227825164795
Epoch:  344  	Training Loss: 0.5125512480735779
Test Loss:  0.5290619134902954
Valid Loss:  0.5003517866134644
Epoch:  345  	Training Loss: 0.5120711326599121
Test Loss:  0.5285666584968567
Valid Loss:  0.4998813271522522
Epoch:  346  	Training Loss: 0.5115914344787598
Test Loss:  0.5280718803405762
Valid Loss:  0.49941134452819824
Epoch:  347  	Training Loss: 0.5111120939254761
Test Loss:  0.5275775790214539
Valid Loss:  0.49894171953201294
Epoch:  348  	Training Loss: 0.5106333494186401
Test Loss:  0.527083694934845
Valid Loss:  0.49847257137298584
Epoch:  349  	Training Loss: 0.5101549625396729
Test Loss:  0.5265903472900391
Valid Loss:  0.49800387024879456
Epoch:  350  	Training Loss: 0.5096770524978638
Test Loss:  0.5260974168777466
Valid Loss:  0.4975356161594391
Epoch:  351  	Training Loss: 0.5091996192932129
Test Loss:  0.5256049633026123
Valid Loss:  0.49706774950027466
Epoch:  352  	Training Loss: 0.5087225437164307
Test Loss:  0.5251102447509766
Valid Loss:  0.4965977966785431
Epoch:  353  	Training Loss: 0.5082433819770813
Test Loss:  0.524616003036499
Valid Loss:  0.49612829089164734
Epoch:  354  	Training Loss: 0.5077645778656006
Test Loss:  0.5241222381591797
Valid Loss:  0.4956591725349426
Epoch:  355  	Training Loss: 0.5072863698005676
Test Loss:  0.5236289501190186
Valid Loss:  0.4951905608177185
Epoch:  356  	Training Loss: 0.5068084597587585
Test Loss:  0.5231360793113708
Valid Loss:  0.4947223365306854
Epoch:  357  	Training Loss: 0.5063310861587524
Test Loss:  0.5226436853408813
Valid Loss:  0.49425461888313293
Epoch:  358  	Training Loss: 0.5058541297912598
Test Loss:  0.5221518278121948
Valid Loss:  0.49378734827041626
Epoch:  359  	Training Loss: 0.5053776502609253
Test Loss:  0.5216603875160217
Valid Loss:  0.4933204650878906
Epoch:  360  	Training Loss: 0.504901647567749
Test Loss:  0.5211694240570068
Valid Loss:  0.4928540289402008
Epoch:  361  	Training Loss: 0.504426121711731
Test Loss:  0.5206789374351501
Valid Loss:  0.4923880994319916
Epoch:  362  	Training Loss: 0.5039509534835815
Test Loss:  0.5201868414878845
Valid Loss:  0.4919206202030182
Epoch:  363  	Training Loss: 0.5034743547439575
Test Loss:  0.5196952223777771
Valid Loss:  0.4914535880088806
Epoch:  364  	Training Loss: 0.5029981136322021
Test Loss:  0.5192040205001831
Valid Loss:  0.49098697304725647
Epoch:  365  	Training Loss: 0.5025222897529602
Test Loss:  0.5187133550643921
Valid Loss:  0.4905208647251129
Epoch:  366  	Training Loss: 0.502047061920166
Test Loss:  0.5182231664657593
Valid Loss:  0.4900552034378052
Epoch:  367  	Training Loss: 0.5015721917152405
Test Loss:  0.5177334547042847
Valid Loss:  0.4895899295806885
Epoch:  368  	Training Loss: 0.5010977983474731
Test Loss:  0.5172441005706787
Valid Loss:  0.48912516236305237
Epoch:  369  	Training Loss: 0.500623881816864
Test Loss:  0.5167553424835205
Valid Loss:  0.4886607825756073
Epoch:  370  	Training Loss: 0.5001503825187683
Test Loss:  0.516266942024231
Valid Loss:  0.4881969094276428
Epoch:  371  	Training Loss: 0.4996773600578308
Test Loss:  0.5157791376113892
Valid Loss:   74%|███████▍  | 371/500 [04:20<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:20<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:20<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:20<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:20<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:27<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:27<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:27<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:27<00:51,  2.22it/s] 78%|███████▊  | 389/500 [04:27<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:33<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:33<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:34<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:34<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:34<00:33,  3.01it/s] 80%|████████  | 401/500 [04:40<01:56,  1.17s/it] 81%|████████  | 403/500 [04:40<01:21,  1.19it/s] 81%|████████  | 405/500 [04:40<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:41<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:41<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:47<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:47<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:47<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:47<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:47<00:26,  3.00it/s] 84%|████████▍ | 421/500 [04:54<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:54<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:54<00:45,  1.63it/s] 85%|████████▌ | 427/500 [04:54<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:54<00:23,  3.00it/s] 86%|████████▌ | 431/500 [05:01<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:01<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:01<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:01<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:01<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:07<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.18it/s]0.4877334535121918
Epoch:  372  	Training Loss: 0.4992047846317291
Test Loss:  0.5152894854545593
Valid Loss:  0.4872682988643646
Epoch:  373  	Training Loss: 0.49873051047325134
Test Loss:  0.5148003101348877
Valid Loss:  0.48680365085601807
Epoch:  374  	Training Loss: 0.4982566833496094
Test Loss:  0.5143116116523743
Valid Loss:  0.48633942008018494
Epoch:  375  	Training Loss: 0.497783362865448
Test Loss:  0.5138234496116638
Valid Loss:  0.48587566614151
Epoch:  376  	Training Loss: 0.49731045961380005
Test Loss:  0.5133357048034668
Valid Loss:  0.4854122996330261
Epoch:  377  	Training Loss: 0.4968379735946655
Test Loss:  0.5128484964370728
Valid Loss:  0.4849494397640228
Epoch:  378  	Training Loss: 0.4963659942150116
Test Loss:  0.5123615860939026
Valid Loss:  0.4844869375228882
Epoch:  379  	Training Loss: 0.4958944618701935
Test Loss:  0.5118752717971802
Valid Loss:  0.4840250015258789
Epoch:  380  	Training Loss: 0.4954233765602112
Test Loss:  0.5113893747329712
Valid Loss:  0.4835634231567383
Epoch:  381  	Training Loss: 0.4949527382850647
Test Loss:  0.5109040141105652
Valid Loss:  0.48310232162475586
Epoch:  382  	Training Loss: 0.49448254704475403
Test Loss:  0.5104158520698547
Valid Loss:  0.48263853788375854
Epoch:  383  	Training Loss: 0.49400970339775085
Test Loss:  0.5099282264709473
Valid Loss:  0.4821753203868866
Epoch:  384  	Training Loss: 0.4935373365879059
Test Loss:  0.5094410181045532
Valid Loss:  0.4817125201225281
Epoch:  385  	Training Loss: 0.49306538701057434
Test Loss:  0.5089542865753174
Valid Loss:  0.4812500476837158
Epoch:  386  	Training Loss: 0.4925938844680786
Test Loss:  0.5084679126739502
Valid Loss:  0.48078808188438416
Epoch:  387  	Training Loss: 0.4921228289604187
Test Loss:  0.5079821348190308
Valid Loss:  0.4803265631198883
Epoch:  388  	Training Loss: 0.4916522204875946
Test Loss:  0.5074967741966248
Valid Loss:  0.47986552119255066
Epoch:  389  	Training Loss: 0.4911820888519287
Test Loss:  0.507011890411377
Valid Loss:  0.47940489649772644
Epoch:  390  	Training Loss: 0.49071240425109863
Test Loss:  0.5065274834632874
Valid Loss:  0.47894468903541565
Epoch:  391  	Training Loss: 0.490243136882782
Test Loss:  0.5060434937477112
Valid Loss:  0.4784849286079407
Epoch:  392  	Training Loss: 0.48977434635162354
Test Loss:  0.5055578947067261
Valid Loss:  0.4780236482620239
Epoch:  393  	Training Loss: 0.48930397629737854
Test Loss:  0.5050727725028992
Valid Loss:  0.4775627851486206
Epoch:  394  	Training Loss: 0.48883405327796936
Test Loss:  0.5045881271362305
Valid Loss:  0.4771023988723755
Epoch:  395  	Training Loss: 0.488364577293396
Test Loss:  0.5041038990020752
Valid Loss:  0.4766424298286438
Epoch:  396  	Training Loss: 0.48789554834365845
Test Loss:  0.5036201477050781
Valid Loss:  0.47618281841278076
Epoch:  397  	Training Loss: 0.4874269664287567
Test Loss:  0.5031368732452393
Valid Loss:  0.4757238030433655
Epoch:  398  	Training Loss: 0.4869588613510132
Test Loss:  0.5026540756225586
Valid Loss:  0.4752652049064636
Epoch:  399  	Training Loss: 0.48649120330810547
Test Loss:  0.5021717548370361
Valid Loss:  0.4748070240020752
Epoch:  400  	Training Loss: 0.4860239624977112
Test Loss:  0.5016899108886719
Valid Loss:  0.4743492603302002
Epoch:  401  	Training Loss: 0.4855572581291199
Test Loss:  0.501208484172821
Valid Loss:  0.4738919734954834
Epoch:  402  	Training Loss: 0.485090970993042
Test Loss:  0.5007247924804688
Valid Loss:  0.4734324812889099
Epoch:  403  	Training Loss: 0.48462241888046265
Test Loss:  0.5002416372299194
Valid Loss:  0.4729735255241394
Epoch:  404  	Training Loss: 0.4841543436050415
Test Loss:  0.49975889921188354
Valid Loss:  0.47251489758491516
Epoch:  405  	Training Loss: 0.48368674516677856
Test Loss:  0.49927663803100586
Valid Loss:  0.4720568060874939
Epoch:  406  	Training Loss: 0.48321959376335144
Test Loss:  0.498794823884964
Valid Loss:  0.47159916162490845
Epoch:  407  	Training Loss: 0.4827529191970825
Test Loss:  0.49831345677375793
Valid Loss:  0.47114190459251404
Epoch:  408  	Training Loss: 0.482286661863327
Test Loss:  0.49783262610435486
Valid Loss:  0.47068512439727783
Epoch:  409  	Training Loss: 0.4818209111690521
Test Loss:  0.4973522424697876
Valid Loss:  0.47022879123687744
Epoch:  410  	Training Loss: 0.48135560750961304
Test Loss:  0.49687233567237854
Valid Loss:  0.46977293491363525
Epoch:  411  	Training Loss: 0.4808907210826874
Test Loss:  0.4963929057121277
Valid Loss:  0.4693175256252289
Epoch:  412  	Training Loss: 0.4804263114929199
Test Loss:  0.49591127038002014
Valid Loss:  0.46886003017425537
Epoch:  413  	Training Loss: 0.4799598157405853
Test Loss:  0.4954301714897156
Valid Loss:  0.46840304136276245
Epoch:  414  	Training Loss: 0.47949379682540894
Test Loss:  0.4949495792388916
Valid Loss:  0.46794643998146057
Epoch:  415  	Training Loss: 0.47902822494506836
Test Loss:  0.4944693446159363
Valid Loss:  0.4674903154373169
Epoch:  416  	Training Loss: 0.4785630702972412
Test Loss:  0.49398958683013916
Valid Loss:  0.46703457832336426
Epoch:  417  	Training Loss: 0.4780983626842499
Test Loss:  0.493510365486145
Valid Loss:  0.4665793180465698
Epoch:  418  	Training Loss: 0.47763413190841675
Test Loss:  0.4930315315723419
Valid Loss:  0.4661244750022888
Epoch:  419  	Training Loss: 0.47717034816741943
Test Loss:  0.492553174495697
Valid Loss:  0.465670108795166
Epoch:  420  	Training Loss: 0.47670698165893555
Test Loss:  0.4920753240585327
Valid Loss:  0.46521613001823425
Epoch:  421  	Training Loss: 0.47624409198760986
Test Loss:  0.49159789085388184
Valid Loss:  0.4647626280784607
Epoch:  422  	Training Loss: 0.47578164935112
Test Loss:  0.49111953377723694
Valid Loss:  0.4643082022666931
Epoch:  423  	Training Loss: 0.4753183126449585
Test Loss:  0.49064165353775024
Valid Loss:  0.4638543128967285
Epoch:  424  	Training Loss: 0.4748553931713104
Test Loss:  0.490164190530777
Valid Loss:  0.46340084075927734
Epoch:  425  	Training Loss: 0.47439295053482056
Test Loss:  0.4896872043609619
Valid Loss:  0.462947815656662
Epoch:  426  	Training Loss: 0.4739309549331665
Test Loss:  0.48921072483062744
Valid Loss:  0.46249517798423767
Epoch:  427  	Training Loss: 0.47346940636634827
Test Loss:  0.4887346625328064
Valid Loss:  0.46204304695129395
Epoch:  428  	Training Loss: 0.47300827503204346
Test Loss:  0.48825907707214355
Valid Loss:  0.46159133315086365
Epoch:  429  	Training Loss: 0.47254765033721924
Test Loss:  0.48778393864631653
Valid Loss:  0.4611400365829468
Epoch:  430  	Training Loss: 0.47208747267723083
Test Loss:  0.4873093068599701
Valid Loss:  0.4606892168521881
Epoch:  431  	Training Loss: 0.47162771224975586
Test Loss:  0.4868350923061371
Valid Loss:  0.4602387845516205
Epoch:  432  	Training Loss: 0.4711683690547943
Test Loss:  0.4863588213920593
Valid Loss:  0.45978644490242004
Epoch:  433  	Training Loss: 0.47070708870887756
Test Loss:  0.48588305711746216
Valid Loss:  0.4593345522880554
Epoch:  434  	Training Loss: 0.47024625539779663
Test Loss:  0.4854077398777008
Valid Loss:  0.4588831067085266
Epoch:  435  	Training Loss: 0.4697858393192291
Test Loss:  0.48493289947509766
Valid Loss:  0.4584321081638336
Epoch:  436  	Training Loss: 0.4693259298801422
Test Loss:  0.4844585061073303
Valid Loss:  0.45798152685165405
Epoch:  437  	Training Loss: 0.4688664674758911
Test Loss:  0.48398467898368835
Valid Loss:  0.4575314223766327
Epoch:  438  	Training Loss: 0.46840745210647583
Test Loss:  0.4835112690925598
Valid Loss:  0.45708176493644714
Epoch:  439  	Training Loss: 0.46794891357421875
Test Loss:  0.4830383062362671
Valid Loss:  0.4566325545310974
Epoch:  440  	Training Loss: 0.4674908518791199
Test Loss:  0.48256582021713257
Valid Loss:  0.4561838209629059
Epoch:  441  	Training Loss: 0.4670332074165344
Test Loss:  0.48209378123283386
Valid Loss:  0.4557355046272278
Epoch:  442  	Training Loss: 0.4665759801864624
Test Loss:  0.48161959648132324
Valid Loss:  0.45528507232666016
Epoch:  443  	Training Loss: 0.46611666679382324
Test Loss:  0.48114582896232605
Valid Loss:  0.4548351466655731
Epoch:  444  	Training Loss: 0.4656578302383423
Test Loss:  0.48067253828048706
Valid Loss:  0.4543856382369995
 89%|████████▉ | 445/500 [05:08<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:08<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:08<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:14<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:15<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:15<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:15<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:21<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:22<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:22<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:28<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:28<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:29<00:06,  3.00it/s] 96%|█████████▌| 481/500 [05:35<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:35<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:35<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:35<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:35<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:42<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:42<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:42<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:42<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:42<00:00,  2.98it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
Epoch:  445  	Training Loss: 0.46519941091537476
Test Loss:  0.4801997244358063
Valid Loss:  0.45393651723861694
Epoch:  446  	Training Loss: 0.46474140882492065
Test Loss:  0.4797273874282837
Valid Loss:  0.45348790287971497
Epoch:  447  	Training Loss: 0.46428388357162476
Test Loss:  0.4792555272579193
Valid Loss:  0.4530397355556488
Epoch:  448  	Training Loss: 0.46382689476013184
Test Loss:  0.47878414392471313
Valid Loss:  0.45259201526641846
Epoch:  449  	Training Loss: 0.46337026357650757
Test Loss:  0.4783131778240204
Valid Loss:  0.45214471220970154
Epoch:  450  	Training Loss: 0.4629141092300415
Test Loss:  0.47784265875816345
Valid Loss:  0.45169782638549805
Epoch:  451  	Training Loss: 0.46245837211608887
Test Loss:  0.4773726463317871
Valid Loss:  0.45125144720077515
Epoch:  452  	Training Loss: 0.4620031416416168
Test Loss:  0.4769012928009033
Valid Loss:  0.4508037567138672
Epoch:  453  	Training Loss: 0.4615466296672821
Test Loss:  0.4764304757118225
Valid Loss:  0.4503566026687622
Epoch:  454  	Training Loss: 0.4610905647277832
Test Loss:  0.47596001625061035
Valid Loss:  0.4499098062515259
Epoch:  455  	Training Loss: 0.46063491702079773
Test Loss:  0.4754900336265564
Valid Loss:  0.44946345686912537
Epoch:  456  	Training Loss: 0.4601796865463257
Test Loss:  0.47502052783966064
Valid Loss:  0.4490175247192383
Epoch:  457  	Training Loss: 0.45972493290901184
Test Loss:  0.4745514392852783
Valid Loss:  0.448572039604187
Epoch:  458  	Training Loss: 0.4592706561088562
Test Loss:  0.4740828573703766
Valid Loss:  0.44812703132629395
Epoch:  459  	Training Loss: 0.458816796541214
Test Loss:  0.47361475229263306
Valid Loss:  0.4476824402809143
Epoch:  460  	Training Loss: 0.4583633840084076
Test Loss:  0.4731470048427582
Valid Loss:  0.4472382366657257
Epoch:  461  	Training Loss: 0.457910418510437
Test Loss:  0.4726797938346863
Valid Loss:  0.4467945098876953
Epoch:  462  	Training Loss: 0.45745787024497986
Test Loss:  0.47221076488494873
Valid Loss:  0.4463490843772888
Epoch:  463  	Training Loss: 0.45700356364250183
Test Loss:  0.4717421531677246
Valid Loss:  0.44590407609939575
Epoch:  464  	Training Loss: 0.4565497040748596
Test Loss:  0.4712740182876587
Valid Loss:  0.4454594850540161
Epoch:  465  	Training Loss: 0.4560962915420532
Test Loss:  0.470806360244751
Valid Loss:  0.4450153708457947
Epoch:  466  	Training Loss: 0.45564335584640503
Test Loss:  0.47033917903900146
Valid Loss:  0.4445716440677643
Epoch:  467  	Training Loss: 0.45519086718559265
Test Loss:  0.46987244486808777
Valid Loss:  0.4441284239292145
Epoch:  468  	Training Loss: 0.4547387957572937
Test Loss:  0.4694061875343323
Valid Loss:  0.4436856508255005
Epoch:  469  	Training Loss: 0.45428723096847534
Test Loss:  0.4689404368400574
Valid Loss:  0.4432432949542999
Epoch:  470  	Training Loss: 0.4538361132144928
Test Loss:  0.4684751033782959
Valid Loss:  0.44280141592025757
Epoch:  471  	Training Loss: 0.45338544249534607
Test Loss:  0.4680102467536926
Valid Loss:  0.442359983921051
Epoch:  472  	Training Loss: 0.45293521881103516
Test Loss:  0.4675436019897461
Valid Loss:  0.441916823387146
Epoch:  473  	Training Loss: 0.45248326659202576
Test Loss:  0.46707749366760254
Valid Loss:  0.44147413969039917
Epoch:  474  	Training Loss: 0.45203179121017456
Test Loss:  0.4666118025779724
Valid Loss:  0.44103187322616577
Epoch:  475  	Training Loss: 0.4515807330608368
Test Loss:  0.4661465585231781
Valid Loss:  0.4405900835990906
Epoch:  476  	Training Loss: 0.4511301517486572
Test Loss:  0.465681791305542
Valid Loss:  0.4401487112045288
Epoch:  477  	Training Loss: 0.4506800174713135
Test Loss:  0.4652174711227417
Valid Loss:  0.43970781564712524
Epoch:  478  	Training Loss: 0.45023033022880554
Test Loss:  0.4647536277770996
Valid Loss:  0.4392673075199127
Epoch:  479  	Training Loss: 0.4497811198234558
Test Loss:  0.46429020166397095
Valid Loss:  0.4388272166252136
Epoch:  480  	Training Loss: 0.44933226704597473
Test Loss:  0.46382734179496765
Valid Loss:  0.4383876323699951
Epoch:  481  	Training Loss: 0.44888395071029663
Test Loss:  0.4633648991584778
Valid Loss:  0.43794846534729004
Epoch:  482  	Training Loss: 0.44843602180480957
Test Loss:  0.46290123462677
Valid Loss:  0.437508225440979
Epoch:  483  	Training Loss: 0.44798702001571655
Test Loss:  0.46243807673454285
Valid Loss:  0.4370684027671814
Epoch:  484  	Training Loss: 0.44753843545913696
Test Loss:  0.4619753956794739
Valid Loss:  0.4366289973258972
Epoch:  485  	Training Loss: 0.4470903277397156
Test Loss:  0.4615131616592407
Valid Loss:  0.43619009852409363
Epoch:  486  	Training Loss: 0.44664266705513
Test Loss:  0.4610513746738434
Valid Loss:  0.43575161695480347
Epoch:  487  	Training Loss: 0.44619542360305786
Test Loss:  0.46059009432792664
Valid Loss:  0.4353135824203491
Epoch:  488  	Training Loss: 0.4457486867904663
Test Loss:  0.4601292908191681
Valid Loss:  0.434876024723053
Epoch:  489  	Training Loss: 0.44530239701271057
Test Loss:  0.45966893434524536
Valid Loss:  0.43443888425827026
Epoch:  490  	Training Loss: 0.44485652446746826
Test Loss:  0.45920905470848083
Valid Loss:  0.43400219082832336
Epoch:  491  	Training Loss: 0.44441115856170654
Test Loss:  0.4587496519088745
Valid Loss:  0.4335659444332123
Epoch:  492  	Training Loss: 0.44396620988845825
Test Loss:  0.4582879841327667
Valid Loss:  0.43312758207321167
Epoch:  493  	Training Loss: 0.44351914525032043
Test Loss:  0.4578268527984619
Valid Loss:  0.4326896667480469
Epoch:  494  	Training Loss: 0.4430725574493408
Test Loss:  0.4573662281036377
Valid Loss:  0.4322522282600403
Epoch:  495  	Training Loss: 0.44262635707855225
Test Loss:  0.4569060206413269
Valid Loss:  0.4318152666091919
Epoch:  496  	Training Loss: 0.44218069314956665
Test Loss:  0.45644623041152954
Valid Loss:  0.43137872219085693
Epoch:  497  	Training Loss: 0.4417354464530945
Test Loss:  0.45598703622817993
Valid Loss:  0.4309426248073578
Epoch:  498  	Training Loss: 0.44129061698913574
Test Loss:  0.45552825927734375
Valid Loss:  0.43050697445869446
Epoch:  499  	Training Loss: 0.4408462941646576
Test Loss:  0.455069899559021
Valid Loss:  0.43007174134254456
Epoch:  500  	Training Loss: 0.44040244817733765
Test Loss:  0.45461204648017883
Valid Loss:  0.42963701486587524
seed is  16
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:14,  6.28s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:53,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:19<09:28,  1.19s/it]  5%|▍         | 23/500 [00:20<06:46,  1.17it/s]  5%|▌         | 25/500 [00:26<12:18,  1.55s/it]  5%|▌         | 27/500 [00:26<08:42,  1.11s/it]  6%|▌         | 29/500 [00:26<06:12,  1.26it/s]  6%|▌         | 31/500 [00:32<11:39,  1.49s/it]  7%|▋         | 33/500 [00:33<08:16,  1.06s/it]  7%|▋         | 35/500 [00:33<05:54,  1.31it/s]  7%|▋         | 37/500 [00:33<04:17,  1.80it/s]  8%|▊         | 39/500 [00:33<03:08,  2.44it/s]  8%|▊         | 41/500 [00:45<16:28,  2.15s/it]  9%|▊         | 43/500 [00:46<11:38,  1.53s/it]  9%|▉         | 45/500 [00:46<08:15,  1.09s/it]  9%|▉         | 47/500 [00:46<05:54,  1.28it/s] 10%|▉         | 49/500 [00:46<04:15,  1.76it/s] 10%|█         | 51/500 [00:52<10:00,  1.34s/it] 11%|█         | 53/500 [00:52<07:07,  1.05it/s] 11%|█         | 55/500 [00:52<05:06,  1.45it/s] 11%|█▏        | 57/500 [00:53<03:42,  1.99it/s] 12%|█▏        | 59/500 [00:53<02:43,  2.69it/s] 12%|█▏        | 61/500 [00:59<08:54,  1.22s/it] 13%|█▎        | 63/500 [00:59<06:21,  1.15it/s] 13%|█▎        | 65/500 [00:59<04:34,  1.59it/s] 13%|█▎        | 67/500 [01:00<03:19,  2.17it/s]Epoch:  1  	Training Loss: 0.5381231307983398
Test Loss:  2.7234244346618652
Valid Loss:  2.6726126670837402
Epoch:  2  	Training Loss: 2.6861724853515625
Test Loss:  12.394065856933594
Valid Loss:  12.647889137268066
Epoch:  3  	Training Loss: 12.612970352172852
Test Loss:  0.0046587493270635605
Valid Loss:  0.004394513089209795
Epoch:  4  	Training Loss: 0.0042905984446406364
Test Loss:  0.004656646400690079
Valid Loss:  0.004392193630337715
Epoch:  5  	Training Loss: 0.004287932999432087
Test Loss:  0.004654432646930218
Valid Loss:  0.004389878362417221
Epoch:  6  	Training Loss: 0.004285275936126709
Test Loss:  0.0046519082970917225
Valid Loss:  0.00438736705109477
Epoch:  7  	Training Loss: 0.004282628186047077
Test Loss:  0.0046493420377373695
Valid Loss:  0.004384826868772507
Epoch:  8  	Training Loss: 0.0042799413204193115
Test Loss:  0.004646663554012775
Valid Loss:  0.0043821753934025764
Epoch:  9  	Training Loss: 0.004277021158486605
Test Loss:  0.0046438733115792274
Valid Loss:  0.004379418678581715
Epoch:  10  	Training Loss: 0.004273891448974609
Test Loss:  0.004641090519726276
Valid Loss:  0.004376578144729137
Epoch:  11  	Training Loss: 0.0042706821113824844
Test Loss:  0.0046381959691643715
Valid Loss:  0.00437333295121789
Epoch:  12  	Training Loss: 0.0042672716081142426
Test Loss:  0.010918181389570236
Valid Loss:  0.008235607296228409
Epoch:  13  	Training Loss: 0.008695807307958603
Test Loss:  0.021685082465410233
Valid Loss:  0.02372543141245842
Epoch:  14  	Training Loss: 0.023227985948324203
Test Loss:  0.012768587097525597
Valid Loss:  0.009899874217808247
Epoch:  15  	Training Loss: 0.010391386225819588
Test Loss:  0.0056877657771110535
Valid Loss:  0.00634925439953804
Epoch:  16  	Training Loss: 0.006169882602989674
Test Loss:  0.005131873302161694
Valid Loss:  0.0036013564094901085
Epoch:  17  	Training Loss: 0.003839886514469981
Test Loss:  0.0025480687618255615
Valid Loss:  0.0026021518278867006
Epoch:  18  	Training Loss: 0.002588294679298997
Test Loss:  0.0026578810065984726
Valid Loss:  0.0017549574840813875
Epoch:  19  	Training Loss: 0.0018940512090921402
Test Loss:  0.0016258374089375138
Valid Loss:  0.001462346175685525
Epoch:  20  	Training Loss: 0.0015051495283842087
Test Loss:  0.0017814271850511432
Valid Loss:  0.0011826022528111935
Epoch:  21  	Training Loss: 0.0012805014848709106
Test Loss:  0.0013802070170640945
Valid Loss:  0.0011808676645159721
Epoch:  22  	Training Loss: 0.0012396606616675854
Test Loss:  0.0013513073790818453
Valid Loss:  0.0010169758461415768
Epoch:  23  	Training Loss: 0.0010886040981858969
Test Loss:  0.0012909809593111277
Valid Loss:  0.0010256427340209484
Epoch:  24  	Training Loss: 0.0010951433796435595
Test Loss:  0.0012997069861739874
Valid Loss:  0.0009692461462691426
Epoch:  25  	Training Loss: 0.0010444747749716043
Test Loss:  0.0012658676132559776
Valid Loss:  0.0009519520099274814
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.001023023622110486
Test Loss:  0.0012311837635934353
Valid Loss:  0.0009102665935643017
Epoch:  27  	Training Loss: 0.0009830747731029987
Test Loss:  0.001139078289270401
Valid Loss:  0.0008801284129731357
Epoch:  28  	Training Loss: 0.0009469237411394715
Test Loss:  0.001137132989242673
Valid Loss:  0.0008581524016335607
Epoch:  29  	Training Loss: 0.0009250093135051429
Test Loss:  0.0010656483937054873
Valid Loss:  0.0008415270713157952
Epoch:  30  	Training Loss: 0.0009053688263520598
Test Loss:  0.0010817940346896648
Valid Loss:  0.0008304065559059381
Epoch:  31  	Training Loss: 0.0008941991254687309
Test Loss:  0.0010233987122774124
Valid Loss:  0.0008305253577418625
Epoch:  32  	Training Loss: 0.0008916616206988692
Test Loss:  0.0010745394974946976
Valid Loss:  0.0008059283718466759
Epoch:  33  	Training Loss: 0.0008668868103995919
Test Loss:  0.0010084881214424968
Valid Loss:  0.0008636345155537128
Epoch:  34  	Training Loss: 0.0009211266878992319
Test Loss:  0.0012948347721248865
Valid Loss:  0.0009801134001463652
Epoch:  35  	Training Loss: 0.0010446093510836363
Test Loss:  0.0012357952073216438
Valid Loss:  0.0012434511445462704
Epoch:  36  	Training Loss: 0.0013020571786910295
Test Loss:  0.0019073148723691702
Valid Loss:  0.0015125423669815063
Epoch:  37  	Training Loss: 0.0015770134050399065
Test Loss:  0.0018229247070848942
Valid Loss:  0.0019524081144481897
Epoch:  38  	Training Loss: 0.0020022918470203876
Test Loss:  0.0032190128695219755
Valid Loss:  0.0026809442788362503
Epoch:  39  	Training Loss: 0.0027502872981131077
Test Loss:  0.002758642192929983
Valid Loss:  0.0030204160138964653
Epoch:  40  	Training Loss: 0.003077383153140545
Test Loss:  0.0014537390088662505
Valid Loss:  0.0010534534230828285
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.0011287282686680555
Test Loss:  0.0012069251388311386
Valid Loss:  0.0008734361617825925
Epoch:  42  	Training Loss: 0.0009444193565286696
Test Loss:  0.0010866668308153749
Valid Loss:  0.0008224847842939198
Epoch:  43  	Training Loss: 0.0008886968716979027
Test Loss:  0.001068206736817956
Valid Loss:  0.0008197745773941278
Epoch:  44  	Training Loss: 0.0008849799050949514
Test Loss:  0.0010614797938615084
Valid Loss:  0.0008186009363271296
Epoch:  45  	Training Loss: 0.0008834194741211832
Test Loss:  0.001056803041137755
Valid Loss:  0.0008176428964361548
Epoch:  46  	Training Loss: 0.0008821930969133973
Test Loss:  0.0010527228005230427
Valid Loss:  0.0008168187341652811
Epoch:  47  	Training Loss: 0.0008812109590508044
Test Loss:  0.0010492533911019564
Valid Loss:  0.0008160799043253064
Epoch:  48  	Training Loss: 0.0008803420350886881
Test Loss:  0.0010459988843649626
Valid Loss:  0.0008154278621077538
Epoch:  49  	Training Loss: 0.0008795952307991683
Test Loss:  0.0010431131813675165
Valid Loss:  0.0008148711640387774
Epoch:  50  	Training Loss: 0.0008789437124505639
Test Loss:  0.001040440984070301
Valid Loss:  0.0008143843151628971
Epoch:  51  	Training Loss: 0.000878386665135622
Test Loss:  0.001038039568811655
Valid Loss:  0.0008139665005728602
Epoch:  52  	Training Loss: 0.000877898302860558
Test Loss:  0.0010255787055939436
Valid Loss:  0.0008061282569542527
Epoch:  53  	Training Loss: 0.0008697076700627804
Test Loss:  0.0010129637084901333
Valid Loss:  0.0007988728466443717
Epoch:  54  	Training Loss: 0.0008620136650279164
Test Loss:  0.001001665834337473
Valid Loss:  0.0007923705270513892
Epoch:  55  	Training Loss: 0.0008550882339477539
Test Loss:  0.0009923999896273017
Valid Loss:  0.0007873735157772899
Epoch:  56  	Training Loss: 0.0008494192734360695
Test Loss:  0.000984708545729518
Valid Loss:  0.000783383147791028
Epoch:  57  	Training Loss: 0.0008448750013485551
Test Loss:  0.000978680676780641
Valid Loss:  0.000780155067332089
Epoch:  58  	Training Loss: 0.0008412174647673965
Test Loss:  0.0009735900675877929
Valid Loss:  0.0007775076664984226
Epoch:  59  	Training Loss: 0.0008382809464819729
Test Loss:  0.000969278160482645
Valid Loss:  0.0007753355894237757
Epoch:  60  	Training Loss: 0.0008358060149475932
Test Loss:  0.0009658366325311363
Valid Loss:  0.0007734911632724106
Epoch:  61  	Training Loss: 0.0008337292238138616
Test Loss:  0.0009632222354412079
Valid Loss:  0.000771779683418572
Epoch:  62  	Training Loss: 0.0008321073837578297
Test Loss:  0.0009610138367861509
Valid Loss:  0.0007644622819498181
Epoch:  63  	Training Loss: 0.0008249333477579057
Test Loss:  0.0009617923060432076
Valid Loss:  0.0007612993940711021
Epoch:  64  	Training Loss: 0.0008220989257097244
Test Loss:  0.0009615321177989244
Valid Loss:  0.0007595092756673694
Epoch:  65  	Training Loss: 0.0008203341858461499
Test Loss:  0.0009611625573597848
Valid Loss:  0.0007580822566524148
Epoch:  66  	Training Loss: 0.0008189193904399872
Test Loss:  0.0009606075473129749
Valid Loss:  0.0007567516877315938
Epoch:  67  	Training Loss: 0.0008176445844583213
Test Loss:  0.0009600096382200718
Valid Loss:  0.0007555248448625207
Epoch:  68  	Training Loss: 0.0008164889877662063
Test Loss:   14%|█▍        | 69/500 [01:00<02:27,  2.93it/s] 14%|█▍        | 71/500 [01:06<08:30,  1.19s/it] 15%|█▍        | 73/500 [01:06<06:06,  1.17it/s] 15%|█▌        | 75/500 [01:06<04:23,  1.61it/s] 15%|█▌        | 77/500 [01:06<03:11,  2.21it/s] 16%|█▌        | 79/500 [01:07<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:13<08:14,  1.18s/it] 17%|█▋        | 83/500 [01:13<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:13<04:13,  1.63it/s] 17%|█▋        | 87/500 [01:13<03:04,  2.23it/s] 18%|█▊        | 89/500 [01:13<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:20<07:58,  1.17s/it] 19%|█▊        | 93/500 [01:20<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:20<04:06,  1.65it/s] 19%|█▉        | 97/500 [01:20<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:20<02:12,  3.03it/s] 20%|██        | 101/500 [01:26<07:45,  1.17s/it] 21%|██        | 103/500 [01:27<05:32,  1.19it/s] 21%|██        | 105/500 [01:27<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:27<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:27<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:33<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:33<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:33<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:34<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:34<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:40<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:40<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:40<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:40<02:46,  2.25it/s] 26%|██▌       | 129/500 [01:41<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:47<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:47<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:47<03:41,  1.65it/s]0.0009594264556653798
Valid Loss:  0.0007543429965153337
Epoch:  69  	Training Loss: 0.0008153915405273438
Test Loss:  0.0009588597458787262
Valid Loss:  0.0007532340823672712
Epoch:  70  	Training Loss: 0.0008143787272274494
Test Loss:  0.0009579882025718689
Valid Loss:  0.0007522227824665606
Epoch:  71  	Training Loss: 0.0008133732480928302
Test Loss:  0.0009575156727805734
Valid Loss:  0.0007511115400120616
Epoch:  72  	Training Loss: 0.0008122997242026031
Test Loss:  0.0009524180786684155
Valid Loss:  0.0007494108285754919
Epoch:  73  	Training Loss: 0.0008107030298560858
Test Loss:  0.0009491752134636045
Valid Loss:  0.0007474105805158615
Epoch:  74  	Training Loss: 0.0008093180949799716
Test Loss:  0.0009467437630519271
Valid Loss:  0.0007454983424395323
Epoch:  75  	Training Loss: 0.0008079617982730269
Test Loss:  0.0009445340256206691
Valid Loss:  0.0007434888975694776
Epoch:  76  	Training Loss: 0.0008064479334279895
Test Loss:  0.0009426393080502748
Valid Loss:  0.0007413808489218354
Epoch:  77  	Training Loss: 0.000804722832981497
Test Loss:  0.0009409365011379123
Valid Loss:  0.0007391637191176414
Epoch:  78  	Training Loss: 0.0008028268348425627
Test Loss:  0.0009394107619300485
Valid Loss:  0.0007370037492364645
Epoch:  79  	Training Loss: 0.000800981477368623
Test Loss:  0.0009378104005008936
Valid Loss:  0.0007349550141952932
Epoch:  80  	Training Loss: 0.0007991669699549675
Test Loss:  0.0009363142307847738
Valid Loss:  0.0007328231586143374
Epoch:  81  	Training Loss: 0.0007971205050125718
Test Loss:  0.0009348505991511047
Valid Loss:  0.0007305265171453357
Epoch:  82  	Training Loss: 0.0007948842830955982
Test Loss:  0.0009345360449515283
Valid Loss:  0.0007298332639038563
Epoch:  83  	Training Loss: 0.000794149236753583
Test Loss:  0.0009340507094748318
Valid Loss:  0.000729093502741307
Epoch:  84  	Training Loss: 0.0007933615706861019
Test Loss:  0.0009334789356216788
Valid Loss:  0.0007283544400706887
Epoch:  85  	Training Loss: 0.0007925916579551995
Test Loss:  0.0009328932501375675
Valid Loss:  0.0007273771916516125
Epoch:  86  	Training Loss: 0.000791794853284955
Test Loss:  0.000932262628339231
Valid Loss:  0.0007263260777108371
Epoch:  87  	Training Loss: 0.0007909114356152713
Test Loss:  0.0009315838688053191
Valid Loss:  0.0007252939976751804
Epoch:  88  	Training Loss: 0.0007900408236309886
Test Loss:  0.0009309679735451937
Valid Loss:  0.0007242736755870283
Epoch:  89  	Training Loss: 0.0007891848799772561
Test Loss:  0.0009303033584728837
Valid Loss:  0.0007232686621136963
Epoch:  90  	Training Loss: 0.0007882713107392192
Test Loss:  0.000929617031943053
Valid Loss:  0.0007221980486065149
Epoch:  91  	Training Loss: 0.0007872291607782245
Test Loss:  0.0009289107983931899
Valid Loss:  0.000721061893273145
Epoch:  92  	Training Loss: 0.00078611820936203
Test Loss:  0.0009254951146431267
Valid Loss:  0.0007187079172581434
Epoch:  93  	Training Loss: 0.0007837631274014711
Test Loss:  0.0009229197166860104
Valid Loss:  0.0007162489928305149
Epoch:  94  	Training Loss: 0.0007816992001608014
Test Loss:  0.0009209447307512164
Valid Loss:  0.0007139167282730341
Epoch:  95  	Training Loss: 0.0007798968581482768
Test Loss:  0.0009194008307531476
Valid Loss:  0.0007116250926628709
Epoch:  96  	Training Loss: 0.0007783302571624517
Test Loss:  0.000918070669285953
Valid Loss:  0.0007095006876625121
Epoch:  97  	Training Loss: 0.0007768996292725205
Test Loss:  0.0009166920790448785
Valid Loss:  0.0007074361201375723
Epoch:  98  	Training Loss: 0.0007754951366223395
Test Loss:  0.0009152807178907096
Valid Loss:  0.0007054374436847866
Epoch:  99  	Training Loss: 0.0007741304580122232
Test Loss:  0.0009139965986832976
Valid Loss:  0.0007035229355096817
Epoch:  100  	Training Loss: 0.0007728138007223606
Test Loss:  0.0009128018282353878
Valid Loss:  0.0007016518502496183
Epoch:  101  	Training Loss: 0.0007715506944805384
Test Loss:  0.0009116110159084201
Valid Loss:  0.0006998189492151141
Epoch:  102  	Training Loss: 0.0007703075534664094
Test Loss:  0.0009117209701798856
Valid Loss:  0.000697701470926404
Epoch:  103  	Training Loss: 0.0007682038703933358
Test Loss:  0.0009120535105466843
Valid Loss:  0.0006967863300815225
Epoch:  104  	Training Loss: 0.0007672025822103024
Test Loss:  0.0009120428003370762
Valid Loss:  0.0006962064653635025
Epoch:  105  	Training Loss: 0.000766474287956953
Test Loss:  0.0009115278371609747
Valid Loss:  0.0006958249723538756
Epoch:  106  	Training Loss: 0.0007660756236873567
Test Loss:  0.0009109270176850259
Valid Loss:  0.0006955373100936413
Epoch:  107  	Training Loss: 0.0007657482055947185
Test Loss:  0.0009103271877393126
Valid Loss:  0.000695235503371805
Epoch:  108  	Training Loss: 0.0007654415676370263
Test Loss:  0.0009097402216866612
Valid Loss:  0.0006949342787265778
Epoch:  109  	Training Loss: 0.0007651530322618783
Test Loss:  0.0009092105319723487
Valid Loss:  0.000694630725774914
Epoch:  110  	Training Loss: 0.0007648846367374063
Test Loss:  0.0009086125064641237
Valid Loss:  0.0006943303742446005
Epoch:  111  	Training Loss: 0.000764633936341852
Test Loss:  0.0009080271702259779
Valid Loss:  0.0006940307794138789
Epoch:  112  	Training Loss: 0.0007643855060450733
Test Loss:  0.0009080256568267941
Valid Loss:  0.00069373135920614
Epoch:  113  	Training Loss: 0.0007641597185283899
Test Loss:  0.0009079932933673263
Valid Loss:  0.0006934243720024824
Epoch:  114  	Training Loss: 0.0007639155955985188
Test Loss:  0.0009079408482648432
Valid Loss:  0.0006931194802746177
Epoch:  115  	Training Loss: 0.0007636725204065442
Test Loss:  0.0009078772854991257
Valid Loss:  0.0006928169168531895
Epoch:  116  	Training Loss: 0.0007634313078597188
Test Loss:  0.0009078012080863118
Valid Loss:  0.0006925170309841633
Epoch:  117  	Training Loss: 0.000763187650591135
Test Loss:  0.0009077094728127122
Valid Loss:  0.0006922062020748854
Epoch:  118  	Training Loss: 0.0007629254250787199
Test Loss:  0.000907610694412142
Valid Loss:  0.0006918949075043201
Epoch:  119  	Training Loss: 0.0007626630831509829
Test Loss:  0.000907494337297976
Valid Loss:  0.000691561377607286
Epoch:  120  	Training Loss: 0.0007623575511388481
Test Loss:  0.000907373963855207
Valid Loss:  0.000691229768563062
Epoch:  121  	Training Loss: 0.0007620527176186442
Test Loss:  0.000907254172489047
Valid Loss:  0.0006908965297043324
Epoch:  122  	Training Loss: 0.0007617487572133541
Test Loss:  0.0009045432670973241
Valid Loss:  0.0006897799321450293
Epoch:  123  	Training Loss: 0.0007605990394949913
Test Loss:  0.0009024881292134523
Valid Loss:  0.0006887956988066435
Epoch:  124  	Training Loss: 0.0007596760988235474
Test Loss:  0.0009007395128719509
Valid Loss:  0.0006880114087834954
Epoch:  125  	Training Loss: 0.0007589250453747809
Test Loss:  0.0008992180810309947
Valid Loss:  0.0006873435340821743
Epoch:  126  	Training Loss: 0.0007583358092233539
Test Loss:  0.0008980459533631802
Valid Loss:  0.0006868536584079266
Epoch:  127  	Training Loss: 0.0007579204975627363
Test Loss:  0.0008970949565991759
Valid Loss:  0.0006865060422569513
Epoch:  128  	Training Loss: 0.0007576028001494706
Test Loss:  0.0008961273124441504
Valid Loss:  0.0006861845613457263
Epoch:  129  	Training Loss: 0.0007572948234155774
Test Loss:  0.000895174453034997
Valid Loss:  0.000685873266775161
Epoch:  130  	Training Loss: 0.0007570002926513553
Test Loss:  0.0008943218272179365
Valid Loss:  0.0006856413674540818
Epoch:  131  	Training Loss: 0.0007567440043203533
Test Loss:  0.0008934830548241735
Valid Loss:  0.0006854241946712136
Epoch:  132  	Training Loss: 0.0007564947009086609
Test Loss:  0.0008911625482141972
Valid Loss:  0.0006829268531873822
Epoch:  133  	Training Loss: 0.0007544952677562833
Test Loss:  0.0008892720798030496
Valid Loss:  0.0006805367884226143
Epoch:  134  	Training Loss: 0.0007526184199377894
Test Loss:  0.0008875634521245956
Valid Loss:  0.0006781028350815177
Epoch:  135  	Training Loss: 0.0007507511181756854
Test Loss:  0.0008859778754413128
Valid Loss:  0.0006757497321814299
Epoch:  136  	Training Loss: 0.0007489625131711364
Test Loss:  0.0008844833937473595
Valid Loss:  0.0006735135684721172
 27%|██▋       | 137/500 [01:47<02:41,  2.25it/s] 28%|██▊       | 139/500 [01:47<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:54<07:05,  1.18s/it] 29%|██▊       | 143/500 [01:54<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:54<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:54<02:38,  2.22it/s] 30%|██▉       | 149/500 [01:54<01:57,  2.99it/s] 30%|███       | 151/500 [02:00<06:48,  1.17s/it] 31%|███       | 153/500 [02:01<04:51,  1.19it/s] 31%|███       | 155/500 [02:01<03:29,  1.65it/s] 31%|███▏      | 157/500 [02:01<02:32,  2.25it/s] 32%|███▏      | 159/500 [02:01<01:52,  3.02it/s] 32%|███▏      | 161/500 [02:07<06:39,  1.18s/it] 33%|███▎      | 163/500 [02:07<04:44,  1.18it/s] 33%|███▎      | 165/500 [02:08<03:24,  1.64it/s] 33%|███▎      | 167/500 [02:08<02:28,  2.24it/s] 34%|███▍      | 169/500 [02:08<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:14<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:14<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:14<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:15<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:15<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:21<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:21<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:21<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:21<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:22<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:28<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:28<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:28<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:28<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:28<01:38,  3.04it/s] 40%|████      | 201/500 [02:35<05:53,  1.18s/it] 41%|████      | 203/500 [02:35<04:12,  1.18it/s]Epoch:  137  	Training Loss: 0.0007472627330571413
Test Loss:  0.0008831219747662544
Valid Loss:  0.0006713395705446601
Epoch:  138  	Training Loss: 0.0007456183084286749
Test Loss:  0.0008818854112178087
Valid Loss:  0.0006692378083243966
Epoch:  139  	Training Loss: 0.0007440853514708579
Test Loss:  0.0008807680569589138
Valid Loss:  0.0006669848226010799
Epoch:  140  	Training Loss: 0.0007426167139783502
Test Loss:  0.0008796975016593933
Valid Loss:  0.0006647838745266199
Epoch:  141  	Training Loss: 0.0007412065751850605
Test Loss:  0.0008787102997303009
Valid Loss:  0.0006625571986660361
Epoch:  142  	Training Loss: 0.0007396847940981388
Test Loss:  0.0008802130469121039
Valid Loss:  0.0006615185411646962
Epoch:  143  	Training Loss: 0.0007386052748188376
Test Loss:  0.0008807927370071411
Valid Loss:  0.000660885067190975
Epoch:  144  	Training Loss: 0.0007377515430562198
Test Loss:  0.0008808173588477075
Valid Loss:  0.0006606248207390308
Epoch:  145  	Training Loss: 0.0007372723775915802
Test Loss:  0.0008805558318272233
Valid Loss:  0.0006605099770240486
Epoch:  146  	Training Loss: 0.0007370179519057274
Test Loss:  0.000880217005033046
Valid Loss:  0.0006604819791391492
Epoch:  147  	Training Loss: 0.0007368723745457828
Test Loss:  0.0008799296338111162
Valid Loss:  0.0006604569498449564
Epoch:  148  	Training Loss: 0.0007367618381977081
Test Loss:  0.0008797104237601161
Valid Loss:  0.0006604294758290052
Epoch:  149  	Training Loss: 0.0007366734789684415
Test Loss:  0.0008794517489150167
Valid Loss:  0.0006604113150388002
Epoch:  150  	Training Loss: 0.000736624002456665
Test Loss:  0.000879222818184644
Valid Loss:  0.0006603961810469627
Epoch:  151  	Training Loss: 0.0007365909405052662
Test Loss:  0.0008790124556981027
Valid Loss:  0.0006603839574381709
Epoch:  152  	Training Loss: 0.0007365704514086246
Test Loss:  0.0008766286773607135
Valid Loss:  0.0006594734732061625
Epoch:  153  	Training Loss: 0.0007355647394433618
Test Loss:  0.0008747188840061426
Valid Loss:  0.0006586344679817557
Epoch:  154  	Training Loss: 0.0007346856873482466
Test Loss:  0.0008731953566893935
Valid Loss:  0.0006578512256965041
Epoch:  155  	Training Loss: 0.00073384924326092
Test Loss:  0.0008717660675756633
Valid Loss:  0.0006570784607902169
Epoch:  156  	Training Loss: 0.0007330278749577701
Test Loss:  0.0008705201908014715
Valid Loss:  0.0006563289789482951
Epoch:  157  	Training Loss: 0.0007322171004489064
Test Loss:  0.0008693162817507982
Valid Loss:  0.0006555841537192464
Epoch:  158  	Training Loss: 0.0007314106333069503
Test Loss:  0.000868146657012403
Valid Loss:  0.0006548446253873408
Epoch:  159  	Training Loss: 0.000730606319848448
Test Loss:  0.0008670095703564584
Valid Loss:  0.0006541077746078372
Epoch:  160  	Training Loss: 0.0007298060227185488
Test Loss:  0.0008658922743052244
Valid Loss:  0.0006533742416650057
Epoch:  161  	Training Loss: 0.0007290086359716952
Test Loss:  0.0008648002985864878
Valid Loss:  0.0006526437355205417
Epoch:  162  	Training Loss: 0.0007282145088538527
Test Loss:  0.0008650960517115891
Valid Loss:  0.0006506913341581821
Epoch:  163  	Training Loss: 0.0007269175839610398
Test Loss:  0.0008652437827549875
Valid Loss:  0.0006487929495051503
Epoch:  164  	Training Loss: 0.000725658843293786
Test Loss:  0.0008652845281176269
Valid Loss:  0.0006469416548497975
Epoch:  165  	Training Loss: 0.0007244271691888571
Test Loss:  0.0008652134565636516
Valid Loss:  0.0006450173677876592
Epoch:  166  	Training Loss: 0.0007230706396512687
Test Loss:  0.0008650919189676642
Valid Loss:  0.0006431381916627288
Epoch:  167  	Training Loss: 0.0007217456586658955
Test Loss:  0.0008649293449707329
Valid Loss:  0.0006413005758076906
Epoch:  168  	Training Loss: 0.0007204529247246683
Test Loss:  0.0008647334761917591
Valid Loss:  0.0006395028904080391
Epoch:  169  	Training Loss: 0.0007191900513134897
Test Loss:  0.0008643309120088816
Valid Loss:  0.0006377412937581539
Epoch:  170  	Training Loss: 0.0007179527310654521
Test Loss:  0.0008637316059321165
Valid Loss:  0.0006359097314998507
Epoch:  171  	Training Loss: 0.0007165856077335775
Test Loss:  0.0008631257805973291
Valid Loss:  0.000634115538559854
Epoch:  172  	Training Loss: 0.0007152504986152053
Test Loss:  0.0008631555829197168
Valid Loss:  0.0006337909726426005
Epoch:  173  	Training Loss: 0.0007149311131797731
Test Loss:  0.0008631134405732155
Valid Loss:  0.000633474497590214
Epoch:  174  	Training Loss: 0.0007146144635044038
Test Loss:  0.0008630136726424098
Valid Loss:  0.0006331660551950336
Epoch:  175  	Training Loss: 0.0007142940303310752
Test Loss:  0.0008628683281131089
Valid Loss:  0.0006328526651486754
Epoch:  176  	Training Loss: 0.0007139586959965527
Test Loss:  0.0008626932976767421
Valid Loss:  0.000632542883977294
Epoch:  177  	Training Loss: 0.0007136190542951226
Test Loss:  0.0008624910842627287
Valid Loss:  0.0006322258850559592
Epoch:  178  	Training Loss: 0.0007132620085030794
Test Loss:  0.0008622767636552453
Valid Loss:  0.0006319110398180783
Epoch:  179  	Training Loss: 0.0007129050209186971
Test Loss:  0.0008620418375357985
Valid Loss:  0.0006315871141850948
Epoch:  180  	Training Loss: 0.0007125260890461504
Test Loss:  0.0008618010906502604
Valid Loss:  0.0006312651094049215
Epoch:  181  	Training Loss: 0.0007121488451957703
Test Loss:  0.0008615534170530736
Valid Loss:  0.0006309435702860355
Epoch:  182  	Training Loss: 0.0007117724744603038
Test Loss:  0.0008589201024733484
Valid Loss:  0.0006285773124545813
Epoch:  183  	Training Loss: 0.0007097463239915669
Test Loss:  0.0008568194461986423
Valid Loss:  0.0006262244423851371
Epoch:  184  	Training Loss: 0.0007077524205669761
Test Loss:  0.0008546755416318774
Valid Loss:  0.0006238983478397131
Epoch:  185  	Training Loss: 0.0007057839538902044
Test Loss:  0.0008525467128492892
Valid Loss:  0.0006216028705239296
Epoch:  186  	Training Loss: 0.0007037839386612177
Test Loss:  0.0008504042634740472
Valid Loss:  0.0006192437140271068
Epoch:  187  	Training Loss: 0.000701701850630343
Test Loss:  0.0008482425473630428
Valid Loss:  0.00061682058731094
Epoch:  188  	Training Loss: 0.0006995090516284108
Test Loss:  0.0008461179677397013
Valid Loss:  0.0006144327344372869
Epoch:  189  	Training Loss: 0.0006973452982492745
Test Loss:  0.0008440158562734723
Valid Loss:  0.0006120740436017513
Epoch:  190  	Training Loss: 0.0006952100084163249
Test Loss:  0.0008419340010732412
Valid Loss:  0.000609748880378902
Epoch:  191  	Training Loss: 0.0006931018433533609
Test Loss:  0.0008398149511776865
Valid Loss:  0.0006073657423257828
Epoch:  192  	Training Loss: 0.0006908682407811284
Test Loss:  0.0008399661164730787
Valid Loss:  0.0006070313975214958
Epoch:  193  	Training Loss: 0.0006905243499204516
Test Loss:  0.0008398881182074547
Valid Loss:  0.0006067231297492981
Epoch:  194  	Training Loss: 0.0006901865708641708
Test Loss:  0.0008396949851885438
Valid Loss:  0.0006064262124709785
Epoch:  195  	Training Loss: 0.0006898469291627407
Test Loss:  0.0008394327596761286
Valid Loss:  0.0006061268504709005
Epoch:  196  	Training Loss: 0.0006894898833706975
Test Loss:  0.0008391431765630841
Valid Loss:  0.0006058308063074946
Epoch:  197  	Training Loss: 0.000689134350977838
Test Loss:  0.0008388400310650468
Valid Loss:  0.0006055377889424562
Epoch:  198  	Training Loss: 0.0006887794006615877
Test Loss:  0.0008385323453694582
Valid Loss:  0.0006052461103536189
Epoch:  199  	Training Loss: 0.0006884242175146937
Test Loss:  0.0008382232626900077
Valid Loss:  0.0006049556541256607
Epoch:  200  	Training Loss: 0.0006880707805976272
Test Loss:  0.000837913656141609
Valid Loss:  0.0006046659545972943
Epoch:  201  	Training Loss: 0.0006877176929265261
Test Loss:  0.0008376050973311067
Valid Loss:  0.0006043770699761808
Epoch:  202  	Training Loss: 0.0006873656529933214
Test Loss:  0.0008372276788577437
Valid Loss:  0.0006040740991011262
Epoch:  203  	Training Loss: 0.0006869774078950286
Test Loss:  0.000836704159155488
Valid Loss:  0.0006038144929334521
Epoch:  204  	Training Loss: 0.0006866304902359843
Test Loss:  0.0008361045038327575
Valid Loss:  0.0006035693804733455
Epoch:  205  	Training Loss: 0.0006863202434033155
 41%|████      | 205/500 [02:35<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:35<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:35<01:37,  3.00it/s] 42%|████▏     | 211/500 [02:41<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:42<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:42<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:42<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:42<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:48<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:48<03:55,  1.17it/s] 45%|████▌     | 225/500 [02:49<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:49<02:03,  2.22it/s] 46%|████▌     | 229/500 [02:49<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:55<05:20,  1.19s/it] 47%|████▋     | 233/500 [02:55<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:55<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:56<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:56<01:27,  2.99it/s] 48%|████▊     | 241/500 [03:02<05:06,  1.18s/it] 49%|████▊     | 243/500 [03:02<03:38,  1.18it/s] 49%|████▉     | 245/500 [03:02<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:02<01:53,  2.23it/s] 50%|████▉     | 249/500 [03:03<01:23,  3.00it/s] 50%|█████     | 251/500 [03:09<04:56,  1.19s/it] 51%|█████     | 253/500 [03:09<03:30,  1.17it/s] 51%|█████     | 255/500 [03:09<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:09<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:09<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:16<04:45,  1.19s/it] 53%|█████▎    | 263/500 [03:16<03:23,  1.17it/s] 53%|█████▎    | 265/500 [03:16<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:16<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:16<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:23<04:32,  1.19s/it]Test Loss:  0.0008354887249879539
Valid Loss:  0.0006033416138961911
Epoch:  206  	Training Loss: 0.0006860242574475706
Test Loss:  0.0008348654955625534
Valid Loss:  0.0006031689699739218
Epoch:  207  	Training Loss: 0.0006857971893623471
Test Loss:  0.0008342587389051914
Valid Loss:  0.0006029947544448078
Epoch:  208  	Training Loss: 0.0006855748943053186
Test Loss:  0.0008336383034475148
Valid Loss:  0.0006028295611031353
Epoch:  209  	Training Loss: 0.0006853785598650575
Test Loss:  0.000833095982670784
Valid Loss:  0.0006026726914569736
Epoch:  210  	Training Loss: 0.0006852060905657709
Test Loss:  0.0008325320086441934
Valid Loss:  0.0006025251350365579
Epoch:  211  	Training Loss: 0.0006850429344922304
Test Loss:  0.0008319889893755317
Valid Loss:  0.0006023906171321869
Epoch:  212  	Training Loss: 0.0006848840275779366
Test Loss:  0.0008304443908855319
Valid Loss:  0.000600870291236788
Epoch:  213  	Training Loss: 0.0006834767409600317
Test Loss:  0.0008291378035210073
Valid Loss:  0.0005993657978251576
Epoch:  214  	Training Loss: 0.000682042445987463
Test Loss:  0.0008279961766675115
Valid Loss:  0.0005977359833195806
Epoch:  215  	Training Loss: 0.0006804417935200036
Test Loss:  0.0008269252721220255
Valid Loss:  0.0005961294518783689
Epoch:  216  	Training Loss: 0.0006788722239434719
Test Loss:  0.0008259540772996843
Valid Loss:  0.0005945531884208322
Epoch:  217  	Training Loss: 0.0006773396162316203
Test Loss:  0.0008249959209933877
Valid Loss:  0.0005930039915256202
Epoch:  218  	Training Loss: 0.000675834424328059
Test Loss:  0.0008240252500399947
Valid Loss:  0.0005914797075092793
Epoch:  219  	Training Loss: 0.000674330280162394
Test Loss:  0.0008227379294112325
Valid Loss:  0.000589911884162575
Epoch:  220  	Training Loss: 0.0006727298605255783
Test Loss:  0.0008214768022298813
Valid Loss:  0.0005883708945475519
Epoch:  221  	Training Loss: 0.0006711595342494547
Test Loss:  0.0008202342432923615
Valid Loss:  0.0005868568550795317
Epoch:  222  	Training Loss: 0.0006696163909509778
Test Loss:  0.0008166102925315499
Valid Loss:  0.0005847259890288115
Epoch:  223  	Training Loss: 0.0006673105526715517
Test Loss:  0.0008134565432555974
Valid Loss:  0.0005827255663461983
Epoch:  224  	Training Loss: 0.0006651519797742367
Test Loss:  0.0008106544846668839
Valid Loss:  0.0005807621637359262
Epoch:  225  	Training Loss: 0.0006630739662796259
Test Loss:  0.0008081258274614811
Valid Loss:  0.0005788657581433654
Epoch:  226  	Training Loss: 0.0006610878626815975
Test Loss:  0.0008058652747422457
Valid Loss:  0.0005770322168245912
Epoch:  227  	Training Loss: 0.0006591925630345941
Test Loss:  0.0008038397645577788
Valid Loss:  0.0005753128789365292
Epoch:  228  	Training Loss: 0.0006573780556209385
Test Loss:  0.0008020455716177821
Valid Loss:  0.0005736766033805907
Epoch:  229  	Training Loss: 0.0006556636653840542
Test Loss:  0.0008003312395885587
Valid Loss:  0.0005720641347579658
Epoch:  230  	Training Loss: 0.000653965980745852
Test Loss:  0.0007986314594745636
Valid Loss:  0.0005704174982383847
Epoch:  231  	Training Loss: 0.00065218610689044
Test Loss:  0.000797184300608933
Valid Loss:  0.0005688514211215079
Epoch:  232  	Training Loss: 0.0006505156634375453
Test Loss:  0.0007982028764672577
Valid Loss:  0.000567261129617691
Epoch:  233  	Training Loss: 0.0006486668717116117
Test Loss:  0.000798344612121582
Valid Loss:  0.0005657924339175224
Epoch:  234  	Training Loss: 0.0006469248328357935
Test Loss:  0.0007978793000802398
Valid Loss:  0.0005643425392918289
Epoch:  235  	Training Loss: 0.0006451241206377745
Test Loss:  0.0007971200393512845
Valid Loss:  0.0005629536462947726
Epoch:  236  	Training Loss: 0.0006433879025280476
Test Loss:  0.0007961667724885046
Valid Loss:  0.000561614811886102
Epoch:  237  	Training Loss: 0.0006416552932932973
Test Loss:  0.0007950820727273822
Valid Loss:  0.0005602706223726273
Epoch:  238  	Training Loss: 0.0006398874102160335
Test Loss:  0.000793966930359602
Valid Loss:  0.000558972533326596
Epoch:  239  	Training Loss: 0.0006381752900779247
Test Loss:  0.0007928452105261385
Valid Loss:  0.0005577194970101118
Epoch:  240  	Training Loss: 0.0006364625878632069
Test Loss:  0.0007916842587292194
Valid Loss:  0.0005564605817198753
Epoch:  241  	Training Loss: 0.0006347187445499003
Test Loss:  0.000790544378105551
Valid Loss:  0.0005552438087761402
Epoch:  242  	Training Loss: 0.0006330317119136453
Test Loss:  0.0007897288887761533
Valid Loss:  0.0005547429900616407
Epoch:  243  	Training Loss: 0.0006323035340756178
Test Loss:  0.0007894631708040833
Valid Loss:  0.0005544791929423809
Epoch:  244  	Training Loss: 0.000631974427960813
Test Loss:  0.0007893603178672493
Valid Loss:  0.0005543888546526432
Epoch:  245  	Training Loss: 0.0006317913648672402
Test Loss:  0.0007894054288044572
Valid Loss:  0.0005543429870158434
Epoch:  246  	Training Loss: 0.0006317170918919146
Test Loss:  0.0007894516456872225
Valid Loss:  0.0005543002625927329
Epoch:  247  	Training Loss: 0.0006316611543297768
Test Loss:  0.0007894743466749787
Valid Loss:  0.0005542573053389788
Epoch:  248  	Training Loss: 0.0006316093495115638
Test Loss:  0.0007894610753282905
Valid Loss:  0.0005542167345993221
Epoch:  249  	Training Loss: 0.0006315592909231782
Test Loss:  0.0007894457667134702
Valid Loss:  0.0005541704595088959
Epoch:  250  	Training Loss: 0.0006315115606412292
Test Loss:  0.00078940688399598
Valid Loss:  0.0005541234277188778
Epoch:  251  	Training Loss: 0.0006314635975286365
Test Loss:  0.0007893523434177041
Valid Loss:  0.0005540778511203825
Epoch:  252  	Training Loss: 0.000631416798569262
Test Loss:  0.0007904590456746519
Valid Loss:  0.0005533476360142231
Epoch:  253  	Training Loss: 0.0006308996817097068
Test Loss:  0.0007910595741122961
Valid Loss:  0.0005527144530788064
Epoch:  254  	Training Loss: 0.0006304454291239381
Test Loss:  0.0007913201698102057
Valid Loss:  0.0005521608400158584
Epoch:  255  	Training Loss: 0.0006300430977717042
Test Loss:  0.0007913393201306462
Valid Loss:  0.000551653909496963
Epoch:  256  	Training Loss: 0.0006296709179878235
Test Loss:  0.0007912254659458995
Valid Loss:  0.000551183067727834
Epoch:  257  	Training Loss: 0.0006293254555203021
Test Loss:  0.0007909904816187918
Valid Loss:  0.0005507354508154094
Epoch:  258  	Training Loss: 0.0006289936718530953
Test Loss:  0.0007906773244030774
Valid Loss:  0.0005503046559169888
Epoch:  259  	Training Loss: 0.0006286504794843495
Test Loss:  0.0007902815705165267
Valid Loss:  0.00054984848247841
Epoch:  260  	Training Loss: 0.0006282665999606252
Test Loss:  0.0007898351759649813
Valid Loss:  0.000549366173800081
Epoch:  261  	Training Loss: 0.0006278223590925336
Test Loss:  0.000789420329965651
Valid Loss:  0.0005488998722285032
Epoch:  262  	Training Loss: 0.0006273927865549922
Test Loss:  0.0007864702492952347
Valid Loss:  0.0005486054578796029
Epoch:  263  	Training Loss: 0.0006270292215049267
Test Loss:  0.0007848539389669895
Valid Loss:  0.0005483492277562618
Epoch:  264  	Training Loss: 0.0006267299177125096
Test Loss:  0.0007838458986952901
Valid Loss:  0.0005480999825522304
Epoch:  265  	Training Loss: 0.0006264476687647402
Test Loss:  0.0007831291877664626
Valid Loss:  0.0005478553357534111
Epoch:  266  	Training Loss: 0.0006261729868128896
Test Loss:  0.0007825741195119917
Valid Loss:  0.0005476181395351887
Epoch:  267  	Training Loss: 0.0006259089568629861
Test Loss:  0.0007821292383596301
Valid Loss:  0.0005473900237120688
Epoch:  268  	Training Loss: 0.0006256535416468978
Test Loss:  0.0007816872093826532
Valid Loss:  0.0005471679614856839
Epoch:  269  	Training Loss: 0.0006254016188904643
Test Loss:  0.0007812515832483768
Valid Loss:  0.0005469497991725802
Epoch:  270  	Training Loss: 0.0006251526065170765
Test Loss:  0.0007808246882632375
Valid Loss:  0.0005467369919642806
Epoch:  271  	Training Loss: 0.0006249062716960907
Test Loss:  0.0007804066990502179
Valid Loss:  0.0005465273279696703
Epoch:  272  	Training Loss: 0.0006246629636734724
Test Loss:  0.0007785599445924163
Valid Loss:  0.000544844486285001
Epoch:  273  	Training Loss: 0.0006224543321877718
Test Loss:  0.0007768223294988275
Valid Loss:   55%|█████▍    | 273/500 [03:23<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:23<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:23<01:40,  2.21it/s] 56%|█████▌    | 279/500 [03:23<01:14,  2.97it/s] 56%|█████▌    | 281/500 [03:29<04:14,  1.16s/it] 57%|█████▋    | 283/500 [03:30<03:00,  1.20it/s] 57%|█████▋    | 285/500 [03:30<02:09,  1.66it/s] 57%|█████▋    | 287/500 [03:30<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:30<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:36<04:03,  1.17s/it] 59%|█████▊    | 293/500 [03:36<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:37<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:37<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:37<01:07,  2.99it/s] 60%|██████    | 301/500 [03:43<03:56,  1.19s/it] 61%|██████    | 303/500 [03:43<02:47,  1.17it/s] 61%|██████    | 305/500 [03:43<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:44<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:44<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:50<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:50<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:50<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:50<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:51<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:57<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:57<02:30,  1.17it/s] 65%|██████▌   | 325/500 [03:57<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:57<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:57<00:58,  2.94it/s] 66%|██████▌   | 331/500 [04:04<03:21,  1.19s/it] 67%|██████▋   | 333/500 [04:04<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:04<01:42,  1.62it/s] 67%|██████▋   | 337/500 [04:04<01:13,  2.21it/s] 68%|██████▊   | 339/500 [04:04<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:11<03:08,  1.18s/it]0.0005432054167613387
Epoch:  274  	Training Loss: 0.0006203092634677887
Test Loss:  0.0007752334931865335
Valid Loss:  0.0005416212952695787
Epoch:  275  	Training Loss: 0.0006182582001201808
Test Loss:  0.0007738284766674042
Valid Loss:  0.0005401166272349656
Epoch:  276  	Training Loss: 0.0006162807694636285
Test Loss:  0.0007724373135715723
Valid Loss:  0.0005386303528212011
Epoch:  277  	Training Loss: 0.0006141950143501163
Test Loss:  0.0007710913196206093
Valid Loss:  0.000537187559530139
Epoch:  278  	Training Loss: 0.0006121644400991499
Test Loss:  0.0007697827531956136
Valid Loss:  0.0005357851623557508
Epoch:  279  	Training Loss: 0.000610179384239018
Test Loss:  0.0007685016025789082
Valid Loss:  0.0005344185628928244
Epoch:  280  	Training Loss: 0.0006082383915781975
Test Loss:  0.0007672521169297397
Valid Loss:  0.000533091661054641
Epoch:  281  	Training Loss: 0.000606346526183188
Test Loss:  0.0007660319679416716
Valid Loss:  0.0005318037001416087
Epoch:  282  	Training Loss: 0.0006045025074854493
Test Loss:  0.0007649873150512576
Valid Loss:  0.0005290209082886577
Epoch:  283  	Training Loss: 0.0006009748321957886
Test Loss:  0.0007628975436091423
Valid Loss:  0.0005266215885058045
Epoch:  284  	Training Loss: 0.0005979715497232974
Test Loss:  0.0007606376893818378
Valid Loss:  0.0005243459017947316
Epoch:  285  	Training Loss: 0.0005951593047939241
Test Loss:  0.0007584205595776439
Valid Loss:  0.0005222379695624113
Epoch:  286  	Training Loss: 0.0005925629520788789
Test Loss:  0.0007560850353911519
Valid Loss:  0.0005203293403610587
Epoch:  287  	Training Loss: 0.0005901599070057273
Test Loss:  0.0007536822813563049
Valid Loss:  0.0005186128546483815
Epoch:  288  	Training Loss: 0.0005878789816051722
Test Loss:  0.0007512458832934499
Valid Loss:  0.0005170111544430256
Epoch:  289  	Training Loss: 0.0005856711650267243
Test Loss:  0.000748676888179034
Valid Loss:  0.0005155585240572691
Epoch:  290  	Training Loss: 0.0005835919873788953
Test Loss:  0.0007460634806193411
Valid Loss:  0.0005143003072589636
Epoch:  291  	Training Loss: 0.0005817820783704519
Test Loss:  0.0007435968145728111
Valid Loss:  0.0005130905192345381
Epoch:  292  	Training Loss: 0.000580067397095263
Test Loss:  0.0007436472224071622
Valid Loss:  0.0005108483601361513
Epoch:  293  	Training Loss: 0.0005774623714387417
Test Loss:  0.0007399868918582797
Valid Loss:  0.0005088109173811972
Epoch:  294  	Training Loss: 0.0005749965785071254
Test Loss:  0.0007373255211859941
Valid Loss:  0.0005069138715043664
Epoch:  295  	Training Loss: 0.000572656630538404
Test Loss:  0.0007344637997448444
Valid Loss:  0.0005051617044955492
Epoch:  296  	Training Loss: 0.0005704370560124516
Test Loss:  0.0007316729752346873
Valid Loss:  0.0005034705973230302
Epoch:  297  	Training Loss: 0.0005682734772562981
Test Loss:  0.0007291621877811849
Valid Loss:  0.0005019414820708334
Epoch:  298  	Training Loss: 0.0005662026815116405
Test Loss:  0.0007262062863446772
Valid Loss:  0.0005004960112273693
Epoch:  299  	Training Loss: 0.0005642774049192667
Test Loss:  0.0007235403172671795
Valid Loss:  0.0004991462337784469
Epoch:  300  	Training Loss: 0.0005624346085824072
Test Loss:  0.0007207767339423299
Valid Loss:  0.000497824396006763
Epoch:  301  	Training Loss: 0.0005606782506220043
Test Loss:  0.0007181638502515852
Valid Loss:  0.0004965408588759601
Epoch:  302  	Training Loss: 0.000558966479729861
Test Loss:  0.0007186271250247955
Valid Loss:  0.0004964780528098345
Epoch:  303  	Training Loss: 0.0005589139182120562
Test Loss:  0.0007183261914178729
Valid Loss:  0.0004964283434674144
Epoch:  304  	Training Loss: 0.0005588682251982391
Test Loss:  0.0007180493557825685
Valid Loss:  0.0004963805549778044
Epoch:  305  	Training Loss: 0.0005588251515291631
Test Loss:  0.0007177820662036538
Valid Loss:  0.0004963362589478493
Epoch:  306  	Training Loss: 0.0005587838822975755
Test Loss:  0.0007175208884291351
Valid Loss:  0.000496292719617486
Epoch:  307  	Training Loss: 0.0005587450577877462
Test Loss:  0.0007172676268965006
Valid Loss:  0.0004962512757629156
Epoch:  308  	Training Loss: 0.0005587072810158134
Test Loss:  0.000717021175660193
Valid Loss:  0.0004962121020071208
Epoch:  309  	Training Loss: 0.0005586715415120125
Test Loss:  0.0007167835719883442
Valid Loss:  0.0004961746162734926
Epoch:  310  	Training Loss: 0.0005586377810686827
Test Loss:  0.0007165509159676731
Valid Loss:  0.0004961385275237262
Epoch:  311  	Training Loss: 0.0005586057668551803
Test Loss:  0.0007163257105275989
Valid Loss:  0.0004961041267961264
Epoch:  312  	Training Loss: 0.0005585744511336088
Test Loss:  0.0007162692490965128
Valid Loss:  0.0004960497026331723
Epoch:  313  	Training Loss: 0.0005585156613960862
Test Loss:  0.0007158914813771844
Valid Loss:  0.0004959968500770628
Epoch:  314  	Training Loss: 0.0005584596074186265
Test Loss:  0.0007156142964959145
Valid Loss:  0.0004959458601661026
Epoch:  315  	Training Loss: 0.0005584055325016379
Test Loss:  0.0007153460755944252
Valid Loss:  0.0004958966746926308
Epoch:  316  	Training Loss: 0.0005583527963608503
Test Loss:  0.0007150985766202211
Valid Loss:  0.0004958497593179345
Epoch:  317  	Training Loss: 0.0005583021556958556
Test Loss:  0.0007148567237891257
Valid Loss:  0.000495803658850491
Epoch:  318  	Training Loss: 0.000558252795599401
Test Loss:  0.000714621099177748
Valid Loss:  0.000495760643389076
Epoch:  319  	Training Loss: 0.0005582108860835433
Test Loss:  0.0007141545647755265
Valid Loss:  0.0004957190249115229
Epoch:  320  	Training Loss: 0.0005581728764809668
Test Loss:  0.0007140115485526621
Valid Loss:  0.0004956795019097626
Epoch:  321  	Training Loss: 0.0005581359728239477
Test Loss:  0.0007137855282053351
Valid Loss:  0.0004956410848535597
Epoch:  322  	Training Loss: 0.000558100116904825
Test Loss:  0.0007113347528502345
Valid Loss:  0.0004948099376633763
Epoch:  323  	Training Loss: 0.0005568914348259568
Test Loss:  0.0007092042360454798
Valid Loss:  0.000494037929456681
Epoch:  324  	Training Loss: 0.0005557605181820691
Test Loss:  0.0007072509615682065
Valid Loss:  0.0004932994488626719
Epoch:  325  	Training Loss: 0.0005546640604734421
Test Loss:  0.0007054418092593551
Valid Loss:  0.0004925845423713326
Epoch:  326  	Training Loss: 0.0005536098615266383
Test Loss:  0.0007038350449874997
Valid Loss:  0.0004919121856801212
Epoch:  327  	Training Loss: 0.0005526246968656778
Test Loss:  0.0007024025544524193
Valid Loss:  0.0004913005977869034
Epoch:  328  	Training Loss: 0.0005516861565411091
Test Loss:  0.0007010368863120675
Valid Loss:  0.000490710255689919
Epoch:  329  	Training Loss: 0.0005507682217285037
Test Loss:  0.0006997258751653135
Valid Loss:  0.0004901349311694503
Epoch:  330  	Training Loss: 0.0005498722894117236
Test Loss:  0.0006985014770179987
Valid Loss:  0.0004895806196145713
Epoch:  331  	Training Loss: 0.0005490127368830144
Test Loss:  0.0006973912240937352
Valid Loss:  0.0004890532582066953
Epoch:  332  	Training Loss: 0.0005481868865899742
Test Loss:  0.0006965443608351052
Valid Loss:  0.0004884549416601658
Epoch:  333  	Training Loss: 0.000547232455573976
Test Loss:  0.0006954864365980029
Valid Loss:  0.00048787376726977527
Epoch:  334  	Training Loss: 0.0005463039269670844
Test Loss:  0.000694319314789027
Valid Loss:  0.0004873052821494639
Epoch:  335  	Training Loss: 0.0005453935591503978
Test Loss:  0.0006931079551577568
Valid Loss:  0.00048675303696654737
Epoch:  336  	Training Loss: 0.0005444487323984504
Test Loss:  0.0006918047438375652
Valid Loss:  0.0004861816705670208
Epoch:  337  	Training Loss: 0.000543457455933094
Test Loss:  0.0006905021145939827
Valid Loss:  0.0004856163577642292
Epoch:  338  	Training Loss: 0.0005424628034234047
Test Loss:  0.000689216423779726
Valid Loss:  0.00048504574806429446
Epoch:  339  	Training Loss: 0.0005414866609498858
Test Loss:  0.0006879470311105251
Valid Loss:  0.00048447970766574144
Epoch:  340  	Training Loss: 0.0005405242554843426
Test Loss:  0.0006866846815682948
Valid Loss:  0.00048392172902822495
Epoch:  341  	Training Loss: 0.0005395689513534307
Test Loss:  0.000685438746586442
Valid Loss:  0.00048337673069909215
 69%|██████▊   | 343/500 [04:11<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:11<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:11<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:11<00:50,  2.98it/s] 70%|███████   | 351/500 [04:18<02:55,  1.18s/it] 71%|███████   | 353/500 [04:18<02:04,  1.18it/s] 71%|███████   | 355/500 [04:18<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:18<01:03,  2.23it/s] 72%|███████▏  | 359/500 [04:18<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:24<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:24<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:25<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:25<01:00,  2.18it/s] 74%|███████▍  | 369/500 [04:25<00:45,  2.89it/s] 74%|███████▍  | 371/500 [04:31<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:31<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:32<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:32<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:32<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:38<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:38<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:38<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:39<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:39<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:45<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:45<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:45<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:45<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:46<00:33,  2.98it/s] 80%|████████  | 401/500 [04:52<01:57,  1.19s/it] 81%|████████  | 403/500 [04:52<01:22,  1.17it/s] 81%|████████  | 405/500 [04:52<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:52<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:53<00:30,  2.94it/s]Epoch:  342  	Training Loss: 0.0005386301781982183
Test Loss:  0.0006858195993117988
Valid Loss:  0.000482765375636518
Epoch:  343  	Training Loss: 0.0005375412292778492
Test Loss:  0.0006854915409348905
Valid Loss:  0.0004822083283215761
Epoch:  344  	Training Loss: 0.0005364815006032586
Test Loss:  0.0006847804761491716
Valid Loss:  0.0004816680448129773
Epoch:  345  	Training Loss: 0.000535380095243454
Test Loss:  0.0006838327972218394
Valid Loss:  0.00048109330236911774
Epoch:  346  	Training Loss: 0.0005341569776646793
Test Loss:  0.0006829159101471305
Valid Loss:  0.00048030941979959607
Epoch:  347  	Training Loss: 0.0005329733248800039
Test Loss:  0.0006820359267294407
Valid Loss:  0.00047955289483070374
Epoch:  348  	Training Loss: 0.0005317819304764271
Test Loss:  0.0006810956401750445
Valid Loss:  0.00047879130579531193
Epoch:  349  	Training Loss: 0.0005305518861860037
Test Loss:  0.0006802124553360045
Valid Loss:  0.0004780593444593251
Epoch:  350  	Training Loss: 0.0005293599097058177
Test Loss:  0.0006793589564040303
Valid Loss:  0.0004773528780788183
Epoch:  351  	Training Loss: 0.0005282040219753981
Test Loss:  0.0006785397999919951
Valid Loss:  0.00047667179023846984
Epoch:  352  	Training Loss: 0.0005270809051580727
Test Loss:  0.0006753703346475959
Valid Loss:  0.00047624806757085025
Epoch:  353  	Training Loss: 0.0005267271189950407
Test Loss:  0.0006746828439645469
Valid Loss:  0.00047601727419532835
Epoch:  354  	Training Loss: 0.0005264695500954986
Test Loss:  0.0006736957002431154
Valid Loss:  0.0004758160503115505
Epoch:  355  	Training Loss: 0.0005262619233690202
Test Loss:  0.0006728778826072812
Valid Loss:  0.00047565659042447805
Epoch:  356  	Training Loss: 0.0005260921316221356
Test Loss:  0.0006721600657328963
Valid Loss:  0.00047552306205034256
Epoch:  357  	Training Loss: 0.0005259478930383921
Test Loss:  0.0006715288036502898
Valid Loss:  0.0004754130495712161
Epoch:  358  	Training Loss: 0.0005258264718577266
Test Loss:  0.0006709728622809052
Valid Loss:  0.0004753204120788723
Epoch:  359  	Training Loss: 0.0005257237935438752
Test Loss:  0.0006704847910441458
Valid Loss:  0.0004752426175400615
Epoch:  360  	Training Loss: 0.0005256333388388157
Test Loss:  0.0006700601661577821
Valid Loss:  0.0004751748638227582
Epoch:  361  	Training Loss: 0.0005255547002889216
Test Loss:  0.0006696980562992394
Valid Loss:  0.0004751166270580143
Epoch:  362  	Training Loss: 0.0005254830466583371
Test Loss:  0.0006680303486064076
Valid Loss:  0.0004743264289572835
Epoch:  363  	Training Loss: 0.0005243566120043397
Test Loss:  0.0006664820830337703
Valid Loss:  0.00047342508332803845
Epoch:  364  	Training Loss: 0.0005232805851846933
Test Loss:  0.0006650361465290189
Valid Loss:  0.0004725680919364095
Epoch:  365  	Training Loss: 0.0005222389008849859
Test Loss:  0.0006636159960180521
Valid Loss:  0.00047170487232506275
Epoch:  366  	Training Loss: 0.0005211480893194675
Test Loss:  0.0006622850196436048
Valid Loss:  0.00047088440624065697
Epoch:  367  	Training Loss: 0.0005201040767133236
Test Loss:  0.0006610311684198678
Valid Loss:  0.0004701062280219048
Epoch:  368  	Training Loss: 0.0005191024974919856
Test Loss:  0.0006598463514819741
Valid Loss:  0.0004693623341154307
Epoch:  369  	Training Loss: 0.0005180889274924994
Test Loss:  0.0006586649105884135
Valid Loss:  0.00046861020382493734
Epoch:  370  	Training Loss: 0.0005170575459487736
Test Loss:  0.0006575429579243064
Valid Loss:  0.0004678920086007565
Epoch:  371  	Training Loss: 0.0005160693544894457
Test Loss:  0.0006564793293364346
Valid Loss:  0.00046720431419089437
Epoch:  372  	Training Loss: 0.0005151181248947978
Test Loss:  0.0006609703414142132
Valid Loss:  0.0004661839338950813
Epoch:  373  	Training Loss: 0.000513317296281457
Test Loss:  0.0006580655463039875
Valid Loss:  0.00046510895481333137
Epoch:  374  	Training Loss: 0.0005119002889841795
Test Loss:  0.0006566063966602087
Valid Loss:  0.00046418156125582755
Epoch:  375  	Training Loss: 0.0005105552263557911
Test Loss:  0.0006548301316797733
Valid Loss:  0.00046326295705512166
Epoch:  376  	Training Loss: 0.0005092682549729943
Test Loss:  0.0006531385588459671
Valid Loss:  0.00046236353227868676
Epoch:  377  	Training Loss: 0.0005080078262835741
Test Loss:  0.0006514142733067274
Valid Loss:  0.0004615088691934943
Epoch:  378  	Training Loss: 0.0005068298196420074
Test Loss:  0.000649792724289
Valid Loss:  0.00046069594100117683
Epoch:  379  	Training Loss: 0.0005056835943832994
Test Loss:  0.0006484129698947072
Valid Loss:  0.00045987963676452637
Epoch:  380  	Training Loss: 0.0005045809084549546
Test Loss:  0.0006465950282290578
Valid Loss:  0.00045910931657999754
Epoch:  381  	Training Loss: 0.0005035114008933306
Test Loss:  0.0006453258101828396
Valid Loss:  0.0004583807021845132
Epoch:  382  	Training Loss: 0.000502465816680342
Test Loss:  0.0006456900737248361
Valid Loss:  0.0004583786067087203
Epoch:  383  	Training Loss: 0.0005024345591664314
Test Loss:  0.0006459077703766525
Valid Loss:  0.0004583694681059569
Epoch:  384  	Training Loss: 0.0005024074343964458
Test Loss:  0.0006460312288254499
Valid Loss:  0.0004583556728903204
Epoch:  385  	Training Loss: 0.0005023826379328966
Test Loss:  0.0006460951408371329
Valid Loss:  0.0004583363770507276
Epoch:  386  	Training Loss: 0.0005023585399612784
Test Loss:  0.0006461213924922049
Valid Loss:  0.0004583154513966292
Epoch:  387  	Training Loss: 0.0005023345001973212
Test Loss:  0.000646122032776475
Valid Loss:  0.00045829202281311154
Epoch:  388  	Training Loss: 0.0005023106932640076
Test Loss:  0.0006461091106757522
Valid Loss:  0.00045826833229511976
Epoch:  389  	Training Loss: 0.0005022871773689985
Test Loss:  0.0006460861768573523
Valid Loss:  0.00045824339031241834
Epoch:  390  	Training Loss: 0.0005022645927965641
Test Loss:  0.0006460585864260793
Valid Loss:  0.0004582187975756824
Epoch:  391  	Training Loss: 0.0005022413097321987
Test Loss:  0.0006460256408900023
Valid Loss:  0.00045819373917765915
Epoch:  392  	Training Loss: 0.000502217561006546
Test Loss:  0.0006458921125158668
Valid Loss:  0.0004581041866913438
Epoch:  393  	Training Loss: 0.0005021037068217993
Test Loss:  0.0006457767449319363
Valid Loss:  0.00045801664236932993
Epoch:  394  	Training Loss: 0.0005019897944293916
Test Loss:  0.0006456715054810047
Valid Loss:  0.00045793040771968663
Epoch:  395  	Training Loss: 0.0005018759984523058
Test Loss:  0.0006455715629272163
Valid Loss:  0.0004578454827424139
Epoch:  396  	Training Loss: 0.0005017630173824728
Test Loss:  0.0006454773829318583
Valid Loss:  0.00045776006300002337
Epoch:  397  	Training Loss: 0.0005016497452743351
Test Loss:  0.0006453670212067664
Valid Loss:  0.0004576738574542105
Epoch:  398  	Training Loss: 0.0005015369388274848
Test Loss:  0.0006452543893828988
Valid Loss:  0.0004575899220071733
Epoch:  399  	Training Loss: 0.0005014241323806345
Test Loss:  0.0006451422232203186
Valid Loss:  0.0004575051134452224
Epoch:  400  	Training Loss: 0.0005013118498027325
Test Loss:  0.0006450296496041119
Valid Loss:  0.00045742132351733744
Epoch:  401  	Training Loss: 0.0005011995672248304
Test Loss:  0.0006449189968407154
Valid Loss:  0.0004573362530209124
Epoch:  402  	Training Loss: 0.0005010898457840085
Test Loss:  0.0006416125106625259
Valid Loss:  0.0004564638657029718
Epoch:  403  	Training Loss: 0.0004999982775188982
Test Loss:  0.0006399464327841997
Valid Loss:  0.00045574147952720523
Epoch:  404  	Training Loss: 0.0004989593289792538
Test Loss:  0.0006384666194207966
Valid Loss:  0.0004550520097836852
Epoch:  405  	Training Loss: 0.0004978992510586977
Test Loss:  0.0006368116592057049
Valid Loss:  0.00045434970525093377
Epoch:  406  	Training Loss: 0.0004968024441041052
Test Loss:  0.000635216711089015
Valid Loss:  0.00045366730773821473
Epoch:  407  	Training Loss: 0.0004957271739840508
Test Loss:  0.0006336536607705057
Valid Loss:  0.00045300295460037887
Epoch:  408  	Training Loss: 0.0004946730332449079
Test Loss:  0.0006321191322058439
Valid Loss:  0.0004523565585259348
Epoch:  409  	Training Loss: 0.0004936405457556248
Test Loss:  0.0006306107388809323
Valid Loss:  0.00045172733371146023
 82%|████████▏ | 411/500 [04:59<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:59<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:59<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:59<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:59<00:27,  2.96it/s] 84%|████████▍ | 421/500 [05:06<01:33,  1.18s/it] 85%|████████▍ | 423/500 [05:06<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:06<00:46,  1.63it/s] 85%|████████▌ | 427/500 [05:06<00:32,  2.23it/s] 86%|████████▌ | 429/500 [05:06<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:13<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:13<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:13<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:13<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:13<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:19<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:20<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:20<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:20<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:20<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:26<00:57,  1.16s/it] 91%|█████████ | 453/500 [05:26<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:26<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:27<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:27<00:13,  2.94it/s] 92%|█████████▏| 461/500 [05:33<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:33<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:33<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:34<00:15,  2.20it/s] 94%|█████████▍| 469/500 [05:34<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:40<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:40<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:40<00:15,  1.63it/s]Epoch:  410  	Training Loss: 0.0004926281981170177
Test Loss:  0.0006291276658885181
Valid Loss:  0.00045111519284546375
Epoch:  411  	Training Loss: 0.000491635815706104
Test Loss:  0.0006276705535128713
Valid Loss:  0.0004505180404521525
Epoch:  412  	Training Loss: 0.0004906631074845791
Test Loss:  0.0006259360234253109
Valid Loss:  0.00044997414806857705
Epoch:  413  	Training Loss: 0.0004898268962278962
Test Loss:  0.0006243564421311021
Valid Loss:  0.0004494335444178432
Epoch:  414  	Training Loss: 0.000488939112983644
Test Loss:  0.0006229500868357718
Valid Loss:  0.00044891820289194584
Epoch:  415  	Training Loss: 0.00048807711573317647
Test Loss:  0.000621667830273509
Valid Loss:  0.0004484322271309793
Epoch:  416  	Training Loss: 0.00048723776126280427
Test Loss:  0.0006204735254868865
Valid Loss:  0.0004479647905100137
Epoch:  417  	Training Loss: 0.0004864191578235477
Test Loss:  0.0006193456938490272
Valid Loss:  0.0004475158639252186
Epoch:  418  	Training Loss: 0.00048561953008174896
Test Loss:  0.0006182655924931169
Valid Loss:  0.00044708530185744166
Epoch:  419  	Training Loss: 0.00048484347644262016
Test Loss:  0.0006172258872538805
Valid Loss:  0.00044666932080872357
Epoch:  420  	Training Loss: 0.0004840836045332253
Test Loss:  0.0006162147037684917
Valid Loss:  0.0004462652141228318
Epoch:  421  	Training Loss: 0.00048334035091102123
Test Loss:  0.0006152295391075313
Valid Loss:  0.0004458744078874588
Epoch:  422  	Training Loss: 0.0004826119402423501
Test Loss:  0.0006162854842841625
Valid Loss:  0.00044552842155098915
Epoch:  423  	Training Loss: 0.00048191595124080777
Test Loss:  0.0006163055077195168
Valid Loss:  0.00044521677773445845
Epoch:  424  	Training Loss: 0.0004813650739379227
Test Loss:  0.000615883560385555
Valid Loss:  0.0004448970139492303
Epoch:  425  	Training Loss: 0.0004808813100680709
Test Loss:  0.0006153106223791838
Valid Loss:  0.0004445888916961849
Epoch:  426  	Training Loss: 0.00048044801224023104
Test Loss:  0.0006146637024357915
Valid Loss:  0.0004442830104380846
Epoch:  427  	Training Loss: 0.00048004635027609766
Test Loss:  0.0006140932673588395
Valid Loss:  0.000444011326180771
Epoch:  428  	Training Loss: 0.00047970269224606454
Test Loss:  0.0006135135772638023
Valid Loss:  0.00044374808203428984
Epoch:  429  	Training Loss: 0.0004793755942955613
Test Loss:  0.0006129331886768341
Valid Loss:  0.0004434922302607447
Epoch:  430  	Training Loss: 0.00047905961400829256
Test Loss:  0.0006124037317931652
Valid Loss:  0.00044325541239231825
Epoch:  431  	Training Loss: 0.0004787734360434115
Test Loss:  0.0006118831224739552
Valid Loss:  0.000443024531705305
Epoch:  432  	Training Loss: 0.0004784985212609172
Test Loss:  0.0006120252655819058
Valid Loss:  0.0004430269473232329
Epoch:  433  	Training Loss: 0.0004784578341059387
Test Loss:  0.0006119816680438817
Valid Loss:  0.0004430072149261832
Epoch:  434  	Training Loss: 0.00047841918421909213
Test Loss:  0.0006118855671957135
Valid Loss:  0.0004429812543094158
Epoch:  435  	Training Loss: 0.0004783805925399065
Test Loss:  0.0006117722950875759
Valid Loss:  0.0004429544205777347
Epoch:  436  	Training Loss: 0.0004783451440744102
Test Loss:  0.0006116579752415419
Valid Loss:  0.00044293078826740384
Epoch:  437  	Training Loss: 0.0004783115873578936
Test Loss:  0.0006115457508713007
Valid Loss:  0.00044290925143286586
Epoch:  438  	Training Loss: 0.0004782786127179861
Test Loss:  0.0006114352727308869
Valid Loss:  0.0004428870161063969
Epoch:  439  	Training Loss: 0.00047824610373936594
Test Loss:  0.0006113274721428752
Valid Loss:  0.0004428657703101635
Epoch:  440  	Training Loss: 0.0004782137111760676
Test Loss:  0.0006112317787483335
Valid Loss:  0.0004428437096066773
Epoch:  441  	Training Loss: 0.0004781824245583266
Test Loss:  0.0006111395196057856
Valid Loss:  0.0004428234533406794
Epoch:  442  	Training Loss: 0.0004781503521371633
Test Loss:  0.000610071700066328
Valid Loss:  0.0004426295345183462
Epoch:  443  	Training Loss: 0.0004779831797350198
Test Loss:  0.0006094384007155895
Valid Loss:  0.00044248526683077216
Epoch:  444  	Training Loss: 0.0004778294824063778
Test Loss:  0.0006090066162869334
Valid Loss:  0.00044236931717023253
Epoch:  445  	Training Loss: 0.00047768192598596215
Test Loss:  0.0006086677312850952
Valid Loss:  0.0004422637284733355
Epoch:  446  	Training Loss: 0.0004775365814566612
Test Loss:  0.000608377973549068
Valid Loss:  0.00044216285459697247
Epoch:  447  	Training Loss: 0.0004773898399434984
Test Loss:  0.0006081133033148944
Valid Loss:  0.00044206331949681044
Epoch:  448  	Training Loss: 0.0004772451356984675
Test Loss:  0.0006078631849959493
Valid Loss:  0.00044196652015671134
Epoch:  449  	Training Loss: 0.0004771021194756031
Test Loss:  0.0006076261051930487
Valid Loss:  0.0004418703611008823
Epoch:  450  	Training Loss: 0.0004769611987285316
Test Loss:  0.0006073969416320324
Valid Loss:  0.0004417740274220705
Epoch:  451  	Training Loss: 0.00047682138392701745
Test Loss:  0.0006071759853512049
Valid Loss:  0.0004416764131747186
Epoch:  452  	Training Loss: 0.0004766785423271358
Test Loss:  0.0006074426346458495
Valid Loss:  0.00044156983494758606
Epoch:  453  	Training Loss: 0.0004765128833241761
Test Loss:  0.0006074820412322879
Valid Loss:  0.00044145097490400076
Epoch:  454  	Training Loss: 0.0004763639881275594
Test Loss:  0.0006074175471439958
Valid Loss:  0.0004413385468069464
Epoch:  455  	Training Loss: 0.000476236135000363
Test Loss:  0.0006073155673220754
Valid Loss:  0.00044122376129962504
Epoch:  456  	Training Loss: 0.0004761152667924762
Test Loss:  0.0006071958923712373
Valid Loss:  0.0004411109257489443
Epoch:  457  	Training Loss: 0.0004760047886520624
Test Loss:  0.0006070720846764743
Valid Loss:  0.0004410013207234442
Epoch:  458  	Training Loss: 0.0004759062430821359
Test Loss:  0.0006069500232115388
Valid Loss:  0.0004409011744428426
Epoch:  459  	Training Loss: 0.000475813343655318
Test Loss:  0.0006068335496820509
Valid Loss:  0.00044081074884161353
Epoch:  460  	Training Loss: 0.00047572594485245645
Test Loss:  0.0006067180656827986
Valid Loss:  0.00044072247692383826
Epoch:  461  	Training Loss: 0.0004756428534165025
Test Loss:  0.0006066105561330914
Valid Loss:  0.0004406374064274132
Epoch:  462  	Training Loss: 0.00047556881327182055
Test Loss:  0.000606524059548974
Valid Loss:  0.00044013402657583356
Epoch:  463  	Training Loss: 0.00047487119445577264
Test Loss:  0.0006060339510440826
Valid Loss:  0.00043962144991382957
Epoch:  464  	Training Loss: 0.00047424889635294676
Test Loss:  0.0006048741051927209
Valid Loss:  0.0004390436224639416
Epoch:  465  	Training Loss: 0.00047365750651806593
Test Loss:  0.0006044299807399511
Valid Loss:  0.00043859006837010384
Epoch:  466  	Training Loss: 0.0004731588705908507
Test Loss:  0.0006033429526723921
Valid Loss:  0.00043809294584207237
Epoch:  467  	Training Loss: 0.0004727051127701998
Test Loss:  0.000603009364567697
Valid Loss:  0.00043774544610641897
Epoch:  468  	Training Loss: 0.00047229649499058723
Test Loss:  0.0006020206492394209
Valid Loss:  0.0004373723641037941
Epoch:  469  	Training Loss: 0.0004719155258499086
Test Loss:  0.0006012663943693042
Valid Loss:  0.0004370401147753
Epoch:  470  	Training Loss: 0.00047157303197309375
Test Loss:  0.0006011545774526894
Valid Loss:  0.0004367911606095731
Epoch:  471  	Training Loss: 0.00047126918798312545
Test Loss:  0.000600374536588788
Valid Loss:  0.00043649677536450326
Epoch:  472  	Training Loss: 0.0004710127832368016
Test Loss:  0.0006005830364301801
Valid Loss:  0.00043587666004896164
Epoch:  473  	Training Loss: 0.00047017785254865885
Test Loss:  0.00060064229182899
Valid Loss:  0.0004354584380052984
Epoch:  474  	Training Loss: 0.00046963535714894533
Test Loss:  0.0006001659203320742
Valid Loss:  0.00043507051304914057
Epoch:  475  	Training Loss: 0.00046923226909711957
Test Loss:  0.000600003229919821
Valid Loss:  0.00043483637273311615
Epoch:  476  	Training Loss: 0.0004689238267019391
Test Loss:  0.000599786639213562
Valid Loss:  0.00043461748282425106
Epoch:  477  	Training Loss: 0.00046866602497175336
Test Loss:  0.0005995543906465173
Valid Loss:   95%|█████████▌| 477/500 [05:40<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:41<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:47<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:47<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:47<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:47<00:05,  2.20it/s] 98%|█████████▊| 489/500 [05:47<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:54<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:54<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:54<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:54<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:54<00:00,  2.97it/s]100%|██████████| 500/500 [05:54<00:00,  1.41it/s]
0.0004344147746451199
Epoch:  478  	Training Loss: 0.0004684484447352588
Test Loss:  0.0005993170198053122
Valid Loss:  0.00043424489558674395
Epoch:  479  	Training Loss: 0.00046829419443383813
Test Loss:  0.0005991030484437943
Valid Loss:  0.00043409463251009583
Epoch:  480  	Training Loss: 0.0004681748687289655
Test Loss:  0.0005989121273159981
Valid Loss:  0.0004339634906500578
Epoch:  481  	Training Loss: 0.0004680779529735446
Test Loss:  0.0005987513577565551
Valid Loss:  0.0004338841827120632
Epoch:  482  	Training Loss: 0.0004679940757341683
Test Loss:  0.0005961809074506164
Valid Loss:  0.00043310524779371917
Epoch:  483  	Training Loss: 0.0004674084484577179
Test Loss:  0.0005949462065473199
Valid Loss:  0.00043271566391922534
Epoch:  484  	Training Loss: 0.0004670290509238839
Test Loss:  0.0005944453878328204
Valid Loss:  0.00043256243225187063
Epoch:  485  	Training Loss: 0.00046683859545737505
Test Loss:  0.0005941245472058654
Valid Loss:  0.0004324548353906721
Epoch:  486  	Training Loss: 0.0004667083849199116
Test Loss:  0.0005938699468970299
Valid Loss:  0.00043239540536887944
Epoch:  487  	Training Loss: 0.0004666110617108643
Test Loss:  0.0005936434026807547
Valid Loss:  0.0004323453758843243
Epoch:  488  	Training Loss: 0.0004665367887355387
Test Loss:  0.0005934720393270254
Valid Loss:  0.00043231455492787063
Epoch:  489  	Training Loss: 0.0004664733714889735
Test Loss:  0.000593247648794204
Valid Loss:  0.00043227989226579666
Epoch:  490  	Training Loss: 0.0004664160078391433
Test Loss:  0.0005930411862209439
Valid Loss:  0.0004322506138123572
Epoch:  491  	Training Loss: 0.00046636330080218613
Test Loss:  0.0005928529426455498
Valid Loss:  0.0004322286695241928
Epoch:  492  	Training Loss: 0.00046631437726318836
Test Loss:  0.0005919610266573727
Valid Loss:  0.00043205750989727676
Epoch:  493  	Training Loss: 0.0004661956918425858
Test Loss:  0.0005914195789955556
Valid Loss:  0.00043191848089918494
Epoch:  494  	Training Loss: 0.0004660916165448725
Test Loss:  0.0005910880863666534
Valid Loss:  0.00043179874774068594
Epoch:  495  	Training Loss: 0.00046599519555456936
Test Loss:  0.000590881216339767
Valid Loss:  0.0004316909471526742
Epoch:  496  	Training Loss: 0.00046590418787673116
Test Loss:  0.0005907503073103726
Valid Loss:  0.00043159062624908984
Epoch:  497  	Training Loss: 0.000465812481706962
Test Loss:  0.0005906665464863181
Valid Loss:  0.0004314848338253796
Epoch:  498  	Training Loss: 0.00046570750419050455
Test Loss:  0.0005906112492084503
Valid Loss:  0.00043138532782904804
Epoch:  499  	Training Loss: 0.0004656077071558684
Test Loss:  0.0005905709695070982
Valid Loss:  0.0004312894307076931
Epoch:  500  	Training Loss: 0.0004655102966353297
Test Loss:  0.0005905410507693887
Valid Loss:  0.0004311987431719899
seed is  17
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.38it/s]  1%|          | 4/500 [00:00<00:29, 16.57it/s]  1%|          | 6/500 [00:00<00:29, 16.65it/s]  2%|▏         | 8/500 [00:00<00:29, 16.63it/s]  2%|▏         | 10/500 [00:00<00:29, 16.65it/s]  2%|▏         | 12/500 [00:00<00:29, 16.49it/s]  3%|▎         | 14/500 [00:00<00:29, 16.33it/s]  3%|▎         | 16/500 [00:00<00:29, 16.26it/s]  4%|▎         | 18/500 [00:01<00:29, 16.34it/s]  4%|▍         | 20/500 [00:01<00:29, 16.47it/s]  4%|▍         | 22/500 [00:01<00:28, 16.53it/s]  5%|▍         | 24/500 [00:01<00:28, 16.59it/s]  5%|▌         | 26/500 [00:01<00:28, 16.46it/s]  6%|▌         | 28/500 [00:01<00:28, 16.42it/s]  6%|▌         | 30/500 [00:01<00:28, 16.47it/s]  6%|▋         | 32/500 [00:01<00:28, 16.51it/s]  7%|▋         | 34/500 [00:02<00:28, 16.30it/s]  7%|▋         | 36/500 [00:02<00:28, 16.09it/s]  8%|▊         | 38/500 [00:02<00:29, 15.90it/s]  8%|▊         | 40/500 [00:02<00:29, 15.59it/s]  8%|▊         | 42/500 [00:02<00:28, 15.89it/s]  9%|▉         | 44/500 [00:02<00:28, 15.99it/s]  9%|▉         | 46/500 [00:02<00:28, 15.97it/s] 10%|▉         | 48/500 [00:02<00:27, 16.24it/s] 10%|█         | 50/500 [00:03<00:27, 16.39it/s] 10%|█         | 52/500 [00:03<00:27, 16.38it/s] 11%|█         | 54/500 [00:03<00:27, 16.26it/s] 11%|█         | 56/500 [00:03<00:28, 15.81it/s] 12%|█▏        | 58/500 [00:03<00:27, 15.84it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.78it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.95it/s] 13%|█▎        | 64/500 [00:03<00:27, 15.99it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.16it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.37it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.38it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.54it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.04it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.31it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.22it/s] 16%|█▌        | 80/500 [00:04<00:26, 16.08it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.96it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.47it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.86it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.17it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.39it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.54it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.37it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.39it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.35it/s] 20%|██        | 100/500 [00:06<00:24, 16.31it/s] 20%|██        | 102/500 [00:06<00:24, 16.15it/s] 21%|██        | 104/500 [00:06<00:26, 15.07it/s] 21%|██        | 106/500 [00:06<00:25, 15.58it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.92it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.17it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.39it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.53it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.56it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.59it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.65it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.69it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.68it/s]Epoch:  1  	Training Loss: 0.12120464444160461
Test Loss:  2088.623779296875
Valid Loss:  2066.39453125
Epoch:  2  	Training Loss: 2072.63037109375
Test Loss:  159676649963520.0
Valid Loss:  160323042541568.0
Epoch:  3  	Training Loss: 160197934841856.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.66it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.67it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.69it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.70it/s] 27%|██▋       | 134/500 [00:08<00:21, 16.73it/s] 27%|██▋       | 136/500 [00:08<00:21, 16.83it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.77it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.79it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.74it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.56it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.54it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.61it/s] 30%|███       | 150/500 [00:09<00:21, 16.66it/s] 30%|███       | 152/500 [00:09<00:20, 16.74it/s] 31%|███       | 154/500 [00:09<00:20, 16.74it/s] 31%|███       | 156/500 [00:09<00:20, 16.60it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.52it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.58it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.52it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.52it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.62it/s] 34%|███▎      | 168/500 [00:10<00:19, 16.71it/s] 34%|███▍      | 170/500 [00:10<00:19, 16.77it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.82it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.60it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.70it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.65it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.28it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.36it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.40it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.43it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.54it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.35it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.50it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.43it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.42it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.49it/s] 40%|████      | 200/500 [00:12<00:18, 16.60it/s] 40%|████      | 202/500 [00:12<00:17, 16.66it/s] 41%|████      | 204/500 [00:12<00:17, 16.53it/s] 41%|████      | 206/500 [00:12<00:17, 16.50it/s] 42%|████▏     | 208/500 [00:12<00:19, 15.32it/s] 42%|████▏     | 210/500 [00:12<00:18, 15.58it/s] 42%|████▏     | 212/500 [00:13<00:19, 14.82it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.11it/s] 43%|████▎     | 216/500 [00:13<00:19, 14.40it/s] 44%|████▎     | 218/500 [00:13<00:18, 15.01it/s] 44%|████▍     | 220/500 [00:13<00:18, 15.49it/s] 44%|████▍     | 222/500 [00:13<00:17, 15.55it/s] 45%|████▍     | 224/500 [00:13<00:17, 15.94it/s] 45%|████▌     | 226/500 [00:13<00:17, 15.97it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.12it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.22it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.07it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.11it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.34it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.54it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.68it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.73it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.75it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.75it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.74it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:14, 16.78it/s] 50%|█████     | 252/500 [00:15<00:14, 16.76it/s] 51%|█████     | 254/500 [00:15<00:14, 16.59it/s] 51%|█████     | 256/500 [00:15<00:14, 16.54it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.53it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.62it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.53it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.65it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.66it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.44it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.35it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.33it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.30it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.44it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.55it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.60it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.59it/s] 57%|█████▋    | 284/500 [00:17<00:12, 16.66it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.70it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.60it/s] 58%|█████▊    | 290/500 [00:17<00:13, 15.56it/s] 58%|█████▊    | 292/500 [00:17<00:13, 15.03it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.47it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.83it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.99it/s] 60%|██████    | 300/500 [00:18<00:12, 16.09it/s] 60%|██████    | 302/500 [00:18<00:12, 16.25it/s] 61%|██████    | 304/500 [00:18<00:12, 16.04it/s] 61%|██████    | 306/500 [00:18<00:13, 14.58it/s] 62%|██████▏   | 308/500 [00:18<00:13, 13.87it/s] 62%|██████▏   | 310/500 [00:19<00:14, 13.53it/s] 62%|██████▏   | 312/500 [00:19<00:13, 14.40it/s] 63%|██████▎   | 314/500 [00:19<00:12, 15.02it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.55it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.72it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.01it/s] 64%|██████▍   | 322/500 [00:19<00:11, 16.12it/s] 65%|██████▍   | 324/500 [00:19<00:11, 15.99it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.20it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.24it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.13it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.00it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.22it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.41it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.55it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.65it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.58it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.61it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.65it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.71it/s] 70%|███████   | 350/500 [00:21<00:08, 16.69it/s] 70%|███████   | 352/500 [00:21<00:08, 16.67it/s] 71%|███████   | 354/500 [00:21<00:08, 16.65it/s] 71%|███████   | 356/500 [00:21<00:08, 16.64it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.71it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.65it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.71it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.60it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.48it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.50it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.54it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.62it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.59it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.42it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.44it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.55it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.49it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.40it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.33it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.35it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.29it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.26it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.30it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.47it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.56it/s] 80%|████████  | 400/500 [00:24<00:06, 16.65it/s] 80%|████████  | 402/500 [00:24<00:05, 16.55it/s] 81%|████████  | 404/500 [00:24<00:05, 16.64it/s] 81%|████████  | 406/500 [00:24<00:05, 16.39it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.44it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.40it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.51it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.48it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.46it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.46it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.57it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.49it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.29it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.60it/s] 86%|████████▌ | 428/500 [00:26<00:04, 15.86it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.09it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.24it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.30it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.29it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.28it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.28it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.43it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.49it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.60it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.46it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.55it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.59it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.64it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.66it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.53it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.64it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.66it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.70it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.33it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.41it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.44it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.56it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.59it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.60it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.48it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.44it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.51it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.59it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.65it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.68it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.69it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.66it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.67it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.47it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.23it/s]100%|██████████| 500/500 [00:30<00:00, 16.36it/s]100%|██████████| 500/500 [00:30<00:00, 16.30it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  17
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:16,  6.41s/it]  1%|          | 3/500 [00:06<14:11,  1.71s/it]  1%|          | 5/500 [00:06<07:08,  1.15it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<10:44,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:19<12:59,  1.61s/it]  3%|▎         | 17/500 [00:19<09:02,  1.12s/it]  4%|▍         | 19/500 [00:19<06:24,  1.25it/s]  4%|▍         | 21/500 [00:32<19:45,  2.47s/it]  5%|▍         | 23/500 [00:32<13:50,  1.74s/it]  5%|▌         | 25/500 [00:38<17:13,  2.18s/it]  5%|▌         | 27/500 [00:38<12:08,  1.54s/it]  6%|▌         | 29/500 [00:39<08:35,  1.09s/it]  6%|▌         | 31/500 [00:51<20:38,  2.64s/it]  7%|▋         | 33/500 [00:51<14:31,  1.87s/it]  7%|▋         | 35/500 [00:57<17:24,  2.25s/it]  7%|▋         | 37/500 [00:58<12:17,  1.59s/it]  8%|▊         | 39/500 [00:58<08:42,  1.13s/it]  8%|▊         | 41/500 [01:10<20:15,  2.65s/it]  9%|▊         | 43/500 [01:10<14:16,  1.87s/it]  9%|▉         | 45/500 [01:16<17:07,  2.26s/it]  9%|▉         | 47/500 [01:17<12:05,  1.60s/it] 10%|▉         | 49/500 [01:17<08:34,  1.14s/it] 10%|█         | 51/500 [01:29<20:03,  2.68s/it] 11%|█         | 53/500 [01:29<14:08,  1.90s/it] 11%|█         | 55/500 [01:36<16:49,  2.27s/it] 11%|█▏        | 57/500 [01:36<11:53,  1.61s/it] 12%|█▏        | 59/500 [01:36<08:25,  1.15s/it] 12%|█▏        | 61/500 [01:48<19:30,  2.67s/it]Epoch:  1  	Training Loss: 0.12120464444160461
Test Loss:  0.7372180223464966
Valid Loss:  0.7726395130157471
Epoch:  2  	Training Loss: 0.7606831789016724
Test Loss:  0.11719119548797607
Valid Loss:  0.1055520623922348
Epoch:  3  	Training Loss: 0.11146041005849838
Test Loss:  0.11639437079429626
Valid Loss:  0.10474124550819397
Epoch:  4  	Training Loss: 0.11065058410167694
Test Loss:  0.11638589203357697
Valid Loss:  0.10473236441612244
Epoch:  5  	Training Loss: 0.11064307391643524
Test Loss:  0.11638586223125458
Valid Loss:  0.10473234951496124
Epoch:  6  	Training Loss: 0.11064302921295166
Test Loss:  0.11638586968183517
Valid Loss:  0.10473233461380005
Epoch:  7  	Training Loss: 0.11064301431179047
Test Loss:  0.11638587713241577
Valid Loss:  0.10473232716321945
Epoch:  8  	Training Loss: 0.11064301431179047
Test Loss:  0.11638587713241577
Valid Loss:  0.10473231971263885
Epoch:  9  	Training Loss: 0.11064299941062927
Test Loss:  0.11638587713241577
Valid Loss:  0.10473231226205826
Epoch:  10  	Training Loss: 0.11064300686120987
Test Loss:  0.11638587713241577
Valid Loss:  0.10473230481147766
Epoch:  11  	Training Loss: 0.11064299941062927
Test Loss:  0.11638587713241577
Valid Loss:  0.10473231226205826
Epoch:  12  	Training Loss: 0.11064299941062927
Test Loss:  0.11638586223125458
Valid Loss:  0.10473231226205826
Epoch:  13  	Training Loss: 0.11064299941062927
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  14  	Training Loss: 0.11064299941062927
Test Loss:  0.11638585478067398
Valid Loss:  0.10473231226205826
Epoch:  15  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  17  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  18  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  19  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  20  	Training Loss: 0.11064299196004868
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  22  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  23  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  24  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  25  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  27  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  28  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  29  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  30  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  32  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  33  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  34  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  35  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  37  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  38  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  39  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  40  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  42  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473230481147766
Epoch:  43  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  44  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  45  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  47  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  48  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  49  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  50  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  52  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  53  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  54  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  55  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  57  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  58  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  59  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  60  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  62  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766 13%|█▎        | 63/500 [01:49<13:45,  1.89s/it] 13%|█▎        | 65/500 [01:55<16:25,  2.27s/it] 13%|█▎        | 67/500 [01:55<11:36,  1.61s/it] 14%|█▍        | 69/500 [01:55<08:13,  1.15s/it] 14%|█▍        | 69/500 [02:06<08:13,  1.15s/it] 14%|█▍        | 71/500 [02:07<18:58,  2.65s/it] 15%|█▍        | 73/500 [02:08<13:22,  1.88s/it] 15%|█▌        | 75/500 [02:14<15:55,  2.25s/it] 15%|█▌        | 77/500 [02:14<11:16,  1.60s/it] 16%|█▌        | 79/500 [02:14<07:59,  1.14s/it] 16%|█▌        | 79/500 [02:26<07:59,  1.14s/it] 16%|█▌        | 81/500 [02:27<18:41,  2.68s/it] 17%|█▋        | 83/500 [02:27<13:10,  1.89s/it] 17%|█▋        | 85/500 [02:33<15:44,  2.28s/it] 17%|█▋        | 87/500 [02:33<11:06,  1.61s/it] 18%|█▊        | 89/500 [02:33<07:52,  1.15s/it] 18%|█▊        | 89/500 [02:46<07:52,  1.15s/it] 18%|█▊        | 91/500 [02:46<18:17,  2.68s/it] 19%|█▊        | 93/500 [02:46<12:53,  1.90s/it] 19%|█▉        | 95/500 [02:52<15:17,  2.26s/it] 19%|█▉        | 97/500 [02:52<10:47,  1.61s/it] 20%|█▉        | 99/500 [02:53<07:38,  1.14s/it] 20%|██        | 101/500 [03:05<17:50,  2.68s/it] 21%|██        | 103/500 [03:05<12:34,  1.90s/it] 21%|██        | 105/500 [03:12<14:56,  2.27s/it] 21%|██▏       | 107/500 [03:12<10:32,  1.61s/it] 22%|██▏       | 109/500 [03:12<07:28,  1.15s/it] 22%|██▏       | 111/500 [03:24<17:20,  2.67s/it] 23%|██▎       | 113/500 [03:24<12:12,  1.89s/it] 23%|██▎       | 115/500 [03:31<14:31,  2.26s/it] 23%|██▎       | 117/500 [03:31<10:15,  1.61s/it] 24%|██▍       | 119/500 [03:31<07:16,  1.14s/it] 24%|██▍       | 121/500 [03:43<16:49,  2.66s/it]
Epoch:  63  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  64  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  65  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  67  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  68  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  69  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  70  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  72  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  73  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  74  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  75  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  77  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  78  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  79  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  80  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  82  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  83  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  84  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  85  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  87  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  88  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  89  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  90  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  92  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  93  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  94  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  95  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  97  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  98  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  99  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473229736089706
Epoch:  100  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  102  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  103  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  104  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  105  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  107  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  108  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  109  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  110  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  112  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  113  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  114  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  115  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  117  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  118  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  119  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  120  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  122  	Training Loss: 0.11064298450946808
Test Loss:   25%|██▍       | 123/500 [03:44<11:51,  1.89s/it] 25%|██▌       | 125/500 [03:50<14:08,  2.26s/it] 25%|██▌       | 127/500 [03:50<09:58,  1.60s/it] 26%|██▌       | 129/500 [03:50<07:04,  1.14s/it] 26%|██▌       | 131/500 [04:02<16:22,  2.66s/it] 27%|██▋       | 133/500 [04:03<11:33,  1.89s/it] 27%|██▋       | 135/500 [04:09<13:50,  2.27s/it] 27%|██▋       | 137/500 [04:09<09:45,  1.61s/it] 28%|██▊       | 139/500 [04:09<06:54,  1.15s/it] 28%|██▊       | 141/500 [04:22<15:59,  2.67s/it] 29%|██▊       | 143/500 [04:22<11:15,  1.89s/it] 29%|██▉       | 145/500 [04:28<13:24,  2.27s/it] 29%|██▉       | 147/500 [04:28<09:27,  1.61s/it] 30%|██▉       | 149/500 [04:28<06:42,  1.15s/it] 30%|███       | 151/500 [04:41<15:31,  2.67s/it] 31%|███       | 153/500 [04:41<10:56,  1.89s/it] 31%|███       | 155/500 [04:47<13:06,  2.28s/it] 31%|███▏      | 157/500 [04:48<09:14,  1.62s/it] 32%|███▏      | 159/500 [04:48<06:32,  1.15s/it] 32%|███▏      | 161/500 [05:00<15:11,  2.69s/it] 33%|███▎      | 163/500 [05:00<10:41,  1.90s/it] 33%|███▎      | 165/500 [05:07<12:45,  2.29s/it] 33%|███▎      | 167/500 [05:07<08:59,  1.62s/it] 34%|███▍      | 169/500 [05:07<06:22,  1.16s/it] 34%|███▍      | 171/500 [05:19<14:41,  2.68s/it] 35%|███▍      | 173/500 [05:20<10:20,  1.90s/it] 35%|███▌      | 175/500 [05:26<12:18,  2.27s/it] 35%|███▌      | 177/500 [05:26<08:40,  1.61s/it] 36%|███▌      | 179/500 [05:26<06:08,  1.15s/it]0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  123  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  124  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  125  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  127  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  128  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  129  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  130  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  132  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  133  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  134  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  135  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473230481147766
Epoch:  137  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  138  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  139  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  140  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  142  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  143  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  144  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  145  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  147  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  148  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  149  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  150  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  152  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  153  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  154  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  155  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  157  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  158  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  159  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  160  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  162  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  163  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  164  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  165  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  167  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  168  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  169  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  170  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  172  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  173  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  174  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  175  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  177  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  178  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  179  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  180  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
 36%|███▌      | 181/500 [05:39<14:11,  2.67s/it] 37%|███▋      | 183/500 [05:39<09:59,  1.89s/it] 37%|███▋      | 185/500 [05:45<11:49,  2.25s/it] 37%|███▋      | 187/500 [05:45<08:20,  1.60s/it] 38%|███▊      | 189/500 [05:45<05:54,  1.14s/it] 38%|███▊      | 189/500 [05:56<05:54,  1.14s/it] 38%|███▊      | 191/500 [05:58<13:48,  2.68s/it] 39%|███▊      | 193/500 [05:58<09:43,  1.90s/it] 39%|███▉      | 195/500 [06:04<11:37,  2.29s/it] 39%|███▉      | 197/500 [06:04<08:11,  1.62s/it] 40%|███▉      | 199/500 [06:05<05:47,  1.16s/it] 40%|███▉      | 199/500 [06:16<05:47,  1.16s/it] 40%|████      | 201/500 [06:17<13:21,  2.68s/it] 41%|████      | 203/500 [06:17<09:23,  1.90s/it] 41%|████      | 205/500 [06:24<11:10,  2.27s/it] 41%|████▏     | 207/500 [06:24<07:52,  1.61s/it] 42%|████▏     | 209/500 [06:24<05:34,  1.15s/it] 42%|████▏     | 209/500 [06:36<05:34,  1.15s/it] 42%|████▏     | 211/500 [06:36<12:50,  2.66s/it] 43%|████▎     | 213/500 [06:36<09:01,  1.89s/it] 43%|████▎     | 215/500 [06:43<10:44,  2.26s/it] 43%|████▎     | 217/500 [06:43<07:33,  1.60s/it] 44%|████▍     | 219/500 [06:43<05:21,  1.14s/it] 44%|████▍     | 221/500 [06:56<12:33,  2.70s/it] 45%|████▍     | 223/500 [06:56<08:49,  1.91s/it] 45%|████▌     | 225/500 [07:02<10:27,  2.28s/it] 45%|████▌     | 227/500 [07:02<07:21,  1.62s/it] 46%|████▌     | 229/500 [07:02<05:11,  1.15s/it] 46%|████▌     | 231/500 [07:15<12:07,  2.70s/it] 47%|████▋     | 233/500 [07:15<08:31,  1.91s/it] 47%|████▋     | 235/500 [07:21<10:05,  2.28s/it] 47%|████▋     | 237/500 [07:21<07:05,  1.62s/it] 48%|████▊     | 239/500 [07:22<05:00,  1.15s/it]Valid Loss:  0.10473230481147766
Epoch:  182  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  183  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  184  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  185  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  187  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  188  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  189  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  190  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  192  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  193  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  194  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  195  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  197  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  198  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  199  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  200  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  202  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  203  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  204  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  205  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  207  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  208  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  209  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  210  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  212  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  213  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  214  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  215  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  217  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  218  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  219  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  220  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  222  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  223  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  224  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  225  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  227  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  228  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  229  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  230  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  232  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  233  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  234  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  235  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  237  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  238  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  239  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  240  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
 48%|████▊     | 241/500 [07:34<11:31,  2.67s/it] 49%|████▊     | 243/500 [07:34<08:05,  1.89s/it] 49%|████▉     | 245/500 [07:40<09:38,  2.27s/it] 49%|████▉     | 247/500 [07:41<06:47,  1.61s/it] 50%|████▉     | 249/500 [07:41<04:47,  1.15s/it] 50%|█████     | 251/500 [07:53<11:01,  2.66s/it] 51%|█████     | 253/500 [07:53<07:44,  1.88s/it] 51%|█████     | 255/500 [08:00<09:13,  2.26s/it] 51%|█████▏    | 257/500 [08:00<06:29,  1.60s/it] 52%|█████▏    | 259/500 [08:00<04:34,  1.14s/it] 52%|█████▏    | 261/500 [08:12<10:33,  2.65s/it] 53%|█████▎    | 263/500 [08:12<07:24,  1.88s/it] 53%|█████▎    | 265/500 [08:19<08:48,  2.25s/it] 53%|█████▎    | 267/500 [08:19<06:11,  1.60s/it] 54%|█████▍    | 269/500 [08:19<04:22,  1.14s/it] 54%|█████▍    | 271/500 [08:31<10:07,  2.65s/it] 55%|█████▍    | 273/500 [08:31<07:06,  1.88s/it] 55%|█████▌    | 275/500 [08:38<08:28,  2.26s/it] 55%|█████▌    | 277/500 [08:38<05:57,  1.60s/it] 56%|█████▌    | 279/500 [08:38<04:12,  1.14s/it] 56%|█████▌    | 281/500 [08:50<09:44,  2.67s/it] 57%|█████▋    | 283/500 [08:50<06:49,  1.89s/it] 57%|█████▋    | 285/500 [08:57<08:05,  2.26s/it] 57%|█████▋    | 287/500 [08:57<05:41,  1.60s/it] 58%|█████▊    | 289/500 [08:57<04:00,  1.14s/it] 58%|█████▊    | 291/500 [09:09<09:16,  2.66s/it] 59%|█████▊    | 293/500 [09:10<06:29,  1.88s/it] 59%|█████▉    | 295/500 [09:16<07:41,  2.25s/it] 59%|█████▉    | 297/500 [09:16<05:24,  1.60s/it] 60%|█████▉    | 299/500 [09:16<03:48,  1.14s/it]**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  242  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  243  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  244  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  245  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473231226205826
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  247  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  248  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  249  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  250  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  252  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  253  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  254  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  255  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  257  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  258  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  259  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  260  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473231226205826
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  262  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  263  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  264  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  265  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  267  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  268  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  269  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  270  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  272  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  273  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  274  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  275  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  277  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  278  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  279  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  280  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  282  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  283  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  284  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  285  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  287  	Training Loss: 0.11064299196004868
Test Loss:  0.11638583987951279
Valid Loss:  0.10473230481147766
Epoch:  288  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  289  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  290  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  292  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  293  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  294  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  295  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  297  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  298  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  299  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
 60%|██████    | 301/500 [09:28<08:46,  2.65s/it] 61%|██████    | 303/500 [09:29<06:09,  1.87s/it] 61%|██████    | 305/500 [09:35<07:20,  2.26s/it] 61%|██████▏   | 307/500 [09:35<05:09,  1.60s/it] 62%|██████▏   | 309/500 [09:35<03:37,  1.14s/it] 62%|██████▏   | 309/500 [09:46<03:37,  1.14s/it] 62%|██████▏   | 311/500 [09:47<08:21,  2.65s/it] 63%|██████▎   | 313/500 [09:48<05:50,  1.88s/it] 63%|██████▎   | 315/500 [09:54<06:55,  2.25s/it] 63%|██████▎   | 317/500 [09:54<04:51,  1.59s/it] 64%|██████▍   | 319/500 [09:54<03:25,  1.14s/it] 64%|██████▍   | 319/500 [10:06<03:25,  1.14s/it] 64%|██████▍   | 321/500 [10:06<07:53,  2.65s/it] 65%|██████▍   | 323/500 [10:07<05:31,  1.88s/it] 65%|██████▌   | 325/500 [10:13<06:36,  2.27s/it] 65%|██████▌   | 327/500 [10:13<04:38,  1.61s/it] 66%|██████▌   | 329/500 [10:13<03:15,  1.14s/it] 66%|██████▌   | 329/500 [10:26<03:15,  1.14s/it] 66%|██████▌   | 331/500 [10:26<07:36,  2.70s/it] 67%|██████▋   | 333/500 [10:26<05:19,  1.91s/it] 67%|██████▋   | 335/500 [10:32<06:15,  2.27s/it] 67%|██████▋   | 337/500 [10:32<04:22,  1.61s/it] 68%|██████▊   | 339/500 [10:33<03:05,  1.15s/it] 68%|██████▊   | 341/500 [10:45<07:06,  2.68s/it] 69%|██████▊   | 343/500 [10:45<04:57,  1.90s/it] 69%|██████▉   | 345/500 [10:51<05:51,  2.27s/it] 69%|██████▉   | 347/500 [10:52<04:06,  1.61s/it] 70%|██████▉   | 349/500 [10:52<02:53,  1.15s/it] 70%|███████   | 351/500 [11:04<06:38,  2.67s/it] 71%|███████   | 353/500 [11:04<04:38,  1.89s/it] 71%|███████   | 355/500 [11:11<05:28,  2.26s/it] 71%|███████▏  | 357/500 [11:11<03:49,  1.60s/it]Epoch:  300  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  302  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  303  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  304  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  305  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  307  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473230481147766
Epoch:  308  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  309  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  310  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  312  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  313  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  314  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  315  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  317  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  318  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  319  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  320  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  322  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  323  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  324  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  325  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  327  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  328  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  329  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  330  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  332  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  333  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  334  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  335  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  337  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  338  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  339  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  340  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  342  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  343  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  344  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  345  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  347  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  348  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  349  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  350  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  352  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  353  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  354  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  355  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  357  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  358  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
 72%|███████▏  | 359/500 [11:11<02:41,  1.14s/it] 72%|███████▏  | 361/500 [11:23<06:10,  2.67s/it] 73%|███████▎  | 363/500 [11:23<04:18,  1.89s/it] 73%|███████▎  | 365/500 [11:30<05:04,  2.26s/it] 73%|███████▎  | 367/500 [11:30<03:32,  1.60s/it] 74%|███████▍  | 369/500 [11:30<02:29,  1.14s/it] 74%|███████▍  | 371/500 [11:42<05:44,  2.67s/it] 75%|███████▍  | 373/500 [11:43<04:00,  1.89s/it] 75%|███████▌  | 375/500 [11:49<04:42,  2.26s/it] 75%|███████▌  | 377/500 [11:49<03:17,  1.60s/it] 76%|███████▌  | 379/500 [11:49<02:18,  1.14s/it] 76%|███████▌  | 381/500 [12:02<05:20,  2.69s/it] 77%|███████▋  | 383/500 [12:02<03:43,  1.91s/it] 77%|███████▋  | 385/500 [12:08<04:22,  2.28s/it] 77%|███████▋  | 387/500 [12:08<03:02,  1.62s/it] 78%|███████▊  | 389/500 [12:08<02:07,  1.15s/it] 78%|███████▊  | 391/500 [12:21<04:52,  2.68s/it] 79%|███████▊  | 393/500 [12:21<03:23,  1.90s/it] 79%|███████▉  | 395/500 [12:28<04:00,  2.29s/it] 79%|███████▉  | 397/500 [12:28<02:47,  1.63s/it] 80%|███████▉  | 399/500 [12:28<01:56,  1.16s/it] 80%|████████  | 401/500 [12:40<04:27,  2.71s/it] 81%|████████  | 403/500 [12:41<03:05,  1.92s/it] 81%|████████  | 405/500 [12:47<03:38,  2.30s/it] 81%|████████▏ | 407/500 [12:47<02:31,  1.63s/it] 82%|████████▏ | 409/500 [12:47<01:45,  1.16s/it] 82%|████████▏ | 411/500 [13:00<03:59,  2.69s/it] 83%|████████▎ | 413/500 [13:00<02:45,  1.90s/it] 83%|████████▎ | 415/500 [13:06<03:14,  2.29s/it] 83%|████████▎ | 417/500 [13:06<02:14,  1.62s/it]Epoch:  359  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  360  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  362  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  363  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  364  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  365  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  367  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  368  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  369  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  370  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  372  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  373  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  374  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  375  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  377  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  378  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  379  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  380  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  382  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  383  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  384  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  385  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  387  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  388  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  389  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  390  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  392  	Training Loss: 0.11064299196004868
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  393  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  394  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  395  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  397  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  398  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  399  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  400  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  402  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  403  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  404  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  405  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  407  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  408  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  409  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  410  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  412  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  413  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473231226205826
Epoch:  414  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  415  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  417  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
 84%|████████▍ | 419/500 [13:07<01:33,  1.15s/it] 84%|████████▍ | 421/500 [13:19<03:35,  2.72s/it] 85%|████████▍ | 423/500 [13:19<02:28,  1.93s/it] 85%|████████▌ | 425/500 [13:26<02:54,  2.32s/it] 85%|████████▌ | 427/500 [13:26<02:00,  1.65s/it] 86%|████████▌ | 429/500 [13:26<01:23,  1.17s/it] 86%|████████▌ | 431/500 [13:39<03:05,  2.69s/it] 87%|████████▋ | 433/500 [13:39<02:07,  1.90s/it] 87%|████████▋ | 435/500 [13:45<02:28,  2.28s/it] 87%|████████▋ | 437/500 [13:45<01:41,  1.62s/it] 88%|████████▊ | 439/500 [13:45<01:10,  1.15s/it] 88%|████████▊ | 439/500 [13:56<01:10,  1.15s/it] 88%|████████▊ | 441/500 [13:58<02:38,  2.69s/it] 89%|████████▊ | 443/500 [13:58<01:48,  1.90s/it] 89%|████████▉ | 445/500 [14:04<02:05,  2.29s/it] 89%|████████▉ | 447/500 [14:05<01:26,  1.62s/it] 90%|████████▉ | 449/500 [14:05<00:58,  1.16s/it] 90%|████████▉ | 449/500 [14:16<00:58,  1.16s/it] 90%|█████████ | 451/500 [14:17<02:11,  2.69s/it] 91%|█████████ | 453/500 [14:17<01:29,  1.91s/it] 91%|█████████ | 455/500 [14:24<01:42,  2.28s/it] 91%|█████████▏| 457/500 [14:24<01:09,  1.61s/it] 92%|█████████▏| 459/500 [14:24<00:47,  1.15s/it] 92%|█████████▏| 459/500 [14:36<00:47,  1.15s/it] 92%|█████████▏| 461/500 [14:36<01:43,  2.66s/it] 93%|█████████▎| 463/500 [14:36<01:09,  1.89s/it] 93%|█████████▎| 465/500 [14:43<01:19,  2.26s/it] 93%|█████████▎| 467/500 [14:43<00:52,  1.60s/it] 94%|█████████▍| 469/500 [14:43<00:35,  1.14s/it] 94%|█████████▍| 471/500 [14:55<01:17,  2.66s/it] 95%|█████████▍| 473/500 [14:56<00:50,  1.88s/it] 95%|█████████▌| 475/500 [15:02<00:56,  2.26s/it]Epoch:  418  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  419  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  420  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  422  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  423  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  424  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  425  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  427  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  428  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  429  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  430  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  432  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  433  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  434  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  435  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  437  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  438  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  439  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  440  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  442  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  443  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  444  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  445  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  447  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  448  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  449  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  450  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473231226205826
Epoch:  452  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473230481147766
Epoch:  453  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  454  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  455  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  457  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  458  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  459  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  460  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  462  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  463  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  464  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  465  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473231226205826
Epoch:  467  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  468  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  469  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  470  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
Epoch:  472  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  473  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473230481147766
Epoch:  474  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  475  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
 95%|█████████▌| 477/500 [15:02<00:36,  1.61s/it] 96%|█████████▌| 479/500 [15:02<00:24,  1.14s/it] 96%|█████████▌| 481/500 [15:15<00:50,  2.66s/it] 97%|█████████▋| 483/500 [15:15<00:32,  1.89s/it] 97%|█████████▋| 485/500 [15:21<00:34,  2.27s/it] 97%|█████████▋| 487/500 [15:21<00:20,  1.61s/it] 98%|█████████▊| 489/500 [15:21<00:12,  1.15s/it] 98%|█████████▊| 491/500 [15:34<00:24,  2.70s/it] 99%|█████████▊| 493/500 [15:34<00:13,  1.91s/it] 99%|█████████▉| 495/500 [15:40<00:11,  2.28s/it] 99%|█████████▉| 497/500 [15:41<00:04,  1.61s/it]100%|█████████▉| 499/500 [15:41<00:01,  1.15s/it]100%|██████████| 500/500 [15:47<00:00,  1.89s/it]
Epoch:  477  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  478  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  479  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  480  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  482  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  483  	Training Loss: 0.11064299196004868
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  484  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  485  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  487  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  488  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  489  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  490  	Training Loss: 0.11064298450946808
Test Loss:  0.11638583987951279
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  492  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  493  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  494  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  495  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  497  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  498  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  499  	Training Loss: 0.11064298450946808
Test Loss:  0.11638584733009338
Valid Loss:  0.10473230481147766
Epoch:  500  	Training Loss: 0.11064298450946808
Test Loss:  0.11638585478067398
Valid Loss:  0.10473230481147766
**************************************************learning rate decay**************************************************
seed is  17
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:38,  6.21s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:36,  1.20s/it]  5%|▍         | 23/500 [00:20<06:49,  1.16it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:06,  1.17s/it]  7%|▋         | 33/500 [00:26<06:30,  1.20it/s]  7%|▋         | 35/500 [00:26<04:41,  1.65it/s]  7%|▋         | 37/500 [00:27<03:25,  2.26it/s]  8%|▊         | 39/500 [00:27<02:31,  3.04it/s]  8%|▊         | 41/500 [00:33<09:03,  1.18s/it]  9%|▊         | 43/500 [00:33<06:27,  1.18it/s]  9%|▉         | 45/500 [00:33<04:39,  1.63it/s]  9%|▉         | 47/500 [00:33<03:23,  2.22it/s] 10%|▉         | 49/500 [00:34<02:31,  2.99it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:18,  1.18it/s] 11%|█         | 55/500 [00:46<11:24,  1.54s/it] 11%|█▏        | 57/500 [00:46<08:06,  1.10s/it] 12%|█▏        | 59/500 [00:47<05:47,  1.27it/s] 12%|█▏        | 61/500 [00:53<10:59,  1.50s/it] 13%|█▎        | 63/500 [00:53<07:48,  1.07s/it] 13%|█▎        | 65/500 [00:53<05:35,  1.30it/s] 13%|█▎        | 67/500 [00:53<04:01,  1.79it/s]Epoch:  1  	Training Loss: 0.12120464444160461
Test Loss:  0.03203263133764267
Valid Loss:  0.04061611741781235
Epoch:  2  	Training Loss: 0.0388457328081131
Test Loss:  0.025526247918605804
Valid Loss:  0.024496428668498993
Epoch:  3  	Training Loss: 0.02622980624437332
Test Loss:  0.015165327116847038
Valid Loss:  0.018788626417517662
Epoch:  4  	Training Loss: 0.018520459532737732
Test Loss:  0.012673953548073769
Valid Loss:  0.013441601768136024
Epoch:  5  	Training Loss: 0.014219382777810097
Test Loss:  0.009307028725743294
Valid Loss:  0.011584099382162094
Epoch:  6  	Training Loss: 0.011623317375779152
Test Loss:  0.00795979518443346
Valid Loss:  0.009041179902851582
Epoch:  7  	Training Loss: 0.009502588771283627
Test Loss:  0.006171155255287886
Valid Loss:  0.007825258187949657
Epoch:  8  	Training Loss: 0.00796159915626049
Test Loss:  0.005319006275385618
Valid Loss:  0.0064531657844781876
Epoch:  9  	Training Loss: 0.006743104197084904
Test Loss:  0.004362612031400204
Valid Loss:  0.005642521660774946
Epoch:  10  	Training Loss: 0.005799596663564444
Test Loss:  0.0037990757264196873
Valid Loss:  0.00484880618751049
Epoch:  11  	Training Loss: 0.005051495507359505
Test Loss:  0.0032690800726413727
Valid Loss:  0.004323079250752926
Epoch:  12  	Training Loss: 0.004461423493921757
Test Loss:  0.002484699711203575
Valid Loss:  0.003272509668022394
Epoch:  13  	Training Loss: 0.003405149793252349
Test Loss:  0.0019467081874608994
Valid Loss:  0.002540790941566229
Epoch:  14  	Training Loss: 0.002635552315041423
Test Loss:  0.0015906966291368008
Valid Loss:  0.0020023926626890898
Epoch:  15  	Training Loss: 0.002107819076627493
Test Loss:  0.001465649576857686
Valid Loss:  0.001736163510940969
Epoch:  16  	Training Loss: 0.0018070148071274161
Test Loss:  0.0013762798625975847
Valid Loss:  0.0015792108606547117
Epoch:  17  	Training Loss: 0.0016551681328564882
Test Loss:  0.0014236378483474255
Valid Loss:  0.0015081388410180807
Epoch:  18  	Training Loss: 0.001575003145262599
Test Loss:  0.0013616776559501886
Valid Loss:  0.0014771749265491962
Epoch:  19  	Training Loss: 0.0015380291733890772
Test Loss:  0.0014787757536396384
Valid Loss:  0.0014600676950067282
Epoch:  20  	Training Loss: 0.001524793915450573
Test Loss:  0.001393491867929697
Valid Loss:  0.001474305521696806
Epoch:  21  	Training Loss: 0.001527343993075192
Test Loss:  0.0015715764602646232
Valid Loss:  0.0014817334013059735
Epoch:  22  	Training Loss: 0.0015481457812711596
Test Loss:  0.0014022820396348834
Valid Loss:  0.0014018469955772161
Epoch:  23  	Training Loss: 0.0014429441653192043
Test Loss:  0.0014370159478858113
Valid Loss:  0.0013426211662590504
Epoch:  24  	Training Loss: 0.0014027694705873728
Test Loss:  0.001360016642138362
Valid Loss:  0.0013208439340814948
Epoch:  25  	Training Loss: 0.0013657583622261882
Test Loss:  0.0013865084620192647
Valid Loss:  0.0012886150507256389
Epoch:  26  	Training Loss: 0.00134694401640445
Test Loss:  0.0013438580790534616
Valid Loss:  0.0012822222197428346
Epoch:  27  	Training Loss: 0.0013300059363245964
Test Loss:  0.0013644129503518343
Valid Loss:  0.0012621160130947828
Epoch:  28  	Training Loss: 0.0013189881574362516
Test Loss:  0.0013359668664634228
Valid Loss:  0.0012597390450537205
Epoch:  29  	Training Loss: 0.0013092993758618832
Test Loss:  0.0013514917809516191
Valid Loss:  0.0012458397541195154
Epoch:  30  	Training Loss: 0.001302065560594201
Test Loss:  0.0013324228348210454
Valid Loss:  0.0012446647742763162
Epoch:  31  	Training Loss: 0.0012953020632266998
Test Loss:  0.001344705349765718
Valid Loss:  0.0012343827402219176
Epoch:  32  	Training Loss: 0.001289885607548058
Test Loss:  0.0013246850576251745
Valid Loss:  0.0012233704328536987
Epoch:  33  	Training Loss: 0.0012777786469087005
Test Loss:  0.0013241420965641737
Valid Loss:  0.001217767596244812
Epoch:  34  	Training Loss: 0.0012721361126750708
Test Loss:  0.001324513927102089
Valid Loss:  0.0012128062080591917
Epoch:  35  	Training Loss: 0.0012673016171902418
Test Loss:  0.0013251863420009613
Valid Loss:  0.0012095392448827624
Epoch:  36  	Training Loss: 0.0012636525789275765
Test Loss:  0.0013270762283354998
Valid Loss:  0.0012058524880558252
Epoch:  37  	Training Loss: 0.001260765129700303
Test Loss:  0.0013278776314109564
Valid Loss:  0.0012034145183861256
Epoch:  38  	Training Loss: 0.0012581045739352703
Test Loss:  0.0013303289888426661
Valid Loss:  0.0012003001756966114
Epoch:  39  	Training Loss: 0.001256353105418384
Test Loss:  0.001331182662397623
Valid Loss:  0.0011989707127213478
Epoch:  40  	Training Loss: 0.0012548014055937529
Test Loss:  0.0013335342518985271
Valid Loss:  0.0011959902476519346
Epoch:  41  	Training Loss: 0.0012532772962003946
Test Loss:  0.0013331921072676778
Valid Loss:  0.0011946391314268112
Epoch:  42  	Training Loss: 0.0012515917187556624
Test Loss:  0.001331494189798832
Valid Loss:  0.001174239907413721
Epoch:  43  	Training Loss: 0.0012324323179200292
Test Loss:  0.0013167273718863726
Valid Loss:  0.00117097282782197
Epoch:  44  	Training Loss: 0.0012281337985768914
Test Loss:  0.0013140931259840727
Valid Loss:  0.0011679893359541893
Epoch:  45  	Training Loss: 0.0012250131694599986
Test Loss:  0.0013132255990058184
Valid Loss:  0.0011652512475848198
Epoch:  46  	Training Loss: 0.0012223575031384826
Test Loss:  0.0013121998636052012
Valid Loss:  0.0011626696214079857
Epoch:  47  	Training Loss: 0.001219840720295906
Test Loss:  0.0013114529429003596
Valid Loss:  0.0011602239683270454
Epoch:  48  	Training Loss: 0.001217476325109601
Test Loss:  0.001311285886913538
Valid Loss:  0.0011581666767597198
Epoch:  49  	Training Loss: 0.00121531100012362
Test Loss:  0.0013091496657580137
Valid Loss:  0.001156524522230029
Epoch:  50  	Training Loss: 0.001213418785482645
Test Loss:  0.001309887389652431
Valid Loss:  0.0011548358015716076
Epoch:  51  	Training Loss: 0.001211764756590128
Test Loss:  0.0013104523532092571
Valid Loss:  0.0011532148346304893
Epoch:  52  	Training Loss: 0.0012102802284061909
Test Loss:  0.0013243467546999454
Valid Loss:  0.001158529776148498
Epoch:  53  	Training Loss: 0.0012122916523367167
Test Loss:  0.0013308095512911677
Valid Loss:  0.0011450301390141249
Epoch:  54  	Training Loss: 0.001203277613967657
Test Loss:  0.0013265368761494756
Valid Loss:  0.0011736341984942555
Epoch:  55  	Training Loss: 0.001223596278578043
Test Loss:  0.001370726735331118
Valid Loss:  0.001158000435680151
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.0012193559668958187
Test Loss:  0.0013076462782919407
Valid Loss:  0.0011302975472062826
Epoch:  57  	Training Loss: 0.001186474459245801
Test Loss:  0.0013092176523059607
Valid Loss:  0.0011222094763070345
Epoch:  58  	Training Loss: 0.0011782823130488396
Test Loss:  0.001290965941734612
Valid Loss:  0.0011139343259856105
Epoch:  59  	Training Loss: 0.001168729504570365
Test Loss:  0.0012914109975099564
Valid Loss:  0.0011114429216831923
Epoch:  60  	Training Loss: 0.0011664264602586627
Test Loss:  0.0012868748744949698
Valid Loss:  0.001109229400753975
Epoch:  61  	Training Loss: 0.0011643294710665941
Test Loss:  0.0012916179839521646
Valid Loss:  0.0011077361414209008
Epoch:  62  	Training Loss: 0.0011634898837655783
Test Loss:  0.0012907539494335651
Valid Loss:  0.0011077362578362226
Epoch:  63  	Training Loss: 0.0011633681133389473
Test Loss:  0.0012903606984764338
Valid Loss:  0.0011077122762799263
Epoch:  64  	Training Loss: 0.0011632805690169334
Test Loss:  0.0012903462629765272
Valid Loss:  0.0011076361406594515
Epoch:  65  	Training Loss: 0.0011632151436060667
Test Loss:  0.001290106913074851
Valid Loss:  0.0011076164664700627
Epoch:  66  	Training Loss: 0.0011631478555500507
Test Loss:  0.0012900109868496656
Valid Loss:  0.0011075817747041583
Epoch:  67  	Training Loss: 0.001163087785243988
Test Loss:  0.001289983163587749
Valid Loss:  0.0011075417278334498
Epoch:  68  	Training Loss: 0.0011630343506112695
Test Loss:  0.001290007377974689
Valid Loss:  0.0011074997019022703
Epoch:  69  	Training Loss: 0.0011629925575107336
Test Loss:   14%|█▍        | 69/500 [00:53<02:56,  2.44it/s] 14%|█▍        | 71/500 [01:00<08:45,  1.23s/it] 15%|█▍        | 73/500 [01:00<06:15,  1.14it/s] 15%|█▌        | 75/500 [01:00<04:30,  1.57it/s] 15%|█▌        | 77/500 [01:00<03:16,  2.15it/s] 16%|█▌        | 79/500 [01:00<02:25,  2.89it/s] 16%|█▌        | 81/500 [01:07<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:07<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:07<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:07<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:07<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:13<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:13<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:14<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:14<02:13,  3.01it/s] 20%|██        | 101/500 [01:20<07:51,  1.18s/it] 21%|██        | 103/500 [01:20<05:36,  1.18it/s] 21%|██        | 105/500 [01:20<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:21<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:27<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:27<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:27<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:27<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:28<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:34<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:34<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:34<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:34<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:34<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:41<07:11,  1.17s/it] 27%|██▋       | 133/500 [01:41<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:41<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:41<02:41,  2.25it/s]0.0012901946902275085
Valid Loss:  0.0011074214708060026
Epoch:  70  	Training Loss: 0.0011629555374383926
Test Loss:  0.0012900702422484756
Valid Loss:  0.0011074100621044636
Epoch:  71  	Training Loss: 0.0011629172367975116
Test Loss:  0.001290047075599432
Valid Loss:  0.0011073864297941327
Epoch:  72  	Training Loss: 0.001162882661446929
Test Loss:  0.001287502353079617
Valid Loss:  0.0011002726387232542
Epoch:  73  	Training Loss: 0.001152366166934371
Test Loss:  0.001287335529923439
Valid Loss:  0.001094714505597949
Epoch:  74  	Training Loss: 0.0011463288683444262
Test Loss:  0.0012872344814240932
Valid Loss:  0.0010901580099016428
Epoch:  75  	Training Loss: 0.0011417549103498459
Test Loss:  0.0012867599725723267
Valid Loss:  0.0010862380731850863
Epoch:  76  	Training Loss: 0.0011379022616893053
Test Loss:  0.0012856340035796165
Valid Loss:  0.0010828897356987
Epoch:  77  	Training Loss: 0.0011346475221216679
Test Loss:  0.0012840565759688616
Valid Loss:  0.0010799991432577372
Epoch:  78  	Training Loss: 0.0011316093150526285
Test Loss:  0.0012822211720049381
Valid Loss:  0.0010773299727588892
Epoch:  79  	Training Loss: 0.0011286784429103136
Test Loss:  0.0012801403645426035
Valid Loss:  0.0010748555650934577
Epoch:  80  	Training Loss: 0.0011260316241532564
Test Loss:  0.0012777443043887615
Valid Loss:  0.001072498271241784
Epoch:  81  	Training Loss: 0.001123618334531784
Test Loss:  0.0012750696623697877
Valid Loss:  0.001070179045200348
Epoch:  82  	Training Loss: 0.001121425535529852
Test Loss:  0.0012660949723795056
Valid Loss:  0.0010635682847350836
Epoch:  83  	Training Loss: 0.0011144758900627494
Test Loss:  0.001269825268536806
Valid Loss:  0.0010621317196637392
Epoch:  84  	Training Loss: 0.0011130699422210455
Test Loss:  0.0012578365858644247
Valid Loss:  0.0010581878013908863
Epoch:  85  	Training Loss: 0.0011084959842264652
Test Loss:  0.0012623993679881096
Valid Loss:  0.0010570251615718007
Epoch:  86  	Training Loss: 0.0011075014481320977
Test Loss:  0.0012514800764620304
Valid Loss:  0.0010533654130995274
Epoch:  87  	Training Loss: 0.0011032870970666409
Test Loss:  0.001255956944078207
Valid Loss:  0.001052197301760316
Epoch:  88  	Training Loss: 0.0011023107217624784
Test Loss:  0.0012459830613806844
Valid Loss:  0.001049193786457181
Epoch:  89  	Training Loss: 0.0010988002177327871
Test Loss:  0.0012515857815742493
Valid Loss:  0.0010486380197107792
Epoch:  90  	Training Loss: 0.0010984521359205246
Test Loss:  0.001241315738297999
Valid Loss:  0.001045301789417863
Epoch:  91  	Training Loss: 0.0010945112444460392
Test Loss:  0.0012455573305487633
Valid Loss:  0.001044222037307918
Epoch:  92  	Training Loss: 0.0010936334729194641
Test Loss:  0.0012421919964253902
Valid Loss:  0.001043166033923626
Epoch:  93  	Training Loss: 0.0010924561647698283
Test Loss:  0.0012399711413308978
Valid Loss:  0.0010423660278320312
Epoch:  94  	Training Loss: 0.0010916606988757849
Test Loss:  0.0012380231637507677
Valid Loss:  0.00104172108694911
Epoch:  95  	Training Loss: 0.0010909541742876172
Test Loss:  0.0012362564448267221
Valid Loss:  0.0010411819675937295
Epoch:  96  	Training Loss: 0.0010903335642069578
Test Loss:  0.001234712777659297
Valid Loss:  0.00104075251147151
Epoch:  97  	Training Loss: 0.0010898462496697903
Test Loss:  0.0012333320919424295
Valid Loss:  0.0010403450578451157
Epoch:  98  	Training Loss: 0.001089401077479124
Test Loss:  0.0012320951791480184
Valid Loss:  0.0010399625170975924
Epoch:  99  	Training Loss: 0.0010890101548284292
Test Loss:  0.0012309543089941144
Valid Loss:  0.0010395969729870558
Epoch:  100  	Training Loss: 0.0010886599775403738
Test Loss:  0.0012299302034080029
Valid Loss:  0.0010392718249931931
Epoch:  101  	Training Loss: 0.0010883628856390715
Test Loss:  0.0012290411395952106
Valid Loss:  0.001038990681990981
Epoch:  102  	Training Loss: 0.0010881407652050257
Test Loss:  0.0012286222772672772
Valid Loss:  0.0010389854433014989
Epoch:  103  	Training Loss: 0.0010878206230700016
Test Loss:  0.001228501321747899
Valid Loss:  0.0010389898670837283
Epoch:  104  	Training Loss: 0.0010875449515879154
Test Loss:  0.001228454988449812
Valid Loss:  0.0010389653034508228
Epoch:  105  	Training Loss: 0.0010873230639845133
Test Loss:  0.0012283637188374996
Valid Loss:  0.0010389216477051377
Epoch:  106  	Training Loss: 0.0010871681151911616
Test Loss:  0.0012282172683626413
Valid Loss:  0.0010388849768787622
Epoch:  107  	Training Loss: 0.001087019219994545
Test Loss:  0.001228016335517168
Valid Loss:  0.0010388456284999847
Epoch:  108  	Training Loss: 0.0010868979152292013
Test Loss:  0.0012277716305106878
Valid Loss:  0.0010388114023953676
Epoch:  109  	Training Loss: 0.0010867769597098231
Test Loss:  0.0012275066692382097
Valid Loss:  0.001038778806105256
Epoch:  110  	Training Loss: 0.0010866583324968815
Test Loss:  0.0012272216845303774
Valid Loss:  0.0010387487709522247
Epoch:  111  	Training Loss: 0.0010865461081266403
Test Loss:  0.001226921915076673
Valid Loss:  0.001038717688061297
Epoch:  112  	Training Loss: 0.0010864364448934793
Test Loss:  0.0012104606721550226
Valid Loss:  0.001031269202940166
Epoch:  113  	Training Loss: 0.0010781860910356045
Test Loss:  0.001207822933793068
Valid Loss:  0.0010293114464730024
Epoch:  114  	Training Loss: 0.0010763334576040506
Test Loss:  0.0012061840388923883
Valid Loss:  0.0010275475215166807
Epoch:  115  	Training Loss: 0.001074867439456284
Test Loss:  0.001205353531986475
Valid Loss:  0.0010260252747684717
Epoch:  116  	Training Loss: 0.0010736972326412797
Test Loss:  0.0012045418843626976
Valid Loss:  0.0010246625170111656
Epoch:  117  	Training Loss: 0.0010726815089583397
Test Loss:  0.0012038582935929298
Valid Loss:  0.001023528748191893
Epoch:  118  	Training Loss: 0.0010717997793108225
Test Loss:  0.0012032982194796205
Valid Loss:  0.0010225498117506504
Epoch:  119  	Training Loss: 0.0010709642665460706
Test Loss:  0.0012027428019791842
Valid Loss:  0.001021610340103507
Epoch:  120  	Training Loss: 0.0010701632127165794
Test Loss:  0.0012022804003208876
Valid Loss:  0.0010207043960690498
Epoch:  121  	Training Loss: 0.001069383230060339
Test Loss:  0.0012017106637358665
Valid Loss:  0.0010198557283729315
Epoch:  122  	Training Loss: 0.0010686581954360008
Test Loss:  0.0012015807442367077
Valid Loss:  0.0010189878521487117
Epoch:  123  	Training Loss: 0.0010676018428057432
Test Loss:  0.0012015432585030794
Valid Loss:  0.0010183266131207347
Epoch:  124  	Training Loss: 0.0010668199975043535
Test Loss:  0.0012014613021165133
Valid Loss:  0.001017618691548705
Epoch:  125  	Training Loss: 0.0010661014821380377
Test Loss:  0.0012012983206659555
Valid Loss:  0.0010169439483433962
Epoch:  126  	Training Loss: 0.0010654317447915673
Test Loss:  0.0012010654900223017
Valid Loss:  0.0010163120459765196
Epoch:  127  	Training Loss: 0.0010647691087797284
Test Loss:  0.0012007856275886297
Valid Loss:  0.0010156857315450907
Epoch:  128  	Training Loss: 0.0010641191620379686
Test Loss:  0.001200381899252534
Valid Loss:  0.0010150016751140356
Epoch:  129  	Training Loss: 0.001063512172549963
Test Loss:  0.001199902966618538
Valid Loss:  0.0010143481194972992
Epoch:  130  	Training Loss: 0.0010629125172272325
Test Loss:  0.0011993814259767532
Valid Loss:  0.0010137181961908937
Epoch:  131  	Training Loss: 0.0010623170528560877
Test Loss:  0.001198837999254465
Valid Loss:  0.0010130980517715216
Epoch:  132  	Training Loss: 0.001061722869053483
Test Loss:  0.0012007274199277163
Valid Loss:  0.0010073750745505095
Epoch:  133  	Training Loss: 0.001054460764862597
Test Loss:  0.0011990696657449007
Valid Loss:  0.001005284022539854
Epoch:  134  	Training Loss: 0.0010517968330532312
Test Loss:  0.0011984168086200953
Valid Loss:  0.001003308454528451
Epoch:  135  	Training Loss: 0.001049427897669375
Test Loss:  0.0011980346171185374
Valid Loss:  0.0010013801511377096
Epoch:  136  	Training Loss: 0.00104719796217978
Test Loss:  0.0011976674431934953
Valid Loss:  0.0009994826978072524
Epoch:  137  	Training Loss: 0.0010450717527419329
Test Loss:  0.0011974305380135775
Valid Loss:  0.0009976139990612864
Epoch:  138  	Training Loss: 0.001043056370690465
 28%|██▊       | 139/500 [01:41<01:59,  3.03it/s] 28%|██▊       | 141/500 [01:47<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:48<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:48<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:48<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:48<01:56,  3.00it/s] 30%|███       | 151/500 [01:54<06:52,  1.18s/it] 31%|███       | 153/500 [01:54<04:54,  1.18it/s] 31%|███       | 155/500 [01:55<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:55<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:55<01:53,  3.00it/s] 32%|███▏      | 161/500 [02:01<06:38,  1.18s/it] 33%|███▎      | 163/500 [02:01<04:44,  1.18it/s] 33%|███▎      | 165/500 [02:01<03:24,  1.64it/s] 33%|███▎      | 167/500 [02:01<02:28,  2.24it/s] 34%|███▍      | 169/500 [02:02<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:08<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:08<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:08<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:08<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:09<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:15<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:15<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:15<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:15<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:15<01:43,  2.99it/s] 38%|███▊      | 191/500 [02:22<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:22<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:22<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:22<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:22<01:40,  2.99it/s] 40%|████      | 201/500 [02:29<05:57,  1.19s/it] 41%|████      | 203/500 [02:29<04:14,  1.17it/s] 41%|████      | 205/500 [02:29<03:03,  1.61it/s]Test Loss:  0.0011969998013228178
Valid Loss:  0.0009957961738109589
Epoch:  139  	Training Loss: 0.0010411685798317194
Test Loss:  0.0011962992139160633
Valid Loss:  0.0009940614691004157
Epoch:  140  	Training Loss: 0.0010394873097538948
Test Loss:  0.001195559510961175
Valid Loss:  0.0009924734476953745
Epoch:  141  	Training Loss: 0.001037872163578868
Test Loss:  0.0011944143334403634
Valid Loss:  0.0009909525979310274
Epoch:  142  	Training Loss: 0.0010362621396780014
Test Loss:  0.0011953364592045546
Valid Loss:  0.0009896514238789678
Epoch:  143  	Training Loss: 0.0010353905381634831
Test Loss:  0.0011949220206588507
Valid Loss:  0.0009890487417578697
Epoch:  144  	Training Loss: 0.0010347265051677823
Test Loss:  0.001194327138364315
Valid Loss:  0.0009885081090033054
Epoch:  145  	Training Loss: 0.0010340737644582987
Test Loss:  0.0011936838272958994
Valid Loss:  0.0009879763238132
Epoch:  146  	Training Loss: 0.0010334360413253307
Test Loss:  0.0011929620523005724
Valid Loss:  0.000987471779808402
Epoch:  147  	Training Loss: 0.0010328758507966995
Test Loss:  0.0011921919649466872
Valid Loss:  0.0009869863279163837
Epoch:  148  	Training Loss: 0.001032321248203516
Test Loss:  0.001191411749459803
Valid Loss:  0.0009865047177299857
Epoch:  149  	Training Loss: 0.001031773048453033
Test Loss:  0.001190617447718978
Valid Loss:  0.0009860286954790354
Epoch:  150  	Training Loss: 0.001031229505315423
Test Loss:  0.00118981150444597
Valid Loss:  0.0009856377728283405
Epoch:  151  	Training Loss: 0.0010306917829439044
Test Loss:  0.0011889991583302617
Valid Loss:  0.0009853099472820759
Epoch:  152  	Training Loss: 0.001030180836096406
Test Loss:  0.0011847809655591846
Valid Loss:  0.0009814929217100143
Epoch:  153  	Training Loss: 0.0010269219055771828
Test Loss:  0.0011796301696449518
Valid Loss:  0.0009753566118888557
Epoch:  154  	Training Loss: 0.0010212684283033013
Test Loss:  0.0011730804108083248
Valid Loss:  0.000967662432231009
Epoch:  155  	Training Loss: 0.001013423316180706
Test Loss:  0.0011657766299322248
Valid Loss:  0.000959102064371109
Epoch:  156  	Training Loss: 0.0010047628311440349
Test Loss:  0.0011586081236600876
Valid Loss:  0.000950671557802707
Epoch:  157  	Training Loss: 0.0009962036274373531
Test Loss:  0.001152480486780405
Valid Loss:  0.0009435993852093816
Epoch:  158  	Training Loss: 0.000988910673186183
Test Loss:  0.0011480271350592375
Valid Loss:  0.000938163255341351
Epoch:  159  	Training Loss: 0.000983462668955326
Test Loss:  0.0011446444550529122
Valid Loss:  0.0009344598511233926
Epoch:  160  	Training Loss: 0.0009792480850592256
Test Loss:  0.001141678774729371
Valid Loss:  0.000931549584493041
Epoch:  161  	Training Loss: 0.0009756221552379429
Test Loss:  0.00113898073323071
Valid Loss:  0.0009298913064412773
Epoch:  162  	Training Loss: 0.0009729686425998807
Test Loss:  0.0011353277368471026
Valid Loss:  0.0009289198787882924
Epoch:  163  	Training Loss: 0.0009719521040096879
Test Loss:  0.0011320863850414753
Valid Loss:  0.0009279773803427815
Epoch:  164  	Training Loss: 0.0009709911537356675
Test Loss:  0.0011291529517620802
Valid Loss:  0.0009270586306229234
Epoch:  165  	Training Loss: 0.0009700767695903778
Test Loss:  0.0011264479253441095
Valid Loss:  0.0009261724771931767
Epoch:  166  	Training Loss: 0.0009691988816484809
Test Loss:  0.0011239346349611878
Valid Loss:  0.0009253172902390361
Epoch:  167  	Training Loss: 0.0009683571406640112
Test Loss:  0.0011215814156457782
Valid Loss:  0.0009244864340871572
Epoch:  168  	Training Loss: 0.0009675607434473932
Test Loss:  0.001119386637583375
Valid Loss:  0.0009237340418621898
Epoch:  169  	Training Loss: 0.0009668127167969942
Test Loss:  0.0011173218954354525
Valid Loss:  0.0009230594732798636
Epoch:  170  	Training Loss: 0.0009660889045335352
Test Loss:  0.0011153670493513346
Valid Loss:  0.0009224057430401444
Epoch:  171  	Training Loss: 0.0009653855813667178
Test Loss:  0.0011135137174278498
Valid Loss:  0.0009217682527378201
Epoch:  172  	Training Loss: 0.0009647051338106394
Test Loss:  0.0011098013492301106
Valid Loss:  0.0009163459180854261
Epoch:  173  	Training Loss: 0.0009594694711267948
Test Loss:  0.0011061758268624544
Valid Loss:  0.0009114061249420047
Epoch:  174  	Training Loss: 0.0009547452791593969
Test Loss:  0.001102687674574554
Valid Loss:  0.0009069926454685628
Epoch:  175  	Training Loss: 0.0009504752233624458
Test Loss:  0.0010992761235684156
Valid Loss:  0.0009028582135215402
Epoch:  176  	Training Loss: 0.0009465369512327015
Test Loss:  0.0010960988001897931
Valid Loss:  0.0008992118528112769
Epoch:  177  	Training Loss: 0.0009430429781787097
Test Loss:  0.001093100756406784
Valid Loss:  0.0008958774851635098
Epoch:  178  	Training Loss: 0.0009397286921739578
Test Loss:  0.0010901705827564
Valid Loss:  0.0008926033042371273
Epoch:  179  	Training Loss: 0.0009364699944853783
Test Loss:  0.0010873423889279366
Valid Loss:  0.000889557646587491
Epoch:  180  	Training Loss: 0.0009333157795481384
Test Loss:  0.0010845647193491459
Valid Loss:  0.0008865336421877146
Epoch:  181  	Training Loss: 0.0009302208200097084
Test Loss:  0.0010818750597536564
Valid Loss:  0.0008835933404043317
Epoch:  182  	Training Loss: 0.0009272081078961492
Test Loss:  0.0010799848241731524
Valid Loss:  0.0008814316242933273
Epoch:  183  	Training Loss: 0.0009245775290764868
Test Loss:  0.0010790007654577494
Valid Loss:  0.0008795160101726651
Epoch:  184  	Training Loss: 0.0009224247187376022
Test Loss:  0.0010781793389469385
Valid Loss:  0.0008778910851106048
Epoch:  185  	Training Loss: 0.0009205024689435959
Test Loss:  0.0010772186797112226
Valid Loss:  0.0008763101068325341
Epoch:  186  	Training Loss: 0.0009187158429995179
Test Loss:  0.0010762563906610012
Valid Loss:  0.000874933204613626
Epoch:  187  	Training Loss: 0.000917044177185744
Test Loss:  0.0010750936344265938
Valid Loss:  0.000873610086273402
Epoch:  188  	Training Loss: 0.0009155927109532058
Test Loss:  0.0010738096898421645
Valid Loss:  0.0008724302751943469
Epoch:  189  	Training Loss: 0.0009142276830971241
Test Loss:  0.0010722519364207983
Valid Loss:  0.0008712620474398136
Epoch:  190  	Training Loss: 0.0009130135294981301
Test Loss:  0.0010706107132136822
Valid Loss:  0.0008701672777533531
Epoch:  191  	Training Loss: 0.0009118544985540211
Test Loss:  0.0010689578484743834
Valid Loss:  0.0008691192488186061
Epoch:  192  	Training Loss: 0.0009107090882025659
Test Loss:  0.0010682200081646442
Valid Loss:  0.0008679120801389217
Epoch:  193  	Training Loss: 0.0009097293950617313
Test Loss:  0.0010660042753443122
Valid Loss:  0.0008674586424604058
Epoch:  194  	Training Loss: 0.0009089693194255233
Test Loss:  0.001064410200342536
Valid Loss:  0.0008669116068631411
Epoch:  195  	Training Loss: 0.0009083132608793676
Test Loss:  0.0010627636220306158
Valid Loss:  0.0008663489716127515
Epoch:  196  	Training Loss: 0.0009076910209842026
Test Loss:  0.0010610641911625862
Valid Loss:  0.0008658599690534174
Epoch:  197  	Training Loss: 0.0009070809464901686
Test Loss:  0.0010594771010801196
Valid Loss:  0.0008653767290525138
Epoch:  198  	Training Loss: 0.0009064822224900126
Test Loss:  0.0010579099180176854
Valid Loss:  0.0008648730581626296
Epoch:  199  	Training Loss: 0.0009059010772034526
Test Loss:  0.0010563577525317669
Valid Loss:  0.0008644319023005664
Epoch:  200  	Training Loss: 0.0009053294779732823
Test Loss:  0.0010549027938395739
Valid Loss:  0.0008640477317385375
Epoch:  201  	Training Loss: 0.0009047666098922491
Test Loss:  0.001053494866937399
Valid Loss:  0.0008636799175292253
Epoch:  202  	Training Loss: 0.0009042499004863203
Test Loss:  0.0010516885668039322
Valid Loss:  0.0008615327533334494
Epoch:  203  	Training Loss: 0.000902243540622294
Test Loss:  0.001049716374836862
Valid Loss:  0.0008594822138547897
Epoch:  204  	Training Loss: 0.0009002634324133396
Test Loss:  0.0010477297473698854
Valid Loss:  0.0008574738167226315
Epoch:  205  	Training Loss: 0.0008983061416074634
Test Loss:  0.00104575976729393
Valid Loss:  0.0008554772939532995
Epoch:  206  	Training Loss: 0.0008963615400716662
Test Loss:  0.0010438417084515095
Valid Loss:  0.0008535331580787897
 41%|████▏     | 207/500 [02:29<02:13,  2.20it/s] 42%|████▏     | 209/500 [02:29<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:36<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:36<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:36<02:57,  1.61it/s] 43%|████▎     | 217/500 [02:36<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:36<01:35,  2.95it/s] 44%|████▍     | 221/500 [02:42<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:43<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:43<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:43<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:43<01:31,  2.98it/s] 46%|████▌     | 231/500 [02:49<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:50<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:50<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:50<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:50<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:56<05:04,  1.18s/it] 49%|████▊     | 243/500 [02:56<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:56<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:57<01:53,  2.24it/s] 50%|████▉     | 249/500 [02:57<01:23,  3.00it/s] 50%|█████     | 251/500 [03:03<04:53,  1.18s/it] 51%|█████     | 253/500 [03:03<03:28,  1.18it/s] 51%|█████     | 255/500 [03:03<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:03<01:49,  2.23it/s] 52%|█████▏    | 259/500 [03:04<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:10<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:10<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:10<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:10<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:10<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:17<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:17<03:11,  1.19it/s]Epoch:  207  	Training Loss: 0.0008944862056523561
Test Loss:  0.0010419519385322928
Valid Loss:  0.0008516934467479587
Epoch:  208  	Training Loss: 0.0008926198352128267
Test Loss:  0.0010400874307379127
Valid Loss:  0.0008498664828948677
Epoch:  209  	Training Loss: 0.000890759692993015
Test Loss:  0.0010382424807175994
Valid Loss:  0.000848050694912672
Epoch:  210  	Training Loss: 0.0008889073505997658
Test Loss:  0.0010364181362092495
Valid Loss:  0.0008462384575977921
Epoch:  211  	Training Loss: 0.0008870682213455439
Test Loss:  0.0010346253402531147
Valid Loss:  0.0008444765117019415
Epoch:  212  	Training Loss: 0.0008852538885548711
Test Loss:  0.0010330970399081707
Valid Loss:  0.0008434702176600695
Epoch:  213  	Training Loss: 0.0008840614464133978
Test Loss:  0.0010317156556993723
Valid Loss:  0.0008424418047070503
Epoch:  214  	Training Loss: 0.0008829013677313924
Test Loss:  0.0010304362513124943
Valid Loss:  0.0008414289331994951
Epoch:  215  	Training Loss: 0.0008817696943879128
Test Loss:  0.0010291974758729339
Valid Loss:  0.0008404095424339175
Epoch:  216  	Training Loss: 0.0008806405821815133
Test Loss:  0.00102798524312675
Valid Loss:  0.000839387474115938
Epoch:  217  	Training Loss: 0.0008795140311121941
Test Loss:  0.0010267870966345072
Valid Loss:  0.0008383677341043949
Epoch:  218  	Training Loss: 0.0008783884113654494
Test Loss:  0.0010256009409204125
Valid Loss:  0.0008373486343771219
Epoch:  219  	Training Loss: 0.0008772658766247332
Test Loss:  0.00102441874332726
Valid Loss:  0.000836380640976131
Epoch:  220  	Training Loss: 0.0008761452045291662
Test Loss:  0.0010232431814074516
Valid Loss:  0.0008354530436918139
Epoch:  221  	Training Loss: 0.0008750258130021393
Test Loss:  0.001022071111947298
Valid Loss:  0.0008346070535480976
Epoch:  222  	Training Loss: 0.000873909390065819
Test Loss:  0.001020168769173324
Valid Loss:  0.0008332853903993964
Epoch:  223  	Training Loss: 0.0008725696825422347
Test Loss:  0.0010181323159486055
Valid Loss:  0.0008320835768245161
Epoch:  224  	Training Loss: 0.0008713026763871312
Test Loss:  0.0010161346290260553
Valid Loss:  0.0008308973046950996
Epoch:  225  	Training Loss: 0.0008701215265318751
Test Loss:  0.0010142117971554399
Valid Loss:  0.000829805969260633
Epoch:  226  	Training Loss: 0.0008689755341038108
Test Loss:  0.00101237662602216
Valid Loss:  0.0008287490345537663
Epoch:  227  	Training Loss: 0.00086784060113132
Test Loss:  0.0010106200352311134
Valid Loss:  0.0008277040906250477
Epoch:  228  	Training Loss: 0.0008667166111990809
Test Loss:  0.0010090090800076723
Valid Loss:  0.000826689531095326
Epoch:  229  	Training Loss: 0.0008656433783471584
Test Loss:  0.0010074134916067123
Valid Loss:  0.0008256341679953039
Epoch:  230  	Training Loss: 0.0008646076312288642
Test Loss:  0.0010057943873107433
Valid Loss:  0.000824638525955379
Epoch:  231  	Training Loss: 0.0008635831181891263
Test Loss:  0.0010042476933449507
Valid Loss:  0.0008236574940383434
Epoch:  232  	Training Loss: 0.0008625685004517436
Test Loss:  0.0010031015845015645
Valid Loss:  0.0008223947370424867
Epoch:  233  	Training Loss: 0.0008602276793681085
Test Loss:  0.001002636505290866
Valid Loss:  0.0008211885578930378
Epoch:  234  	Training Loss: 0.0008586792391724885
Test Loss:  0.0010023079812526703
Valid Loss:  0.0008201721357181668
Epoch:  235  	Training Loss: 0.0008576327818445861
Test Loss:  0.0010018997127190232
Valid Loss:  0.0008193376706913114
Epoch:  236  	Training Loss: 0.0008567823097109795
Test Loss:  0.001001332188025117
Valid Loss:  0.0008187023340724409
Epoch:  237  	Training Loss: 0.0008560860878787935
Test Loss:  0.0010006832890212536
Valid Loss:  0.0008181965677067637
Epoch:  238  	Training Loss: 0.0008554515661671758
Test Loss:  0.0009999530157074332
Valid Loss:  0.0008177916170097888
Epoch:  239  	Training Loss: 0.0008549485355615616
Test Loss:  0.0009991180850192904
Valid Loss:  0.0008174125105142593
Epoch:  240  	Training Loss: 0.0008545322343707085
Test Loss:  0.0009982417104765773
Valid Loss:  0.0008170773508027196
Epoch:  241  	Training Loss: 0.0008541381685063243
Test Loss:  0.0009973671985790133
Valid Loss:  0.000816765648778528
Epoch:  242  	Training Loss: 0.0008537793764844537
Test Loss:  0.0009958971058949828
Valid Loss:  0.0008135819807648659
Epoch:  243  	Training Loss: 0.0008488956373184919
Test Loss:  0.0009959132876247168
Valid Loss:  0.0008122621802613139
Epoch:  244  	Training Loss: 0.0008475282811559737
Test Loss:  0.0009953724220395088
Valid Loss:  0.0008114351076073945
Epoch:  245  	Training Loss: 0.0008465991704724729
Test Loss:  0.0009942763717845082
Valid Loss:  0.0008106807945296168
Epoch:  246  	Training Loss: 0.0008459172677248716
Test Loss:  0.0009928207146003842
Valid Loss:  0.0008099952829070389
Epoch:  247  	Training Loss: 0.0008453027694486082
Test Loss:  0.0009912550449371338
Valid Loss:  0.0008093947544693947
Epoch:  248  	Training Loss: 0.0008447106811217964
Test Loss:  0.0009896806441247463
Valid Loss:  0.0008088077302090824
Epoch:  249  	Training Loss: 0.0008441436802968383
Test Loss:  0.000988152576610446
Valid Loss:  0.0008082545245997608
Epoch:  250  	Training Loss: 0.0008435898344032466
Test Loss:  0.0009867064654827118
Valid Loss:  0.0008077225647866726
Epoch:  251  	Training Loss: 0.0008430600864812732
Test Loss:  0.000985296443104744
Valid Loss:  0.0008071759948506951
Epoch:  252  	Training Loss: 0.0008425709092989564
Test Loss:  0.0009827998001128435
Valid Loss:  0.0008038772502914071
Epoch:  253  	Training Loss: 0.0008396248449571431
Test Loss:  0.000980478711426258
Valid Loss:  0.0008016125066205859
Epoch:  254  	Training Loss: 0.0008375889156013727
Test Loss:  0.0009783025598153472
Valid Loss:  0.0007998625515028834
Epoch:  255  	Training Loss: 0.0008359261555597186
Test Loss:  0.0009762640111148357
Valid Loss:  0.0007984039257280529
Epoch:  256  	Training Loss: 0.0008344724774360657
Test Loss:  0.000974448281340301
Valid Loss:  0.0007970932638272643
Epoch:  257  	Training Loss: 0.0008331832941621542
Test Loss:  0.0009727681754156947
Valid Loss:  0.000795862462837249
Epoch:  258  	Training Loss: 0.0008319767657667398
Test Loss:  0.0009712119936011732
Valid Loss:  0.000794724328443408
Epoch:  259  	Training Loss: 0.0008308920077979565
Test Loss:  0.0009698070352897048
Valid Loss:  0.0007936732145026326
Epoch:  260  	Training Loss: 0.000829933094792068
Test Loss:  0.0009685215190984309
Valid Loss:  0.0007927498663775623
Epoch:  261  	Training Loss: 0.0008290975820273161
Test Loss:  0.0009673591703176498
Valid Loss:  0.0007918630726635456
Epoch:  262  	Training Loss: 0.0008283233619295061
Test Loss:  0.0009668000275269151
Valid Loss:  0.0007919176714494824
Epoch:  263  	Training Loss: 0.0008282220223918557
Test Loss:  0.0009666095138527453
Valid Loss:  0.0007919073686935008
Epoch:  264  	Training Loss: 0.0008281590417027473
Test Loss:  0.0009664803510531783
Valid Loss:  0.0007918831543065608
Epoch:  265  	Training Loss: 0.0008280975162051618
Test Loss:  0.0009663621312938631
Valid Loss:  0.0007918559713289142
Epoch:  266  	Training Loss: 0.000828044954687357
Test Loss:  0.0009662387892603874
Valid Loss:  0.0007918440969660878
Epoch:  267  	Training Loss: 0.0008280053152702749
Test Loss:  0.000966103165410459
Valid Loss:  0.0007918401388451457
Epoch:  268  	Training Loss: 0.000827969575766474
Test Loss:  0.0009659635252319276
Valid Loss:  0.0007918360061012208
Epoch:  269  	Training Loss: 0.0008279393659904599
Test Loss:  0.000965818646363914
Valid Loss:  0.0007918330375105143
Epoch:  270  	Training Loss: 0.0008279095636680722
Test Loss:  0.0009656698093749583
Valid Loss:  0.0007918286719359457
Epoch:  271  	Training Loss: 0.0008278871537186205
Test Loss:  0.0009655189933255315
Valid Loss:  0.0007918252376839519
Epoch:  272  	Training Loss: 0.0008278645109385252
Test Loss:  0.0009647435508668423
Valid Loss:  0.0007900157943367958
Epoch:  273  	Training Loss: 0.0008258771849796176
Test Loss:  0.0009647045517340302
Valid Loss:  0.0007882733480073512
Epoch:  274  	Training Loss: 0.0008241066825576127
Test Loss:  0.0009647284750826657
Valid Loss:  0.0007865920197218657
Epoch:  275  	Training Loss: 0.0008225050987675786
Test Loss:   55%|█████▌    | 275/500 [03:17<02:16,  1.64it/s] 55%|█████▌    | 277/500 [03:17<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:17<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:23<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:24<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:24<02:10,  1.64it/s] 57%|█████▋    | 287/500 [03:24<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:24<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:30<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:30<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:31<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:31<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:31<01:06,  3.02it/s] 60%|██████    | 301/500 [03:37<03:52,  1.17s/it] 61%|██████    | 303/500 [03:37<02:45,  1.19it/s] 61%|██████    | 305/500 [03:37<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:37<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:38<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:44<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:44<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:44<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:44<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:44<01:00,  3.00it/s] 64%|██████▍   | 321/500 [03:51<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:51<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:51<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:51<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:51<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:58<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:58<02:23,  1.16it/s] 67%|██████▋   | 335/500 [03:58<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:58<01:13,  2.20it/s] 68%|██████▊   | 339/500 [03:58<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:05<03:07,  1.18s/it]0.0009646064136177301
Valid Loss:  0.0007850708207115531
Epoch:  276  	Training Loss: 0.0008211704553104937
Test Loss:  0.0009643579833209515
Valid Loss:  0.0007838398450985551
Epoch:  277  	Training Loss: 0.0008199881995096803
Test Loss:  0.0009639837080612779
Valid Loss:  0.0007827237132005394
Epoch:  278  	Training Loss: 0.0008188532083295286
Test Loss:  0.0009635320748202503
Valid Loss:  0.0007816526340320706
Epoch:  279  	Training Loss: 0.0008177653653547168
Test Loss:  0.0009630052372813225
Valid Loss:  0.0007806518697179854
Epoch:  280  	Training Loss: 0.0008167325286194682
Test Loss:  0.0009624338708817959
Valid Loss:  0.0007796980207785964
Epoch:  281  	Training Loss: 0.0008157321717590094
Test Loss:  0.0009617952164262533
Valid Loss:  0.0007787616923451424
Epoch:  282  	Training Loss: 0.0008147957269102335
Test Loss:  0.0009602421196177602
Valid Loss:  0.0007758655701763928
Epoch:  283  	Training Loss: 0.0008121680002659559
Test Loss:  0.0009583043283782899
Valid Loss:  0.0007733572856523097
Epoch:  284  	Training Loss: 0.000809907098300755
Test Loss:  0.0009562739869579673
Valid Loss:  0.000771303428336978
Epoch:  285  	Training Loss: 0.0008079182589426637
Test Loss:  0.0009542935295030475
Valid Loss:  0.0007694362429901958
Epoch:  286  	Training Loss: 0.0008061401313170791
Test Loss:  0.0009524400811642408
Valid Loss:  0.0007678615511395037
Epoch:  287  	Training Loss: 0.0008046842413023114
Test Loss:  0.0009506815113127232
Valid Loss:  0.0007664329605177045
Epoch:  288  	Training Loss: 0.0008033744525164366
Test Loss:  0.0009490824304521084
Valid Loss:  0.0007652623462490737
Epoch:  289  	Training Loss: 0.0008022293914109468
Test Loss:  0.000947555701714009
Valid Loss:  0.000764125376008451
Epoch:  290  	Training Loss: 0.0008011028985492885
Test Loss:  0.000946070475038141
Valid Loss:  0.0007630006293766201
Epoch:  291  	Training Loss: 0.0008000124944373965
Test Loss:  0.000944622210226953
Valid Loss:  0.0007619825191795826
Epoch:  292  	Training Loss: 0.00079897022806108
Test Loss:  0.0009431547950953245
Valid Loss:  0.0007609453750774264
Epoch:  293  	Training Loss: 0.0007978418143466115
Test Loss:  0.000942101061809808
Valid Loss:  0.0007598380325362086
Epoch:  294  	Training Loss: 0.0007967238780111074
Test Loss:  0.0009409854537807405
Valid Loss:  0.0007587514701299369
Epoch:  295  	Training Loss: 0.0007956245681270957
Test Loss:  0.0009398990077897906
Valid Loss:  0.0007576923817396164
Epoch:  296  	Training Loss: 0.0007945462130010128
Test Loss:  0.0009388282778672874
Valid Loss:  0.0007566381245851517
Epoch:  297  	Training Loss: 0.0007934763561934233
Test Loss:  0.0009377635433338583
Valid Loss:  0.0007555962074548006
Epoch:  298  	Training Loss: 0.0007924233796074986
Test Loss:  0.0009367117891088128
Valid Loss:  0.0007545689004473388
Epoch:  299  	Training Loss: 0.0007913890294730663
Test Loss:  0.0009356866357848048
Valid Loss:  0.0007535435725003481
Epoch:  300  	Training Loss: 0.0007903724908828735
Test Loss:  0.0009346863953396678
Valid Loss:  0.0007525495020672679
Epoch:  301  	Training Loss: 0.0007893891306594014
Test Loss:  0.0009336976800113916
Valid Loss:  0.0007515961769968271
Epoch:  302  	Training Loss: 0.0007884277729317546
Test Loss:  0.0009329323656857014
Valid Loss:  0.0007508071139454842
Epoch:  303  	Training Loss: 0.000787692959420383
Test Loss:  0.0009320878889411688
Valid Loss:  0.0007500866195186973
Epoch:  304  	Training Loss: 0.0007869780529290438
Test Loss:  0.0009312212932854891
Valid Loss:  0.00074939732439816
Epoch:  305  	Training Loss: 0.0007862845668569207
Test Loss:  0.0009303535334765911
Valid Loss:  0.0007487157126888633
Epoch:  306  	Training Loss: 0.0007855959702283144
Test Loss:  0.0009294964838773012
Valid Loss:  0.0007480389904230833
Epoch:  307  	Training Loss: 0.0007849195972084999
Test Loss:  0.0009286634740419686
Valid Loss:  0.0007473941659554839
Epoch:  308  	Training Loss: 0.0007842762861400843
Test Loss:  0.000927855959162116
Valid Loss:  0.0007467742543667555
Epoch:  309  	Training Loss: 0.0007836433942429721
Test Loss:  0.0009270648006349802
Valid Loss:  0.0007461565546691418
Epoch:  310  	Training Loss: 0.0007830179529264569
Test Loss:  0.0009262904641218483
Valid Loss:  0.0007455477025359869
Epoch:  311  	Training Loss: 0.0007824106724001467
Test Loss:  0.000925542670302093
Valid Loss:  0.0007449603290297091
Epoch:  312  	Training Loss: 0.0007818174781277776
Test Loss:  0.0009247985435649753
Valid Loss:  0.0007443594513460994
Epoch:  313  	Training Loss: 0.0007810292881913483
Test Loss:  0.0009245856781490147
Valid Loss:  0.000743687036447227
Epoch:  314  	Training Loss: 0.000780275440774858
Test Loss:  0.0009243731619790196
Valid Loss:  0.0007430098485201597
Epoch:  315  	Training Loss: 0.0007795333513058722
Test Loss:  0.0009240908548235893
Valid Loss:  0.0007423391798511147
Epoch:  316  	Training Loss: 0.0007788012735545635
Test Loss:  0.0009237357880920172
Valid Loss:  0.0007417149026878178
Epoch:  317  	Training Loss: 0.0007780762389302254
Test Loss:  0.0009233158780261874
Valid Loss:  0.0007411458063870668
Epoch:  318  	Training Loss: 0.0007773663965053856
Test Loss:  0.0009228339185938239
Valid Loss:  0.0007405992946587503
Epoch:  319  	Training Loss: 0.0007767041097395122
Test Loss:  0.0009222912485711277
Valid Loss:  0.0007400715257972479
Epoch:  320  	Training Loss: 0.0007760461885482073
Test Loss:  0.0009217113838531077
Valid Loss:  0.0007395479478873312
Epoch:  321  	Training Loss: 0.0007753922836855054
Test Loss:  0.0009210966527462006
Valid Loss:  0.0007390280952677131
Epoch:  322  	Training Loss: 0.0007747416384518147
Test Loss:  0.0009193796431645751
Valid Loss:  0.0007376341964118183
Epoch:  323  	Training Loss: 0.000772364204749465
Test Loss:  0.000918318924959749
Valid Loss:  0.0007364640478044748
Epoch:  324  	Training Loss: 0.0007704555755481124
Test Loss:  0.0009175363229587674
Valid Loss:  0.0007353511173278093
Epoch:  325  	Training Loss: 0.0007688058540225029
Test Loss:  0.000916980323381722
Valid Loss:  0.0007343285251408815
Epoch:  326  	Training Loss: 0.0007675636443309486
Test Loss:  0.0009164204238913953
Valid Loss:  0.0007333433022722602
Epoch:  327  	Training Loss: 0.0007664412842132151
Test Loss:  0.0009158888715319335
Valid Loss:  0.0007323796162381768
Epoch:  328  	Training Loss: 0.0007654102519154549
Test Loss:  0.0009153252467513084
Valid Loss:  0.0007314500398933887
Epoch:  329  	Training Loss: 0.0007644364959560335
Test Loss:  0.0009147904347628355
Valid Loss:  0.0007305299513973296
Epoch:  330  	Training Loss: 0.0007635289221070707
Test Loss:  0.0009141617920249701
Valid Loss:  0.0007297442061826587
Epoch:  331  	Training Loss: 0.0007627438753843307
Test Loss:  0.0009134752326644957
Valid Loss:  0.0007289967616088688
Epoch:  332  	Training Loss: 0.0007619684911333025
Test Loss:  0.0009126146323978901
Valid Loss:  0.0007268078625202179
Epoch:  333  	Training Loss: 0.0007599827949889004
Test Loss:  0.0009112170082516968
Valid Loss:  0.0007249474292621017
Epoch:  334  	Training Loss: 0.0007581623503938317
Test Loss:  0.0009095981367863715
Valid Loss:  0.0007232422940433025
Epoch:  335  	Training Loss: 0.0007563953986391425
Test Loss:  0.0009078822331503034
Valid Loss:  0.0007216293597593904
Epoch:  336  	Training Loss: 0.0007546631386503577
Test Loss:  0.0009061628952622414
Valid Loss:  0.0007200672989711165
Epoch:  337  	Training Loss: 0.0007529875729233027
Test Loss:  0.000904474058188498
Valid Loss:  0.0007185137365013361
Epoch:  338  	Training Loss: 0.0007513266173191369
Test Loss:  0.0009028056520037353
Valid Loss:  0.0007169759483076632
Epoch:  339  	Training Loss: 0.0007496873731724918
Test Loss:  0.0009011289803311229
Valid Loss:  0.0007154591148719192
Epoch:  340  	Training Loss: 0.0007480594795197248
Test Loss:  0.0008994505042210221
Valid Loss:  0.0007139598019421101
Epoch:  341  	Training Loss: 0.0007464446825906634
Test Loss:  0.000897788442671299
Valid Loss:  0.0007124769035726786
Epoch:  342  	Training Loss: 0.0007448622491210699
Test Loss:  0.0008953694486990571
Valid Loss:  0.0007104466203600168
Epoch:  343  	Training Loss: 0.0007425406365655363
Test Loss:  0.0008929921314120293
Valid Loss:   69%|██████▊   | 343/500 [04:05<02:12,  1.18it/s] 69%|██████▉   | 345/500 [04:05<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:05<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:05<00:50,  2.98it/s] 70%|███████   | 351/500 [04:11<02:57,  1.19s/it] 71%|███████   | 353/500 [04:12<02:05,  1.17it/s] 71%|███████   | 355/500 [04:12<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:12<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:12<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:18<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:18<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:19<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:19<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:19<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:25<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:25<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:25<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:26<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:26<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:32<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:32<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:32<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:32<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:33<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:39<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:39<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:39<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:39<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:39<00:33,  3.00it/s] 80%|████████  | 401/500 [04:46<01:57,  1.18s/it] 81%|████████  | 403/500 [04:46<01:22,  1.18it/s] 81%|████████  | 405/500 [04:46<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:46<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:46<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:53<01:45,  1.18s/it]0.0007091387524269521
Epoch:  344  	Training Loss: 0.0007409984245896339
Test Loss:  0.0008907753508538008
Valid Loss:  0.0007080481736920774
Epoch:  345  	Training Loss: 0.0007398269372060895
Test Loss:  0.0008887122385203838
Valid Loss:  0.0007071079453453422
Epoch:  346  	Training Loss: 0.0007387737277895212
Test Loss:  0.0008867411524988711
Valid Loss:  0.0007063538068905473
Epoch:  347  	Training Loss: 0.0007378767477348447
Test Loss:  0.0008849747246131301
Valid Loss:  0.0007056973408907652
Epoch:  348  	Training Loss: 0.0007371470564976335
Test Loss:  0.0008834358304738998
Valid Loss:  0.0007050693966448307
Epoch:  349  	Training Loss: 0.0007364948396570981
Test Loss:  0.0008820504881441593
Valid Loss:  0.0007044484373182058
Epoch:  350  	Training Loss: 0.0007358601433224976
Test Loss:  0.000880770618095994
Valid Loss:  0.0007038343464955688
Epoch:  351  	Training Loss: 0.0007352404063567519
Test Loss:  0.0008795707253739238
Valid Loss:  0.0007032257271930575
Epoch:  352  	Training Loss: 0.000734631554223597
Test Loss:  0.000879208673723042
Valid Loss:  0.0007020547054708004
Epoch:  353  	Training Loss: 0.0007335097761824727
Test Loss:  0.0008785809041000903
Valid Loss:  0.0007010075496509671
Epoch:  354  	Training Loss: 0.0007324353791773319
Test Loss:  0.0008779367199167609
Valid Loss:  0.0007000243058428168
Epoch:  355  	Training Loss: 0.0007314181420952082
Test Loss:  0.0008772789733484387
Valid Loss:  0.0006990518886595964
Epoch:  356  	Training Loss: 0.0007304130704142153
Test Loss:  0.0008766136015765369
Valid Loss:  0.000698092277161777
Epoch:  357  	Training Loss: 0.0007294203387573361
Test Loss:  0.0008759507909417152
Valid Loss:  0.0006971582770347595
Epoch:  358  	Training Loss: 0.000728469283785671
Test Loss:  0.0008752804133109748
Valid Loss:  0.0006962333573028445
Epoch:  359  	Training Loss: 0.0007275308016687632
Test Loss:  0.0008746058447286487
Valid Loss:  0.0006953173433430493
Epoch:  360  	Training Loss: 0.0007266133325174451
Test Loss:  0.0008739421609789133
Valid Loss:  0.0006944251945242286
Epoch:  361  	Training Loss: 0.0007257248507812619
Test Loss:  0.0008733041468076408
Valid Loss:  0.0006935691344551742
Epoch:  362  	Training Loss: 0.000724846264347434
Test Loss:  0.0008677627192810178
Valid Loss:  0.0006904981564730406
Epoch:  363  	Training Loss: 0.0007209366885945201
Test Loss:  0.0008654413977637887
Valid Loss:  0.0006879448192194104
Epoch:  364  	Training Loss: 0.0007180881802923977
Test Loss:  0.0008633440011180937
Valid Loss:  0.00068556988844648
Epoch:  365  	Training Loss: 0.0007155535276979208
Test Loss:  0.0008614757098257542
Valid Loss:  0.0006833852967247367
Epoch:  366  	Training Loss: 0.0007132891332730651
Test Loss:  0.000859760504681617
Valid Loss:  0.0006812672945670784
Epoch:  367  	Training Loss: 0.0007112101884558797
Test Loss:  0.0008581522270105779
Valid Loss:  0.0006795180379413068
Epoch:  368  	Training Loss: 0.0007095579640008509
Test Loss:  0.0008565069874748588
Valid Loss:  0.000677873264066875
Epoch:  369  	Training Loss: 0.0007079810020513833
Test Loss:  0.0008548595942556858
Valid Loss:  0.0006763060810044408
Epoch:  370  	Training Loss: 0.0007065244717523456
Test Loss:  0.0008531335042789578
Valid Loss:  0.0006748804589733481
Epoch:  371  	Training Loss: 0.0007050993153825402
Test Loss:  0.0008515287190675735
Valid Loss:  0.0006735962815582752
Epoch:  372  	Training Loss: 0.0007037939503788948
Test Loss:  0.0008495170623064041
Valid Loss:  0.0006732443580403924
Epoch:  373  	Training Loss: 0.0007034613518044353
Test Loss:  0.0008479232783429325
Valid Loss:  0.0006729356828145683
Epoch:  374  	Training Loss: 0.0007031757850199938
Test Loss:  0.0008465059800073504
Valid Loss:  0.0006726564024575055
Epoch:  375  	Training Loss: 0.0007029268308542669
Test Loss:  0.0008453035261482
Valid Loss:  0.0006724059348925948
Epoch:  376  	Training Loss: 0.0007027067476883531
Test Loss:  0.0008441810496151447
Valid Loss:  0.0006721861427649856
Epoch:  377  	Training Loss: 0.0007024997612461448
Test Loss:  0.000843190005980432
Valid Loss:  0.0006719852681271732
Epoch:  378  	Training Loss: 0.0007023091311566532
Test Loss:  0.0008422661921940744
Valid Loss:  0.0006717957439832389
Epoch:  379  	Training Loss: 0.0007021272322162986
Test Loss:  0.0008414070471189916
Valid Loss:  0.0006716165808029473
Epoch:  380  	Training Loss: 0.0007019529584795237
Test Loss:  0.0008406131528317928
Valid Loss:  0.0006714481860399246
Epoch:  381  	Training Loss: 0.0007017838070169091
Test Loss:  0.0008399162325076759
Valid Loss:  0.0006712940521538258
Epoch:  382  	Training Loss: 0.0007016249001026154
Test Loss:  0.0008398996433243155
Valid Loss:  0.0006703226827085018
Epoch:  383  	Training Loss: 0.0007003363571129739
Test Loss:  0.0008399924263358116
Valid Loss:  0.0006695060292258859
Epoch:  384  	Training Loss: 0.000699169933795929
Test Loss:  0.000839877116959542
Valid Loss:  0.0006687550339847803
Epoch:  385  	Training Loss: 0.0006982266786508262
Test Loss:  0.000839518615975976
Valid Loss:  0.0006681319791823626
Epoch:  386  	Training Loss: 0.0006974117131903768
Test Loss:  0.000838914536871016
Valid Loss:  0.0006675133481621742
Epoch:  387  	Training Loss: 0.0006967250956222415
Test Loss:  0.0008381549268960953
Valid Loss:  0.0006669280119240284
Epoch:  388  	Training Loss: 0.0006960428436286747
Test Loss:  0.0008373355958610773
Valid Loss:  0.000666353153064847
Epoch:  389  	Training Loss: 0.0006953734555281699
Test Loss:  0.0008364266250282526
Valid Loss:  0.0006657781777903438
Epoch:  390  	Training Loss: 0.0006947810761630535
Test Loss:  0.000835457060020417
Valid Loss:  0.0006652959855273366
Epoch:  391  	Training Loss: 0.0006941946339793503
Test Loss:  0.0008344543748535216
Valid Loss:  0.0006648041890002787
Epoch:  392  	Training Loss: 0.0006936456775292754
Test Loss:  0.0008329988922923803
Valid Loss:  0.0006624351954087615
Epoch:  393  	Training Loss: 0.0006913855904713273
Test Loss:  0.00083136186003685
Valid Loss:  0.0006603568326681852
Epoch:  394  	Training Loss: 0.0006892780074849725
Test Loss:  0.0008298150496557355
Valid Loss:  0.0006584231741726398
Epoch:  395  	Training Loss: 0.0006873937090858817
Test Loss:  0.0008282240596599877
Valid Loss:  0.0006566052325069904
Epoch:  396  	Training Loss: 0.0006856711115688086
Test Loss:  0.0008267160737887025
Valid Loss:  0.0006550663383677602
Epoch:  397  	Training Loss: 0.0006841782014816999
Test Loss:  0.0008252411498688161
Valid Loss:  0.0006536140572279692
Epoch:  398  	Training Loss: 0.0006827458273619413
Test Loss:  0.0008238345035351813
Valid Loss:  0.0006523168412968516
Epoch:  399  	Training Loss: 0.0006814898806624115
Test Loss:  0.0008224535849876702
Valid Loss:  0.0006511277751997113
Epoch:  400  	Training Loss: 0.0006802404532209039
Test Loss:  0.0008210829109884799
Valid Loss:  0.0006500021554529667
Epoch:  401  	Training Loss: 0.0006790269981138408
Test Loss:  0.0008196876151487231
Valid Loss:  0.0006489290972240269
Epoch:  402  	Training Loss: 0.0006778942770324647
Test Loss:  0.0008184700272977352
Valid Loss:  0.0006477686110883951
Epoch:  403  	Training Loss: 0.0006759450770914555
Test Loss:  0.0008177498821169138
Valid Loss:  0.0006465304177254438
Epoch:  404  	Training Loss: 0.0006742741679772735
Test Loss:  0.0008169948705472052
Valid Loss:  0.0006453883834183216
Epoch:  405  	Training Loss: 0.0006729391170665622
Test Loss:  0.0008161119185388088
Valid Loss:  0.000644320622086525
Epoch:  406  	Training Loss: 0.0006717175710946321
Test Loss:  0.0008152169757522643
Valid Loss:  0.000643303501419723
Epoch:  407  	Training Loss: 0.0006705718697048724
Test Loss:  0.0008142883889377117
Valid Loss:  0.0006423466838896275
Epoch:  408  	Training Loss: 0.0006695074262097478
Test Loss:  0.0008132966468110681
Valid Loss:  0.0006414603558368981
Epoch:  409  	Training Loss: 0.0006685139378532767
Test Loss:  0.0008122259168885648
Valid Loss:  0.0006406274042092264
Epoch:  410  	Training Loss: 0.0006675521144643426
Test Loss:  0.0008111059432849288
Valid Loss:  0.0006398509722203016
Epoch:  411  	Training Loss: 0.0006666271947324276
Test Loss:  0.0008100298000499606
Valid Loss:  0.00063909130403772
 83%|████████▎ | 413/500 [04:53<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:53<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:53<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.98it/s] 84%|████████▍ | 421/500 [05:00<01:35,  1.21s/it] 85%|████████▍ | 423/500 [05:00<01:07,  1.15it/s] 85%|████████▌ | 425/500 [05:00<00:47,  1.59it/s] 85%|████████▌ | 427/500 [05:00<00:33,  2.16it/s] 86%|████████▌ | 429/500 [05:00<00:24,  2.91it/s] 86%|████████▌ | 431/500 [05:07<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:07<00:57,  1.18it/s] 87%|████████▋ | 435/500 [05:07<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:07<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:13<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:13<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:14<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:14<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:14<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:20<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:20<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:21<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:21<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:27<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:28<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:34<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:34<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:34<00:06,  3.04it/s]Epoch:  412  	Training Loss: 0.0006657193880528212
Test Loss:  0.0008071978809311986
Valid Loss:  0.0006346945883706212
Epoch:  413  	Training Loss: 0.0006602072389796376
Test Loss:  0.0008050627075135708
Valid Loss:  0.0006322297267615795
Epoch:  414  	Training Loss: 0.0006568272947333753
Test Loss:  0.0008031183388084173
Valid Loss:  0.0006299195811152458
Epoch:  415  	Training Loss: 0.0006541831535287201
Test Loss:  0.0008011910249479115
Valid Loss:  0.0006277135107666254
Epoch:  416  	Training Loss: 0.0006519113667309284
Test Loss:  0.0007992924656718969
Valid Loss:  0.0006256346823647618
Epoch:  417  	Training Loss: 0.0006498165894299746
Test Loss:  0.0007973274332471192
Valid Loss:  0.0006236945046111941
Epoch:  418  	Training Loss: 0.0006478941650129855
Test Loss:  0.0007953186286613345
Valid Loss:  0.0006218674243427813
Epoch:  419  	Training Loss: 0.0006460633012466133
Test Loss:  0.0007933129090815783
Valid Loss:  0.0006202165968716145
Epoch:  420  	Training Loss: 0.0006442874437198043
Test Loss:  0.0007912194123491645
Valid Loss:  0.0006186885293573141
Epoch:  421  	Training Loss: 0.0006426882464438677
Test Loss:  0.000789118348620832
Valid Loss:  0.0006172374123707414
Epoch:  422  	Training Loss: 0.0006412522052414715
Test Loss:  0.0007875225273892283
Valid Loss:  0.0006168807158246636
Epoch:  423  	Training Loss: 0.0006406756001524627
Test Loss:  0.0007861598860472441
Valid Loss:  0.0006165142403915524
Epoch:  424  	Training Loss: 0.0006401581922546029
Test Loss:  0.000784852949436754
Valid Loss:  0.0006162036443129182
Epoch:  425  	Training Loss: 0.0006396788521669805
Test Loss:  0.0007835617288947105
Valid Loss:  0.0006158888572826982
Epoch:  426  	Training Loss: 0.0006392369978129864
Test Loss:  0.0007822854095138609
Valid Loss:  0.00061559904133901
Epoch:  427  	Training Loss: 0.0006388216279447079
Test Loss:  0.0007810655515640974
Valid Loss:  0.0006153219728730619
Epoch:  428  	Training Loss: 0.0006384217413142323
Test Loss:  0.0007798761944286525
Valid Loss:  0.0006150553235784173
Epoch:  429  	Training Loss: 0.0006380412960425019
Test Loss:  0.0007787457434460521
Valid Loss:  0.0006148072425276041
Epoch:  430  	Training Loss: 0.0006376702222041786
Test Loss:  0.000777643930632621
Valid Loss:  0.0006145615479908884
Epoch:  431  	Training Loss: 0.000637309392914176
Test Loss:  0.0007766064372844994
Valid Loss:  0.0006143234204500914
Epoch:  432  	Training Loss: 0.0006369537441059947
Test Loss:  0.0007757419371046126
Valid Loss:  0.0006131239933893085
Epoch:  433  	Training Loss: 0.0006356746307574213
Test Loss:  0.0007749286596663296
Valid Loss:  0.0006121378391981125
Epoch:  434  	Training Loss: 0.0006346559966914356
Test Loss:  0.0007741590379737318
Valid Loss:  0.0006112917326390743
Epoch:  435  	Training Loss: 0.0006337303784675896
Test Loss:  0.0007733845850452781
Valid Loss:  0.000610476708970964
Epoch:  436  	Training Loss: 0.0006328198360279202
Test Loss:  0.0007726136827841401
Valid Loss:  0.0006097117438912392
Epoch:  437  	Training Loss: 0.000631948234513402
Test Loss:  0.0007718175183981657
Valid Loss:  0.000608979957178235
Epoch:  438  	Training Loss: 0.0006311202305369079
Test Loss:  0.0007710563950240612
Valid Loss:  0.0006083260523155332
Epoch:  439  	Training Loss: 0.0006303692935034633
Test Loss:  0.0007703423034399748
Valid Loss:  0.0006077133002690971
Epoch:  440  	Training Loss: 0.0006296540377661586
Test Loss:  0.0007696467218920588
Valid Loss:  0.0006071027601137757
Epoch:  441  	Training Loss: 0.0006289489683695138
Test Loss:  0.0007689785561524332
Valid Loss:  0.0006065104971639812
Epoch:  442  	Training Loss: 0.0006282988470047712
Test Loss:  0.000768377329222858
Valid Loss:  0.0006062670145183802
Epoch:  443  	Training Loss: 0.0006279960507526994
Test Loss:  0.0007677075918763876
Valid Loss:  0.0006060831947252154
Epoch:  444  	Training Loss: 0.0006276980275288224
Test Loss:  0.0007670157356187701
Valid Loss:  0.0006059122970327735
Epoch:  445  	Training Loss: 0.0006274036131799221
Test Loss:  0.0007663280703127384
Valid Loss:  0.0006057494319975376
Epoch:  446  	Training Loss: 0.0006271126912906766
Test Loss:  0.0007656500092707574
Valid Loss:  0.0006055918056517839
Epoch:  447  	Training Loss: 0.0006268229335546494
Test Loss:  0.0007649853941984475
Valid Loss:  0.0006054358091205359
Epoch:  448  	Training Loss: 0.0006265497067943215
Test Loss:  0.0007643111748620868
Valid Loss:  0.0006052814424037933
Epoch:  449  	Training Loss: 0.0006263102404773235
Test Loss:  0.0007636400987394154
Valid Loss:  0.0006051357486285269
Epoch:  450  	Training Loss: 0.0006260761292651296
Test Loss:  0.000762971758376807
Valid Loss:  0.0006049927906133235
Epoch:  451  	Training Loss: 0.0006258627399802208
Test Loss:  0.0007623133133165538
Valid Loss:  0.0006048566428944468
Epoch:  452  	Training Loss: 0.0006256513297557831
Test Loss:  0.000760747934691608
Valid Loss:  0.0006033191457390785
Epoch:  453  	Training Loss: 0.0006239005597308278
Test Loss:  0.0007595861097797751
Valid Loss:  0.0006018901476636529
Epoch:  454  	Training Loss: 0.0006224297685548663
Test Loss:  0.0007584327831864357
Valid Loss:  0.0006006731418892741
Epoch:  455  	Training Loss: 0.0006212242878973484
Test Loss:  0.000757283007260412
Valid Loss:  0.0005996230174787343
Epoch:  456  	Training Loss: 0.0006201249780133367
Test Loss:  0.0007560820668004453
Valid Loss:  0.0005986704491078854
Epoch:  457  	Training Loss: 0.0006190824788063765
Test Loss:  0.0007548932917416096
Valid Loss:  0.0005978653207421303
Epoch:  458  	Training Loss: 0.0006181516218930483
Test Loss:  0.0007536349585279822
Valid Loss:  0.0005970921483822167
Epoch:  459  	Training Loss: 0.000617402489297092
Test Loss:  0.0007523093954659998
Valid Loss:  0.0005963657749816775
Epoch:  460  	Training Loss: 0.0006166857783682644
Test Loss:  0.000750976032577455
Valid Loss:  0.0005956836976110935
Epoch:  461  	Training Loss: 0.0006160296034067869
Test Loss:  0.0007496466278098524
Valid Loss:  0.0005950379418209195
Epoch:  462  	Training Loss: 0.0006154068396426737
Test Loss:  0.0007480274653062224
Valid Loss:  0.0005941579584032297
Epoch:  463  	Training Loss: 0.0006145869847387075
Test Loss:  0.0007464388618245721
Valid Loss:  0.0005934048676863313
Epoch:  464  	Training Loss: 0.0006138285389170051
Test Loss:  0.0007449694094248116
Valid Loss:  0.0005927040474489331
Epoch:  465  	Training Loss: 0.0006131465779617429
Test Loss:  0.0007436100859194994
Valid Loss:  0.000592052296269685
Epoch:  466  	Training Loss: 0.0006125243380665779
Test Loss:  0.0007423774804919958
Valid Loss:  0.0005914682406000793
Epoch:  467  	Training Loss: 0.0006119577446952462
Test Loss:  0.000741264084354043
Valid Loss:  0.0005909402389079332
Epoch:  468  	Training Loss: 0.0006114457501098514
Test Loss:  0.0007402391638606787
Valid Loss:  0.0005904425051994622
Epoch:  469  	Training Loss: 0.0006109626265242696
Test Loss:  0.0007392650586552918
Valid Loss:  0.0005899595562368631
Epoch:  470  	Training Loss: 0.0006105101783759892
Test Loss:  0.0007383270421996713
Valid Loss:  0.0005894973874092102
Epoch:  471  	Training Loss: 0.0006100675091147423
Test Loss:  0.0007374528795480728
Valid Loss:  0.0005890778265893459
Epoch:  472  	Training Loss: 0.0006096448050811887
Test Loss:  0.0007373247062787414
Valid Loss:  0.0005889029707759619
Epoch:  473  	Training Loss: 0.000609304872341454
Test Loss:  0.0007371931569650769
Valid Loss:  0.0005887196166440845
Epoch:  474  	Training Loss: 0.0006089708767831326
Test Loss:  0.0007370061939582229
Valid Loss:  0.0005885472055524588
Epoch:  475  	Training Loss: 0.0006086406647227705
Test Loss:  0.0007367925136350095
Valid Loss:  0.0005883749108761549
Epoch:  476  	Training Loss: 0.000608336238656193
Test Loss:  0.0007365307537838817
Valid Loss:  0.0005882121622562408
Epoch:  477  	Training Loss: 0.0006080713937990367
Test Loss:  0.000736221089027822
Valid Loss:  0.0005880634416826069
Epoch:  478  	Training Loss: 0.0006078205769881606
Test Loss:  0.0007358957082033157
Valid Loss:  0.0005879130330868065
Epoch:  479  	Training Loss: 0.0006075856508687139
Test Loss:  0.0007355437846854329
Valid Loss:  0.0005877723451703787
Epoch:  480  	Training Loss: 0.0006073534023016691
 96%|█████████▌| 481/500 [05:40<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.66it/s] 97%|█████████▋| 487/500 [05:41<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:41<00:03,  3.03it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.99it/s]100%|██████████| 500/500 [05:48<00:00,  1.44it/s]
Test Loss:  0.0007351870299316943
Valid Loss:  0.0005876312498003244
Epoch:  481  	Training Loss: 0.0006071225507184863
Test Loss:  0.0007348201470449567
Valid Loss:  0.0005874914349988103
Epoch:  482  	Training Loss: 0.0006068944348953664
Test Loss:  0.0007351771928369999
Valid Loss:  0.0005852882168255746
Epoch:  483  	Training Loss: 0.0006040795706212521
Test Loss:  0.0007355411071330309
Valid Loss:  0.0005834804032929242
Epoch:  484  	Training Loss: 0.0006019952124916017
Test Loss:  0.0007357893628068268
Valid Loss:  0.0005817259079776704
Epoch:  485  	Training Loss: 0.0006001082365401089
Test Loss:  0.00073584308847785
Valid Loss:  0.0005800399230793118
Epoch:  486  	Training Loss: 0.0005983920418657362
Test Loss:  0.0007357304566539824
Valid Loss:  0.0005784797249361873
Epoch:  487  	Training Loss: 0.0005968071636743844
Test Loss:  0.0007354271365329623
Valid Loss:  0.0005770169664174318
Epoch:  488  	Training Loss: 0.0005953498184680939
Test Loss:  0.0007350051309913397
Valid Loss:  0.000575618410948664
Epoch:  489  	Training Loss: 0.0005939481197856367
Test Loss:  0.0007344888290390372
Valid Loss:  0.0005743309739045799
Epoch:  490  	Training Loss: 0.0005926170269958675
Test Loss:  0.0007338550640270114
Valid Loss:  0.0005731314304284751
Epoch:  491  	Training Loss: 0.0005913893110118806
Test Loss:  0.0007331451051868498
Valid Loss:  0.000571971177123487
Epoch:  492  	Training Loss: 0.0005902311531826854
Test Loss:  0.0007317262352444232
Valid Loss:  0.0005704570794478059
Epoch:  493  	Training Loss: 0.0005889897001907229
Test Loss:  0.000730111903976649
Valid Loss:  0.0005692171398550272
Epoch:  494  	Training Loss: 0.0005878557567484677
Test Loss:  0.000728452461771667
Valid Loss:  0.0005681633483618498
Epoch:  495  	Training Loss: 0.000586783280596137
Test Loss:  0.000726768805179745
Valid Loss:  0.0005671480321325362
Epoch:  496  	Training Loss: 0.0005857464857399464
Test Loss:  0.0007251127972267568
Valid Loss:  0.000566166709177196
Epoch:  497  	Training Loss: 0.0005847307620570064
Test Loss:  0.0007235141820274293
Valid Loss:  0.0005652304389514029
Epoch:  498  	Training Loss: 0.0005837607895955443
Test Loss:  0.0007219515973702073
Valid Loss:  0.0005643070326186717
Epoch:  499  	Training Loss: 0.000582812528591603
Test Loss:  0.0007204316789284348
Valid Loss:  0.0005633964901790023
Epoch:  500  	Training Loss: 0.0005818745121359825
Test Loss:  0.000718957744538784
Valid Loss:  0.0005625232588499784
seed is  18
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 14.68it/s]  1%|          | 4/500 [00:00<00:33, 14.80it/s]  1%|          | 6/500 [00:00<00:31, 15.53it/s]  2%|▏         | 8/500 [00:00<00:31, 15.81it/s]  2%|▏         | 10/500 [00:00<00:30, 16.11it/s]  2%|▏         | 12/500 [00:00<00:30, 16.13it/s]  3%|▎         | 14/500 [00:00<00:30, 15.96it/s]  3%|▎         | 16/500 [00:01<00:30, 15.71it/s]  4%|▎         | 18/500 [00:01<00:30, 15.95it/s]  4%|▍         | 20/500 [00:01<00:29, 16.20it/s]  4%|▍         | 22/500 [00:01<00:29, 15.99it/s]  5%|▍         | 24/500 [00:01<00:29, 15.94it/s]  5%|▌         | 26/500 [00:01<00:29, 16.10it/s]  6%|▌         | 28/500 [00:01<00:29, 16.14it/s]  6%|▌         | 30/500 [00:01<00:29, 15.77it/s]  6%|▋         | 32/500 [00:02<00:29, 15.95it/s]  7%|▋         | 34/500 [00:02<00:29, 16.04it/s]  7%|▋         | 36/500 [00:02<00:28, 16.07it/s]  8%|▊         | 38/500 [00:02<00:28, 16.21it/s]  8%|▊         | 40/500 [00:02<00:28, 16.36it/s]  8%|▊         | 42/500 [00:02<00:27, 16.46it/s]  9%|▉         | 44/500 [00:02<00:27, 16.45it/s]  9%|▉         | 46/500 [00:02<00:27, 16.47it/s] 10%|▉         | 48/500 [00:02<00:27, 16.32it/s] 10%|█         | 50/500 [00:03<00:28, 15.91it/s] 10%|█         | 52/500 [00:03<00:28, 15.95it/s] 11%|█         | 54/500 [00:03<00:27, 16.02it/s] 11%|█         | 56/500 [00:03<00:27, 16.13it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.22it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.32it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.30it/s] 13%|█▎        | 64/500 [00:03<00:27, 16.13it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.11it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.25it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.25it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.33it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.41it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.41it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.50it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.44it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.40it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.41it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.41it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.41it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.45it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.46it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.45it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.34it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.98it/s] 20%|██        | 100/500 [00:06<00:24, 16.17it/s] 20%|██        | 102/500 [00:06<00:24, 16.24it/s] 21%|██        | 104/500 [00:06<00:24, 16.42it/s] 21%|██        | 106/500 [00:06<00:24, 16.19it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.17it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.22it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.29it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.99it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.01it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.09it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.20it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.06it/s] 25%|██▍       | 124/500 [00:07<00:25, 14.74it/s]Epoch:  1  	Training Loss: 0.5142406225204468
Test Loss:  11246.46875
Valid Loss:  11219.837890625
Epoch:  2  	Training Loss: 11234.884765625
Test Loss:  3.1975986603670005e+20
Valid Loss:  3.2109729438854074e+20
Epoch:  3  	Training Loss: 3.2082982279192143e+20
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:25, 14.59it/s] 26%|██▌       | 128/500 [00:07<00:24, 15.16it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.55it/s] 26%|██▋       | 132/500 [00:08<00:24, 15.23it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.58it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.84it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.85it/s] 28%|██▊       | 140/500 [00:08<00:22, 15.83it/s] 28%|██▊       | 142/500 [00:08<00:22, 15.66it/s] 29%|██▉       | 144/500 [00:08<00:22, 15.64it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.43it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.72it/s] 30%|███       | 150/500 [00:09<00:22, 15.76it/s] 30%|███       | 152/500 [00:09<00:23, 14.57it/s] 31%|███       | 154/500 [00:09<00:24, 14.04it/s] 31%|███       | 156/500 [00:09<00:23, 14.65it/s] 32%|███▏      | 158/500 [00:09<00:22, 15.02it/s] 32%|███▏      | 160/500 [00:10<00:22, 15.32it/s] 32%|███▏      | 162/500 [00:10<00:23, 14.68it/s] 33%|███▎      | 164/500 [00:10<00:22, 15.17it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.33it/s] 34%|███▎      | 168/500 [00:10<00:21, 15.70it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.92it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.07it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.18it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.13it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.25it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.19it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.22it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.21it/s] 37%|███▋      | 186/500 [00:11<00:20, 15.55it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.81it/s] 38%|███▊      | 190/500 [00:11<00:19, 15.86it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.62it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.77it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.99it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.02it/s] 40%|████      | 200/500 [00:12<00:18, 16.02it/s] 40%|████      | 202/500 [00:12<00:18, 16.21it/s] 41%|████      | 204/500 [00:12<00:18, 16.32it/s] 41%|████      | 206/500 [00:12<00:17, 16.36it/s] 42%|████▏     | 208/500 [00:13<00:17, 16.39it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.44it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.40it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.48it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.43it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.99it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.13it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.29it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.08it/s] 45%|████▌     | 226/500 [00:14<00:18, 14.87it/s] 46%|████▌     | 228/500 [00:14<00:18, 15.11it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.53it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.77it/s] 47%|████▋     | 234/500 [00:14<00:17, 15.58it/s] 47%|████▋     | 236/500 [00:14<00:16, 15.62it/s] 48%|████▊     | 238/500 [00:14<00:16, 15.89it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.93it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.99it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.81it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.01it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.10it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.06it/s] 50%|█████     | 252/500 [00:15<00:15, 16.16it/s] 51%|█████     | 254/500 [00:15<00:15, 16.12it/s] 51%|█████     | 256/500 [00:16<00:15, 16.26it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.38it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.39it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.43it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.48it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.39it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.28it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.17it/s] 54%|█████▍    | 272/500 [00:17<00:14, 15.96it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.16it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.16it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.28it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.33it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.42it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.46it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.49it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.43it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.34it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.22it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.23it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.91it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.00it/s] 60%|██████    | 300/500 [00:18<00:12, 16.13it/s] 60%|██████    | 302/500 [00:18<00:12, 15.95it/s] 61%|██████    | 304/500 [00:19<00:12, 15.84it/s] 61%|██████    | 306/500 [00:19<00:12, 15.91it/s] 62%|██████▏   | 308/500 [00:19<00:12, 14.95it/s] 62%|██████▏   | 310/500 [00:19<00:14, 13.37it/s] 62%|██████▏   | 312/500 [00:19<00:13, 14.12it/s] 63%|██████▎   | 314/500 [00:19<00:12, 14.54it/s] 63%|██████▎   | 316/500 [00:19<00:12, 15.03it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.46it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.64it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.75it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.78it/s] 65%|██████▌   | 326/500 [00:20<00:10, 15.90it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.03it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.23it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.36it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.42it/s] 67%|██████▋   | 336/500 [00:21<00:09, 16.44it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.47it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.28it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.34it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.23it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.30it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.27it/s] 70%|███████   | 350/500 [00:21<00:09, 16.19it/s] 70%|███████   | 352/500 [00:22<00:09, 15.96it/s] 71%|███████   | 354/500 [00:22<00:09, 15.50it/s] 71%|███████   | 356/500 [00:22<00:09, 15.72it/s] 72%|███████▏  | 358/500 [00:22<00:08, 15.81it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.92it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.13it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.16it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.94it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.06it/s] 74%|███████▍  | 370/500 [00:23<00:11, 11.31it/s] 74%|███████▍  | 372/500 [00:23<00:16,  7.90it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:13,  9.30it/s] 75%|███████▌  | 376/500 [00:24<00:11, 10.55it/s] 76%|███████▌  | 378/500 [00:24<00:10, 11.22it/s] 76%|███████▌  | 380/500 [00:24<00:09, 12.36it/s] 76%|███████▋  | 382/500 [00:24<00:08, 13.33it/s] 77%|███████▋  | 384/500 [00:24<00:08, 14.12it/s] 77%|███████▋  | 386/500 [00:24<00:07, 14.81it/s] 78%|███████▊  | 388/500 [00:24<00:07, 15.17it/s] 78%|███████▊  | 390/500 [00:24<00:07, 15.57it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.68it/s] 79%|███████▉  | 394/500 [00:25<00:07, 14.99it/s] 79%|███████▉  | 396/500 [00:25<00:07, 14.49it/s] 80%|███████▉  | 398/500 [00:25<00:06, 14.94it/s] 80%|████████  | 400/500 [00:25<00:06, 15.37it/s] 80%|████████  | 402/500 [00:25<00:06, 15.64it/s] 81%|████████  | 404/500 [00:25<00:06, 15.92it/s] 81%|████████  | 406/500 [00:26<00:05, 15.94it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.13it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.24it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.17it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.26it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.26it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.21it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.29it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.38it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.42it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.43it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.46it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.19it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.18it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.16it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.12it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.01it/s] 88%|████████▊ | 440/500 [00:28<00:03, 15.91it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.09it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.18it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.32it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.40it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.43it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.46it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.39it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.41it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.43it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.44it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.02it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.08it/s] 93%|█████████▎| 466/500 [00:29<00:02, 14.74it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.20it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.42it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.65it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.79it/s] 95%|█████████▌| 476/500 [00:30<00:01, 12.10it/s] 96%|█████████▌| 478/500 [00:30<00:02,  7.65it/s] 96%|█████████▌| 480/500 [00:31<00:02,  8.95it/s] 96%|█████████▋| 482/500 [00:31<00:01, 10.27it/s] 97%|█████████▋| 484/500 [00:31<00:01, 11.50it/s] 97%|█████████▋| 486/500 [00:31<00:01, 12.34it/s] 98%|█████████▊| 488/500 [00:31<00:00, 13.16it/s] 98%|█████████▊| 490/500 [00:31<00:00, 13.61it/s] 98%|█████████▊| 492/500 [00:31<00:00, 14.25it/s] 99%|█████████▉| 494/500 [00:32<00:00, 14.58it/s] 99%|█████████▉| 496/500 [00:32<00:00, 14.88it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 15.10it/s]100%|██████████| 500/500 [00:32<00:00, 15.40it/s]100%|██████████| 500/500 [00:32<00:00, 15.43it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  18
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:11,  6.15s/it]  1%|          | 3/500 [00:06<13:38,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:13<11:19,  1.39s/it]  2%|▏         | 12/500 [00:13<09:37,  1.18s/it]  3%|▎         | 14/500 [00:13<06:20,  1.28it/s]  3%|▎         | 16/500 [00:14<04:20,  1.86it/s]  4%|▎         | 18/500 [00:14<03:05,  2.60it/s]  4%|▍         | 20/500 [00:14<02:16,  3.52it/s]  4%|▍         | 22/500 [00:20<09:47,  1.23s/it]  5%|▍         | 24/500 [00:21<06:54,  1.15it/s]  5%|▌         | 26/500 [00:21<04:56,  1.60it/s]  6%|▌         | 28/500 [00:21<03:34,  2.20it/s]  6%|▌         | 30/500 [00:21<02:38,  2.97it/s]  6%|▋         | 32/500 [00:27<09:26,  1.21s/it]  7%|▋         | 34/500 [00:28<06:43,  1.15it/s]  7%|▋         | 36/500 [00:28<04:50,  1.60it/s]  8%|▊         | 38/500 [00:28<03:31,  2.19it/s]  8%|▊         | 40/500 [00:28<02:37,  2.91it/s]  8%|▊         | 42/500 [00:34<09:11,  1.20s/it]  9%|▉         | 44/500 [00:34<06:32,  1.16it/s]  9%|▉         | 46/500 [00:35<04:42,  1.61it/s] 10%|▉         | 48/500 [00:35<03:26,  2.19it/s] 10%|█         | 50/500 [00:35<02:32,  2.95it/s] 10%|█         | 52/500 [00:41<08:49,  1.18s/it] 11%|█         | 54/500 [00:41<06:17,  1.18it/s] 11%|█         | 56/500 [00:41<04:31,  1.63it/s] 12%|█▏        | 58/500 [00:42<03:17,  2.24it/s] 12%|█▏        | 60/500 [00:42<02:26,  3.01it/s] 12%|█▏        | 62/500 [00:48<08:32,  1.17s/it] 13%|█▎        | 64/500 [00:48<06:05,  1.19it/s] 13%|█▎        | 66/500 [00:48<04:23,  1.65it/s] 14%|█▎        | 68/500 [00:48<03:11,  2.25it/s] 14%|█▍        | 70/500 [00:48<02:21,  3.03it/s] 14%|█▍        | 72/500 [00:55<08:19,  1.17s/it]Epoch:  1  	Training Loss: 0.5142406225204468
Test Loss:  68.21807861328125
Valid Loss:  68.60010528564453
Epoch:  2  	Training Loss: 68.52960205078125
Test Loss:  0.48749619722366333
Valid Loss:  0.4588138461112976
Epoch:  3  	Training Loss: 0.4709206223487854
Test Loss:  0.48747122287750244
Valid Loss:  0.4587896466255188
Epoch:  4  	Training Loss: 0.4708961546421051
Test Loss:  0.48744624853134155
Valid Loss:  0.45876550674438477
Epoch:  5  	Training Loss: 0.4708716869354248
Test Loss:  0.48742133378982544
Valid Loss:  0.4587414264678955
Epoch:  6  	Training Loss: 0.4708472490310669
Test Loss:  0.4873964190483093
Valid Loss:  0.45871734619140625
Epoch:  7  	Training Loss: 0.470822811126709
Test Loss:  0.4873715043067932
Valid Loss:  0.4586932361125946
Epoch:  8  	Training Loss: 0.4707983732223511
Test Loss:  0.4873465895652771
Valid Loss:  0.45866912603378296
Epoch:  9  	Training Loss: 0.47077396512031555
Test Loss:  0.4873217046260834
Valid Loss:  0.4586450457572937
Epoch:  10  	Training Loss: 0.47074955701828003
Test Loss:  0.48729681968688965
Valid Loss:  0.4586210250854492
Epoch:  11  	Training Loss: 0.4707251489162445
Test Loss:  0.4872719943523407
Valid Loss:  0.45859697461128235
Epoch:  12  	Training Loss: 0.47070077061653137
Test Loss:  0.48724690079689026
Valid Loss:  0.45857274532318115
Epoch:  13  	Training Loss: 0.4706761837005615
Test Loss:  0.48722198605537415
Valid Loss:  0.4585486650466919
Epoch:  14  	Training Loss: 0.4706517457962036
Test Loss:  0.48719722032546997
Valid Loss:  0.4585246741771698
Epoch:  15  	Training Loss: 0.47062748670578003
Test Loss:  0.4871726334095001
Valid Loss:  0.4585009217262268
Epoch:  16  	Training Loss: 0.470603346824646
Test Loss:  0.4871481657028198
Valid Loss:  0.458477258682251
Epoch:  17  	Training Loss: 0.4705793857574463
Test Loss:  0.48712384700775146
Valid Loss:  0.4584537148475647
Epoch:  18  	Training Loss: 0.47055554389953613
Test Loss:  0.48709967732429504
Valid Loss:  0.45843034982681274
Epoch:  19  	Training Loss: 0.4705318212509155
Test Loss:  0.48707568645477295
Valid Loss:  0.45840710401535034
Epoch:  20  	Training Loss: 0.47050830721855164
Test Loss:  0.4870518445968628
Valid Loss:  0.45838406682014465
Epoch:  21  	Training Loss: 0.4704849421977997
Test Loss:  0.4870281517505646
Valid Loss:  0.4583611488342285
Epoch:  22  	Training Loss: 0.47046172618865967
Test Loss:  0.4870036840438843
Valid Loss:  0.4583374559879303
Epoch:  23  	Training Loss: 0.4704377055168152
Test Loss:  0.48697933554649353
Valid Loss:  0.4583139419555664
Epoch:  24  	Training Loss: 0.47041386365890503
Test Loss:  0.48695507645606995
Valid Loss:  0.4582904577255249
Epoch:  25  	Training Loss: 0.4703900218009949
Test Loss:  0.48693087697029114
Valid Loss:  0.4582670331001282
Epoch:  26  	Training Loss: 0.4703662693500519
Test Loss:  0.4869067668914795
Valid Loss:  0.458243727684021
Epoch:  27  	Training Loss: 0.47034263610839844
Test Loss:  0.486882746219635
Valid Loss:  0.4582204818725586
Epoch:  28  	Training Loss: 0.47031909227371216
Test Loss:  0.4868587851524353
Valid Loss:  0.45819735527038574
Epoch:  29  	Training Loss: 0.47029560804367065
Test Loss:  0.48683497309684753
Valid Loss:  0.45817428827285767
Epoch:  30  	Training Loss: 0.4702722430229187
Test Loss:  0.48681119084358215
Valid Loss:  0.45815131068229675
Epoch:  31  	Training Loss: 0.4702489674091339
Test Loss:  0.4867875576019287
Valid Loss:  0.4581283926963806
Epoch:  32  	Training Loss: 0.4702257215976715
Test Loss:  0.4867641031742096
Valid Loss:  0.4581057131290436
Epoch:  33  	Training Loss: 0.4702027440071106
Test Loss:  0.4867405891418457
Valid Loss:  0.45808303356170654
Epoch:  34  	Training Loss: 0.4701797068119049
Test Loss:  0.4867171049118042
Valid Loss:  0.45806026458740234
Epoch:  35  	Training Loss: 0.4701566696166992
Test Loss:  0.4866935610771179
Valid Loss:  0.45803749561309814
Epoch:  36  	Training Loss: 0.47013360261917114
Test Loss:  0.48667001724243164
Valid Loss:  0.45801472663879395
Epoch:  37  	Training Loss: 0.4701104760169983
Test Loss:  0.486646443605423
Valid Loss:  0.45799195766448975
Epoch:  38  	Training Loss: 0.4700873792171478
Test Loss:  0.4866228699684143
Valid Loss:  0.45796912908554077
Epoch:  39  	Training Loss: 0.470064252614975
Test Loss:  0.48659926652908325
Valid Loss:  0.4579463005065918
Epoch:  40  	Training Loss: 0.47004106640815735
Test Loss:  0.4865756034851074
Valid Loss:  0.45792341232299805
Epoch:  41  	Training Loss: 0.4700179100036621
Test Loss:  0.4865519404411316
Valid Loss:  0.4579005837440491
Epoch:  42  	Training Loss: 0.4699946939945221
Test Loss:  0.48652786016464233
Valid Loss:  0.4578772485256195
Epoch:  43  	Training Loss: 0.46997109055519104
Test Loss:  0.4865037798881531
Valid Loss:  0.4578539729118347
Epoch:  44  	Training Loss: 0.4699474573135376
Test Loss:  0.4864796996116638
Valid Loss:  0.45783066749572754
Epoch:  45  	Training Loss: 0.46992385387420654
Test Loss:  0.48645561933517456
Valid Loss:  0.45780742168426514
Epoch:  46  	Training Loss: 0.46990031003952026
Test Loss:  0.4864315688610077
Valid Loss:  0.45778417587280273
Epoch:  47  	Training Loss: 0.4698766767978668
Test Loss:  0.4864075183868408
Valid Loss:  0.45776087045669556
Epoch:  48  	Training Loss: 0.46985310316085815
Test Loss:  0.4863834083080292
Valid Loss:  0.4577375650405884
Epoch:  49  	Training Loss: 0.4698294997215271
Test Loss:  0.4863593578338623
Valid Loss:  0.457714319229126
Epoch:  50  	Training Loss: 0.46980583667755127
Test Loss:  0.48633524775505066
Valid Loss:  0.4576910138130188
Epoch:  51  	Training Loss: 0.4697822332382202
Test Loss:  0.4863112270832062
Valid Loss:  0.4576677680015564
Epoch:  52  	Training Loss: 0.46975868940353394
Test Loss:  0.4862874448299408
Valid Loss:  0.4576447606086731
Epoch:  53  	Training Loss: 0.46973538398742676
Test Loss:  0.486263632774353
Valid Loss:  0.4576217830181122
Epoch:  54  	Training Loss: 0.4697120785713196
Test Loss:  0.4862399101257324
Valid Loss:  0.45759880542755127
Epoch:  55  	Training Loss: 0.46968874335289
Test Loss:  0.48621612787246704
Valid Loss:  0.45757579803466797
Epoch:  56  	Training Loss: 0.4696654677391052
Test Loss:  0.48619237542152405
Valid Loss:  0.45755285024642944
Epoch:  57  	Training Loss: 0.46964216232299805
Test Loss:  0.48616862297058105
Valid Loss:  0.45752987265586853
Epoch:  58  	Training Loss: 0.46961888670921326
Test Loss:  0.48614487051963806
Valid Loss:  0.4575068950653076
Epoch:  59  	Training Loss: 0.46959561109542847
Test Loss:  0.48612111806869507
Valid Loss:  0.4574839472770691
Epoch:  60  	Training Loss: 0.4695723354816437
Test Loss:  0.48609739542007446
Valid Loss:  0.45746099948883057
Epoch:  61  	Training Loss: 0.4695490598678589
Test Loss:  0.48607367277145386
Valid Loss:  0.45743805170059204
Epoch:  62  	Training Loss: 0.4695257544517517
Test Loss:  0.486050546169281
Valid Loss:  0.4574156701564789
Epoch:  63  	Training Loss: 0.4695030748844147
Test Loss:  0.486027330160141
Valid Loss:  0.45739322900772095
Epoch:  64  	Training Loss: 0.46948033571243286
Test Loss:  0.48600414395332336
Valid Loss:  0.4573708176612854
Epoch:  65  	Training Loss: 0.46945762634277344
Test Loss:  0.4859810173511505
Valid Loss:  0.45734840631484985
Epoch:  66  	Training Loss: 0.469434916973114
Test Loss:  0.4859578013420105
Valid Loss:  0.4573259651660919
Epoch:  67  	Training Loss: 0.4694121479988098
Test Loss:  0.4859345257282257
Valid Loss:  0.4573034644126892
Epoch:  68  	Training Loss: 0.4693893492221832
Test Loss:  0.4859113097190857
Valid Loss:  0.45728105306625366
Epoch:  69  	Training Loss: 0.46936658024787903
Test Loss:  0.4858880043029785
Valid Loss:  0.45725855231285095
Epoch:  70  	Training Loss: 0.46934378147125244
Test Loss:  0.4858647286891937
Valid Loss:  0.45723605155944824
Epoch:  71  	Training Loss: 0.4693209230899811
Test Loss:  0.48584145307540894
Valid Loss:  0.45721346139907837
Epoch:  72  	Training Loss: 0.4692980945110321
Test Loss:  0.48581886291503906
Valid Loss:  0.4571916460990906
Epoch:  73  	Training Loss: 0.46927595138549805
Test Loss:  0.48579639196395874
Valid Loss:  0.45716989040374756
Epoch:  74  	Training Loss: 0.46925386786460876
Test Loss:  0.4857739210128784
Valid Loss:   15%|█▍        | 74/500 [00:55<05:56,  1.20it/s] 15%|█▌        | 76/500 [00:55<04:16,  1.66it/s] 16%|█▌        | 78/500 [00:55<03:06,  2.26it/s] 16%|█▌        | 80/500 [00:55<02:18,  3.04it/s] 16%|█▋        | 82/500 [01:01<08:08,  1.17s/it] 17%|█▋        | 84/500 [01:02<05:48,  1.19it/s] 17%|█▋        | 86/500 [01:02<04:10,  1.65it/s] 18%|█▊        | 88/500 [01:02<03:02,  2.26it/s] 18%|█▊        | 90/500 [01:02<02:15,  3.03it/s] 18%|█▊        | 92/500 [01:08<07:59,  1.17s/it] 19%|█▉        | 94/500 [01:08<05:41,  1.19it/s] 19%|█▉        | 96/500 [01:09<04:06,  1.64it/s] 20%|█▉        | 98/500 [01:09<02:59,  2.24it/s] 20%|██        | 100/500 [01:09<02:12,  3.02it/s] 20%|██        | 102/500 [01:15<07:53,  1.19s/it] 21%|██        | 104/500 [01:15<05:37,  1.17it/s] 21%|██        | 106/500 [01:15<04:02,  1.63it/s] 22%|██▏       | 108/500 [01:16<02:56,  2.22it/s] 22%|██▏       | 110/500 [01:16<02:10,  3.00it/s] 22%|██▏       | 112/500 [01:22<07:36,  1.18s/it] 23%|██▎       | 114/500 [01:22<05:25,  1.19it/s] 23%|██▎       | 116/500 [01:22<03:54,  1.64it/s] 24%|██▎       | 118/500 [01:22<02:50,  2.24it/s] 24%|██▍       | 120/500 [01:22<02:06,  3.02it/s] 24%|██▍       | 122/500 [01:29<07:21,  1.17s/it] 25%|██▍       | 124/500 [01:29<05:14,  1.20it/s] 25%|██▌       | 126/500 [01:29<03:46,  1.65it/s] 26%|██▌       | 128/500 [01:29<02:44,  2.26it/s] 26%|██▌       | 130/500 [01:29<02:02,  3.02it/s] 26%|██▋       | 132/500 [01:36<07:16,  1.19s/it] 27%|██▋       | 134/500 [01:36<05:10,  1.18it/s] 27%|██▋       | 136/500 [01:36<03:43,  1.63it/s] 28%|██▊       | 138/500 [01:36<02:42,  2.23it/s] 28%|██▊       | 140/500 [01:36<02:00,  2.99it/s] 28%|██▊       | 142/500 [01:42<07:03,  1.18s/it] 29%|██▉       | 144/500 [01:43<05:02,  1.18it/s] 29%|██▉       | 146/500 [01:43<03:39,  1.61it/s]0.4571481943130493
Epoch:  75  	Training Loss: 0.46923187375068665
Test Loss:  0.48575153946876526
Valid Loss:  0.45712655782699585
Epoch:  76  	Training Loss: 0.4692099094390869
Test Loss:  0.4857292175292969
Valid Loss:  0.45710498094558716
Epoch:  77  	Training Loss: 0.46918803453445435
Test Loss:  0.48570704460144043
Valid Loss:  0.45708349347114563
Epoch:  78  	Training Loss: 0.46916627883911133
Test Loss:  0.4856848120689392
Valid Loss:  0.4570620059967041
Epoch:  79  	Training Loss: 0.4691445231437683
Test Loss:  0.4856627583503723
Valid Loss:  0.4570406377315521
Epoch:  80  	Training Loss: 0.46912285685539246
Test Loss:  0.48564067482948303
Valid Loss:  0.4570193290710449
Epoch:  81  	Training Loss: 0.4691011905670166
Test Loss:  0.4856187403202057
Valid Loss:  0.4569981098175049
Epoch:  82  	Training Loss: 0.4690796732902527
Test Loss:  0.4855961501598358
Valid Loss:  0.4569762349128723
Epoch:  83  	Training Loss: 0.46905753016471863
Test Loss:  0.48557350039482117
Valid Loss:  0.45695433020591736
Epoch:  84  	Training Loss: 0.4690353572368622
Test Loss:  0.48555096983909607
Valid Loss:  0.45693254470825195
Epoch:  85  	Training Loss: 0.46901318430900574
Test Loss:  0.4855283498764038
Valid Loss:  0.4569106698036194
Epoch:  86  	Training Loss: 0.4689910411834717
Test Loss:  0.4855058193206787
Valid Loss:  0.4568887948989868
Epoch:  87  	Training Loss: 0.46896892786026
Test Loss:  0.48548322916030884
Valid Loss:  0.456866979598999
Epoch:  88  	Training Loss: 0.46894678473472595
Test Loss:  0.48546066880226135
Valid Loss:  0.45684516429901123
Epoch:  89  	Training Loss: 0.4689246714115143
Test Loss:  0.48543810844421387
Valid Loss:  0.45682334899902344
Epoch:  90  	Training Loss: 0.4689025282859802
Test Loss:  0.48541560769081116
Valid Loss:  0.45680156350135803
Epoch:  91  	Training Loss: 0.46888041496276855
Test Loss:  0.48539304733276367
Valid Loss:  0.4567797780036926
Epoch:  92  	Training Loss: 0.4688583016395569
Test Loss:  0.4853696823120117
Valid Loss:  0.45675715804100037
Epoch:  93  	Training Loss: 0.4688354432582855
Test Loss:  0.48534637689590454
Valid Loss:  0.4567345976829529
Epoch:  94  	Training Loss: 0.4688125252723694
Test Loss:  0.48532286286354065
Valid Loss:  0.45671185851097107
Epoch:  95  	Training Loss: 0.4687895178794861
Test Loss:  0.4852992296218872
Valid Loss:  0.4566890299320221
Epoch:  96  	Training Loss: 0.46876636147499084
Test Loss:  0.4852755665779114
Valid Loss:  0.45666617155075073
Epoch:  97  	Training Loss: 0.46874314546585083
Test Loss:  0.48525184392929077
Valid Loss:  0.45664316415786743
Epoch:  98  	Training Loss: 0.46871984004974365
Test Loss:  0.4852279722690582
Valid Loss:  0.45662009716033936
Epoch:  99  	Training Loss: 0.4686964750289917
Test Loss:  0.4852041006088257
Valid Loss:  0.4565970301628113
Epoch:  100  	Training Loss: 0.46867305040359497
Test Loss:  0.4851800799369812
Valid Loss:  0.4565737843513489
Epoch:  101  	Training Loss: 0.4686495065689087
Test Loss:  0.4851560890674591
Valid Loss:  0.4565505385398865
Epoch:  102  	Training Loss: 0.46862590312957764
Test Loss:  0.4851323664188385
Valid Loss:  0.45652762055397034
Epoch:  103  	Training Loss: 0.46860265731811523
Test Loss:  0.4851086735725403
Valid Loss:  0.4565047025680542
Epoch:  104  	Training Loss: 0.4685794413089752
Test Loss:  0.4850849509239197
Valid Loss:  0.45648178458213806
Epoch:  105  	Training Loss: 0.4685562252998352
Test Loss:  0.48506128787994385
Valid Loss:  0.4564588665962219
Epoch:  106  	Training Loss: 0.4685329496860504
Test Loss:  0.48503753542900085
Valid Loss:  0.4564359486103058
Epoch:  107  	Training Loss: 0.4685097336769104
Test Loss:  0.48501384258270264
Valid Loss:  0.4564129710197449
Epoch:  108  	Training Loss: 0.468486487865448
Test Loss:  0.48499011993408203
Valid Loss:  0.45639005303382874
Epoch:  109  	Training Loss: 0.4684631824493408
Test Loss:  0.4849664270877838
Valid Loss:  0.4563671350479126
Epoch:  110  	Training Loss: 0.4684399664402008
Test Loss:  0.4849426746368408
Valid Loss:  0.4563441872596741
Epoch:  111  	Training Loss: 0.468416690826416
Test Loss:  0.484919011592865
Valid Loss:  0.45632123947143555
Epoch:  112  	Training Loss: 0.4683934450149536
Test Loss:  0.4848955273628235
Valid Loss:  0.4562985897064209
Epoch:  113  	Training Loss: 0.4683704972267151
Test Loss:  0.4848721921443939
Valid Loss:  0.456275999546051
Epoch:  114  	Training Loss: 0.46834757924079895
Test Loss:  0.48484885692596436
Valid Loss:  0.45625340938568115
Epoch:  115  	Training Loss: 0.4683247208595276
Test Loss:  0.4848255217075348
Valid Loss:  0.4562308192253113
Epoch:  116  	Training Loss: 0.46830177307128906
Test Loss:  0.48480212688446045
Valid Loss:  0.4562082588672638
Epoch:  117  	Training Loss: 0.4682788848876953
Test Loss:  0.48477882146835327
Valid Loss:  0.4561856687068939
Epoch:  118  	Training Loss: 0.46825602650642395
Test Loss:  0.4847555160522461
Valid Loss:  0.45616310834884644
Epoch:  119  	Training Loss: 0.4682331383228302
Test Loss:  0.4847322106361389
Valid Loss:  0.45614057779312134
Epoch:  120  	Training Loss: 0.46821025013923645
Test Loss:  0.48470884561538696
Valid Loss:  0.45611804723739624
Epoch:  121  	Training Loss: 0.4681874215602875
Test Loss:  0.48468559980392456
Valid Loss:  0.4560955762863159
Epoch:  122  	Training Loss: 0.4681646227836609
Test Loss:  0.48466190695762634
Valid Loss:  0.4560726284980774
Epoch:  123  	Training Loss: 0.4681413769721985
Test Loss:  0.4846382141113281
Valid Loss:  0.45604974031448364
Epoch:  124  	Training Loss: 0.46811819076538086
Test Loss:  0.4846145510673523
Valid Loss:  0.45602697134017944
Epoch:  125  	Training Loss: 0.468095064163208
Test Loss:  0.484591007232666
Valid Loss:  0.45600414276123047
Epoch:  126  	Training Loss: 0.46807190775871277
Test Loss:  0.48456740379333496
Valid Loss:  0.45598137378692627
Epoch:  127  	Training Loss: 0.4680488407611847
Test Loss:  0.48454388976097107
Valid Loss:  0.45595866441726685
Epoch:  128  	Training Loss: 0.46802574396133423
Test Loss:  0.48452043533325195
Valid Loss:  0.4559359550476074
Epoch:  129  	Training Loss: 0.4680027663707733
Test Loss:  0.4844970107078552
Valid Loss:  0.4559133052825928
Epoch:  130  	Training Loss: 0.4679797887802124
Test Loss:  0.4844735264778137
Valid Loss:  0.4558906853199005
Epoch:  131  	Training Loss: 0.4679568409919739
Test Loss:  0.48445019125938416
Valid Loss:  0.45586806535720825
Epoch:  132  	Training Loss: 0.46793389320373535
Test Loss:  0.4844275116920471
Valid Loss:  0.4558461904525757
Epoch:  133  	Training Loss: 0.4679117202758789
Test Loss:  0.48440486192703247
Valid Loss:  0.45582425594329834
Epoch:  134  	Training Loss: 0.4678894877433777
Test Loss:  0.48438218235969543
Valid Loss:  0.455802321434021
Epoch:  135  	Training Loss: 0.46786725521087646
Test Loss:  0.4843595325946808
Valid Loss:  0.45578038692474365
Epoch:  136  	Training Loss: 0.46784505248069763
Test Loss:  0.4843369126319885
Valid Loss:  0.4557585120201111
Epoch:  137  	Training Loss: 0.467822790145874
Test Loss:  0.4843142032623291
Valid Loss:  0.45573654770851135
Epoch:  138  	Training Loss: 0.4678005576133728
Test Loss:  0.48429155349731445
Valid Loss:  0.4557145833969116
Epoch:  139  	Training Loss: 0.4677783250808716
Test Loss:  0.4842689037322998
Valid Loss:  0.4556926488876343
Epoch:  140  	Training Loss: 0.46775609254837036
Test Loss:  0.48424622416496277
Valid Loss:  0.4556707441806793
Epoch:  141  	Training Loss: 0.46773388981819153
Test Loss:  0.4842236042022705
Valid Loss:  0.45564883947372437
Epoch:  142  	Training Loss: 0.4677116572856903
Test Loss:  0.48419979214668274
Valid Loss:  0.45562583208084106
Epoch:  143  	Training Loss: 0.46768835186958313
Test Loss:  0.48417600989341736
Valid Loss:  0.45560282468795776
Epoch:  144  	Training Loss: 0.46766501665115356
Test Loss:  0.4841521382331848
Valid Loss:  0.45557981729507446
Epoch:  145  	Training Loss: 0.4676416516304016
Test Loss:  0.48412832617759705
Valid Loss:  0.455556720495224
Epoch:  146  	Training Loss: 0.46761828660964966
Test Loss:  0.4841044843196869
Valid Loss:  0.4555336534976959
Epoch:  147  	Training Loss: 0.4675948917865753
Test Loss:  0.48408061265945435
Valid Loss:  0.45551058650016785
 30%|██▉       | 148/500 [01:43<02:40,  2.19it/s] 30%|███       | 150/500 [01:43<01:58,  2.95it/s] 30%|███       | 152/500 [01:49<06:52,  1.19s/it] 31%|███       | 154/500 [01:50<04:53,  1.18it/s] 31%|███       | 156/500 [01:50<03:31,  1.63it/s] 32%|███▏      | 158/500 [01:50<02:33,  2.23it/s] 32%|███▏      | 160/500 [01:50<01:53,  2.99it/s] 32%|███▏      | 162/500 [01:56<06:41,  1.19s/it] 33%|███▎      | 164/500 [01:56<04:46,  1.17it/s] 33%|███▎      | 166/500 [01:57<03:26,  1.62it/s] 34%|███▎      | 168/500 [01:57<02:30,  2.21it/s] 34%|███▍      | 170/500 [01:57<01:51,  2.97it/s] 34%|███▍      | 172/500 [02:03<06:32,  1.20s/it] 35%|███▍      | 174/500 [02:03<04:39,  1.17it/s] 35%|███▌      | 176/500 [02:03<03:21,  1.61it/s] 36%|███▌      | 178/500 [02:04<02:27,  2.19it/s] 36%|███▌      | 180/500 [02:04<01:48,  2.95it/s] 36%|███▋      | 182/500 [02:10<06:13,  1.18s/it] 37%|███▋      | 184/500 [02:10<04:26,  1.19it/s] 37%|███▋      | 186/500 [02:10<03:11,  1.64it/s] 38%|███▊      | 188/500 [02:10<02:19,  2.24it/s] 38%|███▊      | 190/500 [02:11<01:42,  3.01it/s] 38%|███▊      | 192/500 [02:17<05:58,  1.16s/it] 39%|███▉      | 194/500 [02:17<04:14,  1.20it/s] 39%|███▉      | 196/500 [02:17<03:03,  1.66it/s] 40%|███▉      | 198/500 [02:17<02:13,  2.26it/s] 40%|████      | 200/500 [02:17<01:38,  3.04it/s] 40%|████      | 202/500 [02:24<05:47,  1.17s/it] 41%|████      | 204/500 [02:24<04:07,  1.20it/s] 41%|████      | 206/500 [02:24<02:57,  1.65it/s] 42%|████▏     | 208/500 [02:24<02:09,  2.26it/s] 42%|████▏     | 210/500 [02:24<01:35,  3.04it/s] 42%|████▏     | 212/500 [02:30<05:41,  1.19s/it] 43%|████▎     | 214/500 [02:31<04:02,  1.18it/s] 43%|████▎     | 216/500 [02:31<02:54,  1.63it/s] 44%|████▎     | 218/500 [02:31<02:06,  2.23it/s]Epoch:  148  	Training Loss: 0.467571496963501
Test Loss:  0.4840567409992218
Valid Loss:  0.45548751950263977
Epoch:  149  	Training Loss: 0.46754807233810425
Test Loss:  0.48403283953666687
Valid Loss:  0.4554644227027893
Epoch:  150  	Training Loss: 0.4675246477127075
Test Loss:  0.4840089678764343
Valid Loss:  0.45544129610061646
Epoch:  151  	Training Loss: 0.4675012230873108
Test Loss:  0.4839850664138794
Valid Loss:  0.455418199300766
Epoch:  152  	Training Loss: 0.46747782826423645
Test Loss:  0.4839603900909424
Valid Loss:  0.45539429783821106
Epoch:  153  	Training Loss: 0.46745359897613525
Test Loss:  0.483935683965683
Valid Loss:  0.45537039637565613
Epoch:  154  	Training Loss: 0.46742933988571167
Test Loss:  0.48391100764274597
Valid Loss:  0.4553464651107788
Epoch:  155  	Training Loss: 0.46740514039993286
Test Loss:  0.4838862419128418
Valid Loss:  0.4553225338459015
Epoch:  156  	Training Loss: 0.4673808217048645
Test Loss:  0.4838614761829376
Valid Loss:  0.4552985429763794
Epoch:  157  	Training Loss: 0.46735650300979614
Test Loss:  0.48383668065071106
Valid Loss:  0.4552745223045349
Epoch:  158  	Training Loss: 0.4673321843147278
Test Loss:  0.4838118255138397
Valid Loss:  0.45525050163269043
Epoch:  159  	Training Loss: 0.46730780601501465
Test Loss:  0.4837869703769684
Valid Loss:  0.45522642135620117
Epoch:  160  	Training Loss: 0.4672834277153015
Test Loss:  0.48376208543777466
Valid Loss:  0.4552023410797119
Epoch:  161  	Training Loss: 0.4672589898109436
Test Loss:  0.4837372303009033
Valid Loss:  0.45517823100090027
Epoch:  162  	Training Loss: 0.4672345519065857
Test Loss:  0.48371684551239014
Valid Loss:  0.4551585614681244
Epoch:  163  	Training Loss: 0.4672146439552307
Test Loss:  0.4836966395378113
Valid Loss:  0.4551389813423157
Epoch:  164  	Training Loss: 0.46719473600387573
Test Loss:  0.48367637395858765
Valid Loss:  0.45511937141418457
Epoch:  165  	Training Loss: 0.4671749174594879
Test Loss:  0.4836561679840088
Valid Loss:  0.45509985089302063
Epoch:  166  	Training Loss: 0.4671550989151001
Test Loss:  0.4836360216140747
Valid Loss:  0.45508038997650146
Epoch:  167  	Training Loss: 0.46713533997535706
Test Loss:  0.4836159348487854
Valid Loss:  0.4550609588623047
Epoch:  168  	Training Loss: 0.4671156406402588
Test Loss:  0.48359590768814087
Valid Loss:  0.4550415873527527
Epoch:  169  	Training Loss: 0.4670960009098053
Test Loss:  0.48357588052749634
Valid Loss:  0.4550222158432007
Epoch:  170  	Training Loss: 0.4670764207839966
Test Loss:  0.48355600237846375
Valid Loss:  0.45500290393829346
Epoch:  171  	Training Loss: 0.46705687046051025
Test Loss:  0.4835360050201416
Valid Loss:  0.454983651638031
Epoch:  172  	Training Loss: 0.46703729033470154
Test Loss:  0.4835125207901001
Valid Loss:  0.4549609124660492
Epoch:  173  	Training Loss: 0.4670141935348511
Test Loss:  0.4834890365600586
Valid Loss:  0.454938143491745
Epoch:  174  	Training Loss: 0.466991126537323
Test Loss:  0.4834654927253723
Valid Loss:  0.45491543412208557
Epoch:  175  	Training Loss: 0.4669681191444397
Test Loss:  0.48344194889068604
Valid Loss:  0.454892635345459
Epoch:  176  	Training Loss: 0.46694502234458923
Test Loss:  0.48341846466064453
Valid Loss:  0.4548698663711548
Epoch:  177  	Training Loss: 0.46692195534706116
Test Loss:  0.48339489102363586
Valid Loss:  0.454847127199173
Epoch:  178  	Training Loss: 0.4668988585472107
Test Loss:  0.483371376991272
Valid Loss:  0.45482438802719116
Epoch:  179  	Training Loss: 0.4668757915496826
Test Loss:  0.4833478331565857
Valid Loss:  0.45480161905288696
Epoch:  180  	Training Loss: 0.46685272455215454
Test Loss:  0.4833242893218994
Valid Loss:  0.45477885007858276
Epoch:  181  	Training Loss: 0.4668295979499817
Test Loss:  0.48330071568489075
Valid Loss:  0.45475608110427856
Epoch:  182  	Training Loss: 0.4668065011501312
Test Loss:  0.48328083753585815
Valid Loss:  0.4547367990016937
Epoch:  183  	Training Loss: 0.4667870104312897
Test Loss:  0.48326101899147034
Valid Loss:  0.45471757650375366
Epoch:  184  	Training Loss: 0.4667675197124481
Test Loss:  0.48324117064476013
Valid Loss:  0.45469844341278076
Epoch:  185  	Training Loss: 0.46674808859825134
Test Loss:  0.4832213819026947
Valid Loss:  0.45467931032180786
Epoch:  186  	Training Loss: 0.46672868728637695
Test Loss:  0.48320165276527405
Valid Loss:  0.45466017723083496
Epoch:  187  	Training Loss: 0.4667093753814697
Test Loss:  0.4831819534301758
Valid Loss:  0.4546411633491516
Epoch:  188  	Training Loss: 0.4666900634765625
Test Loss:  0.4831623136997223
Valid Loss:  0.45462214946746826
Epoch:  189  	Training Loss: 0.46667078137397766
Test Loss:  0.4831427037715912
Valid Loss:  0.45460325479507446
Epoch:  190  	Training Loss: 0.4666515588760376
Test Loss:  0.48312312364578247
Valid Loss:  0.4545842409133911
Epoch:  191  	Training Loss: 0.46663230657577515
Test Loss:  0.48310357332229614
Valid Loss:  0.4545653760433197
Epoch:  192  	Training Loss: 0.46661317348480225
Test Loss:  0.4830802083015442
Valid Loss:  0.45454272627830505
Epoch:  193  	Training Loss: 0.4665902256965637
Test Loss:  0.48305678367614746
Valid Loss:  0.4545201063156128
Epoch:  194  	Training Loss: 0.4665672779083252
Test Loss:  0.48303335905075073
Valid Loss:  0.4544975161552429
Epoch:  195  	Training Loss: 0.46654433012008667
Test Loss:  0.4830099940299988
Valid Loss:  0.45447486639022827
Epoch:  196  	Training Loss: 0.46652138233184814
Test Loss:  0.48298653960227966
Valid Loss:  0.4544522166252136
Epoch:  197  	Training Loss: 0.4664984345436096
Test Loss:  0.4829631745815277
Valid Loss:  0.45442962646484375
Epoch:  198  	Training Loss: 0.4664754867553711
Test Loss:  0.48293977975845337
Valid Loss:  0.4544069170951843
Epoch:  199  	Training Loss: 0.46645253896713257
Test Loss:  0.48291629552841187
Valid Loss:  0.4543842673301697
Epoch:  200  	Training Loss: 0.46642956137657166
Test Loss:  0.4828929007053375
Valid Loss:  0.45436158776283264
Epoch:  201  	Training Loss: 0.46640658378601074
Test Loss:  0.4828694462776184
Valid Loss:  0.4543389678001404
Epoch:  202  	Training Loss: 0.46638360619544983
Test Loss:  0.482846736907959
Valid Loss:  0.45431697368621826
Epoch:  203  	Training Loss: 0.4663613438606262
Test Loss:  0.4828239679336548
Valid Loss:  0.45429497957229614
Epoch:  204  	Training Loss: 0.46633899211883545
Test Loss:  0.48280125856399536
Valid Loss:  0.454272985458374
Epoch:  205  	Training Loss: 0.46631672978401184
Test Loss:  0.48277848958969116
Valid Loss:  0.4542510509490967
Epoch:  206  	Training Loss: 0.46629446744918823
Test Loss:  0.4827558100223541
Valid Loss:  0.4542289972305298
Epoch:  207  	Training Loss: 0.46627217531204224
Test Loss:  0.4827330708503723
Valid Loss:  0.45420703291893005
Epoch:  208  	Training Loss: 0.46624988317489624
Test Loss:  0.48271042108535767
Valid Loss:  0.4541851282119751
Epoch:  209  	Training Loss: 0.466227650642395
Test Loss:  0.48268768191337585
Valid Loss:  0.45416319370269775
Epoch:  210  	Training Loss: 0.4662053883075714
Test Loss:  0.4826650619506836
Valid Loss:  0.4541412591934204
Epoch:  211  	Training Loss: 0.4661831259727478
Test Loss:  0.48264235258102417
Valid Loss:  0.4541192948818207
Epoch:  212  	Training Loss: 0.4661608934402466
Test Loss:  0.4826182723045349
Valid Loss:  0.45409607887268066
Epoch:  213  	Training Loss: 0.4661373496055603
Test Loss:  0.4825942814350128
Valid Loss:  0.4540728032588959
Epoch:  214  	Training Loss: 0.46611377596855164
Test Loss:  0.48257020115852356
Valid Loss:  0.4540495276451111
Epoch:  215  	Training Loss: 0.46609020233154297
Test Loss:  0.48254621028900146
Valid Loss:  0.4540262818336487
Epoch:  216  	Training Loss: 0.4660665988922119
Test Loss:  0.482522189617157
Valid Loss:  0.45400309562683105
Epoch:  217  	Training Loss: 0.46604305505752563
Test Loss:  0.4824981689453125
Valid Loss:  0.45397984981536865
Epoch:  218  	Training Loss: 0.46601951122283936
Test Loss:  0.48247408866882324
Valid Loss:  0.45395657420158386
Epoch:  219  	Training Loss: 0.4659959375858307
Test Loss:  0.48245006799697876
Valid Loss:  0.45393335819244385
Epoch:  220  	Training Loss: 0.465972363948822
Test Loss:  0.4824260175228119
Valid Loss:  0.45391011238098145
 44%|████▍     | 220/500 [02:31<01:33,  3.00it/s] 44%|████▍     | 222/500 [02:37<05:25,  1.17s/it] 45%|████▍     | 224/500 [02:37<03:51,  1.19it/s] 45%|████▌     | 226/500 [02:37<02:46,  1.65it/s] 46%|████▌     | 228/500 [02:38<02:00,  2.25it/s] 46%|████▌     | 230/500 [02:38<01:28,  3.03it/s] 46%|████▋     | 232/500 [02:44<05:14,  1.17s/it] 47%|████▋     | 234/500 [02:44<03:43,  1.19it/s] 47%|████▋     | 236/500 [02:44<02:40,  1.65it/s] 48%|████▊     | 238/500 [02:44<01:56,  2.25it/s] 48%|████▊     | 240/500 [02:44<01:25,  3.03it/s] 48%|████▊     | 242/500 [02:51<05:08,  1.19s/it] 49%|████▉     | 244/500 [02:51<03:39,  1.17it/s] 49%|████▉     | 246/500 [02:51<02:37,  1.62it/s] 50%|████▉     | 248/500 [02:51<01:54,  2.21it/s] 50%|█████     | 250/500 [02:51<01:24,  2.97it/s] 50%|█████     | 252/500 [02:58<05:03,  1.22s/it] 51%|█████     | 254/500 [02:58<03:35,  1.14it/s] 51%|█████     | 256/500 [02:58<02:34,  1.58it/s] 52%|█████▏    | 258/500 [02:58<01:51,  2.16it/s] 52%|█████▏    | 260/500 [02:58<01:22,  2.92it/s] 52%|█████▏    | 262/500 [03:05<04:45,  1.20s/it] 53%|█████▎    | 264/500 [03:05<03:23,  1.16it/s] 53%|█████▎    | 266/500 [03:05<02:25,  1.61it/s] 54%|█████▎    | 268/500 [03:05<01:45,  2.20it/s] 54%|█████▍    | 270/500 [03:05<01:17,  2.96it/s] 54%|█████▍    | 272/500 [03:12<04:31,  1.19s/it] 55%|█████▍    | 274/500 [03:12<03:12,  1.17it/s] 55%|█████▌    | 276/500 [03:12<02:18,  1.62it/s] 56%|█████▌    | 278/500 [03:12<01:40,  2.22it/s] 56%|█████▌    | 280/500 [03:12<01:13,  2.99it/s] 56%|█████▋    | 282/500 [03:19<04:19,  1.19s/it] 57%|█████▋    | 284/500 [03:19<03:04,  1.17it/s] 57%|█████▋    | 286/500 [03:19<02:11,  1.62it/s] 58%|█████▊    | 288/500 [03:19<01:35,  2.22it/s] 58%|█████▊    | 290/500 [03:19<01:10,  2.99it/s] 58%|█████▊    | 292/500 [03:25<04:03,  1.17s/it]Epoch:  221  	Training Loss: 0.46594882011413574
Test Loss:  0.482401967048645
Valid Loss:  0.45388686656951904
Epoch:  222  	Training Loss: 0.4659252166748047
Test Loss:  0.4823787212371826
Valid Loss:  0.4538643956184387
Epoch:  223  	Training Loss: 0.4659024477005005
Test Loss:  0.482355535030365
Valid Loss:  0.4538419544696808
Epoch:  224  	Training Loss: 0.4658797085285187
Test Loss:  0.48233234882354736
Valid Loss:  0.4538194537162781
Epoch:  225  	Training Loss: 0.46585696935653687
Test Loss:  0.48230910301208496
Valid Loss:  0.45379704236984253
Epoch:  226  	Training Loss: 0.4658341705799103
Test Loss:  0.48228591680526733
Valid Loss:  0.4537745714187622
Epoch:  227  	Training Loss: 0.4658113718032837
Test Loss:  0.48226258158683777
Valid Loss:  0.4537521302700043
Epoch:  228  	Training Loss: 0.4657886028289795
Test Loss:  0.48223936557769775
Valid Loss:  0.45372962951660156
Epoch:  229  	Training Loss: 0.4657658338546753
Test Loss:  0.4822161793708801
Valid Loss:  0.453707218170166
Epoch:  230  	Training Loss: 0.4657430648803711
Test Loss:  0.4821929633617401
Valid Loss:  0.4536846876144409
Epoch:  231  	Training Loss: 0.4657202959060669
Test Loss:  0.48216965794563293
Valid Loss:  0.4536622166633606
Epoch:  232  	Training Loss: 0.4656974673271179
Test Loss:  0.4821479618549347
Valid Loss:  0.4536411762237549
Epoch:  233  	Training Loss: 0.4656761884689331
Test Loss:  0.48212629556655884
Valid Loss:  0.4536202549934387
Epoch:  234  	Training Loss: 0.4656549096107483
Test Loss:  0.4821045696735382
Valid Loss:  0.4535992443561554
Epoch:  235  	Training Loss: 0.4656336307525635
Test Loss:  0.48208290338516235
Valid Loss:  0.45357832312583923
Epoch:  236  	Training Loss: 0.46561238169670105
Test Loss:  0.4820612668991089
Valid Loss:  0.4535573422908783
Epoch:  237  	Training Loss: 0.4655911326408386
Test Loss:  0.4820394814014435
Valid Loss:  0.45353639125823975
Epoch:  238  	Training Loss: 0.4655698835849762
Test Loss:  0.4820178151130676
Valid Loss:  0.4535154104232788
Epoch:  239  	Training Loss: 0.46554863452911377
Test Loss:  0.48199617862701416
Valid Loss:  0.4534945487976074
Epoch:  240  	Training Loss: 0.46552741527557373
Test Loss:  0.48197460174560547
Valid Loss:  0.45347359776496887
Epoch:  241  	Training Loss: 0.4655062258243561
Test Loss:  0.4819529950618744
Valid Loss:  0.4534527063369751
Epoch:  242  	Training Loss: 0.46548500657081604
Test Loss:  0.48193082213401794
Valid Loss:  0.45343124866485596
Epoch:  243  	Training Loss: 0.4654632806777954
Test Loss:  0.4819086790084839
Valid Loss:  0.4534098207950592
Epoch:  244  	Training Loss: 0.4654415249824524
Test Loss:  0.48188650608062744
Valid Loss:  0.4533884525299072
Epoch:  245  	Training Loss: 0.46541985869407654
Test Loss:  0.481864333152771
Valid Loss:  0.45336705446243286
Epoch:  246  	Training Loss: 0.4653981328010559
Test Loss:  0.4818422496318817
Valid Loss:  0.4533456265926361
Epoch:  247  	Training Loss: 0.46537649631500244
Test Loss:  0.48182016611099243
Valid Loss:  0.45332422852516174
Epoch:  248  	Training Loss: 0.4653548002243042
Test Loss:  0.48179805278778076
Valid Loss:  0.45330291986465454
Epoch:  249  	Training Loss: 0.46533310413360596
Test Loss:  0.48177599906921387
Valid Loss:  0.45328158140182495
Epoch:  250  	Training Loss: 0.4653114676475525
Test Loss:  0.4817539155483246
Valid Loss:  0.4532601833343506
Epoch:  251  	Training Loss: 0.465289831161499
Test Loss:  0.4817318618297577
Valid Loss:  0.45323896408081055
Epoch:  252  	Training Loss: 0.46526822447776794
Test Loss:  0.4817102551460266
Valid Loss:  0.4532179534435272
Epoch:  253  	Training Loss: 0.4652470350265503
Test Loss:  0.48168861865997314
Valid Loss:  0.45319706201553345
Epoch:  254  	Training Loss: 0.4652257561683655
Test Loss:  0.4816669523715973
Valid Loss:  0.4531761407852173
Epoch:  255  	Training Loss: 0.4652045965194702
Test Loss:  0.4816453456878662
Valid Loss:  0.4531552791595459
Epoch:  256  	Training Loss: 0.46518343687057495
Test Loss:  0.4816238284111023
Valid Loss:  0.4531343877315521
Epoch:  257  	Training Loss: 0.4651622474193573
Test Loss:  0.4816022515296936
Valid Loss:  0.45311352610588074
Epoch:  258  	Training Loss: 0.46514105796813965
Test Loss:  0.48158058524131775
Valid Loss:  0.45309266448020935
Epoch:  259  	Training Loss: 0.4651198983192444
Test Loss:  0.4815590977668762
Valid Loss:  0.4530717134475708
Epoch:  260  	Training Loss: 0.4650987386703491
Test Loss:  0.48153746128082275
Valid Loss:  0.4530509114265442
Epoch:  261  	Training Loss: 0.46507757902145386
Test Loss:  0.48151594400405884
Valid Loss:  0.4530300796031952
Epoch:  262  	Training Loss: 0.465056449174881
Test Loss:  0.48149141669273376
Valid Loss:  0.45300641655921936
Epoch:  263  	Training Loss: 0.4650324881076813
Test Loss:  0.48146694898605347
Valid Loss:  0.45298272371292114
Epoch:  264  	Training Loss: 0.4650084674358368
Test Loss:  0.4814424216747284
Valid Loss:  0.4529590308666229
Epoch:  265  	Training Loss: 0.4649844169616699
Test Loss:  0.48141783475875854
Valid Loss:  0.45293527841567993
Epoch:  266  	Training Loss: 0.46496033668518066
Test Loss:  0.48139333724975586
Valid Loss:  0.4529115855693817
Epoch:  267  	Training Loss: 0.4649362564086914
Test Loss:  0.4813688099384308
Valid Loss:  0.45288777351379395
Epoch:  268  	Training Loss: 0.46491220593452454
Test Loss:  0.4813441038131714
Valid Loss:  0.4528639614582062
Epoch:  269  	Training Loss: 0.4648880362510681
Test Loss:  0.48131948709487915
Valid Loss:  0.45284008979797363
Epoch:  270  	Training Loss: 0.4648638963699341
Test Loss:  0.4812948703765869
Valid Loss:  0.452816367149353
Epoch:  271  	Training Loss: 0.4648396968841553
Test Loss:  0.4812701940536499
Valid Loss:  0.4527924954891205
Epoch:  272  	Training Loss: 0.46481555700302124
Test Loss:  0.48124998807907104
Valid Loss:  0.45277294516563416
Epoch:  273  	Training Loss: 0.46479570865631104
Test Loss:  0.4812297821044922
Valid Loss:  0.4527534246444702
Epoch:  274  	Training Loss: 0.4647759795188904
Test Loss:  0.48120957612991333
Valid Loss:  0.45273393392562866
Epoch:  275  	Training Loss: 0.46475616097450256
Test Loss:  0.48118942975997925
Valid Loss:  0.4527144730091095
Epoch:  276  	Training Loss: 0.4647364020347595
Test Loss:  0.48116928339004517
Valid Loss:  0.45269501209259033
Epoch:  277  	Training Loss: 0.46471667289733887
Test Loss:  0.48114922642707825
Valid Loss:  0.4526755213737488
Epoch:  278  	Training Loss: 0.464697003364563
Test Loss:  0.4811291992664337
Valid Loss:  0.45265620946884155
Epoch:  279  	Training Loss: 0.4646773040294647
Test Loss:  0.4811091423034668
Valid Loss:  0.4526367783546448
Epoch:  280  	Training Loss: 0.4646576941013336
Test Loss:  0.4810890555381775
Valid Loss:  0.45261746644973755
Epoch:  281  	Training Loss: 0.46463802456855774
Test Loss:  0.48106905817985535
Valid Loss:  0.45259809494018555
Epoch:  282  	Training Loss: 0.46461841464042664
Test Loss:  0.4810408353805542
Valid Loss:  0.45257076621055603
Epoch:  283  	Training Loss: 0.46459075808525085
Test Loss:  0.48101264238357544
Valid Loss:  0.4525434076786041
Epoch:  284  	Training Loss: 0.4645630717277527
Test Loss:  0.4809843897819519
Valid Loss:  0.4525160789489746
Epoch:  285  	Training Loss: 0.46453529596328735
Test Loss:  0.4809560477733612
Valid Loss:  0.45248866081237793
Epoch:  286  	Training Loss: 0.4645075798034668
Test Loss:  0.4809277653694153
Valid Loss:  0.452461302280426
Epoch:  287  	Training Loss: 0.4644797742366791
Test Loss:  0.4808993935585022
Valid Loss:  0.45243382453918457
Epoch:  288  	Training Loss: 0.46445193886756897
Test Loss:  0.48087090253829956
Valid Loss:  0.4524064064025879
Epoch:  289  	Training Loss: 0.4644240736961365
Test Loss:  0.4808424115180969
Valid Loss:  0.4523788094520569
Epoch:  290  	Training Loss: 0.4643961489200592
Test Loss:  0.48081403970718384
Valid Loss:  0.45235127210617065
Epoch:  291  	Training Loss: 0.46436822414398193
Test Loss:  0.4807855486869812
Valid Loss:  0.45232367515563965
Epoch:  292  	Training Loss: 0.4643402695655823
Test Loss:  0.48076164722442627
Valid Loss:  0.4523005783557892
Epoch:  293  	Training Loss: 0.46431684494018555
Test Loss:  0.48073768615722656
Valid Loss:  0.45227742195129395
 59%|█████▉    | 294/500 [03:26<02:53,  1.19it/s] 59%|█████▉    | 296/500 [03:26<02:03,  1.65it/s] 60%|█████▉    | 298/500 [03:26<01:29,  2.25it/s] 60%|██████    | 300/500 [03:26<01:05,  3.03it/s] 60%|██████    | 302/500 [03:32<03:50,  1.17s/it] 61%|██████    | 304/500 [03:32<02:43,  1.20it/s] 61%|██████    | 306/500 [03:32<01:57,  1.65it/s] 62%|██████▏   | 308/500 [03:33<01:24,  2.26it/s] 62%|██████▏   | 310/500 [03:33<01:02,  3.04it/s] 62%|██████▏   | 312/500 [03:39<03:43,  1.19s/it] 63%|██████▎   | 314/500 [03:39<02:38,  1.18it/s] 63%|██████▎   | 316/500 [03:39<01:52,  1.63it/s] 64%|██████▎   | 318/500 [03:39<01:21,  2.23it/s] 64%|██████▍   | 320/500 [03:40<00:59,  3.00it/s] 64%|██████▍   | 322/500 [03:46<03:30,  1.18s/it] 65%|██████▍   | 324/500 [03:46<02:28,  1.18it/s] 65%|██████▌   | 326/500 [03:46<01:46,  1.63it/s] 66%|██████▌   | 328/500 [03:46<01:16,  2.23it/s] 66%|██████▌   | 330/500 [03:46<00:56,  2.99it/s] 66%|██████▋   | 332/500 [03:53<03:18,  1.18s/it] 67%|██████▋   | 334/500 [03:53<02:20,  1.18it/s] 67%|██████▋   | 336/500 [03:53<01:40,  1.63it/s] 68%|██████▊   | 338/500 [03:53<01:12,  2.23it/s] 68%|██████▊   | 340/500 [03:53<00:53,  3.01it/s] 68%|██████▊   | 342/500 [04:00<03:07,  1.19s/it] 69%|██████▉   | 344/500 [04:00<02:12,  1.17it/s] 69%|██████▉   | 346/500 [04:00<01:34,  1.63it/s] 70%|██████▉   | 348/500 [04:00<01:08,  2.22it/s] 70%|███████   | 350/500 [04:00<00:50,  2.99it/s] 70%|███████   | 352/500 [04:06<02:54,  1.18s/it] 71%|███████   | 354/500 [04:07<02:03,  1.18it/s] 71%|███████   | 356/500 [04:07<01:27,  1.64it/s] 72%|███████▏  | 358/500 [04:07<01:03,  2.24it/s] 72%|███████▏  | 360/500 [04:07<00:46,  3.02it/s] 72%|███████▏  | 362/500 [04:13<02:41,  1.17s/it] 73%|███████▎  | 364/500 [04:13<01:54,  1.19it/s] 73%|███████▎  | 366/500 [04:13<01:21,  1.65it/s]Epoch:  294  	Training Loss: 0.46429339051246643
Test Loss:  0.48071372509002686
Valid Loss:  0.4522543251514435
Epoch:  295  	Training Loss: 0.4642699360847473
Test Loss:  0.4806898236274719
Valid Loss:  0.452231228351593
Epoch:  296  	Training Loss: 0.4642464816570282
Test Loss:  0.480665922164917
Valid Loss:  0.4522080421447754
Epoch:  297  	Training Loss: 0.4642230272293091
Test Loss:  0.4806419610977173
Valid Loss:  0.45218491554260254
Epoch:  298  	Training Loss: 0.46419957280158997
Test Loss:  0.48061802983283997
Valid Loss:  0.4521617889404297
Epoch:  299  	Training Loss: 0.46417611837387085
Test Loss:  0.48059409856796265
Valid Loss:  0.45213860273361206
Epoch:  300  	Training Loss: 0.46415266394615173
Test Loss:  0.48057013750076294
Valid Loss:  0.4521154761314392
Epoch:  301  	Training Loss: 0.46412914991378784
Test Loss:  0.48054617643356323
Valid Loss:  0.45209231972694397
Epoch:  302  	Training Loss: 0.4641056954860687
Test Loss:  0.4805241823196411
Valid Loss:  0.452070951461792
Epoch:  303  	Training Loss: 0.46408402919769287
Test Loss:  0.48050206899642944
Valid Loss:  0.4520496726036072
Epoch:  304  	Training Loss: 0.4640624523162842
Test Loss:  0.48048004508018494
Valid Loss:  0.45202839374542236
Epoch:  305  	Training Loss: 0.4640408754348755
Test Loss:  0.48045802116394043
Valid Loss:  0.45200708508491516
Epoch:  306  	Training Loss: 0.464019238948822
Test Loss:  0.48043596744537354
Valid Loss:  0.45198577642440796
Epoch:  307  	Training Loss: 0.46399763226509094
Test Loss:  0.4804140329360962
Valid Loss:  0.45196443796157837
Epoch:  308  	Training Loss: 0.46397608518600464
Test Loss:  0.4803919494152069
Valid Loss:  0.45194321870803833
Epoch:  309  	Training Loss: 0.46395444869995117
Test Loss:  0.4803699851036072
Valid Loss:  0.4519219398498535
Epoch:  310  	Training Loss: 0.46393290162086487
Test Loss:  0.48034799098968506
Valid Loss:  0.4519006609916687
Epoch:  311  	Training Loss: 0.46391135454177856
Test Loss:  0.4803260266780853
Valid Loss:  0.45187944173812866
Epoch:  312  	Training Loss: 0.4638897776603699
Test Loss:  0.48029932379722595
Valid Loss:  0.45185357332229614
Epoch:  313  	Training Loss: 0.4638636112213135
Test Loss:  0.4802725911140442
Valid Loss:  0.451827734708786
Epoch:  314  	Training Loss: 0.4638374149799347
Test Loss:  0.4802458584308624
Valid Loss:  0.4518018364906311
Epoch:  315  	Training Loss: 0.4638112187385559
Test Loss:  0.4802190661430359
Valid Loss:  0.45177599787712097
Epoch:  316  	Training Loss: 0.46378493309020996
Test Loss:  0.48019230365753174
Valid Loss:  0.45175012946128845
Epoch:  317  	Training Loss: 0.4637587070465088
Test Loss:  0.48016542196273804
Valid Loss:  0.45172417163848877
Epoch:  318  	Training Loss: 0.46373242139816284
Test Loss:  0.4801385998725891
Valid Loss:  0.4516981542110443
Epoch:  319  	Training Loss: 0.4637060761451721
Test Loss:  0.4801117181777954
Valid Loss:  0.4516722559928894
Epoch:  320  	Training Loss: 0.4636797308921814
Test Loss:  0.4800848364830017
Valid Loss:  0.45164620876312256
Epoch:  321  	Training Loss: 0.4636533856391907
Test Loss:  0.48005789518356323
Valid Loss:  0.4516202211380005
Epoch:  322  	Training Loss: 0.46362701058387756
Test Loss:  0.48003584146499634
Valid Loss:  0.4515989422798157
Epoch:  323  	Training Loss: 0.4636053740978241
Test Loss:  0.48001372814178467
Valid Loss:  0.4515776038169861
Epoch:  324  	Training Loss: 0.463583767414093
Test Loss:  0.47999173402786255
Valid Loss:  0.4515562653541565
Epoch:  325  	Training Loss: 0.46356213092803955
Test Loss:  0.4799696207046509
Valid Loss:  0.4515349268913269
Epoch:  326  	Training Loss: 0.4635404944419861
Test Loss:  0.479947566986084
Valid Loss:  0.4515136778354645
Epoch:  327  	Training Loss: 0.4635188579559326
Test Loss:  0.4799254834651947
Valid Loss:  0.4514922797679901
Epoch:  328  	Training Loss: 0.46349722146987915
Test Loss:  0.4799034595489502
Valid Loss:  0.4514709711074829
Epoch:  329  	Training Loss: 0.4634755849838257
Test Loss:  0.4798814356327057
Valid Loss:  0.4514496326446533
Epoch:  330  	Training Loss: 0.4634539783000946
Test Loss:  0.4798593521118164
Valid Loss:  0.45142829418182373
Epoch:  331  	Training Loss: 0.4634323716163635
Test Loss:  0.4798373579978943
Valid Loss:  0.45140695571899414
Epoch:  332  	Training Loss: 0.46341076493263245
Test Loss:  0.47981661558151245
Valid Loss:  0.4513869285583496
Epoch:  333  	Training Loss: 0.46339040994644165
Test Loss:  0.4797958731651306
Valid Loss:  0.45136696100234985
Epoch:  334  	Training Loss: 0.4633701741695404
Test Loss:  0.47977524995803833
Valid Loss:  0.4513469934463501
Epoch:  335  	Training Loss: 0.46334993839263916
Test Loss:  0.47975462675094604
Valid Loss:  0.45132699608802795
Epoch:  336  	Training Loss: 0.4633296728134155
Test Loss:  0.47973397374153137
Valid Loss:  0.4513070583343506
Epoch:  337  	Training Loss: 0.4633094072341919
Test Loss:  0.4797133207321167
Valid Loss:  0.4512872099876404
Epoch:  338  	Training Loss: 0.4632892608642578
Test Loss:  0.479692667722702
Valid Loss:  0.45126721262931824
Epoch:  339  	Training Loss: 0.46326902508735657
Test Loss:  0.4796721935272217
Valid Loss:  0.4512473940849304
Epoch:  340  	Training Loss: 0.4632488489151001
Test Loss:  0.4796516001224518
Valid Loss:  0.45122742652893066
Epoch:  341  	Training Loss: 0.46322867274284363
Test Loss:  0.4796310365200043
Valid Loss:  0.45120757818222046
Epoch:  342  	Training Loss: 0.46320855617523193
Test Loss:  0.47960948944091797
Valid Loss:  0.4511868357658386
Epoch:  343  	Training Loss: 0.46318742632865906
Test Loss:  0.47958797216415405
Valid Loss:  0.45116591453552246
Epoch:  344  	Training Loss: 0.4631662964820862
Test Loss:  0.4795665144920349
Valid Loss:  0.45114511251449585
Epoch:  345  	Training Loss: 0.46314525604248047
Test Loss:  0.4795450270175934
Valid Loss:  0.4511244297027588
Epoch:  346  	Training Loss: 0.46312418580055237
Test Loss:  0.47952350974082947
Valid Loss:  0.45110365748405457
Epoch:  347  	Training Loss: 0.46310317516326904
Test Loss:  0.4795021116733551
Valid Loss:  0.45108288526535034
Epoch:  348  	Training Loss: 0.46308213472366333
Test Loss:  0.4794806241989136
Valid Loss:  0.45106223225593567
Epoch:  349  	Training Loss: 0.4630610942840576
Test Loss:  0.47945916652679443
Valid Loss:  0.45104146003723145
Epoch:  350  	Training Loss: 0.4630400538444519
Test Loss:  0.47943779826164246
Valid Loss:  0.4510207176208496
Epoch:  351  	Training Loss: 0.46301913261413574
Test Loss:  0.4794163703918457
Valid Loss:  0.45100000500679016
Epoch:  352  	Training Loss: 0.4629981517791748
Test Loss:  0.4793940782546997
Valid Loss:  0.45097845792770386
Epoch:  353  	Training Loss: 0.46297624707221985
Test Loss:  0.47937172651290894
Valid Loss:  0.45095694065093994
Epoch:  354  	Training Loss: 0.4629543423652649
Test Loss:  0.4793494939804077
Valid Loss:  0.450935423374176
Epoch:  355  	Training Loss: 0.4629325270652771
Test Loss:  0.4793272018432617
Valid Loss:  0.45091378688812256
Epoch:  356  	Training Loss: 0.4629106819629669
Test Loss:  0.4793049097061157
Valid Loss:  0.45089226961135864
Epoch:  357  	Training Loss: 0.46288883686065674
Test Loss:  0.4792826175689697
Valid Loss:  0.45087072253227234
Epoch:  358  	Training Loss: 0.46286696195602417
Test Loss:  0.4792603850364685
Valid Loss:  0.4508492350578308
Epoch:  359  	Training Loss: 0.4628451466560364
Test Loss:  0.4792381525039673
Valid Loss:  0.4508276879787445
Epoch:  360  	Training Loss: 0.4628233313560486
Test Loss:  0.4792158901691437
Valid Loss:  0.450806200504303
Epoch:  361  	Training Loss: 0.462801456451416
Test Loss:  0.4791935682296753
Valid Loss:  0.4507846534252167
Epoch:  362  	Training Loss: 0.4627796411514282
Test Loss:  0.4791611433029175
Valid Loss:  0.45075318217277527
Epoch:  363  	Training Loss: 0.4627477824687958
Test Loss:  0.47912847995758057
Valid Loss:  0.4507216811180115
Epoch:  364  	Training Loss: 0.46271586418151855
Test Loss:  0.47909578680992126
Valid Loss:  0.4506900906562805
Epoch:  365  	Training Loss: 0.462683767080307
Test Loss:  0.4790630638599396
Valid Loss:  0.45065838098526
Epoch:  366  	Training Loss: 0.46265166997909546
Test Loss:  0.4790302515029907
Valid Loss:  0.4506266713142395
 74%|███████▎  | 368/500 [04:14<00:58,  2.26it/s] 74%|███████▍  | 370/500 [04:14<00:42,  3.04it/s] 74%|███████▍  | 372/500 [04:20<02:31,  1.19s/it] 75%|███████▍  | 374/500 [04:20<01:47,  1.18it/s] 75%|███████▌  | 376/500 [04:20<01:16,  1.63it/s] 76%|███████▌  | 378/500 [04:21<00:54,  2.22it/s] 76%|███████▌  | 380/500 [04:21<00:40,  2.99it/s] 76%|███████▋  | 382/500 [04:27<02:20,  1.19s/it] 77%|███████▋  | 384/500 [04:27<01:38,  1.17it/s] 77%|███████▋  | 386/500 [04:27<01:10,  1.62it/s] 78%|███████▊  | 388/500 [04:27<00:50,  2.22it/s] 78%|███████▊  | 390/500 [04:28<00:36,  2.99it/s] 78%|███████▊  | 392/500 [04:34<02:07,  1.18s/it] 79%|███████▉  | 394/500 [04:34<01:29,  1.18it/s] 79%|███████▉  | 396/500 [04:34<01:03,  1.63it/s] 80%|███████▉  | 398/500 [04:34<00:45,  2.23it/s] 80%|████████  | 400/500 [04:34<00:33,  3.00it/s] 80%|████████  | 402/500 [04:41<01:55,  1.18s/it] 81%|████████  | 404/500 [04:41<01:21,  1.18it/s] 81%|████████  | 406/500 [04:41<00:57,  1.64it/s] 82%|████████▏ | 408/500 [04:41<00:41,  2.24it/s] 82%|████████▏ | 410/500 [04:41<00:29,  3.01it/s] 82%|████████▏ | 412/500 [04:48<01:43,  1.18s/it] 83%|████████▎ | 414/500 [04:48<01:12,  1.18it/s] 83%|████████▎ | 416/500 [04:48<00:51,  1.64it/s] 84%|████████▎ | 418/500 [04:48<00:36,  2.24it/s] 84%|████████▍ | 420/500 [04:48<00:26,  3.02it/s] 84%|████████▍ | 422/500 [04:54<01:32,  1.18s/it] 85%|████████▍ | 424/500 [04:55<01:04,  1.18it/s] 85%|████████▌ | 426/500 [04:55<00:45,  1.63it/s] 86%|████████▌ | 428/500 [04:55<00:32,  2.23it/s] 86%|████████▌ | 430/500 [04:55<00:23,  2.99it/s] 86%|████████▋ | 432/500 [05:01<01:19,  1.17s/it] 87%|████████▋ | 434/500 [05:01<00:55,  1.19it/s] 87%|████████▋ | 436/500 [05:01<00:38,  1.65it/s] 88%|████████▊ | 438/500 [05:02<00:27,  2.25it/s]Epoch:  367  	Training Loss: 0.46261948347091675
Test Loss:  0.4789973199367523
Valid Loss:  0.4505949020385742
Epoch:  368  	Training Loss: 0.46258723735809326
Test Loss:  0.47896435856819153
Valid Loss:  0.4505630135536194
Epoch:  369  	Training Loss: 0.462554931640625
Test Loss:  0.4789313077926636
Valid Loss:  0.4505310654640198
Epoch:  370  	Training Loss: 0.46252256631851196
Test Loss:  0.47889822721481323
Valid Loss:  0.4504989981651306
Epoch:  371  	Training Loss: 0.4624900817871094
Test Loss:  0.4788649082183838
Valid Loss:  0.45046696066856384
Epoch:  372  	Training Loss: 0.4624575078487396
Test Loss:  0.47883784770965576
Valid Loss:  0.4504406452178955
Epoch:  373  	Training Loss: 0.46243083477020264
Test Loss:  0.4788106083869934
Valid Loss:  0.45041438937187195
Epoch:  374  	Training Loss: 0.46240419149398804
Test Loss:  0.47878339886665344
Valid Loss:  0.45038801431655884
Epoch:  375  	Training Loss: 0.46237754821777344
Test Loss:  0.4787561893463135
Valid Loss:  0.4503616690635681
Epoch:  376  	Training Loss: 0.46235084533691406
Test Loss:  0.4787289500236511
Valid Loss:  0.4503353536128998
Epoch:  377  	Training Loss: 0.4623240828514099
Test Loss:  0.4787015914916992
Valid Loss:  0.45030897855758667
Epoch:  378  	Training Loss: 0.46229737997055054
Test Loss:  0.4786744713783264
Valid Loss:  0.45028257369995117
Epoch:  379  	Training Loss: 0.4622706174850464
Test Loss:  0.4786471724510193
Valid Loss:  0.4502561688423157
Epoch:  380  	Training Loss: 0.462243914604187
Test Loss:  0.4786198139190674
Valid Loss:  0.4502297639846802
Epoch:  381  	Training Loss: 0.4622170925140381
Test Loss:  0.47859251499176025
Valid Loss:  0.4502032995223999
Epoch:  382  	Training Loss: 0.46219033002853394
Test Loss:  0.47856658697128296
Valid Loss:  0.45017820596694946
Epoch:  383  	Training Loss: 0.46216487884521484
Test Loss:  0.4785405993461609
Valid Loss:  0.450153112411499
Epoch:  384  	Training Loss: 0.46213939785957336
Test Loss:  0.47851455211639404
Valid Loss:  0.45012789964675903
Epoch:  385  	Training Loss: 0.4621138572692871
Test Loss:  0.478488564491272
Valid Loss:  0.45010268688201904
Epoch:  386  	Training Loss: 0.46208834648132324
Test Loss:  0.4784623980522156
Valid Loss:  0.45007753372192383
Epoch:  387  	Training Loss: 0.4620627760887146
Test Loss:  0.4784364104270935
Valid Loss:  0.45005229115486145
Epoch:  388  	Training Loss: 0.46203720569610596
Test Loss:  0.4784103035926819
Valid Loss:  0.4500271677970886
Epoch:  389  	Training Loss: 0.4620116353034973
Test Loss:  0.47838419675827026
Valid Loss:  0.4500018358230591
Epoch:  390  	Training Loss: 0.4619860053062439
Test Loss:  0.47835808992385864
Valid Loss:  0.44997653365135193
Epoch:  391  	Training Loss: 0.4619603753089905
Test Loss:  0.4783318042755127
Valid Loss:  0.44995129108428955
Epoch:  392  	Training Loss: 0.46193474531173706
Test Loss:  0.4783047139644623
Valid Loss:  0.4499250054359436
Epoch:  393  	Training Loss: 0.46190816164016724
Test Loss:  0.4782775342464447
Valid Loss:  0.44989877939224243
Epoch:  394  	Training Loss: 0.46188151836395264
Test Loss:  0.4782503843307495
Valid Loss:  0.4498724341392517
Epoch:  395  	Training Loss: 0.46185487508773804
Test Loss:  0.47822311520576477
Valid Loss:  0.4498462677001953
Epoch:  396  	Training Loss: 0.46182820200920105
Test Loss:  0.4781959652900696
Valid Loss:  0.4498199224472046
Epoch:  397  	Training Loss: 0.4618014991283417
Test Loss:  0.4781687259674072
Valid Loss:  0.4497934877872467
Epoch:  398  	Training Loss: 0.4617748260498047
Test Loss:  0.4781414866447449
Valid Loss:  0.44976726174354553
Epoch:  399  	Training Loss: 0.4617481231689453
Test Loss:  0.47811415791511536
Valid Loss:  0.4497408866882324
Epoch:  400  	Training Loss: 0.4617213308811188
Test Loss:  0.47808682918548584
Valid Loss:  0.44971442222595215
Epoch:  401  	Training Loss: 0.461694598197937
Test Loss:  0.47805947065353394
Valid Loss:  0.4496880769729614
Epoch:  402  	Training Loss: 0.4616677463054657
Test Loss:  0.47803834080696106
Valid Loss:  0.4496675133705139
Epoch:  403  	Training Loss: 0.4616469740867615
Test Loss:  0.4780171513557434
Valid Loss:  0.44964703917503357
Epoch:  404  	Training Loss: 0.46162623167037964
Test Loss:  0.47799593210220337
Valid Loss:  0.4496265649795532
Epoch:  405  	Training Loss: 0.461605429649353
Test Loss:  0.4779747724533081
Valid Loss:  0.4496060609817505
Epoch:  406  	Training Loss: 0.46158474683761597
Test Loss:  0.4779536724090576
Valid Loss:  0.44958561658859253
Epoch:  407  	Training Loss: 0.46156400442123413
Test Loss:  0.47793257236480713
Valid Loss:  0.44956526160240173
Epoch:  408  	Training Loss: 0.4615432918071747
Test Loss:  0.4779115617275238
Valid Loss:  0.4495447874069214
Epoch:  409  	Training Loss: 0.4615226089954376
Test Loss:  0.47789040207862854
Valid Loss:  0.4495244026184082
Epoch:  410  	Training Loss: 0.46150195598602295
Test Loss:  0.4778692126274109
Valid Loss:  0.4495040774345398
Epoch:  411  	Training Loss: 0.4614812731742859
Test Loss:  0.47784826159477234
Valid Loss:  0.449483722448349
Epoch:  412  	Training Loss: 0.4614606499671936
Test Loss:  0.47782549262046814
Valid Loss:  0.4494616985321045
Epoch:  413  	Training Loss: 0.4614383578300476
Test Loss:  0.47780272364616394
Valid Loss:  0.4494397044181824
Epoch:  414  	Training Loss: 0.46141600608825684
Test Loss:  0.4777800440788269
Valid Loss:  0.44941776990890503
Epoch:  415  	Training Loss: 0.46139371395111084
Test Loss:  0.47775721549987793
Valid Loss:  0.44939571619033813
Epoch:  416  	Training Loss: 0.46137142181396484
Test Loss:  0.4777345061302185
Valid Loss:  0.449373722076416
Epoch:  417  	Training Loss: 0.46134912967681885
Test Loss:  0.4777117371559143
Valid Loss:  0.4493517577648163
Epoch:  418  	Training Loss: 0.46132683753967285
Test Loss:  0.4776890277862549
Valid Loss:  0.44932979345321655
Epoch:  419  	Training Loss: 0.46130454540252686
Test Loss:  0.47766628861427307
Valid Loss:  0.4493078887462616
Epoch:  420  	Training Loss: 0.46128231287002563
Test Loss:  0.4776436686515808
Valid Loss:  0.4492858946323395
Epoch:  421  	Training Loss: 0.461260050535202
Test Loss:  0.4776209890842438
Valid Loss:  0.4492639899253845
Epoch:  422  	Training Loss: 0.4612378180027008
Test Loss:  0.4775938093662262
Valid Loss:  0.44923773407936096
Epoch:  423  	Training Loss: 0.46121126413345337
Test Loss:  0.4775666296482086
Valid Loss:  0.4492115080356598
Epoch:  424  	Training Loss: 0.4611845314502716
Test Loss:  0.47753921151161194
Valid Loss:  0.4491850733757019
Epoch:  425  	Training Loss: 0.46115782856941223
Test Loss:  0.4775119423866272
Valid Loss:  0.44915878772735596
Epoch:  426  	Training Loss: 0.4611310064792633
Test Loss:  0.4774845242500305
Valid Loss:  0.44913217425346375
Epoch:  427  	Training Loss: 0.461104154586792
Test Loss:  0.4774570167064667
Valid Loss:  0.4491056203842163
Epoch:  428  	Training Loss: 0.4610772132873535
Test Loss:  0.47742944955825806
Valid Loss:  0.4490790367126465
Epoch:  429  	Training Loss: 0.46105021238327026
Test Loss:  0.4774017333984375
Valid Loss:  0.4490523934364319
Epoch:  430  	Training Loss: 0.46102312207221985
Test Loss:  0.4773740768432617
Valid Loss:  0.44902560114860535
Epoch:  431  	Training Loss: 0.46099603176116943
Test Loss:  0.477346271276474
Valid Loss:  0.4489987790584564
Epoch:  432  	Training Loss: 0.4609687924385071
Test Loss:  0.47732484340667725
Valid Loss:  0.44897812604904175
Epoch:  433  	Training Loss: 0.46094781160354614
Test Loss:  0.4773035943508148
Valid Loss:  0.4489574134349823
Epoch:  434  	Training Loss: 0.46092677116394043
Test Loss:  0.4772821068763733
Valid Loss:  0.4489367604255676
Epoch:  435  	Training Loss: 0.46090584993362427
Test Loss:  0.4772607088088989
Valid Loss:  0.4489160478115082
Epoch:  436  	Training Loss: 0.46088480949401855
Test Loss:  0.4772394001483917
Valid Loss:  0.4488953948020935
Epoch:  437  	Training Loss: 0.4608638882637024
Test Loss:  0.4772179126739502
Valid Loss:  0.44887471199035645
Epoch:  438  	Training Loss: 0.46084293723106384
Test Loss:  0.4771966338157654
Valid Loss:  0.4488540291786194
Epoch:  439  	Training Loss: 0.4608219861984253
Test Loss:  0.4771753251552582
Valid Loss:  0.4488334059715271
 88%|████████▊ | 440/500 [05:02<00:19,  3.03it/s] 88%|████████▊ | 442/500 [05:08<01:08,  1.17s/it] 89%|████████▉ | 444/500 [05:08<00:47,  1.19it/s] 89%|████████▉ | 446/500 [05:08<00:32,  1.64it/s] 90%|████████▉ | 448/500 [05:08<00:23,  2.25it/s] 90%|█████████ | 450/500 [05:08<00:16,  3.02it/s] 90%|█████████ | 452/500 [05:15<00:57,  1.20s/it] 91%|█████████ | 454/500 [05:15<00:39,  1.16it/s] 91%|█████████ | 456/500 [05:15<00:27,  1.61it/s] 92%|█████████▏| 458/500 [05:15<00:19,  2.21it/s] 92%|█████████▏| 460/500 [05:15<00:13,  2.96it/s] 92%|█████████▏| 462/500 [05:22<00:44,  1.18s/it] 93%|█████████▎| 464/500 [05:22<00:30,  1.19it/s] 93%|█████████▎| 466/500 [05:22<00:20,  1.64it/s] 94%|█████████▎| 468/500 [05:22<00:14,  2.24it/s] 94%|█████████▍| 470/500 [05:22<00:09,  3.02it/s] 94%|█████████▍| 472/500 [05:28<00:32,  1.17s/it] 95%|█████████▍| 474/500 [05:29<00:21,  1.19it/s] 95%|█████████▌| 476/500 [05:29<00:14,  1.65it/s] 96%|█████████▌| 478/500 [05:29<00:09,  2.25it/s] 96%|█████████▌| 480/500 [05:29<00:06,  3.02it/s] 96%|█████████▋| 482/500 [05:35<00:21,  1.18s/it] 97%|█████████▋| 484/500 [05:35<00:13,  1.18it/s] 97%|█████████▋| 486/500 [05:36<00:08,  1.64it/s] 98%|█████████▊| 488/500 [05:36<00:05,  2.24it/s] 98%|█████████▊| 490/500 [05:36<00:03,  3.01it/s] 98%|█████████▊| 492/500 [05:42<00:09,  1.19s/it] 99%|█████████▉| 494/500 [05:42<00:05,  1.17it/s] 99%|█████████▉| 496/500 [05:43<00:02,  1.61it/s]100%|█████████▉| 498/500 [05:43<00:00,  2.20it/s]100%|██████████| 500/500 [05:43<00:00,  2.96it/s]100%|██████████| 500/500 [05:43<00:00,  1.46it/s]
Epoch:  440  	Training Loss: 0.46080106496810913
Test Loss:  0.4771539568901062
Valid Loss:  0.4488128423690796
Epoch:  441  	Training Loss: 0.46078014373779297
Test Loss:  0.4771326184272766
Valid Loss:  0.44879212975502014
Epoch:  442  	Training Loss: 0.4607592225074768
Test Loss:  0.47708940505981445
Valid Loss:  0.448750376701355
Epoch:  443  	Training Loss: 0.4607168138027191
Test Loss:  0.4770459532737732
Valid Loss:  0.4487084150314331
Epoch:  444  	Training Loss: 0.46067434549331665
Test Loss:  0.47700250148773193
Valid Loss:  0.4486663341522217
Epoch:  445  	Training Loss: 0.46063166856765747
Test Loss:  0.4769587516784668
Valid Loss:  0.4486241340637207
Epoch:  446  	Training Loss: 0.46058887243270874
Test Loss:  0.4769148826599121
Valid Loss:  0.4485816955566406
Epoch:  447  	Training Loss: 0.4605458378791809
Test Loss:  0.4768710136413574
Valid Loss:  0.44853925704956055
Epoch:  448  	Training Loss: 0.4605028033256531
Test Loss:  0.47682684659957886
Valid Loss:  0.4484964609146118
Epoch:  449  	Training Loss: 0.460459440946579
Test Loss:  0.47678250074386597
Valid Loss:  0.4484536647796631
Epoch:  450  	Training Loss: 0.4604160189628601
Test Loss:  0.4767380952835083
Valid Loss:  0.44841066002845764
Epoch:  451  	Training Loss: 0.4603723883628845
Test Loss:  0.47669339179992676
Valid Loss:  0.44836756587028503
Epoch:  452  	Training Loss: 0.4603286683559418
Test Loss:  0.47667598724365234
Valid Loss:  0.4483506977558136
Epoch:  453  	Training Loss: 0.46031150221824646
Test Loss:  0.476658433675766
Valid Loss:  0.448333740234375
Epoch:  454  	Training Loss: 0.4602944552898407
Test Loss:  0.47664105892181396
Valid Loss:  0.4483169913291931
Epoch:  455  	Training Loss: 0.46027737855911255
Test Loss:  0.47662368416786194
Valid Loss:  0.44830018281936646
Epoch:  456  	Training Loss: 0.4602603316307068
Test Loss:  0.47660642862319946
Valid Loss:  0.4482833445072174
Epoch:  457  	Training Loss: 0.4602433145046234
Test Loss:  0.47658902406692505
Valid Loss:  0.44826656579971313
Epoch:  458  	Training Loss: 0.4602263271808624
Test Loss:  0.47657158970832825
Valid Loss:  0.44824984669685364
Epoch:  459  	Training Loss: 0.46020928025245667
Test Loss:  0.4765543043613434
Valid Loss:  0.44823312759399414
Epoch:  460  	Training Loss: 0.46019232273101807
Test Loss:  0.4765370488166809
Valid Loss:  0.44821634888648987
Epoch:  461  	Training Loss: 0.4601753056049347
Test Loss:  0.47651976346969604
Valid Loss:  0.44819968938827515
Epoch:  462  	Training Loss: 0.46015840768814087
Test Loss:  0.4765005111694336
Valid Loss:  0.44818100333213806
Epoch:  463  	Training Loss: 0.46013957262039185
Test Loss:  0.4764813780784607
Valid Loss:  0.44816261529922485
Epoch:  464  	Training Loss: 0.4601207971572876
Test Loss:  0.47646233439445496
Valid Loss:  0.4481440782546997
Epoch:  465  	Training Loss: 0.4601020812988281
Test Loss:  0.47644323110580444
Valid Loss:  0.4481256902217865
Epoch:  466  	Training Loss: 0.46008336544036865
Test Loss:  0.4764241576194763
Valid Loss:  0.4481073319911957
Epoch:  467  	Training Loss: 0.46006473898887634
Test Loss:  0.47640523314476013
Valid Loss:  0.4480888843536377
Epoch:  468  	Training Loss: 0.46004611253738403
Test Loss:  0.47638627886772156
Valid Loss:  0.4480705261230469
Epoch:  469  	Training Loss: 0.4600274860858917
Test Loss:  0.47636720538139343
Valid Loss:  0.44805219769477844
Epoch:  470  	Training Loss: 0.46000897884368896
Test Loss:  0.47634825110435486
Valid Loss:  0.44803386926651
Epoch:  471  	Training Loss: 0.45999032258987427
Test Loss:  0.47632938623428345
Valid Loss:  0.44801563024520874
Epoch:  472  	Training Loss: 0.4599717855453491
Test Loss:  0.47630274295806885
Valid Loss:  0.44798994064331055
Epoch:  473  	Training Loss: 0.4599457383155823
Test Loss:  0.47627609968185425
Valid Loss:  0.4479641318321228
Epoch:  474  	Training Loss: 0.4599195718765259
Test Loss:  0.47624945640563965
Valid Loss:  0.44793835282325745
Epoch:  475  	Training Loss: 0.45989346504211426
Test Loss:  0.4762227535247803
Valid Loss:  0.4479125142097473
Epoch:  476  	Training Loss: 0.45986732840538025
Test Loss:  0.4761960506439209
Valid Loss:  0.4478868246078491
Epoch:  477  	Training Loss: 0.45984116196632385
Test Loss:  0.4761693775653839
Valid Loss:  0.4478609561920166
Epoch:  478  	Training Loss: 0.45981499552726746
Test Loss:  0.4761427044868469
Valid Loss:  0.44783520698547363
Epoch:  479  	Training Loss: 0.45978882908821106
Test Loss:  0.47611600160598755
Valid Loss:  0.4478093385696411
Epoch:  480  	Training Loss: 0.4597626328468323
Test Loss:  0.476089209318161
Valid Loss:  0.44778358936309814
Epoch:  481  	Training Loss: 0.4597364366054535
Test Loss:  0.47606250643730164
Valid Loss:  0.44775766134262085
Epoch:  482  	Training Loss: 0.4597102403640747
Test Loss:  0.4760408401489258
Valid Loss:  0.44773679971694946
Epoch:  483  	Training Loss: 0.45968908071517944
Test Loss:  0.4760192334651947
Valid Loss:  0.4477159380912781
Epoch:  484  	Training Loss: 0.4596678614616394
Test Loss:  0.4759977459907532
Valid Loss:  0.4476950466632843
Epoch:  485  	Training Loss: 0.4596467614173889
Test Loss:  0.4759761095046997
Valid Loss:  0.4476742148399353
Epoch:  486  	Training Loss: 0.45962557196617126
Test Loss:  0.47595468163490295
Valid Loss:  0.4476533532142639
Epoch:  487  	Training Loss: 0.45960450172424316
Test Loss:  0.4759330153465271
Valid Loss:  0.4476325511932373
Epoch:  488  	Training Loss: 0.4595833420753479
Test Loss:  0.47591155767440796
Valid Loss:  0.4476117491722107
Epoch:  489  	Training Loss: 0.4595622718334198
Test Loss:  0.47589004039764404
Valid Loss:  0.44759106636047363
Epoch:  490  	Training Loss: 0.4595412611961365
Test Loss:  0.4758685529232025
Valid Loss:  0.447570264339447
Epoch:  491  	Training Loss: 0.45952022075653076
Test Loss:  0.4758472144603729
Valid Loss:  0.44754958152770996
Epoch:  492  	Training Loss: 0.45949915051460266
Test Loss:  0.4758158326148987
Valid Loss:  0.4475191831588745
Epoch:  493  	Training Loss: 0.4594684839248657
Test Loss:  0.47578442096710205
Valid Loss:  0.4474889039993286
Epoch:  494  	Training Loss: 0.45943763852119446
Test Loss:  0.47575297951698303
Valid Loss:  0.44745856523513794
Epoch:  495  	Training Loss: 0.45940685272216797
Test Loss:  0.4757215678691864
Valid Loss:  0.44742801785469055
Epoch:  496  	Training Loss: 0.4593760073184967
Test Loss:  0.47569000720977783
Valid Loss:  0.4473976492881775
Epoch:  497  	Training Loss: 0.45934513211250305
Test Loss:  0.47565847635269165
Valid Loss:  0.4473671615123749
Epoch:  498  	Training Loss: 0.4593141973018646
Test Loss:  0.47562697529792786
Valid Loss:  0.44733649492263794
Epoch:  499  	Training Loss: 0.4592832326889038
Test Loss:  0.47559526562690735
Valid Loss:  0.44730597734451294
Epoch:  500  	Training Loss: 0.4592522084712982
Test Loss:  0.47556358575820923
Valid Loss:  0.44727522134780884
seed is  18
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:16,  6.28s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:58,  1.35s/it]  3%|▎         | 13/500 [00:13<07:28,  1.08it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.17it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:32,  1.20s/it]  5%|▍         | 23/500 [00:20<06:46,  1.17it/s]  5%|▌         | 25/500 [00:26<12:12,  1.54s/it]  5%|▌         | 27/500 [00:26<08:39,  1.10s/it]  6%|▌         | 29/500 [00:26<06:10,  1.27it/s]  6%|▌         | 31/500 [00:32<11:42,  1.50s/it]  7%|▋         | 33/500 [00:33<08:19,  1.07s/it]  7%|▋         | 35/500 [00:33<05:56,  1.30it/s]  7%|▋         | 37/500 [00:33<04:18,  1.79it/s]  8%|▊         | 39/500 [00:33<03:12,  2.40it/s]  8%|▊         | 41/500 [00:39<09:25,  1.23s/it]  9%|▊         | 43/500 [00:39<06:44,  1.13it/s]  9%|▉         | 45/500 [00:40<04:51,  1.56it/s]  9%|▉         | 47/500 [00:40<03:32,  2.13it/s] 10%|▉         | 49/500 [00:40<02:37,  2.87it/s] 10%|█         | 51/500 [00:46<08:53,  1.19s/it] 11%|█         | 53/500 [00:46<06:20,  1.17it/s] 11%|█         | 55/500 [00:46<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:47<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:47<02:28,  2.98it/s] 12%|█▏        | 61/500 [00:53<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:53<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:53<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:53<03:14,  2.23it/s]Epoch:  1  	Training Loss: 0.5142406225204468
Test Loss:  8.500199317932129
Valid Loss:  8.653831481933594
Epoch:  2  	Training Loss: 8.604068756103516
Test Loss:  4.039618015289307
Valid Loss:  4.2745513916015625
Epoch:  3  	Training Loss: 4.210380554199219
Test Loss:  0.2895447611808777
Valid Loss:  0.28517746925354004
Epoch:  4  	Training Loss: 0.2852345108985901
Test Loss:  0.022364817559719086
Valid Loss:  0.024974703788757324
Epoch:  5  	Training Loss: 0.02416975051164627
Test Loss:  0.0074727898463606834
Valid Loss:  0.004792613442987204
Epoch:  6  	Training Loss: 0.005209270864725113
Test Loss:  0.005028505343943834
Valid Loss:  0.0035617738030850887
Epoch:  7  	Training Loss: 0.0037324680015444756
Test Loss:  0.004918886348605156
Valid Loss:  0.003248356282711029
Epoch:  8  	Training Loss: 0.003473267424851656
Test Loss:  0.004623622167855501
Valid Loss:  0.003116810694336891
Epoch:  9  	Training Loss: 0.003316137008368969
Test Loss:  0.004429230000823736
Valid Loss:  0.0029864227399230003
Epoch:  10  	Training Loss: 0.0031794263049960136
Test Loss:  0.004235398955643177
Valid Loss:  0.0028718288522213697
Epoch:  11  	Training Loss: 0.003056122222915292
Test Loss:  0.004062109626829624
Valid Loss:  0.0027662853244692087
Epoch:  12  	Training Loss: 0.0029447972774505615
Test Loss:  0.0034832421224564314
Valid Loss:  0.002564256312325597
Epoch:  13  	Training Loss: 0.0027072327211499214
Test Loss:  0.0034757002722471952
Valid Loss:  0.002378098201006651
Epoch:  14  	Training Loss: 0.0025622444227337837
Test Loss:  0.0029943352565169334
Valid Loss:  0.0023124353028833866
Epoch:  15  	Training Loss: 0.0024503138847649097
Test Loss:  0.0031933223363012075
Valid Loss:  0.002158417832106352
Epoch:  16  	Training Loss: 0.002350765047594905
Test Loss:  0.002695864997804165
Valid Loss:  0.0021476447582244873
Epoch:  17  	Training Loss: 0.0022830376401543617
Test Loss:  0.0031341235153377056
Valid Loss:  0.002058390760794282
Epoch:  18  	Training Loss: 0.0022461172193288803
Test Loss:  0.002502238377928734
Valid Loss:  0.0021143185440450907
Epoch:  19  	Training Loss: 0.0022374317049980164
Test Loss:  0.0032584723085165024
Valid Loss:  0.0021208939142525196
Epoch:  20  	Training Loss: 0.002297778148204088
Test Loss:  0.0025222650729119778
Valid Loss:  0.0023030745796859264
Epoch:  21  	Training Loss: 0.002425209619104862
Test Loss:  0.0038035218603909016
Valid Loss:  0.0025253980420529842
Epoch:  22  	Training Loss: 0.0026986119337379932
Test Loss:  0.003470662049949169
Valid Loss:  0.0035478004720062017
Epoch:  23  	Training Loss: 0.0036492638755589724
Test Loss:  0.007184506393969059
Valid Loss:  0.005548395682126284
Epoch:  24  	Training Loss: 0.005713094957172871
Test Loss:  0.008424458093941212
Valid Loss:  0.009384410455822945
Epoch:  25  	Training Loss: 0.009402301162481308
Test Loss:  0.017597615718841553
Valid Loss:  0.015529519878327847
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.015633251518011093
Test Loss:  0.0081058070063591
Valid Loss:  0.006547835189849138
Epoch:  27  	Training Loss: 0.006692952010780573
Test Loss:  0.005528666079044342
Valid Loss:  0.00411659711971879
Epoch:  28  	Training Loss: 0.004329853691160679
Test Loss:  0.004074851982295513
Valid Loss:  0.0027626343071460724
Epoch:  29  	Training Loss: 0.002988395281136036
Test Loss:  0.0032841749489307404
Valid Loss:  0.0020744958892464638
Epoch:  30  	Training Loss: 0.0022871852852404118
Test Loss:  0.002830507466569543
Valid Loss:  0.0017170626670122147
Epoch:  31  	Training Loss: 0.0019173992332071066
Test Loss:  0.002558627864345908
Valid Loss:  0.0015225778333842754
Epoch:  32  	Training Loss: 0.0017101356061175466
Test Loss:  0.0021411976777017117
Valid Loss:  0.0013252025237306952
Epoch:  33  	Training Loss: 0.0014943403657525778
Test Loss:  0.0020264373160898685
Valid Loss:  0.0012835762463510036
Epoch:  34  	Training Loss: 0.0014481078833341599
Test Loss:  0.0019612719770520926
Valid Loss:  0.0012518292060121894
Epoch:  35  	Training Loss: 0.0014146602479740977
Test Loss:  0.0019070485141128302
Valid Loss:  0.0012197366449981928
Epoch:  36  	Training Loss: 0.0013811324024572968
Test Loss:  0.0018541102763265371
Valid Loss:  0.0011865722481161356
Epoch:  37  	Training Loss: 0.001346728764474392
Test Loss:  0.0018026437610387802
Valid Loss:  0.0011531441705301404
Epoch:  38  	Training Loss: 0.001311636995524168
Test Loss:  0.0017528972821310163
Valid Loss:  0.001120050554163754
Epoch:  39  	Training Loss: 0.0012769439490512013
Test Loss:  0.0017064288258552551
Valid Loss:  0.0010897383326664567
Epoch:  40  	Training Loss: 0.0012448978377506137
Test Loss:  0.0016644932329654694
Valid Loss:  0.0010619607055559754
Epoch:  41  	Training Loss: 0.0012151675764471292
Test Loss:  0.0016277576796710491
Valid Loss:  0.0010379455052316189
Epoch:  42  	Training Loss: 0.0011881738901138306
Test Loss:  0.0016125381225720048
Valid Loss:  0.0010288776829838753
Epoch:  43  	Training Loss: 0.00117882015183568
Test Loss:  0.0015966040082275867
Valid Loss:  0.001020423835143447
Epoch:  44  	Training Loss: 0.0011699353344738483
Test Loss:  0.0015815552324056625
Valid Loss:  0.0010122021194547415
Epoch:  45  	Training Loss: 0.0011614036047831178
Test Loss:  0.0015673399902880192
Valid Loss:  0.0010041635250672698
Epoch:  46  	Training Loss: 0.0011531347408890724
Test Loss:  0.001553811365738511
Valid Loss:  0.0009964576456695795
Epoch:  47  	Training Loss: 0.0011450359597802162
Test Loss:  0.0015408348990604281
Valid Loss:  0.000988651649095118
Epoch:  48  	Training Loss: 0.0011367842089384794
Test Loss:  0.0015285032568499446
Valid Loss:  0.000980424229055643
Epoch:  49  	Training Loss: 0.0011286719236522913
Test Loss:  0.0015166052617132664
Valid Loss:  0.0009720060625113547
Epoch:  50  	Training Loss: 0.0011205098126083612
Test Loss:  0.0015050722286105156
Valid Loss:  0.0009638335322961211
Epoch:  51  	Training Loss: 0.001112567842938006
Test Loss:  0.0014937869273126125
Valid Loss:  0.0009558765450492501
Epoch:  52  	Training Loss: 0.0011048001470044255
Test Loss:  0.0014493715716525912
Valid Loss:  0.0009126003133133054
Epoch:  53  	Training Loss: 0.001055639935657382
Test Loss:  0.0013992476742714643
Valid Loss:  0.0008707572123967111
Epoch:  54  	Training Loss: 0.001007772283628583
Test Loss:  0.0013540111249312758
Valid Loss:  0.0008352724835276604
Epoch:  55  	Training Loss: 0.0009665921097621322
Test Loss:  0.0013204608112573624
Valid Loss:  0.0008065744768828154
Epoch:  56  	Training Loss: 0.000933521892875433
Test Loss:  0.0012875761603936553
Valid Loss:  0.0007799932500347495
Epoch:  57  	Training Loss: 0.0009028580388985574
Test Loss:  0.0012534300331026316
Valid Loss:  0.0007553235627710819
Epoch:  58  	Training Loss: 0.0008743506041355431
Test Loss:  0.0012222439981997013
Valid Loss:  0.0007319775759242475
Epoch:  59  	Training Loss: 0.0008473751950077713
Test Loss:  0.0011901569087058306
Valid Loss:  0.0007101813098415732
Epoch:  60  	Training Loss: 0.0008219301234930754
Test Loss:  0.0011603131424635649
Valid Loss:  0.0006895174738019705
Epoch:  61  	Training Loss: 0.0007978837238624692
Test Loss:  0.0011300246696919203
Valid Loss:  0.00066997209796682
Epoch:  62  	Training Loss: 0.0007750602089799941
Test Loss:  0.001108267460949719
Valid Loss:  0.000645554275251925
Epoch:  63  	Training Loss: 0.0007494199671782553
Test Loss:  0.0010797535069286823
Valid Loss:  0.0006264385301619768
Epoch:  64  	Training Loss: 0.000728112761862576
Test Loss:  0.0010506347753107548
Valid Loss:  0.0006090020760893822
Epoch:  65  	Training Loss: 0.000708423147443682
Test Loss:  0.0010225630830973387
Valid Loss:  0.0005927274469286203
Epoch:  66  	Training Loss: 0.0006900143343955278
Test Loss:  0.0009959775488823652
Valid Loss:  0.0005776191828772426
Epoch:  67  	Training Loss: 0.0006727495929226279
Test Loss:  0.000970970606431365
Valid Loss:  0.000563517096452415
Epoch:  68  	Training Loss: 0.000656497897580266
Test Loss:  0.0009475137339904904
Valid Loss:  0.0005502323620021343
Epoch:  69  	Training Loss: 0.0006411690847016871
Test Loss:  0.0009252966847270727
 14%|█▍        | 69/500 [00:54<02:24,  2.99it/s] 14%|█▍        | 71/500 [01:00<08:31,  1.19s/it] 15%|█▍        | 73/500 [01:00<06:05,  1.17it/s] 15%|█▌        | 75/500 [01:00<04:22,  1.62it/s] 15%|█▌        | 77/500 [01:00<03:12,  2.20it/s] 16%|█▌        | 79/500 [01:01<02:22,  2.95it/s] 16%|█▌        | 81/500 [01:07<08:12,  1.17s/it] 17%|█▋        | 83/500 [01:07<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:07<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:07<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:07<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:14<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:14<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:14<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:14<02:13,  3.01it/s] 20%|██        | 101/500 [01:20<07:51,  1.18s/it] 21%|██        | 103/500 [01:21<05:37,  1.18it/s] 21%|██        | 105/500 [01:21<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:21<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.96it/s] 22%|██▏       | 111/500 [01:27<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:27<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:28<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:28<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:28<02:06,  3.00it/s] 24%|██▍       | 121/500 [01:34<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:34<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:34<03:52,  1.62it/s] 25%|██▌       | 127/500 [01:35<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:35<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:41<07:19,  1.19s/it] 27%|██▋       | 133/500 [01:41<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:41<03:45,  1.62it/s]Valid Loss:  0.0005380791262723505
Epoch:  70  	Training Loss: 0.0006267441203817725
Test Loss:  0.0009043350000865757
Valid Loss:  0.000526594347320497
Epoch:  71  	Training Loss: 0.000613102805800736
Test Loss:  0.0008846406126394868
Valid Loss:  0.0005157935665920377
Epoch:  72  	Training Loss: 0.0006003660964779556
Test Loss:  0.0008367233676835895
Valid Loss:  0.0005035612848587334
Epoch:  73  	Training Loss: 0.0005823391256853938
Test Loss:  0.0008302413625642657
Valid Loss:  0.0004919036873616278
Epoch:  74  	Training Loss: 0.000569579191505909
Test Loss:  0.0008159090066328645
Valid Loss:  0.0004834597639273852
Epoch:  75  	Training Loss: 0.0005593944806605577
Test Loss:  0.000804418814368546
Valid Loss:  0.0004749715735670179
Epoch:  76  	Training Loss: 0.0005500094266608357
Test Loss:  0.0007906390819698572
Valid Loss:  0.0004671654896810651
Epoch:  77  	Training Loss: 0.0005409138975664973
Test Loss:  0.0007783339242450893
Valid Loss:  0.00045944779412820935
Epoch:  78  	Training Loss: 0.00053211092017591
Test Loss:  0.0007661086856387556
Valid Loss:  0.00045199698070064187
Epoch:  79  	Training Loss: 0.0005235528806224465
Test Loss:  0.0007542555104009807
Valid Loss:  0.0004448211984708905
Epoch:  80  	Training Loss: 0.00051524443551898
Test Loss:  0.0007428685203194618
Valid Loss:  0.0004379273159429431
Epoch:  81  	Training Loss: 0.0005071913474239409
Test Loss:  0.0007318058051168919
Valid Loss:  0.00043124015792272985
Epoch:  82  	Training Loss: 0.0004993755137547851
Test Loss:  0.0007276920368894935
Valid Loss:  0.000425839563831687
Epoch:  83  	Training Loss: 0.0004937855992466211
Test Loss:  0.0007182966219261289
Valid Loss:  0.0004218825197312981
Epoch:  84  	Training Loss: 0.0004889779957011342
Test Loss:  0.000711152097210288
Valid Loss:  0.00041836011223495007
Epoch:  85  	Training Loss: 0.00048456306103616953
Test Loss:  0.000704384408891201
Valid Loss:  0.00041518546640872955
Epoch:  86  	Training Loss: 0.0004804538330063224
Test Loss:  0.0006981038022786379
Valid Loss:  0.00041225823224522173
Epoch:  87  	Training Loss: 0.0004766070342157036
Test Loss:  0.0006921847816556692
Valid Loss:  0.00040963577339425683
Epoch:  88  	Training Loss: 0.00047308646026067436
Test Loss:  0.0006870158831588924
Valid Loss:  0.0004071821749676019
Epoch:  89  	Training Loss: 0.0004697964177466929
Test Loss:  0.0006821042625233531
Valid Loss:  0.00040494248969480395
Epoch:  90  	Training Loss: 0.00046674528857693076
Test Loss:  0.0006776191294193268
Valid Loss:  0.00040286799776367843
Epoch:  91  	Training Loss: 0.000463843229226768
Test Loss:  0.000673578237183392
Valid Loss:  0.00040092587005347013
Epoch:  92  	Training Loss: 0.0004611185286194086
Test Loss:  0.0006687752902507782
Valid Loss:  0.0004007510142400861
Epoch:  93  	Training Loss: 0.000460505805676803
Test Loss:  0.0006694279727526009
Valid Loss:  0.0004000533081125468
Epoch:  94  	Training Loss: 0.00045995478285476565
Test Loss:  0.0006678667850792408
Valid Loss:  0.00039963179733604193
Epoch:  95  	Training Loss: 0.00045942532597109675
Test Loss:  0.0006672936142422259
Valid Loss:  0.0003991221310570836
Epoch:  96  	Training Loss: 0.0004589082673192024
Test Loss:  0.0006663353415206075
Valid Loss:  0.0003986720694229007
Epoch:  97  	Training Loss: 0.0004584031121339649
Test Loss:  0.0006655735778622329
Valid Loss:  0.00039821595419198275
Epoch:  98  	Training Loss: 0.0004579056112561375
Test Loss:  0.0006647561676800251
Valid Loss:  0.00039778355858288705
Epoch:  99  	Training Loss: 0.0004574199265334755
Test Loss:  0.0006639193161390722
Valid Loss:  0.0003973596612922847
Epoch:  100  	Training Loss: 0.00045694338041357696
Test Loss:  0.0006631005089730024
Valid Loss:  0.0003969560202676803
Epoch:  101  	Training Loss: 0.00045649425010196865
Test Loss:  0.0006622935179620981
Valid Loss:  0.00039656259468756616
Epoch:  102  	Training Loss: 0.0004560368834063411
Test Loss:  0.0006565218791365623
Valid Loss:  0.0003916457644663751
Epoch:  103  	Training Loss: 0.0004492881125770509
Test Loss:  0.0006506442441605031
Valid Loss:  0.00038750030216760933
Epoch:  104  	Training Loss: 0.0004434098373167217
Test Loss:  0.0006449595093727112
Valid Loss:  0.0003839403798338026
Epoch:  105  	Training Loss: 0.00043824585736729205
Test Loss:  0.0006391517817974091
Valid Loss:  0.00038069000584073365
Epoch:  106  	Training Loss: 0.0004336924757808447
Test Loss:  0.0006340317195281386
Valid Loss:  0.00037754839286208153
Epoch:  107  	Training Loss: 0.00042944453889504075
Test Loss:  0.000628640700597316
Valid Loss:  0.00037454828270711005
Epoch:  108  	Training Loss: 0.00042544567259028554
Test Loss:  0.0006235194741748273
Valid Loss:  0.0003716078936122358
Epoch:  109  	Training Loss: 0.00042159942677244544
Test Loss:  0.0006183668738231063
Valid Loss:  0.00036873813951388
Epoch:  110  	Training Loss: 0.00041786039946600795
Test Loss:  0.0006132766138762236
Valid Loss:  0.0003659291542135179
Epoch:  111  	Training Loss: 0.00041422751382924616
Test Loss:  0.0006082812324166298
Valid Loss:  0.0003632028237916529
Epoch:  112  	Training Loss: 0.00041069986764341593
Test Loss:  0.0006050636293366551
Valid Loss:  0.0003572160785552114
Epoch:  113  	Training Loss: 0.00040400843136012554
Test Loss:  0.000594333978369832
Valid Loss:  0.0003526108921505511
Epoch:  114  	Training Loss: 0.00039789764559827745
Test Loss:  0.0005882641416974366
Valid Loss:  0.0003476995334494859
Epoch:  115  	Training Loss: 0.0003920737071894109
Test Loss:  0.0005796194891445339
Valid Loss:  0.0003433322999626398
Epoch:  116  	Training Loss: 0.0003865051257889718
Test Loss:  0.0005728327669203281
Valid Loss:  0.0003389008343219757
Epoch:  117  	Training Loss: 0.00038117205258458853
Test Loss:  0.0005652165273204446
Valid Loss:  0.0003346900921314955
Epoch:  118  	Training Loss: 0.0003759828978218138
Test Loss:  0.0005583653692156076
Valid Loss:  0.0003304944548290223
Epoch:  119  	Training Loss: 0.0003709195589181036
Test Loss:  0.0005513862706720829
Valid Loss:  0.00032649829518049955
Epoch:  120  	Training Loss: 0.00036598421866074204
Test Loss:  0.0005445134011097252
Valid Loss:  0.0003226044645998627
Epoch:  121  	Training Loss: 0.0003611631109379232
Test Loss:  0.000537851476110518
Valid Loss:  0.0003187650872860104
Epoch:  122  	Training Loss: 0.00035647727781906724
Test Loss:  0.0005274149589240551
Valid Loss:  0.00031680893152952194
Epoch:  123  	Training Loss: 0.0003534588613547385
Test Loss:  0.0005247402004897594
Valid Loss:  0.0003141578927170485
Epoch:  124  	Training Loss: 0.00035068055149167776
Test Loss:  0.0005196382408030331
Valid Loss:  0.0003120102337561548
Epoch:  125  	Training Loss: 0.00034801027504727244
Test Loss:  0.0005158141138963401
Valid Loss:  0.00030975230038166046
Epoch:  126  	Training Loss: 0.0003454167162999511
Test Loss:  0.0005117979017086327
Valid Loss:  0.0003076056018471718
Epoch:  127  	Training Loss: 0.0003428812779020518
Test Loss:  0.0005080284900031984
Valid Loss:  0.000305502355331555
Epoch:  128  	Training Loss: 0.00034034944837912917
Test Loss:  0.0005043837008997798
Valid Loss:  0.0003034478868357837
Epoch:  129  	Training Loss: 0.00033787498250603676
Test Loss:  0.0005009466549381614
Valid Loss:  0.0003013964742422104
Epoch:  130  	Training Loss: 0.00033541384618729353
Test Loss:  0.0004974507028236985
Valid Loss:  0.00029941959655843675
Epoch:  131  	Training Loss: 0.0003329816972836852
Test Loss:  0.0004940973594784737
Valid Loss:  0.0002975204843096435
Epoch:  132  	Training Loss: 0.0003305975697003305
Test Loss:  0.0004884118679910898
Valid Loss:  0.0002955379895865917
Epoch:  133  	Training Loss: 0.00032759906025603414
Test Loss:  0.00048672256525605917
Valid Loss:  0.0002933440846391022
Epoch:  134  	Training Loss: 0.00032490567537024617
Test Loss:  0.0004841763584408909
Valid Loss:  0.00029129552422091365
Epoch:  135  	Training Loss: 0.000322318053804338
Test Loss:  0.00048175393021665514
Valid Loss:  0.0002892900665756315
Epoch:  136  	Training Loss: 0.0003197685582563281
Test Loss:  0.0004792303079739213
Valid Loss:  0.0002873626071959734
Epoch:  137  	Training Loss: 0.00031732808565720916
Test Loss:  0.0004768060171045363
Valid Loss:   27%|██▋       | 137/500 [01:42<02:43,  2.21it/s] 28%|██▊       | 139/500 [01:42<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:48<07:01,  1.18s/it] 29%|██▊       | 143/500 [01:48<05:01,  1.19it/s] 29%|██▉       | 145/500 [01:48<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:48<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:48<01:56,  3.02it/s] 30%|███       | 151/500 [01:55<06:47,  1.17s/it] 31%|███       | 153/500 [01:55<04:50,  1.19it/s] 31%|███       | 155/500 [01:55<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:55<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:55<01:53,  3.02it/s] 32%|███▏      | 161/500 [02:02<06:40,  1.18s/it] 33%|███▎      | 163/500 [02:02<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:02<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:02<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:02<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:08<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:09<04:35,  1.18it/s] 35%|███▌      | 175/500 [02:09<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:09<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:09<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:15<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:15<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:16<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:16<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:16<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:22<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:22<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:22<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:23<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:23<01:41,  2.96it/s] 40%|████      | 201/500 [02:29<05:58,  1.20s/it] 41%|████      | 203/500 [02:29<04:15,  1.16it/s]0.00028546625981107354
Epoch:  138  	Training Loss: 0.00031500105978921056
Test Loss:  0.0004744140023831278
Valid Loss:  0.000283652450889349
Epoch:  139  	Training Loss: 0.0003127309028059244
Test Loss:  0.00047201532288454473
Valid Loss:  0.0002818919310811907
Epoch:  140  	Training Loss: 0.00031049037352204323
Test Loss:  0.00046961705083958805
Valid Loss:  0.0002801630471367389
Epoch:  141  	Training Loss: 0.00030828366288915277
Test Loss:  0.0004671854549087584
Valid Loss:  0.00027849600883200765
Epoch:  142  	Training Loss: 0.0003061781753785908
Test Loss:  0.00046960776671767235
Valid Loss:  0.0002741813659667969
Epoch:  143  	Training Loss: 0.0003019610303454101
Test Loss:  0.00046117501915432513
Valid Loss:  0.00027090960065834224
Epoch:  144  	Training Loss: 0.00029804330551996827
Test Loss:  0.0004580153035931289
Valid Loss:  0.00026753562269732356
Epoch:  145  	Training Loss: 0.00029431359143927693
Test Loss:  0.0004529696307145059
Valid Loss:  0.0002645472122821957
Epoch:  146  	Training Loss: 0.00029081583488732576
Test Loss:  0.0004489450075197965
Valid Loss:  0.0002618310390971601
Epoch:  147  	Training Loss: 0.0002876325452234596
Test Loss:  0.00044498310307972133
Valid Loss:  0.00025922973873093724
Epoch:  148  	Training Loss: 0.0002846422721631825
Test Loss:  0.0004411711706779897
Valid Loss:  0.00025678370730020106
Epoch:  149  	Training Loss: 0.0002818637585733086
Test Loss:  0.000437500246334821
Valid Loss:  0.0002544882008805871
Epoch:  150  	Training Loss: 0.0002792525920085609
Test Loss:  0.0004342176835052669
Valid Loss:  0.0002523117873352021
Epoch:  151  	Training Loss: 0.0002767453552223742
Test Loss:  0.00043066611397080123
Valid Loss:  0.0002503367722965777
Epoch:  152  	Training Loss: 0.0002744212106335908
Test Loss:  0.0004203630378469825
Valid Loss:  0.0002474249922670424
Epoch:  153  	Training Loss: 0.0002708967658691108
Test Loss:  0.000418237061239779
Valid Loss:  0.00024426073650829494
Epoch:  154  	Training Loss: 0.00026752037229016423
Test Loss:  0.00041176064405590296
Valid Loss:  0.00024138785374816507
Epoch:  155  	Training Loss: 0.00026423318195156753
Test Loss:  0.0004077506309840828
Valid Loss:  0.00023847035481594503
Epoch:  156  	Training Loss: 0.00026101787807419896
Test Loss:  0.0004024926165584475
Valid Loss:  0.00023570770281367004
Epoch:  157  	Training Loss: 0.00025786610785871744
Test Loss:  0.0003980265464633703
Valid Loss:  0.0002329705748707056
Epoch:  158  	Training Loss: 0.00025479859323240817
Test Loss:  0.0003932315157726407
Valid Loss:  0.0002303000946994871
Epoch:  159  	Training Loss: 0.0002517863758839667
Test Loss:  0.0003887208004016429
Valid Loss:  0.00022766545589547604
Epoch:  160  	Training Loss: 0.0002488292520865798
Test Loss:  0.00038416084134951234
Valid Loss:  0.00022508465917780995
Epoch:  161  	Training Loss: 0.0002459342940710485
Test Loss:  0.00037976232124492526
Valid Loss:  0.00022257973614614457
Epoch:  162  	Training Loss: 0.000243153830524534
Test Loss:  0.0003776882658712566
Valid Loss:  0.00022082011855673045
Epoch:  163  	Training Loss: 0.00024107287754304707
Test Loss:  0.0003739540698006749
Valid Loss:  0.00021933583775535226
Epoch:  164  	Training Loss: 0.00023924442939460278
Test Loss:  0.00037086772499606013
Valid Loss:  0.000218004803173244
Epoch:  165  	Training Loss: 0.00023760383191984147
Test Loss:  0.0003679654037114233
Valid Loss:  0.0002168602222809568
Epoch:  166  	Training Loss: 0.00023606904142070562
Test Loss:  0.0003651082515716553
Valid Loss:  0.0002158053102903068
Epoch:  167  	Training Loss: 0.00023465952835977077
Test Loss:  0.0003625344834290445
Valid Loss:  0.0002148339553968981
Epoch:  168  	Training Loss: 0.00023335358127951622
Test Loss:  0.00036005076253786683
Valid Loss:  0.00021392659982666373
Epoch:  169  	Training Loss: 0.00023210963991004974
Test Loss:  0.00035776570439338684
Valid Loss:  0.0002130803040927276
Epoch:  170  	Training Loss: 0.00023093426716513932
Test Loss:  0.0003556268638931215
Valid Loss:  0.00021228456171229482
Epoch:  171  	Training Loss: 0.00022982583323027939
Test Loss:  0.00035350723192095757
Valid Loss:  0.00021153653506189585
Epoch:  172  	Training Loss: 0.00022877661103848368
Test Loss:  0.0003508285153657198
Valid Loss:  0.00020958716049790382
Epoch:  173  	Training Loss: 0.00022644428827334195
Test Loss:  0.0003487172652967274
Valid Loss:  0.00020812926231883466
Epoch:  174  	Training Loss: 0.00022465563961304724
Test Loss:  0.00034722694545052946
Valid Loss:  0.00020690556266345084
Epoch:  175  	Training Loss: 0.00022314052330330014
Test Loss:  0.0003457677084952593
Valid Loss:  0.00020584379672072828
Epoch:  176  	Training Loss: 0.00022182900283951312
Test Loss:  0.00034454750129953027
Valid Loss:  0.00020485832646954805
Epoch:  177  	Training Loss: 0.00022060015180613846
Test Loss:  0.000343367166351527
Valid Loss:  0.00020393120939843357
Epoch:  178  	Training Loss: 0.0002194021944887936
Test Loss:  0.00034227565629407763
Valid Loss:  0.00020305189536884427
Epoch:  179  	Training Loss: 0.00021823700808454305
Test Loss:  0.00034118694020435214
Valid Loss:  0.0002021559193963185
Epoch:  180  	Training Loss: 0.00021710977307520807
Test Loss:  0.00034008253715001047
Valid Loss:  0.00020127955940552056
Epoch:  181  	Training Loss: 0.00021602146443910897
Test Loss:  0.0003389449557289481
Valid Loss:  0.00020043183758389205
Epoch:  182  	Training Loss: 0.00021499475406017154
Test Loss:  0.00033534126123413444
Valid Loss:  0.00019924320804420859
Epoch:  183  	Training Loss: 0.00021353084594011307
Test Loss:  0.0003333373460918665
Valid Loss:  0.00019816610438283533
Epoch:  184  	Training Loss: 0.0002122989681083709
Test Loss:  0.0003319110837765038
Valid Loss:  0.00019717341638170183
Epoch:  185  	Training Loss: 0.00021117515279911458
Test Loss:  0.0003306100843474269
Valid Loss:  0.00019623305706772953
Epoch:  186  	Training Loss: 0.00021009918418712914
Test Loss:  0.00032940926030278206
Valid Loss:  0.00019533323938958347
Epoch:  187  	Training Loss: 0.00020907707221340388
Test Loss:  0.00032833218574523926
Valid Loss:  0.00019446700753178447
Epoch:  188  	Training Loss: 0.0002081204584101215
Test Loss:  0.0003273235051892698
Valid Loss:  0.00019362890452612191
Epoch:  189  	Training Loss: 0.00020720550674013793
Test Loss:  0.0003263220132794231
Valid Loss:  0.00019286881433799863
Epoch:  190  	Training Loss: 0.00020632395171560347
Test Loss:  0.00032536807702854276
Valid Loss:  0.000192127627087757
Epoch:  191  	Training Loss: 0.000205475022085011
Test Loss:  0.00032445957185700536
Valid Loss:  0.00019143143435940146
Epoch:  192  	Training Loss: 0.00020466611022129655
Test Loss:  0.0003240301157347858
Valid Loss:  0.0001907582045532763
Epoch:  193  	Training Loss: 0.00020396299078129232
Test Loss:  0.00032312620896846056
Valid Loss:  0.00019038916798308492
Epoch:  194  	Training Loss: 0.00020353187574073672
Test Loss:  0.0003224069077987224
Valid Loss:  0.00019014973076991737
Epoch:  195  	Training Loss: 0.0002032516640610993
Test Loss:  0.00032179662957787514
Valid Loss:  0.0001899821072584018
Epoch:  196  	Training Loss: 0.00020304240752011538
Test Loss:  0.0003213072777725756
Valid Loss:  0.0001898601185530424
Epoch:  197  	Training Loss: 0.00020287145162001252
Test Loss:  0.0003208849229849875
Valid Loss:  0.0001897785405162722
Epoch:  198  	Training Loss: 0.00020273607515264302
Test Loss:  0.00032055212068371475
Valid Loss:  0.00018972763791680336
Epoch:  199  	Training Loss: 0.0002026289002969861
Test Loss:  0.0003202619554940611
Valid Loss:  0.0001896916946861893
Epoch:  200  	Training Loss: 0.0002025396388489753
Test Loss:  0.0003200235078111291
Valid Loss:  0.00018966944480780512
Epoch:  201  	Training Loss: 0.00020246478379704058
Test Loss:  0.000319841259624809
Valid Loss:  0.00018965566414408386
Epoch:  202  	Training Loss: 0.00020240050798747689
Test Loss:  0.0003171130665577948
Valid Loss:  0.00018777578952722251
Epoch:  203  	Training Loss: 0.0002002268738579005
Test Loss:  0.0003147246898151934
Valid Loss:  0.00018604740034788847
Epoch:  204  	Training Loss: 0.0001982772519113496
Test Loss:  0.0003122507478110492
Valid Loss:  0.00018441480642650276
 41%|████      | 205/500 [02:29<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:30<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:30<01:38,  2.94it/s] 42%|████▏     | 211/500 [02:36<05:51,  1.22s/it] 43%|████▎     | 213/500 [02:36<04:10,  1.14it/s] 43%|████▎     | 215/500 [02:37<02:59,  1.58it/s] 43%|████▎     | 217/500 [02:37<02:10,  2.17it/s] 44%|████▍     | 219/500 [02:37<01:36,  2.92it/s] 44%|████▍     | 221/500 [02:43<05:35,  1.20s/it] 45%|████▍     | 223/500 [02:43<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:43<02:51,  1.61it/s] 45%|████▌     | 227/500 [02:44<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:44<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:50<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:50<03:47,  1.18it/s] 47%|████▋     | 235/500 [02:50<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:50<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:51<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:57<05:04,  1.18s/it] 49%|████▊     | 243/500 [02:57<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:57<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:57<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:57<01:23,  2.99it/s] 50%|█████     | 251/500 [03:04<04:51,  1.17s/it] 51%|█████     | 253/500 [03:04<03:27,  1.19it/s] 51%|█████     | 255/500 [03:04<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:04<01:48,  2.25it/s] 52%|█████▏    | 259/500 [03:04<01:19,  3.03it/s] 52%|█████▏    | 261/500 [03:10<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:11<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:11<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:11<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:11<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:17<04:36,  1.21s/it]Epoch:  205  	Training Loss: 0.0001964616240002215
Test Loss:  0.00030987869831733406
Valid Loss:  0.00018288752471562475
Epoch:  206  	Training Loss: 0.000194769527297467
Test Loss:  0.0003074946580454707
Valid Loss:  0.00018141641339752823
Epoch:  207  	Training Loss: 0.0001931360166054219
Test Loss:  0.0003052445827051997
Valid Loss:  0.00017998929251916707
Epoch:  208  	Training Loss: 0.0001915565226227045
Test Loss:  0.0003029974759556353
Valid Loss:  0.000178599773789756
Epoch:  209  	Training Loss: 0.00019005080685019493
Test Loss:  0.0003008182975463569
Valid Loss:  0.00017731025582179427
Epoch:  210  	Training Loss: 0.0001886736135929823
Test Loss:  0.00029870393336750567
Valid Loss:  0.00017604352615308017
Epoch:  211  	Training Loss: 0.00018732756143435836
Test Loss:  0.00029655947582796216
Valid Loss:  0.00017477798974141479
Epoch:  212  	Training Loss: 0.00018600486509967595
Test Loss:  0.00029542273841798306
Valid Loss:  0.00017444949480704963
Epoch:  213  	Training Loss: 0.000185497134225443
Test Loss:  0.00029449869180098176
Valid Loss:  0.00017414326430298388
Epoch:  214  	Training Loss: 0.00018502386228647083
Test Loss:  0.00029361125780269504
Valid Loss:  0.00017384643433615565
Epoch:  215  	Training Loss: 0.00018459005514159799
Test Loss:  0.00029276771238073707
Valid Loss:  0.0001735700643621385
Epoch:  216  	Training Loss: 0.0001841786433942616
Test Loss:  0.0002919764956459403
Valid Loss:  0.00017331313574686646
Epoch:  217  	Training Loss: 0.0001837859454099089
Test Loss:  0.0002912291674874723
Valid Loss:  0.00017306744121015072
Epoch:  218  	Training Loss: 0.00018340414681006223
Test Loss:  0.0002905189758166671
Valid Loss:  0.0001728380157146603
Epoch:  219  	Training Loss: 0.0001830389373935759
Test Loss:  0.00028984659002162516
Valid Loss:  0.00017262401524931192
Epoch:  220  	Training Loss: 0.00018268736312165856
Test Loss:  0.00028921262128278613
Valid Loss:  0.00017241913883481175
Epoch:  221  	Training Loss: 0.0001823434286052361
Test Loss:  0.0002886285074055195
Valid Loss:  0.00017222538008354604
Epoch:  222  	Training Loss: 0.0001820133620640263
Test Loss:  0.00028641786775551736
Valid Loss:  0.00017089581524487585
Epoch:  223  	Training Loss: 0.00018064529285766184
Test Loss:  0.0002845799317583442
Valid Loss:  0.00016962335212156177
Epoch:  224  	Training Loss: 0.00017934651987161487
Test Loss:  0.00028284176369197667
Valid Loss:  0.0001684117887634784
Epoch:  225  	Training Loss: 0.00017810624558478594
Test Loss:  0.00028113677399232984
Valid Loss:  0.00016735776443965733
Epoch:  226  	Training Loss: 0.0001769198861438781
Test Loss:  0.0002794130705296993
Valid Loss:  0.00016633491031825542
Epoch:  227  	Training Loss: 0.00017576589016243815
Test Loss:  0.0002776866895146668
Valid Loss:  0.00016534050519112498
Epoch:  228  	Training Loss: 0.0001746400084812194
Test Loss:  0.0002759592898655683
Valid Loss:  0.00016438064631074667
Epoch:  229  	Training Loss: 0.00017353679868392646
Test Loss:  0.00027423532446846366
Valid Loss:  0.00016343890456482768
Epoch:  230  	Training Loss: 0.00017245204071514308
Test Loss:  0.00027251182473264635
Valid Loss:  0.00016250941553153098
Epoch:  231  	Training Loss: 0.00017138614202849567
Test Loss:  0.0002708976389840245
Valid Loss:  0.0001615958462934941
Epoch:  232  	Training Loss: 0.0001703576126601547
Test Loss:  0.0002698901225812733
Valid Loss:  0.0001607779267942533
Epoch:  233  	Training Loss: 0.0001694682869128883
Test Loss:  0.0002678796008694917
Valid Loss:  0.00016011320985853672
Epoch:  234  	Training Loss: 0.00016867219528649002
Test Loss:  0.0002666325308382511
Valid Loss:  0.0001594922796357423
Epoch:  235  	Training Loss: 0.00016795092960819602
Test Loss:  0.00026527149020694196
Valid Loss:  0.00015893361705821007
Epoch:  236  	Training Loss: 0.0001672893122304231
Test Loss:  0.00026413582963868976
Valid Loss:  0.00015841133426874876
Epoch:  237  	Training Loss: 0.00016668073658365756
Test Loss:  0.0002630443195812404
Valid Loss:  0.00015792077465448529
Epoch:  238  	Training Loss: 0.00016610685270279646
Test Loss:  0.00026203226298093796
Valid Loss:  0.00015745373093523085
Epoch:  239  	Training Loss: 0.00016556971240788698
Test Loss:  0.0002610773663036525
Valid Loss:  0.0001570242311572656
Epoch:  240  	Training Loss: 0.00016507974942214787
Test Loss:  0.00026022904785349965
Valid Loss:  0.0001566076243761927
Epoch:  241  	Training Loss: 0.00016460630286019295
Test Loss:  0.00025940631167031825
Valid Loss:  0.0001562039105920121
Epoch:  242  	Training Loss: 0.00016414574929513037
Test Loss:  0.0002566311159171164
Valid Loss:  0.00015499454457312822
Epoch:  243  	Training Loss: 0.00016274198424071074
Test Loss:  0.0002575051039457321
Valid Loss:  0.000153785411384888
Epoch:  244  	Training Loss: 0.00016152301395777613
Test Loss:  0.0002543839509598911
Valid Loss:  0.00015289883594959974
Epoch:  245  	Training Loss: 0.00016044950461946428
Test Loss:  0.0002558522392064333
Valid Loss:  0.00015186793461907655
Epoch:  246  	Training Loss: 0.00015946911298669875
Test Loss:  0.0002521653368603438
Valid Loss:  0.00015120409079827368
Epoch:  247  	Training Loss: 0.00015857521793805063
Test Loss:  0.0002544257731642574
Valid Loss:  0.0001502532250015065
Epoch:  248  	Training Loss: 0.00015772893675602973
Test Loss:  0.00024979148292914033
Valid Loss:  0.00014972747885622084
Epoch:  249  	Training Loss: 0.00015691133739892393
Test Loss:  0.00025304764858447015
Valid Loss:  0.00014875613851472735
Epoch:  250  	Training Loss: 0.0001561282988404855
Test Loss:  0.0002472636988386512
Valid Loss:  0.00014838710194453597
Epoch:  251  	Training Loss: 0.00015538185834884644
Test Loss:  0.00025194918271154165
Valid Loss:  0.00014739563630428165
Epoch:  252  	Training Loss: 0.00015468650963157415
Test Loss:  0.0002496063825674355
Valid Loss:  0.0001465652894694358
Epoch:  253  	Training Loss: 0.00015374805661849678
Test Loss:  0.00024800459505058825
Valid Loss:  0.00014582254516426474
Epoch:  254  	Training Loss: 0.0001529540168121457
Test Loss:  0.0002466897713020444
Valid Loss:  0.00014508429740089923
Epoch:  255  	Training Loss: 0.0001521858648629859
Test Loss:  0.00024547797511331737
Valid Loss:  0.00014435329649131745
Epoch:  256  	Training Loss: 0.00015146186342462897
Test Loss:  0.0002443042758386582
Valid Loss:  0.0001436814054613933
Epoch:  257  	Training Loss: 0.00015079285367392004
Test Loss:  0.00024319434305652976
Valid Loss:  0.00014301540795713663
Epoch:  258  	Training Loss: 0.00015013152733445168
Test Loss:  0.00024211459094658494
Valid Loss:  0.0001423536305082962
Epoch:  259  	Training Loss: 0.00014948027092032135
Test Loss:  0.00024105882039293647
Valid Loss:  0.0001416998275090009
Epoch:  260  	Training Loss: 0.00014883955009281635
Test Loss:  0.00024001626297831535
Valid Loss:  0.00014105401351116598
Epoch:  261  	Training Loss: 0.00014820779324509203
Test Loss:  0.00023898763174656779
Valid Loss:  0.0001404978975187987
Epoch:  262  	Training Loss: 0.00014760083286091685
Test Loss:  0.00023534666979685426
Valid Loss:  0.00013959273928776383
Epoch:  263  	Training Loss: 0.00014649170043412596
Test Loss:  0.0002334048767806962
Valid Loss:  0.00013874226715415716
Epoch:  264  	Training Loss: 0.00014550669584423304
Test Loss:  0.00023164712183643132
Valid Loss:  0.00013790506636723876
Epoch:  265  	Training Loss: 0.000144540928886272
Test Loss:  0.00022991059813648462
Valid Loss:  0.00013708480400964618
Epoch:  266  	Training Loss: 0.00014359518536366522
Test Loss:  0.00022837788856122643
Valid Loss:  0.00013627641601487994
Epoch:  267  	Training Loss: 0.00014266600192058831
Test Loss:  0.00022691034246236086
Valid Loss:  0.00013548231800086796
Epoch:  268  	Training Loss: 0.00014174962416291237
Test Loss:  0.0002255010767839849
Valid Loss:  0.00013469945406541228
Epoch:  269  	Training Loss: 0.00014085191651247442
Test Loss:  0.00022409326629713178
Valid Loss:  0.0001339303416898474
Epoch:  270  	Training Loss: 0.00013996641791891307
Test Loss:  0.00022270347108133137
Valid Loss:  0.00013317202683538198
Epoch:  271  	Training Loss: 0.0001391306141158566
Test Loss:  0.00022131911828182638
Valid Loss:  0.00013250368647277355
 55%|█████▍    | 273/500 [03:18<03:16,  1.15it/s] 55%|█████▌    | 275/500 [03:18<02:21,  1.59it/s] 55%|█████▌    | 277/500 [03:18<01:42,  2.17it/s] 56%|█████▌    | 279/500 [03:18<01:15,  2.92it/s] 56%|█████▌    | 281/500 [03:24<04:23,  1.21s/it] 57%|█████▋    | 283/500 [03:25<03:07,  1.16it/s] 57%|█████▋    | 285/500 [03:25<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:25<01:37,  2.18it/s] 58%|█████▊    | 289/500 [03:25<01:11,  2.93it/s] 58%|█████▊    | 291/500 [03:31<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:31<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:32<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:32<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:32<01:06,  3.02it/s] 60%|██████    | 301/500 [03:38<03:56,  1.19s/it] 61%|██████    | 303/500 [03:38<02:48,  1.17it/s] 61%|██████    | 305/500 [03:38<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:39<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:39<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:45<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:45<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:45<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:45<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:46<01:01,  2.95it/s] 64%|██████▍   | 321/500 [03:52<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:52<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:52<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:52<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:53<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:59<03:18,  1.18s/it] 67%|██████▋   | 333/500 [03:59<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:59<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:59<01:13,  2.23it/s]Epoch:  272  	Training Loss: 0.00013841620238963515
Test Loss:  0.0002204905031248927
Valid Loss:  0.00013203479466028512
Epoch:  273  	Training Loss: 0.0001378297311021015
Test Loss:  0.0002195588604081422
Valid Loss:  0.00013158575166016817
Epoch:  274  	Training Loss: 0.0001372655387967825
Test Loss:  0.00021867708710487932
Valid Loss:  0.00013115174078848213
Epoch:  275  	Training Loss: 0.0001367434160783887
Test Loss:  0.0002177946298616007
Valid Loss:  0.0001307572820223868
Epoch:  276  	Training Loss: 0.00013626358122564852
Test Loss:  0.0002169633808080107
Valid Loss:  0.00013036983727943152
Epoch:  277  	Training Loss: 0.00013580435188487172
Test Loss:  0.0002160694421036169
Valid Loss:  0.00013000213948544115
Epoch:  278  	Training Loss: 0.00013536811457015574
Test Loss:  0.00021532039681915194
Valid Loss:  0.00012964915367774665
Epoch:  279  	Training Loss: 0.000134950372739695
Test Loss:  0.00021459021081682295
Valid Loss:  0.00012930951197631657
Epoch:  280  	Training Loss: 0.00013454348663799465
Test Loss:  0.00021390183246694505
Valid Loss:  0.0001289772626478225
Epoch:  281  	Training Loss: 0.00013416120782494545
Test Loss:  0.00021322591055650264
Valid Loss:  0.0001286980987060815
Epoch:  282  	Training Loss: 0.00013382018369156867
Test Loss:  0.00021189742255955935
Valid Loss:  0.00012819311814382672
Epoch:  283  	Training Loss: 0.00013318656419869512
Test Loss:  0.00021186043159104884
Valid Loss:  0.00012768968008458614
Epoch:  284  	Training Loss: 0.000132653396576643
Test Loss:  0.00021109788212925196
Valid Loss:  0.00012729244190268219
Epoch:  285  	Training Loss: 0.00013217546802479774
Test Loss:  0.00021066769841127098
Valid Loss:  0.0001268946216441691
Epoch:  286  	Training Loss: 0.0001317293499596417
Test Loss:  0.00021003602887503803
Valid Loss:  0.00012652843724936247
Epoch:  287  	Training Loss: 0.0001313054235652089
Test Loss:  0.0002094946103170514
Valid Loss:  0.00012616973253898323
Epoch:  288  	Training Loss: 0.00013090418360661715
Test Loss:  0.00020888051949441433
Valid Loss:  0.00012582639465108514
Epoch:  289  	Training Loss: 0.00013051879068370908
Test Loss:  0.00020829416462220252
Valid Loss:  0.00012549830717034638
Epoch:  290  	Training Loss: 0.00013014560681767762
Test Loss:  0.00020768609829246998
Valid Loss:  0.00012518352014012635
Epoch:  291  	Training Loss: 0.00012978562153875828
Test Loss:  0.00020708731608465314
Valid Loss:  0.0001248754997504875
Epoch:  292  	Training Loss: 0.00012943681213073432
Test Loss:  0.00020643135940190405
Valid Loss:  0.00012456704280339181
Epoch:  293  	Training Loss: 0.00012910983059555292
Test Loss:  0.0002057515230262652
Valid Loss:  0.00012430697097443044
Epoch:  294  	Training Loss: 0.0001288352650590241
Test Loss:  0.00020506783039309084
Valid Loss:  0.0001240929850609973
Epoch:  295  	Training Loss: 0.00012860479182563722
Test Loss:  0.00020449512521736324
Valid Loss:  0.00012390311167109758
Epoch:  296  	Training Loss: 0.00012840150156989694
Test Loss:  0.00020397974003572017
Valid Loss:  0.0001237364485859871
Epoch:  297  	Training Loss: 0.00012822166900150478
Test Loss:  0.00020350504200905561
Valid Loss:  0.00012358771346043795
Epoch:  298  	Training Loss: 0.0001280615688301623
Test Loss:  0.00020306670921854675
Valid Loss:  0.00012345591676421463
Epoch:  299  	Training Loss: 0.00012792051711585373
Test Loss:  0.00020264262275304645
Valid Loss:  0.00012334765051491559
Epoch:  300  	Training Loss: 0.00012780418910551816
Test Loss:  0.0002022818080149591
Valid Loss:  0.00012324692215770483
Epoch:  301  	Training Loss: 0.0001276982802664861
Test Loss:  0.00020195134857203811
Valid Loss:  0.00012315655476413667
Epoch:  302  	Training Loss: 0.0001276022376259789
Test Loss:  0.00020155902893748134
Valid Loss:  0.00012299360241740942
Epoch:  303  	Training Loss: 0.0001274331589229405
Test Loss:  0.00020115957886446267
Valid Loss:  0.0001228461624123156
Epoch:  304  	Training Loss: 0.00012728024739772081
Test Loss:  0.00020076624059583992
Valid Loss:  0.0001227049360750243
Epoch:  305  	Training Loss: 0.00012713616888504475
Test Loss:  0.0002003870322369039
Valid Loss:  0.0001225740707013756
Epoch:  306  	Training Loss: 0.00012699916260316968
Test Loss:  0.0002000253734877333
Valid Loss:  0.0001224527950398624
Epoch:  307  	Training Loss: 0.00012687267735600471
Test Loss:  0.0001996543287532404
Valid Loss:  0.0001223554863827303
Epoch:  308  	Training Loss: 0.0001267766929231584
Test Loss:  0.00019934787997044623
Valid Loss:  0.00012225817772559822
Epoch:  309  	Training Loss: 0.0001266914769075811
Test Loss:  0.00019903859356418252
Valid Loss:  0.00012218444317113608
Epoch:  310  	Training Loss: 0.00012662462540902197
Test Loss:  0.00019879854517057538
Valid Loss:  0.00012211021385155618
Epoch:  311  	Training Loss: 0.00012656090257223696
Test Loss:  0.0001985878188861534
Valid Loss:  0.00012203535152366385
Epoch:  312  	Training Loss: 0.00012649991549551487
Test Loss:  0.00019654797506518662
Valid Loss:  0.00012140229227952659
Epoch:  313  	Training Loss: 0.00012548196536954492
Test Loss:  0.00019549383432604373
Valid Loss:  0.00012086725473636761
Epoch:  314  	Training Loss: 0.00012470126966945827
Test Loss:  0.00019461996271274984
Valid Loss:  0.000120387296192348
Epoch:  315  	Training Loss: 0.00012402537686284631
Test Loss:  0.00019378031720407307
Valid Loss:  0.00011994420492555946
Epoch:  316  	Training Loss: 0.00012341704859863967
Test Loss:  0.00019294940284453332
Valid Loss:  0.00011952876957366243
Epoch:  317  	Training Loss: 0.0001228584733325988
Test Loss:  0.0001921203511301428
Valid Loss:  0.00011913022171938792
Epoch:  318  	Training Loss: 0.00012233300367370248
Test Loss:  0.00019129669817630202
Valid Loss:  0.00011874471238115802
Epoch:  319  	Training Loss: 0.00012183318904135376
Test Loss:  0.000190476217539981
Valid Loss:  0.00011836794146802276
Epoch:  320  	Training Loss: 0.00012135733413742855
Test Loss:  0.0001896605535876006
Valid Loss:  0.00011800610809586942
Epoch:  321  	Training Loss: 0.00012088201037840918
Test Loss:  0.0001887395919766277
Valid Loss:  0.00011764866940211505
Epoch:  322  	Training Loss: 0.00012039700959576294
Test Loss:  0.00018934125546365976
Valid Loss:  0.00011717213783413172
Epoch:  323  	Training Loss: 0.00011997218825854361
Test Loss:  0.00018880947027355433
Valid Loss:  0.00011685492791002616
Epoch:  324  	Training Loss: 0.0001196423836518079
Test Loss:  0.0001882167998701334
Valid Loss:  0.00011656364222289994
Epoch:  325  	Training Loss: 0.00011932868801523
Test Loss:  0.00018763140542432666
Valid Loss:  0.00011631000961642712
Epoch:  326  	Training Loss: 0.00011904932762263343
Test Loss:  0.00018707542039919645
Valid Loss:  0.00011607359920162708
Epoch:  327  	Training Loss: 0.0001187974849017337
Test Loss:  0.00018655508756637573
Valid Loss:  0.00011585462925722823
Epoch:  328  	Training Loss: 0.00011856220953632146
Test Loss:  0.00018607682432048023
Valid Loss:  0.00011564389569684863
Epoch:  329  	Training Loss: 0.00011833611642941833
Test Loss:  0.00018561487377155572
Valid Loss:  0.0001154387355200015
Epoch:  330  	Training Loss: 0.00011811754666268826
Test Loss:  0.0001851693814387545
Valid Loss:  0.00011523888679221272
Epoch:  331  	Training Loss: 0.00011791013093898073
Test Loss:  0.00018474104581400752
Valid Loss:  0.00011504621215863153
Epoch:  332  	Training Loss: 0.00011771103163482621
Test Loss:  0.00018366496078670025
Valid Loss:  0.00011476696818135679
Epoch:  333  	Training Loss: 0.00011742854258045554
Test Loss:  0.0001832816342357546
Valid Loss:  0.00011447697761468589
Epoch:  334  	Training Loss: 0.00011717317829607055
Test Loss:  0.00018290069419890642
Valid Loss:  0.0001141980683314614
Epoch:  335  	Training Loss: 0.00011692621046677232
Test Loss:  0.00018251824076287448
Valid Loss:  0.00011392781743779778
Epoch:  336  	Training Loss: 0.00011668712249957025
Test Loss:  0.00018214137526229024
Valid Loss:  0.00011366623220965266
Epoch:  337  	Training Loss: 0.00011645658378256485
Test Loss:  0.00018177618039771914
Valid Loss:  0.00011341235949657857
Epoch:  338  	Training Loss: 0.00011623256432358176
Test Loss:  0.00018140734755434096
Valid Loss:  0.00011316641757730395
 68%|██████▊   | 339/500 [03:59<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:06<03:15,  1.23s/it] 69%|██████▊   | 343/500 [04:06<02:18,  1.13it/s] 69%|██████▉   | 345/500 [04:06<01:38,  1.57it/s] 69%|██████▉   | 347/500 [04:06<01:11,  2.15it/s] 70%|██████▉   | 349/500 [04:06<00:52,  2.90it/s] 70%|███████   | 351/500 [04:13<02:57,  1.19s/it] 71%|███████   | 353/500 [04:13<02:05,  1.17it/s] 71%|███████   | 355/500 [04:13<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:13<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:13<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:20<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:20<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:20<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:20<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:20<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:27<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:27<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:27<01:17,  1.60it/s] 75%|███████▌  | 377/500 [04:27<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:27<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:33<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:34<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:34<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:34<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:34<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:40<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:40<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:41<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:41<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:41<00:33,  2.97it/s] 80%|████████  | 401/500 [04:47<01:58,  1.20s/it] 81%|████████  | 403/500 [04:47<01:23,  1.17it/s]Epoch:  339  	Training Loss: 0.00011601511505432427
Test Loss:  0.00018104395712725818
Valid Loss:  0.00011292729323031381
Epoch:  340  	Training Loss: 0.00011580283171497285
Test Loss:  0.0001806833897717297
Valid Loss:  0.00011269457172602415
Epoch:  341  	Training Loss: 0.00011559669655980542
Test Loss:  0.0001803280902095139
Valid Loss:  0.00011246762733208016
Epoch:  342  	Training Loss: 0.00011539531988091767
Test Loss:  0.00017990099149756134
Valid Loss:  0.00011237026774324477
Epoch:  343  	Training Loss: 0.00011528923641890287
Test Loss:  0.00017960392870008945
Valid Loss:  0.00011227864888496697
Epoch:  344  	Training Loss: 0.00011519603140186518
Test Loss:  0.00017934413335751742
Valid Loss:  0.00011219744192203507
Epoch:  345  	Training Loss: 0.00011511359480209649
Test Loss:  0.00017910714086610824
Valid Loss:  0.00011212273966521025
Epoch:  346  	Training Loss: 0.00011503850691951811
Test Loss:  0.00017889223818201572
Valid Loss:  0.00011205331975361332
Epoch:  347  	Training Loss: 0.00011496874503791332
Test Loss:  0.00017869289149530232
Valid Loss:  0.00011198896390851587
Epoch:  348  	Training Loss: 0.00011490484757814556
Test Loss:  0.00017850898439064622
Valid Loss:  0.00011192777310498059
Epoch:  349  	Training Loss: 0.0001148468436440453
Test Loss:  0.0001783400512067601
Valid Loss:  0.00011186980555066839
Epoch:  350  	Training Loss: 0.00011479431123007089
Test Loss:  0.00017818488413468003
Valid Loss:  0.00011181508307345212
Epoch:  351  	Training Loss: 0.00011474560596980155
Test Loss:  0.0001780417951522395
Valid Loss:  0.00011176250700373203
Epoch:  352  	Training Loss: 0.00011469945457065478
Test Loss:  0.00017660341109149158
Valid Loss:  0.00011129987251479179
Epoch:  353  	Training Loss: 0.00011405244731577113
Test Loss:  0.00017614536045584828
Valid Loss:  0.00011091502528870478
Epoch:  354  	Training Loss: 0.00011354273010510951
Test Loss:  0.00017563599976710975
Valid Loss:  0.00011058693053200841
Epoch:  355  	Training Loss: 0.00011309977708151564
Test Loss:  0.00017513075727038085
Valid Loss:  0.00011029539746232331
Epoch:  356  	Training Loss: 0.0001127016221289523
Test Loss:  0.0001746099442243576
Valid Loss:  0.00011002614337485284
Epoch:  357  	Training Loss: 0.00011232927499804646
Test Loss:  0.00017403136007487774
Valid Loss:  0.0001097672211471945
Epoch:  358  	Training Loss: 0.00011193781392648816
Test Loss:  0.0001734747493173927
Valid Loss:  0.00010951987496810034
Epoch:  359  	Training Loss: 0.00011156860273331404
Test Loss:  0.00017291995754931122
Valid Loss:  0.00010928133269771934
Epoch:  360  	Training Loss: 0.00011121405987069011
Test Loss:  0.00017237075371667743
Valid Loss:  0.00010905058297794312
Epoch:  361  	Training Loss: 0.00011087180610047653
Test Loss:  0.00017181498697027564
Valid Loss:  0.00010882553760893643
Epoch:  362  	Training Loss: 0.0001105390110751614
Test Loss:  0.000171295105246827
Valid Loss:  0.00010856588778551668
Epoch:  363  	Training Loss: 0.00011017069482477382
Test Loss:  0.00017093865608330816
Valid Loss:  0.00010834653949132189
Epoch:  364  	Training Loss: 0.0001098613502108492
Test Loss:  0.00017060771642718464
Valid Loss:  0.00010815224959515035
Epoch:  365  	Training Loss: 0.00010958640632452443
Test Loss:  0.00017031500465236604
Valid Loss:  0.00010797363211167976
Epoch:  366  	Training Loss: 0.00010933920566458255
Test Loss:  0.00016998972569126636
Valid Loss:  0.0001078005152521655
Epoch:  367  	Training Loss: 0.0001091015656129457
Test Loss:  0.00016965238319244236
Valid Loss:  0.00010763198952190578
Epoch:  368  	Training Loss: 0.00010887450480367988
Test Loss:  0.0001693324011284858
Valid Loss:  0.00010747533815447241
Epoch:  369  	Training Loss: 0.00010865961667150259
Test Loss:  0.00016899296315386891
Valid Loss:  0.00010732360533438623
Epoch:  370  	Training Loss: 0.00010845191718544811
Test Loss:  0.00016865759971551597
Valid Loss:  0.00010717391705838963
Epoch:  371  	Training Loss: 0.00010824971832334995
Test Loss:  0.00016831132234074175
Valid Loss:  0.0001070246216841042
Epoch:  372  	Training Loss: 0.00010805077181430534
Test Loss:  0.00016807112842798233
Valid Loss:  0.00010674126679077744
Epoch:  373  	Training Loss: 0.00010774553811643273
Test Loss:  0.00016724830493330956
Valid Loss:  0.00010650332842487842
Epoch:  374  	Training Loss: 0.00010748644126579165
Test Loss:  0.00016671093180775642
Valid Loss:  0.00010628886957420036
Epoch:  375  	Training Loss: 0.00010725776519393548
Test Loss:  0.00016617051733192056
Valid Loss:  0.0001060931826941669
Epoch:  376  	Training Loss: 0.00010705103341024369
Test Loss:  0.00016570005391258746
Valid Loss:  0.0001059114292729646
Epoch:  377  	Training Loss: 0.00010686156019801274
Test Loss:  0.00016526391846127808
Valid Loss:  0.00010573920735623688
Epoch:  378  	Training Loss: 0.00010668465256458148
Test Loss:  0.00016486177628394216
Valid Loss:  0.00010557797213550657
Epoch:  379  	Training Loss: 0.0001065176329575479
Test Loss:  0.0001644930598558858
Valid Loss:  0.000105426755908411
Epoch:  380  	Training Loss: 0.00010636105434969068
Test Loss:  0.00016414112178608775
Valid Loss:  0.00010528049460845068
Epoch:  381  	Training Loss: 0.00010621105320751667
Test Loss:  0.00016381024033762515
Valid Loss:  0.00010513824236113578
Epoch:  382  	Training Loss: 0.00010606612340779975
Test Loss:  0.00016328877245541662
Valid Loss:  0.00010490986460354179
Epoch:  383  	Training Loss: 0.00010582664981484413
Test Loss:  0.0001627827004995197
Valid Loss:  0.00010468954860698432
Epoch:  384  	Training Loss: 0.00010560038208495826
Test Loss:  0.0001622975687496364
Valid Loss:  0.00010447930981172249
Epoch:  385  	Training Loss: 0.00010538524657022208
Test Loss:  0.00016183363914024085
Valid Loss:  0.00010427720553707331
Epoch:  386  	Training Loss: 0.00010518248018343002
Test Loss:  0.00016139596118591726
Valid Loss:  0.00010408322123112157
Epoch:  387  	Training Loss: 0.00010498878691578284
Test Loss:  0.0001609927276149392
Valid Loss:  0.00010389262752141804
Epoch:  388  	Training Loss: 0.00010480150376679376
Test Loss:  0.0001605992001714185
Valid Loss:  0.00010370657400926575
Epoch:  389  	Training Loss: 0.00010462047066539526
Test Loss:  0.00016022086492739618
Valid Loss:  0.0001035260793287307
Epoch:  390  	Training Loss: 0.00010444724466651678
Test Loss:  0.00015987806546036154
Valid Loss:  0.00010334994294680655
Epoch:  391  	Training Loss: 0.00010427783126942813
Test Loss:  0.0001595351059222594
Valid Loss:  0.00010317546548321843
Epoch:  392  	Training Loss: 0.00010411127004772425
Test Loss:  0.00015932729002088308
Valid Loss:  0.00010316778207197785
Epoch:  393  	Training Loss: 0.00010409079550299793
Test Loss:  0.00015923648606985807
Valid Loss:  0.00010316110274288803
Epoch:  394  	Training Loss: 0.00010407203808426857
Test Loss:  0.0001591483160154894
Valid Loss:  0.00010315505642211065
Epoch:  395  	Training Loss: 0.00010405453940620646
Test Loss:  0.00015906785847619176
Valid Loss:  0.00010314825340174139
Epoch:  396  	Training Loss: 0.00010403807391412556
Test Loss:  0.0001589945750311017
Valid Loss:  0.00010314281826140359
Epoch:  397  	Training Loss: 0.00010402197221992537
Test Loss:  0.00015892685041762888
Valid Loss:  0.00010313739767298102
Epoch:  398  	Training Loss: 0.0001040072093019262
Test Loss:  0.00015886336041148752
Valid Loss:  0.00010313247184967622
Epoch:  399  	Training Loss: 0.00010399238090030849
Test Loss:  0.00015880510909482837
Valid Loss:  0.00010312759695807472
Epoch:  400  	Training Loss: 0.00010397780715720728
Test Loss:  0.000158750030095689
Valid Loss:  0.00010312270751455799
Epoch:  401  	Training Loss: 0.00010396393190603703
Test Loss:  0.00015869861817918718
Valid Loss:  0.00010311898950021714
Epoch:  402  	Training Loss: 0.00010395008575869724
Test Loss:  0.0001582330442033708
Valid Loss:  0.00010289154306519777
Epoch:  403  	Training Loss: 0.00010370575182605535
Test Loss:  0.00015804311260581017
Valid Loss:  0.00010269065387547016
Epoch:  404  	Training Loss: 0.00010348593787057325
Test Loss:  0.00015783740673214197
Valid Loss:  0.00010249811020912603
Epoch:  405  	Training Loss: 0.00010327683412469923
Test Loss:  0.0001576200738782063
Valid Loss:   81%|████████  | 405/500 [04:48<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:48<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:48<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:54<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:54<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:55<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:55<00:37,  2.20it/s] 84%|████████▍ | 419/500 [04:55<00:27,  2.97it/s] 84%|████████▍ | 421/500 [05:01<01:34,  1.20s/it] 85%|████████▍ | 423/500 [05:01<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:01<00:46,  1.60it/s] 85%|████████▌ | 427/500 [05:02<00:33,  2.19it/s] 86%|████████▌ | 429/500 [05:02<00:24,  2.94it/s] 86%|████████▌ | 431/500 [05:08<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:08<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:08<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:08<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:09<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:15<01:11,  1.20s/it] 89%|████████▊ | 443/500 [05:15<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:15<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:15<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:16<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:22<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:22<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:22<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:22<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:22<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:29<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:29<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:29<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:29<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:29<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:36<00:34,  1.18s/it]0.0001023130607791245
Epoch:  406  	Training Loss: 0.00010307662887498736
Test Loss:  0.00015739112859591842
Valid Loss:  0.00010213352652499452
Epoch:  407  	Training Loss: 0.00010288250632584095
Test Loss:  0.00015715279732830822
Valid Loss:  0.00010195785580435768
Epoch:  408  	Training Loss: 0.00010269477206747979
Test Loss:  0.0001569074229337275
Valid Loss:  0.00010178988304687664
Epoch:  409  	Training Loss: 0.00010251109779346734
Test Loss:  0.00015665842511225492
Valid Loss:  0.00010162429680349305
Epoch:  410  	Training Loss: 0.00010233064676867798
Test Loss:  0.0001564004778629169
Valid Loss:  0.00010146251588594168
Epoch:  411  	Training Loss: 0.000102156242064666
Test Loss:  0.00015614637231919914
Valid Loss:  0.0001013050350593403
Epoch:  412  	Training Loss: 0.00010199037205893546
Test Loss:  0.00015567810623906553
Valid Loss:  0.00010126506094820797
Epoch:  413  	Training Loss: 0.0001019427872961387
Test Loss:  0.0001554123591631651
Valid Loss:  0.00010123390529770404
Epoch:  414  	Training Loss: 0.00010190761531703174
Test Loss:  0.00015525994240306318
Valid Loss:  0.00010120730439666659
Epoch:  415  	Training Loss: 0.00010187772568315268
Test Loss:  0.0001551602763356641
Valid Loss:  0.00010118167119799182
Epoch:  416  	Training Loss: 0.00010185042629018426
Test Loss:  0.00015509166405536234
Valid Loss:  0.00010115849727299064
Epoch:  417  	Training Loss: 0.00010182526602875441
Test Loss:  0.00015503627946600318
Valid Loss:  0.000101136312878225
Epoch:  418  	Training Loss: 0.00010180268145631999
Test Loss:  0.00015499061555601656
Valid Loss:  0.00010111612209584564
Epoch:  419  	Training Loss: 0.00010178225056733936
Test Loss:  0.0001549539010738954
Valid Loss:  0.00010109762661159039
Epoch:  420  	Training Loss: 0.00010176480282098055
Test Loss:  0.00015492155216634274
Valid Loss:  0.00010108111018780619
Epoch:  421  	Training Loss: 0.00010175106581300497
Test Loss:  0.000154894805746153
Valid Loss:  0.00010106607805937529
Epoch:  422  	Training Loss: 0.00010173850751016289
Test Loss:  0.0001543279067846015
Valid Loss:  0.0001005491940304637
Epoch:  423  	Training Loss: 0.00010126082634087652
Test Loss:  0.00015458595589734614
Valid Loss:  0.00010015492443926632
Epoch:  424  	Training Loss: 0.00010089963325299323
Test Loss:  0.00015412861830554903
Valid Loss:  9.982939809560776e-05
Epoch:  425  	Training Loss: 0.00010060633212560788
Test Loss:  0.0001541963720228523
Valid Loss:  9.954977576853707e-05
Epoch:  426  	Training Loss: 0.00010034904698841274
Test Loss:  0.00015379523392766714
Valid Loss:  9.929206862580031e-05
Epoch:  427  	Training Loss: 0.00010011609992943704
Test Loss:  0.00015373485803138465
Valid Loss:  9.905132174026221e-05
Epoch:  428  	Training Loss: 9.98974428512156e-05
Test Loss:  0.00015337632794398814
Valid Loss:  9.882513404591009e-05
Epoch:  429  	Training Loss: 9.969504026230425e-05
Test Loss:  0.00015323320985771716
Valid Loss:  9.860991849564016e-05
Epoch:  430  	Training Loss: 9.950253297574818e-05
Test Loss:  0.00015291894669644535
Valid Loss:  9.840331767918542e-05
Epoch:  431  	Training Loss: 9.932003013091162e-05
Test Loss:  0.0001527339336462319
Valid Loss:  9.820603008847684e-05
Epoch:  432  	Training Loss: 9.914513066178188e-05
Test Loss:  0.00015236870967783034
Valid Loss:  9.808665345190093e-05
Epoch:  433  	Training Loss: 9.900688019115478e-05
Test Loss:  0.00015201434143818915
Valid Loss:  9.797890379559249e-05
Epoch:  434  	Training Loss: 9.888249769574031e-05
Test Loss:  0.00015169016842264682
Valid Loss:  9.788171155378222e-05
Epoch:  435  	Training Loss: 9.876998228719458e-05
Test Loss:  0.00015139287279453129
Valid Loss:  9.779111132957041e-05
Epoch:  436  	Training Loss: 9.866750770015642e-05
Test Loss:  0.00015112216351553798
Valid Loss:  9.770675387699157e-05
Epoch:  437  	Training Loss: 9.857332770479843e-05
Test Loss:  0.00015087125939317048
Valid Loss:  9.762847912497818e-05
Epoch:  438  	Training Loss: 9.848587797023356e-05
Test Loss:  0.00015064077160786837
Valid Loss:  9.755280916579068e-05
Epoch:  439  	Training Loss: 9.840470011113212e-05
Test Loss:  0.00015042767336126417
Valid Loss:  9.748210140969604e-05
Epoch:  440  	Training Loss: 9.832854266278446e-05
Test Loss:  0.00015022989828139544
Valid Loss:  9.741444955579937e-05
Epoch:  441  	Training Loss: 9.825686720432714e-05
Test Loss:  0.00015004753367975354
Valid Loss:  9.734858758747578e-05
Epoch:  442  	Training Loss: 9.818856051424518e-05
Test Loss:  0.00014961845590732992
Valid Loss:  9.731601312523708e-05
Epoch:  443  	Training Loss: 9.813063661567867e-05
Test Loss:  0.00014933731290511787
Valid Loss:  9.728867735248059e-05
Epoch:  444  	Training Loss: 9.808332833927125e-05
Test Loss:  0.00014914548955857754
Valid Loss:  9.726233838591725e-05
Epoch:  445  	Training Loss: 9.804080036701635e-05
Test Loss:  0.0001490119902882725
Valid Loss:  9.723684343043715e-05
Epoch:  446  	Training Loss: 9.800053521757945e-05
Test Loss:  0.0001489135465817526
Valid Loss:  9.721129026729614e-05
Epoch:  447  	Training Loss: 9.796224185265601e-05
Test Loss:  0.00014883851690683514
Valid Loss:  9.718613000586629e-05
Epoch:  448  	Training Loss: 9.79250980890356e-05
Test Loss:  0.00014877697685733438
Valid Loss:  9.716118802316487e-05
Epoch:  449  	Training Loss: 9.788875468075275e-05
Test Loss:  0.0001487260451540351
Valid Loss:  9.71373519860208e-05
Epoch:  450  	Training Loss: 9.785318979993463e-05
Test Loss:  0.00014868084690533578
Valid Loss:  9.711387974675745e-05
Epoch:  451  	Training Loss: 9.78191164904274e-05
Test Loss:  0.0001486404798924923
Valid Loss:  9.709056030260399e-05
Epoch:  452  	Training Loss: 9.778579988051206e-05
Test Loss:  0.00014780464698560536
Valid Loss:  9.668824350228533e-05
Epoch:  453  	Training Loss: 9.72947382251732e-05
Test Loss:  0.00014764735533390194
Valid Loss:  9.636758477427065e-05
Epoch:  454  	Training Loss: 9.689336002338678e-05
Test Loss:  0.00014710779942106456
Valid Loss:  9.609405242372304e-05
Epoch:  455  	Training Loss: 9.6533665782772e-05
Test Loss:  0.00014664522313978523
Valid Loss:  9.58300952333957e-05
Epoch:  456  	Training Loss: 9.619687625672668e-05
Test Loss:  0.00014603283489122987
Valid Loss:  9.552900155540556e-05
Epoch:  457  	Training Loss: 9.587388922227547e-05
Test Loss:  0.00014544586883857846
Valid Loss:  9.524019696982577e-05
Epoch:  458  	Training Loss: 9.556073200656101e-05
Test Loss:  0.00014483652194030583
Valid Loss:  9.495954145677388e-05
Epoch:  459  	Training Loss: 9.525561472401023e-05
Test Loss:  0.00014422547246795148
Valid Loss:  9.468535427004099e-05
Epoch:  460  	Training Loss: 9.49568348005414e-05
Test Loss:  0.00014361765352077782
Valid Loss:  9.441783186048269e-05
Epoch:  461  	Training Loss: 9.466397750657052e-05
Test Loss:  0.00014301607734523714
Valid Loss:  9.415455861017108e-05
Epoch:  462  	Training Loss: 9.43766935961321e-05
Test Loss:  0.0001426893868483603
Valid Loss:  9.392444917466491e-05
Epoch:  463  	Training Loss: 9.411043720319867e-05
Test Loss:  0.00014207459753379226
Valid Loss:  9.371104533784091e-05
Epoch:  464  	Training Loss: 9.385807788930833e-05
Test Loss:  0.00014151349023450166
Valid Loss:  9.350723121315241e-05
Epoch:  465  	Training Loss: 9.361159027321264e-05
Test Loss:  0.0001409307587891817
Valid Loss:  9.330395550932735e-05
Epoch:  466  	Training Loss: 9.335967479273677e-05
Test Loss:  0.0001403948845108971
Valid Loss:  9.310551831731573e-05
Epoch:  467  	Training Loss: 9.311464236816391e-05
Test Loss:  0.00013980857329443097
Valid Loss:  9.29196976358071e-05
Epoch:  468  	Training Loss: 9.286101703764871e-05
Test Loss:  0.0001393086276948452
Valid Loss:  9.274198964703828e-05
Epoch:  469  	Training Loss: 9.261982631869614e-05
Test Loss:  0.00013883116480428725
Valid Loss:  9.257288184016943e-05
Epoch:  470  	Training Loss: 9.239068458555266e-05
Test Loss:  0.0001383612398058176
Valid Loss:  9.240910731023178e-05
Epoch:  471  	Training Loss: 9.21672472031787e-05
Test Loss:  0.00013786603813059628
Valid Loss:  9.22425024327822e-05
Epoch:  472  	Training Loss: 9.192117431666702e-05
Test Loss:  0.0001373806589981541
Valid Loss:  9.20024249353446e-05
Epoch:  473  	Training Loss: 9.171039710054174e-05
Test Loss:   95%|█████████▍| 473/500 [05:36<00:23,  1.16it/s] 95%|█████████▍| 474/500 [05:36<00:19,  1.36it/s] 95%|█████████▌| 475/500 [05:36<00:15,  1.58it/s] 95%|█████████▌| 476/500 [05:36<00:12,  1.92it/s] 96%|█████████▌| 478/500 [05:36<00:07,  2.87it/s] 96%|█████████▌| 480/500 [05:37<00:04,  4.03it/s] 96%|█████████▋| 482/500 [05:43<00:22,  1.24s/it] 97%|█████████▋| 484/500 [05:43<00:13,  1.16it/s] 97%|█████████▋| 486/500 [05:43<00:08,  1.64it/s] 98%|█████████▊| 488/500 [05:43<00:05,  2.28it/s] 98%|█████████▊| 490/500 [05:44<00:03,  3.08it/s] 98%|█████████▊| 492/500 [05:50<00:09,  1.19s/it] 99%|█████████▉| 494/500 [05:50<00:05,  1.17it/s] 99%|█████████▉| 496/500 [05:50<00:02,  1.63it/s]100%|█████████▉| 498/500 [05:50<00:00,  2.23it/s]100%|██████████| 500/500 [05:50<00:00,  3.00it/s]100%|██████████| 500/500 [05:50<00:00,  1.42it/s]
0.00013717894034925848
Valid Loss:  9.178658365271986e-05
Epoch:  474  	Training Loss: 9.150942787528038e-05
Test Loss:  0.00013684097211807966
Valid Loss:  9.158011380350217e-05
Epoch:  475  	Training Loss: 9.131970000453293e-05
Test Loss:  0.0001365683856420219
Valid Loss:  9.138147288467735e-05
Epoch:  476  	Training Loss: 9.113566920859739e-05
Test Loss:  0.00013626395957544446
Valid Loss:  9.118929301621392e-05
Epoch:  477  	Training Loss: 9.095970017369837e-05
Test Loss:  0.00013598124496638775
Valid Loss:  9.100637544179335e-05
Epoch:  478  	Training Loss: 9.07893045223318e-05
Test Loss:  0.00013569537259172648
Valid Loss:  9.082830365514383e-05
Epoch:  479  	Training Loss: 9.062248864211142e-05
Test Loss:  0.00013540971849579364
Valid Loss:  9.065799531526864e-05
Epoch:  480  	Training Loss: 9.04601183719933e-05
Test Loss:  0.00013513521116692573
Valid Loss:  9.049115760717541e-05
Epoch:  481  	Training Loss: 9.030017827171832e-05
Test Loss:  0.00013486712123267353
Valid Loss:  9.032970410771668e-05
Epoch:  482  	Training Loss: 9.01452440302819e-05
Test Loss:  0.00013482137001119554
Valid Loss:  9.021888399729505e-05
Epoch:  483  	Training Loss: 9.002739534480497e-05
Test Loss:  0.00013460675836540759
Valid Loss:  9.010345092974603e-05
Epoch:  484  	Training Loss: 8.99118313100189e-05
Test Loss:  0.0001344088523183018
Valid Loss:  8.998841076390818e-05
Epoch:  485  	Training Loss: 8.979724952951074e-05
Test Loss:  0.00013421279436443
Valid Loss:  8.987446199171245e-05
Epoch:  486  	Training Loss: 8.968336624093354e-05
Test Loss:  0.00013401967589743435
Valid Loss:  8.976177196018398e-05
Epoch:  487  	Training Loss: 8.957032696343958e-05
Test Loss:  0.0001338333822786808
Valid Loss:  8.965014421846718e-05
Epoch:  488  	Training Loss: 8.945829176809639e-05
Test Loss:  0.00013364426558837295
Valid Loss:  8.954000804806128e-05
Epoch:  489  	Training Loss: 8.934748620958999e-05
Test Loss:  0.00013345872866921127
Valid Loss:  8.94295226316899e-05
Epoch:  490  	Training Loss: 8.923678251449019e-05
Test Loss:  0.00013327461783774197
Valid Loss:  8.93197429832071e-05
Epoch:  491  	Training Loss: 8.912663179216906e-05
Test Loss:  0.00013309188943821937
Valid Loss:  8.921013795770705e-05
Epoch:  492  	Training Loss: 8.901742694433779e-05
Test Loss:  0.0001331323874182999
Valid Loss:  8.878054359229282e-05
Epoch:  493  	Training Loss: 8.862830873113126e-05
Test Loss:  0.000132552653667517
Valid Loss:  8.845623960951343e-05
Epoch:  494  	Training Loss: 8.835878543322906e-05
Test Loss:  0.000132284767460078
Valid Loss:  8.822345989756286e-05
Epoch:  495  	Training Loss: 8.814297325443476e-05
Test Loss:  0.0001319224975304678
Valid Loss:  8.804176468402147e-05
Epoch:  496  	Training Loss: 8.797548071015626e-05
Test Loss:  0.00013162376126274467
Valid Loss:  8.78893188200891e-05
Epoch:  497  	Training Loss: 8.783324301475659e-05
Test Loss:  0.0001313324028160423
Valid Loss:  8.774959133006632e-05
Epoch:  498  	Training Loss: 8.770529530011117e-05
Test Loss:  0.00013105552352499217
Valid Loss:  8.76205594977364e-05
Epoch:  499  	Training Loss: 8.758646436035633e-05
Test Loss:  0.00013079261407256126
Valid Loss:  8.749988046474755e-05
Epoch:  500  	Training Loss: 8.747566607780755e-05
Test Loss:  0.0001305469049839303
Valid Loss:  8.738847100175917e-05
seed is  19
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.42it/s]  1%|          | 4/500 [00:00<00:29, 16.58it/s]  1%|          | 6/500 [00:00<00:30, 16.47it/s]  2%|▏         | 8/500 [00:00<00:29, 16.41it/s]  2%|▏         | 10/500 [00:00<00:29, 16.56it/s]  2%|▏         | 12/500 [00:00<00:29, 16.60it/s]  3%|▎         | 14/500 [00:00<00:29, 16.63it/s]  3%|▎         | 16/500 [00:00<00:29, 16.68it/s]  4%|▎         | 18/500 [00:01<00:28, 16.74it/s]  4%|▍         | 20/500 [00:01<00:28, 16.66it/s]  4%|▍         | 22/500 [00:01<00:28, 16.58it/s]  5%|▍         | 24/500 [00:01<00:28, 16.48it/s]  5%|▌         | 26/500 [00:01<00:29, 15.94it/s]  6%|▌         | 28/500 [00:01<00:29, 16.05it/s]  6%|▌         | 30/500 [00:01<00:28, 16.23it/s]  6%|▋         | 32/500 [00:01<00:28, 16.34it/s]  7%|▋         | 34/500 [00:02<00:28, 16.41it/s]  7%|▋         | 36/500 [00:02<00:28, 16.42it/s]  8%|▊         | 38/500 [00:02<00:28, 16.39it/s]  8%|▊         | 40/500 [00:02<00:28, 16.29it/s]  8%|▊         | 42/500 [00:02<00:27, 16.38it/s]  9%|▉         | 44/500 [00:02<00:28, 16.28it/s]  9%|▉         | 46/500 [00:02<00:27, 16.34it/s] 10%|▉         | 48/500 [00:02<00:27, 16.49it/s] 10%|█         | 50/500 [00:03<00:27, 16.49it/s] 10%|█         | 52/500 [00:03<00:27, 16.32it/s] 11%|█         | 54/500 [00:03<00:27, 16.45it/s] 11%|█         | 56/500 [00:03<00:26, 16.49it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.36it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.15it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.31it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.41it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.48it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.75it/s] 14%|█▍        | 70/500 [00:04<00:29, 14.53it/s] 14%|█▍        | 72/500 [00:04<00:30, 13.90it/s] 15%|█▍        | 74/500 [00:04<00:29, 14.58it/s] 15%|█▌        | 76/500 [00:04<00:30, 14.11it/s] 16%|█▌        | 78/500 [00:04<00:31, 13.57it/s] 16%|█▌        | 80/500 [00:05<00:31, 13.22it/s] 16%|█▋        | 82/500 [00:05<00:30, 13.71it/s] 17%|█▋        | 84/500 [00:05<00:28, 14.43it/s] 17%|█▋        | 86/500 [00:05<00:27, 14.93it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.39it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.75it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.00it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.25it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.28it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.35it/s] 20%|██        | 100/500 [00:06<00:24, 16.38it/s] 20%|██        | 102/500 [00:06<00:24, 16.39it/s] 21%|██        | 104/500 [00:06<00:24, 16.37it/s] 21%|██        | 106/500 [00:06<00:24, 16.38it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.45it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.56it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.52it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.49it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.48it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.42it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.37it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.42it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.42it/s]Epoch:  1  	Training Loss: 0.04459550604224205
Test Loss:  1069.882568359375
Valid Loss:  1060.28857421875
Epoch:  2  	Training Loss: 1063.6455078125
Test Loss:  223389620895744.0
Valid Loss:  224498594873344.0
Epoch:  3  	Training Loss: 224257422393344.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.34it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.37it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.36it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.30it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.41it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.47it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.42it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.47it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.33it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.47it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.50it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.53it/s] 30%|███       | 150/500 [00:09<00:21, 16.58it/s] 30%|███       | 152/500 [00:09<00:20, 16.61it/s] 31%|███       | 154/500 [00:09<00:20, 16.64it/s] 31%|███       | 156/500 [00:09<00:20, 16.66it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.65it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.49it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.50it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.44it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.50it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.59it/s] 34%|███▍      | 170/500 [00:10<00:19, 16.65it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.69it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.71it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.68it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.70it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.63it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.54it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.52it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.50it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.49it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.53it/s] 38%|███▊      | 192/500 [00:11<00:19, 16.20it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.18it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.15it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.28it/s] 40%|████      | 200/500 [00:12<00:19, 15.29it/s] 40%|████      | 202/500 [00:12<00:19, 15.11it/s] 41%|████      | 204/500 [00:12<00:19, 15.52it/s] 41%|████      | 206/500 [00:12<00:18, 15.80it/s] 42%|████▏     | 208/500 [00:12<00:18, 16.03it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.92it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.06it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.19it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.29it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.37it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.42it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.54it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.47it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.52it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.61it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.47it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.38it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.49it/s] 47%|████▋     | 236/500 [00:14<00:15, 16.55it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.67it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.61it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.60it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.64it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.72it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.69it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:14, 16.75it/s] 50%|█████     | 252/500 [00:15<00:14, 16.68it/s] 51%|█████     | 254/500 [00:15<00:14, 16.58it/s] 51%|█████     | 256/500 [00:15<00:14, 16.50it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.55it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.46it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.57it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.43it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.50it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.46it/s] 54%|█████▍    | 270/500 [00:16<00:14, 15.99it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.05it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.23it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.29it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.42it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.50it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.52it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.53it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.55it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.61it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.69it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.56it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.50it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.46it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.48it/s] 60%|██████    | 300/500 [00:18<00:12, 16.43it/s] 60%|██████    | 302/500 [00:18<00:12, 16.36it/s] 61%|██████    | 304/500 [00:18<00:11, 16.36it/s] 61%|██████    | 306/500 [00:18<00:11, 16.42it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.49it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.52it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.48it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.48it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.55it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.41it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.32it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.35it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.32it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.39it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.44it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.45it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.52it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.59it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.50it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.41it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.45it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.18it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.22it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.34it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.36it/s] 70%|███████   | 350/500 [00:21<00:09, 15.61it/s] 70%|███████   | 352/500 [00:21<00:09, 15.90it/s] 71%|███████   | 354/500 [00:21<00:09, 16.00it/s] 71%|███████   | 356/500 [00:21<00:08, 16.17it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.33it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.48it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.49it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.56it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.60it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.59it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.47it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.50it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.51it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.45it/s] 76%|███████▌  | 378/500 [00:23<00:07, 15.28it/s] 76%|███████▌  | 380/500 [00:23<00:08, 14.29it/s] 76%|███████▋  | 382/500 [00:23<00:08, 13.89it/s] 77%|███████▋  | 384/500 [00:23<00:07, 14.61it/s] 77%|███████▋  | 386/500 [00:23<00:07, 15.05it/s] 78%|███████▊  | 388/500 [00:23<00:07, 15.43it/s] 78%|███████▊  | 390/500 [00:24<00:06, 15.78it/s] 78%|███████▊  | 392/500 [00:24<00:07, 15.29it/s] 79%|███████▉  | 394/500 [00:24<00:07, 14.29it/s] 79%|███████▉  | 396/500 [00:24<00:07, 13.75it/s] 80%|███████▉  | 398/500 [00:24<00:07, 14.34it/s] 80%|████████  | 400/500 [00:24<00:06, 15.01it/s] 80%|████████  | 402/500 [00:24<00:06, 15.46it/s] 81%|████████  | 404/500 [00:25<00:06, 15.81it/s] 81%|████████  | 406/500 [00:25<00:05, 16.06it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.25it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.38it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.52it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.57it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.64it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.64it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.70it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.73it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.77it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.76it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.75it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.60it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.59it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.57it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.58it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.47it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.45it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.44it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.47it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.49it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.23it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.21it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.30it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.33it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.43it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.49it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.38it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.41it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.52it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.60it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.58it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.58it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.58it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.66it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.60it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.52it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.49it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.53it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.57it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.62it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.64it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.46it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.42it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.47it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.46it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.20it/s]100%|██████████| 500/500 [00:30<00:00, 16.33it/s]100%|██████████| 500/500 [00:30<00:00, 16.22it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  19
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:39,  6.21s/it]  1%|          | 3/500 [00:06<13:46,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:11,  1.18s/it]  7%|▋         | 33/500 [00:26<06:34,  1.19it/s]  7%|▋         | 35/500 [00:26<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:55,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:20,  2.25it/s] 10%|▉         | 49/500 [00:33<02:28,  3.03it/s] 10%|█         | 51/500 [00:40<08:45,  1.17s/it] 11%|█         | 53/500 [00:40<06:15,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:47<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:53<08:22,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:58,  1.19it/s]Epoch:  1  	Training Loss: 0.04459550604224205
Test Loss:  69.06776428222656
Valid Loss:  67.80296325683594
Epoch:  2  	Training Loss: 68.25324249267578
Test Loss:  1204.7197265625
Valid Loss:  1212.14892578125
Epoch:  3  	Training Loss: 1211.135498046875
Test Loss:  2.856037139892578
Valid Loss:  2.8162331581115723
Epoch:  4  	Training Loss: 2.836650848388672
Test Loss:  2.603642225265503
Valid Loss:  2.5650949478149414
Epoch:  5  	Training Loss: 2.5846729278564453
Test Loss:  2.373467445373535
Valid Loss:  2.336193561553955
Epoch:  6  	Training Loss: 2.3549585342407227
Test Loss:  2.1635851860046387
Valid Loss:  2.127593994140625
Epoch:  7  	Training Loss: 2.145570755004883
Test Loss:  1.9722273349761963
Valid Loss:  1.9375216960906982
Epoch:  8  	Training Loss: 1.9547369480133057
Test Loss:  1.7977814674377441
Valid Loss:  1.7643567323684692
Epoch:  9  	Training Loss: 1.7808359861373901
Test Loss:  1.6387686729431152
Valid Loss:  1.6066157817840576
Epoch:  10  	Training Loss: 1.6223846673965454
Test Loss:  1.4938393831253052
Valid Loss:  1.4629440307617188
Epoch:  11  	Training Loss: 1.4780281782150269
Test Loss:  1.3617576360702515
Valid Loss:  1.3321021795272827
Epoch:  12  	Training Loss: 1.3465265035629272
Test Loss:  1.240938425064087
Valid Loss:  1.2125051021575928
Epoch:  13  	Training Loss: 1.2262918949127197
Test Loss:  1.130946397781372
Valid Loss:  1.1037102937698364
Epoch:  14  	Training Loss: 1.116884708404541
Test Loss:  1.0308105945587158
Valid Loss:  1.0047452449798584
Epoch:  15  	Training Loss: 1.0173311233520508
Test Loss:  0.9396454691886902
Valid Loss:  0.9147221446037292
Epoch:  16  	Training Loss: 0.9267431497573853
Test Loss:  0.8566470146179199
Valid Loss:  0.8328355550765991
Epoch:  17  	Training Loss: 0.8443145751953125
Test Loss:  0.7810815572738647
Valid Loss:  0.75835120677948
Epoch:  18  	Training Loss: 0.769310474395752
Test Loss:  0.7122831344604492
Valid Loss:  0.6906019449234009
Epoch:  19  	Training Loss: 0.7010630965232849
Test Loss:  0.6496438980102539
Valid Loss:  0.6289793252944946
Epoch:  20  	Training Loss: 0.6389632225036621
Test Loss:  0.5926114320755005
Valid Loss:  0.5729309320449829
Epoch:  21  	Training Loss: 0.5824577808380127
Test Loss:  0.540682315826416
Valid Loss:  0.521952748298645
Epoch:  22  	Training Loss: 0.5310421586036682
Test Loss:  0.49366170167922974
Valid Loss:  0.4758458137512207
Epoch:  23  	Training Loss: 0.484518826007843
Test Loss:  0.45079630613327026
Valid Loss:  0.43386226892471313
Epoch:  24  	Training Loss: 0.44213661551475525
Test Loss:  0.4117211401462555
Valid Loss:  0.3956374228000641
Epoch:  25  	Training Loss: 0.40353041887283325
Test Loss:  0.37610340118408203
Valid Loss:  0.3608386516571045
Epoch:  26  	Training Loss: 0.3683668375015259
Test Loss:  0.34363824129104614
Valid Loss:  0.3291616439819336
Epoch:  27  	Training Loss: 0.33634108304977417
Test Loss:  0.3140479326248169
Valid Loss:  0.30032914876937866
Epoch:  28  	Training Loss: 0.30717530846595764
Test Loss:  0.28707873821258545
Valid Loss:  0.2740880250930786
Epoch:  29  	Training Loss: 0.28061574697494507
Test Loss:  0.2624989151954651
Valid Loss:  0.25020715594291687
Epoch:  30  	Training Loss: 0.25643080472946167
Test Loss:  0.24009719491004944
Valid Loss:  0.2284759283065796
Epoch:  31  	Training Loss: 0.23440921306610107
Test Loss:  0.2196807563304901
Valid Loss:  0.20870231091976166
Epoch:  32  	Training Loss: 0.21435846388339996
Test Loss:  0.2010345458984375
Valid Loss:  0.19067120552062988
Epoch:  33  	Training Loss: 0.1960628479719162
Test Loss:  0.18409579992294312
Valid Loss:  0.1743197739124298
Epoch:  34  	Training Loss: 0.1794598400592804
Test Loss:  0.16870099306106567
Valid Loss:  0.15948554873466492
Epoch:  35  	Training Loss: 0.1643863022327423
Test Loss:  0.1547030508518219
Valid Loss:  0.1460224986076355
Epoch:  36  	Training Loss: 0.15069562196731567
Test Loss:  0.14196960628032684
Valid Loss:  0.13379934430122375
Epoch:  37  	Training Loss: 0.13825593888759613
Test Loss:  0.1303815096616745
Valid Loss:  0.12269794940948486
Epoch:  38  	Training Loss: 0.1269485354423523
Test Loss:  0.11983135342597961
Valid Loss:  0.11261191219091415
Epoch:  39  	Training Loss: 0.11666650325059891
Test Loss:  0.11022226512432098
Valid Loss:  0.10344529151916504
Epoch:  40  	Training Loss: 0.10731340199708939
Test Loss:  0.1014668419957161
Valid Loss:  0.09511162340641022
Epoch:  41  	Training Loss: 0.09880231320858002
Test Loss:  0.09380879998207092
Valid Loss:  0.08768410980701447
Epoch:  42  	Training Loss: 0.09121952950954437
Test Loss:  0.08928902447223663
Valid Loss:  0.08287376910448074
Epoch:  43  	Training Loss: 0.08641248941421509
Test Loss:  0.08725126087665558
Valid Loss:  0.0806034579873085
Epoch:  44  	Training Loss: 0.0841359943151474
Test Loss:  0.0862872451543808
Valid Loss:  0.07941506057977676
Epoch:  45  	Training Loss: 0.08304701000452042
Test Loss:  0.08568572998046875
Valid Loss:  0.07876548171043396
Epoch:  46  	Training Loss: 0.08246149122714996
Test Loss:  0.08528417348861694
Valid Loss:  0.0782979279756546
Epoch:  47  	Training Loss: 0.08210796117782593
Test Loss:  0.08499588817358017
Valid Loss:  0.07801222801208496
Epoch:  48  	Training Loss: 0.0818791463971138
Test Loss:  0.08480983972549438
Valid Loss:  0.0778331309556961
Epoch:  49  	Training Loss: 0.08171723783016205
Test Loss:  0.08470244705677032
Valid Loss:  0.07772196829319
Epoch:  50  	Training Loss: 0.08161520957946777
Test Loss:  0.08464024215936661
Valid Loss:  0.07765164971351624
Epoch:  51  	Training Loss: 0.08155852556228638
Test Loss:  0.08459707349538803
Valid Loss:  0.07760597765445709
Epoch:  52  	Training Loss: 0.08151926100254059
Test Loss:  0.08456399291753769
Valid Loss:  0.07757788896560669
Epoch:  53  	Training Loss: 0.08149424195289612
Test Loss:  0.08454117178916931
Valid Loss:  0.0775601863861084
Epoch:  54  	Training Loss: 0.0814761072397232
Test Loss:  0.08452366292476654
Valid Loss:  0.07754688709974289
Epoch:  55  	Training Loss: 0.08146260678768158
Test Loss:  0.0845109075307846
Valid Loss:  0.07754024863243103
Epoch:  56  	Training Loss: 0.08145362138748169
Test Loss:  0.08449968695640564
Valid Loss:  0.07753507047891617
Epoch:  57  	Training Loss: 0.0814473032951355
Test Loss:  0.08449284732341766
Valid Loss:  0.07753218710422516
Epoch:  58  	Training Loss: 0.0814429372549057
Test Loss:  0.08448688685894012
Valid Loss:  0.07752957940101624
Epoch:  59  	Training Loss: 0.08143866062164307
Test Loss:  0.0844811499118805
Valid Loss:  0.07752703875303268
Epoch:  60  	Training Loss: 0.08143475651741028
Test Loss:  0.08447706699371338
Valid Loss:  0.07752488553524017
Epoch:  61  	Training Loss: 0.08143166452646255
Test Loss:  0.08447350561618805
Valid Loss:  0.07752276957035065
Epoch:  62  	Training Loss: 0.08142862468957901
Test Loss:  0.08447040617465973
Valid Loss:  0.07752087712287903
Epoch:  63  	Training Loss: 0.08142594993114471
Test Loss:  0.08446778357028961
Valid Loss:  0.07751995325088501
Epoch:  64  	Training Loss: 0.08142384886741638
Test Loss:  0.0844653844833374
Valid Loss:  0.07751961797475815
Epoch:  65  	Training Loss: 0.08142244070768356
Test Loss:  0.08446361124515533
Valid Loss:  0.07751938700675964
Epoch:  66  	Training Loss: 0.08142147958278656
Test Loss:  0.08446204662322998
Valid Loss:  0.07751917839050293
Epoch:  67  	Training Loss: 0.08142069727182388
Test Loss:  0.08446050435304642
Valid Loss:  0.07751897722482681
Epoch:  68  	Training Loss: 0.0814199298620224
Test Loss:  0.08445896953344345
Valid Loss:  0.0775187760591507
Epoch:  69  	Training Loss: 0.08141916990280151
Test Loss:  0.08445745706558228
Valid Loss:  0.07751859724521637
Epoch:  70  	Training Loss: 0.08141841739416122
Test Loss:  0.08445623517036438
Valid Loss:  0.07751840353012085
Epoch:  71  	Training Loss: 0.08141767978668213
Test Loss:  0.08445508033037186
Valid Loss:  0.07751823961734772
Epoch:  72  	Training Loss: 0.08141694962978363
Test Loss:  0.08445410430431366
Valid Loss:  0.0775180384516716
Epoch:  73  	Training Loss: 0.08141621202230453
Test Loss:  0.0844535306096077
Valid Loss:  0.07751783728599548
Epoch:  74  	Training Loss: 0.08141547441482544
Test Loss:  0.08445297181606293
 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:00<05:57,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:01<03:07,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:07<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:48,  1.17s/it] 21%|██        | 103/500 [01:14<05:36,  1.18it/s] 21%|██        | 105/500 [01:14<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:14<03:00,  2.17it/s] 22%|██▏       | 109/500 [01:15<02:13,  2.93it/s] 22%|██▏       | 111/500 [01:21<07:45,  1.20s/it] 23%|██▎       | 113/500 [01:21<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:21<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:21<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:22<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:28<07:33,  1.20s/it] 25%|██▍       | 123/500 [01:28<05:23,  1.16it/s] 25%|██▌       | 125/500 [01:28<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:28<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:28<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:35<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:35<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:42<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:42<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:42<03:35,  1.64it/s]Valid Loss:  0.07751765847206116
Epoch:  75  	Training Loss: 0.08141475915908813
Test Loss:  0.08445242047309875
Valid Loss:  0.07751747965812683
Epoch:  76  	Training Loss: 0.08141404390335083
Test Loss:  0.08445186913013458
Valid Loss:  0.0775173008441925
Epoch:  77  	Training Loss: 0.08141334354877472
Test Loss:  0.08445137739181519
Valid Loss:  0.07751714438199997
Epoch:  78  	Training Loss: 0.08141277730464935
Test Loss:  0.08445090055465698
Valid Loss:  0.07751699537038803
Epoch:  79  	Training Loss: 0.08141222596168518
Test Loss:  0.08445041626691818
Valid Loss:  0.07751685380935669
Epoch:  80  	Training Loss: 0.0814116820693016
Test Loss:  0.08445000648498535
Valid Loss:  0.07751673460006714
Epoch:  81  	Training Loss: 0.08141124248504639
Test Loss:  0.08444958925247192
Valid Loss:  0.07751661539077759
Epoch:  82  	Training Loss: 0.08141085505485535
Test Loss:  0.08444922417402267
Valid Loss:  0.07751651108264923
Epoch:  83  	Training Loss: 0.08141055703163147
Test Loss:  0.084448903799057
Valid Loss:  0.07751642167568207
Epoch:  84  	Training Loss: 0.08141028881072998
Test Loss:  0.08444859087467194
Valid Loss:  0.0775163471698761
Epoch:  85  	Training Loss: 0.08141006529331207
Test Loss:  0.08444832265377045
Valid Loss:  0.07751626521348953
Epoch:  86  	Training Loss: 0.08140987157821655
Test Loss:  0.08444805443286896
Valid Loss:  0.07751619815826416
Epoch:  87  	Training Loss: 0.08140967786312103
Test Loss:  0.08444778621196747
Valid Loss:  0.07751612365245819
Epoch:  88  	Training Loss: 0.0814094990491867
Test Loss:  0.08444751799106598
Valid Loss:  0.07751606404781342
Epoch:  89  	Training Loss: 0.08140933513641357
Test Loss:  0.08444728702306747
Valid Loss:  0.07751598954200745
Epoch:  90  	Training Loss: 0.08140919357538223
Test Loss:  0.08444707095623016
Valid Loss:  0.07751594483852386
Epoch:  91  	Training Loss: 0.08140905201435089
Test Loss:  0.08444690704345703
Valid Loss:  0.07751588523387909
Epoch:  92  	Training Loss: 0.08140893280506134
Test Loss:  0.08444678038358688
Valid Loss:  0.07751582562923431
Epoch:  93  	Training Loss: 0.08140882849693298
Test Loss:  0.08444663882255554
Valid Loss:  0.07751576602458954
Epoch:  94  	Training Loss: 0.08140872418880463
Test Loss:  0.08444651961326599
Valid Loss:  0.07751571387052536
Epoch:  95  	Training Loss: 0.08140861243009567
Test Loss:  0.08444638550281525
Valid Loss:  0.07751565426588058
Epoch:  96  	Training Loss: 0.08140850812196732
Test Loss:  0.0844462513923645
Valid Loss:  0.0775156021118164
Epoch:  97  	Training Loss: 0.08140842616558075
Test Loss:  0.08444616198539734
Valid Loss:  0.07751554995775223
Epoch:  98  	Training Loss: 0.08140836656093597
Test Loss:  0.08444605767726898
Valid Loss:  0.07751550525426865
Epoch:  99  	Training Loss: 0.0814083069562912
Test Loss:  0.08444596827030182
Valid Loss:  0.07751545310020447
Epoch:  100  	Training Loss: 0.08140824735164642
Test Loss:  0.08444589376449585
Valid Loss:  0.07751540839672089
Epoch:  101  	Training Loss: 0.08140820264816284
Test Loss:  0.08444580435752869
Valid Loss:  0.07751535624265671
Epoch:  102  	Training Loss: 0.08140815794467926
Test Loss:  0.08444574475288391
Valid Loss:  0.07751533389091492
Epoch:  103  	Training Loss: 0.08140812814235687
Test Loss:  0.08444568514823914
Valid Loss:  0.07751530408859253
Epoch:  104  	Training Loss: 0.08140809834003448
Test Loss:  0.08444562554359436
Valid Loss:  0.07751528173685074
Epoch:  105  	Training Loss: 0.0814080685377121
Test Loss:  0.08444558084011078
Valid Loss:  0.07751525193452835
Epoch:  106  	Training Loss: 0.08140803873538971
Test Loss:  0.084445521235466
Valid Loss:  0.07751522958278656
Epoch:  107  	Training Loss: 0.08140800893306732
Test Loss:  0.08444546163082123
Valid Loss:  0.07751520723104477
Epoch:  108  	Training Loss: 0.08140797913074493
Test Loss:  0.08444540202617645
Valid Loss:  0.07751518487930298
Epoch:  109  	Training Loss: 0.08140794932842255
Test Loss:  0.08444534242153168
Valid Loss:  0.07751515507698059
Epoch:  110  	Training Loss: 0.08140792697668076
Test Loss:  0.08444530516862869
Valid Loss:  0.0775151401758194
Epoch:  111  	Training Loss: 0.08140791207551956
Test Loss:  0.08444525301456451
Valid Loss:  0.07751511037349701
Epoch:  112  	Training Loss: 0.08140788972377777
Test Loss:  0.08444522321224213
Valid Loss:  0.07751509547233582
Epoch:  113  	Training Loss: 0.08140787482261658
Test Loss:  0.08444518595933914
Valid Loss:  0.07751508057117462
Epoch:  114  	Training Loss: 0.08140785992145538
Test Loss:  0.08444514870643616
Valid Loss:  0.07751506567001343
Epoch:  115  	Training Loss: 0.08140783756971359
Test Loss:  0.08444512635469437
Valid Loss:  0.07751504331827164
Epoch:  116  	Training Loss: 0.0814078226685524
Test Loss:  0.08444510400295258
Valid Loss:  0.07751502841711044
Epoch:  117  	Training Loss: 0.0814078077673912
Test Loss:  0.08444508165121078
Valid Loss:  0.07751500606536865
Epoch:  118  	Training Loss: 0.08140778541564941
Test Loss:  0.084445059299469
Valid Loss:  0.07751499116420746
Epoch:  119  	Training Loss: 0.08140777796506882
Test Loss:  0.0844450294971466
Valid Loss:  0.07751497626304626
Epoch:  120  	Training Loss: 0.08140776306390762
Test Loss:  0.08444500714540482
Valid Loss:  0.07751496136188507
Epoch:  121  	Training Loss: 0.08140774816274643
Test Loss:  0.08444498479366302
Valid Loss:  0.07751494646072388
Epoch:  122  	Training Loss: 0.08140773326158524
Test Loss:  0.08444496989250183
Valid Loss:  0.07751493155956268
Epoch:  123  	Training Loss: 0.08140771090984344
Test Loss:  0.08444494009017944
Valid Loss:  0.07751491665840149
Epoch:  124  	Training Loss: 0.08140769600868225
Test Loss:  0.08444491773843765
Valid Loss:  0.0775149017572403
Epoch:  125  	Training Loss: 0.08140768855810165
Test Loss:  0.08444488793611526
Valid Loss:  0.0775148794054985
Epoch:  126  	Training Loss: 0.08140766620635986
Test Loss:  0.08444487303495407
Valid Loss:  0.07751485705375671
Epoch:  127  	Training Loss: 0.08140765130519867
Test Loss:  0.08444484323263168
Valid Loss:  0.07751484215259552
Epoch:  128  	Training Loss: 0.08140763640403748
Test Loss:  0.08444482833147049
Valid Loss:  0.07751482725143433
Epoch:  129  	Training Loss: 0.08140762150287628
Test Loss:  0.0844448059797287
Valid Loss:  0.07751481235027313
Epoch:  130  	Training Loss: 0.08140759915113449
Test Loss:  0.0844447910785675
Valid Loss:  0.07751480489969254
Epoch:  131  	Training Loss: 0.0814075917005539
Test Loss:  0.08444476127624512
Valid Loss:  0.07751478254795074
Epoch:  132  	Training Loss: 0.0814075693488121
Test Loss:  0.08444474637508392
Valid Loss:  0.07751476764678955
Epoch:  133  	Training Loss: 0.08140755444765091
Test Loss:  0.08444472402334213
Valid Loss:  0.07751475274562836
Epoch:  134  	Training Loss: 0.08140754699707031
Test Loss:  0.08444470167160034
Valid Loss:  0.07751473784446716
Epoch:  135  	Training Loss: 0.08140752464532852
Test Loss:  0.08444468677043915
Valid Loss:  0.07751472294330597
Epoch:  136  	Training Loss: 0.08140750974416733
Test Loss:  0.08444466441869736
Valid Loss:  0.07751470804214478
Epoch:  137  	Training Loss: 0.08140748739242554
Test Loss:  0.08444464206695557
Valid Loss:  0.07751468569040298
Epoch:  138  	Training Loss: 0.08140747249126434
Test Loss:  0.08444462716579437
Valid Loss:  0.07751467078924179
Epoch:  139  	Training Loss: 0.08140745759010315
Test Loss:  0.08444461226463318
Valid Loss:  0.0775146484375
Epoch:  140  	Training Loss: 0.08140744268894196
Test Loss:  0.08444458246231079
Valid Loss:  0.0775146409869194
Epoch:  141  	Training Loss: 0.08140742778778076
Test Loss:  0.0844445750117302
Valid Loss:  0.07751461863517761
Epoch:  142  	Training Loss: 0.08140741288661957
Test Loss:  0.0844445526599884
Valid Loss:  0.07751460373401642
Epoch:  143  	Training Loss: 0.08140739798545837
Test Loss:  0.08444453775882721
Valid Loss:  0.07751458883285522
Epoch:  144  	Training Loss: 0.08140738308429718
Test Loss:  0.08444452285766602
Valid Loss:  0.07751457393169403
Epoch:  145  	Training Loss: 0.08140736818313599
Test Loss:  0.08444450050592422
Valid Loss:  0.07751455903053284
Epoch:  146  	Training Loss: 0.08140735328197479
Test Loss:  0.08444448560476303
Valid Loss:  0.07751454412937164
 29%|██▉       | 147/500 [01:42<02:37,  2.25it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.02it/s] 30%|███       | 151/500 [01:49<06:57,  1.20s/it] 31%|███       | 153/500 [01:49<04:58,  1.16it/s] 31%|███       | 155/500 [01:49<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:49<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:49<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:55<06:42,  1.19s/it] 33%|███▎      | 163/500 [01:56<04:47,  1.17it/s] 33%|███▎      | 165/500 [01:56<03:26,  1.62it/s] 33%|███▎      | 167/500 [01:56<02:30,  2.22it/s] 34%|███▍      | 169/500 [01:56<01:51,  2.98it/s] 34%|███▍      | 171/500 [02:02<06:23,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:33,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:16,  1.65it/s] 35%|███▌      | 177/500 [02:03<02:23,  2.26it/s] 36%|███▌      | 179/500 [02:03<01:45,  3.03it/s] 36%|███▌      | 181/500 [02:09<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:27,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:16<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:16<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:16<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.01it/s] 40%|████      | 201/500 [02:23<05:47,  1.16s/it] 41%|████      | 203/500 [02:23<04:08,  1.20it/s] 41%|████      | 205/500 [02:23<02:58,  1.65it/s] 41%|████▏     | 207/500 [02:23<02:09,  2.26it/s] 42%|████▏     | 209/500 [02:23<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:29<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:30<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:30<02:07,  2.21it/s]Epoch:  147  	Training Loss: 0.0814073383808136
Test Loss:  0.08444446325302124
Valid Loss:  0.07751452922821045
Epoch:  148  	Training Loss: 0.0814073234796524
Test Loss:  0.08444443345069885
Valid Loss:  0.07751452177762985
Epoch:  149  	Training Loss: 0.08140730857849121
Test Loss:  0.08444441854953766
Valid Loss:  0.07751449942588806
Epoch:  150  	Training Loss: 0.08140729367733002
Test Loss:  0.08444440364837646
Valid Loss:  0.07751448452472687
Epoch:  151  	Training Loss: 0.08140728622674942
Test Loss:  0.08444438874721527
Valid Loss:  0.07751446962356567
Epoch:  152  	Training Loss: 0.08140726387500763
Test Loss:  0.08444437384605408
Valid Loss:  0.07751446217298508
Epoch:  153  	Training Loss: 0.08140725642442703
Test Loss:  0.08444435149431229
Valid Loss:  0.07751444727182388
Epoch:  154  	Training Loss: 0.08140724152326584
Test Loss:  0.0844443291425705
Valid Loss:  0.07751442492008209
Epoch:  155  	Training Loss: 0.08140721917152405
Test Loss:  0.0844443142414093
Valid Loss:  0.0775144100189209
Epoch:  156  	Training Loss: 0.08140720427036285
Test Loss:  0.08444429188966751
Valid Loss:  0.0775143951177597
Epoch:  157  	Training Loss: 0.08140718936920166
Test Loss:  0.08444426953792572
Valid Loss:  0.07751438021659851
Epoch:  158  	Training Loss: 0.08140717446804047
Test Loss:  0.08444425463676453
Valid Loss:  0.07751436531543732
Epoch:  159  	Training Loss: 0.08140715956687927
Test Loss:  0.08444423973560333
Valid Loss:  0.07751434296369553
Epoch:  160  	Training Loss: 0.08140714466571808
Test Loss:  0.08444420993328094
Valid Loss:  0.07751433551311493
Epoch:  161  	Training Loss: 0.08140712976455688
Test Loss:  0.08444419503211975
Valid Loss:  0.07751432061195374
Epoch:  162  	Training Loss: 0.08140711486339569
Test Loss:  0.08444418013095856
Valid Loss:  0.07751429826021194
Epoch:  163  	Training Loss: 0.0814070999622345
Test Loss:  0.08444415777921677
Valid Loss:  0.07751428335905075
Epoch:  164  	Training Loss: 0.0814070850610733
Test Loss:  0.08444415032863617
Valid Loss:  0.07751426100730896
Epoch:  165  	Training Loss: 0.08140707015991211
Test Loss:  0.08444412052631378
Valid Loss:  0.07751425355672836
Epoch:  166  	Training Loss: 0.08140705525875092
Test Loss:  0.08444410562515259
Valid Loss:  0.07751423120498657
Epoch:  167  	Training Loss: 0.08140703290700912
Test Loss:  0.0844440758228302
Valid Loss:  0.07751421630382538
Epoch:  168  	Training Loss: 0.08140702545642853
Test Loss:  0.084444060921669
Valid Loss:  0.07751420140266418
Epoch:  169  	Training Loss: 0.08140699565410614
Test Loss:  0.08444404602050781
Valid Loss:  0.07751418650150299
Epoch:  170  	Training Loss: 0.08140698820352554
Test Loss:  0.08444402366876602
Valid Loss:  0.0775141716003418
Epoch:  171  	Training Loss: 0.08140697330236435
Test Loss:  0.08444400131702423
Valid Loss:  0.0775141492486
Epoch:  172  	Training Loss: 0.08140695840120316
Test Loss:  0.08444398641586304
Valid Loss:  0.07751412689685822
Epoch:  173  	Training Loss: 0.08140693604946136
Test Loss:  0.08444396406412125
Valid Loss:  0.07751411944627762
Epoch:  174  	Training Loss: 0.08140692114830017
Test Loss:  0.08444394171237946
Valid Loss:  0.07751410454511642
Epoch:  175  	Training Loss: 0.08140690624713898
Test Loss:  0.08444392681121826
Valid Loss:  0.07751408964395523
Epoch:  176  	Training Loss: 0.08140689134597778
Test Loss:  0.08444390445947647
Valid Loss:  0.07751407474279404
Epoch:  177  	Training Loss: 0.08140687644481659
Test Loss:  0.08444388210773468
Valid Loss:  0.07751405239105225
Epoch:  178  	Training Loss: 0.0814068615436554
Test Loss:  0.08444386720657349
Valid Loss:  0.07751403748989105
Epoch:  179  	Training Loss: 0.0814068466424942
Test Loss:  0.0844438448548317
Valid Loss:  0.07751402258872986
Epoch:  180  	Training Loss: 0.08140683174133301
Test Loss:  0.0844438374042511
Valid Loss:  0.07751400768756866
Epoch:  181  	Training Loss: 0.08140681684017181
Test Loss:  0.08444380760192871
Valid Loss:  0.07751399278640747
Epoch:  182  	Training Loss: 0.08140679448843002
Test Loss:  0.08444379270076752
Valid Loss:  0.07751397788524628
Epoch:  183  	Training Loss: 0.08140678703784943
Test Loss:  0.08444377034902573
Valid Loss:  0.07751396298408508
Epoch:  184  	Training Loss: 0.08140677213668823
Test Loss:  0.08444376289844513
Valid Loss:  0.07751394808292389
Epoch:  185  	Training Loss: 0.08140675723552704
Test Loss:  0.08444373309612274
Valid Loss:  0.0775139331817627
Epoch:  186  	Training Loss: 0.08140674233436584
Test Loss:  0.08444371819496155
Valid Loss:  0.0775139182806015
Epoch:  187  	Training Loss: 0.08140672743320465
Test Loss:  0.08444370329380035
Valid Loss:  0.07751390337944031
Epoch:  188  	Training Loss: 0.08140671253204346
Test Loss:  0.08444368839263916
Valid Loss:  0.07751388847827911
Epoch:  189  	Training Loss: 0.08140669763088226
Test Loss:  0.08444367349147797
Valid Loss:  0.07751387357711792
Epoch:  190  	Training Loss: 0.08140668272972107
Test Loss:  0.08444365113973618
Valid Loss:  0.07751385867595673
Epoch:  191  	Training Loss: 0.08140666037797928
Test Loss:  0.08444363623857498
Valid Loss:  0.07751385867595673
Epoch:  192  	Training Loss: 0.08140665292739868
Test Loss:  0.08444361388683319
Valid Loss:  0.07751382887363434
Epoch:  193  	Training Loss: 0.08140663802623749
Test Loss:  0.084443598985672
Valid Loss:  0.07751381397247314
Epoch:  194  	Training Loss: 0.0814066231250763
Test Loss:  0.0844435766339302
Valid Loss:  0.07751379907131195
Epoch:  195  	Training Loss: 0.0814066082239151
Test Loss:  0.08444356173276901
Valid Loss:  0.07751378417015076
Epoch:  196  	Training Loss: 0.08140658587217331
Test Loss:  0.08444353938102722
Valid Loss:  0.07751376926898956
Epoch:  197  	Training Loss: 0.08140657842159271
Test Loss:  0.08444352447986603
Valid Loss:  0.07751375436782837
Epoch:  198  	Training Loss: 0.08140656352043152
Test Loss:  0.08444350212812424
Valid Loss:  0.07751373946666718
Epoch:  199  	Training Loss: 0.08140654116868973
Test Loss:  0.08444348722696304
Valid Loss:  0.07751372456550598
Epoch:  200  	Training Loss: 0.08140652626752853
Test Loss:  0.08444346487522125
Valid Loss:  0.07751370966434479
Epoch:  201  	Training Loss: 0.08140651136636734
Test Loss:  0.08444344997406006
Valid Loss:  0.0775136947631836
Epoch:  202  	Training Loss: 0.08140649646520615
Test Loss:  0.08444342762231827
Valid Loss:  0.0775136798620224
Epoch:  203  	Training Loss: 0.08140648156404495
Test Loss:  0.08444340527057648
Valid Loss:  0.07751365751028061
Epoch:  204  	Training Loss: 0.08140646666288376
Test Loss:  0.08444339036941528
Valid Loss:  0.07751365005970001
Epoch:  205  	Training Loss: 0.08140644431114197
Test Loss:  0.08444337546825409
Valid Loss:  0.07751363515853882
Epoch:  206  	Training Loss: 0.08140642940998077
Test Loss:  0.0844433605670929
Valid Loss:  0.07751362025737762
Epoch:  207  	Training Loss: 0.08140641450881958
Test Loss:  0.0844433456659317
Valid Loss:  0.07751360535621643
Epoch:  208  	Training Loss: 0.08140639960765839
Test Loss:  0.08444332331418991
Valid Loss:  0.07751358300447464
Epoch:  209  	Training Loss: 0.08140638470649719
Test Loss:  0.08444330841302872
Valid Loss:  0.07751356810331345
Epoch:  210  	Training Loss: 0.0814063623547554
Test Loss:  0.08444330096244812
Valid Loss:  0.07751356065273285
Epoch:  211  	Training Loss: 0.0814063549041748
Test Loss:  0.08444327116012573
Valid Loss:  0.07751354575157166
Epoch:  212  	Training Loss: 0.08140634000301361
Test Loss:  0.08444325625896454
Valid Loss:  0.07751352339982986
Epoch:  213  	Training Loss: 0.08140632510185242
Test Loss:  0.08444322645664215
Valid Loss:  0.07751350849866867
Epoch:  214  	Training Loss: 0.08140630275011063
Test Loss:  0.08444322645664215
Valid Loss:  0.07751349359750748
Epoch:  215  	Training Loss: 0.08140628784894943
Test Loss:  0.08444320410490036
Valid Loss:  0.07751347869634628
Epoch:  216  	Training Loss: 0.08140627294778824
Test Loss:  0.08444319665431976
Valid Loss:  0.07751346379518509
Epoch:  217  	Training Loss: 0.08140625059604645
Test Loss:  0.08444316685199738
Valid Loss:  0.07751345634460449
Epoch:  218  	Training Loss: 0.08140623569488525
Test Loss:  0.08444315195083618
Valid Loss:  0.0775134265422821
 44%|████▍     | 219/500 [02:30<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:36<05:30,  1.19s/it] 45%|████▍     | 223/500 [02:36<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:37<02:49,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:37<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:43<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:50<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.22it/s] 50%|████▉     | 249/500 [02:51<01:24,  2.98it/s] 50%|█████     | 251/500 [02:57<04:52,  1.18s/it] 51%|█████     | 253/500 [02:57<03:28,  1.19it/s] 51%|█████     | 255/500 [02:57<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:57<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:04<04:50,  1.22s/it] 53%|█████▎    | 263/500 [03:04<03:27,  1.14it/s] 53%|█████▎    | 265/500 [03:04<02:28,  1.58it/s] 53%|█████▎    | 267/500 [03:04<01:47,  2.16it/s] 54%|█████▍    | 269/500 [03:04<01:19,  2.91it/s] 54%|█████▍    | 271/500 [03:11<04:38,  1.21s/it] 55%|█████▍    | 273/500 [03:11<03:17,  1.15it/s] 55%|█████▌    | 275/500 [03:11<02:21,  1.59it/s] 55%|█████▌    | 277/500 [03:11<01:42,  2.17it/s] 56%|█████▌    | 279/500 [03:11<01:15,  2.93it/s] 56%|█████▌    | 281/500 [03:18<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:18<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:18<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:18<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:18<01:11,  2.96it/s]Epoch:  219  	Training Loss: 0.08140622079372406
Test Loss:  0.08444313704967499
Valid Loss:  0.07751341164112091
Epoch:  220  	Training Loss: 0.08140620589256287
Test Loss:  0.0844431221485138
Valid Loss:  0.07751340419054031
Epoch:  221  	Training Loss: 0.08140619099140167
Test Loss:  0.084443099796772
Valid Loss:  0.07751338183879852
Epoch:  222  	Training Loss: 0.08140617609024048
Test Loss:  0.08444307744503021
Valid Loss:  0.07751336693763733
Epoch:  223  	Training Loss: 0.08140616118907928
Test Loss:  0.08444307744503021
Valid Loss:  0.07751335948705673
Epoch:  224  	Training Loss: 0.0814061388373375
Test Loss:  0.08444304764270782
Valid Loss:  0.07751333713531494
Epoch:  225  	Training Loss: 0.0814061313867569
Test Loss:  0.08444303274154663
Valid Loss:  0.07751332223415375
Epoch:  226  	Training Loss: 0.0814061164855957
Test Loss:  0.08444300293922424
Valid Loss:  0.07751330733299255
Epoch:  227  	Training Loss: 0.08140609413385391
Test Loss:  0.08444300293922424
Valid Loss:  0.07751329243183136
Epoch:  228  	Training Loss: 0.08140607923269272
Test Loss:  0.08444297313690186
Valid Loss:  0.07751327753067017
Epoch:  229  	Training Loss: 0.08140606433153152
Test Loss:  0.08444295823574066
Valid Loss:  0.07751326262950897
Epoch:  230  	Training Loss: 0.08140604197978973
Test Loss:  0.08444294333457947
Valid Loss:  0.07751324772834778
Epoch:  231  	Training Loss: 0.08140602707862854
Test Loss:  0.08444293588399887
Valid Loss:  0.07751323282718658
Epoch:  232  	Training Loss: 0.08140601217746735
Test Loss:  0.08444291353225708
Valid Loss:  0.07751321792602539
Epoch:  233  	Training Loss: 0.08140599727630615
Test Loss:  0.08444289863109589
Valid Loss:  0.0775132104754448
Epoch:  234  	Training Loss: 0.08140598237514496
Test Loss:  0.08444288372993469
Valid Loss:  0.077513188123703
Epoch:  235  	Training Loss: 0.08140596747398376
Test Loss:  0.0844428613781929
Valid Loss:  0.0775131806731224
Epoch:  236  	Training Loss: 0.08140595257282257
Test Loss:  0.08444284647703171
Valid Loss:  0.07751316577196121
Epoch:  237  	Training Loss: 0.08140593767166138
Test Loss:  0.08444283157587051
Valid Loss:  0.07751314342021942
Epoch:  238  	Training Loss: 0.08140592277050018
Test Loss:  0.08444280922412872
Valid Loss:  0.07751312851905823
Epoch:  239  	Training Loss: 0.08140590041875839
Test Loss:  0.08444279432296753
Valid Loss:  0.07751311361789703
Epoch:  240  	Training Loss: 0.0814058855175972
Test Loss:  0.08444278687238693
Valid Loss:  0.07751310616731644
Epoch:  241  	Training Loss: 0.0814058780670166
Test Loss:  0.08444276452064514
Valid Loss:  0.07751308381557465
Epoch:  242  	Training Loss: 0.08140585571527481
Test Loss:  0.08444274961948395
Valid Loss:  0.07751306891441345
Epoch:  243  	Training Loss: 0.08140584081411362
Test Loss:  0.08444273471832275
Valid Loss:  0.07751305401325226
Epoch:  244  	Training Loss: 0.08140581846237183
Test Loss:  0.08444271236658096
Valid Loss:  0.07751303911209106
Epoch:  245  	Training Loss: 0.08140580356121063
Test Loss:  0.08444269001483917
Valid Loss:  0.07751302421092987
Epoch:  246  	Training Loss: 0.08140579611063004
Test Loss:  0.08444267511367798
Valid Loss:  0.07751300930976868
Epoch:  247  	Training Loss: 0.08140577375888824
Test Loss:  0.08444266021251678
Valid Loss:  0.07751299440860748
Epoch:  248  	Training Loss: 0.08140575885772705
Test Loss:  0.08444264531135559
Valid Loss:  0.07751297950744629
Epoch:  249  	Training Loss: 0.08140575140714645
Test Loss:  0.0844426229596138
Valid Loss:  0.0775129646062851
Epoch:  250  	Training Loss: 0.08140572160482407
Test Loss:  0.0844426080584526
Valid Loss:  0.0775129497051239
Epoch:  251  	Training Loss: 0.08140571415424347
Test Loss:  0.08444258570671082
Valid Loss:  0.07751293480396271
Epoch:  252  	Training Loss: 0.08140569925308228
Test Loss:  0.08444257825613022
Valid Loss:  0.07751291990280151
Epoch:  253  	Training Loss: 0.08140568435192108
Test Loss:  0.08444255590438843
Valid Loss:  0.07751291245222092
Epoch:  254  	Training Loss: 0.08140566200017929
Test Loss:  0.08444254100322723
Valid Loss:  0.07751289010047913
Epoch:  255  	Training Loss: 0.0814056470990181
Test Loss:  0.08444252610206604
Valid Loss:  0.07751287519931793
Epoch:  256  	Training Loss: 0.0814056396484375
Test Loss:  0.08444251120090485
Valid Loss:  0.07751286029815674
Epoch:  257  	Training Loss: 0.08140561729669571
Test Loss:  0.08444248884916306
Valid Loss:  0.07751284539699554
Epoch:  258  	Training Loss: 0.08140560239553452
Test Loss:  0.08444247394800186
Valid Loss:  0.07751283049583435
Epoch:  259  	Training Loss: 0.08140559494495392
Test Loss:  0.08444245159626007
Valid Loss:  0.07751281559467316
Epoch:  260  	Training Loss: 0.08140557259321213
Test Loss:  0.08444244414567947
Valid Loss:  0.07751280069351196
Epoch:  261  	Training Loss: 0.08140555024147034
Test Loss:  0.08444242179393768
Valid Loss:  0.07751278579235077
Epoch:  262  	Training Loss: 0.08140553534030914
Test Loss:  0.08444240689277649
Valid Loss:  0.07751277089118958
Epoch:  263  	Training Loss: 0.08140552788972855
Test Loss:  0.0844423919916153
Valid Loss:  0.07751276344060898
Epoch:  264  	Training Loss: 0.08140551298856735
Test Loss:  0.0844423770904541
Valid Loss:  0.07751274108886719
Epoch:  265  	Training Loss: 0.08140549063682556
Test Loss:  0.0844423696398735
Valid Loss:  0.07751273363828659
Epoch:  266  	Training Loss: 0.08140548318624496
Test Loss:  0.08444234728813171
Valid Loss:  0.0775127187371254
Epoch:  267  	Training Loss: 0.08140546083450317
Test Loss:  0.08444232493638992
Valid Loss:  0.0775126963853836
Epoch:  268  	Training Loss: 0.08140544593334198
Test Loss:  0.08444231003522873
Valid Loss:  0.07751268148422241
Epoch:  269  	Training Loss: 0.08140543103218079
Test Loss:  0.08444230258464813
Valid Loss:  0.07751267403364182
Epoch:  270  	Training Loss: 0.08140541613101959
Test Loss:  0.08444227278232574
Valid Loss:  0.07751265168190002
Epoch:  271  	Training Loss: 0.0814054012298584
Test Loss:  0.08444225788116455
Valid Loss:  0.07751263678073883
Epoch:  272  	Training Loss: 0.0814053863286972
Test Loss:  0.08444224298000336
Valid Loss:  0.07751262933015823
Epoch:  273  	Training Loss: 0.08140537142753601
Test Loss:  0.08444222807884216
Valid Loss:  0.07751261442899704
Epoch:  274  	Training Loss: 0.08140535652637482
Test Loss:  0.08444221317768097
Valid Loss:  0.07751259207725525
Epoch:  275  	Training Loss: 0.08140534162521362
Test Loss:  0.08444219082593918
Valid Loss:  0.07751258462667465
Epoch:  276  	Training Loss: 0.08140531927347183
Test Loss:  0.08444216847419739
Valid Loss:  0.07751256227493286
Epoch:  277  	Training Loss: 0.08140530437231064
Test Loss:  0.0844421535730362
Valid Loss:  0.07751254737377167
Epoch:  278  	Training Loss: 0.08140528202056885
Test Loss:  0.084442138671875
Valid Loss:  0.07751253247261047
Epoch:  279  	Training Loss: 0.08140527456998825
Test Loss:  0.0844421237707138
Valid Loss:  0.07751251757144928
Epoch:  280  	Training Loss: 0.08140525966882706
Test Loss:  0.08444210141897202
Valid Loss:  0.07751250267028809
Epoch:  281  	Training Loss: 0.08140523731708527
Test Loss:  0.08444207906723022
Valid Loss:  0.07751248776912689
Epoch:  282  	Training Loss: 0.08140522241592407
Test Loss:  0.08444207161664963
Valid Loss:  0.0775124728679657
Epoch:  283  	Training Loss: 0.08140521496534348
Test Loss:  0.08444204926490784
Valid Loss:  0.0775124579668045
Epoch:  284  	Training Loss: 0.08140519261360168
Test Loss:  0.08444203436374664
Valid Loss:  0.07751244306564331
Epoch:  285  	Training Loss: 0.08140517771244049
Test Loss:  0.08444201946258545
Valid Loss:  0.07751242816448212
Epoch:  286  	Training Loss: 0.0814051628112793
Test Loss:  0.08444200456142426
Valid Loss:  0.07751241326332092
Epoch:  287  	Training Loss: 0.0814051404595375
Test Loss:  0.08444198966026306
Valid Loss:  0.07751239836215973
Epoch:  288  	Training Loss: 0.08140513300895691
Test Loss:  0.08444197475910187
Valid Loss:  0.07751238346099854
Epoch:  289  	Training Loss: 0.08140511810779572
Test Loss:  0.08444195985794067
Valid Loss:  0.07751236855983734
Epoch:  290  	Training Loss: 0.08140510320663452
Test Loss:  0.08444193005561829
Valid Loss:  0.07751235365867615
 58%|█████▊    | 291/500 [03:25<04:11,  1.20s/it] 59%|█████▊    | 293/500 [03:25<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:25<02:07,  1.60it/s] 59%|█████▉    | 297/500 [03:25<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:25<01:08,  2.95it/s] 60%|██████    | 301/500 [03:32<03:52,  1.17s/it] 61%|██████    | 303/500 [03:32<02:45,  1.19it/s] 61%|██████    | 305/500 [03:32<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:32<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:32<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:38<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:39,  1.18it/s] 63%|██████▎   | 315/500 [03:39<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:39<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:39<01:01,  2.93it/s] 64%|██████▍   | 321/500 [03:45<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:46<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:46<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:46<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:46<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:52<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:52<02:23,  1.16it/s] 67%|██████▋   | 335/500 [03:53<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:53<01:13,  2.20it/s] 68%|██████▊   | 339/500 [03:53<00:54,  2.97it/s] 68%|██████▊   | 341/500 [03:59<03:08,  1.18s/it] 69%|██████▊   | 343/500 [03:59<02:13,  1.18it/s] 69%|██████▉   | 345/500 [03:59<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:00<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:00<00:50,  2.99it/s] 70%|███████   | 351/500 [04:06<02:53,  1.17s/it] 71%|███████   | 353/500 [04:06<02:03,  1.19it/s] 71%|███████   | 355/500 [04:06<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:06<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:13<02:44,  1.19s/it]Epoch:  291  	Training Loss: 0.08140508830547333
Test Loss:  0.08444191515445709
Valid Loss:  0.07751233875751495
Epoch:  292  	Training Loss: 0.08140506595373154
Test Loss:  0.0844419077038765
Valid Loss:  0.07751233130693436
Epoch:  293  	Training Loss: 0.08140505105257034
Test Loss:  0.0844418853521347
Valid Loss:  0.07751230895519257
Epoch:  294  	Training Loss: 0.08140504360198975
Test Loss:  0.08444187045097351
Valid Loss:  0.07751230150461197
Epoch:  295  	Training Loss: 0.08140502125024796
Test Loss:  0.08444185554981232
Valid Loss:  0.07751227915287018
Epoch:  296  	Training Loss: 0.08140501379966736
Test Loss:  0.08444184064865112
Valid Loss:  0.07751226425170898
Epoch:  297  	Training Loss: 0.08140499889850616
Test Loss:  0.08444181829690933
Valid Loss:  0.07751224935054779
Epoch:  298  	Training Loss: 0.08140498399734497
Test Loss:  0.08444180339574814
Valid Loss:  0.0775122344493866
Epoch:  299  	Training Loss: 0.08140495419502258
Test Loss:  0.08444179594516754
Valid Loss:  0.077512226998806
Epoch:  300  	Training Loss: 0.08140493929386139
Test Loss:  0.08444177359342575
Valid Loss:  0.0775122120976448
Epoch:  301  	Training Loss: 0.08140493929386139
Test Loss:  0.08444175124168396
Valid Loss:  0.07751218974590302
Epoch:  302  	Training Loss: 0.081404909491539
Test Loss:  0.08444173634052277
Valid Loss:  0.07751218229532242
Epoch:  303  	Training Loss: 0.08140489459037781
Test Loss:  0.08444172143936157
Valid Loss:  0.07751216739416122
Epoch:  304  	Training Loss: 0.08140487968921661
Test Loss:  0.08444170653820038
Valid Loss:  0.07751214504241943
Epoch:  305  	Training Loss: 0.08140486478805542
Test Loss:  0.08444168418645859
Valid Loss:  0.07751213014125824
Epoch:  306  	Training Loss: 0.08140484988689423
Test Loss:  0.0844416618347168
Valid Loss:  0.07751211524009705
Epoch:  307  	Training Loss: 0.08140482753515244
Test Loss:  0.0844416543841362
Valid Loss:  0.07751210033893585
Epoch:  308  	Training Loss: 0.08140481263399124
Test Loss:  0.08444163203239441
Valid Loss:  0.07751209288835526
Epoch:  309  	Training Loss: 0.08140479773283005
Test Loss:  0.08444161713123322
Valid Loss:  0.07751207053661346
Epoch:  310  	Training Loss: 0.08140478283166885
Test Loss:  0.08444160223007202
Valid Loss:  0.07751205563545227
Epoch:  311  	Training Loss: 0.08140476047992706
Test Loss:  0.08444158732891083
Valid Loss:  0.07751204073429108
Epoch:  312  	Training Loss: 0.08140474557876587
Test Loss:  0.08444155752658844
Valid Loss:  0.07751202583312988
Epoch:  313  	Training Loss: 0.08140473067760468
Test Loss:  0.08444154262542725
Valid Loss:  0.07751201093196869
Epoch:  314  	Training Loss: 0.08140471577644348
Test Loss:  0.08444152772426605
Valid Loss:  0.0775119960308075
Epoch:  315  	Training Loss: 0.08140470087528229
Test Loss:  0.08444151282310486
Valid Loss:  0.0775119811296463
Epoch:  316  	Training Loss: 0.0814046859741211
Test Loss:  0.08444149047136307
Valid Loss:  0.07751196622848511
Epoch:  317  	Training Loss: 0.0814046710729599
Test Loss:  0.08444148302078247
Valid Loss:  0.07751195132732391
Epoch:  318  	Training Loss: 0.0814046561717987
Test Loss:  0.08444145321846008
Valid Loss:  0.07751193642616272
Epoch:  319  	Training Loss: 0.08140464127063751
Test Loss:  0.08444143831729889
Valid Loss:  0.07751192152500153
Epoch:  320  	Training Loss: 0.08140461891889572
Test Loss:  0.08444143086671829
Valid Loss:  0.07751190662384033
Epoch:  321  	Training Loss: 0.08140461146831512
Test Loss:  0.0844414085149765
Valid Loss:  0.07751189172267914
Epoch:  322  	Training Loss: 0.08140459656715393
Test Loss:  0.0844414010643959
Valid Loss:  0.07751187682151794
Epoch:  323  	Training Loss: 0.08140457421541214
Test Loss:  0.08444137871265411
Valid Loss:  0.07751186192035675
Epoch:  324  	Training Loss: 0.08140455931425095
Test Loss:  0.08444136381149292
Valid Loss:  0.07751184701919556
Epoch:  325  	Training Loss: 0.08140454441308975
Test Loss:  0.08444134891033173
Valid Loss:  0.07751183211803436
Epoch:  326  	Training Loss: 0.08140452951192856
Test Loss:  0.08444133400917053
Valid Loss:  0.07751181721687317
Epoch:  327  	Training Loss: 0.08140450716018677
Test Loss:  0.08444131910800934
Valid Loss:  0.07751180231571198
Epoch:  328  	Training Loss: 0.08140449225902557
Test Loss:  0.08444130420684814
Valid Loss:  0.07751178741455078
Epoch:  329  	Training Loss: 0.08140448480844498
Test Loss:  0.08444128930568695
Valid Loss:  0.07751177251338959
Epoch:  330  	Training Loss: 0.08140446990728378
Test Loss:  0.08444125950336456
Valid Loss:  0.0775117576122284
Epoch:  331  	Training Loss: 0.08140444755554199
Test Loss:  0.08444124460220337
Valid Loss:  0.0775117501616478
Epoch:  332  	Training Loss: 0.0814044326543808
Test Loss:  0.08444122970104218
Valid Loss:  0.077511727809906
Epoch:  333  	Training Loss: 0.0814044177532196
Test Loss:  0.08444120734930038
Valid Loss:  0.07751171290874481
Epoch:  334  	Training Loss: 0.08140440285205841
Test Loss:  0.08444119244813919
Valid Loss:  0.07751169800758362
Epoch:  335  	Training Loss: 0.08140438795089722
Test Loss:  0.084441177546978
Valid Loss:  0.07751168310642242
Epoch:  336  	Training Loss: 0.08140437304973602
Test Loss:  0.0844411626458168
Valid Loss:  0.07751166820526123
Epoch:  337  	Training Loss: 0.08140435069799423
Test Loss:  0.08444114029407501
Valid Loss:  0.07751165330410004
Epoch:  338  	Training Loss: 0.08140433579683304
Test Loss:  0.08444112539291382
Valid Loss:  0.07751163840293884
Epoch:  339  	Training Loss: 0.08140432834625244
Test Loss:  0.08444110304117203
Valid Loss:  0.07751162350177765
Epoch:  340  	Training Loss: 0.08140430599451065
Test Loss:  0.08444108068943024
Valid Loss:  0.07751160860061646
Epoch:  341  	Training Loss: 0.08140429109334946
Test Loss:  0.08444107323884964
Valid Loss:  0.07751159369945526
Epoch:  342  	Training Loss: 0.08140428364276886
Test Loss:  0.08444106578826904
Valid Loss:  0.07751157879829407
Epoch:  343  	Training Loss: 0.08140426874160767
Test Loss:  0.08444104343652725
Valid Loss:  0.07751156389713287
Epoch:  344  	Training Loss: 0.08140423893928528
Test Loss:  0.08444102108478546
Valid Loss:  0.07751154899597168
Epoch:  345  	Training Loss: 0.08140422403812408
Test Loss:  0.08444101363420486
Valid Loss:  0.07751153409481049
Epoch:  346  	Training Loss: 0.08140420913696289
Test Loss:  0.08444099128246307
Valid Loss:  0.0775115117430687
Epoch:  347  	Training Loss: 0.0814041942358017
Test Loss:  0.08444096893072128
Valid Loss:  0.0775115042924881
Epoch:  348  	Training Loss: 0.0814041793346405
Test Loss:  0.08444095402956009
Valid Loss:  0.0775114893913269
Epoch:  349  	Training Loss: 0.08140416443347931
Test Loss:  0.08444094657897949
Valid Loss:  0.07751147449016571
Epoch:  350  	Training Loss: 0.08140414953231812
Test Loss:  0.0844409167766571
Valid Loss:  0.07751145958900452
Epoch:  351  	Training Loss: 0.08140413463115692
Test Loss:  0.08444090187549591
Valid Loss:  0.07751143723726273
Epoch:  352  	Training Loss: 0.08140411972999573
Test Loss:  0.08444088697433472
Valid Loss:  0.07751142978668213
Epoch:  353  	Training Loss: 0.08140409737825394
Test Loss:  0.08444087207317352
Valid Loss:  0.07751139998435974
Epoch:  354  	Training Loss: 0.08140408247709274
Test Loss:  0.08444084227085114
Valid Loss:  0.07751139998435974
Epoch:  355  	Training Loss: 0.08140406757593155
Test Loss:  0.08444083482027054
Valid Loss:  0.07751137763261795
Epoch:  356  	Training Loss: 0.08140404522418976
Test Loss:  0.08444081991910934
Valid Loss:  0.07751135528087616
Epoch:  357  	Training Loss: 0.08140403032302856
Test Loss:  0.08444079756736755
Valid Loss:  0.07751134037971497
Epoch:  358  	Training Loss: 0.08140401542186737
Test Loss:  0.08444078266620636
Valid Loss:  0.07751133292913437
Epoch:  359  	Training Loss: 0.08140400052070618
Test Loss:  0.08444076776504517
Valid Loss:  0.07751131802797318
Epoch:  360  	Training Loss: 0.08140398561954498
Test Loss:  0.08444074541330338
Valid Loss:  0.07751129567623138
Epoch:  361  	Training Loss: 0.08140397071838379
Test Loss:  0.08444073051214218
Valid Loss:  0.07751129567623138
Epoch:  362  	Training Loss: 0.081403948366642
Test Loss:  0.08444070816040039
Valid Loss:  0.0775112733244896
 73%|███████▎  | 363/500 [04:13<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:13<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:13<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:20<02:35,  1.21s/it] 75%|███████▍  | 373/500 [04:20<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:20<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:20<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:20<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:27<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:27<01:41,  1.16it/s] 77%|███████▋  | 385/500 [04:27<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:27<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:27<00:37,  2.94it/s] 78%|███████▊  | 391/500 [04:34<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:34<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:34<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:34<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:34<00:34,  2.94it/s] 80%|████████  | 401/500 [04:41<01:58,  1.20s/it] 81%|████████  | 403/500 [04:41<01:23,  1.16it/s] 81%|████████  | 405/500 [04:41<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:41<00:42,  2.19it/s] 82%|████████▏ | 409/500 [04:41<00:30,  2.94it/s] 82%|████████▏ | 411/500 [04:48<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:48<01:15,  1.15it/s] 83%|████████▎ | 415/500 [04:48<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:48<00:27,  2.95it/s] 84%|████████▍ | 421/500 [04:55<01:33,  1.19s/it] 85%|████████▍ | 423/500 [04:55<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:55<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:55<00:32,  2.21it/s] 86%|████████▌ | 429/500 [04:55<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:02<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:02<00:57,  1.16it/s]Epoch:  363  	Training Loss: 0.0814039334654808
Test Loss:  0.0844407007098198
Valid Loss:  0.0775112509727478
Epoch:  364  	Training Loss: 0.08140391856431961
Test Loss:  0.084440678358078
Valid Loss:  0.0775112435221672
Epoch:  365  	Training Loss: 0.08140390366315842
Test Loss:  0.08444066345691681
Valid Loss:  0.07751122862100601
Epoch:  366  	Training Loss: 0.08140388876199722
Test Loss:  0.08444063365459442
Valid Loss:  0.07751120626926422
Epoch:  367  	Training Loss: 0.08140387386083603
Test Loss:  0.08444063365459442
Valid Loss:  0.07751119136810303
Epoch:  368  	Training Loss: 0.08140385150909424
Test Loss:  0.08444061130285263
Valid Loss:  0.07751118391752243
Epoch:  369  	Training Loss: 0.08140383660793304
Test Loss:  0.08444059640169144
Valid Loss:  0.07751116901636124
Epoch:  370  	Training Loss: 0.08140382170677185
Test Loss:  0.08444057404994965
Valid Loss:  0.07751114666461945
Epoch:  371  	Training Loss: 0.08140379935503006
Test Loss:  0.08444055914878845
Valid Loss:  0.07751113176345825
Epoch:  372  	Training Loss: 0.08140379190444946
Test Loss:  0.08444054424762726
Valid Loss:  0.07751111686229706
Epoch:  373  	Training Loss: 0.08140377700328827
Test Loss:  0.08444052189588547
Valid Loss:  0.07751110196113586
Epoch:  374  	Training Loss: 0.08140376210212708
Test Loss:  0.08444049954414368
Valid Loss:  0.07751108705997467
Epoch:  375  	Training Loss: 0.08140373229980469
Test Loss:  0.08444048464298248
Valid Loss:  0.07751107215881348
Epoch:  376  	Training Loss: 0.08140373229980469
Test Loss:  0.08444047719240189
Valid Loss:  0.07751106470823288
Epoch:  377  	Training Loss: 0.0814037099480629
Test Loss:  0.0844404548406601
Valid Loss:  0.07751104235649109
Epoch:  378  	Training Loss: 0.0814036875963211
Test Loss:  0.0844404324889183
Valid Loss:  0.0775110200047493
Epoch:  379  	Training Loss: 0.08140367269515991
Test Loss:  0.08444042503833771
Valid Loss:  0.0775110125541687
Epoch:  380  	Training Loss: 0.08140365779399872
Test Loss:  0.08444040268659592
Valid Loss:  0.07751099020242691
Epoch:  381  	Training Loss: 0.08140363544225693
Test Loss:  0.08444038033485413
Valid Loss:  0.07751098275184631
Epoch:  382  	Training Loss: 0.08140362799167633
Test Loss:  0.08444036543369293
Valid Loss:  0.07751096785068512
Epoch:  383  	Training Loss: 0.08140361309051514
Test Loss:  0.08444035798311234
Valid Loss:  0.07751094549894333
Epoch:  384  	Training Loss: 0.08140359818935394
Test Loss:  0.08444033563137054
Valid Loss:  0.07751093804836273
Epoch:  385  	Training Loss: 0.08140358328819275
Test Loss:  0.08444031327962875
Valid Loss:  0.07751092314720154
Epoch:  386  	Training Loss: 0.08140356838703156
Test Loss:  0.08444030582904816
Valid Loss:  0.07751090824604034
Epoch:  387  	Training Loss: 0.08140355348587036
Test Loss:  0.08444028347730637
Valid Loss:  0.07751089334487915
Epoch:  388  	Training Loss: 0.08140353858470917
Test Loss:  0.08444026112556458
Valid Loss:  0.07751087844371796
Epoch:  389  	Training Loss: 0.08140350878238678
Test Loss:  0.08444026112556458
Valid Loss:  0.07751086354255676
Epoch:  390  	Training Loss: 0.08140350133180618
Test Loss:  0.08444023132324219
Valid Loss:  0.07751084864139557
Epoch:  391  	Training Loss: 0.08140349388122559
Test Loss:  0.084440216422081
Valid Loss:  0.07751083374023438
Epoch:  392  	Training Loss: 0.0814034715294838
Test Loss:  0.0844402015209198
Valid Loss:  0.07751081883907318
Epoch:  393  	Training Loss: 0.081403449177742
Test Loss:  0.0844401866197586
Valid Loss:  0.07751080393791199
Epoch:  394  	Training Loss: 0.08140343427658081
Test Loss:  0.08444017171859741
Valid Loss:  0.0775107890367508
Epoch:  395  	Training Loss: 0.08140342682600021
Test Loss:  0.08444015681743622
Valid Loss:  0.0775107741355896
Epoch:  396  	Training Loss: 0.08140341192483902
Test Loss:  0.08444013446569443
Valid Loss:  0.0775107592344284
Epoch:  397  	Training Loss: 0.08140339702367783
Test Loss:  0.08444011956453323
Valid Loss:  0.07751074433326721
Epoch:  398  	Training Loss: 0.08140337467193604
Test Loss:  0.08444009721279144
Valid Loss:  0.07751072943210602
Epoch:  399  	Training Loss: 0.08140335977077484
Test Loss:  0.08444008976221085
Valid Loss:  0.07751071453094482
Epoch:  400  	Training Loss: 0.08140334486961365
Test Loss:  0.08444006741046906
Valid Loss:  0.07751069962978363
Epoch:  401  	Training Loss: 0.08140332996845245
Test Loss:  0.08444005250930786
Valid Loss:  0.07751069217920303
Epoch:  402  	Training Loss: 0.08140331506729126
Test Loss:  0.08444003760814667
Valid Loss:  0.07751066982746124
Epoch:  403  	Training Loss: 0.08140330016613007
Test Loss:  0.08444002270698547
Valid Loss:  0.07751065492630005
Epoch:  404  	Training Loss: 0.08140328526496887
Test Loss:  0.08444000780582428
Valid Loss:  0.07751064002513885
Epoch:  405  	Training Loss: 0.08140327036380768
Test Loss:  0.08443999290466309
Valid Loss:  0.07751062512397766
Epoch:  406  	Training Loss: 0.08140325546264648
Test Loss:  0.08443997800350189
Valid Loss:  0.07751061022281647
Epoch:  407  	Training Loss: 0.08140324056148529
Test Loss:  0.0844399556517601
Valid Loss:  0.07751059532165527
Epoch:  408  	Training Loss: 0.0814032256603241
Test Loss:  0.08443994075059891
Valid Loss:  0.07751058042049408
Epoch:  409  	Training Loss: 0.0814032107591629
Test Loss:  0.08443991839885712
Valid Loss:  0.07751056551933289
Epoch:  410  	Training Loss: 0.08140318840742111
Test Loss:  0.08443990349769592
Valid Loss:  0.07751055061817169
Epoch:  411  	Training Loss: 0.08140318095684052
Test Loss:  0.08443988859653473
Valid Loss:  0.0775105431675911
Epoch:  412  	Training Loss: 0.08140316605567932
Test Loss:  0.08443987369537354
Valid Loss:  0.0775105282664299
Epoch:  413  	Training Loss: 0.08140315115451813
Test Loss:  0.08443985879421234
Valid Loss:  0.07751051336526871
Epoch:  414  	Training Loss: 0.08140313625335693
Test Loss:  0.08443984389305115
Valid Loss:  0.07751049846410751
Epoch:  415  	Training Loss: 0.08140312135219574
Test Loss:  0.08443982899188995
Valid Loss:  0.07751048356294632
Epoch:  416  	Training Loss: 0.08140310645103455
Test Loss:  0.08443980664014816
Valid Loss:  0.07751046866178513
Epoch:  417  	Training Loss: 0.08140308409929276
Test Loss:  0.08443978428840637
Valid Loss:  0.07751045376062393
Epoch:  418  	Training Loss: 0.08140306919813156
Test Loss:  0.08443976938724518
Valid Loss:  0.07751043140888214
Epoch:  419  	Training Loss: 0.08140304684638977
Test Loss:  0.08443975448608398
Valid Loss:  0.07751042395830154
Epoch:  420  	Training Loss: 0.08140303939580917
Test Loss:  0.08443974703550339
Valid Loss:  0.07751040905714035
Epoch:  421  	Training Loss: 0.08140302449464798
Test Loss:  0.0844397246837616
Valid Loss:  0.07751039415597916
Epoch:  422  	Training Loss: 0.08140300214290619
Test Loss:  0.0844397097826004
Valid Loss:  0.07751037180423737
Epoch:  423  	Training Loss: 0.081402987241745
Test Loss:  0.08443969488143921
Valid Loss:  0.07751037180423737
Epoch:  424  	Training Loss: 0.0814029723405838
Test Loss:  0.08443967252969742
Valid Loss:  0.07751034945249557
Epoch:  425  	Training Loss: 0.08140295743942261
Test Loss:  0.08443965017795563
Valid Loss:  0.07751032710075378
Epoch:  426  	Training Loss: 0.08140294253826141
Test Loss:  0.08443963527679443
Valid Loss:  0.07751031219959259
Epoch:  427  	Training Loss: 0.08140292763710022
Test Loss:  0.08443962037563324
Valid Loss:  0.077510304749012
Epoch:  428  	Training Loss: 0.08140291273593903
Test Loss:  0.08443960547447205
Valid Loss:  0.0775102823972702
Epoch:  429  	Training Loss: 0.08140289783477783
Test Loss:  0.08443958312273026
Valid Loss:  0.07751026749610901
Epoch:  430  	Training Loss: 0.08140287548303604
Test Loss:  0.08443956822156906
Valid Loss:  0.07751025259494781
Epoch:  431  	Training Loss: 0.08140286803245544
Test Loss:  0.08443956077098846
Valid Loss:  0.07751023769378662
Epoch:  432  	Training Loss: 0.08140284568071365
Test Loss:  0.08443953096866608
Valid Loss:  0.07751022279262543
Epoch:  433  	Training Loss: 0.08140283077955246
Test Loss:  0.08443951606750488
Valid Loss:  0.07751021534204483
Epoch:  434  	Training Loss: 0.08140281587839127
Test Loss:  0.08443950861692429
Valid Loss:  0.07751019299030304
 87%|████████▋ | 435/500 [05:02<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:02<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.95it/s] 88%|████████▊ | 441/500 [05:08<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:09<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:09<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:09<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:09<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:15<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:15<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:16<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:16<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:16<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:22<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:22<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:23<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:23<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:23<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:29<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:29<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:29<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:30<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:36<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:36<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:36<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:36<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:43<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:43<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:43<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:43<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:43<00:00,  2.96it/s]100%|██████████| 500/500 [05:43<00:00,  1.45it/s]
Epoch:  435  	Training Loss: 0.08140280097723007
Test Loss:  0.0844394862651825
Valid Loss:  0.07751017808914185
Epoch:  436  	Training Loss: 0.08140277862548828
Test Loss:  0.0844394713640213
Valid Loss:  0.07751016318798065
Epoch:  437  	Training Loss: 0.08140276372432709
Test Loss:  0.08443945646286011
Valid Loss:  0.07751014828681946
Epoch:  438  	Training Loss: 0.0814027488231659
Test Loss:  0.08443943411111832
Valid Loss:  0.07751013338565826
Epoch:  439  	Training Loss: 0.0814027339220047
Test Loss:  0.08443942666053772
Valid Loss:  0.07751013338565826
Epoch:  440  	Training Loss: 0.0814027190208435
Test Loss:  0.08443939685821533
Valid Loss:  0.07751010358333588
Epoch:  441  	Training Loss: 0.08140270411968231
Test Loss:  0.08443938195705414
Valid Loss:  0.07751008868217468
Epoch:  442  	Training Loss: 0.08140268921852112
Test Loss:  0.08443937450647354
Valid Loss:  0.07751007378101349
Epoch:  443  	Training Loss: 0.08140267431735992
Test Loss:  0.08443934470415115
Valid Loss:  0.0775100588798523
Epoch:  444  	Training Loss: 0.08140265196561813
Test Loss:  0.08443932235240936
Valid Loss:  0.0775100439786911
Epoch:  445  	Training Loss: 0.08140263706445694
Test Loss:  0.08443931490182877
Valid Loss:  0.07751002907752991
Epoch:  446  	Training Loss: 0.08140262216329575
Test Loss:  0.08443930000066757
Valid Loss:  0.07751001417636871
Epoch:  447  	Training Loss: 0.08140260726213455
Test Loss:  0.08443927764892578
Valid Loss:  0.07750999927520752
Epoch:  448  	Training Loss: 0.08140259236097336
Test Loss:  0.08443926274776459
Valid Loss:  0.07750998437404633
Epoch:  449  	Training Loss: 0.08140257000923157
Test Loss:  0.0844392478466034
Valid Loss:  0.07750996947288513
Epoch:  450  	Training Loss: 0.08140255510807037
Test Loss:  0.0844392329454422
Valid Loss:  0.07750995457172394
Epoch:  451  	Training Loss: 0.08140254020690918
Test Loss:  0.084439218044281
Valid Loss:  0.07750993967056274
Epoch:  452  	Training Loss: 0.08140252530574799
Test Loss:  0.08443920314311981
Valid Loss:  0.07750991731882095
Epoch:  453  	Training Loss: 0.08140251040458679
Test Loss:  0.08443917334079742
Valid Loss:  0.07750990986824036
Epoch:  454  	Training Loss: 0.0814024955034256
Test Loss:  0.08443915843963623
Valid Loss:  0.07750989496707916
Epoch:  455  	Training Loss: 0.0814024806022644
Test Loss:  0.08443914353847504
Valid Loss:  0.07750988006591797
Epoch:  456  	Training Loss: 0.08140245079994202
Test Loss:  0.08443912118673325
Valid Loss:  0.07750986516475677
Epoch:  457  	Training Loss: 0.08140244334936142
Test Loss:  0.08443910628557205
Valid Loss:  0.07750984281301498
Epoch:  458  	Training Loss: 0.08140242844820023
Test Loss:  0.08443908393383026
Valid Loss:  0.07750983536243439
Epoch:  459  	Training Loss: 0.08140241354703903
Test Loss:  0.08443906903266907
Valid Loss:  0.0775098204612732
Epoch:  460  	Training Loss: 0.08140239864587784
Test Loss:  0.08443906158208847
Valid Loss:  0.077509805560112
Epoch:  461  	Training Loss: 0.08140237629413605
Test Loss:  0.08443903177976608
Valid Loss:  0.0775097906589508
Epoch:  462  	Training Loss: 0.08140236139297485
Test Loss:  0.08443900942802429
Valid Loss:  0.07750977575778961
Epoch:  463  	Training Loss: 0.08140234649181366
Test Loss:  0.0844390019774437
Valid Loss:  0.07750975340604782
Epoch:  464  	Training Loss: 0.08140233159065247
Test Loss:  0.0844389796257019
Valid Loss:  0.07750973105430603
Epoch:  465  	Training Loss: 0.08140230923891068
Test Loss:  0.08443895727396011
Valid Loss:  0.07750972360372543
Epoch:  466  	Training Loss: 0.08140228688716888
Test Loss:  0.08443893492221832
Valid Loss:  0.07750970125198364
Epoch:  467  	Training Loss: 0.08140227198600769
Test Loss:  0.08443892747163773
Valid Loss:  0.07750968635082245
Epoch:  468  	Training Loss: 0.0814022496342659
Test Loss:  0.08443890511989594
Valid Loss:  0.07750966399908066
Epoch:  469  	Training Loss: 0.0814022421836853
Test Loss:  0.08443888276815414
Valid Loss:  0.07750964909791946
Epoch:  470  	Training Loss: 0.08140221238136292
Test Loss:  0.08443886041641235
Valid Loss:  0.07750962674617767
Epoch:  471  	Training Loss: 0.08140219748020172
Test Loss:  0.08443884551525116
Valid Loss:  0.07750961184501648
Epoch:  472  	Training Loss: 0.08140218257904053
Test Loss:  0.08443881571292877
Valid Loss:  0.07750959694385529
Epoch:  473  	Training Loss: 0.08140216767787933
Test Loss:  0.08443881571292877
Valid Loss:  0.0775095745921135
Epoch:  474  	Training Loss: 0.08140214532613754
Test Loss:  0.08443878591060638
Valid Loss:  0.0775095671415329
Epoch:  475  	Training Loss: 0.08140213787555695
Test Loss:  0.08443877100944519
Valid Loss:  0.0775095522403717
Epoch:  476  	Training Loss: 0.08140211552381516
Test Loss:  0.084438756108284
Valid Loss:  0.07750952988862991
Epoch:  477  	Training Loss: 0.08140209317207336
Test Loss:  0.0844387412071228
Valid Loss:  0.07750951498746872
Epoch:  478  	Training Loss: 0.08140207827091217
Test Loss:  0.08443872630596161
Valid Loss:  0.07750950008630753
Epoch:  479  	Training Loss: 0.08140206336975098
Test Loss:  0.08443871140480042
Valid Loss:  0.07750948518514633
Epoch:  480  	Training Loss: 0.08140204846858978
Test Loss:  0.08443868160247803
Valid Loss:  0.07750947028398514
Epoch:  481  	Training Loss: 0.08140203356742859
Test Loss:  0.08443866670131683
Valid Loss:  0.07750945538282394
Epoch:  482  	Training Loss: 0.0814020186662674
Test Loss:  0.08443865180015564
Valid Loss:  0.07750944793224335
Epoch:  483  	Training Loss: 0.0814020037651062
Test Loss:  0.08443863689899445
Valid Loss:  0.07750942558050156
Epoch:  484  	Training Loss: 0.08140198886394501
Test Loss:  0.08443860709667206
Valid Loss:  0.07750941067934036
Epoch:  485  	Training Loss: 0.08140196651220322
Test Loss:  0.08443860709667206
Valid Loss:  0.07750940322875977
Epoch:  486  	Training Loss: 0.08140195906162262
Test Loss:  0.08443858474493027
Valid Loss:  0.07750938832759857
Epoch:  487  	Training Loss: 0.08140193670988083
Test Loss:  0.08443856239318848
Valid Loss:  0.07750935852527618
Epoch:  488  	Training Loss: 0.08140192180871964
Test Loss:  0.08443856239318848
Valid Loss:  0.07750935852527618
Epoch:  489  	Training Loss: 0.08140189945697784
Test Loss:  0.08443853259086609
Valid Loss:  0.0775093361735344
Epoch:  490  	Training Loss: 0.08140188455581665
Test Loss:  0.0844385176897049
Valid Loss:  0.0775093212723732
Epoch:  491  	Training Loss: 0.08140187710523605
Test Loss:  0.0844385027885437
Valid Loss:  0.0775093138217926
Epoch:  492  	Training Loss: 0.08140185475349426
Test Loss:  0.08443848788738251
Valid Loss:  0.07750929892063141
Epoch:  493  	Training Loss: 0.08140183985233307
Test Loss:  0.08443847298622131
Valid Loss:  0.07750927656888962
Epoch:  494  	Training Loss: 0.08140182495117188
Test Loss:  0.08443845808506012
Valid Loss:  0.07750926911830902
Epoch:  495  	Training Loss: 0.08140181005001068
Test Loss:  0.08443843573331833
Valid Loss:  0.07750925421714783
Epoch:  496  	Training Loss: 0.08140179514884949
Test Loss:  0.08443842083215714
Valid Loss:  0.07750923931598663
Epoch:  497  	Training Loss: 0.0814017802476883
Test Loss:  0.08443841338157654
Valid Loss:  0.07750922441482544
Epoch:  498  	Training Loss: 0.0814017653465271
Test Loss:  0.08443838357925415
Valid Loss:  0.07750920951366425
Epoch:  499  	Training Loss: 0.0814017504453659
Test Loss:  0.08443836867809296
Valid Loss:  0.07750919461250305
Epoch:  500  	Training Loss: 0.08140173554420471
Test Loss:  0.08443835377693176
Valid Loss:  0.07750917971134186
seed is  19
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:19,  6.17s/it]  1%|          | 3/500 [00:06<13:40,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:49,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:08,  1.17s/it]  7%|▋         | 33/500 [00:26<06:31,  1.19it/s]  7%|▋         | 35/500 [00:26<04:41,  1.65it/s]  7%|▋         | 37/500 [00:27<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<09:04,  1.19s/it]  9%|▊         | 43/500 [00:33<06:28,  1.18it/s]  9%|▉         | 45/500 [00:33<04:39,  1.63it/s]  9%|▉         | 47/500 [00:33<03:24,  2.22it/s] 10%|▉         | 49/500 [00:34<02:31,  2.98it/s] 10%|█         | 51/500 [00:40<08:53,  1.19s/it] 11%|█         | 53/500 [00:40<06:22,  1.17it/s] 11%|█         | 55/500 [00:40<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:40<02:28,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:45,  1.20s/it] 13%|█▎        | 63/500 [00:47<06:15,  1.16it/s] 13%|█▎        | 65/500 [00:47<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:47<03:16,  2.20it/s] 14%|█▍        | 69/500 [00:47<02:25,  2.97it/s]Epoch:  1  	Training Loss: 0.04459550604224205
Test Loss:  3.824068069458008
Valid Loss:  3.8831558227539062
Epoch:  2  	Training Loss: 3.8649485111236572
Test Loss:  6.746971130371094
Valid Loss:  5.762195110321045
Epoch:  3  	Training Loss: 6.084118843078613
Test Loss:  0.04891039431095123
Valid Loss:  0.0555051825940609
Epoch:  4  	Training Loss: 0.05367906391620636
Test Loss:  0.043399907648563385
Valid Loss:  0.0494379922747612
Epoch:  5  	Training Loss: 0.04779727756977081
Test Loss:  0.03853931277990341
Valid Loss:  0.04407887905836105
Epoch:  6  	Training Loss: 0.04260457307100296
Test Loss:  0.034253355115652084
Valid Loss:  0.03934604302048683
Epoch:  7  	Training Loss: 0.038021355867385864
Test Loss:  0.030474897474050522
Valid Loss:  0.03516630083322525
Epoch:  8  	Training Loss: 0.03397665172815323
Test Loss:  0.027144907042384148
Valid Loss:  0.03147561848163605
Epoch:  9  	Training Loss: 0.030407927930355072
Test Loss:  0.024210363626480103
Valid Loss:  0.028217505663633347
Epoch:  10  	Training Loss: 0.02725967764854431
Test Loss:  0.021625373512506485
Valid Loss:  0.02534153312444687
Epoch:  11  	Training Loss: 0.024482889100909233
Test Loss:  0.0193485040217638
Valid Loss:  0.02280305325984955
Epoch:  12  	Training Loss: 0.022033950313925743
Test Loss:  0.013520085252821445
Valid Loss:  0.013568536378443241
Epoch:  13  	Training Loss: 0.014365876093506813
Test Loss:  0.01718887872993946
Valid Loss:  0.02037409320473671
Epoch:  14  	Training Loss: 0.019667645916342735
Test Loss:  0.014001628383994102
Valid Loss:  0.016991354525089264
Epoch:  15  	Training Loss: 0.016415605321526527
Test Loss:  0.010485175997018814
Valid Loss:  0.013521639630198479
Epoch:  16  	Training Loss: 0.013088608160614967
Test Loss:  0.00932982936501503
Valid Loss:  0.012229070998728275
Epoch:  17  	Training Loss: 0.011910727247595787
Test Loss:  0.008759488351643085
Valid Loss:  0.011518865823745728
Epoch:  18  	Training Loss: 0.011273464187979698
Test Loss:  0.008344363421201706
Valid Loss:  0.010983314365148544
Epoch:  19  	Training Loss: 0.01078374870121479
Test Loss:  0.00798095017671585
Valid Loss:  0.010516633279621601
Epoch:  20  	Training Loss: 0.01034589670598507
Test Loss:  0.007644152268767357
Valid Loss:  0.01008633617311716
Epoch:  21  	Training Loss: 0.009936865419149399
Test Loss:  0.007327355444431305
Valid Loss:  0.009682130068540573
Epoch:  22  	Training Loss: 0.009549993090331554
Test Loss:  0.00815591961145401
Valid Loss:  0.009228433482348919
Epoch:  23  	Training Loss: 0.009789681993424892
Test Loss:  0.0055305627174675465
Valid Loss:  0.007004656363278627
Epoch:  24  	Training Loss: 0.00717203738167882
Test Loss:  0.005455289036035538
Valid Loss:  0.006699476856738329
Epoch:  25  	Training Loss: 0.006980630103498697
Test Loss:  0.005192961078137159
Valid Loss:  0.006722037680447102
Epoch:  26  	Training Loss: 0.006837565451860428
Test Loss:  0.004971926100552082
Valid Loss:  0.00600422453135252
Epoch:  27  	Training Loss: 0.006290486082434654
Test Loss:  0.004635888617485762
Valid Loss:  0.005839972291141748
Epoch:  28  	Training Loss: 0.006049302872270346
Test Loss:  0.004509550519287586
Valid Loss:  0.005615087226033211
Epoch:  29  	Training Loss: 0.0058517418801784515
Test Loss:  0.00434020534157753
Valid Loss:  0.005464897491037846
Epoch:  30  	Training Loss: 0.005685197189450264
Test Loss:  0.00421485211700201
Valid Loss:  0.005313577596098185
Epoch:  31  	Training Loss: 0.005534148309379816
Test Loss:  0.004089288413524628
Valid Loss:  0.005179110448807478
Epoch:  32  	Training Loss: 0.005394400097429752
Test Loss:  0.0031427431385964155
Valid Loss:  0.004168091807514429
Epoch:  33  	Training Loss: 0.00430269492790103
Test Loss:  0.0029651536606252193
Valid Loss:  0.003939214628189802
Epoch:  34  	Training Loss: 0.004025301896035671
Test Loss:  0.002922188490629196
Valid Loss:  0.0038536814972758293
Epoch:  35  	Training Loss: 0.003924299031496048
Test Loss:  0.0029173754155635834
Valid Loss:  0.003816119395196438
Epoch:  36  	Training Loss: 0.003879604395478964
Test Loss:  0.002918347716331482
Valid Loss:  0.0037903892807662487
Epoch:  37  	Training Loss: 0.0038521697279065847
Test Loss:  0.0029166745953261852
Valid Loss:  0.0037680212408304214
Epoch:  38  	Training Loss: 0.003829321824014187
Test Loss:  0.002911544870585203
Valid Loss:  0.0037456187419593334
Epoch:  39  	Training Loss: 0.003806262044236064
Test Loss:  0.0029030805453658104
Valid Loss:  0.0037217247299849987
Epoch:  40  	Training Loss: 0.0037795579992234707
Test Loss:  0.0028923754580318928
Valid Loss:  0.0036925594322383404
Epoch:  41  	Training Loss: 0.00374701339751482
Test Loss:  0.0028786808252334595
Valid Loss:  0.003654771950095892
Epoch:  42  	Training Loss: 0.003708264324814081
Test Loss:  0.002553439699113369
Valid Loss:  0.0031003286130726337
Epoch:  43  	Training Loss: 0.0032746163196861744
Test Loss:  0.0019358019344508648
Valid Loss:  0.0022666598670184612
Epoch:  44  	Training Loss: 0.0023712608963251114
Test Loss:  0.001841059885919094
Valid Loss:  0.0020058434456586838
Epoch:  45  	Training Loss: 0.0021396453958004713
Test Loss:  0.0017321630148217082
Valid Loss:  0.0017601462313905358
Epoch:  46  	Training Loss: 0.0019093913724645972
Test Loss:  0.001627650810405612
Valid Loss:  0.0015519179869443178
Epoch:  47  	Training Loss: 0.0016867324011400342
Test Loss:  0.0015224501257762313
Valid Loss:  0.0013901684433221817
Epoch:  48  	Training Loss: 0.0015087753999978304
Test Loss:  0.0014358661137521267
Valid Loss:  0.0012543919729068875
Epoch:  49  	Training Loss: 0.001362284761853516
Test Loss:  0.0013618221273645759
Valid Loss:  0.0011508525349199772
Epoch:  50  	Training Loss: 0.0012504642363637686
Test Loss:  0.0013032725546509027
Valid Loss:  0.0010633724741637707
Epoch:  51  	Training Loss: 0.001160113257355988
Test Loss:  0.0012559820897877216
Valid Loss:  0.000994016882032156
Epoch:  52  	Training Loss: 0.0010893915314227343
Test Loss:  0.001263733021914959
Valid Loss:  0.000987174455076456
Epoch:  53  	Training Loss: 0.0010807932121679187
Test Loss:  0.0012448595371097326
Valid Loss:  0.0009810192277655005
Epoch:  54  	Training Loss: 0.0010737687116488814
Test Loss:  0.001241724705323577
Valid Loss:  0.0009756630752235651
Epoch:  55  	Training Loss: 0.0010675794910639524
Test Loss:  0.0012327181175351143
Valid Loss:  0.0009703644318506122
Epoch:  56  	Training Loss: 0.0010616369545459747
Test Loss:  0.0012273327447474003
Valid Loss:  0.0009651406435295939
Epoch:  57  	Training Loss: 0.0010559745132923126
Test Loss:  0.0012208539992570877
Valid Loss:  0.0009600127814337611
Epoch:  58  	Training Loss: 0.0010505288373678923
Test Loss:  0.0012155012227594852
Valid Loss:  0.0009551368420943618
Epoch:  59  	Training Loss: 0.00104517734143883
Test Loss:  0.0012100266758352518
Valid Loss:  0.0009500650921836495
Epoch:  60  	Training Loss: 0.001039697672240436
Test Loss:  0.0012048236094415188
Valid Loss:  0.0009450427605770528
Epoch:  61  	Training Loss: 0.0010342891328036785
Test Loss:  0.0011997600086033344
Valid Loss:  0.0009400089620612562
Epoch:  62  	Training Loss: 0.0010287724435329437
Test Loss:  0.0011942364508286119
Valid Loss:  0.0009357299422845244
Epoch:  63  	Training Loss: 0.0010258876718580723
Test Loss:  0.0012037312844768167
Valid Loss:  0.000935564108658582
Epoch:  64  	Training Loss: 0.0010232552886009216
Test Loss:  0.0011941483244299889
Valid Loss:  0.0009311046451330185
Epoch:  65  	Training Loss: 0.0010207778541371226
Test Loss:  0.0012015521060675383
Valid Loss:  0.0009305647690780461
Epoch:  66  	Training Loss: 0.0010186205618083477
Test Loss:  0.0011930065229535103
Valid Loss:  0.0009261354571208358
Epoch:  67  	Training Loss: 0.001016325899399817
Test Loss:  0.0012000557035207748
Valid Loss:  0.0009255651384592056
Epoch:  68  	Training Loss: 0.0010150396265089512
Test Loss:  0.0011919621611014009
Valid Loss:  0.0009214580641128123
Epoch:  69  	Training Loss: 0.001012857654131949
Test Loss:  0.0011992347426712513
Valid Loss:  0.0009210758726112545
Epoch:  70  	Training Loss: 0.0010117592755705118
Test Loss:  0.0011909237364307046
Valid Loss:  0.0009168602991849184
 14%|█▍        | 71/500 [00:54<08:22,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:59,  1.19it/s] 15%|█▌        | 75/500 [01:00<10:48,  1.53s/it] 15%|█▌        | 77/500 [01:00<07:40,  1.09s/it] 16%|█▌        | 79/500 [01:00<05:29,  1.28it/s] 16%|█▌        | 81/500 [01:13<16:52,  2.42s/it] 17%|█▋        | 83/500 [01:13<11:54,  1.71s/it] 17%|█▋        | 85/500 [01:13<08:25,  1.22s/it] 17%|█▋        | 87/500 [01:13<06:00,  1.15it/s] 18%|█▊        | 89/500 [01:13<04:18,  1.59it/s] 18%|█▊        | 91/500 [01:20<09:23,  1.38s/it] 19%|█▊        | 93/500 [01:20<06:41,  1.01it/s] 19%|█▉        | 95/500 [01:20<04:47,  1.41it/s] 19%|█▉        | 97/500 [01:20<03:28,  1.94it/s] 20%|█▉        | 99/500 [01:20<02:32,  2.63it/s] 20%|██        | 101/500 [01:26<08:01,  1.21s/it] 21%|██        | 103/500 [01:26<05:43,  1.15it/s] 21%|██        | 105/500 [01:27<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:27<02:59,  2.18it/s] 22%|██▏       | 109/500 [01:27<02:12,  2.94it/s] 22%|██▏       | 111/500 [01:33<07:43,  1.19s/it] 23%|██▎       | 113/500 [01:33<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:33<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:34<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:34<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:40<07:26,  1.18s/it] 25%|██▍       | 123/500 [01:40<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:40<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:40<02:46,  2.23it/s] 26%|██▌       | 129/500 [01:41<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:47<07:13,  1.17s/it] 27%|██▋       | 133/500 [01:47<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:47<03:42,  1.64it/s]Epoch:  71  	Training Loss: 0.0010092693846672773
Test Loss:  0.0011984286829829216
Valid Loss:  0.0009163921349681914
Epoch:  72  	Training Loss: 0.0010083855595439672
Test Loss:  0.001175097655504942
Valid Loss:  0.0009143651695922017
Epoch:  73  	Training Loss: 0.001007577870041132
Test Loss:  0.0012186805251985788
Valid Loss:  0.0009199742344208062
Epoch:  74  	Training Loss: 0.0010103414533659816
Test Loss:  0.001152816810645163
Valid Loss:  0.0009309977176599205
Epoch:  75  	Training Loss: 0.001026319107040763
Test Loss:  0.001374037703499198
Valid Loss:  0.0010075322352349758
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.0010920127388089895
Test Loss:  0.0011632053647190332
Valid Loss:  0.0010201437398791313
Epoch:  77  	Training Loss: 0.001118045998737216
Test Loss:  0.001465330016799271
Valid Loss:  0.0010721472790464759
Epoch:  78  	Training Loss: 0.0011541401036083698
Test Loss:  0.0011984684970229864
Valid Loss:  0.0010873038554564118
Epoch:  79  	Training Loss: 0.0011877703946083784
Test Loss:  0.0015866381581872702
Valid Loss:  0.0011615725234150887
Epoch:  80  	Training Loss: 0.001241295482032001
Test Loss:  0.001257147639989853
Valid Loss:  0.00118076684884727
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0012835952220484614
Test Loss:  0.0011881794780492783
Valid Loss:  0.0010373456170782447
Epoch:  82  	Training Loss: 0.001133891986683011
Test Loss:  0.0011667953804135323
Valid Loss:  0.0009644659585319459
Epoch:  83  	Training Loss: 0.001058145659044385
Test Loss:  0.0011687689693644643
Valid Loss:  0.000932040682528168
Epoch:  84  	Training Loss: 0.0010245316661894321
Test Loss:  0.0011760469060391188
Valid Loss:  0.0009167494717985392
Epoch:  85  	Training Loss: 0.0010086160618811846
Test Loss:  0.0011829809518530965
Valid Loss:  0.0009092077380046248
Epoch:  86  	Training Loss: 0.0010007137898355722
Test Loss:  0.001188123133033514
Valid Loss:  0.0009054052643477917
Epoch:  87  	Training Loss: 0.0009965876815840602
Test Loss:  0.0011912559857591987
Valid Loss:  0.0009031224763020873
Epoch:  88  	Training Loss: 0.0009940342279151082
Test Loss:  0.0011927660088986158
Valid Loss:  0.000901655585039407
Epoch:  89  	Training Loss: 0.0009922590106725693
Test Loss:  0.0011930676409974694
Valid Loss:  0.0009005207102745771
Epoch:  90  	Training Loss: 0.000990870175883174
Test Loss:  0.0011925497092306614
Valid Loss:  0.0008995929383672774
Epoch:  91  	Training Loss: 0.0009897059062495828
Test Loss:  0.001191486488096416
Valid Loss:  0.000898832397069782
Epoch:  92  	Training Loss: 0.0009887015912681818
Test Loss:  0.0011988156475126743
Valid Loss:  0.0008938084938563406
Epoch:  93  	Training Loss: 0.0009839775739237666
Test Loss:  0.001194592798128724
Valid Loss:  0.0008916213409975171
Epoch:  94  	Training Loss: 0.0009817620739340782
Test Loss:  0.0011904332786798477
Valid Loss:  0.0008900879765860736
Epoch:  95  	Training Loss: 0.0009801756823435426
Test Loss:  0.0011876863427460194
Valid Loss:  0.0008888377342373133
Epoch:  96  	Training Loss: 0.000978776253759861
Test Loss:  0.0011851419694721699
Valid Loss:  0.0008879230008460581
Epoch:  97  	Training Loss: 0.0009775737999007106
Test Loss:  0.001182393403723836
Valid Loss:  0.000887128000613302
Epoch:  98  	Training Loss: 0.0009766246657818556
Test Loss:  0.0011799962958320975
Valid Loss:  0.000886423047631979
Epoch:  99  	Training Loss: 0.0009758112719282508
Test Loss:  0.0011779420310631394
Valid Loss:  0.00088578334543854
Epoch:  100  	Training Loss: 0.0009750832105055451
Test Loss:  0.0011760402703657746
Valid Loss:  0.0008852258324623108
Epoch:  101  	Training Loss: 0.0009744216222316027
Test Loss:  0.0011742867063730955
Valid Loss:  0.000884712440893054
Epoch:  102  	Training Loss: 0.000973802525550127
Test Loss:  0.0011680220486596227
Valid Loss:  0.000883237924426794
Epoch:  103  	Training Loss: 0.0009723909897729754
Test Loss:  0.0011652454268187284
Valid Loss:  0.0008822380914352834
Epoch:  104  	Training Loss: 0.0009714174084365368
Test Loss:  0.001163330627605319
Valid Loss:  0.0008813152089715004
Epoch:  105  	Training Loss: 0.0009705144912004471
Test Loss:  0.0011615401599556208
Valid Loss:  0.0008804166573099792
Epoch:  106  	Training Loss: 0.0009696425986476243
Test Loss:  0.0011599381687119603
Valid Loss:  0.000879538943991065
Epoch:  107  	Training Loss: 0.0009687957353889942
Test Loss:  0.0011584684252738953
Valid Loss:  0.000878671242389828
Epoch:  108  	Training Loss: 0.0009679672657512128
Test Loss:  0.0011571220820769668
Valid Loss:  0.0008778030751273036
Epoch:  109  	Training Loss: 0.0009671526495367289
Test Loss:  0.0011558884289115667
Valid Loss:  0.0008769433479756117
Epoch:  110  	Training Loss: 0.0009663525270298123
Test Loss:  0.0011547217145562172
Valid Loss:  0.0008760910714045167
Epoch:  111  	Training Loss: 0.0009655631729401648
Test Loss:  0.0011536458041518927
Valid Loss:  0.000875246012583375
Epoch:  112  	Training Loss: 0.0009647905826568604
Test Loss:  0.0011147384066134691
Valid Loss:  0.0008319523185491562
Epoch:  113  	Training Loss: 0.0009196798782795668
Test Loss:  0.0010950443102046847
Valid Loss:  0.0008036941289901733
Epoch:  114  	Training Loss: 0.0008848971920087934
Test Loss:  0.0011045534629374743
Valid Loss:  0.0007947661215439439
Epoch:  115  	Training Loss: 0.0008758859476074576
Test Loss:  0.0011019003577530384
Valid Loss:  0.000790692400187254
Epoch:  116  	Training Loss: 0.0008717451710253954
Test Loss:  0.0010982929961755872
Valid Loss:  0.0007875632145442069
Epoch:  117  	Training Loss: 0.000868257659021765
Test Loss:  0.001093490980565548
Valid Loss:  0.0007852899143472314
Epoch:  118  	Training Loss: 0.0008652469841763377
Test Loss:  0.0010904658120125532
Valid Loss:  0.0007827827939763665
Epoch:  119  	Training Loss: 0.0008629155345261097
Test Loss:  0.0010821076575666666
Valid Loss:  0.0007811047835275531
Epoch:  120  	Training Loss: 0.0008605926996096969
Test Loss:  0.0010803765617311
Valid Loss:  0.000778846675530076
Epoch:  121  	Training Loss: 0.0008585372124798596
Test Loss:  0.0010719388956204057
Valid Loss:  0.0007777364808134735
Epoch:  122  	Training Loss: 0.0008567447657696903
Test Loss:  0.001067680073902011
Valid Loss:  0.0007763801841065288
Epoch:  123  	Training Loss: 0.0008551564533263445
Test Loss:  0.0010636524530127645
Valid Loss:  0.0007751745288260281
Epoch:  124  	Training Loss: 0.0008537498652003706
Test Loss:  0.0010599528905004263
Valid Loss:  0.0007740875007584691
Epoch:  125  	Training Loss: 0.0008524768054485321
Test Loss:  0.0010566019918769598
Valid Loss:  0.0007730990182608366
Epoch:  126  	Training Loss: 0.0008513105567544699
Test Loss:  0.0010535381734371185
Valid Loss:  0.0007722045993432403
Epoch:  127  	Training Loss: 0.00085024768486619
Test Loss:  0.0010507330298423767
Valid Loss:  0.0007713866070844233
Epoch:  128  	Training Loss: 0.0008492728229612112
Test Loss:  0.001048133010044694
Valid Loss:  0.000770642189309001
Epoch:  129  	Training Loss: 0.0008483784040436149
Test Loss:  0.0010457171592861414
Valid Loss:  0.0007699596462771297
Epoch:  130  	Training Loss: 0.0008475538343191147
Test Loss:  0.001043469412252307
Valid Loss:  0.0007693324005231261
Epoch:  131  	Training Loss: 0.000846792827360332
Test Loss:  0.001041376031935215
Valid Loss:  0.0007687503239139915
Epoch:  132  	Training Loss: 0.000846087175887078
Test Loss:  0.0010361974127590656
Valid Loss:  0.0007613911293447018
Epoch:  133  	Training Loss: 0.000837404397316277
Test Loss:  0.0010373091790825129
Valid Loss:  0.0007601669058203697
Epoch:  134  	Training Loss: 0.000835882849059999
Test Loss:  0.0010268967598676682
Valid Loss:  0.0007589327869936824
Epoch:  135  	Training Loss: 0.0008346680551767349
Test Loss:  0.0010288117919117212
Valid Loss:  0.0007580604869872332
Epoch:  136  	Training Loss: 0.0008335994207300246
Test Loss:  0.0010187217267230153
Valid Loss:  0.0007570097222924232
Epoch:  137  	Training Loss: 0.0008326882962137461
Test Loss:  0.001023121876642108
Valid Loss:   27%|██▋       | 137/500 [01:47<02:41,  2.24it/s] 28%|██▊       | 139/500 [01:47<01:59,  3.01it/s] 28%|██▊       | 141/500 [01:54<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:54<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:54<03:37,  1.64it/s] 29%|██▉       | 147/500 [01:54<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:54<01:56,  3.00it/s] 30%|███       | 151/500 [02:00<06:48,  1.17s/it] 31%|███       | 153/500 [02:01<04:51,  1.19it/s] 31%|███       | 155/500 [02:01<03:30,  1.64it/s] 31%|███▏      | 157/500 [02:01<02:33,  2.23it/s] 32%|███▏      | 159/500 [02:01<01:54,  2.99it/s] 32%|███▏      | 161/500 [02:07<06:40,  1.18s/it] 33%|███▎      | 163/500 [02:07<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:08<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:08<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:08<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:14<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:14<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:14<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:15<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:15<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:21<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:21<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:21<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:22<02:21,  2.20it/s] 38%|███▊      | 189/500 [02:22<01:44,  2.96it/s] 38%|███▊      | 191/500 [02:28<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:28<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:28<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:28<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:28<01:40,  3.00it/s] 40%|████      | 201/500 [02:35<05:49,  1.17s/it] 41%|████      | 203/500 [02:35<04:09,  1.19it/s] 41%|████      | 205/500 [02:35<02:59,  1.64it/s]0.0007564268307760358
Epoch:  138  	Training Loss: 0.0008318474283441901
Test Loss:  0.001011981745250523
Valid Loss:  0.0007554006879217923
Epoch:  139  	Training Loss: 0.0008310610428452492
Test Loss:  0.0010187657317146659
Valid Loss:  0.0007549736183136702
Epoch:  140  	Training Loss: 0.0008303290233016014
Test Loss:  0.0010067869443446398
Valid Loss:  0.0007539693615399301
Epoch:  141  	Training Loss: 0.0008296526502817869
Test Loss:  0.0010157281067222357
Valid Loss:  0.0007537282654084265
Epoch:  142  	Training Loss: 0.0008290602709166706
Test Loss:  0.0009992995765060186
Valid Loss:  0.0007528666756115854
Epoch:  143  	Training Loss: 0.0008283409406431019
Test Loss:  0.0010055953171104193
Valid Loss:  0.0007526453118771315
Epoch:  144  	Training Loss: 0.0008279291214421391
Test Loss:  0.0010008617537096143
Valid Loss:  0.0007523208623751998
Epoch:  145  	Training Loss: 0.0008276188746094704
Test Loss:  0.001002064673230052
Valid Loss:  0.0007521189982071519
Epoch:  146  	Training Loss: 0.0008273383136838675
Test Loss:  0.0010004498763009906
Valid Loss:  0.0007518780184909701
Epoch:  147  	Training Loss: 0.000827068230137229
Test Loss:  0.0010004278738051653
Valid Loss:  0.0007516761543229222
Epoch:  148  	Training Loss: 0.0008268067613244057
Test Loss:  0.000999719137325883
Valid Loss:  0.000751461717300117
Epoch:  149  	Training Loss: 0.000826554954983294
Test Loss:  0.0009994651190936565
Valid Loss:  0.0007512546144425869
Epoch:  150  	Training Loss: 0.0008263061172328889
Test Loss:  0.000999061157926917
Valid Loss:  0.0007510455325245857
Epoch:  151  	Training Loss: 0.0008260650793090463
Test Loss:  0.0009987978264689445
Valid Loss:  0.0007508378475904465
Epoch:  152  	Training Loss: 0.0008258255547843874
Test Loss:  0.0009987570811063051
Valid Loss:  0.0007505707326345146
Epoch:  153  	Training Loss: 0.0008255335269495845
Test Loss:  0.000998718081973493
Valid Loss:  0.0007502662483602762
Epoch:  154  	Training Loss: 0.0008251697290688753
Test Loss:  0.0009986886288970709
Valid Loss:  0.0007499718340113759
Epoch:  155  	Training Loss: 0.000824815477244556
Test Loss:  0.000998663017526269
Valid Loss:  0.000749687198549509
Epoch:  156  	Training Loss: 0.0008244703058153391
Test Loss:  0.0009986408986151218
Valid Loss:  0.0007494091987609863
Epoch:  157  	Training Loss: 0.0008241350296884775
Test Loss:  0.0009986180812120438
Valid Loss:  0.0007491392316296697
Epoch:  158  	Training Loss: 0.0008238077280111611
Test Loss:  0.0009985951473936439
Valid Loss:  0.0007488790433853865
Epoch:  159  	Training Loss: 0.0008234905544668436
Test Loss:  0.0009985711658373475
Valid Loss:  0.0007486413232982159
Epoch:  160  	Training Loss: 0.000823186885099858
Test Loss:  0.0009985467186197639
Valid Loss:  0.0007484115194529295
Epoch:  161  	Training Loss: 0.0008228907827287912
Test Loss:  0.0009985212236642838
Valid Loss:  0.0007481876527890563
Epoch:  162  	Training Loss: 0.0008226023055613041
Test Loss:  0.0009960585739463568
Valid Loss:  0.0007428873213939369
Epoch:  163  	Training Loss: 0.0008173448732122779
Test Loss:  0.0009936477290466428
Valid Loss:  0.0007410127436742187
Epoch:  164  	Training Loss: 0.0008154268143698573
Test Loss:  0.0009913386311382055
Valid Loss:  0.0007397010922431946
Epoch:  165  	Training Loss: 0.0008137132972478867
Test Loss:  0.0009893054375424981
Valid Loss:  0.0007387726800516248
Epoch:  166  	Training Loss: 0.0008124307496473193
Test Loss:  0.000987543840892613
Valid Loss:  0.0007382624316960573
Epoch:  167  	Training Loss: 0.0008114378433674574
Test Loss:  0.0009863496525213122
Valid Loss:  0.0007378965383395553
Epoch:  168  	Training Loss: 0.000810863683000207
Test Loss:  0.0009854078525677323
Valid Loss:  0.0007375575951300561
Epoch:  169  	Training Loss: 0.0008103089639917016
Test Loss:  0.0009848137851804495
Valid Loss:  0.0007372352993115783
Epoch:  170  	Training Loss: 0.0008098372491076589
Test Loss:  0.0009843155276030302
Valid Loss:  0.0007369698723778129
Epoch:  171  	Training Loss: 0.0008094970835372806
Test Loss:  0.000983939622528851
Valid Loss:  0.0007367170182988048
Epoch:  172  	Training Loss: 0.0008091827621683478
Test Loss:  0.00098231784068048
Valid Loss:  0.0007361929165199399
Epoch:  173  	Training Loss: 0.0008087356109172106
Test Loss:  0.000982756493613124
Valid Loss:  0.0007358372677117586
Epoch:  174  	Training Loss: 0.0008083295542746782
Test Loss:  0.000983126345090568
Valid Loss:  0.0007354730041697621
Epoch:  175  	Training Loss: 0.0008078680257312953
Test Loss:  0.000983453239314258
Valid Loss:  0.0007351280655711889
Epoch:  176  	Training Loss: 0.0008074273937381804
Test Loss:  0.0009837134275585413
Valid Loss:  0.0007347979117184877
Epoch:  177  	Training Loss: 0.0008070024778135121
Test Loss:  0.000983922858722508
Valid Loss:  0.0007344866171479225
Epoch:  178  	Training Loss: 0.0008065927540883422
Test Loss:  0.000984054058790207
Valid Loss:  0.000734182889573276
Epoch:  179  	Training Loss: 0.000806196010671556
Test Loss:  0.0009841594146564603
Valid Loss:  0.000733894994482398
Epoch:  180  	Training Loss: 0.0008058099774643779
Test Loss:  0.0009842067956924438
Valid Loss:  0.0007336148410104215
Epoch:  181  	Training Loss: 0.0008054346544668078
Test Loss:  0.0009841867722570896
Valid Loss:  0.0007333385292440653
Epoch:  182  	Training Loss: 0.0008050663163885474
Test Loss:  0.0009749865275807679
Valid Loss:  0.0007237483514472842
Epoch:  183  	Training Loss: 0.000795018975622952
Test Loss:  0.000969436950981617
Valid Loss:  0.0007147552678361535
Epoch:  184  	Training Loss: 0.0007855584844946861
Test Loss:  0.000962136487942189
Valid Loss:  0.0007055358146317303
Epoch:  185  	Training Loss: 0.0007761449087411165
Test Loss:  0.0009557315497659147
Valid Loss:  0.0006967905792407691
Epoch:  186  	Training Loss: 0.0007670498453080654
Test Loss:  0.0009488919749855995
Valid Loss:  0.0006882636807858944
Epoch:  187  	Training Loss: 0.0007582793477922678
Test Loss:  0.0009419628768227994
Valid Loss:  0.0006799019756726921
Epoch:  188  	Training Loss: 0.0007497507613152266
Test Loss:  0.0009349093306809664
Valid Loss:  0.0006718332879245281
Epoch:  189  	Training Loss: 0.0007414351566694677
Test Loss:  0.0009279685327783227
Valid Loss:  0.0006640747305937111
Epoch:  190  	Training Loss: 0.0007334336405619979
Test Loss:  0.0009210091084241867
Valid Loss:  0.000656386255286634
Epoch:  191  	Training Loss: 0.000725638004951179
Test Loss:  0.0009139061439782381
Valid Loss:  0.0006488552317023277
Epoch:  192  	Training Loss: 0.0007179367821663618
Test Loss:  0.000906975066754967
Valid Loss:  0.0006413350347429514
Epoch:  193  	Training Loss: 0.0007102548843249679
Test Loss:  0.0009007862536236644
Valid Loss:  0.0006341621628962457
Epoch:  194  	Training Loss: 0.0007028828840702772
Test Loss:  0.0008945211302489042
Valid Loss:  0.0006272693863138556
Epoch:  195  	Training Loss: 0.0006957504665479064
Test Loss:  0.0008882795227691531
Valid Loss:  0.0006205916870385408
Epoch:  196  	Training Loss: 0.000688765780068934
Test Loss:  0.0008820872171781957
Valid Loss:  0.00061411177739501
Epoch:  197  	Training Loss: 0.000681942910887301
Test Loss:  0.0008758560288697481
Valid Loss:  0.0006077578873373568
Epoch:  198  	Training Loss: 0.0006752263871021569
Test Loss:  0.0008695707656443119
Valid Loss:  0.0006014385144226253
Epoch:  199  	Training Loss: 0.0006685706321150064
Test Loss:  0.00086336734239012
Valid Loss:  0.0005952819483354688
Epoch:  200  	Training Loss: 0.0006620154599659145
Test Loss:  0.0008571686921641231
Valid Loss:  0.0005892209010198712
Epoch:  201  	Training Loss: 0.0006555130239576101
Test Loss:  0.0008510103216394782
Valid Loss:  0.0005833370378240943
Epoch:  202  	Training Loss: 0.0006491814274340868
Test Loss:  0.0008352735312655568
Valid Loss:  0.0005774206947535276
Epoch:  203  	Training Loss: 0.0006429313216358423
Test Loss:  0.0008264109492301941
Valid Loss:  0.0005726127419620752
Epoch:  204  	Training Loss: 0.0006377645768225193
Test Loss:  0.00082014239160344
Valid Loss:  0.0005681242328137159
Epoch:  205  	Training Loss: 0.0006328924791887403
Test Loss:  0.0008149102795869112
Valid Loss:  0.0005637729773297906
 41%|████▏     | 207/500 [02:35<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:35<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:42<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:42<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:42<02:55,  1.63it/s] 43%|████▎     | 217/500 [02:42<02:07,  2.23it/s] 44%|████▍     | 219/500 [02:42<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:48<05:25,  1.17s/it] 45%|████▍     | 223/500 [02:49<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:49<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:49<02:01,  2.26it/s] 46%|████▌     | 229/500 [02:49<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:55<05:12,  1.16s/it] 47%|████▋     | 233/500 [02:55<03:42,  1.20it/s] 47%|████▋     | 235/500 [02:55<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:56<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:56<01:26,  3.03it/s] 48%|████▊     | 241/500 [03:02<05:05,  1.18s/it] 49%|████▊     | 243/500 [03:02<03:38,  1.18it/s] 49%|████▉     | 245/500 [03:02<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:02<01:53,  2.22it/s] 50%|████▉     | 249/500 [03:03<01:24,  2.99it/s] 50%|█████     | 251/500 [03:09<05:09,  1.24s/it] 51%|█████     | 253/500 [03:09<03:40,  1.12it/s] 51%|█████     | 255/500 [03:10<02:37,  1.55it/s] 51%|█████▏    | 257/500 [03:10<01:54,  2.12it/s] 52%|█████▏    | 259/500 [03:10<01:24,  2.84it/s] 52%|█████▏    | 261/500 [03:16<04:47,  1.20s/it] 52%|█████▏    | 262/500 [03:16<04:00,  1.01s/it] 53%|█████▎    | 264/500 [03:16<02:45,  1.42it/s] 53%|█████▎    | 266/500 [03:17<01:56,  2.01it/s] 54%|█████▎    | 268/500 [03:17<01:24,  2.75it/s] 54%|█████▍    | 270/500 [03:17<01:02,  3.68it/s] 54%|█████▍    | 272/500 [03:23<04:26,  1.17s/it]Epoch:  206  	Training Loss: 0.0006281578680500388
Test Loss:  0.0008100970298983157
Valid Loss:  0.0005595468683168292
Epoch:  207  	Training Loss: 0.0006235428736545146
Test Loss:  0.0008054603822529316
Valid Loss:  0.000555418198928237
Epoch:  208  	Training Loss: 0.000619006750639528
Test Loss:  0.0008009119192138314
Valid Loss:  0.00055132299894467
Epoch:  209  	Training Loss: 0.0006145414663478732
Test Loss:  0.0007963875541463494
Valid Loss:  0.0005473056808114052
Epoch:  210  	Training Loss: 0.0006101441103965044
Test Loss:  0.0007919508498162031
Valid Loss:  0.0005433739861473441
Epoch:  211  	Training Loss: 0.0006058330181986094
Test Loss:  0.0007875483715906739
Valid Loss:  0.0005395273910835385
Epoch:  212  	Training Loss: 0.0006016046390868723
Test Loss:  0.0008056535152718425
Valid Loss:  0.0005368308047764003
Epoch:  213  	Training Loss: 0.0005973704974167049
Test Loss:  0.0007779733277857304
Valid Loss:  0.0005331150023266673
Epoch:  214  	Training Loss: 0.0005944657605141401
Test Loss:  0.0007877479074522853
Valid Loss:  0.000532143865711987
Epoch:  215  	Training Loss: 0.0005923546850681305
Test Loss:  0.0007711287471465766
Valid Loss:  0.0005300040356814861
Epoch:  216  	Training Loss: 0.0005906664300709963
Test Loss:  0.0007759584113955498
Valid Loss:  0.0005294654401950538
Epoch:  217  	Training Loss: 0.0005892956396564841
Test Loss:  0.0007656273664906621
Valid Loss:  0.000528082309756428
Epoch:  218  	Training Loss: 0.0005881498800590634
Test Loss:  0.000767760444432497
Valid Loss:  0.000527700234670192
Epoch:  219  	Training Loss: 0.000587170070502907
Test Loss:  0.0007611559703946114
Valid Loss:  0.0005267516826279461
Epoch:  220  	Training Loss: 0.0005863340338692069
Test Loss:  0.0007618981180712581
Valid Loss:  0.000526395277120173
Epoch:  221  	Training Loss: 0.00058557721786201
Test Loss:  0.0007575310883112252
Valid Loss:  0.0005256751319393516
Epoch:  222  	Training Loss: 0.0005848371656611562
Test Loss:  0.0007392358966171741
Valid Loss:  0.0005101413116790354
Epoch:  223  	Training Loss: 0.0005700620822608471
Test Loss:  0.000738348055165261
Valid Loss:  0.000506000011228025
Epoch:  224  	Training Loss: 0.0005652109393849969
Test Loss:  0.0007379178423434496
Valid Loss:  0.0005021248944103718
Epoch:  225  	Training Loss: 0.0005608948995359242
Test Loss:  0.000736276910174638
Valid Loss:  0.0004985398845747113
Epoch:  226  	Training Loss: 0.0005568743217736483
Test Loss:  0.0007341117598116398
Valid Loss:  0.0004951136652380228
Epoch:  227  	Training Loss: 0.0005530280759558082
Test Loss:  0.000731617386918515
Valid Loss:  0.0004918432678095996
Epoch:  228  	Training Loss: 0.0005493127973750234
Test Loss:  0.000729089486412704
Valid Loss:  0.000488575897179544
Epoch:  229  	Training Loss: 0.0005456978105939925
Test Loss:  0.0007259179838001728
Valid Loss:  0.0004854680155403912
Epoch:  230  	Training Loss: 0.0005421391688287258
Test Loss:  0.0007230550982058048
Valid Loss:  0.0004823352792300284
Epoch:  231  	Training Loss: 0.0005386536940932274
Test Loss:  0.0007196782389655709
Valid Loss:  0.0004793212574440986
Epoch:  232  	Training Loss: 0.0005352214211598039
Test Loss:  0.0007256722310557961
Valid Loss:  0.00047716678818687797
Epoch:  233  	Training Loss: 0.0005322454962879419
Test Loss:  0.0007248152396641672
Valid Loss:  0.0004762891912832856
Epoch:  234  	Training Loss: 0.0005310999695211649
Test Loss:  0.0007226777379401028
Valid Loss:  0.00047541127423755825
Epoch:  235  	Training Loss: 0.0005300649208948016
Test Loss:  0.0007203990826383233
Valid Loss:  0.00047455975436605513
Epoch:  236  	Training Loss: 0.0005290902336128056
Test Loss:  0.000718196970410645
Valid Loss:  0.0004737467388622463
Epoch:  237  	Training Loss: 0.0005281592020764947
Test Loss:  0.0007160853128880262
Valid Loss:  0.0004729700740426779
Epoch:  238  	Training Loss: 0.0005272681009955704
Test Loss:  0.0007140620145946741
Valid Loss:  0.0004722260346170515
Epoch:  239  	Training Loss: 0.0005264166393317282
Test Loss:  0.0007121199741959572
Valid Loss:  0.0004715107788797468
Epoch:  240  	Training Loss: 0.0005255998694337904
Test Loss:  0.0007102625677362084
Valid Loss:  0.0004708237829618156
Epoch:  241  	Training Loss: 0.0005248135421425104
Test Loss:  0.0007084804819896817
Valid Loss:  0.0004701624275185168
Epoch:  242  	Training Loss: 0.0005240548634901643
Test Loss:  0.0006979880854487419
Valid Loss:  0.00046338821994140744
Epoch:  243  	Training Loss: 0.0005173683748580515
Test Loss:  0.0006929871160537004
Valid Loss:  0.0004598003579303622
Epoch:  244  	Training Loss: 0.0005135165411047637
Test Loss:  0.0006896376144140959
Valid Loss:  0.00045684160431846976
Epoch:  245  	Training Loss: 0.000510244513861835
Test Loss:  0.0006869138451293111
Valid Loss:  0.00045397778740152717
Epoch:  246  	Training Loss: 0.0005071018822491169
Test Loss:  0.0006841584108769894
Valid Loss:  0.00045128422789275646
Epoch:  247  	Training Loss: 0.0005041085532866418
Test Loss:  0.0006816379609517753
Valid Loss:  0.0004486780962906778
Epoch:  248  	Training Loss: 0.0005011956091038883
Test Loss:  0.000678945507388562
Valid Loss:  0.00044614230864681304
Epoch:  249  	Training Loss: 0.0004983361577615142
Test Loss:  0.0006762820994481444
Valid Loss:  0.00044365678331814706
Epoch:  250  	Training Loss: 0.0004955313052050769
Test Loss:  0.0006736335926689208
Valid Loss:  0.00044122347026132047
Epoch:  251  	Training Loss: 0.0004927794798277318
Test Loss:  0.0006709612207487226
Valid Loss:  0.00043883020407520235
Epoch:  252  	Training Loss: 0.0004900674102827907
Test Loss:  0.0006728606531396508
Valid Loss:  0.0004359319864306599
Epoch:  253  	Training Loss: 0.00048657122533768415
Test Loss:  0.0006726719439029694
Valid Loss:  0.0004336065030656755
Epoch:  254  	Training Loss: 0.0004838036256842315
Test Loss:  0.0006714829942211509
Valid Loss:  0.0004313999670557678
Epoch:  255  	Training Loss: 0.0004812219995073974
Test Loss:  0.0006698652287013829
Valid Loss:  0.0004292501544114202
Epoch:  256  	Training Loss: 0.00047872442519292235
Test Loss:  0.0006680656224489212
Valid Loss:  0.00042715162271633744
Epoch:  257  	Training Loss: 0.0004762933240272105
Test Loss:  0.0006661899387836456
Valid Loss:  0.00042510521598160267
Epoch:  258  	Training Loss: 0.0004739214200526476
Test Loss:  0.0006642796797677875
Valid Loss:  0.00042310869321227074
Epoch:  259  	Training Loss: 0.0004716060357168317
Test Loss:  0.0006623597582802176
Valid Loss:  0.0004211592604406178
Epoch:  260  	Training Loss: 0.0004693394585046917
Test Loss:  0.0006604382069781423
Valid Loss:  0.0004192522610537708
Epoch:  261  	Training Loss: 0.0004671178467106074
Test Loss:  0.0006585220107808709
Valid Loss:  0.0004173855413682759
Epoch:  262  	Training Loss: 0.0004649406182579696
Test Loss:  0.0006599755142815411
Valid Loss:  0.0004170983738731593
Epoch:  263  	Training Loss: 0.0004645299632102251
Test Loss:  0.0006604667869396508
Valid Loss:  0.00041688187047839165
Epoch:  264  	Training Loss: 0.00046424445463344455
Test Loss:  0.0006605159724131227
Valid Loss:  0.0004166642902418971
Epoch:  265  	Training Loss: 0.0004639827529899776
Test Loss:  0.0006603719666600227
Valid Loss:  0.00041644240263849497
Epoch:  266  	Training Loss: 0.0004637271340470761
Test Loss:  0.0006601441418752074
Valid Loss:  0.0004162167606409639
Epoch:  267  	Training Loss: 0.000463473261334002
Test Loss:  0.0006598831387236714
Valid Loss:  0.00041599030373618007
Epoch:  268  	Training Loss: 0.000463217991637066
Test Loss:  0.0006596014136448503
Valid Loss:  0.00041575933573767543
Epoch:  269  	Training Loss: 0.00046295480569824576
Test Loss:  0.0006593167781829834
Valid Loss:  0.0004155299684498459
Epoch:  270  	Training Loss: 0.00046269421000033617
Test Loss:  0.0006590316770598292
Valid Loss:  0.00041530124144628644
Epoch:  271  	Training Loss: 0.000462434662040323
Test Loss:  0.0006587450625374913
Valid Loss:  0.00041507353307679296
Epoch:  272  	Training Loss: 0.0004621756379492581
Test Loss:  0.0006484139012172818
Valid Loss:  0.00041272531962022185
Epoch:  273  	Training Loss: 0.0004596422950271517
Test Loss:  0.0006464041071012616
Valid Loss:  0.0004107015847694129
 55%|█████▍    | 274/500 [03:23<03:08,  1.20it/s] 55%|█████▌    | 276/500 [03:24<02:14,  1.67it/s] 56%|█████▌    | 278/500 [03:24<01:37,  2.28it/s] 56%|█████▌    | 280/500 [03:24<01:11,  3.07it/s] 56%|█████▋    | 282/500 [03:30<04:16,  1.17s/it] 57%|█████▋    | 284/500 [03:30<03:01,  1.19it/s] 57%|█████▋    | 286/500 [03:30<02:10,  1.64it/s] 58%|█████▊    | 288/500 [03:30<01:34,  2.24it/s] 58%|█████▊    | 290/500 [03:31<01:09,  3.02it/s] 58%|█████▊    | 292/500 [03:37<04:09,  1.20s/it] 59%|█████▉    | 294/500 [03:37<02:57,  1.16it/s] 59%|█████▉    | 296/500 [03:37<02:06,  1.61it/s] 60%|█████▉    | 298/500 [03:37<01:31,  2.20it/s] 60%|██████    | 300/500 [03:38<01:07,  2.96it/s] 60%|██████    | 302/500 [03:44<03:57,  1.20s/it] 61%|██████    | 304/500 [03:44<02:48,  1.17it/s] 61%|██████    | 306/500 [03:44<02:00,  1.61it/s] 62%|██████▏   | 308/500 [03:44<01:27,  2.20it/s] 62%|██████▏   | 310/500 [03:45<01:04,  2.96it/s] 62%|██████▏   | 312/500 [03:51<03:45,  1.20s/it] 63%|██████▎   | 314/500 [03:51<02:39,  1.16it/s] 63%|██████▎   | 316/500 [03:51<01:54,  1.61it/s] 64%|██████▎   | 318/500 [03:51<01:22,  2.20it/s] 64%|██████▍   | 320/500 [03:51<01:00,  2.97it/s] 64%|██████▍   | 322/500 [03:58<03:33,  1.20s/it] 65%|██████▍   | 324/500 [03:58<02:31,  1.16it/s] 65%|██████▌   | 326/500 [03:58<01:48,  1.61it/s] 66%|██████▌   | 328/500 [03:58<01:18,  2.20it/s] 66%|██████▌   | 330/500 [03:58<00:57,  2.96it/s] 66%|██████▋   | 332/500 [04:05<03:19,  1.19s/it] 67%|██████▋   | 334/500 [04:05<02:21,  1.17it/s] 67%|██████▋   | 336/500 [04:05<01:40,  1.62it/s] 68%|██████▊   | 338/500 [04:05<01:12,  2.22it/s] 68%|██████▊   | 340/500 [04:05<00:53,  2.99it/s]Epoch:  274  	Training Loss: 0.0004572846810333431
Test Loss:  0.0006396128446795046
Valid Loss:  0.00040876478306017816
Epoch:  275  	Training Loss: 0.0004551969177555293
Test Loss:  0.0006364240543916821
Valid Loss:  0.00040717326919548213
Epoch:  276  	Training Loss: 0.00045333924936130643
Test Loss:  0.000631157192401588
Valid Loss:  0.00040561988134868443
Epoch:  277  	Training Loss: 0.00045161187881603837
Test Loss:  0.0006284299306571484
Valid Loss:  0.0004043008666485548
Epoch:  278  	Training Loss: 0.00045003299601376057
Test Loss:  0.0006241202354431152
Valid Loss:  0.00040302681736648083
Epoch:  279  	Training Loss: 0.00044855009764432907
Test Loss:  0.0006210771971382201
Valid Loss:  0.00040186214027926326
Epoch:  280  	Training Loss: 0.0004471489228308201
Test Loss:  0.000618072459474206
Valid Loss:  0.00040076550794765353
Epoch:  281  	Training Loss: 0.0004458343319129199
Test Loss:  0.000614953984040767
Valid Loss:  0.00039970228681340814
Epoch:  282  	Training Loss: 0.0004446046077646315
Test Loss:  0.0006154091679491103
Valid Loss:  0.0003993848222307861
Epoch:  283  	Training Loss: 0.00044409726979210973
Test Loss:  0.0006142170750536025
Valid Loss:  0.00039902079151943326
Epoch:  284  	Training Loss: 0.0004436708113644272
Test Loss:  0.0006129963439889252
Valid Loss:  0.000398669159039855
Epoch:  285  	Training Loss: 0.0004432635032571852
Test Loss:  0.0006118168821558356
Valid Loss:  0.00039833300979807973
Epoch:  286  	Training Loss: 0.00044287426862865686
Test Loss:  0.0006106775836087763
Valid Loss:  0.00039801292587071657
Epoch:  287  	Training Loss: 0.0004425027291290462
Test Loss:  0.0006095787975937128
Valid Loss:  0.00039770727744325995
Epoch:  288  	Training Loss: 0.0004421473713591695
Test Loss:  0.000608518545050174
Valid Loss:  0.0003974146966356784
Epoch:  289  	Training Loss: 0.0004418067110236734
Test Loss:  0.0006074935663491488
Valid Loss:  0.00039713497972115874
Epoch:  290  	Training Loss: 0.00044147943845018744
Test Loss:  0.0006065031629987061
Valid Loss:  0.00039686704985797405
Epoch:  291  	Training Loss: 0.00044116564095020294
Test Loss:  0.0006055462872609496
Valid Loss:  0.0003966091317124665
Epoch:  292  	Training Loss: 0.0004408639797475189
Test Loss:  0.0006016282713972032
Valid Loss:  0.0003954388666898012
Epoch:  293  	Training Loss: 0.00043971952982246876
Test Loss:  0.0005993450758978724
Valid Loss:  0.00039459828985854983
Epoch:  294  	Training Loss: 0.0004387463559396565
Test Loss:  0.0005975275998935103
Valid Loss:  0.000393939990317449
Epoch:  295  	Training Loss: 0.00043792917858809233
Test Loss:  0.0005958706606179476
Valid Loss:  0.00039340139483101666
Epoch:  296  	Training Loss: 0.0004372509429231286
Test Loss:  0.0005942571442574263
Valid Loss:  0.00039293334702961147
Epoch:  297  	Training Loss: 0.0004366450593806803
Test Loss:  0.000592764001339674
Valid Loss:  0.0003925550263375044
Epoch:  298  	Training Loss: 0.0004361175815574825
Test Loss:  0.0005913311033509672
Valid Loss:  0.00039220601320266724
Epoch:  299  	Training Loss: 0.0004356462450232357
Test Loss:  0.0005899823154322803
Valid Loss:  0.0003918868023902178
Epoch:  300  	Training Loss: 0.0004352147807367146
Test Loss:  0.0005887474399060011
Valid Loss:  0.00039162911707535386
Epoch:  301  	Training Loss: 0.00043484600610099733
Test Loss:  0.0005875278729945421
Valid Loss:  0.00039137207204476
Epoch:  302  	Training Loss: 0.00043452822137624025
Test Loss:  0.0005843807593919337
Valid Loss:  0.0003894177498295903
Epoch:  303  	Training Loss: 0.00043230384471826255
Test Loss:  0.000581644824706018
Valid Loss:  0.00038809695979580283
Epoch:  304  	Training Loss: 0.0004308050556574017
Test Loss:  0.0005795034812763333
Valid Loss:  0.00038723109173588455
Epoch:  305  	Training Loss: 0.0004298090352676809
Test Loss:  0.0005778492195531726
Valid Loss:  0.0003867116174660623
Epoch:  306  	Training Loss: 0.0004292392113711685
Test Loss:  0.000576602469664067
Valid Loss:  0.0003863622550852597
Epoch:  307  	Training Loss: 0.0004288367344997823
Test Loss:  0.0005755817401222885
Valid Loss:  0.0003861598379444331
Epoch:  308  	Training Loss: 0.00042860081885010004
Test Loss:  0.0005748232360929251
Valid Loss:  0.00038604525616392493
Epoch:  309  	Training Loss: 0.0004283870803192258
Test Loss:  0.0005741692730225623
Valid Loss:  0.00038594193756580353
Epoch:  310  	Training Loss: 0.00042819089139811695
Test Loss:  0.0005735933664254844
Valid Loss:  0.0003858454874716699
Epoch:  311  	Training Loss: 0.0004280088469386101
Test Loss:  0.0005730813718400896
Valid Loss:  0.0003857554402202368
Epoch:  312  	Training Loss: 0.00042783786193467677
Test Loss:  0.0005730194970965385
Valid Loss:  0.00038574059726670384
Epoch:  313  	Training Loss: 0.0004277955158613622
Test Loss:  0.0005728080868721008
Valid Loss:  0.0003857076808344573
Epoch:  314  	Training Loss: 0.0004277538391761482
Test Loss:  0.000572645862121135
Valid Loss:  0.00038567904266528785
Epoch:  315  	Training Loss: 0.00042771289008669555
Test Loss:  0.0005724820075556636
Valid Loss:  0.0003856495313812047
Epoch:  316  	Training Loss: 0.0004276717663742602
Test Loss:  0.000572330376598984
Valid Loss:  0.00038561958353966475
Epoch:  317  	Training Loss: 0.00042763142846524715
Test Loss:  0.0005721854977309704
Valid Loss:  0.0003855903632938862
Epoch:  318  	Training Loss: 0.0004275909159332514
Test Loss:  0.0005720477784052491
Valid Loss:  0.0003855606191791594
Epoch:  319  	Training Loss: 0.00042755124741233885
Test Loss:  0.0005719157634302974
Valid Loss:  0.00038553093327209353
Epoch:  320  	Training Loss: 0.0004275116662029177
Test Loss:  0.0005717907333746552
Valid Loss:  0.0003855005488730967
Epoch:  321  	Training Loss: 0.0004274719103705138
Test Loss:  0.0005716699524782598
Valid Loss:  0.00038547010626643896
Epoch:  322  	Training Loss: 0.0004274325619917363
Test Loss:  0.0005715619772672653
Valid Loss:  0.00038544548442587256
Epoch:  323  	Training Loss: 0.0004274000530131161
Test Loss:  0.0005714823491871357
Valid Loss:  0.00038542249239981174
Epoch:  324  	Training Loss: 0.0004273696686141193
Test Loss:  0.0005714105209335685
Valid Loss:  0.0003854003734886646
Epoch:  325  	Training Loss: 0.00042733963346108794
Test Loss:  0.0005713421269319952
Valid Loss:  0.0003853779926430434
Epoch:  326  	Training Loss: 0.00042730983113870025
Test Loss:  0.0005712760030291975
Valid Loss:  0.00038535564090125263
Epoch:  327  	Training Loss: 0.0004272795922588557
Test Loss:  0.000571209704503417
Valid Loss:  0.0003853329108096659
Epoch:  328  	Training Loss: 0.0004272504011169076
Test Loss:  0.0005711440462619066
Valid Loss:  0.0003853089874610305
Epoch:  329  	Training Loss: 0.00042722118087112904
Test Loss:  0.0005710766417905688
Valid Loss:  0.0003852875088341534
Epoch:  330  	Training Loss: 0.00042719184421002865
Test Loss:  0.0005710120312869549
Valid Loss:  0.00038526387652382255
Epoch:  331  	Training Loss: 0.00042716276948340237
Test Loss:  0.0005709456745535135
Valid Loss:  0.0003852407680824399
Epoch:  332  	Training Loss: 0.0004271332873031497
Test Loss:  0.0005698853638023138
Valid Loss:  0.00038443139055743814
Epoch:  333  	Training Loss: 0.00042637070873752236
Test Loss:  0.0005695813451893628
Valid Loss:  0.0003838655538856983
Epoch:  334  	Training Loss: 0.0004257330729160458
Test Loss:  0.0005694043356925249
Valid Loss:  0.0003834091476164758
Epoch:  335  	Training Loss: 0.00042521930299699306
Test Loss:  0.0005691911210305989
Valid Loss:  0.00038300291635096073
Epoch:  336  	Training Loss: 0.0004247573669999838
Test Loss:  0.0005689046229235828
Valid Loss:  0.00038262049201875925
Epoch:  337  	Training Loss: 0.000424317957367748
Test Loss:  0.0005685314536094666
Valid Loss:  0.0003822311700787395
Epoch:  338  	Training Loss: 0.00042388506699353456
Test Loss:  0.0005681862821802497
Valid Loss:  0.0003818658005911857
Epoch:  339  	Training Loss: 0.0004234591906424612
Test Loss:  0.0005677869194187224
Valid Loss:  0.0003814956871792674
Epoch:  340  	Training Loss: 0.00042302929796278477
Test Loss:  0.000567376846447587
Valid Loss:  0.0003811206843238324
Epoch:  341  	Training Loss: 0.0004225845914334059
Test Loss:  0.0005669693928211927
Valid Loss:   68%|██████▊   | 342/500 [04:12<03:06,  1.18s/it] 69%|██████▉   | 344/500 [04:12<02:11,  1.18it/s] 69%|██████▉   | 346/500 [04:12<01:34,  1.64it/s] 70%|██████▉   | 348/500 [04:12<01:07,  2.24it/s] 70%|███████   | 350/500 [04:12<00:49,  3.01it/s] 70%|███████   | 352/500 [04:18<02:54,  1.18s/it] 71%|███████   | 354/500 [04:19<02:03,  1.18it/s] 71%|███████   | 356/500 [04:19<01:28,  1.64it/s] 72%|███████▏  | 358/500 [04:19<01:03,  2.23it/s] 72%|███████▏  | 360/500 [04:19<00:46,  3.01it/s] 72%|███████▏  | 362/500 [04:25<02:42,  1.18s/it] 73%|███████▎  | 364/500 [04:25<01:54,  1.18it/s] 73%|███████▎  | 366/500 [04:25<01:21,  1.64it/s] 74%|███████▎  | 368/500 [04:26<00:58,  2.24it/s] 74%|███████▍  | 370/500 [04:26<00:43,  3.02it/s] 74%|███████▍  | 372/500 [04:32<02:29,  1.17s/it] 75%|███████▍  | 374/500 [04:32<01:45,  1.20it/s] 75%|███████▌  | 376/500 [04:32<01:14,  1.65it/s] 76%|███████▌  | 378/500 [04:32<00:53,  2.26it/s] 76%|███████▌  | 380/500 [04:32<00:39,  3.03it/s] 76%|███████▋  | 382/500 [04:39<02:18,  1.17s/it] 77%|███████▋  | 384/500 [04:39<01:37,  1.19it/s] 77%|███████▋  | 386/500 [04:39<01:09,  1.65it/s] 78%|███████▊  | 388/500 [04:39<00:49,  2.25it/s] 78%|███████▊  | 390/500 [04:39<00:36,  3.02it/s] 78%|███████▊  | 392/500 [04:46<02:08,  1.19s/it] 79%|███████▉  | 394/500 [04:46<01:30,  1.17it/s] 79%|███████▉  | 396/500 [04:52<02:39,  1.53s/it] 80%|███████▉  | 398/500 [04:52<01:51,  1.09s/it] 80%|████████  | 400/500 [04:52<01:18,  1.28it/s] 80%|████████  | 402/500 [04:59<02:26,  1.50s/it] 81%|████████  | 404/500 [04:59<01:42,  1.07s/it] 81%|████████  | 406/500 [04:59<01:12,  1.30it/s]0.00038074885378591716
Epoch:  342  	Training Loss: 0.0004221433773636818
Test Loss:  0.000563203648198396
Valid Loss:  0.0003770749317482114
Epoch:  343  	Training Loss: 0.00041822067578323185
Test Loss:  0.0005615664413198829
Valid Loss:  0.0003738469094969332
Epoch:  344  	Training Loss: 0.0004145191633142531
Test Loss:  0.000558826606720686
Valid Loss:  0.0003706987190525979
Epoch:  345  	Training Loss: 0.00041100772796198726
Test Loss:  0.0005565666942857206
Valid Loss:  0.0003677591448649764
Epoch:  346  	Training Loss: 0.00040765409357845783
Test Loss:  0.0005539997364394367
Valid Loss:  0.0003649290301837027
Epoch:  347  	Training Loss: 0.00040443456964567304
Test Loss:  0.0005515172379091382
Valid Loss:  0.00036222481867298484
Epoch:  348  	Training Loss: 0.00040133000584319234
Test Loss:  0.0005489300237968564
Valid Loss:  0.0003596124006435275
Epoch:  349  	Training Loss: 0.0003983249480370432
Test Loss:  0.0005463383276946843
Valid Loss:  0.00035709035000763834
Epoch:  350  	Training Loss: 0.0003954044950660318
Test Loss:  0.0005436930805444717
Valid Loss:  0.0003546402440406382
Epoch:  351  	Training Loss: 0.0003925558994524181
Test Loss:  0.0005410317098721862
Valid Loss:  0.00035225399187766016
Epoch:  352  	Training Loss: 0.0003897776477970183
Test Loss:  0.0005394394975155592
Valid Loss:  0.00035185489105060697
Epoch:  353  	Training Loss: 0.0003893207758665085
Test Loss:  0.0005381341325119138
Valid Loss:  0.0003514887357596308
Epoch:  354  	Training Loss: 0.0003888877108693123
Test Loss:  0.0005370220169425011
Valid Loss:  0.0003511440008878708
Epoch:  355  	Training Loss: 0.0003884726611431688
Test Loss:  0.0005360463401302695
Valid Loss:  0.0003508152440190315
Epoch:  356  	Training Loss: 0.0003880688745994121
Test Loss:  0.0005351658910512924
Valid Loss:  0.0003504983615130186
Epoch:  357  	Training Loss: 0.0003876749542541802
Test Loss:  0.0005343568045645952
Valid Loss:  0.0003501913452055305
Epoch:  358  	Training Loss: 0.0003872902016155422
Test Loss:  0.0005336008034646511
Valid Loss:  0.0003498920996207744
Epoch:  359  	Training Loss: 0.000386913277907297
Test Loss:  0.000532887876033783
Valid Loss:  0.0003496006247587502
Epoch:  360  	Training Loss: 0.0003865431353915483
Test Loss:  0.0005322103388607502
Valid Loss:  0.000349314883351326
Epoch:  361  	Training Loss: 0.0003861798904836178
Test Loss:  0.0005315603921189904
Valid Loss:  0.00034903595224022865
Epoch:  362  	Training Loss: 0.00038582325214520097
Test Loss:  0.0005316054448485374
Valid Loss:  0.0003487504436634481
Epoch:  363  	Training Loss: 0.00038531041354872286
Test Loss:  0.0005300415796227753
Valid Loss:  0.0003483959590084851
Epoch:  364  	Training Loss: 0.0003848610504064709
Test Loss:  0.000528881442733109
Valid Loss:  0.00034808667260222137
Epoch:  365  	Training Loss: 0.0003844416933134198
Test Loss:  0.0005277928430587053
Valid Loss:  0.00034779339330270886
Epoch:  366  	Training Loss: 0.00038404142833314836
Test Loss:  0.0005268031964078546
Valid Loss:  0.00034750899067148566
Epoch:  367  	Training Loss: 0.00038364596548490226
Test Loss:  0.0005259000463411212
Valid Loss:  0.0003472365206107497
Epoch:  368  	Training Loss: 0.0003832660149782896
Test Loss:  0.0005250723916105926
Valid Loss:  0.0003469748771749437
Epoch:  369  	Training Loss: 0.0003828990738838911
Test Loss:  0.0005243094637989998
Valid Loss:  0.0003467198694124818
Epoch:  370  	Training Loss: 0.00038254199898801744
Test Loss:  0.0005236029392108321
Valid Loss:  0.0003464743203949183
Epoch:  371  	Training Loss: 0.0003821937716566026
Test Loss:  0.0005229500238783658
Valid Loss:  0.0003462324966676533
Epoch:  372  	Training Loss: 0.00038185290759429336
Test Loss:  0.0005222937325015664
Valid Loss:  0.00034616683842614293
Epoch:  373  	Training Loss: 0.00038179894909262657
Test Loss:  0.0005218117730692029
Valid Loss:  0.0003461165470071137
Epoch:  374  	Training Loss: 0.00038175168447196484
Test Loss:  0.0005214441916905344
Valid Loss:  0.0003460735024418682
Epoch:  375  	Training Loss: 0.0003817082033492625
Test Loss:  0.0005211603129282594
Valid Loss:  0.0003460348816588521
Epoch:  376  	Training Loss: 0.00038166664307937026
Test Loss:  0.0005209376686252654
Valid Loss:  0.0003460007719695568
Epoch:  377  	Training Loss: 0.00038162610144354403
Test Loss:  0.000520750239957124
Valid Loss:  0.00034596744808368385
Epoch:  378  	Training Loss: 0.00038158585084602237
Test Loss:  0.0005205926718190312
Valid Loss:  0.00034593488089740276
Epoch:  379  	Training Loss: 0.0003815462114289403
Test Loss:  0.0005204579210840166
Valid Loss:  0.00034590507857501507
Epoch:  380  	Training Loss: 0.00038150674663484097
Test Loss:  0.0005203354521654546
Valid Loss:  0.00034587475238367915
Epoch:  381  	Training Loss: 0.0003814675728790462
Test Loss:  0.0005202234024181962
Valid Loss:  0.0003458447172306478
Epoch:  382  	Training Loss: 0.00038142810808494687
Test Loss:  0.0005110513302497566
Valid Loss:  0.0003379839181434363
Epoch:  383  	Training Loss: 0.00037307984894141555
Test Loss:  0.0005200935411266983
Valid Loss:  0.00033522467128932476
Epoch:  384  	Training Loss: 0.00036890621413476765
Test Loss:  0.0005084199365228415
Valid Loss:  0.0003321816329844296
Epoch:  385  	Training Loss: 0.0003661213268060237
Test Loss:  0.0005208135698921978
Valid Loss:  0.000331260496750474
Epoch:  386  	Training Loss: 0.0003639592323452234
Test Loss:  0.0005048573948442936
Valid Loss:  0.0003290419408585876
Epoch:  387  	Training Loss: 0.00036222219932824373
Test Loss:  0.000522434595040977
Valid Loss:  0.00032919569639489055
Epoch:  388  	Training Loss: 0.0003610584535636008
Test Loss:  0.0005004576523788273
Valid Loss:  0.0003274625341873616
Epoch:  389  	Training Loss: 0.0003600725613068789
Test Loss:  0.0005263612838461995
Valid Loss:  0.00032916702912189066
Epoch:  390  	Training Loss: 0.00036018239916302264
Test Loss:  0.0004963771789334714
Valid Loss:  0.00032844627276062965
Epoch:  391  	Training Loss: 0.0003604800149332732
Test Loss:  0.0005345882964320481
Valid Loss:  0.00033249397529289126
Epoch:  392  	Training Loss: 0.00036260992055758834
Test Loss:  0.0005100692505948246
Valid Loss:  0.0003230241418350488
Epoch:  393  	Training Loss: 0.0003532403497956693
Test Loss:  0.0004974583862349391
Valid Loss:  0.0003193549928255379
Epoch:  394  	Training Loss: 0.0003496511490084231
Test Loss:  0.0004905267851427197
Valid Loss:  0.0003178277984261513
Epoch:  395  	Training Loss: 0.0003481655730865896
Test Loss:  0.0004865384253207594
Valid Loss:  0.0003171081771142781
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.00034746003802865744
Test Loss:  0.0004854853614233434
Valid Loss:  0.0003167704853694886
Epoch:  397  	Training Loss: 0.0003471238596830517
Test Loss:  0.00048466265434399247
Valid Loss:  0.0003165032248944044
Epoch:  398  	Training Loss: 0.00034684347338043153
Test Loss:  0.0004839918401557952
Valid Loss:  0.00031628774013370275
Epoch:  399  	Training Loss: 0.00034662536927498877
Test Loss:  0.00048343889648094773
Valid Loss:  0.00031608945573680103
Epoch:  400  	Training Loss: 0.00034641852835193276
Test Loss:  0.00048296665772795677
Valid Loss:  0.00031590397702530026
Epoch:  401  	Training Loss: 0.00034622004022821784
Test Loss:  0.0004825516662094742
Valid Loss:  0.0003157264436595142
Epoch:  402  	Training Loss: 0.00034604640677571297
Test Loss:  0.0004822116461582482
Valid Loss:  0.00031542283250018954
Epoch:  403  	Training Loss: 0.0003457161656115204
Test Loss:  0.0004818759625777602
Valid Loss:  0.0003151539131067693
Epoch:  404  	Training Loss: 0.0003454169200267643
Test Loss:  0.0004815473221242428
Valid Loss:  0.00031492416746914387
Epoch:  405  	Training Loss: 0.00034513871651142836
Test Loss:  0.0004812335246242583
Valid Loss:  0.00031469896202906966
Epoch:  406  	Training Loss: 0.00034486493677832186
Test Loss:  0.0004809298843611032
Valid Loss:  0.0003144886577501893
Epoch:  407  	Training Loss: 0.00034459703601896763
Test Loss:  0.000480636052088812
Valid Loss:  0.0003142873174510896
Epoch:  408  	Training Loss: 0.00034434121334925294
Test Loss:   82%|████████▏ | 408/500 [04:59<00:51,  1.80it/s] 82%|████████▏ | 410/500 [04:59<00:36,  2.44it/s] 82%|████████▏ | 412/500 [05:06<01:50,  1.26s/it] 83%|████████▎ | 414/500 [05:06<01:17,  1.11it/s] 83%|████████▎ | 416/500 [05:06<00:54,  1.54it/s] 84%|████████▎ | 418/500 [05:06<00:38,  2.11it/s] 84%|████████▍ | 420/500 [05:06<00:28,  2.84it/s] 84%|████████▍ | 422/500 [05:13<01:35,  1.23s/it] 85%|████████▍ | 424/500 [05:13<01:06,  1.14it/s] 85%|████████▌ | 426/500 [05:13<00:47,  1.57it/s] 86%|████████▌ | 428/500 [05:13<00:33,  2.15it/s] 86%|████████▌ | 430/500 [05:13<00:24,  2.89it/s] 86%|████████▋ | 432/500 [05:19<01:20,  1.18s/it] 87%|████████▋ | 434/500 [05:20<00:55,  1.18it/s] 87%|████████▋ | 436/500 [05:20<00:39,  1.64it/s] 88%|████████▊ | 438/500 [05:20<00:27,  2.24it/s] 88%|████████▊ | 440/500 [05:20<00:19,  3.01it/s] 88%|████████▊ | 442/500 [05:26<01:08,  1.17s/it] 89%|████████▉ | 444/500 [05:26<00:47,  1.19it/s] 89%|████████▉ | 446/500 [05:27<00:32,  1.65it/s] 90%|████████▉ | 448/500 [05:27<00:23,  2.25it/s] 90%|█████████ | 450/500 [05:27<00:16,  3.03it/s] 90%|█████████ | 452/500 [05:33<00:56,  1.18s/it] 91%|█████████ | 454/500 [05:33<00:38,  1.18it/s] 91%|█████████ | 456/500 [05:33<00:26,  1.64it/s] 92%|█████████▏| 458/500 [05:33<00:18,  2.24it/s] 92%|█████████▏| 460/500 [05:34<00:13,  3.00it/s] 92%|█████████▏| 462/500 [05:40<00:44,  1.17s/it] 93%|█████████▎| 464/500 [05:40<00:30,  1.20it/s] 93%|█████████▎| 466/500 [05:40<00:20,  1.65it/s] 94%|█████████▎| 468/500 [05:40<00:14,  2.25it/s] 94%|█████████▍| 470/500 [05:40<00:09,  3.02it/s] 94%|█████████▍| 472/500 [05:47<00:32,  1.16s/it] 95%|█████████▍| 474/500 [05:47<00:21,  1.20it/s]0.00048034981591627
Valid Loss:  0.00031409336952492595
Epoch:  409  	Training Loss: 0.0003440986620262265
Test Loss:  0.00048007501754909754
Valid Loss:  0.0003139030304737389
Epoch:  410  	Training Loss: 0.0003438736603129655
Test Loss:  0.0004798042355105281
Valid Loss:  0.00031372607918456197
Epoch:  411  	Training Loss: 0.0003436618426349014
Test Loss:  0.0004795501008629799
Valid Loss:  0.0003135526494588703
Epoch:  412  	Training Loss: 0.00034345471067354083
Test Loss:  0.0004777900758199394
Valid Loss:  0.00031231215689331293
Epoch:  413  	Training Loss: 0.00034211069578304887
Test Loss:  0.00047645007725805044
Valid Loss:  0.000311175623210147
Epoch:  414  	Training Loss: 0.00034084319486282766
Test Loss:  0.0004753437533508986
Valid Loss:  0.00031010020757094026
Epoch:  415  	Training Loss: 0.0003396242100279778
Test Loss:  0.0004743636818602681
Valid Loss:  0.00030907196924090385
Epoch:  416  	Training Loss: 0.0003384471347089857
Test Loss:  0.0004734499962069094
Valid Loss:  0.00030807562870904803
Epoch:  417  	Training Loss: 0.00033729535061866045
Test Loss:  0.00047257920959964395
Valid Loss:  0.00030710233841091394
Epoch:  418  	Training Loss: 0.0003361694107297808
Test Loss:  0.0004717279807664454
Valid Loss:  0.0003061527095269412
Epoch:  419  	Training Loss: 0.000335067103151232
Test Loss:  0.0004708800988737494
Valid Loss:  0.0003052246756851673
Epoch:  420  	Training Loss: 0.0003339858667459339
Test Loss:  0.00047002817154861987
Valid Loss:  0.0003043162287212908
Epoch:  421  	Training Loss: 0.0003329241881147027
Test Loss:  0.0004691721114795655
Valid Loss:  0.0003034253604710102
Epoch:  422  	Training Loss: 0.00033188180532306433
Test Loss:  0.00046918305451981723
Valid Loss:  0.000303294655168429
Epoch:  423  	Training Loss: 0.00033170011010952294
Test Loss:  0.00046907621435821056
Valid Loss:  0.0003031719825230539
Epoch:  424  	Training Loss: 0.0003315356734674424
Test Loss:  0.00046888116048648953
Valid Loss:  0.0003030500956811011
Epoch:  425  	Training Loss: 0.0003313772613182664
Test Loss:  0.00046864262549206614
Valid Loss:  0.0003029328945558518
Epoch:  426  	Training Loss: 0.00033123797038570046
Test Loss:  0.00046837973059155047
Valid Loss:  0.0003028221835847944
Epoch:  427  	Training Loss: 0.00033110729418694973
Test Loss:  0.0004681034479290247
Valid Loss:  0.0003027161583304405
Epoch:  428  	Training Loss: 0.00033098860876634717
Test Loss:  0.00046780682168900967
Valid Loss:  0.0003026106860488653
Epoch:  429  	Training Loss: 0.00033087554038502276
Test Loss:  0.00046751333866268396
Valid Loss:  0.00030251138377934694
Epoch:  430  	Training Loss: 0.00033076945692300797
Test Loss:  0.00046721036778762937
Valid Loss:  0.0003024282050319016
Epoch:  431  	Training Loss: 0.00033066817559301853
Test Loss:  0.0004669184563681483
Valid Loss:  0.0003023542230948806
Epoch:  432  	Training Loss: 0.0003305734717287123
Test Loss:  0.00046641661901958287
Valid Loss:  0.0003012834640685469
Epoch:  433  	Training Loss: 0.0003295181377325207
Test Loss:  0.00046613989979960024
Valid Loss:  0.0003004994068760425
Epoch:  434  	Training Loss: 0.0003286366118118167
Test Loss:  0.000465928518678993
Valid Loss:  0.000299941428238526
Epoch:  435  	Training Loss: 0.00032796672894619405
Test Loss:  0.00046581769129261374
Valid Loss:  0.0002995591494254768
Epoch:  436  	Training Loss: 0.00032749370438978076
Test Loss:  0.00046569539699703455
Valid Loss:  0.0002992580411955714
Epoch:  437  	Training Loss: 0.00032711701351217926
Test Loss:  0.0004655789816752076
Valid Loss:  0.0002990013163071126
Epoch:  438  	Training Loss: 0.0003268241125624627
Test Loss:  0.00046543756616301835
Valid Loss:  0.0002987866464536637
Epoch:  439  	Training Loss: 0.00032657908741384745
Test Loss:  0.00046526023652404547
Valid Loss:  0.0002986089966725558
Epoch:  440  	Training Loss: 0.000326360110193491
Test Loss:  0.00046509195817634463
Valid Loss:  0.00029844039818271995
Epoch:  441  	Training Loss: 0.00032617629040032625
Test Loss:  0.0004650295595638454
Valid Loss:  0.0002983126323670149
Epoch:  442  	Training Loss: 0.000326018052874133
Test Loss:  0.0004645066801458597
Valid Loss:  0.00029824412195011973
Epoch:  443  	Training Loss: 0.0003259448567405343
Test Loss:  0.00046403793385252357
Valid Loss:  0.00029818248003721237
Epoch:  444  	Training Loss: 0.000325876462738961
Test Loss:  0.0004636129015125334
Valid Loss:  0.0002981254365295172
Epoch:  445  	Training Loss: 0.00032581196865066886
Test Loss:  0.0004632235213648528
Valid Loss:  0.0002980730205308646
Epoch:  446  	Training Loss: 0.0003257511416450143
Test Loss:  0.00046286513679660857
Valid Loss:  0.0002980230492539704
Epoch:  447  	Training Loss: 0.000325692817568779
Test Loss:  0.00046253137406893075
Valid Loss:  0.00029797665774822235
Epoch:  448  	Training Loss: 0.00032563688000664115
Test Loss:  0.00046221830416470766
Valid Loss:  0.0002979323035106063
Epoch:  449  	Training Loss: 0.0003255829797126353
Test Loss:  0.0004619237151928246
Valid Loss:  0.0002978909178636968
Epoch:  450  	Training Loss: 0.0003255310875829309
Test Loss:  0.00046164379455149174
Valid Loss:  0.0002978505508508533
Epoch:  451  	Training Loss: 0.0003254805924370885
Test Loss:  0.0004613770288415253
Valid Loss:  0.00029781213379465044
Epoch:  452  	Training Loss: 0.0003254319599363953
Test Loss:  0.00045631456305272877
Valid Loss:  0.0002950814086943865
Epoch:  453  	Training Loss: 0.0003222993400413543
Test Loss:  0.0004568157601170242
Valid Loss:  0.00029327673837542534
Epoch:  454  	Training Loss: 0.00032009766437113285
Test Loss:  0.00045365787809714675
Valid Loss:  0.0002916333614848554
Epoch:  455  	Training Loss: 0.0003181416541337967
Test Loss:  0.0004522959643509239
Valid Loss:  0.00029021722730249166
Epoch:  456  	Training Loss: 0.00031638878863304853
Test Loss:  0.0004496896581258625
Valid Loss:  0.00028883825871162117
Epoch:  457  	Training Loss: 0.0003147254465147853
Test Loss:  0.00044750532833859324
Valid Loss:  0.0002874817291740328
Epoch:  458  	Training Loss: 0.00031311018392443657
Test Loss:  0.0004453107248991728
Valid Loss:  0.0002861892571672797
Epoch:  459  	Training Loss: 0.0003115915460512042
Test Loss:  0.00044289216748438776
Valid Loss:  0.0002849088632501662
Epoch:  460  	Training Loss: 0.00031011481769382954
Test Loss:  0.0004408465465530753
Valid Loss:  0.00028369732899591327
Epoch:  461  	Training Loss: 0.0003087078221142292
Test Loss:  0.0004384292697068304
Valid Loss:  0.00028249298338778317
Epoch:  462  	Training Loss: 0.0003073190164286643
Test Loss:  0.0004380641912575811
Valid Loss:  0.00028226885478943586
Epoch:  463  	Training Loss: 0.00030704191885888577
Test Loss:  0.00043754937360063195
Valid Loss:  0.00028206242132000625
Epoch:  464  	Training Loss: 0.0003067839134018868
Test Loss:  0.000436963455285877
Valid Loss:  0.000281865504803136
Epoch:  465  	Training Loss: 0.000306537258438766
Test Loss:  0.00043634892790578306
Valid Loss:  0.00028167630080133677
Epoch:  466  	Training Loss: 0.00030630046967417
Test Loss:  0.000435729423770681
Valid Loss:  0.0002814949257299304
Epoch:  467  	Training Loss: 0.00030607200460508466
Test Loss:  0.0004351178649812937
Valid Loss:  0.00028131960425525904
Epoch:  468  	Training Loss: 0.00030585058266296983
Test Loss:  0.0004345192573964596
Valid Loss:  0.0002811499871313572
Epoch:  469  	Training Loss: 0.0003056361456401646
Test Loss:  0.00043393863597884774
Valid Loss:  0.0002809867437463254
Epoch:  470  	Training Loss: 0.00030542799504473805
Test Loss:  0.0004333753604441881
Valid Loss:  0.0002808280405588448
Epoch:  471  	Training Loss: 0.0003052256361115724
Test Loss:  0.0004328306531533599
Valid Loss:  0.0002806748088914901
Epoch:  472  	Training Loss: 0.0003050288069061935
Test Loss:  0.0004323412722442299
Valid Loss:  0.00028057751478627324
Epoch:  473  	Training Loss: 0.00030490680364891887
Test Loss:  0.00043183841626159847
Valid Loss:  0.0002804886316880584
Epoch:  474  	Training Loss: 0.00030479684937745333
Test Loss:  0.0004313526442274451
Valid Loss:  0.0002804066753014922
Epoch:  475  	Training Loss: 0.00030469606281258166
Test Loss:  0.00043088640086352825
Valid Loss:  0.00028033365379087627
 95%|█████████▌| 476/500 [05:47<00:14,  1.66it/s] 96%|█████████▌| 478/500 [05:47<00:09,  2.27it/s] 96%|█████████▌| 480/500 [05:47<00:06,  3.05it/s] 96%|█████████▋| 482/500 [05:53<00:20,  1.16s/it] 97%|█████████▋| 484/500 [05:53<00:13,  1.20it/s] 97%|█████████▋| 486/500 [05:54<00:08,  1.66it/s] 98%|█████████▊| 488/500 [05:54<00:05,  2.27it/s] 98%|█████████▊| 490/500 [05:54<00:03,  3.05it/s] 98%|█████████▊| 492/500 [06:00<00:09,  1.18s/it] 99%|█████████▉| 494/500 [06:00<00:05,  1.19it/s] 99%|█████████▉| 496/500 [06:00<00:02,  1.64it/s]100%|█████████▉| 498/500 [06:01<00:00,  2.24it/s]100%|██████████| 500/500 [06:01<00:00,  3.00it/s]100%|██████████| 500/500 [06:01<00:00,  1.38it/s]
Epoch:  476  	Training Loss: 0.0003046044730581343
Test Loss:  0.0004304349422454834
Valid Loss:  0.0002802636008709669
Epoch:  477  	Training Loss: 0.0003045183257199824
Test Loss:  0.00043000117875635624
Valid Loss:  0.00028019832097925246
Epoch:  478  	Training Loss: 0.0003044372424483299
Test Loss:  0.00042958761332556605
Valid Loss:  0.0002801356604322791
Epoch:  479  	Training Loss: 0.0003043606411665678
Test Loss:  0.000429194828029722
Valid Loss:  0.00028007570654153824
Epoch:  480  	Training Loss: 0.0003042884054593742
Test Loss:  0.0004288211348466575
Valid Loss:  0.0002800189540721476
Epoch:  481  	Training Loss: 0.0003042204771190882
Test Loss:  0.00042847380973398685
Valid Loss:  0.00027996869175694883
Epoch:  482  	Training Loss: 0.00030415854416787624
Test Loss:  0.0004266038886271417
Valid Loss:  0.0002795715699903667
Epoch:  483  	Training Loss: 0.0003037526912521571
Test Loss:  0.0004259733541402966
Valid Loss:  0.00027936912374570966
Epoch:  484  	Training Loss: 0.0003035578120034188
Test Loss:  0.000425787060521543
Valid Loss:  0.00027923210291191936
Epoch:  485  	Training Loss: 0.00030343368416652083
Test Loss:  0.00042573013342916965
Valid Loss:  0.00027914484962821007
Epoch:  486  	Training Loss: 0.0003033355751540512
Test Loss:  0.00042550457874312997
Valid Loss:  0.0002790513972286135
Epoch:  487  	Training Loss: 0.00030324404360726476
Test Loss:  0.00042522497824393213
Valid Loss:  0.00027895253151655197
Epoch:  488  	Training Loss: 0.0003031547530554235
Test Loss:  0.00042492678039707243
Valid Loss:  0.00027885165764018893
Epoch:  489  	Training Loss: 0.00030306694679893553
Test Loss:  0.00042462791316211224
Valid Loss:  0.0002787517150864005
Epoch:  490  	Training Loss: 0.00030297989724203944
Test Loss:  0.0004243330913595855
Valid Loss:  0.00027865104493685067
Epoch:  491  	Training Loss: 0.00030289957066997886
Test Loss:  0.000424123922130093
Valid Loss:  0.00027858075918629766
Epoch:  492  	Training Loss: 0.00030282733496278524
Test Loss:  0.00042367156129330397
Valid Loss:  0.0002784007810987532
Epoch:  493  	Training Loss: 0.00030262948712334037
Test Loss:  0.0004232464707456529
Valid Loss:  0.00027822080301120877
Epoch:  494  	Training Loss: 0.00030243326909840107
Test Loss:  0.00042291812133044004
Valid Loss:  0.0002780730137601495
Epoch:  495  	Training Loss: 0.0003022442979272455
Test Loss:  0.00042252690764144063
Valid Loss:  0.000277916609775275
Epoch:  496  	Training Loss: 0.00030205881921574473
Test Loss:  0.00042212498374283314
Valid Loss:  0.0002777564513962716
Epoch:  497  	Training Loss: 0.0003018745337612927
Test Loss:  0.0004217300156597048
Valid Loss:  0.0002775936736725271
Epoch:  498  	Training Loss: 0.0003016912378370762
Test Loss:  0.0004213459324091673
Valid Loss:  0.0002774287713691592
Epoch:  499  	Training Loss: 0.00030150910606607795
Test Loss:  0.00042097424739040434
Valid Loss:  0.0002772639272734523
Epoch:  500  	Training Loss: 0.00030132802203297615
Test Loss:  0.00042061269050464034
Valid Loss:  0.0002770980354398489
seed is  20
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.34it/s]  1%|          | 4/500 [00:00<00:30, 16.27it/s]  1%|          | 6/500 [00:00<00:30, 16.40it/s]  2%|▏         | 8/500 [00:00<00:29, 16.48it/s]  2%|▏         | 10/500 [00:00<00:29, 16.41it/s]  2%|▏         | 12/500 [00:00<00:29, 16.31it/s]  3%|▎         | 14/500 [00:00<00:29, 16.33it/s]  3%|▎         | 16/500 [00:00<00:29, 16.44it/s]  4%|▎         | 18/500 [00:01<00:29, 16.48it/s]  4%|▍         | 20/500 [00:01<00:29, 16.53it/s]  4%|▍         | 22/500 [00:01<00:28, 16.59it/s]  5%|▍         | 24/500 [00:01<00:28, 16.60it/s]  5%|▌         | 26/500 [00:01<00:28, 16.59it/s]  6%|▌         | 28/500 [00:01<00:28, 16.58it/s]  6%|▌         | 30/500 [00:01<00:28, 16.42it/s]  6%|▋         | 32/500 [00:01<00:28, 16.38it/s]  7%|▋         | 34/500 [00:02<00:28, 16.42it/s]  7%|▋         | 36/500 [00:02<00:28, 16.48it/s]  8%|▊         | 38/500 [00:02<00:27, 16.51it/s]  8%|▊         | 40/500 [00:02<00:28, 16.41it/s]  8%|▊         | 42/500 [00:02<00:28, 16.26it/s]  9%|▉         | 44/500 [00:02<00:27, 16.34it/s]  9%|▉         | 46/500 [00:02<00:27, 16.51it/s] 10%|▉         | 48/500 [00:02<00:27, 16.54it/s] 10%|█         | 50/500 [00:03<00:27, 16.49it/s] 10%|█         | 52/500 [00:03<00:27, 16.54it/s] 11%|█         | 54/500 [00:03<00:27, 16.47it/s] 11%|█         | 56/500 [00:03<00:26, 16.53it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.55it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.62it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.50it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.53it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.61it/s] 14%|█▎        | 68/500 [00:04<00:25, 16.71it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.50it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.48it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.47it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.44it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.52it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.54it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.51it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.62it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.61it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.59it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.59it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.52it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.46it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.55it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.63it/s] 20%|██        | 100/500 [00:06<00:24, 16.59it/s] 20%|██        | 102/500 [00:06<00:24, 16.55it/s] 21%|██        | 104/500 [00:06<00:23, 16.58it/s] 21%|██        | 106/500 [00:06<00:23, 16.59it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.59it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.61it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.68it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.62it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.48it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.58it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.55it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.60it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.61it/s]Epoch:  1  	Training Loss: 0.22666406631469727
Test Loss:  3732.70654296875
Valid Loss:  3738.90478515625
Epoch:  2  	Training Loss: 3736.45068359375
Test Loss:  136791025778688.0
Valid Loss:  137335706484736.0
Epoch:  3  	Training Loss: 137229691256832.0
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.67it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.62it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.60it/s] 26%|██▋       | 132/500 [00:07<00:22, 16.37it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.26it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.18it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.31it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.40it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.48it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.53it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.57it/s] 30%|██▉       | 148/500 [00:08<00:21, 16.58it/s] 30%|███       | 150/500 [00:09<00:21, 16.65it/s] 30%|███       | 152/500 [00:09<00:21, 16.48it/s] 31%|███       | 154/500 [00:09<00:21, 16.48it/s] 31%|███       | 156/500 [00:09<00:20, 16.52it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.56it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.44it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.52it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.55it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.60it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.58it/s] 34%|███▍      | 170/500 [00:10<00:19, 16.56it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.51it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.54it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.52it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.57it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.60it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.49it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.50it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.46it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.47it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.50it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.52it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.55it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.58it/s] 40%|███▉      | 198/500 [00:11<00:18, 16.55it/s] 40%|████      | 200/500 [00:12<00:18, 16.59it/s] 40%|████      | 202/500 [00:12<00:17, 16.61it/s] 41%|████      | 204/500 [00:12<00:17, 16.60it/s] 41%|████      | 206/500 [00:12<00:17, 16.61it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.60it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.46it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.56it/s] 43%|████▎     | 214/500 [00:12<00:17, 16.66it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.68it/s] 44%|████▎     | 218/500 [00:13<00:16, 16.63it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.52it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.36it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.37it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.29it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.31it/s] 46%|████▌     | 230/500 [00:13<00:16, 16.35it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.32it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.40it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.41it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.39it/s] 48%|████▊     | 240/500 [00:14<00:16, 16.17it/s] 48%|████▊     | 242/500 [00:14<00:16, 16.11it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.03it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.17it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.34it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.23it/s] 50%|█████     | 252/500 [00:15<00:15, 16.36it/s] 51%|█████     | 254/500 [00:15<00:14, 16.44it/s] 51%|█████     | 256/500 [00:15<00:14, 16.56it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.43it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.14it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.24it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.41it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.48it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.48it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.53it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.42it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.48it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.37it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.50it/s] 56%|█████▌    | 280/500 [00:16<00:13, 16.57it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.55it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.40it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.31it/s] 58%|█████▊    | 288/500 [00:17<00:13, 16.21it/s] 58%|█████▊    | 290/500 [00:17<00:13, 16.13it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.15it/s] 59%|█████▉    | 294/500 [00:17<00:12, 15.91it/s] 59%|█████▉    | 296/500 [00:17<00:12, 15.95it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.93it/s] 60%|██████    | 300/500 [00:18<00:12, 15.93it/s] 60%|██████    | 302/500 [00:18<00:13, 15.20it/s] 61%|██████    | 304/500 [00:18<00:12, 15.45it/s] 61%|██████    | 306/500 [00:18<00:12, 15.55it/s] 62%|██████▏   | 308/500 [00:18<00:12, 15.69it/s] 62%|██████▏   | 310/500 [00:18<00:12, 15.74it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.82it/s] 63%|██████▎   | 314/500 [00:19<00:11, 15.91it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.87it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.68it/s] 64%|██████▍   | 320/500 [00:19<00:11, 15.84it/s] 64%|██████▍   | 322/500 [00:19<00:11, 15.90it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.06it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.14it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.10it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.08it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.21it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.26it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.32it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.33it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.38it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.46it/s] 69%|██████▉   | 344/500 [00:20<00:09, 16.54it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.48it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.41it/s] 70%|███████   | 350/500 [00:21<00:09, 16.35it/s] 70%|███████   | 352/500 [00:21<00:09, 16.35it/s] 71%|███████   | 354/500 [00:21<00:08, 16.32it/s] 71%|███████   | 356/500 [00:21<00:08, 16.39it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.49it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.35it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.44it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.46it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.52it/s] 74%|███████▎  | 368/500 [00:22<00:07, 16.50it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.27it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.29it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.39it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.49it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.56it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.61it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.59it/s] 77%|███████▋  | 384/500 [00:23<00:06, 16.64it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.66it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.55it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.58it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.56it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.55it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.35it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.43it/s] 80%|████████  | 400/500 [00:24<00:06, 16.44it/s] 80%|████████  | 402/500 [00:24<00:05, 16.48it/s] 81%|████████  | 404/500 [00:24<00:05, 16.55it/s] 81%|████████  | 406/500 [00:24<00:05, 16.58it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.62it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.60it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.62it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.58it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.54it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.48it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.62it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.54it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.62it/s] 85%|████████▌ | 426/500 [00:25<00:04, 16.59it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.35it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.47it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.38it/s] 87%|████████▋ | 434/500 [00:26<00:03, 16.54it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.61it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.60it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.60it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.59it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.51it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.45it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.48it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.40it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.37it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.47it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.56it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.60it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.57it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.55it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.20it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.29it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.23it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.23it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.24it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.32it/s] 95%|█████████▌| 476/500 [00:28<00:01, 16.43it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.55it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.56it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.57it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.59it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.60it/s] 98%|█████████▊| 488/500 [00:29<00:00, 16.57it/s] 98%|█████████▊| 490/500 [00:29<00:00, 16.58it/s] 98%|█████████▊| 492/500 [00:29<00:00, 16.45it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.42it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.49it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.52it/s]100%|██████████| 500/500 [00:30<00:00, 16.57it/s]100%|██████████| 500/500 [00:30<00:00, 16.43it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  20
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:32,  6.20s/it]  1%|          | 3/500 [00:06<13:44,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:20<09:46,  1.22s/it]  5%|▍         | 23/500 [00:20<06:56,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.59it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:26<09:09,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:27<04:42,  1.65it/s]  7%|▋         | 37/500 [00:27<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<09:14,  1.21s/it]  9%|▊         | 43/500 [00:33<06:37,  1.15it/s]  9%|▉         | 45/500 [00:34<04:46,  1.59it/s]  9%|▉         | 47/500 [00:34<03:28,  2.17it/s] 10%|▉         | 49/500 [00:34<02:33,  2.93it/s] 10%|█         | 51/500 [00:40<08:51,  1.18s/it] 11%|█         | 53/500 [00:40<06:19,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:27,  3.00it/s] 12%|█▏        | 61/500 [00:47<08:36,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:48<02:23,  3.01it/s]Epoch:  1  	Training Loss: 0.22666405141353607
Test Loss:  373.10870361328125
Valid Loss:  372.7251892089844
Epoch:  2  	Training Loss: 373.1944885253906
Test Loss:  0.1916494071483612
Valid Loss:  0.17571884393692017
Epoch:  3  	Training Loss: 0.18301929533481598
Test Loss:  0.11733194440603256
Valid Loss:  0.10622840374708176
Epoch:  4  	Training Loss: 0.11164430528879166
Test Loss:  0.0743551105260849
Valid Loss:  0.06679020822048187
Epoch:  5  	Training Loss: 0.0708269402384758
Test Loss:  0.049304038286209106
Valid Loss:  0.044326361268758774
Epoch:  6  	Training Loss: 0.04735259339213371
Test Loss:  0.03453155606985092
Valid Loss:  0.031440675258636475
Epoch:  7  	Training Loss: 0.033725593239068985
Test Loss:  0.025674492120742798
Valid Loss:  0.02395578846335411
Epoch:  8  	Training Loss: 0.025696150958538055
Test Loss:  0.020239058881998062
Valid Loss:  0.01951516792178154
Epoch:  9  	Training Loss: 0.020854854956269264
Test Loss:  0.016796790063381195
Valid Loss:  0.01679128035902977
Epoch:  10  	Training Loss: 0.01783560961484909
Test Loss:  0.014526673592627048
Valid Loss:  0.01503730472177267
Epoch:  11  	Training Loss: 0.01586339622735977
Test Loss:  0.0129548953846097
Valid Loss:  0.013833817094564438
Epoch:  12  	Training Loss: 0.01449822448194027
Test Loss:  0.011779981665313244
Valid Loss:  0.012925289571285248
Epoch:  13  	Training Loss: 0.013466572389006615
Test Loss:  0.010877875611186028
Valid Loss:  0.012208567000925541
Epoch:  14  	Training Loss: 0.01265803538262844
Test Loss:  0.01014993991702795
Valid Loss:  0.011606899090111256
Epoch:  15  	Training Loss: 0.011987539939582348
Test Loss:  0.00953730009496212
Valid Loss:  0.011077361181378365
Epoch:  16  	Training Loss: 0.011406123638153076
Test Loss:  0.009004347026348114
Valid Loss:  0.010596029460430145
Epoch:  17  	Training Loss: 0.01088541466742754
Test Loss:  0.008529148995876312
Valid Loss:  0.010149484500288963
Epoch:  18  	Training Loss: 0.010408722795546055
Test Loss:  0.00809791125357151
Valid Loss:  0.009730196557939053
Epoch:  19  	Training Loss: 0.009966123849153519
Test Loss:  0.007701702881604433
Valid Loss:  0.009333780035376549
Epoch:  20  	Training Loss: 0.009551497176289558
Test Loss:  0.007334579713642597
Valid Loss:  0.008957618847489357
Epoch:  21  	Training Loss: 0.009160907939076424
Test Loss:  0.006992388982325792
Valid Loss:  0.008600062690675259
Epoch:  22  	Training Loss: 0.008791739121079445
Test Loss:  0.006672034040093422
Valid Loss:  0.008260006085038185
Epoch:  23  	Training Loss: 0.008442121557891369
Test Loss:  0.006371494382619858
Valid Loss:  0.007936405017971992
Epoch:  24  	Training Loss: 0.008110594935715199
Test Loss:  0.006088940426707268
Valid Loss:  0.007628465536981821
Epoch:  25  	Training Loss: 0.0077959876507520676
Test Loss:  0.005822993349283934
Valid Loss:  0.0073354775086045265
Epoch:  26  	Training Loss: 0.007497284561395645
Test Loss:  0.005572442431002855
Valid Loss:  0.0070567624643445015
Epoch:  27  	Training Loss: 0.0072136251255869865
Test Loss:  0.005336245987564325
Valid Loss:  0.006791661959141493
Epoch:  28  	Training Loss: 0.0069441767409443855
Test Loss:  0.005113501567393541
Valid Loss:  0.006539582274854183
Epoch:  29  	Training Loss: 0.006688219495117664
Test Loss:  0.0049033863469958305
Valid Loss:  0.006299913860857487
Epoch:  30  	Training Loss: 0.006445057224482298
Test Loss:  0.004705164581537247
Valid Loss:  0.006072073709219694
Epoch:  31  	Training Loss: 0.006214042194187641
Test Loss:  0.004518155939877033
Valid Loss:  0.0058554913848638535
Epoch:  32  	Training Loss: 0.005994562990963459
Test Loss:  0.004341723397374153
Valid Loss:  0.005649607628583908
Epoch:  33  	Training Loss: 0.005786004476249218
Test Loss:  0.004175285808742046
Valid Loss:  0.005453932099044323
Epoch:  34  	Training Loss: 0.005587874911725521
Test Loss:  0.004018308129161596
Valid Loss:  0.005267978645861149
Epoch:  35  	Training Loss: 0.00539963087067008
Test Loss:  0.0038702753372490406
Valid Loss:  0.005091273225843906
Epoch:  36  	Training Loss: 0.005220786668360233
Test Loss:  0.0037307054735720158
Valid Loss:  0.004923366475850344
Epoch:  37  	Training Loss: 0.005050871521234512
Test Loss:  0.003599132178351283
Valid Loss:  0.00476380018517375
Epoch:  38  	Training Loss: 0.004889432340860367
Test Loss:  0.00347513472661376
Valid Loss:  0.004612173419445753
Epoch:  39  	Training Loss: 0.004736054688692093
Test Loss:  0.003358290297910571
Valid Loss:  0.004468107130378485
Epoch:  40  	Training Loss: 0.0045903329737484455
Test Loss:  0.00324825057759881
Valid Loss:  0.004331204574555159
Epoch:  41  	Training Loss: 0.00445188395678997
Test Loss:  0.003144610207527876
Valid Loss:  0.004201127216219902
Epoch:  42  	Training Loss: 0.004320337437093258
Test Loss:  0.0030470783822238445
Valid Loss:  0.004077364224940538
Epoch:  43  	Training Loss: 0.004195312038064003
Test Loss:  0.002955271862447262
Valid Loss:  0.003959793597459793
Epoch:  44  	Training Loss: 0.00407651299610734
Test Loss:  0.0028688753955066204
Valid Loss:  0.0038480961229652166
Epoch:  45  	Training Loss: 0.0039636557921767235
Test Loss:  0.0027876088861376047
Valid Loss:  0.003741987282410264
Epoch:  46  	Training Loss: 0.00385642540641129
Test Loss:  0.0027111812960356474
Valid Loss:  0.0036411776673048735
Epoch:  47  	Training Loss: 0.003754552686586976
Test Loss:  0.002639368874952197
Valid Loss:  0.0035453983582556248
Epoch:  48  	Training Loss: 0.0036577514838427305
Test Loss:  0.0025718999095261097
Valid Loss:  0.003454393707215786
Epoch:  49  	Training Loss: 0.003565798979252577
Test Loss:  0.0025085380766540766
Valid Loss:  0.003367927623912692
Epoch:  50  	Training Loss: 0.00347842276096344
Test Loss:  0.00244907196611166
Valid Loss:  0.0032857581973075867
Epoch:  51  	Training Loss: 0.0033954079262912273
Test Loss:  0.00239327410236001
Valid Loss:  0.00320769683457911
Epoch:  52  	Training Loss: 0.003316535148769617
Test Loss:  0.002340822946280241
Valid Loss:  0.003133604768663645
Epoch:  53  	Training Loss: 0.0032414388842880726
Test Loss:  0.002291696844622493
Valid Loss:  0.003063141368329525
Epoch:  54  	Training Loss: 0.0031700902618467808
Test Loss:  0.002245707204565406
Valid Loss:  0.002996136900037527
Epoch:  55  	Training Loss: 0.0031023090705275536
Test Loss:  0.0022026770748198032
Valid Loss:  0.0029324230272322893
Epoch:  56  	Training Loss: 0.0030379099771380424
Test Loss:  0.002162436256185174
Valid Loss:  0.0028718861285597086
Epoch:  57  	Training Loss: 0.0029767213854938745
Test Loss:  0.002124822698533535
Valid Loss:  0.002814322244375944
Epoch:  58  	Training Loss: 0.0029185900930315256
Test Loss:  0.002089687157422304
Valid Loss:  0.0027596214786171913
Epoch:  59  	Training Loss: 0.0028633561450988054
Test Loss:  0.0020568768959492445
Valid Loss:  0.0027076336555182934
Epoch:  60  	Training Loss: 0.002810882870107889
Test Loss:  0.0020262841135263443
Valid Loss:  0.0026582255959510803
Epoch:  61  	Training Loss: 0.0027610245160758495
Test Loss:  0.001997774699702859
Valid Loss:  0.0026112741325050592
Epoch:  62  	Training Loss: 0.0027136607095599174
Test Loss:  0.0019712354987859726
Valid Loss:  0.0025666854344308376
Epoch:  63  	Training Loss: 0.002668729517608881
Test Loss:  0.001946546952240169
Valid Loss:  0.002524322597309947
Epoch:  64  	Training Loss: 0.0026260444428771734
Test Loss:  0.0019236104562878609
Valid Loss:  0.0024840827099978924
Epoch:  65  	Training Loss: 0.002585491631180048
Test Loss:  0.0019023134373128414
Valid Loss:  0.0024458467960357666
Epoch:  66  	Training Loss: 0.00254695862531662
Test Loss:  0.0018825593870133162
Valid Loss:  0.0024095166008919477
Epoch:  67  	Training Loss: 0.002510359976440668
Test Loss:  0.0018642821814864874
Valid Loss:  0.0023750043474137783
Epoch:  68  	Training Loss: 0.002475582994520664
Test Loss:  0.0018473693635314703
Valid Loss:  0.0023422064259648323
Epoch:  69  	Training Loss: 0.0024425399024039507
Test Loss:  0.00183175690472126
Valid Loss:  0.0023110401816666126
Epoch:  70  	Training Loss: 0.002411148976534605
Test Loss:  0.0018173616845160723
Valid Loss:  0.002281441818922758
Epoch:  71  	Training Loss: 0.0023813259322196245
Test Loss:   14%|█▍        | 71/500 [00:54<08:17,  1.16s/it] 15%|█▍        | 73/500 [00:54<05:55,  1.20it/s] 15%|█▌        | 75/500 [00:54<04:16,  1.66it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.26it/s] 16%|█▌        | 79/500 [00:54<02:18,  3.03it/s] 16%|█▌        | 81/500 [01:01<08:29,  1.22s/it] 17%|█▋        | 83/500 [01:01<06:05,  1.14it/s] 17%|█▋        | 85/500 [01:01<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:01<03:11,  2.16it/s] 18%|█▊        | 89/500 [01:01<02:21,  2.91it/s] 18%|█▊        | 91/500 [01:08<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.98it/s] 20%|██        | 101/500 [01:14<07:43,  1.16s/it] 21%|██        | 103/500 [01:15<05:31,  1.20it/s] 21%|██        | 105/500 [01:15<03:58,  1.65it/s] 21%|██▏       | 107/500 [01:15<02:53,  2.26it/s] 22%|██▏       | 109/500 [01:15<02:08,  3.04it/s] 22%|██▏       | 111/500 [01:21<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:22<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:22<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:28<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:28<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:07,  1.16s/it] 27%|██▋       | 133/500 [01:35<05:05,  1.20it/s] 27%|██▋       | 135/500 [01:35<03:39,  1.66it/s] 27%|██▋       | 137/500 [01:35<02:40,  2.27it/s] 28%|██▊       | 139/500 [01:35<01:58,  3.05it/s]0.001804115017876029
Valid Loss:  0.002253304235637188
Epoch:  72  	Training Loss: 0.002352991607040167
Test Loss:  0.0017919379752129316
Valid Loss:  0.002226542681455612
Epoch:  73  	Training Loss: 0.002326032379642129
Test Loss:  0.001780784223228693
Valid Loss:  0.002201114082708955
Epoch:  74  	Training Loss: 0.002300416585057974
Test Loss:  0.0017705743666738272
Valid Loss:  0.0021769399754703045
Epoch:  75  	Training Loss: 0.0022760843858122826
Test Loss:  0.0017612644005566835
Valid Loss:  0.002153970766812563
Epoch:  76  	Training Loss: 0.0022529622074216604
Test Loss:  0.0017527926247566938
Valid Loss:  0.0021321456879377365
Epoch:  77  	Training Loss: 0.0022310041822493076
Test Loss:  0.001745103858411312
Valid Loss:  0.002111413050442934
Epoch:  78  	Training Loss: 0.002210139762610197
Test Loss:  0.0017381629440933466
Valid Loss:  0.002091697882860899
Epoch:  79  	Training Loss: 0.002190313534811139
Test Loss:  0.001731927739456296
Valid Loss:  0.002072976902127266
Epoch:  80  	Training Loss: 0.0021714861504733562
Test Loss:  0.0017263339832425117
Valid Loss:  0.002055183984339237
Epoch:  81  	Training Loss: 0.0021535917185246944
Test Loss:  0.0017213455867022276
Valid Loss:  0.002038273960351944
Epoch:  82  	Training Loss: 0.0021365955471992493
Test Loss:  0.0017168838530778885
Valid Loss:  0.0020222507882863283
Epoch:  83  	Training Loss: 0.00212051416747272
Test Loss:  0.001712973928079009
Valid Loss:  0.002007037401199341
Epoch:  84  	Training Loss: 0.0021052430383861065
Test Loss:  0.0017095720395445824
Valid Loss:  0.001992578152567148
Epoch:  85  	Training Loss: 0.0020907255820930004
Test Loss:  0.0017066402360796928
Valid Loss:  0.0019788402132689953
Epoch:  86  	Training Loss: 0.002076932694762945
Test Loss:  0.001704155933111906
Valid Loss:  0.001965789357200265
Epoch:  87  	Training Loss: 0.0020638275891542435
Test Loss:  0.0017020797822624445
Valid Loss:  0.001953378552570939
Epoch:  88  	Training Loss: 0.0020513790659606457
Test Loss:  0.0017003961838781834
Valid Loss:  0.0019416072173044086
Epoch:  89  	Training Loss: 0.0020395515020936728
Test Loss:  0.0016990613657981157
Valid Loss:  0.0019303972367197275
Epoch:  90  	Training Loss: 0.002028312534093857
Test Loss:  0.001698054140433669
Valid Loss:  0.0019197426736354828
Epoch:  91  	Training Loss: 0.0020176339894533157
Test Loss:  0.0016973563469946384
Valid Loss:  0.0019096306059509516
Epoch:  92  	Training Loss: 0.002007483271881938
Test Loss:  0.0016968999989330769
Valid Loss:  0.0018999946769326925
Epoch:  93  	Training Loss: 0.001997828483581543
Test Loss:  0.0016967238625511527
Valid Loss:  0.0018908455967903137
Epoch:  94  	Training Loss: 0.00198865938000381
Test Loss:  0.0016967973206192255
Valid Loss:  0.0018821443663910031
Epoch:  95  	Training Loss: 0.0019799433648586273
Test Loss:  0.0016971000004559755
Valid Loss:  0.001873882720246911
Epoch:  96  	Training Loss: 0.0019716627430170774
Test Loss:  0.0016976133920252323
Valid Loss:  0.001866021892055869
Epoch:  97  	Training Loss: 0.001963798888027668
Test Loss:  0.0016983316745609045
Valid Loss:  0.0018585559446364641
Epoch:  98  	Training Loss: 0.0019563224632292986
Test Loss:  0.0016992269083857536
Valid Loss:  0.0018514631083235145
Epoch:  99  	Training Loss: 0.001949223456904292
Test Loss:  0.001700288150459528
Valid Loss:  0.0018447211477905512
Epoch:  100  	Training Loss: 0.001942474627867341
Test Loss:  0.001701500965282321
Valid Loss:  0.0018383098067715764
Epoch:  101  	Training Loss: 0.0019360652659088373
Test Loss:  0.0017028541769832373
Valid Loss:  0.0018322207033634186
Epoch:  102  	Training Loss: 0.0019299727864563465
Test Loss:  0.001704355119727552
Valid Loss:  0.0018264229875057936
Epoch:  103  	Training Loss: 0.0019241786794736981
Test Loss:  0.0017059601377695799
Valid Loss:  0.0018209072295576334
Epoch:  104  	Training Loss: 0.0019186717690899968
Test Loss:  0.001707682153210044
Valid Loss:  0.001815678202547133
Epoch:  105  	Training Loss: 0.0019134394824504852
Test Loss:  0.0017094782087951899
Valid Loss:  0.001810695743188262
Epoch:  106  	Training Loss: 0.001908470643684268
Test Loss:  0.0017113583162426949
Valid Loss:  0.0018059656722471118
Epoch:  107  	Training Loss: 0.0019037495367228985
Test Loss:  0.0017133231740444899
Valid Loss:  0.0018014662200585008
Epoch:  108  	Training Loss: 0.0018992610275745392
Test Loss:  0.001715348451398313
Valid Loss:  0.001797195291146636
Epoch:  109  	Training Loss: 0.001895000459626317
Test Loss:  0.0017174379900097847
Valid Loss:  0.0017931251786649227
Epoch:  110  	Training Loss: 0.0018909473437815905
Test Loss:  0.0017195693217217922
Valid Loss:  0.0017892653122544289
Epoch:  111  	Training Loss: 0.0018871008651331067
Test Loss:  0.0017217559507116675
Valid Loss:  0.0017855965998023748
Epoch:  112  	Training Loss: 0.001883445424027741
Test Loss:  0.0017240201123058796
Valid Loss:  0.0017821122892200947
Epoch:  113  	Training Loss: 0.0018799754325300455
Test Loss:  0.0017263160552829504
Valid Loss:  0.0017787993419915438
Epoch:  114  	Training Loss: 0.0018766808789223433
Test Loss:  0.0017286313232034445
Valid Loss:  0.0017756543820723891
Epoch:  115  	Training Loss: 0.0018735521007329226
Test Loss:  0.0017309595132246614
Valid Loss:  0.001772657735273242
Epoch:  116  	Training Loss: 0.0018705761758610606
Test Loss:  0.0017333202995359898
Valid Loss:  0.001769809634424746
Epoch:  117  	Training Loss: 0.00186775135807693
Test Loss:  0.0017356668831780553
Valid Loss:  0.0017671105451881886
Epoch:  118  	Training Loss: 0.0018650708952918649
Test Loss:  0.001738040242344141
Valid Loss:  0.0017645400948822498
Epoch:  119  	Training Loss: 0.0018625245429575443
Test Loss:  0.0017404202371835709
Valid Loss:  0.0017620904836803675
Epoch:  120  	Training Loss: 0.001860103104263544
Test Loss:  0.0017427996499463916
Valid Loss:  0.0017597719561308622
Epoch:  121  	Training Loss: 0.0018577997107058764
Test Loss:  0.0017451706808060408
Valid Loss:  0.0017575582023710012
Epoch:  122  	Training Loss: 0.0018556162249296904
Test Loss:  0.0017475094646215439
Valid Loss:  0.0017554662190377712
Epoch:  123  	Training Loss: 0.0018535341368988156
Test Loss:  0.0017498579109087586
Valid Loss:  0.0017534650396555662
Epoch:  124  	Training Loss: 0.0018515563569962978
Test Loss:  0.0017521941335871816
Valid Loss:  0.0017515654908493161
Epoch:  125  	Training Loss: 0.001849679509177804
Test Loss:  0.0017545311711728573
Valid Loss:  0.0017497591907158494
Epoch:  126  	Training Loss: 0.00184789695776999
Test Loss:  0.0017568502807989717
Valid Loss:  0.0017480378737673163
Epoch:  127  	Training Loss: 0.001846197061240673
Test Loss:  0.001759164035320282
Valid Loss:  0.0017464127158746123
Epoch:  128  	Training Loss: 0.001844590762630105
Test Loss:  0.0017614590469747782
Valid Loss:  0.0017448586877435446
Epoch:  129  	Training Loss: 0.0018430592026561499
Test Loss:  0.0017637340351939201
Valid Loss:  0.0017433831235393882
Epoch:  130  	Training Loss: 0.0018416079692542553
Test Loss:  0.0017659959848970175
Valid Loss:  0.0017419785726815462
Epoch:  131  	Training Loss: 0.0018402243731543422
Test Loss:  0.001768231624737382
Valid Loss:  0.0017406523693352938
Epoch:  132  	Training Loss: 0.0018389136530458927
Test Loss:  0.0017704581841826439
Valid Loss:  0.0017393758753314614
Epoch:  133  	Training Loss: 0.0018376659136265516
Test Loss:  0.001772650284692645
Valid Loss:  0.0017381778452545404
Epoch:  134  	Training Loss: 0.001836483716033399
Test Loss:  0.0017748239915817976
Valid Loss:  0.0017370281275361776
Epoch:  135  	Training Loss: 0.001835355069488287
Test Loss:  0.0017769777914509177
Valid Loss:  0.0017359335906803608
Epoch:  136  	Training Loss: 0.0018342866096645594
Test Loss:  0.001779093174263835
Valid Loss:  0.0017348960973322392
Epoch:  137  	Training Loss: 0.0018332690233364701
Test Loss:  0.001781183760613203
Valid Loss:  0.001733905985020101
Epoch:  138  	Training Loss: 0.0018323060357943177
Test Loss:  0.0017832505982369184
Valid Loss:  0.0017329731490463018
Epoch:  139  	Training Loss: 0.001831389614380896
Test Loss:  0.0017852955497801304
Valid Loss:  0.0017320788465440273
Epoch:  140  	Training Loss: 0.0018305155681446195
Test Loss:   28%|██▊       | 141/500 [01:42<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:42<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:42<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:42<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.02it/s] 30%|███       | 151/500 [01:48<06:50,  1.18s/it] 31%|███       | 153/500 [01:49<04:54,  1.18it/s] 31%|███       | 155/500 [01:49<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:24,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:56<01:50,  3.01it/s] 34%|███▍      | 171/500 [02:02<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:03<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:09<06:21,  1.19s/it] 37%|███▋      | 183/500 [02:09<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:09<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:09<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:10<01:45,  2.96it/s] 38%|███▊      | 191/500 [02:16<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:16<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:16<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:16<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:16<01:41,  2.98it/s] 40%|████      | 201/500 [02:23<05:51,  1.18s/it] 41%|████      | 203/500 [02:23<04:11,  1.18it/s] 41%|████      | 205/500 [02:23<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.24it/s]0.001787299057468772
Valid Loss:  0.0017312313430011272
Epoch:  141  	Training Loss: 0.001829690532758832
Test Loss:  0.0017892811447381973
Valid Loss:  0.0017304257489740849
Epoch:  142  	Training Loss: 0.0018289003055542707
Test Loss:  0.0017911694012582302
Valid Loss:  0.0017296597361564636
Epoch:  143  	Training Loss: 0.001828153501264751
Test Loss:  0.0017930481117218733
Valid Loss:  0.0017289303941652179
Epoch:  144  	Training Loss: 0.001827444415539503
Test Loss:  0.001794901443645358
Valid Loss:  0.001728238770738244
Epoch:  145  	Training Loss: 0.0018267679261043668
Test Loss:  0.0017967368476092815
Valid Loss:  0.001727578230202198
Epoch:  146  	Training Loss: 0.0018261244986206293
Test Loss:  0.0017985515296459198
Valid Loss:  0.0017269495874643326
Epoch:  147  	Training Loss: 0.0018255137838423252
Test Loss:  0.0018003338482230902
Valid Loss:  0.0017263496993109584
Epoch:  148  	Training Loss: 0.0018249369459226727
Test Loss:  0.0018020954448729753
Valid Loss:  0.0017257833387702703
Epoch:  149  	Training Loss: 0.0018243803642690182
Test Loss:  0.0018038154812529683
Valid Loss:  0.0017252411926165223
Epoch:  150  	Training Loss: 0.0018238556804135442
Test Loss:  0.0018055194523185492
Valid Loss:  0.0017247244250029325
Epoch:  151  	Training Loss: 0.001823357306420803
Test Loss:  0.00180718838237226
Valid Loss:  0.0017242396716028452
Epoch:  152  	Training Loss: 0.0018228861736133695
Test Loss:  0.0018088743090629578
Valid Loss:  0.0017237727297469974
Epoch:  153  	Training Loss: 0.001822435180656612
Test Loss:  0.0018105072667822242
Valid Loss:  0.0017233237158507109
Epoch:  154  	Training Loss: 0.0018220101483166218
Test Loss:  0.001812113099731505
Valid Loss:  0.0017228976357728243
Epoch:  155  	Training Loss: 0.0018216036260128021
Test Loss:  0.0018136920407414436
Valid Loss:  0.0017224994953721762
Epoch:  156  	Training Loss: 0.0018212207360193133
Test Loss:  0.0018152242992073298
Valid Loss:  0.001722115557640791
Epoch:  157  	Training Loss: 0.0018208553083240986
Test Loss:  0.00181674025952816
Valid Loss:  0.001721749547868967
Epoch:  158  	Training Loss: 0.0018205078085884452
Test Loss:  0.001818212098442018
Valid Loss:  0.0017214042600244284
Epoch:  159  	Training Loss: 0.0018201754428446293
Test Loss:  0.001819660305045545
Valid Loss:  0.0017210727091878653
Epoch:  160  	Training Loss: 0.0018198633333668113
Test Loss:  0.0018210888374596834
Valid Loss:  0.0017207660712301731
Epoch:  161  	Training Loss: 0.0018195640295743942
Test Loss:  0.0018224703380838037
Valid Loss:  0.0017204605974256992
Epoch:  162  	Training Loss: 0.0018192813731729984
Test Loss:  0.0018238509073853493
Valid Loss:  0.0017201780574396253
Epoch:  163  	Training Loss: 0.0018190147820860147
Test Loss:  0.0018252095906063914
Valid Loss:  0.001719907857477665
Epoch:  164  	Training Loss: 0.0018187585519626737
Test Loss:  0.0018265312537550926
Valid Loss:  0.0017196498811244965
Epoch:  165  	Training Loss: 0.0018185169901698828
Test Loss:  0.0018278195057064295
Valid Loss:  0.0017194123938679695
Epoch:  166  	Training Loss: 0.0018182857893407345
Test Loss:  0.0018290828447788954
Valid Loss:  0.0017191760707646608
Epoch:  167  	Training Loss: 0.0018180666957050562
Test Loss:  0.0018303111428394914
Valid Loss:  0.0017189515056088567
Epoch:  168  	Training Loss: 0.0018178593600168824
Test Loss:  0.001831522909924388
Valid Loss:  0.0017187399789690971
Epoch:  169  	Training Loss: 0.0018176602898165584
Test Loss:  0.0018326985882595181
Valid Loss:  0.0017185440519824624
Epoch:  170  	Training Loss: 0.001817471580579877
Test Loss:  0.001833854941651225
Valid Loss:  0.0017183467280119658
Epoch:  171  	Training Loss: 0.0018172964919358492
Test Loss:  0.0018349827732890844
Valid Loss:  0.0017181698931381106
Epoch:  172  	Training Loss: 0.0018171274568885565
Test Loss:  0.0018360856920480728
Valid Loss:  0.0017179992282763124
Epoch:  173  	Training Loss: 0.0018169637769460678
Test Loss:  0.0018371649784967303
Valid Loss:  0.0017178332200273871
Epoch:  174  	Training Loss: 0.0018168105743825436
Test Loss:  0.0018382254056632519
Valid Loss:  0.0017176754772663116
Epoch:  175  	Training Loss: 0.0018166648223996162
Test Loss:  0.0018392566125839949
Valid Loss:  0.0017175243701785803
Epoch:  176  	Training Loss: 0.0018165286164730787
Test Loss:  0.001840268261730671
Valid Loss:  0.0017173778032884002
Epoch:  177  	Training Loss: 0.0018163968343287706
Test Loss:  0.0018412618665024638
Valid Loss:  0.0017172526568174362
Epoch:  178  	Training Loss: 0.0018162736669182777
Test Loss:  0.0018422296270728111
Valid Loss:  0.0017171178478747606
Epoch:  179  	Training Loss: 0.0018161553889513016
Test Loss:  0.0018431693315505981
Valid Loss:  0.0017169981729239225
Epoch:  180  	Training Loss: 0.0018160450272262096
Test Loss:  0.0018440913408994675
Valid Loss:  0.0017168824560940266
Epoch:  181  	Training Loss: 0.0018159369938075542
Test Loss:  0.0018450015923008323
Valid Loss:  0.001716766506433487
Epoch:  182  	Training Loss: 0.001815834897570312
Test Loss:  0.0018458764534443617
Valid Loss:  0.0017166670877486467
Epoch:  183  	Training Loss: 0.001815739437006414
Test Loss:  0.0018467400223016739
Valid Loss:  0.0017165681347250938
Epoch:  184  	Training Loss: 0.0018156494479626417
Test Loss:  0.001847581472247839
Valid Loss:  0.00171646848320961
Epoch:  185  	Training Loss: 0.0018155613215640187
Test Loss:  0.0018484139582142234
Valid Loss:  0.0017163814045488834
Epoch:  186  	Training Loss: 0.0018154783174395561
Test Loss:  0.0018492215313017368
Valid Loss:  0.001716291531920433
Epoch:  187  	Training Loss: 0.0018153996206820011
Test Loss:  0.001850009080953896
Valid Loss:  0.0017162095755338669
Epoch:  188  	Training Loss: 0.0018153255805373192
Test Loss:  0.0018507837085053325
Valid Loss:  0.001716130180284381
Epoch:  189  	Training Loss: 0.0018152552656829357
Test Loss:  0.001851536799222231
Valid Loss:  0.0017160505522042513
Epoch:  190  	Training Loss: 0.0018151890253648162
Test Loss:  0.0018522755708545446
Valid Loss:  0.001715981517918408
Epoch:  191  	Training Loss: 0.0018151270924136043
Test Loss:  0.0018529949011281133
Valid Loss:  0.0017159183043986559
Epoch:  192  	Training Loss: 0.0018150662072002888
Test Loss:  0.0018536929273977876
Valid Loss:  0.0017158500850200653
Epoch:  193  	Training Loss: 0.0018150035757571459
Test Loss:  0.0018543663900345564
Valid Loss:  0.0017157882684841752
Epoch:  194  	Training Loss: 0.0018149540992453694
Test Loss:  0.0018550236709415913
Valid Loss:  0.0017157313413918018
Epoch:  195  	Training Loss: 0.0018149041570723057
Test Loss:  0.0018556764116510749
Valid Loss:  0.0017156724352389574
Epoch:  196  	Training Loss: 0.0018148513045161963
Test Loss:  0.0018563098274171352
Valid Loss:  0.0017156191170215607
Epoch:  197  	Training Loss: 0.0018148026429116726
Test Loss:  0.0018569311359897256
Valid Loss:  0.0017155733658000827
Epoch:  198  	Training Loss: 0.001814757939428091
Test Loss:  0.001857538241893053
Valid Loss:  0.001715524704195559
Epoch:  199  	Training Loss: 0.0018147185910493135
Test Loss:  0.0018581375479698181
Valid Loss:  0.001715472200885415
Epoch:  200  	Training Loss: 0.001814677263610065
Test Loss:  0.0018587108934298158
Valid Loss:  0.0017154293600469828
Epoch:  201  	Training Loss: 0.0018146403599530458
Test Loss:  0.0018592774868011475
Valid Loss:  0.0017153860535472631
Epoch:  202  	Training Loss: 0.0018145996145904064
Test Loss:  0.0018598346505314112
Valid Loss:  0.0017153485678136349
Epoch:  203  	Training Loss: 0.0018145707435905933
Test Loss:  0.0018603750504553318
Valid Loss:  0.001715305494144559
Epoch:  204  	Training Loss: 0.0018145369831472635
Test Loss:  0.0018609014805406332
Valid Loss:  0.001715275226160884
Epoch:  205  	Training Loss: 0.0018145071808248758
Test Loss:  0.0018614251166582108
Valid Loss:  0.001715233433060348
Epoch:  206  	Training Loss: 0.0018144756322726607
Test Loss:  0.0018619326874613762
Valid Loss:  0.0017152022337540984
Epoch:  207  	Training Loss: 0.001814444549381733
Test Loss:  0.0018624237272888422
Valid Loss:  0.0017151761567220092
Epoch:  208  	Training Loss: 0.0018144180066883564
Test Loss:  0.001862898701801896
Valid Loss:  0.001715141348540783
 42%|████▏     | 209/500 [02:23<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:30<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:30<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:36<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:37<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:37<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:37<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:43<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:44<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:50<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.00it/s] 50%|█████     | 251/500 [02:57<04:58,  1.20s/it] 51%|█████     | 253/500 [02:57<03:32,  1.16it/s] 51%|█████     | 255/500 [02:57<02:32,  1.61it/s] 51%|█████▏    | 257/500 [02:57<01:50,  2.20it/s] 52%|█████▏    | 259/500 [02:58<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:04<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:10<06:01,  1.54s/it] 53%|█████▎    | 267/500 [03:10<04:15,  1.10s/it] 54%|█████▍    | 269/500 [03:11<03:01,  1.27it/s] 54%|█████▍    | 271/500 [03:17<05:39,  1.48s/it] 55%|█████▍    | 273/500 [03:17<04:00,  1.06s/it]Epoch:  209  	Training Loss: 0.0018143942579627037
Test Loss:  0.0018633687868714333
Valid Loss:  0.0017151052597910166
Epoch:  210  	Training Loss: 0.0018143735360354185
Test Loss:  0.0018638295587152243
Valid Loss:  0.0017150815110653639
Epoch:  211  	Training Loss: 0.0018143486231565475
Test Loss:  0.0018642733339220285
Valid Loss:  0.0017150614876300097
Epoch:  212  	Training Loss: 0.0018143270863220096
Test Loss:  0.0018647077959030867
Valid Loss:  0.0017150294734165072
Epoch:  213  	Training Loss: 0.0018143070628866553
Test Loss:  0.0018651338759809732
Valid Loss:  0.001715004676952958
Epoch:  214  	Training Loss: 0.0018142851768061519
Test Loss:  0.0018655413296073675
Valid Loss:  0.0017149833729490638
Epoch:  215  	Training Loss: 0.001814268995076418
Test Loss:  0.0018659461056813598
Valid Loss:  0.0017149602063000202
Epoch:  216  	Training Loss: 0.0018142473418265581
Test Loss:  0.0018663485534489155
Valid Loss:  0.0017149359919130802
Epoch:  217  	Training Loss: 0.0018142352346330881
Test Loss:  0.0018667294643819332
Valid Loss:  0.0017149210907518864
Epoch:  218  	Training Loss: 0.001814217772334814
Test Loss:  0.001867101644165814
Valid Loss:  0.001714895712211728
Epoch:  219  	Training Loss: 0.0018142001936212182
Test Loss:  0.0018674673046916723
Valid Loss:  0.001714874291792512
Epoch:  220  	Training Loss: 0.0018141861073672771
Test Loss:  0.0018678371561691165
Valid Loss:  0.00171486078761518
Epoch:  221  	Training Loss: 0.00181417481508106
Test Loss:  0.0018681802321225405
Valid Loss:  0.001714850077405572
Epoch:  222  	Training Loss: 0.0018141608452424407
Test Loss:  0.0018685299437493086
Valid Loss:  0.001714832615107298
Epoch:  223  	Training Loss: 0.0018141490872949362
Test Loss:  0.0018688607960939407
Valid Loss:  0.0017148151528090239
Epoch:  224  	Training Loss: 0.0018141380278393626
Test Loss:  0.0018691946752369404
Valid Loss:  0.0017148044425994158
Epoch:  225  	Training Loss: 0.0018141267355531454
Test Loss:  0.0018695162143558264
Valid Loss:  0.001714785466901958
Epoch:  226  	Training Loss: 0.0018141143955290318
Test Loss:  0.0018698216881603003
Valid Loss:  0.0017147635808214545
Epoch:  227  	Training Loss: 0.0018141060136258602
Test Loss:  0.0018701298395171762
Valid Loss:  0.0017147555481642485
Epoch:  228  	Training Loss: 0.001814097398892045
Test Loss:  0.001870428561232984
Valid Loss:  0.0017147413454949856
Epoch:  229  	Training Loss: 0.0018140857573598623
Test Loss:  0.0018707194831222296
Valid Loss:  0.0017147355247288942
Epoch:  230  	Training Loss: 0.001814077259041369
Test Loss:  0.0018709932919591665
Valid Loss:  0.0017147220205515623
Epoch:  231  	Training Loss: 0.0018140665488317609
Test Loss:  0.0018712675664573908
Valid Loss:  0.0017147054895758629
Epoch:  232  	Training Loss: 0.001814062474295497
Test Loss:  0.0018715406768023968
Valid Loss:  0.0017147031612694263
Epoch:  233  	Training Loss: 0.0018140546744689345
Test Loss:  0.0018718000501394272
Valid Loss:  0.0017146922182291746
Epoch:  234  	Training Loss: 0.0018140480387955904
Test Loss:  0.0018720511579886079
Valid Loss:  0.0017146858153864741
Epoch:  235  	Training Loss: 0.00181404163595289
Test Loss:  0.001872300636023283
Valid Loss:  0.001714672427624464
Epoch:  236  	Training Loss: 0.0018140380270779133
Test Loss:  0.0018725446425378323
Valid Loss:  0.0017146700993180275
Epoch:  237  	Training Loss: 0.001814032206311822
Test Loss:  0.001872774213552475
Valid Loss:  0.00171465624589473
Epoch:  238  	Training Loss: 0.0018140266183763742
Test Loss:  0.001873009605333209
Valid Loss:  0.0017146575264632702
Epoch:  239  	Training Loss: 0.0018140209140256047
Test Loss:  0.0018732283497229218
Valid Loss:  0.0017146412283182144
Epoch:  240  	Training Loss: 0.0018140178872272372
Test Loss:  0.0018734519835561514
Valid Loss:  0.001714638201519847
Epoch:  241  	Training Loss: 0.0018140152096748352
Test Loss:  0.0018736671190708876
Valid Loss:  0.0017146309837698936
Epoch:  242  	Training Loss: 0.0018140089232474566
Test Loss:  0.0018738687504082918
Valid Loss:  0.0017146256286650896
Epoch:  243  	Training Loss: 0.0018140036845579743
Test Loss:  0.0018740709638223052
Valid Loss:  0.0017146205063909292
Epoch:  244  	Training Loss: 0.0018139979802072048
Test Loss:  0.0018742616521194577
Valid Loss:  0.001714614569209516
Epoch:  245  	Training Loss: 0.0018139953026548028
Test Loss:  0.0018744550179690123
Valid Loss:  0.001714604441076517
Epoch:  246  	Training Loss: 0.0018139909952878952
Test Loss:  0.00187464221380651
Valid Loss:  0.0017146035097539425
Epoch:  247  	Training Loss: 0.001813987735658884
Test Loss:  0.0018748281290754676
Valid Loss:  0.0017145965248346329
Epoch:  248  	Training Loss: 0.0018139851745218039
Test Loss:  0.0018750031013041735
Valid Loss:  0.0017145866295322776
Epoch:  249  	Training Loss: 0.001813980983570218
Test Loss:  0.0018751765601336956
Valid Loss:  0.001714589772745967
Epoch:  250  	Training Loss: 0.0018139744643121958
Test Loss:  0.0018753473414108157
Valid Loss:  0.0017145761521533132
Epoch:  251  	Training Loss: 0.0018139744643121958
Test Loss:  0.0018755218479782343
Valid Loss:  0.0017145754536613822
Epoch:  252  	Training Loss: 0.001813971670344472
Test Loss:  0.0018756799399852753
Valid Loss:  0.0017145697493106127
Epoch:  253  	Training Loss: 0.001813970971852541
Test Loss:  0.0018758337246254086
Valid Loss:  0.0017145653255283833
Epoch:  254  	Training Loss: 0.0018139672465622425
Test Loss:  0.0018759804079309106
Valid Loss:  0.0017145617166534066
Epoch:  255  	Training Loss: 0.0018139630556106567
Test Loss:  0.0018761365208774805
Valid Loss:  0.0017145622987300158
Epoch:  256  	Training Loss: 0.0018139613093808293
Test Loss:  0.0018762850668281317
Valid Loss:  0.001714553451165557
Epoch:  257  	Training Loss: 0.0018139565363526344
Test Loss:  0.001876432215794921
Valid Loss:  0.001714548678137362
Epoch:  258  	Training Loss: 0.0018139546737074852
Test Loss:  0.0018765628337860107
Valid Loss:  0.0017145450692623854
Epoch:  259  	Training Loss: 0.0018139553721994162
Test Loss:  0.001876706606708467
Valid Loss:  0.0017145408783107996
Epoch:  260  	Training Loss: 0.001813952811062336
Test Loss:  0.0018768340814858675
Valid Loss:  0.0017145436722785234
Epoch:  261  	Training Loss: 0.001813952112570405
Test Loss:  0.0018769653979688883
Valid Loss:  0.001714535290375352
Epoch:  262  	Training Loss: 0.0018139465246349573
Test Loss:  0.0018770861206576228
Valid Loss:  0.0017145297024399042
Epoch:  263  	Training Loss: 0.0018139472231268883
Test Loss:  0.001877220463939011
Valid Loss:  0.0017145328456535935
Epoch:  264  	Training Loss: 0.0018139468738809228
Test Loss:  0.0018773316405713558
Valid Loss:  0.001714529236778617
Epoch:  265  	Training Loss: 0.0018139472231268883
Test Loss:  0.0018774463096633554
Valid Loss:  0.0017145263263955712
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0018139395397156477
Test Loss:  0.0018775053322315216
Valid Loss:  0.001714522484689951
Epoch:  267  	Training Loss: 0.001813942682929337
Test Loss:  0.0018775599310174584
Valid Loss:  0.0017145263263955712
Epoch:  268  	Training Loss: 0.0018139403546229005
Test Loss:  0.0018776182550936937
Valid Loss:  0.001714522484689951
Epoch:  269  	Training Loss: 0.0018139409366995096
Test Loss:  0.001877672504633665
Valid Loss:  0.001714515034109354
Epoch:  270  	Training Loss: 0.001813939306885004
Test Loss:  0.0018777279183268547
Valid Loss:  0.0017145138699561357
Epoch:  271  	Training Loss: 0.0018139409366995096
Test Loss:  0.0018777769291773438
Valid Loss:  0.0017145160818472505
Epoch:  272  	Training Loss: 0.0018139367457479239
Test Loss:  0.0018778317607939243
Valid Loss:  0.0017145161982625723
Epoch:  273  	Training Loss: 0.0018139379099011421
Test Loss:  0.001877882401458919
Valid Loss:  0.0017145186429843307
Epoch:  274  	Training Loss: 0.001813938608393073
Test Loss:  0.0018779400270432234
Valid Loss:  0.0017145192250609398
Epoch:  275  	Training Loss: 0.0018139369785785675
Test Loss:  0.0018779854290187359
Valid Loss:  0.0017145138699561357
 55%|█████▌    | 275/500 [03:23<06:16,  1.67s/it] 55%|█████▌    | 277/500 [03:23<04:25,  1.19s/it] 56%|█████▌    | 279/500 [03:23<03:08,  1.17it/s] 56%|█████▌    | 281/500 [03:36<08:56,  2.45s/it] 57%|█████▋    | 283/500 [03:36<06:16,  1.74s/it] 57%|█████▋    | 285/500 [03:36<04:25,  1.24s/it] 57%|█████▋    | 287/500 [03:36<03:08,  1.13it/s] 58%|█████▊    | 289/500 [03:36<02:14,  1.57it/s] 58%|█████▊    | 291/500 [03:49<08:11,  2.35s/it] 58%|█████▊    | 292/500 [03:49<06:50,  1.97s/it] 59%|█████▉    | 294/500 [03:49<04:37,  1.35s/it] 59%|█████▉    | 296/500 [03:50<03:10,  1.07it/s] 60%|█████▉    | 298/500 [03:50<02:13,  1.52it/s] 60%|██████    | 300/500 [03:56<04:46,  1.43s/it] 60%|██████    | 301/500 [04:02<07:39,  2.31s/it] 61%|██████    | 303/500 [04:02<05:03,  1.54s/it] 61%|██████    | 305/500 [04:02<03:26,  1.06s/it] 61%|██████▏   | 307/500 [04:03<02:22,  1.35it/s] 62%|██████▏   | 309/500 [04:03<01:41,  1.89it/s] 62%|██████▏   | 311/500 [04:15<07:19,  2.32s/it] 63%|██████▎   | 313/500 [04:16<05:05,  1.63s/it] 63%|██████▎   | 315/500 [04:22<06:30,  2.11s/it] 63%|██████▎   | 317/500 [04:22<04:33,  1.49s/it] 64%|██████▍   | 319/500 [04:22<03:12,  1.06s/it] 64%|██████▍   | 321/500 [04:29<05:05,  1.71s/it] 65%|██████▍   | 323/500 [04:29<03:34,  1.21s/it] 65%|██████▌   | 325/500 [04:35<05:17,  1.81s/it] 65%|██████▌   | 327/500 [04:35<03:43,  1.29s/it] 66%|██████▌   | 329/500 [04:35<02:37,  1.08it/s] 66%|██████▌   | 331/500 [04:42<04:32,  1.61s/it] 67%|██████▋   | 333/500 [04:42<03:12,  1.15s/it] 67%|██████▋   | 335/500 [04:49<04:54,  1.79s/it]**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0018139372114092112
Test Loss:  0.0018780126702040434
Valid Loss:  0.0017145115416496992
Epoch:  277  	Training Loss: 0.001813940703868866
Test Loss:  0.0018780401442199945
Valid Loss:  0.0017145113088190556
Epoch:  278  	Training Loss: 0.0018139362800866365
Test Loss:  0.0018780585378408432
Valid Loss:  0.0017145138699561357
Epoch:  279  	Training Loss: 0.0018139381427317858
Test Loss:  0.0018780868267640471
Valid Loss:  0.0017145107267424464
Epoch:  280  	Training Loss: 0.0018139339517802
Test Loss:  0.0018781137187033892
Valid Loss:  0.0017145079327747226
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0018139355815947056
Test Loss:  0.001878126640804112
Valid Loss:  0.0017145094461739063
Epoch:  282  	Training Loss: 0.001813934650272131
Test Loss:  0.0018781344406306744
Valid Loss:  0.0017145117744803429
Epoch:  283  	Training Loss: 0.0018139344174414873
Test Loss:  0.0018781495746225119
Valid Loss:  0.0017145120073109865
Epoch:  284  	Training Loss: 0.001813937327824533
Test Loss:  0.0018781567923724651
Valid Loss:  0.0017145071178674698
Epoch:  285  	Training Loss: 0.0018139367457479239
Test Loss:  0.0018781803082674742
Valid Loss:  0.0017145127058029175
Epoch:  286  	Training Loss: 0.0018139351159334183
Test Loss:  0.0018781808903440833
Valid Loss:  0.0017145044403150678
Epoch:  287  	Training Loss: 0.0018139363965019584
Test Loss:  0.0018781989347189665
Valid Loss:  0.0017145094461739063
Epoch:  288  	Training Loss: 0.0018139358144253492
Test Loss:  0.0018782129045575857
Valid Loss:  0.0017145080491900444
Epoch:  289  	Training Loss: 0.0018139351159334183
Test Loss:  0.0018782186089083552
Valid Loss:  0.0017145078163594007
Epoch:  290  	Training Loss: 0.0018139345338568091
Test Loss:  0.0018782296683639288
Valid Loss:  0.0017145094461739063
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0018139323219656944
Test Loss:  0.0018782403785735369
Valid Loss:  0.0017145012971013784
Epoch:  292  	Training Loss: 0.0018139361636713147
Test Loss:  0.0018782467814162374
Valid Loss:  0.0017145051388069987
Epoch:  293  	Training Loss: 0.0018139327876269817
Test Loss:  0.001878251088783145
Valid Loss:  0.0017145066522061825
Epoch:  294  	Training Loss: 0.0018139354651793838
Test Loss:  0.0018782588886097074
Valid Loss:  0.0017145138699561357
Epoch:  295  	Training Loss: 0.001813934650272131
Test Loss:  0.001878261100500822
Valid Loss:  0.0017145026940852404
Epoch:  296  	Training Loss: 0.0018139362800866365
Test Loss:  0.0018782608676701784
Valid Loss:  0.0017145057208836079
Epoch:  297  	Training Loss: 0.0018139339517802
Test Loss:  0.0018782743718475103
Valid Loss:  0.0017145088640972972
Epoch:  298  	Training Loss: 0.0018139331368729472
Test Loss:  0.0018782902043312788
Valid Loss:  0.0017145031597465277
Epoch:  299  	Training Loss: 0.001813934650272131
Test Loss:  0.001878286711871624
Valid Loss:  0.0017145026940852404
Epoch:  300  	Training Loss: 0.0018139337189495564
Test Loss:  0.0018782936967909336
Valid Loss:  0.001714507001452148
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0018139327876269817
Test Loss:  0.0018782978877425194
Valid Loss:  0.00171451095957309
Epoch:  302  	Training Loss: 0.001813933253288269
Test Loss:  0.001878300216048956
Valid Loss:  0.0017145080491900444
Epoch:  303  	Training Loss: 0.001813935348764062
Test Loss:  0.0018783037085086107
Valid Loss:  0.0017145051388069987
Epoch:  304  	Training Loss: 0.0018139343010261655
Test Loss:  0.0018782998668029904
Valid Loss:  0.0017145099118351936
Epoch:  305  	Training Loss: 0.0018139327876269817
Test Loss:  0.0018783105770125985
Valid Loss:  0.0017145054880529642
Epoch:  306  	Training Loss: 0.0018139348831027746
Test Loss:  0.0018783078994601965
Valid Loss:  0.0017145073506981134
Epoch:  307  	Training Loss: 0.0018139343010261655
Test Loss:  0.0018783113919198513
Valid Loss:  0.0017145092133432627
Epoch:  308  	Training Loss: 0.0018139341846108437
Test Loss:  0.0018783130217343569
Valid Loss:  0.0017145085148513317
Epoch:  309  	Training Loss: 0.0018139327876269817
Test Loss:  0.0018783140694722533
Valid Loss:  0.0017145122401416302
Epoch:  310  	Training Loss: 0.001813935348764062
Test Loss:  0.001878316281363368
Valid Loss:  0.0017145060701295733
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0018139339517802
Test Loss:  0.0018783200066536665
Valid Loss:  0.0017145078163594007
Epoch:  312  	Training Loss: 0.001813934650272131
Test Loss:  0.0018783241976052523
Valid Loss:  0.0017145113088190556
Epoch:  313  	Training Loss: 0.0018139348831027746
Test Loss:  0.0018783246632665396
Valid Loss:  0.0017145093297585845
Epoch:  314  	Training Loss: 0.0018139323219656944
Test Loss:  0.0018783282721415162
Valid Loss:  0.0017145102610811591
Epoch:  315  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783267587423325
Valid Loss:  0.0017145066522061825
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0018139316234737635
Test Loss:  0.0018783279228955507
Valid Loss:  0.001714507583528757
Epoch:  317  	Training Loss: 0.0018139311578124762
Test Loss:  0.001878329087048769
Valid Loss:  0.0017145025776699185
Epoch:  318  	Training Loss: 0.0018139308085665107
Test Loss:  0.001878331764601171
Valid Loss:  0.001714501529932022
Epoch:  319  	Training Loss: 0.0018139313906431198
Test Loss:  0.0018783300183713436
Valid Loss:  0.0017145072342827916
Epoch:  320  	Training Loss: 0.0018139336025342345
Test Loss:  0.0018783323466777802
Valid Loss:  0.0017145017627626657
Epoch:  321  	Training Loss: 0.0018139344174414873
Test Loss:  0.0018783316481858492
Valid Loss:  0.0017145054880529642
Epoch:  322  	Training Loss: 0.0018139324383810163
Test Loss:  0.0018783353734761477
Valid Loss:  0.0017145059537142515
Epoch:  323  	Training Loss: 0.001813932554796338
Test Loss:  0.0018783314153552055
Valid Loss:  0.001714507001452148
Epoch:  324  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783352570608258
Valid Loss:  0.0017145052552223206
Epoch:  325  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783339764922857
Valid Loss:  0.0017145080491900444
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0018139360472559929
Test Loss:  0.001878335839137435
Valid Loss:  0.0017145060701295733
Epoch:  327  	Training Loss: 0.0018139336025342345
Test Loss:  0.001878334442153573
Valid Loss:  0.0017145061865448952
Epoch:  328  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783311825245619
Valid Loss:  0.0017145072342827916
Epoch:  329  	Training Loss: 0.0018139327876269817
Test Loss:  0.0018783330451697111
Valid Loss:  0.0017145087476819754
Epoch:  330  	Training Loss: 0.0018139330204576254
Test Loss:  0.001878333743661642
Valid Loss:  0.0017145085148513317
Epoch:  331  	Training Loss: 0.0018139334861189127
Test Loss:  0.0018783297855407
Valid Loss:  0.0017145068850368261
Epoch:  332  	Training Loss: 0.0018139334861189127
Test Loss:  0.0018783346749842167
Valid Loss:  0.0017145033925771713
Epoch:  333  	Training Loss: 0.0018139334861189127
Test Loss:  0.0018783307168632746
Valid Loss:  0.0017145040910691023
Epoch:  334  	Training Loss: 0.0018139348831027746
Test Loss:  0.0018783307168632746
Valid Loss:  0.0017145038582384586
Epoch:  335  	Training Loss: 0.00181393523234874
Test Loss:  0.001878330367617309
Valid Loss:  0.001714505022391677
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0018139330204576254
Test Loss:   67%|██████▋   | 337/500 [04:49<03:27,  1.27s/it] 68%|██████▊   | 339/500 [04:49<02:26,  1.10it/s] 68%|██████▊   | 341/500 [04:55<04:16,  1.61s/it] 69%|██████▊   | 343/500 [04:55<03:00,  1.15s/it] 69%|██████▉   | 345/500 [05:02<04:32,  1.76s/it] 69%|██████▉   | 347/500 [05:02<03:11,  1.25s/it] 70%|██████▉   | 349/500 [05:02<02:15,  1.11it/s] 70%|███████   | 351/500 [05:09<03:58,  1.60s/it] 71%|███████   | 353/500 [05:09<02:47,  1.14s/it] 71%|███████   | 355/500 [05:15<04:19,  1.79s/it] 71%|███████▏  | 357/500 [05:15<03:02,  1.27s/it] 72%|███████▏  | 359/500 [05:16<02:08,  1.10it/s] 72%|███████▏  | 361/500 [05:28<05:51,  2.53s/it] 73%|███████▎  | 363/500 [05:28<04:05,  1.79s/it] 73%|███████▎  | 365/500 [05:35<04:57,  2.21s/it] 73%|███████▎  | 367/500 [05:35<03:28,  1.56s/it] 74%|███████▍  | 369/500 [05:35<02:25,  1.11s/it] 74%|███████▍  | 371/500 [05:47<05:41,  2.65s/it] 75%|███████▍  | 373/500 [05:48<03:58,  1.87s/it] 75%|███████▌  | 375/500 [05:54<04:42,  2.26s/it] 75%|███████▌  | 377/500 [05:54<03:17,  1.60s/it] 76%|███████▌  | 379/500 [05:54<02:18,  1.14s/it] 76%|███████▌  | 381/500 [06:07<05:26,  2.75s/it] 77%|███████▋  | 383/500 [06:07<03:47,  1.94s/it] 77%|███████▋  | 385/500 [06:14<04:25,  2.31s/it] 77%|███████▋  | 387/500 [06:14<03:05,  1.64s/it] 78%|███████▊  | 389/500 [06:14<02:09,  1.17s/it] 78%|███████▊  | 391/500 [06:27<04:55,  2.71s/it] 79%|███████▊  | 393/500 [06:27<03:25,  1.92s/it]0.0018783295527100563
Valid Loss:  0.001714505022391677
Epoch:  337  	Training Loss: 0.00181393267121166
Test Loss:  0.0018783300183713436
Valid Loss:  0.001714505022391677
Epoch:  338  	Training Loss: 0.0018139327876269817
Test Loss:  0.0018783300183713436
Valid Loss:  0.001714504323899746
Epoch:  339  	Training Loss: 0.0018139323219656944
Test Loss:  0.0018783292034640908
Valid Loss:  0.001714504323899746
Epoch:  340  	Training Loss: 0.0018139323219656944
Test Loss:  0.0018783292034640908
Valid Loss:  0.0017145045567303896
Epoch:  341  	Training Loss: 0.00181393267121166
Test Loss:  0.0018783295527100563
Valid Loss:  0.0017145040910691023
Epoch:  342  	Training Loss: 0.00181393267121166
Test Loss:  0.0018783307168632746
Valid Loss:  0.0017145040910691023
Epoch:  343  	Training Loss: 0.001813932554796338
Test Loss:  0.0018783307168632746
Valid Loss:  0.0017145040910691023
Epoch:  344  	Training Loss: 0.0018139327876269817
Test Loss:  0.0018783323466777802
Valid Loss:  0.0017145037418231368
Epoch:  345  	Training Loss: 0.0018139333697035909
Test Loss:  0.0018783321138471365
Valid Loss:  0.0017145038582384586
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0018139333697035909
Test Loss:  0.0018783323466777802
Valid Loss:  0.0017145037418231368
Epoch:  347  	Training Loss: 0.001813933253288269
Test Loss:  0.0018783323466777802
Valid Loss:  0.0017145038582384586
Epoch:  348  	Training Loss: 0.0018139331368729472
Test Loss:  0.0018783323466777802
Valid Loss:  0.0017145037418231368
Epoch:  349  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783323466777802
Valid Loss:  0.0017145037418231368
Epoch:  350  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783323466777802
Valid Loss:  0.0017145037418231368
Epoch:  351  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783325795084238
Valid Loss:  0.0017145038582384586
Epoch:  352  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783325795084238
Valid Loss:  0.001714504323899746
Epoch:  353  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783332780003548
Valid Loss:  0.001714504323899746
Epoch:  354  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783335108309984
Valid Loss:  0.001714502926915884
Epoch:  355  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  357  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  358  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  359  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  360  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  362  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  363  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  364  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  365  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  367  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  368  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  369  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  370  	Training Loss: 0.0018139327876269817
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  372  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  373  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  374  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783339764922857
Valid Loss:  0.0017145032761618495
Epoch:  375  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783339764922857
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  377  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  378  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  379  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  380  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  382  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  383  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  384  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  385  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  387  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  388  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  389  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  390  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145033925771713
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  392  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  393  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  394  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  395  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:   79%|███████▉  | 395/500 [06:33<03:59,  2.28s/it] 79%|███████▉  | 397/500 [06:33<02:46,  1.62s/it] 80%|███████▉  | 399/500 [06:33<01:56,  1.15s/it] 80%|████████  | 401/500 [06:46<04:28,  2.71s/it] 81%|████████  | 403/500 [06:46<03:05,  1.92s/it] 81%|████████  | 405/500 [06:46<02:09,  1.36s/it] 81%|████████▏ | 407/500 [06:46<01:30,  1.03it/s] 82%|████████▏ | 409/500 [06:46<01:03,  1.43it/s] 82%|████████▏ | 411/500 [06:59<03:29,  2.35s/it] 83%|████████▎ | 413/500 [06:59<02:25,  1.67s/it] 83%|████████▎ | 415/500 [07:05<03:01,  2.13s/it] 83%|████████▎ | 417/500 [07:06<02:05,  1.51s/it] 84%|████████▍ | 419/500 [07:06<01:27,  1.08s/it] 84%|████████▍ | 421/500 [07:18<03:27,  2.63s/it] 85%|████████▍ | 423/500 [07:18<02:23,  1.86s/it] 85%|████████▌ | 425/500 [07:25<02:47,  2.24s/it] 85%|████████▌ | 427/500 [07:25<01:56,  1.59s/it] 86%|████████▌ | 429/500 [07:25<01:20,  1.13s/it] 86%|████████▌ | 431/500 [07:38<03:08,  2.73s/it] 87%|████████▋ | 433/500 [07:38<02:09,  1.93s/it] 87%|████████▋ | 435/500 [07:44<02:29,  2.30s/it] 87%|████████▋ | 437/500 [07:44<01:42,  1.63s/it] 88%|████████▊ | 439/500 [07:44<01:10,  1.16s/it] 88%|████████▊ | 441/500 [07:57<02:38,  2.68s/it] 89%|████████▊ | 443/500 [07:57<01:48,  1.90s/it] 89%|████████▉ | 445/500 [08:03<02:04,  2.27s/it] 89%|████████▉ | 447/500 [08:03<01:25,  1.61s/it] 90%|████████▉ | 449/500 [08:04<00:58,  1.14s/it] 90%|█████████ | 451/500 [08:16<02:10,  2.67s/it]0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  397  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  398  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  399  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  400  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  402  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  403  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783339764922857
Valid Loss:  0.0017145032761618495
Epoch:  404  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  405  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  406  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  407  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  408  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  409  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  410  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  412  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  413  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  414  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  415  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0018139327876269817
Test Loss:  0.0018783339764922857
Valid Loss:  0.0017145031597465277
Epoch:  417  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  418  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  419  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  420  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  422  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  423  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  424  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  425  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  427  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  428  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  429  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  430  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  432  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  433  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  434  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  435  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  437  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  438  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  439  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  440  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  442  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  443  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145033925771713
Epoch:  444  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  445  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  447  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  448  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  449  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  450  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  452  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
 91%|█████████ | 453/500 [08:16<01:28,  1.89s/it] 91%|█████████ | 455/500 [08:22<01:41,  2.26s/it] 91%|█████████▏| 457/500 [08:23<01:09,  1.61s/it] 92%|█████████▏| 459/500 [08:23<00:46,  1.14s/it] 92%|█████████▏| 461/500 [08:35<01:43,  2.66s/it] 93%|█████████▎| 463/500 [08:35<01:09,  1.89s/it] 93%|█████████▎| 465/500 [08:42<01:19,  2.27s/it] 93%|█████████▎| 467/500 [08:42<00:53,  1.61s/it] 94%|█████████▍| 469/500 [08:42<00:35,  1.15s/it] 94%|█████████▍| 471/500 [08:54<01:17,  2.68s/it] 95%|█████████▍| 473/500 [08:55<00:51,  1.90s/it] 95%|█████████▌| 475/500 [09:01<00:57,  2.31s/it] 95%|█████████▌| 477/500 [09:01<00:37,  1.63s/it] 96%|█████████▌| 479/500 [09:01<00:24,  1.16s/it] 96%|█████████▌| 481/500 [09:14<00:52,  2.74s/it] 97%|█████████▋| 483/500 [09:14<00:32,  1.94s/it] 97%|█████████▋| 485/500 [09:21<00:34,  2.30s/it] 97%|█████████▋| 487/500 [09:21<00:21,  1.63s/it] 98%|█████████▊| 489/500 [09:21<00:12,  1.16s/it] 98%|█████████▊| 489/500 [09:31<00:12,  1.16s/it] 98%|█████████▊| 491/500 [09:33<00:24,  2.69s/it] 99%|█████████▊| 493/500 [09:34<00:13,  1.91s/it] 99%|█████████▉| 495/500 [09:40<00:11,  2.28s/it] 99%|█████████▉| 497/500 [09:40<00:04,  1.62s/it]100%|█████████▉| 499/500 [09:40<00:01,  1.15s/it]100%|██████████| 500/500 [09:46<00:00,  1.17s/it]
Epoch:  453  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  454  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  455  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  457  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  458  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  459  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783339764922857
Valid Loss:  0.0017145032761618495
Epoch:  460  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  462  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  463  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  464  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  465  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  467  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  468  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  469  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  470  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  472  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  473  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  474  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  475  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  477  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  478  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  479  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  480  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  482  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  483  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
Epoch:  484  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  485  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  487  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  488  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  489  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145032761618495
Epoch:  490  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  492  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783339764922857
Valid Loss:  0.0017145032761618495
Epoch:  493  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145033925771713
Epoch:  494  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  495  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145033925771713
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  497  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  498  	Training Loss: 0.0018139330204576254
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145031597465277
Epoch:  499  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783342093229294
Valid Loss:  0.0017145032761618495
Epoch:  500  	Training Loss: 0.0018139329040423036
Test Loss:  0.0018783340929076076
Valid Loss:  0.0017145031597465277
**************************************************learning rate decay**************************************************
seed is  20
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:08,  6.27s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.87it/s]  2%|▏         | 11/500 [00:13<10:53,  1.34s/it]  3%|▎         | 13/500 [00:13<07:24,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:27<09:38,  1.23s/it]  7%|▋         | 33/500 [00:27<06:53,  1.13it/s]  7%|▋         | 35/500 [00:33<12:27,  1.61s/it]  7%|▋         | 37/500 [00:34<08:50,  1.15s/it]  8%|▊         | 39/500 [00:34<06:18,  1.22it/s]  8%|▊         | 41/500 [00:40<11:41,  1.53s/it]  9%|▊         | 43/500 [00:40<08:18,  1.09s/it]  9%|▉         | 45/500 [00:40<05:56,  1.28it/s]  9%|▉         | 47/500 [00:40<04:17,  1.76it/s] 10%|▉         | 49/500 [00:41<03:07,  2.40it/s] 10%|█         | 51/500 [00:47<09:28,  1.27s/it] 11%|█         | 53/500 [00:47<06:45,  1.10it/s] 11%|█         | 55/500 [00:47<04:51,  1.52it/s] 11%|█▏        | 57/500 [00:47<03:31,  2.09it/s] 12%|█▏        | 59/500 [00:48<02:36,  2.82it/s] 12%|█▏        | 61/500 [00:54<08:51,  1.21s/it] 13%|█▎        | 63/500 [00:54<06:19,  1.15it/s] 13%|█▎        | 65/500 [01:01<11:22,  1.57s/it] 13%|█▎        | 67/500 [01:01<08:04,  1.12s/it] 14%|█▍        | 69/500 [01:01<05:46,  1.24it/s]Epoch:  1  	Training Loss: 0.22666405141353607
Test Loss:  40.013526916503906
Valid Loss:  39.042789459228516
Epoch:  2  	Training Loss: 39.375492095947266
Test Loss:  1280.99462890625
Valid Loss:  1105.25927734375
Epoch:  3  	Training Loss: 1160.69873046875
Test Loss:  17.59092903137207
Valid Loss:  17.978111267089844
Epoch:  4  	Training Loss: 17.929676055908203
Test Loss:  17.33002471923828
Valid Loss:  17.742435455322266
Epoch:  5  	Training Loss: 17.685791015625
Test Loss:  17.06841468811035
Valid Loss:  17.506206512451172
Epoch:  6  	Training Loss: 17.441553115844727
Test Loss:  16.806190490722656
Valid Loss:  17.269351959228516
Epoch:  7  	Training Loss: 17.196735382080078
Test Loss:  16.543638229370117
Valid Loss:  17.032054901123047
Epoch:  8  	Training Loss: 16.951513290405273
Test Loss:  16.280677795410156
Valid Loss:  16.794239044189453
Epoch:  9  	Training Loss: 16.70578384399414
Test Loss:  16.017539978027344
Valid Loss:  16.556047439575195
Epoch:  10  	Training Loss: 16.459712982177734
Test Loss:  15.754453659057617
Valid Loss:  16.31797218322754
Epoch:  11  	Training Loss: 16.213489532470703
Test Loss:  15.49161148071289
Valid Loss:  16.080028533935547
Epoch:  12  	Training Loss: 15.967275619506836
Test Loss:  35.57323455810547
Valid Loss:  36.03282165527344
Epoch:  13  	Training Loss: 35.750274658203125
Test Loss:  0.20940181612968445
Valid Loss:  0.33637315034866333
Epoch:  14  	Training Loss: 0.32761961221694946
Test Loss:  0.20782551169395447
Valid Loss:  0.3348567485809326
Epoch:  15  	Training Loss: 0.3260512053966522
Test Loss:  0.20627331733703613
Valid Loss:  0.33336248993873596
Epoch:  16  	Training Loss: 0.3245059847831726
Test Loss:  0.2047695517539978
Valid Loss:  0.3320179283618927
Epoch:  17  	Training Loss: 0.3230481743812561
Test Loss:  0.20337112247943878
Valid Loss:  0.33071091771125793
Epoch:  18  	Training Loss: 0.32163774967193604
Test Loss:  0.20202943682670593
Valid Loss:  0.3294142186641693
Epoch:  19  	Training Loss: 0.32025307416915894
Test Loss:  0.2007264941930771
Valid Loss:  0.3282395303249359
Epoch:  20  	Training Loss: 0.3189420700073242
Test Loss:  0.19946250319480896
Valid Loss:  0.3271297216415405
Epoch:  21  	Training Loss: 0.3176744282245636
Test Loss:  0.19823262095451355
Valid Loss:  0.32612597942352295
Epoch:  22  	Training Loss: 0.31647026538848877
Test Loss:  0.6678929328918457
Valid Loss:  0.6266108751296997
Epoch:  23  	Training Loss: 0.646983802318573
Test Loss:  0.07651202380657196
Valid Loss:  0.1603577733039856
Epoch:  24  	Training Loss: 0.15606647729873657
Test Loss:  0.07448048889636993
Valid Loss:  0.15561839938163757
Epoch:  25  	Training Loss: 0.15140356123447418
Test Loss:  0.07277695834636688
Valid Loss:  0.15259234607219696
Epoch:  26  	Training Loss: 0.14850115776062012
Test Loss:  0.07124250382184982
Valid Loss:  0.15009333193302155
Epoch:  27  	Training Loss: 0.14612628519535065
Test Loss:  0.06979961693286896
Valid Loss:  0.14776234328746796
Epoch:  28  	Training Loss: 0.14389145374298096
Test Loss:  0.06841007620096207
Valid Loss:  0.14558035135269165
Epoch:  29  	Training Loss: 0.1417584866285324
Test Loss:  0.06705811619758606
Valid Loss:  0.1434762179851532
Epoch:  30  	Training Loss: 0.13969773054122925
Test Loss:  0.06573757529258728
Valid Loss:  0.14143475890159607
Epoch:  31  	Training Loss: 0.13769295811653137
Test Loss:  0.06444542109966278
Valid Loss:  0.13944675028324127
Epoch:  32  	Training Loss: 0.13573649525642395
Test Loss:  0.05618695542216301
Valid Loss:  0.10253427922725677
Epoch:  33  	Training Loss: 0.09986841678619385
Test Loss:  0.056505076587200165
Valid Loss:  0.09983085095882416
Epoch:  34  	Training Loss: 0.09835970401763916
Test Loss:  0.0570966862142086
Valid Loss:  0.1009073257446289
Epoch:  35  	Training Loss: 0.09898042678833008
Test Loss:  0.06095055863261223
Valid Loss:  0.10244925320148468
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.1014489084482193
Test Loss:  0.057073384523391724
Valid Loss:  0.09436511993408203
Epoch:  37  	Training Loss: 0.09382699429988861
Test Loss:  0.04316425696015358
Valid Loss:  0.08013474196195602
Epoch:  38  	Training Loss: 0.07888899743556976
Test Loss:  0.035525158047676086
Valid Loss:  0.06985355168581009
Epoch:  39  	Training Loss: 0.06835035234689713
Test Loss:  0.031230676919221878
Valid Loss:  0.06259030103683472
Epoch:  40  	Training Loss: 0.061104629188776016
Test Loss:  0.0316338837146759
Valid Loss:  0.060680896043777466
Epoch:  41  	Training Loss: 0.059320028871297836
Test Loss:  0.025633899495005608
Valid Loss:  0.05364925414323807
Epoch:  42  	Training Loss: 0.05190466344356537
Test Loss:  0.02279181405901909
Valid Loss:  0.03802260011434555
Epoch:  43  	Training Loss: 0.03577391058206558
Test Loss:  0.01227101031690836
Valid Loss:  0.028448326513171196
Epoch:  44  	Training Loss: 0.026514865458011627
Test Loss:  0.01036220695823431
Valid Loss:  0.021967574954032898
Epoch:  45  	Training Loss: 0.02034057304263115
Test Loss:  0.007126255892217159
Valid Loss:  0.017342517152428627
Epoch:  46  	Training Loss: 0.015894412994384766
Test Loss:  0.0057154688984155655
Valid Loss:  0.013782196678221226
Epoch:  47  	Training Loss: 0.012645617127418518
Test Loss:  0.004377972334623337
Valid Loss:  0.011170847341418266
Epoch:  48  	Training Loss: 0.010257797315716743
Test Loss:  0.003615718334913254
Valid Loss:  0.009130279533565044
Epoch:  49  	Training Loss: 0.008479711599647999
Test Loss:  0.0030623977072536945
Valid Loss:  0.0075959437526762486
Epoch:  50  	Training Loss: 0.0071667879819869995
Test Loss:  0.002709981519728899
Valid Loss:  0.006400804966688156
Epoch:  51  	Training Loss: 0.006168941967189312
Test Loss:  0.002437917748466134
Valid Loss:  0.0055042956955730915
Epoch:  52  	Training Loss: 0.0054114582017064095
Test Loss:  0.0019722043070942163
Valid Loss:  0.004669248126447201
Epoch:  53  	Training Loss: 0.0045377579517662525
Test Loss:  0.0019300298299640417
Valid Loss:  0.004578158259391785
Epoch:  54  	Training Loss: 0.004445055965334177
Test Loss:  0.0018741044914349914
Valid Loss:  0.004498099908232689
Epoch:  55  	Training Loss: 0.004360973834991455
Test Loss:  0.0018396280938759446
Valid Loss:  0.00442146323621273
Epoch:  56  	Training Loss: 0.004273159895092249
Test Loss:  0.0018136126454919577
Valid Loss:  0.004328451585024595
Epoch:  57  	Training Loss: 0.004182701464742422
Test Loss:  0.0017834233585745096
Valid Loss:  0.004227232187986374
Epoch:  58  	Training Loss: 0.004091048613190651
Test Loss:  0.001747670816257596
Valid Loss:  0.004119471646845341
Epoch:  59  	Training Loss: 0.003996875137090683
Test Loss:  0.001708777854219079
Valid Loss:  0.004004517570137978
Epoch:  60  	Training Loss: 0.0038903008680790663
Test Loss:  0.0016777769196778536
Valid Loss:  0.0038665977772325277
Epoch:  61  	Training Loss: 0.00377159402705729
Test Loss:  0.0016453394200652838
Valid Loss:  0.0037300800904631615
Epoch:  62  	Training Loss: 0.0036557759158313274
Test Loss:  0.0015581264160573483
Valid Loss:  0.0033985781483352184
Epoch:  63  	Training Loss: 0.0033551622182130814
Test Loss:  0.001822007237933576
Valid Loss:  0.0034284237772226334
Epoch:  64  	Training Loss: 0.003380446694791317
Test Loss:  0.002178166527301073
Valid Loss:  0.003771812655031681
Epoch:  65  	Training Loss: 0.0037350128404796124
Test Loss:  0.0036504860036075115
Valid Loss:  0.004797030705958605
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.004796783905476332
Test Loss:  0.002029762603342533
Valid Loss:  0.0029956449288874865
Epoch:  67  	Training Loss: 0.0029671352822333574
Test Loss:  0.0018907010089606047
Valid Loss:  0.0028947284445166588
Epoch:  68  	Training Loss: 0.002876089420169592
Test Loss:  0.0018928037025034428
Valid Loss:  0.0028937957249581814
Epoch:  69  	Training Loss: 0.0028736144304275513
Test Loss:  0.001887826481834054
Valid Loss:  0.002893238328397274
Epoch:  70  	Training Loss: 0.0028733648359775543
Test Loss:  0.001883291406556964
Valid Loss:  0.002892819931730628
 14%|█▍        | 71/500 [01:07<11:02,  1.54s/it] 15%|█▍        | 73/500 [01:07<07:51,  1.10s/it] 15%|█▌        | 75/500 [01:08<05:36,  1.26it/s] 15%|█▌        | 77/500 [01:08<04:03,  1.74it/s] 16%|█▌        | 79/500 [01:08<02:58,  2.36it/s] 16%|█▌        | 81/500 [01:14<08:47,  1.26s/it] 17%|█▋        | 83/500 [01:14<06:16,  1.11it/s] 17%|█▋        | 85/500 [01:15<04:30,  1.53it/s] 17%|█▋        | 87/500 [01:15<03:16,  2.10it/s] 18%|█▊        | 89/500 [01:15<02:25,  2.83it/s] 18%|█▊        | 91/500 [01:21<08:11,  1.20s/it] 19%|█▊        | 93/500 [01:21<05:51,  1.16it/s] 19%|█▉        | 95/500 [01:28<10:33,  1.56s/it] 19%|█▉        | 97/500 [01:28<07:29,  1.12s/it] 20%|█▉        | 99/500 [01:28<05:21,  1.25it/s] 20%|██        | 101/500 [01:34<10:08,  1.53s/it] 21%|██        | 103/500 [01:35<07:12,  1.09s/it] 21%|██        | 105/500 [01:35<05:08,  1.28it/s] 21%|██▏       | 107/500 [01:35<03:43,  1.76it/s] 22%|██▏       | 109/500 [01:35<02:43,  2.40it/s] 22%|██▏       | 111/500 [01:42<08:16,  1.28s/it] 23%|██▎       | 113/500 [01:42<05:54,  1.09it/s] 23%|██▎       | 115/500 [01:42<04:14,  1.51it/s] 23%|██▎       | 117/500 [01:42<03:04,  2.07it/s] 24%|██▍       | 119/500 [01:42<02:16,  2.79it/s] 24%|██▍       | 121/500 [01:49<07:42,  1.22s/it] 25%|██▍       | 123/500 [01:49<05:30,  1.14it/s] 25%|██▌       | 125/500 [01:49<03:57,  1.58it/s] 25%|██▌       | 127/500 [01:49<02:52,  2.16it/s] 26%|██▌       | 129/500 [01:49<02:07,  2.92it/s] 26%|██▌       | 131/500 [01:56<07:25,  1.21s/it] 27%|██▋       | 133/500 [01:56<05:18,  1.15it/s] 27%|██▋       | 135/500 [01:56<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:56<02:46,  2.18it/s]Epoch:  71  	Training Loss: 0.0028730924241244793
Test Loss:  0.0018782011466100812
Valid Loss:  0.0028921528719365597
Epoch:  72  	Training Loss: 0.0028726744931191206
Test Loss:  0.0018780352547764778
Valid Loss:  0.0028920734766870737
Epoch:  73  	Training Loss: 0.0028725918382406235
Test Loss:  0.0018778705270960927
Valid Loss:  0.0028919922187924385
Epoch:  74  	Training Loss: 0.0028725089505314827
Test Loss:  0.0018776999786496162
Valid Loss:  0.0028919146861881018
Epoch:  75  	Training Loss: 0.0028724297881126404
Test Loss:  0.0018775309436023235
Valid Loss:  0.002891833893954754
Epoch:  76  	Training Loss: 0.0028723482973873615
Test Loss:  0.0018773660995066166
Valid Loss:  0.0028917521703988314
Epoch:  77  	Training Loss: 0.0028722635470330715
Test Loss:  0.001877198345027864
Valid Loss:  0.0028916713781654835
Epoch:  78  	Training Loss: 0.002872183918952942
Test Loss:  0.0018770373426377773
Valid Loss:  0.002891592215746641
Epoch:  79  	Training Loss: 0.002872103825211525
Test Loss:  0.0018768706358969212
Valid Loss:  0.002891511656343937
Epoch:  80  	Training Loss: 0.0028720232658088207
Test Loss:  0.0018767027650028467
Valid Loss:  0.002891432959586382
Epoch:  81  	Training Loss: 0.0028719445690512657
Test Loss:  0.0018765389686450362
Valid Loss:  0.0028913533315062523
Epoch:  82  	Training Loss: 0.0028718626126646996
Test Loss:  0.0018500367878004909
Valid Loss:  0.00275406870059669
Epoch:  83  	Training Loss: 0.0027487613260746002
Test Loss:  0.0018266106490045786
Valid Loss:  0.0026347299572080374
Epoch:  84  	Training Loss: 0.0026381516363471746
Test Loss:  0.0018059320282191038
Valid Loss:  0.002528681419789791
Epoch:  85  	Training Loss: 0.002538837492465973
Test Loss:  0.0017878107028082013
Valid Loss:  0.0024337703362107277
Epoch:  86  	Training Loss: 0.002450705273076892
Test Loss:  0.0017718956805765629
Valid Loss:  0.0023485131096094847
Epoch:  87  	Training Loss: 0.0023715002462267876
Test Loss:  0.0017579239793121815
Valid Loss:  0.002273356541991234
Epoch:  88  	Training Loss: 0.0023003285750746727
Test Loss:  0.0017455725464969873
Valid Loss:  0.002204727381467819
Epoch:  89  	Training Loss: 0.0022356847766786814
Test Loss:  0.001734738820232451
Valid Loss:  0.0021423124708235264
Epoch:  90  	Training Loss: 0.0021773057524114847
Test Loss:  0.0017252411926165223
Valid Loss:  0.0020854061003774405
Epoch:  91  	Training Loss: 0.0021240937057882547
Test Loss:  0.0017168731428682804
Valid Loss:  0.0020330799743533134
Epoch:  92  	Training Loss: 0.0020750747062265873
Test Loss:  0.0017304144566878676
Valid Loss:  0.0020271376706659794
Epoch:  93  	Training Loss: 0.002092448528856039
Test Loss:  0.0018065746407955885
Valid Loss:  0.002222633920609951
Epoch:  94  	Training Loss: 0.002240076195448637
Test Loss:  0.0021983161568641663
Valid Loss:  0.002566001145169139
Epoch:  95  	Training Loss: 0.0026486446149647236
Test Loss:  0.003182025859132409
Valid Loss:  0.0037480113096535206
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.0036997671704739332
Test Loss:  0.001906317425891757
Valid Loss:  0.0023033847101032734
Epoch:  97  	Training Loss: 0.0023135801311582327
Test Loss:  0.0016580920200794935
Valid Loss:  0.001996302744373679
Epoch:  98  	Training Loss: 0.0020309698302298784
Test Loss:  0.0016153209144249558
Valid Loss:  0.001934620551764965
Epoch:  99  	Training Loss: 0.0019790008664131165
Test Loss:  0.001604683231562376
Valid Loss:  0.0019201262621209025
Epoch:  100  	Training Loss: 0.0019684447906911373
Test Loss:  0.001598065486177802
Valid Loss:  0.001915489207021892
Epoch:  101  	Training Loss: 0.001965413335710764
Test Loss:  0.0015916294651106
Valid Loss:  0.0019132622983306646
Epoch:  102  	Training Loss: 0.001963829156011343
Test Loss:  0.0015922943130135536
Valid Loss:  0.0018999942112714052
Epoch:  103  	Training Loss: 0.001948996214196086
Test Loss:  0.0015935394912958145
Valid Loss:  0.001887017861008644
Epoch:  104  	Training Loss: 0.0019344760803505778
Test Loss:  0.0015948063228279352
Valid Loss:  0.0018729811999946833
Epoch:  105  	Training Loss: 0.0019202958792448044
Test Loss:  0.0015948825748637319
Valid Loss:  0.0018594919238239527
Epoch:  106  	Training Loss: 0.0019069956615567207
Test Loss:  0.0015939681325107813
Valid Loss:  0.0018459035782143474
Epoch:  107  	Training Loss: 0.0018934067338705063
Test Loss:  0.001592120504938066
Valid Loss:  0.0018321864772588015
Epoch:  108  	Training Loss: 0.0018802814884111285
Test Loss:  0.001589802443049848
Valid Loss:  0.0018182004569098353
Epoch:  109  	Training Loss: 0.0018673388985916972
Test Loss:  0.001587388222105801
Valid Loss:  0.0018040374852716923
Epoch:  110  	Training Loss: 0.0018540893215686083
Test Loss:  0.0015850409399718046
Valid Loss:  0.001790190814062953
Epoch:  111  	Training Loss: 0.0018409937620162964
Test Loss:  0.0015827228780835867
Valid Loss:  0.0017760689370334148
Epoch:  112  	Training Loss: 0.0018278515199199319
Test Loss:  0.0015793645288795233
Valid Loss:  0.0017724791541695595
Epoch:  113  	Training Loss: 0.001826021820306778
Test Loss:  0.001576764858327806
Valid Loss:  0.0017713159322738647
Epoch:  114  	Training Loss: 0.0018252446316182613
Test Loss:  0.001574188587255776
Valid Loss:  0.0017705392092466354
Epoch:  115  	Training Loss: 0.001824533217586577
Test Loss:  0.001571637112647295
Valid Loss:  0.0017698517767712474
Epoch:  116  	Training Loss: 0.0018238336779177189
Test Loss:  0.001569106592796743
Valid Loss:  0.0017691919347271323
Epoch:  117  	Training Loss: 0.0018231486901640892
Test Loss:  0.0015666191466152668
Valid Loss:  0.0017685473430901766
Epoch:  118  	Training Loss: 0.0018224726663902402
Test Loss:  0.0015641594072803855
Valid Loss:  0.0017679148586466908
Epoch:  119  	Training Loss: 0.001821806188672781
Test Loss:  0.0015617175959050655
Valid Loss:  0.001767289242707193
Epoch:  120  	Training Loss: 0.001821149024181068
Test Loss:  0.0015592982526868582
Valid Loss:  0.0017666701460257173
Epoch:  121  	Training Loss: 0.0018204882508143783
Test Loss:  0.001556913135573268
Valid Loss:  0.0017660593148320913
Epoch:  122  	Training Loss: 0.0018198390025645494
Test Loss:  0.001553480513393879
Valid Loss:  0.0017562896246090531
Epoch:  123  	Training Loss: 0.001810251036658883
Test Loss:  0.001549568260088563
Valid Loss:  0.0017496785148978233
Epoch:  124  	Training Loss: 0.001804740633815527
Test Loss:  0.0015451156068593264
Valid Loss:  0.001744910259731114
Epoch:  125  	Training Loss: 0.0018009539926424623
Test Loss:  0.0015403013676404953
Valid Loss:  0.0017425179248675704
Epoch:  126  	Training Loss: 0.001798227895051241
Test Loss:  0.001535680377855897
Valid Loss:  0.001740146428346634
Epoch:  127  	Training Loss: 0.0017958091339096427
Test Loss:  0.001531086047179997
Valid Loss:  0.001738212420605123
Epoch:  128  	Training Loss: 0.001793727045878768
Test Loss:  0.0015267645940184593
Valid Loss:  0.0017362714279443026
Epoch:  129  	Training Loss: 0.0017919042147696018
Test Loss:  0.0015225335955619812
Valid Loss:  0.0017348118126392365
Epoch:  130  	Training Loss: 0.001790571608580649
Test Loss:  0.0015184365911409259
Valid Loss:  0.0017343827057629824
Epoch:  131  	Training Loss: 0.001789585454389453
Test Loss:  0.0015148795209825039
Valid Loss:  0.001733273034915328
Epoch:  132  	Training Loss: 0.0017887346912175417
Test Loss:  0.0015147430822253227
Valid Loss:  0.0017333917785435915
Epoch:  133  	Training Loss: 0.0017885616980493069
Test Loss:  0.0015146288787946105
Valid Loss:  0.0017334597650915384
Epoch:  134  	Training Loss: 0.001788445981219411
Test Loss:  0.0015145299257710576
Valid Loss:  0.0017334942240267992
Epoch:  135  	Training Loss: 0.0017883551772683859
Test Loss:  0.0015144228236749768
Valid Loss:  0.0017334945732727647
Epoch:  136  	Training Loss: 0.0017882701940834522
Test Loss:  0.0015143111813813448
Valid Loss:  0.001733470126055181
Epoch:  137  	Training Loss: 0.0017881868407130241
Test Loss:  0.0015141993062570691
Valid Loss:  0.0017334253061562777
Epoch:  138  	Training Loss: 0.0017881066305562854
Test Loss:  0.001514079631306231
Valid Loss:  0.001733375946059823
 28%|██▊       | 139/500 [01:56<02:03,  2.92it/s] 28%|██▊       | 141/500 [02:03<07:11,  1.20s/it] 29%|██▊       | 143/500 [02:03<05:08,  1.16it/s] 29%|██▉       | 145/500 [02:03<03:41,  1.60it/s] 29%|██▉       | 147/500 [02:03<02:42,  2.17it/s] 30%|██▉       | 149/500 [02:03<02:00,  2.92it/s] 30%|███       | 151/500 [02:10<07:08,  1.23s/it] 31%|███       | 153/500 [02:10<05:06,  1.13it/s] 31%|███       | 155/500 [02:10<03:39,  1.57it/s] 31%|███▏      | 157/500 [02:10<02:39,  2.15it/s] 32%|███▏      | 159/500 [02:10<01:57,  2.89it/s] 32%|███▏      | 161/500 [02:17<06:47,  1.20s/it] 33%|███▎      | 163/500 [02:17<04:50,  1.16it/s] 33%|███▎      | 165/500 [02:17<03:29,  1.60it/s] 33%|███▎      | 167/500 [02:17<02:32,  2.19it/s] 34%|███▍      | 169/500 [02:17<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:24<06:44,  1.23s/it] 35%|███▍      | 173/500 [02:24<04:48,  1.13it/s] 35%|███▌      | 175/500 [02:24<03:27,  1.57it/s] 35%|███▌      | 177/500 [02:24<02:30,  2.15it/s] 36%|███▌      | 179/500 [02:24<01:50,  2.90it/s] 36%|███▌      | 181/500 [02:31<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:31<04:29,  1.17it/s] 37%|███▋      | 185/500 [02:31<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:31<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:31<01:43,  2.99it/s] 38%|███▊      | 191/500 [02:38<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:38<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:38<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:38<02:19,  2.17it/s] 40%|███▉      | 199/500 [02:38<01:44,  2.87it/s] 40%|████      | 201/500 [02:45<06:02,  1.21s/it] 41%|████      | 203/500 [02:45<04:18,  1.15it/s] 41%|████      | 205/500 [02:45<03:05,  1.59it/s]Epoch:  139  	Training Loss: 0.001788026769645512
Test Loss:  0.0015139634488150477
Valid Loss:  0.0017333191353827715
Epoch:  140  	Training Loss: 0.001787947490811348
Test Loss:  0.001513834809884429
Valid Loss:  0.0017332565039396286
Epoch:  141  	Training Loss: 0.001787866814993322
Test Loss:  0.0015137199079617858
Valid Loss:  0.001733187003992498
Epoch:  142  	Training Loss: 0.0017877835780382156
Test Loss:  0.0015050231013447046
Valid Loss:  0.0017264593625441194
Epoch:  143  	Training Loss: 0.0017814983148127794
Test Loss:  0.0014971786877140403
Valid Loss:  0.0017196640837937593
Epoch:  144  	Training Loss: 0.0017753478605300188
Test Loss:  0.0014899789821356535
Valid Loss:  0.0017131364438682795
Epoch:  145  	Training Loss: 0.001769336173310876
Test Loss:  0.0014832704328000546
Valid Loss:  0.001707131159491837
Epoch:  146  	Training Loss: 0.001763553824275732
Test Loss:  0.0014770706184208393
Valid Loss:  0.0017014102777466178
Epoch:  147  	Training Loss: 0.0017579441191628575
Test Loss:  0.0014714091084897518
Valid Loss:  0.001695737475529313
Epoch:  148  	Training Loss: 0.001752421143464744
Test Loss:  0.0014661290915682912
Valid Loss:  0.001689976081252098
Epoch:  149  	Training Loss: 0.0017467949073761702
Test Loss:  0.0014611512888222933
Valid Loss:  0.0016842465847730637
Epoch:  150  	Training Loss: 0.0017412388697266579
Test Loss:  0.001456406549550593
Valid Loss:  0.0016785438638180494
Epoch:  151  	Training Loss: 0.0017357446486130357
Test Loss:  0.0014518422540277243
Valid Loss:  0.0016728686168789864
Epoch:  152  	Training Loss: 0.001730287098325789
Test Loss:  0.0014482960104942322
Valid Loss:  0.0016526234103366733
Epoch:  153  	Training Loss: 0.00171118532307446
Test Loss:  0.0014449849259108305
Valid Loss:  0.0016333102248609066
Epoch:  154  	Training Loss: 0.0016930485144257545
Test Loss:  0.0014418873470276594
Valid Loss:  0.0016147386049851775
Epoch:  155  	Training Loss: 0.0016755792312324047
Test Loss:  0.001438983716070652
Valid Loss:  0.0015968794468790293
Epoch:  156  	Training Loss: 0.0016588496509939432
Test Loss:  0.0014362781075760722
Valid Loss:  0.0015798138920217752
Epoch:  157  	Training Loss: 0.0016428196104243398
Test Loss:  0.0014337582979351282
Valid Loss:  0.0015633938601240516
Epoch:  158  	Training Loss: 0.0016273991204798222
Test Loss:  0.0014314127620309591
Valid Loss:  0.0015476883854717016
Epoch:  159  	Training Loss: 0.0016126370755955577
Test Loss:  0.0014292264822870493
Valid Loss:  0.0015325471758842468
Epoch:  160  	Training Loss: 0.0015983517514541745
Test Loss:  0.0014271930558606982
Valid Loss:  0.0015179670881479979
Epoch:  161  	Training Loss: 0.0015845245216041803
Test Loss:  0.001425294205546379
Valid Loss:  0.0015042379964143038
Epoch:  162  	Training Loss: 0.0015711444430053234
Test Loss:  0.0014226927887648344
Valid Loss:  0.0014870529994368553
Epoch:  163  	Training Loss: 0.0015544111374765635
Test Loss:  0.0014203517930582166
Valid Loss:  0.0014705004869028926
Epoch:  164  	Training Loss: 0.0015382901765406132
Test Loss:  0.0014184019528329372
Valid Loss:  0.0014545454178005457
Epoch:  165  	Training Loss: 0.0015227581607177854
Test Loss:  0.001416552346199751
Valid Loss:  0.0014391696313396096
Epoch:  166  	Training Loss: 0.0015077826101332903
Test Loss:  0.0014148068148642778
Valid Loss:  0.0014243533369153738
Epoch:  167  	Training Loss: 0.0014933120692148805
Test Loss:  0.0014131542993709445
Valid Loss:  0.0014100221451371908
Epoch:  168  	Training Loss: 0.0014792997390031815
Test Loss:  0.0014115929370746017
Valid Loss:  0.0013962017837911844
Epoch:  169  	Training Loss: 0.0014657843858003616
Test Loss:  0.001410130294971168
Valid Loss:  0.0013828710652887821
Epoch:  170  	Training Loss: 0.001452745869755745
Test Loss:  0.001408752636052668
Valid Loss:  0.0013700092677026987
Epoch:  171  	Training Loss: 0.0014401678927242756
Test Loss:  0.0014074570499360561
Valid Loss:  0.0013576047495007515
Epoch:  172  	Training Loss: 0.0014280307805165648
Test Loss:  0.0014046780997887254
Valid Loss:  0.001348289311863482
Epoch:  173  	Training Loss: 0.0014187954366207123
Test Loss:  0.0014020772650837898
Valid Loss:  0.0013393154367804527
Epoch:  174  	Training Loss: 0.0014099274994805455
Test Loss:  0.0013997007627040148
Valid Loss:  0.0013306899927556515
Epoch:  175  	Training Loss: 0.0014014546759426594
Test Loss:  0.0013975228648632765
Valid Loss:  0.0013224320719018579
Epoch:  176  	Training Loss: 0.001393347978591919
Test Loss:  0.0013955397298559546
Valid Loss:  0.0013144774129614234
Epoch:  177  	Training Loss: 0.0013855404686182737
Test Loss:  0.0013937323819845915
Valid Loss:  0.001306783058680594
Epoch:  178  	Training Loss: 0.001377988257445395
Test Loss:  0.0013920183992013335
Valid Loss:  0.0012993596028536558
Epoch:  179  	Training Loss: 0.001370692509226501
Test Loss:  0.0013903898652642965
Valid Loss:  0.001292175380513072
Epoch:  180  	Training Loss: 0.001363632152788341
Test Loss:  0.0013888461980968714
Valid Loss:  0.0012852458748966455
Epoch:  181  	Training Loss: 0.0013568123104050756
Test Loss:  0.0013873697025701404
Valid Loss:  0.0012785389553755522
Epoch:  182  	Training Loss: 0.001350207021459937
Test Loss:  0.0013858595630154014
Valid Loss:  0.0012782176490873098
Epoch:  183  	Training Loss: 0.0013498440384864807
Test Loss:  0.0013844193890690804
Valid Loss:  0.0012779062381014228
Epoch:  184  	Training Loss: 0.0013494899030774832
Test Loss:  0.0013830279931426048
Valid Loss:  0.001277597388252616
Epoch:  185  	Training Loss: 0.001349142869003117
Test Loss:  0.0013816885184496641
Valid Loss:  0.001277286559343338
Epoch:  186  	Training Loss: 0.0013488037511706352
Test Loss:  0.0013803886249661446
Valid Loss:  0.0012769801542162895
Epoch:  187  	Training Loss: 0.0013484667288139462
Test Loss:  0.001379142515361309
Valid Loss:  0.0012766786385327578
Epoch:  188  	Training Loss: 0.0013481357600539923
Test Loss:  0.0013779286528006196
Valid Loss:  0.0012763738632202148
Epoch:  189  	Training Loss: 0.0013478113105520606
Test Loss:  0.0013767625205218792
Valid Loss:  0.0012760753743350506
Epoch:  190  	Training Loss: 0.0013474904699251056
Test Loss:  0.0013756275875493884
Valid Loss:  0.0012757782824337482
Epoch:  191  	Training Loss: 0.0013471735874190927
Test Loss:  0.001374530023895204
Valid Loss:  0.0012754735071212053
Epoch:  192  	Training Loss: 0.0013468594988808036
Test Loss:  0.0013693143846467137
Valid Loss:  0.0012712100287899375
Epoch:  193  	Training Loss: 0.0013434209395200014
Test Loss:  0.0013637952506542206
Valid Loss:  0.0012679081410169601
Epoch:  194  	Training Loss: 0.0013407785445451736
Test Loss:  0.0013581285020336509
Valid Loss:  0.0012648322153836489
Epoch:  195  	Training Loss: 0.0013383144978433847
Test Loss:  0.00135247060097754
Valid Loss:  0.0012620248598977923
Epoch:  196  	Training Loss: 0.0013360264711081982
Test Loss:  0.00134687265381217
Valid Loss:  0.0012594021391123533
Epoch:  197  	Training Loss: 0.001333893509581685
Test Loss:  0.001341390423476696
Valid Loss:  0.0012569561367854476
Epoch:  198  	Training Loss: 0.0013318988494575024
Test Loss:  0.0013360544107854366
Valid Loss:  0.0012547107180580497
Epoch:  199  	Training Loss: 0.0013300321297720075
Test Loss:  0.001330882078036666
Valid Loss:  0.0012525937054306269
Epoch:  200  	Training Loss: 0.001328282174654305
Test Loss:  0.0013259025290608406
Valid Loss:  0.0012506017228588462
Epoch:  201  	Training Loss: 0.0013266310561448336
Test Loss:  0.0013210864271968603
Valid Loss:  0.0012487380299717188
Epoch:  202  	Training Loss: 0.0013250851770862937
Test Loss:  0.0013173494953662157
Valid Loss:  0.001241793273948133
Epoch:  203  	Training Loss: 0.0013179905945435166
Test Loss:  0.0013144403928890824
Valid Loss:  0.0012351119657978415
Epoch:  204  	Training Loss: 0.0013111872831359506
Test Loss:  0.0013121501542627811
Valid Loss:  0.0012286580167710781
Epoch:  205  	Training Loss: 0.001304641948081553
Test Loss:  0.0013103478122502565
Valid Loss:  0.001222417689859867
Epoch:  206  	Training Loss: 0.0012983203632757068
Test Loss:  0.0013089003041386604
Valid Loss:  0.001216374570503831
Epoch:  207  	Training Loss: 0.0012922085588797927
Test Loss:   41%|████▏     | 207/500 [02:45<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:45<01:39,  2.94it/s] 42%|████▏     | 211/500 [02:52<06:01,  1.25s/it] 43%|████▎     | 213/500 [02:52<04:17,  1.12it/s] 43%|████▎     | 215/500 [02:52<03:04,  1.55it/s] 43%|████▎     | 217/500 [02:52<02:13,  2.11it/s] 44%|████▍     | 219/500 [02:52<01:38,  2.84it/s] 44%|████▍     | 221/500 [02:59<05:42,  1.23s/it] 45%|████▍     | 223/500 [02:59<04:03,  1.14it/s] 45%|████▌     | 225/500 [02:59<02:54,  1.57it/s] 45%|████▌     | 227/500 [02:59<02:06,  2.15it/s] 46%|████▌     | 229/500 [03:00<01:33,  2.91it/s] 46%|████▌     | 231/500 [03:06<05:28,  1.22s/it] 47%|████▋     | 233/500 [03:06<03:53,  1.14it/s] 47%|████▋     | 235/500 [03:06<02:47,  1.58it/s] 47%|████▋     | 237/500 [03:06<02:01,  2.16it/s] 48%|████▊     | 239/500 [03:07<01:29,  2.90it/s] 48%|████▊     | 241/500 [03:13<05:14,  1.21s/it] 49%|████▊     | 243/500 [03:13<03:43,  1.15it/s] 49%|████▉     | 245/500 [03:13<02:40,  1.59it/s] 49%|████▉     | 247/500 [03:13<01:56,  2.18it/s] 50%|████▉     | 249/500 [03:14<01:25,  2.94it/s] 50%|█████     | 251/500 [03:20<04:56,  1.19s/it] 51%|█████     | 253/500 [03:20<03:31,  1.17it/s] 51%|█████     | 255/500 [03:20<02:32,  1.61it/s] 51%|█████▏    | 257/500 [03:20<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:21<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:27<04:47,  1.20s/it] 53%|█████▎    | 263/500 [03:27<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:27<02:26,  1.60it/s] 53%|█████▎    | 267/500 [03:27<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:27<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:34<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:34<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:34<02:18,  1.62it/s]0.001307729515247047
Valid Loss:  0.0012105220230296254
Epoch:  208  	Training Loss: 0.0012862884905189276
Test Loss:  0.001306777005083859
Valid Loss:  0.0012048532953485847
Epoch:  209  	Training Loss: 0.0012805538717657328
Test Loss:  0.0013059788616374135
Valid Loss:  0.0011993611697107553
Epoch:  210  	Training Loss: 0.001274994807317853
Test Loss:  0.001305307843722403
Valid Loss:  0.0011940402910113335
Epoch:  211  	Training Loss: 0.0012696045450866222
Test Loss:  0.001304734731093049
Valid Loss:  0.0011888871667906642
Epoch:  212  	Training Loss: 0.0012643758673220873
Test Loss:  0.001302748336456716
Valid Loss:  0.001181258587166667
Epoch:  213  	Training Loss: 0.0012588565004989505
Test Loss:  0.0013016466982662678
Valid Loss:  0.0011764548253268003
Epoch:  214  	Training Loss: 0.0012556005967780948
Test Loss:  0.0013007748639211059
Valid Loss:  0.0011732915882021189
Epoch:  215  	Training Loss: 0.0012535713613033295
Test Loss:  0.001299857860431075
Valid Loss:  0.0011710897088050842
Epoch:  216  	Training Loss: 0.001252215588465333
Test Loss:  0.0012987966183573008
Valid Loss:  0.0011694745626300573
Epoch:  217  	Training Loss: 0.0012512262910604477
Test Loss:  0.0012975656427443027
Valid Loss:  0.0011682239128276706
Epoch:  218  	Training Loss: 0.0012504446785897017
Test Loss:  0.0012961870525032282
Valid Loss:  0.0011672049295157194
Epoch:  219  	Training Loss: 0.001249777153134346
Test Loss:  0.001294689835049212
Valid Loss:  0.0011663346085697412
Epoch:  220  	Training Loss: 0.0012491806410253048
Test Loss:  0.0012931014643982053
Valid Loss:  0.001165570691227913
Epoch:  221  	Training Loss: 0.0012486267369240522
Test Loss:  0.00129144755192101
Valid Loss:  0.0011648802319541574
Epoch:  222  	Training Loss: 0.0012481017038226128
Test Loss:  0.001286773825995624
Valid Loss:  0.001163695240393281
Epoch:  223  	Training Loss: 0.0012469510547816753
Test Loss:  0.0012823656434193254
Valid Loss:  0.0011625417973846197
Epoch:  224  	Training Loss: 0.0012458660639822483
Test Loss:  0.0012781727127730846
Valid Loss:  0.0011614363174885511
Epoch:  225  	Training Loss: 0.0012448399793356657
Test Loss:  0.0012741715181618929
Valid Loss:  0.001160376355983317
Epoch:  226  	Training Loss: 0.0012438674457371235
Test Loss:  0.0012703342363238335
Valid Loss:  0.0011593636590987444
Epoch:  227  	Training Loss: 0.0012429466005414724
Test Loss:  0.0012666522525250912
Valid Loss:  0.0011583982268348336
Epoch:  228  	Training Loss: 0.001242075115442276
Test Loss:  0.0012631048448383808
Valid Loss:  0.0011574712116271257
Epoch:  229  	Training Loss: 0.0012412453070282936
Test Loss:  0.0012596930610015988
Valid Loss:  0.0011565948370844126
Epoch:  230  	Training Loss: 0.001240459969267249
Test Loss:  0.0012564053758978844
Valid Loss:  0.0011557594407349825
Epoch:  231  	Training Loss: 0.0012397136306390166
Test Loss:  0.0012532365508377552
Valid Loss:  0.001154960598796606
Epoch:  232  	Training Loss: 0.0012390019837766886
Test Loss:  0.0012469654902815819
Valid Loss:  0.0011540019186213613
Epoch:  233  	Training Loss: 0.0012378941755741835
Test Loss:  0.0012416746467351913
Valid Loss:  0.001153081888332963
Epoch:  234  	Training Loss: 0.0012369354953989387
Test Loss:  0.0012370566837489605
Valid Loss:  0.0011521903797984123
Epoch:  235  	Training Loss: 0.0012360706459730864
Test Loss:  0.001232930226251483
Valid Loss:  0.0011513321660459042
Epoch:  236  	Training Loss: 0.0012352783232927322
Test Loss:  0.0012291683815419674
Valid Loss:  0.0011505092261359096
Epoch:  237  	Training Loss: 0.001234543859027326
Test Loss:  0.0012256988557055593
Valid Loss:  0.0011497254017740488
Epoch:  238  	Training Loss: 0.0012338599190115929
Test Loss:  0.001222463557496667
Valid Loss:  0.0011489761527627707
Epoch:  239  	Training Loss: 0.001233219401910901
Test Loss:  0.0012194279115647078
Valid Loss:  0.0011482683476060629
Epoch:  240  	Training Loss: 0.0012326177675276995
Test Loss:  0.0012165617663413286
Valid Loss:  0.001147596980445087
Epoch:  241  	Training Loss: 0.0012320539681240916
Test Loss:  0.0012138559250161052
Valid Loss:  0.0011469641467556357
Epoch:  242  	Training Loss: 0.0012315241619944572
Test Loss:  0.001214078045450151
Valid Loss:  0.0011398226488381624
Epoch:  243  	Training Loss: 0.001224912703037262
Test Loss:  0.0012138800229877234
Valid Loss:  0.001133495126850903
Epoch:  244  	Training Loss: 0.0012185733066871762
Test Loss:  0.0012134839780628681
Valid Loss:  0.00112744455691427
Epoch:  245  	Training Loss: 0.0012124155182391405
Test Loss:  0.001213002484291792
Valid Loss:  0.0011215897975489497
Epoch:  246  	Training Loss: 0.0012064254842698574
Test Loss:  0.001212477101944387
Valid Loss:  0.0011158909182995558
Epoch:  247  	Training Loss: 0.001200660364702344
Test Loss:  0.0012119156308472157
Valid Loss:  0.001110423938371241
Epoch:  248  	Training Loss: 0.001195139135234058
Test Loss:  0.0012113344855606556
Valid Loss:  0.001105091767385602
Epoch:  249  	Training Loss: 0.0011897569056600332
Test Loss:  0.0012107380898669362
Valid Loss:  0.001099891378544271
Epoch:  250  	Training Loss: 0.0011845056433230639
Test Loss:  0.001210130751132965
Valid Loss:  0.0010948146227747202
Epoch:  251  	Training Loss: 0.0011793833691626787
Test Loss:  0.0012095100246369839
Valid Loss:  0.0010898561449721456
Epoch:  252  	Training Loss: 0.0011743877548724413
Test Loss:  0.0012063891626894474
Valid Loss:  0.0010847938247025013
Epoch:  253  	Training Loss: 0.0011691785184666514
Test Loss:  0.0012037190608680248
Valid Loss:  0.0010797547874972224
Epoch:  254  	Training Loss: 0.0011641057208180428
Test Loss:  0.0012012382503598928
Valid Loss:  0.0010747989872470498
Epoch:  255  	Training Loss: 0.001159152016043663
Test Loss:  0.0011988576734438539
Valid Loss:  0.0010699420236051083
Epoch:  256  	Training Loss: 0.0011543103028088808
Test Loss:  0.0011965411249548197
Valid Loss:  0.0010651983320713043
Epoch:  257  	Training Loss: 0.00114958337508142
Test Loss:  0.001194294192828238
Valid Loss:  0.001060557784512639
Epoch:  258  	Training Loss: 0.0011450317688286304
Test Loss:  0.001192088471725583
Valid Loss:  0.0010560958180576563
Epoch:  259  	Training Loss: 0.0011406573466956615
Test Loss:  0.0011899310629814863
Valid Loss:  0.0010517279151827097
Epoch:  260  	Training Loss: 0.0011363783851265907
Test Loss:  0.001187837217003107
Valid Loss:  0.001047630445100367
Epoch:  261  	Training Loss: 0.0011321925558149815
Test Loss:  0.0011857884237542748
Valid Loss:  0.0010437258752062917
Epoch:  262  	Training Loss: 0.0011280995095148683
Test Loss:  0.001186023815535009
Valid Loss:  0.0010436105076223612
Epoch:  263  	Training Loss: 0.0011280744802206755
Test Loss:  0.0011862078681588173
Valid Loss:  0.0010435300646349788
Epoch:  264  	Training Loss: 0.0011280574835836887
Test Loss:  0.0011863472172990441
Valid Loss:  0.0010434665018692613
Epoch:  265  	Training Loss: 0.0011280450271442533
Test Loss:  0.0011864572297781706
Valid Loss:  0.0010434186551719904
Epoch:  266  	Training Loss: 0.0011280375765636563
Test Loss:  0.0011865339474752545
Valid Loss:  0.0010433855932205915
Epoch:  267  	Training Loss: 0.0011280304752290249
Test Loss:  0.001186595531180501
Valid Loss:  0.0010433589341118932
Epoch:  268  	Training Loss: 0.0011280241888016462
Test Loss:  0.001186635927297175
Valid Loss:  0.0010433356510475278
Epoch:  269  	Training Loss: 0.0011280195321887732
Test Loss:  0.001186674926429987
Valid Loss:  0.001043320749886334
Epoch:  270  	Training Loss: 0.0011280158068984747
Test Loss:  0.0011867022840306163
Valid Loss:  0.001043307245709002
Epoch:  271  	Training Loss: 0.0011280103353783488
Test Loss:  0.0011867193970829248
Valid Loss:  0.0010432952549308538
Epoch:  272  	Training Loss: 0.0011280071921646595
Test Loss:  0.0011789884883910418
Valid Loss:  0.0010369429364800453
Epoch:  273  	Training Loss: 0.0011209460208192468
Test Loss:  0.0011734741274267435
Valid Loss:  0.00103071890771389
Epoch:  274  	Training Loss: 0.0011142137227579951
Test Loss:  0.0011691446416079998
Valid Loss:  0.0010245905723422766
Epoch:  275  	Training Loss: 0.0011077129747718573
Test Loss:  0.0011654498521238565
Valid Loss:  0.0010185466380789876
 55%|█████▌    | 277/500 [03:34<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:34<01:16,  2.90it/s] 56%|█████▌    | 281/500 [03:41<04:30,  1.23s/it] 57%|█████▋    | 283/500 [03:41<03:12,  1.13it/s] 57%|█████▋    | 285/500 [03:41<02:17,  1.56it/s] 57%|█████▋    | 287/500 [03:41<01:39,  2.14it/s] 58%|█████▊    | 289/500 [03:42<01:13,  2.87it/s] 58%|█████▊    | 291/500 [03:48<04:20,  1.25s/it] 59%|█████▊    | 293/500 [03:48<03:05,  1.12it/s] 59%|█████▉    | 295/500 [03:49<02:12,  1.55it/s] 59%|█████▉    | 297/500 [03:49<01:35,  2.12it/s] 60%|█████▉    | 299/500 [03:49<01:10,  2.86it/s] 60%|██████    | 301/500 [03:55<03:58,  1.20s/it] 61%|██████    | 303/500 [03:55<02:49,  1.16it/s] 61%|██████    | 305/500 [03:55<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:56<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:56<01:04,  2.96it/s] 62%|██████▏   | 311/500 [04:02<03:48,  1.21s/it] 63%|██████▎   | 313/500 [04:02<02:42,  1.15it/s] 63%|██████▎   | 315/500 [04:02<01:55,  1.59it/s] 63%|██████▎   | 317/500 [04:03<01:23,  2.18it/s] 64%|██████▍   | 319/500 [04:03<01:01,  2.94it/s] 64%|██████▍   | 321/500 [04:09<03:34,  1.20s/it] 65%|██████▍   | 323/500 [04:09<02:32,  1.16it/s] 65%|██████▌   | 325/500 [04:09<01:48,  1.61it/s] 65%|██████▌   | 327/500 [04:10<01:19,  2.17it/s] 66%|██████▌   | 329/500 [04:10<00:59,  2.89it/s] 66%|██████▌   | 331/500 [04:16<03:25,  1.22s/it] 67%|██████▋   | 333/500 [04:16<02:25,  1.14it/s] 67%|██████▋   | 335/500 [04:16<01:44,  1.58it/s] 67%|██████▋   | 337/500 [04:17<01:15,  2.17it/s] 68%|██████▊   | 339/500 [04:17<00:55,  2.92it/s] 68%|██████▊   | 341/500 [04:23<03:13,  1.22s/it] 69%|██████▊   | 343/500 [04:23<02:17,  1.15it/s]Epoch:  276  	Training Loss: 0.0011013795156031847
Test Loss:  0.0011621066369116306
Valid Loss:  0.001012591877952218
Epoch:  277  	Training Loss: 0.0010951841250061989
Test Loss:  0.0011589310597628355
Valid Loss:  0.0010066782124340534
Epoch:  278  	Training Loss: 0.0010890030534937978
Test Loss:  0.001155880163423717
Valid Loss:  0.0010008637327700853
Epoch:  279  	Training Loss: 0.001082956325262785
Test Loss:  0.0011528960894793272
Valid Loss:  0.0009951541433110833
Epoch:  280  	Training Loss: 0.0010770189110189676
Test Loss:  0.0011499336687847972
Valid Loss:  0.0009894900722429156
Epoch:  281  	Training Loss: 0.001071097911335528
Test Loss:  0.0011470026802271605
Valid Loss:  0.0009839280974119902
Epoch:  282  	Training Loss: 0.0010653010103851557
Test Loss:  0.0011479771928861737
Valid Loss:  0.0009803513530641794
Epoch:  283  	Training Loss: 0.0010620648972690105
Test Loss:  0.0011477605439722538
Valid Loss:  0.0009772947523742914
Epoch:  284  	Training Loss: 0.0010591215686872602
Test Loss:  0.0011469994205981493
Valid Loss:  0.0009744706330820918
Epoch:  285  	Training Loss: 0.001056382548995316
Test Loss:  0.0011460059322416782
Valid Loss:  0.0009717500652186573
Epoch:  286  	Training Loss: 0.0010537020862102509
Test Loss:  0.0011449246667325497
Valid Loss:  0.0009690952720120549
Epoch:  287  	Training Loss: 0.0010510784341022372
Test Loss:  0.0011438197689130902
Valid Loss:  0.0009664951357990503
Epoch:  288  	Training Loss: 0.001048506936058402
Test Loss:  0.0011427189456298947
Valid Loss:  0.0009639477357268333
Epoch:  289  	Training Loss: 0.0010459879413247108
Test Loss:  0.0011416262714192271
Valid Loss:  0.0009614455047994852
Epoch:  290  	Training Loss: 0.00104352249763906
Test Loss:  0.0011405500117689371
Valid Loss:  0.0009589899564161897
Epoch:  291  	Training Loss: 0.001041105017066002
Test Loss:  0.0011394941247999668
Valid Loss:  0.0009565799846313894
Epoch:  292  	Training Loss: 0.0010387368965893984
Test Loss:  0.0011399420909583569
Valid Loss:  0.0009563611238263547
Epoch:  293  	Training Loss: 0.001038598595187068
Test Loss:  0.001140086678788066
Valid Loss:  0.0009562112973071635
Epoch:  294  	Training Loss: 0.0010384786874055862
Test Loss:  0.0011400870280340314
Valid Loss:  0.0009560876060277224
Epoch:  295  	Training Loss: 0.0010383641347289085
Test Loss:  0.0011400256771594286
Valid Loss:  0.0009559742175042629
Epoch:  296  	Training Loss: 0.0010382495820522308
Test Loss:  0.0011399354552850127
Valid Loss:  0.000955865834839642
Epoch:  297  	Training Loss: 0.0010381366591900587
Test Loss:  0.001139831030741334
Valid Loss:  0.0009557593148201704
Epoch:  298  	Training Loss: 0.001038022106513381
Test Loss:  0.0011397204361855984
Valid Loss:  0.000955653318669647
Epoch:  299  	Training Loss: 0.0010379091836512089
Test Loss:  0.0011396065820008516
Valid Loss:  0.0009555505821481347
Epoch:  300  	Training Loss: 0.0010377955622971058
Test Loss:  0.0011394950561225414
Valid Loss:  0.0009554448770359159
Epoch:  301  	Training Loss: 0.0010376819409430027
Test Loss:  0.0011393821332603693
Valid Loss:  0.0009553427807986736
Epoch:  302  	Training Loss: 0.0010375690180808306
Test Loss:  0.0011362931691110134
Valid Loss:  0.0009550326503813267
Epoch:  303  	Training Loss: 0.0010371546959504485
Test Loss:  0.0011341322679072618
Valid Loss:  0.0009546813671477139
Epoch:  304  	Training Loss: 0.0010367840295657516
Test Loss:  0.0011322094360366464
Valid Loss:  0.0009543366031721234
Epoch:  305  	Training Loss: 0.0010364390909671783
Test Loss:  0.001130415708757937
Valid Loss:  0.0009540076134726405
Epoch:  306  	Training Loss: 0.0010361119639128447
Test Loss:  0.0011287238448858261
Valid Loss:  0.0009537037112750113
Epoch:  307  	Training Loss: 0.0010358067229390144
Test Loss:  0.0011271219700574875
Valid Loss:  0.0009534127893857658
Epoch:  308  	Training Loss: 0.0010355155682191253
Test Loss:  0.001125604729168117
Valid Loss:  0.0009531326359137893
Epoch:  309  	Training Loss: 0.0010352408280596137
Test Loss:  0.0011241680476814508
Valid Loss:  0.0009528727969154716
Epoch:  310  	Training Loss: 0.0010349794756621122
Test Loss:  0.0011228034272789955
Valid Loss:  0.000952624948695302
Epoch:  311  	Training Loss: 0.0010347298812121153
Test Loss:  0.0011215109843760729
Valid Loss:  0.0009523867629468441
Epoch:  312  	Training Loss: 0.00103449122980237
Test Loss:  0.0011209140066057444
Valid Loss:  0.0009522294858470559
Epoch:  313  	Training Loss: 0.0010343142785131931
Test Loss:  0.0011203394969925284
Valid Loss:  0.0009520667372271419
Epoch:  314  	Training Loss: 0.0010341418674215674
Test Loss:  0.0011197852436453104
Valid Loss:  0.0009519102168269455
Epoch:  315  	Training Loss: 0.0010339710861444473
Test Loss:  0.001119256136007607
Valid Loss:  0.0009517542202956975
Epoch:  316  	Training Loss: 0.0010337989078834653
Test Loss:  0.0011187344789505005
Valid Loss:  0.0009516005520708859
Epoch:  317  	Training Loss: 0.001033629523590207
Test Loss:  0.0011182352900505066
Valid Loss:  0.0009514429257251322
Epoch:  318  	Training Loss: 0.0010334618855267763
Test Loss:  0.0011177447158843279
Valid Loss:  0.0009512893157079816
Epoch:  319  	Training Loss: 0.0010332942474633455
Test Loss:  0.0011172668309882283
Valid Loss:  0.0009511345997452736
Epoch:  320  	Training Loss: 0.0010331294033676386
Test Loss:  0.0011168016353622079
Valid Loss:  0.0009509811061434448
Epoch:  321  	Training Loss: 0.0010329619981348515
Test Loss:  0.0011163465678691864
Valid Loss:  0.0009508314542472363
Epoch:  322  	Training Loss: 0.0010327973868697882
Test Loss:  0.0011154388776049018
Valid Loss:  0.0009484413312748075
Epoch:  323  	Training Loss: 0.0010304234456270933
Test Loss:  0.0011146476026624441
Valid Loss:  0.0009461483568884432
Epoch:  324  	Training Loss: 0.0010281703434884548
Test Loss:  0.0011139421258121729
Valid Loss:  0.000943895778618753
Epoch:  325  	Training Loss: 0.0010259655537083745
Test Loss:  0.001113309757784009
Valid Loss:  0.0009416771354153752
Epoch:  326  	Training Loss: 0.001023804652504623
Test Loss:  0.0011127250036224723
Valid Loss:  0.0009394935332238674
Epoch:  327  	Training Loss: 0.0010216862428933382
Test Loss:  0.0011121866991743445
Valid Loss:  0.0009373513166792691
Epoch:  328  	Training Loss: 0.0010196090443059802
Test Loss:  0.0011116734240204096
Valid Loss:  0.0009352401830255985
Epoch:  329  	Training Loss: 0.001017572358250618
Test Loss:  0.0011112010106444359
Valid Loss:  0.0009331665933132172
Epoch:  330  	Training Loss: 0.0010155743220821023
Test Loss:  0.0011107423342764378
Valid Loss:  0.000931123795453459
Epoch:  331  	Training Loss: 0.0010136134224012494
Test Loss:  0.0011102966964244843
Valid Loss:  0.0009291172027587891
Epoch:  332  	Training Loss: 0.0010116961784660816
Test Loss:  0.0011097807437181473
Valid Loss:  0.0009289785521104932
Epoch:  333  	Training Loss: 0.0010115390177816153
Test Loss:  0.0011092948261648417
Valid Loss:  0.000928841473069042
Epoch:  334  	Training Loss: 0.0010113843018189073
Test Loss:  0.001108833821490407
Valid Loss:  0.0009287024149671197
Epoch:  335  	Training Loss: 0.0010112293530255556
Test Loss:  0.001108397962525487
Valid Loss:  0.0009285674314014614
Epoch:  336  	Training Loss: 0.0010110760340467095
Test Loss:  0.0011079855030402541
Valid Loss:  0.0009284262778237462
Epoch:  337  	Training Loss: 0.0010109234135597944
Test Loss:  0.001107594114728272
Valid Loss:  0.0009282915270887315
Epoch:  338  	Training Loss: 0.0010107707930728793
Test Loss:  0.0011072185589000583
Valid Loss:  0.0009281567763537169
Epoch:  339  	Training Loss: 0.0010106180561706424
Test Loss:  0.0011068577878177166
Valid Loss:  0.0009280189406126738
Epoch:  340  	Training Loss: 0.0010104678804054856
Test Loss:  0.0011065169237554073
Valid Loss:  0.0009278811630792916
Epoch:  341  	Training Loss: 0.0010103181703016162
Test Loss:  0.0011061845580115914
Valid Loss:  0.0009277478675357997
Epoch:  342  	Training Loss: 0.0010101685766130686
Test Loss:  0.0011066917795687914
Valid Loss:  0.0009274983895011246
Epoch:  343  	Training Loss: 0.0010100181680172682
Test Loss:  0.0011066403239965439
Valid Loss:  0.000927340763155371
Epoch:  344  	Training Loss: 0.0010099182836711407
Test Loss:   69%|██████▉   | 345/500 [04:24<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:24<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:24<00:51,  2.92it/s] 70%|███████   | 351/500 [04:30<02:58,  1.20s/it] 71%|███████   | 353/500 [04:30<02:06,  1.16it/s] 71%|███████   | 355/500 [04:30<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:31<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:31<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:37<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:37<01:57,  1.16it/s] 73%|███████▎  | 365/500 [04:37<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:38<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:38<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:44<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:44<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:44<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:44<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:45<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:51<02:25,  1.23s/it] 77%|███████▋  | 383/500 [04:51<01:42,  1.14it/s] 77%|███████▋  | 385/500 [04:51<01:13,  1.57it/s] 77%|███████▋  | 387/500 [04:52<00:52,  2.15it/s] 78%|███████▊  | 389/500 [04:52<00:38,  2.90it/s] 78%|███████▊  | 391/500 [04:58<02:11,  1.21s/it] 79%|███████▊  | 393/500 [04:58<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:58<01:05,  1.59it/s] 79%|███████▉  | 397/500 [04:59<00:47,  2.18it/s] 80%|███████▉  | 399/500 [04:59<00:34,  2.93it/s] 80%|████████  | 401/500 [05:05<01:58,  1.19s/it] 81%|████████  | 403/500 [05:05<01:22,  1.17it/s] 81%|████████  | 405/500 [05:05<00:58,  1.62it/s] 81%|████████▏ | 407/500 [05:05<00:42,  2.20it/s] 82%|████████▏ | 409/500 [05:06<00:31,  2.92it/s] 82%|████████▏ | 411/500 [05:12<01:45,  1.18s/it]0.0011063036508858204
Valid Loss:  0.0009272292372770607
Epoch:  345  	Training Loss: 0.0010098357452079654
Test Loss:  0.00110581424087286
Valid Loss:  0.0009271417511627078
Epoch:  346  	Training Loss: 0.0010097621707245708
Test Loss:  0.001105263363569975
Valid Loss:  0.0009270609589293599
Epoch:  347  	Training Loss: 0.0010096938349306583
Test Loss:  0.001104686874896288
Valid Loss:  0.0009269849397242069
Epoch:  348  	Training Loss: 0.0010096306214109063
Test Loss:  0.0011041169054806232
Valid Loss:  0.0009269216097891331
Epoch:  349  	Training Loss: 0.0010095688048750162
Test Loss:  0.0011035559000447392
Valid Loss:  0.0009268609574064612
Epoch:  350  	Training Loss: 0.0010095126926898956
Test Loss:  0.001103017944842577
Valid Loss:  0.0009268044377677143
Epoch:  351  	Training Loss: 0.001009457977488637
Test Loss:  0.0011024954728782177
Valid Loss:  0.0009267510031349957
Epoch:  352  	Training Loss: 0.001009405474178493
Test Loss:  0.0011022097896784544
Valid Loss:  0.0009248506976291537
Epoch:  353  	Training Loss: 0.0010076516773551702
Test Loss:  0.0011018699733540416
Valid Loss:  0.00092298723757267
Epoch:  354  	Training Loss: 0.001005927799269557
Test Loss:  0.0011015156051144004
Valid Loss:  0.0009211478754878044
Epoch:  355  	Training Loss: 0.0010042344219982624
Test Loss:  0.0011011509923264384
Valid Loss:  0.0009193446603603661
Epoch:  356  	Training Loss: 0.001002572476863861
Test Loss:  0.001100784633308649
Valid Loss:  0.0009175677550956607
Epoch:  357  	Training Loss: 0.0010009370744228363
Test Loss:  0.001100417459383607
Valid Loss:  0.0009158211178146303
Epoch:  358  	Training Loss: 0.0009993298444896936
Test Loss:  0.0011000444646924734
Valid Loss:  0.0009141023037955165
Epoch:  359  	Training Loss: 0.000997750903479755
Test Loss:  0.001099680084735155
Valid Loss:  0.0009124067728407681
Epoch:  360  	Training Loss: 0.000996201648376882
Test Loss:  0.001099312212318182
Valid Loss:  0.0009107442456297576
Epoch:  361  	Training Loss: 0.000994677422568202
Test Loss:  0.0010989431757479906
Valid Loss:  0.0009091072715818882
Epoch:  362  	Training Loss: 0.0009931799722835422
Test Loss:  0.0010981811210513115
Valid Loss:  0.0009074328700080514
Epoch:  363  	Training Loss: 0.000991625478491187
Test Loss:  0.0010975641198456287
Valid Loss:  0.0009057768620550632
Epoch:  364  	Training Loss: 0.0009901002049446106
Test Loss:  0.001097011612728238
Valid Loss:  0.0009041459998115897
Epoch:  365  	Training Loss: 0.0009885989129543304
Test Loss:  0.0010964960092678666
Valid Loss:  0.0009025336476042867
Epoch:  366  	Training Loss: 0.0009871366200968623
Test Loss:  0.0010959934443235397
Valid Loss:  0.0009009930654428899
Epoch:  367  	Training Loss: 0.0009857661789283156
Test Loss:  0.0010954912286251783
Valid Loss:  0.0008994768722914159
Epoch:  368  	Training Loss: 0.0009844166925176978
Test Loss:  0.0010949972784146667
Valid Loss:  0.0008979781996458769
Epoch:  369  	Training Loss: 0.000983086647465825
Test Loss:  0.0010945081012323499
Valid Loss:  0.0008965040906332433
Epoch:  370  	Training Loss: 0.0009817765094339848
Test Loss:  0.0010940285865217447
Valid Loss:  0.0008950508781708777
Epoch:  371  	Training Loss: 0.0009804855799302459
Test Loss:  0.0010935540776699781
Valid Loss:  0.0008936143713071942
Epoch:  372  	Training Loss: 0.0009792139753699303
Test Loss:  0.0010926868999376893
Valid Loss:  0.0008914073114283383
Epoch:  373  	Training Loss: 0.0009768502786755562
Test Loss:  0.0010918612824752927
Valid Loss:  0.00088923005387187
Epoch:  374  	Training Loss: 0.0009744618437252939
Test Loss:  0.0010910353157669306
Valid Loss:  0.0008870183955878019
Epoch:  375  	Training Loss: 0.0009720227099023759
Test Loss:  0.0010902375215664506
Valid Loss:  0.0008848291472531855
Epoch:  376  	Training Loss: 0.0009696150082163513
Test Loss:  0.0010894692968577147
Valid Loss:  0.0008826704579405487
Epoch:  377  	Training Loss: 0.0009672384476289153
Test Loss:  0.0010887195821851492
Valid Loss:  0.0008805390098132193
Epoch:  378  	Training Loss: 0.000964893086347729
Test Loss:  0.0010879868641495705
Valid Loss:  0.000878437771461904
Epoch:  379  	Training Loss: 0.0009625783422961831
Test Loss:  0.0010872698621824384
Valid Loss:  0.0008763635996729136
Epoch:  380  	Training Loss: 0.0009602931095287204
Test Loss:  0.0010865696240216494
Valid Loss:  0.0008743141079321504
Epoch:  381  	Training Loss: 0.0009580391924828291
Test Loss:  0.0010858874302357435
Valid Loss:  0.0008722915663383901
Epoch:  382  	Training Loss: 0.0009558121673762798
Test Loss:  0.001085180789232254
Valid Loss:  0.0008722219499759376
Epoch:  383  	Training Loss: 0.0009557406301610172
Test Loss:  0.0010844649514183402
Valid Loss:  0.0008721579797565937
Epoch:  384  	Training Loss: 0.0009556768927723169
Test Loss:  0.001083762152120471
Valid Loss:  0.0008721037302166224
Epoch:  385  	Training Loss: 0.000955616997089237
Test Loss:  0.0010830853134393692
Valid Loss:  0.0008720524492673576
Epoch:  386  	Training Loss: 0.0009555618744343519
Test Loss:  0.0010824331548064947
Valid Loss:  0.0008720034384168684
Epoch:  387  	Training Loss: 0.0009555129799991846
Test Loss:  0.001081810682080686
Valid Loss:  0.0008719632169231772
Epoch:  388  	Training Loss: 0.0009554661228321493
Test Loss:  0.001081215450540185
Valid Loss:  0.0008719235192984343
Epoch:  389  	Training Loss: 0.0009554247371852398
Test Loss:  0.0010806516511365771
Valid Loss:  0.0008718905737623572
Epoch:  390  	Training Loss: 0.0009553873096592724
Test Loss:  0.0010801061289384961
Valid Loss:  0.0008718554163351655
Epoch:  391  	Training Loss: 0.0009553508716635406
Test Loss:  0.0010795907583087683
Valid Loss:  0.0008718282915651798
Epoch:  392  	Training Loss: 0.000955316936597228
Test Loss:  0.0010789254447445273
Valid Loss:  0.0008718057069927454
Epoch:  393  	Training Loss: 0.000955288705881685
Test Loss:  0.0010783576872199774
Valid Loss:  0.0008717871969565749
Epoch:  394  	Training Loss: 0.0009552622796036303
Test Loss:  0.0010778593132272363
Valid Loss:  0.0008717664750292897
Epoch:  395  	Training Loss: 0.0009552389965392649
Test Loss:  0.0010774156544357538
Valid Loss:  0.000871750176884234
Epoch:  396  	Training Loss: 0.0009552176343277097
Test Loss:  0.0010770100634545088
Valid Loss:  0.0008717304444871843
Epoch:  397  	Training Loss: 0.0009551983675919473
Test Loss:  0.001076634624041617
Valid Loss:  0.0008717126911506057
Epoch:  398  	Training Loss: 0.0009551786351948977
Test Loss:  0.001076276646926999
Valid Loss:  0.0008716993615962565
Epoch:  399  	Training Loss: 0.0009551627445034683
Test Loss:  0.0010759509168565273
Valid Loss:  0.0008716830052435398
Epoch:  400  	Training Loss: 0.0009551469702273607
Test Loss:  0.0010756360134109855
Valid Loss:  0.0008716704323887825
Epoch:  401  	Training Loss: 0.0009551342227496207
Test Loss:  0.0010753350798040628
Valid Loss:  0.0008716583834029734
Epoch:  402  	Training Loss: 0.0009551194962114096
Test Loss:  0.001075239502824843
Valid Loss:  0.0008715080330148339
Epoch:  403  	Training Loss: 0.0009549726382829249
Test Loss:  0.001074993284419179
Valid Loss:  0.0008713697316125035
Epoch:  404  	Training Loss: 0.0009548286907374859
Test Loss:  0.0010746876941993833
Valid Loss:  0.0008712373673915863
Epoch:  405  	Training Loss: 0.0009546861401759088
Test Loss:  0.0010743520688265562
Valid Loss:  0.0008711062255315483
Epoch:  406  	Training Loss: 0.0009545464999973774
Test Loss:  0.0010740121360868216
Valid Loss:  0.0008709782268851995
Epoch:  407  	Training Loss: 0.0009544071508571506
Test Loss:  0.00107366475276649
Valid Loss:  0.0008708533714525402
Epoch:  408  	Training Loss: 0.0009542681509628892
Test Loss:  0.0010733262170106173
Valid Loss:  0.0008707307279109955
Epoch:  409  	Training Loss: 0.0009541296749375761
Test Loss:  0.001072995364665985
Valid Loss:  0.0008706033113412559
Epoch:  410  	Training Loss: 0.0009539906168356538
Test Loss:  0.0010726680047810078
Valid Loss:  0.0008704826468601823
Epoch:  411  	Training Loss: 0.0009538531303405762
Test Loss:  0.001072346931323409
Valid Loss:  0.0008703586063347757
Epoch:  412  	Training Loss: 0.0009537159348838031
Test Loss:  0.0010696121025830507
Valid Loss:  0.0008684085914865136
 83%|████████▎ | 413/500 [05:12<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:12<00:52,  1.63it/s] 83%|████████▎ | 417/500 [05:12<00:37,  2.23it/s] 84%|████████▍ | 419/500 [05:12<00:27,  3.00it/s] 84%|████████▍ | 421/500 [05:19<01:35,  1.21s/it] 85%|████████▍ | 423/500 [05:19<01:06,  1.15it/s] 85%|████████▌ | 425/500 [05:19<00:46,  1.60it/s] 85%|████████▌ | 427/500 [05:19<00:33,  2.18it/s] 86%|████████▌ | 429/500 [05:19<00:24,  2.94it/s] 86%|████████▌ | 431/500 [05:26<01:24,  1.22s/it] 87%|████████▋ | 433/500 [05:26<00:58,  1.14it/s] 87%|████████▋ | 435/500 [05:26<00:41,  1.58it/s] 87%|████████▋ | 437/500 [05:26<00:29,  2.16it/s] 88%|████████▊ | 439/500 [05:27<00:20,  2.91it/s] 88%|████████▊ | 441/500 [05:33<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:33<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:33<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:33<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:34<00:17,  2.95it/s] 90%|█████████ | 451/500 [05:40<01:00,  1.23s/it] 91%|█████████ | 453/500 [05:40<00:41,  1.13it/s] 91%|█████████ | 455/500 [05:40<00:28,  1.57it/s] 91%|█████████▏| 457/500 [05:41<00:20,  2.14it/s] 92%|█████████▏| 459/500 [05:41<00:14,  2.88it/s] 92%|█████████▏| 461/500 [05:47<00:47,  1.22s/it] 93%|█████████▎| 463/500 [05:47<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:47<00:22,  1.59it/s] 93%|█████████▎| 467/500 [05:48<00:15,  2.17it/s] 94%|█████████▍| 469/500 [05:48<00:10,  2.92it/s] 94%|█████████▍| 471/500 [05:54<00:35,  1.23s/it] 95%|█████████▍| 473/500 [05:54<00:23,  1.14it/s] 95%|█████████▌| 475/500 [05:55<00:15,  1.58it/s] 95%|█████████▌| 477/500 [05:55<00:10,  2.16it/s] 96%|█████████▌| 479/500 [05:55<00:07,  2.90it/s]Epoch:  413  	Training Loss: 0.0009507461218163371
Test Loss:  0.0010681585408747196
Valid Loss:  0.0008671031682752073
Epoch:  414  	Training Loss: 0.000948597036767751
Test Loss:  0.0010672662174329162
Valid Loss:  0.0008659262675791979
Epoch:  415  	Training Loss: 0.0009470056393183768
Test Loss:  0.0010667683091014624
Valid Loss:  0.0008649781229905784
Epoch:  416  	Training Loss: 0.000945914420299232
Test Loss:  0.0010664183646440506
Valid Loss:  0.0008641424356028438
Epoch:  417  	Training Loss: 0.0009450200013816357
Test Loss:  0.0010661182459443808
Valid Loss:  0.0008634113473817706
Epoch:  418  	Training Loss: 0.0009442867012694478
Test Loss:  0.0010657727252691984
Valid Loss:  0.0008628626819700003
Epoch:  419  	Training Loss: 0.0009437025291845202
Test Loss:  0.0010653359349817038
Valid Loss:  0.0008623789181001484
Epoch:  420  	Training Loss: 0.0009431762155145407
Test Loss:  0.0010648404713720083
Valid Loss:  0.0008619981235824525
Epoch:  421  	Training Loss: 0.0009427029872313142
Test Loss:  0.0010642859851941466
Valid Loss:  0.0008616507984697819
Epoch:  422  	Training Loss: 0.0009422313305549324
Test Loss:  0.001063574105501175
Valid Loss:  0.0008592410013079643
Epoch:  423  	Training Loss: 0.0009401122806593776
Test Loss:  0.0010628318414092064
Valid Loss:  0.0008566913893446326
Epoch:  424  	Training Loss: 0.0009377866517752409
Test Loss:  0.0010621174005791545
Valid Loss:  0.0008540537673979998
Epoch:  425  	Training Loss: 0.0009355313377454877
Test Loss:  0.0010614210041239858
Valid Loss:  0.0008511480409651995
Epoch:  426  	Training Loss: 0.0009333478519693017
Test Loss:  0.001060750219039619
Valid Loss:  0.0008480901014991105
Epoch:  427  	Training Loss: 0.000931232760194689
Test Loss:  0.0010601045796647668
Valid Loss:  0.0008451213361695409
Epoch:  428  	Training Loss: 0.0009291821625083685
Test Loss:  0.001059478148818016
Valid Loss:  0.0008422461687587202
Epoch:  429  	Training Loss: 0.000927192042581737
Test Loss:  0.001058872789144516
Valid Loss:  0.000839455402456224
Epoch:  430  	Training Loss: 0.0009252633899450302
Test Loss:  0.0010582845425233245
Valid Loss:  0.000836745894048363
Epoch:  431  	Training Loss: 0.0009233921300619841
Test Loss:  0.0010577118955552578
Valid Loss:  0.0008341193897649646
Epoch:  432  	Training Loss: 0.0009215190075337887
Test Loss:  0.001058063586242497
Valid Loss:  0.000831651734188199
Epoch:  433  	Training Loss: 0.0009189731208607554
Test Loss:  0.0010578169021755457
Valid Loss:  0.0008293763385154307
Epoch:  434  	Training Loss: 0.0009165019728243351
Test Loss:  0.0010571816237643361
Valid Loss:  0.0008272079285234213
Epoch:  435  	Training Loss: 0.0009141055634245276
Test Loss:  0.0010562906973063946
Valid Loss:  0.0008251098915934563
Epoch:  436  	Training Loss: 0.0009117531590163708
Test Loss:  0.0010552421445026994
Valid Loss:  0.0008231059182435274
Epoch:  437  	Training Loss: 0.0009094595443457365
Test Loss:  0.001054087420925498
Valid Loss:  0.0008211479289457202
Epoch:  438  	Training Loss: 0.0009071913082152605
Test Loss:  0.0010528709972277284
Valid Loss:  0.0008192188106477261
Epoch:  439  	Training Loss: 0.0009049513610079885
Test Loss:  0.001051622093655169
Valid Loss:  0.0008173275273293257
Epoch:  440  	Training Loss: 0.0009027557680383325
Test Loss:  0.0010503509547561407
Valid Loss:  0.0008154538227245212
Epoch:  441  	Training Loss: 0.0009005838073790073
Test Loss:  0.0010490670101717114
Valid Loss:  0.0008136058459058404
Epoch:  442  	Training Loss: 0.000898430123925209
Test Loss:  0.0010470312554389238
Valid Loss:  0.0008133573574014008
Epoch:  443  	Training Loss: 0.0008981542196124792
Test Loss:  0.0010453442810103297
Valid Loss:  0.0008131316280923784
Epoch:  444  	Training Loss: 0.0008979032281786203
Test Loss:  0.0010439077159389853
Valid Loss:  0.0008129135239869356
Epoch:  445  	Training Loss: 0.0008976683602668345
Test Loss:  0.0010426529916003346
Valid Loss:  0.0008127084001898766
Epoch:  446  	Training Loss: 0.0008974499069154263
Test Loss:  0.001041544834151864
Valid Loss:  0.0008125073509290814
Epoch:  447  	Training Loss: 0.000897239544428885
Test Loss:  0.0010405427310615778
Valid Loss:  0.0008123136940412223
Epoch:  448  	Training Loss: 0.0008970388444140553
Test Loss:  0.0010396288707852364
Valid Loss:  0.0008121248101815581
Epoch:  449  	Training Loss: 0.00089684734120965
Test Loss:  0.0010387790389358997
Valid Loss:  0.0008119404665194452
Epoch:  450  	Training Loss: 0.0008966646273620427
Test Loss:  0.0010379867162555456
Valid Loss:  0.0008117705583572388
Epoch:  451  	Training Loss: 0.0008964871522039175
Test Loss:  0.0010372344404459
Valid Loss:  0.0008115989621728659
Epoch:  452  	Training Loss: 0.0008963168365880847
Test Loss:  0.0010369939263910055
Valid Loss:  0.0008114611264318228
Epoch:  453  	Training Loss: 0.000896188139449805
Test Loss:  0.0010367045179009438
Valid Loss:  0.0008113307412713766
Epoch:  454  	Training Loss: 0.0008960635750554502
Test Loss:  0.0010363792534917593
Valid Loss:  0.0008112048963084817
Epoch:  455  	Training Loss: 0.000895941280759871
Test Loss:  0.001036022906191647
Valid Loss:  0.0008110825438052416
Epoch:  456  	Training Loss: 0.0008958216058090329
Test Loss:  0.0010356528218835592
Valid Loss:  0.0008109654299914837
Epoch:  457  	Training Loss: 0.0008957061218097806
Test Loss:  0.0010352721437811852
Valid Loss:  0.0008108514011837542
Epoch:  458  	Training Loss: 0.0008955927914939821
Test Loss:  0.0010348844807595015
Valid Loss:  0.0008107406320050359
Epoch:  459  	Training Loss: 0.0008954784134402871
Test Loss:  0.0010344955371692777
Valid Loss:  0.0008106317836791277
Epoch:  460  	Training Loss: 0.0008953678188845515
Test Loss:  0.0010341049637645483
Valid Loss:  0.0008105251472443342
Epoch:  461  	Training Loss: 0.0008952628704719245
Test Loss:  0.0010337219573557377
Valid Loss:  0.0008104194421321154
Epoch:  462  	Training Loss: 0.000895156292244792
Test Loss:  0.0010332483798265457
Valid Loss:  0.0008103803847916424
Epoch:  463  	Training Loss: 0.0008951196214184165
Test Loss:  0.0010327911004424095
Valid Loss:  0.0008103447617031634
Epoch:  464  	Training Loss: 0.0008950893534347415
Test Loss:  0.0010323654860258102
Valid Loss:  0.0008103117579594254
Epoch:  465  	Training Loss: 0.0008950584451667964
Test Loss:  0.0010319576831534505
Valid Loss:  0.0008102812571451068
Epoch:  466  	Training Loss: 0.0008950323099270463
Test Loss:  0.001031568506732583
Valid Loss:  0.0008102499414235353
Epoch:  467  	Training Loss: 0.0008950053597800434
Test Loss:  0.0010311994701623917
Valid Loss:  0.0008102231076918542
Epoch:  468  	Training Loss: 0.0008949828916229308
Test Loss:  0.0010308453347533941
Valid Loss:  0.0008101960411295295
Epoch:  469  	Training Loss: 0.0008949607145041227
Test Loss:  0.0010305012110620737
Valid Loss:  0.000810173456557095
Epoch:  470  	Training Loss: 0.0008949396433308721
Test Loss:  0.001030181534588337
Valid Loss:  0.0008101538987830281
Epoch:  471  	Training Loss: 0.0008949210750870407
Test Loss:  0.0010298698907718062
Valid Loss:  0.0008101331768557429
Epoch:  472  	Training Loss: 0.0008949043112806976
Test Loss:  0.0010297908447682858
Valid Loss:  0.0008100780542008579
Epoch:  473  	Training Loss: 0.0008948588510975242
Test Loss:  0.0010295597603544593
Valid Loss:  0.0008100333507172763
Epoch:  474  	Training Loss: 0.0008948175236582756
Test Loss:  0.0010292676743119955
Valid Loss:  0.0008099901024252176
Epoch:  475  	Training Loss: 0.0008947784663178027
Test Loss:  0.0010289569618180394
Valid Loss:  0.0008099546539597213
Epoch:  476  	Training Loss: 0.0008947398164309561
Test Loss:  0.001028648461215198
Valid Loss:  0.0008099159458652139
Epoch:  477  	Training Loss: 0.0008947013411670923
Test Loss:  0.0010283489245921373
Valid Loss:  0.0008098853868432343
Epoch:  478  	Training Loss: 0.0008946647867560387
Test Loss:  0.0010280600981786847
Valid Loss:  0.0008098497637547553
Epoch:  479  	Training Loss: 0.0008946294547058642
Test Loss:  0.0010277782566845417
Valid Loss:  0.0008098195539787412
Epoch:  480  	Training Loss: 0.0008945965673774481
Test Loss:  0.0010275118984282017
Valid Loss:  0.0008097902755253017
Epoch:  481  	Training Loss: 0.0008945621084421873
Test Loss:  96%|█████████▌| 481/500 [06:01<00:23,  1.22s/it] 97%|█████████▋| 483/500 [06:02<00:14,  1.14it/s] 97%|█████████▋| 485/500 [06:02<00:09,  1.58it/s] 97%|█████████▋| 487/500 [06:02<00:06,  2.16it/s] 98%|█████████▊| 489/500 [06:02<00:03,  2.91it/s] 98%|█████████▊| 491/500 [06:08<00:10,  1.22s/it] 99%|█████████▊| 493/500 [06:09<00:06,  1.14it/s] 99%|█████████▉| 495/500 [06:09<00:03,  1.58it/s] 99%|█████████▉| 497/500 [06:09<00:01,  2.17it/s]100%|█████████▉| 499/500 [06:09<00:00,  2.92it/s]100%|██████████| 500/500 [06:09<00:00,  1.35it/s]
 0.0010272518265992403
Valid Loss:  0.0008097582031041384
Epoch:  482  	Training Loss: 0.0008945284062065184
Test Loss:  0.0010268483310937881
Valid Loss:  0.0008096614619717002
Epoch:  483  	Training Loss: 0.0008944171131588519
Test Loss:  0.0010264882585033774
Valid Loss:  0.0008095619850791991
Epoch:  484  	Training Loss: 0.0008943062275648117
Test Loss:  0.0010261526331305504
Valid Loss:  0.0008094653603620827
Epoch:  485  	Training Loss: 0.0008941967389546335
Test Loss:  0.001025833422318101
Valid Loss:  0.0008093749056570232
Epoch:  486  	Training Loss: 0.000894087424967438
Test Loss:  0.0010255351662635803
Valid Loss:  0.0008092811913229525
Epoch:  487  	Training Loss: 0.0008939794497564435
Test Loss:  0.0010252483189105988
Valid Loss:  0.0008091953350231051
Epoch:  488  	Training Loss: 0.0008938699029386044
Test Loss:  0.0010249672923237085
Valid Loss:  0.0008091058116406202
Epoch:  489  	Training Loss: 0.00089376384858042
Test Loss:  0.00102469720877707
Valid Loss:  0.0008090221090242267
Epoch:  490  	Training Loss: 0.0008936595404520631
Test Loss:  0.0010244396980851889
Valid Loss:  0.0008089417824521661
Epoch:  491  	Training Loss: 0.0008935532532632351
Test Loss:  0.001024184050038457
Valid Loss:  0.0008088538888841867
Epoch:  492  	Training Loss: 0.000893449760042131
Test Loss:  0.0010241677518934011
Valid Loss:  0.0008077595848590136
Epoch:  493  	Training Loss: 0.0008924823487177491
Test Loss:  0.001024162513203919
Valid Loss:  0.0008066822774708271
Epoch:  494  	Training Loss: 0.0008915323996916413
Test Loss:  0.0010241647250950336
Valid Loss:  0.0008056224905885756
Epoch:  495  	Training Loss: 0.0008905939175747335
Test Loss:  0.001024175202473998
Valid Loss:  0.0008045732975006104
Epoch:  496  	Training Loss: 0.0008896755171008408
Test Loss:  0.0010241896379739046
Valid Loss:  0.000803539645858109
Epoch:  497  	Training Loss: 0.0008887709118425846
Test Loss:  0.0010242064017802477
Valid Loss:  0.0008025264251045883
Epoch:  498  	Training Loss: 0.000887879345100373
Test Loss:  0.0010242268908768892
Valid Loss:  0.0008015251951292157
Epoch:  499  	Training Loss: 0.0008870032615959644
Test Loss:  0.0010242476128041744
Valid Loss:  0.0008005383424460888
Epoch:  500  	Training Loss: 0.000886139867361635
Test Loss:  0.0010242767166346312
Valid Loss:  0.0007995693013072014
