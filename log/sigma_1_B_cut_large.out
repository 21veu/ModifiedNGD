/home/yuyi/Documents/ModifiedNGD/utils/readData.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/home/yuyi/anaconda3/envs/ng/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/autograd/engine.cpp:1151.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
train data shape torch.Size([256, 2])
train label shape torch.Size([256, 1])
torch.Size([256, 3])
train_data shape torch.Size([3])
seed is  1
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:08,  6.15s/it]  1%|          | 3/500 [00:06<13:37,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:12,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:40,  1.31s/it]  3%|▎         | 13/500 [00:13<07:16,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:26,  1.18s/it]  5%|▍         | 23/500 [00:19<06:42,  1.19it/s]  5%|▌         | 25/500 [00:19<04:48,  1.65it/s]  5%|▌         | 27/500 [00:20<03:29,  2.26it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:06,  1.16s/it]  7%|▋         | 33/500 [00:26<06:30,  1.20it/s]  7%|▋         | 35/500 [00:26<04:40,  1.66it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:26<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:52,  1.16s/it]  9%|▊         | 43/500 [00:33<06:20,  1.20it/s]  9%|▉         | 45/500 [00:33<04:33,  1.66it/s]  9%|▉         | 47/500 [00:33<03:19,  2.27it/s] 10%|▉         | 49/500 [00:33<02:28,  3.05it/s] 10%|█         | 51/500 [00:39<08:36,  1.15s/it] 11%|█         | 53/500 [00:39<06:09,  1.21it/s] 11%|█         | 55/500 [00:40<04:26,  1.67it/s] 11%|█▏        | 57/500 [00:40<03:14,  2.28it/s] 12%|█▏        | 59/500 [00:40<02:24,  3.06it/s] 12%|█▏        | 61/500 [00:52<15:21,  2.10s/it] 13%|█▎        | 63/500 [00:52<10:51,  1.49s/it] 13%|█▎        | 65/500 [00:53<07:42,  1.06s/it] 13%|█▎        | 67/500 [00:53<05:30,  1.31it/s] 14%|█▍        | 69/500 [00:53<03:58,  1.81it/s]Epoch:  1  	Training Loss: 0.030495241284370422
Test Loss:  0.11968487501144409
Valid Loss:  0.09850607812404633
Epoch:  2  	Training Loss: 0.09286364912986755
Test Loss:  0.010632270015776157
Valid Loss:  0.018407855182886124
Epoch:  3  	Training Loss: 0.031051747500896454
Test Loss:  0.015083396807312965
Valid Loss:  0.02255372144281864
Epoch:  4  	Training Loss: 0.030769627541303635
Test Loss:  0.012978281825780869
Valid Loss:  0.020248152315616608
Epoch:  5  	Training Loss: 0.029602423310279846
Test Loss:  0.012003395706415176
Valid Loss:  0.01894458569586277
Epoch:  6  	Training Loss: 0.02838856726884842
Test Loss:  0.01071807462722063
Valid Loss:  0.0176263228058815
Epoch:  7  	Training Loss: 0.02766440249979496
Test Loss:  0.010344985872507095
Valid Loss:  0.017116857692599297
Epoch:  8  	Training Loss: 0.02712251991033554
Test Loss:  0.009689489379525185
Valid Loss:  0.016320232301950455
Epoch:  9  	Training Loss: 0.02681116573512554
Test Loss:  0.009576275944709778
Valid Loss:  0.016209619119763374
Epoch:  10  	Training Loss: 0.026582226157188416
Test Loss:  0.009136201813817024
Valid Loss:  0.015711456537246704
Epoch:  11  	Training Loss: 0.026367196813225746
Test Loss:  0.008967379108071327
Valid Loss:  0.01548838336020708
Epoch:  12  	Training Loss: 0.02621258981525898
Test Loss:  0.008737113326787949
Valid Loss:  0.015287782065570354
Epoch:  13  	Training Loss: 0.026058664545416832
Test Loss:  0.008495159447193146
Valid Loss:  0.015147428028285503
Epoch:  14  	Training Loss: 0.025942223146557808
Test Loss:  0.008294937200844288
Valid Loss:  0.015068842098116875
Epoch:  15  	Training Loss: 0.02585471421480179
Test Loss:  0.00808610487729311
Valid Loss:  0.015006650239229202
Epoch:  16  	Training Loss: 0.025762107223272324
Test Loss:  0.007933534681797028
Valid Loss:  0.014976000413298607
Epoch:  17  	Training Loss: 0.025690652430057526
Test Loss:  0.007854113355278969
Valid Loss:  0.014945117756724358
Epoch:  18  	Training Loss: 0.02564229629933834
Test Loss:  0.007804458029568195
Valid Loss:  0.014922079630196095
Epoch:  19  	Training Loss: 0.025613386183977127
Test Loss:  0.007774546276777983
Valid Loss:  0.014898039400577545
Epoch:  20  	Training Loss: 0.02559194713830948
Test Loss:  0.007762976922094822
Valid Loss:  0.01487267017364502
Epoch:  21  	Training Loss: 0.025576714426279068
Test Loss:  0.007742605172097683
Valid Loss:  0.014859478920698166
Epoch:  22  	Training Loss: 0.02556677907705307
Test Loss:  0.007741647306829691
Valid Loss:  0.01484309695661068
Epoch:  23  	Training Loss: 0.02556057646870613
Test Loss:  0.007731293328106403
Valid Loss:  0.014836279675364494
Epoch:  24  	Training Loss: 0.02555566281080246
Test Loss:  0.007731322199106216
Valid Loss:  0.014824793674051762
Epoch:  25  	Training Loss: 0.02555152401328087
Test Loss:  0.007726396434009075
Valid Loss:  0.014817800372838974
Epoch:  26  	Training Loss: 0.02554808184504509
Test Loss:  0.007725760340690613
Valid Loss:  0.014809972606599331
Epoch:  27  	Training Loss: 0.025545038282871246
Test Loss:  0.007720079272985458
Valid Loss:  0.014806108549237251
Epoch:  28  	Training Loss: 0.025542717427015305
Test Loss:  0.007731218822300434
Valid Loss:  0.01479500625282526
Epoch:  29  	Training Loss: 0.025540854781866074
Test Loss:  0.007717937231063843
Valid Loss:  0.014796404168009758
Epoch:  30  	Training Loss: 0.02553948014974594
Test Loss:  0.007735406048595905
Valid Loss:  0.01478509046137333
Epoch:  31  	Training Loss: 0.02553834207355976
Test Loss:  0.007716645020991564
Valid Loss:  0.014789046719670296
Epoch:  32  	Training Loss: 0.02553737908601761
Test Loss:  0.007734163664281368
Valid Loss:  0.01477920450270176
Epoch:  33  	Training Loss: 0.025536272674798965
Test Loss:  0.007720639929175377
Valid Loss:  0.014781253412365913
Epoch:  34  	Training Loss: 0.025535553693771362
Test Loss:  0.007733342237770557
Valid Loss:  0.014774780720472336
Epoch:  35  	Training Loss: 0.025534896180033684
Test Loss:  0.0077222008258104324
Valid Loss:  0.014776214025914669
Epoch:  36  	Training Loss: 0.025534477084875107
Test Loss:  0.007731090299785137
Valid Loss:  0.014771675691008568
Epoch:  37  	Training Loss: 0.025533977895975113
Test Loss:  0.007729186210781336
Valid Loss:  0.014770783483982086
Epoch:  38  	Training Loss: 0.02553369104862213
Test Loss:  0.007728718686848879
Valid Loss:  0.014769570901989937
Epoch:  39  	Training Loss: 0.025533437728881836
Test Loss:  0.007728089578449726
Valid Loss:  0.014768497087061405
Epoch:  40  	Training Loss: 0.02553320676088333
Test Loss:  0.007727522403001785
Valid Loss:  0.014767481945455074
Epoch:  41  	Training Loss: 0.025533000007271767
Test Loss:  0.007726994808763266
Valid Loss:  0.014766530133783817
Epoch:  42  	Training Loss: 0.025532811880111694
Test Loss:  0.0077264998108148575
Valid Loss:  0.014765641652047634
Epoch:  43  	Training Loss: 0.025532644242048264
Test Loss:  0.007726176641881466
Valid Loss:  0.014764806255698204
Epoch:  44  	Training Loss: 0.025532491505146027
Test Loss:  0.007725896313786507
Valid Loss:  0.014764020219445229
Epoch:  45  	Training Loss: 0.025532349944114685
Test Loss:  0.0077256388030946255
Valid Loss:  0.014763285405933857
Epoch:  46  	Training Loss: 0.025532227009534836
Test Loss:  0.007725398056209087
Valid Loss:  0.014762597158551216
Epoch:  47  	Training Loss: 0.025532115250825882
Test Loss:  0.0077251954935491085
Valid Loss:  0.01476194802671671
Epoch:  48  	Training Loss: 0.025532014667987823
Test Loss:  0.007725032977759838
Valid Loss:  0.014761339873075485
Epoch:  49  	Training Loss: 0.025531943887472153
Test Loss:  0.007729046978056431
Valid Loss:  0.014759885147213936
Epoch:  50  	Training Loss: 0.02553192526102066
Test Loss:  0.007724354509264231
Valid Loss:  0.014760556630790234
Epoch:  51  	Training Loss: 0.025531813502311707
Test Loss:  0.007728935219347477
Valid Loss:  0.014759018085896969
Epoch:  52  	Training Loss: 0.02553180605173111
Test Loss:  0.0077241710387170315
Valid Loss:  0.014759738929569721
Epoch:  53  	Training Loss: 0.02553170546889305
Test Loss:  0.007730289828032255
Valid Loss:  0.014757982455193996
Epoch:  54  	Training Loss: 0.025531761348247528
Test Loss:  0.007724655792117119
Valid Loss:  0.014758948236703873
Epoch:  55  	Training Loss: 0.02553165704011917
Test Loss:  0.007730958051979542
Valid Loss:  0.014757282100617886
Epoch:  56  	Training Loss: 0.025531720370054245
Test Loss:  0.007723680231720209
Valid Loss:  0.01475862879306078
Epoch:  57  	Training Loss: 0.02553170919418335
Test Loss:  0.007737223990261555
Valid Loss:  0.014755893498659134
Epoch:  58  	Training Loss: 0.02553202211856842
Test Loss:  0.007722980342805386
Valid Loss:  0.01475856825709343
Epoch:  59  	Training Loss: 0.025531789287924767
Test Loss:  0.007744499482214451
Valid Loss:  0.01475503109395504
Epoch:  60  	Training Loss: 0.025532586500048637
Test Loss:  0.007722320966422558
Valid Loss:  0.01475880853831768
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.025531888008117676
Test Loss:  0.007731241174042225
Valid Loss:  0.014756765216588974
Epoch:  62  	Training Loss: 0.025531692430377007
Test Loss:  0.007727385498583317
Valid Loss:  0.014757431112229824
Epoch:  63  	Training Loss: 0.025531599298119545
Test Loss:  0.007727600634098053
Valid Loss:  0.014757271856069565
Epoch:  64  	Training Loss: 0.02553156390786171
Test Loss:  0.007728249300271273
Valid Loss:  0.014757039956748486
Epoch:  65  	Training Loss: 0.02553156018257141
Test Loss:  0.007726786192506552
Valid Loss:  0.014757231809198856
Epoch:  66  	Training Loss: 0.02553156018257141
Test Loss:  0.007728636264801025
Valid Loss:  0.014756757766008377
Epoch:  67  	Training Loss: 0.025531549006700516
Test Loss:  0.007728666998445988
Valid Loss:  0.014756678603589535
Epoch:  68  	Training Loss: 0.025531545281410217
Test Loss:  0.0077269431203603745
Valid Loss:  0.014756934717297554
Epoch:  69  	Training Loss: 0.02553156390786171
Test Loss:  0.007730836048722267
Valid Loss:  0.014756133779883385
Epoch:  70  	Training Loss: 0.025531603023409843
Test Loss:  0.007727513555437326
Valid Loss:  0.0147567018866539
 14%|█▍        | 71/500 [01:05<16:02,  2.24s/it] 15%|█▍        | 73/500 [01:05<11:20,  1.59s/it] 15%|█▌        | 75/500 [01:05<08:02,  1.14s/it] 15%|█▌        | 77/500 [01:06<05:44,  1.23it/s] 16%|█▌        | 79/500 [01:06<04:08,  1.70it/s] 16%|█▌        | 81/500 [01:12<09:21,  1.34s/it] 17%|█▋        | 83/500 [01:12<06:39,  1.04it/s] 17%|█▋        | 85/500 [01:18<10:59,  1.59s/it] 17%|█▋        | 87/500 [01:18<07:48,  1.13s/it] 18%|█▊        | 89/500 [01:18<05:34,  1.23it/s] 18%|█▊        | 89/500 [01:30<05:34,  1.23it/s] 18%|█▊        | 91/500 [01:31<16:26,  2.41s/it] 19%|█▊        | 93/500 [01:31<11:36,  1.71s/it] 19%|█▉        | 95/500 [01:37<14:22,  2.13s/it] 19%|█▉        | 97/500 [01:37<10:09,  1.51s/it] 20%|█▉        | 99/500 [01:37<07:12,  1.08s/it] 20%|█▉        | 99/500 [01:50<07:12,  1.08s/it] 20%|██        | 101/500 [01:50<17:18,  2.60s/it] 21%|██        | 103/500 [01:50<12:11,  1.84s/it] 21%|██        | 105/500 [01:56<14:34,  2.21s/it] 21%|██▏       | 107/500 [01:56<10:17,  1.57s/it] 22%|██▏       | 109/500 [01:56<07:17,  1.12s/it] 22%|██▏       | 111/500 [02:08<16:57,  2.62s/it] 23%|██▎       | 113/500 [02:09<11:56,  1.85s/it] 23%|██▎       | 115/500 [02:15<14:12,  2.21s/it] 23%|██▎       | 117/500 [02:15<10:01,  1.57s/it] 24%|██▍       | 119/500 [02:15<07:06,  1.12s/it] 24%|██▍       | 121/500 [02:27<16:39,  2.64s/it] 25%|██▍       | 123/500 [02:28<11:44,  1.87s/it] 25%|██▌       | 125/500 [02:34<14:00,  2.24s/it] 25%|██▌       | 127/500 [02:34<09:52,  1.59s/it] 26%|██▌       | 129/500 [02:34<06:59,  1.13s/it]**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.025531545281410217
Test Loss:  0.007728219963610172
Valid Loss:  0.014756524935364723
Epoch:  72  	Training Loss: 0.025531534105539322
Test Loss:  0.007728727534413338
Valid Loss:  0.014756395481526852
Epoch:  73  	Training Loss: 0.025531530380249023
Test Loss:  0.007728888653218746
Valid Loss:  0.014756337739527225
Epoch:  74  	Training Loss: 0.025531526654958725
Test Loss:  0.007728150114417076
Valid Loss:  0.014756439253687859
Epoch:  75  	Training Loss: 0.025531534105539322
Test Loss:  0.007728675380349159
Valid Loss:  0.014756310731172562
Epoch:  76  	Training Loss: 0.025531526654958725
Test Loss:  0.007729055359959602
Valid Loss:  0.0147562175989151
Epoch:  77  	Training Loss: 0.025531524792313576
Test Loss:  0.007729325443506241
Valid Loss:  0.01475614309310913
Epoch:  78  	Training Loss: 0.025531522929668427
Test Loss:  0.00772931519895792
Valid Loss:  0.014756126329302788
Epoch:  79  	Training Loss: 0.025531522929668427
Test Loss:  0.007729513570666313
Valid Loss:  0.014756071381270885
Epoch:  80  	Training Loss: 0.025531519204378128
Test Loss:  0.007729652337729931
Valid Loss:  0.014756031334400177
Epoch:  81  	Training Loss: 0.025531522929668427
Test Loss:  0.0077286940068006516
Valid Loss:  0.014756182208657265
Epoch:  82  	Training Loss: 0.025531526654958725
Test Loss:  0.007729061879217625
Valid Loss:  0.014756090939044952
Epoch:  83  	Training Loss: 0.025531524792313576
Test Loss:  0.007728942669928074
Valid Loss:  0.014756090007722378
Epoch:  84  	Training Loss: 0.025531522929668427
Test Loss:  0.007729240693151951
Valid Loss:  0.014756015501916409
Epoch:  85  	Training Loss: 0.025531521067023277
Test Loss:  0.007729444187134504
Valid Loss:  0.014755960553884506
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.025531519204378128
Test Loss:  0.007729521952569485
Valid Loss:  0.014755940064787865
Epoch:  87  	Training Loss: 0.025531519204378128
Test Loss:  0.007729589007794857
Valid Loss:  0.014755920507013798
Epoch:  88  	Training Loss: 0.025531521067023277
Test Loss:  0.0077296472154557705
Valid Loss:  0.014755903743207455
Epoch:  89  	Training Loss: 0.025531519204378128
Test Loss:  0.007729696575552225
Valid Loss:  0.01475588884204626
Epoch:  90  	Training Loss: 0.025531519204378128
Test Loss:  0.00772973895072937
Valid Loss:  0.014755873940885067
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.025531521067023277
Test Loss:  0.007729757577180862
Valid Loss:  0.01475586835294962
Epoch:  92  	Training Loss: 0.025531519204378128
Test Loss:  0.007729722186923027
Valid Loss:  0.014755871146917343
Epoch:  93  	Training Loss: 0.025531519204378128
Test Loss:  0.007729742676019669
Valid Loss:  0.014755865558981895
Epoch:  94  	Training Loss: 0.025531519204378128
Test Loss:  0.007729759439826012
Valid Loss:  0.014755859971046448
Epoch:  95  	Training Loss: 0.025531521067023277
Test Loss:  0.007729775737971067
Valid Loss:  0.014755854383111
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.025531519204378128
Test Loss:  0.007729783654212952
Valid Loss:  0.014755850657820702
Epoch:  97  	Training Loss: 0.025531519204378128
Test Loss:  0.007729791104793549
Valid Loss:  0.014755848795175552
Epoch:  98  	Training Loss: 0.025531519204378128
Test Loss:  0.007729799021035433
Valid Loss:  0.014755845069885254
Epoch:  99  	Training Loss: 0.025531519204378128
Test Loss:  0.007729806005954742
Valid Loss:  0.014755843207240105
Epoch:  100  	Training Loss: 0.025531519204378128
Test Loss:  0.007729812059551477
Valid Loss:  0.01475584041327238
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.025531519204378128
Test Loss:  0.007729816250503063
Valid Loss:  0.014755839481949806
Epoch:  102  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298185788095
Valid Loss:  0.014755838550627232
Epoch:  103  	Training Loss: 0.025531519204378128
Test Loss:  0.007729820907115936
Valid Loss:  0.014755836687982082
Epoch:  104  	Training Loss: 0.025531519204378128
Test Loss:  0.007729824632406235
Valid Loss:  0.014755835756659508
Epoch:  105  	Training Loss: 0.025531519204378128
Test Loss:  0.007729827426373959
Valid Loss:  0.014755833894014359
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.025531519204378128
Test Loss:  0.007729829754680395
Valid Loss:  0.014755833894014359
Epoch:  107  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298302203416824
Valid Loss:  0.014755832962691784
Epoch:  108  	Training Loss: 0.025531519204378128
Test Loss:  0.007729833014309406
Valid Loss:  0.014755832962691784
Epoch:  109  	Training Loss: 0.025531519204378128
Test Loss:  0.007729833014309406
Valid Loss:  0.01475583203136921
Epoch:  110  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298348769545555
Valid Loss:  0.01475583203136921
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.025531519204378128
Test Loss:  0.00772983580827713
Valid Loss:  0.014755831100046635
Epoch:  112  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298362739384174
Valid Loss:  0.01475583016872406
Epoch:  113  	Training Loss: 0.025531519204378128
Test Loss:  0.007729837670922279
Valid Loss:  0.014755831100046635
Epoch:  114  	Training Loss: 0.025531519204378128
Test Loss:  0.007729838602244854
Valid Loss:  0.01475583016872406
Epoch:  115  	Training Loss: 0.025531519204378128
Test Loss:  0.007729838602244854
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.025531519204378128
Test Loss:  0.007729840464890003
Valid Loss:  0.014755829237401485
Epoch:  117  	Training Loss: 0.025531521067023277
Test Loss:  0.007729839533567429
Valid Loss:  0.01475583016872406
Epoch:  118  	Training Loss: 0.025531519204378128
Test Loss:  0.007729840464890003
Valid Loss:  0.01475583016872406
Epoch:  119  	Training Loss: 0.025531519204378128
Test Loss:  0.007729840464890003
Valid Loss:  0.01475583016872406
Epoch:  120  	Training Loss: 0.025531519204378128
Test Loss:  0.007729840464890003
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.025531519204378128
Test Loss:  0.007729840464890003
Valid Loss:  0.01475583016872406
Epoch:  122  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
Epoch:  123  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  124  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
Epoch:  125  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298409305512905
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  127  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298409305512905
Valid Loss:  0.014755829237401485
Epoch:  128  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  129  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  130  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
 26%|██▌       | 131/500 [02:46<16:09,  2.63s/it] 27%|██▋       | 133/500 [02:46<11:22,  1.86s/it] 27%|██▋       | 135/500 [02:53<13:34,  2.23s/it] 27%|██▋       | 137/500 [02:53<09:34,  1.58s/it] 28%|██▊       | 139/500 [02:53<06:47,  1.13s/it] 28%|██▊       | 141/500 [03:05<15:39,  2.62s/it] 29%|██▊       | 143/500 [03:05<11:01,  1.85s/it] 29%|██▉       | 145/500 [03:11<13:12,  2.23s/it] 29%|██▉       | 147/500 [03:12<09:19,  1.58s/it] 30%|██▉       | 149/500 [03:12<06:36,  1.13s/it] 30%|███       | 151/500 [03:24<15:09,  2.61s/it] 31%|███       | 153/500 [03:24<10:40,  1.85s/it] 31%|███       | 155/500 [03:30<12:44,  2.22s/it] 31%|███▏      | 157/500 [03:30<08:59,  1.57s/it] 32%|███▏      | 159/500 [03:30<06:22,  1.12s/it] 32%|███▏      | 161/500 [03:43<14:47,  2.62s/it] 33%|███▎      | 163/500 [03:43<10:24,  1.85s/it] 33%|███▎      | 165/500 [03:49<12:32,  2.25s/it] 33%|███▎      | 167/500 [03:49<08:50,  1.59s/it] 34%|███▍      | 169/500 [03:49<06:15,  1.13s/it] 34%|███▍      | 169/500 [04:00<06:15,  1.13s/it] 34%|███▍      | 171/500 [04:02<14:31,  2.65s/it] 35%|███▍      | 173/500 [04:02<10:13,  1.88s/it] 35%|███▌      | 175/500 [04:08<12:08,  2.24s/it] 35%|███▌      | 177/500 [04:08<08:34,  1.59s/it] 36%|███▌      | 179/500 [04:08<06:04,  1.14s/it] 36%|███▌      | 179/500 [04:20<06:04,  1.14s/it] 36%|███▌      | 181/500 [04:20<13:55,  2.62s/it] 37%|███▋      | 183/500 [04:21<09:47,  1.85s/it] 37%|███▋      | 185/500 [04:27<11:41,  2.23s/it] 37%|███▋      | 187/500 [04:27<08:14,  1.58s/it]**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  132  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  133  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  134  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  135  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  137  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  138  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  139  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  140  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  142  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  143  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
Epoch:  144  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  145  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  147  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  148  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  149  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  150  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  152  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  153  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
Epoch:  154  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  155  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  157  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  158  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  159  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  160  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  162  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  163  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  164  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  165  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  167  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  168  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  169  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  170  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  172  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  173  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  174  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  175  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  177  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  178  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  179  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  180  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  182  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  183  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  184  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  185  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  187  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  188  	Training Loss: 0.025531519204378128
Test Loss:   38%|███▊      | 189/500 [04:27<05:49,  1.13s/it] 38%|███▊      | 191/500 [04:39<13:30,  2.62s/it] 39%|███▊      | 193/500 [04:39<09:29,  1.86s/it] 39%|███▉      | 195/500 [04:46<11:16,  2.22s/it] 39%|███▉      | 197/500 [04:46<07:57,  1.58s/it] 40%|███▉      | 199/500 [04:46<05:37,  1.12s/it] 40%|████      | 201/500 [04:58<13:03,  2.62s/it] 41%|████      | 203/500 [04:58<09:11,  1.86s/it] 41%|████      | 205/500 [05:04<10:54,  2.22s/it] 41%|████▏     | 207/500 [05:05<07:40,  1.57s/it] 42%|████▏     | 209/500 [05:05<05:25,  1.12s/it] 42%|████▏     | 211/500 [05:17<12:43,  2.64s/it] 43%|████▎     | 213/500 [05:17<08:56,  1.87s/it] 43%|████▎     | 215/500 [05:23<10:38,  2.24s/it] 43%|████▎     | 217/500 [05:24<07:30,  1.59s/it] 44%|████▍     | 219/500 [05:24<05:18,  1.13s/it] 44%|████▍     | 221/500 [05:36<12:12,  2.63s/it] 45%|████▍     | 223/500 [05:36<08:34,  1.86s/it] 45%|████▌     | 225/500 [05:42<10:13,  2.23s/it] 45%|████▌     | 227/500 [05:42<07:12,  1.59s/it] 46%|████▌     | 229/500 [05:42<05:05,  1.13s/it] 46%|████▌     | 231/500 [05:55<11:47,  2.63s/it] 47%|████▋     | 233/500 [05:55<08:17,  1.86s/it] 47%|████▋     | 235/500 [06:01<09:50,  2.23s/it] 47%|████▋     | 237/500 [06:01<06:55,  1.58s/it] 48%|████▊     | 239/500 [06:01<04:53,  1.13s/it] 48%|████▊     | 241/500 [06:14<11:19,  2.62s/it] 49%|████▊     | 243/500 [06:14<07:57,  1.86s/it] 49%|████▉     | 245/500 [06:20<09:26,  2.22s/it]0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  189  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  190  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  192  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  193  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  194  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  195  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  197  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  198  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  199  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  200  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  202  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  203  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  204  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  205  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  207  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  208  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  209  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  210  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  212  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  213  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  214  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  215  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  217  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  218  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  219  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  220  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  222  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  223  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  224  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  225  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  227  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  228  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  229  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  230  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  232  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  233  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  234  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  235  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  237  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  238  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  239  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  240  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  242  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  243  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  244  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  245  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
 49%|████▉     | 247/500 [06:20<06:39,  1.58s/it] 50%|████▉     | 249/500 [06:20<04:41,  1.12s/it] 50%|█████     | 251/500 [06:32<10:54,  2.63s/it] 51%|█████     | 253/500 [06:33<07:39,  1.86s/it] 51%|█████     | 255/500 [06:39<09:07,  2.23s/it] 51%|█████▏    | 257/500 [06:39<06:25,  1.59s/it] 52%|█████▏    | 259/500 [06:39<04:32,  1.13s/it] 52%|█████▏    | 259/500 [06:50<04:32,  1.13s/it] 52%|█████▏    | 261/500 [06:51<10:24,  2.61s/it] 53%|█████▎    | 263/500 [06:51<07:18,  1.85s/it] 53%|█████▎    | 265/500 [06:57<08:42,  2.22s/it] 53%|█████▎    | 267/500 [06:58<06:07,  1.58s/it] 54%|█████▍    | 269/500 [06:58<04:19,  1.12s/it] 54%|█████▍    | 269/500 [07:10<04:19,  1.12s/it] 54%|█████▍    | 271/500 [07:10<09:59,  2.62s/it] 55%|█████▍    | 273/500 [07:10<07:00,  1.85s/it] 55%|█████▌    | 275/500 [07:16<08:21,  2.23s/it] 55%|█████▌    | 277/500 [07:16<05:52,  1.58s/it] 56%|█████▌    | 279/500 [07:17<04:09,  1.13s/it] 56%|█████▌    | 281/500 [07:29<09:35,  2.63s/it] 57%|█████▋    | 283/500 [07:29<06:43,  1.86s/it] 57%|█████▋    | 285/500 [07:35<07:59,  2.23s/it] 57%|█████▋    | 287/500 [07:35<05:36,  1.58s/it] 58%|█████▊    | 289/500 [07:35<03:57,  1.13s/it] 58%|█████▊    | 291/500 [07:48<09:06,  2.61s/it] 59%|█████▊    | 293/500 [07:48<06:23,  1.85s/it] 59%|█████▉    | 295/500 [07:54<07:34,  2.22s/it] 59%|█████▉    | 297/500 [07:54<05:19,  1.57s/it] 60%|█████▉    | 299/500 [07:54<03:45,  1.12s/it] 60%|██████    | 301/500 [08:06<08:41,  2.62s/it] 61%|██████    | 303/500 [08:07<06:05,  1.85s/it]Epoch:  246  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  247  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  248  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  249  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  250  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  252  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  253  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  254  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  255  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  257  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  258  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  259  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  260  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  262  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
Epoch:  263  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  264  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  265  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  267  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  268  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  269  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  270  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  272  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  273  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  274  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  275  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  277  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  278  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  279  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  280  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  282  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  283  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  284  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  285  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  287  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  288  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  289  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  290  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  292  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  293  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  294  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  295  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  297  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  298  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  299  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  300  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  302  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  303  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  304  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
 61%|██████    | 305/500 [08:13<07:18,  2.25s/it] 61%|██████▏   | 307/500 [08:13<05:07,  1.59s/it] 62%|██████▏   | 309/500 [08:13<03:36,  1.14s/it] 62%|██████▏   | 311/500 [08:25<08:17,  2.63s/it] 63%|██████▎   | 313/500 [08:25<05:48,  1.86s/it] 63%|██████▎   | 315/500 [08:32<06:52,  2.23s/it] 63%|██████▎   | 317/500 [08:32<04:49,  1.58s/it] 64%|██████▍   | 319/500 [08:32<03:24,  1.13s/it] 64%|██████▍   | 321/500 [08:44<07:48,  2.62s/it] 65%|██████▍   | 323/500 [08:44<05:28,  1.85s/it] 65%|██████▌   | 325/500 [08:50<06:29,  2.22s/it] 65%|██████▌   | 327/500 [08:51<04:32,  1.58s/it] 66%|██████▌   | 329/500 [08:51<03:11,  1.12s/it] 66%|██████▌   | 331/500 [09:03<07:23,  2.63s/it] 67%|██████▋   | 333/500 [09:03<05:10,  1.86s/it] 67%|██████▋   | 335/500 [09:09<06:07,  2.23s/it] 67%|██████▋   | 337/500 [09:09<04:17,  1.58s/it] 68%|██████▊   | 339/500 [09:10<03:01,  1.13s/it] 68%|██████▊   | 339/500 [09:20<03:01,  1.13s/it] 68%|██████▊   | 341/500 [09:22<06:55,  2.62s/it] 69%|██████▊   | 343/500 [09:22<04:50,  1.85s/it] 69%|██████▉   | 345/500 [09:28<05:45,  2.23s/it] 69%|██████▉   | 347/500 [09:28<04:02,  1.58s/it] 70%|██████▉   | 349/500 [09:28<02:50,  1.13s/it] 70%|██████▉   | 349/500 [09:40<02:50,  1.13s/it] 70%|███████   | 351/500 [09:41<06:33,  2.64s/it] 71%|███████   | 353/500 [09:41<04:34,  1.87s/it] 71%|███████   | 355/500 [09:47<05:24,  2.24s/it] 71%|███████▏  | 357/500 [09:47<03:47,  1.59s/it] 72%|███████▏  | 359/500 [09:47<02:39,  1.13s/it] 72%|███████▏  | 359/500 [10:00<02:39,  1.13s/it] 72%|███████▏  | 361/500 [10:00<06:06,  2.64s/it]Valid Loss:  0.01475583016872406
Epoch:  305  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  307  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  308  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  309  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  310  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  312  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  313  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  314  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  315  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  317  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  318  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  319  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  320  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  322  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  323  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  324  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  325  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  327  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  328  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  329  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  330  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  332  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  333  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  334  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  335  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  337  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  338  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  339  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  340  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  342  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  343  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  344  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  345  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  347  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  348  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  349  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  350  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  352  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  353  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  354  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  355  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  357  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  358  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  359  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  360  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
 73%|███████▎  | 363/500 [10:00<04:15,  1.87s/it] 73%|███████▎  | 365/500 [10:06<05:00,  2.23s/it] 73%|███████▎  | 367/500 [10:06<03:29,  1.58s/it] 74%|███████▍  | 369/500 [10:06<02:27,  1.13s/it] 74%|███████▍  | 371/500 [10:19<05:39,  2.63s/it] 75%|███████▍  | 373/500 [10:19<03:56,  1.87s/it] 75%|███████▌  | 375/500 [10:25<04:39,  2.24s/it] 75%|███████▌  | 377/500 [10:25<03:15,  1.59s/it] 76%|███████▌  | 379/500 [10:25<02:16,  1.13s/it] 76%|███████▌  | 381/500 [10:37<05:13,  2.63s/it] 77%|███████▋  | 383/500 [10:38<03:38,  1.86s/it] 77%|███████▋  | 385/500 [10:44<04:20,  2.26s/it] 77%|███████▋  | 387/500 [10:44<03:01,  1.60s/it] 78%|███████▊  | 389/500 [10:44<02:06,  1.14s/it] 78%|███████▊  | 391/500 [10:56<04:47,  2.64s/it] 79%|███████▊  | 393/500 [10:57<03:19,  1.87s/it] 79%|███████▉  | 395/500 [11:03<03:56,  2.25s/it] 79%|███████▉  | 397/500 [11:03<02:44,  1.60s/it] 80%|███████▉  | 399/500 [11:03<01:54,  1.14s/it] 80%|████████  | 401/500 [11:15<04:20,  2.64s/it] 81%|████████  | 403/500 [11:16<03:00,  1.87s/it] 81%|████████  | 405/500 [11:22<03:31,  2.23s/it] 81%|████████▏ | 407/500 [11:22<02:27,  1.58s/it] 82%|████████▏ | 409/500 [11:22<01:42,  1.13s/it] 82%|████████▏ | 411/500 [11:34<03:54,  2.64s/it] 83%|████████▎ | 413/500 [11:34<02:42,  1.87s/it] 83%|████████▎ | 415/500 [11:41<03:09,  2.23s/it] 83%|████████▎ | 417/500 [11:41<02:11,  1.58s/it] 84%|████████▍ | 419/500 [11:41<01:31,  1.13s/it]Epoch:  362  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  363  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  364  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
Epoch:  365  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  367  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  368  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  369  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  370  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  372  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  373  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  374  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  375  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  377  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  378  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  379  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  380  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  382  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  383  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  384  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  385  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  387  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  388  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  389  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  390  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  392  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  393  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  394  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  395  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  397  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475582830607891
Epoch:  398  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  399  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  400  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  402  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  403  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  404  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  405  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  407  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  408  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  409  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  410  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  412  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  413  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  414  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  415  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  417  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  418  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  419  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  420  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
 84%|████████▍ | 421/500 [11:53<03:26,  2.62s/it] 85%|████████▍ | 423/500 [11:53<02:22,  1.85s/it] 85%|████████▌ | 425/500 [11:59<02:47,  2.24s/it] 85%|████████▌ | 427/500 [12:00<01:55,  1.59s/it] 86%|████████▌ | 429/500 [12:00<01:20,  1.13s/it] 86%|████████▌ | 431/500 [12:12<03:01,  2.63s/it] 87%|████████▋ | 433/500 [12:12<02:04,  1.86s/it] 87%|████████▋ | 435/500 [12:18<02:25,  2.24s/it] 87%|████████▋ | 437/500 [12:19<01:40,  1.59s/it] 88%|████████▊ | 439/500 [12:19<01:09,  1.13s/it] 88%|████████▊ | 439/500 [12:30<01:09,  1.13s/it] 88%|████████▊ | 441/500 [12:31<02:35,  2.64s/it] 89%|████████▊ | 443/500 [12:31<01:46,  1.87s/it] 89%|████████▉ | 445/500 [12:37<02:02,  2.23s/it] 89%|████████▉ | 447/500 [12:37<01:23,  1.58s/it] 90%|████████▉ | 449/500 [12:38<00:57,  1.13s/it] 90%|████████▉ | 449/500 [12:50<00:57,  1.13s/it] 90%|█████████ | 451/500 [12:50<02:09,  2.64s/it] 91%|█████████ | 453/500 [12:50<01:27,  1.87s/it] 91%|█████████ | 455/500 [12:56<01:40,  2.24s/it] 91%|█████████▏| 457/500 [12:56<01:08,  1.59s/it] 92%|█████████▏| 459/500 [12:57<00:46,  1.13s/it] 92%|█████████▏| 461/500 [13:09<01:42,  2.64s/it] 93%|█████████▎| 463/500 [13:09<01:09,  1.87s/it] 93%|█████████▎| 465/500 [13:15<01:18,  2.23s/it] 93%|█████████▎| 467/500 [13:15<00:52,  1.58s/it] 94%|█████████▍| 469/500 [13:15<00:34,  1.13s/it] 94%|█████████▍| 471/500 [13:28<01:16,  2.62s/it] 95%|█████████▍| 473/500 [13:28<00:50,  1.86s/it] 95%|█████████▌| 475/500 [13:34<00:55,  2.23s/it] 95%|█████████▌| 477/500 [13:34<00:36,  1.58s/it]Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  422  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  423  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  424  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  425  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  427  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  428  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  429  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  430  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  432  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  433  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  434  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  435  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  437  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  438  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  439  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  440  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
Epoch:  442  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  443  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  444  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  445  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  447  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  448  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  449  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  450  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  452  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  453  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  454  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  455  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  457  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  458  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  459  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  460  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.01475583016872406
Epoch:  462  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  463  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  464  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  465  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  467  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  468  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  469  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  470  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  472  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  473  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  474  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  475  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  477  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
Epoch:  478  	Training Loss: 0.025531519204378128
 96%|█████████▌| 479/500 [13:34<00:23,  1.12s/it] 96%|█████████▌| 481/500 [13:47<00:50,  2.66s/it] 97%|█████████▋| 483/500 [13:47<00:32,  1.89s/it] 97%|█████████▋| 485/500 [13:53<00:33,  2.25s/it] 97%|█████████▋| 487/500 [13:53<00:20,  1.59s/it] 98%|█████████▊| 489/500 [13:53<00:12,  1.13s/it] 98%|█████████▊| 491/500 [14:06<00:23,  2.65s/it] 99%|█████████▊| 493/500 [14:06<00:13,  1.87s/it] 99%|█████████▉| 495/500 [14:12<00:11,  2.24s/it] 99%|█████████▉| 497/500 [14:12<00:04,  1.59s/it]100%|█████████▉| 499/500 [14:12<00:01,  1.13s/it]100%|██████████| 500/500 [14:18<00:00,  1.72s/it]
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  479  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  480  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  482  	Training Loss: 0.025531521067023277
Test Loss:  0.00772984279319644
Valid Loss:  0.01475582830607891
Epoch:  483  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  484  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  485  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  487  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841396212578
Valid Loss:  0.014755829237401485
Epoch:  488  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
Epoch:  489  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  490  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475582830607891
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  492  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  493  	Training Loss: 0.025531521067023277
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
Epoch:  494  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.014755829237401485
Epoch:  495  	Training Loss: 0.025531519204378128
Test Loss:  0.0077298423275351524
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  497  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.01475582830607891
Epoch:  498  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  499  	Training Loss: 0.025531519204378128
Test Loss:  0.007729841861873865
Valid Loss:  0.014755829237401485
Epoch:  500  	Training Loss: 0.025531521067023277
Test Loss:  0.007729841861873865
Valid Loss:  0.01475583016872406
**************************************************learning rate decay**************************************************
seed is  2
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:03,  6.14s/it]  1%|          | 3/500 [00:06<13:36,  1.64s/it]  1%|          | 5/500 [00:06<06:51,  1.20it/s]  1%|▏         | 7/500 [00:06<04:09,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.94it/s]  2%|▏         | 11/500 [00:12<10:40,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:19<09:26,  1.18s/it]  5%|▍         | 23/500 [00:19<06:41,  1.19it/s]  5%|▌         | 25/500 [00:26<12:13,  1.54s/it]  5%|▌         | 27/500 [00:26<08:39,  1.10s/it]  6%|▌         | 29/500 [00:26<06:11,  1.27it/s]  6%|▌         | 31/500 [00:32<11:33,  1.48s/it]  7%|▋         | 33/500 [00:32<08:12,  1.06s/it]  7%|▋         | 35/500 [00:32<05:52,  1.32it/s]  7%|▋         | 37/500 [00:32<04:14,  1.82it/s]  8%|▊         | 39/500 [00:33<03:06,  2.47it/s]  8%|▊         | 41/500 [00:39<09:18,  1.22s/it]  9%|▊         | 43/500 [00:39<06:38,  1.15it/s]  9%|▉         | 45/500 [00:39<04:46,  1.59it/s]  9%|▉         | 47/500 [00:39<03:28,  2.17it/s] 10%|▉         | 49/500 [00:39<02:34,  2.92it/s] 10%|█         | 51/500 [00:46<08:47,  1.17s/it] 11%|█         | 53/500 [00:46<06:17,  1.19it/s] 11%|█         | 55/500 [00:46<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:46<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:46<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:52<08:29,  1.16s/it] 13%|█▎        | 63/500 [00:52<06:04,  1.20it/s] 13%|█▎        | 65/500 [00:53<04:22,  1.66it/s] 13%|█▎        | 67/500 [00:53<03:11,  2.26it/s]Epoch:  1  	Training Loss: 0.04824826121330261
Test Loss:  0.043648093938827515
Valid Loss:  0.04908900707960129
Epoch:  2  	Training Loss: 0.04002208635210991
Test Loss:  0.023933399468660355
Valid Loss:  0.032448381185531616
Epoch:  3  	Training Loss: 0.03221249580383301
Test Loss:  0.02225727029144764
Valid Loss:  0.023324407637119293
Epoch:  4  	Training Loss: 0.021911904215812683
Test Loss:  0.008154777809977531
Valid Loss:  0.012351542711257935
Epoch:  5  	Training Loss: 0.01656479388475418
Test Loss:  0.01478978805243969
Valid Loss:  0.012313172221183777
Epoch:  6  	Training Loss: 0.012992091476917267
Test Loss:  0.003148841205984354
Valid Loss:  0.0059435004368424416
Epoch:  7  	Training Loss: 0.010462982580065727
Test Loss:  0.010218754410743713
Valid Loss:  0.006842233240604401
Epoch:  8  	Training Loss: 0.00851636566221714
Test Loss:  0.005320051219314337
Valid Loss:  0.008423764258623123
Epoch:  9  	Training Loss: 0.012064112350344658
Test Loss:  0.025143416598439217
Valid Loss:  0.01651114597916603
Epoch:  10  	Training Loss: 0.018683772534132004
Test Loss:  0.005099565722048283
Valid Loss:  0.007594386115670204
Epoch:  11  	Training Loss: 0.010914607904851437
Test Loss:  0.01213135477155447
Valid Loss:  0.0073180729523301125
Epoch:  12  	Training Loss: 0.009720719419419765
Test Loss:  0.002088390290737152
Valid Loss:  0.003785663051530719
Epoch:  13  	Training Loss: 0.005332989152520895
Test Loss:  0.004741610959172249
Valid Loss:  0.002857551444321871
Epoch:  14  	Training Loss: 0.004593076184391975
Test Loss:  0.0014842819655314088
Valid Loss:  0.0027539758011698723
Epoch:  15  	Training Loss: 0.0034165573306381702
Test Loss:  0.003226303495466709
Valid Loss:  0.0020172977820038795
Epoch:  16  	Training Loss: 0.0033670212142169476
Test Loss:  0.0014434021431952715
Valid Loss:  0.002592851873487234
Epoch:  17  	Training Loss: 0.002888462273404002
Test Loss:  0.003148806979879737
Valid Loss:  0.0019558165222406387
Epoch:  18  	Training Loss: 0.0032084111589938402
Test Loss:  0.0015457995468750596
Valid Loss:  0.002674379851669073
Epoch:  19  	Training Loss: 0.002821281785145402
Test Loss:  0.0033241170458495617
Valid Loss:  0.0020315772853791714
Epoch:  20  	Training Loss: 0.003286534221842885
Test Loss:  0.0016391598619520664
Valid Loss:  0.0027152635157108307
Epoch:  21  	Training Loss: 0.0028379452414810658
Test Loss:  0.0036014211364090443
Valid Loss:  0.0021814382635056973
Epoch:  22  	Training Loss: 0.0034729731269180775
Test Loss:  0.0015958118019625545
Valid Loss:  0.002592996694147587
Epoch:  23  	Training Loss: 0.0027481457218527794
Test Loss:  0.0031588736455887556
Valid Loss:  0.0019608670845627785
Epoch:  24  	Training Loss: 0.003128260374069214
Test Loss:  0.0014061995316296816
Valid Loss:  0.0022949676495045424
Epoch:  25  	Training Loss: 0.0024336199276149273
Test Loss:  0.002627180889248848
Valid Loss:  0.0017000947846099734
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0027035302482545376
Test Loss:  0.0006404234445653856
Valid Loss:  0.0008451950270682573
Epoch:  27  	Training Loss: 0.0012459708377718925
Test Loss:  0.0005599621217697859
Valid Loss:  0.0008690045797266066
Epoch:  28  	Training Loss: 0.001170904841274023
Test Loss:  0.0005524470470845699
Valid Loss:  0.0008551295613870025
Epoch:  29  	Training Loss: 0.0011277110315859318
Test Loss:  0.000545680639334023
Valid Loss:  0.0008373705204576254
Epoch:  30  	Training Loss: 0.0010890280827879906
Test Loss:  0.0005370822036638856
Valid Loss:  0.000820997403934598
Epoch:  31  	Training Loss: 0.0010532084852457047
Test Loss:  0.0005282751517370343
Valid Loss:  0.0008038615924306214
Epoch:  32  	Training Loss: 0.0010199857642874122
Test Loss:  0.0005189039511606097
Valid Loss:  0.0007876364979892969
Epoch:  33  	Training Loss: 0.000988595187664032
Test Loss:  0.0005099280970171094
Valid Loss:  0.0007701994618400931
Epoch:  34  	Training Loss: 0.0009593352442607284
Test Loss:  0.0005008230218663812
Valid Loss:  0.00075208127964288
Epoch:  35  	Training Loss: 0.0009328188025392592
Test Loss:  0.0004928922280669212
Valid Loss:  0.0007321228040382266
Epoch:  36  	Training Loss: 0.0009086277568712831
Test Loss:  0.00048384509864263237
Valid Loss:  0.0007140053203329444
Epoch:  37  	Training Loss: 0.0008863604161888361
Test Loss:  0.00047549803275614977
Valid Loss:  0.0006948597729206085
Epoch:  38  	Training Loss: 0.0008661192841827869
Test Loss:  0.0004661985149141401
Valid Loss:  0.0006778638926334679
Epoch:  39  	Training Loss: 0.000847018207423389
Test Loss:  0.00045733212027698755
Valid Loss:  0.0006607919349335134
Epoch:  40  	Training Loss: 0.0008290341938845813
Test Loss:  0.0004483492812141776
Valid Loss:  0.0006449439097195864
Epoch:  41  	Training Loss: 0.0008119563572108746
Test Loss:  0.0004397306183818728
Valid Loss:  0.0006298110820353031
Epoch:  42  	Training Loss: 0.0007958585047163069
Test Loss:  0.0004312498203944415
Valid Loss:  0.0006154626025818288
Epoch:  43  	Training Loss: 0.000780528353061527
Test Loss:  0.00042308351839892566
Valid Loss:  0.0006017704145051539
Epoch:  44  	Training Loss: 0.0007657981477677822
Test Loss:  0.000414317415561527
Valid Loss:  0.0005903720739297569
Epoch:  45  	Training Loss: 0.0007515293546020985
Test Loss:  0.00040803279262036085
Valid Loss:  0.0005765699315816164
Epoch:  46  	Training Loss: 0.0007379938615486026
Test Loss:  0.0003988735261373222
Valid Loss:  0.0005674614803865552
Epoch:  47  	Training Loss: 0.0007249682676047087
Test Loss:  0.000393092748709023
Valid Loss:  0.0005547626642510295
Epoch:  48  	Training Loss: 0.0007123686373233795
Test Loss:  0.0003839195123873651
Valid Loss:  0.0005466043949127197
Epoch:  49  	Training Loss: 0.0007002493366599083
Test Loss:  0.0003796593809965998
Valid Loss:  0.0005334224551916122
Epoch:  50  	Training Loss: 0.0006884633912704885
Test Loss:  0.0003707541909534484
Valid Loss:  0.0005256884032860398
Epoch:  51  	Training Loss: 0.0006771141197532415
Test Loss:  0.00036516180261969566
Valid Loss:  0.0005152664380148053
Epoch:  52  	Training Loss: 0.0006660420913249254
Test Loss:  0.0003579121548682451
Valid Loss:  0.0005070612533017993
Epoch:  53  	Training Loss: 0.0006552950362674892
Test Loss:  0.00035172817297279835
Valid Loss:  0.0004986083367839456
Epoch:  54  	Training Loss: 0.0006448361673392355
Test Loss:  0.0003452752425801009
Valid Loss:  0.0004910510033369064
Epoch:  55  	Training Loss: 0.0006346334703266621
Test Loss:  0.00033917269320227206
Valid Loss:  0.0004838856984861195
Epoch:  56  	Training Loss: 0.0006246687844395638
Test Loss:  0.00033339267247356474
Valid Loss:  0.0004770630330312997
Epoch:  57  	Training Loss: 0.0006149336695671082
Test Loss:  0.00032790517434477806
Valid Loss:  0.0004705462197307497
Epoch:  58  	Training Loss: 0.0006054419791325927
Test Loss:  0.0003234561299905181
Valid Loss:  0.00046340576955117285
Epoch:  59  	Training Loss: 0.0005961684510111809
Test Loss:  0.00031735881930217147
Valid Loss:  0.0004582122201099992
Epoch:  60  	Training Loss: 0.0005871084285899997
Test Loss:  0.00031357340048998594
Valid Loss:  0.0004513022140599787
Epoch:  61  	Training Loss: 0.0005782548687420785
Test Loss:  0.0003078831941820681
Valid Loss:  0.00044651085045188665
Epoch:  62  	Training Loss: 0.0005696351872757077
Test Loss:  0.0003047423087991774
Valid Loss:  0.00043969188118353486
Epoch:  63  	Training Loss: 0.0005612027016468346
Test Loss:  0.0002995686954818666
Valid Loss:  0.0004346866044215858
Epoch:  64  	Training Loss: 0.0005529368063434958
Test Loss:  0.0002956487296614796
Valid Loss:  0.0004289784119464457
Epoch:  65  	Training Loss: 0.0005448726005852222
Test Loss:  0.0002913765492849052
Valid Loss:  0.00042380235390737653
Epoch:  66  	Training Loss: 0.0005369985592551529
Test Loss:  0.0002872611512430012
Valid Loss:  0.0004188115708529949
Epoch:  67  	Training Loss: 0.0005292868590913713
Test Loss:  0.0002833668258972466
Valid Loss:  0.00041398845496587455
Epoch:  68  	Training Loss: 0.0005217493744567037
Test Loss:  0.00027965003391727805
Valid Loss:  0.00040930448449216783
 14%|█▍        | 69/500 [00:53<02:21,  3.04it/s] 14%|█▍        | 71/500 [00:59<08:19,  1.16s/it] 15%|█▍        | 73/500 [00:59<05:57,  1.20it/s] 15%|█▌        | 75/500 [00:59<04:17,  1.65it/s] 15%|█▌        | 77/500 [00:59<03:07,  2.26it/s] 16%|█▌        | 79/500 [01:00<02:18,  3.04it/s] 16%|█▌        | 81/500 [01:06<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:06<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:06<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:06<03:03,  2.26it/s] 18%|█▊        | 89/500 [01:06<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:13<07:57,  1.17s/it] 19%|█▊        | 93/500 [01:13<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:13<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:13<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:13<02:12,  3.03it/s] 20%|██        | 101/500 [01:19<07:41,  1.16s/it] 21%|██        | 103/500 [01:19<05:30,  1.20it/s] 21%|██        | 105/500 [01:20<03:57,  1.66it/s] 21%|██▏       | 107/500 [01:20<02:53,  2.27it/s] 22%|██▏       | 109/500 [01:20<02:08,  3.05it/s] 22%|██▏       | 111/500 [01:26<07:29,  1.16s/it] 23%|██▎       | 113/500 [01:26<05:21,  1.20it/s] 23%|██▎       | 115/500 [01:26<03:51,  1.67it/s] 23%|██▎       | 117/500 [01:26<02:48,  2.28it/s] 24%|██▍       | 119/500 [01:27<02:04,  3.05it/s] 24%|██▍       | 121/500 [01:33<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:33<05:15,  1.19it/s] 25%|██▌       | 125/500 [01:33<03:46,  1.65it/s] 25%|██▌       | 127/500 [01:33<02:45,  2.26it/s] 26%|██▌       | 129/500 [01:33<02:02,  3.04it/s] 26%|██▌       | 131/500 [01:39<07:06,  1.15s/it] 27%|██▋       | 133/500 [01:40<05:04,  1.21it/s] 27%|██▋       | 135/500 [01:40<03:38,  1.67it/s]Epoch:  69  	Training Loss: 0.0005143810412846506
Test Loss:  0.0002760983188636601
Valid Loss:  0.00040477735456079245
Epoch:  70  	Training Loss: 0.0005071763880550861
Test Loss:  0.0002726676466409117
Valid Loss:  0.00040039417217485607
Epoch:  71  	Training Loss: 0.0005001393728889525
Test Loss:  0.0002696281881071627
Valid Loss:  0.0003958214074373245
Epoch:  72  	Training Loss: 0.0004932560259476304
Test Loss:  0.00026631762739270926
Valid Loss:  0.0003916745772585273
Epoch:  73  	Training Loss: 0.0004865278024226427
Test Loss:  0.000262889196164906
Valid Loss:  0.0003879443393088877
Epoch:  74  	Training Loss: 0.0004799427115358412
Test Loss:  0.00026026152772828937
Valid Loss:  0.0003835383104160428
Epoch:  75  	Training Loss: 0.00047346402425318956
Test Loss:  0.000257022213190794
Valid Loss:  0.0003798350808210671
Epoch:  76  	Training Loss: 0.0004671310307458043
Test Loss:  0.0002544031594879925
Valid Loss:  0.0003758409002330154
Epoch:  77  	Training Loss: 0.0004609464085660875
Test Loss:  0.00025173602625727654
Valid Loss:  0.000372045673429966
Epoch:  78  	Training Loss: 0.0004549045115709305
Test Loss:  0.000248993921559304
Valid Loss:  0.0003684622934088111
Epoch:  79  	Training Loss: 0.00044898191117681563
Test Loss:  0.0002464157878421247
Valid Loss:  0.00036496989196166396
Epoch:  80  	Training Loss: 0.0004431889101397246
Test Loss:  0.00024394983483944088
Valid Loss:  0.00036158825969323516
Epoch:  81  	Training Loss: 0.0004375223070383072
Test Loss:  0.00024159321037586778
Valid Loss:  0.0003583077050279826
Epoch:  82  	Training Loss: 0.0004319784347899258
Test Loss:  0.00023933668853715062
Valid Loss:  0.00035512170870788395
Epoch:  83  	Training Loss: 0.00042655598372220993
Test Loss:  0.00023717756266705692
Valid Loss:  0.000352023693267256
Epoch:  84  	Training Loss: 0.0004212496569380164
Test Loss:  0.00023510929895564914
Valid Loss:  0.00034901034086942673
Epoch:  85  	Training Loss: 0.000416056253015995
Test Loss:  0.00023312721168622375
Valid Loss:  0.0003460753941908479
Epoch:  86  	Training Loss: 0.0004109728033654392
Test Loss:  0.0002312270225957036
Valid Loss:  0.00034321617567911744
Epoch:  87  	Training Loss: 0.00040599971543997526
Test Loss:  0.00022963866649661213
Valid Loss:  0.00034019610029645264
Epoch:  88  	Training Loss: 0.00040113943396136165
Test Loss:  0.00022760123829357326
Valid Loss:  0.0003376953536644578
Epoch:  89  	Training Loss: 0.0003963624476455152
Test Loss:  0.00022603431716561317
Valid Loss:  0.00033477754914201796
Epoch:  90  	Training Loss: 0.00039165758062154055
Test Loss:  0.00022432045079767704
Valid Loss:  0.000332113093463704
Epoch:  91  	Training Loss: 0.0003870529471896589
Test Loss:  0.00022270949557423592
Valid Loss:  0.00032951380126178265
Epoch:  92  	Training Loss: 0.0003825438325293362
Test Loss:  0.00022117243497632444
Valid Loss:  0.0003269916633144021
Epoch:  93  	Training Loss: 0.00037812942173331976
Test Loss:  0.00021968473447486758
Valid Loss:  0.0003245379193685949
Epoch:  94  	Training Loss: 0.00037380645517259836
Test Loss:  0.00021847450989298522
Valid Loss:  0.0003218294004909694
Epoch:  95  	Training Loss: 0.00036957772681489587
Test Loss:  0.00021675601601600647
Valid Loss:  0.00031966608366928995
Epoch:  96  	Training Loss: 0.00036542845191434026
Test Loss:  0.00021539605222642422
Valid Loss:  0.00031736408709548414
Epoch:  97  	Training Loss: 0.00036137388087809086
Test Loss:  0.00021430151537060738
Valid Loss:  0.00031492437119595706
Epoch:  98  	Training Loss: 0.00035741005558520555
Test Loss:  0.00021287149866111577
Valid Loss:  0.0003128673997707665
Epoch:  99  	Training Loss: 0.0003535384894348681
Test Loss:  0.00021196345915086567
Valid Loss:  0.00031047494849190116
Epoch:  100  	Training Loss: 0.0003497565630823374
Test Loss:  0.00021062578889541328
Valid Loss:  0.0003084975469391793
Epoch:  101  	Training Loss: 0.0003460574662312865
Test Loss:  0.00020963474526070058
Valid Loss:  0.0003063551848754287
Epoch:  102  	Training Loss: 0.00034244381822645664
Test Loss:  0.00020858334028162062
Valid Loss:  0.00030434399377554655
Epoch:  103  	Training Loss: 0.00033891404746100307
Test Loss:  0.0002075228258036077
Valid Loss:  0.0003024121397174895
Epoch:  104  	Training Loss: 0.0003354612272232771
Test Loss:  0.00020646044868044555
Valid Loss:  0.0003004504251293838
Epoch:  105  	Training Loss: 0.00033208192326128483
Test Loss:  0.00020542117999866605
Valid Loss:  0.00029855920001864433
Epoch:  106  	Training Loss: 0.00032877319608815014
Test Loss:  0.0002044340071734041
Valid Loss:  0.0002967155887745321
Epoch:  107  	Training Loss: 0.0003255333285778761
Test Loss:  0.00020349345868453383
Valid Loss:  0.0002949194167740643
Epoch:  108  	Training Loss: 0.00032236037077382207
Test Loss:  0.0002025964786298573
Valid Loss:  0.00029316716245375574
Epoch:  109  	Training Loss: 0.00031925266375765204
Test Loss:  0.00020174027304165065
Valid Loss:  0.0002914562064688653
Epoch:  110  	Training Loss: 0.0003162106149829924
Test Loss:  0.00020108121680095792
Valid Loss:  0.0002896430087275803
Epoch:  111  	Training Loss: 0.0003132368437945843
Test Loss:  0.00020008256251458079
Valid Loss:  0.0002881085965782404
Epoch:  112  	Training Loss: 0.0003103243943769485
Test Loss:  0.0001994874037336558
Valid Loss:  0.00028635584749281406
Epoch:  113  	Training Loss: 0.00030746939592063427
Test Loss:  0.0001987189898500219
Valid Loss:  0.00028477219166234136
Epoch:  114  	Training Loss: 0.00030467435135506094
Test Loss:  0.000198007735889405
Valid Loss:  0.00028321455465629697
Epoch:  115  	Training Loss: 0.0003019360010512173
Test Loss:  0.00019732885994017124
Valid Loss:  0.0002816937048919499
Epoch:  116  	Training Loss: 0.00029926036950200796
Test Loss:  0.00019676663214340806
Valid Loss:  0.00028014383860863745
Epoch:  117  	Training Loss: 0.00029664099565707147
Test Loss:  0.0001961356756510213
Valid Loss:  0.00027869001496583223
Epoch:  118  	Training Loss: 0.00029407700640149415
Test Loss:  0.00019557197811082006
Valid Loss:  0.00027724404935725033
Epoch:  119  	Training Loss: 0.0002915693330578506
Test Loss:  0.00019505960517562926
Valid Loss:  0.00027581281028687954
Epoch:  120  	Training Loss: 0.00028911925619468093
Test Loss:  0.00019467304809950292
Valid Loss:  0.00027434428920969367
Epoch:  121  	Training Loss: 0.0002867295406758785
Test Loss:  0.0001940055808518082
Valid Loss:  0.0002731052227318287
Epoch:  122  	Training Loss: 0.0002843849651981145
Test Loss:  0.0001936805492732674
Valid Loss:  0.00027170788962394
Epoch:  123  	Training Loss: 0.00028208777075633407
Test Loss:  0.00019320764113217592
Valid Loss:  0.00027043549926020205
Epoch:  124  	Training Loss: 0.0002798425266519189
Test Loss:  0.0001928583806147799
Valid Loss:  0.0002690722467377782
Epoch:  125  	Training Loss: 0.0002776474866550416
Test Loss:  0.00019244525174144655
Valid Loss:  0.0002677800366654992
Epoch:  126  	Training Loss: 0.00027549947844818234
Test Loss:  0.00019209359015803784
Valid Loss:  0.0002664992352947593
Epoch:  127  	Training Loss: 0.00027340027736499906
Test Loss:  0.00019178609363734722
Valid Loss:  0.0002652356633916497
Epoch:  128  	Training Loss: 0.00027134816627949476
Test Loss:  0.00019146522390656173
Valid Loss:  0.0002640184247866273
Epoch:  129  	Training Loss: 0.0002693402348086238
Test Loss:  0.00019115804752800614
Valid Loss:  0.00026283497572876513
Epoch:  130  	Training Loss: 0.00026737299049273133
Test Loss:  0.0001908739359350875
Valid Loss:  0.0002616778656374663
Epoch:  131  	Training Loss: 0.0002654451527632773
Test Loss:  0.000190610415302217
Valid Loss:  0.0002605461631901562
Epoch:  132  	Training Loss: 0.00026355742011219263
Test Loss:  0.0001904805685626343
Valid Loss:  0.00025937813916243613
Epoch:  133  	Training Loss: 0.0002617121208459139
Test Loss:  0.00019006147340405732
Valid Loss:  0.0002583253080956638
Epoch:  134  	Training Loss: 0.0002599030267447233
Test Loss:  0.0001899153576232493
Valid Loss:  0.0002571829245425761
Epoch:  135  	Training Loss: 0.00025812850799411535
Test Loss:  0.00018959553563036025
Valid Loss:  0.00025611958699300885
Epoch:  136  	Training Loss: 0.00025639121304266155
Test Loss:  0.00018928179633803666
 27%|██▋       | 137/500 [01:40<02:39,  2.28it/s] 28%|██▊       | 139/500 [01:40<01:57,  3.06it/s] 28%|██▊       | 141/500 [01:46<06:54,  1.15s/it] 29%|██▊       | 143/500 [01:46<04:55,  1.21it/s] 29%|██▉       | 145/500 [01:46<03:32,  1.67it/s] 29%|██▉       | 147/500 [01:47<02:34,  2.28it/s] 30%|██▉       | 149/500 [01:47<01:54,  3.07it/s] 30%|███       | 151/500 [01:53<06:40,  1.15s/it] 31%|███       | 153/500 [01:53<04:46,  1.21it/s] 31%|███       | 155/500 [01:53<03:25,  1.68it/s] 31%|███▏      | 157/500 [01:53<02:29,  2.29it/s] 32%|███▏      | 159/500 [01:53<01:50,  3.08it/s] 32%|███▏      | 161/500 [02:00<06:35,  1.17s/it] 33%|███▎      | 163/500 [02:00<04:42,  1.19it/s] 33%|███▎      | 165/500 [02:00<03:22,  1.65it/s] 33%|███▎      | 167/500 [02:00<02:27,  2.26it/s] 34%|███▍      | 169/500 [02:00<01:48,  3.04it/s] 34%|███▍      | 171/500 [02:06<06:17,  1.15s/it] 35%|███▍      | 173/500 [02:06<04:30,  1.21it/s] 35%|███▌      | 175/500 [02:07<03:14,  1.67it/s] 35%|███▌      | 177/500 [02:07<02:21,  2.29it/s] 36%|███▌      | 179/500 [02:07<01:44,  3.07it/s] 36%|███▌      | 181/500 [02:13<06:07,  1.15s/it] 37%|███▋      | 183/500 [02:13<04:22,  1.21it/s] 37%|███▋      | 185/500 [02:13<03:08,  1.67it/s] 37%|███▋      | 187/500 [02:13<02:17,  2.28it/s] 38%|███▊      | 189/500 [02:13<01:41,  3.06it/s] 38%|███▊      | 191/500 [02:20<05:57,  1.16s/it] 39%|███▊      | 193/500 [02:20<04:14,  1.21it/s] 39%|███▉      | 195/500 [02:20<03:03,  1.67it/s] 39%|███▉      | 197/500 [02:20<02:13,  2.28it/s] 40%|███▉      | 199/500 [02:20<01:38,  3.06it/s] 40%|████      | 201/500 [02:26<05:44,  1.15s/it]Valid Loss:  0.0002550742356106639
Epoch:  137  	Training Loss: 0.0002546909963712096
Test Loss:  0.00018904870375990868
Valid Loss:  0.0002540243440307677
Epoch:  138  	Training Loss: 0.0002530291094444692
Test Loss:  0.0001887558028101921
Valid Loss:  0.00025302154244855046
Epoch:  139  	Training Loss: 0.0002514029620215297
Test Loss:  0.00018851080676540732
Valid Loss:  0.00025203070254065096
Epoch:  140  	Training Loss: 0.00024981400929391384
Test Loss:  0.00018829776672646403
Valid Loss:  0.0002510531630832702
Epoch:  141  	Training Loss: 0.00024825974833220243
Test Loss:  0.00018806704611051828
Valid Loss:  0.00025010533863678575
Epoch:  142  	Training Loss: 0.0002467384620103985
Test Loss:  0.00018784348503686488
Valid Loss:  0.00024918181588873267
Epoch:  143  	Training Loss: 0.00024524753098376095
Test Loss:  0.0001876231108326465
Valid Loss:  0.0002482769195921719
Epoch:  144  	Training Loss: 0.00024378570378758013
Test Loss:  0.00018739624647423625
Valid Loss:  0.0002473903587087989
Epoch:  145  	Training Loss: 0.00024235245655290782
Test Loss:  0.00018713236204348505
Valid Loss:  0.00024652149295434356
Epoch:  146  	Training Loss: 0.00024094610125757754
Test Loss:  0.0001868637336883694
Valid Loss:  0.0002456685760989785
Epoch:  147  	Training Loss: 0.00023956689983606339
Test Loss:  0.00018660564091987908
Valid Loss:  0.0002448309096507728
Epoch:  148  	Training Loss: 0.00023821345530450344
Test Loss:  0.0001863591023720801
Valid Loss:  0.0002440075040794909
Epoch:  149  	Training Loss: 0.00023688496730756015
Test Loss:  0.00018612382700666785
Valid Loss:  0.00024319792282767594
Epoch:  150  	Training Loss: 0.00023558108659926802
Test Loss:  0.00018589902902022004
Valid Loss:  0.00024240222410298884
Epoch:  151  	Training Loss: 0.0002343013184145093
Test Loss:  0.00018568392260931432
Valid Loss:  0.00024161874898709357
Epoch:  152  	Training Loss: 0.00023304497881326824
Test Loss:  0.0001855799346230924
Valid Loss:  0.00024083013704512268
Epoch:  153  	Training Loss: 0.00023182100267149508
Test Loss:  0.00018526107305660844
Valid Loss:  0.00024008737818803638
Epoch:  154  	Training Loss: 0.0002306177921127528
Test Loss:  0.00018518709111958742
Valid Loss:  0.0002393251343164593
Epoch:  155  	Training Loss: 0.00022943608928471804
Test Loss:  0.0001849684485932812
Valid Loss:  0.0002385920670349151
Epoch:  156  	Training Loss: 0.00022827766952104867
Test Loss:  0.0001847415987867862
Valid Loss:  0.0002378706994932145
Epoch:  157  	Training Loss: 0.00022714036458637565
Test Loss:  0.0001845239894464612
Valid Loss:  0.00023716205032542348
Epoch:  158  	Training Loss: 0.00022602338867727667
Test Loss:  0.0001843016070779413
Valid Loss:  0.0002364656247664243
Epoch:  159  	Training Loss: 0.00022492639254778624
Test Loss:  0.00018408647156320512
Valid Loss:  0.00023576902458444238
Epoch:  160  	Training Loss: 0.00022384869225788862
Test Loss:  0.00018388047465123236
Valid Loss:  0.0002350549475522712
Epoch:  161  	Training Loss: 0.00022278983669821173
Test Loss:  0.00018368259770795703
Valid Loss:  0.00023434300965163857
Epoch:  162  	Training Loss: 0.0002217501460108906
Test Loss:  0.00018354589701630175
Valid Loss:  0.00023364053049590439
Epoch:  163  	Training Loss: 0.00022073778382036835
Test Loss:  0.00018335040658712387
Valid Loss:  0.00023294742277357727
Epoch:  164  	Training Loss: 0.00021974950504954904
Test Loss:  0.00018336254288442433
Valid Loss:  0.00023227363999467343
Epoch:  165  	Training Loss: 0.00021878283587284386
Test Loss:  0.00018297325004823506
Valid Loss:  0.0002315870369784534
Epoch:  166  	Training Loss: 0.00021782307885587215
Test Loss:  0.0001829296088544652
Valid Loss:  0.00023093998606782407
Epoch:  167  	Training Loss: 0.00021689108689315617
Test Loss:  0.0001826859515858814
Valid Loss:  0.00023028621217235923
Epoch:  168  	Training Loss: 0.00021598594321403652
Test Loss:  0.0001827022060751915
Valid Loss:  0.00022967263066675514
Epoch:  169  	Training Loss: 0.00021509730140678585
Test Loss:  0.0001822285121306777
Valid Loss:  0.00022901964257471263
Epoch:  170  	Training Loss: 0.00021422287682071328
Test Loss:  0.0001822134363465011
Valid Loss:  0.00022843960323370993
Epoch:  171  	Training Loss: 0.00021336627833079547
Test Loss:  0.00018173884018324316
Valid Loss:  0.00022780898143537343
Epoch:  172  	Training Loss: 0.00021253761951811612
Test Loss:  0.00018173408170696348
Valid Loss:  0.0002272658166475594
Epoch:  173  	Training Loss: 0.00021171721164137125
Test Loss:  0.00018116971477866173
Valid Loss:  0.00022663500567432493
Epoch:  174  	Training Loss: 0.00021092407405376434
Test Loss:  0.00018118740990757942
Valid Loss:  0.00022612368047703058
Epoch:  175  	Training Loss: 0.0002101352729368955
Test Loss:  0.00018083496252074838
Valid Loss:  0.00022555298346560448
Epoch:  176  	Training Loss: 0.00020937978115398437
Test Loss:  0.00018061991431750357
Valid Loss:  0.0002250121906399727
Epoch:  177  	Training Loss: 0.00020864303223788738
Test Loss:  0.00018031103536486626
Valid Loss:  0.0002244559582322836
Epoch:  178  	Training Loss: 0.00020792556460946798
Test Loss:  0.0001800537866074592
Valid Loss:  0.0002239249151898548
Epoch:  179  	Training Loss: 0.00020722366753034294
Test Loss:  0.00017977879906538874
Valid Loss:  0.0002233979757875204
Epoch:  180  	Training Loss: 0.00020653623505495489
Test Loss:  0.0001795219723135233
Valid Loss:  0.00022288461332209408
Epoch:  181  	Training Loss: 0.00020586210303008556
Test Loss:  0.00017927639419212937
Valid Loss:  0.0002223825140390545
Epoch:  182  	Training Loss: 0.00020520435646176338
Test Loss:  0.00017923465929925442
Valid Loss:  0.00022196111967787147
Epoch:  183  	Training Loss: 0.00020456616766750813
Test Loss:  0.0001787441287888214
Valid Loss:  0.00022139483189675957
Epoch:  184  	Training Loss: 0.00020392867736518383
Test Loss:  0.00017866629059426486
Valid Loss:  0.00022097898181527853
Epoch:  185  	Training Loss: 0.00020331295672804117
Test Loss:  0.00017853968893177807
Valid Loss:  0.00022057248861528933
Epoch:  186  	Training Loss: 0.00020272075198590755
Test Loss:  0.00017800826753955334
Valid Loss:  0.00022002530749887228
Epoch:  187  	Training Loss: 0.00020212866365909576
Test Loss:  0.00017810074496082962
Valid Loss:  0.0002197191643062979
Epoch:  188  	Training Loss: 0.00020155802485533059
Test Loss:  0.00017735768051352352
Valid Loss:  0.00021909423230681568
Epoch:  189  	Training Loss: 0.00020097868400625885
Test Loss:  0.000177423789864406
Valid Loss:  0.0002187715144827962
Epoch:  190  	Training Loss: 0.00020039157243445516
Test Loss:  0.000176536530489102
Valid Loss:  0.00021807194571010768
Epoch:  191  	Training Loss: 0.0001998136576730758
Test Loss:  0.00017659734294284135
Valid Loss:  0.0002177464048145339
Epoch:  192  	Training Loss: 0.00019920681370422244
Test Loss:  0.00017571478383615613
Valid Loss:  0.00021703953098040074
Epoch:  193  	Training Loss: 0.00019862328190356493
Test Loss:  0.00017572524666320533
Valid Loss:  0.00021671090507879853
Epoch:  194  	Training Loss: 0.0001980199449462816
Test Loss:  0.00017479577218182385
Valid Loss:  0.00021597975865006447
Epoch:  195  	Training Loss: 0.0001974512415472418
Test Loss:  0.00017501026741228998
Valid Loss:  0.00021576910512521863
Epoch:  196  	Training Loss: 0.00019687401072587818
Test Loss:  0.00017412153829354793
Valid Loss:  0.00021506499615497887
Epoch:  197  	Training Loss: 0.00019632672774605453
Test Loss:  0.00017438722716178745
Valid Loss:  0.00021490445942617953
Epoch:  198  	Training Loss: 0.00019577512284740806
Test Loss:  0.00017354397277813405
Valid Loss:  0.00021422500140033662
Epoch:  199  	Training Loss: 0.00019525332027114928
Test Loss:  0.0001738459395710379
Valid Loss:  0.00021410323097370565
Epoch:  200  	Training Loss: 0.0001947209530044347
Test Loss:  0.00017307406233157963
Valid Loss:  0.00021346050198189914
Epoch:  201  	Training Loss: 0.00019421923207119107
Test Loss:  0.00017331149138044566
Valid Loss:  0.00021332388860173523
Epoch:  202  	Training Loss: 0.0001936979970196262
Test Loss:  0.00017271010437980294
Valid Loss:  0.0002127742482116446
Epoch:  203  	Training Loss: 0.00019320267892908305
Test Loss:  0.00017278851009905338
 41%|████      | 203/500 [02:26<04:05,  1.21it/s] 41%|████      | 205/500 [02:27<02:56,  1.67it/s] 41%|████▏     | 207/500 [02:27<02:08,  2.28it/s] 42%|████▏     | 209/500 [02:27<01:35,  3.05it/s] 42%|████▏     | 211/500 [02:33<05:33,  1.16s/it] 43%|████▎     | 213/500 [02:33<03:57,  1.21it/s] 43%|████▎     | 215/500 [02:33<02:50,  1.67it/s] 43%|████▎     | 217/500 [02:33<02:03,  2.28it/s] 44%|████▍     | 219/500 [02:34<01:31,  3.06it/s] 44%|████▍     | 221/500 [02:40<05:23,  1.16s/it] 45%|████▍     | 223/500 [02:40<03:50,  1.20it/s] 45%|████▌     | 225/500 [02:40<02:45,  1.66it/s] 45%|████▌     | 227/500 [02:40<02:00,  2.27it/s] 46%|████▌     | 229/500 [02:40<01:28,  3.05it/s] 46%|████▌     | 231/500 [02:47<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:47<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:47<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:47<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:47<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:53<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:54<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:54<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:54<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:54<01:24,  2.97it/s] 50%|█████     | 251/500 [03:00<04:54,  1.18s/it] 51%|█████     | 253/500 [03:00<03:29,  1.18it/s] 51%|█████     | 255/500 [03:01<02:29,  1.64it/s] 51%|█████▏    | 257/500 [03:01<01:48,  2.24it/s] 52%|█████▏    | 259/500 [03:01<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:07<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:07<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:07<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:07<01:42,  2.27it/s] 54%|█████▍    | 269/500 [03:08<01:15,  3.05it/s]Valid Loss:  0.00021258214837871492
Epoch:  204  	Training Loss: 0.0001927112607518211
Test Loss:  0.00017217127606272697
Valid Loss:  0.00021202454809099436
Epoch:  205  	Training Loss: 0.0001922003284562379
Test Loss:  0.0001721504668239504
Valid Loss:  0.00021178954921197146
Epoch:  206  	Training Loss: 0.00019170936138834804
Test Loss:  0.00017159810522571206
Valid Loss:  0.00021126330830156803
Epoch:  207  	Training Loss: 0.0001912301522679627
Test Loss:  0.00017158020636998117
Valid Loss:  0.00021102791652083397
Epoch:  208  	Training Loss: 0.00019075258751399815
Test Loss:  0.00017132970970124006
Valid Loss:  0.00021067957277409732
Epoch:  209  	Training Loss: 0.00019029329996556044
Test Loss:  0.00017112800560425967
Valid Loss:  0.000210359605262056
Epoch:  210  	Training Loss: 0.00018984278722200543
Test Loss:  0.0001709001517156139
Valid Loss:  0.00021002383437007666
Epoch:  211  	Training Loss: 0.00018940187874250114
Test Loss:  0.00017065748397726566
Valid Loss:  0.00020967263844795525
Epoch:  212  	Training Loss: 0.00018897096742875874
Test Loss:  0.0001706700713839382
Valid Loss:  0.00020948320161551237
Epoch:  213  	Training Loss: 0.00018854124937206507
Test Loss:  0.0001704170135781169
Valid Loss:  0.0002091487986035645
Epoch:  214  	Training Loss: 0.00018811639165505767
Test Loss:  0.00017027391004376113
Valid Loss:  0.00020888335711788386
Epoch:  215  	Training Loss: 0.00018770014867186546
Test Loss:  0.0001700675638858229
Valid Loss:  0.00020858083735220134
Epoch:  216  	Training Loss: 0.0001872926950454712
Test Loss:  0.00016992294695228338
Valid Loss:  0.00020831802976317704
Epoch:  217  	Training Loss: 0.0001868861581897363
Test Loss:  0.00016963688540272415
Valid Loss:  0.0002079732366837561
Epoch:  218  	Training Loss: 0.00018646815442480147
Test Loss:  0.00016944232629612088
Valid Loss:  0.0002076836535707116
Epoch:  219  	Training Loss: 0.00018605928926263005
Test Loss:  0.00016925398085732013
Valid Loss:  0.00020739951287396252
Epoch:  220  	Training Loss: 0.0001856591843534261
Test Loss:  0.00016907998360693455
Valid Loss:  0.00020712552941404283
Epoch:  221  	Training Loss: 0.00018526549683883786
Test Loss:  0.00016887836682144552
Valid Loss:  0.00020683588809333742
Epoch:  222  	Training Loss: 0.00018487125635147095
Test Loss:  0.00016871228581294417
Valid Loss:  0.0002065690787276253
Epoch:  223  	Training Loss: 0.00018448475748300552
Test Loss:  0.0001685551251284778
Valid Loss:  0.00020630835206247866
Epoch:  224  	Training Loss: 0.00018410597112961113
Test Loss:  0.00016840864554978907
Valid Loss:  0.0002060549013549462
Epoch:  225  	Training Loss: 0.00018373405328020453
Test Loss:  0.00016827078070491552
Valid Loss:  0.00020580744603648782
Epoch:  226  	Training Loss: 0.00018336562789045274
Test Loss:  0.0001680249406490475
Valid Loss:  0.00020549485634546727
Epoch:  227  	Training Loss: 0.00018298070062883198
Test Loss:  0.00016786225023679435
Valid Loss:  0.00020523625425994396
Epoch:  228  	Training Loss: 0.00018260354408994317
Test Loss:  0.00016770526417531073
Valid Loss:  0.00020498206140473485
Epoch:  229  	Training Loss: 0.00018223386723548174
Test Loss:  0.00016756098193582147
Valid Loss:  0.00020473609038162977
Epoch:  230  	Training Loss: 0.00018187097157351673
Test Loss:  0.0001674271043157205
Valid Loss:  0.0002044973080046475
Epoch:  231  	Training Loss: 0.00018151465337723494
Test Loss:  0.0001673017250141129
Valid Loss:  0.00020426468108780682
Epoch:  232  	Training Loss: 0.00018116491264663637
Test Loss:  0.00016718465485610068
Valid Loss:  0.00020403723465278745
Epoch:  233  	Training Loss: 0.0001808211236493662
Test Loss:  0.00016707481699995697
Valid Loss:  0.00020381450303830206
Epoch:  234  	Training Loss: 0.00018048309721052647
Test Loss:  0.00016697078535798937
Valid Loss:  0.00020359538029879332
Epoch:  235  	Training Loss: 0.00018015093519352376
Test Loss:  0.00016685473383404315
Valid Loss:  0.00020337999740149826
Epoch:  236  	Training Loss: 0.00017982431745622307
Test Loss:  0.00016673312347847968
Valid Loss:  0.00020316739392001182
Epoch:  237  	Training Loss: 0.00017950276378542185
Test Loss:  0.00016660516848787665
Valid Loss:  0.00020295790454838425
Epoch:  238  	Training Loss: 0.0001791866816347465
Test Loss:  0.00016646698350086808
Valid Loss:  0.00020275085989851505
Epoch:  239  	Training Loss: 0.00017887717694975436
Test Loss:  0.00016642424452584237
Valid Loss:  0.00020262690668459982
Epoch:  240  	Training Loss: 0.00017857187776826322
Test Loss:  0.00016617891378700733
Valid Loss:  0.00020234182011336088
Epoch:  241  	Training Loss: 0.00017827097326517105
Test Loss:  0.00016615644562989473
Valid Loss:  0.0002022332773776725
Epoch:  242  	Training Loss: 0.0001779755111783743
Test Loss:  0.0001658896217122674
Valid Loss:  0.00020195081015117466
Epoch:  243  	Training Loss: 0.00017768394900485873
Test Loss:  0.0001658301189308986
Valid Loss:  0.00020184635650366545
Epoch:  244  	Training Loss: 0.00017739759641699493
Test Loss:  0.00016555114416405559
Valid Loss:  0.0002015674253925681
Epoch:  245  	Training Loss: 0.00017711520195007324
Test Loss:  0.00016549747670069337
Valid Loss:  0.00020146658062003553
Epoch:  246  	Training Loss: 0.0001768365764291957
Test Loss:  0.00016522532678209245
Valid Loss:  0.0002011897595366463
Epoch:  247  	Training Loss: 0.000176564950379543
Test Loss:  0.00016522921214345843
Valid Loss:  0.00020113956998102367
Epoch:  248  	Training Loss: 0.00017629534704610705
Test Loss:  0.00016500341007485986
Valid Loss:  0.0002009025774896145
Epoch:  249  	Training Loss: 0.00017603233573026955
Test Loss:  0.00016493839211761951
Valid Loss:  0.0002007985458476469
Epoch:  250  	Training Loss: 0.0001757762220222503
Test Loss:  0.0001646327436901629
Valid Loss:  0.00020049273734912276
Epoch:  251  	Training Loss: 0.00017552360077388585
Test Loss:  0.0001646384916966781
Valid Loss:  0.0002004415582632646
Epoch:  252  	Training Loss: 0.00017527377349324524
Test Loss:  0.0001644444273551926
Valid Loss:  0.00020024020341224968
Epoch:  253  	Training Loss: 0.00017502994160167873
Test Loss:  0.0001642975548747927
Valid Loss:  0.00020007745479233563
Epoch:  254  	Training Loss: 0.00017478992231190205
Test Loss:  0.0001641283743083477
Valid Loss:  0.00019990313739981502
Epoch:  255  	Training Loss: 0.00017455307533964515
Test Loss:  0.0001639251713640988
Valid Loss:  0.00019970886933151633
Epoch:  256  	Training Loss: 0.00017431244486942887
Test Loss:  0.0001637487148400396
Valid Loss:  0.00019953385344706476
Epoch:  257  	Training Loss: 0.00017407553968951106
Test Loss:  0.00016357410640921444
Valid Loss:  0.0001993590994970873
Epoch:  258  	Training Loss: 0.00017384198145009577
Test Loss:  0.00016340389265678823
Valid Loss:  0.00019918655743822455
Epoch:  259  	Training Loss: 0.00017361185746267438
Test Loss:  0.0001632369967410341
Valid Loss:  0.00019901531049981713
Epoch:  260  	Training Loss: 0.0001733850804157555
Test Loss:  0.000163073927978985
Valid Loss:  0.0001988456933759153
Epoch:  261  	Training Loss: 0.00017316130106337368
Test Loss:  0.00016291323117911816
Valid Loss:  0.0001986774877877906
Epoch:  262  	Training Loss: 0.00017294086865149438
Test Loss:  0.0001627551973797381
Valid Loss:  0.00019850983517244458
Epoch:  263  	Training Loss: 0.00017272292461711913
Test Loss:  0.00016259902622550726
Valid Loss:  0.00019834309932775795
Epoch:  264  	Training Loss: 0.00017250794917345047
Test Loss:  0.00016244524158537388
Valid Loss:  0.00019817694555968046
Epoch:  265  	Training Loss: 0.00017228734213858843
Test Loss:  0.00016216622316278517
Valid Loss:  0.00019794239779002964
Epoch:  266  	Training Loss: 0.00017205782933160663
Test Loss:  0.00016195741773117334
Valid Loss:  0.00019776556291617453
Epoch:  267  	Training Loss: 0.0001718316925689578
Test Loss:  0.00016174746269825846
Valid Loss:  0.0001975870254682377
Epoch:  268  	Training Loss: 0.00017160872812382877
Test Loss:  0.00016153082833625376
Valid Loss:  0.0001974127080757171
Epoch:  269  	Training Loss: 0.00017138896510004997
Test Loss:  0.00016131933080032468
Valid Loss:  0.0001972417812794447
Epoch:  270  	Training Loss: 0.0001711724471533671
Test Loss:  0.00016120659711305052
 54%|█████▍    | 271/500 [03:14<04:25,  1.16s/it] 55%|█████▍    | 273/500 [03:14<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:14<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:14<01:38,  2.25it/s] 56%|█████▌    | 279/500 [03:14<01:12,  3.03it/s] 56%|█████▌    | 281/500 [03:21<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:21<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:21<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:21<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:21<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:27<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:27<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:28<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:28<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:28<01:06,  3.02it/s] 60%|██████    | 301/500 [03:34<03:52,  1.17s/it] 61%|██████    | 303/500 [03:34<02:45,  1.19it/s] 61%|██████    | 305/500 [03:34<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:34<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:35<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:41<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:41<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:41<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:41<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:42<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:48<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:48<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:48<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:48<01:18,  2.19it/s] 66%|██████▌   | 329/500 [03:49<00:57,  2.95it/s] 66%|██████▌   | 331/500 [03:55<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:55<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:55<01:41,  1.62it/s]Valid Loss:  0.00019716656242962927
Epoch:  271  	Training Loss: 0.0001709609932731837
Test Loss:  0.00016089144628494978
Valid Loss:  0.00019690801855176687
Epoch:  272  	Training Loss: 0.00017074949573725462
Test Loss:  0.00016080186469480395
Valid Loss:  0.000196849083295092
Epoch:  273  	Training Loss: 0.0001705439353827387
Test Loss:  0.00016049382975324988
Valid Loss:  0.0001965929550351575
Epoch:  274  	Training Loss: 0.0001703381130937487
Test Loss:  0.00016041142225731164
Valid Loss:  0.00019653777417261153
Epoch:  275  	Training Loss: 0.0001701375440461561
Test Loss:  0.00016011029947549105
Valid Loss:  0.00019628385780379176
Epoch:  276  	Training Loss: 0.00016993749886751175
Test Loss:  0.0001600338873686269
Valid Loss:  0.0001962310343515128
Epoch:  277  	Training Loss: 0.00016974117897916585
Test Loss:  0.00015970674576237798
Valid Loss:  0.0001959788496606052
Epoch:  278  	Training Loss: 0.00016954366583377123
Test Loss:  0.00015955689013935626
Valid Loss:  0.00019590489682741463
Epoch:  279  	Training Loss: 0.00016934347513597459
Test Loss:  0.00015920988516882062
Valid Loss:  0.0001956511550815776
Epoch:  280  	Training Loss: 0.00016914776642806828
Test Loss:  0.00015908744535408914
Valid Loss:  0.0001955963234649971
Epoch:  281  	Training Loss: 0.00016895179578568786
Test Loss:  0.00015882337174843997
Valid Loss:  0.00019543810049071908
Epoch:  282  	Training Loss: 0.00016875927394721657
Test Loss:  0.00015848597104195505
Valid Loss:  0.0001951989543158561
Epoch:  283  	Training Loss: 0.00016856967704370618
Test Loss:  0.00015835536760278046
Valid Loss:  0.0001951460144482553
Epoch:  284  	Training Loss: 0.00016838106967043132
Test Loss:  0.00015814200742170215
Valid Loss:  0.00019504543161019683
Epoch:  285  	Training Loss: 0.00016819687152747065
Test Loss:  0.00015787858865223825
Valid Loss:  0.00019490381237119436
Epoch:  286  	Training Loss: 0.00016801009769551456
Test Loss:  0.00015754319611005485
Valid Loss:  0.00019472406711429358
Epoch:  287  	Training Loss: 0.00016781012527644634
Test Loss:  0.0001572577457409352
Valid Loss:  0.000194583524717018
Epoch:  288  	Training Loss: 0.00016761317965574563
Test Loss:  0.000156898851855658
Valid Loss:  0.00019436510046944022
Epoch:  289  	Training Loss: 0.0001674195664236322
Test Loss:  0.00015667444677092135
Valid Loss:  0.00019426362996455282
Epoch:  290  	Training Loss: 0.0001672280195634812
Test Loss:  0.00015646935207769275
Valid Loss:  0.00019418951706029475
Epoch:  291  	Training Loss: 0.00016703983419574797
Test Loss:  0.00015620730118826032
Valid Loss:  0.00019406958017498255
Epoch:  292  	Training Loss: 0.00016685144510120153
Test Loss:  0.00015581345360260457
Valid Loss:  0.0001938734931172803
Epoch:  293  	Training Loss: 0.00016665065777488053
Test Loss:  0.00015551171964034438
Valid Loss:  0.0001937529887072742
Epoch:  294  	Training Loss: 0.00016645307186990976
Test Loss:  0.00015519838780164719
Valid Loss:  0.00019361880549695343
Epoch:  295  	Training Loss: 0.00016625864373054355
Test Loss:  0.00015489532961510122
Valid Loss:  0.00019349029753357172
Epoch:  296  	Training Loss: 0.00016606677672825754
Test Loss:  0.00015459969290532172
Valid Loss:  0.00019336480181664228
Epoch:  297  	Training Loss: 0.00016587768914178014
Test Loss:  0.00015430993516929448
Valid Loss:  0.00019323811284266412
Epoch:  298  	Training Loss: 0.0001656910462770611
Test Loss:  0.00015402588178403676
Valid Loss:  0.00019310045172460377
Epoch:  299  	Training Loss: 0.00016550254076719284
Test Loss:  0.00015370818437077105
Valid Loss:  0.0001929429272422567
Epoch:  300  	Training Loss: 0.00016530930588487536
Test Loss:  0.00015341833932325244
Valid Loss:  0.00019280609558336437
Epoch:  301  	Training Loss: 0.00016511857393197715
Test Loss:  0.0001531313464511186
Valid Loss:  0.0001926685799844563
Epoch:  302  	Training Loss: 0.00016492875874973834
Test Loss:  0.00015273092139977962
Valid Loss:  0.00019246898591518402
Epoch:  303  	Training Loss: 0.0001647122553549707
Test Loss:  0.00015229027485474944
Valid Loss:  0.00019226560834795237
Epoch:  304  	Training Loss: 0.00016448451788164675
Test Loss:  0.0001519257784821093
Valid Loss:  0.00019211994367651641
Epoch:  305  	Training Loss: 0.00016426120419055223
Test Loss:  0.00015156743756961077
Valid Loss:  0.00019197451183572412
Epoch:  306  	Training Loss: 0.00016404176130890846
Test Loss:  0.0001512218441348523
Valid Loss:  0.00019183533731848001
Epoch:  307  	Training Loss: 0.00016382522881031036
Test Loss:  0.00015084909682627767
Valid Loss:  0.0001916795881697908
Epoch:  308  	Training Loss: 0.00016360176960006356
Test Loss:  0.0001505081745563075
Valid Loss:  0.00019154552137479186
Epoch:  309  	Training Loss: 0.00016337598208338022
Test Loss:  0.0001501368242315948
Valid Loss:  0.00019139336654916406
Epoch:  310  	Training Loss: 0.0001631468185223639
Test Loss:  0.0001497971679782495
Valid Loss:  0.00019126223924104124
Epoch:  311  	Training Loss: 0.0001629210019018501
Test Loss:  0.00014946365263313055
Valid Loss:  0.00019113293092232198
Epoch:  312  	Training Loss: 0.00016269838670268655
Test Loss:  0.00014913776249159127
Valid Loss:  0.00019100584904663265
Epoch:  313  	Training Loss: 0.00016247753228526562
Test Loss:  0.0001487837580498308
Valid Loss:  0.00019086174143012613
Epoch:  314  	Training Loss: 0.00016224742284975946
Test Loss:  0.00014845779514871538
Valid Loss:  0.0001907369151012972
Epoch:  315  	Training Loss: 0.00016201467951759696
Test Loss:  0.0001481007202528417
Valid Loss:  0.00019059309852309525
Epoch:  316  	Training Loss: 0.0001617755915503949
Test Loss:  0.00014777242904528975
Valid Loss:  0.0001904690871015191
Epoch:  317  	Training Loss: 0.0001615394139662385
Test Loss:  0.0001474487071391195
Valid Loss:  0.00019034543947782367
Epoch:  318  	Training Loss: 0.00016130601579789072
Test Loss:  0.00014713165001012385
Valid Loss:  0.00019022286869585514
Epoch:  319  	Training Loss: 0.00016107512055896223
Test Loss:  0.00014681975881103426
Valid Loss:  0.00019010264077223837
Epoch:  320  	Training Loss: 0.0001608450256753713
Test Loss:  0.0001464790548197925
Valid Loss:  0.00018996403377968818
Epoch:  321  	Training Loss: 0.00016060343477874994
Test Loss:  0.00014616374392062426
Valid Loss:  0.0001898434420581907
Epoch:  322  	Training Loss: 0.0001603646669536829
Test Loss:  0.0001458516053389758
Valid Loss:  0.00018972231191582978
Epoch:  323  	Training Loss: 0.0001601230469532311
Test Loss:  0.00014543745783157647
Valid Loss:  0.0001895443710964173
Epoch:  324  	Training Loss: 0.00015987124061211944
Test Loss:  0.0001451019779779017
Valid Loss:  0.00018942588940262794
Epoch:  325  	Training Loss: 0.00015962275210767984
Test Loss:  0.0001447582762921229
Valid Loss:  0.00018930411897599697
Epoch:  326  	Training Loss: 0.00015937763964757323
Test Loss:  0.0001444133959012106
Valid Loss:  0.00018916817498393357
Epoch:  327  	Training Loss: 0.0001591354375705123
Test Loss:  0.0001440752821508795
Valid Loss:  0.00018903380259871483
Epoch:  328  	Training Loss: 0.00015889626229181886
Test Loss:  0.00014374349848367274
Valid Loss:  0.00018890108913183212
Epoch:  329  	Training Loss: 0.00015865970635786653
Test Loss:  0.00014341739006340504
Valid Loss:  0.00018876951071433723
Epoch:  330  	Training Loss: 0.00015842559514567256
Test Loss:  0.00014309596735984087
Valid Loss:  0.00018863864534068853
Epoch:  331  	Training Loss: 0.0001581944088684395
Test Loss:  0.0001427793176844716
Valid Loss:  0.000188508493010886
Epoch:  332  	Training Loss: 0.00015796558000147343
Test Loss:  0.00014246723731048405
Valid Loss:  0.00018837914103642106
Epoch:  333  	Training Loss: 0.00015773915220052004
Test Loss:  0.00014215933333616704
Valid Loss:  0.00018825012375600636
Epoch:  334  	Training Loss: 0.0001575151545694098
Test Loss:  0.00014185468899086118
Valid Loss:  0.0001881215430330485
Epoch:  335  	Training Loss: 0.0001572934997966513
Test Loss:  0.00014155401731841266
Valid Loss:  0.0001879929332062602
Epoch:  336  	Training Loss: 0.00015707395505160093
Test Loss:  0.00014125651796348393
Valid Loss:  0.00018786455621011555
Epoch:  337  	Training Loss: 0.00015685679682064801
Test Loss:  0.0001409625547239557
Valid Loss:   67%|██████▋   | 337/500 [03:55<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:55<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:02<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:02<02:12,  1.18it/s] 69%|██████▉   | 345/500 [04:02<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:02<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:02<00:50,  3.01it/s] 70%|███████   | 351/500 [04:08<02:54,  1.17s/it] 71%|███████   | 353/500 [04:09<02:03,  1.19it/s] 71%|███████   | 355/500 [04:09<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:09<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:09<00:46,  3.03it/s] 72%|███████▏  | 361/500 [04:15<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:15<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:16<01:22,  1.65it/s] 73%|███████▎  | 367/500 [04:16<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:16<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:22<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:22<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:22<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:23<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:23<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:29<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:29<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:29<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:29<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:29<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:36<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:36<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:36<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:36<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:36<00:33,  2.99it/s] 80%|████████  | 401/500 [04:43<01:55,  1.16s/it] 81%|████████  | 403/500 [04:43<01:21,  1.20it/s]0.0001877357135526836
Epoch:  338  	Training Loss: 0.00015664153033867478
Test Loss:  0.0001406711235176772
Valid Loss:  0.00018760723469313234
Epoch:  339  	Training Loss: 0.00015642846119590104
Test Loss:  0.00014038299559615552
Valid Loss:  0.00018747869762592018
Epoch:  340  	Training Loss: 0.0001562125253258273
Test Loss:  0.00013999892689753324
Valid Loss:  0.0001872956199804321
Epoch:  341  	Training Loss: 0.00015598666504956782
Test Loss:  0.0001396775769535452
Valid Loss:  0.00018715910846367478
Epoch:  342  	Training Loss: 0.00015575438737869263
Test Loss:  0.00013919896446168423
Valid Loss:  0.00018691582954488695
Epoch:  343  	Training Loss: 0.0001554871560074389
Test Loss:  0.00013883510837331414
Valid Loss:  0.00018676150648389012
Epoch:  344  	Training Loss: 0.00015522251487709582
Test Loss:  0.00013844360364601016
Valid Loss:  0.00018658539920579642
Epoch:  345  	Training Loss: 0.00015494966646656394
Test Loss:  0.00013808166841045022
Valid Loss:  0.00018642838404048234
Epoch:  346  	Training Loss: 0.0001546803250676021
Test Loss:  0.00013772737293038517
Valid Loss:  0.0001862731878645718
Epoch:  347  	Training Loss: 0.0001544094702694565
Test Loss:  0.0001373545965179801
Valid Loss:  0.00018610341066960245
Epoch:  348  	Training Loss: 0.00015413039363920689
Test Loss:  0.00013698203838430345
Valid Loss:  0.0001859336334746331
Epoch:  349  	Training Loss: 0.00015384098514914513
Test Loss:  0.00013663315621670336
Valid Loss:  0.00018576635920908302
Epoch:  350  	Training Loss: 0.00015355515643022954
Test Loss:  0.0001362900948151946
Valid Loss:  0.00018558149167802185
Epoch:  351  	Training Loss: 0.00015326736320275813
Test Loss:  0.00013586643035523593
Valid Loss:  0.0001853541616583243
Epoch:  352  	Training Loss: 0.00015295730554498732
Test Loss:  0.00013548042625188828
Valid Loss:  0.0001851545093813911
Epoch:  353  	Training Loss: 0.00015264074318110943
Test Loss:  0.0001351157552562654
Valid Loss:  0.00018496831762604415
Epoch:  354  	Training Loss: 0.00015232324949465692
Test Loss:  0.0001346703211311251
Valid Loss:  0.00018473545787855983
Epoch:  355  	Training Loss: 0.00015199306653812528
Test Loss:  0.00013430204126052558
Valid Loss:  0.00018456093675922602
Epoch:  356  	Training Loss: 0.00015165877994149923
Test Loss:  0.0001338896108791232
Valid Loss:  0.00018434754747431725
Epoch:  357  	Training Loss: 0.00015130703104659915
Test Loss:  0.00013352172391023487
Valid Loss:  0.00018416544480714947
Epoch:  358  	Training Loss: 0.0001509605790488422
Test Loss:  0.00013316080730874091
Valid Loss:  0.00018398422980681062
Epoch:  359  	Training Loss: 0.000150618827319704
Test Loss:  0.00013280977145768702
Valid Loss:  0.00018380660912953317
Epoch:  360  	Training Loss: 0.00015028190682642162
Test Loss:  0.00013246735034044832
Valid Loss:  0.00018363114213570952
Epoch:  361  	Training Loss: 0.00014994779485277832
Test Loss:  0.00013211066834628582
Valid Loss:  0.0001834413269534707
Epoch:  362  	Training Loss: 0.00014960355474613607
Test Loss:  0.00013177614891901612
Valid Loss:  0.00018326510326005518
Epoch:  363  	Training Loss: 0.0001492637093178928
Test Loss:  0.0001314483815804124
Valid Loss:  0.00018309010192751884
Epoch:  364  	Training Loss: 0.00014892788021825254
Test Loss:  0.00013112666783854365
Valid Loss:  0.00018291643937118351
Epoch:  365  	Training Loss: 0.00014859634393360466
Test Loss:  0.00013081160432193428
Valid Loss:  0.00018274413014296442
Epoch:  366  	Training Loss: 0.00014826683036517352
Test Loss:  0.0001304226170759648
Valid Loss:  0.00018252911104355007
Epoch:  367  	Training Loss: 0.00014792443835176528
Test Loss:  0.00013010494876652956
Valid Loss:  0.00018236685718875378
Epoch:  368  	Training Loss: 0.00014758696488570422
Test Loss:  0.0001297892304137349
Valid Loss:  0.00018220185302197933
Epoch:  369  	Training Loss: 0.0001472531585022807
Test Loss:  0.00012946163769811392
Valid Loss:  0.00018202447972726077
Epoch:  370  	Training Loss: 0.00014691005344502628
Test Loss:  0.0001291548105655238
Valid Loss:  0.00018185918452218175
Epoch:  371  	Training Loss: 0.00014656459097750485
Test Loss:  0.0001288331113755703
Valid Loss:  0.0001816789445001632
Epoch:  372  	Training Loss: 0.00014621258014813066
Test Loss:  0.00012851427891291678
Valid Loss:  0.00018149736570194364
Epoch:  373  	Training Loss: 0.0001458442711737007
Test Loss:  0.00012819451512768865
Valid Loss:  0.00018131130491383374
Epoch:  374  	Training Loss: 0.00014546341844834387
Test Loss:  0.00012787728337571025
Valid Loss:  0.000181124807568267
Epoch:  375  	Training Loss: 0.00014507517335005105
Test Loss:  0.00012757294462062418
Valid Loss:  0.00018094482948072255
Epoch:  376  	Training Loss: 0.00014468966401182115
Test Loss:  0.00012725804117508233
Valid Loss:  0.00018075329717248678
Epoch:  377  	Training Loss: 0.00014429425937123597
Test Loss:  0.00012696169142145663
Valid Loss:  0.00018057264969684184
Epoch:  378  	Training Loss: 0.00014390354044735432
Test Loss:  0.00012667079863604158
Valid Loss:  0.00018039369024336338
Epoch:  379  	Training Loss: 0.00014351733261719346
Test Loss:  0.0001263555750483647
Valid Loss:  0.00018021650612354279
Epoch:  380  	Training Loss: 0.00014313557767309248
Test Loss:  0.00012603959476109594
Valid Loss:  0.00018004074809141457
Epoch:  381  	Training Loss: 0.0001427580282324925
Test Loss:  0.00012572976993396878
Valid Loss:  0.00017986597958952188
Epoch:  382  	Training Loss: 0.00014238490257412195
Test Loss:  0.00012542650802060962
Valid Loss:  0.00017969298642128706
Epoch:  383  	Training Loss: 0.00014201586600393057
Test Loss:  0.00012512868852354586
Valid Loss:  0.00017952118651010096
Epoch:  384  	Training Loss: 0.0001416508894180879
Test Loss:  0.00012483638420235366
Valid Loss:  0.00017935021605808288
Epoch:  385  	Training Loss: 0.0001412900019204244
Test Loss:  0.00012452751980163157
Valid Loss:  0.00017917988589033484
Epoch:  386  	Training Loss: 0.0001409331161994487
Test Loss:  0.00012421736028045416
Valid Loss:  0.00017901096725836396
Epoch:  387  	Training Loss: 0.00014058040687814355
Test Loss:  0.00012391152267809957
Valid Loss:  0.00017884233966469765
Epoch:  388  	Training Loss: 0.0001402315974701196
Test Loss:  0.0001236111856997013
Valid Loss:  0.0001786748180165887
Epoch:  389  	Training Loss: 0.0001398865133523941
Test Loss:  0.00012331514153629541
Valid Loss:  0.00017850808217190206
Epoch:  390  	Training Loss: 0.00013954497990198433
Test Loss:  0.00012302384129725397
Valid Loss:  0.00017834182654041797
Epoch:  391  	Training Loss: 0.0001392071135342121
Test Loss:  0.00012273671745788306
Valid Loss:  0.00017817504703998566
Epoch:  392  	Training Loss: 0.00013887285604141653
Test Loss:  0.00012245363905094564
Valid Loss:  0.00017800700152292848
Epoch:  393  	Training Loss: 0.00013854193093720824
Test Loss:  0.00012217510084155947
Valid Loss:  0.00017783975636120886
Epoch:  394  	Training Loss: 0.00013821435277350247
Test Loss:  0.0001218998950207606
Valid Loss:  0.00017767297686077654
Epoch:  395  	Training Loss: 0.00013788453361485153
Test Loss:  0.0001215986703755334
Valid Loss:  0.00017749580729287118
Epoch:  396  	Training Loss: 0.0001375515275867656
Test Loss:  0.00012130295363022014
Valid Loss:  0.0001773271942511201
Epoch:  397  	Training Loss: 0.00013722165022045374
Test Loss:  0.00012100976891815662
Valid Loss:  0.00017715942522045225
Epoch:  398  	Training Loss: 0.0001368943485431373
Test Loss:  0.00012071912351530045
Valid Loss:  0.00017699081217870116
Epoch:  399  	Training Loss: 0.00013657056842930615
Test Loss:  0.0001204330546897836
Valid Loss:  0.0001768234942574054
Epoch:  400  	Training Loss: 0.0001362498151138425
Test Loss:  0.0001201506529469043
Valid Loss:  0.00017665652558207512
Epoch:  401  	Training Loss: 0.00013593232142738998
Test Loss:  0.00011987167818006128
Valid Loss:  0.0001764906628523022
Epoch:  402  	Training Loss: 0.0001356099674012512
Test Loss:  0.00011956692469539121
Valid Loss:  0.0001763054315233603
Epoch:  403  	Training Loss: 0.00013527704868465662
Test Loss:  0.0001192847266793251
Valid Loss:  0.00017613518866710365
Epoch:  404  	Training Loss: 0.0001349474478047341
Test Loss:  0.00011900501704076305
Valid Loss:   81%|████████  | 405/500 [04:43<00:57,  1.66it/s] 81%|████████▏ | 407/500 [04:43<00:41,  2.26it/s] 82%|████████▏ | 409/500 [04:43<00:29,  3.04it/s] 82%|████████▏ | 411/500 [04:49<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:49<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:50<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:50<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:50<00:27,  2.98it/s] 84%|████████▍ | 421/500 [04:56<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:56<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:56<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:57<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:57<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:03<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:03<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:03<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:03<00:28,  2.25it/s] 88%|████████▊ | 439/500 [05:04<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:10<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:10<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:10<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:10<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:10<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:17<00:57,  1.16s/it] 91%|█████████ | 453/500 [05:17<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:17<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:17<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:23<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:24<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:24<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:24<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:24<00:10,  3.00it/s]0.00017596481484360993
Epoch:  405  	Training Loss: 0.00013462093193084002
Test Loss:  0.0001187292582471855
Valid Loss:  0.00017579567793291062
Epoch:  406  	Training Loss: 0.00013429803948383778
Test Loss:  0.00011845697008538991
Valid Loss:  0.00017562728316988796
Epoch:  407  	Training Loss: 0.00013397652946878225
Test Loss:  0.00011817691847681999
Valid Loss:  0.00017545183072797954
Epoch:  408  	Training Loss: 0.00013364999904297292
Test Loss:  0.0001179081664304249
Valid Loss:  0.00017528346506878734
Epoch:  409  	Training Loss: 0.00013332637900020927
Test Loss:  0.00011764293594751507
Valid Loss:  0.0001751151867210865
Epoch:  410  	Training Loss: 0.0001330059312749654
Test Loss:  0.00011738155444618315
Valid Loss:  0.00017494833446107805
Epoch:  411  	Training Loss: 0.00013268855400383472
Test Loss:  0.00011712309060385451
Valid Loss:  0.00017478212248533964
Epoch:  412  	Training Loss: 0.00013237437815405428
Test Loss:  0.00011686976358760148
Valid Loss:  0.00017461710376664996
Epoch:  413  	Training Loss: 0.00013206308358348906
Test Loss:  0.00011660506424959749
Valid Loss:  0.00017445298726670444
Epoch:  414  	Training Loss: 0.00013175461208447814
Test Loss:  0.00011634087422862649
Valid Loss:  0.00017428991850465536
Epoch:  415  	Training Loss: 0.00013144902186468244
Test Loss:  0.00011607998749241233
Valid Loss:  0.0001741277374094352
Epoch:  416  	Training Loss: 0.0001311461819568649
Test Loss:  0.00011582241859287024
Valid Loss:  0.000173965934664011
Epoch:  417  	Training Loss: 0.00013084604870527983
Test Loss:  0.00011556809477042407
Valid Loss:  0.0001738049031700939
Epoch:  418  	Training Loss: 0.00013054866576567292
Test Loss:  0.0001153171033365652
Valid Loss:  0.00017364436644129455
Epoch:  419  	Training Loss: 0.00013025393127463758
Test Loss:  0.000115069022285752
Valid Loss:  0.00017348496476188302
Epoch:  420  	Training Loss: 0.0001299615832976997
Test Loss:  0.00011482428817544132
Valid Loss:  0.00017332573770545423
Epoch:  421  	Training Loss: 0.00012967204384040087
Test Loss:  0.00011456758511485532
Valid Loss:  0.000173167311004363
Epoch:  422  	Training Loss: 0.0001293844252359122
Test Loss:  0.00011430395534262061
Valid Loss:  0.00017300323816016316
Epoch:  423  	Training Loss: 0.00012909257202409208
Test Loss:  0.0001140487875090912
Valid Loss:  0.00017284414207097143
Epoch:  424  	Training Loss: 0.0001288034109165892
Test Loss:  0.00011379606439732015
Valid Loss:  0.00017268481315113604
Epoch:  425  	Training Loss: 0.0001285166945308447
Test Loss:  0.00011354626622051
Valid Loss:  0.00017252608085982502
Epoch:  426  	Training Loss: 0.0001282322482438758
Test Loss:  0.0001132995166699402
Valid Loss:  0.00017236816347576678
Epoch:  427  	Training Loss: 0.00012794924259651452
Test Loss:  0.00011304618965368718
Valid Loss:  0.00017220564768649638
Epoch:  428  	Training Loss: 0.0001276631373912096
Test Loss:  0.00011280082981102169
Valid Loss:  0.00017204722098540515
Epoch:  429  	Training Loss: 0.00012737933138851076
Test Loss:  0.00011256049037910998
Valid Loss:  0.00017188896890729666
Epoch:  430  	Training Loss: 0.00012709808652289212
Test Loss:  0.00011232389806536958
Valid Loss:  0.00017173172091133893
Epoch:  431  	Training Loss: 0.00012681915541179478
Test Loss:  0.00011208985961275175
Valid Loss:  0.00017157501133624464
Epoch:  432  	Training Loss: 0.00012654252350330353
Test Loss:  0.00011185838957317173
Valid Loss:  0.0001714192476356402
Epoch:  433  	Training Loss: 0.00012626813258975744
Test Loss:  0.00011162999726366252
Valid Loss:  0.0001712641242193058
Epoch:  434  	Training Loss: 0.00012599601177498698
Test Loss:  0.00011140399146825075
Valid Loss:  0.00017110946646425873
Epoch:  435  	Training Loss: 0.00012572632113005966
Test Loss:  0.00011118060501758009
Valid Loss:  0.00017095549264922738
Epoch:  436  	Training Loss: 0.00012545872596092522
Test Loss:  0.00011095995432697237
Valid Loss:  0.0001708021736703813
Epoch:  437  	Training Loss: 0.00012519316805992275
Test Loss:  0.0001107417992898263
Valid Loss:  0.00017064920393750072
Epoch:  438  	Training Loss: 0.00012492976384237409
Test Loss:  0.00011052583431592211
Valid Loss:  0.00017049677262548357
Epoch:  439  	Training Loss: 0.0001246684551006183
Test Loss:  0.0001103125250665471
Valid Loss:  0.00017034496704582125
Epoch:  440  	Training Loss: 0.00012440915452316403
Test Loss:  0.00011010542948497459
Valid Loss:  0.00017019358347170055
Epoch:  441  	Training Loss: 0.00012415194942150265
Test Loss:  0.00010990032023983076
Valid Loss:  0.00017004262190312147
Epoch:  442  	Training Loss: 0.00012389683979563415
Test Loss:  0.00010969681898131967
Valid Loss:  0.00016989116556942463
Epoch:  443  	Training Loss: 0.00012364389840513468
Test Loss:  0.00010949668649118394
Valid Loss:  0.00016974103346001357
Epoch:  444  	Training Loss: 0.0001233939838130027
Test Loss:  0.00010929496784228832
Valid Loss:  0.00016958918422460556
Epoch:  445  	Training Loss: 0.00012314709601923823
Test Loss:  0.00010909942648140714
Valid Loss:  0.00016943963419180363
Epoch:  446  	Training Loss: 0.00012290242011658847
Test Loss:  0.00010890299017773941
Valid Loss:  0.00016928950208239257
Epoch:  447  	Training Loss: 0.00012266157136764377
Test Loss:  0.00010870640107896179
Valid Loss:  0.0001691427023615688
Epoch:  448  	Training Loss: 0.00012242257071193308
Test Loss:  0.00010851110710063949
Valid Loss:  0.00016899610636755824
Epoch:  449  	Training Loss: 0.00012218538904562593
Test Loss:  0.00010831819236045703
Valid Loss:  0.0001688500342424959
Epoch:  450  	Training Loss: 0.00012194983719382435
Test Loss:  0.0001081267764675431
Valid Loss:  0.000168703991221264
Epoch:  451  	Training Loss: 0.00012171611160738394
Test Loss:  0.00010793757974170148
Valid Loss:  0.00016855885041877627
Epoch:  452  	Training Loss: 0.00012148343375883996
Test Loss:  0.00010774339898489416
Valid Loss:  0.00016841012984514236
Epoch:  453  	Training Loss: 0.00012124892236897722
Test Loss:  0.00010754928371170536
Valid Loss:  0.00016826106002554297
Epoch:  454  	Training Loss: 0.00012101410538889468
Test Loss:  0.00010736015246948227
Valid Loss:  0.0001681142020970583
Epoch:  455  	Training Loss: 0.00012078082363586873
Test Loss:  0.00010717255645431578
Valid Loss:  0.00016796804266050458
Epoch:  456  	Training Loss: 0.00012054935359628871
Test Loss:  0.00010698699043132365
Valid Loss:  0.0001678222615737468
Epoch:  457  	Training Loss: 0.00012031960795866325
Test Loss:  0.0001068026467692107
Valid Loss:  0.00016767473425716162
Epoch:  458  	Training Loss: 0.00012009141210000962
Test Loss:  0.00010662073327694088
Valid Loss:  0.00016752412193454802
Epoch:  459  	Training Loss: 0.00011986463505309075
Test Loss:  0.00010643602581694722
Valid Loss:  0.00016737145779188722
Epoch:  460  	Training Loss: 0.00011963707220274955
Test Loss:  0.00010625433060340583
Valid Loss:  0.00016722071450203657
Epoch:  461  	Training Loss: 0.00011941062257392332
Test Loss:  0.00010607019066810608
Valid Loss:  0.00016706762835383415
Epoch:  462  	Training Loss: 0.00011918369273189455
Test Loss:  0.00010588920849841088
Valid Loss:  0.00016691620112396777
Epoch:  463  	Training Loss: 0.00011895819625351578
Test Loss:  0.0001057099289027974
Valid Loss:  0.00016676544328220189
Epoch:  464  	Training Loss: 0.00011873434414155781
Test Loss:  0.00010553222091402858
Valid Loss:  0.00016661513654980808
Epoch:  465  	Training Loss: 0.00011851201998069882
Test Loss:  0.00010535652108956128
Valid Loss:  0.0001664654992055148
Epoch:  466  	Training Loss: 0.00011829015420516953
Test Loss:  0.00010517725604586303
Valid Loss:  0.0001663134025875479
Epoch:  467  	Training Loss: 0.00011806872498709708
Test Loss:  0.00010500190546736121
Valid Loss:  0.00016616351786069572
Epoch:  468  	Training Loss: 0.00011784861271735281
Test Loss:  0.0001048283011186868
Valid Loss:  0.00016601390962023288
Epoch:  469  	Training Loss: 0.00011763010115828365
Test Loss:  0.00010465595551067963
Valid Loss:  0.0001658647961448878
Epoch:  470  	Training Loss: 0.00011741300841094926
Test Loss:  0.00010448503599036485
Valid Loss:  0.00016571610467508435
Epoch:  471  	Training Loss: 0.00011719755275407806
Test Loss:  0.00010431610280647874
 94%|█████████▍| 471/500 [05:30<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:30<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:31<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:31<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:37<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:37<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:38<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:44<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:44<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:44<00:00,  2.96it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
Valid Loss:  0.00016556834452785552
Epoch:  472  	Training Loss: 0.0001169834504253231
Test Loss:  0.00010414827556814998
Valid Loss:  0.0001654207444516942
Epoch:  473  	Training Loss: 0.00011677067959681153
Test Loss:  0.0001039820781443268
Valid Loss:  0.00016527384286746383
Epoch:  474  	Training Loss: 0.00011655914568109438
Test Loss:  0.00010380792082287371
Valid Loss:  0.00016512227011844516
Epoch:  475  	Training Loss: 0.00011635005648713559
Test Loss:  0.00010364419722463936
Valid Loss:  0.0001649760961299762
Epoch:  476  	Training Loss: 0.00011614218237809837
Test Loss:  0.00010348125215386972
Valid Loss:  0.00016483005310874432
Epoch:  477  	Training Loss: 0.00011593574163271114
Test Loss:  0.0001033196022035554
Valid Loss:  0.00016468478133901954
Epoch:  478  	Training Loss: 0.00011573065421544015
Test Loss:  0.00010315930558135733
Valid Loss:  0.00016453975695185363
Epoch:  479  	Training Loss: 0.00011552673822734505
Test Loss:  0.00010300094436388463
Valid Loss:  0.00016439546016044915
Epoch:  480  	Training Loss: 0.00011532409553183243
Test Loss:  0.00010284333257004619
Valid Loss:  0.00016425162903033197
Epoch:  481  	Training Loss: 0.0001151227843365632
Test Loss:  0.00010268735059071332
Valid Loss:  0.00016410808893851936
Epoch:  482  	Training Loss: 0.00011492274643387645
Test Loss:  0.0001025322126224637
Valid Loss:  0.00016396466526202857
Epoch:  483  	Training Loss: 0.00011472444020910189
Test Loss:  0.00010237198148388416
Valid Loss:  0.00016381818568333983
Epoch:  484  	Training Loss: 0.00011452854232629761
Test Loss:  0.00010221719276160002
Valid Loss:  0.00016367415082640946
Epoch:  485  	Training Loss: 0.00011433247709646821
Test Loss:  0.00010206348088104278
Valid Loss:  0.00016352934471797198
Epoch:  486  	Training Loss: 0.00011413747415645048
Test Loss:  0.00010191064939135686
Valid Loss:  0.00016338471323251724
Epoch:  487  	Training Loss: 0.0001139436280936934
Test Loss:  0.00010175924398936331
Valid Loss:  0.00016324096941389143
Epoch:  488  	Training Loss: 0.00011375091708032414
Test Loss:  0.00010160828242078424
Valid Loss:  0.0001630972692510113
Epoch:  489  	Training Loss: 0.00011355937749613076
Test Loss:  0.00010145895066671073
Valid Loss:  0.00016295479144901037
Epoch:  490  	Training Loss: 0.00011336899478919804
Test Loss:  0.00010131036106031388
Valid Loss:  0.00016281200805678964
Epoch:  491  	Training Loss: 0.0001131795288529247
Test Loss:  0.00010116287012351677
Valid Loss:  0.00016266974853351712
Epoch:  492  	Training Loss: 0.00011299131438136101
Test Loss:  0.0001010162231978029
Valid Loss:  0.0001625283621251583
Epoch:  493  	Training Loss: 0.00011280413309577852
Test Loss:  0.00010087092232424766
Valid Loss:  0.00016238700482062995
Epoch:  494  	Training Loss: 0.00011261764302616939
Test Loss:  0.00010072403529193252
Valid Loss:  0.00016224478895310313
Epoch:  495  	Training Loss: 0.00011243200424360111
Test Loss:  0.00010057877807412297
Valid Loss:  0.00016210332978516817
Epoch:  496  	Training Loss: 0.0001122475805459544
Test Loss:  0.00010043437941931188
Valid Loss:  0.0001619619579287246
Epoch:  497  	Training Loss: 0.0001120638771681115
Test Loss:  0.00010029091936303303
Valid Loss:  0.0001618211535969749
Epoch:  498  	Training Loss: 0.00011188139615114778
Test Loss:  0.00010014729923568666
Valid Loss:  0.0001616802328499034
Epoch:  499  	Training Loss: 0.00011170000652782619
Test Loss:  0.00010000601469073445
Valid Loss:  0.00016154003969859332
Epoch:  500  	Training Loss: 0.0001115196428145282
Test Loss:  9.986564691644162e-05
Valid Loss:  0.0001614005450392142
seed is  3
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:35,  6.32s/it]  1%|          | 3/500 [00:06<14:00,  1.69s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:17,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.85it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 19/500 [00:24<02:41,  2.97it/s]  4%|▍         | 21/500 [00:26<17:08,  2.15s/it]  5%|▍         | 23/500 [00:26<12:02,  1.51s/it]  5%|▌         | 25/500 [00:32<15:57,  2.01s/it]  5%|▌         | 27/500 [00:32<11:14,  1.43s/it]  6%|▌         | 29/500 [00:32<07:58,  1.02s/it]  6%|▌         | 29/500 [00:44<07:58,  1.02s/it]  6%|▌         | 31/500 [00:45<20:06,  2.57s/it]  7%|▋         | 33/500 [00:45<14:10,  1.82s/it]  7%|▋         | 35/500 [00:51<17:17,  2.23s/it]  7%|▋         | 37/500 [00:51<12:13,  1.58s/it]  8%|▊         | 39/500 [00:52<08:39,  1.13s/it]  8%|▊         | 41/500 [01:04<20:05,  2.63s/it]  9%|▊         | 43/500 [01:04<14:11,  1.86s/it]  9%|▉         | 45/500 [01:10<17:05,  2.25s/it]  9%|▉         | 47/500 [01:10<12:05,  1.60s/it] 10%|▉         | 49/500 [01:11<08:34,  1.14s/it] 10%|█         | 51/500 [01:23<20:09,  2.69s/it] 11%|█         | 53/500 [01:23<14:14,  1.91s/it] 11%|█         | 55/500 [01:30<17:17,  2.33s/it] 11%|█▏        | 57/500 [01:30<12:14,  1.66s/it] 12%|█▏        | 59/500 [01:30<08:42,  1.19s/it] 12%|█▏        | 60/500 [01:37<15:48,  2.16s/it] 12%|█▏        | 61/500 [01:44<22:16,  3.04s/it] 13%|█▎        | 63/500 [01:44<14:15,  1.96s/it]Epoch:  1  	Training Loss: 0.09565693140029907
Test Loss:  22.451217651367188
Valid Loss:  21.76800537109375
Epoch:  2  	Training Loss: 22.037845611572266
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  3  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  4  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  5  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  6  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  7  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  8  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  9  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  10  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  11  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  12  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  13  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  14  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  15  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  16  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  17  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  18  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  19  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  20  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  22  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  23  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  24  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  25  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  27  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  28  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  29  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  30  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  32  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  33  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  34  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  35  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  37  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  38  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  39  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  40  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  42  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  43  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  44  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  45  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  47  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  48  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  49  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  50  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  52  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  53  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  54  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  55  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  57  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  58  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  59  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  60  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  62  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  63  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
 13%|█▎        | 65/500 [01:50<17:12,  2.37s/it] 13%|█▎        | 67/500 [01:50<11:39,  1.62s/it] 14%|█▍        | 69/500 [01:50<08:03,  1.12s/it] 14%|█▍        | 71/500 [02:03<19:50,  2.77s/it] 15%|█▍        | 73/500 [02:03<13:46,  1.94s/it] 15%|█▌        | 75/500 [02:10<16:34,  2.34s/it] 15%|█▌        | 77/500 [02:10<11:37,  1.65s/it] 16%|█▌        | 79/500 [02:10<08:12,  1.17s/it] 16%|█▌        | 81/500 [02:23<19:09,  2.74s/it] 17%|█▋        | 83/500 [02:23<13:28,  1.94s/it] 17%|█▋        | 85/500 [02:29<16:07,  2.33s/it] 17%|█▋        | 87/500 [02:30<11:22,  1.65s/it] 18%|█▊        | 89/500 [02:30<08:02,  1.18s/it] 18%|█▊        | 91/500 [02:36<12:05,  1.77s/it] 19%|█▊        | 93/500 [02:36<08:34,  1.26s/it] 19%|█▉        | 95/500 [02:43<12:25,  1.84s/it] 19%|█▉        | 97/500 [02:43<08:47,  1.31s/it] 20%|█▉        | 99/500 [02:43<06:16,  1.07it/s] 20%|█▉        | 99/500 [02:54<06:16,  1.07it/s] 20%|██        | 101/500 [02:55<16:54,  2.54s/it] 21%|██        | 103/500 [02:56<11:57,  1.81s/it] 21%|██        | 105/500 [03:02<14:40,  2.23s/it] 21%|██▏       | 107/500 [03:02<10:22,  1.58s/it] 22%|██▏       | 109/500 [03:02<07:21,  1.13s/it] 22%|██▏       | 109/500 [03:14<07:21,  1.13s/it] 22%|██▏       | 111/500 [03:15<17:22,  2.68s/it] 23%|██▎       | 113/500 [03:15<12:14,  1.90s/it] 23%|██▎       | 115/500 [03:22<14:43,  2.29s/it] 23%|██▎       | 117/500 [03:22<10:23,  1.63s/it] 24%|██▍       | 119/500 [03:22<07:21,  1.16s/it] 24%|██▍       | 119/500 [03:34<07:21,  1.16s/it] 24%|██▍       | 121/500 [03:34<17:00,  2.69s/it] 25%|██▍       | 123/500 [03:34<11:58,  1.91s/it]Epoch:  64  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  65  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  67  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  68  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  69  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  70  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  72  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  73  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  74  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  75  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  77  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  78  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  79  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  80  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  82  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  83  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  84  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  85  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  87  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  88  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  89  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  90  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  91  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  92  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  93  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  94  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  95  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  97  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  98  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  99  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  100  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  102  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  103  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  104  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  105  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  107  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  108  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  109  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  110  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  112  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  113  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  114  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  115  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  117  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  118  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  119  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  120  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  122  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  123  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  124  	Training Loss: 0.08740552514791489
Test Loss:   25%|██▌       | 125/500 [03:41<14:22,  2.30s/it] 25%|██▌       | 127/500 [03:41<10:08,  1.63s/it] 26%|██▌       | 129/500 [03:41<07:10,  1.16s/it] 26%|██▌       | 131/500 [03:54<16:30,  2.69s/it] 27%|██▋       | 133/500 [03:54<11:36,  1.90s/it] 27%|██▋       | 135/500 [04:00<13:59,  2.30s/it] 27%|██▋       | 137/500 [04:00<09:53,  1.63s/it] 28%|██▊       | 139/500 [04:01<07:00,  1.17s/it] 28%|██▊       | 141/500 [04:13<16:24,  2.74s/it] 29%|██▊       | 143/500 [04:14<11:33,  1.94s/it] 29%|██▉       | 145/500 [04:20<13:40,  2.31s/it] 29%|██▉       | 147/500 [04:20<09:38,  1.64s/it] 30%|██▉       | 149/500 [04:20<06:49,  1.17s/it] 30%|███       | 151/500 [04:33<15:45,  2.71s/it] 31%|███       | 153/500 [04:33<11:05,  1.92s/it] 31%|███       | 155/500 [04:39<13:14,  2.30s/it] 31%|███▏      | 157/500 [04:40<09:20,  1.63s/it] 32%|███▏      | 159/500 [04:40<06:36,  1.16s/it] 32%|███▏      | 161/500 [04:52<15:26,  2.73s/it] 33%|███▎      | 163/500 [04:53<10:52,  1.94s/it] 33%|███▎      | 165/500 [04:59<12:55,  2.32s/it] 33%|███▎      | 167/500 [04:59<09:07,  1.64s/it] 34%|███▍      | 169/500 [04:59<06:27,  1.17s/it] 34%|███▍      | 171/500 [05:12<15:01,  2.74s/it] 35%|███▍      | 173/500 [05:12<10:34,  1.94s/it] 35%|███▌      | 175/500 [05:19<12:37,  2.33s/it] 35%|███▌      | 177/500 [05:19<08:55,  1.66s/it] 36%|███▌      | 179/500 [05:19<06:19,  1.18s/it] 36%|███▌      | 181/500 [05:32<14:34,  2.74s/it]0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  125  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  127  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  128  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  129  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  130  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  132  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  133  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  134  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  135  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  137  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  138  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  139  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  140  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  142  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  143  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  144  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  145  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  147  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  148  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  149  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  150  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  152  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  153  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  154  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  155  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  157  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  158  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  159  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  160  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  162  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  163  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  164  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  165  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  167  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  168  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  169  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  170  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  172  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  173  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  174  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  175  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  177  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  178  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  179  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  180  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  182  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  183  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
 37%|███▋      | 183/500 [05:32<10:14,  1.94s/it] 37%|███▋      | 185/500 [05:38<12:09,  2.32s/it] 37%|███▋      | 187/500 [05:38<08:33,  1.64s/it] 38%|███▊      | 189/500 [05:39<06:03,  1.17s/it] 38%|███▊      | 191/500 [05:51<14:01,  2.72s/it] 39%|███▊      | 193/500 [05:51<09:53,  1.93s/it] 39%|███▉      | 195/500 [05:58<11:40,  2.30s/it] 39%|███▉      | 197/500 [05:58<08:13,  1.63s/it] 40%|███▉      | 199/500 [05:58<05:49,  1.16s/it] 40%|████      | 201/500 [06:11<13:30,  2.71s/it] 41%|████      | 203/500 [06:11<09:31,  1.92s/it] 41%|████      | 205/500 [06:17<11:22,  2.32s/it] 41%|████▏     | 207/500 [06:17<08:01,  1.64s/it] 42%|████▏     | 209/500 [06:18<05:40,  1.17s/it] 42%|████▏     | 211/500 [06:30<13:07,  2.72s/it] 43%|████▎     | 213/500 [06:30<09:13,  1.93s/it] 43%|████▎     | 215/500 [06:37<10:55,  2.30s/it] 43%|████▎     | 217/500 [06:37<07:41,  1.63s/it] 44%|████▍     | 219/500 [06:37<05:26,  1.16s/it] 44%|████▍     | 221/500 [06:50<12:39,  2.72s/it] 45%|████▍     | 223/500 [06:50<08:53,  1.92s/it] 45%|████▌     | 225/500 [06:56<10:32,  2.30s/it] 45%|████▌     | 227/500 [06:56<07:24,  1.63s/it] 46%|████▌     | 229/500 [06:56<05:14,  1.16s/it] 46%|████▌     | 231/500 [07:09<12:10,  2.72s/it] 47%|████▋     | 233/500 [07:09<08:33,  1.92s/it] 47%|████▋     | 235/500 [07:16<10:08,  2.29s/it] 47%|████▋     | 237/500 [07:16<07:08,  1.63s/it] 48%|████▊     | 239/500 [07:16<05:02,  1.16s/it] 48%|████▊     | 241/500 [07:28<11:33,  2.68s/it]Valid Loss:  0.11271681636571884
Epoch:  184  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  185  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  187  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  188  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  189  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  190  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  192  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  193  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  194  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  195  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  197  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  198  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  199  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  200  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  202  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  203  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  204  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  205  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  207  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  208  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  209  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  210  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  212  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  213  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  214  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  215  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  217  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  218  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  219  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  220  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  222  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  223  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  224  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  225  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  227  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  228  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  229  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  230  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  232  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  233  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  234  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  235  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  237  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  238  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  239  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  240  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  242  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:   49%|████▊     | 243/500 [07:28<08:07,  1.90s/it] 49%|████▉     | 245/500 [07:35<09:45,  2.30s/it] 49%|████▉     | 247/500 [07:35<06:52,  1.63s/it] 50%|████▉     | 249/500 [07:35<04:51,  1.16s/it] 50%|█████     | 251/500 [07:48<11:13,  2.71s/it] 51%|█████     | 253/500 [07:48<07:53,  1.92s/it] 51%|█████     | 255/500 [07:54<09:24,  2.30s/it] 51%|█████▏    | 257/500 [07:55<06:38,  1.64s/it] 52%|█████▏    | 259/500 [07:55<04:41,  1.17s/it] 52%|█████▏    | 261/500 [08:07<10:52,  2.73s/it] 53%|█████▎    | 263/500 [08:08<07:37,  1.93s/it] 53%|█████▎    | 265/500 [08:14<09:00,  2.30s/it] 53%|█████▎    | 267/500 [08:14<06:21,  1.64s/it] 54%|█████▍    | 269/500 [08:14<04:30,  1.17s/it] 54%|█████▍    | 271/500 [08:27<10:28,  2.74s/it] 55%|█████▍    | 273/500 [08:27<07:20,  1.94s/it] 55%|█████▌    | 275/500 [08:34<08:45,  2.33s/it] 55%|█████▌    | 277/500 [08:34<06:09,  1.66s/it] 56%|█████▌    | 279/500 [08:34<04:20,  1.18s/it] 56%|█████▌    | 279/500 [08:44<04:20,  1.18s/it] 56%|█████▌    | 281/500 [08:47<09:59,  2.74s/it] 57%|█████▋    | 283/500 [08:47<07:00,  1.94s/it] 57%|█████▋    | 285/500 [08:53<08:15,  2.31s/it] 57%|█████▋    | 287/500 [08:53<05:48,  1.64s/it] 58%|█████▊    | 289/500 [08:54<04:05,  1.16s/it] 58%|█████▊    | 289/500 [09:04<04:05,  1.16s/it] 58%|█████▊    | 291/500 [09:06<09:23,  2.70s/it] 59%|█████▊    | 293/500 [09:06<06:35,  1.91s/it] 59%|█████▉    | 295/500 [09:13<07:53,  2.31s/it] 59%|█████▉    | 297/500 [09:13<05:32,  1.64s/it] 60%|█████▉    | 299/500 [09:13<03:54,  1.17s/it] 60%|█████▉    | 299/500 [09:24<03:54,  1.17s/it] 60%|██████    | 301/500 [09:26<09:04,  2.74s/it]0.11271682381629944
Epoch:  243  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  244  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  245  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  247  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  248  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  249  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  250  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  252  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  253  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  254  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  255  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  257  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  258  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  259  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  260  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  262  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  263  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  264  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  265  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  267  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  268  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  269  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  270  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  272  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  273  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  274  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  275  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  277  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  278  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  279  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  280  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  282  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  283  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  284  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  285  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  287  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  288  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  289  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  290  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  292  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  293  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  294  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  295  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  297  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  298  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  299  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  300  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
 61%|██████    | 303/500 [09:26<06:21,  1.94s/it] 61%|██████    | 305/500 [09:32<07:28,  2.30s/it] 61%|██████▏   | 307/500 [09:32<05:15,  1.63s/it] 62%|██████▏   | 309/500 [09:32<03:42,  1.16s/it] 62%|██████▏   | 309/500 [09:44<03:42,  1.16s/it] 62%|██████▏   | 311/500 [09:45<08:32,  2.71s/it] 63%|██████▎   | 313/500 [09:45<05:58,  1.92s/it] 63%|██████▎   | 315/500 [09:52<07:03,  2.29s/it] 63%|██████▎   | 317/500 [09:52<04:57,  1.63s/it] 64%|██████▍   | 319/500 [09:52<03:29,  1.16s/it] 64%|██████▍   | 319/500 [10:04<03:29,  1.16s/it] 64%|██████▍   | 321/500 [10:04<08:00,  2.69s/it] 65%|██████▍   | 323/500 [10:05<05:36,  1.90s/it] 65%|██████▌   | 325/500 [10:11<06:39,  2.28s/it] 65%|██████▌   | 327/500 [10:11<04:39,  1.62s/it] 66%|██████▌   | 329/500 [10:11<03:16,  1.15s/it] 66%|██████▌   | 331/500 [10:24<07:32,  2.68s/it] 67%|██████▋   | 333/500 [10:24<05:17,  1.90s/it] 67%|██████▋   | 335/500 [10:30<06:20,  2.31s/it] 67%|██████▋   | 337/500 [10:30<04:26,  1.64s/it] 68%|██████▊   | 339/500 [10:31<03:07,  1.16s/it] 68%|██████▊   | 341/500 [10:43<07:06,  2.68s/it] 69%|██████▊   | 343/500 [10:43<04:59,  1.91s/it] 69%|██████▉   | 345/500 [10:50<05:56,  2.30s/it] 69%|██████▉   | 347/500 [10:50<04:09,  1.63s/it] 70%|██████▉   | 349/500 [10:50<02:55,  1.16s/it] 70%|███████   | 351/500 [11:02<06:39,  2.68s/it] 71%|███████   | 353/500 [11:03<04:39,  1.90s/it] 71%|███████   | 355/500 [11:09<05:30,  2.28s/it] 71%|███████▏  | 357/500 [11:09<03:51,  1.62s/it] 72%|███████▏  | 359/500 [11:09<02:42,  1.15s/it]Epoch:  302  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  303  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  304  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  305  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  307  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  308  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  309  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  310  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  312  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  313  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  314  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  315  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  317  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  318  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  319  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  320  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  322  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  323  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  324  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  325  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  327  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  328  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  329  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  330  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  332  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  333  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  334  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  335  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  337  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  338  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  339  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  340  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  342  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  343  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  344  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  345  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  347  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  348  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  349  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  350  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  352  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  353  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  354  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  355  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  357  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  358  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  359  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  360  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
 72%|███████▏  | 361/500 [11:22<06:13,  2.69s/it] 73%|███████▎  | 363/500 [11:22<04:20,  1.90s/it] 73%|███████▎  | 365/500 [11:28<05:12,  2.31s/it] 73%|███████▎  | 367/500 [11:29<03:38,  1.64s/it] 74%|███████▍  | 369/500 [11:29<02:33,  1.17s/it] 74%|███████▍  | 371/500 [11:41<05:50,  2.72s/it] 75%|███████▍  | 373/500 [11:41<04:04,  1.92s/it] 75%|███████▌  | 375/500 [11:48<04:47,  2.30s/it] 75%|███████▌  | 377/500 [11:48<03:20,  1.63s/it] 76%|███████▌  | 379/500 [11:48<02:21,  1.17s/it] 76%|███████▌  | 381/500 [12:01<05:25,  2.74s/it] 77%|███████▋  | 383/500 [12:01<03:46,  1.94s/it] 77%|███████▋  | 385/500 [12:08<04:28,  2.34s/it] 77%|███████▋  | 387/500 [12:08<03:07,  1.66s/it] 78%|███████▊  | 389/500 [12:08<02:10,  1.18s/it] 78%|███████▊  | 391/500 [12:21<05:02,  2.78s/it] 79%|███████▊  | 393/500 [12:21<03:30,  1.97s/it] 79%|███████▉  | 395/500 [12:28<04:08,  2.36s/it] 79%|███████▉  | 397/500 [12:28<02:52,  1.67s/it] 80%|███████▉  | 399/500 [12:28<02:00,  1.19s/it] 80%|████████  | 401/500 [12:40<04:29,  2.72s/it] 81%|████████  | 403/500 [12:41<03:06,  1.92s/it] 81%|████████  | 405/500 [12:41<02:09,  1.37s/it] 81%|████████▏ | 407/500 [12:41<01:30,  1.03it/s] 82%|████████▏ | 409/500 [12:41<01:03,  1.43it/s] 82%|████████▏ | 411/500 [12:54<03:33,  2.40s/it] 83%|████████▎ | 413/500 [12:54<02:27,  1.70s/it] 83%|████████▎ | 415/500 [13:00<03:02,  2.15s/it] 83%|████████▎ | 417/500 [13:00<02:06,  1.52s/it] 84%|████████▍ | 419/500 [13:00<01:27,  1.09s/it]Epoch:  361  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  362  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  363  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  364  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  365  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  367  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  368  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  369  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  370  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  372  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  373  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  374  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  375  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  377  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  378  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  379  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  380  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  382  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  383  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  384  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  385  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  387  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  388  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  389  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  390  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  392  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  393  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  394  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  395  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  397  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  398  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  399  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  400  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  402  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  403  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  404  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  405  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  406  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  407  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  408  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  409  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  410  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  412  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  413  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  414  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  415  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  417  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  418  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  419  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  420  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
 84%|████████▍ | 421/500 [13:13<03:31,  2.68s/it] 85%|████████▍ | 423/500 [13:13<02:26,  1.90s/it] 85%|████████▌ | 425/500 [13:20<02:50,  2.28s/it] 85%|████████▌ | 427/500 [13:20<01:57,  1.61s/it] 86%|████████▌ | 429/500 [13:20<01:21,  1.15s/it] 86%|████████▌ | 431/500 [13:33<03:05,  2.69s/it] 87%|████████▋ | 433/500 [13:33<02:07,  1.91s/it] 87%|████████▋ | 435/500 [13:39<02:29,  2.30s/it] 87%|████████▋ | 437/500 [13:39<01:42,  1.63s/it] 88%|████████▊ | 439/500 [13:39<01:10,  1.16s/it] 88%|████████▊ | 441/500 [13:52<02:39,  2.70s/it] 89%|████████▊ | 443/500 [13:52<01:49,  1.91s/it] 89%|████████▉ | 445/500 [13:59<02:06,  2.29s/it] 89%|████████▉ | 447/500 [13:59<01:26,  1.62s/it] 90%|████████▉ | 449/500 [13:59<00:58,  1.15s/it] 90%|█████████ | 451/500 [14:11<02:11,  2.69s/it] 91%|█████████ | 453/500 [14:11<01:29,  1.90s/it] 91%|█████████ | 455/500 [14:18<01:41,  2.26s/it] 91%|█████████▏| 457/500 [14:18<01:09,  1.61s/it] 92%|█████████▏| 459/500 [14:18<00:47,  1.15s/it] 92%|█████████▏| 461/500 [14:31<01:44,  2.68s/it] 93%|█████████▎| 463/500 [14:31<01:10,  1.90s/it] 93%|█████████▎| 465/500 [14:37<01:20,  2.29s/it] 93%|█████████▎| 467/500 [14:37<00:53,  1.63s/it] 94%|█████████▍| 469/500 [14:37<00:35,  1.16s/it] 94%|█████████▍| 471/500 [14:50<01:18,  2.72s/it] 95%|█████████▍| 473/500 [14:50<00:51,  1.92s/it] 95%|█████████▌| 475/500 [14:57<00:57,  2.30s/it] 95%|█████████▌| 477/500 [14:57<00:37,  1.63s/it] 96%|█████████▌| 479/500 [14:57<00:24,  1.17s/it]Epoch:  421  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  422  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  423  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  424  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  425  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  427  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  428  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  429  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  430  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  432  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  433  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  434  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  435  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  437  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  438  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  439  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  440  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  442  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  443  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  444  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  445  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  447  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  448  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  449  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  450  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  452  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  453  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  454  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  455  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  457  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  458  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  459  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  460  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  462  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  463  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  464  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  465  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  467  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  468  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  469  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  470  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271682381629944
Epoch:  472  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  473  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  474  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  475  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  477  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  478  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271682381629944
Epoch:  479  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  480  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
 96%|█████████▌| 481/500 [15:10<00:51,  2.73s/it] 97%|█████████▋| 483/500 [15:10<00:32,  1.93s/it] 97%|█████████▋| 485/500 [15:16<00:34,  2.32s/it] 97%|█████████▋| 487/500 [15:16<00:21,  1.65s/it] 98%|█████████▊| 489/500 [15:16<00:12,  1.17s/it] 98%|█████████▊| 491/500 [15:29<00:24,  2.73s/it] 99%|█████████▊| 493/500 [15:29<00:13,  1.93s/it] 99%|█████████▉| 495/500 [15:36<00:11,  2.29s/it] 99%|█████████▉| 497/500 [15:36<00:04,  1.63s/it]100%|█████████▉| 499/500 [15:36<00:01,  1.16s/it]100%|██████████| 500/500 [15:42<00:00,  1.89s/it]
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  482  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  483  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
Epoch:  484  	Training Loss: 0.08740551769733429
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  485  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  487  	Training Loss: 0.08740553259849548
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
Epoch:  488  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  489  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271680891513824
Epoch:  490  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.08740553259849548
Test Loss:  0.11881943047046661
Valid Loss:  0.11271682381629944
Epoch:  492  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  493  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  494  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  495  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271680891513824
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943047046661
Valid Loss:  0.11271681636571884
Epoch:  497  	Training Loss: 0.08740552514791489
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
Epoch:  498  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  499  	Training Loss: 0.08740552514791489
Test Loss:  0.11881943792104721
Valid Loss:  0.11271681636571884
Epoch:  500  	Training Loss: 0.08740551769733429
Test Loss:  0.11881944537162781
Valid Loss:  0.11271681636571884
**************************************************learning rate decay**************************************************
seed is  4
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:12,  6.40s/it]  1%|          | 3/500 [00:06<14:10,  1.71s/it]  1%|          | 5/500 [00:06<07:08,  1.16it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<10:52,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:19<13:21,  1.65s/it]  3%|▎         | 17/500 [00:19<09:19,  1.16s/it]  4%|▍         | 19/500 [00:20<06:37,  1.21it/s]  4%|▍         | 20/500 [00:26<14:31,  1.82s/it]  4%|▍         | 21/500 [00:32<21:53,  2.74s/it]  5%|▍         | 23/500 [00:32<13:56,  1.75s/it]  5%|▌         | 25/500 [00:39<17:39,  2.23s/it]  5%|▌         | 27/500 [00:39<11:56,  1.52s/it]  6%|▌         | 29/500 [00:39<08:14,  1.05s/it]  6%|▌         | 31/500 [00:51<20:59,  2.69s/it]  7%|▋         | 33/500 [00:52<14:35,  1.88s/it]  7%|▋         | 35/500 [00:58<17:31,  2.26s/it]  7%|▋         | 37/500 [00:58<12:18,  1.59s/it]  8%|▊         | 39/500 [00:58<08:41,  1.13s/it]  8%|▊         | 41/500 [01:11<20:50,  2.72s/it]  9%|▊         | 43/500 [01:11<14:39,  1.92s/it]  9%|▉         | 45/500 [01:17<17:25,  2.30s/it]  9%|▉         | 47/500 [01:18<12:16,  1.63s/it] 10%|▉         | 49/500 [01:18<08:41,  1.16s/it] 10%|█         | 51/500 [01:30<20:06,  2.69s/it] 11%|█         | 53/500 [01:30<14:09,  1.90s/it] 11%|█         | 55/500 [01:37<16:51,  2.27s/it] 11%|█▏        | 57/500 [01:37<11:53,  1.61s/it] 12%|█▏        | 59/500 [01:37<08:25,  1.15s/it] 12%|█▏        | 61/500 [01:49<19:37,  2.68s/it]Epoch:  1  	Training Loss: 0.07232363522052765
Test Loss:  10.962833404541016
Valid Loss:  10.750956535339355
Epoch:  2  	Training Loss: 10.553133010864258
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  3  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  4  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  5  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  6  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  7  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  8  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  9  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  10  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  11  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  12  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  13  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  14  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  15  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  17  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  18  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  19  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  20  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  22  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  23  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  24  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  25  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  27  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  28  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  29  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  30  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  32  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  33  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  34  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  35  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  37  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  38  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  39  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  40  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  42  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  43  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  44  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  45  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  47  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  48  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  49  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  50  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  52  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  53  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  54  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  55  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  57  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  58  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  59  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  60  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  62  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  63  	Training Loss: 0.0765903890132904
Test Loss:   13%|█▎        | 63/500 [01:50<13:52,  1.90s/it] 13%|█▎        | 65/500 [01:56<16:41,  2.30s/it] 13%|█▎        | 67/500 [01:56<11:47,  1.63s/it] 14%|█▍        | 69/500 [01:56<08:21,  1.16s/it] 14%|█▍        | 71/500 [02:09<19:22,  2.71s/it] 15%|█▍        | 73/500 [02:09<13:39,  1.92s/it] 15%|█▌        | 75/500 [02:16<16:25,  2.32s/it] 15%|█▌        | 77/500 [02:16<11:36,  1.65s/it] 16%|█▌        | 79/500 [02:16<08:13,  1.17s/it] 16%|█▌        | 81/500 [02:29<19:01,  2.72s/it] 17%|█▋        | 83/500 [02:29<13:25,  1.93s/it] 17%|█▋        | 85/500 [02:35<16:04,  2.32s/it] 17%|█▋        | 87/500 [02:35<11:20,  1.65s/it] 18%|█▊        | 89/500 [02:35<08:02,  1.17s/it] 18%|█▊        | 89/500 [02:46<08:02,  1.17s/it] 18%|█▊        | 91/500 [02:48<18:30,  2.71s/it] 19%|█▊        | 93/500 [02:48<13:01,  1.92s/it] 19%|█▉        | 95/500 [02:55<15:40,  2.32s/it] 19%|█▉        | 97/500 [02:55<11:02,  1.64s/it] 20%|█▉        | 99/500 [02:55<07:49,  1.17s/it] 20%|█▉        | 99/500 [03:06<07:49,  1.17s/it] 20%|██        | 101/500 [03:08<18:15,  2.74s/it] 21%|██        | 103/500 [03:08<12:51,  1.94s/it] 21%|██        | 105/500 [03:14<15:24,  2.34s/it] 21%|██▏       | 107/500 [03:15<10:51,  1.66s/it] 22%|██▏       | 109/500 [03:15<07:41,  1.18s/it] 22%|██▏       | 109/500 [03:26<07:41,  1.18s/it] 22%|██▏       | 111/500 [03:27<17:38,  2.72s/it] 23%|██▎       | 113/500 [03:28<12:24,  1.92s/it] 23%|██▎       | 115/500 [03:34<14:49,  2.31s/it] 23%|██▎       | 117/500 [03:34<10:26,  1.64s/it] 24%|██▍       | 119/500 [03:34<07:23,  1.16s/it] 24%|██▍       | 119/500 [03:46<07:23,  1.16s/it] 24%|██▍       | 121/500 [03:47<17:01,  2.70s/it]0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  64  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  65  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  67  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  68  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  69  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  70  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  72  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  73  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  74  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  75  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  77  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  78  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  79  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  80  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  82  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  83  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  84  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  85  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  87  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  88  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  89  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  90  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  92  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  93  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  94  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  95  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  97  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  98  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  99  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  100  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  102  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  103  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  104  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  105  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  107  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  108  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  109  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  110  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  112  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  113  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  114  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  115  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  117  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  118  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  119  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  120  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  122  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760818958282
Epoch:  123  	Training Loss: 0.0765903890132904
Test Loss:   25%|██▍       | 123/500 [03:47<11:58,  1.91s/it] 25%|██▌       | 125/500 [03:53<14:19,  2.29s/it] 25%|██▌       | 127/500 [03:53<10:05,  1.62s/it] 26%|██▌       | 129/500 [03:54<07:08,  1.16s/it] 26%|██▌       | 129/500 [04:06<07:08,  1.16s/it] 26%|██▌       | 131/500 [04:06<16:45,  2.72s/it] 27%|██▋       | 133/500 [04:06<11:49,  1.93s/it] 27%|██▋       | 135/500 [04:13<14:13,  2.34s/it] 27%|██▋       | 137/500 [04:13<10:02,  1.66s/it] 28%|██▊       | 139/500 [04:13<07:06,  1.18s/it] 28%|██▊       | 139/500 [04:26<07:06,  1.18s/it] 28%|██▊       | 141/500 [04:26<16:20,  2.73s/it] 29%|██▊       | 143/500 [04:26<11:29,  1.93s/it] 29%|██▉       | 145/500 [04:32<13:37,  2.30s/it] 29%|██▉       | 147/500 [04:33<09:36,  1.63s/it] 30%|██▉       | 149/500 [04:33<06:48,  1.16s/it] 30%|███       | 151/500 [04:45<15:50,  2.72s/it] 31%|███       | 153/500 [04:46<11:08,  1.93s/it] 31%|███       | 155/500 [04:52<13:18,  2.32s/it] 31%|███▏      | 157/500 [04:52<09:23,  1.64s/it] 32%|███▏      | 159/500 [04:52<06:38,  1.17s/it] 32%|███▏      | 161/500 [05:05<15:18,  2.71s/it] 33%|███▎      | 163/500 [05:05<10:46,  1.92s/it] 33%|███▎      | 165/500 [05:12<12:54,  2.31s/it] 33%|███▎      | 167/500 [05:12<09:06,  1.64s/it] 34%|███▍      | 169/500 [05:12<06:26,  1.17s/it] 34%|███▍      | 171/500 [05:24<14:45,  2.69s/it] 35%|███▍      | 173/500 [05:24<10:22,  1.90s/it] 35%|███▌      | 175/500 [05:31<12:26,  2.30s/it] 35%|███▌      | 177/500 [05:31<08:46,  1.63s/it] 36%|███▌      | 179/500 [05:31<06:12,  1.16s/it] 36%|███▌      | 181/500 [05:44<14:29,  2.73s/it]0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  124  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  125  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  127  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  128  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  129  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  130  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  132  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  133  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  134  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  135  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  137  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  138  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  139  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  140  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  142  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  143  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  144  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  145  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  147  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  148  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  149  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  150  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  152  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  153  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  154  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  155  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  157  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  158  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  159  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  160  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  162  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  163  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  164  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  165  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  167  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  168  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  169  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  170  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  172  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  173  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  174  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  175  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  177  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  178  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  179  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  180  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  182  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
 37%|███▋      | 183/500 [05:44<10:12,  1.93s/it] 37%|███▋      | 185/500 [05:50<12:09,  2.32s/it] 37%|███▋      | 187/500 [05:51<08:34,  1.64s/it] 38%|███▊      | 189/500 [05:51<06:03,  1.17s/it] 38%|███▊      | 191/500 [06:04<14:03,  2.73s/it] 39%|███▊      | 193/500 [06:04<09:53,  1.93s/it] 39%|███▉      | 195/500 [06:10<11:41,  2.30s/it] 39%|███▉      | 197/500 [06:10<08:13,  1.63s/it] 40%|███▉      | 199/500 [06:10<05:49,  1.16s/it] 40%|████      | 201/500 [06:23<13:32,  2.72s/it] 41%|████      | 203/500 [06:23<09:32,  1.93s/it] 41%|████      | 205/500 [06:30<11:22,  2.31s/it] 41%|████▏     | 207/500 [06:30<08:00,  1.64s/it] 42%|████▏     | 209/500 [06:30<05:40,  1.17s/it] 42%|████▏     | 211/500 [06:42<13:01,  2.70s/it] 43%|████▎     | 213/500 [06:43<09:09,  1.91s/it] 43%|████▎     | 215/500 [06:49<10:53,  2.29s/it] 43%|████▎     | 217/500 [06:49<07:41,  1.63s/it] 44%|████▍     | 219/500 [06:49<05:27,  1.17s/it] 44%|████▍     | 221/500 [07:02<12:37,  2.72s/it] 45%|████▍     | 223/500 [07:02<08:52,  1.92s/it] 45%|████▌     | 225/500 [07:09<10:38,  2.32s/it] 45%|████▌     | 227/500 [07:09<07:29,  1.65s/it] 46%|████▌     | 229/500 [07:09<05:18,  1.17s/it] 46%|████▌     | 231/500 [07:21<12:12,  2.72s/it] 47%|████▋     | 233/500 [07:22<08:34,  1.93s/it] 47%|████▋     | 235/500 [07:28<10:10,  2.30s/it] 47%|████▋     | 237/500 [07:28<07:10,  1.64s/it] 48%|████▊     | 239/500 [07:28<05:05,  1.17s/it] 48%|████▊     | 241/500 [07:41<11:45,  2.72s/it]Epoch:  183  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  184  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  185  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  187  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  188  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  189  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  190  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  192  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  193  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  194  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  195  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  197  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  198  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  199  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  200  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  202  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  203  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  204  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  205  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  207  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  208  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  209  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  210  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  212  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  213  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  214  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  215  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  217  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  218  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  219  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  220  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  222  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  223  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  224  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  225  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  227  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  228  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  229  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  230  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  232  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  233  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  234  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  235  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  237  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  238  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  239  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  240  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  242  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
 49%|████▊     | 243/500 [07:41<08:15,  1.93s/it] 49%|████▉     | 245/500 [07:48<09:52,  2.32s/it] 49%|████▉     | 247/500 [07:48<06:57,  1.65s/it] 50%|████▉     | 249/500 [07:48<04:54,  1.17s/it] 50%|█████     | 251/500 [08:01<11:15,  2.71s/it] 51%|█████     | 253/500 [08:01<07:54,  1.92s/it] 51%|█████     | 255/500 [08:07<09:25,  2.31s/it] 51%|█████▏    | 257/500 [08:07<06:39,  1.64s/it] 52%|█████▏    | 259/500 [08:07<04:43,  1.18s/it] 52%|█████▏    | 261/500 [08:20<10:55,  2.74s/it] 53%|█████▎    | 263/500 [08:20<07:39,  1.94s/it] 53%|█████▎    | 265/500 [08:27<09:02,  2.31s/it] 53%|█████▎    | 267/500 [08:27<06:21,  1.64s/it] 54%|█████▍    | 269/500 [08:27<04:29,  1.17s/it] 54%|█████▍    | 271/500 [08:40<10:22,  2.72s/it] 55%|█████▍    | 273/500 [08:40<07:16,  1.92s/it] 55%|█████▌    | 275/500 [08:46<08:41,  2.32s/it] 55%|█████▌    | 277/500 [08:46<06:06,  1.64s/it] 56%|█████▌    | 279/500 [08:47<04:18,  1.17s/it] 56%|█████▌    | 281/500 [08:59<10:03,  2.76s/it] 57%|█████▋    | 283/500 [09:00<07:03,  1.95s/it] 57%|█████▋    | 285/500 [09:06<08:20,  2.33s/it] 57%|█████▋    | 287/500 [09:06<05:51,  1.65s/it] 58%|█████▊    | 289/500 [09:06<04:07,  1.18s/it] 58%|█████▊    | 291/500 [09:19<09:31,  2.73s/it] 59%|█████▊    | 293/500 [09:19<06:40,  1.93s/it] 59%|█████▉    | 295/500 [09:26<07:52,  2.31s/it] 59%|█████▉    | 297/500 [09:26<05:33,  1.64s/it] 60%|█████▉    | 299/500 [09:26<03:56,  1.17s/it] 60%|█████▉    | 299/500 [09:36<03:56,  1.17s/it] 60%|██████    | 301/500 [09:38<08:57,  2.70s/it]Valid Loss:  0.10711760073900223
Epoch:  243  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  244  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  245  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  247  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  248  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  249  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  250  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  252  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  253  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  254  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  255  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  257  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  258  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  259  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  260  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  262  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  263  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  264  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  265  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  267  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  268  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  269  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  270  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  272  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  273  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  274  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  275  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  277  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  278  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  279  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  280  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  282  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  283  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  284  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  285  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  287  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  288  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  289  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  290  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  292  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  293  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  294  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  295  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  297  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  298  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  299  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  300  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  302  	Training Loss: 0.0765903890132904
Test Loss:   61%|██████    | 303/500 [09:39<06:16,  1.91s/it] 61%|██████    | 305/500 [09:45<07:26,  2.29s/it] 61%|██████▏   | 307/500 [09:45<05:13,  1.62s/it] 62%|██████▏   | 309/500 [09:45<03:40,  1.16s/it] 62%|██████▏   | 309/500 [09:56<03:40,  1.16s/it] 62%|██████▏   | 311/500 [09:58<08:30,  2.70s/it] 63%|██████▎   | 313/500 [09:58<05:57,  1.91s/it] 63%|██████▎   | 315/500 [10:04<07:00,  2.27s/it] 63%|██████▎   | 317/500 [10:04<04:55,  1.61s/it] 64%|██████▍   | 319/500 [10:04<03:27,  1.15s/it] 64%|██████▍   | 319/500 [10:16<03:27,  1.15s/it] 64%|██████▍   | 321/500 [10:17<08:09,  2.73s/it] 65%|██████▍   | 323/500 [10:17<05:42,  1.93s/it] 65%|██████▌   | 325/500 [10:24<06:41,  2.29s/it] 65%|██████▌   | 327/500 [10:24<04:41,  1.63s/it] 66%|██████▌   | 329/500 [10:24<03:17,  1.16s/it] 66%|██████▌   | 329/500 [10:36<03:17,  1.16s/it] 66%|██████▌   | 331/500 [10:37<07:36,  2.70s/it] 67%|██████▋   | 333/500 [10:37<05:19,  1.91s/it] 67%|██████▋   | 335/500 [10:43<06:21,  2.31s/it] 67%|██████▋   | 337/500 [10:43<04:26,  1.64s/it] 68%|██████▊   | 339/500 [10:43<03:07,  1.17s/it] 68%|██████▊   | 339/500 [10:56<03:07,  1.17s/it] 68%|██████▊   | 341/500 [10:56<07:09,  2.70s/it] 69%|██████▊   | 343/500 [10:56<04:59,  1.91s/it] 69%|██████▉   | 345/500 [11:02<05:52,  2.27s/it] 69%|██████▉   | 347/500 [11:03<04:06,  1.61s/it] 70%|██████▉   | 349/500 [11:03<02:53,  1.15s/it] 70%|███████   | 351/500 [11:15<06:40,  2.69s/it] 71%|███████   | 353/500 [11:15<04:39,  1.90s/it] 71%|███████   | 355/500 [11:22<05:32,  2.29s/it] 71%|███████▏  | 357/500 [11:22<03:52,  1.63s/it] 72%|███████▏  | 359/500 [11:22<02:43,  1.16s/it] 72%|███████▏  | 361/500 [11:35<06:15,  2.70s/it]0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  303  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  304  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  305  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  307  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  308  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  309  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  310  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  312  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  313  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  314  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  315  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  317  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  318  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  319  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  320  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  322  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  323  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  324  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  325  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  327  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  328  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  329  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  330  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  332  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  333  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  334  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  335  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  337  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  338  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  339  	Training Loss: 0.076590396463871
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  340  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  342  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  343  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  344  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  345  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  347  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  348  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  349  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  350  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  352  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  353  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  354  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  355  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  357  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  358  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  359  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  360  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
 73%|███████▎  | 363/500 [11:35<04:22,  1.91s/it] 73%|███████▎  | 365/500 [11:41<05:10,  2.30s/it] 73%|███████▎  | 367/500 [11:41<03:36,  1.63s/it] 74%|███████▍  | 369/500 [11:41<02:31,  1.16s/it] 74%|███████▍  | 371/500 [11:54<05:48,  2.70s/it] 75%|███████▍  | 373/500 [11:54<04:02,  1.91s/it] 75%|███████▌  | 375/500 [12:01<04:47,  2.30s/it] 75%|███████▌  | 377/500 [12:01<03:20,  1.63s/it] 76%|███████▌  | 379/500 [12:01<02:20,  1.16s/it] 76%|███████▌  | 381/500 [12:13<05:21,  2.70s/it] 77%|███████▋  | 383/500 [12:14<03:43,  1.91s/it] 77%|███████▋  | 385/500 [12:20<04:21,  2.27s/it] 77%|███████▋  | 387/500 [12:20<03:02,  1.62s/it] 78%|███████▊  | 389/500 [12:20<02:07,  1.15s/it] 78%|███████▊  | 391/500 [12:33<04:54,  2.70s/it] 79%|███████▊  | 393/500 [12:33<03:24,  1.91s/it] 79%|███████▉  | 395/500 [12:39<03:59,  2.28s/it] 79%|███████▉  | 397/500 [12:39<02:46,  1.62s/it] 80%|███████▉  | 399/500 [12:39<01:56,  1.15s/it] 80%|████████  | 401/500 [12:52<04:29,  2.72s/it] 81%|████████  | 403/500 [12:52<03:07,  1.93s/it] 81%|████████  | 405/500 [12:59<03:41,  2.33s/it] 81%|████████▏ | 407/500 [12:59<02:33,  1.65s/it] 82%|████████▏ | 409/500 [12:59<01:46,  1.18s/it] 82%|████████▏ | 411/500 [13:12<04:03,  2.74s/it] 83%|████████▎ | 413/500 [13:12<02:48,  1.94s/it] 83%|████████▎ | 415/500 [13:18<03:16,  2.31s/it] 83%|████████▎ | 417/500 [13:19<02:16,  1.64s/it] 84%|████████▍ | 419/500 [13:19<01:34,  1.17s/it]Epoch:  362  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  363  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  364  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  365  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  367  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  368  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  369  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  370  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  372  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  373  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  374  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  375  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  377  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  378  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  379  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  380  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  382  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  383  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  384  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  385  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  387  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  388  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  389  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  390  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  392  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  393  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  394  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  395  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  397  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  398  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  399  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  400  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  402  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  403  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  404  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  405  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  407  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  408  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  409  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  410  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  412  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  413  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  414  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  415  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  417  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  418  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  419  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  420  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
 84%|████████▍ | 421/500 [13:32<03:36,  2.74s/it] 85%|████████▍ | 423/500 [13:32<02:29,  1.94s/it] 85%|████████▌ | 425/500 [13:38<02:54,  2.32s/it] 85%|████████▌ | 427/500 [13:38<02:00,  1.65s/it] 86%|████████▌ | 429/500 [13:38<01:23,  1.17s/it] 86%|████████▌ | 431/500 [13:51<03:07,  2.71s/it] 87%|████████▋ | 433/500 [13:51<02:08,  1.92s/it] 87%|████████▋ | 435/500 [13:58<02:30,  2.31s/it] 87%|████████▋ | 437/500 [13:58<01:43,  1.64s/it] 88%|████████▊ | 439/500 [13:58<01:11,  1.17s/it] 88%|████████▊ | 441/500 [14:10<02:39,  2.70s/it] 89%|████████▊ | 443/500 [14:11<01:48,  1.91s/it] 89%|████████▉ | 445/500 [14:17<02:06,  2.31s/it] 89%|████████▉ | 447/500 [14:17<01:26,  1.64s/it] 90%|████████▉ | 449/500 [14:17<00:59,  1.17s/it] 90%|█████████ | 451/500 [14:30<02:12,  2.70s/it] 91%|█████████ | 453/500 [14:30<01:29,  1.91s/it] 91%|█████████ | 455/500 [14:36<01:43,  2.29s/it] 91%|█████████▏| 457/500 [14:36<01:09,  1.62s/it] 92%|█████████▏| 459/500 [14:37<00:47,  1.16s/it] 92%|█████████▏| 461/500 [14:49<01:45,  2.70s/it] 93%|█████████▎| 463/500 [14:49<01:10,  1.91s/it] 93%|█████████▎| 465/500 [14:56<01:19,  2.28s/it] 93%|█████████▎| 467/500 [14:56<00:53,  1.62s/it] 94%|█████████▍| 469/500 [14:56<00:35,  1.15s/it] 94%|█████████▍| 469/500 [15:06<00:35,  1.15s/it] 94%|█████████▍| 471/500 [15:08<01:18,  2.69s/it] 95%|█████████▍| 473/500 [15:09<00:51,  1.90s/it] 95%|█████████▌| 475/500 [15:15<00:57,  2.30s/it] 95%|█████████▌| 477/500 [15:15<00:37,  1.63s/it] 96%|█████████▌| 479/500 [15:15<00:24,  1.16s/it]Valid Loss:  0.10711759328842163
Epoch:  422  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  423  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  424  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  425  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  427  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  428  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  429  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  430  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  432  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  433  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  434  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  435  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  437  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  438  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  439  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  440  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  442  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  443  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
Epoch:  444  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  445  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  447  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  448  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  449  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  450  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  452  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  453  	Training Loss: 0.076590396463871
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  454  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  455  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  457  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  458  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  459  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  460  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  462  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  463  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  464  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  465  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  467  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  468  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  469  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  470  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  472  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  473  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  474  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  475  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  477  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  478  	Training Loss: 0.0765903890132904
Test Loss:  0.10408255457878113
Valid Loss:  0.10711759328842163
Epoch:  479  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  480  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0765903890132904
 96%|█████████▌| 479/500 [15:26<00:24,  1.16s/it] 96%|█████████▌| 481/500 [15:28<00:51,  2.70s/it] 97%|█████████▋| 483/500 [15:28<00:32,  1.91s/it] 97%|█████████▋| 485/500 [15:34<00:34,  2.29s/it] 97%|█████████▋| 487/500 [15:35<00:21,  1.63s/it] 98%|█████████▊| 489/500 [15:35<00:12,  1.16s/it] 98%|█████████▊| 489/500 [15:46<00:12,  1.16s/it] 98%|█████████▊| 491/500 [15:47<00:24,  2.71s/it] 99%|█████████▊| 493/500 [15:47<00:13,  1.92s/it] 99%|█████████▉| 495/500 [15:54<00:11,  2.30s/it] 99%|█████████▉| 497/500 [15:54<00:04,  1.64s/it]100%|█████████▉| 499/500 [15:54<00:01,  1.17s/it]100%|██████████| 500/500 [16:01<00:00,  1.92s/it]
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  482  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  483  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  484  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  485  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711760073900223
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  487  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  488  	Training Loss: 0.076590396463871
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  489  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  490  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  492  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  493  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  494  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  495  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
Epoch:  497  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711760073900223
Epoch:  498  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  499  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256202936172
Valid Loss:  0.10711759328842163
Epoch:  500  	Training Loss: 0.0765903890132904
Test Loss:  0.10408256947994232
Valid Loss:  0.10711759328842163
**************************************************learning rate decay**************************************************
seed is  5
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:41,  6.34s/it]  1%|          | 3/500 [00:06<14:02,  1.69s/it]  1%|          | 5/500 [00:06<07:04,  1.17it/s]  1%|▏         | 7/500 [00:06<04:21,  1.88it/s]  2%|▏         | 9/500 [00:06<02:57,  2.76it/s]  2%|▏         | 11/500 [00:13<11:17,  1.39s/it]  3%|▎         | 13/500 [00:13<07:44,  1.05it/s]  3%|▎         | 15/500 [00:13<05:24,  1.50it/s]  3%|▎         | 17/500 [00:13<03:50,  2.09it/s]  4%|▍         | 19/500 [00:14<02:50,  2.82it/s]  4%|▍         | 21/500 [00:20<09:50,  1.23s/it]  5%|▍         | 23/500 [00:20<06:58,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.58it/s]  5%|▌         | 27/500 [00:20<03:38,  2.17it/s]  6%|▌         | 29/500 [00:21<02:40,  2.93it/s]  6%|▌         | 31/500 [00:27<09:33,  1.22s/it]  7%|▋         | 33/500 [00:27<06:49,  1.14it/s]  7%|▋         | 35/500 [00:27<04:54,  1.58it/s]  7%|▋         | 37/500 [00:28<03:34,  2.16it/s]  8%|▊         | 39/500 [00:28<02:38,  2.91it/s]  8%|▊         | 41/500 [00:34<09:29,  1.24s/it]  9%|▊         | 43/500 [00:34<06:46,  1.12it/s]  9%|▉         | 45/500 [00:35<04:52,  1.56it/s]  9%|▉         | 47/500 [00:35<03:35,  2.11it/s] 10%|▉         | 49/500 [00:35<02:39,  2.83it/s] 10%|█         | 51/500 [00:41<09:11,  1.23s/it] 11%|█         | 53/500 [00:42<06:33,  1.14it/s] 11%|█         | 55/500 [00:42<04:43,  1.57it/s] 11%|█▏        | 57/500 [00:42<03:27,  2.13it/s] 12%|█▏        | 59/500 [00:42<02:35,  2.83it/s] 12%|█▏        | 61/500 [00:48<08:46,  1.20s/it] 13%|█▎        | 63/500 [00:49<06:16,  1.16it/s] 13%|█▎        | 65/500 [00:49<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:49<03:16,  2.20it/s] 14%|█▍        | 69/500 [00:49<02:25,  2.96it/s]Epoch:  1  	Training Loss: 0.18019041419029236
Test Loss:  0.06361015141010284
Valid Loss:  0.06464660167694092
Epoch:  2  	Training Loss: 0.047125257551670074
Test Loss:  0.029406066983938217
Valid Loss:  0.032964058220386505
Epoch:  3  	Training Loss: 0.026384690776467323
Test Loss:  0.01930905133485794
Valid Loss:  0.02328852005302906
Epoch:  4  	Training Loss: 0.021105583757162094
Test Loss:  0.015225394628942013
Valid Loss:  0.018965834751725197
Epoch:  5  	Training Loss: 0.01857922412455082
Test Loss:  0.012986957095563412
Valid Loss:  0.016283631324768066
Epoch:  6  	Training Loss: 0.016669191420078278
Test Loss:  0.01143156923353672
Valid Loss:  0.014255771413445473
Epoch:  7  	Training Loss: 0.015025539323687553
Test Loss:  0.010199131444096565
Valid Loss:  0.01258027646690607
Epoch:  8  	Training Loss: 0.013575125485658646
Test Loss:  0.009159061126410961
Valid Loss:  0.011144799180328846
Epoch:  9  	Training Loss: 0.012288841418921947
Test Loss:  0.00826170202344656
Valid Loss:  0.00989996176213026
Epoch:  10  	Training Loss: 0.011146817356348038
Test Loss:  0.00747855706140399
Valid Loss:  0.008814435452222824
Epoch:  11  	Training Loss: 0.01013268157839775
Test Loss:  0.006791120395064354
Valid Loss:  0.00786573439836502
Epoch:  12  	Training Loss: 0.00923208612948656
Test Loss:  0.006186500191688538
Valid Loss:  0.007036307826638222
Epoch:  13  	Training Loss: 0.008432189002633095
Test Loss:  0.005653394386172295
Valid Loss:  0.006311243865638971
Epoch:  14  	Training Loss: 0.0077218348160386086
Test Loss:  0.005184614099562168
Valid Loss:  0.0056786248460412025
Epoch:  15  	Training Loss: 0.007091004401445389
Test Loss:  0.004771439358592033
Valid Loss:  0.00512689258903265
Epoch:  16  	Training Loss: 0.006530785467475653
Test Loss:  0.004408663138747215
Valid Loss:  0.004646880552172661
Epoch:  17  	Training Loss: 0.006033275742083788
Test Loss:  0.004089499823749065
Valid Loss:  0.00422960240393877
Epoch:  18  	Training Loss: 0.005591461434960365
Test Loss:  0.0038090208545327187
Valid Loss:  0.0038675847463309765
Epoch:  19  	Training Loss: 0.005199096631258726
Test Loss:  0.0035629854537546635
Valid Loss:  0.003554233815521002
Epoch:  20  	Training Loss: 0.00485065346583724
Test Loss:  0.0033470764756202698
Valid Loss:  0.003283538855612278
Epoch:  21  	Training Loss: 0.0045412159524858
Test Loss:  0.0031578820198774338
Valid Loss:  0.003050318220630288
Epoch:  22  	Training Loss: 0.004266410134732723
Test Loss:  0.002992080757394433
Valid Loss:  0.002849895739927888
Epoch:  23  	Training Loss: 0.0040223244577646255
Test Loss:  0.0028471581172198057
Valid Loss:  0.0026783179491758347
Epoch:  24  	Training Loss: 0.003805559128522873
Test Loss:  0.0027206153608858585
Valid Loss:  0.0025319745764136314
Epoch:  25  	Training Loss: 0.0036130507942289114
Test Loss:  0.0026102587580680847
Valid Loss:  0.0024076797999441624
Epoch:  26  	Training Loss: 0.003442083951085806
Test Loss:  0.002514192834496498
Valid Loss:  0.0023026498965919018
Epoch:  27  	Training Loss: 0.003290256019681692
Test Loss:  0.0024309188593178988
Valid Loss:  0.002214435487985611
Epoch:  28  	Training Loss: 0.0031554277520626783
Test Loss:  0.0023585190065205097
Valid Loss:  0.0021408020984381437
Epoch:  29  	Training Loss: 0.0030356906354427338
Test Loss:  0.002295728772878647
Valid Loss:  0.002079862402752042
Epoch:  30  	Training Loss: 0.002929351758211851
Test Loss:  0.0022414231207221746
Valid Loss:  0.002029945608228445
Epoch:  31  	Training Loss: 0.002834911923855543
Test Loss:  0.002194599946960807
Valid Loss:  0.0019895874429494143
Epoch:  32  	Training Loss: 0.002751040505245328
Test Loss:  0.0021545118652284145
Valid Loss:  0.0019574908073991537
Epoch:  33  	Training Loss: 0.002676564734429121
Test Loss:  0.002120064338669181
Valid Loss:  0.0019324995810166001
Epoch:  34  	Training Loss: 0.0026104217395186424
Test Loss:  0.00209060893394053
Valid Loss:  0.0019136166665703058
Epoch:  35  	Training Loss: 0.0025516811292618513
Test Loss:  0.0020656692795455456
Valid Loss:  0.0018999744206666946
Epoch:  36  	Training Loss: 0.0024995130952447653
Test Loss:  0.0020444951951503754
Valid Loss:  0.0018908008933067322
Epoch:  37  	Training Loss: 0.002453183988109231
Test Loss:  0.002026643604040146
Valid Loss:  0.0018854322843253613
Epoch:  38  	Training Loss: 0.0024120360612869263
Test Loss:  0.0020118015818297863
Valid Loss:  0.0018832723144441843
Epoch:  39  	Training Loss: 0.002375495620071888
Test Loss:  0.0019994620233774185
Valid Loss:  0.0018838199321180582
Epoch:  40  	Training Loss: 0.0023430432192981243
Test Loss:  0.001989298965781927
Valid Loss:  0.0018866300815716386
Epoch:  41  	Training Loss: 0.0023142213467508554
Test Loss:  0.0019810290541499853
Valid Loss:  0.001891318242996931
Epoch:  42  	Training Loss: 0.002288621151819825
Test Loss:  0.0019743868615478277
Valid Loss:  0.001897548558190465
Epoch:  43  	Training Loss: 0.0022658759262412786
Test Loss:  0.001969191012904048
Valid Loss:  0.001905022538267076
Epoch:  44  	Training Loss: 0.0022456736769527197
Test Loss:  0.0019652266055345535
Valid Loss:  0.0019134929170832038
Epoch:  45  	Training Loss: 0.0022277305833995342
Test Loss:  0.0019623208791017532
Valid Loss:  0.0019227380398660898
Epoch:  46  	Training Loss: 0.0022117907647043467
Test Loss:  0.0019603190012276173
Valid Loss:  0.001932577695697546
Epoch:  47  	Training Loss: 0.0021976318676024675
Test Loss:  0.0019591753371059895
Valid Loss:  0.0019428222440183163
Epoch:  48  	Training Loss: 0.0021850604098290205
Test Loss:  0.0019586216658353806
Valid Loss:  0.001953381346538663
Epoch:  49  	Training Loss: 0.0021738954819738865
Test Loss:  0.001958593726158142
Valid Loss:  0.001964119030162692
Epoch:  50  	Training Loss: 0.002163978759199381
Test Loss:  0.0019591955933719873
Valid Loss:  0.0019749021157622337
Epoch:  51  	Training Loss: 0.0021551758982241154
Test Loss:  0.00196006428450346
Valid Loss:  0.0019857101142406464
Epoch:  52  	Training Loss: 0.0021473574452102184
Test Loss:  0.0019611981697380543
Valid Loss:  0.0019964645616710186
Epoch:  53  	Training Loss: 0.0021404135040938854
Test Loss:  0.0019627101719379425
Valid Loss:  0.00200706091709435
Epoch:  54  	Training Loss: 0.0021342476829886436
Test Loss:  0.0019642282277345657
Valid Loss:  0.002017531543970108
Epoch:  55  	Training Loss: 0.0021287724375724792
Test Loss:  0.0019660741090774536
Valid Loss:  0.0020277430303394794
Epoch:  56  	Training Loss: 0.002123910002410412
Test Loss:  0.0019678673706948757
Valid Loss:  0.002037755213677883
Epoch:  57  	Training Loss: 0.002119592856615782
Test Loss:  0.001969883218407631
Valid Loss:  0.0020474614575505257
Epoch:  58  	Training Loss: 0.0021157576702535152
Test Loss:  0.0019719600677490234
Valid Loss:  0.002056877128779888
Epoch:  59  	Training Loss: 0.0021123532205820084
Test Loss:  0.0019739805720746517
Valid Loss:  0.002066022716462612
Epoch:  60  	Training Loss: 0.002109329681843519
Test Loss:  0.001976108644157648
Valid Loss:  0.0020748255774378777
Epoch:  61  	Training Loss: 0.00210664258338511
Test Loss:  0.001978208776563406
Valid Loss:  0.002083323895931244
Epoch:  62  	Training Loss: 0.0021042600274086
Test Loss:  0.001980288652703166
Valid Loss:  0.0020915023051202297
Epoch:  63  	Training Loss: 0.002102141035720706
Test Loss:  0.0019823452457785606
Valid Loss:  0.0020993570797145367
Epoch:  64  	Training Loss: 0.0021002613939344883
Test Loss:  0.0019843655172735453
Valid Loss:  0.002106892643496394
Epoch:  65  	Training Loss: 0.002098590135574341
Test Loss:  0.001986345974728465
Valid Loss:  0.002114109694957733
Epoch:  66  	Training Loss: 0.0020971070043742657
Test Loss:  0.0019882775377482176
Valid Loss:  0.002121020806953311
Epoch:  67  	Training Loss: 0.0020957894157618284
Test Loss:  0.0019901602063328028
Valid Loss:  0.0021276199258863926
Epoch:  68  	Training Loss: 0.0020946203731000423
Test Loss:  0.0019919865299016237
Valid Loss:  0.002133925911039114
Epoch:  69  	Training Loss: 0.0020935796201229095
Test Loss:  0.001993756275624037
Valid Loss:  0.0021399338729679585
Epoch:  70  	Training Loss: 0.002092655748128891
Test Loss:  0.0019954689778387547
Valid Loss:  0.002145663369446993
 14%|█▍        | 71/500 [00:55<08:38,  1.21s/it] 15%|█▍        | 73/500 [00:56<06:10,  1.15it/s] 15%|█▌        | 75/500 [00:56<04:26,  1.60it/s] 15%|█▌        | 77/500 [00:56<03:15,  2.16it/s] 16%|█▌        | 79/500 [00:56<02:27,  2.86it/s] 16%|█▌        | 81/500 [01:02<08:29,  1.22s/it] 17%|█▋        | 83/500 [01:03<06:04,  1.14it/s] 17%|█▋        | 85/500 [01:03<04:21,  1.58it/s] 17%|█▋        | 87/500 [01:03<03:10,  2.17it/s] 18%|█▊        | 89/500 [01:03<02:20,  2.92it/s] 18%|█▊        | 91/500 [01:09<08:13,  1.21s/it] 19%|█▊        | 93/500 [01:10<05:52,  1.15it/s] 19%|█▉        | 95/500 [01:10<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:10<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:10<02:15,  2.95it/s] 20%|██        | 101/500 [01:16<07:55,  1.19s/it] 21%|██        | 103/500 [01:16<05:38,  1.17it/s] 21%|██        | 105/500 [01:17<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:17<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:17<02:15,  2.88it/s] 22%|██▏       | 111/500 [01:23<07:48,  1.20s/it] 23%|██▎       | 113/500 [01:24<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:24<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:24<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:24<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:30<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:30<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:31<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:31<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:31<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:37<07:19,  1.19s/it] 27%|██▋       | 133/500 [01:37<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:44<09:31,  1.57s/it] 27%|██▋       | 137/500 [01:44<06:45,  1.12s/it]Epoch:  71  	Training Loss: 0.0020918352529406548
Test Loss:  0.0019971129950135946
Valid Loss:  0.0021511204540729523
Epoch:  72  	Training Loss: 0.0020911074243485928
Test Loss:  0.001998762832954526
Valid Loss:  0.002156293485313654
Epoch:  73  	Training Loss: 0.0020904620178043842
Test Loss:  0.002000328153371811
Valid Loss:  0.002161222044378519
Epoch:  74  	Training Loss: 0.002089887857437134
Test Loss:  0.0020018061622977257
Valid Loss:  0.0021659121848642826
Epoch:  75  	Training Loss: 0.002089378423988819
Test Loss:  0.0020032154861837626
Valid Loss:  0.0021703762467950583
Epoch:  76  	Training Loss: 0.0020889253355562687
Test Loss:  0.0020045628771185875
Valid Loss:  0.0021746153943240643
Epoch:  77  	Training Loss: 0.0020885232370346785
Test Loss:  0.002005847869440913
Valid Loss:  0.0021786384750157595
Epoch:  78  	Training Loss: 0.0020881660748273134
Test Loss:  0.0020070758182555437
Valid Loss:  0.0021824571304023266
Epoch:  79  	Training Loss: 0.002087849425151944
Test Loss:  0.002008246723562479
Valid Loss:  0.0021860776469111443
Epoch:  80  	Training Loss: 0.0020875674672424793
Test Loss:  0.0020093610510230064
Valid Loss:  0.0021895100362598896
Epoch:  81  	Training Loss: 0.0020873171743005514
Test Loss:  0.002010426251217723
Valid Loss:  0.0021927570924162865
Epoch:  82  	Training Loss: 0.0020870943553745747
Test Loss:  0.0020114367362111807
Valid Loss:  0.002195836743339896
Epoch:  83  	Training Loss: 0.002086896914988756
Test Loss:  0.002012399025261402
Valid Loss:  0.002198752947151661
Epoch:  84  	Training Loss: 0.002086721360683441
Test Loss:  0.0020133161451667547
Valid Loss:  0.0022015131544321775
Epoch:  85  	Training Loss: 0.002086565364152193
Test Loss:  0.002014182973653078
Valid Loss:  0.0022041210904717445
Epoch:  86  	Training Loss: 0.0020864277612417936
Test Loss:  0.0020150095224380493
Valid Loss:  0.0022065918892621994
Epoch:  87  	Training Loss: 0.002086303662508726
Test Loss:  0.0020157918334007263
Valid Loss:  0.0022089246194809675
Epoch:  88  	Training Loss: 0.002086193300783634
Test Loss:  0.0020165364257991314
Valid Loss:  0.0022111355792731047
Epoch:  89  	Training Loss: 0.002086095977574587
Test Loss:  0.002017243066802621
Valid Loss:  0.0022132217418402433
Epoch:  90  	Training Loss: 0.002086008433252573
Test Loss:  0.0020179084967821836
Valid Loss:  0.0022151926532387733
Epoch:  91  	Training Loss: 0.0020859315991401672
Test Loss:  0.002018546685576439
Valid Loss:  0.002217057393863797
Epoch:  92  	Training Loss: 0.0020858636125922203
Test Loss:  0.0020191476214677095
Valid Loss:  0.0022188143339008093
Epoch:  93  	Training Loss: 0.0020858014468103647
Test Loss:  0.002019711537286639
Valid Loss:  0.002220476046204567
Epoch:  94  	Training Loss: 0.002085748128592968
Test Loss:  0.0020202528685331345
Valid Loss:  0.002222046721726656
Epoch:  95  	Training Loss: 0.0020856994669884443
Test Loss:  0.002020759042352438
Valid Loss:  0.002223529852926731
Epoch:  96  	Training Loss: 0.002085657324641943
Test Loss:  0.0020212368108332157
Valid Loss:  0.002224927069619298
Epoch:  97  	Training Loss: 0.002085618209093809
Test Loss:  0.00202176277525723
Valid Loss:  0.002226227894425392
Epoch:  98  	Training Loss: 0.0020855856128036976
Test Loss:  0.0020222067832946777
Valid Loss:  0.002227476565167308
Epoch:  99  	Training Loss: 0.0020855553448200226
Test Loss:  0.0020225851330906153
Valid Loss:  0.002228674478828907
Epoch:  100  	Training Loss: 0.002085530199110508
Test Loss:  0.0020230086520314217
Valid Loss:  0.0022297766990959644
Epoch:  101  	Training Loss: 0.0020855048205703497
Test Loss:  0.0020233900286257267
Valid Loss:  0.0022308288607746363
Epoch:  102  	Training Loss: 0.002085484331473708
Test Loss:  0.002023727633059025
Valid Loss:  0.0022318316623568535
Epoch:  103  	Training Loss: 0.0020854671020060778
Test Loss:  0.002024013316258788
Valid Loss:  0.002232789061963558
Epoch:  104  	Training Loss: 0.0020854496397078037
Test Loss:  0.002024357207119465
Valid Loss:  0.0022336612455546856
Epoch:  105  	Training Loss: 0.002085436135530472
Test Loss:  0.0020246633794158697
Valid Loss:  0.002234495710581541
Epoch:  106  	Training Loss: 0.00208542263135314
Test Loss:  0.0020249418448656797
Valid Loss:  0.002235284075140953
Epoch:  107  	Training Loss: 0.002085411688312888
Test Loss:  0.0020252056419849396
Valid Loss:  0.002236027270555496
Epoch:  108  	Training Loss: 0.0020854007452726364
Test Loss:  0.002025438705459237
Valid Loss:  0.00223674182780087
Epoch:  109  	Training Loss: 0.0020853918977081776
Test Loss:  0.0020256254356354475
Valid Loss:  0.0022374256514012814
Epoch:  110  	Training Loss: 0.002085383515805006
Test Loss:  0.002025878755375743
Valid Loss:  0.0022380331065505743
Epoch:  111  	Training Loss: 0.0020853769965469837
Test Loss:  0.002026099944487214
Valid Loss:  0.0022386168129742146
Epoch:  112  	Training Loss: 0.0020853709429502487
Test Loss:  0.0020263008773326874
Valid Loss:  0.002239175606518984
Epoch:  113  	Training Loss: 0.0020853644236922264
Test Loss:  0.0020264890044927597
Valid Loss:  0.002239698776975274
Epoch:  114  	Training Loss: 0.002085359301418066
Test Loss:  0.0020266652572900057
Valid Loss:  0.0022401942405849695
Epoch:  115  	Training Loss: 0.002085355343297124
Test Loss:  0.0020268280059099197
Valid Loss:  0.002240662230178714
Epoch:  116  	Training Loss: 0.0020853509195148945
Test Loss:  0.0020269681699573994
Valid Loss:  0.002241111360490322
Epoch:  117  	Training Loss: 0.0020853474270552397
Test Loss:  0.0020271227695047855
Valid Loss:  0.0022415248677134514
Epoch:  118  	Training Loss: 0.002085345331579447
Test Loss:  0.0020272645633667707
Valid Loss:  0.0022419127635657787
Epoch:  119  	Training Loss: 0.002085341140627861
Test Loss:  0.002027342561632395
Valid Loss:  0.0022423032205551863
Epoch:  120  	Training Loss: 0.002085339277982712
Test Loss:  0.002027495764195919
Valid Loss:  0.0022426326759159565
Epoch:  121  	Training Loss: 0.002085336484014988
Test Loss:  0.0020276219584047794
Valid Loss:  0.0022429581731557846
Epoch:  122  	Training Loss: 0.0020853369496762753
Test Loss:  0.002027737908065319
Valid Loss:  0.0022432603873312473
Epoch:  123  	Training Loss: 0.002085333224385977
Test Loss:  0.002027842914685607
Valid Loss:  0.00224356004036963
Epoch:  124  	Training Loss: 0.0020853313617408276
Test Loss:  0.002027939073741436
Valid Loss:  0.0022438326850533485
Epoch:  125  	Training Loss: 0.0020853299647569656
Test Loss:  0.0020280308090150356
Valid Loss:  0.0022440929897129536
Epoch:  126  	Training Loss: 0.002085329731926322
Test Loss:  0.002028117887675762
Valid Loss:  0.0022443393245339394
Epoch:  127  	Training Loss: 0.0020853294990956783
Test Loss:  0.0020281991455703974
Valid Loss:  0.002244567032903433
Epoch:  128  	Training Loss: 0.002085327170789242
Test Loss:  0.0020282771438360214
Valid Loss:  0.0022447858937084675
Epoch:  129  	Training Loss: 0.002085327170789242
Test Loss:  0.002028348622843623
Valid Loss:  0.002244994742795825
Epoch:  130  	Training Loss: 0.00208532577380538
Test Loss:  0.002028416143730283
Valid Loss:  0.002245183801278472
Epoch:  131  	Training Loss: 0.002085325075313449
Test Loss:  0.0020284801721572876
Valid Loss:  0.0022453684359788895
Epoch:  132  	Training Loss: 0.0020853248424828053
Test Loss:  0.0020285407081246376
Valid Loss:  0.002245538868010044
Epoch:  133  	Training Loss: 0.0020853225141763687
Test Loss:  0.0020285979844629765
Valid Loss:  0.0022457013837993145
Epoch:  134  	Training Loss: 0.0020853234454989433
Test Loss:  0.0020286384969949722
Valid Loss:  0.002245861105620861
Epoch:  135  	Training Loss: 0.0020853220485150814
Test Loss:  0.0020286974031478167
Valid Loss:  0.002245997078716755
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0020853225141763687
Test Loss:  0.0020287218503654003
Valid Loss:  0.002246064366772771
Epoch:  137  	Training Loss: 0.0020853225141763687
Test Loss:  0.002028746297582984
Valid Loss:  0.0022461311891674995
Epoch:  138  	Training Loss: 0.0020853220485150814
Test Loss:  0.002028772607445717
Valid Loss:  0.002246193354949355
 28%|██▊       | 139/500 [01:44<04:49,  1.25it/s] 28%|██▊       | 141/500 [01:57<14:32,  2.43s/it] 29%|██▊       | 143/500 [01:57<10:14,  1.72s/it] 29%|██▉       | 145/500 [01:57<07:14,  1.22s/it] 29%|██▉       | 147/500 [01:57<05:09,  1.14it/s] 30%|██▉       | 149/500 [01:57<03:42,  1.58it/s] 30%|██▉       | 149/500 [02:09<03:42,  1.58it/s] 30%|███       | 151/500 [02:10<13:37,  2.34s/it] 31%|███       | 153/500 [02:10<09:36,  1.66s/it] 31%|███       | 155/500 [02:10<06:47,  1.18s/it] 31%|███▏      | 157/500 [02:10<04:51,  1.18it/s] 32%|███▏      | 159/500 [02:10<03:31,  1.61it/s] 32%|███▏      | 161/500 [02:23<13:07,  2.32s/it] 33%|███▎      | 163/500 [02:23<09:15,  1.65s/it] 33%|███▎      | 165/500 [02:29<11:44,  2.10s/it] 33%|███▎      | 167/500 [02:30<08:19,  1.50s/it] 34%|███▍      | 169/500 [02:30<05:55,  1.08s/it] 34%|███▍      | 171/500 [02:42<14:29,  2.64s/it] 35%|███▍      | 173/500 [02:42<10:11,  1.87s/it] 35%|███▌      | 175/500 [02:49<12:16,  2.26s/it] 35%|███▌      | 177/500 [02:49<08:38,  1.61s/it] 36%|███▌      | 179/500 [02:49<06:07,  1.14s/it] 36%|███▌      | 181/500 [02:55<09:16,  1.75s/it] 37%|███▋      | 183/500 [02:56<06:34,  1.24s/it] 37%|███▋      | 185/500 [03:02<09:32,  1.82s/it] 37%|███▋      | 187/500 [03:02<06:44,  1.29s/it] 38%|███▊      | 189/500 [03:02<04:47,  1.08it/s] 38%|███▊      | 191/500 [03:15<13:08,  2.55s/it] 39%|███▊      | 193/500 [03:15<09:15,  1.81s/it] 39%|███▉      | 195/500 [03:21<11:23,  2.24s/it] 39%|███▉      | 197/500 [03:22<08:02,  1.59s/it]Epoch:  139  	Training Loss: 0.0020853225141763687
Test Loss:  0.002028791233897209
Valid Loss:  0.002246255986392498
Epoch:  140  	Training Loss: 0.0020853218156844378
Test Loss:  0.0020288145169615746
Valid Loss:  0.0022463155910372734
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.002085321582853794
Test Loss:  0.002028827089816332
Valid Loss:  0.002246343996375799
Epoch:  142  	Training Loss: 0.002085321117192507
Test Loss:  0.002028835006058216
Valid Loss:  0.002246372401714325
Epoch:  143  	Training Loss: 0.0020853206515312195
Test Loss:  0.0020288468804210424
Valid Loss:  0.0022464031353592873
Epoch:  144  	Training Loss: 0.002085321117192507
Test Loss:  0.0020288564264774323
Valid Loss:  0.002246432937681675
Epoch:  145  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028865274041891
Valid Loss:  0.0022464580833911896
Epoch:  146  	Training Loss: 0.0020853220485150814
Test Loss:  0.002028876217082143
Valid Loss:  0.0022464855574071407
Epoch:  147  	Training Loss: 0.0020853206515312195
Test Loss:  0.00202888622879982
Valid Loss:  0.002246514894068241
Epoch:  148  	Training Loss: 0.0020853220485150814
Test Loss:  0.002028893679380417
Valid Loss:  0.0022465416695922613
Epoch:  149  	Training Loss: 0.0020853220485150814
Test Loss:  0.0020289034582674503
Valid Loss:  0.002246567513793707
Epoch:  150  	Training Loss: 0.0020853218156844378
Test Loss:  0.002028912538662553
Valid Loss:  0.0022465907968580723
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0020853220485150814
Test Loss:  0.0020289174281060696
Valid Loss:  0.0022466019727289677
Epoch:  152  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289227832108736
Valid Loss:  0.0022466150112450123
Epoch:  153  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289262756705284
Valid Loss:  0.002246629213914275
Epoch:  154  	Training Loss: 0.002085320884361863
Test Loss:  0.0020289309322834015
Valid Loss:  0.0022466417867690325
Epoch:  155  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289337262511253
Valid Loss:  0.002246655523777008
Epoch:  156  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289390813559294
Valid Loss:  0.0022466660011559725
Epoch:  157  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028943970799446
Valid Loss:  0.002246677875518799
Epoch:  158  	Training Loss: 0.002085321117192507
Test Loss:  0.00202894676476717
Valid Loss:  0.0022466876544058323
Epoch:  159  	Training Loss: 0.002085321117192507
Test Loss:  0.002028948627412319
Valid Loss:  0.002246701391413808
Epoch:  160  	Training Loss: 0.002085320884361863
Test Loss:  0.002028954215347767
Valid Loss:  0.0022467137314379215
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289570093154907
Valid Loss:  0.002246720716357231
Epoch:  162  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289591047912836
Valid Loss:  0.0022467223461717367
Epoch:  163  	Training Loss: 0.002085321117192507
Test Loss:  0.002028961665928364
Valid Loss:  0.0022467318922281265
Epoch:  164  	Training Loss: 0.0020853220485150814
Test Loss:  0.00202896143309772
Valid Loss:  0.002246737014502287
Epoch:  165  	Training Loss: 0.0020853206515312195
Test Loss:  0.0020289658568799496
Valid Loss:  0.0022467421367764473
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0020853220485150814
Test Loss:  0.0020289644598960876
Valid Loss:  0.0022467474918812513
Epoch:  167  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289686508476734
Valid Loss:  0.002246747724711895
Epoch:  168  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289672538638115
Valid Loss:  0.0022467528469860554
Epoch:  169  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289700478315353
Valid Loss:  0.002246755175292492
Epoch:  170  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289714448153973
Valid Loss:  0.002246756572276354
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.002085321582853794
Test Loss:  0.002028971677646041
Valid Loss:  0.002246757037937641
Epoch:  172  	Training Loss: 0.002085321582853794
Test Loss:  0.002028971677646041
Valid Loss:  0.0022467593662440777
Epoch:  173  	Training Loss: 0.0020853218156844378
Test Loss:  0.0020289714448153973
Valid Loss:  0.0022467616945505142
Epoch:  174  	Training Loss: 0.002085320418700576
Test Loss:  0.00202897354029119
Valid Loss:  0.0022467616945505142
Epoch:  175  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289754029363394
Valid Loss:  0.0022467635571956635
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.002085322281345725
Test Loss:  0.0020289761014282703
Valid Loss:  0.0022467642556875944
Epoch:  177  	Training Loss: 0.0020853218156844378
Test Loss:  0.002028974937275052
Valid Loss:  0.002246767282485962
Epoch:  178  	Training Loss: 0.0020853218156844378
Test Loss:  0.0020289754029363394
Valid Loss:  0.0022467677481472492
Epoch:  179  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289747044444084
Valid Loss:  0.0022467656526714563
Epoch:  180  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467677481472492
Epoch:  181  	Training Loss: 0.002085320884361863
Test Loss:  0.0020289765670895576
Valid Loss:  0.002246767282485962
Epoch:  182  	Training Loss: 0.0020853206515312195
Test Loss:  0.0020289754029363394
Valid Loss:  0.0022467710077762604
Epoch:  183  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289754029363394
Valid Loss:  0.0022467703092843294
Epoch:  184  	Training Loss: 0.002085320185869932
Test Loss:  0.002028975635766983
Valid Loss:  0.002246772637590766
Epoch:  185  	Training Loss: 0.0020853206515312195
Test Loss:  0.0020289747044444084
Valid Loss:  0.0022467742674052715
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0020853206515312195
Test Loss:  0.0020289761014282703
Valid Loss:  0.002246773336082697
Epoch:  187  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289765670895576
Valid Loss:  0.002246774034574628
Epoch:  188  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  189  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289761014282703
Valid Loss:  0.00224677543155849
Epoch:  190  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289774984121323
Valid Loss:  0.0022467770613729954
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289765670895576
Valid Loss:  0.0022467761300504208
Epoch:  192  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467761300504208
Epoch:  193  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289767999202013
Valid Loss:  0.0022467763628810644
Epoch:  194  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289767999202013
Valid Loss:  0.002246775897219777
Epoch:  195  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246775198727846
Epoch:  197  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  198  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246775198727846
 40%|███▉      | 199/500 [03:22<05:41,  1.13s/it] 40%|████      | 201/500 [03:34<13:18,  2.67s/it] 41%|████      | 203/500 [03:34<09:21,  1.89s/it] 41%|████      | 205/500 [03:41<11:10,  2.27s/it] 41%|████▏     | 207/500 [03:41<07:52,  1.61s/it] 42%|████▏     | 209/500 [03:41<05:34,  1.15s/it] 42%|████▏     | 211/500 [03:53<12:51,  2.67s/it] 43%|████▎     | 213/500 [03:54<09:02,  1.89s/it] 43%|████▎     | 215/500 [04:00<10:47,  2.27s/it] 43%|████▎     | 217/500 [04:00<07:35,  1.61s/it] 44%|████▍     | 219/500 [04:00<05:22,  1.15s/it] 44%|████▍     | 221/500 [04:13<12:24,  2.67s/it] 45%|████▍     | 223/500 [04:13<08:43,  1.89s/it] 45%|████▌     | 225/500 [04:19<10:24,  2.27s/it] 45%|████▌     | 227/500 [04:19<07:20,  1.61s/it] 46%|████▌     | 229/500 [04:19<05:11,  1.15s/it] 46%|████▌     | 231/500 [04:32<12:04,  2.69s/it] 47%|████▋     | 233/500 [04:32<08:28,  1.91s/it] 47%|████▋     | 235/500 [04:38<10:07,  2.29s/it] 47%|████▋     | 237/500 [04:39<07:07,  1.63s/it] 48%|████▊     | 239/500 [04:39<05:02,  1.16s/it] 48%|████▊     | 239/500 [04:49<05:02,  1.16s/it] 48%|████▊     | 241/500 [04:51<11:37,  2.69s/it] 49%|████▊     | 243/500 [04:51<08:10,  1.91s/it] 49%|████▉     | 245/500 [04:58<09:39,  2.27s/it] 49%|████▉     | 247/500 [04:58<06:48,  1.61s/it] 50%|████▉     | 249/500 [04:58<04:48,  1.15s/it] 50%|████▉     | 249/500 [05:09<04:48,  1.15s/it] 50%|█████     | 251/500 [05:11<11:08,  2.69s/it] 51%|█████     | 253/500 [05:11<07:49,  1.90s/it]Epoch:  199  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  200  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  202  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  203  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  204  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  205  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  207  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  208  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  209  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  210  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  212  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  213  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  214  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  215  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  217  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  218  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  219  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  220  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  222  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  223  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  224  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  225  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  227  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  228  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  229  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  230  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246775198727846
Epoch:  232  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  233  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  234  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  235  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  237  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  238  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  239  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  240  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  242  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  243  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  244  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  245  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  247  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  248  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  249  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  250  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  252  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  253  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  254  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  255  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay************************************************** 51%|█████     | 255/500 [05:17<09:23,  2.30s/it] 51%|█████▏    | 257/500 [05:17<06:37,  1.64s/it] 52%|█████▏    | 259/500 [05:17<04:42,  1.17s/it] 52%|█████▏    | 259/500 [05:29<04:42,  1.17s/it] 52%|█████▏    | 261/500 [05:30<11:01,  2.77s/it] 53%|█████▎    | 263/500 [05:31<07:43,  1.96s/it] 53%|█████▎    | 265/500 [05:37<09:07,  2.33s/it] 53%|█████▎    | 267/500 [05:37<06:25,  1.65s/it] 54%|█████▍    | 269/500 [05:37<04:31,  1.18s/it] 54%|█████▍    | 269/500 [05:49<04:31,  1.18s/it] 54%|█████▍    | 271/500 [05:50<10:21,  2.71s/it] 55%|█████▍    | 273/500 [05:50<07:15,  1.92s/it] 55%|█████▌    | 275/500 [05:56<08:38,  2.30s/it] 55%|█████▌    | 277/500 [05:57<06:04,  1.63s/it] 56%|█████▌    | 279/500 [05:57<04:17,  1.16s/it] 56%|█████▌    | 279/500 [06:09<04:17,  1.16s/it] 56%|█████▌    | 281/500 [06:09<09:49,  2.69s/it] 57%|█████▋    | 283/500 [06:09<06:53,  1.90s/it] 57%|█████▋    | 285/500 [06:16<08:13,  2.30s/it] 57%|█████▋    | 287/500 [06:16<05:46,  1.63s/it] 58%|█████▊    | 289/500 [06:16<04:04,  1.16s/it] 58%|█████▊    | 291/500 [06:29<09:25,  2.71s/it] 59%|█████▊    | 293/500 [06:29<06:37,  1.92s/it] 59%|█████▉    | 295/500 [06:35<07:55,  2.32s/it] 59%|█████▉    | 297/500 [06:35<05:34,  1.65s/it] 60%|█████▉    | 299/500 [06:36<03:56,  1.18s/it] 60%|██████    | 301/500 [06:48<08:59,  2.71s/it] 61%|██████    | 303/500 [06:48<06:18,  1.92s/it] 61%|██████    | 305/500 [06:55<07:28,  2.30s/it] 61%|██████▏   | 307/500 [06:55<05:14,  1.63s/it] 62%|██████▏   | 309/500 [06:55<03:41,  1.16s/it] 62%|██████▏   | 311/500 [07:08<08:29,  2.70s/it]
Epoch:  256  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  257  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  258  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  259  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  260  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  262  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  263  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  264  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  265  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  267  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  268  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  269  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  270  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  272  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  273  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  274  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  275  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  277  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  278  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  279  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  280  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  282  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  283  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  284  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  285  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  287  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  288  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  289  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  290  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  292  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  293  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  294  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  295  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  297  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  298  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246774733066559
Epoch:  299  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  300  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  302  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  303  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  304  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  305  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  307  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  308  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  309  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  310  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  312  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246774733066559
Epoch:  313  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:   63%|██████▎   | 313/500 [07:08<05:57,  1.91s/it] 63%|██████▎   | 315/500 [07:14<07:06,  2.31s/it] 63%|██████▎   | 317/500 [07:14<04:59,  1.64s/it] 64%|██████▍   | 319/500 [07:14<03:30,  1.16s/it] 64%|██████▍   | 321/500 [07:27<08:05,  2.71s/it] 65%|██████▍   | 323/500 [07:27<05:39,  1.92s/it] 65%|██████▌   | 325/500 [07:33<06:38,  2.28s/it] 65%|██████▌   | 327/500 [07:34<04:39,  1.62s/it] 66%|██████▌   | 329/500 [07:34<03:16,  1.15s/it] 66%|██████▌   | 331/500 [07:46<07:32,  2.68s/it] 67%|██████▋   | 333/500 [07:46<05:16,  1.90s/it] 67%|██████▋   | 335/500 [07:53<06:14,  2.27s/it] 67%|██████▋   | 337/500 [07:53<04:22,  1.61s/it] 68%|██████▊   | 339/500 [07:53<03:04,  1.15s/it] 68%|██████▊   | 341/500 [08:05<07:05,  2.67s/it] 69%|██████▊   | 343/500 [08:06<04:57,  1.89s/it] 69%|██████▉   | 345/500 [08:12<05:53,  2.28s/it] 69%|██████▉   | 347/500 [08:12<04:07,  1.62s/it] 70%|██████▉   | 349/500 [08:12<02:53,  1.15s/it] 70%|███████   | 351/500 [08:25<06:41,  2.69s/it] 71%|███████   | 353/500 [08:25<04:40,  1.91s/it] 71%|███████   | 355/500 [08:31<05:31,  2.28s/it] 71%|███████▏  | 357/500 [08:31<03:52,  1.63s/it] 72%|███████▏  | 359/500 [08:32<02:44,  1.16s/it] 72%|███████▏  | 361/500 [08:45<06:22,  2.75s/it] 73%|███████▎  | 363/500 [08:45<04:26,  1.95s/it] 73%|███████▎  | 365/500 [08:51<05:13,  2.32s/it] 73%|███████▎  | 367/500 [08:51<03:38,  1.65s/it] 74%|███████▍  | 369/500 [08:51<02:33,  1.17s/it]0.002246774733066559
Epoch:  314  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  315  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  317  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  318  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  319  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  320  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  322  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  323  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  324  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  325  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  327  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  328  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  329  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  330  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  332  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  333  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  334  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  335  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  337  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  338  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  339  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  340  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  342  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  343  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  344  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  345  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  347  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  348  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  349  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  350  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  352  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  353  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  354  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  355  	Training Loss: 0.002085321117192507
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  357  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  358  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  359  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  360  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  362  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  363  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  364  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  365  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  367  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  368  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  369  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  370  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
 74%|███████▍  | 371/500 [09:04<05:49,  2.71s/it] 75%|███████▍  | 373/500 [09:04<04:03,  1.92s/it] 75%|███████▌  | 375/500 [09:10<04:45,  2.28s/it] 75%|███████▌  | 377/500 [09:10<03:19,  1.62s/it] 76%|███████▌  | 379/500 [09:11<02:19,  1.15s/it] 76%|███████▌  | 381/500 [09:23<05:19,  2.69s/it] 77%|███████▋  | 383/500 [09:23<03:42,  1.90s/it] 77%|███████▋  | 385/500 [09:30<04:21,  2.27s/it] 77%|███████▋  | 387/500 [09:30<03:02,  1.61s/it] 78%|███████▊  | 389/500 [09:30<02:07,  1.15s/it] 78%|███████▊  | 391/500 [09:42<04:53,  2.69s/it] 79%|███████▊  | 393/500 [09:43<03:23,  1.90s/it] 79%|███████▉  | 395/500 [09:49<03:59,  2.28s/it] 79%|███████▉  | 397/500 [09:49<02:46,  1.61s/it] 80%|███████▉  | 399/500 [09:49<01:56,  1.15s/it] 80%|████████  | 401/500 [10:02<04:25,  2.69s/it] 81%|████████  | 403/500 [10:02<03:04,  1.90s/it] 81%|████████  | 405/500 [10:08<03:37,  2.29s/it] 81%|████████▏ | 407/500 [10:08<02:31,  1.62s/it] 82%|████████▏ | 409/500 [10:08<01:45,  1.16s/it] 82%|████████▏ | 409/500 [10:19<01:45,  1.16s/it] 82%|████████▏ | 411/500 [10:21<03:59,  2.69s/it] 83%|████████▎ | 413/500 [10:21<02:45,  1.90s/it] 83%|████████▎ | 415/500 [10:27<03:13,  2.27s/it] 83%|████████▎ | 417/500 [10:28<02:14,  1.62s/it] 84%|████████▍ | 419/500 [10:28<01:33,  1.16s/it] 84%|████████▍ | 419/500 [10:39<01:33,  1.16s/it] 84%|████████▍ | 421/500 [10:40<03:32,  2.68s/it] 85%|████████▍ | 423/500 [10:40<02:26,  1.90s/it] 85%|████████▌ | 425/500 [10:47<02:49,  2.26s/it]**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  372  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  373  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  374  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  375  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  377  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  378  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  379  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  380  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  382  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  383  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  384  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  385  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  387  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  388  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  389  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  390  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  392  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  393  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  394  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  395  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  397  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  398  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  399  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  400  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  402  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  403  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  404  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  405  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  407  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  408  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  409  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  410  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  412  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  413  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  414  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  415  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  417  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  418  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  419  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  420  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  422  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  423  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  424  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  425  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  427  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:   85%|████████▌ | 427/500 [10:47<01:57,  1.61s/it] 86%|████████▌ | 429/500 [10:47<01:21,  1.14s/it] 86%|████████▌ | 429/500 [10:59<01:21,  1.14s/it] 86%|████████▌ | 431/500 [10:59<03:05,  2.69s/it] 87%|████████▋ | 433/500 [11:00<02:07,  1.91s/it] 87%|████████▋ | 435/500 [11:06<02:29,  2.30s/it] 87%|████████▋ | 437/500 [11:06<01:42,  1.63s/it] 88%|████████▊ | 439/500 [11:06<01:10,  1.16s/it] 88%|████████▊ | 441/500 [11:19<02:39,  2.70s/it] 89%|████████▊ | 443/500 [11:19<01:48,  1.91s/it] 89%|████████▉ | 445/500 [11:25<02:05,  2.29s/it] 89%|████████▉ | 447/500 [11:25<01:25,  1.62s/it] 90%|████████▉ | 449/500 [11:26<00:58,  1.15s/it] 90%|█████████ | 451/500 [11:38<02:12,  2.71s/it] 91%|█████████ | 453/500 [11:38<01:30,  1.92s/it] 91%|█████████ | 455/500 [11:45<01:43,  2.30s/it] 91%|█████████▏| 457/500 [11:45<01:10,  1.63s/it] 92%|█████████▏| 459/500 [11:45<00:47,  1.16s/it] 92%|█████████▏| 461/500 [11:58<01:45,  2.71s/it] 93%|█████████▎| 463/500 [11:58<01:11,  1.92s/it] 93%|█████████▎| 465/500 [12:04<01:21,  2.32s/it] 93%|█████████▎| 467/500 [12:05<00:54,  1.64s/it] 94%|█████████▍| 469/500 [12:05<00:36,  1.17s/it] 94%|█████████▍| 471/500 [12:17<01:19,  2.73s/it] 95%|█████████▍| 473/500 [12:18<00:52,  1.94s/it] 95%|█████████▌| 475/500 [12:24<00:58,  2.34s/it] 95%|█████████▌| 477/500 [12:24<00:38,  1.66s/it] 96%|█████████▌| 479/500 [12:24<00:24,  1.18s/it] 96%|█████████▌| 481/500 [12:37<00:52,  2.74s/it] 97%|█████████▋| 483/500 [12:37<00:33,  1.94s/it]0.0022467749658972025
Epoch:  428  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  429  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  430  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  432  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  433  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  434  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  435  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  437  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  438  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  439  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  440  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  442  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  443  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  444  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  445  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  447  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  448  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  449  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  450  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  452  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  453  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  454  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  455  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  457  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  458  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  459  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  460  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  462  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  463  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  464  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  465  	Training Loss: 0.002085321117192507
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  467  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  468  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  469  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  470  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  472  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  473  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  474  	Training Loss: 0.002085321582853794
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  475  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  477  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  478  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246775198727846
Epoch:  479  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  480  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  482  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  483  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  484  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  485  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
 97%|█████████▋| 485/500 [12:44<00:34,  2.32s/it] 97%|█████████▋| 487/500 [12:44<00:21,  1.65s/it] 98%|█████████▊| 489/500 [12:44<00:12,  1.17s/it] 98%|█████████▊| 491/500 [12:57<00:24,  2.71s/it] 99%|█████████▊| 493/500 [12:57<00:13,  1.92s/it] 99%|█████████▉| 495/500 [13:03<00:11,  2.29s/it] 99%|█████████▉| 497/500 [13:03<00:04,  1.62s/it]100%|█████████▉| 499/500 [13:03<00:01,  1.16s/it]100%|██████████| 500/500 [13:10<00:00,  1.58s/it]
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  487  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  488  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  489  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  490  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  492  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  493  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  494  	Training Loss: 0.0020853213500231504
Test Loss:  0.0020289772655814886
Valid Loss:  0.0022467749658972025
Epoch:  495  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  497  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  498  	Training Loss: 0.002085321582853794
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
Epoch:  499  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.002246774733066559
Epoch:  500  	Training Loss: 0.0020853213500231504
Test Loss:  0.002028977032750845
Valid Loss:  0.0022467749658972025
**************************************************learning rate decay**************************************************
seed is  6
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:08,  6.27s/it]  1%|          | 3/500 [00:06<13:53,  1.68s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:40,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:26<12:27,  1.57s/it]  5%|▌         | 27/500 [00:26<08:49,  1.12s/it]  6%|▌         | 29/500 [00:26<06:17,  1.25it/s]  6%|▌         | 31/500 [00:33<11:50,  1.52s/it]  7%|▋         | 33/500 [00:33<08:23,  1.08s/it]  7%|▋         | 35/500 [00:33<05:59,  1.29it/s]  7%|▋         | 37/500 [00:33<04:19,  1.78it/s]  8%|▊         | 39/500 [00:33<03:09,  2.43it/s]  8%|▊         | 41/500 [00:40<09:32,  1.25s/it]  9%|▊         | 43/500 [00:40<06:47,  1.12it/s]  9%|▉         | 45/500 [00:40<04:52,  1.55it/s]  9%|▉         | 47/500 [00:40<03:32,  2.13it/s] 10%|▉         | 49/500 [00:40<02:37,  2.87it/s] 10%|█         | 51/500 [00:46<08:55,  1.19s/it] 11%|█         | 53/500 [00:47<06:24,  1.16it/s] 11%|█         | 55/500 [00:47<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:47<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:47<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:53<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:54<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:54<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:54<03:20,  2.16it/s]Epoch:  1  	Training Loss: 0.0236221831291914
Test Loss:  0.007797903846949339
Valid Loss:  0.011706961318850517
Epoch:  2  	Training Loss: 0.016787443310022354
Test Loss:  0.032807689160108566
Valid Loss:  0.025563109666109085
Epoch:  3  	Training Loss: 0.02378934994339943
Test Loss:  0.019231412559747696
Valid Loss:  0.02688450738787651
Epoch:  4  	Training Loss: 0.03860686719417572
Test Loss:  0.022851333022117615
Valid Loss:  0.02418767474591732
Epoch:  5  	Training Loss: 0.022036023437976837
Test Loss:  0.018212832510471344
Valid Loss:  0.01879531890153885
Epoch:  6  	Training Loss: 0.01857452094554901
Test Loss:  0.009969498962163925
Valid Loss:  0.011243436485528946
Epoch:  7  	Training Loss: 0.013274921104311943
Test Loss:  0.0073399837128818035
Valid Loss:  0.008045814000070095
Epoch:  8  	Training Loss: 0.010633477941155434
Test Loss:  0.006203682627528906
Valid Loss:  0.006327478215098381
Epoch:  9  	Training Loss: 0.009155116975307465
Test Loss:  0.004508547484874725
Valid Loss:  0.004901065956801176
Epoch:  10  	Training Loss: 0.00787903368473053
Test Loss:  0.003352457657456398
Valid Loss:  0.003907416015863419
Epoch:  11  	Training Loss: 0.006568414159119129
Test Loss:  0.0024031540378928185
Valid Loss:  0.003494580276310444
Epoch:  12  	Training Loss: 0.005691674072295427
Test Loss:  0.0024715345352888107
Valid Loss:  0.0031612454913556576
Epoch:  13  	Training Loss: 0.005178341642022133
Test Loss:  0.002356166485697031
Valid Loss:  0.003141567576676607
Epoch:  14  	Training Loss: 0.0048670656979084015
Test Loss:  0.0025063820648938417
Valid Loss:  0.0030276807956397533
Epoch:  15  	Training Loss: 0.0046211956068873405
Test Loss:  0.0024080192670226097
Valid Loss:  0.0030781261157244444
Epoch:  16  	Training Loss: 0.004410157911479473
Test Loss:  0.0025072747375816107
Valid Loss:  0.0030073742382228374
Epoch:  17  	Training Loss: 0.004223655443638563
Test Loss:  0.0024797229561954737
Valid Loss:  0.0030309692956507206
Epoch:  18  	Training Loss: 0.004067491739988327
Test Loss:  0.002572430530562997
Valid Loss:  0.002971169538795948
Epoch:  19  	Training Loss: 0.003932706546038389
Test Loss:  0.002526074182242155
Valid Loss:  0.0030060214921832085
Epoch:  20  	Training Loss: 0.0038185562007129192
Test Loss:  0.0027069365605711937
Valid Loss:  0.0029174014925956726
Epoch:  21  	Training Loss: 0.003724462818354368
Test Loss:  0.0025085071101784706
Valid Loss:  0.0030560619197785854
Epoch:  22  	Training Loss: 0.0036642705090343952
Test Loss:  0.0030525820329785347
Valid Loss:  0.0028815562836825848
Epoch:  23  	Training Loss: 0.0036789551377296448
Test Loss:  0.0024034790694713593
Valid Loss:  0.003388261655345559
Epoch:  24  	Training Loss: 0.0037643529940396547
Test Loss:  0.0038097212091088295
Valid Loss:  0.0030215010046958923
Epoch:  25  	Training Loss: 0.003961929585784674
Test Loss:  0.0024471618235111237
Valid Loss:  0.0039335330948233604
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.004067332483828068
Test Loss:  0.0028459159657359123
Valid Loss:  0.002963777631521225
Epoch:  27  	Training Loss: 0.0034075037110596895
Test Loss:  0.0027061253786087036
Valid Loss:  0.003043218981474638
Epoch:  28  	Training Loss: 0.003381183836609125
Test Loss:  0.0027792660985141993
Valid Loss:  0.0030129561200737953
Epoch:  29  	Training Loss: 0.003364305477589369
Test Loss:  0.002764550969004631
Valid Loss:  0.0030340475495904684
Epoch:  30  	Training Loss: 0.00335181737318635
Test Loss:  0.0027886079624295235
Valid Loss:  0.003034568391740322
Epoch:  31  	Training Loss: 0.0033402247354388237
Test Loss:  0.0027891825884580612
Valid Loss:  0.003047666512429714
Epoch:  32  	Training Loss: 0.0033296188339591026
Test Loss:  0.0027995482087135315
Valid Loss:  0.003055316861718893
Epoch:  33  	Training Loss: 0.0033198329620063305
Test Loss:  0.002805023454129696
Valid Loss:  0.003065345110371709
Epoch:  34  	Training Loss: 0.003310716012492776
Test Loss:  0.0028084334917366505
Valid Loss:  0.003075855551287532
Epoch:  35  	Training Loss: 0.0033021001145243645
Test Loss:  0.0028114663437008858
Valid Loss:  0.003085863310843706
Epoch:  36  	Training Loss: 0.0032939717639237642
Test Loss:  0.002819373505190015
Valid Loss:  0.003092933911830187
Epoch:  37  	Training Loss: 0.003286383580416441
Test Loss:  0.0028227707371115685
Valid Loss:  0.003102031070739031
Epoch:  38  	Training Loss: 0.0032792987767606974
Test Loss:  0.0028342988807708025
Valid Loss:  0.003106825053691864
Epoch:  39  	Training Loss: 0.003272796981036663
Test Loss:  0.0028398470021784306
Valid Loss:  0.0031148346606642008
Epoch:  40  	Training Loss: 0.003266835119575262
Test Loss:  0.0028455043211579323
Valid Loss:  0.003122457303106785
Epoch:  41  	Training Loss: 0.003261246718466282
Test Loss:  0.0028485548682510853
Valid Loss:  0.0031309393234550953
Epoch:  42  	Training Loss: 0.00325593538582325
Test Loss:  0.002856235019862652
Valid Loss:  0.0031367302872240543
Epoch:  43  	Training Loss: 0.003251011949032545
Test Loss:  0.002859361469745636
Valid Loss:  0.0031446125358343124
Epoch:  44  	Training Loss: 0.0032464051619172096
Test Loss:  0.00286558223888278
Valid Loss:  0.0031505459919571877
Epoch:  45  	Training Loss: 0.0032421222422271967
Test Loss:  0.0028687207959592342
Valid Loss:  0.0031577586196362972
Epoch:  46  	Training Loss: 0.0032381443306803703
Test Loss:  0.002877666149288416
Valid Loss:  0.003161907894536853
Epoch:  47  	Training Loss: 0.003234465140849352
Test Loss:  0.0028832275420427322
Valid Loss:  0.003167941002175212
Epoch:  48  	Training Loss: 0.0032310630194842815
Test Loss:  0.0028859747108072042
Valid Loss:  0.003175025340169668
Epoch:  49  	Training Loss: 0.003227835986763239
Test Loss:  0.002893335185945034
Valid Loss:  0.0031795816030353308
Epoch:  50  	Training Loss: 0.003224838525056839
Test Loss:  0.0028961310163140297
Valid Loss:  0.0031862901523709297
Epoch:  51  	Training Loss: 0.003222072497010231
Test Loss:  0.0029023271054029465
Valid Loss:  0.003191034309566021
Epoch:  52  	Training Loss: 0.0032195087987929583
Test Loss:  0.00290494947694242
Valid Loss:  0.003197362879291177
Epoch:  53  	Training Loss: 0.003217074554413557
Test Loss:  0.002907038200646639
Valid Loss:  0.0032034183386713266
Epoch:  54  	Training Loss: 0.003214737866073847
Test Loss:  0.0029089609161019325
Valid Loss:  0.0032090144231915474
Epoch:  55  	Training Loss: 0.0032124854624271393
Test Loss:  0.002910722279921174
Valid Loss:  0.0032141900155693293
Epoch:  56  	Training Loss: 0.003210308263078332
Test Loss:  0.0029123430140316486
Valid Loss:  0.0032189595513045788
Epoch:  57  	Training Loss: 0.0032081929966807365
Test Loss:  0.0029138391837477684
Valid Loss:  0.0032233474776148796
Epoch:  58  	Training Loss: 0.0032061352394521236
Test Loss:  0.002920313272625208
Valid Loss:  0.0032252026721835136
Epoch:  59  	Training Loss: 0.0032042507082223892
Test Loss:  0.0029172380454838276
Valid Loss:  0.0032316227443516254
Epoch:  60  	Training Loss: 0.003202409017831087
Test Loss:  0.0029230203945189714
Valid Loss:  0.003233057912439108
Epoch:  61  	Training Loss: 0.0032006637193262577
Test Loss:  0.002928508212789893
Valid Loss:  0.0032350944820791483
Epoch:  62  	Training Loss: 0.0031990925781428814
Test Loss:  0.0029305745847523212
Valid Loss:  0.0032389299012720585
Epoch:  63  	Training Loss: 0.0031976806931197643
Test Loss:  0.002942299470305443
Valid Loss:  0.00323851453140378
Epoch:  64  	Training Loss: 0.0031963714864104986
Test Loss:  0.0029347629752010107
Valid Loss:  0.0032474342733621597
Epoch:  65  	Training Loss: 0.0031951519194990396
Test Loss:  0.0029534511268138885
Valid Loss:  0.0032435799948871136
Epoch:  66  	Training Loss: 0.0031940583139657974
Test Loss:  0.0029411460272967815
Valid Loss:  0.0032549877651035786
Epoch:  67  	Training Loss: 0.0031932450365275145
Test Loss:  0.002972112502902746
Valid Loss:  0.0032462365925312042
Epoch:  68  	Training Loss: 0.003192614298313856
Test Loss:  0.0029437656048685312
Valid Loss:  0.0032657168339937925
Epoch:  69  	Training Loss: 0.0031917523592710495
Test Loss:  0.002978813135996461
Valid Loss:   14%|█▍        | 69/500 [00:54<02:28,  2.90it/s] 14%|█▍        | 71/500 [01:00<08:30,  1.19s/it] 15%|█▍        | 73/500 [01:00<06:04,  1.17it/s] 15%|█▌        | 75/500 [01:01<04:22,  1.62it/s] 15%|█▌        | 77/500 [01:01<03:10,  2.22it/s] 16%|█▌        | 79/500 [01:01<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:07<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:07<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:08<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:08<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:08<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:14<08:05,  1.19s/it] 19%|█▊        | 93/500 [01:14<05:46,  1.17it/s] 19%|█▉        | 95/500 [01:14<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:15<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:15<02:14,  2.98it/s] 20%|██        | 101/500 [01:21<07:54,  1.19s/it] 21%|██        | 103/500 [01:21<05:38,  1.17it/s] 21%|██        | 105/500 [01:21<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:21<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:22<02:14,  2.90it/s] 22%|██▏       | 111/500 [01:28<08:02,  1.24s/it] 23%|██▎       | 113/500 [01:28<05:44,  1.12it/s] 23%|██▎       | 115/500 [01:29<04:07,  1.56it/s] 23%|██▎       | 117/500 [01:29<02:59,  2.13it/s] 24%|██▍       | 119/500 [01:29<02:12,  2.88it/s] 24%|██▍       | 121/500 [01:35<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:35<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:35<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:35<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:36<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:42<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:42<05:12,  1.17it/s] 27%|██▋       | 135/500 [01:42<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:42<02:43,  2.22it/s]0.003254157956689596
Epoch:  70  	Training Loss: 0.00319095840677619
Test Loss:  0.002948290202766657
Valid Loss:  0.0032742461189627647
Epoch:  71  	Training Loss: 0.0031904347706586123
Test Loss:  0.002987106330692768
Valid Loss:  0.003260653465986252
Epoch:  72  	Training Loss: 0.003189687617123127
Test Loss:  0.0029555216897279024
Valid Loss:  0.0032811311539262533
Epoch:  73  	Training Loss: 0.0031891311518847942
Test Loss:  0.00299032311886549
Valid Loss:  0.003269043518230319
Epoch:  74  	Training Loss: 0.0031883521005511284
Test Loss:  0.002961191348731518
Valid Loss:  0.0032878518104553223
Epoch:  75  	Training Loss: 0.003188107395544648
Test Loss:  0.002993198810145259
Valid Loss:  0.0032765958458185196
Epoch:  76  	Training Loss: 0.0031871788669377565
Test Loss:  0.0029745937790721655
Valid Loss:  0.0032904655672609806
Epoch:  77  	Training Loss: 0.0031867967918515205
Test Loss:  0.002996893599629402
Valid Loss:  0.0032844236120581627
Epoch:  78  	Training Loss: 0.0031863530166447163
Test Loss:  0.0029790184926241636
Valid Loss:  0.0032974244095385075
Epoch:  79  	Training Loss: 0.0031860261224210262
Test Loss:  0.0029995464719831944
Valid Loss:  0.0032916152849793434
Epoch:  80  	Training Loss: 0.003185647539794445
Test Loss:  0.002985673025250435
Valid Loss:  0.00330240186303854
Epoch:  81  	Training Loss: 0.0031853411346673965
Test Loss:  0.0030022573191672564
Valid Loss:  0.0032982586417347193
Epoch:  82  	Training Loss: 0.0031849732622504234
Test Loss:  0.002994868438690901
Valid Loss:  0.003305938560515642
Epoch:  83  	Training Loss: 0.0031847162172198296
Test Loss:  0.0030000959523022175
Valid Loss:  0.003306811675429344
Epoch:  84  	Training Loss: 0.0031844675540924072
Test Loss:  0.003001510864123702
Valid Loss:  0.003309683408588171
Epoch:  85  	Training Loss: 0.003184251021593809
Test Loss:  0.003002540674060583
Valid Loss:  0.0033124792389571667
Epoch:  86  	Training Loss: 0.0031840461306273937
Test Loss:  0.0030034631490707397
Valid Loss:  0.003315053414553404
Epoch:  87  	Training Loss: 0.0031838552094995975
Test Loss:  0.0030043069273233414
Valid Loss:  0.0033174112904816866
Epoch:  88  	Training Loss: 0.003183686640113592
Test Loss:  0.003010151442140341
Valid Loss:  0.0033176271244883537
Epoch:  89  	Training Loss: 0.0031835371628403664
Test Loss:  0.003006485290825367
Valid Loss:  0.003322191070765257
Epoch:  90  	Training Loss: 0.0031833606772124767
Test Loss:  0.003007723018527031
Valid Loss:  0.0033237652387470007
Epoch:  91  	Training Loss: 0.003183214459568262
Test Loss:  0.003012479515746236
Valid Loss:  0.0033239219337701797
Epoch:  92  	Training Loss: 0.0031830929219722748
Test Loss:  0.0030101111624389887
Valid Loss:  0.00332739413715899
Epoch:  93  	Training Loss: 0.0031829578801989555
Test Loss:  0.0030164276249706745
Valid Loss:  0.003326747100800276
Epoch:  94  	Training Loss: 0.0031828703358769417
Test Loss:  0.003011721419170499
Valid Loss:  0.0033312139566987753
Epoch:  95  	Training Loss: 0.0031827539205551147
Test Loss:  0.0030192723497748375
Valid Loss:  0.0033297534100711346
Epoch:  96  	Training Loss: 0.0031826687045395374
Test Loss:  0.0030140585731714964
Valid Loss:  0.0033343450631946325
Epoch:  97  	Training Loss: 0.003182574873790145
Test Loss:  0.003019357565790415
Valid Loss:  0.003333584638312459
Epoch:  98  	Training Loss: 0.003182477317750454
Test Loss:  0.0030188497621566057
Valid Loss:  0.003335838671773672
Epoch:  99  	Training Loss: 0.003182400017976761
Test Loss:  0.003022058866918087
Valid Loss:  0.0033362882677465677
Epoch:  100  	Training Loss: 0.0031823357567191124
Test Loss:  0.0030178497545421124
Valid Loss:  0.0033399215899407864
Epoch:  101  	Training Loss: 0.0031822817400097847
Test Loss:  0.003022832330316305
Valid Loss:  0.0033389662858098745
Epoch:  102  	Training Loss: 0.0031822072342038155
Test Loss:  0.003022516379132867
Valid Loss:  0.0033408203162252903
Epoch:  103  	Training Loss: 0.003182151820510626
Test Loss:  0.0030241282656788826
Valid Loss:  0.0033416333608329296
Epoch:  104  	Training Loss: 0.0031820996664464474
Test Loss:  0.00302469776943326
Valid Loss:  0.00334293395280838
Epoch:  105  	Training Loss: 0.003182051470503211
Test Loss:  0.003025150392204523
Valid Loss:  0.003344164229929447
Epoch:  106  	Training Loss: 0.003182005602866411
Test Loss:  0.003025559475645423
Valid Loss:  0.003345291595906019
Epoch:  107  	Training Loss: 0.0031819618307054043
Test Loss:  0.0030259317718446255
Valid Loss:  0.003346323501318693
Epoch:  108  	Training Loss: 0.0031819187570363283
Test Loss:  0.0030262735672295094
Valid Loss:  0.0033472636714577675
Epoch:  109  	Training Loss: 0.0031818789429962635
Test Loss:  0.0030265836976468563
Valid Loss:  0.003348124213516712
Epoch:  110  	Training Loss: 0.003181839594617486
Test Loss:  0.003026867751032114
Valid Loss:  0.0033489111810922623
Epoch:  111  	Training Loss: 0.003181800711899996
Test Loss:  0.00302712875418365
Valid Loss:  0.0033496287651360035
Epoch:  112  	Training Loss: 0.0031817639246582985
Test Loss:  0.0030273646116256714
Valid Loss:  0.0033502853475511074
Epoch:  113  	Training Loss: 0.0031817257404327393
Test Loss:  0.003027582075446844
Valid Loss:  0.003350883722305298
Epoch:  114  	Training Loss: 0.003181690350174904
Test Loss:  0.0030277795158326626
Valid Loss:  0.003351430408656597
Epoch:  115  	Training Loss: 0.003181654494255781
Test Loss:  0.0030279597267508507
Valid Loss:  0.003351930994540453
Epoch:  116  	Training Loss: 0.0031816186383366585
Test Loss:  0.003028126200661063
Valid Loss:  0.003352388506755233
Epoch:  117  	Training Loss: 0.0031815837137401104
Test Loss:  0.003028275677934289
Valid Loss:  0.0033528022468090057
Epoch:  118  	Training Loss: 0.0031815501861274242
Test Loss:  0.0030284132808446884
Valid Loss:  0.003353181527927518
Epoch:  119  	Training Loss: 0.003181514563038945
Test Loss:  0.0030285378452390432
Valid Loss:  0.0033535282127559185
Epoch:  120  	Training Loss: 0.0031814798712730408
Test Loss:  0.0030286512337625027
Valid Loss:  0.0033538478892296553
Epoch:  121  	Training Loss: 0.0031814458779990673
Test Loss:  0.0030287562403827906
Valid Loss:  0.0033541349694132805
Epoch:  122  	Training Loss: 0.003181411884725094
Test Loss:  0.003028850071132183
Valid Loss:  0.0033543985337018967
Epoch:  123  	Training Loss: 0.0031813778914511204
Test Loss:  0.0030289350543171167
Valid Loss:  0.003354638582095504
Epoch:  124  	Training Loss: 0.003181354608386755
Test Loss:  0.0030340952798724174
Valid Loss:  0.003352934494614601
Epoch:  125  	Training Loss: 0.003181345295161009
Test Loss:  0.0030297834891825914
Valid Loss:  0.0033557459246367216
Epoch:  126  	Training Loss: 0.0031812950037419796
Test Loss:  0.0030294868629425764
Valid Loss:  0.003356057219207287
Epoch:  127  	Training Loss: 0.0031812619417905807
Test Loss:  0.0030294915195554495
Valid Loss:  0.003356168046593666
Epoch:  128  	Training Loss: 0.0031812451779842377
Test Loss:  0.003034590743482113
Valid Loss:  0.00335433310829103
Epoch:  129  	Training Loss: 0.003181231440976262
Test Loss:  0.0030302435625344515
Valid Loss:  0.0033570192754268646
Epoch:  130  	Training Loss: 0.003181192558258772
Test Loss:  0.003031143918633461
Valid Loss:  0.0033567470964044333
Epoch:  131  	Training Loss: 0.0031811632215976715
Test Loss:  0.0030366566497832537
Valid Loss:  0.0033548977226018906
Epoch:  132  	Training Loss: 0.003181173000484705
Test Loss:  0.0030308563727885485
Valid Loss:  0.0033583231270313263
Epoch:  133  	Training Loss: 0.0031811376102268696
Test Loss:  0.0030343784019351006
Valid Loss:  0.0033569412771612406
Epoch:  134  	Training Loss: 0.0031811269000172615
Test Loss:  0.0030359458178281784
Valid Loss:  0.003356981324031949
Epoch:  135  	Training Loss: 0.0031811115331947803
Test Loss:  0.0030336740892380476
Valid Loss:  0.00335867190733552
Epoch:  136  	Training Loss: 0.0031810987275093794
Test Loss:  0.00303775817155838
Valid Loss:  0.003357416018843651
Epoch:  137  	Training Loss: 0.003181092906743288
Test Loss:  0.0030341993551701307
Valid Loss:  0.003359766211360693
Epoch:  138  	Training Loss: 0.003181078936904669
Test Loss:  0.0030381488613784313
Valid Loss:  0.003358467947691679
 28%|██▊       | 139/500 [01:43<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:49<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:49<05:02,  1.18it/s] 29%|██▉       | 145/500 [01:55<09:04,  1.53s/it] 29%|██▉       | 147/500 [01:55<06:26,  1.09s/it] 30%|██▉       | 149/500 [01:55<04:35,  1.27it/s] 30%|███       | 151/500 [02:02<08:37,  1.48s/it] 31%|███       | 153/500 [02:02<06:07,  1.06s/it] 31%|███       | 155/500 [02:02<04:22,  1.32it/s] 31%|███▏      | 157/500 [02:02<03:09,  1.81it/s] 32%|███▏      | 159/500 [02:02<02:18,  2.46it/s] 32%|███▏      | 159/500 [02:12<02:18,  2.46it/s] 32%|███▏      | 161/500 [02:15<12:24,  2.20s/it] 33%|███▎      | 163/500 [02:15<08:45,  1.56s/it] 33%|███▎      | 165/500 [02:15<06:11,  1.11s/it] 33%|███▎      | 167/500 [02:15<04:25,  1.26it/s] 34%|███▍      | 169/500 [02:16<03:11,  1.73it/s] 34%|███▍      | 171/500 [02:28<12:38,  2.31s/it] 35%|███▍      | 173/500 [02:28<08:56,  1.64s/it] 35%|███▌      | 175/500 [02:29<06:21,  1.17s/it] 35%|███▌      | 177/500 [02:29<04:33,  1.18it/s] 36%|███▌      | 179/500 [02:29<03:18,  1.62it/s] 36%|███▌      | 181/500 [02:41<12:18,  2.31s/it] 37%|███▋      | 183/500 [02:42<08:40,  1.64s/it] 37%|███▋      | 185/500 [02:48<10:57,  2.09s/it] 37%|███▋      | 187/500 [02:48<07:46,  1.49s/it] 38%|███▊      | 189/500 [02:48<05:32,  1.07s/it] 38%|███▊      | 191/500 [03:01<13:39,  2.65s/it] 39%|███▊      | 193/500 [03:01<09:36,  1.88s/it] 39%|███▉      | 195/500 [03:07<11:28,  2.26s/it] 39%|███▉      | 197/500 [03:07<08:05,  1.60s/it] 40%|███▉      | 199/500 [03:08<05:43,  1.14s/it]Epoch:  139  	Training Loss: 0.0031810675282031298
Test Loss:  0.0030345693230628967
Valid Loss:  0.0033607222139835358
Epoch:  140  	Training Loss: 0.003181064734235406
Test Loss:  0.0030397295486181974
Valid Loss:  0.003358878893777728
Epoch:  141  	Training Loss: 0.0031810514628887177
Test Loss:  0.0030337830539792776
Valid Loss:  0.0033621792681515217
Epoch:  142  	Training Loss: 0.0031810663640499115
Test Loss:  0.0030408776365220547
Valid Loss:  0.0033592849504202604
Epoch:  143  	Training Loss: 0.003181030508130789
Test Loss:  0.003039764706045389
Valid Loss:  0.0033608474768698215
Epoch:  144  	Training Loss: 0.0031810267828404903
Test Loss:  0.0030355839990079403
Valid Loss:  0.00336319487541914
Epoch:  145  	Training Loss: 0.003181037725880742
Test Loss:  0.0030415388755500317
Valid Loss:  0.0033608220983296633
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0031810144428163767
Test Loss:  0.003040919080376625
Valid Loss:  0.0033615604043006897
Epoch:  147  	Training Loss: 0.00318099744617939
Test Loss:  0.0030392385087907314
Valid Loss:  0.003362600691616535
Epoch:  148  	Training Loss: 0.0031810076907277107
Test Loss:  0.0030389796011149883
Valid Loss:  0.0033629154786467552
Epoch:  149  	Training Loss: 0.0031810030341148376
Test Loss:  0.003040741663426161
Valid Loss:  0.003362435381859541
Epoch:  150  	Training Loss: 0.003180993255227804
Test Loss:  0.003041609190404415
Valid Loss:  0.0033624444622546434
Epoch:  151  	Training Loss: 0.0031809918582439423
Test Loss:  0.0030385227873921394
Valid Loss:  0.003363992553204298
Epoch:  152  	Training Loss: 0.0031810030341148376
Test Loss:  0.0030399668030440807
Valid Loss:  0.0033635199069976807
Epoch:  153  	Training Loss: 0.003180993255227804
Test Loss:  0.0030414233915507793
Valid Loss:  0.003363178111612797
Epoch:  154  	Training Loss: 0.003180986037477851
Test Loss:  0.0030421193223446608
Valid Loss:  0.0033632400445640087
Epoch:  155  	Training Loss: 0.003180983942002058
Test Loss:  0.003038935363292694
Valid Loss:  0.0033648021053522825
Epoch:  156  	Training Loss: 0.003180996049195528
Test Loss:  0.003040328621864319
Valid Loss:  0.003364317584782839
Epoch:  157  	Training Loss: 0.003180987201631069
Test Loss:  0.0030417335219681263
Valid Loss:  0.003363954136148095
Epoch:  158  	Training Loss: 0.0031809804495424032
Test Loss:  0.0030424068681895733
Valid Loss:  0.0033639909233897924
Epoch:  159  	Training Loss: 0.0031809769570827484
Test Loss:  0.0030429810285568237
Valid Loss:  0.003364107571542263
Epoch:  160  	Training Loss: 0.0031809816136956215
Test Loss:  0.003039573086425662
Valid Loss:  0.0033657453022897243
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.003180988132953644
Test Loss:  0.00304019870236516
Valid Loss:  0.003365514101460576
Epoch:  162  	Training Loss: 0.0031809830106794834
Test Loss:  0.003041006624698639
Valid Loss:  0.0033652461133897305
Epoch:  163  	Training Loss: 0.003180979285389185
Test Loss:  0.0030416417866945267
Valid Loss:  0.0033650805708020926
Epoch:  164  	Training Loss: 0.0031809755600988865
Test Loss:  0.003042142139747739
Valid Loss:  0.003364992793649435
Epoch:  165  	Training Loss: 0.0031809741631150246
Test Loss:  0.0030421516858041286
Valid Loss:  0.0033651061821728945
Epoch:  166  	Training Loss: 0.0031809736974537373
Test Loss:  0.0030425558798015118
Valid Loss:  0.0033650705590844154
Epoch:  167  	Training Loss: 0.0031809716019779444
Test Loss:  0.003042879281565547
Valid Loss:  0.003365080337971449
Epoch:  168  	Training Loss: 0.003180970437824726
Test Loss:  0.0030431414488703012
Valid Loss:  0.0033651222474873066
Epoch:  169  	Training Loss: 0.0031809713691473007
Test Loss:  0.003041471354663372
Valid Loss:  0.0033658945467323065
Epoch:  170  	Training Loss: 0.0031809741631150246
Test Loss:  0.0030420541297644377
Valid Loss:  0.0033657392486929893
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0031809713691473007
Test Loss:  0.003042096272110939
Valid Loss:  0.0033657695166766644
Epoch:  172  	Training Loss: 0.0031809713691473007
Test Loss:  0.003042318858206272
Valid Loss:  0.0033657304011285305
Epoch:  173  	Training Loss: 0.003180969972163439
Test Loss:  0.0030425237491726875
Valid Loss:  0.003365702461451292
Epoch:  174  	Training Loss: 0.0031809688080102205
Test Loss:  0.0030427086167037487
Valid Loss:  0.0033656852319836617
Epoch:  175  	Training Loss: 0.0031809688080102205
Test Loss:  0.0030428748577833176
Valid Loss:  0.0033656798768788576
Epoch:  176  	Training Loss: 0.0031809688080102205
Test Loss:  0.00304302666336298
Valid Loss:  0.003365681506693363
Epoch:  177  	Training Loss: 0.003180967178195715
Test Loss:  0.003042974742129445
Valid Loss:  0.0033657641615718603
Epoch:  178  	Training Loss: 0.0031809676438570023
Test Loss:  0.003043110016733408
Valid Loss:  0.003365770447999239
Epoch:  179  	Training Loss: 0.0031809674110263586
Test Loss:  0.0030432408675551414
Valid Loss:  0.0033657841850072145
Epoch:  180  	Training Loss: 0.0031809681095182896
Test Loss:  0.003042536787688732
Valid Loss:  0.0033661117777228355
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.0031809681095182896
Test Loss:  0.0030425735749304295
Valid Loss:  0.0033661196939647198
Epoch:  182  	Training Loss: 0.003180968575179577
Test Loss:  0.0030426704324781895
Valid Loss:  0.0033661052584648132
Epoch:  183  	Training Loss: 0.0031809681095182896
Test Loss:  0.003042763564735651
Valid Loss:  0.003366095945239067
Epoch:  184  	Training Loss: 0.0031809681095182896
Test Loss:  0.003042848315089941
Valid Loss:  0.0033660894259810448
Epoch:  185  	Training Loss: 0.0031809667125344276
Test Loss:  0.0030429307371377945
Valid Loss:  0.0033660833723843098
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0031809667125344276
Test Loss:  0.0030429710168391466
Valid Loss:  0.0033660801127552986
Epoch:  187  	Training Loss: 0.003180967178195715
Test Loss:  0.0030430094338953495
Valid Loss:  0.0033660796470940113
Epoch:  188  	Training Loss: 0.003180967178195715
Test Loss:  0.003043046221137047
Valid Loss:  0.003366079879924655
Epoch:  189  	Training Loss: 0.003180965781211853
Test Loss:  0.003043051343411207
Valid Loss:  0.003366089891642332
Epoch:  190  	Training Loss: 0.003180965781211853
Test Loss:  0.0030430899932980537
Valid Loss:  0.003366091987118125
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.003180965781211853
Test Loss:  0.0030431076884269714
Valid Loss:  0.0033660917542874813
Epoch:  192  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030431211926043034
Valid Loss:  0.0033660936169326305
Epoch:  193  	Training Loss: 0.003180965781211853
Test Loss:  0.003043118864297867
Valid Loss:  0.0033661010675132275
Epoch:  194  	Training Loss: 0.003180965781211853
Test Loss:  0.003043136326596141
Valid Loss:  0.003366099437698722
Epoch:  195  	Training Loss: 0.0031809662468731403
Test Loss:  0.003043154254555702
Valid Loss:  0.0033660996705293655
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0031809660140424967
Test Loss:  0.003043161705136299
Valid Loss:  0.0033661015331745148
Epoch:  197  	Training Loss: 0.0031809660140424967
Test Loss:  0.0030431703198701143
Valid Loss:  0.0033660996705293655
Epoch:  198  	Training Loss: 0.003180965781211853
Test Loss:  0.003043179167434573
Valid Loss:  0.00336610060185194
Epoch:  199  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043187316507101
Valid Loss:  0.003366101300343871
Epoch:  200  	Training Loss: 0.003180965781211853
Test Loss:  0.0030431959312409163
Valid Loss:   40%|████      | 201/500 [03:14<08:41,  1.74s/it] 41%|████      | 203/500 [03:14<06:08,  1.24s/it] 41%|████      | 205/500 [03:20<08:54,  1.81s/it] 41%|████▏     | 207/500 [03:20<06:17,  1.29s/it] 42%|████▏     | 209/500 [03:21<04:27,  1.09it/s] 42%|████▏     | 209/500 [03:32<04:27,  1.09it/s] 42%|████▏     | 211/500 [03:33<12:14,  2.54s/it] 43%|████▎     | 213/500 [03:33<08:36,  1.80s/it] 43%|████▎     | 215/500 [03:40<10:28,  2.21s/it] 43%|████▎     | 217/500 [03:40<07:23,  1.57s/it] 44%|████▍     | 219/500 [03:40<05:13,  1.12s/it] 44%|████▍     | 219/500 [03:52<05:13,  1.12s/it] 44%|████▍     | 221/500 [03:53<12:26,  2.68s/it] 45%|████▍     | 223/500 [03:53<08:44,  1.90s/it] 45%|████▌     | 225/500 [03:53<06:10,  1.35s/it] 45%|████▌     | 227/500 [03:53<04:22,  1.04it/s] 46%|████▌     | 229/500 [03:53<03:07,  1.44it/s] 46%|████▌     | 231/500 [04:06<10:35,  2.36s/it] 47%|████▋     | 233/500 [04:06<07:27,  1.68s/it] 47%|████▋     | 235/500 [04:06<05:15,  1.19s/it] 47%|████▋     | 237/500 [04:06<03:44,  1.17it/s] 48%|████▊     | 239/500 [04:06<02:41,  1.62it/s] 48%|████▊     | 241/500 [04:19<10:05,  2.34s/it] 49%|████▊     | 243/500 [04:19<07:05,  1.66s/it] 49%|████▉     | 245/500 [04:26<09:07,  2.15s/it] 49%|████▉     | 247/500 [04:26<06:25,  1.52s/it] 50%|████▉     | 249/500 [04:26<04:32,  1.09s/it] 50%|█████     | 251/500 [04:39<11:09,  2.69s/it] 51%|█████     | 253/500 [04:39<07:49,  1.90s/it] 51%|█████     | 255/500 [04:45<09:23,  2.30s/it] 51%|█████▏    | 257/500 [04:45<06:36,  1.63s/it] 52%|█████▏    | 259/500 [04:46<04:40,  1.16s/it]0.00336610060185194
Epoch:  201  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432050116360188
Valid Loss:  0.0033661024644970894
Epoch:  202  	Training Loss: 0.0031809653155505657
Test Loss:  0.003043213626369834
Valid Loss:  0.0033661015331745148
Epoch:  203  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432227067649364
Valid Loss:  0.003366103395819664
Epoch:  204  	Training Loss: 0.003180964384227991
Test Loss:  0.0030432299245148897
Valid Loss:  0.003366101998835802
Epoch:  205  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432387720793486
Valid Loss:  0.003366103395819664
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.0031809662468731403
Test Loss:  0.0030432366766035557
Valid Loss:  0.0033661071211099625
Epoch:  207  	Training Loss: 0.0031809648498892784
Test Loss:  0.0030432401690632105
Valid Loss:  0.0033661064226180315
Epoch:  208  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432443600147963
Valid Loss:  0.003366106655448675
Epoch:  209  	Training Loss: 0.003180965082719922
Test Loss:  0.0030432483181357384
Valid Loss:  0.003366108052432537
Epoch:  210  	Training Loss: 0.0031809653155505657
Test Loss:  0.003043251810595393
Valid Loss:  0.003366105956956744
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432536732405424
Valid Loss:  0.0033661078196018934
Epoch:  212  	Training Loss: 0.003180965781211853
Test Loss:  0.003043255303055048
Valid Loss:  0.0033661082852631807
Epoch:  213  	Training Loss: 0.0031809653155505657
Test Loss:  0.003043258562684059
Valid Loss:  0.003366108052432537
Epoch:  214  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432594940066338
Valid Loss:  0.0033661092165857553
Epoch:  215  	Training Loss: 0.003180965082719922
Test Loss:  0.0030432604253292084
Valid Loss:  0.0033661103807389736
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043262055143714
Valid Loss:  0.0033661106135696173
Epoch:  217  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432625208050013
Valid Loss:  0.0033661092165857553
Epoch:  218  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432622879743576
Valid Loss:  0.0033661092165857553
Epoch:  219  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432622879743576
Valid Loss:  0.003366109449416399
Epoch:  220  	Training Loss: 0.0031809662468731403
Test Loss:  0.0030432636849582195
Valid Loss:  0.003366108750924468
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432650819420815
Valid Loss:  0.003366109449416399
Epoch:  222  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432662460952997
Valid Loss:  0.003366109449416399
Epoch:  223  	Training Loss: 0.003180965082719922
Test Loss:  0.0030432669445872307
Valid Loss:  0.003366109449416399
Epoch:  224  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432664789259434
Valid Loss:  0.0033661092165857553
Epoch:  225  	Training Loss: 0.0031809648498892784
Test Loss:  0.0030432664789259434
Valid Loss:  0.0033661082852631807
Epoch:  226  	Training Loss: 0.003180965781211853
Test Loss:  0.003043268108740449
Valid Loss:  0.0033661071211099625
Epoch:  227  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432683415710926
Valid Loss:  0.003366108750924468
Epoch:  228  	Training Loss: 0.003180965781211853
Test Loss:  0.003043268108740449
Valid Loss:  0.003366109449416399
Epoch:  229  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432692728936672
Valid Loss:  0.003366108052432537
Epoch:  230  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432690400630236
Valid Loss:  0.0033661078196018934
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432692728936672
Valid Loss:  0.00336611014790833
Epoch:  232  	Training Loss: 0.0031809653155505657
Test Loss:  0.003043270669877529
Valid Loss:  0.003366109449416399
Epoch:  233  	Training Loss: 0.003180965082719922
Test Loss:  0.00304326880723238
Valid Loss:  0.003366108052432537
Epoch:  234  	Training Loss: 0.0031809648498892784
Test Loss:  0.0030432692728936672
Valid Loss:  0.0033661075867712498
Epoch:  235  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432690400630236
Valid Loss:  0.0033661057241261005
Epoch:  236  	Training Loss: 0.0031809653155505657
Test Loss:  0.00304327136836946
Valid Loss:  0.003366106189787388
Epoch:  237  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043272066861391
Valid Loss:  0.003366106655448675
Epoch:  238  	Training Loss: 0.0031809648498892784
Test Loss:  0.0030432718340307474
Valid Loss:  0.003366106655448675
Epoch:  239  	Training Loss: 0.0031809653155505657
Test Loss:  0.003043270204216242
Valid Loss:  0.003366106655448675
Epoch:  240  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043272066861391
Valid Loss:  0.003366105956956744
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.003180965781211853
Test Loss:  0.003043270669877529
Valid Loss:  0.003366105491295457
Epoch:  242  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432716012001038
Valid Loss:  0.0033661057241261005
Epoch:  243  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432716012001038
Valid Loss:  0.003366106189787388
Epoch:  244  	Training Loss: 0.0031809653155505657
Test Loss:  0.0030432722996920347
Valid Loss:  0.003366106888279319
Epoch:  245  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432725325226784
Valid Loss:  0.003366106655448675
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432725325226784
Valid Loss:  0.0033661064226180315
Epoch:  247  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432722996920347
Valid Loss:  0.0033661057241261005
Epoch:  248  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432716012001038
Valid Loss:  0.003366105491295457
Epoch:  249  	Training Loss: 0.003180965781211853
Test Loss:  0.003043272066861391
Valid Loss:  0.0033661050256341696
Epoch:  250  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432729981839657
Valid Loss:  0.0033661050256341696
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0031809660140424967
Test Loss:  0.0030432736966758966
Valid Loss:  0.0033661052584648132
Epoch:  252  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432736966758966
Valid Loss:  0.0033661050256341696
Epoch:  253  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043273463845253
Valid Loss:  0.0033661050256341696
Epoch:  254  	Training Loss: 0.0031809653155505657
Test Loss:  0.003043273463845253
Valid Loss:  0.003366104792803526
Epoch:  255  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432739295065403
Valid Loss:  0.0033661052584648132
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432739295065403
Valid Loss:  0.0033661052584648132
Epoch:  257  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661052584648132
Epoch:  258  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661052584648132
Epoch:  259  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432739295065403
Valid Loss:  0.0033661052584648132
Epoch:  260  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
 52%|█████▏    | 261/500 [04:58<10:49,  2.72s/it] 53%|█████▎    | 263/500 [04:58<07:36,  1.93s/it] 53%|█████▎    | 265/500 [05:05<08:58,  2.29s/it] 53%|█████▎    | 267/500 [05:05<06:18,  1.63s/it] 54%|█████▍    | 269/500 [05:05<04:27,  1.16s/it] 54%|█████▍    | 271/500 [05:18<10:22,  2.72s/it] 55%|█████▍    | 273/500 [05:18<07:16,  1.92s/it] 55%|█████▌    | 275/500 [05:24<08:38,  2.30s/it] 55%|█████▌    | 277/500 [05:24<06:04,  1.63s/it] 56%|█████▌    | 279/500 [05:24<04:16,  1.16s/it] 56%|█████▌    | 281/500 [05:37<09:51,  2.70s/it] 57%|█████▋    | 283/500 [05:37<06:55,  1.91s/it] 57%|█████▋    | 285/500 [05:44<08:14,  2.30s/it] 57%|█████▋    | 287/500 [05:44<05:47,  1.63s/it] 58%|█████▊    | 289/500 [05:44<04:05,  1.16s/it] 58%|█████▊    | 291/500 [05:56<09:23,  2.70s/it] 59%|█████▊    | 293/500 [05:57<06:35,  1.91s/it] 59%|█████▉    | 295/500 [06:03<07:50,  2.30s/it] 59%|█████▉    | 297/500 [06:03<05:30,  1.63s/it] 60%|█████▉    | 299/500 [06:03<03:53,  1.16s/it] 60%|██████    | 301/500 [06:16<08:54,  2.69s/it] 61%|██████    | 303/500 [06:16<06:14,  1.90s/it] 61%|██████    | 305/500 [06:22<07:25,  2.29s/it] 61%|██████▏   | 307/500 [06:22<05:12,  1.62s/it] 62%|██████▏   | 309/500 [06:23<03:40,  1.15s/it] 62%|██████▏   | 311/500 [06:35<08:29,  2.69s/it] 63%|██████▎   | 313/500 [06:35<05:57,  1.91s/it] 63%|██████▎   | 315/500 [06:42<07:07,  2.31s/it]Valid Loss:  0.0033661052584648132
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432739295065403
Valid Loss:  0.003366105491295457
Epoch:  262  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105491295457
Epoch:  263  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  264  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  265  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  267  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  268  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  269  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  270  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  272  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  273  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  274  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  275  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  277  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  278  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432739295065403
Valid Loss:  0.0033661057241261005
Epoch:  279  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  280  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  282  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  283  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  284  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432739295065403
Valid Loss:  0.0033661057241261005
Epoch:  285  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  287  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  288  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  289  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  290  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  292  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  293  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  294  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  295  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  297  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  298  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432739295065403
Valid Loss:  0.003366105956956744
Epoch:  299  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  300  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  302  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  303  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  304  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  305  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  307  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  308  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  309  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  310  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  312  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  313  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  314  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  315  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  317  	Training Loss: 0.0031809655483812094
Test Loss:   63%|██████▎   | 317/500 [06:42<04:59,  1.64s/it] 64%|██████▍   | 319/500 [06:42<03:30,  1.17s/it] 64%|██████▍   | 319/500 [06:52<03:30,  1.17s/it] 64%|██████▍   | 321/500 [06:55<08:05,  2.71s/it] 65%|██████▍   | 323/500 [06:55<05:41,  1.93s/it] 65%|██████▌   | 325/500 [07:01<06:45,  2.32s/it] 65%|██████▌   | 327/500 [07:01<04:44,  1.64s/it] 66%|██████▌   | 329/500 [07:02<03:20,  1.17s/it] 66%|██████▌   | 329/500 [07:12<03:20,  1.17s/it] 66%|██████▌   | 331/500 [07:14<07:38,  2.71s/it] 67%|██████▋   | 333/500 [07:14<05:20,  1.92s/it] 67%|██████▋   | 335/500 [07:21<06:14,  2.27s/it] 67%|██████▋   | 337/500 [07:21<04:22,  1.61s/it] 68%|██████▊   | 339/500 [07:21<03:04,  1.15s/it] 68%|██████▊   | 339/500 [07:32<03:04,  1.15s/it] 68%|██████▊   | 341/500 [07:33<07:05,  2.67s/it] 69%|██████▊   | 343/500 [07:33<04:58,  1.90s/it] 69%|██████▉   | 345/500 [07:40<05:53,  2.28s/it] 69%|██████▉   | 347/500 [07:40<04:07,  1.62s/it] 70%|██████▉   | 349/500 [07:40<02:53,  1.15s/it] 70%|██████▉   | 349/500 [07:52<02:53,  1.15s/it] 70%|███████   | 351/500 [07:53<06:39,  2.68s/it] 71%|███████   | 353/500 [07:53<04:39,  1.90s/it] 71%|███████   | 355/500 [07:59<05:29,  2.27s/it] 71%|███████▏  | 357/500 [07:59<03:50,  1.61s/it] 72%|███████▏  | 359/500 [07:59<02:42,  1.15s/it] 72%|███████▏  | 361/500 [08:12<06:12,  2.68s/it] 73%|███████▎  | 363/500 [08:12<04:19,  1.89s/it] 73%|███████▎  | 365/500 [08:18<05:06,  2.27s/it] 73%|███████▎  | 367/500 [08:18<03:34,  1.61s/it] 74%|███████▍  | 369/500 [08:18<02:30,  1.15s/it] 74%|███████▍  | 371/500 [08:31<05:47,  2.69s/it] 75%|███████▍  | 373/500 [08:31<04:02,  1.91s/it]0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  318  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  319  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  320  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105491295457
Epoch:  322  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  323  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  324  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  325  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  327  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  328  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  329  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  330  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  332  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  333  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  334  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  335  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  337  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432739295065403
Valid Loss:  0.0033661057241261005
Epoch:  338  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  339  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  340  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  342  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  343  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  344  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  345  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  347  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  348  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  349  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  350  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  352  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  353  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  354  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  355  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  357  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  358  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  359  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  360  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  362  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  363  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  364  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  365  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  367  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  368  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  369  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  370  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  372  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  373  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  374  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
 75%|███████▌  | 375/500 [08:38<04:48,  2.31s/it] 75%|███████▌  | 377/500 [08:38<03:21,  1.63s/it] 76%|███████▌  | 379/500 [08:38<02:21,  1.17s/it] 76%|███████▌  | 381/500 [08:51<05:23,  2.72s/it] 77%|███████▋  | 383/500 [08:51<03:44,  1.92s/it] 77%|███████▋  | 385/500 [08:57<04:24,  2.30s/it] 77%|███████▋  | 387/500 [08:57<03:04,  1.63s/it] 78%|███████▊  | 389/500 [08:57<02:09,  1.16s/it] 78%|███████▊  | 391/500 [09:10<04:54,  2.71s/it] 79%|███████▊  | 393/500 [09:10<03:24,  1.91s/it] 79%|███████▉  | 395/500 [09:17<04:01,  2.30s/it] 79%|███████▉  | 397/500 [09:17<02:47,  1.63s/it] 80%|███████▉  | 399/500 [09:17<01:57,  1.16s/it] 80%|████████  | 401/500 [09:29<04:26,  2.69s/it] 81%|████████  | 403/500 [09:30<03:04,  1.90s/it] 81%|████████  | 405/500 [09:36<03:36,  2.28s/it] 81%|████████▏ | 407/500 [09:36<02:30,  1.62s/it] 82%|████████▏ | 409/500 [09:36<01:44,  1.15s/it] 82%|████████▏ | 411/500 [09:49<03:59,  2.69s/it] 83%|████████▎ | 413/500 [09:49<02:45,  1.91s/it] 83%|████████▎ | 415/500 [09:55<03:14,  2.29s/it] 83%|████████▎ | 417/500 [09:55<02:14,  1.62s/it] 84%|████████▍ | 419/500 [09:55<01:33,  1.16s/it] 84%|████████▍ | 421/500 [10:08<03:33,  2.70s/it] 85%|████████▍ | 423/500 [10:08<02:27,  1.91s/it] 85%|████████▌ | 425/500 [10:15<02:52,  2.29s/it] 85%|████████▌ | 427/500 [10:15<01:58,  1.63s/it] 86%|████████▌ | 429/500 [10:15<01:22,  1.16s/it]Epoch:  375  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  377  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  378  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  379  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  380  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  382  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  383  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  384  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  385  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  387  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  388  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  389  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  390  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  392  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  393  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  394  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  395  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  397  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  398  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  399  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  400  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105491295457
Epoch:  402  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  403  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  404  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  405  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  407  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  408  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  409  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  410  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  412  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  413  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  414  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  415  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  417  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  418  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  419  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  420  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  422  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  423  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  424  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  425  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  427  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  428  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  429  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  430  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:   86%|████████▌ | 431/500 [10:27<03:05,  2.69s/it] 87%|████████▋ | 433/500 [10:28<02:07,  1.90s/it] 87%|████████▋ | 435/500 [10:34<02:29,  2.30s/it] 87%|████████▋ | 437/500 [10:34<01:42,  1.63s/it] 88%|████████▊ | 439/500 [10:34<01:10,  1.16s/it] 88%|████████▊ | 441/500 [10:47<02:40,  2.72s/it] 89%|████████▊ | 443/500 [10:47<01:49,  1.92s/it] 89%|████████▉ | 445/500 [10:53<02:05,  2.28s/it] 89%|████████▉ | 447/500 [10:53<01:25,  1.62s/it] 90%|████████▉ | 449/500 [10:54<00:58,  1.15s/it] 90%|█████████ | 451/500 [11:06<02:11,  2.68s/it] 91%|█████████ | 453/500 [11:06<01:29,  1.90s/it] 91%|█████████ | 455/500 [11:13<01:42,  2.28s/it] 91%|█████████▏| 457/500 [11:13<01:09,  1.62s/it] 92%|█████████▏| 459/500 [11:13<00:47,  1.15s/it] 92%|█████████▏| 461/500 [11:25<01:44,  2.69s/it] 93%|█████████▎| 463/500 [11:26<01:10,  1.90s/it] 93%|█████████▎| 465/500 [11:32<01:20,  2.29s/it] 93%|█████████▎| 467/500 [11:32<00:53,  1.62s/it] 94%|█████████▍| 469/500 [11:32<00:35,  1.15s/it] 94%|█████████▍| 469/500 [11:42<00:35,  1.15s/it] 94%|█████████▍| 471/500 [11:45<01:17,  2.67s/it] 95%|█████████▍| 473/500 [11:45<00:51,  1.89s/it] 95%|█████████▌| 475/500 [11:51<00:56,  2.28s/it] 95%|█████████▌| 477/500 [11:51<00:37,  1.62s/it] 96%|█████████▌| 479/500 [11:51<00:24,  1.16s/it] 96%|█████████▌| 479/500 [12:02<00:24,  1.16s/it] 96%|█████████▌| 481/500 [12:04<00:51,  2.70s/it] 97%|█████████▋| 483/500 [12:04<00:32,  1.91s/it] 97%|█████████▋| 485/500 [12:11<00:34,  2.29s/it] 97%|█████████▋| 487/500 [12:11<00:21,  1.62s/it]0.0033661057241261005
Epoch:  432  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  433  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  434  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  435  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  437  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  438  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  439  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  440  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  442  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105491295457
Epoch:  443  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  444  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  445  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  447  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  448  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  449  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  450  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  452  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  453  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  454  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  455  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  457  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  458  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  459  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  460  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  462  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  463  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  464  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  465  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  467  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  468  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  469  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  470  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  472  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  473  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  474  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  475  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  477  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  478  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  479  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.003366105956956744
Epoch:  480  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  482  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  483  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432739295065403
Valid Loss:  0.0033661057241261005
Epoch:  484  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  485  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  487  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  488  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  489  	Training Loss: 0.0031809655483812094
Test Loss:   98%|█████████▊| 489/500 [12:11<00:12,  1.15s/it] 98%|█████████▊| 489/500 [12:22<00:12,  1.15s/it] 98%|█████████▊| 491/500 [12:23<00:24,  2.68s/it] 99%|█████████▊| 493/500 [12:23<00:13,  1.89s/it] 99%|█████████▉| 495/500 [12:30<00:11,  2.28s/it] 99%|█████████▉| 496/500 [12:30<00:07,  1.90s/it]100%|█████████▉| 498/500 [12:30<00:02,  1.29s/it]100%|██████████| 500/500 [12:36<00:00,  1.91s/it]100%|██████████| 500/500 [12:36<00:00,  1.51s/it]
0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  490  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  492  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  493  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  494  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.003366105956956744
Epoch:  495  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.003180965781211853
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  497  	Training Loss: 0.0031809655483812094
Test Loss:  0.003043274162337184
Valid Loss:  0.0033661057241261005
Epoch:  498  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  499  	Training Loss: 0.003180965781211853
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
Epoch:  500  	Training Loss: 0.0031809655483812094
Test Loss:  0.0030432743951678276
Valid Loss:  0.0033661057241261005
**************************************************learning rate decay**************************************************
seed is  7
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:39,  6.33s/it]  1%|          | 3/500 [00:06<14:05,  1.70s/it]  1%|          | 5/500 [00:06<07:10,  1.15it/s]  1%|▏         | 7/500 [00:06<04:25,  1.86it/s]  2%|▏         | 9/500 [00:07<03:00,  2.73it/s]  2%|▏         | 11/500 [00:13<11:03,  1.36s/it]  3%|▎         | 13/500 [00:13<07:32,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:45,  2.90it/s]  4%|▍         | 21/500 [00:20<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:27<09:13,  1.18s/it]  7%|▋         | 33/500 [00:27<06:36,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:00,  1.18s/it]  9%|▊         | 43/500 [00:34<06:26,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.64it/s]  9%|▉         | 47/500 [00:34<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:41<04:32,  1.64it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.24it/s] 12%|█▏        | 59/500 [00:41<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:47<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:48<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:48<02:23,  2.99it/s]Epoch:  1  	Training Loss: 0.2261407971382141
Test Loss:  0.17930060625076294
Valid Loss:  0.18865084648132324
Epoch:  2  	Training Loss: 0.23976320028305054
Test Loss:  0.2897263765335083
Valid Loss:  0.26590991020202637
Epoch:  3  	Training Loss: 0.22663268446922302
Test Loss:  0.018759876489639282
Valid Loss:  0.01560088712722063
Epoch:  4  	Training Loss: 0.013593481853604317
Test Loss:  0.004127096384763718
Valid Loss:  0.006956251338124275
Epoch:  5  	Training Loss: 0.010672376491129398
Test Loss:  0.012588725425302982
Valid Loss:  0.009360363706946373
Epoch:  6  	Training Loss: 0.009073831140995026
Test Loss:  0.003002557437866926
Valid Loss:  0.005286890082061291
Epoch:  7  	Training Loss: 0.007255847565829754
Test Loss:  0.008825672790408134
Valid Loss:  0.005968502722680569
Epoch:  8  	Training Loss: 0.00640095304697752
Test Loss:  0.002367711625993252
Valid Loss:  0.004315447062253952
Epoch:  9  	Training Loss: 0.005231094546616077
Test Loss:  0.006373448297381401
Valid Loss:  0.004043362103402615
Epoch:  10  	Training Loss: 0.004694276489317417
Test Loss:  0.0019959500059485435
Valid Loss:  0.003685679752379656
Epoch:  11  	Training Loss: 0.004004089627414942
Test Loss:  0.004890738986432552
Valid Loss:  0.0030368196312338114
Epoch:  12  	Training Loss: 0.0036768505815416574
Test Loss:  0.001801669830456376
Valid Loss:  0.003293696092441678
Epoch:  13  	Training Loss: 0.0032790955156087875
Test Loss:  0.004027604125440121
Valid Loss:  0.0025382433086633682
Epoch:  14  	Training Loss: 0.003094172105193138
Test Loss:  0.0017092436319217086
Valid Loss:  0.0030533969402313232
Epoch:  15  	Training Loss: 0.002855433849617839
Test Loss:  0.0035189492627978325
Valid Loss:  0.0022937224712222815
Epoch:  16  	Training Loss: 0.002757743000984192
Test Loss:  0.0016675464576110244
Valid Loss:  0.002899942919611931
Epoch:  17  	Training Loss: 0.0026000221259891987
Test Loss:  0.0031701214611530304
Valid Loss:  0.0021548315417021513
Epoch:  18  	Training Loss: 0.002530402271077037
Test Loss:  0.0016441639745607972
Valid Loss:  0.0027792896144092083
Epoch:  19  	Training Loss: 0.002428429201245308
Test Loss:  0.0029259552247822285
Valid Loss:  0.0020745317451655865
Epoch:  20  	Training Loss: 0.0023730865214020014
Test Loss:  0.0016311926301568747
Valid Loss:  0.002681155689060688
Epoch:  21  	Training Loss: 0.0023086639121174812
Test Loss:  0.0027487396728247404
Valid Loss:  0.0020256866700947285
Epoch:  22  	Training Loss: 0.0022614316549152136
Test Loss:  0.0016245008446276188
Valid Loss:  0.0025986451655626297
Epoch:  23  	Training Loss: 0.0022210439201444387
Test Loss:  0.00261422386392951
Valid Loss:  0.001995159313082695
Epoch:  24  	Training Loss: 0.0021803947165608406
Test Loss:  0.0016215131618082523
Valid Loss:  0.0025198424700647593
Epoch:  25  	Training Loss: 0.0021482890006154776
Test Loss:  0.0024964725598692894
Valid Loss:  0.00197357009164989
Epoch:  26  	Training Loss: 0.002115017268806696
Test Loss:  0.0016227848827838898
Valid Loss:  0.002449014689773321
Epoch:  27  	Training Loss: 0.002089653629809618
Test Loss:  0.0023964387364685535
Valid Loss:  0.0019592181779444218
Epoch:  28  	Training Loss: 0.002062809420749545
Test Loss:  0.0016276855021715164
Valid Loss:  0.002387759042903781
Epoch:  29  	Training Loss: 0.0020435084588825703
Test Loss:  0.0023130346089601517
Valid Loss:  0.001950651640072465
Epoch:  30  	Training Loss: 0.0020220205187797546
Test Loss:  0.0016364541370421648
Valid Loss:  0.0023306692019104958
Epoch:  31  	Training Loss: 0.0020038846414536238
Test Loss:  0.002236628206446767
Valid Loss:  0.0019462903728708625
Epoch:  32  	Training Loss: 0.0019873823039233685
Test Loss:  0.001647726632654667
Valid Loss:  0.002282259287312627
Epoch:  33  	Training Loss: 0.0019730431959033012
Test Loss:  0.0021728018764406443
Valid Loss:  0.001945634838193655
Epoch:  34  	Training Loss: 0.0019605199340730906
Test Loss:  0.0016602732939645648
Valid Loss:  0.002241981215775013
Epoch:  35  	Training Loss: 0.0019495559390634298
Test Loss:  0.002119967248290777
Valid Loss:  0.0019474796717986465
Epoch:  36  	Training Loss: 0.0019399774027988315
Test Loss:  0.0016734276432543993
Valid Loss:  0.0022083832882344723
Epoch:  37  	Training Loss: 0.0019315893296152353
Test Loss:  0.0020760195329785347
Valid Loss:  0.001950954901985824
Epoch:  38  	Training Loss: 0.0019242633134126663
Test Loss:  0.0016866615042090416
Valid Loss:  0.00218034815043211
Epoch:  39  	Training Loss: 0.0019178444053977728
Test Loss:  0.002039293758571148
Valid Loss:  0.0019554286263883114
Epoch:  40  	Training Loss: 0.0019122393568977714
Test Loss:  0.0016995929181575775
Valid Loss:  0.0021569239906966686
Epoch:  41  	Training Loss: 0.0019073300063610077
Test Loss:  0.002008479554206133
Valid Loss:  0.0019604614935815334
Epoch:  42  	Training Loss: 0.001903039519675076
Test Loss:  0.0017119846306741238
Valid Loss:  0.0021372446790337563
Epoch:  43  	Training Loss: 0.0018992647528648376
Test Loss:  0.00198239553719759
Valid Loss:  0.001965754898265004
Epoch:  44  	Training Loss: 0.0018959678709506989
Test Loss:  0.0017236946150660515
Valid Loss:  0.0021207286044955254
Epoch:  45  	Training Loss: 0.0018930832156911492
Test Loss:  0.0019603651016950607
Valid Loss:  0.00197105435654521
Epoch:  46  	Training Loss: 0.0018905652686953545
Test Loss:  0.0017345738597214222
Valid Loss:  0.002106851665303111
Epoch:  47  	Training Loss: 0.001888360595330596
Test Loss:  0.001941703842021525
Valid Loss:  0.001976209692656994
Epoch:  48  	Training Loss: 0.0018864368321374059
Test Loss:  0.0017445842968299985
Valid Loss:  0.0020951596088707447
Epoch:  49  	Training Loss: 0.0018847514875233173
Test Loss:  0.0019258405081927776
Valid Loss:  0.001981116598471999
Epoch:  50  	Training Loss: 0.0018832823261618614
Test Loss:  0.00175371952354908
Valid Loss:  0.002085285261273384
Epoch:  51  	Training Loss: 0.0018819929100573063
Test Loss:  0.0019123150268569589
Valid Loss:  0.001985717797651887
Epoch:  52  	Training Loss: 0.0018808713648468256
Test Loss:  0.001762009458616376
Valid Loss:  0.0020769040565937757
Epoch:  53  	Training Loss: 0.001879880204796791
Test Loss:  0.00190072157420218
Valid Loss:  0.0019899944309145212
Epoch:  54  	Training Loss: 0.0018790231551975012
Test Loss:  0.001769496826454997
Valid Loss:  0.0020697754807770252
Epoch:  55  	Training Loss: 0.0018782659899443388
Test Loss:  0.0018907955382019281
Valid Loss:  0.001993916928768158
Epoch:  56  	Training Loss: 0.0018776122014969587
Test Loss:  0.001776216086000204
Valid Loss:  0.0020637058187276125
Epoch:  57  	Training Loss: 0.0018770323367789388
Test Loss:  0.0018822747515514493
Valid Loss:  0.00199748482555151
Epoch:  58  	Training Loss: 0.0018765355926007032
Test Loss:  0.0017822242807596922
Valid Loss:  0.0020585269667208195
Epoch:  59  	Training Loss: 0.0018760913517326117
Test Loss:  0.0018749493174254894
Valid Loss:  0.002000715583562851
Epoch:  60  	Training Loss: 0.0018757113721221685
Test Loss:  0.0017875744961202145
Valid Loss:  0.002054099226370454
Epoch:  61  	Training Loss: 0.0018753721378743649
Test Loss:  0.0018686384428292513
Valid Loss:  0.002003621542826295
Epoch:  62  	Training Loss: 0.0018750844756141305
Test Loss:  0.0017923279665410519
Valid Loss:  0.0020502989646047354
Epoch:  63  	Training Loss: 0.0018748253351077437
Test Loss:  0.001863194047473371
Valid Loss:  0.002006226684898138
Epoch:  64  	Training Loss: 0.001874603796750307
Test Loss:  0.001796544762328267
Valid Loss:  0.0020470344461500645
Epoch:  65  	Training Loss: 0.0018744058907032013
Test Loss:  0.0018584849312901497
Valid Loss:  0.002008553594350815
Epoch:  66  	Training Loss: 0.001874237903393805
Test Loss:  0.0018002789001911879
Valid Loss:  0.0020442286040633917
Epoch:  67  	Training Loss: 0.0018740870291367173
Test Loss:  0.0018544169142842293
Valid Loss:  0.0020106222946196795
Epoch:  68  	Training Loss: 0.0018739579245448112
Test Loss:  0.0018035722896456718
Valid Loss:  0.002041812054812908
Epoch:  69  	Training Loss: 0.0018738431390374899
Test Loss:  0.0018508901121094823
Valid Loss:  0.002012460958212614
Epoch:  70  	Training Loss: 0.0018737432546913624
Test Loss:  0.001806478830985725
Valid Loss:   14%|█▍        | 71/500 [00:54<08:30,  1.19s/it] 15%|█▍        | 73/500 [00:54<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:54<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:54<03:11,  2.21it/s] 16%|█▌        | 79/500 [00:55<02:22,  2.95it/s] 16%|█▌        | 81/500 [01:01<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:01<06:01,  1.15it/s] 17%|█▋        | 85/500 [01:01<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:02<03:13,  2.14it/s] 18%|█▊        | 89/500 [01:02<02:24,  2.84it/s] 18%|█▊        | 91/500 [01:08<08:08,  1.20s/it] 19%|█▊        | 93/500 [01:08<05:51,  1.16it/s] 19%|█▉        | 95/500 [01:08<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:08<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.94it/s] 20%|██        | 101/500 [01:15<07:58,  1.20s/it] 21%|██        | 103/500 [01:15<05:44,  1.15it/s] 21%|██        | 105/500 [01:15<04:09,  1.58it/s] 21%|██▏       | 107/500 [01:15<03:02,  2.16it/s] 22%|██▏       | 109/500 [01:16<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:22<07:52,  1.21s/it] 23%|██▎       | 113/500 [01:22<05:37,  1.15it/s] 23%|██▎       | 115/500 [01:29<09:57,  1.55s/it] 23%|██▎       | 117/500 [01:29<07:05,  1.11s/it] 24%|██▍       | 119/500 [01:29<05:04,  1.25it/s] 24%|██▍       | 121/500 [01:35<09:40,  1.53s/it] 25%|██▍       | 123/500 [01:35<06:51,  1.09s/it] 25%|██▌       | 125/500 [01:42<10:47,  1.73s/it] 25%|██▌       | 127/500 [01:42<07:38,  1.23s/it] 26%|██▌       | 129/500 [01:42<05:26,  1.14it/s] 26%|██▌       | 131/500 [01:55<15:26,  2.51s/it] 27%|██▋       | 133/500 [01:55<10:54,  1.78s/it]0.002039722166955471
Epoch:  71  	Training Loss: 0.0018736565252766013
Test Loss:  0.0018478319980204105
Valid Loss:  0.0020140884444117546
Epoch:  72  	Training Loss: 0.0018735809717327356
Test Loss:  0.0018090371740981936
Valid Loss:  0.0020379219204187393
Epoch:  73  	Training Loss: 0.001873514847829938
Test Loss:  0.001845181337557733
Valid Loss:  0.002015527803450823
Epoch:  74  	Training Loss: 0.0018734580371528864
Test Loss:  0.001811290392652154
Valid Loss:  0.0020363577641546726
Epoch:  75  	Training Loss: 0.0018734063487499952
Test Loss:  0.001842877478338778
Valid Loss:  0.0020167967304587364
Epoch:  76  	Training Loss: 0.0018733619945123792
Test Loss:  0.0018132675904780626
Valid Loss:  0.0020350047852844
Epoch:  77  	Training Loss: 0.001873323111794889
Test Loss:  0.0018408737378194928
Valid Loss:  0.0020179180428385735
Epoch:  78  	Training Loss: 0.0018732898170128465
Test Loss:  0.0018150096293538809
Valid Loss:  0.0020338334143161774
Epoch:  79  	Training Loss: 0.001873259199783206
Test Loss:  0.0018391343764960766
Valid Loss:  0.002018905244767666
Epoch:  80  	Training Loss: 0.0018732352182269096
Test Loss:  0.0018165353685617447
Valid Loss:  0.0020328154787421227
Epoch:  81  	Training Loss: 0.0018732110038399696
Test Loss:  0.0018376181833446026
Valid Loss:  0.0020197732374072075
Epoch:  82  	Training Loss: 0.00187319191172719
Test Loss:  0.00181787449400872
Valid Loss:  0.002031924668699503
Epoch:  83  	Training Loss: 0.0018731742165982723
Test Loss:  0.0018362996634095907
Valid Loss:  0.002020535059273243
Epoch:  84  	Training Loss: 0.001873159664683044
Test Loss:  0.0018190463306382298
Valid Loss:  0.0020311567932367325
Epoch:  85  	Training Loss: 0.001873146160505712
Test Loss:  0.0018351516919210553
Valid Loss:  0.002021205145865679
Epoch:  86  	Training Loss: 0.0018731353338807821
Test Loss:  0.0018200732301920652
Valid Loss:  0.0020304913632571697
Epoch:  87  	Training Loss: 0.001873124623671174
Test Loss:  0.0018341521499678493
Valid Loss:  0.0020217939745634794
Epoch:  88  	Training Loss: 0.0018731164745986462
Test Loss:  0.001820973353460431
Valid Loss:  0.0020299088209867477
Epoch:  89  	Training Loss: 0.0018731094896793365
Test Loss:  0.0018332806648686528
Valid Loss:  0.002022307366132736
Epoch:  90  	Training Loss: 0.0018731015734374523
Test Loss:  0.0018217648612335324
Valid Loss:  0.0020294038113206625
Epoch:  91  	Training Loss: 0.0018730973824858665
Test Loss:  0.0018325205892324448
Valid Loss:  0.0020227571949362755
Epoch:  92  	Training Loss: 0.001873091096058488
Test Loss:  0.0018224535742774606
Valid Loss:  0.0020289612002670765
Epoch:  93  	Training Loss: 0.001873087021522224
Test Loss:  0.001831855159252882
Valid Loss:  0.0020231527741998434
Epoch:  94  	Training Loss: 0.001873082248494029
Test Loss:  0.0018230590503662825
Valid Loss:  0.002028575399890542
Epoch:  95  	Training Loss: 0.0018730786396190524
Test Loss:  0.0018312743632122874
Valid Loss:  0.002023503417149186
Epoch:  96  	Training Loss: 0.0018730765441432595
Test Loss:  0.0018235899042338133
Valid Loss:  0.002028239658102393
Epoch:  97  	Training Loss: 0.0018730738665908575
Test Loss:  0.0018307712161913514
Valid Loss:  0.0020238044671714306
Epoch:  98  	Training Loss: 0.0018730717711150646
Test Loss:  0.0018240519566461444
Valid Loss:  0.0020279488526284695
Epoch:  99  	Training Loss: 0.0018730689771473408
Test Loss:  0.0018303325632587075
Valid Loss:  0.0020240715239197016
Epoch:  100  	Training Loss: 0.0018730678129941225
Test Loss:  0.0018244574312120676
Valid Loss:  0.0020276906434446573
Epoch:  101  	Training Loss: 0.0018730671145021915
Test Loss:  0.0018299450166523457
Valid Loss:  0.0020243055187165737
Epoch:  102  	Training Loss: 0.0018730652518570423
Test Loss:  0.0018248078413307667
Valid Loss:  0.0020274692215025425
Epoch:  103  	Training Loss: 0.0018730636220425367
Test Loss:  0.0018296093912795186
Valid Loss:  0.0020245066843926907
Epoch:  104  	Training Loss: 0.0018730631563812494
Test Loss:  0.0018251234432682395
Valid Loss:  0.002027275040745735
Epoch:  105  	Training Loss: 0.0018730618758127093
Test Loss:  0.0018293150933459401
Valid Loss:  0.0020246868953108788
Epoch:  106  	Training Loss: 0.0018730615265667439
Test Loss:  0.0018253918970003724
Valid Loss:  0.002027105540037155
Epoch:  107  	Training Loss: 0.0018730595475062728
Test Loss:  0.001829058863222599
Valid Loss:  0.002024843357503414
Epoch:  108  	Training Loss: 0.00187306001316756
Test Loss:  0.0018256305484101176
Valid Loss:  0.002026960253715515
Epoch:  109  	Training Loss: 0.0018730591982603073
Test Loss:  0.0018288376741111279
Valid Loss:  0.0020249770022928715
Epoch:  110  	Training Loss: 0.001873058034107089
Test Loss:  0.001825837418437004
Valid Loss:  0.0020268280059099197
Epoch:  111  	Training Loss: 0.0018730589654296637
Test Loss:  0.0018286412814632058
Valid Loss:  0.002025099005550146
Epoch:  112  	Training Loss: 0.0018730578012764454
Test Loss:  0.0018260182114318013
Valid Loss:  0.002026717644184828
Epoch:  113  	Training Loss: 0.0018730584997683764
Test Loss:  0.0018284721300005913
Valid Loss:  0.0020252023823559284
Epoch:  114  	Training Loss: 0.0018730582669377327
Test Loss:  0.0018261766526848078
Valid Loss:  0.002026618691161275
Epoch:  115  	Training Loss: 0.001873057335615158
Test Loss:  0.0018283218378201127
Valid Loss:  0.002025294117629528
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0018730571027845144
Test Loss:  0.001827317290008068
Valid Loss:  0.00202591042034328
Epoch:  117  	Training Loss: 0.0018730552401393652
Test Loss:  0.0018272862071171403
Valid Loss:  0.0020259330049157143
Epoch:  118  	Training Loss: 0.0018730558222159743
Test Loss:  0.0018272846937179565
Valid Loss:  0.0020259327720850706
Epoch:  119  	Training Loss: 0.0018730557058006525
Test Loss:  0.0018272848101332784
Valid Loss:  0.0020259330049157143
Epoch:  120  	Training Loss: 0.0018730557058006525
Test Loss:  0.0018272846937179565
Valid Loss:  0.002025932539254427
Epoch:  121  	Training Loss: 0.0018730557058006525
Test Loss:  0.0018272828310728073
Valid Loss:  0.002025932539254427
Epoch:  122  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272835295647383
Valid Loss:  0.002025932539254427
Epoch:  123  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
Epoch:  124  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  125  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  127  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  128  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  129  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  130  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  132  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  133  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  134  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  135  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
 27%|██▋       | 135/500 [02:01<13:28,  2.21s/it] 27%|██▋       | 137/500 [02:02<09:30,  1.57s/it] 28%|██▊       | 139/500 [02:02<06:44,  1.12s/it] 28%|██▊       | 141/500 [02:14<16:00,  2.68s/it] 29%|██▊       | 143/500 [02:14<11:16,  1.89s/it] 29%|██▉       | 145/500 [02:21<13:32,  2.29s/it] 29%|██▉       | 147/500 [02:21<09:33,  1.63s/it] 30%|██▉       | 149/500 [02:21<06:46,  1.16s/it] 30%|███       | 151/500 [02:34<15:44,  2.71s/it] 31%|███       | 153/500 [02:34<11:06,  1.92s/it] 31%|███       | 155/500 [02:40<13:09,  2.29s/it] 31%|███▏      | 157/500 [02:40<09:17,  1.62s/it] 32%|███▏      | 159/500 [02:40<06:34,  1.16s/it] 32%|███▏      | 161/500 [02:53<15:10,  2.69s/it] 33%|███▎      | 163/500 [02:53<10:43,  1.91s/it] 33%|███▎      | 165/500 [03:00<12:44,  2.28s/it] 33%|███▎      | 167/500 [03:00<08:59,  1.62s/it] 34%|███▍      | 169/500 [03:00<06:21,  1.15s/it] 34%|███▍      | 171/500 [03:12<14:47,  2.70s/it] 35%|███▍      | 173/500 [03:13<10:24,  1.91s/it] 35%|███▌      | 175/500 [03:19<12:23,  2.29s/it] 35%|███▌      | 177/500 [03:19<08:45,  1.63s/it] 36%|███▌      | 179/500 [03:19<06:12,  1.16s/it] 36%|███▌      | 179/500 [03:30<06:12,  1.16s/it] 36%|███▌      | 181/500 [03:32<14:20,  2.70s/it] 37%|███▋      | 183/500 [03:32<10:05,  1.91s/it] 37%|███▋      | 185/500 [03:38<11:57,  2.28s/it] 37%|███▋      | 187/500 [03:38<08:26,  1.62s/it] 38%|███▊      | 189/500 [03:38<05:58,  1.15s/it] 38%|███▊      | 189/500 [03:50<05:58,  1.15s/it] 38%|███▊      | 191/500 [03:51<13:50,  2.69s/it]**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  137  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  138  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  139  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  140  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  142  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
Epoch:  143  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  144  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  145  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  147  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  148  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  149  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  150  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  152  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.002025933237746358
Epoch:  153  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  154  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  155  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  157  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  158  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  159  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  160  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  162  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  163  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  164  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  165  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  167  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  168  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  169  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  170  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  172  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  173  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.002025933237746358
Epoch:  174  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  175  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  177  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  178  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  179  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  180  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.002025933237746358
Epoch:  182  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  183  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  184  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  185  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  187  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  188  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  189  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  190  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  192  	Training Loss: 0.0018730554729700089
 39%|███▊      | 193/500 [03:51<09:44,  1.90s/it] 39%|███▉      | 195/500 [03:58<11:37,  2.29s/it] 39%|███▉      | 197/500 [03:58<08:11,  1.62s/it] 40%|███▉      | 199/500 [03:58<05:47,  1.15s/it] 40%|███▉      | 199/500 [04:10<05:47,  1.15s/it] 40%|████      | 201/500 [04:10<13:26,  2.70s/it] 41%|████      | 203/500 [04:11<09:26,  1.91s/it] 41%|████      | 205/500 [04:17<11:13,  2.28s/it] 41%|████▏     | 207/500 [04:17<07:54,  1.62s/it] 42%|████▏     | 209/500 [04:17<05:35,  1.15s/it] 42%|████▏     | 209/500 [04:30<05:35,  1.15s/it] 42%|████▏     | 211/500 [04:30<13:01,  2.70s/it] 43%|████▎     | 213/500 [04:30<09:09,  1.91s/it] 43%|████▎     | 215/500 [04:36<11:01,  2.32s/it] 43%|████▎     | 217/500 [04:37<07:45,  1.65s/it] 44%|████▍     | 219/500 [04:37<05:29,  1.17s/it] 44%|████▍     | 221/500 [04:50<12:52,  2.77s/it] 45%|████▍     | 223/500 [04:50<09:02,  1.96s/it] 45%|████▌     | 225/500 [04:56<10:44,  2.34s/it] 45%|████▌     | 227/500 [04:56<07:34,  1.66s/it] 46%|████▌     | 229/500 [04:57<05:21,  1.18s/it] 46%|████▌     | 231/500 [05:09<12:13,  2.73s/it] 47%|████▋     | 233/500 [05:09<08:35,  1.93s/it] 47%|████▋     | 235/500 [05:16<10:10,  2.30s/it] 47%|████▋     | 237/500 [05:16<07:09,  1.63s/it] 48%|████▊     | 239/500 [05:16<05:03,  1.16s/it] 48%|████▊     | 241/500 [05:29<11:37,  2.69s/it] 49%|████▊     | 243/500 [05:29<08:10,  1.91s/it] 49%|████▉     | 245/500 [05:35<09:41,  2.28s/it] 49%|████▉     | 247/500 [05:35<06:49,  1.62s/it]Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  193  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  194  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  195  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  197  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  198  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  199  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  200  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  202  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  203  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  204  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  205  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  207  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  208  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  209  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  210  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  212  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  213  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  214  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  215  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  217  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  218  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  219  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  220  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  222  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  223  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  224  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  225  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  227  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  228  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  229  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  230  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  232  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  233  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  234  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  235  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  237  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  238  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  239  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
Epoch:  240  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  242  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  243  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  244  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  245  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  247  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  248  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  249  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:   50%|████▉     | 249/500 [05:35<04:49,  1.15s/it] 50%|█████     | 251/500 [05:48<11:11,  2.70s/it] 51%|█████     | 253/500 [05:48<07:51,  1.91s/it] 51%|█████     | 255/500 [05:54<09:17,  2.28s/it] 51%|█████▏    | 257/500 [05:54<06:32,  1.61s/it] 52%|█████▏    | 259/500 [05:55<04:37,  1.15s/it] 52%|█████▏    | 261/500 [06:07<10:42,  2.69s/it] 53%|█████▎    | 263/500 [06:07<07:31,  1.91s/it] 53%|█████▎    | 265/500 [06:14<09:03,  2.31s/it] 53%|█████▎    | 267/500 [06:14<06:22,  1.64s/it] 54%|█████▍    | 269/500 [06:14<04:29,  1.17s/it] 54%|█████▍    | 271/500 [06:27<10:18,  2.70s/it] 55%|█████▍    | 273/500 [06:27<07:14,  1.91s/it] 55%|█████▌    | 275/500 [06:33<08:31,  2.27s/it] 55%|█████▌    | 277/500 [06:33<05:59,  1.61s/it] 56%|█████▌    | 279/500 [06:33<04:13,  1.15s/it] 56%|█████▌    | 281/500 [06:46<09:47,  2.68s/it] 57%|█████▋    | 283/500 [06:46<06:51,  1.90s/it] 57%|█████▋    | 285/500 [06:52<08:14,  2.30s/it] 57%|█████▋    | 287/500 [06:53<05:47,  1.63s/it] 58%|█████▊    | 289/500 [06:53<04:05,  1.16s/it] 58%|█████▊    | 291/500 [07:05<09:24,  2.70s/it] 59%|█████▊    | 293/500 [07:05<06:35,  1.91s/it] 59%|█████▉    | 295/500 [07:12<07:49,  2.29s/it] 59%|█████▉    | 297/500 [07:12<05:29,  1.62s/it] 60%|█████▉    | 299/500 [07:12<03:52,  1.16s/it] 60%|██████    | 301/500 [07:24<08:49,  2.66s/it] 61%|██████    | 303/500 [07:25<06:11,  1.88s/it] 61%|██████    | 305/500 [07:31<07:24,  2.28s/it]0.0020259330049157143
Epoch:  250  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.002025933237746358
Epoch:  252  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  253  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  254  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
Epoch:  255  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  257  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  258  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  259  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  260  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  262  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  263  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  264  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  265  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  267  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  268  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  269  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  270  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0018730552401393652
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  272  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  273  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  274  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  275  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  277  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  278  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  279  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  280  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  282  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  283  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  284  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  285  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  287  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  288  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  289  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  290  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  292  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  293  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  294  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  295  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  297  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  298  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  299  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  300  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  302  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  303  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  304  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
Epoch:  305  	Training Loss: 0.0018730552401393652
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
 61%|██████▏   | 307/500 [07:31<05:12,  1.62s/it] 62%|██████▏   | 309/500 [07:31<03:39,  1.15s/it] 62%|██████▏   | 311/500 [07:44<08:28,  2.69s/it] 63%|██████▎   | 313/500 [07:44<05:55,  1.90s/it] 63%|██████▎   | 315/500 [07:50<07:02,  2.29s/it] 63%|██████▎   | 317/500 [07:50<04:56,  1.62s/it] 64%|██████▍   | 319/500 [07:51<03:28,  1.15s/it] 64%|██████▍   | 321/500 [08:03<08:01,  2.69s/it] 65%|██████▍   | 323/500 [08:03<05:37,  1.91s/it] 65%|██████▌   | 325/500 [08:10<06:41,  2.30s/it] 65%|██████▌   | 327/500 [08:10<04:41,  1.63s/it] 66%|██████▌   | 329/500 [08:10<03:18,  1.16s/it] 66%|██████▌   | 331/500 [08:22<07:34,  2.69s/it] 67%|██████▋   | 333/500 [08:23<05:17,  1.90s/it] 67%|██████▋   | 335/500 [08:29<06:14,  2.27s/it] 67%|██████▋   | 337/500 [08:29<04:23,  1.61s/it] 68%|██████▊   | 339/500 [08:29<03:05,  1.15s/it] 68%|██████▊   | 339/500 [08:40<03:05,  1.15s/it] 68%|██████▊   | 341/500 [08:42<07:05,  2.68s/it] 69%|██████▊   | 343/500 [08:42<04:58,  1.90s/it] 69%|██████▉   | 345/500 [08:48<05:53,  2.28s/it] 69%|██████▉   | 347/500 [08:48<04:07,  1.62s/it] 70%|██████▉   | 349/500 [08:48<02:53,  1.15s/it] 70%|██████▉   | 349/500 [09:00<02:53,  1.15s/it] 70%|███████   | 351/500 [09:01<06:41,  2.70s/it] 71%|███████   | 353/500 [09:01<04:40,  1.91s/it] 71%|███████   | 355/500 [09:08<05:35,  2.31s/it] 71%|███████▏  | 357/500 [09:08<03:54,  1.64s/it] 72%|███████▏  | 359/500 [09:08<02:45,  1.17s/it] 72%|███████▏  | 359/500 [09:20<02:45,  1.17s/it] 72%|███████▏  | 361/500 [09:21<06:21,  2.75s/it]Epoch:  306  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  307  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  308  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  309  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  310  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  312  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  313  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  314  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.002025933237746358
Epoch:  315  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  317  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  318  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  319  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  320  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  322  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  323  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  324  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  325  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  327  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  328  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  329  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  330  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  332  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  333  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  334  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  335  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
Epoch:  337  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  338  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  339  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  340  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  342  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  343  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  344  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  345  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  347  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  348  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  349  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  350  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  352  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  353  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  354  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  355  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  357  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  358  	Training Loss: 0.0018730555893853307
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  359  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  360  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  362  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  363  	Training Loss: 0.0018730554729700089
 73%|███████▎  | 363/500 [09:21<04:26,  1.94s/it] 73%|███████▎  | 365/500 [09:27<05:16,  2.34s/it] 73%|███████▎  | 367/500 [09:28<03:41,  1.66s/it] 74%|███████▍  | 369/500 [09:28<02:34,  1.18s/it] 74%|███████▍  | 369/500 [09:40<02:34,  1.18s/it] 74%|███████▍  | 371/500 [09:40<05:52,  2.73s/it] 75%|███████▍  | 373/500 [09:41<04:05,  1.93s/it] 75%|███████▌  | 375/500 [09:47<04:50,  2.32s/it] 75%|███████▌  | 377/500 [09:47<03:22,  1.65s/it] 76%|███████▌  | 379/500 [09:47<02:21,  1.17s/it] 76%|███████▌  | 381/500 [10:00<05:21,  2.70s/it] 77%|███████▋  | 383/500 [10:00<03:43,  1.91s/it] 77%|███████▋  | 385/500 [10:06<04:23,  2.29s/it] 77%|███████▋  | 387/500 [10:06<03:03,  1.63s/it] 78%|███████▊  | 389/500 [10:07<02:08,  1.16s/it] 78%|███████▊  | 391/500 [10:19<04:52,  2.69s/it] 79%|███████▊  | 393/500 [10:19<03:23,  1.90s/it] 79%|███████▉  | 395/500 [10:26<03:58,  2.27s/it] 79%|███████▉  | 397/500 [10:26<02:45,  1.61s/it] 80%|███████▉  | 399/500 [10:26<01:55,  1.15s/it] 80%|████████  | 401/500 [10:39<04:30,  2.73s/it] 81%|████████  | 403/500 [10:39<03:07,  1.93s/it] 81%|████████  | 405/500 [10:45<03:39,  2.31s/it] 81%|████████▏ | 407/500 [10:45<02:32,  1.64s/it] 82%|████████▏ | 409/500 [10:45<01:46,  1.17s/it] 82%|████████▏ | 411/500 [10:58<04:01,  2.71s/it] 83%|████████▎ | 413/500 [10:58<02:47,  1.92s/it] 83%|████████▎ | 415/500 [11:04<03:13,  2.28s/it] 83%|████████▎ | 417/500 [11:05<02:14,  1.62s/it] 84%|████████▍ | 419/500 [11:05<01:33,  1.15s/it]Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  364  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  365  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  367  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  368  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  369  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  370  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  372  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  373  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  374  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  375  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.001873055356554687
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  377  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  378  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  379  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  380  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  382  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  383  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  384  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  385  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  387  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  388  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  389  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  390  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  392  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  393  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  394  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  395  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  397  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  398  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  399  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
Epoch:  400  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  402  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  403  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  404  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  405  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  407  	Training Loss: 0.001873055356554687
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  408  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  409  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  410  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  412  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  413  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  414  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  415  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  417  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  418  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  419  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  420  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:   84%|████████▍ | 421/500 [11:17<03:32,  2.69s/it] 85%|████████▍ | 423/500 [11:17<02:26,  1.91s/it] 85%|████████▌ | 425/500 [11:24<02:52,  2.30s/it] 85%|████████▌ | 427/500 [11:24<01:59,  1.63s/it] 86%|████████▌ | 429/500 [11:24<01:22,  1.16s/it] 86%|████████▌ | 431/500 [11:37<03:06,  2.71s/it] 87%|████████▋ | 433/500 [11:37<02:08,  1.92s/it] 87%|████████▋ | 435/500 [11:43<02:27,  2.27s/it] 87%|████████▋ | 437/500 [11:43<01:41,  1.61s/it] 88%|████████▊ | 439/500 [11:43<01:10,  1.15s/it] 88%|████████▊ | 441/500 [11:56<02:39,  2.70s/it] 89%|████████▊ | 443/500 [11:56<01:48,  1.91s/it] 89%|████████▉ | 445/500 [12:03<02:05,  2.29s/it] 89%|████████▉ | 447/500 [12:03<01:26,  1.62s/it] 90%|████████▉ | 449/500 [12:03<00:58,  1.16s/it] 90%|█████████ | 451/500 [12:15<02:10,  2.67s/it] 91%|█████████ | 453/500 [12:15<01:28,  1.89s/it] 91%|█████████ | 455/500 [12:22<01:43,  2.30s/it] 91%|█████████▏| 457/500 [12:22<01:10,  1.63s/it] 92%|█████████▏| 459/500 [12:22<00:47,  1.16s/it] 92%|█████████▏| 461/500 [12:35<01:45,  2.70s/it] 93%|█████████▎| 463/500 [12:35<01:10,  1.91s/it] 93%|█████████▎| 465/500 [12:41<01:20,  2.29s/it] 93%|█████████▎| 467/500 [12:41<00:53,  1.63s/it] 94%|█████████▍| 469/500 [12:42<00:35,  1.16s/it] 94%|█████████▍| 471/500 [12:54<01:17,  2.68s/it] 95%|█████████▍| 473/500 [12:54<00:51,  1.90s/it] 95%|█████████▌| 475/500 [13:01<00:57,  2.29s/it]0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  422  	Training Loss: 0.001873055356554687
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  423  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  424  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  425  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  427  	Training Loss: 0.001873055356554687
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  428  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  429  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  430  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  432  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  433  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272841116413474
Valid Loss:  0.0020259330049157143
Epoch:  434  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  435  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  437  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  438  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  439  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  440  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  442  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  443  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  444  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  445  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  447  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  448  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  449  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  450  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  452  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  453  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  454  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  455  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  457  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  458  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  459  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  460  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  462  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  463  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  464  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  465  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  467  	Training Loss: 0.0018730555893853307
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  468  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  469  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  470  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  472  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  473  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  474  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  475  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
 95%|█████████▌| 477/500 [13:01<00:37,  1.63s/it] 96%|█████████▌| 479/500 [13:01<00:24,  1.17s/it] 96%|█████████▌| 481/500 [13:13<00:51,  2.69s/it] 97%|█████████▋| 483/500 [13:14<00:32,  1.91s/it] 97%|█████████▋| 485/500 [13:20<00:34,  2.31s/it] 97%|█████████▋| 487/500 [13:20<00:21,  1.64s/it] 98%|█████████▊| 489/500 [13:20<00:12,  1.17s/it] 98%|█████████▊| 491/500 [13:33<00:24,  2.71s/it] 99%|█████████▊| 493/500 [13:33<00:13,  1.91s/it] 99%|█████████▉| 495/500 [13:39<00:11,  2.29s/it] 99%|█████████▉| 497/500 [13:40<00:04,  1.63s/it]100%|█████████▉| 499/500 [13:40<00:01,  1.17s/it]100%|██████████| 500/500 [13:46<00:00,  1.65s/it]
Epoch:  477  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  478  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  479  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  480  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  482  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  483  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  484  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  485  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  487  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  488  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  489  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272841116413474
Valid Loss:  0.002025933237746358
Epoch:  490  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  492  	Training Loss: 0.0018730552401393652
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
Epoch:  493  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  494  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  495  	Training Loss: 0.0018730554729700089
Test Loss:  0.001827284344471991
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.002025933237746358
Epoch:  497  	Training Loss: 0.0018730554729700089
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  498  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  499  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
Epoch:  500  	Training Loss: 0.001873055356554687
Test Loss:  0.0018272842280566692
Valid Loss:  0.0020259330049157143
**************************************************learning rate decay**************************************************
seed is  8
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:40,  6.09s/it]  1%|          | 3/500 [00:06<13:32,  1.63s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:54,  2.81it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:30,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:46,  2.13it/s]  4%|▍         | 19/500 [00:13<02:46,  2.89it/s]  4%|▍         | 21/500 [00:20<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:39,  2.15it/s]  6%|▌         | 29/500 [00:20<02:44,  2.86it/s]  6%|▌         | 31/500 [00:27<09:22,  1.20s/it]  7%|▋         | 33/500 [00:27<06:42,  1.16it/s]  7%|▋         | 35/500 [00:27<04:49,  1.61it/s]  7%|▋         | 37/500 [00:27<03:32,  2.18it/s]  8%|▊         | 39/500 [00:27<02:39,  2.90it/s]  8%|▊         | 41/500 [00:33<09:02,  1.18s/it]  9%|▊         | 43/500 [00:34<06:30,  1.17it/s]  9%|▉         | 45/500 [00:34<04:43,  1.61it/s]  9%|▉         | 47/500 [00:34<03:25,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:41<09:08,  1.22s/it] 11%|█         | 53/500 [00:41<06:31,  1.14it/s] 11%|█         | 55/500 [00:41<04:41,  1.58it/s] 11%|█▏        | 57/500 [00:41<03:24,  2.16it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.92it/s] 12%|█▏        | 61/500 [00:47<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:48<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:48<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:48<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:48<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:54<08:23,  1.17s/it]Epoch:  1  	Training Loss: 0.029436571523547173
Test Loss:  0.0070754652842879295
Valid Loss:  0.01208948902785778
Epoch:  2  	Training Loss: 0.020130760967731476
Test Loss:  0.1253816783428192
Valid Loss:  0.10615391284227371
Epoch:  3  	Training Loss: 0.09572009742259979
Test Loss:  0.011987523175776005
Valid Loss:  0.017740514129400253
Epoch:  4  	Training Loss: 0.02487894333899021
Test Loss:  0.013100655749440193
Valid Loss:  0.018038686364889145
Epoch:  5  	Training Loss: 0.024948514997959137
Test Loss:  0.008125947788357735
Valid Loss:  0.013727088458836079
Epoch:  6  	Training Loss: 0.02276581898331642
Test Loss:  0.010097895748913288
Valid Loss:  0.015022503212094307
Epoch:  7  	Training Loss: 0.022913971915841103
Test Loss:  0.0074972170405089855
Valid Loss:  0.012859293259680271
Epoch:  8  	Training Loss: 0.021861998364329338
Test Loss:  0.007596725132316351
Valid Loss:  0.012768273241817951
Epoch:  9  	Training Loss: 0.021346883848309517
Test Loss:  0.006687565241008997
Valid Loss:  0.011928196996450424
Epoch:  10  	Training Loss: 0.021032731980085373
Test Loss:  0.006882292218506336
Valid Loss:  0.012144075706601143
Epoch:  11  	Training Loss: 0.020936477929353714
Test Loss:  0.006505297496914864
Valid Loss:  0.011827407404780388
Epoch:  12  	Training Loss: 0.02081652544438839
Test Loss:  0.006515707820653915
Valid Loss:  0.011840194463729858
Epoch:  13  	Training Loss: 0.020758531987667084
Test Loss:  0.006417246535420418
Valid Loss:  0.011771873570978642
Epoch:  14  	Training Loss: 0.0207170732319355
Test Loss:  0.0063902828842401505
Valid Loss:  0.011761913076043129
Epoch:  15  	Training Loss: 0.020683350041508675
Test Loss:  0.006322351284325123
Valid Loss:  0.011719169095158577
Epoch:  16  	Training Loss: 0.020655017346143723
Test Loss:  0.006289544515311718
Valid Loss:  0.011705562472343445
Epoch:  17  	Training Loss: 0.020632639527320862
Test Loss:  0.0062636723741889
Valid Loss:  0.011697247624397278
Epoch:  18  	Training Loss: 0.020612206310033798
Test Loss:  0.0062415217980742455
Valid Loss:  0.01169087179005146
Epoch:  19  	Training Loss: 0.02059360221028328
Test Loss:  0.006216320209205151
Valid Loss:  0.011681413277983665
Epoch:  20  	Training Loss: 0.020577898249030113
Test Loss:  0.006197832524776459
Valid Loss:  0.011675994843244553
Epoch:  21  	Training Loss: 0.02056456357240677
Test Loss:  0.0061720735393464565
Valid Loss:  0.01166735403239727
Epoch:  22  	Training Loss: 0.020553357899188995
Test Loss:  0.006160399876534939
Valid Loss:  0.011664765886962414
Epoch:  23  	Training Loss: 0.020544270053505898
Test Loss:  0.006137493532150984
Valid Loss:  0.011658906936645508
Epoch:  24  	Training Loss: 0.020536409690976143
Test Loss:  0.006128454115241766
Valid Loss:  0.011657637543976307
Epoch:  25  	Training Loss: 0.02052983269095421
Test Loss:  0.006115914322435856
Valid Loss:  0.011655768379569054
Epoch:  26  	Training Loss: 0.02052423730492592
Test Loss:  0.006109634414315224
Valid Loss:  0.011655420996248722
Epoch:  27  	Training Loss: 0.020519163459539413
Test Loss:  0.006104921922087669
Valid Loss:  0.011655445210635662
Epoch:  28  	Training Loss: 0.020514363422989845
Test Loss:  0.006100738886743784
Valid Loss:  0.011655623093247414
Epoch:  29  	Training Loss: 0.020509809255599976
Test Loss:  0.006096868775784969
Valid Loss:  0.011655900627374649
Epoch:  30  	Training Loss: 0.02050548605620861
Test Loss:  0.006093140225857496
Valid Loss:  0.011656240560114384
Epoch:  31  	Training Loss: 0.020501550287008286
Test Loss:  0.00608419394120574
Valid Loss:  0.011656008660793304
Epoch:  32  	Training Loss: 0.020497966557741165
Test Loss:  0.006080231629312038
Valid Loss:  0.011656265705823898
Epoch:  33  	Training Loss: 0.020494693890213966
Test Loss:  0.006075969897210598
Valid Loss:  0.011656505987048149
Epoch:  34  	Training Loss: 0.020491670817136765
Test Loss:  0.00606934167444706
Valid Loss:  0.011656669899821281
Epoch:  35  	Training Loss: 0.02048887126147747
Test Loss:  0.0060663772746920586
Valid Loss:  0.011656854301691055
Epoch:  36  	Training Loss: 0.02048623561859131
Test Loss:  0.006064226850867271
Valid Loss:  0.01165701262652874
Epoch:  37  	Training Loss: 0.020483672618865967
Test Loss:  0.00606230553239584
Valid Loss:  0.011657148599624634
Epoch:  38  	Training Loss: 0.02048124000430107
Test Loss:  0.006056914571672678
Valid Loss:  0.011657399125397205
Epoch:  39  	Training Loss: 0.02047891914844513
Test Loss:  0.0060557094402611256
Valid Loss:  0.011657336726784706
Epoch:  40  	Training Loss: 0.020476795732975006
Test Loss:  0.006049762945622206
Valid Loss:  0.011657658964395523
Epoch:  41  	Training Loss: 0.020474601536989212
Test Loss:  0.006052051670849323
Valid Loss:  0.01165706105530262
Epoch:  42  	Training Loss: 0.02047259919345379
Test Loss:  0.006045790389180183
Valid Loss:  0.011657449416816235
Epoch:  43  	Training Loss: 0.020470404997467995
Test Loss:  0.006043757311999798
Valid Loss:  0.011657187715172768
Epoch:  44  	Training Loss: 0.0204684529453516
Test Loss:  0.0060444604605436325
Valid Loss:  0.011656484566628933
Epoch:  45  	Training Loss: 0.020466499030590057
Test Loss:  0.006040549837052822
Valid Loss:  0.011656523682177067
Epoch:  46  	Training Loss: 0.02046452835202217
Test Loss:  0.00604011956602335
Valid Loss:  0.011655880138278008
Epoch:  47  	Training Loss: 0.02046261355280876
Test Loss:  0.00603814423084259
Valid Loss:  0.011655512265861034
Epoch:  48  	Training Loss: 0.020460709929466248
Test Loss:  0.006037021055817604
Valid Loss:  0.011654935777187347
Epoch:  49  	Training Loss: 0.02045881375670433
Test Loss:  0.006036092527210712
Valid Loss:  0.01165430061519146
Epoch:  50  	Training Loss: 0.02045692875981331
Test Loss:  0.006035217549651861
Valid Loss:  0.011653636582195759
Epoch:  51  	Training Loss: 0.020455045625567436
Test Loss:  0.00603435980156064
Valid Loss:  0.011652959510684013
Epoch:  52  	Training Loss: 0.02045316807925701
Test Loss:  0.006033523939549923
Valid Loss:  0.011652272194623947
Epoch:  53  	Training Loss: 0.02045130357146263
Test Loss:  0.006032698787748814
Valid Loss:  0.011651571840047836
Epoch:  54  	Training Loss: 0.0204494409263134
Test Loss:  0.006031885277479887
Valid Loss:  0.011650856584310532
Epoch:  55  	Training Loss: 0.020447582006454468
Test Loss:  0.006031083408743143
Valid Loss:  0.011650126427412033
Epoch:  56  	Training Loss: 0.020445726811885834
Test Loss:  0.006030295044183731
Valid Loss:  0.01164938509464264
Epoch:  57  	Training Loss: 0.020443875342607498
Test Loss:  0.00602951692417264
Valid Loss:  0.0116486307233572
Epoch:  58  	Training Loss: 0.020442022010684013
Test Loss:  0.00602874718606472
Valid Loss:  0.011647864244878292
Epoch:  59  	Training Loss: 0.020440179854631424
Test Loss:  0.00602798443287611
Valid Loss:  0.011647086590528488
Epoch:  60  	Training Loss: 0.020438335835933685
Test Loss:  0.00602723378688097
Valid Loss:  0.01164629403501749
Epoch:  61  	Training Loss: 0.020436489954590797
Test Loss:  0.0060264915227890015
Valid Loss:  0.011645495891571045
Epoch:  62  	Training Loss: 0.020434651523828506
Test Loss:  0.006025772076100111
Valid Loss:  0.011644684709608555
Epoch:  63  	Training Loss: 0.020432814955711365
Test Loss:  0.0060250647366046906
Valid Loss:  0.011643864214420319
Epoch:  64  	Training Loss: 0.02043098211288452
Test Loss:  0.006024363450706005
Valid Loss:  0.011643031612038612
Epoch:  65  	Training Loss: 0.020429151132702827
Test Loss:  0.006023667752742767
Valid Loss:  0.011642194353044033
Epoch:  66  	Training Loss: 0.020427320152521133
Test Loss:  0.006022981368005276
Valid Loss:  0.01164134033024311
Epoch:  67  	Training Loss: 0.02042549103498459
Test Loss:  0.006022296845912933
Valid Loss:  0.011640483513474464
Epoch:  68  	Training Loss: 0.020423665642738342
Test Loss:  0.006021618377417326
Valid Loss:  0.011639613658189774
Epoch:  69  	Training Loss: 0.020421840250492096
Test Loss:  0.00602094316855073
Valid Loss:  0.011638738214969635
Epoch:  70  	Training Loss: 0.020420020446181297
Test Loss:  0.006020276341587305
Valid Loss:  0.011637857183814049
Epoch:  71  	Training Loss: 0.02041819877922535
Test Loss:  0.0060196127742528915
Valid Loss:  0.011636961251497269
 15%|█▍        | 73/500 [00:54<05:59,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:55<03:08,  2.25it/s] 16%|█▌        | 79/500 [00:55<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:01<08:13,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:02<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:08<07:54,  1.16s/it] 19%|█▊        | 93/500 [01:08<05:39,  1.20it/s] 19%|█▉        | 95/500 [01:08<04:04,  1.66it/s] 19%|█▉        | 97/500 [01:08<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:08<02:12,  3.04it/s] 20%|██        | 101/500 [01:15<07:51,  1.18s/it] 21%|██        | 103/500 [01:15<05:36,  1.18it/s] 21%|██        | 105/500 [01:15<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:15<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:15<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:21<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:26,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:22<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:28<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:29<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:29<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:35<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:36<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:36<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:42<07:07,  1.19s/it]Epoch:  72  	Training Loss: 0.0204163771122694
Test Loss:  0.0060189529322087765
Valid Loss:  0.011636054143309593
Epoch:  73  	Training Loss: 0.020414551720023155
Test Loss:  0.006018294021487236
Valid Loss:  0.011635147035121918
Epoch:  74  	Training Loss: 0.020412728190422058
Test Loss:  0.006016417406499386
Valid Loss:  0.011634467169642448
Epoch:  75  	Training Loss: 0.020410913974046707
Test Loss:  0.006016647908836603
Valid Loss:  0.011633278802037239
Epoch:  76  	Training Loss: 0.020409084856510162
Test Loss:  0.006016225554049015
Valid Loss:  0.011632295325398445
Epoch:  77  	Training Loss: 0.020407257601618767
Test Loss:  0.006015647668391466
Valid Loss:  0.011631343513727188
Epoch:  78  	Training Loss: 0.020405437797307968
Test Loss:  0.006015037186443806
Valid Loss:  0.011630400083959103
Epoch:  79  	Training Loss: 0.02040361613035202
Test Loss:  0.00601442065089941
Valid Loss:  0.011629452928900719
Epoch:  80  	Training Loss: 0.020401794463396072
Test Loss:  0.006013804581016302
Valid Loss:  0.011628499254584312
Epoch:  81  	Training Loss: 0.020399976521730423
Test Loss:  0.006013190373778343
Valid Loss:  0.01162753812968731
Epoch:  82  	Training Loss: 0.020398158580064774
Test Loss:  0.006012575700879097
Valid Loss:  0.011626571416854858
Epoch:  83  	Training Loss: 0.020396336913108826
Test Loss:  0.006011961959302425
Valid Loss:  0.011625598184764385
Epoch:  84  	Training Loss: 0.020394518971443176
Test Loss:  0.006011348217725754
Valid Loss:  0.011624621227383614
Epoch:  85  	Training Loss: 0.02039269730448723
Test Loss:  0.006010738667100668
Valid Loss:  0.01162363775074482
Epoch:  86  	Training Loss: 0.020390881225466728
Test Loss:  0.0060101281851530075
Valid Loss:  0.011622649617493153
Epoch:  87  	Training Loss: 0.020389065146446228
Test Loss:  0.006009519100189209
Valid Loss:  0.011621657758951187
Epoch:  88  	Training Loss: 0.02038724720478058
Test Loss:  0.006008909549564123
Valid Loss:  0.011620661243796349
Epoch:  89  	Training Loss: 0.02038542926311493
Test Loss:  0.006008302792906761
Valid Loss:  0.011619658209383488
Epoch:  90  	Training Loss: 0.02038361132144928
Test Loss:  0.006007697433233261
Valid Loss:  0.011618653312325478
Epoch:  91  	Training Loss: 0.02038179710507393
Test Loss:  0.006007092539221048
Valid Loss:  0.011617644689977169
Epoch:  92  	Training Loss: 0.02037997916340828
Test Loss:  0.006006491836160421
Valid Loss:  0.011616645380854607
Epoch:  93  	Training Loss: 0.02037818171083927
Test Loss:  0.0060058943927288055
Valid Loss:  0.011615637689828873
Epoch:  94  	Training Loss: 0.020376384258270264
Test Loss:  0.006005295552313328
Valid Loss:  0.011614629998803139
Epoch:  95  	Training Loss: 0.020374588668346405
Test Loss:  0.006004698574542999
Valid Loss:  0.011613616719841957
Epoch:  96  	Training Loss: 0.020372791215777397
Test Loss:  0.006004103925079107
Valid Loss:  0.011612598784267902
Epoch:  97  	Training Loss: 0.02037099376320839
Test Loss:  0.006003507412970066
Valid Loss:  0.011611578986048698
Epoch:  98  	Training Loss: 0.02036919631063938
Test Loss:  0.006002915557473898
Valid Loss:  0.01161055825650692
Epoch:  99  	Training Loss: 0.020367398858070374
Test Loss:  0.0060023171827197075
Valid Loss:  0.011609531007707119
Epoch:  100  	Training Loss: 0.020365601405501366
Test Loss:  0.006001725327223539
Valid Loss:  0.011608502827584743
Epoch:  101  	Training Loss: 0.020363803952932358
Test Loss:  0.006001131609082222
Valid Loss:  0.011607471853494644
Epoch:  102  	Training Loss: 0.02036200650036335
Test Loss:  0.00600053183734417
Valid Loss:  0.011606421321630478
Epoch:  103  	Training Loss: 0.02036018669605255
Test Loss:  0.005999932065606117
Valid Loss:  0.011605368927121162
Epoch:  104  	Training Loss: 0.020358366891741753
Test Loss:  0.005999332293868065
Valid Loss:  0.011604314669966698
Epoch:  105  	Training Loss: 0.020356543362140656
Test Loss:  0.005998730659484863
Valid Loss:  0.011603259481489658
Epoch:  106  	Training Loss: 0.020354725420475006
Test Loss:  0.005998135544359684
Valid Loss:  0.01160220056772232
Epoch:  107  	Training Loss: 0.020352907478809357
Test Loss:  0.005997533909976482
Valid Loss:  0.011601138859987259
Epoch:  108  	Training Loss: 0.02035108581185341
Test Loss:  0.0059969364665448666
Valid Loss:  0.011600075289607048
Epoch:  109  	Training Loss: 0.020349260419607162
Test Loss:  0.0059963371604681015
Valid Loss:  0.011599007062613964
Epoch:  110  	Training Loss: 0.020347438752651215
Test Loss:  0.0059957378543913364
Valid Loss:  0.01159793883562088
Epoch:  111  	Training Loss: 0.020345617085695267
Test Loss:  0.005995138548314571
Valid Loss:  0.011596865952014923
Epoch:  112  	Training Loss: 0.02034379169344902
Test Loss:  0.005994545761495829
Valid Loss:  0.011595802381634712
Epoch:  113  	Training Loss: 0.020341984927654266
Test Loss:  0.005993952043354511
Valid Loss:  0.011594738811254501
Epoch:  114  	Training Loss: 0.020340178161859512
Test Loss:  0.005993357859551907
Valid Loss:  0.011593673378229141
Epoch:  115  	Training Loss: 0.02033837139606476
Test Loss:  0.005992766935378313
Valid Loss:  0.011592604219913483
Epoch:  116  	Training Loss: 0.020336564630270004
Test Loss:  0.005992175079882145
Valid Loss:  0.011591536924242973
Epoch:  117  	Training Loss: 0.02033475786447525
Test Loss:  0.0059915827587246895
Valid Loss:  0.011590464040637016
Epoch:  118  	Training Loss: 0.020332949236035347
Test Loss:  0.005990991368889809
Valid Loss:  0.01158939115703106
Epoch:  119  	Training Loss: 0.020331142470240593
Test Loss:  0.005990400444716215
Valid Loss:  0.011588319204747677
Epoch:  120  	Training Loss: 0.020329337567090988
Test Loss:  0.0059898109175264835
Valid Loss:  0.011587245389819145
Epoch:  121  	Training Loss: 0.020327530801296234
Test Loss:  0.00598921999335289
Valid Loss:  0.01158616691827774
Epoch:  122  	Training Loss: 0.02032572776079178
Test Loss:  0.005988634191453457
Valid Loss:  0.011585081927478313
Epoch:  123  	Training Loss: 0.02032390609383583
Test Loss:  0.0059880418702960014
Valid Loss:  0.011583993211388588
Epoch:  124  	Training Loss: 0.020322086289525032
Test Loss:  0.005987452808767557
Valid Loss:  0.011582905426621437
Epoch:  125  	Training Loss: 0.020320266485214233
Test Loss:  0.0059868632815778255
Valid Loss:  0.011581816710531712
Epoch:  126  	Training Loss: 0.020318444818258286
Test Loss:  0.0059862760826945305
Valid Loss:  0.011580724269151688
Epoch:  127  	Training Loss: 0.020316626876592636
Test Loss:  0.005985686555504799
Valid Loss:  0.011579632759094238
Epoch:  128  	Training Loss: 0.020314805209636688
Test Loss:  0.005985104478895664
Valid Loss:  0.01157853938639164
Epoch:  129  	Training Loss: 0.02031298168003559
Test Loss:  0.005984530784189701
Valid Loss:  0.011577446013689041
Epoch:  130  	Training Loss: 0.020311160013079643
Test Loss:  0.005983959883451462
Valid Loss:  0.011576350778341293
Epoch:  131  	Training Loss: 0.020309340208768845
Test Loss:  0.005983386654406786
Valid Loss:  0.011575253680348396
Epoch:  132  	Training Loss: 0.020307518541812897
Test Loss:  0.00598282041028142
Valid Loss:  0.011574169620871544
Epoch:  133  	Training Loss: 0.02030571922659874
Test Loss:  0.00598225649446249
Valid Loss:  0.011573086492717266
Epoch:  134  	Training Loss: 0.020303921774029732
Test Loss:  0.0059816911816596985
Valid Loss:  0.011572000570595264
Epoch:  135  	Training Loss: 0.020302124321460724
Test Loss:  0.0059811268001794815
Valid Loss:  0.011570916511118412
Epoch:  136  	Training Loss: 0.020300325006246567
Test Loss:  0.005980564281344414
Valid Loss:  0.011569833382964134
Epoch:  137  	Training Loss: 0.02029852755367756
Test Loss:  0.005980000831186771
Valid Loss:  0.011568743735551834
Epoch:  138  	Training Loss: 0.0202967319637537
Test Loss:  0.005979437381029129
Valid Loss:  0.011567655950784683
Epoch:  139  	Training Loss: 0.020294934511184692
Test Loss:  0.005978873930871487
Valid Loss:  0.011566568166017532
Epoch:  140  	Training Loss: 0.020293135195970535
Test Loss:  0.005978312809020281
Valid Loss:  0.01156548224389553
Epoch:  141  	Training Loss: 0.020291339606046677
Test Loss:  0.0059777507558465
Valid Loss:  0.011564391665160656
Epoch:  142  	Training Loss: 0.02028954215347767
 29%|██▊       | 143/500 [01:42<05:04,  1.17it/s] 29%|██▉       | 145/500 [01:42<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:42<02:39,  2.22it/s] 30%|██▉       | 149/500 [01:43<01:57,  2.98it/s] 30%|███       | 151/500 [01:49<06:49,  1.17s/it] 31%|███       | 153/500 [01:49<04:53,  1.18it/s] 31%|███       | 155/500 [01:49<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:56<06:35,  1.17s/it] 33%|███▎      | 163/500 [01:56<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:56<03:23,  1.65it/s] 33%|███▎      | 167/500 [01:56<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:56<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:02<06:23,  1.17s/it] 35%|███▍      | 173/500 [02:03<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:03<03:16,  1.65it/s] 35%|███▌      | 177/500 [02:03<02:23,  2.26it/s] 36%|███▌      | 179/500 [02:03<01:45,  3.03it/s] 36%|███▌      | 181/500 [02:09<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:16<06:09,  1.20s/it] 39%|███▊      | 193/500 [02:16<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:16<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:17<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:17<01:41,  2.96it/s] 40%|████      | 201/500 [02:23<05:58,  1.20s/it] 41%|████      | 203/500 [02:23<04:15,  1.16it/s] 41%|████      | 205/500 [02:23<03:03,  1.61it/s] 41%|████▏     | 207/500 [02:24<02:13,  2.20it/s] 42%|████▏     | 209/500 [02:24<01:38,  2.97it/s] 42%|████▏     | 211/500 [02:30<05:39,  1.17s/it]Test Loss:  0.005977191496640444
Valid Loss:  0.01156330294907093
Epoch:  143  	Training Loss: 0.02028774842619896
Test Loss:  0.005976632237434387
Valid Loss:  0.011562218889594078
Epoch:  144  	Training Loss: 0.02028595097362995
Test Loss:  0.0059760697185993195
Valid Loss:  0.011561126448214054
Epoch:  145  	Training Loss: 0.02028416097164154
Test Loss:  0.005975509528070688
Valid Loss:  0.011560036800801754
Epoch:  146  	Training Loss: 0.020282365381717682
Test Loss:  0.005974951665848494
Valid Loss:  0.011558950878679752
Epoch:  147  	Training Loss: 0.020280569791793823
Test Loss:  0.005974393337965012
Valid Loss:  0.011557860299944878
Epoch:  148  	Training Loss: 0.020278777927160263
Test Loss:  0.005973833613097668
Valid Loss:  0.011556770652532578
Epoch:  149  	Training Loss: 0.020276980474591255
Test Loss:  0.005973273888230324
Valid Loss:  0.011555679142475128
Epoch:  150  	Training Loss: 0.020275188609957695
Test Loss:  0.005972716491669416
Valid Loss:  0.011554587632417679
Epoch:  151  	Training Loss: 0.020273393020033836
Test Loss:  0.0059721581637859344
Valid Loss:  0.011553498916327953
Epoch:  152  	Training Loss: 0.020271603018045425
Test Loss:  0.005971597041934729
Valid Loss:  0.011552395299077034
Epoch:  153  	Training Loss: 0.020269792526960373
Test Loss:  0.005971032194793224
Valid Loss:  0.011551295407116413
Epoch:  154  	Training Loss: 0.02026798576116562
Test Loss:  0.005970469675958157
Valid Loss:  0.011550195515155792
Epoch:  155  	Training Loss: 0.020266178995370865
Test Loss:  0.005969907157123089
Valid Loss:  0.011549098417162895
Epoch:  156  	Training Loss: 0.02026437595486641
Test Loss:  0.005969347432255745
Valid Loss:  0.011547994799911976
Epoch:  157  	Training Loss: 0.020262569189071655
Test Loss:  0.005968786310404539
Valid Loss:  0.011546896770596504
Epoch:  158  	Training Loss: 0.02026076428592205
Test Loss:  0.0059682223945856094
Valid Loss:  0.011545799672603607
Epoch:  159  	Training Loss: 0.020258955657482147
Test Loss:  0.005967663135379553
Valid Loss:  0.011544695124030113
Epoch:  160  	Training Loss: 0.02025715261697769
Test Loss:  0.005967102479189634
Valid Loss:  0.011543592438101768
Epoch:  161  	Training Loss: 0.020255349576473236
Test Loss:  0.005966542288661003
Valid Loss:  0.011542493477463722
Epoch:  162  	Training Loss: 0.020253542810678482
Test Loss:  0.005965981632471085
Valid Loss:  0.011541393585503101
Epoch:  163  	Training Loss: 0.020251737907528877
Test Loss:  0.0059654247015714645
Valid Loss:  0.011540292762219906
Epoch:  164  	Training Loss: 0.02024994045495987
Test Loss:  0.005964861251413822
Valid Loss:  0.011539190076291561
Epoch:  165  	Training Loss: 0.020248133689165115
Test Loss:  0.005964305251836777
Valid Loss:  0.01153809204697609
Epoch:  166  	Training Loss: 0.020246334373950958
Test Loss:  0.005963744595646858
Valid Loss:  0.011536989361047745
Epoch:  167  	Training Loss: 0.020244533196091652
Test Loss:  0.0059631867334246635
Valid Loss:  0.0115358866751194
Epoch:  168  	Training Loss: 0.020242728292942047
Test Loss:  0.005962627474218607
Valid Loss:  0.011534787714481354
Epoch:  169  	Training Loss: 0.02024092897772789
Test Loss:  0.00596206821501255
Valid Loss:  0.011533685028553009
Epoch:  170  	Training Loss: 0.020239129662513733
Test Loss:  0.005961510352790356
Valid Loss:  0.011532584205269814
Epoch:  171  	Training Loss: 0.020237328484654427
Test Loss:  0.00596095435321331
Valid Loss:  0.011531484313309193
Epoch:  172  	Training Loss: 0.02023553103208542
Test Loss:  0.005960400681942701
Valid Loss:  0.011530395597219467
Epoch:  173  	Training Loss: 0.020233744755387306
Test Loss:  0.005959846545010805
Valid Loss:  0.01152930036187172
Epoch:  174  	Training Loss: 0.020231958478689194
Test Loss:  0.00595929566770792
Valid Loss:  0.01152820885181427
Epoch:  175  	Training Loss: 0.02023017778992653
Test Loss:  0.005958740599453449
Valid Loss:  0.01152711734175682
Epoch:  176  	Training Loss: 0.020228393375873566
Test Loss:  0.005958189256489277
Valid Loss:  0.01152602769434452
Epoch:  177  	Training Loss: 0.020226607099175453
Test Loss:  0.005957636050879955
Valid Loss:  0.011524934321641922
Epoch:  178  	Training Loss: 0.02022482641041279
Test Loss:  0.005957083776593208
Valid Loss:  0.011523840948939323
Epoch:  179  	Training Loss: 0.020223040133714676
Test Loss:  0.0059565333649516106
Valid Loss:  0.011522750370204449
Epoch:  180  	Training Loss: 0.020221257582306862
Test Loss:  0.005955982021987438
Valid Loss:  0.011521657928824425
Epoch:  181  	Training Loss: 0.020219475030899048
Test Loss:  0.0059554316103458405
Valid Loss:  0.011520568281412125
Epoch:  182  	Training Loss: 0.020217692479491234
Test Loss:  0.005954881198704243
Valid Loss:  0.011519476771354675
Epoch:  183  	Training Loss: 0.020215913653373718
Test Loss:  0.005954328924417496
Valid Loss:  0.0115183861926198
Epoch:  184  	Training Loss: 0.020214131101965904
Test Loss:  0.005953778512775898
Valid Loss:  0.011517293751239777
Epoch:  185  	Training Loss: 0.02021234855055809
Test Loss:  0.005953227635473013
Valid Loss:  0.011516204103827477
Epoch:  186  	Training Loss: 0.020210569724440575
Test Loss:  0.005952676758170128
Valid Loss:  0.011515111662447453
Epoch:  187  	Training Loss: 0.02020878903567791
Test Loss:  0.0059521254152059555
Valid Loss:  0.011514026671648026
Epoch:  188  	Training Loss: 0.020207010209560394
Test Loss:  0.005951577797532082
Valid Loss:  0.011512935161590576
Epoch:  189  	Training Loss: 0.02020523138344288
Test Loss:  0.005951025988906622
Valid Loss:  0.011511843651533127
Epoch:  190  	Training Loss: 0.020203452557325363
Test Loss:  0.0059504760429263115
Valid Loss:  0.011510755866765976
Epoch:  191  	Training Loss: 0.020201675593852997
Test Loss:  0.005949925631284714
Valid Loss:  0.011509662494063377
Epoch:  192  	Training Loss: 0.020199894905090332
Test Loss:  0.005949375219643116
Valid Loss:  0.011508574709296227
Epoch:  193  	Training Loss: 0.020198114216327667
Test Loss:  0.005948828067630529
Valid Loss:  0.011507485061883926
Epoch:  194  	Training Loss: 0.020196333527565002
Test Loss:  0.0059482743963599205
Valid Loss:  0.011506393551826477
Epoch:  195  	Training Loss: 0.020194552838802338
Test Loss:  0.005947725847363472
Valid Loss:  0.011505307629704475
Epoch:  196  	Training Loss: 0.02019277960062027
Test Loss:  0.005947176367044449
Valid Loss:  0.011504215188324451
Epoch:  197  	Training Loss: 0.020191000774502754
Test Loss:  0.005946625955402851
Valid Loss:  0.011503122746944427
Epoch:  198  	Training Loss: 0.020189223811030388
Test Loss:  0.005946078337728977
Valid Loss:  0.011502034962177277
Epoch:  199  	Training Loss: 0.020187444984912872
Test Loss:  0.005945527460426092
Valid Loss:  0.011500947177410126
Epoch:  200  	Training Loss: 0.020185668021440506
Test Loss:  0.0059449803084135056
Valid Loss:  0.011499859392642975
Epoch:  201  	Training Loss: 0.020183896645903587
Test Loss:  0.005944431759417057
Valid Loss:  0.011498769745230675
Epoch:  202  	Training Loss: 0.02018212154507637
Test Loss:  0.005943887401372194
Valid Loss:  0.011497688479721546
Epoch:  203  	Training Loss: 0.0201803557574749
Test Loss:  0.005943340249359608
Valid Loss:  0.011496605351567268
Epoch:  204  	Training Loss: 0.02017858996987343
Test Loss:  0.005942799150943756
Valid Loss:  0.011495523154735565
Epoch:  205  	Training Loss: 0.020176827907562256
Test Loss:  0.005942250601947308
Valid Loss:  0.011494440957903862
Epoch:  206  	Training Loss: 0.020175062119960785
Test Loss:  0.005941707640886307
Valid Loss:  0.01149335689842701
Epoch:  207  	Training Loss: 0.020173296332359314
Test Loss:  0.0059411609545350075
Valid Loss:  0.011492276564240456
Epoch:  208  	Training Loss: 0.020171528682112694
Test Loss:  0.00594061566516757
Valid Loss:  0.011491192504763603
Epoch:  209  	Training Loss: 0.020169762894511223
Test Loss:  0.005940071307122707
Valid Loss:  0.011490105651319027
Epoch:  210  	Training Loss: 0.020167995244264603
Test Loss:  0.005939525552093983
Valid Loss:  0.011489023454487324
Epoch:  211  	Training Loss: 0.020166227594017982
Test Loss:  0.005938979797065258
Valid Loss:  0.011487942188978195
Epoch:  212  	Training Loss: 0.020164459943771362
Test Loss:   43%|████▎     | 213/500 [02:30<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:37<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:37<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:37<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.22it/s] 46%|████▌     | 229/500 [02:37<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:44<05:18,  1.19s/it] 47%|████▋     | 233/500 [02:44<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:44<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:44<02:01,  2.16it/s] 48%|████▊     | 239/500 [02:44<01:31,  2.86it/s] 48%|████▊     | 241/500 [02:51<05:09,  1.20s/it] 49%|████▊     | 243/500 [02:51<03:40,  1.17it/s] 49%|████▉     | 245/500 [02:51<02:37,  1.61it/s] 49%|████▉     | 247/500 [02:51<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:51<01:24,  2.97it/s] 50%|█████     | 251/500 [02:57<04:52,  1.17s/it] 51%|█████     | 253/500 [02:58<03:28,  1.19it/s] 51%|█████     | 255/500 [02:58<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:58<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:58<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:04<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:05<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:05<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:05<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:11<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:11<03:16,  1.16it/s] 55%|█████▌    | 275/500 [03:12<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:12<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:12<01:15,  2.94it/s] 56%|█████▌    | 281/500 [03:18<04:16,  1.17s/it]0.005938427522778511
Valid Loss:  0.011486840434372425
Epoch:  213  	Training Loss: 0.020162666216492653
Test Loss:  0.005937875714153051
Valid Loss:  0.01148573774844408
Epoch:  214  	Training Loss: 0.020160872489213943
Test Loss:  0.005937321577221155
Valid Loss:  0.01148463785648346
Epoch:  215  	Training Loss: 0.020159076899290085
Test Loss:  0.005936767905950546
Valid Loss:  0.011483537033200264
Epoch:  216  	Training Loss: 0.020157283172011375
Test Loss:  0.005936214700341225
Valid Loss:  0.011482436209917068
Epoch:  217  	Training Loss: 0.020155487582087517
Test Loss:  0.005935659632086754
Valid Loss:  0.011481333523988724
Epoch:  218  	Training Loss: 0.020153693854808807
Test Loss:  0.005935104563832283
Valid Loss:  0.011480232700705528
Epoch:  219  	Training Loss: 0.020151900127530098
Test Loss:  0.005934552289545536
Valid Loss:  0.011479131877422333
Epoch:  220  	Training Loss: 0.02015010267496109
Test Loss:  0.005933997221291065
Valid Loss:  0.011478031054139137
Epoch:  221  	Training Loss: 0.02014830708503723
Test Loss:  0.005933442153036594
Valid Loss:  0.011476928368210793
Epoch:  222  	Training Loss: 0.020146511495113373
Test Loss:  0.005932886619120836
Valid Loss:  0.011475825682282448
Epoch:  223  	Training Loss: 0.020144712179899216
Test Loss:  0.005932332947850227
Valid Loss:  0.011474721133708954
Epoch:  224  	Training Loss: 0.02014291286468506
Test Loss:  0.00593177555128932
Valid Loss:  0.011473617516458035
Epoch:  225  	Training Loss: 0.0201411135494709
Test Loss:  0.005932308267802
Valid Loss:  0.011472264304757118
Epoch:  226  	Training Loss: 0.02013932541012764
Test Loss:  0.005930859129875898
Valid Loss:  0.011471436358988285
Epoch:  227  	Training Loss: 0.020137518644332886
Test Loss:  0.005930200219154358
Valid Loss:  0.011470368131995201
Epoch:  228  	Training Loss: 0.020135723054409027
Test Loss:  0.005932639352977276
Valid Loss:  0.011468631215393543
Epoch:  229  	Training Loss: 0.020133990794420242
Test Loss:  0.00592951662838459
Valid Loss:  0.011468268930912018
Epoch:  230  	Training Loss: 0.020132139325141907
Test Loss:  0.005928433500230312
Valid Loss:  0.011467324569821358
Epoch:  231  	Training Loss: 0.0201303418725729
Test Loss:  0.0059288679622113705
Valid Loss:  0.011465986259281635
Epoch:  232  	Training Loss: 0.020128551870584488
Test Loss:  0.005927396006882191
Valid Loss:  0.011465158313512802
Epoch:  233  	Training Loss: 0.02012675255537033
Test Loss:  0.0059298379346728325
Valid Loss:  0.011463411152362823
Epoch:  234  	Training Loss: 0.020125020295381546
Test Loss:  0.005926634185016155
Valid Loss:  0.011463070288300514
Epoch:  235  	Training Loss: 0.02012316882610321
Test Loss:  0.0059255389496684074
Valid Loss:  0.011462118476629257
Epoch:  236  	Training Loss: 0.02012137696146965
Test Loss:  0.0059259734116494656
Valid Loss:  0.011460773646831512
Epoch:  237  	Training Loss: 0.020119590684771538
Test Loss:  0.0059245890006423
Valid Loss:  0.011459915898740292
Epoch:  238  	Training Loss: 0.02011779695749283
Test Loss:  0.00592688238248229
Valid Loss:  0.011458192951977253
Epoch:  239  	Training Loss: 0.020116053521633148
Test Loss:  0.005923738703131676
Valid Loss:  0.011457827873528004
Epoch:  240  	Training Loss: 0.02011420577764511
Test Loss:  0.0059226686134934425
Valid Loss:  0.011456862092018127
Epoch:  241  	Training Loss: 0.02011241391301155
Test Loss:  0.005923178978264332
Valid Loss:  0.011455491185188293
Epoch:  242  	Training Loss: 0.02011062204837799
Test Loss:  0.0059216637164354324
Valid Loss:  0.011454685591161251
Epoch:  243  	Training Loss: 0.02010888233780861
Test Loss:  0.005924023222178221
Valid Loss:  0.011452954262495041
Epoch:  244  	Training Loss: 0.020107153803110123
Test Loss:  0.005920910742133856
Valid Loss:  0.01145260315388441
Epoch:  245  	Training Loss: 0.020105350762605667
Test Loss:  0.005920943804085255
Valid Loss:  0.011451397091150284
Epoch:  246  	Training Loss: 0.02010359987616539
Test Loss:  0.005919492803514004
Valid Loss:  0.011450575664639473
Epoch:  247  	Training Loss: 0.02010186016559601
Test Loss:  0.005921781063079834
Valid Loss:  0.011448855511844158
Epoch:  248  	Training Loss: 0.02010013535618782
Test Loss:  0.005918655078858137
Valid Loss:  0.011448505334556103
Epoch:  249  	Training Loss: 0.020098334178328514
Test Loss:  0.005918693728744984
Valid Loss:  0.011447293683886528
Epoch:  250  	Training Loss: 0.020096581429243088
Test Loss:  0.005917241796851158
Valid Loss:  0.01144646480679512
Epoch:  251  	Training Loss: 0.0200948566198349
Test Loss:  0.0059195347130298615
Valid Loss:  0.011444734409451485
Epoch:  252  	Training Loss: 0.02009311318397522
Test Loss:  0.00591641291975975
Valid Loss:  0.011444369331002235
Epoch:  253  	Training Loss: 0.020091306418180466
Test Loss:  0.005916530266404152
Valid Loss:  0.011443119496107101
Epoch:  254  	Training Loss: 0.020089535042643547
Test Loss:  0.005918026901781559
Valid Loss:  0.011441640555858612
Epoch:  255  	Training Loss: 0.02008782885968685
Test Loss:  0.005914733745157719
Valid Loss:  0.011441316455602646
Epoch:  256  	Training Loss: 0.02008601278066635
Test Loss:  0.0059148166328668594
Valid Loss:  0.011440071277320385
Epoch:  257  	Training Loss: 0.02008424513041973
Test Loss:  0.005916312336921692
Valid Loss:  0.011438584886491299
Epoch:  258  	Training Loss: 0.020082533359527588
Test Loss:  0.005913020111620426
Valid Loss:  0.011438253335654736
Epoch:  259  	Training Loss: 0.020080722868442535
Test Loss:  0.005913108587265015
Valid Loss:  0.011437002569437027
Epoch:  260  	Training Loss: 0.020078957080841064
Test Loss:  0.005914605222642422
Valid Loss:  0.011435508728027344
Epoch:  261  	Training Loss: 0.020077243447303772
Test Loss:  0.005911317653954029
Valid Loss:  0.011435171589255333
Epoch:  262  	Training Loss: 0.02007542923092842
Test Loss:  0.005911396816372871
Valid Loss:  0.011433880776166916
Epoch:  263  	Training Loss: 0.02007361501455307
Test Loss:  0.005912874825298786
Valid Loss:  0.011432335712015629
Epoch:  264  	Training Loss: 0.020071830600500107
Test Loss:  0.005909577943384647
Valid Loss:  0.01143197063356638
Epoch:  265  	Training Loss: 0.02006997913122177
Test Loss:  0.005909653380513191
Valid Loss:  0.011430671438574791
Epoch:  266  	Training Loss: 0.020068172365427017
Test Loss:  0.0059111337177455425
Valid Loss:  0.011429124511778355
Epoch:  267  	Training Loss: 0.02006637677550316
Test Loss:  0.005907840095460415
Valid Loss:  0.011428751051425934
Epoch:  268  	Training Loss: 0.020064523443579674
Test Loss:  0.0059110550209879875
Valid Loss:  0.011426789686083794
Epoch:  269  	Training Loss: 0.020062781870365143
Test Loss:  0.005906863138079643
Valid Loss:  0.011426655575633049
Epoch:  270  	Training Loss: 0.020060893148183823
Test Loss:  0.00590676162391901
Valid Loss:  0.011425403878092766
Epoch:  271  	Training Loss: 0.020059091970324516
Test Loss:  0.0059082116931676865
Valid Loss:  0.011423852294683456
Epoch:  272  	Training Loss: 0.02005729079246521
Test Loss:  0.005904918536543846
Valid Loss:  0.011423490010201931
Epoch:  273  	Training Loss: 0.020055480301380157
Test Loss:  0.005908146966248751
Valid Loss:  0.011421548202633858
Epoch:  274  	Training Loss: 0.020053774118423462
Test Loss:  0.005903972312808037
Valid Loss:  0.011421417817473412
Epoch:  275  	Training Loss: 0.02005191147327423
Test Loss:  0.005907024722546339
Valid Loss:  0.011419525370001793
Epoch:  276  	Training Loss: 0.02005022019147873
Test Loss:  0.005902813281863928
Valid Loss:  0.011419398710131645
Epoch:  277  	Training Loss: 0.02004835568368435
Test Loss:  0.005905859172344208
Valid Loss:  0.011417500674724579
Epoch:  278  	Training Loss: 0.020046662539243698
Test Loss:  0.005901649594306946
Valid Loss:  0.011417376808822155
Epoch:  279  	Training Loss: 0.020044798031449318
Test Loss:  0.005904699210077524
Valid Loss:  0.011415467597544193
Epoch:  280  	Training Loss: 0.020043106749653816
Test Loss:  0.005900492891669273
Valid Loss:  0.011415338143706322
Epoch:  281  	Training Loss: 0.020041245967149734
Test Loss:  0.005903543904423714
Valid Loss:  0.011413424275815487
Epoch:  282  	Training Loss: 0.020039549097418785
Test Loss:  0.005899338982999325
Valid Loss:   57%|█████▋    | 283/500 [03:18<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:18<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:19<01:34,  2.24it/s] 58%|█████▊    | 289/500 [03:19<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:25<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:25<02:54,  1.18it/s] 59%|█████▉    | 295/500 [03:25<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:25<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:26<01:08,  2.92it/s] 60%|██████    | 301/500 [03:32<03:56,  1.19s/it] 61%|██████    | 303/500 [03:32<02:47,  1.17it/s] 61%|██████    | 305/500 [03:32<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:32<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:39<03:42,  1.18s/it] 63%|██████▎   | 313/500 [03:39<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:39<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:39<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:39<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:45<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:46<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:46<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:46<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:46<00:57,  2.95it/s] 66%|██████▌   | 331/500 [03:52<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:53<02:23,  1.17it/s] 67%|██████▋   | 335/500 [03:53<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:53<01:13,  2.20it/s] 68%|██████▊   | 339/500 [03:53<00:54,  2.97it/s] 68%|██████▊   | 341/500 [03:59<03:08,  1.18s/it] 69%|██████▊   | 343/500 [03:59<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:00<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:00<01:09,  2.22it/s] 70%|██████▉   | 349/500 [04:00<00:50,  2.99it/s] 70%|███████   | 351/500 [04:06<02:55,  1.18s/it]0.011413278989493847
Epoch:  283  	Training Loss: 0.020037680864334106
Test Loss:  0.005902385339140892
Valid Loss:  0.011411342769861221
Epoch:  284  	Training Loss: 0.020035957917571068
Test Loss:  0.005898177623748779
Valid Loss:  0.01141119934618473
Epoch:  285  	Training Loss: 0.020034093409776688
Test Loss:  0.005901225842535496
Valid Loss:  0.011409257538616657
Epoch:  286  	Training Loss: 0.0200323648750782
Test Loss:  0.005897025112062693
Valid Loss:  0.011409109458327293
Epoch:  287  	Training Loss: 0.020030509680509567
Test Loss:  0.005900071933865547
Valid Loss:  0.011407161131501198
Epoch:  288  	Training Loss: 0.020028777420520782
Test Loss:  0.005895874463021755
Valid Loss:  0.01140701211988926
Epoch:  289  	Training Loss: 0.020026927813887596
Test Loss:  0.005898922681808472
Valid Loss:  0.01140506099909544
Epoch:  290  	Training Loss: 0.020025191828608513
Test Loss:  0.005894726607948542
Valid Loss:  0.011404911056160927
Epoch:  291  	Training Loss: 0.020023345947265625
Test Loss:  0.005897779017686844
Valid Loss:  0.011402953416109085
Epoch:  292  	Training Loss: 0.020021606236696243
Test Loss:  0.005893595516681671
Valid Loss:  0.011402824893593788
Epoch:  293  	Training Loss: 0.020019814372062683
Test Loss:  0.005897810682654381
Valid Loss:  0.011400675401091576
Epoch:  294  	Training Loss: 0.020018160343170166
Test Loss:  0.005892675835639238
Valid Loss:  0.011400780640542507
Epoch:  295  	Training Loss: 0.020016318187117577
Test Loss:  0.005894514732062817
Valid Loss:  0.011399108916521072
Epoch:  296  	Training Loss: 0.020014557987451553
Test Loss:  0.005891155451536179
Valid Loss:  0.011398754082620144
Epoch:  297  	Training Loss: 0.020012836903333664
Test Loss:  0.00589545164257288
Valid Loss:  0.01139654591679573
Epoch:  298  	Training Loss: 0.020011138170957565
Test Loss:  0.005890431813895702
Valid Loss:  0.011396628804504871
Epoch:  299  	Training Loss: 0.020009323954582214
Test Loss:  0.00589230190962553
Valid Loss:  0.011394936591386795
Epoch:  300  	Training Loss: 0.020007552579045296
Test Loss:  0.005888945423066616
Valid Loss:  0.011394581757485867
Epoch:  301  	Training Loss: 0.020005851984024048
Test Loss:  0.005893228575587273
Valid Loss:  0.011392375454306602
Epoch:  302  	Training Loss: 0.020004136487841606
Test Loss:  0.005888217128813267
Valid Loss:  0.011392428539693356
Epoch:  303  	Training Loss: 0.02000231109559536
Test Loss:  0.005893310531973839
Valid Loss:  0.011390110477805138
Epoch:  304  	Training Loss: 0.020000657066702843
Test Loss:  0.005888374522328377
Valid Loss:  0.011390152387320995
Epoch:  305  	Training Loss: 0.019998688250780106
Test Loss:  0.005887041799724102
Valid Loss:  0.011389235965907574
Epoch:  306  	Training Loss: 0.019996952265501022
Test Loss:  0.005888259503990412
Valid Loss:  0.011387698352336884
Epoch:  307  	Training Loss: 0.01999514363706112
Test Loss:  0.005886055063456297
Valid Loss:  0.011387034319341183
Epoch:  308  	Training Loss: 0.019993392750620842
Test Loss:  0.0058873482048511505
Valid Loss:  0.011385489255189896
Epoch:  309  	Training Loss: 0.01999158412218094
Test Loss:  0.005884982645511627
Valid Loss:  0.011384870857000351
Epoch:  310  	Training Loss: 0.01998983323574066
Test Loss:  0.005889303982257843
Valid Loss:  0.01138276793062687
Epoch:  311  	Training Loss: 0.01998819410800934
Test Loss:  0.005884500686079264
Valid Loss:  0.011382773518562317
Epoch:  312  	Training Loss: 0.019986232742667198
Test Loss:  0.005886244587600231
Valid Loss:  0.011381221935153008
Epoch:  313  	Training Loss: 0.01998455449938774
Test Loss:  0.005881797056645155
Valid Loss:  0.011381137184798717
Epoch:  314  	Training Loss: 0.019982807338237762
Test Loss:  0.005886053200811148
Valid Loss:  0.011378936469554901
Epoch:  315  	Training Loss: 0.019981104880571365
Test Loss:  0.005880862008780241
Valid Loss:  0.011379038915038109
Epoch:  316  	Training Loss: 0.019979333505034447
Test Loss:  0.005885755643248558
Valid Loss:  0.011376745067536831
Epoch:  317  	Training Loss: 0.019977666437625885
Test Loss:  0.005881068296730518
Valid Loss:  0.01137673668563366
Epoch:  318  	Training Loss: 0.019975747913122177
Test Loss:  0.005882851779460907
Valid Loss:  0.011375157162547112
Epoch:  319  	Training Loss: 0.019974060356616974
Test Loss:  0.005878416821360588
Valid Loss:  0.011375060304999352
Epoch:  320  	Training Loss: 0.01997232995927334
Test Loss:  0.005882690194994211
Valid Loss:  0.011372840031981468
Epoch:  321  	Training Loss: 0.019970614463090897
Test Loss:  0.005877499468624592
Valid Loss:  0.011372934095561504
Epoch:  322  	Training Loss: 0.019968867301940918
Test Loss:  0.005882376804947853
Valid Loss:  0.011370601132512093
Epoch:  323  	Training Loss: 0.019967149943113327
Test Loss:  0.00587769690901041
Valid Loss:  0.011370571330189705
Epoch:  324  	Training Loss: 0.019965223968029022
Test Loss:  0.0058806287124753
Valid Loss:  0.01136874035000801
Epoch:  325  	Training Loss: 0.019963553175330162
Test Loss:  0.005875241942703724
Valid Loss:  0.011368866078555584
Epoch:  326  	Training Loss: 0.019961772486567497
Test Loss:  0.0058802710846066475
Valid Loss:  0.011366499587893486
Epoch:  327  	Training Loss: 0.01996006816625595
Test Loss:  0.005875349976122379
Valid Loss:  0.011366518214344978
Epoch:  328  	Training Loss: 0.019958140328526497
Test Loss:  0.005878320429474115
Valid Loss:  0.01136466022580862
Epoch:  329  	Training Loss: 0.019956454634666443
Test Loss:  0.005872949026525021
Valid Loss:  0.011364777572453022
Epoch:  330  	Training Loss: 0.01995469257235527
Test Loss:  0.005879153497517109
Valid Loss:  0.011362199671566486
Epoch:  331  	Training Loss: 0.019953034818172455
Test Loss:  0.005872171372175217
Valid Loss:  0.011362691409885883
Epoch:  332  	Training Loss: 0.019951097667217255
Test Loss:  0.0058759357780218124
Valid Loss:  0.011360583826899529
Epoch:  333  	Training Loss: 0.019949370995163918
Test Loss:  0.005870668683201075
Valid Loss:  0.011360682547092438
Epoch:  334  	Training Loss: 0.01994764804840088
Test Loss:  0.005876692943274975
Valid Loss:  0.011358125135302544
Epoch:  335  	Training Loss: 0.019945967942476273
Test Loss:  0.005869968794286251
Valid Loss:  0.011358566582202911
Epoch:  336  	Training Loss: 0.019944079220294952
Test Loss:  0.005873711779713631
Valid Loss:  0.011356456205248833
Epoch:  337  	Training Loss: 0.019942335784435272
Test Loss:  0.005868421867489815
Valid Loss:  0.01135656051337719
Epoch:  338  	Training Loss: 0.019940633326768875
Test Loss:  0.005874545779079199
Valid Loss:  0.011353972367942333
Epoch:  339  	Training Loss: 0.019938938319683075
Test Loss:  0.005867666099220514
Valid Loss:  0.01135445199906826
Epoch:  340  	Training Loss: 0.019937066361308098
Test Loss:  0.005874775815755129
Valid Loss:  0.011351760476827621
Epoch:  341  	Training Loss: 0.01993553712964058
Test Loss:  0.005866761319339275
Valid Loss:  0.011352483183145523
Epoch:  342  	Training Loss: 0.019933536648750305
Test Loss:  0.005870339460670948
Valid Loss:  0.011350424960255623
Epoch:  343  	Training Loss: 0.01993183046579361
Test Loss:  0.005865047685801983
Valid Loss:  0.0113505395129323
Epoch:  344  	Training Loss: 0.019930163398385048
Test Loss:  0.00587117113173008
Valid Loss:  0.01134795043617487
Epoch:  345  	Training Loss: 0.019928492605686188
Test Loss:  0.005864305421710014
Valid Loss:  0.011348431929945946
Epoch:  346  	Training Loss: 0.019926654174923897
Test Loss:  0.0058714235201478004
Valid Loss:  0.011345740407705307
Epoch:  347  	Training Loss: 0.01992514356970787
Test Loss:  0.005863426253199577
Valid Loss:  0.011346468701958656
Epoch:  348  	Training Loss: 0.019923174753785133
Test Loss:  0.005870332010090351
Valid Loss:  0.011343837715685368
Epoch:  349  	Training Loss: 0.019921699538826942
Test Loss:  0.005862287245690823
Valid Loss:  0.011344569735229015
Epoch:  350  	Training Loss: 0.01991971582174301
Test Loss:  0.005865877028554678
Valid Loss:  0.0113424863666296
Epoch:  351  	Training Loss: 0.01991800218820572
Test Loss:  0.005860575940459967
Valid Loss:  0.01134258508682251
Epoch:  352  	Training Loss: 0.0199163556098938
Test Loss:  0.005866707302629948
Valid Loss:  0.011339961551129818
 71%|███████   | 353/500 [04:06<02:04,  1.18it/s] 71%|███████   | 355/500 [04:06<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:07<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:07<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:13<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:13<01:57,  1.16it/s] 73%|███████▎  | 365/500 [04:13<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:14<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:14<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:20<02:34,  1.19s/it] 75%|███████▍  | 373/500 [04:20<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:20<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:20<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:21<00:40,  2.95it/s] 76%|███████▌  | 381/500 [04:27<02:21,  1.19s/it] 76%|███████▋  | 382/500 [04:27<01:57,  1.00it/s] 77%|███████▋  | 384/500 [04:27<01:20,  1.45it/s] 77%|███████▋  | 386/500 [04:27<00:56,  2.02it/s] 78%|███████▊  | 388/500 [04:28<00:40,  2.79it/s] 78%|███████▊  | 390/500 [04:28<00:29,  3.72it/s] 78%|███████▊  | 392/500 [04:34<02:07,  1.18s/it] 79%|███████▉  | 394/500 [04:34<01:28,  1.19it/s] 79%|███████▉  | 396/500 [04:34<01:02,  1.66it/s] 80%|███████▉  | 398/500 [04:34<00:44,  2.27it/s] 80%|████████  | 400/500 [04:35<00:32,  3.06it/s] 80%|████████  | 402/500 [04:41<01:54,  1.17s/it] 81%|████████  | 404/500 [04:41<01:20,  1.19it/s] 81%|████████  | 406/500 [04:41<00:56,  1.65it/s] 82%|████████▏ | 408/500 [04:41<00:40,  2.26it/s] 82%|████████▏ | 410/500 [04:41<00:29,  3.04it/s] 82%|████████▏ | 412/500 [04:48<01:45,  1.19s/it] 83%|████████▎ | 414/500 [04:48<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:48<00:52,  1.61it/s] 84%|████████▎ | 418/500 [04:48<00:37,  2.20it/s] 84%|████████▍ | 420/500 [04:48<00:27,  2.96it/s] 84%|████████▍ | 422/500 [04:55<01:31,  1.17s/it]Epoch:  353  	Training Loss: 0.0199146531522274
Test Loss:  0.00585985416546464
Valid Loss:  0.011340438388288021
Epoch:  354  	Training Loss: 0.019912853837013245
Test Loss:  0.0058669778518378735
Valid Loss:  0.011337706819176674
Epoch:  355  	Training Loss: 0.019911296665668488
Test Loss:  0.005858989432454109
Valid Loss:  0.011338428594172001
Epoch:  356  	Training Loss: 0.019909361377358437
Test Loss:  0.005865894258022308
Valid Loss:  0.011335757561028004
Epoch:  357  	Training Loss: 0.019907835870981216
Test Loss:  0.005857860203832388
Valid Loss:  0.011336488649249077
Epoch:  358  	Training Loss: 0.019905894994735718
Test Loss:  0.005864758975803852
Valid Loss:  0.011333808302879333
Epoch:  359  	Training Loss: 0.019904371351003647
Test Loss:  0.005856730043888092
Valid Loss:  0.011334539391100407
Epoch:  360  	Training Loss: 0.019902434200048447
Test Loss:  0.005863630678504705
Valid Loss:  0.011331852525472641
Epoch:  361  	Training Loss: 0.019900906831026077
Test Loss:  0.005855601746588945
Valid Loss:  0.011332576163113117
Epoch:  362  	Training Loss: 0.019898973405361176
Test Loss:  0.005862503312528133
Valid Loss:  0.011329878121614456
Epoch:  363  	Training Loss: 0.019897447898983955
Test Loss:  0.0058544715866446495
Valid Loss:  0.011330584064126015
Epoch:  364  	Training Loss: 0.019895490258932114
Test Loss:  0.005861374083906412
Valid Loss:  0.011327880434691906
Epoch:  365  	Training Loss: 0.019893959164619446
Test Loss:  0.0058533502742648125
Valid Loss:  0.011328584514558315
Epoch:  366  	Training Loss: 0.0198920089751482
Test Loss:  0.005860249511897564
Valid Loss:  0.011325866915285587
Epoch:  367  	Training Loss: 0.019890472292900085
Test Loss:  0.005852226633578539
Valid Loss:  0.011326572857797146
Epoch:  368  	Training Loss: 0.019888531416654587
Test Loss:  0.005859128199517727
Valid Loss:  0.011323845013976097
Epoch:  369  	Training Loss: 0.019886991009116173
Test Loss:  0.0058511109091341496
Valid Loss:  0.011324550025165081
Epoch:  370  	Training Loss: 0.019885055720806122
Test Loss:  0.005858009681105614
Valid Loss:  0.011321820318698883
Epoch:  371  	Training Loss: 0.01988350972533226
Test Loss:  0.0058499956503510475
Valid Loss:  0.011322518810629845
Epoch:  372  	Training Loss: 0.019881583750247955
Test Loss:  0.005856888834387064
Valid Loss:  0.011319760233163834
Epoch:  373  	Training Loss: 0.019879987463355064
Test Loss:  0.005848882254213095
Valid Loss:  0.011320473626255989
Epoch:  374  	Training Loss: 0.019878096878528595
Test Loss:  0.0058557745069265366
Valid Loss:  0.011317707598209381
Epoch:  375  	Training Loss: 0.01987648382782936
Test Loss:  0.005847767926752567
Valid Loss:  0.011318420059978962
Epoch:  376  	Training Loss: 0.019874613732099533
Test Loss:  0.005854662042111158
Valid Loss:  0.011315645650029182
Epoch:  377  	Training Loss: 0.019872982054948807
Test Loss:  0.005846655927598476
Valid Loss:  0.011316357180476189
Epoch:  378  	Training Loss: 0.019871124997735023
Test Loss:  0.005853552371263504
Valid Loss:  0.011313577182590961
Epoch:  379  	Training Loss: 0.019869478419423103
Test Loss:  0.0058455513790249825
Valid Loss:  0.011314285919070244
Epoch:  380  	Training Loss: 0.019867636263370514
Test Loss:  0.0058524468913674355
Valid Loss:  0.011311501264572144
Epoch:  381  	Training Loss: 0.0198659747838974
Test Loss:  0.005844448693096638
Valid Loss:  0.011312214657664299
Epoch:  382  	Training Loss: 0.019864151254296303
Test Loss:  0.005851342808455229
Valid Loss:  0.011309430003166199
Epoch:  383  	Training Loss: 0.019862480461597443
Test Loss:  0.00584334135055542
Valid Loss:  0.011310121975839138
Epoch:  384  	Training Loss: 0.0198606476187706
Test Loss:  0.005850235931575298
Valid Loss:  0.011307330802083015
Epoch:  385  	Training Loss: 0.019858961924910545
Test Loss:  0.0058422330766916275
Valid Loss:  0.011308024637401104
Epoch:  386  	Training Loss: 0.019857145845890045
Test Loss:  0.005849128123372793
Valid Loss:  0.011305229738354683
Epoch:  387  	Training Loss: 0.01985543966293335
Test Loss:  0.005841129459440708
Valid Loss:  0.011305920779705048
Epoch:  388  	Training Loss: 0.01985364407300949
Test Loss:  0.005848024971783161
Valid Loss:  0.011303124949336052
Epoch:  389  	Training Loss: 0.019851919263601303
Test Loss:  0.0058400267735123634
Valid Loss:  0.011303819715976715
Epoch:  390  	Training Loss: 0.019850147888064384
Test Loss:  0.005846920423209667
Valid Loss:  0.011301016435027122
Epoch:  391  	Training Loss: 0.019848402589559555
Test Loss:  0.005838925950229168
Valid Loss:  0.011301703751087189
Epoch:  392  	Training Loss: 0.01984664797782898
Test Loss:  0.005845814943313599
Valid Loss:  0.0112988892942667
Epoch:  393  	Training Loss: 0.019844859838485718
Test Loss:  0.00583781860768795
Valid Loss:  0.011299566365778446
Epoch:  394  	Training Loss: 0.01984311267733574
Test Loss:  0.005844703875482082
Valid Loss:  0.011296745389699936
Epoch:  395  	Training Loss: 0.019841302186250687
Test Loss:  0.005836706608533859
Valid Loss:  0.01129742432385683
Epoch:  396  	Training Loss: 0.0198395736515522
Test Loss:  0.0058435918763279915
Valid Loss:  0.01129460334777832
Epoch:  397  	Training Loss: 0.019837742671370506
Test Loss:  0.005835594609379768
Valid Loss:  0.01129528135061264
Epoch:  398  	Training Loss: 0.01983603462576866
Test Loss:  0.005842483602464199
Valid Loss:  0.011292455717921257
Epoch:  399  	Training Loss: 0.019834183156490326
Test Loss:  0.005834485404193401
Valid Loss:  0.011293129995465279
Epoch:  400  	Training Loss: 0.019832497462630272
Test Loss:  0.005841375328600407
Valid Loss:  0.01129030529409647
Epoch:  401  	Training Loss: 0.019830621778964996
Test Loss:  0.005833381786942482
Valid Loss:  0.011290982365608215
Epoch:  402  	Training Loss: 0.01982896402478218
Test Loss:  0.005840266589075327
Valid Loss:  0.01128816045820713
Epoch:  403  	Training Loss: 0.019827071577310562
Test Loss:  0.005832277704030275
Valid Loss:  0.011288843117654324
Epoch:  404  	Training Loss: 0.019825439900159836
Test Loss:  0.005839166231453419
Valid Loss:  0.011286013759672642
Epoch:  405  	Training Loss: 0.019823526963591576
Test Loss:  0.00583118200302124
Valid Loss:  0.011286687105894089
Epoch:  406  	Training Loss: 0.01982191577553749
Test Loss:  0.005838057026267052
Valid Loss:  0.011283865198493004
Epoch:  407  	Training Loss: 0.01981997862458229
Test Loss:  0.005831170827150345
Valid Loss:  0.011284274980425835
Epoch:  408  	Training Loss: 0.019818291068077087
Test Loss:  0.005837167613208294
Valid Loss:  0.011281749233603477
Epoch:  409  	Training Loss: 0.01981644704937935
Test Loss:  0.005829076282680035
Valid Loss:  0.011282449588179588
Epoch:  410  	Training Loss: 0.01981484144926071
Test Loss:  0.005835856776684523
Valid Loss:  0.011279648169875145
Epoch:  411  	Training Loss: 0.019812889397144318
Test Loss:  0.005830948241055012
Valid Loss:  0.011279614642262459
Epoch:  412  	Training Loss: 0.019811080768704414
Test Loss:  0.0058353375643491745
Valid Loss:  0.011277632787823677
Epoch:  413  	Training Loss: 0.01980944350361824
Test Loss:  0.005826802924275398
Valid Loss:  0.011278444901108742
Epoch:  414  	Training Loss: 0.019807834178209305
Test Loss:  0.0058336034417152405
Valid Loss:  0.01127565000206232
Epoch:  415  	Training Loss: 0.0198059119284153
Test Loss:  0.0058267079293727875
Valid Loss:  0.011276083067059517
Epoch:  416  	Training Loss: 0.01980430632829666
Test Loss:  0.005832723341882229
Valid Loss:  0.011273559182882309
Epoch:  417  	Training Loss: 0.01980246603488922
Test Loss:  0.005827739834785461
Valid Loss:  0.011273553594946861
Epoch:  418  	Training Loss: 0.019800692796707153
Test Loss:  0.00583202950656414
Valid Loss:  0.011271588504314423
Epoch:  419  	Training Loss: 0.01979903317987919
Test Loss:  0.005823490675538778
Valid Loss:  0.011272395960986614
Epoch:  420  	Training Loss: 0.019797449931502342
Test Loss:  0.005830278620123863
Valid Loss:  0.011269583366811275
Epoch:  421  	Training Loss: 0.019795503467321396
Test Loss:  0.005823464598506689
Valid Loss:  0.011269990354776382
Epoch:  422  	Training Loss: 0.01979392021894455
Test Loss:  0.005829419009387493
Valid Loss:  0.011267468333244324
 85%|████████▍ | 424/500 [04:55<01:04,  1.19it/s] 85%|████████▌ | 426/500 [04:55<00:45,  1.64it/s] 86%|████████▌ | 428/500 [04:55<00:32,  2.24it/s] 86%|████████▌ | 430/500 [04:55<00:23,  3.01it/s] 86%|████████▋ | 432/500 [05:02<01:20,  1.19s/it] 87%|████████▋ | 434/500 [05:02<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:02<00:39,  1.60it/s] 88%|████████▊ | 438/500 [05:02<00:28,  2.16it/s] 88%|████████▊ | 440/500 [05:02<00:20,  2.86it/s] 88%|████████▊ | 442/500 [05:09<01:09,  1.20s/it] 89%|████████▉ | 444/500 [05:09<00:48,  1.16it/s] 89%|████████▉ | 446/500 [05:09<00:33,  1.60it/s] 90%|████████▉ | 448/500 [05:09<00:23,  2.18it/s] 90%|█████████ | 450/500 [05:09<00:16,  2.94it/s] 90%|█████████ | 452/500 [05:15<00:56,  1.19s/it] 91%|█████████ | 454/500 [05:16<00:39,  1.18it/s] 91%|█████████ | 456/500 [05:16<00:27,  1.63it/s] 92%|█████████▏| 458/500 [05:16<00:18,  2.22it/s] 92%|█████████▏| 460/500 [05:16<00:13,  2.99it/s] 92%|█████████▏| 462/500 [05:22<00:44,  1.17s/it] 93%|█████████▎| 464/500 [05:22<00:30,  1.19it/s] 93%|█████████▎| 466/500 [05:22<00:20,  1.65it/s] 94%|█████████▎| 468/500 [05:23<00:14,  2.25it/s] 94%|█████████▍| 470/500 [05:23<00:09,  3.03it/s] 94%|█████████▍| 472/500 [05:29<00:33,  1.19s/it] 95%|█████████▍| 474/500 [05:29<00:22,  1.17it/s] 95%|█████████▌| 476/500 [05:29<00:14,  1.62it/s] 96%|█████████▌| 478/500 [05:30<00:09,  2.22it/s] 96%|█████████▌| 480/500 [05:30<00:06,  2.99it/s] 96%|█████████▋| 482/500 [05:36<00:21,  1.19s/it] 97%|█████████▋| 484/500 [05:36<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:36<00:08,  1.62it/s] 98%|█████████▊| 488/500 [05:36<00:05,  2.22it/s] 98%|█████████▊| 490/500 [05:37<00:03,  2.98it/s] 98%|█████████▊| 492/500 [05:43<00:09,  1.18s/it]Epoch:  423  	Training Loss: 0.019792066887021065
Test Loss:  0.005824341904371977
Valid Loss:  0.01126747764647007
Epoch:  424  	Training Loss: 0.01979031227529049
Test Loss:  0.0058287037536501884
Valid Loss:  0.011265469714999199
Epoch:  425  	Training Loss: 0.01978861168026924
Test Loss:  0.005821270868182182
Valid Loss:  0.011265987530350685
Epoch:  426  	Training Loss: 0.019786953926086426
Test Loss:  0.0058271815069019794
Valid Loss:  0.011263465508818626
Epoch:  427  	Training Loss: 0.019785095006227493
Test Loss:  0.005822187755256891
Valid Loss:  0.011263450607657433
Epoch:  428  	Training Loss: 0.019783345982432365
Test Loss:  0.005826475098729134
Valid Loss:  0.01126144826412201
Epoch:  429  	Training Loss: 0.01978164166212082
Test Loss:  0.0058190347626805305
Valid Loss:  0.011261970736086369
Epoch:  430  	Training Loss: 0.0197799950838089
Test Loss:  0.0058249435387551785
Valid Loss:  0.011259432882070541
Epoch:  431  	Training Loss: 0.01977813057601452
Test Loss:  0.005819953512400389
Valid Loss:  0.011259411461651325
Epoch:  432  	Training Loss: 0.019776392728090286
Test Loss:  0.005824251100420952
Valid Loss:  0.011257411912083626
Epoch:  433  	Training Loss: 0.019774693995714188
Test Loss:  0.005816915072500706
Valid Loss:  0.011257941834628582
Epoch:  434  	Training Loss: 0.01977311447262764
Test Loss:  0.005822769366204739
Valid Loss:  0.011255431920289993
Epoch:  435  	Training Loss: 0.0197712704539299
Test Loss:  0.005817693192511797
Valid Loss:  0.011255448684096336
Epoch:  436  	Training Loss: 0.019769590348005295
Test Loss:  0.005822060629725456
Valid Loss:  0.01125341933220625
Epoch:  437  	Training Loss: 0.019767867401242256
Test Loss:  0.005814743228256702
Valid Loss:  0.011253940872848034
Epoch:  438  	Training Loss: 0.01976630836725235
Test Loss:  0.005820601247251034
Valid Loss:  0.0112514179199934
Epoch:  439  	Training Loss: 0.019764453172683716
Test Loss:  0.005815531592816114
Valid Loss:  0.011251436546444893
Epoch:  440  	Training Loss: 0.019762791693210602
Test Loss:  0.00581990135833621
Valid Loss:  0.011249392293393612
Epoch:  441  	Training Loss: 0.019761046394705772
Test Loss:  0.005812589079141617
Valid Loss:  0.01124991662800312
Epoch:  442  	Training Loss: 0.019759517163038254
Test Loss:  0.005818434525281191
Valid Loss:  0.011247348040342331
Epoch:  443  	Training Loss: 0.01975759118795395
Test Loss:  0.005813358351588249
Valid Loss:  0.011247343383729458
Epoch:  444  	Training Loss: 0.01975591480731964
Test Loss:  0.005817713215947151
Valid Loss:  0.011245260015130043
Epoch:  445  	Training Loss: 0.019754091277718544
Test Loss:  0.005813539959490299
Valid Loss:  0.01124507375061512
Epoch:  446  	Training Loss: 0.019752364605665207
Test Loss:  0.0058168391697108746
Valid Loss:  0.01124330423772335
Epoch:  447  	Training Loss: 0.019750632345676422
Test Loss:  0.005809293128550053
Valid Loss:  0.011243848130106926
Epoch:  448  	Training Loss: 0.01974906213581562
Test Loss:  0.005815095268189907
Valid Loss:  0.01124127022922039
Epoch:  449  	Training Loss: 0.01974712498486042
Test Loss:  0.005810012575238943
Valid Loss:  0.01124125998467207
Epoch:  450  	Training Loss: 0.019745469093322754
Test Loss:  0.005814370699226856
Valid Loss:  0.01123916357755661
Epoch:  451  	Training Loss: 0.019743630662560463
Test Loss:  0.005810201168060303
Valid Loss:  0.011238966137170792
Epoch:  452  	Training Loss: 0.019741922616958618
Test Loss:  0.005813507363200188
Valid Loss:  0.011237191036343575
Epoch:  453  	Training Loss: 0.01974017545580864
Test Loss:  0.005809111520648003
Valid Loss:  0.011237027123570442
Epoch:  454  	Training Loss: 0.01973843201994896
Test Loss:  0.00581237580627203
Valid Loss:  0.011235259473323822
Epoch:  455  	Training Loss: 0.019736694172024727
Test Loss:  0.005804823711514473
Valid Loss:  0.011235777288675308
Epoch:  456  	Training Loss: 0.019735123962163925
Test Loss:  0.005810628645122051
Valid Loss:  0.01123318262398243
Epoch:  457  	Training Loss: 0.019733192399144173
Test Loss:  0.005808791145682335
Valid Loss:  0.011232515797019005
Epoch:  458  	Training Loss: 0.019731462001800537
Test Loss:  0.005807211622595787
Valid Loss:  0.011231724172830582
Epoch:  459  	Training Loss: 0.019729698076844215
Test Loss:  0.005809773225337267
Valid Loss:  0.011230146512389183
Epoch:  460  	Training Loss: 0.019727982580661774
Test Loss:  0.005805227905511856
Valid Loss:  0.011230004951357841
Epoch:  461  	Training Loss: 0.01972624473273754
Test Loss:  0.005808462388813496
Valid Loss:  0.011228218674659729
Epoch:  462  	Training Loss: 0.019724495708942413
Test Loss:  0.0058040679432451725
Valid Loss:  0.01122807152569294
Epoch:  463  	Training Loss: 0.01972281001508236
Test Loss:  0.005807339213788509
Valid Loss:  0.011226275935769081
Epoch:  464  	Training Loss: 0.01972106285393238
Test Loss:  0.005802960135042667
Valid Loss:  0.011226124130189419
Epoch:  465  	Training Loss: 0.019719380885362625
Test Loss:  0.0058062332682311535
Valid Loss:  0.011224310845136642
Epoch:  466  	Training Loss: 0.019717633724212646
Test Loss:  0.005801857449114323
Valid Loss:  0.011224156245589256
Epoch:  467  	Training Loss: 0.01971595548093319
Test Loss:  0.005805129650980234
Valid Loss:  0.011222345754504204
Epoch:  468  	Training Loss: 0.01971420645713806
Test Loss:  0.005800756625831127
Valid Loss:  0.011222179979085922
Epoch:  469  	Training Loss: 0.019712531939148903
Test Loss:  0.005804033018648624
Valid Loss:  0.011220360174775124
Epoch:  470  	Training Loss: 0.019710779190063477
Test Loss:  0.005799661390483379
Valid Loss:  0.011220192536711693
Epoch:  471  	Training Loss: 0.019709110260009766
Test Loss:  0.005802935920655727
Valid Loss:  0.011218365281820297
Epoch:  472  	Training Loss: 0.01970735192298889
Test Loss:  0.005799710750579834
Valid Loss:  0.011217947117984295
Epoch:  473  	Training Loss: 0.01970561221241951
Test Loss:  0.005800853483378887
Valid Loss:  0.011216571554541588
Epoch:  474  	Training Loss: 0.019703850150108337
Test Loss:  0.005798492580652237
Valid Loss:  0.011215943843126297
Epoch:  475  	Training Loss: 0.019702136516571045
Test Loss:  0.005799636244773865
Valid Loss:  0.011214558966457844
Epoch:  476  	Training Loss: 0.019700370728969574
Test Loss:  0.005797364749014378
Valid Loss:  0.011213894933462143
Epoch:  477  	Training Loss: 0.01969866082072258
Test Loss:  0.005798527970910072
Valid Loss:  0.011212506331503391
Epoch:  478  	Training Loss: 0.01969689130783081
Test Loss:  0.005796276032924652
Valid Loss:  0.011211838573217392
Epoch:  479  	Training Loss: 0.019695192575454712
Test Loss:  0.005797422491014004
Valid Loss:  0.011210446245968342
Epoch:  480  	Training Loss: 0.019693421199917793
Test Loss:  0.005795177072286606
Valid Loss:  0.01120978593826294
Epoch:  481  	Training Loss: 0.019691720604896545
Test Loss:  0.005796325393021107
Valid Loss:  0.011208387091755867
Epoch:  482  	Training Loss: 0.019689952954649925
Test Loss:  0.0057973964139819145
Valid Loss:  0.011207135394215584
Epoch:  483  	Training Loss: 0.019688252359628677
Test Loss:  0.0057937148958444595
Valid Loss:  0.011206798255443573
Epoch:  484  	Training Loss: 0.019686497747898102
Test Loss:  0.005794768687337637
Valid Loss:  0.011205421760678291
Epoch:  485  	Training Loss: 0.019684720784425735
Test Loss:  0.005792406853288412
Valid Loss:  0.011204767972230911
Epoch:  486  	Training Loss: 0.01968301646411419
Test Loss:  0.0057947211898863316
Valid Loss:  0.011203156784176826
Epoch:  487  	Training Loss: 0.01968126744031906
Test Loss:  0.005792455282062292
Valid Loss:  0.011202536523342133
Epoch:  488  	Training Loss: 0.019679516553878784
Test Loss:  0.005790600553154945
Valid Loss:  0.011201740242540836
Epoch:  489  	Training Loss: 0.019677789881825447
Test Loss:  0.005793038755655289
Valid Loss:  0.011200090870261192
Epoch:  490  	Training Loss: 0.019676022231578827
Test Loss:  0.00578982662409544
Valid Loss:  0.01119963824748993
Epoch:  491  	Training Loss: 0.01967429555952549
Test Loss:  0.005791994743049145
Valid Loss:  0.011198049411177635
Epoch:  492  	Training Loss: 0.01967254839837551
Test Loss:  0.005789684597402811
Valid Loss:  0.011197425425052643
 99%|█████████▉| 494/500 [05:43<00:05,  1.19it/s] 99%|█████████▉| 496/500 [05:43<00:02,  1.64it/s]100%|█████████▉| 498/500 [05:43<00:00,  2.23it/s]100%|██████████| 500/500 [05:43<00:00,  2.98it/s]100%|██████████| 500/500 [05:43<00:00,  1.45it/s]
Epoch:  493  	Training Loss: 0.01967078447341919
Test Loss:  0.005787836387753487
Valid Loss:  0.011196626350283623
Epoch:  494  	Training Loss: 0.01966906525194645
Test Loss:  0.005790248513221741
Valid Loss:  0.011194951832294464
Epoch:  495  	Training Loss: 0.01966727152466774
Test Loss:  0.0057870494201779366
Valid Loss:  0.011194489896297455
Epoch:  496  	Training Loss: 0.019665559753775597
Test Loss:  0.0057892147451639175
Valid Loss:  0.011192885227501392
Epoch:  497  	Training Loss: 0.019663792103528976
Test Loss:  0.005786909721791744
Valid Loss:  0.011192255653440952
Epoch:  498  	Training Loss: 0.019662033766508102
Test Loss:  0.005788372363895178
Valid Loss:  0.011190847493708134
Epoch:  499  	Training Loss: 0.01966032013297081
Test Loss:  0.0057847872376441956
Valid Loss:  0.011190471239387989
Epoch:  500  	Training Loss: 0.019658556208014488
Test Loss:  0.005787055008113384
Valid Loss:  0.01118883490562439
seed is  9
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:46,  6.35s/it]  1%|          | 3/500 [00:06<14:01,  1.69s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:50,  2.87it/s]  2%|▏         | 11/500 [00:13<10:55,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:26<17:14,  2.16s/it]  5%|▍         | 23/500 [00:26<12:04,  1.52s/it]  5%|▌         | 25/500 [00:32<16:10,  2.04s/it]  5%|▌         | 27/500 [00:33<11:23,  1.45s/it]  6%|▌         | 29/500 [00:33<08:04,  1.03s/it]  6%|▌         | 31/500 [00:45<20:17,  2.60s/it]  7%|▋         | 33/500 [00:45<14:16,  1.83s/it]  7%|▋         | 35/500 [00:52<17:23,  2.24s/it]  7%|▋         | 37/500 [00:52<12:16,  1.59s/it]  8%|▊         | 39/500 [00:52<08:41,  1.13s/it]  8%|▊         | 41/500 [01:04<20:27,  2.67s/it]  9%|▊         | 43/500 [01:05<14:24,  1.89s/it]  9%|▉         | 45/500 [01:11<17:07,  2.26s/it]  9%|▉         | 47/500 [01:11<12:04,  1.60s/it] 10%|▉         | 49/500 [01:11<08:33,  1.14s/it] 10%|█         | 51/500 [01:24<20:17,  2.71s/it] 11%|█         | 53/500 [01:24<14:17,  1.92s/it] 11%|█         | 55/500 [01:30<17:10,  2.32s/it] 11%|█▏        | 57/500 [01:31<12:07,  1.64s/it] 12%|█▏        | 59/500 [01:31<08:35,  1.17s/it] 12%|█▏        | 61/500 [01:43<19:42,  2.69s/it] 13%|█▎        | 63/500 [01:43<13:52,  1.90s/it]Epoch:  1  	Training Loss: 0.07082174718379974
Test Loss:  4.690181732177734
Valid Loss:  4.594934463500977
Epoch:  2  	Training Loss: 4.6454267501831055
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  3  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  4  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  5  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  6  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  7  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  8  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  9  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  10  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  11  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  12  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  13  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  14  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  15  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  16  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  17  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  18  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  19  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  20  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  22  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  23  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  24  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  25  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  27  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  28  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  29  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  30  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  32  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  33  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  34  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  35  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  37  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  38  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  39  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  40  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  42  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  43  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  44  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  45  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  47  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  48  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  49  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  50  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  52  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  53  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  54  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  55  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  57  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  58  	Training Loss: 0.0758219063282013
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  59  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.10288466513156891
Epoch:  60  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  62  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  63  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  64  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
 13%|█▎        | 65/500 [01:50<16:42,  2.30s/it] 13%|█▎        | 67/500 [01:50<11:47,  1.63s/it] 14%|█▍        | 69/500 [01:50<08:21,  1.16s/it] 14%|█▍        | 71/500 [02:03<19:30,  2.73s/it] 15%|█▍        | 73/500 [02:03<13:46,  1.94s/it] 15%|█▌        | 75/500 [02:10<16:32,  2.33s/it] 15%|█▌        | 77/500 [02:10<11:42,  1.66s/it] 16%|█▌        | 79/500 [02:10<08:20,  1.19s/it] 16%|█▌        | 80/500 [02:16<14:53,  2.13s/it] 16%|█▌        | 81/500 [02:23<20:51,  2.99s/it] 17%|█▋        | 83/500 [02:23<13:21,  1.92s/it] 17%|█▋        | 85/500 [02:29<16:12,  2.34s/it] 17%|█▋        | 87/500 [02:29<11:00,  1.60s/it] 18%|█▊        | 89/500 [02:30<07:36,  1.11s/it] 18%|█▊        | 90/500 [02:36<14:05,  2.06s/it] 18%|█▊        | 91/500 [02:42<20:13,  2.97s/it] 19%|█▊        | 93/500 [02:42<12:45,  1.88s/it] 19%|█▉        | 95/500 [02:49<15:43,  2.33s/it] 19%|█▉        | 97/500 [02:49<10:36,  1.58s/it] 20%|█▉        | 99/500 [02:49<07:20,  1.10s/it] 20%|██        | 100/500 [02:55<13:52,  2.08s/it] 20%|██        | 101/500 [03:02<19:47,  2.98s/it] 21%|██        | 103/500 [03:02<12:29,  1.89s/it] 21%|██        | 105/500 [03:08<15:23,  2.34s/it] 21%|██▏       | 107/500 [03:08<10:22,  1.58s/it] 22%|██▏       | 109/500 [03:08<07:07,  1.09s/it] 22%|██▏       | 111/500 [03:21<17:45,  2.74s/it] 23%|██▎       | 113/500 [03:21<12:19,  1.91s/it] 23%|██▎       | 115/500 [03:28<14:48,  2.31s/it] 23%|██▎       | 117/500 [03:28<10:22,  1.62s/it] 24%|██▍       | 119/500 [03:28<07:18,  1.15s/it] 24%|██▍       | 121/500 [03:40<17:07,  2.71s/it] 25%|██▍       | 123/500 [03:41<12:01,  1.91s/it]Epoch:  65  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  67  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  68  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  69  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  70  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  72  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  73  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  74  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  75  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  77  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  78  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  79  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  80  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  82  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  83  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  84  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  85  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  87  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  88  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  89  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  90  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  92  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  93  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  94  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  95  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  97  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  98  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  99  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  100  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  102  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  103  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  104  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  105  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  107  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  108  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  109  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  110  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  112  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  113  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  114  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  115  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  117  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  118  	Training Loss: 0.0758219063282013
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  119  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  120  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  122  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  123  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  124  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  125  	Training Loss: 0.0758218988776207
Test Loss:  25%|██▌       | 125/500 [03:47<14:13,  2.28s/it] 25%|██▌       | 127/500 [03:47<10:01,  1.61s/it] 26%|██▌       | 129/500 [03:47<07:05,  1.15s/it] 26%|██▌       | 129/500 [03:58<07:05,  1.15s/it] 26%|██▌       | 131/500 [04:00<16:37,  2.70s/it] 27%|██▋       | 133/500 [04:00<11:41,  1.91s/it] 27%|██▋       | 135/500 [04:06<13:50,  2.27s/it] 27%|██▋       | 137/500 [04:06<09:45,  1.61s/it] 28%|██▊       | 139/500 [04:06<06:54,  1.15s/it] 28%|██▊       | 139/500 [04:18<06:54,  1.15s/it] 28%|██▊       | 141/500 [04:19<16:05,  2.69s/it] 29%|██▊       | 143/500 [04:19<11:19,  1.90s/it] 29%|██▉       | 145/500 [04:25<13:30,  2.28s/it] 29%|██▉       | 147/500 [04:26<09:31,  1.62s/it] 30%|██▉       | 149/500 [04:26<06:44,  1.15s/it] 30%|██▉       | 149/500 [04:38<06:44,  1.15s/it] 30%|███       | 151/500 [04:38<15:31,  2.67s/it] 31%|███       | 153/500 [04:38<10:54,  1.89s/it] 31%|███       | 155/500 [04:45<13:03,  2.27s/it] 31%|███▏      | 157/500 [04:45<09:12,  1.61s/it] 32%|███▏      | 159/500 [04:45<06:30,  1.15s/it] 32%|███▏      | 161/500 [04:57<15:07,  2.68s/it] 33%|███▎      | 163/500 [04:58<10:38,  1.89s/it] 33%|███▎      | 165/500 [05:04<12:45,  2.28s/it] 33%|███▎      | 167/500 [05:04<08:58,  1.62s/it] 34%|███▍      | 169/500 [05:04<06:21,  1.15s/it] 34%|███▍      | 171/500 [05:17<14:36,  2.66s/it] 35%|███▍      | 173/500 [05:17<10:16,  1.89s/it] 35%|███▌      | 175/500 [05:23<12:15,  2.26s/it] 35%|███▌      | 177/500 [05:23<08:38,  1.60s/it] 36%|███▌      | 179/500 [05:23<06:06,  1.14s/it] 36%|███▌      | 181/500 [05:36<14:16,  2.69s/it] 37%|███▋      | 183/500 [05:36<10:02,  1.90s/it] 0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  127  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  128  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  129  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  130  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  132  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  133  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  134  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  135  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  137  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  138  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  139  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  140  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  142  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  143  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  144  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  145  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  147  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  148  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  149  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  150  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  152  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  153  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  154  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  155  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  157  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  158  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  159  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  160  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  162  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  163  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  164  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  165  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  167  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  168  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  169  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  170  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  172  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  173  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  174  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  175  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  177  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  178  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  179  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  180  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  182  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  183  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  184  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  185  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
 37%|███▋      | 185/500 [05:42<12:00,  2.29s/it] 37%|███▋      | 187/500 [05:42<08:27,  1.62s/it] 38%|███▊      | 189/500 [05:43<05:59,  1.16s/it] 38%|███▊      | 191/500 [05:55<13:51,  2.69s/it] 39%|███▊      | 193/500 [05:55<09:44,  1.90s/it] 39%|███▉      | 195/500 [06:02<11:35,  2.28s/it] 39%|███▉      | 197/500 [06:02<08:10,  1.62s/it] 40%|███▉      | 199/500 [06:02<05:46,  1.15s/it] 40%|████      | 201/500 [06:14<13:22,  2.68s/it] 41%|████      | 203/500 [06:15<09:24,  1.90s/it] 41%|████      | 205/500 [06:21<11:18,  2.30s/it] 41%|████▏     | 207/500 [06:21<07:58,  1.63s/it] 42%|████▏     | 209/500 [06:21<05:38,  1.16s/it] 42%|████▏     | 211/500 [06:34<12:59,  2.70s/it] 43%|████▎     | 213/500 [06:34<09:08,  1.91s/it] 43%|████▎     | 215/500 [06:40<10:50,  2.28s/it] 43%|████▎     | 217/500 [06:40<07:37,  1.62s/it] 44%|████▍     | 219/500 [06:41<05:23,  1.15s/it] 44%|████▍     | 221/500 [06:53<12:39,  2.72s/it] 45%|████▍     | 223/500 [06:53<08:53,  1.93s/it] 45%|████▌     | 225/500 [07:00<10:34,  2.31s/it] 45%|████▌     | 227/500 [07:00<07:26,  1.64s/it] 46%|████▌     | 229/500 [07:00<05:15,  1.17s/it] 46%|████▌     | 231/500 [07:06<07:52,  1.75s/it] 47%|████▋     | 233/500 [07:07<05:33,  1.25s/it] 47%|████▋     | 235/500 [07:13<08:07,  1.84s/it] 47%|████▋     | 237/500 [07:13<05:44,  1.31s/it] 48%|████▊     | 239/500 [07:13<04:04,  1.07it/s] 48%|████▊     | 241/500 [07:26<10:55,  2.53s/it] 49%|████▊     | 243/500 [07:26<07:40,  1.79s/it]Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  187  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  188  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  189  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  190  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  192  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  193  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  194  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  195  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  197  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  198  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  199  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  200  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  202  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  203  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  204  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  205  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  207  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  208  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  209  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  210  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  212  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  213  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  214  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  215  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  217  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  218  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  219  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  220  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  222  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  223  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  224  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  225  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  227  	Training Loss: 0.0758219063282013
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  228  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  229  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  230  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  231  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  232  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  233  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  234  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  235  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  237  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  238  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  239  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  240  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  242  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  243  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  244  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  245  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
 49%|████▉     | 245/500 [07:32<09:18,  2.19s/it] 49%|████▉     | 247/500 [07:32<06:34,  1.56s/it] 50%|████▉     | 249/500 [07:32<04:40,  1.12s/it] 50%|█████     | 251/500 [07:45<11:04,  2.67s/it] 51%|█████     | 253/500 [07:45<07:47,  1.89s/it] 51%|█████     | 255/500 [07:52<09:20,  2.29s/it] 51%|█████▏    | 257/500 [07:52<06:34,  1.62s/it] 52%|█████▏    | 259/500 [07:52<04:38,  1.16s/it] 52%|█████▏    | 261/500 [08:05<10:48,  2.71s/it] 53%|█████▎    | 263/500 [08:05<07:36,  1.92s/it] 53%|█████▎    | 265/500 [08:11<09:02,  2.31s/it] 53%|█████▎    | 267/500 [08:11<06:22,  1.64s/it] 54%|█████▍    | 269/500 [08:11<04:30,  1.17s/it] 54%|█████▍    | 271/500 [08:24<10:16,  2.69s/it] 55%|█████▍    | 273/500 [08:24<07:12,  1.91s/it] 55%|█████▌    | 275/500 [08:30<08:34,  2.28s/it] 55%|█████▌    | 277/500 [08:31<06:01,  1.62s/it] 56%|█████▌    | 279/500 [08:31<04:15,  1.15s/it] 56%|█████▌    | 281/500 [08:44<09:58,  2.73s/it] 57%|█████▋    | 283/500 [08:44<06:59,  1.93s/it] 57%|█████▋    | 285/500 [08:50<08:21,  2.33s/it] 57%|█████▋    | 287/500 [08:50<05:52,  1.66s/it] 58%|█████▊    | 289/500 [08:50<04:08,  1.18s/it] 58%|█████▊    | 291/500 [09:03<09:29,  2.73s/it] 59%|█████▊    | 293/500 [09:03<06:39,  1.93s/it] 59%|█████▉    | 295/500 [09:10<07:51,  2.30s/it] 59%|█████▉    | 297/500 [09:10<05:31,  1.63s/it] 60%|█████▉    | 299/500 [09:10<03:54,  1.17s/it] 60%|██████    | 301/500 [09:23<08:59,  2.71s/it] 61%|██████    | 303/500 [09:23<06:18,  1.92s/it]**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  247  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  248  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  249  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  250  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  252  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  253  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  254  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  255  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  257  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  258  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  259  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  260  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  262  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  263  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  264  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  265  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  267  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  268  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  269  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  270  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  272  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  273  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  274  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  275  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  277  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  278  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  279  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  280  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  282  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  283  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  284  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  285  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  287  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  288  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  289  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  290  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  292  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  293  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  294  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  295  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  297  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  298  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  299  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  300  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  302  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  303  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  304  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  305  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
 61%|██████    | 305/500 [09:29<07:27,  2.30s/it] 61%|██████▏   | 307/500 [09:29<05:14,  1.63s/it] 62%|██████▏   | 309/500 [09:29<03:41,  1.16s/it] 62%|██████▏   | 311/500 [09:42<08:29,  2.69s/it] 63%|██████▎   | 313/500 [09:42<05:56,  1.91s/it] 63%|██████▎   | 315/500 [09:49<07:06,  2.31s/it] 63%|██████▎   | 317/500 [09:49<04:59,  1.63s/it] 64%|██████▍   | 319/500 [09:49<03:30,  1.16s/it] 64%|██████▍   | 321/500 [10:01<08:05,  2.71s/it] 65%|██████▍   | 323/500 [10:02<05:40,  1.92s/it] 65%|██████▌   | 325/500 [10:08<06:40,  2.29s/it] 65%|██████▌   | 327/500 [10:08<04:40,  1.62s/it] 66%|██████▌   | 329/500 [10:08<03:17,  1.15s/it] 66%|██████▌   | 331/500 [10:21<07:37,  2.70s/it] 67%|██████▋   | 333/500 [10:21<05:19,  1.91s/it] 67%|██████▋   | 335/500 [10:27<06:19,  2.30s/it] 67%|██████▋   | 337/500 [10:27<04:25,  1.63s/it] 68%|██████▊   | 339/500 [10:28<03:06,  1.16s/it] 68%|██████▊   | 339/500 [10:38<03:06,  1.16s/it] 68%|██████▊   | 341/500 [10:40<07:08,  2.70s/it] 69%|██████▊   | 343/500 [10:40<04:59,  1.91s/it] 69%|██████▉   | 345/500 [10:47<05:53,  2.28s/it] 69%|██████▉   | 347/500 [10:47<04:07,  1.62s/it] 70%|██████▉   | 349/500 [10:47<02:53,  1.15s/it] 70%|██████▉   | 349/500 [10:58<02:53,  1.15s/it] 70%|███████   | 351/500 [10:59<06:40,  2.69s/it] 71%|███████   | 353/500 [11:00<04:39,  1.90s/it] 71%|███████   | 355/500 [11:06<05:31,  2.29s/it] 71%|███████▏  | 357/500 [11:06<03:51,  1.62s/it] 72%|███████▏  | 359/500 [11:06<02:42,  1.16s/it] 72%|███████▏  | 359/500 [11:18<02:42,  1.16s/it] 72%|███████▏  | 361/500 [11:19<06:16,  2.71s/it] 73%|███████▎  | 363/500 [11:19<04:22,  1.92s/it] 73%|███████▎  | 365/500 [11:19<03:04,  1.36s/it]**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  307  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  308  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  309  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  310  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  312  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  313  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  314  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.10288466513156891
Epoch:  315  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  317  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  318  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  319  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  320  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  322  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  323  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  324  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  325  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  327  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  328  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  329  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  330  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  332  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  333  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  334  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  335  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  337  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  338  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  339  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  340  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  342  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  343  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  344  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  345  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  347  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  348  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  349  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  350  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  352  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  353  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  354  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  355  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  357  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  358  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  359  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  360  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  362  	Training Loss: 0.0758219063282013
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  363  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  364  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  365  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
 73%|███████▎  | 367/500 [11:19<02:09,  1.03it/s] 74%|███████▍  | 369/500 [11:19<01:31,  1.42it/s] 74%|███████▍  | 371/500 [11:32<05:05,  2.37s/it] 75%|███████▍  | 373/500 [11:32<03:32,  1.68s/it] 75%|███████▌  | 375/500 [11:38<04:22,  2.10s/it] 75%|███████▌  | 377/500 [11:38<03:03,  1.49s/it] 76%|███████▌  | 379/500 [11:38<02:08,  1.07s/it] 76%|███████▌  | 381/500 [11:51<05:14,  2.65s/it] 77%|███████▋  | 383/500 [11:51<03:39,  1.87s/it] 77%|███████▋  | 385/500 [11:58<04:18,  2.25s/it] 77%|███████▋  | 387/500 [11:58<03:00,  1.59s/it] 78%|███████▊  | 389/500 [11:58<02:06,  1.14s/it] 78%|███████▊  | 391/500 [12:10<04:53,  2.69s/it] 79%|███████▊  | 393/500 [12:11<03:23,  1.90s/it] 79%|███████▉  | 395/500 [12:17<04:00,  2.29s/it] 79%|███████▉  | 397/500 [12:17<02:47,  1.62s/it] 80%|███████▉  | 399/500 [12:17<01:56,  1.15s/it] 80%|███████▉  | 399/500 [12:28<01:56,  1.15s/it] 80%|████████  | 401/500 [12:30<04:25,  2.68s/it] 81%|████████  | 403/500 [12:30<03:03,  1.90s/it] 81%|████████  | 405/500 [12:36<03:36,  2.28s/it] 81%|████████▏ | 407/500 [12:36<02:30,  1.62s/it] 82%|████████▏ | 409/500 [12:36<01:44,  1.15s/it] 82%|████████▏ | 409/500 [12:48<01:44,  1.15s/it] 82%|████████▏ | 411/500 [12:49<04:00,  2.70s/it] 83%|████████▎ | 413/500 [12:49<02:46,  1.91s/it] 83%|████████▎ | 415/500 [12:56<03:14,  2.29s/it] 83%|████████▎ | 417/500 [12:56<02:15,  1.63s/it] 84%|████████▍ | 419/500 [12:56<01:34,  1.16s/it] 84%|████████▍ | 419/500 [13:08<01:34,  1.16s/it] 84%|████████▍ | 421/500 [13:09<03:34,  2.72s/it] 85%|████████▍ | 423/500 [13:09<02:27,  1.92s/it] 85%|████████▌ | 425/500 [13:15<02:53,  2.31s/it]Epoch:  366  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  367  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  368  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  369  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  370  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  372  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  373  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  374  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  375  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  377  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  378  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  379  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  380  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  382  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  383  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  384  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  385  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  387  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  388  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  389  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  390  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  392  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  393  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  394  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  395  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  397  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  398  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  399  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  400  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  402  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  403  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  404  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  405  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  407  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  408  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  409  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  410  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  412  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  413  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  414  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  415  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  417  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  418  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  419  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  420  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  422  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  423  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  424  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  425  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
 85%|████████▌ | 427/500 [13:15<01:59,  1.64s/it] 86%|████████▌ | 429/500 [13:15<01:22,  1.17s/it] 86%|████████▌ | 429/500 [13:28<01:22,  1.17s/it] 86%|████████▌ | 431/500 [13:28<03:06,  2.70s/it] 87%|████████▋ | 433/500 [13:28<02:08,  1.91s/it] 87%|████████▋ | 435/500 [13:34<02:28,  2.28s/it] 87%|████████▋ | 437/500 [13:35<01:41,  1.62s/it] 88%|████████▊ | 439/500 [13:35<01:10,  1.15s/it] 88%|████████▊ | 441/500 [13:47<02:38,  2.68s/it] 89%|████████▊ | 443/500 [13:47<01:48,  1.90s/it] 89%|████████▉ | 445/500 [13:54<02:05,  2.29s/it] 89%|████████▉ | 447/500 [13:54<01:25,  1.62s/it] 90%|████████▉ | 449/500 [13:54<00:58,  1.15s/it] 90%|█████████ | 451/500 [14:06<02:11,  2.68s/it] 91%|█████████ | 453/500 [14:07<01:29,  1.90s/it] 91%|█████████ | 455/500 [14:13<01:43,  2.29s/it] 91%|█████████▏| 457/500 [14:13<01:10,  1.63s/it] 92%|█████████▏| 459/500 [14:13<00:47,  1.17s/it] 92%|█████████▏| 461/500 [14:26<01:48,  2.78s/it] 93%|█████████▎| 463/500 [14:27<01:12,  1.97s/it] 93%|█████████▎| 465/500 [14:33<01:21,  2.34s/it] 93%|█████████▎| 467/500 [14:33<00:54,  1.66s/it] 94%|█████████▍| 469/500 [14:33<00:36,  1.18s/it] 94%|█████████▍| 471/500 [14:46<01:19,  2.74s/it] 95%|█████████▍| 473/500 [14:46<00:52,  1.94s/it] 95%|█████████▌| 475/500 [14:53<00:58,  2.32s/it] 95%|█████████▌| 477/500 [14:53<00:37,  1.65s/it] 96%|█████████▌| 479/500 [14:53<00:24,  1.17s/it] 96%|█████████▌| 481/500 [15:05<00:50,  2.68s/it] 97%|█████████▋| 483/500 [15:05<00:32,  1.90s/it] 97%|█████████▋| 485/500 [15:12<00:34,  2.28s/it]Epoch:  426  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  427  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  428  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  429  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  430  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  432  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  433  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  434  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  435  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  437  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  438  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  439  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  440  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  442  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  443  	Training Loss: 0.0758219063282013
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  444  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  445  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  447  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  448  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  449  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  450  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  452  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  453  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  454  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  455  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.10288466513156891
Epoch:  457  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  458  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  459  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  460  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  462  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  463  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  464  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.10288466513156891
Epoch:  465  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  467  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  468  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  469  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  470  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  472  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  473  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  474  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  475  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  477  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  478  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  479  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846725821495
Epoch:  480  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  482  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  483  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  484  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  485  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
 97%|█████████▋| 487/500 [15:12<00:21,  1.62s/it] 98%|█████████▊| 489/500 [15:12<00:12,  1.15s/it] 98%|█████████▊| 491/500 [15:18<00:15,  1.77s/it] 99%|█████████▊| 493/500 [15:19<00:08,  1.26s/it] 99%|█████████▉| 495/500 [15:25<00:09,  1.83s/it] 99%|█████████▉| 497/500 [15:25<00:03,  1.30s/it]100%|█████████▉| 499/500 [15:25<00:00,  1.07it/s]100%|██████████| 500/500 [15:31<00:00,  1.86s/it]
Epoch:  486  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  487  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  488  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  489  	Training Loss: 0.0758218988776207
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  490  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  491  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  492  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  493  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  494  	Training Loss: 0.0758218914270401
Test Loss:  0.10421233624219894
Valid Loss:  0.1028846800327301
Epoch:  495  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  497  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  498  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846800327301
Epoch:  499  	Training Loss: 0.0758218914270401
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
Epoch:  500  	Training Loss: 0.0758218988776207
Test Loss:  0.10421234369277954
Valid Loss:  0.1028846725821495
**************************************************learning rate decay**************************************************
seed is  10
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:32,  6.32s/it]  1%|          | 3/500 [00:06<13:58,  1.69s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:59,  1.35s/it]  3%|▎         | 13/500 [00:13<07:28,  1.09it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:38,  1.21s/it]  5%|▍         | 23/500 [00:20<06:49,  1.16it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:27<09:24,  1.20s/it]  7%|▋         | 33/500 [00:27<06:41,  1.16it/s]  7%|▋         | 35/500 [00:27<04:48,  1.61it/s]  7%|▋         | 37/500 [00:27<03:30,  2.20it/s]  8%|▊         | 39/500 [00:27<02:35,  2.97it/s]  8%|▊         | 41/500 [00:33<09:05,  1.19s/it]  9%|▊         | 43/500 [00:34<06:31,  1.17it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:40<08:54,  1.19s/it] 11%|█         | 53/500 [00:40<06:21,  1.17it/s] 11%|█         | 55/500 [00:41<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:48,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:18,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:35,  1.58it/s] 13%|█▎        | 67/500 [00:48<03:22,  2.14it/s] 14%|█▍        | 69/500 [00:48<02:32,  2.82it/s] 14%|█▍        | 71/500 [00:54<08:32,  1.19s/it]Epoch:  1  	Training Loss: 0.054723095148801804
Test Loss:  0.858258843421936
Valid Loss:  0.8691974878311157
Epoch:  2  	Training Loss: 0.9227123856544495
Test Loss:  0.07386093586683273
Valid Loss:  0.07270614802837372
Epoch:  3  	Training Loss: 0.05475326627492905
Test Loss:  0.07375451922416687
Valid Loss:  0.0726083517074585
Epoch:  4  	Training Loss: 0.05468203127384186
Test Loss:  0.07364781200885773
Valid Loss:  0.07250973582267761
Epoch:  5  	Training Loss: 0.05461045727133751
Test Loss:  0.07353740930557251
Valid Loss:  0.07240651547908783
Epoch:  6  	Training Loss: 0.054536372423172
Test Loss:  0.07341109216213226
Valid Loss:  0.07229050993919373
Epoch:  7  	Training Loss: 0.054451923817396164
Test Loss:  0.0732821449637413
Valid Loss:  0.07217217981815338
Epoch:  8  	Training Loss: 0.054365769028663635
Test Loss:  0.07317807525396347
Valid Loss:  0.07209374755620956
Epoch:  9  	Training Loss: 0.054300688207149506
Test Loss:  0.07313208281993866
Valid Loss:  0.07206347584724426
Epoch:  10  	Training Loss: 0.05427147448062897
Test Loss:  0.07310282438993454
Valid Loss:  0.07203906029462814
Epoch:  11  	Training Loss: 0.0542515367269516
Test Loss:  0.07307786494493484
Valid Loss:  0.0720164030790329
Epoch:  12  	Training Loss: 0.05423485115170479
Test Loss:  0.07305335998535156
Valid Loss:  0.07199415564537048
Epoch:  13  	Training Loss: 0.0542185977101326
Test Loss:  0.07302917540073395
Valid Loss:  0.07197210192680359
Epoch:  14  	Training Loss: 0.05420254170894623
Test Loss:  0.07300521433353424
Valid Loss:  0.07195013761520386
Epoch:  15  	Training Loss: 0.05418652668595314
Test Loss:  0.07298127561807632
Valid Loss:  0.07192818820476532
Epoch:  16  	Training Loss: 0.05417051166296005
Test Loss:  0.07295733690261841
Valid Loss:  0.07190621644258499
Epoch:  17  	Training Loss: 0.05415450036525726
Test Loss:  0.0729333907365799
Valid Loss:  0.07188425213098526
Epoch:  18  	Training Loss: 0.05413848161697388
Test Loss:  0.07290942966938019
Valid Loss:  0.07186228036880493
Epoch:  19  	Training Loss: 0.054122455418109894
Test Loss:  0.07288546115159988
Valid Loss:  0.07184028625488281
Epoch:  20  	Training Loss: 0.05410642549395561
Test Loss:  0.07286150008440018
Valid Loss:  0.07181829959154129
Epoch:  21  	Training Loss: 0.05409039556980133
Test Loss:  0.07283756136894226
Valid Loss:  0.07179630547761917
Epoch:  22  	Training Loss: 0.05407436192035675
Test Loss:  0.07281386852264404
Valid Loss:  0.07177453488111496
Epoch:  23  	Training Loss: 0.05405847728252411
Test Loss:  0.07279020547866821
Valid Loss:  0.07175279408693314
Epoch:  24  	Training Loss: 0.05404260754585266
Test Loss:  0.07276657223701477
Valid Loss:  0.07173106074333191
Epoch:  25  	Training Loss: 0.054026760160923004
Test Loss:  0.07274295389652252
Valid Loss:  0.07170935720205307
Epoch:  26  	Training Loss: 0.054010920226573944
Test Loss:  0.07271936535835266
Valid Loss:  0.07168766856193542
Epoch:  27  	Training Loss: 0.053995102643966675
Test Loss:  0.07269585132598877
Valid Loss:  0.07166601717472076
Epoch:  28  	Training Loss: 0.0539793036878109
Test Loss:  0.07267233729362488
Valid Loss:  0.0716443881392479
Epoch:  29  	Training Loss: 0.053963519632816315
Test Loss:  0.07264885306358337
Valid Loss:  0.07162278145551682
Epoch:  30  	Training Loss: 0.053947750478982925
Test Loss:  0.07262535393238068
Valid Loss:  0.07160118222236633
Epoch:  31  	Training Loss: 0.05393199995160103
Test Loss:  0.07260192185640335
Valid Loss:  0.07157962024211884
Epoch:  32  	Training Loss: 0.05391626060009003
Test Loss:  0.07257874310016632
Valid Loss:  0.07155829668045044
Epoch:  33  	Training Loss: 0.05390070006251335
Test Loss:  0.07255556434392929
Valid Loss:  0.07153697311878204
Epoch:  34  	Training Loss: 0.05388513207435608
Test Loss:  0.07253235578536987
Valid Loss:  0.07151561975479126
Epoch:  35  	Training Loss: 0.05386956036090851
Test Loss:  0.07250915467739105
Valid Loss:  0.07149428129196167
Epoch:  36  	Training Loss: 0.05385398864746094
Test Loss:  0.07248592376708984
Valid Loss:  0.07147292792797089
Epoch:  37  	Training Loss: 0.05383840948343277
Test Loss:  0.07246271520853043
Valid Loss:  0.0714515745639801
Epoch:  38  	Training Loss: 0.0538228303194046
Test Loss:  0.07243946194648743
Valid Loss:  0.07143020629882812
Epoch:  39  	Training Loss: 0.05380724370479584
Test Loss:  0.0724162608385086
Valid Loss:  0.07140883803367615
Epoch:  40  	Training Loss: 0.05379165709018707
Test Loss:  0.07239299267530441
Valid Loss:  0.07138746231794357
Epoch:  41  	Training Loss: 0.05377606675028801
Test Loss:  0.0723697692155838
Valid Loss:  0.071366086602211
Epoch:  42  	Training Loss: 0.05376046895980835
Test Loss:  0.07234637439250946
Valid Loss:  0.07134456932544708
Epoch:  43  	Training Loss: 0.05374479666352272
Test Loss:  0.07232297956943512
Valid Loss:  0.07132306694984436
Epoch:  44  	Training Loss: 0.053729113191366196
Test Loss:  0.0722995400428772
Valid Loss:  0.07130151987075806
Epoch:  45  	Training Loss: 0.05371341109275818
Test Loss:  0.07227609306573868
Valid Loss:  0.07127996534109116
Epoch:  46  	Training Loss: 0.053697697818279266
Test Loss:  0.07225264608860016
Valid Loss:  0.07125839591026306
Epoch:  47  	Training Loss: 0.05368197709321976
Test Loss:  0.07222913950681686
Valid Loss:  0.07123678922653198
Epoch:  48  	Training Loss: 0.05366624891757965
Test Loss:  0.07220561802387238
Valid Loss:  0.0712151825428009
Epoch:  49  	Training Loss: 0.053650498390197754
Test Loss:  0.07218211889266968
Valid Loss:  0.07119356095790863
Epoch:  50  	Training Loss: 0.05363473296165466
Test Loss:  0.0721585601568222
Valid Loss:  0.07117190957069397
Epoch:  51  	Training Loss: 0.053618960082530975
Test Loss:  0.07213498651981354
Valid Loss:  0.07115024328231812
Epoch:  52  	Training Loss: 0.053603172302246094
Test Loss:  0.07211140543222427
Valid Loss:  0.07112856209278107
Epoch:  53  	Training Loss: 0.053587406873703
Test Loss:  0.07208780944347382
Valid Loss:  0.07110686600208282
Epoch:  54  	Training Loss: 0.05357162654399872
Test Loss:  0.07206419110298157
Valid Loss:  0.07108515501022339
Epoch:  55  	Training Loss: 0.05355582386255264
Test Loss:  0.07204052805900574
Valid Loss:  0.07106340676546097
Epoch:  56  	Training Loss: 0.053540002554655075
Test Loss:  0.07201685011386871
Valid Loss:  0.07104162871837616
Epoch:  57  	Training Loss: 0.053524166345596313
Test Loss:  0.07199312746524811
Valid Loss:  0.07101984322071075
Epoch:  58  	Training Loss: 0.053508318960666656
Test Loss:  0.07196938991546631
Valid Loss:  0.07099801301956177
Epoch:  59  	Training Loss: 0.05349244922399521
Test Loss:  0.07194562256336212
Valid Loss:  0.07097617536783218
Epoch:  60  	Training Loss: 0.05347656458616257
Test Loss:  0.07192182540893555
Valid Loss:  0.07095430046319962
Epoch:  61  	Training Loss: 0.05346066504716873
Test Loss:  0.07189800590276718
Valid Loss:  0.07093240320682526
Epoch:  62  	Training Loss: 0.05344473570585251
Test Loss:  0.07187450677156448
Valid Loss:  0.07091078162193298
Epoch:  63  	Training Loss: 0.05342899262905121
Test Loss:  0.07185100764036179
Valid Loss:  0.07088915258646011
Epoch:  64  	Training Loss: 0.05341325327754021
Test Loss:  0.07182754576206207
Valid Loss:  0.07086755335330963
Epoch:  65  	Training Loss: 0.0533975288271904
Test Loss:  0.07180409133434296
Valid Loss:  0.07084597647190094
Epoch:  66  	Training Loss: 0.05338181555271149
Test Loss:  0.07178065180778503
Valid Loss:  0.07082441449165344
Epoch:  67  	Training Loss: 0.05336611717939377
Test Loss:  0.0717572346329689
Valid Loss:  0.07080285996198654
Epoch:  68  	Training Loss: 0.053350429981946945
Test Loss:  0.07173381745815277
Valid Loss:  0.07078132033348083
Epoch:  69  	Training Loss: 0.05333474278450012
Test Loss:  0.07171044498682022
Valid Loss:  0.07075978815555573
Epoch:  70  	Training Loss: 0.05331908166408539
Test Loss:  0.07168707251548767
Valid Loss:  0.070738285779953
Epoch:  71  	Training Loss: 0.05330342799425125
Test Loss:  0.07166370749473572
Valid Loss:  0.07071678340435028
Epoch:  72  	Training Loss: 0.053287774324417114
Test Loss:  0.0716399997472763
Valid Loss:  0.07069496810436249
Epoch:  73  	Training Loss: 0.05327189341187477
Test Loss:   15%|█▍        | 73/500 [00:54<06:05,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:55<03:11,  2.21it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:01<08:12,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:02<03:05,  2.22it/s] 18%|█▊        | 89/500 [01:02<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:08<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:09<02:14,  2.99it/s] 20%|██        | 101/500 [01:15<07:55,  1.19s/it] 21%|██        | 103/500 [01:15<05:40,  1.17it/s] 21%|██        | 105/500 [01:15<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:15<03:01,  2.16it/s] 22%|██▏       | 109/500 [01:16<02:16,  2.86it/s] 22%|██▏       | 111/500 [01:22<07:48,  1.20s/it] 23%|██▎       | 113/500 [01:22<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:22<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:22<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:22<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:29<07:25,  1.17s/it] 25%|██▍       | 123/500 [01:29<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:29<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:29<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:29<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:36<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:36<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:36<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:36<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:36<01:59,  3.01it/s] 28%|██▊       | 141/500 [01:42<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:43<05:02,  1.18it/s]0.07161632925271988
Valid Loss:  0.07067316770553589
Epoch:  74  	Training Loss: 0.05325602367520332
Test Loss:  0.07159265875816345
Valid Loss:  0.07065138965845108
Epoch:  75  	Training Loss: 0.05324016511440277
Test Loss:  0.0715690404176712
Valid Loss:  0.07062964141368866
Epoch:  76  	Training Loss: 0.05322433263063431
Test Loss:  0.07154543697834015
Valid Loss:  0.07060791552066803
Epoch:  77  	Training Loss: 0.05320851504802704
Test Loss:  0.07152184844017029
Valid Loss:  0.0705862045288086
Epoch:  78  	Training Loss: 0.05319271609187126
Test Loss:  0.0714983120560646
Valid Loss:  0.07056453078985214
Epoch:  79  	Training Loss: 0.05317693203687668
Test Loss:  0.07147477567195892
Valid Loss:  0.07054286450147629
Epoch:  80  	Training Loss: 0.05316116660833359
Test Loss:  0.07145128399133682
Valid Loss:  0.07052123546600342
Epoch:  81  	Training Loss: 0.05314542353153229
Test Loss:  0.07142781466245651
Valid Loss:  0.07049962133169174
Epoch:  82  	Training Loss: 0.05312969163060188
Test Loss:  0.07140443474054337
Valid Loss:  0.07047811150550842
Epoch:  83  	Training Loss: 0.05311403423547745
Test Loss:  0.07138106226921082
Valid Loss:  0.0704566091299057
Epoch:  84  	Training Loss: 0.05309838801622391
Test Loss:  0.07135771214962006
Valid Loss:  0.07043512165546417
Epoch:  85  	Training Loss: 0.053082749247550964
Test Loss:  0.0713343545794487
Valid Loss:  0.07041364908218384
Epoch:  86  	Training Loss: 0.05306713283061981
Test Loss:  0.07131100445985794
Valid Loss:  0.0703921839594841
Epoch:  87  	Training Loss: 0.05305152386426926
Test Loss:  0.07128769159317017
Valid Loss:  0.07037074863910675
Epoch:  88  	Training Loss: 0.0530359223484993
Test Loss:  0.07126438617706299
Valid Loss:  0.0703493058681488
Epoch:  89  	Training Loss: 0.05302033573389053
Test Loss:  0.07124108821153641
Valid Loss:  0.07032789289951324
Epoch:  90  	Training Loss: 0.05300476402044296
Test Loss:  0.0712178498506546
Valid Loss:  0.07030650973320007
Epoch:  91  	Training Loss: 0.05298919975757599
Test Loss:  0.071194589138031
Valid Loss:  0.0702851265668869
Epoch:  92  	Training Loss: 0.05297365039587021
Test Loss:  0.07117141038179398
Valid Loss:  0.07026384025812149
Epoch:  93  	Training Loss: 0.0529581718146801
Test Loss:  0.07114827632904053
Valid Loss:  0.07024258375167847
Epoch:  94  	Training Loss: 0.05294272303581238
Test Loss:  0.07112520933151245
Valid Loss:  0.07022137194871902
Epoch:  95  	Training Loss: 0.05292728915810585
Test Loss:  0.07110214233398438
Valid Loss:  0.07020017504692078
Epoch:  96  	Training Loss: 0.05291187763214111
Test Loss:  0.07107909768819809
Valid Loss:  0.07017901539802551
Epoch:  97  	Training Loss: 0.052896492183208466
Test Loss:  0.07105609774589539
Valid Loss:  0.07015787810087204
Epoch:  98  	Training Loss: 0.05288112908601761
Test Loss:  0.07103312015533447
Valid Loss:  0.07013677805662155
Epoch:  99  	Training Loss: 0.052865780889987946
Test Loss:  0.07101017236709595
Valid Loss:  0.07011569291353226
Epoch:  100  	Training Loss: 0.05285046249628067
Test Loss:  0.07098725438117981
Valid Loss:  0.07009463012218475
Epoch:  101  	Training Loss: 0.05283515155315399
Test Loss:  0.07096437364816666
Valid Loss:  0.07007361203432083
Epoch:  102  	Training Loss: 0.0528198704123497
Test Loss:  0.07094145566225052
Valid Loss:  0.07005252689123154
Epoch:  103  	Training Loss: 0.05280454456806183
Test Loss:  0.07091853767633438
Valid Loss:  0.07003146409988403
Epoch:  104  	Training Loss: 0.05278922617435455
Test Loss:  0.07089565694332123
Valid Loss:  0.07001040875911713
Epoch:  105  	Training Loss: 0.05277392640709877
Test Loss:  0.07087279111146927
Valid Loss:  0.06998937577009201
Epoch:  106  	Training Loss: 0.05275863781571388
Test Loss:  0.0708499401807785
Valid Loss:  0.06996835768222809
Epoch:  107  	Training Loss: 0.05274336040019989
Test Loss:  0.07082711160182953
Valid Loss:  0.06994734704494476
Epoch:  108  	Training Loss: 0.05272809788584709
Test Loss:  0.07080429792404175
Valid Loss:  0.06992636620998383
Epoch:  109  	Training Loss: 0.05271284282207489
Test Loss:  0.07078150659799576
Valid Loss:  0.06990540027618408
Epoch:  110  	Training Loss: 0.05269760638475418
Test Loss:  0.07075873017311096
Valid Loss:  0.06988444179296494
Epoch:  111  	Training Loss: 0.052682384848594666
Test Loss:  0.07073597609996796
Valid Loss:  0.06986351311206818
Epoch:  112  	Training Loss: 0.05266717076301575
Test Loss:  0.07071299850940704
Valid Loss:  0.0698423832654953
Epoch:  113  	Training Loss: 0.052651822566986084
Test Loss:  0.07069000601768494
Valid Loss:  0.06982123106718063
Epoch:  114  	Training Loss: 0.052636463195085526
Test Loss:  0.07066699862480164
Valid Loss:  0.06980007141828537
Epoch:  115  	Training Loss: 0.05262110382318497
Test Loss:  0.07064398378133774
Valid Loss:  0.06977890431880951
Epoch:  116  	Training Loss: 0.052605729550123215
Test Loss:  0.07062095403671265
Valid Loss:  0.06975772976875305
Epoch:  117  	Training Loss: 0.052590347826480865
Test Loss:  0.07059790194034576
Valid Loss:  0.0697365328669548
Epoch:  118  	Training Loss: 0.05257496237754822
Test Loss:  0.07057484984397888
Valid Loss:  0.06971533596515656
Epoch:  119  	Training Loss: 0.05255956947803497
Test Loss:  0.07055176794528961
Valid Loss:  0.06969410181045532
Epoch:  120  	Training Loss: 0.052544161677360535
Test Loss:  0.07052868604660034
Valid Loss:  0.06967288255691528
Epoch:  121  	Training Loss: 0.0525287501513958
Test Loss:  0.07050559669733047
Valid Loss:  0.06965164840221405
Epoch:  122  	Training Loss: 0.05251333490014076
Test Loss:  0.07048255950212479
Valid Loss:  0.0696304440498352
Epoch:  123  	Training Loss: 0.05249794200062752
Test Loss:  0.0704595148563385
Valid Loss:  0.06960923969745636
Epoch:  124  	Training Loss: 0.05248255282640457
Test Loss:  0.07043646275997162
Valid Loss:  0.06958802789449692
Epoch:  125  	Training Loss: 0.05246715992689133
Test Loss:  0.07041342556476593
Valid Loss:  0.06956683099269867
Epoch:  126  	Training Loss: 0.05245177820324898
Test Loss:  0.07039039582014084
Valid Loss:  0.06954562664031982
Epoch:  127  	Training Loss: 0.05243638902902603
Test Loss:  0.07036736607551575
Valid Loss:  0.06952443718910217
Epoch:  128  	Training Loss: 0.05242100730538368
Test Loss:  0.07034432888031006
Valid Loss:  0.06950324028730392
Epoch:  129  	Training Loss: 0.05240562930703163
Test Loss:  0.07032130658626556
Valid Loss:  0.06948205828666687
Epoch:  130  	Training Loss: 0.05239025503396988
Test Loss:  0.07029828429222107
Valid Loss:  0.06946086883544922
Epoch:  131  	Training Loss: 0.052374884486198425
Test Loss:  0.07027526944875717
Valid Loss:  0.06943969428539276
Epoch:  132  	Training Loss: 0.05235951393842697
Test Loss:  0.07025250792503357
Valid Loss:  0.06941873580217361
Epoch:  133  	Training Loss: 0.05234430730342865
Test Loss:  0.07022976875305176
Valid Loss:  0.06939779222011566
Epoch:  134  	Training Loss: 0.052329111844301224
Test Loss:  0.07020702958106995
Valid Loss:  0.0693768635392189
Epoch:  135  	Training Loss: 0.052313923835754395
Test Loss:  0.07018432021141052
Valid Loss:  0.06935594975948334
Epoch:  136  	Training Loss: 0.05229874700307846
Test Loss:  0.0701616108417511
Valid Loss:  0.06933504343032837
Epoch:  137  	Training Loss: 0.05228358134627342
Test Loss:  0.07013891637325287
Valid Loss:  0.0693141371011734
Epoch:  138  	Training Loss: 0.052268411964178085
Test Loss:  0.07011623680591583
Valid Loss:  0.06929326057434082
Epoch:  139  	Training Loss: 0.05225325748324394
Test Loss:  0.0700935572385788
Valid Loss:  0.06927236914634705
Epoch:  140  	Training Loss: 0.052238110452890396
Test Loss:  0.07007090002298355
Valid Loss:  0.06925151497125626
Epoch:  141  	Training Loss: 0.052222978323698044
Test Loss:  0.0700482651591301
Valid Loss:  0.06923066079616547
Epoch:  142  	Training Loss: 0.05220784991979599
Test Loss:  0.07002557069063187
Valid Loss:  0.06920976936817169
Epoch:  143  	Training Loss: 0.052192702889442444
Test Loss:  0.07000289857387543
Valid Loss:  0.06918889284133911
Epoch:  144  	Training Loss: 0.052177563309669495
Test Loss:  0.06998023390769958
Valid Loss:  0.06916803121566772
Epoch:  145  	Training Loss: 0.05216243118047714
Test Loss:   29%|██▉       | 145/500 [01:43<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:43<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:43<01:56,  3.00it/s] 30%|███       | 151/500 [01:49<06:53,  1.19s/it] 31%|███       | 153/500 [01:49<04:55,  1.17it/s] 31%|███       | 155/500 [01:50<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:50<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:50<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:56<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:45,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:57<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:57<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:03<06:33,  1.20s/it] 35%|███▍      | 173/500 [02:03<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:03<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:04<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:04<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:10<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:10<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:10<03:18,  1.59it/s] 37%|███▋      | 187/500 [02:11<02:25,  2.15it/s] 38%|███▊      | 189/500 [02:11<01:49,  2.85it/s] 38%|███▊      | 191/500 [02:17<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:17<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:17<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:18<02:19,  2.18it/s] 40%|███▉      | 199/500 [02:18<01:42,  2.93it/s] 40%|████      | 201/500 [02:24<05:59,  1.20s/it] 41%|████      | 203/500 [02:24<04:16,  1.16it/s] 41%|████      | 205/500 [02:24<03:03,  1.60it/s] 41%|████▏     | 207/500 [02:24<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:25<01:38,  2.95it/s] 42%|████▏     | 211/500 [02:31<05:43,  1.19s/it] 43%|████▎     | 213/500 [02:31<04:06,  1.17it/s] 43%|████▎     | 215/500 [02:31<02:58,  1.60it/s]0.06995758414268494
Valid Loss:  0.06914718449115753
Epoch:  146  	Training Loss: 0.05214730650186539
Test Loss:  0.06993494182825089
Valid Loss:  0.06912632286548615
Epoch:  147  	Training Loss: 0.05213218927383423
Test Loss:  0.06991229951381683
Valid Loss:  0.06910547614097595
Epoch:  148  	Training Loss: 0.05211707204580307
Test Loss:  0.06988966464996338
Valid Loss:  0.06908465176820755
Epoch:  149  	Training Loss: 0.052101969718933105
Test Loss:  0.06986705958843231
Valid Loss:  0.06906382739543915
Epoch:  150  	Training Loss: 0.05208686739206314
Test Loss:  0.06984443217515945
Valid Loss:  0.06904299557209015
Epoch:  151  	Training Loss: 0.052071768790483475
Test Loss:  0.0698217898607254
Valid Loss:  0.06902217864990234
Epoch:  152  	Training Loss: 0.052056681364774704
Test Loss:  0.06979911029338837
Valid Loss:  0.06900131702423096
Epoch:  153  	Training Loss: 0.052041564136743546
Test Loss:  0.06977646052837372
Valid Loss:  0.06898048520088196
Epoch:  154  	Training Loss: 0.05202646180987358
Test Loss:  0.06975382566452026
Valid Loss:  0.06895966082811356
Epoch:  155  	Training Loss: 0.05201137810945511
Test Loss:  0.069731205701828
Valid Loss:  0.06893887370824814
Epoch:  156  	Training Loss: 0.05199630185961723
Test Loss:  0.06970863044261932
Valid Loss:  0.06891808658838272
Epoch:  157  	Training Loss: 0.05198124796152115
Test Loss:  0.06968607008457184
Valid Loss:  0.06889733672142029
Epoch:  158  	Training Loss: 0.05196620896458626
Test Loss:  0.06966352462768555
Valid Loss:  0.06887659430503845
Epoch:  159  	Training Loss: 0.051951177418231964
Test Loss:  0.06964100152254105
Valid Loss:  0.06885587424039841
Epoch:  160  	Training Loss: 0.05193616449832916
Test Loss:  0.06961850076913834
Valid Loss:  0.06883516907691956
Epoch:  161  	Training Loss: 0.051921166479587555
Test Loss:  0.06959602981805801
Valid Loss:  0.06881450116634369
Epoch:  162  	Training Loss: 0.05190619081258774
Test Loss:  0.0695735514163971
Valid Loss:  0.06879380345344543
Epoch:  163  	Training Loss: 0.051891203969717026
Test Loss:  0.06955106556415558
Valid Loss:  0.06877313554286957
Epoch:  164  	Training Loss: 0.051876217126846313
Test Loss:  0.06952860206365585
Valid Loss:  0.06875245273113251
Epoch:  165  	Training Loss: 0.051861248910427094
Test Loss:  0.06950614601373672
Valid Loss:  0.06873178482055664
Epoch:  166  	Training Loss: 0.051846280694007874
Test Loss:  0.0694836974143982
Valid Loss:  0.06871111690998077
Epoch:  167  	Training Loss: 0.051831312477588654
Test Loss:  0.06946125626564026
Valid Loss:  0.0686904713511467
Epoch:  168  	Training Loss: 0.05181635543704033
Test Loss:  0.06943882256746292
Valid Loss:  0.06866982579231262
Epoch:  169  	Training Loss: 0.0518014058470726
Test Loss:  0.06941639631986618
Valid Loss:  0.06864918023347855
Epoch:  170  	Training Loss: 0.051786452531814575
Test Loss:  0.06939399242401123
Valid Loss:  0.06862854957580566
Epoch:  171  	Training Loss: 0.05177151784300804
Test Loss:  0.06937158107757568
Valid Loss:  0.06860792636871338
Epoch:  172  	Training Loss: 0.05175658315420151
Test Loss:  0.06934913247823715
Valid Loss:  0.06858726590871811
Epoch:  173  	Training Loss: 0.051741622388362885
Test Loss:  0.06932669878005981
Valid Loss:  0.06856662034988403
Epoch:  174  	Training Loss: 0.051726676523685455
Test Loss:  0.06930424273014069
Valid Loss:  0.06854596734046936
Epoch:  175  	Training Loss: 0.05171173810958862
Test Loss:  0.06928184628486633
Valid Loss:  0.06852534413337708
Epoch:  176  	Training Loss: 0.05169680714607239
Test Loss:  0.0692593976855278
Valid Loss:  0.0685047134757042
Epoch:  177  	Training Loss: 0.05168188363313675
Test Loss:  0.06923700869083405
Valid Loss:  0.0684841051697731
Epoch:  178  	Training Loss: 0.05166696012020111
Test Loss:  0.0692146047949791
Valid Loss:  0.06846350431442261
Epoch:  179  	Training Loss: 0.051652051508426666
Test Loss:  0.06919223815202713
Valid Loss:  0.06844291090965271
Epoch:  180  	Training Loss: 0.05163714662194252
Test Loss:  0.06916984170675278
Valid Loss:  0.06842231750488281
Epoch:  181  	Training Loss: 0.05162225663661957
Test Loss:  0.06914746761322021
Valid Loss:  0.06840173900127411
Epoch:  182  	Training Loss: 0.051607370376586914
Test Loss:  0.06912532448768616
Valid Loss:  0.06838136911392212
Epoch:  183  	Training Loss: 0.0515926331281662
Test Loss:  0.06910324096679688
Valid Loss:  0.06836104393005371
Epoch:  184  	Training Loss: 0.05157791078090668
Test Loss:  0.0690811425447464
Valid Loss:  0.0683407187461853
Epoch:  185  	Training Loss: 0.05156320706009865
Test Loss:  0.06905906647443771
Valid Loss:  0.06832041591405869
Epoch:  186  	Training Loss: 0.051548514515161514
Test Loss:  0.06903699040412903
Valid Loss:  0.06830011308193207
Epoch:  187  	Training Loss: 0.05153382569551468
Test Loss:  0.06901498138904572
Valid Loss:  0.06827984750270844
Epoch:  188  	Training Loss: 0.051519159227609634
Test Loss:  0.06899294257164001
Valid Loss:  0.0682595819234848
Epoch:  189  	Training Loss: 0.05150450021028519
Test Loss:  0.0689709261059761
Valid Loss:  0.06823933124542236
Epoch:  190  	Training Loss: 0.051489852368831635
Test Loss:  0.06894892454147339
Valid Loss:  0.06821910291910172
Epoch:  191  	Training Loss: 0.05147521197795868
Test Loss:  0.06892694532871246
Valid Loss:  0.06819888204336166
Epoch:  192  	Training Loss: 0.051460590213537216
Test Loss:  0.06890492141246796
Valid Loss:  0.06817862391471863
Epoch:  193  	Training Loss: 0.05144593119621277
Test Loss:  0.06888291239738464
Valid Loss:  0.068158358335495
Epoch:  194  	Training Loss: 0.051431283354759216
Test Loss:  0.06886090338230133
Valid Loss:  0.06813811510801315
Epoch:  195  	Training Loss: 0.05141665041446686
Test Loss:  0.0688389241695404
Valid Loss:  0.0681178867816925
Epoch:  196  	Training Loss: 0.0514020174741745
Test Loss:  0.06881695240736008
Valid Loss:  0.06809766590595245
Epoch:  197  	Training Loss: 0.051387399435043335
Test Loss:  0.06879499554634094
Valid Loss:  0.0680774599313736
Epoch:  198  	Training Loss: 0.051372792571783066
Test Loss:  0.0687730461359024
Valid Loss:  0.06805726140737534
Epoch:  199  	Training Loss: 0.051358189433813095
Test Loss:  0.06875111907720566
Valid Loss:  0.06803707778453827
Epoch:  200  	Training Loss: 0.05134360119700432
Test Loss:  0.0687292069196701
Valid Loss:  0.0680169090628624
Epoch:  201  	Training Loss: 0.05132901668548584
Test Loss:  0.06870728731155396
Valid Loss:  0.06799675524234772
Epoch:  202  	Training Loss: 0.05131444334983826
Test Loss:  0.06868542730808258
Valid Loss:  0.06797662377357483
Epoch:  203  	Training Loss: 0.051299892365932465
Test Loss:  0.0686635673046112
Valid Loss:  0.06795651465654373
Epoch:  204  	Training Loss: 0.05128534883260727
Test Loss:  0.06864172220230103
Valid Loss:  0.06793641299009323
Epoch:  205  	Training Loss: 0.05127081647515297
Test Loss:  0.06861989200115204
Valid Loss:  0.06791631877422333
Epoch:  206  	Training Loss: 0.05125629901885986
Test Loss:  0.06859809160232544
Valid Loss:  0.06789624691009521
Epoch:  207  	Training Loss: 0.051241785287857056
Test Loss:  0.06857628375291824
Valid Loss:  0.0678761824965477
Epoch:  208  	Training Loss: 0.051227279007434845
Test Loss:  0.06855449825525284
Valid Loss:  0.06785613298416138
Epoch:  209  	Training Loss: 0.05121278762817383
Test Loss:  0.06853273510932922
Valid Loss:  0.06783610582351685
Epoch:  210  	Training Loss: 0.05119830369949341
Test Loss:  0.0685109794139862
Valid Loss:  0.06781607866287231
Epoch:  211  	Training Loss: 0.05118383467197418
Test Loss:  0.06848923116922379
Valid Loss:  0.06779605895280838
Epoch:  212  	Training Loss: 0.051169365644454956
Test Loss:  0.06846752017736435
Valid Loss:  0.06777608394622803
Epoch:  213  	Training Loss: 0.05115491896867752
Test Loss:  0.06844577938318253
Valid Loss:  0.06775608658790588
Epoch:  214  	Training Loss: 0.05114047974348068
Test Loss:  0.06842411309480667
Valid Loss:  0.06773613393306732
Epoch:  215  	Training Loss: 0.051126059144735336
Test Loss:  0.06840240955352783
Valid Loss:  0.06771617382764816
Epoch:  216  	Training Loss: 0.05111163854598999
Test Loss:  0.06838077306747437
Valid Loss:  0.06769625097513199
 43%|████▎     | 217/500 [02:31<02:10,  2.18it/s] 44%|████▍     | 219/500 [02:32<01:35,  2.93it/s] 44%|████▍     | 221/500 [02:38<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:38<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:38<02:48,  1.64it/s] 45%|████▌     | 227/500 [02:38<02:02,  2.24it/s] 46%|████▌     | 229/500 [02:38<01:30,  3.01it/s] 46%|████▌     | 231/500 [02:45<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:45<03:47,  1.18it/s] 47%|████▋     | 235/500 [02:45<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:45<02:00,  2.18it/s] 48%|████▊     | 239/500 [02:45<01:30,  2.88it/s] 48%|████▊     | 241/500 [02:52<05:09,  1.19s/it] 49%|████▊     | 243/500 [02:52<03:40,  1.17it/s] 49%|████▉     | 245/500 [02:52<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:52<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:52<01:24,  2.97it/s] 50%|█████     | 251/500 [02:58<04:51,  1.17s/it] 51%|█████     | 253/500 [02:59<03:28,  1.19it/s] 51%|█████     | 255/500 [02:59<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:59<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:59<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:05<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:05<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:06<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:06<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:06<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:12<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:12<03:16,  1.16it/s] 55%|█████▌    | 275/500 [03:13<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:13<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:13<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:19<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:19<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:20<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:20<01:36,  2.22it/s]Epoch:  217  	Training Loss: 0.051097236573696136
Test Loss:  0.06835908442735672
Valid Loss:  0.06767632067203522
Epoch:  218  	Training Loss: 0.05108284205198288
Test Loss:  0.06833748519420624
Valid Loss:  0.06765642762184143
Epoch:  219  	Training Loss: 0.051068466156721115
Test Loss:  0.06831584125757217
Valid Loss:  0.06763651967048645
Epoch:  220  	Training Loss: 0.05105409398674965
Test Loss:  0.06829427182674408
Valid Loss:  0.06761665642261505
Epoch:  221  	Training Loss: 0.051039740443229675
Test Loss:  0.068272665143013
Valid Loss:  0.06759679317474365
Epoch:  222  	Training Loss: 0.051025390625
Test Loss:  0.06825073063373566
Valid Loss:  0.06757659465074539
Epoch:  223  	Training Loss: 0.05101080983877182
Test Loss:  0.06822876632213593
Valid Loss:  0.06755639612674713
Epoch:  224  	Training Loss: 0.05099623277783394
Test Loss:  0.06820681691169739
Valid Loss:  0.06753621250391006
Epoch:  225  	Training Loss: 0.05098166689276695
Test Loss:  0.06818491220474243
Valid Loss:  0.06751604378223419
Epoch:  226  	Training Loss: 0.05096710845828056
Test Loss:  0.06816297769546509
Valid Loss:  0.06749586760997772
Epoch:  227  	Training Loss: 0.050952550023794174
Test Loss:  0.06814104318618774
Valid Loss:  0.06747571378946304
Epoch:  228  	Training Loss: 0.05093800276517868
Test Loss:  0.06811918318271637
Valid Loss:  0.06745558232069016
Epoch:  229  	Training Loss: 0.05092347040772438
Test Loss:  0.06809728592634201
Valid Loss:  0.06743544340133667
Epoch:  230  	Training Loss: 0.05090893805027008
Test Loss:  0.06807540357112885
Valid Loss:  0.06741531193256378
Epoch:  231  	Training Loss: 0.050894416868686676
Test Loss:  0.06805352866649628
Valid Loss:  0.06739518791437149
Epoch:  232  	Training Loss: 0.05087989568710327
Test Loss:  0.06803196668624878
Valid Loss:  0.06737536191940308
Epoch:  233  	Training Loss: 0.05086559057235718
Test Loss:  0.06801044195890427
Valid Loss:  0.06735552847385406
Epoch:  234  	Training Loss: 0.05085127055644989
Test Loss:  0.06798890233039856
Valid Loss:  0.06733570992946625
Epoch:  235  	Training Loss: 0.05083697289228439
Test Loss:  0.06796737760305405
Valid Loss:  0.06731590628623962
Epoch:  236  	Training Loss: 0.050822678953409195
Test Loss:  0.06794586777687073
Valid Loss:  0.0672961175441742
Epoch:  237  	Training Loss: 0.05080839991569519
Test Loss:  0.0679243803024292
Valid Loss:  0.06727632880210876
Epoch:  238  	Training Loss: 0.05079412832856178
Test Loss:  0.06790287792682648
Valid Loss:  0.06725655496120453
Epoch:  239  	Training Loss: 0.050779856741428375
Test Loss:  0.06788140535354614
Valid Loss:  0.06723679602146149
Epoch:  240  	Training Loss: 0.05076559633016586
Test Loss:  0.0678599402308464
Valid Loss:  0.06721704453229904
Epoch:  241  	Training Loss: 0.05075134336948395
Test Loss:  0.06783848255872726
Valid Loss:  0.0671972930431366
Epoch:  242  	Training Loss: 0.05073709785938263
Test Loss:  0.06781664490699768
Valid Loss:  0.06717720627784729
Epoch:  243  	Training Loss: 0.05072261393070221
Test Loss:  0.0677948147058487
Valid Loss:  0.06715712696313858
Epoch:  244  	Training Loss: 0.050708137452602386
Test Loss:  0.0677729919552803
Valid Loss:  0.06713706254959106
Epoch:  245  	Training Loss: 0.05069366842508316
Test Loss:  0.0677511990070343
Valid Loss:  0.06711700558662415
Epoch:  246  	Training Loss: 0.05067921429872513
Test Loss:  0.0677294135093689
Valid Loss:  0.06709695607423782
Epoch:  247  	Training Loss: 0.050664760172367096
Test Loss:  0.06770763546228409
Valid Loss:  0.0670769214630127
Epoch:  248  	Training Loss: 0.05065031722187996
Test Loss:  0.06768587231636047
Valid Loss:  0.06705690175294876
Epoch:  249  	Training Loss: 0.05063588544726372
Test Loss:  0.06766411662101746
Valid Loss:  0.06703689694404602
Epoch:  250  	Training Loss: 0.050621457397937775
Test Loss:  0.06764239072799683
Valid Loss:  0.06701689958572388
Epoch:  251  	Training Loss: 0.050607044249773026
Test Loss:  0.0676206573843956
Valid Loss:  0.06699690967798233
Epoch:  252  	Training Loss: 0.05059263855218887
Test Loss:  0.06759950518608093
Valid Loss:  0.06697742640972137
Epoch:  253  	Training Loss: 0.050578586757183075
Test Loss:  0.06757837533950806
Valid Loss:  0.0669579729437828
Epoch:  254  	Training Loss: 0.050564542412757874
Test Loss:  0.06755726039409637
Valid Loss:  0.06693851202726364
Epoch:  255  	Training Loss: 0.05055050551891327
Test Loss:  0.0675361379981041
Valid Loss:  0.06691907346248627
Epoch:  256  	Training Loss: 0.05053647607564926
Test Loss:  0.06751503795385361
Valid Loss:  0.06689964234828949
Epoch:  257  	Training Loss: 0.05052245408296585
Test Loss:  0.06749394536018372
Valid Loss:  0.06688021123409271
Epoch:  258  	Training Loss: 0.050508443266153336
Test Loss:  0.06747286021709442
Valid Loss:  0.06686079502105713
Epoch:  259  	Training Loss: 0.05049443989992142
Test Loss:  0.06745180487632751
Valid Loss:  0.06684139370918274
Epoch:  260  	Training Loss: 0.0504804402589798
Test Loss:  0.06743073463439941
Valid Loss:  0.06682199984788895
Epoch:  261  	Training Loss: 0.050466448068618774
Test Loss:  0.0674096941947937
Valid Loss:  0.06680261343717575
Epoch:  262  	Training Loss: 0.05045246332883835
Test Loss:  0.06738830357789993
Valid Loss:  0.06678292155265808
Epoch:  263  	Training Loss: 0.05043826624751091
Test Loss:  0.06736693531274796
Valid Loss:  0.06676323711872101
Epoch:  264  	Training Loss: 0.050424084067344666
Test Loss:  0.06734556704759598
Valid Loss:  0.06674356758594513
Epoch:  265  	Training Loss: 0.050409913063049316
Test Loss:  0.06732417643070221
Valid Loss:  0.06672390550374985
Epoch:  266  	Training Loss: 0.05039574205875397
Test Loss:  0.06730283796787262
Valid Loss:  0.06670425087213516
Epoch:  267  	Training Loss: 0.05038158595561981
Test Loss:  0.06728148460388184
Valid Loss:  0.06668460369110107
Epoch:  268  	Training Loss: 0.050367437303066254
Test Loss:  0.06726011633872986
Valid Loss:  0.06666495651006699
Epoch:  269  	Training Loss: 0.05035329610109329
Test Loss:  0.06723882257938385
Valid Loss:  0.06664534658193588
Epoch:  270  	Training Loss: 0.05033915862441063
Test Loss:  0.06721749156713486
Valid Loss:  0.06662572920322418
Epoch:  271  	Training Loss: 0.05032502859830856
Test Loss:  0.06719616055488586
Valid Loss:  0.06660611182451248
Epoch:  272  	Training Loss: 0.05031090974807739
Test Loss:  0.06717480719089508
Valid Loss:  0.0665864497423172
Epoch:  273  	Training Loss: 0.05029673874378204
Test Loss:  0.06715340912342072
Valid Loss:  0.06656676530838013
Epoch:  274  	Training Loss: 0.050282567739486694
Test Loss:  0.06713201850652695
Valid Loss:  0.06654709577560425
Epoch:  275  	Training Loss: 0.05026840791106224
Test Loss:  0.06711064279079437
Valid Loss:  0.06652743369340897
Epoch:  276  	Training Loss: 0.05025424808263779
Test Loss:  0.06708932667970657
Valid Loss:  0.06650780141353607
Epoch:  277  	Training Loss: 0.05024009943008423
Test Loss:  0.06706796586513519
Valid Loss:  0.06648814678192139
Epoch:  278  	Training Loss: 0.05022595822811127
Test Loss:  0.06704661250114441
Valid Loss:  0.0664685070514679
Epoch:  279  	Training Loss: 0.050211817026138306
Test Loss:  0.06702527403831482
Valid Loss:  0.0664488896727562
Epoch:  280  	Training Loss: 0.05019768700003624
Test Loss:  0.06700393557548523
Valid Loss:  0.0664292648434639
Epoch:  281  	Training Loss: 0.05018356069922447
Test Loss:  0.06698261201381683
Valid Loss:  0.066409632563591
Epoch:  282  	Training Loss: 0.050169434398412704
Test Loss:  0.06696140021085739
Valid Loss:  0.06639011949300766
Epoch:  283  	Training Loss: 0.050155386328697205
Test Loss:  0.06694020330905914
Valid Loss:  0.06637062132358551
Epoch:  284  	Training Loss: 0.050141360610723495
Test Loss:  0.06691904366016388
Valid Loss:  0.06635114550590515
Epoch:  285  	Training Loss: 0.05012734234333038
Test Loss:  0.06689787656068802
Valid Loss:  0.06633168458938599
Epoch:  286  	Training Loss: 0.05011333152651787
Test Loss:  0.06687674671411514
Valid Loss:  0.06631223857402802
Epoch:  287  	Training Loss: 0.05009933561086655
Test Loss:  0.06685562431812286
Valid Loss:  0.06629280745983124
Epoch:  288  	Training Loss: 0.05008535087108612
Test Loss:  0.06683452427387238
Valid Loss:   58%|█████▊    | 289/500 [03:20<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:26<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:26<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:26<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:26<01:30,  2.23it/s] 60%|█████▉    | 299/500 [03:27<01:06,  3.01it/s] 60%|██████    | 301/500 [03:33<03:56,  1.19s/it] 61%|██████    | 303/500 [03:33<02:47,  1.17it/s] 61%|██████    | 305/500 [03:33<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:33<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:33<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:40<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:40<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:40<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:40<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:40<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:47<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:47<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:47<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:47<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:47<00:56,  3.00it/s] 66%|██████▌   | 331/500 [03:53<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:54<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:54<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:54<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:54<00:53,  3.01it/s] 68%|██████▊   | 341/500 [04:00<03:10,  1.20s/it] 69%|██████▊   | 343/500 [04:01<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:01<01:38,  1.58it/s] 69%|██████▉   | 347/500 [04:01<01:11,  2.13it/s] 70%|██████▉   | 349/500 [04:01<00:53,  2.83it/s] 70%|███████   | 351/500 [04:08<02:59,  1.20s/it] 71%|███████   | 353/500 [04:08<02:07,  1.16it/s] 71%|███████   | 355/500 [04:08<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:08<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:08<00:47,  2.95it/s]0.06627338379621506
Epoch:  289  	Training Loss: 0.05007137730717659
Test Loss:  0.06681343168020248
Valid Loss:  0.06625398248434067
Epoch:  290  	Training Loss: 0.05005741864442825
Test Loss:  0.06679236888885498
Valid Loss:  0.06623458862304688
Epoch:  291  	Training Loss: 0.050043463706970215
Test Loss:  0.06677130609750748
Valid Loss:  0.06621520966291428
Epoch:  292  	Training Loss: 0.05002952367067337
Test Loss:  0.06675250828266144
Valid Loss:  0.06619786471128464
Epoch:  293  	Training Loss: 0.050016991794109344
Test Loss:  0.06673374772071838
Valid Loss:  0.06618054211139679
Epoch:  294  	Training Loss: 0.05000448599457741
Test Loss:  0.06671498715877533
Valid Loss:  0.06616322696208954
Epoch:  295  	Training Loss: 0.04999198019504547
Test Loss:  0.06669624894857407
Valid Loss:  0.06614592671394348
Epoch:  296  	Training Loss: 0.049979496747255325
Test Loss:  0.06667754054069519
Valid Loss:  0.06612865626811981
Epoch:  297  	Training Loss: 0.049967020750045776
Test Loss:  0.0666588544845581
Valid Loss:  0.06611140817403793
Epoch:  298  	Training Loss: 0.04995456337928772
Test Loss:  0.06664019823074341
Valid Loss:  0.06609417498111725
Epoch:  299  	Training Loss: 0.04994212090969086
Test Loss:  0.0666215568780899
Valid Loss:  0.06607696413993835
Epoch:  300  	Training Loss: 0.049929697066545486
Test Loss:  0.06660293787717819
Valid Loss:  0.06605977565050125
Epoch:  301  	Training Loss: 0.04991728067398071
Test Loss:  0.06658434867858887
Valid Loss:  0.06604260206222534
Epoch:  302  	Training Loss: 0.04990488290786743
Test Loss:  0.06656380742788315
Valid Loss:  0.06602369248867035
Epoch:  303  	Training Loss: 0.04989127069711685
Test Loss:  0.06654327362775803
Valid Loss:  0.06600478291511536
Epoch:  304  	Training Loss: 0.04987765848636627
Test Loss:  0.0665227472782135
Valid Loss:  0.06598588824272156
Epoch:  305  	Training Loss: 0.04986407235264778
Test Loss:  0.06650225073099136
Valid Loss:  0.06596700847148895
Epoch:  306  	Training Loss: 0.049850478768348694
Test Loss:  0.06648175418376923
Valid Loss:  0.06594813615083694
Epoch:  307  	Training Loss: 0.0498368963599205
Test Loss:  0.06646127998828888
Valid Loss:  0.06592927128076553
Epoch:  308  	Training Loss: 0.0498233288526535
Test Loss:  0.06644080579280853
Valid Loss:  0.06591042876243591
Epoch:  309  	Training Loss: 0.049809761345386505
Test Loss:  0.06642035394906998
Valid Loss:  0.06589159369468689
Epoch:  310  	Training Loss: 0.0497962087392807
Test Loss:  0.06639991700649261
Valid Loss:  0.06587275862693787
Epoch:  311  	Training Loss: 0.049782659858465195
Test Loss:  0.06637948751449585
Valid Loss:  0.06585395336151123
Epoch:  312  	Training Loss: 0.04976912587881088
Test Loss:  0.0663587749004364
Valid Loss:  0.0658348798751831
Epoch:  313  	Training Loss: 0.049755409359931946
Test Loss:  0.06633805483579636
Valid Loss:  0.06581580638885498
Epoch:  314  	Training Loss: 0.049741704016923904
Test Loss:  0.0663173571228981
Valid Loss:  0.06579674780368805
Epoch:  315  	Training Loss: 0.04972800612449646
Test Loss:  0.06629662215709686
Valid Loss:  0.06577765941619873
Epoch:  316  	Training Loss: 0.04971430450677872
Test Loss:  0.06627587974071503
Valid Loss:  0.0657586082816124
Epoch:  317  	Training Loss: 0.04970061033964157
Test Loss:  0.06625520437955856
Valid Loss:  0.06573957204818726
Epoch:  318  	Training Loss: 0.04968692734837532
Test Loss:  0.06623448431491852
Valid Loss:  0.06572051346302032
Epoch:  319  	Training Loss: 0.04967324435710907
Test Loss:  0.06621378660202026
Valid Loss:  0.06570146977901459
Epoch:  320  	Training Loss: 0.049659568816423416
Test Loss:  0.066193126142025
Valid Loss:  0.06568244099617004
Epoch:  321  	Training Loss: 0.04964590072631836
Test Loss:  0.06617243587970734
Valid Loss:  0.0656634047627449
Epoch:  322  	Training Loss: 0.049632228910923004
Test Loss:  0.0661514475941658
Valid Loss:  0.06564410030841827
Epoch:  323  	Training Loss: 0.049618370831012726
Test Loss:  0.06613046675920486
Valid Loss:  0.06562480330467224
Epoch:  324  	Training Loss: 0.04960451275110245
Test Loss:  0.06610950827598572
Valid Loss:  0.0656055212020874
Epoch:  325  	Training Loss: 0.049590662121772766
Test Loss:  0.06608858704566956
Valid Loss:  0.06558625400066376
Epoch:  326  	Training Loss: 0.04957681521773338
Test Loss:  0.066067636013031
Valid Loss:  0.06556697189807892
Epoch:  327  	Training Loss: 0.049562979489564896
Test Loss:  0.06604668498039246
Valid Loss:  0.06554769724607468
Epoch:  328  	Training Loss: 0.04954914003610611
Test Loss:  0.0660257488489151
Valid Loss:  0.06552843749523163
Epoch:  329  	Training Loss: 0.04953531175851822
Test Loss:  0.06600482016801834
Valid Loss:  0.06550918519496918
Epoch:  330  	Training Loss: 0.04952148720622063
Test Loss:  0.06598389148712158
Valid Loss:  0.06548993289470673
Epoch:  331  	Training Loss: 0.049507662653923035
Test Loss:  0.06596297770738602
Valid Loss:  0.06547068804502487
Epoch:  332  	Training Loss: 0.04949384927749634
Test Loss:  0.06594247370958328
Valid Loss:  0.06545180827379227
Epoch:  333  	Training Loss: 0.049480289220809937
Test Loss:  0.06592197716236115
Valid Loss:  0.06543293595314026
Epoch:  334  	Training Loss: 0.04946674406528473
Test Loss:  0.0659015029668808
Valid Loss:  0.06541408598423004
Epoch:  335  	Training Loss: 0.04945321008563042
Test Loss:  0.06588104367256165
Valid Loss:  0.06539525091648102
Epoch:  336  	Training Loss: 0.0494396835565567
Test Loss:  0.06586059927940369
Valid Loss:  0.06537643074989319
Epoch:  337  	Training Loss: 0.04942616820335388
Test Loss:  0.06584016233682632
Valid Loss:  0.06535761058330536
Epoch:  338  	Training Loss: 0.04941266402602196
Test Loss:  0.06581975519657135
Valid Loss:  0.06533881276845932
Epoch:  339  	Training Loss: 0.04939916729927063
Test Loss:  0.06579934060573578
Valid Loss:  0.06532002985477448
Epoch:  340  	Training Loss: 0.0493856817483902
Test Loss:  0.065778948366642
Valid Loss:  0.06530125439167023
Epoch:  341  	Training Loss: 0.04937220364809036
Test Loss:  0.06575857102870941
Valid Loss:  0.06528248637914658
Epoch:  342  	Training Loss: 0.049358729273080826
Test Loss:  0.06573822349309921
Valid Loss:  0.06526374816894531
Epoch:  343  	Training Loss: 0.04934528097510338
Test Loss:  0.06571788340806961
Valid Loss:  0.06524501740932465
Epoch:  344  	Training Loss: 0.04933182895183563
Test Loss:  0.0656975507736206
Valid Loss:  0.06522629410028458
Epoch:  345  	Training Loss: 0.04931838810443878
Test Loss:  0.065677210688591
Valid Loss:  0.0652075707912445
Epoch:  346  	Training Loss: 0.04930494353175163
Test Loss:  0.06565689295530319
Valid Loss:  0.06518885493278503
Epoch:  347  	Training Loss: 0.04929151386022568
Test Loss:  0.06563657522201538
Valid Loss:  0.06517015397548676
Epoch:  348  	Training Loss: 0.04927809163928032
Test Loss:  0.06561626493930817
Valid Loss:  0.06515144556760788
Epoch:  349  	Training Loss: 0.04926466569304466
Test Loss:  0.06559596955776215
Valid Loss:  0.0651327595114708
Epoch:  350  	Training Loss: 0.0492512509226799
Test Loss:  0.06557568907737732
Valid Loss:  0.0651140809059143
Epoch:  351  	Training Loss: 0.04923783987760544
Test Loss:  0.06555540859699249
Valid Loss:  0.06509540230035782
Epoch:  352  	Training Loss: 0.04922443628311157
Test Loss:  0.06553614139556885
Valid Loss:  0.06507761776447296
Epoch:  353  	Training Loss: 0.04921164736151695
Test Loss:  0.0655168890953064
Valid Loss:  0.0650598406791687
Epoch:  354  	Training Loss: 0.04919885843992233
Test Loss:  0.06549763679504395
Valid Loss:  0.06504206359386444
Epoch:  355  	Training Loss: 0.04918606951832771
Test Loss:  0.06547833979129791
Valid Loss:  0.06502430140972137
Epoch:  356  	Training Loss: 0.04917329549789429
Test Loss:  0.06545909494161606
Valid Loss:  0.06500651687383652
Epoch:  357  	Training Loss: 0.049160514026880264
Test Loss:  0.06543982028961182
Valid Loss:  0.06498875468969345
Epoch:  358  	Training Loss: 0.04914773628115654
Test Loss:  0.06542058289051056
Valid Loss:  0.06497099995613098
Epoch:  359  	Training Loss: 0.04913496598601341
Test Loss:  0.06540131568908691
Valid Loss:  0.06495323777198792
Epoch:  360  	Training Loss: 0.049122199416160583
Test Loss:  0.06538209319114685
 72%|███████▏  | 361/500 [04:14<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:15<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:15<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:15<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:15<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:21<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:21<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:22<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:22<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:22<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:28<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:28<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:28<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:29<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:29<00:38,  2.89it/s] 78%|███████▊  | 391/500 [04:35<02:09,  1.18s/it] 79%|███████▊  | 393/500 [04:35<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:35<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:35<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:36<00:33,  2.99it/s] 80%|████████  | 401/500 [04:42<01:57,  1.18s/it] 81%|████████  | 403/500 [04:42<01:22,  1.18it/s] 81%|████████  | 405/500 [04:42<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:42<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:42<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:49<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:49<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:49<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:49<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:49<00:27,  2.95it/s] 84%|████████▍ | 421/500 [04:56<01:32,  1.18s/it] 85%|████████▍ | 423/500 [04:56<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:56<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:56<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:56<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:02<01:21,  1.18s/it]Valid Loss:  0.06493549048900604
Epoch:  361  	Training Loss: 0.049109429121017456
Test Loss:  0.0653628408908844
Valid Loss:  0.06491772830486298
Epoch:  362  	Training Loss: 0.049096666276454926
Test Loss:  0.06534230709075928
Valid Loss:  0.06489884853363037
Epoch:  363  	Training Loss: 0.049083128571510315
Test Loss:  0.06532182544469833
Valid Loss:  0.06487997621297836
Epoch:  364  	Training Loss: 0.0490695983171463
Test Loss:  0.065301313996315
Valid Loss:  0.06486110389232635
Epoch:  365  	Training Loss: 0.04905606806278229
Test Loss:  0.06528080254793167
Valid Loss:  0.06484223902225494
Epoch:  366  	Training Loss: 0.04904255270957947
Test Loss:  0.06526035070419312
Valid Loss:  0.06482338905334473
Epoch:  367  	Training Loss: 0.04902902990579605
Test Loss:  0.06523984670639038
Valid Loss:  0.06480452418327332
Epoch:  368  	Training Loss: 0.04901551455259323
Test Loss:  0.06521936506032944
Valid Loss:  0.0647856742143631
Epoch:  369  	Training Loss: 0.04900199919939041
Test Loss:  0.0651988834142685
Valid Loss:  0.06476683169603348
Epoch:  370  	Training Loss: 0.048988498747348785
Test Loss:  0.06517843902111053
Valid Loss:  0.06474799662828445
Epoch:  371  	Training Loss: 0.04897499084472656
Test Loss:  0.06515797227621078
Valid Loss:  0.06472915410995483
Epoch:  372  	Training Loss: 0.048961494117975235
Test Loss:  0.06513752043247223
Valid Loss:  0.0647103488445282
Epoch:  373  	Training Loss: 0.0489480122923851
Test Loss:  0.06511708348989487
Valid Loss:  0.06469153612852097
Epoch:  374  	Training Loss: 0.048934537917375565
Test Loss:  0.0650966614484787
Valid Loss:  0.06467273831367493
Epoch:  375  	Training Loss: 0.04892106354236603
Test Loss:  0.06507623195648193
Valid Loss:  0.06465394794940948
Epoch:  376  	Training Loss: 0.048907600343227386
Test Loss:  0.06505583226680756
Valid Loss:  0.06463516503572464
Epoch:  377  	Training Loss: 0.04889414459466934
Test Loss:  0.06503543257713318
Valid Loss:  0.06461638957262039
Epoch:  378  	Training Loss: 0.048880692571401596
Test Loss:  0.0650150403380394
Valid Loss:  0.06459762156009674
Epoch:  379  	Training Loss: 0.04886724799871445
Test Loss:  0.06499466300010681
Valid Loss:  0.06457886844873428
Epoch:  380  	Training Loss: 0.048853810876607895
Test Loss:  0.06497429311275482
Valid Loss:  0.06456012278795242
Epoch:  381  	Training Loss: 0.04884038120508194
Test Loss:  0.06495393812656403
Valid Loss:  0.06454138457775116
Epoch:  382  	Training Loss: 0.04882695525884628
Test Loss:  0.06493375450372696
Valid Loss:  0.06452280282974243
Epoch:  383  	Training Loss: 0.04881364479660988
Test Loss:  0.06491358578205109
Valid Loss:  0.0645042359828949
Epoch:  384  	Training Loss: 0.04880034178495407
Test Loss:  0.06489342451095581
Valid Loss:  0.06448567658662796
Epoch:  385  	Training Loss: 0.04878704249858856
Test Loss:  0.06487328559160233
Valid Loss:  0.06446712464094162
Epoch:  386  	Training Loss: 0.04877375066280365
Test Loss:  0.06485314667224884
Valid Loss:  0.06444858014583588
Epoch:  387  	Training Loss: 0.048760466277599335
Test Loss:  0.06483300775289536
Valid Loss:  0.06443005800247192
Epoch:  388  	Training Loss: 0.048747189342975616
Test Loss:  0.06481288373470306
Valid Loss:  0.06441152095794678
Epoch:  389  	Training Loss: 0.0487339124083519
Test Loss:  0.06479278951883316
Valid Loss:  0.06439300626516342
Epoch:  390  	Training Loss: 0.04872065410017967
Test Loss:  0.06477268040180206
Valid Loss:  0.06437449157238007
Epoch:  391  	Training Loss: 0.04870739206671715
Test Loss:  0.06475258618593216
Valid Loss:  0.06435598433017731
Epoch:  392  	Training Loss: 0.04869414120912552
Test Loss:  0.06473225355148315
Valid Loss:  0.06433727592229843
Epoch:  393  	Training Loss: 0.04868074506521225
Test Loss:  0.06471193581819534
Valid Loss:  0.06431856751441956
Epoch:  394  	Training Loss: 0.04866735637187958
Test Loss:  0.06469161808490753
Valid Loss:  0.06429986655712128
Epoch:  395  	Training Loss: 0.048653971403837204
Test Loss:  0.06467130780220032
Valid Loss:  0.0642811581492424
Epoch:  396  	Training Loss: 0.04864058643579483
Test Loss:  0.0646509975194931
Valid Loss:  0.06426246464252472
Epoch:  397  	Training Loss: 0.04862721264362335
Test Loss:  0.06463070213794708
Valid Loss:  0.06424378603696823
Epoch:  398  	Training Loss: 0.048613838851451874
Test Loss:  0.06461040675640106
Valid Loss:  0.06422509253025055
Epoch:  399  	Training Loss: 0.048600465059280396
Test Loss:  0.06459012627601624
Valid Loss:  0.06420642137527466
Epoch:  400  	Training Loss: 0.04858710989356041
Test Loss:  0.06456984579563141
Valid Loss:  0.06418775767087936
Epoch:  401  	Training Loss: 0.04857374727725983
Test Loss:  0.06454958021640778
Valid Loss:  0.06416909396648407
Epoch:  402  	Training Loss: 0.04856039583683014
Test Loss:  0.0645298957824707
Valid Loss:  0.06415094435214996
Epoch:  403  	Training Loss: 0.048547402024269104
Test Loss:  0.06451021134853363
Valid Loss:  0.06413282454013824
Epoch:  404  	Training Loss: 0.048534415662288666
Test Loss:  0.06449053436517715
Valid Loss:  0.06411468982696533
Epoch:  405  	Training Loss: 0.048521436750888824
Test Loss:  0.06447087973356247
Valid Loss:  0.06409657001495361
Epoch:  406  	Training Loss: 0.04850846901535988
Test Loss:  0.06445121765136719
Valid Loss:  0.06407846510410309
Epoch:  407  	Training Loss: 0.04849550127983093
Test Loss:  0.0644315779209137
Valid Loss:  0.06406036019325256
Epoch:  408  	Training Loss: 0.04848254472017288
Test Loss:  0.0644119530916214
Valid Loss:  0.06404227018356323
Epoch:  409  	Training Loss: 0.04846959188580513
Test Loss:  0.0643923431634903
Valid Loss:  0.0640241950750351
Epoch:  410  	Training Loss: 0.048456646502017975
Test Loss:  0.064372718334198
Valid Loss:  0.06400612741708755
Epoch:  411  	Training Loss: 0.048443712294101715
Test Loss:  0.06435312330722809
Valid Loss:  0.06398805975914001
Epoch:  412  	Training Loss: 0.048430781811475754
Test Loss:  0.06433381140232086
Valid Loss:  0.06397025287151337
Epoch:  413  	Training Loss: 0.04841803014278412
Test Loss:  0.06431452184915543
Valid Loss:  0.0639524757862091
Epoch:  414  	Training Loss: 0.04840528964996338
Test Loss:  0.0642952173948288
Valid Loss:  0.06393468379974365
Epoch:  415  	Training Loss: 0.04839257150888443
Test Loss:  0.06427593529224396
Valid Loss:  0.06391693651676178
Epoch:  416  	Training Loss: 0.048379864543676376
Test Loss:  0.0642566904425621
Valid Loss:  0.0638991966843605
Epoch:  417  	Training Loss: 0.04836716130375862
Test Loss:  0.06423742324113846
Valid Loss:  0.06388145685195923
Epoch:  418  	Training Loss: 0.04835446923971176
Test Loss:  0.0642181783914566
Valid Loss:  0.06386372447013855
Epoch:  419  	Training Loss: 0.0483417883515358
Test Loss:  0.06419895589351654
Valid Loss:  0.06384602934122086
Epoch:  420  	Training Loss: 0.04832912236452103
Test Loss:  0.06417974829673767
Valid Loss:  0.06382834911346436
Epoch:  421  	Training Loss: 0.04831646382808685
Test Loss:  0.06416055560112
Valid Loss:  0.06381066143512726
Epoch:  422  	Training Loss: 0.04830382019281387
Test Loss:  0.0641409158706665
Valid Loss:  0.06379260122776031
Epoch:  423  	Training Loss: 0.04829089343547821
Test Loss:  0.0641213059425354
Valid Loss:  0.06377453356981277
Epoch:  424  	Training Loss: 0.048277974128723145
Test Loss:  0.0641016960144043
Valid Loss:  0.06375646591186523
Epoch:  425  	Training Loss: 0.04826505482196808
Test Loss:  0.0640820786356926
Valid Loss:  0.06373842060565948
Epoch:  426  	Training Loss: 0.04825214296579361
Test Loss:  0.06406249105930328
Valid Loss:  0.06372039020061493
Epoch:  427  	Training Loss: 0.048239246010780334
Test Loss:  0.06404291093349457
Valid Loss:  0.06370235979557037
Epoch:  428  	Training Loss: 0.04822634160518646
Test Loss:  0.06402333080768585
Valid Loss:  0.06368432939052582
Epoch:  429  	Training Loss: 0.048213452100753784
Test Loss:  0.06400376558303833
Valid Loss:  0.06366631388664246
Epoch:  430  	Training Loss: 0.0482005700469017
Test Loss:  0.063984215259552
Valid Loss:  0.0636482983827591
Epoch:  431  	Training Loss: 0.04818768799304962
Test Loss:  0.06396466493606567
Valid Loss:  0.06363029778003693
Epoch:  432  	Training Loss: 0.048174820840358734
Test Loss:   87%|████████▋ | 433/500 [05:03<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:03<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:03<00:28,  2.18it/s] 88%|████████▊ | 439/500 [05:03<00:21,  2.88it/s] 88%|████████▊ | 441/500 [05:10<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:10<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:10<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:10<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:10<00:17,  2.95it/s] 90%|█████████ | 451/500 [05:16<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:17<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:17<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:17<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:23<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:24<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:24<00:22,  1.59it/s] 93%|█████████▎| 467/500 [05:24<00:15,  2.15it/s] 94%|█████████▍| 469/500 [05:24<00:10,  2.88it/s] 94%|█████████▍| 471/500 [05:30<00:34,  1.21s/it] 95%|█████████▍| 473/500 [05:31<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:31<00:15,  1.60it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:31<00:07,  2.95it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:38<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:38<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:38<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:38<00:03,  2.94it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:45<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:45<00:03,  1.60it/s] 99%|█████████▉| 497/500 [05:45<00:01,  2.19it/s]100%|█████████▉| 499/500 [05:45<00:00,  2.94it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
0.06394502520561218
Valid Loss:  0.06361222267150879
Epoch:  433  	Training Loss: 0.04816189408302307
Test Loss:  0.06392539292573929
Valid Loss:  0.06359414011240005
Epoch:  434  	Training Loss: 0.048148974776268005
Test Loss:  0.0639057606458664
Valid Loss:  0.06357607245445251
Epoch:  435  	Training Loss: 0.04813605546951294
Test Loss:  0.0638861358165741
Valid Loss:  0.06355798989534378
Epoch:  436  	Training Loss: 0.048123136162757874
Test Loss:  0.0638664960861206
Valid Loss:  0.06353991478681564
Epoch:  437  	Training Loss: 0.04811021685600281
Test Loss:  0.06384687125682831
Valid Loss:  0.0635218471288681
Epoch:  438  	Training Loss: 0.04809730499982834
Test Loss:  0.06382725387811661
Valid Loss:  0.06350377947092056
Epoch:  439  	Training Loss: 0.04808439686894417
Test Loss:  0.0638076439499855
Valid Loss:  0.06348572671413422
Epoch:  440  	Training Loss: 0.048071496188640594
Test Loss:  0.0637880265712738
Valid Loss:  0.06346765160560608
Epoch:  441  	Training Loss: 0.048058584332466125
Test Loss:  0.0637684166431427
Valid Loss:  0.06344959139823914
Epoch:  442  	Training Loss: 0.04804567992687225
Test Loss:  0.06374900043010712
Valid Loss:  0.06343171000480652
Epoch:  443  	Training Loss: 0.04803289473056793
Test Loss:  0.06372959911823273
Valid Loss:  0.0634138435125351
Epoch:  444  	Training Loss: 0.048020124435424805
Test Loss:  0.06371022015810013
Valid Loss:  0.06339598447084427
Epoch:  445  	Training Loss: 0.048007361590862274
Test Loss:  0.06369082629680634
Valid Loss:  0.06337811797857285
Epoch:  446  	Training Loss: 0.047994598746299744
Test Loss:  0.06367145478725433
Valid Loss:  0.06336027383804321
Epoch:  447  	Training Loss: 0.04798184707760811
Test Loss:  0.06365210562944412
Valid Loss:  0.06334243714809418
Epoch:  448  	Training Loss: 0.04796910285949707
Test Loss:  0.06363274157047272
Valid Loss:  0.06332459300756454
Epoch:  449  	Training Loss: 0.04795636236667633
Test Loss:  0.0636133998632431
Valid Loss:  0.0633067637681961
Epoch:  450  	Training Loss: 0.047943614423274994
Test Loss:  0.06359405070543289
Valid Loss:  0.06328894942998886
Epoch:  451  	Training Loss: 0.04793088510632515
Test Loss:  0.06357471644878387
Valid Loss:  0.06327112019062042
Epoch:  452  	Training Loss: 0.047918159514665604
Test Loss:  0.06355573236942291
Valid Loss:  0.06325362622737885
Epoch:  453  	Training Loss: 0.04790563881397247
Test Loss:  0.06353674829006195
Valid Loss:  0.06323612481355667
Epoch:  454  	Training Loss: 0.04789312928915024
Test Loss:  0.06351777911186218
Valid Loss:  0.0632186308503151
Epoch:  455  	Training Loss: 0.0478806309401989
Test Loss:  0.06349881738424301
Valid Loss:  0.06320114433765411
Epoch:  456  	Training Loss: 0.04786812886595726
Test Loss:  0.06347985565662384
Valid Loss:  0.06318367272615433
Epoch:  457  	Training Loss: 0.047855645418167114
Test Loss:  0.06346093118190765
Valid Loss:  0.06316621601581573
Epoch:  458  	Training Loss: 0.04784316569566727
Test Loss:  0.06344199180603027
Valid Loss:  0.06314875185489655
Epoch:  459  	Training Loss: 0.047830693423748016
Test Loss:  0.06342306733131409
Valid Loss:  0.06313131004571915
Epoch:  460  	Training Loss: 0.04781822860240936
Test Loss:  0.06340416520833969
Valid Loss:  0.06311386823654175
Epoch:  461  	Training Loss: 0.04780576005578041
Test Loss:  0.06338527798652649
Valid Loss:  0.06309644877910614
Epoch:  462  	Training Loss: 0.04779331386089325
Test Loss:  0.06336551159620285
Valid Loss:  0.06307823956012726
Epoch:  463  	Training Loss: 0.047780320048332214
Test Loss:  0.06334571540355682
Valid Loss:  0.06306003034114838
Epoch:  464  	Training Loss: 0.04776734858751297
Test Loss:  0.06332597136497498
Valid Loss:  0.06304185092449188
Epoch:  465  	Training Loss: 0.04775437340140343
Test Loss:  0.06330621242523193
Valid Loss:  0.0630236566066742
Epoch:  466  	Training Loss: 0.04774140939116478
Test Loss:  0.06328645348548889
Valid Loss:  0.0630054846405983
Epoch:  467  	Training Loss: 0.04772844910621643
Test Loss:  0.06326669454574585
Valid Loss:  0.0629873126745224
Epoch:  468  	Training Loss: 0.04771549254655838
Test Loss:  0.0632469579577446
Valid Loss:  0.0629691481590271
Epoch:  469  	Training Loss: 0.04770255088806152
Test Loss:  0.06322722882032394
Valid Loss:  0.0629509910941124
Epoch:  470  	Training Loss: 0.04768960550427437
Test Loss:  0.06320750713348389
Valid Loss:  0.06293284893035889
Epoch:  471  	Training Loss: 0.047676678746938705
Test Loss:  0.06318779289722443
Valid Loss:  0.06291471421718597
Epoch:  472  	Training Loss: 0.047663744539022446
Test Loss:  0.06316855549812317
Valid Loss:  0.0628969669342041
Epoch:  473  	Training Loss: 0.04765108972787857
Test Loss:  0.06314930319786072
Valid Loss:  0.06287924945354462
Epoch:  474  	Training Loss: 0.04763844236731529
Test Loss:  0.06313005089759827
Valid Loss:  0.06286152452230453
Epoch:  475  	Training Loss: 0.04762579873204231
Test Loss:  0.06311081349849701
Valid Loss:  0.06284379959106445
Epoch:  476  	Training Loss: 0.04761316627264023
Test Loss:  0.06309159100055695
Valid Loss:  0.06282609701156616
Epoch:  477  	Training Loss: 0.04760054126381874
Test Loss:  0.06307238340377808
Valid Loss:  0.06280841678380966
Epoch:  478  	Training Loss: 0.04758792370557785
Test Loss:  0.0630531832575798
Valid Loss:  0.06279072165489197
Epoch:  479  	Training Loss: 0.047575317323207855
Test Loss:  0.06303398311138153
Valid Loss:  0.06277304887771606
Epoch:  480  	Training Loss: 0.04756271094083786
Test Loss:  0.06301480531692505
Valid Loss:  0.06275539100170135
Epoch:  481  	Training Loss: 0.04755011200904846
Test Loss:  0.06299562752246857
Valid Loss:  0.06273773312568665
Epoch:  482  	Training Loss: 0.04753752052783966
Test Loss:  0.06297650933265686
Valid Loss:  0.06272011995315552
Epoch:  483  	Training Loss: 0.04752495512366295
Test Loss:  0.06295739859342575
Valid Loss:  0.06270250678062439
Epoch:  484  	Training Loss: 0.047512397170066833
Test Loss:  0.06293828785419464
Valid Loss:  0.06268489360809326
Epoch:  485  	Training Loss: 0.04749983921647072
Test Loss:  0.06291918456554413
Valid Loss:  0.06266729533672333
Epoch:  486  	Training Loss: 0.0474872887134552
Test Loss:  0.0629001036286354
Valid Loss:  0.06264971196651459
Epoch:  487  	Training Loss: 0.04747474938631058
Test Loss:  0.06288103014230728
Valid Loss:  0.06263212114572525
Epoch:  488  	Training Loss: 0.047462210059165955
Test Loss:  0.06286194920539856
Valid Loss:  0.0626145526766777
Epoch:  489  	Training Loss: 0.04744967818260193
Test Loss:  0.06284289062023163
Valid Loss:  0.06259698420763016
Epoch:  490  	Training Loss: 0.0474371537566185
Test Loss:  0.0628238320350647
Valid Loss:  0.06257942318916321
Epoch:  491  	Training Loss: 0.04742463678121567
Test Loss:  0.06280480325222015
Valid Loss:  0.06256187707185745
Epoch:  492  	Training Loss: 0.04741212725639343
Test Loss:  0.06278593838214874
Valid Loss:  0.06254450976848602
Epoch:  493  	Training Loss: 0.04739972949028015
Test Loss:  0.06276709586381912
Valid Loss:  0.0625271275639534
Epoch:  494  	Training Loss: 0.04738735035061836
Test Loss:  0.0627482607960701
Valid Loss:  0.06250976771116257
Epoch:  495  	Training Loss: 0.047374971210956573
Test Loss:  0.06272943317890167
Valid Loss:  0.06249241530895233
Epoch:  496  	Training Loss: 0.04736260324716568
Test Loss:  0.06271062046289444
Valid Loss:  0.06247508525848389
Epoch:  497  	Training Loss: 0.047350235283374786
Test Loss:  0.06269180774688721
Valid Loss:  0.06245773658156395
Epoch:  498  	Training Loss: 0.04733787477016449
Test Loss:  0.06267301738262177
Valid Loss:  0.0624404139816761
Epoch:  499  	Training Loss: 0.04732552170753479
Test Loss:  0.06265422701835632
Valid Loss:  0.062423091381788254
Epoch:  500  	Training Loss: 0.04731317609548569
Test Loss:  0.06263545155525208
Valid Loss:  0.0624057836830616
seed is  11
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:07,  6.15s/it]  1%|          | 3/500 [00:06<13:44,  1.66s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:56,  2.78it/s]  2%|▏         | 11/500 [00:13<10:57,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:36,  1.20s/it]  5%|▍         | 23/500 [00:20<06:49,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  3.00it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:10,  1.20s/it]  9%|▊         | 43/500 [00:33<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:43,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.19it/s] 10%|▉         | 49/500 [00:34<02:32,  2.95it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.24it/s] 12%|█▏        | 59/500 [00:41<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:47<08:33,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:07,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:24,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.02it/s] 14%|█▍        | 71/500 [00:54<08:21,  1.17s/it]Epoch:  1  	Training Loss: 0.029232734814286232
Test Loss:  0.02130424976348877
Valid Loss:  0.029923003166913986
Epoch:  2  	Training Loss: 0.04515428841114044
Test Loss:  0.09003569185733795
Valid Loss:  0.08433026075363159
Epoch:  3  	Training Loss: 0.0652109831571579
Test Loss:  0.034471072256565094
Valid Loss:  0.037173423916101456
Epoch:  4  	Training Loss: 0.03024705871939659
Test Loss:  0.035532716661691666
Valid Loss:  0.03635065257549286
Epoch:  5  	Training Loss: 0.02891712076961994
Test Loss:  0.03365033119916916
Valid Loss:  0.03583965077996254
Epoch:  6  	Training Loss: 0.02840208262205124
Test Loss:  0.034253139048814774
Valid Loss:  0.03538477420806885
Epoch:  7  	Training Loss: 0.027764473110437393
Test Loss:  0.03305739536881447
Valid Loss:  0.03493490070104599
Epoch:  8  	Training Loss: 0.027228916063904762
Test Loss:  0.033226922154426575
Valid Loss:  0.03457169234752655
Epoch:  9  	Training Loss: 0.0268428735435009
Test Loss:  0.03246970474720001
Valid Loss:  0.03423622250556946
Epoch:  10  	Training Loss: 0.026483651250600815
Test Loss:  0.03255998343229294
Valid Loss:  0.03387914597988129
Epoch:  11  	Training Loss: 0.026056673377752304
Test Loss:  0.03194097429513931
Valid Loss:  0.03354532644152641
Epoch:  12  	Training Loss: 0.025729693472385406
Test Loss:  0.031939588487148285
Valid Loss:  0.033209607005119324
Epoch:  13  	Training Loss: 0.025353197008371353
Test Loss:  0.03147566691040993
Valid Loss:  0.03288368135690689
Epoch:  14  	Training Loss: 0.025028478354215622
Test Loss:  0.03138386458158493
Valid Loss:  0.032575152814388275
Epoch:  15  	Training Loss: 0.024721689522266388
Test Loss:  0.030902322381734848
Valid Loss:  0.03226001560688019
Epoch:  16  	Training Loss: 0.024420730769634247
Test Loss:  0.03078662045300007
Valid Loss:  0.03195575252175331
Epoch:  17  	Training Loss: 0.024112775921821594
Test Loss:  0.030439987778663635
Valid Loss:  0.03165315091609955
Epoch:  18  	Training Loss: 0.023823115974664688
Test Loss:  0.030220430344343185
Valid Loss:  0.03135932981967926
Epoch:  19  	Training Loss: 0.023544885218143463
Test Loss:  0.029881270602345467
Valid Loss:  0.03106256201863289
Epoch:  20  	Training Loss: 0.023271936923265457
Test Loss:  0.02968115732073784
Valid Loss:  0.030778121203184128
Epoch:  21  	Training Loss: 0.02300252951681614
Test Loss:  0.029356978833675385
Valid Loss:  0.030487217009067535
Epoch:  22  	Training Loss: 0.02274147793650627
Test Loss:  0.029126137495040894
Valid Loss:  0.030207887291908264
Epoch:  23  	Training Loss: 0.022483933717012405
Test Loss:  0.028868842869997025
Valid Loss:  0.029929151758551598
Epoch:  24  	Training Loss: 0.022233005613088608
Test Loss:  0.028598841279745102
Valid Loss:  0.029651688411831856
Epoch:  25  	Training Loss: 0.021986404433846474
Test Loss:  0.028325073421001434
Valid Loss:  0.029376165941357613
Epoch:  26  	Training Loss: 0.021743401885032654
Test Loss:  0.02805173769593239
Valid Loss:  0.029103070497512817
Epoch:  27  	Training Loss: 0.021503757685422897
Test Loss:  0.02778092585504055
Valid Loss:  0.028832674026489258
Epoch:  28  	Training Loss: 0.0212673582136631
Test Loss:  0.027512112632393837
Valid Loss:  0.028565095737576485
Epoch:  29  	Training Loss: 0.021034374833106995
Test Loss:  0.027259252965450287
Valid Loss:  0.028302419930696487
Epoch:  30  	Training Loss: 0.02080538123846054
Test Loss:  0.02700544334948063
Valid Loss:  0.028041822835803032
Epoch:  31  	Training Loss: 0.020579710602760315
Test Loss:  0.026750929653644562
Valid Loss:  0.02778337523341179
Epoch:  32  	Training Loss: 0.020357470959424973
Test Loss:  0.02651907689869404
Valid Loss:  0.027531512081623077
Epoch:  33  	Training Loss: 0.020138543099164963
Test Loss:  0.02626638114452362
Valid Loss:  0.0272771418094635
Epoch:  34  	Training Loss: 0.019922977313399315
Test Loss:  0.026027675718069077
Valid Loss:  0.027028003707528114
Epoch:  35  	Training Loss: 0.01971043087542057
Test Loss:  0.025785353034734726
Valid Loss:  0.02678000181913376
Epoch:  36  	Training Loss: 0.01950078085064888
Test Loss:  0.025543347001075745
Valid Loss:  0.026534035801887512
Epoch:  37  	Training Loss: 0.0192941352725029
Test Loss:  0.02531110867857933
Valid Loss:  0.026292365044355392
Epoch:  38  	Training Loss: 0.019090360030531883
Test Loss:  0.025075502693653107
Valid Loss:  0.026051726192235947
Epoch:  39  	Training Loss: 0.018889304250478745
Test Loss:  0.024839159101247787
Valid Loss:  0.025812719017267227
Epoch:  40  	Training Loss: 0.018690738826990128
Test Loss:  0.024603765457868576
Valid Loss:  0.02557571604847908
Epoch:  41  	Training Loss: 0.018494583666324615
Test Loss:  0.02437114715576172
Valid Loss:  0.025340884923934937
Epoch:  42  	Training Loss: 0.018300775438547134
Test Loss:  0.024139966815710068
Valid Loss:  0.02510773576796055
Epoch:  43  	Training Loss: 0.01810888573527336
Test Loss:  0.023910799995064735
Valid Loss:  0.024876778945326805
Epoch:  44  	Training Loss: 0.017919182777404785
Test Loss:  0.023683927953243256
Valid Loss:  0.024648034945130348
Epoch:  45  	Training Loss: 0.017731642350554466
Test Loss:  0.023460358381271362
Valid Loss:  0.02442150190472603
Epoch:  46  	Training Loss: 0.017546458169817924
Test Loss:  0.023244889453053474
Valid Loss:  0.02419927343726158
Epoch:  47  	Training Loss: 0.01736360788345337
Test Loss:  0.023029537871479988
Valid Loss:  0.023978468030691147
Epoch:  48  	Training Loss: 0.017183000221848488
Test Loss:  0.022814258933067322
Valid Loss:  0.02375904843211174
Epoch:  49  	Training Loss: 0.017004474997520447
Test Loss:  0.02259993553161621
Valid Loss:  0.02354133501648903
Epoch:  50  	Training Loss: 0.016827967017889023
Test Loss:  0.022387074306607246
Valid Loss:  0.02332550287246704
Epoch:  51  	Training Loss: 0.01665368303656578
Test Loss:  0.022182099521160126
Valid Loss:  0.023113977164030075
Epoch:  52  	Training Loss: 0.01648145727813244
Test Loss:  0.021976687014102936
Valid Loss:  0.02290395088493824
Epoch:  53  	Training Loss: 0.01631171815097332
Test Loss:  0.02177150547504425
Valid Loss:  0.022695306688547134
Epoch:  54  	Training Loss: 0.01614394597709179
Test Loss:  0.021567367017269135
Valid Loss:  0.022488338872790337
Epoch:  55  	Training Loss: 0.015978094190359116
Test Loss:  0.02136470191180706
Valid Loss:  0.022283215075731277
Epoch:  56  	Training Loss: 0.01581411622464657
Test Loss:  0.021163739264011383
Valid Loss:  0.02208000048995018
Epoch:  57  	Training Loss: 0.015651989728212357
Test Loss:  0.020964616909623146
Valid Loss:  0.021878762170672417
Epoch:  58  	Training Loss: 0.015491695143282413
Test Loss:  0.020767368376255035
Valid Loss:  0.021679475903511047
Epoch:  59  	Training Loss: 0.015333205461502075
Test Loss:  0.020572040230035782
Valid Loss:  0.021482162177562714
Epoch:  60  	Training Loss: 0.015176496468484402
Test Loss:  0.020378626883029938
Valid Loss:  0.021286796778440475
Epoch:  61  	Training Loss: 0.015021548606455326
Test Loss:  0.0201871357858181
Valid Loss:  0.02109338343143463
Epoch:  62  	Training Loss: 0.014868346974253654
Test Loss:  0.019997525960206985
Valid Loss:  0.020901856943964958
Epoch:  63  	Training Loss: 0.014716800302267075
Test Loss:  0.01980983093380928
Valid Loss:  0.020712265744805336
Epoch:  64  	Training Loss: 0.014566976577043533
Test Loss:  0.019624030217528343
Valid Loss:  0.020524591207504272
Epoch:  65  	Training Loss: 0.014418854378163815
Test Loss:  0.01944011077284813
Valid Loss:  0.020338810980319977
Epoch:  66  	Training Loss: 0.014272412285208702
Test Loss:  0.019258052110671997
Valid Loss:  0.020154908299446106
Epoch:  67  	Training Loss: 0.014127625152468681
Test Loss:  0.019077837467193604
Valid Loss:  0.01997285708785057
Epoch:  68  	Training Loss: 0.013984479010105133
Test Loss:  0.01889943704009056
Valid Loss:  0.01979263685643673
Epoch:  69  	Training Loss: 0.013842945918440819
Test Loss:  0.018722843378782272
Valid Loss:  0.01961423084139824
Epoch:  70  	Training Loss: 0.01370301190763712
Test Loss:  0.01854803040623665
Valid Loss:  0.019437618553638458
Epoch:  71  	Training Loss: 0.01356465183198452
Test Loss:  0.018374979496002197
Valid Loss:  0.019262775778770447
Epoch:  72  	Training Loss: 0.013427851721644402
 15%|█▍        | 73/500 [00:54<05:58,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:18,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.25it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.03it/s] 16%|█▌        | 81/500 [01:01<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:01<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:01<04:21,  1.59it/s] 17%|█▋        | 87/500 [01:01<03:11,  2.16it/s] 18%|█▊        | 89/500 [01:01<02:21,  2.91it/s] 18%|█▊        | 91/500 [01:08<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:50,  1.18s/it] 21%|██        | 103/500 [01:15<05:36,  1.18it/s] 21%|██        | 105/500 [01:15<04:01,  1.63it/s] 21%|██▏       | 107/500 [01:15<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:15<02:12,  2.96it/s] 22%|██▏       | 111/500 [01:21<07:47,  1.20s/it] 23%|██▎       | 113/500 [01:22<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:22<03:59,  1.60it/s] 23%|██▎       | 117/500 [01:22<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:22<02:08,  2.95it/s] 24%|██▍       | 121/500 [01:28<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.97it/s] 26%|██▌       | 131/500 [01:35<07:24,  1.20s/it] 27%|██▋       | 133/500 [01:35<05:17,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:36<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:36<02:02,  2.95it/s] 28%|██▊       | 141/500 [01:42<07:11,  1.20s/it]Test Loss:  0.018203895539045334
Valid Loss:  0.019089756533503532
Epoch:  73  	Training Loss: 0.013292666524648666
Test Loss:  0.01803477853536606
Valid Loss:  0.018918460234999657
Epoch:  74  	Training Loss: 0.013158991932868958
Test Loss:  0.01786736026406288
Valid Loss:  0.01874888315796852
Epoch:  75  	Training Loss: 0.013026820495724678
Test Loss:  0.017701618373394012
Valid Loss:  0.018581002950668335
Epoch:  76  	Training Loss: 0.012896127998828888
Test Loss:  0.017537549138069153
Valid Loss:  0.01841478794813156
Epoch:  77  	Training Loss: 0.012766893953084946
Test Loss:  0.01737513393163681
Valid Loss:  0.018250228837132454
Epoch:  78  	Training Loss: 0.012639102526009083
Test Loss:  0.017214331775903702
Valid Loss:  0.018087316304445267
Epoch:  79  	Training Loss: 0.01251273788511753
Test Loss:  0.01705511100590229
Valid Loss:  0.017926007509231567
Epoch:  80  	Training Loss: 0.012387776747345924
Test Loss:  0.01689748466014862
Valid Loss:  0.01776631735265255
Epoch:  81  	Training Loss: 0.012264285236597061
Test Loss:  0.0167439803481102
Valid Loss:  0.01760939508676529
Epoch:  82  	Training Loss: 0.012142134830355644
Test Loss:  0.016590535640716553
Valid Loss:  0.017453240230679512
Epoch:  83  	Training Loss: 0.012021277099847794
Test Loss:  0.01643790304660797
Valid Loss:  0.017298273742198944
Epoch:  84  	Training Loss: 0.01190175861120224
Test Loss:  0.016286635771393776
Valid Loss:  0.01714475452899933
Epoch:  85  	Training Loss: 0.011783565394580364
Test Loss:  0.01613648608326912
Valid Loss:  0.01699255406856537
Epoch:  86  	Training Loss: 0.011666701175272465
Test Loss:  0.015990326181054115
Valid Loss:  0.016843046993017197
Epoch:  87  	Training Loss: 0.011551126837730408
Test Loss:  0.015841398388147354
Valid Loss:  0.016692940145730972
Epoch:  88  	Training Loss: 0.011436806991696358
Test Loss:  0.015697110444307327
Valid Loss:  0.01654585637152195
Epoch:  89  	Training Loss: 0.01132374256849289
Test Loss:  0.015553162433207035
Valid Loss:  0.016399668529629707
Epoch:  90  	Training Loss: 0.011211930774152279
Test Loss:  0.015410054475069046
Valid Loss:  0.0162546057254076
Epoch:  91  	Training Loss: 0.011101328767836094
Test Loss:  0.015268008224666119
Valid Loss:  0.016110774129629135
Epoch:  92  	Training Loss: 0.010991920717060566
Test Loss:  0.015127064660191536
Valid Loss:  0.015968147665262222
Epoch:  93  	Training Loss: 0.010883606970310211
Test Loss:  0.014987392351031303
Valid Loss:  0.015826847404241562
Epoch:  94  	Training Loss: 0.010776462964713573
Test Loss:  0.014849024824798107
Valid Loss:  0.015686877071857452
Epoch:  95  	Training Loss: 0.010670468211174011
Test Loss:  0.014711994677782059
Valid Loss:  0.015548263676464558
Epoch:  96  	Training Loss: 0.010565616190433502
Test Loss:  0.014576289802789688
Valid Loss:  0.015410996042191982
Epoch:  97  	Training Loss: 0.010461898520588875
Test Loss:  0.014441892504692078
Valid Loss:  0.015275043435394764
Epoch:  98  	Training Loss: 0.010359290987253189
Test Loss:  0.014308802783489227
Valid Loss:  0.015140409581363201
Epoch:  99  	Training Loss: 0.010257785208523273
Test Loss:  0.014177017845213413
Valid Loss:  0.015007071197032928
Epoch:  100  	Training Loss: 0.010157372802495956
Test Loss:  0.014046518132090569
Valid Loss:  0.014875028282403946
Epoch:  101  	Training Loss: 0.010058034211397171
Test Loss:  0.013917302712798119
Valid Loss:  0.014744268730282784
Epoch:  102  	Training Loss: 0.009959762915968895
Test Loss:  0.013789519667625427
Valid Loss:  0.014614958316087723
Epoch:  103  	Training Loss: 0.009862681850790977
Test Loss:  0.013662982732057571
Valid Loss:  0.014486890286207199
Epoch:  104  	Training Loss: 0.009766637347638607
Test Loss:  0.013537676073610783
Valid Loss:  0.014360049739480019
Epoch:  105  	Training Loss: 0.009671615436673164
Test Loss:  0.013413578271865845
Valid Loss:  0.014234418049454689
Epoch:  106  	Training Loss: 0.009577593766152859
Test Loss:  0.013290686532855034
Valid Loss:  0.014109991490840912
Epoch:  107  	Training Loss: 0.009484573267400265
Test Loss:  0.01316898688673973
Valid Loss:  0.01398676261305809
Epoch:  108  	Training Loss: 0.009392539970576763
Test Loss:  0.013048461638391018
Valid Loss:  0.013864702545106411
Epoch:  109  	Training Loss: 0.009301477111876011
Test Loss:  0.012929107062518597
Valid Loss:  0.013743816874921322
Epoch:  110  	Training Loss: 0.009211382828652859
Test Loss:  0.01281091757118702
Valid Loss:  0.013624079525470734
Epoch:  111  	Training Loss: 0.009122241288423538
Test Loss:  0.012693862430751324
Valid Loss:  0.013505486771464348
Epoch:  112  	Training Loss: 0.009034044109284878
Test Loss:  0.012578118592500687
Valid Loss:  0.013388190418481827
Epoch:  113  	Training Loss: 0.008946888148784637
Test Loss:  0.012463495135307312
Valid Loss:  0.013272018171846867
Epoch:  114  	Training Loss: 0.008860659785568714
Test Loss:  0.012349989265203476
Valid Loss:  0.013156957924365997
Epoch:  115  	Training Loss: 0.00877534318715334
Test Loss:  0.012237576767802238
Valid Loss:  0.013042988255620003
Epoch:  116  	Training Loss: 0.008690926246345043
Test Loss:  0.012126244604587555
Valid Loss:  0.012930100783705711
Epoch:  117  	Training Loss: 0.008607395924627781
Test Loss:  0.012015998363494873
Valid Loss:  0.012818294577300549
Epoch:  118  	Training Loss: 0.008524752222001553
Test Loss:  0.011906817555427551
Valid Loss:  0.01270755473524332
Epoch:  119  	Training Loss: 0.008442978374660015
Test Loss:  0.011798697523772717
Valid Loss:  0.012597864493727684
Epoch:  120  	Training Loss: 0.008362066000699997
Test Loss:  0.011691628023982048
Valid Loss:  0.01248922012746334
Epoch:  121  	Training Loss: 0.008282006718218327
Test Loss:  0.011585579253733158
Valid Loss:  0.01238160114735365
Epoch:  122  	Training Loss: 0.008202784694731236
Test Loss:  0.011480435729026794
Valid Loss:  0.012274879030883312
Epoch:  123  	Training Loss: 0.00812431052327156
Test Loss:  0.01137632131576538
Valid Loss:  0.012169184163212776
Epoch:  124  	Training Loss: 0.008046667091548443
Test Loss:  0.011273220181465149
Valid Loss:  0.01206449419260025
Epoch:  125  	Training Loss: 0.007969840429723263
Test Loss:  0.011171114630997181
Valid Loss:  0.011960799805819988
Epoch:  126  	Training Loss: 0.007893821224570274
Test Loss:  0.011070000007748604
Valid Loss:  0.011858085170388222
Epoch:  127  	Training Loss: 0.00781860388815403
Test Loss:  0.010969866067171097
Valid Loss:  0.01175635028630495
Epoch:  128  	Training Loss: 0.00774417445063591
Test Loss:  0.010870705358684063
Valid Loss:  0.011655587702989578
Epoch:  129  	Training Loss: 0.007670527324080467
Test Loss:  0.010772505775094032
Valid Loss:  0.011555776000022888
Epoch:  130  	Training Loss: 0.007597656920552254
Test Loss:  0.010675261728465557
Valid Loss:  0.011456917971372604
Epoch:  131  	Training Loss: 0.007525552995502949
Test Loss:  0.010578947141766548
Valid Loss:  0.01135898195207119
Epoch:  132  	Training Loss: 0.00745419692248106
Test Loss:  0.010483864694833755
Valid Loss:  0.011262264102697372
Epoch:  133  	Training Loss: 0.007383786141872406
Test Loss:  0.01038968563079834
Valid Loss:  0.011166452430188656
Epoch:  134  	Training Loss: 0.007314109243452549
Test Loss:  0.010296404361724854
Valid Loss:  0.011071526445448399
Epoch:  135  	Training Loss: 0.00724515225738287
Test Loss:  0.010204022750258446
Valid Loss:  0.010977501980960369
Epoch:  136  	Training Loss: 0.007176912855356932
Test Loss:  0.010112522169947624
Valid Loss:  0.010884357616305351
Epoch:  137  	Training Loss: 0.007109384052455425
Test Loss:  0.010021894238889217
Valid Loss:  0.0107920803129673
Epoch:  138  	Training Loss: 0.007042554207146168
Test Loss:  0.00993213802576065
Valid Loss:  0.010700669139623642
Epoch:  139  	Training Loss: 0.006976417265832424
Test Loss:  0.009843251667916775
Valid Loss:  0.010610111057758331
Epoch:  140  	Training Loss: 0.006910966243594885
Test Loss:  0.00975521095097065
Valid Loss:  0.010520403273403645
Epoch:  141  	Training Loss: 0.00684619415551424
Test Loss:  0.009668014943599701
Valid Loss:  0.010431535542011261
Epoch:  142  	Training Loss: 0.006782091222703457
Test Loss:  0.009581618942320347
Valid Loss:  0.010343456640839577
 29%|██▊       | 143/500 [01:42<05:07,  1.16it/s] 29%|██▉       | 145/500 [01:43<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:43<02:40,  2.19it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.96it/s] 30%|███       | 151/500 [01:49<06:52,  1.18s/it] 31%|███       | 153/500 [01:49<04:54,  1.18it/s] 31%|███       | 155/500 [01:49<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:50<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:56<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:45,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:56<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:03<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:03<04:38,  1.18it/s] 35%|███▌      | 175/500 [02:03<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:03<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:10<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:10<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:10<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:16<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:17<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:17<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:17<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:17<01:40,  3.00it/s] 40%|████      | 201/500 [02:23<05:56,  1.19s/it] 41%|████      | 203/500 [02:24<04:13,  1.17it/s] 41%|████      | 205/500 [02:24<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:24<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:24<01:37,  2.97it/s] 42%|████▏     | 211/500 [02:30<05:38,  1.17s/it]Epoch:  143  	Training Loss: 0.0067186239175498486
Test Loss:  0.009496049955487251
Valid Loss:  0.010256199166178703
Epoch:  144  	Training Loss: 0.006655813194811344
Test Loss:  0.009411312639713287
Valid Loss:  0.010169773362576962
Epoch:  145  	Training Loss: 0.006593658123165369
Test Loss:  0.009327388368546963
Valid Loss:  0.010084150359034538
Epoch:  146  	Training Loss: 0.006532146129757166
Test Loss:  0.009244270622730255
Valid Loss:  0.009999332018196583
Epoch:  147  	Training Loss: 0.006471268832683563
Test Loss:  0.00916194636374712
Valid Loss:  0.009915296919643879
Epoch:  148  	Training Loss: 0.0064110239036381245
Test Loss:  0.009080415591597557
Valid Loss:  0.009832054376602173
Epoch:  149  	Training Loss: 0.0063514006324112415
Test Loss:  0.008999673649668694
Valid Loss:  0.009749592281877995
Epoch:  150  	Training Loss: 0.006292395759373903
Test Loss:  0.008919700048863888
Valid Loss:  0.009667889215052128
Epoch:  151  	Training Loss: 0.006233996246010065
Test Loss:  0.008840495720505714
Valid Loss:  0.009586956351995468
Epoch:  152  	Training Loss: 0.00617620162665844
Test Loss:  0.008762005716562271
Valid Loss:  0.009506729431450367
Epoch:  153  	Training Loss: 0.006118968594819307
Test Loss:  0.008684273809194565
Valid Loss:  0.009427251294255257
Epoch:  154  	Training Loss: 0.006062326021492481
Test Loss:  0.008607286959886551
Valid Loss:  0.009348509833216667
Epoch:  155  	Training Loss: 0.006006269715726376
Test Loss:  0.008531042374670506
Valid Loss:  0.00927051343023777
Epoch:  156  	Training Loss: 0.0059507908299565315
Test Loss:  0.008455533534288406
Valid Loss:  0.009193239733576775
Epoch:  157  	Training Loss: 0.0058958875015378
Test Loss:  0.008380753919482231
Valid Loss:  0.00911669060587883
Epoch:  158  	Training Loss: 0.005841552279889584
Test Loss:  0.008306698873639107
Valid Loss:  0.00904085673391819
Epoch:  159  	Training Loss: 0.005787776783108711
Test Loss:  0.00823335163295269
Valid Loss:  0.008965732529759407
Epoch:  160  	Training Loss: 0.005734558217227459
Test Loss:  0.008160719648003578
Valid Loss:  0.00889130961149931
Epoch:  161  	Training Loss: 0.005681890528649092
Test Loss:  0.008088777773082256
Valid Loss:  0.008817572146654129
Epoch:  162  	Training Loss: 0.005629760213196278
Test Loss:  0.008017376065254211
Valid Loss:  0.008744379505515099
Epoch:  163  	Training Loss: 0.00557808019220829
Test Loss:  0.007946670986711979
Valid Loss:  0.00867187324911356
Epoch:  164  	Training Loss: 0.005526929162442684
Test Loss:  0.007876638323068619
Valid Loss:  0.0086000245064497
Epoch:  165  	Training Loss: 0.0054763020016252995
Test Loss:  0.007807279005646706
Valid Loss:  0.008528848178684711
Epoch:  166  	Training Loss: 0.005426192190498114
Test Loss:  0.0077385869808495045
Valid Loss:  0.0084583330899477
Epoch:  167  	Training Loss: 0.00537659740075469
Test Loss:  0.00767055107280612
Valid Loss:  0.008388468064367771
Epoch:  168  	Training Loss: 0.0053275106474757195
Test Loss:  0.00760316289961338
Valid Loss:  0.008319242857396603
Epoch:  169  	Training Loss: 0.005278920289129019
Test Loss:  0.0075364182703197
Valid Loss:  0.008250657469034195
Epoch:  170  	Training Loss: 0.005230829585343599
Test Loss:  0.007470318116247654
Valid Loss:  0.008182711899280548
Epoch:  171  	Training Loss: 0.005183230619877577
Test Loss:  0.0074048470705747604
Valid Loss:  0.008115381933748722
Epoch:  172  	Training Loss: 0.0051361145451664925
Test Loss:  0.007340226322412491
Valid Loss:  0.008048895746469498
Epoch:  173  	Training Loss: 0.0050896164029836655
Test Loss:  0.007276213727891445
Valid Loss:  0.007983023300766945
Epoch:  174  	Training Loss: 0.00504359370097518
Test Loss:  0.007212803699076176
Valid Loss:  0.007917743176221848
Epoch:  175  	Training Loss: 0.004998033866286278
Test Loss:  0.007149944081902504
Valid Loss:  0.007853035815060139
Epoch:  176  	Training Loss: 0.0049529410898685455
Test Loss:  0.007087306119501591
Valid Loss:  0.007788750343024731
Epoch:  177  	Training Loss: 0.004908312112092972
Test Loss:  0.0070254928432404995
Valid Loss:  0.00772517267614603
Epoch:  178  	Training Loss: 0.004864146467298269
Test Loss:  0.006964385509490967
Valid Loss:  0.007662241812795401
Epoch:  179  	Training Loss: 0.004820430185645819
Test Loss:  0.006903942674398422
Valid Loss:  0.007599928416311741
Epoch:  180  	Training Loss: 0.004777158610522747
Test Loss:  0.006844109855592251
Valid Loss:  0.0075382050126791
Epoch:  181  	Training Loss: 0.004734330344945192
Test Loss:  0.006784867960959673
Valid Loss:  0.007477044127881527
Epoch:  182  	Training Loss: 0.00469193747267127
Test Loss:  0.006725681945681572
Valid Loss:  0.00741613982245326
Epoch:  183  	Training Loss: 0.004649873357266188
Test Loss:  0.006667214445769787
Valid Loss:  0.007355859968811274
Epoch:  184  	Training Loss: 0.004608237184584141
Test Loss:  0.006609425414353609
Valid Loss:  0.007296190597116947
Epoch:  185  	Training Loss: 0.004567026160657406
Test Loss:  0.006552253849804401
Valid Loss:  0.007237106095999479
Epoch:  186  	Training Loss: 0.004526229575276375
Test Loss:  0.006495661102235317
Valid Loss:  0.007178565487265587
Epoch:  187  	Training Loss: 0.004485840909183025
Test Loss:  0.006439629476517439
Valid Loss:  0.0071205757558345795
Epoch:  188  	Training Loss: 0.004445867612957954
Test Loss:  0.006384135689586401
Valid Loss:  0.0070631117559969425
Epoch:  189  	Training Loss: 0.004406291991472244
Test Loss:  0.006329173222184181
Valid Loss:  0.007006173953413963
Epoch:  190  	Training Loss: 0.0043671149760484695
Test Loss:  0.006274728570133448
Valid Loss:  0.006949751637876034
Epoch:  191  	Training Loss: 0.0043283309787511826
Test Loss:  0.006220804061740637
Valid Loss:  0.006893837824463844
Epoch:  192  	Training Loss: 0.004289938136935234
Test Loss:  0.006166702136397362
Valid Loss:  0.006837751716375351
Epoch:  193  	Training Loss: 0.004251508973538876
Test Loss:  0.006113131530582905
Valid Loss:  0.006782184820622206
Epoch:  194  	Training Loss: 0.004213469102978706
Test Loss:  0.006060092244297266
Valid Loss:  0.006727126892656088
Epoch:  195  	Training Loss: 0.004175814799964428
Test Loss:  0.006007554940879345
Valid Loss:  0.006672579795122147
Epoch:  196  	Training Loss: 0.004138541873544455
Test Loss:  0.005955532193183899
Valid Loss:  0.006618528626859188
Epoch:  197  	Training Loss: 0.004101648461073637
Test Loss:  0.0059039960615336895
Valid Loss:  0.0065649691969156265
Epoch:  198  	Training Loss: 0.004065124783664942
Test Loss:  0.005852960981428623
Valid Loss:  0.006511897314339876
Epoch:  199  	Training Loss: 0.004028971306979656
Test Loss:  0.005802406929433346
Valid Loss:  0.006459309719502926
Epoch:  200  	Training Loss: 0.003993183374404907
Test Loss:  0.005752336233854294
Valid Loss:  0.006407204084098339
Epoch:  201  	Training Loss: 0.003957756794989109
Test Loss:  0.00570274330675602
Valid Loss:  0.0063555617816746235
Epoch:  202  	Training Loss: 0.0039226822555065155
Test Loss:  0.005654370412230492
Valid Loss:  0.006305147428065538
Epoch:  203  	Training Loss: 0.003888437757268548
Test Loss:  0.005606436170637608
Valid Loss:  0.006255175918340683
Epoch:  204  	Training Loss: 0.0038545317947864532
Test Loss:  0.005558944307267666
Valid Loss:  0.0062056537717580795
Epoch:  205  	Training Loss: 0.003820965299382806
Test Loss:  0.0055118948221206665
Valid Loss:  0.0061565665528178215
Epoch:  206  	Training Loss: 0.003787733381614089
Test Loss:  0.0054652877151966095
Valid Loss:  0.006107919383794069
Epoch:  207  	Training Loss: 0.0037548327818512917
Test Loss:  0.005419136490672827
Valid Loss:  0.006059708539396524
Epoch:  208  	Training Loss: 0.003722259309142828
Test Loss:  0.005373427644371986
Valid Loss:  0.006011928431689739
Epoch:  209  	Training Loss: 0.003690010402351618
Test Loss:  0.005328146740794182
Valid Loss:  0.005964574404060841
Epoch:  210  	Training Loss: 0.0036580851301550865
Test Loss:  0.005283288192003965
Valid Loss:  0.005917646922171116
Epoch:  211  	Training Loss: 0.0036264751106500626
Test Loss:  0.005238849204033613
Valid Loss:  0.005871136207133532
Epoch:  212  	Training Loss: 0.003595177549868822
Test Loss:  0.005194633733481169
Valid Loss:  0.005824847146868706
 43%|████▎     | 213/500 [02:30<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:31<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:31<01:36,  2.91it/s] 44%|████▍     | 221/500 [02:37<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:37<03:53,  1.18it/s] 45%|████▌     | 225/500 [02:37<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:38<01:30,  3.01it/s] 46%|████▌     | 231/500 [02:44<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:44<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:44<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:51<05:04,  1.17s/it] 49%|████▊     | 243/500 [02:51<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:51<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:51<01:53,  2.24it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.01it/s] 50%|█████     | 251/500 [02:58<04:54,  1.18s/it] 51%|█████     | 253/500 [02:58<03:29,  1.18it/s] 51%|█████     | 255/500 [02:58<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:58<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:58<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:05<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:05<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:05<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:05<01:46,  2.20it/s] 54%|█████▍    | 269/500 [03:05<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:11<04:33,  1.20s/it] 55%|█████▍    | 273/500 [03:12<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:12<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:12<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:12<01:14,  2.97it/s] 56%|█████▌    | 281/500 [03:18<04:18,  1.18s/it]Epoch:  213  	Training Loss: 0.0035640723071992397
Test Loss:  0.0051508331671357155
Valid Loss:  0.005778973922133446
Epoch:  214  	Training Loss: 0.003533274633809924
Test Loss:  0.005107451230287552
Valid Loss:  0.005733512807637453
Epoch:  215  	Training Loss: 0.0035027828998863697
Test Loss:  0.005064478609710932
Valid Loss:  0.005688451696187258
Epoch:  216  	Training Loss: 0.0034725945442914963
Test Loss:  0.0050219097174704075
Valid Loss:  0.005643803626298904
Epoch:  217  	Training Loss: 0.003442707471549511
Test Loss:  0.0049797422252595425
Valid Loss:  0.005599552765488625
Epoch:  218  	Training Loss: 0.003413116093724966
Test Loss:  0.004937969148159027
Valid Loss:  0.005555690266191959
Epoch:  219  	Training Loss: 0.0033838169183582067
Test Loss:  0.004896585363894701
Valid Loss:  0.005512224044650793
Epoch:  220  	Training Loss: 0.0033548097126185894
Test Loss:  0.004855589475482702
Valid Loss:  0.005469137337058783
Epoch:  221  	Training Loss: 0.003326085163280368
Test Loss:  0.004814976826310158
Valid Loss:  0.005426432006061077
Epoch:  222  	Training Loss: 0.0032976451329886913
Test Loss:  0.004774876870214939
Valid Loss:  0.005384248681366444
Epoch:  223  	Training Loss: 0.0032695734407752752
Test Loss:  0.004735147580504417
Valid Loss:  0.005342430435121059
Epoch:  224  	Training Loss: 0.003241772297769785
Test Loss:  0.004695788025856018
Valid Loss:  0.005300985183566809
Epoch:  225  	Training Loss: 0.003214247291907668
Test Loss:  0.004656792618334293
Valid Loss:  0.005259905941784382
Epoch:  226  	Training Loss: 0.0031869933009147644
Test Loss:  0.004618166014552116
Valid Loss:  0.005219190381467342
Epoch:  227  	Training Loss: 0.0031600072979927063
Test Loss:  0.004579897504299879
Valid Loss:  0.00517883338034153
Epoch:  228  	Training Loss: 0.0031332895159721375
Test Loss:  0.004541988018900156
Valid Loss:  0.005138835404068232
Epoch:  229  	Training Loss: 0.003106832504272461
Test Loss:  0.004504425451159477
Valid Loss:  0.005099190864712
Epoch:  230  	Training Loss: 0.0030806371942162514
Test Loss:  0.0044672247022390366
Valid Loss:  0.005059901159256697
Epoch:  231  	Training Loss: 0.0030547010246664286
Test Loss:  0.004430356435477734
Valid Loss:  0.00502095278352499
Epoch:  232  	Training Loss: 0.0030290158465504646
Test Loss:  0.004393682815134525
Valid Loss:  0.004982190206646919
Epoch:  233  	Training Loss: 0.0030034841038286686
Test Loss:  0.0043573565781116486
Valid Loss:  0.004943770822137594
Epoch:  234  	Training Loss: 0.002978205680847168
Test Loss:  0.004321376793086529
Valid Loss:  0.004905698820948601
Epoch:  235  	Training Loss: 0.002953176386654377
Test Loss:  0.004285728558897972
Valid Loss:  0.004867959301918745
Epoch:  236  	Training Loss: 0.0029283941257745028
Test Loss:  0.004250417463481426
Valid Loss:  0.004830553196370602
Epoch:  237  	Training Loss: 0.0029038535431027412
Test Loss:  0.004215429071336985
Valid Loss:  0.004793478175997734
Epoch:  238  	Training Loss: 0.002879554172977805
Test Loss:  0.004180772230029106
Valid Loss:  0.004756729118525982
Epoch:  239  	Training Loss: 0.002855493687093258
Test Loss:  0.00414644181728363
Valid Loss:  0.004720308817923069
Epoch:  240  	Training Loss: 0.0028316695243120193
Test Loss:  0.00411243224516511
Valid Loss:  0.004684207495301962
Epoch:  241  	Training Loss: 0.0028080802876502275
Test Loss:  0.004078742582350969
Valid Loss:  0.00464842701330781
Epoch:  242  	Training Loss: 0.0027847241144627333
Test Loss:  0.004045511595904827
Valid Loss:  0.004613109864294529
Epoch:  243  	Training Loss: 0.0027616838924586773
Test Loss:  0.004012582823634148
Valid Loss:  0.004578098654747009
Epoch:  244  	Training Loss: 0.002738865092396736
Test Loss:  0.0039799632504582405
Valid Loss:  0.004543398506939411
Epoch:  245  	Training Loss: 0.0027162726037204266
Test Loss:  0.003947644494473934
Valid Loss:  0.004508999176323414
Epoch:  246  	Training Loss: 0.002693902002647519
Test Loss:  0.003915630280971527
Valid Loss:  0.0044749025255441666
Epoch:  247  	Training Loss: 0.002671752590686083
Test Loss:  0.003883908037096262
Valid Loss:  0.004441103897988796
Epoch:  248  	Training Loss: 0.002649816684424877
Test Loss:  0.003852488938719034
Valid Loss:  0.0044076107442379
Epoch:  249  	Training Loss: 0.0026280987076461315
Test Loss:  0.0038213550578802824
Valid Loss:  0.004374402575194836
Epoch:  250  	Training Loss: 0.0026065881829708815
Test Loss:  0.0037905103527009487
Valid Loss:  0.004341483116149902
Epoch:  251  	Training Loss: 0.0025852881371974945
Test Loss:  0.003759952262043953
Valid Loss:  0.004308846313506365
Epoch:  252  	Training Loss: 0.002564193680882454
Test Loss:  0.0037296409718692303
Valid Loss:  0.0042764670215547085
Epoch:  253  	Training Loss: 0.002543278504163027
Test Loss:  0.003699608612805605
Valid Loss:  0.0042443592101335526
Epoch:  254  	Training Loss: 0.002522572409361601
Test Loss:  0.0036698556505143642
Valid Loss:  0.004212536849081516
Epoch:  255  	Training Loss: 0.0025020630564540625
Test Loss:  0.0036403825506567955
Valid Loss:  0.004180990159511566
Epoch:  256  	Training Loss: 0.002481755567714572
Test Loss:  0.0036111795343458652
Valid Loss:  0.004149723798036575
Epoch:  257  	Training Loss: 0.002461643423885107
Test Loss:  0.003582251723855734
Valid Loss:  0.004118726588785648
Epoch:  258  	Training Loss: 0.0024417268577963114
Test Loss:  0.003553587943315506
Valid Loss:  0.004087995737791061
Epoch:  259  	Training Loss: 0.002422004472464323
Test Loss:  0.0035251944791525602
Valid Loss:  0.004057533573359251
Epoch:  260  	Training Loss: 0.002402473706752062
Test Loss:  0.0034970655106008053
Valid Loss:  0.0040273405611515045
Epoch:  261  	Training Loss: 0.0023831313010305166
Test Loss:  0.0034691966138780117
Valid Loss:  0.003997409250587225
Epoch:  262  	Training Loss: 0.0023639779537916183
Test Loss:  0.0034415703266859055
Valid Loss:  0.003967726603150368
Epoch:  263  	Training Loss: 0.002345005515962839
Test Loss:  0.003414207138121128
Valid Loss:  0.0039382996037602425
Epoch:  264  	Training Loss: 0.0023262137547135353
Test Loss:  0.003387095872312784
Valid Loss:  0.003909126855432987
Epoch:  265  	Training Loss: 0.0023076089564710855
Test Loss:  0.0033602360635995865
Valid Loss:  0.0038802155759185553
Epoch:  266  	Training Loss: 0.0022891804110258818
Test Loss:  0.003333624918013811
Valid Loss:  0.003851549467071891
Epoch:  267  	Training Loss: 0.002270932076498866
Test Loss:  0.0033072622027248144
Valid Loss:  0.0038231341168284416
Epoch:  268  	Training Loss: 0.0022528604604303837
Test Loss:  0.0032811432611197233
Valid Loss:  0.003794965101405978
Epoch:  269  	Training Loss: 0.0022349630016833544
Test Loss:  0.0032552636694163084
Valid Loss:  0.0037670391611754894
Epoch:  270  	Training Loss: 0.002217236440628767
Test Loss:  0.0032296262215822935
Valid Loss:  0.003739349078387022
Epoch:  271  	Training Loss: 0.002199680544435978
Test Loss:  0.00320422207005322
Valid Loss:  0.003711903700605035
Epoch:  272  	Training Loss: 0.002182294148951769
Test Loss:  0.0031790081411600113
Valid Loss:  0.003684643190354109
Epoch:  273  	Training Loss: 0.0021650418639183044
Test Loss:  0.0031540316995233297
Valid Loss:  0.0036576197016984224
Epoch:  274  	Training Loss: 0.002147956285625696
Test Loss:  0.0031292825005948544
Valid Loss:  0.003630827646702528
Epoch:  275  	Training Loss: 0.002131036249920726
Test Loss:  0.0031047621741890907
Valid Loss:  0.0036042695865035057
Epoch:  276  	Training Loss: 0.0021142777986824512
Test Loss:  0.003080470021814108
Valid Loss:  0.003577939700335264
Epoch:  277  	Training Loss: 0.0020976809319108725
Test Loss:  0.003056403249502182
Valid Loss:  0.0035518340300768614
Epoch:  278  	Training Loss: 0.002081244019791484
Test Loss:  0.003032558597624302
Valid Loss:  0.003525953274220228
Epoch:  279  	Training Loss: 0.002064964734017849
Test Loss:  0.003008932340890169
Valid Loss:  0.003500294638797641
Epoch:  280  	Training Loss: 0.002048843540251255
Test Loss:  0.002985523547977209
Valid Loss:  0.0034748646430671215
Epoch:  281  	Training Loss: 0.0020328760147094727
Test Loss:  0.0029623336158692837
Valid Loss:  0.003449643962085247
Epoch:  282  	Training Loss: 0.0020170623902231455
 57%|█████▋    | 283/500 [03:18<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:19<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:19<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:19<01:12,  2.93it/s] 58%|█████▊    | 291/500 [03:25<04:09,  1.20s/it] 59%|█████▊    | 293/500 [03:25<02:57,  1.16it/s] 59%|█████▉    | 295/500 [03:26<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:26<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:26<01:07,  2.97it/s] 60%|██████    | 301/500 [03:32<03:55,  1.18s/it] 61%|██████    | 303/500 [03:32<02:47,  1.17it/s] 61%|██████    | 305/500 [03:32<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:33<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:33<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:39<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:39<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:39<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:40<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:46<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:46<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:46<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:46<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:47<00:57,  2.96it/s] 66%|██████▌   | 331/500 [03:53<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:53<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:53<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:53<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:53<00:53,  2.99it/s] 68%|██████▊   | 341/500 [04:00<03:10,  1.20s/it] 69%|██████▊   | 343/500 [04:00<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:00<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:00<01:09,  2.19it/s] 70%|██████▉   | 349/500 [04:00<00:51,  2.96it/s]Test Loss:  0.0029393546283245087
Valid Loss:  0.0034246398136019707
Epoch:  283  	Training Loss: 0.002001399639993906
Test Loss:  0.0029165917076170444
Valid Loss:  0.0033998535946011543
Epoch:  284  	Training Loss: 0.0019858903251588345
Test Loss:  0.0028940332122147083
Valid Loss:  0.003375276457518339
Epoch:  285  	Training Loss: 0.0019705272279679775
Test Loss:  0.002871684730052948
Valid Loss:  0.0033509142231196165
Epoch:  286  	Training Loss: 0.001955311046913266
Test Loss:  0.002849543932825327
Valid Loss:  0.0033267561811953783
Epoch:  287  	Training Loss: 0.0019402401521801949
Test Loss:  0.0028276077937334776
Valid Loss:  0.003302807454019785
Epoch:  288  	Training Loss: 0.0019253161735832691
Test Loss:  0.002805870259180665
Valid Loss:  0.003279066178947687
Epoch:  289  	Training Loss: 0.001910531660541892
Test Loss:  0.0027843345887959003
Valid Loss:  0.0032555218786001205
Epoch:  290  	Training Loss: 0.0018958891741931438
Test Loss:  0.002762996591627598
Valid Loss:  0.0032321778126060963
Epoch:  291  	Training Loss: 0.0018813873175531626
Test Loss:  0.0027418560348451138
Valid Loss:  0.0032090386375784874
Epoch:  292  	Training Loss: 0.0018670236459001899
Test Loss:  0.002720902906730771
Valid Loss:  0.003186090849339962
Epoch:  293  	Training Loss: 0.0018527968786656857
Test Loss:  0.0027001446578651667
Valid Loss:  0.003163339337334037
Epoch:  294  	Training Loss: 0.001838707597926259
Test Loss:  0.0026795819867402315
Valid Loss:  0.003140786662697792
Epoch:  295  	Training Loss: 0.0018247535917907953
Test Loss:  0.002659207209944725
Valid Loss:  0.0031184188555926085
Epoch:  296  	Training Loss: 0.0018109322991222143
Test Loss:  0.0026390214916318655
Valid Loss:  0.0030962429009377956
Epoch:  297  	Training Loss: 0.0017972409259527922
Test Loss:  0.00261902017518878
Valid Loss:  0.003074261359870434
Epoch:  298  	Training Loss: 0.001783675281330943
Test Loss:  0.0025992789305746555
Valid Loss:  0.003052493091672659
Epoch:  299  	Training Loss: 0.0017702261684462428
Test Loss:  0.002579679014161229
Valid Loss:  0.0030308908317238092
Epoch:  300  	Training Loss: 0.001756907207891345
Test Loss:  0.0025602332316339016
Valid Loss:  0.003009461797773838
Epoch:  301  	Training Loss: 0.0017437160713598132
Test Loss:  0.0025409716181457043
Valid Loss:  0.002988208318129182
Epoch:  302  	Training Loss: 0.0017306467052549124
Test Loss:  0.002521872753277421
Valid Loss:  0.002967134118080139
Epoch:  303  	Training Loss: 0.0017177022527903318
Test Loss:  0.0025029433891177177
Valid Loss:  0.002946228953078389
Epoch:  304  	Training Loss: 0.0017048800364136696
Test Loss:  0.002484179101884365
Valid Loss:  0.0029254970140755177
Epoch:  305  	Training Loss: 0.0016921753995120525
Test Loss:  0.002465588040649891
Valid Loss:  0.0029049450531601906
Epoch:  306  	Training Loss: 0.001679593464359641
Test Loss:  0.002447164384648204
Valid Loss:  0.002884560963138938
Epoch:  307  	Training Loss: 0.0016671288758516312
Test Loss:  0.0024289079010486603
Valid Loss:  0.0028643435798585415
Epoch:  308  	Training Loss: 0.0016547823324799538
Test Loss:  0.0024108137004077435
Valid Loss:  0.00284429918974638
Epoch:  309  	Training Loss: 0.0016425480134785175
Test Loss:  0.0023928869049996138
Valid Loss:  0.002824421040713787
Epoch:  310  	Training Loss: 0.0016304312739521265
Test Loss:  0.0023751230910420418
Valid Loss:  0.0028047142550349236
Epoch:  311  	Training Loss: 0.001618430600501597
Test Loss:  0.0023575229570269585
Valid Loss:  0.002785170916467905
Epoch:  312  	Training Loss: 0.0016065413365140557
Test Loss:  0.002340136794373393
Valid Loss:  0.0027658494655042887
Epoch:  313  	Training Loss: 0.0015947972424328327
Test Loss:  0.0023229073267430067
Valid Loss:  0.0027466865722090006
Epoch:  314  	Training Loss: 0.0015831626951694489
Test Loss:  0.0023058331571519375
Valid Loss:  0.0027276852633804083
Epoch:  315  	Training Loss: 0.0015716374618932605
Test Loss:  0.0022889168467372656
Valid Loss:  0.0027088464703410864
Epoch:  316  	Training Loss: 0.0015602200292050838
Test Loss:  0.0022721521090716124
Valid Loss:  0.0026901629753410816
Epoch:  317  	Training Loss: 0.0015489100478589535
Test Loss:  0.0022555373143404722
Valid Loss:  0.0026716343127191067
Epoch:  318  	Training Loss: 0.001537700416520238
Test Loss:  0.002239173511043191
Valid Loss:  0.0026533021591603756
Epoch:  319  	Training Loss: 0.0015265800757333636
Test Loss:  0.002222903771325946
Valid Loss:  0.0026350938715040684
Epoch:  320  	Training Loss: 0.0015155638102442026
Test Loss:  0.002206742065027356
Valid Loss:  0.0026170259807258844
Epoch:  321  	Training Loss: 0.001504650921560824
Test Loss:  0.0021906807087361813
Valid Loss:  0.002599097788333893
Epoch:  322  	Training Loss: 0.0014938388485461473
Test Loss:  0.0021747592836618423
Valid Loss:  0.002581309527158737
Epoch:  323  	Training Loss: 0.0014831258449703455
Test Loss:  0.0021589878015220165
Valid Loss:  0.0025636767968535423
Epoch:  324  	Training Loss: 0.0014725110959261656
Test Loss:  0.0021433469373732805
Valid Loss:  0.002546185627579689
Epoch:  325  	Training Loss: 0.0014619927387684584
Test Loss:  0.0021278413478285074
Valid Loss:  0.0025288332253694534
Epoch:  326  	Training Loss: 0.0014515738002955914
Test Loss:  0.002112473826855421
Valid Loss:  0.0025116235483437777
Epoch:  327  	Training Loss: 0.0014412504388019443
Test Loss:  0.0020972369238734245
Valid Loss:  0.0024945521727204323
Epoch:  328  	Training Loss: 0.0014310235856100917
Test Loss:  0.002082135993987322
Valid Loss:  0.0024776305072009563
Epoch:  329  	Training Loss: 0.001420891028828919
Test Loss:  0.002067167777568102
Valid Loss:  0.002460838994011283
Epoch:  330  	Training Loss: 0.0014108504401519895
Test Loss:  0.0020523304119706154
Valid Loss:  0.00244418578222394
Epoch:  331  	Training Loss: 0.0014009034493938088
Test Loss:  0.0020376285538077354
Valid Loss:  0.002427672501653433
Epoch:  332  	Training Loss: 0.0013910469133406878
Test Loss:  0.002023050794377923
Valid Loss:  0.0024112779647111893
Epoch:  333  	Training Loss: 0.00138127151876688
Test Loss:  0.0020085989963263273
Valid Loss:  0.002395027782768011
Epoch:  334  	Training Loss: 0.0013715859968215227
Test Loss:  0.001994274090975523
Valid Loss:  0.0023789042606949806
Epoch:  335  	Training Loss: 0.0013619898818433285
Test Loss:  0.001980079570785165
Valid Loss:  0.0023629143834114075
Epoch:  336  	Training Loss: 0.00135248270817101
Test Loss:  0.001966012641787529
Valid Loss:  0.0023470560554414988
Epoch:  337  	Training Loss: 0.00134306401014328
Test Loss:  0.0019520692294463515
Valid Loss:  0.0023313318379223347
Epoch:  338  	Training Loss: 0.0013337340205907822
Test Loss:  0.0019382522441446781
Valid Loss:  0.0023157368414103985
Epoch:  339  	Training Loss: 0.0013244888978078961
Test Loss:  0.001924556097947061
Valid Loss:  0.0023002675734460354
Epoch:  340  	Training Loss: 0.0013153278268873692
Test Loss:  0.0019109866116195917
Valid Loss:  0.002284929621964693
Epoch:  341  	Training Loss: 0.0013062518555670977
Test Loss:  0.0018975340062752366
Valid Loss:  0.0022697090171277523
Epoch:  342  	Training Loss: 0.001297259470447898
Test Loss:  0.0018843262223526835
Valid Loss:  0.002254759892821312
Epoch:  343  	Training Loss: 0.0012884350726380944
Test Loss:  0.0018712419550865889
Valid Loss:  0.0022399320732802153
Epoch:  344  	Training Loss: 0.0012796878581866622
Test Loss:  0.001858265371993184
Valid Loss:  0.002225222997367382
Epoch:  345  	Training Loss: 0.0012710219016298652
Test Loss:  0.0018454018281772733
Valid Loss:  0.002210635459050536
Epoch:  346  	Training Loss: 0.001262436155229807
Test Loss:  0.0018326548160985112
Valid Loss:  0.0021961673628538847
Epoch:  347  	Training Loss: 0.0012539266608655453
Test Loss:  0.001820022938773036
Valid Loss:  0.0021818107925355434
Epoch:  348  	Training Loss: 0.001245496328920126
Test Loss:  0.0018074982799589634
Valid Loss:  0.002167574828490615
Epoch:  349  	Training Loss: 0.0012371422490105033
Test Loss:  0.001795085845515132
Valid Loss:  0.002153453417122364
Epoch:  350  	Training Loss: 0.0012288630241528153
Test Loss:  0.0017827837727963924
Valid Loss:  0.002139442367479205
 70%|███████   | 351/500 [04:07<02:57,  1.19s/it] 71%|███████   | 353/500 [04:07<02:06,  1.17it/s] 71%|███████   | 355/500 [04:07<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:07<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:07<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:14<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:14<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:14<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:14<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:14<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:20<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:21<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:21<01:16,  1.62it/s] 75%|███████▌  | 377/500 [04:21<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:21<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:27<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:28<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:28<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:28<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:28<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:34<02:10,  1.19s/it] 79%|███████▊  | 393/500 [04:34<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:35<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:35<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:35<00:34,  2.97it/s] 80%|████████  | 401/500 [04:41<01:56,  1.17s/it] 81%|████████  | 403/500 [04:41<01:21,  1.18it/s] 81%|████████  | 405/500 [04:41<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:42<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:42<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:48<01:45,  1.19s/it] 83%|████████▎ | 413/500 [04:48<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:48<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.21it/s]Epoch:  351  	Training Loss: 0.001220659352838993
Test Loss:  0.0017705891514196992
Valid Loss:  0.002125551225617528
Epoch:  352  	Training Loss: 0.0012125317007303238
Test Loss:  0.0017584195593371987
Valid Loss:  0.002111676847562194
Epoch:  353  	Training Loss: 0.0012044280301779509
Test Loss:  0.001746359746903181
Valid Loss:  0.002097918651998043
Epoch:  354  	Training Loss: 0.0011963992146775126
Test Loss:  0.0017344087827950716
Valid Loss:  0.0020842724479734898
Epoch:  355  	Training Loss: 0.0011884414125233889
Test Loss:  0.0017225653864443302
Valid Loss:  0.0020707359071820974
Epoch:  356  	Training Loss: 0.0011805584654211998
Test Loss:  0.0017107862513512373
Valid Loss:  0.0020573106594383717
Epoch:  357  	Training Loss: 0.0011727478122338653
Test Loss:  0.0016990965232253075
Valid Loss:  0.0020439974032342434
Epoch:  358  	Training Loss: 0.0011650072410702705
Test Loss:  0.0016875129658728838
Valid Loss:  0.002030786592513323
Epoch:  359  	Training Loss: 0.0011573361698538065
Test Loss:  0.001676026964560151
Valid Loss:  0.0020176891703158617
Epoch:  360  	Training Loss: 0.0011497370433062315
Test Loss:  0.00166464620269835
Valid Loss:  0.002004692330956459
Epoch:  361  	Training Loss: 0.0011422070674598217
Test Loss:  0.001653360901400447
Valid Loss:  0.0019918023608624935
Epoch:  362  	Training Loss: 0.0011347448453307152
Test Loss:  0.0016421539476141334
Valid Loss:  0.0019789906218647957
Epoch:  363  	Training Loss: 0.0011273358250036836
Test Loss:  0.001631041755899787
Valid Loss:  0.001966281794011593
Epoch:  364  	Training Loss: 0.0011199951404705644
Test Loss:  0.0016200204845517874
Valid Loss:  0.001953677274286747
Epoch:  365  	Training Loss: 0.0011127216275781393
Test Loss:  0.001609097933396697
Valid Loss:  0.0019411715911701322
Epoch:  366  	Training Loss: 0.00110551284160465
Test Loss:  0.0015982689801603556
Valid Loss:  0.0019287713803350925
Epoch:  367  	Training Loss: 0.0010983694810420275
Test Loss:  0.0015875318786129355
Valid Loss:  0.0019164709374308586
Epoch:  368  	Training Loss: 0.0010912916623055935
Test Loss:  0.0015768915181979537
Valid Loss:  0.0019042636267840862
Epoch:  369  	Training Loss: 0.0010842769406735897
Test Loss:  0.0015663397498428822
Valid Loss:  0.0018921570153906941
Epoch:  370  	Training Loss: 0.0010773269459605217
Test Loss:  0.0015558833256363869
Valid Loss:  0.001880150055512786
Epoch:  371  	Training Loss: 0.0010704405140131712
Test Loss:  0.0015455164248123765
Valid Loss:  0.0018682372756302357
Epoch:  372  	Training Loss: 0.0010636167135089636
Test Loss:  0.001535214250907302
Valid Loss:  0.0018563910853117704
Epoch:  373  	Training Loss: 0.0010568357538431883
Test Loss:  0.0015250013675540686
Valid Loss:  0.001844639191403985
Epoch:  374  	Training Loss: 0.0010501171927899122
Test Loss:  0.0015148732345551252
Valid Loss:  0.0018329833401367068
Epoch:  375  	Training Loss: 0.0010434596333652735
Test Loss:  0.0015048383502289653
Valid Loss:  0.0018214181764051318
Epoch:  376  	Training Loss: 0.001036862377077341
Test Loss:  0.001494889846071601
Valid Loss:  0.001809950452297926
Epoch:  377  	Training Loss: 0.0010303251910954714
Test Loss:  0.0014850248116999865
Valid Loss:  0.0017985706217586994
Epoch:  378  	Training Loss: 0.0010238469112664461
Test Loss:  0.0014752504648640752
Valid Loss:  0.0017872798489406705
Epoch:  379  	Training Loss: 0.0010174275375902653
Test Loss:  0.001465557492338121
Valid Loss:  0.0017760848859325051
Epoch:  380  	Training Loss: 0.0010110660223290324
Test Loss:  0.0014559503179043531
Valid Loss:  0.0017649766523391008
Epoch:  381  	Training Loss: 0.0010047625983133912
Test Loss:  0.001446424750611186
Valid Loss:  0.0017539572436362505
Epoch:  382  	Training Loss: 0.0009985154028981924
Test Loss:  0.0014370637945830822
Valid Loss:  0.0017431231681257486
Epoch:  383  	Training Loss: 0.0009923754259943962
Test Loss:  0.001427781768143177
Valid Loss:  0.0017323663923889399
Epoch:  384  	Training Loss: 0.0009862901642918587
Test Loss:  0.001418577041476965
Valid Loss:  0.0017216963460668921
Epoch:  385  	Training Loss: 0.0009802591521292925
Test Loss:  0.0014094504294916987
Valid Loss:  0.0017111129127442837
Epoch:  386  	Training Loss: 0.0009742826805450022
Test Loss:  0.0014004092663526535
Valid Loss:  0.0017006122507154942
Epoch:  387  	Training Loss: 0.0009683619136922061
Test Loss:  0.001391438185237348
Valid Loss:  0.0016901963390409946
Epoch:  388  	Training Loss: 0.0009624942904338241
Test Loss:  0.001382553018629551
Valid Loss:  0.0016798601718619466
Epoch:  389  	Training Loss: 0.0009566728258505464
Test Loss:  0.0013737943954765797
Valid Loss:  0.001669667661190033
Epoch:  390  	Training Loss: 0.0009508725488558412
Test Loss:  0.0013650738401338458
Valid Loss:  0.0016595151973888278
Epoch:  391  	Training Loss: 0.0009451261721551418
Test Loss:  0.001356404973194003
Valid Loss:  0.0016494174487888813
Epoch:  392  	Training Loss: 0.0009394327644258738
Test Loss:  0.00134776602499187
Valid Loss:  0.0016393470577895641
Epoch:  393  	Training Loss: 0.0009337698575109243
Test Loss:  0.0013391902903094888
Valid Loss:  0.001629354665055871
Epoch:  394  	Training Loss: 0.0009281561942771077
Test Loss:  0.0013306890614330769
Valid Loss:  0.0016194330528378487
Epoch:  395  	Training Loss: 0.0009225929388776422
Test Loss:  0.0013222600100561976
Valid Loss:  0.0016095881583169103
Epoch:  396  	Training Loss: 0.0009170803241431713
Test Loss:  0.0013138983631506562
Valid Loss:  0.0015998189337551594
Epoch:  397  	Training Loss: 0.0009116160217672586
Test Loss:  0.0013056091265752912
Valid Loss:  0.0015901299193501472
Epoch:  398  	Training Loss: 0.0009062002645805478
Test Loss:  0.0012973920674994588
Valid Loss:  0.0015805128496140242
Epoch:  399  	Training Loss: 0.0009008327615447342
Test Loss:  0.0012892428785562515
Valid Loss:  0.0015709749422967434
Epoch:  400  	Training Loss: 0.0008955131634138525
Test Loss:  0.001281163888052106
Valid Loss:  0.0015615057200193405
Epoch:  401  	Training Loss: 0.0008902414701879025
Test Loss:  0.0012731569586321712
Valid Loss:  0.0015521161258220673
Epoch:  402  	Training Loss: 0.000885015819221735
Test Loss:  0.0012652359437197447
Valid Loss:  0.0015428215265274048
Epoch:  403  	Training Loss: 0.0008798481430858374
Test Loss:  0.001257379655726254
Valid Loss:  0.0015335973585024476
Epoch:  404  	Training Loss: 0.0008747257525101304
Test Loss:  0.0012495939154177904
Valid Loss:  0.0015244483947753906
Epoch:  405  	Training Loss: 0.0008696506265550852
Test Loss:  0.0012418864062055945
Valid Loss:  0.0015153813874348998
Epoch:  406  	Training Loss: 0.0008646175265312195
Test Loss:  0.0012342350091785192
Valid Loss:  0.0015063821338117123
Epoch:  407  	Training Loss: 0.0008596318075433373
Test Loss:  0.001226650201715529
Valid Loss:  0.0014974464429542422
Epoch:  408  	Training Loss: 0.0008546869503334165
Test Loss:  0.0012191261630505323
Valid Loss:  0.001488576177507639
Epoch:  409  	Training Loss: 0.0008497859816998243
Test Loss:  0.0012116634752601385
Valid Loss:  0.001479776343330741
Epoch:  410  	Training Loss: 0.0008449296001344919
Test Loss:  0.0012042650487273932
Valid Loss:  0.001471045077778399
Epoch:  411  	Training Loss: 0.0008401143131777644
Test Loss:  0.001196929719299078
Valid Loss:  0.0014623807510361075
Epoch:  412  	Training Loss: 0.0008353431476280093
Test Loss:  0.001189610455185175
Valid Loss:  0.001453727949410677
Epoch:  413  	Training Loss: 0.000830584205687046
Test Loss:  0.0011823547538369894
Valid Loss:  0.0014451451133936644
Epoch:  414  	Training Loss: 0.0008258636808022857
Test Loss:  0.0011752182617783546
Valid Loss:  0.0014366990653797984
Epoch:  415  	Training Loss: 0.0008211242966353893
Test Loss:  0.0011681629111990333
Valid Loss:  0.0014283463824540377
Epoch:  416  	Training Loss: 0.0008164010941982269
Test Loss:  0.001161105465143919
Valid Loss:  0.001419984851963818
Epoch:  417  	Training Loss: 0.0008117313263937831
Test Loss:  0.0011540765408426523
Valid Loss:  0.001411653240211308
Epoch:  418  	Training Loss: 0.0008071053307503462
Test Loss:  0.00114708230830729
Valid Loss:  0.00140336062759161
Epoch:  419  	Training Loss: 0.0008025195566006005
Test Loss:  0.0011401360388845205 84%|████████▍ | 419/500 [04:49<00:27,  2.93it/s] 84%|████████▍ | 421/500 [04:55<01:34,  1.20s/it] 85%|████████▍ | 423/500 [04:55<01:06,  1.16it/s] 85%|████████▌ | 425/500 [04:55<00:47,  1.59it/s] 85%|████████▌ | 427/500 [04:55<00:33,  2.15it/s] 86%|████████▌ | 429/500 [04:56<00:24,  2.85it/s] 86%|████████▌ | 431/500 [05:02<01:23,  1.22s/it] 87%|████████▋ | 433/500 [05:02<00:58,  1.14it/s] 87%|████████▋ | 435/500 [05:02<00:41,  1.57it/s] 87%|████████▋ | 437/500 [05:03<00:29,  2.15it/s] 88%|████████▊ | 439/500 [05:03<00:21,  2.89it/s] 88%|████████▊ | 441/500 [05:09<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:09<00:48,  1.16it/s] 89%|████████▉ | 445/500 [05:09<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:09<00:24,  2.20it/s] 90%|████████▉ | 449/500 [05:10<00:17,  2.95it/s] 90%|█████████ | 451/500 [05:16<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:16<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:16<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:16<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:17<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:23<00:47,  1.22s/it] 93%|█████████▎| 463/500 [05:23<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:23<00:22,  1.59it/s] 93%|█████████▎| 467/500 [05:24<00:15,  2.16it/s] 94%|█████████▍| 469/500 [05:24<00:10,  2.91it/s] 94%|█████████▍| 471/500 [05:30<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:30<00:23,  1.14it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.57it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.13it/s] 96%|█████████▌| 479/500 [05:31<00:07,  2.86it/s] 96%|█████████▌| 481/500 [05:37<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:38<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:38<00:05,  2.17it/s]
Valid Loss:  0.0013951186556369066
Epoch:  420  	Training Loss: 0.0007979738875292242
Test Loss:  0.0011332466965541244
Valid Loss:  0.001386936055496335
Epoch:  421  	Training Loss: 0.000793468439951539
Test Loss:  0.001126411254517734
Valid Loss:  0.001378810964524746
Epoch:  422  	Training Loss: 0.000789001293014735
Test Loss:  0.0011196050327271223
Valid Loss:  0.0013707197504118085
Epoch:  423  	Training Loss: 0.0007845578948035836
Test Loss:  0.0011128598125651479
Valid Loss:  0.001362685696221888
Epoch:  424  	Training Loss: 0.0007801534957252443
Test Loss:  0.0011061697732657194
Valid Loss:  0.0013547209091484547
Epoch:  425  	Training Loss: 0.000775787397287786
Test Loss:  0.001099536893889308
Valid Loss:  0.0013468116521835327
Epoch:  426  	Training Loss: 0.0007714587263762951
Test Loss:  0.0010929621057584882
Valid Loss:  0.0013389673549681902
Epoch:  427  	Training Loss: 0.0007671687053516507
Test Loss:  0.0010864411015063524
Valid Loss:  0.0013311803340911865
Epoch:  428  	Training Loss: 0.0007629139581695199
Test Loss:  0.0010799728333950043
Valid Loss:  0.0013234548969194293
Epoch:  429  	Training Loss: 0.0007586986757814884
Test Loss:  0.0010735649848356843
Valid Loss:  0.0013157890643924475
Epoch:  430  	Training Loss: 0.0007545177359133959
Test Loss:  0.0010672127828001976
Valid Loss:  0.0013081830693408847
Epoch:  431  	Training Loss: 0.0007503757951781154
Test Loss:  0.0010609123855829239
Valid Loss:  0.0013006384251639247
Epoch:  432  	Training Loss: 0.0007462690118700266
Test Loss:  0.001054692082107067
Valid Loss:  0.0012931856326758862
Epoch:  433  	Training Loss: 0.0007422154303640127
Test Loss:  0.0010485253296792507
Valid Loss:  0.001285784994252026
Epoch:  434  	Training Loss: 0.0007381967734545469
Test Loss:  0.00104240991640836
Valid Loss:  0.0012784423306584358
Epoch:  435  	Training Loss: 0.0007342125754803419
Test Loss:  0.0010363447945564985
Valid Loss:  0.0012711561284959316
Epoch:  436  	Training Loss: 0.0007302640588022768
Test Loss:  0.0010302746668457985
Valid Loss:  0.0012639276683330536
Epoch:  437  	Training Loss: 0.000726348371244967
Test Loss:  0.0010242343414574862
Valid Loss:  0.0012567525263875723
Epoch:  438  	Training Loss: 0.0007224666187539697
Test Loss:  0.0010182400001212955
Valid Loss:  0.0012496351264417171
Epoch:  439  	Training Loss: 0.0007186195580288768
Test Loss:  0.0010122964158654213
Valid Loss:  0.0012425717432051897
Epoch:  440  	Training Loss: 0.0007148045697249472
Test Loss:  0.0010064023081213236
Valid Loss:  0.0012355600483715534
Epoch:  441  	Training Loss: 0.0007110230508260429
Test Loss:  0.0010005582589656115
Valid Loss:  0.0012286026030778885
Epoch:  442  	Training Loss: 0.0007072739535942674
Test Loss:  0.0009947860380634665
Valid Loss:  0.0012217259500175714
Epoch:  443  	Training Loss: 0.0007035522139631212
Test Loss:  0.0009890854125842452
Valid Loss:  0.0012149899266660213
Epoch:  444  	Training Loss: 0.0006998329190537333
Test Loss:  0.0009834038792178035
Valid Loss:  0.0012082550674676895
Epoch:  445  	Training Loss: 0.000696150993462652
Test Loss:  0.0009777502855286002
Valid Loss:  0.001201536739245057
Epoch:  446  	Training Loss: 0.0006924996851012111
Test Loss:  0.000972134992480278
Valid Loss:  0.0011948579922318459
Epoch:  447  	Training Loss: 0.0006888803327456117
Test Loss:  0.0009665610850788653
Valid Loss:  0.001188216032460332
Epoch:  448  	Training Loss: 0.0006852922961115837
Test Loss:  0.0009610318811610341
Valid Loss:  0.0011816187761723995
Epoch:  449  	Training Loss: 0.000681733712553978
Test Loss:  0.000955545692704618
Valid Loss:  0.0011750692501664162
Epoch:  450  	Training Loss: 0.0006782053969800472
Test Loss:  0.0009501021122559905
Valid Loss:  0.0011685637291520834
Epoch:  451  	Training Loss: 0.0006747074658051133
Test Loss:  0.0009447056800127029
Valid Loss:  0.001162116415798664
Epoch:  452  	Training Loss: 0.0006712406175211072
Test Loss:  0.0009392992360517383
Valid Loss:  0.0011556483805179596
Epoch:  453  	Training Loss: 0.0006677692290395498
Test Loss:  0.000933939591050148
Valid Loss:  0.0011492330813780427
Epoch:  454  	Training Loss: 0.0006643261294811964
Test Loss:  0.0009286217391490936
Valid Loss:  0.001142863417044282
Epoch:  455  	Training Loss: 0.0006609139963984489
Test Loss:  0.0009233478922396898
Valid Loss:  0.001136542996391654
Epoch:  456  	Training Loss: 0.0006575306179001927
Test Loss:  0.0009181187488138676
Valid Loss:  0.001130270422436297
Epoch:  457  	Training Loss: 0.0006541764596477151
Test Loss:  0.0009129313402809203
Valid Loss:  0.0011240462772548199
Epoch:  458  	Training Loss: 0.0006508500082418323
Test Loss:  0.0009077879367396235
Valid Loss:  0.001117869047448039
Epoch:  459  	Training Loss: 0.0006475526024587452
Test Loss:  0.0009026865009218454
Valid Loss:  0.001111738383769989
Epoch:  460  	Training Loss: 0.0006442825542762876
Test Loss:  0.0008976262179203331
Valid Loss:  0.0011056548682972789
Epoch:  461  	Training Loss: 0.0006410405621863902
Test Loss:  0.0008926083100959659
Valid Loss:  0.001099616871215403
Epoch:  462  	Training Loss: 0.0006378260441124439
Test Loss:  0.0008876705542206764
Valid Loss:  0.0010936746839433908
Epoch:  463  	Training Loss: 0.0006346632726490498
Test Loss:  0.0008827665587887168
Valid Loss:  0.0010877656750380993
Epoch:  464  	Training Loss: 0.0006315236096270382
Test Loss:  0.0008779055206105113
Valid Loss:  0.001081906259059906
Epoch:  465  	Training Loss: 0.000628411304205656
Test Loss:  0.0008730845293030143
Valid Loss:  0.0010760948061943054
Epoch:  466  	Training Loss: 0.0006253242027014494
Test Loss:  0.000868305389303714
Valid Loss:  0.0010703280568122864
Epoch:  467  	Training Loss: 0.0006222649244591594
Test Loss:  0.000863564433529973
Valid Loss:  0.0010646060109138489
Epoch:  468  	Training Loss: 0.000619230791926384
Test Loss:  0.0008588632335886359
Valid Loss:  0.0010589263401925564
Epoch:  469  	Training Loss: 0.0006162214558571577
Test Loss:  0.0008542003342881799
Valid Loss:  0.0010532911401242018
Epoch:  470  	Training Loss: 0.0006132380804046988
Test Loss:  0.0008495751535519958
Valid Loss:  0.001047697151079774
Epoch:  471  	Training Loss: 0.0006102797342464328
Test Loss:  0.0008449892047792673
Valid Loss:  0.0010421427432447672
Epoch:  472  	Training Loss: 0.0006073472322896123
Test Loss:  0.0008404214167967439
Valid Loss:  0.0010366104543209076
Epoch:  473  	Training Loss: 0.0006044259062036872
Test Loss:  0.0008358898339793086
Valid Loss:  0.0010311175137758255
Epoch:  474  	Training Loss: 0.0006015311228111386
Test Loss:  0.0008313940488733351
Valid Loss:  0.0010256653185933828
Epoch:  475  	Training Loss: 0.0005986580508761108
Test Loss:  0.0008269359823316336
Valid Loss:  0.0010202573612332344
Epoch:  476  	Training Loss: 0.0005958116380497813
Test Loss:  0.0008224837947636843
Valid Loss:  0.0010148872388526797
Epoch:  477  	Training Loss: 0.0005929886247031391
Test Loss:  0.0008180083823390305
Valid Loss:  0.0010095590259879827
Epoch:  478  	Training Loss: 0.0005901898257434368
Test Loss:  0.0008135702228173614
Valid Loss:  0.001004267600364983
Epoch:  479  	Training Loss: 0.0005874151829630136
Test Loss:  0.0008091640775091946
Valid Loss:  0.0009990200633183122
Epoch:  480  	Training Loss: 0.0005846630083397031
Test Loss:  0.0008047972805798054
Valid Loss:  0.0009938115254044533
Epoch:  481  	Training Loss: 0.0005819352227263153
Test Loss:  0.0008004612755030394
Valid Loss:  0.0009886398911476135
Epoch:  482  	Training Loss: 0.00057922990527004
Test Loss:  0.0007961696246638894
Valid Loss:  0.0009835166856646538
Epoch:  483  	Training Loss: 0.0005765521200373769
Test Loss:  0.0007919096387922764
Valid Loss:  0.0009784309659153223
Epoch:  484  	Training Loss: 0.0005738952313549817
Test Loss:  0.0007876866729930043
Valid Loss:  0.0009733833139762282
Epoch:  485  	Training Loss: 0.0005712625570595264
Test Loss:  0.0007834953139536083
Valid Loss:  0.0009683741955086589
Epoch:  486  	Training Loss: 0.0005686521180905402
Test Loss:  0.0007793394033797085
Valid Loss:  0.000963402446359396
Epoch:  487  	Training Loss: 0.0005660625174641609
Test Loss:  0.0007752091623842716
Valid Loss:  0.0009584674844518304
 98%|█████████▊| 489/500 [05:38<00:03,  2.91it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:44<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:45<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:45<00:01,  2.16it/s]100%|█████████▉| 499/500 [05:45<00:00,  2.90it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
Epoch:  488  	Training Loss: 0.0005634952103719115
Test Loss:  0.0007711160578764975
Valid Loss:  0.0009535682620480657
Epoch:  489  	Training Loss: 0.0005609500803984702
Test Loss:  0.0007670545019209385
Valid Loss:  0.0009487050701864064
Epoch:  490  	Training Loss: 0.0005584260215982795
Test Loss:  0.0007630160544067621
Valid Loss:  0.0009438790148124099
Epoch:  491  	Training Loss: 0.0005559225101023912
Test Loss:  0.000759006361477077
Valid Loss:  0.0009390876512043178
Epoch:  492  	Training Loss: 0.000553440535441041
Test Loss:  0.0007550151203759015
Valid Loss:  0.0009343130514025688
Epoch:  493  	Training Loss: 0.0005509710172191262
Test Loss:  0.000751058105379343
Valid Loss:  0.0009295783238485456
Epoch:  494  	Training Loss: 0.0005485221045091748
Test Loss:  0.0007471315911971033
Valid Loss:  0.0009248788119293749
Epoch:  495  	Training Loss: 0.0005460941465571523
Test Loss:  0.0007432361599057913
Valid Loss:  0.0009202134096994996
Epoch:  496  	Training Loss: 0.0005436870851553977
Test Loss:  0.0007393707055598497
Valid Loss:  0.0009155814186669886
Epoch:  497  	Training Loss: 0.0005413013277575374
Test Loss:  0.0007355366833508015
Valid Loss:  0.0009109891252592206
Epoch:  498  	Training Loss: 0.0005389350117184222
Test Loss:  0.00073173304554075
Valid Loss:  0.0009064250625669956
Epoch:  499  	Training Loss: 0.0005365878459997475
Test Loss:  0.000727958045899868
Valid Loss:  0.0009018980781547725
Epoch:  500  	Training Loss: 0.0005342611693777144
Test Loss:  0.0007242141291499138
Valid Loss:  0.0008974048541858792
seed is  12
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:19,  6.17s/it]  1%|          | 3/500 [00:06<13:38,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:19<13:22,  1.65s/it]  3%|▎         | 17/500 [00:19<09:16,  1.15s/it]  4%|▍         | 19/500 [00:19<06:31,  1.23it/s]  4%|▍         | 21/500 [00:32<19:44,  2.47s/it]  5%|▍         | 23/500 [00:32<13:52,  1.75s/it]  5%|▌         | 25/500 [00:38<17:23,  2.20s/it]  5%|▌         | 27/500 [00:39<12:14,  1.55s/it]  6%|▌         | 29/500 [00:39<08:39,  1.10s/it]  6%|▌         | 31/500 [00:51<20:47,  2.66s/it]  7%|▋         | 33/500 [00:51<14:37,  1.88s/it]  7%|▋         | 35/500 [00:58<17:22,  2.24s/it]  7%|▋         | 37/500 [00:58<12:15,  1.59s/it]  8%|▊         | 39/500 [00:58<08:41,  1.13s/it]  8%|▊         | 41/500 [01:10<20:30,  2.68s/it]  9%|▊         | 43/500 [01:11<14:27,  1.90s/it]  9%|▉         | 45/500 [01:17<17:17,  2.28s/it]  9%|▉         | 47/500 [01:17<12:13,  1.62s/it] 10%|▉         | 49/500 [01:17<08:42,  1.16s/it] 10%|█         | 51/500 [01:30<20:06,  2.69s/it] 11%|█         | 53/500 [01:30<14:12,  1.91s/it] 11%|█         | 55/500 [01:36<17:02,  2.30s/it] 11%|█▏        | 57/500 [01:36<12:03,  1.63s/it] 12%|█▏        | 59/500 [01:37<08:35,  1.17s/it] 12%|█▏        | 60/500 [01:43<15:09,  2.07s/it] 12%|█▏        | 61/500 [01:49<21:20,  2.92s/it]Epoch:  1  	Training Loss: 0.1598755419254303
Test Loss:  0.37279194593429565
Valid Loss:  0.3796728253364563
Epoch:  2  	Training Loss: 0.4661930203437805
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  3  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  4  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  5  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  6  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  7  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  8  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  9  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  10  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  11  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  12  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  13  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  14  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  15  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  17  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  18  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  19  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  20  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  22  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  23  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  24  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  25  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  27  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  28  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  29  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  30  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  32  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  33  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  34  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  35  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  37  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  38  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  39  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  40  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  42  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  43  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  44  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724491357803345
Epoch:  45  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  47  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  48  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  49  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  50  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  52  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  53  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  54  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  55  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  57  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  58  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  59  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  60  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  62  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  63  	Training Loss: 0.17531347274780273
 13%|█▎        | 63/500 [01:49<13:40,  1.88s/it] 13%|█▎        | 65/500 [01:56<16:52,  2.33s/it] 13%|█▎        | 67/500 [01:56<11:26,  1.59s/it] 14%|█▍        | 69/500 [01:56<07:54,  1.10s/it] 14%|█▍        | 69/500 [02:06<07:54,  1.10s/it] 14%|█▍        | 71/500 [02:09<19:27,  2.72s/it] 15%|█▍        | 73/500 [02:09<13:31,  1.90s/it] 15%|█▌        | 75/500 [02:15<16:12,  2.29s/it] 15%|█▌        | 77/500 [02:15<11:22,  1.61s/it] 16%|█▌        | 79/500 [02:15<08:02,  1.15s/it] 16%|█▌        | 79/500 [02:26<08:02,  1.15s/it] 16%|█▌        | 81/500 [02:28<18:39,  2.67s/it] 17%|█▋        | 83/500 [02:28<13:07,  1.89s/it] 17%|█▋        | 85/500 [02:34<15:41,  2.27s/it] 17%|█▋        | 87/500 [02:34<11:03,  1.61s/it] 18%|█▊        | 89/500 [02:34<07:50,  1.14s/it] 18%|█▊        | 89/500 [02:46<07:50,  1.14s/it] 18%|█▊        | 91/500 [02:47<18:13,  2.67s/it] 19%|█▊        | 93/500 [02:47<12:49,  1.89s/it] 19%|█▉        | 95/500 [02:53<15:19,  2.27s/it] 19%|█▉        | 97/500 [02:53<10:48,  1.61s/it] 20%|█▉        | 99/500 [02:54<07:39,  1.14s/it] 20%|██        | 101/500 [03:06<17:55,  2.69s/it] 21%|██        | 103/500 [03:06<12:39,  1.91s/it] 21%|██        | 105/500 [03:13<15:05,  2.29s/it] 21%|██▏       | 107/500 [03:13<10:38,  1.63s/it] 22%|██▏       | 109/500 [03:13<07:32,  1.16s/it] 22%|██▏       | 111/500 [03:26<17:26,  2.69s/it] 23%|██▎       | 113/500 [03:26<12:18,  1.91s/it] 23%|██▎       | 115/500 [03:32<14:42,  2.29s/it] 23%|██▎       | 117/500 [03:32<10:22,  1.62s/it] 24%|██▍       | 119/500 [03:32<07:20,  1.16s/it] 24%|██▍       | 121/500 [03:45<17:04,  2.70s/it]Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  64  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  65  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  67  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  68  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724489867687225
Epoch:  69  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  70  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  72  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  73  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  74  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  75  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  77  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  78  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  79  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  80  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  82  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  83  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  84  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  85  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  87  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  88  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  89  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  90  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  92  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  93  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  94  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  95  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  97  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  98  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  99  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  100  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  102  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  103  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  104  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  105  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  107  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  108  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  109  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  110  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  112  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  113  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  114  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  115  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  117  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  118  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  119  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  120  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  122  	Training Loss: 0.17531345784664154
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  123  	Training Loss: 0.17531347274780273
 25%|██▍       | 123/500 [03:45<12:01,  1.91s/it] 25%|██▌       | 125/500 [03:52<14:22,  2.30s/it] 25%|██▌       | 127/500 [03:52<10:08,  1.63s/it] 26%|██▌       | 129/500 [03:52<07:11,  1.16s/it] 26%|██▌       | 131/500 [04:04<16:28,  2.68s/it] 27%|██▋       | 133/500 [04:04<11:36,  1.90s/it] 27%|██▋       | 135/500 [04:11<13:57,  2.30s/it] 27%|██▋       | 137/500 [04:11<09:51,  1.63s/it] 28%|██▊       | 139/500 [04:11<06:58,  1.16s/it] 28%|██▊       | 141/500 [04:24<16:09,  2.70s/it] 29%|██▊       | 143/500 [04:24<11:22,  1.91s/it] 29%|██▉       | 145/500 [04:30<13:27,  2.27s/it] 29%|██▉       | 147/500 [04:30<09:29,  1.61s/it] 30%|██▉       | 149/500 [04:30<06:43,  1.15s/it] 30%|███       | 151/500 [04:43<15:44,  2.71s/it] 31%|███       | 153/500 [04:43<11:05,  1.92s/it] 31%|███       | 155/500 [04:49<13:05,  2.28s/it] 31%|███▏      | 157/500 [04:50<09:14,  1.62s/it] 32%|███▏      | 159/500 [04:50<06:32,  1.15s/it] 32%|███▏      | 161/500 [05:02<15:20,  2.72s/it] 33%|███▎      | 163/500 [05:03<10:48,  1.92s/it] 33%|███▎      | 165/500 [05:09<12:46,  2.29s/it] 33%|███▎      | 167/500 [05:09<09:00,  1.62s/it] 34%|███▍      | 169/500 [05:09<06:22,  1.16s/it] 34%|███▍      | 171/500 [05:22<14:44,  2.69s/it] 35%|███▍      | 173/500 [05:22<10:22,  1.90s/it] 35%|███▌      | 175/500 [05:28<12:30,  2.31s/it] 35%|███▌      | 177/500 [05:28<08:49,  1.64s/it] 36%|███▌      | 179/500 [05:29<06:14,  1.17s/it] 36%|███▌      | 181/500 [05:41<14:16,  2.69s/it]Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  124  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724489867687225
Epoch:  125  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  127  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  128  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  129  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  130  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  132  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  133  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  134  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  135  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  137  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  138  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  139  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  140  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  142  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  143  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  144  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  145  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  147  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  148  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  149  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  150  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724489867687225
Epoch:  152  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  153  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  154  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  155  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  157  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  158  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  159  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  160  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  162  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  163  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  164  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  165  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  167  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  168  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  169  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  170  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724491357803345
Epoch:  172  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  173  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  174  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  175  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  177  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  178  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  179  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  180  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  182  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
 37%|███▋      | 183/500 [05:41<10:01,  1.90s/it] 37%|███▋      | 185/500 [05:48<11:58,  2.28s/it] 37%|███▋      | 187/500 [05:48<08:26,  1.62s/it] 38%|███▊      | 189/500 [05:48<05:58,  1.15s/it] 38%|███▊      | 191/500 [06:00<13:54,  2.70s/it] 39%|███▊      | 193/500 [06:01<09:46,  1.91s/it] 39%|███▉      | 195/500 [06:07<11:33,  2.27s/it] 39%|███▉      | 197/500 [06:07<08:08,  1.61s/it] 40%|███▉      | 199/500 [06:07<05:45,  1.15s/it] 40%|████      | 201/500 [06:20<13:28,  2.70s/it] 41%|████      | 203/500 [06:20<09:28,  1.91s/it] 41%|████      | 205/500 [06:26<11:12,  2.28s/it] 41%|████▏     | 207/500 [06:26<07:53,  1.62s/it] 42%|████▏     | 209/500 [06:26<05:35,  1.15s/it] 42%|████▏     | 209/500 [06:37<05:35,  1.15s/it] 42%|████▏     | 211/500 [06:39<12:59,  2.70s/it] 43%|████▎     | 213/500 [06:39<09:07,  1.91s/it] 43%|████▎     | 215/500 [06:45<10:47,  2.27s/it] 43%|████▎     | 217/500 [06:46<07:35,  1.61s/it] 44%|████▍     | 219/500 [06:46<05:23,  1.15s/it] 44%|████▍     | 219/500 [06:57<05:23,  1.15s/it] 44%|████▍     | 221/500 [06:58<12:31,  2.69s/it] 45%|████▍     | 223/500 [06:58<08:48,  1.91s/it] 45%|████▌     | 225/500 [07:05<10:25,  2.28s/it] 45%|████▌     | 227/500 [07:05<07:20,  1.61s/it] 46%|████▌     | 229/500 [07:05<05:11,  1.15s/it] 46%|████▌     | 229/500 [07:17<05:11,  1.15s/it] 46%|████▌     | 231/500 [07:17<12:01,  2.68s/it] 47%|████▋     | 233/500 [07:18<08:28,  1.91s/it] 47%|████▋     | 235/500 [07:24<10:08,  2.30s/it] 47%|████▋     | 237/500 [07:24<07:08,  1.63s/it] 48%|████▊     | 239/500 [07:24<05:02,  1.16s/it] 48%|████▊     | 239/500 [07:37<05:02,  1.16s/it] 48%|████▊     | 241/500 [07:37<11:36,  2.69s/it]Epoch:  183  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  184  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  185  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  187  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  188  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  189  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  190  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  192  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  193  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  194  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  195  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  197  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  198  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  199  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  200  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  202  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  203  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  204  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  205  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  207  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  208  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  209  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  210  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  212  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  213  	Training Loss: 0.17531348764896393
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  214  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064394235611
Valid Loss:  0.22724488377571106
Epoch:  215  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  217  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  218  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  219  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  220  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  222  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  223  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  224  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  225  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  227  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  228  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  229  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  230  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  232  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  233  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  234  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  235  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  237  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  238  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  239  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  240  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  242  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
 49%|████▊     | 243/500 [07:37<08:09,  1.90s/it] 49%|████▉     | 245/500 [07:43<09:38,  2.27s/it] 49%|████▉     | 247/500 [07:43<06:47,  1.61s/it] 50%|████▉     | 249/500 [07:44<04:47,  1.15s/it] 50%|█████     | 251/500 [07:56<11:05,  2.67s/it] 51%|█████     | 253/500 [07:56<07:47,  1.89s/it] 51%|█████     | 255/500 [08:03<09:27,  2.31s/it] 51%|█████▏    | 257/500 [08:03<06:40,  1.65s/it] 52%|█████▏    | 259/500 [08:03<04:43,  1.18s/it] 52%|█████▏    | 261/500 [08:15<10:41,  2.69s/it] 53%|█████▎    | 263/500 [08:16<07:31,  1.90s/it] 53%|█████▎    | 265/500 [08:22<08:52,  2.27s/it] 53%|█████▎    | 267/500 [08:22<06:14,  1.61s/it] 54%|█████▍    | 269/500 [08:22<04:24,  1.14s/it] 54%|█████▍    | 271/500 [08:35<10:13,  2.68s/it] 55%|█████▍    | 273/500 [08:35<07:10,  1.89s/it] 55%|█████▌    | 275/500 [08:41<08:33,  2.28s/it] 55%|█████▌    | 277/500 [08:41<06:00,  1.62s/it] 56%|█████▌    | 279/500 [08:41<04:14,  1.15s/it] 56%|█████▌    | 281/500 [08:54<09:48,  2.69s/it] 57%|█████▋    | 283/500 [08:54<06:53,  1.91s/it] 57%|█████▋    | 285/500 [09:00<08:10,  2.28s/it] 57%|█████▋    | 287/500 [09:01<05:44,  1.62s/it] 58%|█████▊    | 289/500 [09:01<04:03,  1.15s/it] 58%|█████▊    | 291/500 [09:13<09:21,  2.69s/it] 59%|█████▊    | 293/500 [09:13<06:33,  1.90s/it] 59%|█████▉    | 295/500 [09:20<07:47,  2.28s/it] 59%|█████▉    | 297/500 [09:20<05:27,  1.62s/it] 60%|█████▉    | 299/500 [09:20<03:51,  1.15s/it] 60%|██████    | 301/500 [09:33<08:57,  2.70s/it]Valid Loss:  0.22724489867687225
Epoch:  243  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  244  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  245  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  247  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  248  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  249  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  250  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  252  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  253  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724489867687225
Epoch:  254  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  255  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  257  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  258  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  259  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  260  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  262  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  263  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  264  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  265  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  267  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  268  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  269  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  270  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  272  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  273  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  274  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  275  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724491357803345
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  277  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  278  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  279  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  280  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  282  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  283  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  284  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724489867687225
Epoch:  285  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  287  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  288  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  289  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  290  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  292  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  293  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  294  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  295  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  297  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  298  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  299  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  300  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
 61%|██████    | 303/500 [09:33<06:16,  1.91s/it] 61%|██████    | 305/500 [09:39<07:23,  2.27s/it] 61%|██████▏   | 307/500 [09:39<05:10,  1.61s/it] 62%|██████▏   | 309/500 [09:39<03:39,  1.15s/it] 62%|██████▏   | 311/500 [09:52<08:24,  2.67s/it] 63%|██████▎   | 313/500 [09:52<05:53,  1.89s/it] 63%|██████▎   | 315/500 [09:58<07:04,  2.29s/it] 63%|██████▎   | 317/500 [09:58<04:57,  1.63s/it] 64%|██████▍   | 319/500 [09:59<03:29,  1.16s/it] 64%|██████▍   | 321/500 [10:11<08:04,  2.71s/it] 65%|██████▍   | 323/500 [10:11<05:39,  1.92s/it] 65%|██████▌   | 325/500 [10:18<06:41,  2.29s/it] 65%|██████▌   | 327/500 [10:18<04:41,  1.63s/it] 66%|██████▌   | 329/500 [10:18<03:18,  1.16s/it] 66%|██████▌   | 331/500 [10:30<07:32,  2.68s/it] 67%|██████▋   | 333/500 [10:31<05:16,  1.89s/it] 67%|██████▋   | 335/500 [10:37<06:15,  2.27s/it] 67%|██████▋   | 337/500 [10:37<04:23,  1.62s/it] 68%|██████▊   | 339/500 [10:37<03:05,  1.15s/it] 68%|██████▊   | 341/500 [10:50<07:06,  2.68s/it] 69%|██████▊   | 343/500 [10:50<04:58,  1.90s/it] 69%|██████▉   | 345/500 [10:56<05:53,  2.28s/it] 69%|██████▉   | 347/500 [10:56<04:07,  1.62s/it] 70%|██████▉   | 349/500 [10:56<02:53,  1.15s/it] 70%|██████▉   | 349/500 [11:07<02:53,  1.15s/it] 70%|███████   | 351/500 [11:09<06:34,  2.65s/it] 71%|███████   | 353/500 [11:09<04:35,  1.88s/it] 71%|███████   | 355/500 [11:15<05:29,  2.27s/it] 71%|███████▏  | 357/500 [11:15<03:50,  1.61s/it] 72%|███████▏  | 359/500 [11:16<02:41,  1.15s/it]Epoch:  302  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  303  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  304  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  305  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  307  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  308  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  309  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  310  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  312  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  313  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  314  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  315  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  317  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  318  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  319  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  320  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  322  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  323  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  324  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  325  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724489867687225
Epoch:  327  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  328  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  329  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  330  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  332  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724489867687225
Epoch:  333  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  334  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  335  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  337  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  338  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  339  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  340  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  342  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  343  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  344  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  345  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  347  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  348  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  349  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  350  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  352  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  353  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  354  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  355  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  357  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  358  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  359  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  360  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.17531347274780273
Test Loss:   72%|███████▏  | 359/500 [11:27<02:41,  1.15s/it] 72%|███████▏  | 361/500 [11:28<06:12,  2.68s/it] 73%|███████▎  | 363/500 [11:28<04:19,  1.90s/it] 73%|███████▎  | 365/500 [11:34<05:06,  2.27s/it] 73%|███████▎  | 367/500 [11:35<03:34,  1.61s/it] 74%|███████▍  | 369/500 [11:35<02:30,  1.15s/it] 74%|███████▍  | 369/500 [11:47<02:30,  1.15s/it] 74%|███████▍  | 371/500 [11:47<05:48,  2.70s/it] 75%|███████▍  | 373/500 [11:48<04:03,  1.91s/it] 75%|███████▌  | 375/500 [11:54<04:46,  2.29s/it] 75%|███████▌  | 377/500 [11:54<03:19,  1.63s/it] 76%|███████▌  | 379/500 [11:54<02:20,  1.16s/it] 76%|███████▌  | 379/500 [12:07<02:20,  1.16s/it] 76%|███████▌  | 381/500 [12:07<05:19,  2.69s/it] 77%|███████▋  | 383/500 [12:07<03:42,  1.90s/it] 77%|███████▋  | 385/500 [12:13<04:23,  2.29s/it] 77%|███████▋  | 387/500 [12:13<03:03,  1.62s/it] 78%|███████▊  | 389/500 [12:13<02:08,  1.16s/it] 78%|███████▊  | 391/500 [12:26<04:55,  2.71s/it] 79%|███████▊  | 393/500 [12:26<03:25,  1.92s/it] 79%|███████▉  | 395/500 [12:33<04:05,  2.34s/it] 79%|███████▉  | 397/500 [12:33<02:50,  1.66s/it] 80%|███████▉  | 399/500 [12:33<01:59,  1.18s/it] 80%|████████  | 401/500 [12:46<04:27,  2.70s/it] 81%|████████  | 403/500 [12:46<03:05,  1.91s/it] 81%|████████  | 405/500 [12:52<03:40,  2.32s/it] 81%|████████▏ | 407/500 [12:53<02:33,  1.65s/it] 82%|████████▏ | 409/500 [12:53<01:46,  1.17s/it] 82%|████████▏ | 411/500 [13:05<03:58,  2.68s/it] 83%|████████▎ | 413/500 [13:05<02:45,  1.90s/it] 83%|████████▎ | 415/500 [13:11<03:12,  2.26s/it] 83%|████████▎ | 417/500 [13:12<02:13,  1.61s/it] 84%|████████▍ | 419/500 [13:12<01:32,  1.14s/it]0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  362  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  363  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  364  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  365  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  367  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  368  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  369  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  370  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  372  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  373  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  374  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  375  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  377  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  378  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  379  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  380  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  382  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  383  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  384  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  385  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  387  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  388  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  389  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  390  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  392  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  393  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  394  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  395  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  397  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  398  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  399  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  400  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  402  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  403  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  404  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  405  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  407  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  408  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  409  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  410  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  412  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  413  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  414  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  415  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.17531345784664154
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  417  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  418  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  419  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  420  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
 84%|████████▍ | 421/500 [13:24<03:32,  2.68s/it] 85%|████████▍ | 423/500 [13:24<02:26,  1.90s/it] 85%|████████▌ | 425/500 [13:31<02:50,  2.28s/it] 85%|████████▌ | 427/500 [13:31<01:57,  1.62s/it] 86%|████████▌ | 429/500 [13:31<01:21,  1.15s/it] 86%|████████▌ | 431/500 [13:44<03:06,  2.70s/it] 87%|████████▋ | 433/500 [13:44<02:08,  1.91s/it] 87%|████████▋ | 435/500 [13:50<02:28,  2.29s/it] 87%|████████▋ | 437/500 [13:50<01:42,  1.63s/it] 88%|████████▊ | 439/500 [13:51<01:11,  1.17s/it] 88%|████████▊ | 441/500 [14:03<02:41,  2.74s/it] 89%|████████▊ | 443/500 [14:03<01:50,  1.94s/it] 89%|████████▉ | 445/500 [14:10<02:06,  2.29s/it] 89%|████████▉ | 447/500 [14:10<01:26,  1.63s/it] 90%|████████▉ | 449/500 [14:10<00:59,  1.16s/it] 90%|█████████ | 451/500 [14:23<02:12,  2.71s/it] 91%|█████████ | 453/500 [14:23<01:30,  1.92s/it] 91%|█████████ | 455/500 [14:29<01:44,  2.31s/it] 91%|█████████▏| 457/500 [14:29<01:10,  1.64s/it] 92%|█████████▏| 459/500 [14:30<00:47,  1.17s/it] 92%|█████████▏| 461/500 [14:42<01:46,  2.72s/it] 93%|█████████▎| 463/500 [14:42<01:11,  1.93s/it] 93%|█████████▎| 465/500 [14:49<01:20,  2.30s/it] 93%|█████████▎| 467/500 [14:49<00:54,  1.64s/it] 94%|█████████▍| 469/500 [14:49<00:36,  1.17s/it] 94%|█████████▍| 471/500 [15:02<01:17,  2.69s/it] 95%|█████████▍| 473/500 [15:02<00:51,  1.90s/it] 95%|█████████▌| 475/500 [15:08<00:56,  2.27s/it] 95%|█████████▌| 477/500 [15:08<00:36,  1.61s/it] 96%|█████████▌| 479/500 [15:08<00:24,  1.15s/it]Epoch:  421  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  422  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  423  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  424  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  425  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  427  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  428  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  429  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  430  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  432  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724491357803345
Epoch:  433  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  434  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  435  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  437  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  438  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  439  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  440  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  442  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  443  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  444  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  445  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  447  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  448  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  449  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  450  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  452  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  453  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  454  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  455  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  457  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  458  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  459  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  460  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  462  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  463  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  464  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  465  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  467  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  468  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  469  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  470  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  472  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  473  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  474  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  475  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  477  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  478  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  479  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  480  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064394235611
Valid Loss:  0.22724488377571106
 96%|█████████▌| 481/500 [15:21<00:51,  2.71s/it] 97%|█████████▋| 483/500 [15:21<00:32,  1.92s/it] 97%|█████████▋| 485/500 [15:27<00:34,  2.30s/it] 97%|█████████▋| 487/500 [15:28<00:21,  1.63s/it] 98%|█████████▊| 489/500 [15:28<00:12,  1.16s/it] 98%|█████████▊| 491/500 [15:40<00:24,  2.71s/it] 99%|█████████▊| 493/500 [15:40<00:13,  1.92s/it] 99%|█████████▉| 495/500 [15:47<00:11,  2.29s/it] 99%|█████████▉| 497/500 [15:47<00:04,  1.63s/it]100%|█████████▉| 499/500 [15:47<00:01,  1.16s/it]100%|██████████| 500/500 [15:53<00:00,  1.91s/it]
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  482  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  483  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  484  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  485  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  487  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  488  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  489  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  490  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  492  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  493  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  494  	Training Loss: 0.17531347274780273
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  495  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  497  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
Epoch:  498  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724489867687225
Epoch:  499  	Training Loss: 0.17531345784664154
Test Loss:  0.23340646922588348
Valid Loss:  0.22724488377571106
Epoch:  500  	Training Loss: 0.17531347274780273
Test Loss:  0.2334064543247223
Valid Loss:  0.22724488377571106
**************************************************learning rate decay**************************************************
seed is  13
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:32,  6.20s/it]  1%|          | 3/500 [00:06<13:43,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:27<09:24,  1.20s/it]  7%|▋         | 33/500 [00:27<06:45,  1.15it/s]  7%|▋         | 35/500 [00:27<04:54,  1.58it/s]  7%|▋         | 37/500 [00:27<03:36,  2.14it/s]  8%|▊         | 39/500 [00:27<02:39,  2.88it/s]  8%|▊         | 41/500 [00:33<09:07,  1.19s/it]  9%|▊         | 43/500 [00:34<06:34,  1.16it/s]  9%|▉         | 45/500 [00:34<04:45,  1.59it/s]  9%|▉         | 47/500 [00:34<03:28,  2.18it/s] 10%|▉         | 49/500 [00:34<02:33,  2.93it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:41<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:27,  3.00it/s] 12%|█▏        | 61/500 [00:47<08:26,  1.15s/it] 13%|█▎        | 63/500 [00:47<06:02,  1.20it/s] 13%|█▎        | 65/500 [00:47<04:21,  1.66it/s] 13%|█▎        | 67/500 [00:47<03:10,  2.27it/s] 14%|█▍        | 69/500 [00:48<02:21,  3.05it/s] 14%|█▍        | 71/500 [00:54<08:29,  1.19s/it]Epoch:  1  	Training Loss: 0.04473323002457619
Test Loss:  11.662294387817383
Valid Loss:  11.721354484558105
Epoch:  2  	Training Loss: 10.41790771484375
Test Loss:  12.223230361938477
Valid Loss:  11.621381759643555
Epoch:  3  	Training Loss: 11.386211395263672
Test Loss:  0.08762979507446289
Valid Loss:  0.09021612256765366
Epoch:  4  	Training Loss: 0.06659089028835297
Test Loss:  0.026166727766394615
Valid Loss:  0.033887289464473724
Epoch:  5  	Training Loss: 0.033918894827365875
Test Loss:  0.0237896628677845
Valid Loss:  0.030756667256355286
Epoch:  6  	Training Loss: 0.030590467154979706
Test Loss:  0.03440801054239273
Valid Loss:  0.03650519996881485
Epoch:  7  	Training Loss: 0.030762583017349243
Test Loss:  0.022792097181081772
Valid Loss:  0.028701188042759895
Epoch:  8  	Training Loss: 0.02689472585916519
Test Loss:  0.027291368693113327
Valid Loss:  0.02833191491663456
Epoch:  9  	Training Loss: 0.02456550858914852
Test Loss:  0.02217896096408367
Valid Loss:  0.026453163474798203
Epoch:  10  	Training Loss: 0.023081444203853607
Test Loss:  0.023585930466651917
Valid Loss:  0.025925442576408386
Epoch:  11  	Training Loss: 0.022027157247066498
Test Loss:  0.022534888237714767
Valid Loss:  0.02556399255990982
Epoch:  12  	Training Loss: 0.021382849663496017
Test Loss:  0.022734932601451874
Valid Loss:  0.025298118591308594
Epoch:  13  	Training Loss: 0.02084239572286606
Test Loss:  0.022361695766448975
Valid Loss:  0.025026874616742134
Epoch:  14  	Training Loss: 0.02037821337580681
Test Loss:  0.022107984870672226
Valid Loss:  0.024795178323984146
Epoch:  15  	Training Loss: 0.019956592470407486
Test Loss:  0.021898120641708374
Valid Loss:  0.024588368833065033
Epoch:  16  	Training Loss: 0.019574053585529327
Test Loss:  0.021681318059563637
Valid Loss:  0.024399731308221817
Epoch:  17  	Training Loss: 0.019220465794205666
Test Loss:  0.021453451365232468
Valid Loss:  0.024239882826805115
Epoch:  18  	Training Loss: 0.018883854150772095
Test Loss:  0.02130909264087677
Valid Loss:  0.024107549339532852
Epoch:  19  	Training Loss: 0.018567640334367752
Test Loss:  0.021255670115351677
Valid Loss:  0.02397657185792923
Epoch:  20  	Training Loss: 0.018285593017935753
Test Loss:  0.021197743713855743
Valid Loss:  0.02385997585952282
Epoch:  21  	Training Loss: 0.018030475825071335
Test Loss:  0.021117256954312325
Valid Loss:  0.023754065856337547
Epoch:  22  	Training Loss: 0.01779106818139553
Test Loss:  0.021065186709165573
Valid Loss:  0.023654401302337646
Epoch:  23  	Training Loss: 0.0175730399787426
Test Loss:  0.021022936329245567
Valid Loss:  0.023562315851449966
Epoch:  24  	Training Loss: 0.017373597249388695
Test Loss:  0.021000981330871582
Valid Loss:  0.02347930707037449
Epoch:  25  	Training Loss: 0.01719357632100582
Test Loss:  0.020975686609745026
Valid Loss:  0.023404080420732498
Epoch:  26  	Training Loss: 0.017030727118253708
Test Loss:  0.020937081426382065
Valid Loss:  0.023332983255386353
Epoch:  27  	Training Loss: 0.016879893839359283
Test Loss:  0.020880810916423798
Valid Loss:  0.0232628732919693
Epoch:  28  	Training Loss: 0.01673535443842411
Test Loss:  0.020819518715143204
Valid Loss:  0.023202497512102127
Epoch:  29  	Training Loss: 0.016602298244833946
Test Loss:  0.02082599326968193
Valid Loss:  0.023149993270635605
Epoch:  30  	Training Loss: 0.016480056568980217
Test Loss:  0.02079274319112301
Valid Loss:  0.023103807121515274
Epoch:  31  	Training Loss: 0.016368404030799866
Test Loss:  0.02077270671725273
Valid Loss:  0.023061061277985573
Epoch:  32  	Training Loss: 0.01626594364643097
Test Loss:  0.020745445042848587
Valid Loss:  0.023021113127470016
Epoch:  33  	Training Loss: 0.016170324757695198
Test Loss:  0.02071642503142357
Valid Loss:  0.022983472794294357
Epoch:  34  	Training Loss: 0.016080472618341446
Test Loss:  0.02067398838698864
Valid Loss:  0.02294658124446869
Epoch:  35  	Training Loss: 0.015994973480701447
Test Loss:  0.0206675473600626
Valid Loss:  0.022914942353963852
Epoch:  36  	Training Loss: 0.015917273238301277
Test Loss:  0.020664311945438385
Valid Loss:  0.022886835038661957
Epoch:  37  	Training Loss: 0.015846673399209976
Test Loss:  0.020636294037103653
Valid Loss:  0.02285745181143284
Epoch:  38  	Training Loss: 0.015780337154865265
Test Loss:  0.020612623542547226
Valid Loss:  0.022829942405223846
Epoch:  39  	Training Loss: 0.01571767032146454
Test Loss:  0.02058134600520134
Valid Loss:  0.02280166745185852
Epoch:  40  	Training Loss: 0.0156569667160511
Test Loss:  0.020548533648252487
Valid Loss:  0.02277340367436409
Epoch:  41  	Training Loss: 0.015597796067595482
Test Loss:  0.020516986027359962
Valid Loss:  0.0227455236017704
Epoch:  42  	Training Loss: 0.015540046617388725
Test Loss:  0.020485863089561462
Valid Loss:  0.022718504071235657
Epoch:  43  	Training Loss: 0.015484318137168884
Test Loss:  0.020468048751354218
Valid Loss:  0.022694341838359833
Epoch:  44  	Training Loss: 0.015431440435349941
Test Loss:  0.0204458087682724
Valid Loss:  0.022669754922389984
Epoch:  45  	Training Loss: 0.015380248427391052
Test Loss:  0.020438944920897484
Valid Loss:  0.02264998108148575
Epoch:  46  	Training Loss: 0.015332918614149094
Test Loss:  0.020422354340553284
Valid Loss:  0.02262848988175392
Epoch:  47  	Training Loss: 0.015287346206605434
Test Loss:  0.020401839166879654
Valid Loss:  0.022606439888477325
Epoch:  48  	Training Loss: 0.01524349395185709
Test Loss:  0.020388104021549225
Valid Loss:  0.022586900740861893
Epoch:  49  	Training Loss: 0.015201549977064133
Test Loss:  0.02037014067173004
Valid Loss:  0.022566473111510277
Epoch:  50  	Training Loss: 0.015160707756876945
Test Loss:  0.020352721214294434
Valid Loss:  0.02254590205848217
Epoch:  51  	Training Loss: 0.015120786614716053
Test Loss:  0.02033483237028122
Valid Loss:  0.022525528445839882
Epoch:  52  	Training Loss: 0.015081736259162426
Test Loss:  0.020318783819675446
Valid Loss:  0.022505447268486023
Epoch:  53  	Training Loss: 0.015043678693473339
Test Loss:  0.02030964568257332
Valid Loss:  0.02248810976743698
Epoch:  54  	Training Loss: 0.01500747911632061
Test Loss:  0.020297611132264137
Valid Loss:  0.02247004583477974
Epoch:  55  	Training Loss: 0.01497240737080574
Test Loss:  0.020289987325668335
Valid Loss:  0.022454233840107918
Epoch:  56  	Training Loss: 0.014938995242118835
Test Loss:  0.020279012620449066
Valid Loss:  0.02243744023144245
Epoch:  57  	Training Loss: 0.01490643247961998
Test Loss:  0.0202666986733675
Valid Loss:  0.02242039330303669
Epoch:  58  	Training Loss: 0.014874564483761787
Test Loss:  0.02025395818054676
Valid Loss:  0.022403445094823837
Epoch:  59  	Training Loss: 0.01484336145222187
Test Loss:  0.02024117298424244
Valid Loss:  0.022386731579899788
Epoch:  60  	Training Loss: 0.014812793582677841
Test Loss:  0.02022853121161461
Valid Loss:  0.022370323538780212
Epoch:  61  	Training Loss: 0.014782858081161976
Test Loss:  0.020216088742017746
Valid Loss:  0.022354237735271454
Epoch:  62  	Training Loss: 0.014753531664609909
Test Loss:  0.02020466886460781
Valid Loss:  0.02233840338885784
Epoch:  63  	Training Loss: 0.014724764041602612
Test Loss:  0.020194701850414276
Valid Loss:  0.022322900593280792
Epoch:  64  	Training Loss: 0.01469658687710762
Test Loss:  0.020184926688671112
Valid Loss:  0.022307725623250008
Epoch:  65  	Training Loss: 0.014669517055153847
Test Loss:  0.020183153450489044
Valid Loss:  0.02229691669344902
Epoch:  66  	Training Loss: 0.01464398205280304
Test Loss:  0.020177334547042847
Valid Loss:  0.02228446491062641
Epoch:  67  	Training Loss: 0.014619288966059685
Test Loss:  0.020169764757156372
Valid Loss:  0.02227184548974037
Epoch:  68  	Training Loss: 0.014595143496990204
Test Loss:  0.020161494612693787
Valid Loss:  0.02226027473807335
Epoch:  69  	Training Loss: 0.014571767300367355
Test Loss:  0.02015676535665989
Valid Loss:  0.022250289097428322
Epoch:  70  	Training Loss: 0.014549557119607925
Test Loss:  0.020153746008872986
Valid Loss:  0.022241301834583282
Epoch:  71  	Training Loss: 0.014528265222907066
Test Loss:  0.020147882401943207
Valid Loss:  0.022231459617614746
Epoch:  72  	Training Loss: 0.014507537707686424
 15%|█▍        | 73/500 [00:54<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:54<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:01<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:01<04:20,  1.59it/s] 17%|█▋        | 87/500 [01:01<03:11,  2.15it/s] 18%|█▊        | 89/500 [01:02<02:21,  2.90it/s] 18%|█▊        | 91/500 [01:08<08:16,  1.21s/it] 19%|█▊        | 93/500 [01:08<05:55,  1.15it/s] 19%|█▉        | 95/500 [01:08<04:15,  1.59it/s] 19%|█▉        | 97/500 [01:08<03:05,  2.17it/s] 20%|█▉        | 99/500 [01:09<02:17,  2.92it/s] 20%|██        | 101/500 [01:15<08:01,  1.21s/it] 21%|██        | 103/500 [01:15<05:44,  1.15it/s] 21%|██        | 105/500 [01:15<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:15<03:00,  2.18it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.94it/s] 22%|██▏       | 111/500 [01:22<07:51,  1.21s/it] 23%|██▎       | 113/500 [01:22<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:22<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:22<02:55,  2.18it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.93it/s] 24%|██▍       | 121/500 [01:29<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:29<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:29<02:05,  2.97it/s] 26%|██▌       | 131/500 [01:36<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:36<05:12,  1.18it/s] 27%|██▋       | 135/500 [01:36<03:44,  1.62it/s] 27%|██▋       | 137/500 [01:36<02:45,  2.20it/s] 28%|██▊       | 139/500 [01:36<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:43<07:12,  1.21s/it]Test Loss:  0.0201407577842474
Valid Loss:  0.022221270948648453
Epoch:  73  	Training Loss: 0.014487555250525475
Test Loss:  0.020136794075369835
Valid Loss:  0.022212598472833633
Epoch:  74  	Training Loss: 0.014468269422650337
Test Loss:  0.020130744203925133
Valid Loss:  0.022203274071216583
Epoch:  75  	Training Loss: 0.014449424110352993
Test Loss:  0.020123813301324844
Valid Loss:  0.02219374105334282
Epoch:  76  	Training Loss: 0.014430945739150047
Test Loss:  0.020116552710533142
Valid Loss:  0.022184208035469055
Epoch:  77  	Training Loss: 0.014412952587008476
Test Loss:  0.020112644881010056
Valid Loss:  0.022176280617713928
Epoch:  78  	Training Loss: 0.014395725913345814
Test Loss:  0.020106960088014603
Valid Loss:  0.022167770192027092
Epoch:  79  	Training Loss: 0.014378886669874191
Test Loss:  0.020100492984056473
Valid Loss:  0.022159051150083542
Epoch:  80  	Training Loss: 0.014362351968884468
Test Loss:  0.02009374275803566
Valid Loss:  0.02215033397078514
Epoch:  81  	Training Loss: 0.014346121810376644
Test Loss:  0.020086925476789474
Valid Loss:  0.022141696885228157
Epoch:  82  	Training Loss: 0.014330173842608929
Test Loss:  0.02008020505309105
Valid Loss:  0.022133391350507736
Epoch:  83  	Training Loss: 0.014314986765384674
Test Loss:  0.020079847425222397
Valid Loss:  0.022128311917185783
Epoch:  84  	Training Loss: 0.014300495386123657
Test Loss:  0.020076310262084007
Valid Loss:  0.022122427821159363
Epoch:  85  	Training Loss: 0.014286484569311142
Test Loss:  0.02007131464779377
Valid Loss:  0.022116191685199738
Epoch:  86  	Training Loss: 0.014272762462496758
Test Loss:  0.020065676420927048
Valid Loss:  0.02210984192788601
Epoch:  87  	Training Loss: 0.014259286224842072
Test Loss:  0.020059797912836075
Valid Loss:  0.022103499621152878
Epoch:  88  	Training Loss: 0.014246044680476189
Test Loss:  0.020053856074810028
Valid Loss:  0.022097211331129074
Epoch:  89  	Training Loss: 0.014233126305043697
Test Loss:  0.02005087025463581
Valid Loss:  0.022092044353485107
Epoch:  90  	Training Loss: 0.014220748096704483
Test Loss:  0.020046420395374298
Valid Loss:  0.022086486220359802
Epoch:  91  	Training Loss: 0.014208626002073288
Test Loss:  0.02004132606089115
Valid Loss:  0.022080786526203156
Epoch:  92  	Training Loss: 0.014196719042956829
Test Loss:  0.020035982131958008
Valid Loss:  0.022075075656175613
Epoch:  93  	Training Loss: 0.014185016043484211
Test Loss:  0.020030567422509193
Valid Loss:  0.022069409489631653
Epoch:  94  	Training Loss: 0.014173715375363827
Test Loss:  0.020027901977300644
Valid Loss:  0.022064823657274246
Epoch:  95  	Training Loss: 0.014162769541144371
Test Loss:  0.020023874938488007
Valid Loss:  0.022059844806790352
Epoch:  96  	Training Loss: 0.014152051880955696
Test Loss:  0.020019235089421272
Valid Loss:  0.02205471321940422
Epoch:  97  	Training Loss: 0.014141516759991646
Test Loss:  0.02001434937119484
Valid Loss:  0.02204955741763115
Epoch:  98  	Training Loss: 0.014131154865026474
Test Loss:  0.02000938542187214
Valid Loss:  0.022044431418180466
Epoch:  99  	Training Loss: 0.01412113755941391
Test Loss:  0.02000698447227478
Valid Loss:  0.02204034850001335
Epoch:  100  	Training Loss: 0.014111433178186417
Test Loss:  0.020003322511911392
Valid Loss:  0.0220358744263649
Epoch:  101  	Training Loss: 0.01410192996263504
Test Loss:  0.019999083131551743
Valid Loss:  0.02203124389052391
Epoch:  102  	Training Loss: 0.014092739671468735
Test Loss:  0.019997065886855125
Valid Loss:  0.02202754281461239
Epoch:  103  	Training Loss: 0.014083820395171642
Test Loss:  0.019993707537651062
Valid Loss:  0.02202339470386505
Epoch:  104  	Training Loss: 0.014075087383389473
Test Loss:  0.01998971402645111
Valid Loss:  0.022019051015377045
Epoch:  105  	Training Loss: 0.014066494069993496
Test Loss:  0.019985463470220566
Valid Loss:  0.022014658898115158
Epoch:  106  	Training Loss: 0.014058036729693413
Test Loss:  0.019981108605861664
Valid Loss:  0.022010263055562973
Epoch:  107  	Training Loss: 0.014049800112843513
Test Loss:  0.019979098811745644
Valid Loss:  0.022006891667842865
Epoch:  108  	Training Loss: 0.014041881076991558
Test Loss:  0.019975926727056503
Valid Loss:  0.022003106772899628
Epoch:  109  	Training Loss: 0.014034109190106392
Test Loss:  0.019972214475274086
Valid Loss:  0.02199915237724781
Epoch:  110  	Training Loss: 0.0140264593064785
Test Loss:  0.01996827870607376
Valid Loss:  0.021995149552822113
Epoch:  111  	Training Loss: 0.014018930494785309
Test Loss:  0.019964253529906273
Valid Loss:  0.021991144865751266
Epoch:  112  	Training Loss: 0.014011571183800697
Test Loss:  0.019962556660175323
Valid Loss:  0.02198825776576996
Epoch:  113  	Training Loss: 0.01400461234152317
Test Loss:  0.019959818571805954
Valid Loss:  0.02198503352701664
Epoch:  114  	Training Loss: 0.01399778202176094
Test Loss:  0.019957054406404495
Valid Loss:  0.021982088685035706
Epoch:  115  	Training Loss: 0.013991057872772217
Test Loss:  0.01995408535003662
Valid Loss:  0.021979106590151787
Epoch:  116  	Training Loss: 0.013984564691781998
Test Loss:  0.01995292864739895
Valid Loss:  0.021976836025714874
Epoch:  117  	Training Loss: 0.013978267088532448
Test Loss:  0.01995081454515457
Valid Loss:  0.021974261850118637
Epoch:  118  	Training Loss: 0.0139720868319273
Test Loss:  0.01994824782013893
Valid Loss:  0.021971555426716805
Epoch:  119  	Training Loss: 0.013966001570224762
Test Loss:  0.019945479929447174
Valid Loss:  0.02196880616247654
Epoch:  120  	Training Loss: 0.013960006646811962
Test Loss:  0.019942622631788254
Valid Loss:  0.02196604758501053
Epoch:  121  	Training Loss: 0.013954089023172855
Test Loss:  0.01993974670767784
Valid Loss:  0.02196330763399601
Epoch:  122  	Training Loss: 0.01394825242459774
Test Loss:  0.019936762750148773
Valid Loss:  0.021960465237498283
Epoch:  123  	Training Loss: 0.013942520134150982
Test Loss:  0.019935522228479385
Valid Loss:  0.021958325058221817
Epoch:  124  	Training Loss: 0.013936949893832207
Test Loss:  0.019933460280299187
Valid Loss:  0.021955907344818115
Epoch:  125  	Training Loss: 0.013931479305028915
Test Loss:  0.019931010901927948
Valid Loss:  0.02195337787270546
Epoch:  126  	Training Loss: 0.013926094397902489
Test Loss:  0.019928378984332085
Valid Loss:  0.021950803697109222
Epoch:  127  	Training Loss: 0.013920783065259457
Test Loss:  0.0199256744235754
Valid Loss:  0.02194821834564209
Epoch:  128  	Training Loss: 0.013915540650486946
Test Loss:  0.01992296241223812
Valid Loss:  0.021945659071207047
Epoch:  129  	Training Loss: 0.01391037181019783
Test Loss:  0.019920259714126587
Valid Loss:  0.021943124011158943
Epoch:  130  	Training Loss: 0.01390527281910181
Test Loss:  0.01991758495569229
Valid Loss:  0.021940622478723526
Epoch:  131  	Training Loss: 0.013900239951908588
Test Loss:  0.01991492509841919
Valid Loss:  0.02193814516067505
Epoch:  132  	Training Loss: 0.01389527041465044
Test Loss:  0.019912321120500565
Valid Loss:  0.021935727447271347
Epoch:  133  	Training Loss: 0.01389037910848856
Test Loss:  0.019909758120775223
Valid Loss:  0.021933341398835182
Epoch:  134  	Training Loss: 0.013885557651519775
Test Loss:  0.01990722306072712
Valid Loss:  0.021930987015366554
Epoch:  135  	Training Loss: 0.01388079859316349
Test Loss:  0.019904725253582
Valid Loss:  0.02192866988480091
Epoch:  136  	Training Loss: 0.013876102864742279
Test Loss:  0.01990225911140442
Valid Loss:  0.021926380693912506
Epoch:  137  	Training Loss: 0.013871468603610992
Test Loss:  0.019899826496839523
Valid Loss:  0.021924123167991638
Epoch:  138  	Training Loss: 0.013866889290511608
Test Loss:  0.019897431135177612
Valid Loss:  0.021921899169683456
Epoch:  139  	Training Loss: 0.013862377032637596
Test Loss:  0.019895069301128387
Valid Loss:  0.02191970869898796
Epoch:  140  	Training Loss: 0.013857926242053509
Test Loss:  0.01989273726940155
Valid Loss:  0.02191755175590515
Epoch:  141  	Training Loss: 0.013853533193469048
Test Loss:  0.01989044062793255
Valid Loss:  0.02191542088985443
Epoch:  142  	Training Loss: 0.013849198818206787
Test Loss:  0.01988823525607586
Valid Loss:  0.02191338688135147
 29%|██▊       | 143/500 [01:43<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:43<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:43<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.95it/s] 30%|███       | 151/500 [01:50<06:56,  1.19s/it] 31%|███       | 153/500 [01:50<04:57,  1.17it/s] 31%|███       | 155/500 [01:50<03:33,  1.62it/s] 31%|███▏      | 157/500 [01:50<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:50<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:57<06:46,  1.20s/it] 33%|███▎      | 163/500 [01:57<04:50,  1.16it/s] 33%|███▎      | 165/500 [01:57<03:28,  1.61it/s] 33%|███▎      | 167/500 [01:57<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:57<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:03<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:04<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:04<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:04<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:04<01:46,  3.03it/s] 36%|███▌      | 181/500 [02:10<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:16,  1.60it/s] 37%|███▋      | 187/500 [02:11<02:23,  2.18it/s] 38%|███▊      | 189/500 [02:11<01:47,  2.89it/s] 38%|███▊      | 191/500 [02:17<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:17<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:18<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:18<01:40,  2.98it/s] 40%|████      | 201/500 [02:24<05:58,  1.20s/it] 41%|████      | 203/500 [02:24<04:15,  1.16it/s] 41%|████      | 205/500 [02:24<03:03,  1.61it/s] 41%|████▏     | 207/500 [02:25<02:13,  2.20it/s] 42%|████▏     | 209/500 [02:25<01:39,  2.93it/s] 42%|████▏     | 211/500 [02:31<05:45,  1.20s/it]Epoch:  143  	Training Loss: 0.013844961300492287
Test Loss:  0.019886061549186707
Valid Loss:  0.0219113789498806
Epoch:  144  	Training Loss: 0.013840781524777412
Test Loss:  0.019883915781974792
Valid Loss:  0.021909402683377266
Epoch:  145  	Training Loss: 0.013836655765771866
Test Loss:  0.01988179422914982
Valid Loss:  0.02190745249390602
Epoch:  146  	Training Loss: 0.013832584023475647
Test Loss:  0.01987970434129238
Valid Loss:  0.021905533969402313
Epoch:  147  	Training Loss: 0.013828566297888756
Test Loss:  0.01987764611840248
Valid Loss:  0.021903637796640396
Epoch:  148  	Training Loss: 0.013824605382978916
Test Loss:  0.01987561583518982
Valid Loss:  0.021901769563555717
Epoch:  149  	Training Loss: 0.013820692896842957
Test Loss:  0.019873615354299545
Valid Loss:  0.021899931132793427
Epoch:  150  	Training Loss: 0.0138168353587389
Test Loss:  0.01987164095044136
Valid Loss:  0.021898113191127777
Epoch:  151  	Training Loss: 0.013813030906021595
Test Loss:  0.019869696348905563
Valid Loss:  0.021896328777074814
Epoch:  152  	Training Loss: 0.013809273019433022
Test Loss:  0.019867772236466408
Valid Loss:  0.021894561126828194
Epoch:  153  	Training Loss: 0.013805575668811798
Test Loss:  0.01986588165163994
Valid Loss:  0.021892819553613663
Epoch:  154  	Training Loss: 0.013801926746964455
Test Loss:  0.019864017143845558
Valid Loss:  0.02189110778272152
Epoch:  155  	Training Loss: 0.013798326253890991
Test Loss:  0.019862178713083267
Valid Loss:  0.021889418363571167
Epoch:  156  	Training Loss: 0.013794772326946259
Test Loss:  0.019860368221998215
Valid Loss:  0.021887751296162605
Epoch:  157  	Training Loss: 0.013791266828775406
Test Loss:  0.01985858380794525
Valid Loss:  0.021886112168431282
Epoch:  158  	Training Loss: 0.013787848874926567
Test Loss:  0.019857848063111305
Valid Loss:  0.021884920075535774
Epoch:  159  	Training Loss: 0.013784542679786682
Test Loss:  0.019856631755828857
Valid Loss:  0.021883554756641388
Epoch:  160  	Training Loss: 0.013781296089291573
Test Loss:  0.019855186343193054
Valid Loss:  0.02188211679458618
Epoch:  161  	Training Loss: 0.013778097927570343
Test Loss:  0.019853631034493446
Valid Loss:  0.021880637854337692
Epoch:  162  	Training Loss: 0.013774937950074673
Test Loss:  0.019851990044116974
Valid Loss:  0.021879106760025024
Epoch:  163  	Training Loss: 0.013771778903901577
Test Loss:  0.019850347191095352
Valid Loss:  0.021877596154808998
Epoch:  164  	Training Loss: 0.013768664561212063
Test Loss:  0.019848696887493134
Valid Loss:  0.02187608927488327
Epoch:  165  	Training Loss: 0.013765586540102959
Test Loss:  0.01984705962240696
Valid Loss:  0.021874595433473587
Epoch:  166  	Training Loss: 0.013762548565864563
Test Loss:  0.019845452159643173
Valid Loss:  0.02187313139438629
Epoch:  167  	Training Loss: 0.013759552501142025
Test Loss:  0.019843989983201027
Valid Loss:  0.02187167853116989
Epoch:  168  	Training Loss: 0.013756591826677322
Test Loss:  0.01984262838959694
Valid Loss:  0.021870246157050133
Epoch:  169  	Training Loss: 0.013753671199083328
Test Loss:  0.01984129101037979
Valid Loss:  0.021868843585252762
Epoch:  170  	Training Loss: 0.013750789687037468
Test Loss:  0.01983996108174324
Valid Loss:  0.02186744287610054
Epoch:  171  	Training Loss: 0.013747939839959145
Test Loss:  0.019838649779558182
Valid Loss:  0.021866071969270706
Epoch:  172  	Training Loss: 0.013745129108428955
Test Loss:  0.019837381318211555
Valid Loss:  0.021864738315343857
Epoch:  173  	Training Loss: 0.013742370530962944
Test Loss:  0.019836124032735825
Valid Loss:  0.0218634232878685
Epoch:  174  	Training Loss: 0.013739644549787045
Test Loss:  0.019834883511066437
Valid Loss:  0.021862128749489784
Epoch:  175  	Training Loss: 0.013736957684159279
Test Loss:  0.019833659753203392
Valid Loss:  0.02186085283756256
Epoch:  176  	Training Loss: 0.013734303414821625
Test Loss:  0.01983245462179184
Valid Loss:  0.02185959182679653
Epoch:  177  	Training Loss: 0.013731684535741806
Test Loss:  0.019831962883472443
Valid Loss:  0.021858688443899155
Epoch:  178  	Training Loss: 0.013729175552725792
Test Loss:  0.01983114890754223
Valid Loss:  0.021857647225260735
Epoch:  179  	Training Loss: 0.01372670941054821
Test Loss:  0.01983017474412918
Valid Loss:  0.021856538951396942
Epoch:  180  	Training Loss: 0.013724276795983315
Test Loss:  0.019829124212265015
Valid Loss:  0.02185540646314621
Epoch:  181  	Training Loss: 0.013721874915063381
Test Loss:  0.019828040152788162
Valid Loss:  0.02185426466166973
Epoch:  182  	Training Loss: 0.013719502836465836
Test Loss:  0.019826913252472878
Valid Loss:  0.021853096783161163
Epoch:  183  	Training Loss: 0.013717134483158588
Test Loss:  0.019825782626867294
Valid Loss:  0.021851932629942894
Epoch:  184  	Training Loss: 0.013714795000851154
Test Loss:  0.019824666902422905
Valid Loss:  0.021850785240530968
Epoch:  185  	Training Loss: 0.013712484389543533
Test Loss:  0.01982356235384941
Valid Loss:  0.021849650889635086
Epoch:  186  	Training Loss: 0.013710202649235725
Test Loss:  0.019822467118501663
Valid Loss:  0.021848531439900398
Epoch:  187  	Training Loss: 0.01370794977992773
Test Loss:  0.01982138492166996
Valid Loss:  0.021847428753972054
Epoch:  188  	Training Loss: 0.013705726712942123
Test Loss:  0.0198203194886446
Valid Loss:  0.021846340969204903
Epoch:  189  	Training Loss: 0.013703529722988605
Test Loss:  0.019819265231490135
Valid Loss:  0.021845269948244095
Epoch:  190  	Training Loss: 0.013701360672712326
Test Loss:  0.019818225875496864
Valid Loss:  0.021844208240509033
Epoch:  191  	Training Loss: 0.01369921863079071
Test Loss:  0.019817199558019638
Valid Loss:  0.021843163296580315
Epoch:  192  	Training Loss: 0.013697104528546333
Test Loss:  0.01981622353196144
Valid Loss:  0.02184217795729637
Epoch:  193  	Training Loss: 0.01369507610797882
Test Loss:  0.01981639489531517
Valid Loss:  0.02184176817536354
Epoch:  194  	Training Loss: 0.013693143613636494
Test Loss:  0.019816039130091667
Valid Loss:  0.02184111997485161
Epoch:  195  	Training Loss: 0.013691265136003494
Test Loss:  0.019815411418676376
Valid Loss:  0.021840348839759827
Epoch:  196  	Training Loss: 0.013689419254660606
Test Loss:  0.01981465145945549
Valid Loss:  0.02183951437473297
Epoch:  197  	Training Loss: 0.01368759572505951
Test Loss:  0.019813820719718933
Valid Loss:  0.021838653832674026
Epoch:  198  	Training Loss: 0.013685792684555054
Test Loss:  0.019812965765595436
Valid Loss:  0.021837785840034485
Epoch:  199  	Training Loss: 0.013684013858437538
Test Loss:  0.019812101498246193
Valid Loss:  0.02183692157268524
Epoch:  200  	Training Loss: 0.013682257384061813
Test Loss:  0.019811242818832397
Valid Loss:  0.021836068481206894
Epoch:  201  	Training Loss: 0.013680534437298775
Test Loss:  0.01981090009212494
Valid Loss:  0.021835487335920334
Epoch:  202  	Training Loss: 0.013678867369890213
Test Loss:  0.019810307770967484
Valid Loss:  0.02183477208018303
Epoch:  203  	Training Loss: 0.013677209615707397
Test Loss:  0.01980958878993988
Valid Loss:  0.021834004670381546
Epoch:  204  	Training Loss: 0.013675576075911522
Test Loss:  0.019808821380138397
Valid Loss:  0.021833214908838272
Epoch:  205  	Training Loss: 0.013673963025212288
Test Loss:  0.019808020442724228
Valid Loss:  0.021832413971424103
Epoch:  206  	Training Loss: 0.013672368600964546
Test Loss:  0.01980721205472946
Valid Loss:  0.02183161862194538
Epoch:  207  	Training Loss: 0.013670792803168297
Test Loss:  0.019806407392024994
Valid Loss:  0.021830828860402107
Epoch:  208  	Training Loss: 0.01366923563182354
Test Loss:  0.019805602729320526
Valid Loss:  0.02183004841208458
Epoch:  209  	Training Loss: 0.0136676961556077
Test Loss:  0.019804805517196655
Valid Loss:  0.0218292735517025
Epoch:  210  	Training Loss: 0.013666175305843353
Test Loss:  0.01980401948094368
Valid Loss:  0.021828509867191315
Epoch:  211  	Training Loss: 0.013664670288562775
Test Loss:  0.01980324275791645
Valid Loss:  0.021827753633260727
Epoch:  212  	Training Loss: 0.013663182035088539
Test Loss:  0.019802458584308624
Valid Loss:  0.02182699739933014
Epoch:  213  	Training Loss: 0.013661706820130348
Test Loss:   43%|████▎     | 213/500 [02:31<04:06,  1.17it/s] 43%|████▎     | 215/500 [02:31<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:32<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:32<01:34,  2.96it/s] 44%|████▍     | 221/500 [02:38<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:38<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:38<02:52,  1.59it/s] 45%|████▌     | 227/500 [02:39<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:39<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:45<05:30,  1.23s/it] 47%|████▋     | 233/500 [02:45<03:55,  1.13it/s] 47%|████▋     | 235/500 [02:46<02:48,  1.57it/s] 47%|████▋     | 237/500 [02:46<02:02,  2.15it/s] 48%|████▊     | 239/500 [02:46<01:30,  2.90it/s] 48%|████▊     | 241/500 [02:52<05:08,  1.19s/it] 49%|████▊     | 243/500 [02:52<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:52<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:53<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:53<01:24,  2.99it/s] 50%|█████     | 251/500 [02:59<04:56,  1.19s/it] 51%|█████     | 253/500 [02:59<03:30,  1.17it/s] 51%|█████     | 255/500 [02:59<02:31,  1.62it/s] 51%|█████▏    | 257/500 [02:59<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:00<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:06<04:45,  1.20s/it] 53%|█████▎    | 263/500 [03:06<03:23,  1.17it/s] 53%|█████▎    | 265/500 [03:06<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:06<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:06<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:13<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:13<03:11,  1.18it/s] 55%|█████▌    | 275/500 [03:13<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:13<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:13<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:20<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:20<03:05,  1.17it/s]0.019801683723926544
Valid Loss:  0.02182624861598015
Epoch:  214  	Training Loss: 0.013660242781043053
Test Loss:  0.01980092003941536
Valid Loss:  0.021825509145855904
Epoch:  215  	Training Loss: 0.01365879736840725
Test Loss:  0.01980016380548477
Valid Loss:  0.021824784576892853
Epoch:  216  	Training Loss: 0.01365736685693264
Test Loss:  0.01979941874742508
Valid Loss:  0.02182406559586525
Epoch:  217  	Training Loss: 0.013655953109264374
Test Loss:  0.019798681139945984
Valid Loss:  0.021823393180966377
Epoch:  218  	Training Loss: 0.01365455612540245
Test Loss:  0.01979794353246689
Valid Loss:  0.021822776645421982
Epoch:  219  	Training Loss: 0.013653181493282318
Test Loss:  0.019797634333372116
Valid Loss:  0.021822363138198853
Epoch:  220  	Training Loss: 0.013651855289936066
Test Loss:  0.01979714073240757
Valid Loss:  0.021821873262524605
Epoch:  221  	Training Loss: 0.013650551438331604
Test Loss:  0.019796550273895264
Valid Loss:  0.02182134799659252
Epoch:  222  	Training Loss: 0.013649259693920612
Test Loss:  0.019795916974544525
Valid Loss:  0.0218207985162735
Epoch:  223  	Training Loss: 0.01364798191934824
Test Loss:  0.019795257598161697
Valid Loss:  0.021820245310664177
Epoch:  224  	Training Loss: 0.013646716251969337
Test Loss:  0.019794592633843422
Valid Loss:  0.021819693967700005
Epoch:  225  	Training Loss: 0.013645466417074203
Test Loss:  0.019793935120105743
Valid Loss:  0.02181915193796158
Epoch:  226  	Training Loss: 0.013644235208630562
Test Loss:  0.019793275743722916
Valid Loss:  0.021818606182932854
Epoch:  227  	Training Loss: 0.013643011450767517
Test Loss:  0.019792616367340088
Valid Loss:  0.021818066015839577
Epoch:  228  	Training Loss: 0.013641802594065666
Test Loss:  0.019791964441537857
Valid Loss:  0.021817535161972046
Epoch:  229  	Training Loss: 0.013640605844557285
Test Loss:  0.01979132741689682
Valid Loss:  0.021817009896039963
Epoch:  230  	Training Loss: 0.013639422133564949
Test Loss:  0.019790690392255783
Valid Loss:  0.021816488355398178
Epoch:  231  	Training Loss: 0.013638252392411232
Test Loss:  0.01979006454348564
Valid Loss:  0.02181597799062729
Epoch:  232  	Training Loss: 0.013637096621096134
Test Loss:  0.019789451733231544
Valid Loss:  0.021815476939082146
Epoch:  233  	Training Loss: 0.013635956682264805
Test Loss:  0.019788846373558044
Valid Loss:  0.0218149833381176
Epoch:  234  	Training Loss: 0.013634828850626945
Test Loss:  0.01978824846446514
Valid Loss:  0.0218144953250885
Epoch:  235  	Training Loss: 0.01363371405750513
Test Loss:  0.019787658005952835
Valid Loss:  0.02181401476264
Epoch:  236  	Training Loss: 0.01363261416554451
Test Loss:  0.019787076860666275
Valid Loss:  0.021813541650772095
Epoch:  237  	Training Loss: 0.01363152265548706
Test Loss:  0.019786495715379715
Valid Loss:  0.021813075989484787
Epoch:  238  	Training Loss: 0.013630446046590805
Test Loss:  0.01978592574596405
Valid Loss:  0.02181261219084263
Epoch:  239  	Training Loss: 0.013629380613565445
Test Loss:  0.01978536695241928
Valid Loss:  0.021812157705426216
Epoch:  240  	Training Loss: 0.01362832635641098
Test Loss:  0.01978480815887451
Valid Loss:  0.021811705082654953
Epoch:  241  	Training Loss: 0.01362728513777256
Test Loss:  0.019784260541200638
Valid Loss:  0.021811261773109436
Epoch:  242  	Training Loss: 0.01362625416368246
Test Loss:  0.01978369429707527
Valid Loss:  0.021810803562402725
Epoch:  243  	Training Loss: 0.013625219464302063
Test Loss:  0.0197831392288208
Valid Loss:  0.021810349076986313
Epoch:  244  	Training Loss: 0.01362419780343771
Test Loss:  0.01978258602321148
Valid Loss:  0.021809902042150497
Epoch:  245  	Training Loss: 0.013623187318444252
Test Loss:  0.019782043993473053
Valid Loss:  0.02180946245789528
Epoch:  246  	Training Loss: 0.013622187077999115
Test Loss:  0.019781511276960373
Valid Loss:  0.021809034049510956
Epoch:  247  	Training Loss: 0.013621201738715172
Test Loss:  0.019780978560447693
Valid Loss:  0.021808601915836334
Epoch:  248  	Training Loss: 0.013620222918689251
Test Loss:  0.01978045329451561
Valid Loss:  0.021808180958032608
Epoch:  249  	Training Loss: 0.013619257137179375
Test Loss:  0.019779935479164124
Valid Loss:  0.021807760000228882
Epoch:  250  	Training Loss: 0.013618300668895245
Test Loss:  0.019779425114393234
Valid Loss:  0.021807346493005753
Epoch:  251  	Training Loss: 0.01361735351383686
Test Loss:  0.019778918474912643
Valid Loss:  0.02180694043636322
Epoch:  252  	Training Loss: 0.013616420328617096
Test Loss:  0.019778424873948097
Valid Loss:  0.021806539967656136
Epoch:  253  	Training Loss: 0.013615500181913376
Test Loss:  0.019777940586209297
Valid Loss:  0.021806152537465096
Epoch:  254  	Training Loss: 0.013614590279757977
Test Loss:  0.019777458161115646
Valid Loss:  0.021805763244628906
Epoch:  255  	Training Loss: 0.013613689690828323
Test Loss:  0.01977698504924774
Valid Loss:  0.021805379539728165
Epoch:  256  	Training Loss: 0.01361280120909214
Test Loss:  0.019776515662670135
Valid Loss:  0.02180500328540802
Epoch:  257  	Training Loss: 0.013611921109259129
Test Loss:  0.019776053726673126
Valid Loss:  0.021804632619023323
Epoch:  258  	Training Loss: 0.013611050322651863
Test Loss:  0.019775595515966415
Valid Loss:  0.021804267540574074
Epoch:  259  	Training Loss: 0.013610191643238068
Test Loss:  0.0197751447558403
Valid Loss:  0.021803906187415123
Epoch:  260  	Training Loss: 0.013609344139695168
Test Loss:  0.019774697721004486
Valid Loss:  0.02180355228483677
Epoch:  261  	Training Loss: 0.01360850129276514
Test Loss:  0.019774258136749268
Valid Loss:  0.021803198382258415
Epoch:  262  	Training Loss: 0.013607669621706009
Test Loss:  0.01977384276688099
Valid Loss:  0.0218028724193573
Epoch:  263  	Training Loss: 0.013606862165033817
Test Loss:  0.019773434847593307
Valid Loss:  0.021802550181746483
Epoch:  264  	Training Loss: 0.013606064021587372
Test Loss:  0.019773032516241074
Valid Loss:  0.021802227944135666
Epoch:  265  	Training Loss: 0.013605274260044098
Test Loss:  0.019772633910179138
Valid Loss:  0.021801915019750595
Epoch:  266  	Training Loss: 0.013604491949081421
Test Loss:  0.0197722390294075
Valid Loss:  0.021801605820655823
Epoch:  267  	Training Loss: 0.01360371895134449
Test Loss:  0.019771849736571312
Valid Loss:  0.02180130034685135
Epoch:  268  	Training Loss: 0.013602962717413902
Test Loss:  0.01977166160941124
Valid Loss:  0.021801095455884933
Epoch:  269  	Training Loss: 0.013602226041257381
Test Loss:  0.019771387800574303
Valid Loss:  0.021800849586725235
Epoch:  270  	Training Loss: 0.013601498678326607
Test Loss:  0.019771065562963486
Valid Loss:  0.021800583228468895
Epoch:  271  	Training Loss: 0.013600778765976429
Test Loss:  0.019770722836256027
Valid Loss:  0.021800309419631958
Epoch:  272  	Training Loss: 0.013600070029497147
Test Loss:  0.01977035403251648
Valid Loss:  0.02180001512169838
Epoch:  273  	Training Loss: 0.013599353842437267
Test Loss:  0.019769983366131783
Valid Loss:  0.0217997208237648
Epoch:  274  	Training Loss: 0.013598646968603134
Test Loss:  0.019769610837101936
Valid Loss:  0.021799426525831223
Epoch:  275  	Training Loss: 0.013597948476672173
Test Loss:  0.019769243896007538
Valid Loss:  0.02179914340376854
Epoch:  276  	Training Loss: 0.013597255572676659
Test Loss:  0.01976887881755829
Valid Loss:  0.021798856556415558
Epoch:  277  	Training Loss: 0.013596572913229465
Test Loss:  0.01976851560175419
Valid Loss:  0.021798577159643173
Epoch:  278  	Training Loss: 0.013595894910395145
Test Loss:  0.019768159836530685
Valid Loss:  0.02179829776287079
Epoch:  279  	Training Loss: 0.013595227152109146
Test Loss:  0.01976780779659748
Valid Loss:  0.021798022091388702
Epoch:  280  	Training Loss: 0.01359456405043602
Test Loss:  0.019767457619309425
Valid Loss:  0.021797753870487213
Epoch:  281  	Training Loss: 0.013593909330666065
Test Loss:  0.019767116755247116
Valid Loss:  0.021797485649585724
Epoch:  282  	Training Loss: 0.013593260198831558
Test Loss:  0.019766774028539658
Valid Loss:  0.021797221153974533
Epoch:  283  	Training Loss: 0.013592619448900223
Test Loss:  0.019766438752412796
Valid Loss:  0.02179695852100849
 57%|█████▋    | 285/500 [03:20<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:20<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:20<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:27<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:27<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:27<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:27<01:33,  2.18it/s] 60%|█████▉    | 299/500 [03:27<01:08,  2.93it/s] 60%|██████    | 301/500 [03:34<04:01,  1.21s/it] 61%|██████    | 303/500 [03:34<02:51,  1.15it/s] 61%|██████    | 305/500 [03:34<02:02,  1.59it/s] 61%|██████▏   | 307/500 [03:34<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:34<01:05,  2.92it/s] 62%|██████▏   | 311/500 [03:41<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:41<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:41<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:41<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:41<01:01,  2.95it/s] 64%|██████▍   | 321/500 [03:47<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:47<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:48<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:48<01:16,  2.25it/s] 66%|██████▌   | 329/500 [03:48<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:54<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:54<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:54<01:40,  1.63it/s] 67%|██████▋   | 337/500 [03:55<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:55<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:01<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:01<02:12,  1.19it/s] 69%|██████▉   | 345/500 [04:01<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:01<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:01<00:49,  3.02it/s] 70%|███████   | 351/500 [04:08<02:54,  1.17s/it] 71%|███████   | 353/500 [04:08<02:03,  1.19it/s]Epoch:  284  	Training Loss: 0.013591984286904335
Test Loss:  0.019766109064221382
Valid Loss:  0.021796705201268196
Epoch:  285  	Training Loss: 0.013591358438134193
Test Loss:  0.01976577751338482
Valid Loss:  0.0217964518815279
Epoch:  286  	Training Loss: 0.01359073631465435
Test Loss:  0.019765455275774002
Valid Loss:  0.021796204149723053
Epoch:  287  	Training Loss: 0.013590123504400253
Test Loss:  0.019765134900808334
Valid Loss:  0.021795958280563354
Epoch:  288  	Training Loss: 0.013589516282081604
Test Loss:  0.019764821976423264
Valid Loss:  0.021795712411403656
Epoch:  289  	Training Loss: 0.013588916510343552
Test Loss:  0.019764509052038193
Valid Loss:  0.021795475855469704
Epoch:  290  	Training Loss: 0.013588320463895798
Test Loss:  0.01976420171558857
Valid Loss:  0.0217952411621809
Epoch:  291  	Training Loss: 0.01358773373067379
Test Loss:  0.019763898104429245
Valid Loss:  0.021795008331537247
Epoch:  292  	Training Loss: 0.01358715258538723
Test Loss:  0.019763581454753876
Valid Loss:  0.02179475501179695
Epoch:  293  	Training Loss: 0.013586563058197498
Test Loss:  0.019763261079788208
Valid Loss:  0.021794509142637253
Epoch:  294  	Training Loss: 0.013585980981588364
Test Loss:  0.019762951880693436
Valid Loss:  0.021794263273477554
Epoch:  295  	Training Loss: 0.013585405424237251
Test Loss:  0.019762642681598663
Valid Loss:  0.021794021129608154
Epoch:  296  	Training Loss: 0.013584834523499012
Test Loss:  0.01976233720779419
Valid Loss:  0.02179378643631935
Epoch:  297  	Training Loss: 0.01358426921069622
Test Loss:  0.019762035459280014
Valid Loss:  0.0217935461550951
Epoch:  298  	Training Loss: 0.013583710417151451
Test Loss:  0.019761735573410988
Valid Loss:  0.021793313324451447
Epoch:  299  	Training Loss: 0.01358315721154213
Test Loss:  0.01976144127547741
Valid Loss:  0.021793082356452942
Epoch:  300  	Training Loss: 0.01358261052519083
Test Loss:  0.01976114884018898
Valid Loss:  0.021792855113744736
Epoch:  301  	Training Loss: 0.013582068495452404
Test Loss:  0.01976086013019085
Valid Loss:  0.02179262787103653
Epoch:  302  	Training Loss: 0.013581531122326851
Test Loss:  0.019760608673095703
Valid Loss:  0.021792441606521606
Epoch:  303  	Training Loss: 0.01358102634549141
Test Loss:  0.019760359078645706
Valid Loss:  0.021792257204651833
Epoch:  304  	Training Loss: 0.013580524362623692
Test Loss:  0.019760116934776306
Valid Loss:  0.021792076528072357
Epoch:  305  	Training Loss: 0.01358002983033657
Test Loss:  0.019759874790906906
Valid Loss:  0.02179189771413803
Epoch:  306  	Training Loss: 0.013579539954662323
Test Loss:  0.019759636372327805
Valid Loss:  0.021791720762848854
Epoch:  307  	Training Loss: 0.013579053804278374
Test Loss:  0.019759397953748703
Valid Loss:  0.021791547536849976
Epoch:  308  	Training Loss: 0.013578574173152447
Test Loss:  0.0197591669857502
Valid Loss:  0.021791378036141396
Epoch:  309  	Training Loss: 0.013578100129961967
Test Loss:  0.019758937880396843
Valid Loss:  0.021791210398077965
Epoch:  310  	Training Loss: 0.013577630743384361
Test Loss:  0.01975870691239834
Valid Loss:  0.021791037172079086
Epoch:  311  	Training Loss: 0.013577165082097054
Test Loss:  0.019758479669690132
Valid Loss:  0.021790871396660805
Epoch:  312  	Training Loss: 0.013576705008745193
Test Loss:  0.019758258014917374
Valid Loss:  0.02179071307182312
Epoch:  313  	Training Loss: 0.013576250523328781
Test Loss:  0.019758041948080063
Valid Loss:  0.021790551021695137
Epoch:  314  	Training Loss: 0.013575801625847816
Test Loss:  0.0197578277438879
Valid Loss:  0.02179039642214775
Epoch:  315  	Training Loss: 0.0135753583163023
Test Loss:  0.019757617264986038
Valid Loss:  0.021790243685245514
Epoch:  316  	Training Loss: 0.01357492245733738
Test Loss:  0.019757412374019623
Valid Loss:  0.021790098398923874
Epoch:  317  	Training Loss: 0.013574492186307907
Test Loss:  0.01975720375776291
Valid Loss:  0.021789949387311935
Epoch:  318  	Training Loss: 0.013574061915278435
Test Loss:  0.019757002592086792
Valid Loss:  0.021789800375699997
Epoch:  319  	Training Loss: 0.013573638163506985
Test Loss:  0.019756881520152092
Valid Loss:  0.02178969979286194
Epoch:  320  	Training Loss: 0.01357322558760643
Test Loss:  0.019756723195314407
Valid Loss:  0.02178957313299179
Epoch:  321  	Training Loss: 0.013572816736996174
Test Loss:  0.01975654996931553
Valid Loss:  0.021789446473121643
Epoch:  322  	Training Loss: 0.013572413474321365
Test Loss:  0.01975635066628456
Valid Loss:  0.021789299324154854
Epoch:  323  	Training Loss: 0.013572003692388535
Test Loss:  0.019756149500608444
Valid Loss:  0.021789148449897766
Epoch:  324  	Training Loss: 0.013571598567068577
Test Loss:  0.01975594274699688
Valid Loss:  0.02178899571299553
Epoch:  325  	Training Loss: 0.013571197167038918
Test Loss:  0.019755739718675613
Valid Loss:  0.02178884483873844
Epoch:  326  	Training Loss: 0.013570797629654408
Test Loss:  0.019755538552999496
Valid Loss:  0.02178870141506195
Epoch:  327  	Training Loss: 0.013570405542850494
Test Loss:  0.019755342975258827
Valid Loss:  0.02178855799138546
Epoch:  328  	Training Loss: 0.013570019043982029
Test Loss:  0.019755147397518158
Valid Loss:  0.02178841270506382
Epoch:  329  	Training Loss: 0.013569634407758713
Test Loss:  0.019754957407712936
Valid Loss:  0.021788273006677628
Epoch:  330  	Training Loss: 0.01356925442814827
Test Loss:  0.019754765555262566
Valid Loss:  0.021788135170936584
Epoch:  331  	Training Loss: 0.0135688791051507
Test Loss:  0.019754577428102493
Valid Loss:  0.02178800106048584
Epoch:  332  	Training Loss: 0.013568513095378876
Test Loss:  0.019754517823457718
Valid Loss:  0.021787934005260468
Epoch:  333  	Training Loss: 0.0135681526735425
Test Loss:  0.019754398614168167
Valid Loss:  0.021787837147712708
Epoch:  334  	Training Loss: 0.013567796908318996
Test Loss:  0.01975424773991108
Valid Loss:  0.021787721663713455
Epoch:  335  	Training Loss: 0.013567445799708366
Test Loss:  0.019754081964492798
Valid Loss:  0.021787602454423904
Epoch:  336  	Training Loss: 0.013567095622420311
Test Loss:  0.01975390501320362
Valid Loss:  0.021787472069263458
Epoch:  337  	Training Loss: 0.01356674823909998
Test Loss:  0.019753728061914444
Valid Loss:  0.02178734727203846
Epoch:  338  	Training Loss: 0.013566404581069946
Test Loss:  0.019753549247980118
Valid Loss:  0.021787229925394058
Epoch:  339  	Training Loss: 0.013566065579652786
Test Loss:  0.01975337788462639
Valid Loss:  0.021787120029330254
Epoch:  340  	Training Loss: 0.013565732166171074
Test Loss:  0.01975320279598236
Valid Loss:  0.021787002682685852
Epoch:  341  	Training Loss: 0.013565397821366787
Test Loss:  0.019753027707338333
Valid Loss:  0.0217868871986866
Epoch:  342  	Training Loss: 0.013565067201852798
Test Loss:  0.01975286565721035
Valid Loss:  0.02178678661584854
Epoch:  343  	Training Loss: 0.01356474868953228
Test Loss:  0.019752709195017815
Valid Loss:  0.021786686033010483
Epoch:  344  	Training Loss: 0.01356443203985691
Test Loss:  0.01975255273282528
Valid Loss:  0.021786589175462723
Epoch:  345  	Training Loss: 0.01356412097811699
Test Loss:  0.019752398133277893
Valid Loss:  0.021786488592624664
Epoch:  346  	Training Loss: 0.013563809916377068
Test Loss:  0.019752241671085358
Valid Loss:  0.021786395460367203
Epoch:  347  	Training Loss: 0.013563504442572594
Test Loss:  0.019752085208892822
Valid Loss:  0.021786291152238846
Epoch:  348  	Training Loss: 0.01356319710612297
Test Loss:  0.019751934334635735
Valid Loss:  0.021786196157336235
Epoch:  349  	Training Loss: 0.013562895357608795
Test Loss:  0.019751787185668945
Valid Loss:  0.021786104887723923
Epoch:  350  	Training Loss: 0.013562597334384918
Test Loss:  0.019751641899347305
Valid Loss:  0.02178601175546646
Epoch:  351  	Training Loss: 0.01356230117380619
Test Loss:  0.019751496613025665
Valid Loss:  0.021785924211144447
Epoch:  352  	Training Loss: 0.01356201060116291
Test Loss:  0.019751355051994324
Valid Loss:  0.021785838529467583
Epoch:  353  	Training Loss: 0.013561723753809929
Test Loss:  0.019751224666833878
Valid Loss:  0.021785754710435867
Epoch:  354  	Training Loss: 0.01356144156306982
Test Loss:   71%|███████   | 355/500 [04:08<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:08<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:08<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:15<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:15<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:15<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:15<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:15<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:22<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:22<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:22<01:18,  1.60it/s] 75%|███████▌  | 377/500 [04:22<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:22<00:41,  2.93it/s] 76%|███████▌  | 381/500 [04:29<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:29<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:29<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:29<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:29<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:35<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:35<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:36<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:36<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:36<00:33,  3.01it/s] 80%|████████  | 401/500 [04:42<01:59,  1.20s/it] 81%|████████  | 403/500 [04:42<01:23,  1.16it/s] 81%|████████  | 405/500 [04:43<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:43<00:42,  2.19it/s] 82%|████████▏ | 409/500 [04:43<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:49<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:49<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:49<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:50<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:50<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:56<01:34,  1.19s/it] 85%|████████▍ | 423/500 [04:56<01:06,  1.17it/s]0.019751086831092834
Valid Loss:  0.021785669028759003
Epoch:  355  	Training Loss: 0.013561160303652287
Test Loss:  0.01975095085799694
Valid Loss:  0.021785587072372437
Epoch:  356  	Training Loss: 0.013560881838202477
Test Loss:  0.019750814884901047
Valid Loss:  0.02178550325334072
Epoch:  357  	Training Loss: 0.013560603372752666
Test Loss:  0.019750680774450302
Valid Loss:  0.021785419434309006
Epoch:  358  	Training Loss: 0.013560328632593155
Test Loss:  0.019750550389289856
Valid Loss:  0.02178533561527729
Epoch:  359  	Training Loss: 0.013560055755078793
Test Loss:  0.019750423729419708
Valid Loss:  0.021785259246826172
Epoch:  360  	Training Loss: 0.013559788465499878
Test Loss:  0.01975029520690441
Valid Loss:  0.021785179153084755
Epoch:  361  	Training Loss: 0.013559522107243538
Test Loss:  0.019750172272324562
Valid Loss:  0.021785099059343338
Epoch:  362  	Training Loss: 0.013559257611632347
Test Loss:  0.01975005306303501
Valid Loss:  0.021785030141472816
Epoch:  363  	Training Loss: 0.013559000566601753
Test Loss:  0.01974993571639061
Valid Loss:  0.021784957498311996
Epoch:  364  	Training Loss: 0.013558745384216309
Test Loss:  0.01974981650710106
Valid Loss:  0.021784886717796326
Epoch:  365  	Training Loss: 0.013558492064476013
Test Loss:  0.019749701023101807
Valid Loss:  0.021784819662570953
Epoch:  366  	Training Loss: 0.013558242470026016
Test Loss:  0.019749589264392853
Valid Loss:  0.02178475260734558
Epoch:  367  	Training Loss: 0.013557994738221169
Test Loss:  0.0197494775056839
Valid Loss:  0.021784687414765358
Epoch:  368  	Training Loss: 0.01355775073170662
Test Loss:  0.019749395549297333
Valid Loss:  0.02178463712334633
Epoch:  369  	Training Loss: 0.013557512313127518
Test Loss:  0.019749300554394722
Valid Loss:  0.021784581243991852
Epoch:  370  	Training Loss: 0.013557275757193565
Test Loss:  0.019749201834201813
Valid Loss:  0.021784525364637375
Epoch:  371  	Training Loss: 0.013557041063904762
Test Loss:  0.019749099388718605
Valid Loss:  0.0217844657599926
Epoch:  372  	Training Loss: 0.013556807301938534
Test Loss:  0.019748982042074203
Valid Loss:  0.021784383803606033
Epoch:  373  	Training Loss: 0.01355656422674656
Test Loss:  0.019748860970139503
Valid Loss:  0.021784305572509766
Epoch:  374  	Training Loss: 0.013556323014199734
Test Loss:  0.019748743623495102
Valid Loss:  0.021784231066703796
Epoch:  375  	Training Loss: 0.013556085526943207
Test Loss:  0.019748620688915253
Valid Loss:  0.02178415283560753
Epoch:  376  	Training Loss: 0.013555847108364105
Test Loss:  0.019748505204916
Valid Loss:  0.02178407832980156
Epoch:  377  	Training Loss: 0.013555614277720451
Test Loss:  0.019748389720916748
Valid Loss:  0.02178400196135044
Epoch:  378  	Training Loss: 0.013555379584431648
Test Loss:  0.019748274236917496
Valid Loss:  0.02178392931818962
Epoch:  379  	Training Loss: 0.013555150479078293
Test Loss:  0.019748162478208542
Valid Loss:  0.02178385853767395
Epoch:  380  	Training Loss: 0.013554921373724937
Test Loss:  0.01974804699420929
Valid Loss:  0.02178378403186798
Epoch:  381  	Training Loss: 0.01355469599366188
Test Loss:  0.019747938960790634
Valid Loss:  0.02178370952606201
Epoch:  382  	Training Loss: 0.013554472476243973
Test Loss:  0.019747842103242874
Valid Loss:  0.02178366109728813
Epoch:  383  	Training Loss: 0.01355426199734211
Test Loss:  0.01974775269627571
Valid Loss:  0.021783605217933655
Epoch:  384  	Training Loss: 0.013554052449762821
Test Loss:  0.019747663289308548
Valid Loss:  0.021783553063869476
Epoch:  385  	Training Loss: 0.013553846627473831
Test Loss:  0.019747572019696236
Valid Loss:  0.021783497184515
Epoch:  386  	Training Loss: 0.013553641736507416
Test Loss:  0.019747484475374222
Valid Loss:  0.02178344503045082
Epoch:  387  	Training Loss: 0.013553437776863575
Test Loss:  0.019747398793697357
Valid Loss:  0.02178339660167694
Epoch:  388  	Training Loss: 0.013553237542510033
Test Loss:  0.019747313112020493
Valid Loss:  0.02178334631025791
Epoch:  389  	Training Loss: 0.013553040102124214
Test Loss:  0.019747227430343628
Valid Loss:  0.02178329974412918
Epoch:  390  	Training Loss: 0.01355284359306097
Test Loss:  0.019747141748666763
Valid Loss:  0.021783247590065002
Epoch:  391  	Training Loss: 0.013552647083997726
Test Loss:  0.019747061654925346
Valid Loss:  0.02178320288658142
Epoch:  392  	Training Loss: 0.013552455231547356
Test Loss:  0.019746970385313034
Valid Loss:  0.021783143281936646
Epoch:  393  	Training Loss: 0.013552256859838963
Test Loss:  0.019746879115700722
Valid Loss:  0.02178308740258217
Epoch:  394  	Training Loss: 0.013552060350775719
Test Loss:  0.01974678784608841
Valid Loss:  0.02178303524851799
Epoch:  395  	Training Loss: 0.01355186477303505
Test Loss:  0.019746702164411545
Valid Loss:  0.021782979369163513
Epoch:  396  	Training Loss: 0.013551672920584679
Test Loss:  0.01974661648273468
Valid Loss:  0.021782925352454185
Epoch:  397  	Training Loss: 0.013551481999456882
Test Loss:  0.019746527075767517
Valid Loss:  0.021782871335744858
Epoch:  398  	Training Loss: 0.013551292940974236
Test Loss:  0.01974644511938095
Valid Loss:  0.02178281918168068
Epoch:  399  	Training Loss: 0.013551106676459312
Test Loss:  0.019746363162994385
Valid Loss:  0.021782763302326202
Epoch:  400  	Training Loss: 0.013550919480621815
Test Loss:  0.01974628120660782
Valid Loss:  0.02178271673619747
Epoch:  401  	Training Loss: 0.013550736010074615
Test Loss:  0.019746199250221252
Valid Loss:  0.021782666444778442
Epoch:  402  	Training Loss: 0.01355055533349514
Test Loss:  0.019746139645576477
Valid Loss:  0.021782640367746353
Epoch:  403  	Training Loss: 0.013550388626754284
Test Loss:  0.0197460874915123
Valid Loss:  0.021782614290714264
Epoch:  404  	Training Loss: 0.013550225645303726
Test Loss:  0.01974603347480297
Valid Loss:  0.02178259566426277
Epoch:  405  	Training Loss: 0.013550067320466042
Test Loss:  0.019745977595448494
Valid Loss:  0.02178257331252098
Epoch:  406  	Training Loss: 0.013549907132983208
Test Loss:  0.019745931029319763
Valid Loss:  0.02178254723548889
Epoch:  407  	Training Loss: 0.013549750670790672
Test Loss:  0.019745875149965286
Valid Loss:  0.02178252674639225
Epoch:  408  	Training Loss: 0.013549594208598137
Test Loss:  0.019745822995901108
Valid Loss:  0.02178250253200531
Epoch:  409  	Training Loss: 0.01354943960905075
Test Loss:  0.019745776429772377
Valid Loss:  0.021782483905553818
Epoch:  410  	Training Loss: 0.013549288734793663
Test Loss:  0.019745729863643646
Valid Loss:  0.021782463416457176
Epoch:  411  	Training Loss: 0.013549137860536575
Test Loss:  0.019745681434869766
Valid Loss:  0.021782439202070236
Epoch:  412  	Training Loss: 0.013548987917602062
Test Loss:  0.019745606929063797
Valid Loss:  0.021782394498586655
Epoch:  413  	Training Loss: 0.013548820279538631
Test Loss:  0.019745532423257828
Valid Loss:  0.021782346069812775
Epoch:  414  	Training Loss: 0.013548655435442924
Test Loss:  0.019745463505387306
Valid Loss:  0.021782299503684044
Epoch:  415  	Training Loss: 0.013548491522669792
Test Loss:  0.019745387136936188
Valid Loss:  0.021782254800200462
Epoch:  416  	Training Loss: 0.013548329472541809
Test Loss:  0.019745318219065666
Valid Loss:  0.02178220823407173
Epoch:  417  	Training Loss: 0.013548167422413826
Test Loss:  0.019745251163840294
Valid Loss:  0.02178216725587845
Epoch:  418  	Training Loss: 0.013548009097576141
Test Loss:  0.01974518410861492
Valid Loss:  0.02178211882710457
Epoch:  419  	Training Loss: 0.013547850772738457
Test Loss:  0.01974511332809925
Valid Loss:  0.021782075986266136
Epoch:  420  	Training Loss: 0.013547694310545921
Test Loss:  0.019745048135519028
Valid Loss:  0.021782035008072853
Epoch:  421  	Training Loss: 0.013547541573643684
Test Loss:  0.019744984805583954
Valid Loss:  0.02178199216723442
Epoch:  422  	Training Loss: 0.013547387905418873
Test Loss:  0.01974491961300373
Valid Loss:  0.02178194746375084
Epoch:  423  	Training Loss: 0.013547234237194061
Test Loss:  0.019744854420423508
Valid Loss:  0.021781902760267258
Epoch:  424  	Training Loss: 0.013547081500291824
Test Loss:  0.019744789227843285
Valid Loss:  0.021781861782073975
 85%|████████▌ | 425/500 [04:56<00:46,  1.61it/s] 85%|████████▌ | 427/500 [04:56<00:33,  2.20it/s] 86%|████████▌ | 429/500 [04:57<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:03<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:03<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:03<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:03<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:03<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:10<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:10<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:10<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:10<00:24,  2.20it/s] 90%|████████▉ | 449/500 [05:10<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:17<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:17<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:17<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:17<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:24<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:24<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:24<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:24<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:24<00:10,  2.99it/s] 94%|█████████▍| 471/500 [05:30<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:30<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:31<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:31<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:38<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:38<00:05,  2.20it/s] 98%|█████████▊| 489/500 [05:38<00:03,  2.96it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:44<00:05,  1.18it/s]Epoch:  425  	Training Loss: 0.013546930626034737
Test Loss:  0.01974472403526306
Valid Loss:  0.02178182080388069
Epoch:  426  	Training Loss: 0.013546782545745373
Test Loss:  0.019744668155908585
Valid Loss:  0.02178177982568741
Epoch:  427  	Training Loss: 0.013546636328101158
Test Loss:  0.01974460296332836
Valid Loss:  0.021781738847494125
Epoch:  428  	Training Loss: 0.013546490110456944
Test Loss:  0.019744543358683586
Valid Loss:  0.021781697869300842
Epoch:  429  	Training Loss: 0.013546345755457878
Test Loss:  0.01974448189139366
Valid Loss:  0.02178165689110756
Epoch:  430  	Training Loss: 0.013546204194426537
Test Loss:  0.019744422286748886
Valid Loss:  0.021781615912914276
Epoch:  431  	Training Loss: 0.01354606170207262
Test Loss:  0.01974436640739441
Valid Loss:  0.02178157866001129
Epoch:  432  	Training Loss: 0.013545921072363853
Test Loss:  0.019744299352169037
Valid Loss:  0.02178153023123741
Epoch:  433  	Training Loss: 0.013545775786042213
Test Loss:  0.019744236022233963
Valid Loss:  0.02178148366510868
Epoch:  434  	Training Loss: 0.013545632362365723
Test Loss:  0.01974417269229889
Valid Loss:  0.02178144082427025
Epoch:  435  	Training Loss: 0.013545488938689232
Test Loss:  0.019744107499718666
Valid Loss:  0.021781394258141518
Epoch:  436  	Training Loss: 0.01354534737765789
Test Loss:  0.01974404603242874
Valid Loss:  0.021781349554657936
Epoch:  437  	Training Loss: 0.013545206747949123
Test Loss:  0.019743986427783966
Valid Loss:  0.021781308576464653
Epoch:  438  	Training Loss: 0.01354506891220808
Test Loss:  0.019743923097848892
Valid Loss:  0.021781258285045624
Epoch:  439  	Training Loss: 0.013544930145144463
Test Loss:  0.019743861630558968
Valid Loss:  0.02178121730685234
Epoch:  440  	Training Loss: 0.013544794172048569
Test Loss:  0.019743802025914192
Valid Loss:  0.02178117260336876
Epoch:  441  	Training Loss: 0.013544660061597824
Test Loss:  0.019743744283914566
Valid Loss:  0.021781133487820625
Epoch:  442  	Training Loss: 0.01354452595114708
Test Loss:  0.01974370703101158
Valid Loss:  0.021781112998723984
Epoch:  443  	Training Loss: 0.013544408604502678
Test Loss:  0.019743671640753746
Valid Loss:  0.021781092509627342
Epoch:  444  	Training Loss: 0.013544291257858276
Test Loss:  0.01974363625049591
Valid Loss:  0.021781075745821
Epoch:  445  	Training Loss: 0.013544175773859024
Test Loss:  0.019743602722883224
Valid Loss:  0.02178105339407921
Epoch:  446  	Training Loss: 0.013544062152504921
Test Loss:  0.01974356733262539
Valid Loss:  0.021781034767627716
Epoch:  447  	Training Loss: 0.013543949462473392
Test Loss:  0.019743535667657852
Valid Loss:  0.021781019866466522
Epoch:  448  	Training Loss: 0.013543840497732162
Test Loss:  0.019743504002690315
Valid Loss:  0.02178100496530533
Epoch:  449  	Training Loss: 0.013543728739023209
Test Loss:  0.019743474200367928
Valid Loss:  0.021780986338853836
Epoch:  450  	Training Loss: 0.013543620705604553
Test Loss:  0.01974344439804554
Valid Loss:  0.021780971437692642
Epoch:  451  	Training Loss: 0.013543512672185898
Test Loss:  0.019743412733078003
Valid Loss:  0.02178095281124115
Epoch:  452  	Training Loss: 0.013543406501412392
Test Loss:  0.01974339783191681
Valid Loss:  0.02178095653653145
Epoch:  453  	Training Loss: 0.013543311506509781
Test Loss:  0.019743384793400764
Valid Loss:  0.02178095281124115
Epoch:  454  	Training Loss: 0.013543215580284595
Test Loss:  0.01974336989223957
Valid Loss:  0.02178095281124115
Epoch:  455  	Training Loss: 0.01354312151670456
Test Loss:  0.019743354991078377
Valid Loss:  0.02178094908595085
Epoch:  456  	Training Loss: 0.013543027453124523
Test Loss:  0.019743341952562332
Valid Loss:  0.02178094908595085
Epoch:  457  	Training Loss: 0.013542935252189636
Test Loss:  0.019743330776691437
Valid Loss:  0.02178094908595085
Epoch:  458  	Training Loss: 0.013542842119932175
Test Loss:  0.01974332518875599
Valid Loss:  0.0217809546738863
Epoch:  459  	Training Loss: 0.013542757369577885
Test Loss:  0.019743314012885094
Valid Loss:  0.021780950948596
Epoch:  460  	Training Loss: 0.013542667031288147
Test Loss:  0.01974330097436905
Valid Loss:  0.02178095281124115
Epoch:  461  	Training Loss: 0.013542580418288708
Test Loss:  0.019743287935853004
Valid Loss:  0.0217809546738863
Epoch:  462  	Training Loss: 0.01354249194264412
Test Loss:  0.019743258133530617
Valid Loss:  0.021780936047434807
Epoch:  463  	Training Loss: 0.01354239135980606
Test Loss:  0.01974323019385338
Valid Loss:  0.021780915558338165
Epoch:  464  	Training Loss: 0.013542292639613152
Test Loss:  0.01974320039153099
Valid Loss:  0.021780896931886673
Epoch:  465  	Training Loss: 0.013542193919420242
Test Loss:  0.0197431743144989
Valid Loss:  0.02178087830543518
Epoch:  466  	Training Loss: 0.013542098924517632
Test Loss:  0.019743146374821663
Valid Loss:  0.021780863404273987
Epoch:  467  	Training Loss: 0.013542002066969872
Test Loss:  0.019743118435144424
Valid Loss:  0.021780846640467644
Epoch:  468  	Training Loss: 0.013541906140744686
Test Loss:  0.019743092358112335
Valid Loss:  0.021780826151371002
Epoch:  469  	Training Loss: 0.01354181207716465
Test Loss:  0.019743070006370544
Valid Loss:  0.02178081125020981
Epoch:  470  	Training Loss: 0.013541720807552338
Test Loss:  0.019743042066693306
Valid Loss:  0.021780792623758316
Epoch:  471  	Training Loss: 0.013541627675294876
Test Loss:  0.019743017852306366
Valid Loss:  0.021780777722597122
Epoch:  472  	Training Loss: 0.013541536405682564
Test Loss:  0.019742995500564575
Valid Loss:  0.021780766546726227
Epoch:  473  	Training Loss: 0.01354144886136055
Test Loss:  0.019742976874113083
Valid Loss:  0.02178075537085533
Epoch:  474  	Training Loss: 0.013541363179683685
Test Loss:  0.01974295824766159
Valid Loss:  0.021780744194984436
Epoch:  475  	Training Loss: 0.013541274704039097
Test Loss:  0.0197429358959198
Valid Loss:  0.02178073301911354
Epoch:  476  	Training Loss: 0.013541189022362232
Test Loss:  0.019742920994758606
Valid Loss:  0.021780719980597496
Epoch:  477  	Training Loss: 0.013541104272007942
Test Loss:  0.019742900505661964
Valid Loss:  0.02178071066737175
Epoch:  478  	Training Loss: 0.013541021384298801
Test Loss:  0.01974288374185562
Valid Loss:  0.021780699491500854
Epoch:  479  	Training Loss: 0.013540937565267086
Test Loss:  0.01974286511540413
Valid Loss:  0.02178068831562996
Epoch:  480  	Training Loss: 0.013540854677557945
Test Loss:  0.019742846488952637
Valid Loss:  0.021780679002404213
Epoch:  481  	Training Loss: 0.013540773652493954
Test Loss:  0.019742831587791443
Valid Loss:  0.021780669689178467
Epoch:  482  	Training Loss: 0.013540692627429962
Test Loss:  0.019742809236049652
Valid Loss:  0.021780654788017273
Epoch:  483  	Training Loss: 0.013540608808398247
Test Loss:  0.01974278688430786
Valid Loss:  0.02178063616156578
Epoch:  484  	Training Loss: 0.013540525920689106
Test Loss:  0.01974276266992092
Valid Loss:  0.021780619397759438
Epoch:  485  	Training Loss: 0.013540441170334816
Test Loss:  0.01974274218082428
Valid Loss:  0.021780606359243393
Epoch:  486  	Training Loss: 0.013540360145270824
Test Loss:  0.019742721691727638
Valid Loss:  0.0217805914580822
Epoch:  487  	Training Loss: 0.013540279120206833
Test Loss:  0.019742701202630997
Valid Loss:  0.021780574694275856
Epoch:  488  	Training Loss: 0.013540198095142841
Test Loss:  0.019742682576179504
Valid Loss:  0.021780559793114662
Epoch:  489  	Training Loss: 0.013540118932723999
Test Loss:  0.019742660224437714
Valid Loss:  0.021780546754598618
Epoch:  490  	Training Loss: 0.013540041632950306
Test Loss:  0.01974264159798622
Valid Loss:  0.021780535578727722
Epoch:  491  	Training Loss: 0.013539962470531464
Test Loss:  0.019742624834179878
Valid Loss:  0.02178051695227623
Epoch:  492  	Training Loss: 0.013539886102080345
Test Loss:  0.019742608070373535
Valid Loss:  0.021780507639050484
Epoch:  493  	Training Loss: 0.013539807870984077
Test Loss:  0.01974257081747055
Valid Loss:  0.021780475974082947
Epoch:  494  	Training Loss: 0.013539732433855534
Test Loss:  0.01974254660308361
Valid Loss:  0.021780451759696007
Epoch:  495  	Training Loss: 0.01353965699672699
Test Loss:   99%|█████████▉| 495/500 [05:44<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:45<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:45<00:00,  2.94it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
0.01974252238869667
Valid Loss:  0.021780434995889664
Epoch:  496  	Training Loss: 0.013539580628275871
Test Loss:  0.019742505624890327
Valid Loss:  0.02178041823208332
Epoch:  497  	Training Loss: 0.013539506122469902
Test Loss:  0.019742488861083984
Valid Loss:  0.021780405193567276
Epoch:  498  	Training Loss: 0.013539431616663933
Test Loss:  0.01974247209727764
Valid Loss:  0.021780390292406082
Epoch:  499  	Training Loss: 0.013539358973503113
Test Loss:  0.019742457196116447
Valid Loss:  0.021780379116535187
Epoch:  500  	Training Loss: 0.013539286330342293
Test Loss:  0.019742444157600403
Valid Loss:  0.021780366078019142
seed is  14
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:00,  6.37s/it]  1%|          | 3/500 [00:06<14:08,  1.71s/it]  1%|          | 5/500 [00:06<07:07,  1.16it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:55,  2.79it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:44,  2.93it/s]  4%|▍         | 21/500 [00:20<09:56,  1.25s/it]  5%|▍         | 23/500 [00:20<07:03,  1.13it/s]  5%|▌         | 25/500 [00:20<05:02,  1.57it/s]  5%|▌         | 27/500 [00:20<03:39,  2.15it/s]  6%|▌         | 29/500 [00:20<02:41,  2.91it/s]  6%|▌         | 31/500 [00:27<09:32,  1.22s/it]  7%|▋         | 33/500 [00:27<06:49,  1.14it/s]  7%|▋         | 35/500 [00:27<04:54,  1.58it/s]  7%|▋         | 37/500 [00:27<03:34,  2.16it/s]  8%|▊         | 39/500 [00:28<02:39,  2.90it/s]  8%|▊         | 41/500 [00:34<09:23,  1.23s/it]  9%|▊         | 43/500 [00:34<06:42,  1.14it/s]  9%|▉         | 45/500 [00:34<04:50,  1.56it/s]  9%|▉         | 47/500 [00:35<03:32,  2.13it/s] 10%|▉         | 49/500 [00:35<02:36,  2.87it/s] 10%|█         | 51/500 [00:41<09:02,  1.21s/it] 11%|█         | 53/500 [00:41<06:26,  1.16it/s] 11%|█         | 55/500 [00:41<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:42<03:21,  2.19it/s] 12%|█▏        | 59/500 [00:42<02:29,  2.96it/s] 12%|█▏        | 61/500 [00:48<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:48<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:29,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:49<02:24,  2.98it/s]Epoch:  1  	Training Loss: 0.240797758102417
Test Loss:  0.21468707919120789
Valid Loss:  0.20668409764766693
Epoch:  2  	Training Loss: 0.16244256496429443
Test Loss:  0.15999244153499603
Valid Loss:  0.15515175461769104
Epoch:  3  	Training Loss: 0.11866171658039093
Test Loss:  0.12112538516521454
Valid Loss:  0.11860321462154388
Epoch:  4  	Training Loss: 0.08857384324073792
Test Loss:  0.09330634772777557
Valid Loss:  0.09248940646648407
Epoch:  5  	Training Loss: 0.06782407313585281
Test Loss:  0.07323324680328369
Valid Loss:  0.07367195934057236
Epoch:  6  	Training Loss: 0.053447119891643524
Test Loss:  0.05861769616603851
Valid Loss:  0.05997965484857559
Epoch:  7  	Training Loss: 0.04342272877693176
Test Loss:  0.0478685200214386
Valid Loss:  0.04990570247173309
Epoch:  8  	Training Loss: 0.03637388348579407
Test Loss:  0.039875101298093796
Valid Loss:  0.04240112006664276
Epoch:  9  	Training Loss: 0.03136167302727699
Test Loss:  0.03385910391807556
Valid Loss:  0.03673265129327774
Epoch:  10  	Training Loss: 0.027745617553591728
Test Loss:  0.02927250601351261
Valid Loss:  0.03238581120967865
Epoch:  11  	Training Loss: 0.025088660418987274
Test Loss:  0.025727352127432823
Valid Loss:  0.028997711837291718
Epoch:  12  	Training Loss: 0.02309240773320198
Test Loss:  0.02294970490038395
Valid Loss:  0.02631315216422081
Epoch:  13  	Training Loss: 0.021554064005613327
Test Loss:  0.020738912746310234
Valid Loss:  0.02414623647928238
Epoch:  14  	Training Loss: 0.020332954823970795
Test Loss:  0.018952639773488045
Valid Loss:  0.022365793585777283
Epoch:  15  	Training Loss: 0.01933404803276062
Test Loss:  0.017487509176135063
Valid Loss:  0.020877046510577202
Epoch:  16  	Training Loss: 0.01849227584898472
Test Loss:  0.016267817467451096
Valid Loss:  0.019611068069934845
Epoch:  17  	Training Loss: 0.017763033509254456
Test Loss:  0.015237700194120407
Valid Loss:  0.018517304211854935
Epoch:  18  	Training Loss: 0.01711568608880043
Test Loss:  0.014355597086250782
Valid Loss:  0.01755843125283718
Epoch:  19  	Training Loss: 0.016529157757759094
Test Loss:  0.013590356335043907
Valid Loss:  0.016706557944417
Epoch:  20  	Training Loss: 0.015988904982805252
Test Loss:  0.012918299064040184
Valid Loss:  0.015940746292471886
Epoch:  21  	Training Loss: 0.01548481173813343
Test Loss:  0.012321417219936848
Valid Loss:  0.015245126560330391
Epoch:  22  	Training Loss: 0.015009846538305283
Test Loss:  0.011784454807639122
Valid Loss:  0.014606363140046597
Epoch:  23  	Training Loss: 0.014558734372258186
Test Loss:  0.011298324912786484
Valid Loss:  0.014016450382769108
Epoch:  24  	Training Loss: 0.014128332026302814
Test Loss:  0.010854517109692097
Valid Loss:  0.01346795354038477
Epoch:  25  	Training Loss: 0.013716061599552631
Test Loss:  0.010446229949593544
Valid Loss:  0.012954998761415482
Epoch:  26  	Training Loss: 0.01332002505660057
Test Loss:  0.010068139992654324
Valid Loss:  0.012472975999116898
Epoch:  27  	Training Loss: 0.01293882168829441
Test Loss:  0.009715970605611801
Valid Loss:  0.012018122710287571
Epoch:  28  	Training Loss: 0.012571359053254128
Test Loss:  0.009386246092617512
Valid Loss:  0.011587455868721008
Epoch:  29  	Training Loss: 0.012216776609420776
Test Loss:  0.009076174348592758
Valid Loss:  0.011178442277014256
Epoch:  30  	Training Loss: 0.011874374002218246
Test Loss:  0.008783455938100815
Valid Loss:  0.010789107531309128
Epoch:  31  	Training Loss: 0.011543555185198784
Test Loss:  0.008506186306476593
Valid Loss:  0.01041770912706852
Epoch:  32  	Training Loss: 0.011223813518881798
Test Loss:  0.008241971954703331
Valid Loss:  0.010062143206596375
Epoch:  33  	Training Loss: 0.010914463549852371
Test Loss:  0.007990473881363869
Valid Loss:  0.009721970185637474
Epoch:  34  	Training Loss: 0.010615332052111626
Test Loss:  0.007750580552965403
Valid Loss:  0.009396148845553398
Epoch:  35  	Training Loss: 0.010326048359274864
Test Loss:  0.007521332241594791
Valid Loss:  0.009083762764930725
Epoch:  36  	Training Loss: 0.010046266950666904
Test Loss:  0.007301900535821915
Valid Loss:  0.008783991448581219
Epoch:  37  	Training Loss: 0.009775647893548012
Test Loss:  0.007091613486409187
Valid Loss:  0.008496135473251343
Epoch:  38  	Training Loss: 0.009513882920145988
Test Loss:  0.006889841519296169
Valid Loss:  0.00821956992149353
Epoch:  39  	Training Loss: 0.009260686114430428
Test Loss:  0.0066960640251636505
Valid Loss:  0.007953730411827564
Epoch:  40  	Training Loss: 0.009015753865242004
Test Loss:  0.006509807892143726
Valid Loss:  0.007698098197579384
Epoch:  41  	Training Loss: 0.008778819814324379
Test Loss:  0.006330667994916439
Valid Loss:  0.007452205289155245
Epoch:  42  	Training Loss: 0.008549622260034084
Test Loss:  0.0061587076634168625
Valid Loss:  0.007215920835733414
Epoch:  43  	Training Loss: 0.008327905088663101
Test Loss:  0.005993065424263477
Valid Loss:  0.006988491863012314
Epoch:  44  	Training Loss: 0.00811342429369688
Test Loss:  0.005833454895764589
Valid Loss:  0.006769560277462006
Epoch:  45  	Training Loss: 0.00790594331920147
Test Loss:  0.005679618567228317
Valid Loss:  0.0065588136203587055
Epoch:  46  	Training Loss: 0.007705230265855789
Test Loss:  0.005531324073672295
Valid Loss:  0.006355914752930403
Epoch:  47  	Training Loss: 0.007511068135499954
Test Loss:  0.005388325080275536
Valid Loss:  0.006160578690469265
Epoch:  48  	Training Loss: 0.0073232464492321014
Test Loss:  0.005250432528555393
Valid Loss:  0.005972530227154493
Epoch:  49  	Training Loss: 0.007141546346247196
Test Loss:  0.0051174284890294075
Valid Loss:  0.005791483446955681
Epoch:  50  	Training Loss: 0.00696578249335289
Test Loss:  0.004989142529666424
Valid Loss:  0.0056171780452132225
Epoch:  51  	Training Loss: 0.00679574441164732
Test Loss:  0.0048653967678546906
Valid Loss:  0.005449392832815647
Epoch:  52  	Training Loss: 0.006631257012486458
Test Loss:  0.004746627062559128
Valid Loss:  0.005288394168019295
Epoch:  53  	Training Loss: 0.006472453009337187
Test Loss:  0.004631997551769018
Valid Loss:  0.005133386701345444
Epoch:  54  	Training Loss: 0.0063188280910253525
Test Loss:  0.004521355964243412
Valid Loss:  0.004984152503311634
Epoch:  55  	Training Loss: 0.006170220673084259
Test Loss:  0.004414570517838001
Valid Loss:  0.004840511362999678
Epoch:  56  	Training Loss: 0.0060264659114181995
Test Loss:  0.004311510361731052
Valid Loss:  0.004702263977378607
Epoch:  57  	Training Loss: 0.005887405015528202
Test Loss:  0.0042120483703911304
Valid Loss:  0.004569214768707752
Epoch:  58  	Training Loss: 0.005752881057560444
Test Loss:  0.004116064868867397
Valid Loss:  0.0044411891140043736
Epoch:  59  	Training Loss: 0.0056227464228868484
Test Loss:  0.00402345135807991
Valid Loss:  0.004318011458963156
Epoch:  60  	Training Loss: 0.005496858153492212
Test Loss:  0.003934086300432682
Valid Loss:  0.00419952068477869
Epoch:  61  	Training Loss: 0.005375080741941929
Test Loss:  0.0038478695787489414
Valid Loss:  0.004085530526936054
Epoch:  62  	Training Loss: 0.005257275886833668
Test Loss:  0.003764348104596138
Valid Loss:  0.003975686617195606
Epoch:  63  	Training Loss: 0.005143218673765659
Test Loss:  0.003683818969875574
Valid Loss:  0.003870074637234211
Epoch:  64  	Training Loss: 0.005032883491367102
Test Loss:  0.003606171580031514
Valid Loss:  0.0037685493007302284
Epoch:  65  	Training Loss: 0.004926147870719433
Test Loss:  0.003531309077516198
Valid Loss:  0.0036709727719426155
Epoch:  66  	Training Loss: 0.004822895396500826
Test Loss:  0.0034591280855238438
Valid Loss:  0.003577190451323986
Epoch:  67  	Training Loss: 0.004723011516034603
Test Loss:  0.003389536403119564
Valid Loss:  0.0034870686940848827
Epoch:  68  	Training Loss: 0.004626392386853695
Test Loss:  0.003322431119158864
Valid Loss:  0.0034004682675004005
Epoch:  69  	Training Loss: 0.004532916937023401
Test Loss:  0.0032577277161180973
Valid Loss:  0.0033172848634421825
Epoch:  70  	Training Loss: 0.004442495293915272
Test Loss:  0.0031953463330864906
Valid Loss:  0.0032373764552176
Epoch:  71  	Training Loss: 0.004355024546384811
Test Loss:  0.0031352206133306026
Valid Loss:   14%|█▍        | 71/500 [00:55<08:36,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:08,  1.16it/s] 15%|█▌        | 75/500 [00:55<04:25,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:12,  2.19it/s] 16%|█▌        | 79/500 [00:56<02:22,  2.95it/s] 16%|█▌        | 81/500 [01:02<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.94it/s] 18%|█▊        | 91/500 [01:09<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:09<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:09<04:06,  1.65it/s] 19%|█▉        | 97/500 [01:09<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:09<02:12,  3.02it/s] 20%|██        | 101/500 [01:16<07:59,  1.20s/it] 21%|██        | 103/500 [01:16<05:42,  1.16it/s] 21%|██        | 105/500 [01:16<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:16<03:00,  2.18it/s] 22%|██▏       | 109/500 [01:16<02:15,  2.89it/s] 22%|██▏       | 111/500 [01:23<07:47,  1.20s/it] 23%|██▎       | 113/500 [01:23<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:23<03:59,  1.60it/s] 23%|██▎       | 117/500 [01:23<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:23<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:29<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:30<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:30<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:30<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:30<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:36<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:37<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:37<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:37<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:37<02:01,  2.96it/s]0.0031606366392225027
Epoch:  72  	Training Loss: 0.004270409233868122
Test Loss:  0.003076794557273388
Valid Loss:  0.0030866707675158978
Epoch:  73  	Training Loss: 0.004188405815511942
Test Loss:  0.003020539414137602
Valid Loss:  0.003015688620507717
Epoch:  74  	Training Loss: 0.004109085537493229
Test Loss:  0.0029663746245205402
Valid Loss:  0.002947582397609949
Epoch:  75  	Training Loss: 0.0040323492139577866
Test Loss:  0.002914187964051962
Valid Loss:  0.0028822391759604216
Epoch:  76  	Training Loss: 0.003958120010793209
Test Loss:  0.002863931003957987
Valid Loss:  0.0028195527847856283
Epoch:  77  	Training Loss: 0.0038863152731209993
Test Loss:  0.002815522253513336
Valid Loss:  0.0027594324201345444
Epoch:  78  	Training Loss: 0.0038168563041836023
Test Loss:  0.002768898382782936
Valid Loss:  0.002701779128983617
Epoch:  79  	Training Loss: 0.0037496667355298996
Test Loss:  0.002723988378420472
Valid Loss:  0.0026465021073818207
Epoch:  80  	Training Loss: 0.0036846683360636234
Test Loss:  0.0026807247195392847
Valid Loss:  0.002593513811007142
Epoch:  81  	Training Loss: 0.003621794981881976
Test Loss:  0.002639047335833311
Valid Loss:  0.002542734146118164
Epoch:  82  	Training Loss: 0.0035609742626547813
Test Loss:  0.0025994712486863136
Valid Loss:  0.0024943556636571884
Epoch:  83  	Training Loss: 0.003502288833260536
Test Loss:  0.0025612832978367805
Valid Loss:  0.0024479920975863934
Epoch:  84  	Training Loss: 0.0034455256536602974
Test Loss:  0.0025244387798011303
Valid Loss:  0.0024035528767853975
Epoch:  85  	Training Loss: 0.0033906076569110155
Test Loss:  0.002488907426595688
Valid Loss:  0.002360983518883586
Epoch:  86  	Training Loss: 0.0033374857157468796
Test Loss:  0.002454635687172413
Valid Loss:  0.0023202099837362766
Epoch:  87  	Training Loss: 0.0032860920764505863
Test Loss:  0.0024216044694185257
Valid Loss:  0.002281179651618004
Epoch:  88  	Training Loss: 0.0032363752834498882
Test Loss:  0.0023897727951407433
Valid Loss:  0.0022438312880694866
Epoch:  89  	Training Loss: 0.0031882820185273886
Test Loss:  0.0023591078352183104
Valid Loss:  0.002208100166171789
Epoch:  90  	Training Loss: 0.0031417571008205414
Test Loss:  0.00232956581749022
Valid Loss:  0.002173931337893009
Epoch:  91  	Training Loss: 0.0030967448838055134
Test Loss:  0.0023011136800050735
Valid Loss:  0.002141266129910946
Epoch:  92  	Training Loss: 0.0030532050877809525
Test Loss:  0.0022733602672815323
Valid Loss:  0.0021098980214446783
Epoch:  93  	Training Loss: 0.0030109817162156105
Test Loss:  0.0022466902155429125
Valid Loss:  0.0020799501799046993
Epoch:  94  	Training Loss: 0.002970136934891343
Test Loss:  0.0022210541646927595
Valid Loss:  0.0020513683557510376
Epoch:  95  	Training Loss: 0.002930625109001994
Test Loss:  0.0021964218467473984
Valid Loss:  0.002024104818701744
Epoch:  96  	Training Loss: 0.0028924066573381424
Test Loss:  0.0021727359853684902
Valid Loss:  0.0019981013610959053
Epoch:  97  	Training Loss: 0.0028554312884807587
Test Loss:  0.0021499735303223133
Valid Loss:  0.0019733100198209286
Epoch:  98  	Training Loss: 0.002819665241986513
Test Loss:  0.0021280923392623663
Valid Loss:  0.0019496919121593237
Epoch:  99  	Training Loss: 0.002785065211355686
Test Loss:  0.0021070633083581924
Valid Loss:  0.001927192322909832
Epoch:  100  	Training Loss: 0.0027515986002981663
Test Loss:  0.002086855936795473
Valid Loss:  0.0019057849422097206
Epoch:  101  	Training Loss: 0.0027192262932658195
Test Loss:  0.002067445544525981
Valid Loss:  0.0018854073714464903
Epoch:  102  	Training Loss: 0.002687909174710512
Test Loss:  0.0020487408619374037
Valid Loss:  0.0018660200294107199
Epoch:  103  	Training Loss: 0.0026576081290841103
Test Loss:  0.0020307793747633696
Valid Loss:  0.0018475910183042288
Epoch:  104  	Training Loss: 0.0026282956823706627
Test Loss:  0.002013520570471883
Valid Loss:  0.0018300933297723532
Epoch:  105  	Training Loss: 0.002599941100925207
Test Loss:  0.0019969488494098186
Valid Loss:  0.001813477836549282
Epoch:  106  	Training Loss: 0.0025725127197802067
Test Loss:  0.0019810327794402838
Valid Loss:  0.001797716598957777
Epoch:  107  	Training Loss: 0.0025459816679358482
Test Loss:  0.0019657514058053493
Valid Loss:  0.001782778068445623
Epoch:  108  	Training Loss: 0.002520315581932664
Test Loss:  0.0019510795827955008
Valid Loss:  0.0017686269711703062
Epoch:  109  	Training Loss: 0.0024954876862466335
Test Loss:  0.0019369951914995909
Valid Loss:  0.0017552371136844158
Epoch:  110  	Training Loss: 0.002471469808369875
Test Loss:  0.0019234806532040238
Valid Loss:  0.0017425757832825184
Epoch:  111  	Training Loss: 0.0024482363369315863
Test Loss:  0.001910502789542079
Valid Loss:  0.0017306124791502953
Epoch:  112  	Training Loss: 0.0024257637560367584
Test Loss:  0.00189814658369869
Valid Loss:  0.0017193411476910114
Epoch:  113  	Training Loss: 0.002404049038887024
Test Loss:  0.001886294805444777
Valid Loss:  0.001708716619759798
Epoch:  114  	Training Loss: 0.0023830444552004337
Test Loss:  0.0018749068258330226
Valid Loss:  0.0016987072303891182
Epoch:  115  	Training Loss: 0.002362724393606186
Test Loss:  0.0018639720510691404
Valid Loss:  0.0016892848070710897
Epoch:  116  	Training Loss: 0.0023430688306689262
Test Loss:  0.001853483496233821
Valid Loss:  0.0016804342158138752
Epoch:  117  	Training Loss: 0.002324054716154933
Test Loss:  0.0018434273079037666
Valid Loss:  0.0016721314750611782
Epoch:  118  	Training Loss: 0.0023056608624756336
Test Loss:  0.0018337785732001066
Valid Loss:  0.0016643500421196222
Epoch:  119  	Training Loss: 0.0022878681775182486
Test Loss:  0.0018245315877720714
Valid Loss:  0.0016570726875215769
Epoch:  120  	Training Loss: 0.002270656870678067
Test Loss:  0.0018156704027205706
Valid Loss:  0.0016502778744325042
Epoch:  121  	Training Loss: 0.0022540055215358734
Test Loss:  0.0018071805825456977
Valid Loss:  0.0016439418541267514
Epoch:  122  	Training Loss: 0.0022378999274224043
Test Loss:  0.001799074001610279
Valid Loss:  0.0016380586894229054
Epoch:  123  	Training Loss: 0.0022223242558538914
Test Loss:  0.0017913039773702621
Valid Loss:  0.001632594969123602
Epoch:  124  	Training Loss: 0.0022072598803788424
Test Loss:  0.0017838740022853017
Valid Loss:  0.0016275416128337383
Epoch:  125  	Training Loss: 0.002192686777561903
Test Loss:  0.001776757650077343
Valid Loss:  0.0016228801105171442
Epoch:  126  	Training Loss: 0.002178588882088661
Test Loss:  0.0017699489835649729
Valid Loss:  0.0016185932327061892
Epoch:  127  	Training Loss: 0.002164950128644705
Test Loss:  0.0017634404357522726
Valid Loss:  0.001614656881429255
Epoch:  128  	Training Loss: 0.002151756314560771
Test Loss:  0.00175721594132483
Valid Loss:  0.0016110728029161692
Epoch:  129  	Training Loss: 0.0021389960311353207
Test Loss:  0.0017512703780084848
Valid Loss:  0.0016078059561550617
Epoch:  130  	Training Loss: 0.0021266487892717123
Test Loss:  0.0017455938505008817
Valid Loss:  0.0016048615798354149
Epoch:  131  	Training Loss: 0.00211470783688128
Test Loss:  0.0017401725053787231
Valid Loss:  0.001602216507308185
Epoch:  132  	Training Loss: 0.0021031545475125313
Test Loss:  0.0017350742127746344
Valid Loss:  0.0015998557209968567
Epoch:  133  	Training Loss: 0.002091997768729925
Test Loss:  0.0017302056076005101
Valid Loss:  0.0015977739822119474
Epoch:  134  	Training Loss: 0.0020812032744288445
Test Loss:  0.001725552836433053
Valid Loss:  0.001595955342054367
Epoch:  135  	Training Loss: 0.002070758957415819
Test Loss:  0.0017211097292602062
Valid Loss:  0.0015943769831210375
Epoch:  136  	Training Loss: 0.0020606564357876778
Test Loss:  0.001716869999654591
Valid Loss:  0.0015930464724078774
Epoch:  137  	Training Loss: 0.0020508829038590193
Test Loss:  0.0017128293402493
Valid Loss:  0.0015919345896691084
Epoch:  138  	Training Loss: 0.0020414285827428102
Test Loss:  0.001708976342342794
Valid Loss:  0.0015910466900095344
Epoch:  139  	Training Loss: 0.00203228322789073
Test Loss:  0.001705307513475418
Valid Loss:  0.001590365543961525
Epoch:  140  	Training Loss: 0.0020234347321093082
Test Loss:  0.0017018134240061045
Valid Loss:  0.001589881256222725 28%|██▊       | 141/500 [01:43<07:13,  1.21s/it] 29%|██▊       | 143/500 [01:44<05:11,  1.15it/s] 29%|██▉       | 145/500 [01:44<03:45,  1.57it/s] 29%|██▉       | 147/500 [01:44<02:44,  2.14it/s] 30%|██▉       | 149/500 [01:44<02:01,  2.88it/s] 30%|███       | 151/500 [01:51<07:02,  1.21s/it] 31%|███       | 153/500 [01:51<05:01,  1.15it/s] 31%|███       | 155/500 [01:51<03:36,  1.59it/s] 31%|███▏      | 157/500 [01:51<02:37,  2.18it/s] 32%|███▏      | 159/500 [01:51<01:56,  2.94it/s] 32%|███▏      | 161/500 [01:58<06:49,  1.21s/it] 33%|███▎      | 163/500 [01:58<04:52,  1.15it/s] 33%|███▎      | 165/500 [01:58<03:30,  1.59it/s] 33%|███▎      | 167/500 [01:58<02:33,  2.16it/s] 34%|███▍      | 169/500 [01:58<01:55,  2.87it/s] 34%|███▍      | 171/500 [02:05<06:44,  1.23s/it] 35%|███▍      | 173/500 [02:05<04:49,  1.13it/s] 35%|███▌      | 175/500 [02:05<03:27,  1.56it/s] 35%|███▌      | 177/500 [02:05<02:30,  2.14it/s] 36%|███▌      | 179/500 [02:05<01:51,  2.89it/s] 36%|███▌      | 181/500 [02:12<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:12<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:12<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:12<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:12<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:19<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:19<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:19<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:19<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:19<01:41,  2.97it/s] 40%|████      | 201/500 [02:25<05:54,  1.19s/it] 41%|████      | 203/500 [02:26<04:12,  1.17it/s] 41%|████      | 205/500 [02:26<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:26<02:11,  2.22it/s]
Epoch:  141  	Training Loss: 0.002014872618019581
Test Loss:  0.0016984977992251515
Valid Loss:  0.0015895804390311241
Epoch:  142  	Training Loss: 0.0020065896678715944
Test Loss:  0.0016953046433627605
Valid Loss:  0.0015894670505076647
Epoch:  143  	Training Loss: 0.001998567720875144
Test Loss:  0.001692282035946846
Valid Loss:  0.0015895174583420157
Epoch:  144  	Training Loss: 0.0019908060785382986
Test Loss:  0.0016894224099814892
Valid Loss:  0.0015897415578365326
Epoch:  145  	Training Loss: 0.0019832970574498177
Test Loss:  0.0016867093509063125
Valid Loss:  0.001590110594406724
Epoch:  146  	Training Loss: 0.0019760318100452423
Test Loss:  0.001684144837781787
Valid Loss:  0.0015906270127743483
Epoch:  147  	Training Loss: 0.0019690049812197685
Test Loss:  0.0016817243304103613
Valid Loss:  0.0015912929084151983
Epoch:  148  	Training Loss: 0.0019622081890702248
Test Loss:  0.0016794393304735422
Valid Loss:  0.001592082902789116
Epoch:  149  	Training Loss: 0.001955633517354727
Test Loss:  0.0016772809904068708
Valid Loss:  0.0015930014196783304
Epoch:  150  	Training Loss: 0.0019492711871862411
Test Loss:  0.001675254083238542
Valid Loss:  0.0015940361190587282
Epoch:  151  	Training Loss: 0.001943116309121251
Test Loss:  0.0016733339289203286
Valid Loss:  0.0015951870009303093
Epoch:  152  	Training Loss: 0.0019371670205146074
Test Loss:  0.001671507372520864
Valid Loss:  0.0015964447520673275
Epoch:  153  	Training Loss: 0.0019313993398100138
Test Loss:  0.001669792807660997
Valid Loss:  0.0015978093724697828
Epoch:  154  	Training Loss: 0.0019258242100477219
Test Loss:  0.0016681887209415436
Valid Loss:  0.0015992650296539068
Epoch:  155  	Training Loss: 0.001920429989695549
Test Loss:  0.0016666901065036654
Valid Loss:  0.0016008091624826193
Epoch:  156  	Training Loss: 0.001915213419124484
Test Loss:  0.0016652933554723859
Valid Loss:  0.0016024387441575527
Epoch:  157  	Training Loss: 0.0019101669313386083
Test Loss:  0.0016639854293316603
Valid Loss:  0.0016041473718360066
Epoch:  158  	Training Loss: 0.0019052838906645775
Test Loss:  0.0016627805307507515
Valid Loss:  0.001605927711352706
Epoch:  159  	Training Loss: 0.0019005619687959552
Test Loss:  0.001661654212512076
Valid Loss:  0.0016077852342277765
Epoch:  160  	Training Loss: 0.0018959918525069952
Test Loss:  0.0016606115968897939
Valid Loss:  0.0016097042243927717
Epoch:  161  	Training Loss: 0.0018915736582130194
Test Loss:  0.001659644185565412
Valid Loss:  0.0016116872429847717
Epoch:  162  	Training Loss: 0.001887301099486649
Test Loss:  0.0016587667632848024
Valid Loss:  0.001613719156011939
Epoch:  163  	Training Loss: 0.0018831661436706781
Test Loss:  0.0016579617513343692
Valid Loss:  0.0016158147482201457
Epoch:  164  	Training Loss: 0.0018791680922731757
Test Loss:  0.0016572242602705956
Valid Loss:  0.0016179532976821065
Epoch:  165  	Training Loss: 0.0018752989126369357
Test Loss:  0.0016565525438636541
Valid Loss:  0.001620137132704258
Epoch:  166  	Training Loss: 0.0018715579062700272
Test Loss:  0.0016559367068111897
Valid Loss:  0.0016223660204559565
Epoch:  167  	Training Loss: 0.001867939718067646
Test Loss:  0.0016553818713873625
Valid Loss:  0.0016246389131993055
Epoch:  168  	Training Loss: 0.0018644381780177355
Test Loss:  0.0016548916464671493
Valid Loss:  0.001626939163543284
Epoch:  169  	Training Loss: 0.0018610518891364336
Test Loss:  0.001654448569752276
Valid Loss:  0.0016292782966047525
Epoch:  170  	Training Loss: 0.00185777572914958
Test Loss:  0.0016540603246539831
Valid Loss:  0.001631643041037023
Epoch:  171  	Training Loss: 0.0018546059727668762
Test Loss:  0.001653721323236823
Valid Loss:  0.001634043175727129
Epoch:  172  	Training Loss: 0.0018515412230044603
Test Loss:  0.0016534414608031511
Valid Loss:  0.0016364555340260267
Epoch:  173  	Training Loss: 0.0018485781038179994
Test Loss:  0.0016532110748812556
Valid Loss:  0.0016388969961553812
Epoch:  174  	Training Loss: 0.0018457125406712294
Test Loss:  0.0016530125867575407
Valid Loss:  0.001641355105675757
Epoch:  175  	Training Loss: 0.0018429405754432082
Test Loss:  0.0016528600826859474
Valid Loss:  0.0016438409220427275
Epoch:  176  	Training Loss: 0.0018402587156742811
Test Loss:  0.0016527429688721895
Valid Loss:  0.0016463319770991802
Epoch:  177  	Training Loss: 0.0018376619555056095
Test Loss:  0.0016526635736227036
Valid Loss:  0.0016488417750224471
Epoch:  178  	Training Loss: 0.0018351536709815264
Test Loss:  0.0016526159597560763
Valid Loss:  0.0016513611190021038
Epoch:  179  	Training Loss: 0.0018327245488762856
Test Loss:  0.0016526095569133759
Valid Loss:  0.0016538950148969889
Epoch:  180  	Training Loss: 0.0018303764518350363
Test Loss:  0.0016526273684576154
Valid Loss:  0.0016564291436225176
Epoch:  181  	Training Loss: 0.001828102394938469
Test Loss:  0.001652671955525875
Valid Loss:  0.0016589774750173092
Epoch:  182  	Training Loss: 0.0018259031930938363
Test Loss:  0.0016527340048924088
Valid Loss:  0.0016615400090813637
Epoch:  183  	Training Loss: 0.0018237733747810125
Test Loss:  0.0016528235282748938
Valid Loss:  0.0016640976537019014
Epoch:  184  	Training Loss: 0.0018217114266008139
Test Loss:  0.0016529440181329846
Valid Loss:  0.001666664844378829
Epoch:  185  	Training Loss: 0.001819718163460493
Test Loss:  0.001653082319535315
Valid Loss:  0.0016692249337211251
Epoch:  186  	Training Loss: 0.0018177881138399243
Test Loss:  0.0016532609006389976
Valid Loss:  0.0016717856051400304
Epoch:  187  	Training Loss: 0.0018159233732149005
Test Loss:  0.001653456361964345
Valid Loss:  0.0016743463929742575
Epoch:  188  	Training Loss: 0.0018141190521419048
Test Loss:  0.001653675572015345
Valid Loss:  0.0016769011272117496
Epoch:  189  	Training Loss: 0.0018123735208064318
Test Loss:  0.0016539155039936304
Valid Loss:  0.0016794445691630244
Epoch:  190  	Training Loss: 0.0018106830539181828
Test Loss:  0.0016541755758225918
Valid Loss:  0.0016819857992231846
Epoch:  191  	Training Loss: 0.0018090489320456982
Test Loss:  0.00165445520542562
Valid Loss:  0.0016845200443640351
Epoch:  192  	Training Loss: 0.0018074656836688519
Test Loss:  0.0016547736013308167
Valid Loss:  0.0016870297258719802
Epoch:  193  	Training Loss: 0.0018059451831504703
Test Loss:  0.0016551024746149778
Valid Loss:  0.0016895381268113852
Epoch:  194  	Training Loss: 0.0018044700846076012
Test Loss:  0.0016554479952901602
Valid Loss:  0.00169203185942024
Epoch:  195  	Training Loss: 0.0018030417850241065
Test Loss:  0.0016558041097596288
Valid Loss:  0.0016945169772952795
Epoch:  196  	Training Loss: 0.0018016628455370665
Test Loss:  0.0016561703523620963
Valid Loss:  0.00169698940590024
Epoch:  197  	Training Loss: 0.001800325233489275
Test Loss:  0.0016565516125410795
Valid Loss:  0.0016994505422189832
Epoch:  198  	Training Loss: 0.0017990353517234325
Test Loss:  0.0016569341532886028
Valid Loss:  0.001701901899650693
Epoch:  199  	Training Loss: 0.0017977862153202295
Test Loss:  0.0016573364846408367
Valid Loss:  0.0017043349798768759
Epoch:  200  	Training Loss: 0.0017965740989893675
Test Loss:  0.0016577380010858178
Valid Loss:  0.0017067582812160254
Epoch:  201  	Training Loss: 0.001795405289158225
Test Loss:  0.0016581634990870953
Valid Loss:  0.001709159929305315
Epoch:  202  	Training Loss: 0.0017942740814760327
Test Loss:  0.0016585576813668013
Valid Loss:  0.0017115626251325011
Epoch:  203  	Training Loss: 0.0017931768670678139
Test Loss:  0.0016589784063398838
Valid Loss:  0.001713949954137206
Epoch:  204  	Training Loss: 0.0017921171383932233
Test Loss:  0.0016594093758612871
Valid Loss:  0.001716317143291235
Epoch:  205  	Training Loss: 0.0017910882597789168
Test Loss:  0.0016598448855802417
Valid Loss:  0.0017186643090099096
Epoch:  206  	Training Loss: 0.0017900969833135605
Test Loss:  0.00166029273532331
Valid Loss:  0.001720996806398034
Epoch:  207  	Training Loss: 0.0017891358584165573
Test Loss:  0.0016607427969574928
Valid Loss:  0.0017233118414878845
Epoch:  208  	Training Loss: 0.0017882043030112982
Test Loss:  0.001661199377849698
Valid Loss:  0.0017255995189771056
Epoch:  209  	Training Loss: 0.0017873068572953343
Test Loss:   42%|████▏     | 209/500 [02:26<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:32<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:33<04:08,  1.15it/s] 43%|████▎     | 215/500 [02:33<02:58,  1.59it/s] 43%|████▎     | 217/500 [02:33<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:33<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:39<05:35,  1.20s/it] 45%|████▍     | 223/500 [02:40<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:40<02:52,  1.59it/s] 45%|████▌     | 227/500 [02:40<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:40<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:46<05:25,  1.21s/it] 47%|████▋     | 233/500 [02:47<03:51,  1.15it/s] 47%|████▋     | 235/500 [02:47<02:46,  1.60it/s] 47%|████▋     | 237/500 [02:47<02:00,  2.18it/s] 48%|████▊     | 239/500 [02:47<01:28,  2.94it/s] 48%|████▊     | 241/500 [02:53<05:09,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:40,  1.16it/s] 49%|████▉     | 245/500 [02:54<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:54<01:54,  2.20it/s] 50%|████▉     | 249/500 [02:54<01:24,  2.96it/s] 50%|█████     | 251/500 [03:01<05:10,  1.25s/it] 51%|█████     | 253/500 [03:01<03:41,  1.12it/s] 51%|█████     | 255/500 [03:01<02:38,  1.55it/s] 51%|█████▏    | 257/500 [03:01<01:54,  2.11it/s] 52%|█████▏    | 259/500 [03:01<01:25,  2.81it/s] 52%|█████▏    | 261/500 [03:08<04:50,  1.21s/it] 53%|█████▎    | 263/500 [03:08<03:26,  1.15it/s] 53%|█████▎    | 265/500 [03:08<02:27,  1.59it/s] 53%|█████▎    | 267/500 [03:08<01:47,  2.18it/s] 54%|█████▍    | 269/500 [03:08<01:18,  2.93it/s] 54%|█████▍    | 271/500 [03:15<04:37,  1.21s/it] 55%|█████▍    | 273/500 [03:15<03:18,  1.14it/s] 55%|█████▌    | 275/500 [03:15<02:22,  1.58it/s] 55%|█████▌    | 277/500 [03:15<01:43,  2.15it/s]0.0016616706270724535
Valid Loss:  0.0017278738087043166
Epoch:  210  	Training Loss: 0.0017864382825791836
Test Loss:  0.0016621341928839684
Valid Loss:  0.0017301301704719663
Epoch:  211  	Training Loss: 0.0017855968326330185
Test Loss:  0.0016626081196591258
Valid Loss:  0.0017323644133284688
Epoch:  212  	Training Loss: 0.0017847814597189426
Test Loss:  0.0016630806494504213
Valid Loss:  0.0017345892265439034
Epoch:  213  	Training Loss: 0.0017839974025264382
Test Loss:  0.001663561211898923
Valid Loss:  0.001736786332912743
Epoch:  214  	Training Loss: 0.001783233368769288
Test Loss:  0.0016640406101942062
Valid Loss:  0.001738963183015585
Epoch:  215  	Training Loss: 0.001782495528459549
Test Loss:  0.0016645252471789718
Valid Loss:  0.0017411229200661182
Epoch:  216  	Training Loss: 0.001781785162165761
Test Loss:  0.0016650119796395302
Valid Loss:  0.0017432558815926313
Epoch:  217  	Training Loss: 0.0017810938879847527
Test Loss:  0.0016655003419145942
Valid Loss:  0.0017453762702643871
Epoch:  218  	Training Loss: 0.001780426362529397
Test Loss:  0.001665992895141244
Valid Loss:  0.001747471047565341
Epoch:  219  	Training Loss: 0.0017797823529690504
Test Loss:  0.001666477881371975
Valid Loss:  0.0017495490610599518
Epoch:  220  	Training Loss: 0.0017791581340134144
Test Loss:  0.0016669712495058775
Valid Loss:  0.0017515977378934622
Epoch:  221  	Training Loss: 0.001778554287739098
Test Loss:  0.0016674663638696074
Valid Loss:  0.0017536334926262498
Epoch:  222  	Training Loss: 0.0017779688350856304
Test Loss:  0.0016679712571203709
Valid Loss:  0.0017556296661496162
Epoch:  223  	Training Loss: 0.0017774042207747698
Test Loss:  0.0016684712609276175
Valid Loss:  0.0017576140817254782
Epoch:  224  	Training Loss: 0.0017768581165000796
Test Loss:  0.0016689718468114734
Valid Loss:  0.0017595745157450438
Epoch:  225  	Training Loss: 0.0017763320356607437
Test Loss:  0.001669465797021985
Valid Loss:  0.0017615169053897262
Epoch:  226  	Training Loss: 0.0017758207395672798
Test Loss:  0.0016699638217687607
Valid Loss:  0.0017634298419579864
Epoch:  227  	Training Loss: 0.0017753271386027336
Test Loss:  0.0016704578883945942
Valid Loss:  0.0017653282266110182
Epoch:  228  	Training Loss: 0.0017748493701219559
Test Loss:  0.0016709452029317617
Valid Loss:  0.0017672096146270633
Epoch:  229  	Training Loss: 0.0017743859207257628
Test Loss:  0.0016714328667148948
Valid Loss:  0.0017690712120383978
Epoch:  230  	Training Loss: 0.001773938536643982
Test Loss:  0.0016719166887924075
Valid Loss:  0.0017708982340991497
Epoch:  231  	Training Loss: 0.0017735057044774294
Test Loss:  0.0016724055167287588
Valid Loss:  0.0017727219965308905
Epoch:  232  	Training Loss: 0.00177308963611722
Test Loss:  0.0016728821210563183
Valid Loss:  0.0017745140939950943
Epoch:  233  	Training Loss: 0.0017726829973980784
Test Loss:  0.001673360588029027
Valid Loss:  0.0017762943170964718
Epoch:  234  	Training Loss: 0.0017722928896546364
Test Loss:  0.0016738350968807936
Valid Loss:  0.0017780454363673925
Epoch:  235  	Training Loss: 0.001771913026459515
Test Loss:  0.001674311119131744
Valid Loss:  0.0017797747859731317
Epoch:  236  	Training Loss: 0.0017715436406433582
Test Loss:  0.0016747803892940283
Valid Loss:  0.0017814894672483206
Epoch:  237  	Training Loss: 0.0017711891559883952
Test Loss:  0.0016752451192587614
Valid Loss:  0.0017831784207373857
Epoch:  238  	Training Loss: 0.0017708465456962585
Test Loss:  0.0016757049597799778
Valid Loss:  0.0017848510760813951
Epoch:  239  	Training Loss: 0.0017705156933516264
Test Loss:  0.0016761680599302053
Valid Loss:  0.001786504522897303
Epoch:  240  	Training Loss: 0.0017701933393254876
Test Loss:  0.0016766238259151578
Valid Loss:  0.0017881342209875584
Epoch:  241  	Training Loss: 0.001769885653629899
Test Loss:  0.001677079824730754
Valid Loss:  0.001789742847904563
Epoch:  242  	Training Loss: 0.0017695827409625053
Test Loss:  0.0016775240655988455
Valid Loss:  0.00179133634082973
Epoch:  243  	Training Loss: 0.0017692918190732598
Test Loss:  0.0016779646975919604
Valid Loss:  0.0017929095774888992
Epoch:  244  	Training Loss: 0.0017690127715468407
Test Loss:  0.00167840626090765
Valid Loss:  0.0017944652354344726
Epoch:  245  	Training Loss: 0.0017687393119558692
Test Loss:  0.0016788444481790066
Valid Loss:  0.0017960021505132318
Epoch:  246  	Training Loss: 0.0017684740014374256
Test Loss:  0.0016792831011116505
Valid Loss:  0.0017975128721445799
Epoch:  247  	Training Loss: 0.0017682176548987627
Test Loss:  0.0016797136049717665
Valid Loss:  0.0017990062478929758
Epoch:  248  	Training Loss: 0.0017679744632914662
Test Loss:  0.0016801436431705952
Valid Loss:  0.0018004804151132703
Epoch:  249  	Training Loss: 0.0017677367432042956
Test Loss:  0.0016805632039904594
Valid Loss:  0.0018019365379586816
Epoch:  250  	Training Loss: 0.0017675042618066072
Test Loss:  0.001680985209532082
Valid Loss:  0.0018033612286671996
Epoch:  251  	Training Loss: 0.0017672802787274122
Test Loss:  0.0016814065165817738
Valid Loss:  0.0018047878984361887
Epoch:  252  	Training Loss: 0.001767065143212676
Test Loss:  0.0016818225849419832
Valid Loss:  0.001806184882298112
Epoch:  253  	Training Loss: 0.0017668550135567784
Test Loss:  0.0016822285251691937
Valid Loss:  0.0018075642874464393
Epoch:  254  	Training Loss: 0.0017666553612798452
Test Loss:  0.001682636677287519
Valid Loss:  0.001808923203498125
Epoch:  255  	Training Loss: 0.0017664581537246704
Test Loss:  0.0016830363310873508
Valid Loss:  0.0018102640751749277
Epoch:  256  	Training Loss: 0.0017662683967500925
Test Loss:  0.0016834373818710446
Valid Loss:  0.0018115842249244452
Epoch:  257  	Training Loss: 0.001766084460541606
Test Loss:  0.0016838307492434978
Valid Loss:  0.0018128914525732398
Epoch:  258  	Training Loss: 0.0017659100703895092
Test Loss:  0.0016842265613377094
Valid Loss:  0.0018141792388632894
Epoch:  259  	Training Loss: 0.0017657381249591708
Test Loss:  0.0016846084035933018
Valid Loss:  0.0018154482822865248
Epoch:  260  	Training Loss: 0.0017655733972787857
Test Loss:  0.0016849979292601347
Valid Loss:  0.0018167024245485663
Epoch:  261  	Training Loss: 0.0017654136754572392
Test Loss:  0.001685371738858521
Valid Loss:  0.001817937707528472
Epoch:  262  	Training Loss: 0.001765256398357451
Test Loss:  0.0016857478767633438
Valid Loss:  0.0018191486597061157
Epoch:  263  	Training Loss: 0.0017651107627898455
Test Loss:  0.0016861225012689829
Valid Loss:  0.0018203526269644499
Epoch:  264  	Training Loss: 0.0017649629153311253
Test Loss:  0.0016864815261214972
Valid Loss:  0.0018215375021100044
Epoch:  265  	Training Loss: 0.0017648249631747603
Test Loss:  0.0016868405509740114
Valid Loss:  0.0018227036343887448
Epoch:  266  	Training Loss: 0.0017646902706474066
Test Loss:  0.0016872051637619734
Valid Loss:  0.00182386115193367
Epoch:  267  	Training Loss: 0.0017645575571805239
Test Loss:  0.0016875533619895577
Valid Loss:  0.0018249924760311842
Epoch:  268  	Training Loss: 0.001764429616741836
Test Loss:  0.0016879062168300152
Valid Loss:  0.0018261157674714923
Epoch:  269  	Training Loss: 0.001764307264238596
Test Loss:  0.0016882579075172544
Valid Loss:  0.0018272189190611243
Epoch:  270  	Training Loss: 0.0017641873564571142
Test Loss:  0.0016885933000594378
Valid Loss:  0.0018283067038282752
Epoch:  271  	Training Loss: 0.0017640755977481604
Test Loss:  0.0016889325343072414
Valid Loss:  0.0018293760949745774
Epoch:  272  	Training Loss: 0.0017639624420553446
Test Loss:  0.001689266413450241
Valid Loss:  0.0018304307013750076
Epoch:  273  	Training Loss: 0.0017638555727899075
Test Loss:  0.001689594704657793
Valid Loss:  0.0018314752960577607
Epoch:  274  	Training Loss: 0.0017637505661696196
Test Loss:  0.0016899248585104942
Valid Loss:  0.0018324970733374357
Epoch:  275  	Training Loss: 0.001763652078807354
Test Loss:  0.0016902412753552198
Valid Loss:  0.0018335080239921808
Epoch:  276  	Training Loss: 0.001763555919751525
Test Loss:  0.0016905643278732896
Valid Loss:  0.0018345033749938011
Epoch:  277  	Training Loss: 0.0017634606920182705
Test Loss:  0.0016908756224438548
Valid Loss:  0.001835492206737399
 56%|█████▌    | 279/500 [03:15<01:16,  2.90it/s] 56%|█████▌    | 281/500 [03:22<04:26,  1.22s/it] 57%|█████▋    | 283/500 [03:22<03:09,  1.15it/s] 57%|█████▋    | 285/500 [03:22<02:15,  1.58it/s] 57%|█████▋    | 287/500 [03:22<01:38,  2.16it/s] 58%|█████▊    | 289/500 [03:22<01:12,  2.92it/s] 58%|█████▊    | 291/500 [03:29<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:29<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:29<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:29<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:29<01:07,  2.96it/s] 60%|██████    | 301/500 [03:35<03:55,  1.18s/it] 61%|██████    | 303/500 [03:36<02:47,  1.18it/s] 61%|██████    | 305/500 [03:36<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:36<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:36<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:42<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:43<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:43<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:43<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:43<01:01,  2.94it/s] 64%|██████▍   | 321/500 [03:49<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:49<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:50<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:50<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:50<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:56<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:56<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:56<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:57<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:57<00:53,  2.98it/s] 68%|██████▊   | 341/500 [04:03<03:14,  1.22s/it] 69%|██████▊   | 343/500 [04:03<02:17,  1.14it/s] 69%|██████▉   | 345/500 [04:04<01:38,  1.58it/s]Epoch:  278  	Training Loss: 0.0017633680254220963
Test Loss:  0.0016911858692765236
Valid Loss:  0.0018364631105214357
Epoch:  279  	Training Loss: 0.0017632825765758753
Test Loss:  0.0016914886655285954
Valid Loss:  0.0018374109640717506
Epoch:  280  	Training Loss: 0.0017631936352699995
Test Loss:  0.0016917955363169312
Valid Loss:  0.0018383522983640432
Epoch:  281  	Training Loss: 0.0017631137743592262
Test Loss:  0.0016920885536819696
Valid Loss:  0.0018392783822491765
Epoch:  282  	Training Loss: 0.0017630340298637748
Test Loss:  0.001692384947091341
Valid Loss:  0.0018401904962956905
Epoch:  283  	Training Loss: 0.001762955915182829
Test Loss:  0.0016926741227507591
Valid Loss:  0.00184108957182616
Epoch:  284  	Training Loss: 0.0017628842033445835
Test Loss:  0.0016929635312408209
Valid Loss:  0.0018419784028083086
Epoch:  285  	Training Loss: 0.001762809930369258
Test Loss:  0.001693248050287366
Valid Loss:  0.0018428474431857467
Epoch:  286  	Training Loss: 0.0017627400811761618
Test Loss:  0.0016935254679992795
Valid Loss:  0.0018437150865793228
Epoch:  287  	Training Loss: 0.0017626725602895021
Test Loss:  0.0016937984619289637
Valid Loss:  0.0018445600289851427
Epoch:  288  	Training Loss: 0.001762607367709279
Test Loss:  0.0016940662171691656
Valid Loss:  0.0018453918164595962
Epoch:  289  	Training Loss: 0.0017625447362661362
Test Loss:  0.0016943421214818954
Valid Loss:  0.001846218598075211
Epoch:  290  	Training Loss: 0.001762484316714108
Test Loss:  0.0016946026589721441
Valid Loss:  0.0018470250070095062
Epoch:  291  	Training Loss: 0.0017624234315007925
Test Loss:  0.0016948631964623928
Valid Loss:  0.0018478231504559517
Epoch:  292  	Training Loss: 0.001762368599884212
Test Loss:  0.0016951254801824689
Valid Loss:  0.0018486115150153637
Epoch:  293  	Training Loss: 0.001762312836945057
Test Loss:  0.0016953779850155115
Valid Loss:  0.0018493813695386052
Epoch:  294  	Training Loss: 0.0017622602172195911
Test Loss:  0.0016956336330622435
Valid Loss:  0.0018501451704651117
Epoch:  295  	Training Loss: 0.0017622080631554127
Test Loss:  0.0016958793858066201
Valid Loss:  0.001850899076089263
Epoch:  296  	Training Loss: 0.0017621571896597743
Test Loss:  0.0016961228102445602
Valid Loss:  0.0018516385462135077
Epoch:  297  	Training Loss: 0.0017621072474867105
Test Loss:  0.0016963612288236618
Valid Loss:  0.001852360088378191
Epoch:  298  	Training Loss: 0.001762061147019267
Test Loss:  0.0016966011608019471
Valid Loss:  0.0018530800007283688
Epoch:  299  	Training Loss: 0.001762015512213111
Test Loss:  0.001696831313893199
Valid Loss:  0.001853786874562502
Epoch:  300  	Training Loss: 0.0017619723221287131
Test Loss:  0.0016970611177384853
Valid Loss:  0.0018544874619692564
Epoch:  301  	Training Loss: 0.001761933322995901
Test Loss:  0.0016972904559224844
Valid Loss:  0.0018551680259406567
Epoch:  302  	Training Loss: 0.001761886989697814
Test Loss:  0.0016975158359855413
Valid Loss:  0.0018558495212346315
Epoch:  303  	Training Loss: 0.0017618489218875766
Test Loss:  0.0016977329505607486
Valid Loss:  0.001856509130448103
Epoch:  304  	Training Loss: 0.0017618098063394427
Test Loss:  0.0016979507636278868
Valid Loss:  0.0018571699038147926
Epoch:  305  	Training Loss: 0.0017617737175896764
Test Loss:  0.0016981657827273011
Valid Loss:  0.0018578101880848408
Epoch:  306  	Training Loss: 0.0017617353005334735
Test Loss:  0.0016983746318146586
Valid Loss:  0.0018584518693387508
Epoch:  307  	Training Loss: 0.0017617018893361092
Test Loss:  0.0016985861584544182
Valid Loss:  0.0018590762047097087
Epoch:  308  	Training Loss: 0.0017616695258766413
Test Loss:  0.0016987896524369717
Valid Loss:  0.0018596893642097712
Epoch:  309  	Training Loss: 0.001761635416187346
Test Loss:  0.001698991167359054
Valid Loss:  0.001860296819359064
Epoch:  310  	Training Loss: 0.0017616057302802801
Test Loss:  0.0016991868615150452
Valid Loss:  0.0018608974060043693
Epoch:  311  	Training Loss: 0.0017615758115425706
Test Loss:  0.0016993882600218058
Valid Loss:  0.0018614829750731587
Epoch:  312  	Training Loss: 0.001761545892804861
Test Loss:  0.0016995799960568547
Valid Loss:  0.001862053177319467
Epoch:  313  	Training Loss: 0.0017615176038816571
Test Loss:  0.0016997772036120296
Valid Loss:  0.0018626339733600616
Epoch:  314  	Training Loss: 0.0017614890821278095
Test Loss:  0.0016999569488689303
Valid Loss:  0.0018631971906870604
Epoch:  315  	Training Loss: 0.0017614623066037893
Test Loss:  0.0017001433297991753
Valid Loss:  0.001863744342699647
Epoch:  316  	Training Loss: 0.001761435647495091
Test Loss:  0.0017003295943140984
Valid Loss:  0.0018642923096194863
Epoch:  317  	Training Loss: 0.00176141201518476
Test Loss:  0.001700511435046792
Valid Loss:  0.0018648299155756831
Epoch:  318  	Training Loss: 0.0017613876843824983
Test Loss:  0.0017006879206746817
Valid Loss:  0.0018653509905561805
Epoch:  319  	Training Loss: 0.0017613648669794202
Test Loss:  0.0017008637078106403
Valid Loss:  0.0018658743938431144
Epoch:  320  	Training Loss: 0.0017613435629755259
Test Loss:  0.0017010343726724386
Valid Loss:  0.0018663855735212564
Epoch:  321  	Training Loss: 0.0017613198142498732
Test Loss:  0.0017012039897963405
Valid Loss:  0.0018668915145099163
Epoch:  322  	Training Loss: 0.0017612988594919443
Test Loss:  0.0017013722099363804
Valid Loss:  0.0018673876766115427
Epoch:  323  	Training Loss: 0.0017612790688872337
Test Loss:  0.0017015422927215695
Valid Loss:  0.0018678742926567793
Epoch:  324  	Training Loss: 0.0017612585797905922
Test Loss:  0.0017017039936035872
Valid Loss:  0.001868347404524684
Epoch:  325  	Training Loss: 0.0017612396040931344
Test Loss:  0.0017018632497638464
Valid Loss:  0.0018688254058361053
Epoch:  326  	Training Loss: 0.0017612206283956766
Test Loss:  0.0017020234372466803
Valid Loss:  0.0018692899029701948
Epoch:  327  	Training Loss: 0.0017612047959119081
Test Loss:  0.001702178968116641
Valid Loss:  0.0018697484629228711
Epoch:  328  	Training Loss: 0.0017611872171983123
Test Loss:  0.0017023293767124414
Valid Loss:  0.0018702001543715596
Epoch:  329  	Training Loss: 0.0017611675430089235
Test Loss:  0.0017024809494614601
Valid Loss:  0.0018706412520259619
Epoch:  330  	Training Loss: 0.001761153107509017
Test Loss:  0.0017026298446580768
Valid Loss:  0.0018710765289142728
Epoch:  331  	Training Loss: 0.001761137624271214
Test Loss:  0.0017027801368385553
Valid Loss:  0.0018715047044679523
Epoch:  332  	Training Loss: 0.001761124120093882
Test Loss:  0.0017029261216521263
Valid Loss:  0.0018719328800216317
Epoch:  333  	Training Loss: 0.001761108636856079
Test Loss:  0.0017030690796673298
Valid Loss:  0.0018723440589383245
Epoch:  334  	Training Loss: 0.001761093968525529
Test Loss:  0.0017032070318236947
Valid Loss:  0.0018727548886090517
Epoch:  335  	Training Loss: 0.0017610791837796569
Test Loss:  0.001703342772088945
Valid Loss:  0.0018731605960056186
Epoch:  336  	Training Loss: 0.001761066960170865
Test Loss:  0.001703476533293724
Valid Loss:  0.0018735539633780718
Epoch:  337  	Training Loss: 0.0017610525246709585
Test Loss:  0.001703611807897687
Valid Loss:  0.0018739497754722834
Epoch:  338  	Training Loss: 0.001761039486154914
Test Loss:  0.0017037420766428113
Valid Loss:  0.001874334760941565
Epoch:  339  	Training Loss: 0.0017610297072678804
Test Loss:  0.0017038731602951884
Valid Loss:  0.0018747136928141117
Epoch:  340  	Training Loss: 0.001761017832905054
Test Loss:  0.0017040021484717727
Valid Loss:  0.001875086221843958
Epoch:  341  	Training Loss: 0.001761006424203515
Test Loss:  0.0017041265964508057
Valid Loss:  0.0018754475750029087
Epoch:  342  	Training Loss: 0.0017609953647479415
Test Loss:  0.001704246737062931
Valid Loss:  0.0018758124206215143
Epoch:  343  	Training Loss: 0.0017609873320907354
Test Loss:  0.001704375259578228
Valid Loss:  0.001876168418675661
Epoch:  344  	Training Loss: 0.0017609745264053345
Test Loss:  0.0017044951673597097
Valid Loss:  0.0018765212735161185
Epoch:  345  	Training Loss: 0.001760966144502163
Test Loss:  0.0017046115826815367
Valid Loss:  0.0018768578302115202
Epoch:  346  	Training Loss: 0.001760954735800624
Test Loss:   69%|██████▉   | 347/500 [04:04<01:10,  2.16it/s] 70%|██████▉   | 349/500 [04:04<00:52,  2.85it/s] 70%|███████   | 351/500 [04:10<03:03,  1.23s/it] 71%|███████   | 353/500 [04:11<02:10,  1.13it/s] 71%|███████   | 355/500 [04:11<01:33,  1.55it/s] 71%|███████▏  | 357/500 [04:11<01:08,  2.09it/s] 72%|███████▏  | 359/500 [04:11<00:50,  2.77it/s] 72%|███████▏  | 361/500 [04:18<02:47,  1.21s/it] 73%|███████▎  | 363/500 [04:18<01:58,  1.15it/s] 73%|███████▎  | 365/500 [04:18<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:18<01:00,  2.18it/s] 74%|███████▍  | 369/500 [04:18<00:44,  2.94it/s] 74%|███████▍  | 371/500 [04:24<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:25<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:25<01:17,  1.60it/s] 75%|███████▌  | 377/500 [04:25<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:25<00:41,  2.95it/s] 76%|███████▌  | 381/500 [04:31<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:32<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:32<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:32<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:38<02:12,  1.22s/it] 79%|███████▊  | 393/500 [04:39<01:33,  1.15it/s] 79%|███████▉  | 395/500 [04:45<02:43,  1.56s/it] 79%|███████▉  | 397/500 [04:45<01:54,  1.11s/it] 80%|███████▉  | 399/500 [04:45<01:21,  1.24it/s] 80%|████████  | 401/500 [04:52<02:30,  1.52s/it] 81%|████████  | 403/500 [04:52<01:45,  1.08s/it] 81%|████████  | 405/500 [04:58<02:44,  1.73s/it] 81%|████████▏ | 407/500 [04:58<01:54,  1.23s/it] 82%|████████▏ | 409/500 [04:59<01:20,  1.13it/s] 82%|████████▏ | 411/500 [05:05<02:20,  1.58s/it]0.0017047291621565819
Valid Loss:  0.0018771984614431858
Epoch:  347  	Training Loss: 0.0017609450733289123
Test Loss:  0.0017048453446477652
Valid Loss:  0.0018775268690660596
Epoch:  348  	Training Loss: 0.0017609359929338098
Test Loss:  0.001704953145235777
Valid Loss:  0.001877860864624381
Epoch:  349  	Training Loss: 0.001760929124429822
Test Loss:  0.00170506676658988
Valid Loss:  0.001878181705251336
Epoch:  350  	Training Loss: 0.0017609195783734322
Test Loss:  0.0017051761969923973
Valid Loss:  0.0018785014981403947
Epoch:  351  	Training Loss: 0.0017609114293009043
Test Loss:  0.0017052837647497654
Valid Loss:  0.0018788119778037071
Epoch:  352  	Training Loss: 0.0017609037458896637
Test Loss:  0.0017053899355232716
Valid Loss:  0.0018791173351928592
Epoch:  353  	Training Loss: 0.0017608982743695378
Test Loss:  0.0017054935451596975
Valid Loss:  0.0018794267671182752
Epoch:  354  	Training Loss: 0.0017608911730349064
Test Loss:  0.0017055945936590433
Valid Loss:  0.0018797190859913826
Epoch:  355  	Training Loss: 0.001760881277732551
Test Loss:  0.0017056959914043546
Valid Loss:  0.0018800125690177083
Epoch:  356  	Training Loss: 0.0017608734779059887
Test Loss:  0.0017057998338714242
Valid Loss:  0.0018802979029715061
Epoch:  357  	Training Loss: 0.0017608696362003684
Test Loss:  0.0017058933153748512
Valid Loss:  0.0018805856816470623
Epoch:  358  	Training Loss: 0.0017608621856197715
Test Loss:  0.001705994363874197
Valid Loss:  0.0018808675231412053
Epoch:  359  	Training Loss: 0.0017608560156077147
Test Loss:  0.0017060900572687387
Valid Loss:  0.001881137490272522
Epoch:  360  	Training Loss: 0.0017608491471037269
Test Loss:  0.001706181326881051
Valid Loss:  0.0018814096692949533
Epoch:  361  	Training Loss: 0.0017608453053981066
Test Loss:  0.001706272247247398
Valid Loss:  0.0018816731171682477
Epoch:  362  	Training Loss: 0.0017608392518013716
Test Loss:  0.0017063685227185488
Valid Loss:  0.0018819364486262202
Epoch:  363  	Training Loss: 0.001760834245942533
Test Loss:  0.0017064535059034824
Valid Loss:  0.0018821912817656994
Epoch:  364  	Training Loss: 0.0017608266789466143
Test Loss:  0.0017065426800400019
Valid Loss:  0.0018824459984898567
Epoch:  365  	Training Loss: 0.0017608249327167869
Test Loss:  0.001706626615487039
Valid Loss:  0.0018826932646334171
Epoch:  366  	Training Loss: 0.0017608192283660173
Test Loss:  0.00170671078376472
Valid Loss:  0.0018829437904059887
Epoch:  367  	Training Loss: 0.0017608150374144316
Test Loss:  0.001706799492239952
Valid Loss:  0.0018831866327673197
Epoch:  368  	Training Loss: 0.0017608091002330184
Test Loss:  0.001706880982965231
Valid Loss:  0.001883425284177065
Epoch:  369  	Training Loss: 0.001760802697390318
Test Loss:  0.0017069554887712002
Valid Loss:  0.0018836593953892589
Epoch:  370  	Training Loss: 0.0017608010675758123
Test Loss:  0.0017070421017706394
Valid Loss:  0.0018838862888514996
Epoch:  371  	Training Loss: 0.0017607981571927667
Test Loss:  0.0017071175388991833
Valid Loss:  0.0018841121345758438
Epoch:  372  	Training Loss: 0.0017607933841645718
Test Loss:  0.0017071969341486692
Valid Loss:  0.0018843370489776134
Epoch:  373  	Training Loss: 0.0017607894260436296
Test Loss:  0.0017072734190151095
Valid Loss:  0.0018845524173229933
Epoch:  374  	Training Loss: 0.0017607841873541474
Test Loss:  0.001707343035377562
Valid Loss:  0.0018847673200070858
Epoch:  375  	Training Loss: 0.0017607812769711018
Test Loss:  0.0017074178904294968
Valid Loss:  0.001884983154013753
Epoch:  376  	Training Loss: 0.0017607775516808033
Test Loss:  0.001707488321699202
Valid Loss:  0.0018851904897019267
Epoch:  377  	Training Loss: 0.001760773709975183
Test Loss:  0.0017075706273317337
Valid Loss:  0.0018854013178497553
Epoch:  378  	Training Loss: 0.0017607694026082754
Test Loss:  0.0017076402436941862
Valid Loss:  0.0018855995731428266
Epoch:  379  	Training Loss: 0.0017607684712857008
Test Loss:  0.0017077077645808458
Valid Loss:  0.0018857948016375303
Epoch:  380  	Training Loss: 0.0017607650952413678
Test Loss:  0.0017077679513022304
Valid Loss:  0.0018859906122088432
Epoch:  381  	Training Loss: 0.0017607624176889658
Test Loss:  0.0017078414093703032
Valid Loss:  0.0018861861899495125
Epoch:  382  	Training Loss: 0.00176075822673738
Test Loss:  0.0017079084645956755
Valid Loss:  0.0018863738514482975
Epoch:  383  	Training Loss: 0.0017607572954148054
Test Loss:  0.0017079701647162437
Valid Loss:  0.0018865629099309444
Epoch:  384  	Training Loss: 0.0017607547342777252
Test Loss:  0.0017080324469134212
Valid Loss:  0.0018867461476475
Epoch:  385  	Training Loss: 0.001760750892572105
Test Loss:  0.0017081024125218391
Valid Loss:  0.00188692775554955
Epoch:  386  	Training Loss: 0.0017607486806809902
Test Loss:  0.0017081594560295343
Valid Loss:  0.0018870963249355555
Epoch:  387  	Training Loss: 0.0017607465852051973
Test Loss:  0.0017082156846299767
Valid Loss:  0.0018872716464102268
Epoch:  388  	Training Loss: 0.001760741462931037
Test Loss:  0.0017082786653190851
Valid Loss:  0.001887451158836484
Epoch:  389  	Training Loss: 0.0017607430927455425
Test Loss:  0.0017083403654396534
Valid Loss:  0.0018876148387789726
Epoch:  390  	Training Loss: 0.0017607356421649456
Test Loss:  0.0017084020655602217
Valid Loss:  0.0018877856200560927
Epoch:  391  	Training Loss: 0.0017607383197173476
Test Loss:  0.001708455034531653
Valid Loss:  0.0018879452254623175
Epoch:  392  	Training Loss: 0.001760734710842371
Test Loss:  0.0017085077706724405
Valid Loss:  0.0018881064606830478
Epoch:  393  	Training Loss: 0.001760734710842371
Test Loss:  0.0017085699364542961
Valid Loss:  0.001888270489871502
Epoch:  394  	Training Loss: 0.0017607314512133598
Test Loss:  0.0017086194129660726
Valid Loss:  0.001888421131297946
Epoch:  395  	Training Loss: 0.001760731334798038
Test Loss:  0.0017086730804294348
Valid Loss:  0.001888571190647781
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0017607256304472685
Test Loss:  0.0017087020678445697
Valid Loss:  0.001888652564957738
Epoch:  397  	Training Loss: 0.0017607260961085558
Test Loss:  0.0017087333835661411
Valid Loss:  0.0018887233454734087
Epoch:  398  	Training Loss: 0.0017607263289391994
Test Loss:  0.00170875433832407
Valid Loss:  0.001888797851279378
Epoch:  399  	Training Loss: 0.001760725281201303
Test Loss:  0.001708777155727148
Valid Loss:  0.001888875151053071
Epoch:  400  	Training Loss: 0.0017607235349714756
Test Loss:  0.0017088028835132718
Valid Loss:  0.0018889429047703743
Epoch:  401  	Training Loss: 0.0017607260961085558
Test Loss:  0.0017088301246985793
Valid Loss:  0.0018890155479311943
Epoch:  402  	Training Loss: 0.0017607227200642228
Test Loss:  0.0017088570166379213
Valid Loss:  0.0018890902865678072
Epoch:  403  	Training Loss: 0.0017607221379876137
Test Loss:  0.0017088851891458035
Valid Loss:  0.0018891619984060526
Epoch:  404  	Training Loss: 0.0017607207410037518
Test Loss:  0.0017089048633351922
Valid Loss:  0.0018892331281676888
Epoch:  405  	Training Loss: 0.0017607202753424644
Test Loss:  0.0017089317552745342
Valid Loss:  0.001889300299808383
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0017607177142053843
Test Loss:  0.0017089415341615677
Valid Loss:  0.0018893391825258732
Epoch:  407  	Training Loss: 0.0017607186455279589
Test Loss:  0.0017089591128751636
Valid Loss:  0.001889368868432939
Epoch:  408  	Training Loss: 0.0017607167828828096
Test Loss:  0.0017089641187340021
Valid Loss:  0.0018894055392593145
Epoch:  409  	Training Loss: 0.0017607180634513497
Test Loss:  0.0017089791363105178
Valid Loss:  0.001889436854980886
Epoch:  410  	Training Loss: 0.001760717248544097
Test Loss:  0.0017089920584112406
Valid Loss:  0.0018894734093919396
Epoch:  411  	Training Loss: 0.0017607164336368442
Test Loss:  0.0017090027686208487
Valid Loss:  0.0018895044922828674
Epoch:  412  	Training Loss: 0.0017607174813747406
Test Loss:  0.0017090169712901115
Valid Loss:  0.0018895408138632774
 83%|████████▎ | 413/500 [05:05<01:37,  1.13s/it] 83%|████████▎ | 415/500 [05:11<02:27,  1.74s/it] 83%|████████▎ | 417/500 [05:12<01:42,  1.24s/it] 84%|████████▍ | 419/500 [05:12<01:11,  1.13it/s] 84%|████████▍ | 421/500 [05:18<02:04,  1.57s/it] 85%|████████▍ | 423/500 [05:18<01:26,  1.12s/it] 85%|████████▌ | 425/500 [05:25<02:11,  1.75s/it] 85%|████████▌ | 427/500 [05:25<01:30,  1.25s/it] 86%|████████▌ | 429/500 [05:25<01:03,  1.12it/s] 86%|████████▌ | 431/500 [05:31<01:49,  1.59s/it] 87%|████████▋ | 433/500 [05:31<01:16,  1.14s/it] 87%|████████▋ | 435/500 [05:38<01:54,  1.76s/it] 87%|████████▋ | 437/500 [05:38<01:19,  1.26s/it] 88%|████████▊ | 439/500 [05:38<00:55,  1.10it/s] 88%|████████▊ | 440/500 [05:45<01:53,  1.89s/it] 88%|████████▊ | 441/500 [05:51<02:43,  2.78s/it] 89%|████████▊ | 443/500 [05:51<01:42,  1.79s/it] 89%|████████▉ | 445/500 [05:58<02:05,  2.28s/it] 89%|████████▉ | 447/500 [05:58<01:22,  1.56s/it] 90%|████████▉ | 449/500 [05:58<00:55,  1.09s/it] 90%|█████████ | 450/500 [06:04<01:43,  2.07s/it] 90%|█████████ | 451/500 [06:11<02:27,  3.00s/it] 91%|█████████ | 453/500 [06:11<01:29,  1.90s/it] 91%|█████████ | 455/500 [06:11<00:57,  1.27s/it] 91%|█████████▏| 457/500 [06:11<00:37,  1.15it/s] 92%|█████████▏| 459/500 [06:11<00:25,  1.64it/s] 92%|█████████▏| 461/500 [06:24<01:34,  2.43s/it] 93%|█████████▎| 463/500 [06:24<01:02,  1.70s/it] 93%|█████████▎| 465/500 [06:31<01:15,  2.17s/it] 93%|█████████▎| 467/500 [06:31<00:50,  1.53s/it] 94%|█████████▍| 469/500 [06:31<00:33,  1.08s/it] 94%|█████████▍| 471/500 [06:44<01:17,  2.68s/it]Epoch:  413  	Training Loss: 0.0017607150366529822
Test Loss:  0.0017090284964069724
Valid Loss:  0.0018895827233791351
Epoch:  414  	Training Loss: 0.0017607149202376604
Test Loss:  0.001709042233414948
Valid Loss:  0.001889609731733799
Epoch:  415  	Training Loss: 0.0017607142217457294
Test Loss:  0.0017090565524995327
Valid Loss:  0.0018896425608545542
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0017607149202376604
Test Loss:  0.00170905701816082
Valid Loss:  0.0018896590918302536
Epoch:  417  	Training Loss: 0.0017607139889150858
Test Loss:  0.0017090634210035205
Valid Loss:  0.0018896786496043205
Epoch:  418  	Training Loss: 0.0017607167828828096
Test Loss:  0.0017090693581849337
Valid Loss:  0.0018896914552897215
Epoch:  419  	Training Loss: 0.0017607164336368442
Test Loss:  0.0017090734327211976
Valid Loss:  0.0018897100817412138
Epoch:  420  	Training Loss: 0.0017607153858989477
Test Loss:  0.001709075877442956
Valid Loss:  0.0018897245172411203
Epoch:  421  	Training Loss: 0.0017607142217457294
Test Loss:  0.0017090808833017945
Valid Loss:  0.0018897423287853599
Epoch:  422  	Training Loss: 0.0017607156187295914
Test Loss:  0.001709086587652564
Valid Loss:  0.001889756415039301
Epoch:  423  	Training Loss: 0.001760713872499764
Test Loss:  0.0017090935725718737
Valid Loss:  0.0018897755071520805
Epoch:  424  	Training Loss: 0.0017607130575925112
Test Loss:  0.0017091005574911833
Valid Loss:  0.0018897883128374815
Epoch:  425  	Training Loss: 0.0017607116606086493
Test Loss:  0.001709106843918562
Valid Loss:  0.001889808103442192
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.001760714454576373
Test Loss:  0.001709113596007228
Valid Loss:  0.0018898136913776398
Epoch:  427  	Training Loss: 0.0017607130575925112
Test Loss:  0.001709112199023366
Valid Loss:  0.0018898234702646732
Epoch:  428  	Training Loss: 0.0017607135232537985
Test Loss:  0.001709113596007228
Valid Loss:  0.0018898298731073737
Epoch:  429  	Training Loss: 0.0017607129411771894
Test Loss:  0.001709122210741043
Valid Loss:  0.001889844425022602
Epoch:  430  	Training Loss: 0.0017607127083465457
Test Loss:  0.0017091191839426756
Valid Loss:  0.0018898474518209696
Epoch:  431  	Training Loss: 0.001760713174007833
Test Loss:  0.0017091241898015141
Valid Loss:  0.0018898553680628538
Epoch:  432  	Training Loss: 0.0017607156187295914
Test Loss:  0.0017091265181079507
Valid Loss:  0.001889863284304738
Epoch:  433  	Training Loss: 0.0017607139889150858
Test Loss:  0.001709133037365973
Valid Loss:  0.0018898699199780822
Epoch:  434  	Training Loss: 0.0017607146874070168
Test Loss:  0.0017091328045353293
Valid Loss:  0.0018898778362199664
Epoch:  435  	Training Loss: 0.0017607114277780056
Test Loss:  0.0017091352492570877
Valid Loss:  0.0018898861017078161
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0017607121262699366
Test Loss:  0.0017091346671804786
Valid Loss:  0.0018898998387157917
Epoch:  437  	Training Loss: 0.0017607110785320401
Test Loss:  0.0017091373447328806
Valid Loss:  0.0018898971611633897
Epoch:  438  	Training Loss: 0.001760711194947362
Test Loss:  0.0017091406043618917
Valid Loss:  0.0018899027490988374
Epoch:  439  	Training Loss: 0.0017607135232537985
Test Loss:  0.00170914176851511
Valid Loss:  0.001889906357973814
Epoch:  440  	Training Loss: 0.0017607142217457294
Test Loss:  0.0017091428162530065
Valid Loss:  0.0018899121787399054
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.001760712475515902
Test Loss:  0.0017091445624828339
Valid Loss:  0.001889911131002009
Epoch:  442  	Training Loss: 0.0017607135232537985
Test Loss:  0.0017091459594666958
Valid Loss:  0.0018899107817560434
Epoch:  443  	Training Loss: 0.001760712475515902
Test Loss:  0.001709145843051374
Valid Loss:  0.0018899121787399054
Epoch:  444  	Training Loss: 0.0017607128247618675
Test Loss:  0.0017091475892812014
Valid Loss:  0.001889919163659215
Epoch:  445  	Training Loss: 0.0017607137560844421
Test Loss:  0.0017091480549424887
Valid Loss:  0.0018899210263043642
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0017607141053304076
Test Loss:  0.0017091506160795689
Valid Loss:  0.0018899207934737206
Epoch:  447  	Training Loss: 0.0017607134068384767
Test Loss:  0.0017091506160795689
Valid Loss:  0.001889919745735824
Epoch:  448  	Training Loss: 0.0017607114277780056
Test Loss:  0.0017091527115553617
Valid Loss:  0.0018899227725341916
Epoch:  449  	Training Loss: 0.0017607129411771894
Test Loss:  0.001709149917587638
Valid Loss:  0.00188992521725595
Epoch:  450  	Training Loss: 0.0017607132904231548
Test Loss:  0.0017091450281441212
Valid Loss:  0.001889926614239812
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0017607143381610513
Test Loss:  0.0017091494519263506
Valid Loss:  0.0018899301066994667
Epoch:  452  	Training Loss: 0.0017607125919312239
Test Loss:  0.0017091496847569942
Valid Loss:  0.0018899268470704556
Epoch:  453  	Training Loss: 0.0017607130575925112
Test Loss:  0.0017091502668336034
Valid Loss:  0.001889923121780157
Epoch:  454  	Training Loss: 0.0017607109621167183
Test Loss:  0.0017091521294787526
Valid Loss:  0.0018899233546108007
Epoch:  455  	Training Loss: 0.0017607107292860746
Test Loss:  0.0017091501504182816
Valid Loss:  0.0018899282440543175
Epoch:  456  	Training Loss: 0.0017607135232537985
Test Loss:  0.0017091482877731323
Valid Loss:  0.0018899306887760758
Epoch:  457  	Training Loss: 0.0017607114277780056
Test Loss:  0.0017091459594666958
Valid Loss:  0.001889929291792214
Epoch:  458  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091494519263506
Valid Loss:  0.0018899310380220413
Epoch:  459  	Training Loss: 0.0017607121262699366
Test Loss:  0.0017091486370190978
Valid Loss:  0.0018899308051913977
Epoch:  460  	Training Loss: 0.0017607127083465457
Test Loss:  0.0017091486370190978
Valid Loss:  0.0018899323185905814
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0017607110785320401
Test Loss:  0.0017091486370190978
Valid Loss:  0.0018899310380220413
Epoch:  462  	Training Loss: 0.001760711194947362
Test Loss:  0.0017091475892812014
Valid Loss:  0.0018899310380220413
Epoch:  463  	Training Loss: 0.001760711893439293
Test Loss:  0.001709147123619914
Valid Loss:  0.0018899294082075357
Epoch:  464  	Training Loss: 0.0017607120098546147
Test Loss:  0.0017091491026803851
Valid Loss:  0.0018899306887760758
Epoch:  465  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899311544373631
Epoch:  467  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899311544373631
Epoch:  468  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  469  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  470  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091487534344196
Valid Loss:  0.0018899310380220413
Epoch:  472  	Training Loss: 0.001760711893439293
Test Loss:   95%|█████████▍| 473/500 [06:44<00:51,  1.89s/it] 95%|█████████▌| 475/500 [06:50<00:57,  2.28s/it] 95%|█████████▌| 477/500 [06:50<00:37,  1.62s/it] 96%|█████████▌| 479/500 [06:51<00:24,  1.16s/it] 96%|█████████▌| 481/500 [07:03<00:51,  2.71s/it] 97%|█████████▋| 483/500 [07:03<00:32,  1.92s/it] 97%|█████████▋| 485/500 [07:10<00:34,  2.28s/it] 97%|█████████▋| 487/500 [07:10<00:21,  1.62s/it] 98%|█████████▊| 489/500 [07:10<00:12,  1.15s/it] 98%|█████████▊| 491/500 [07:23<00:24,  2.73s/it] 99%|█████████▊| 493/500 [07:23<00:13,  1.93s/it] 99%|█████████▉| 495/500 [07:29<00:11,  2.30s/it] 99%|█████████▉| 497/500 [07:29<00:04,  1.63s/it]100%|█████████▉| 499/500 [07:29<00:01,  1.16s/it]100%|██████████| 500/500 [07:36<00:00,  1.10it/s]
0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  473  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091487534344196
Valid Loss:  0.0018899311544373631
Epoch:  474  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  475  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899310380220413
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  477  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091487534344196
Valid Loss:  0.0018899310380220413
Epoch:  478  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  479  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899311544373631
Epoch:  480  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899311544373631
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091487534344196
Valid Loss:  0.0018899310380220413
Epoch:  482  	Training Loss: 0.001760711777023971
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  483  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  484  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  485  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899310380220413
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.001760711777023971
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  487  	Training Loss: 0.001760711777023971
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899311544373631
Epoch:  488  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899311544373631
Epoch:  489  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  490  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899311544373631
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091487534344196
Valid Loss:  0.0018899310380220413
Epoch:  492  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  493  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  494  	Training Loss: 0.001760711777023971
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  495  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899311544373631
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899310380220413
Epoch:  497  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
Epoch:  498  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091487534344196
Valid Loss:  0.0018899310380220413
Epoch:  499  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091489862650633
Valid Loss:  0.0018899310380220413
Epoch:  500  	Training Loss: 0.001760711893439293
Test Loss:  0.0017091488698497415
Valid Loss:  0.0018899310380220413
**************************************************learning rate decay**************************************************
seed is  15
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:26,  6.31s/it]  1%|          | 3/500 [00:06<13:58,  1.69s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:44,  2.93it/s]  4%|▍         | 21/500 [00:20<09:52,  1.24s/it]  5%|▍         | 23/500 [00:20<07:00,  1.13it/s]  5%|▌         | 25/500 [00:20<05:01,  1.58it/s]  5%|▌         | 27/500 [00:20<03:38,  2.17it/s]  6%|▌         | 29/500 [00:20<02:40,  2.93it/s]  6%|▌         | 31/500 [00:27<09:22,  1.20s/it]  7%|▋         | 33/500 [00:27<06:42,  1.16it/s]  7%|▋         | 35/500 [00:27<04:49,  1.61it/s]  7%|▋         | 37/500 [00:27<03:30,  2.20it/s]  8%|▊         | 39/500 [00:27<02:35,  2.96it/s]  8%|▊         | 41/500 [00:34<09:25,  1.23s/it]  9%|▊         | 43/500 [00:34<06:44,  1.13it/s]  9%|▉         | 45/500 [00:34<04:52,  1.55it/s]  9%|▉         | 47/500 [00:34<03:35,  2.10it/s] 10%|▉         | 49/500 [00:35<02:42,  2.78it/s] 10%|█         | 51/500 [00:41<09:18,  1.24s/it] 11%|█         | 53/500 [00:41<06:38,  1.12it/s] 11%|█         | 55/500 [00:41<04:46,  1.55it/s] 11%|█▏        | 57/500 [00:42<03:28,  2.13it/s] 12%|█▏        | 59/500 [00:42<02:33,  2.87it/s] 12%|█▏        | 61/500 [00:48<08:47,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:16,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:48<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:49<02:25,  2.95it/s] 14%|█▍        | 71/500 [00:55<08:24,  1.18s/it]Epoch:  1  	Training Loss: 0.09472019225358963
Test Loss:  20.529434204101562
Valid Loss:  19.95977020263672
Epoch:  2  	Training Loss: 20.13135528564453
Test Loss:  0.07568642497062683
Valid Loss:  0.07170812040567398
Epoch:  3  	Training Loss: 0.05505192652344704
Test Loss:  0.07548850774765015
Valid Loss:  0.0715278759598732
Epoch:  4  	Training Loss: 0.05491223186254501
Test Loss:  0.07529130578041077
Valid Loss:  0.07134829461574554
Epoch:  5  	Training Loss: 0.05477311834692955
Test Loss:  0.07511380314826965
Valid Loss:  0.07120267301797867
Epoch:  6  	Training Loss: 0.05465209111571312
Test Loss:  0.0750303864479065
Valid Loss:  0.07115881145000458
Epoch:  7  	Training Loss: 0.05459802970290184
Test Loss:  0.07500147819519043
Valid Loss:  0.07114303857088089
Epoch:  8  	Training Loss: 0.05457357317209244
Test Loss:  0.07499238848686218
Valid Loss:  0.07113663852214813
Epoch:  9  	Training Loss: 0.054565783590078354
Test Loss:  0.07498819380998611
Valid Loss:  0.07113365828990936
Epoch:  10  	Training Loss: 0.05456266552209854
Test Loss:  0.07498586177825928
Valid Loss:  0.07113204896450043
Epoch:  11  	Training Loss: 0.05456118285655975
Test Loss:  0.07498420774936676
Valid Loss:  0.07113116979598999
Epoch:  12  	Training Loss: 0.05456038936972618
Test Loss:  0.07498340308666229
Valid Loss:  0.0711309164762497
Epoch:  13  	Training Loss: 0.05456005036830902
Test Loss:  0.07498286664485931
Valid Loss:  0.07113081216812134
Epoch:  14  	Training Loss: 0.05455987527966499
Test Loss:  0.07498261332511902
Valid Loss:  0.07113073766231537
Epoch:  15  	Training Loss: 0.05455978214740753
Test Loss:  0.0749824196100235
Valid Loss:  0.0711306780576706
Epoch:  16  	Training Loss: 0.054559722542762756
Test Loss:  0.07498232275247574
Valid Loss:  0.0711306482553482
Epoch:  17  	Training Loss: 0.05455968528985977
Test Loss:  0.07498222589492798
Valid Loss:  0.07113061845302582
Epoch:  18  	Training Loss: 0.05455964431166649
Test Loss:  0.07498214393854141
Valid Loss:  0.07113058865070343
Epoch:  19  	Training Loss: 0.054559603333473206
Test Loss:  0.07498206198215485
Valid Loss:  0.07113056629896164
Epoch:  20  	Training Loss: 0.05455956608057022
Test Loss:  0.07498198747634888
Valid Loss:  0.07113054394721985
Epoch:  21  	Training Loss: 0.054559532552957535
Test Loss:  0.07498189061880112
Valid Loss:  0.07113051414489746
Epoch:  22  	Training Loss: 0.05455949157476425
Test Loss:  0.07498182356357574
Valid Loss:  0.07113049179315567
Epoch:  23  	Training Loss: 0.05455945432186127
Test Loss:  0.07498177886009216
Valid Loss:  0.07113046944141388
Epoch:  24  	Training Loss: 0.05455942079424858
Test Loss:  0.07498174160718918
Valid Loss:  0.07113045454025269
Epoch:  25  	Training Loss: 0.05455939099192619
Test Loss:  0.07498171925544739
Valid Loss:  0.07113043963909149
Epoch:  26  	Training Loss: 0.054559364914894104
Test Loss:  0.0749817043542862
Valid Loss:  0.07113043963909149
Epoch:  27  	Training Loss: 0.054559335112571716
Test Loss:  0.0749816969037056
Valid Loss:  0.0711304247379303
Epoch:  28  	Training Loss: 0.05455930531024933
Test Loss:  0.0749816745519638
Valid Loss:  0.0711304098367691
Epoch:  29  	Training Loss: 0.05455928295850754
Test Loss:  0.0749816745519638
Valid Loss:  0.0711304098367691
Epoch:  30  	Training Loss: 0.05455924943089485
Test Loss:  0.0749816820025444
Valid Loss:  0.0711304098367691
Epoch:  31  	Training Loss: 0.05455922335386276
Test Loss:  0.0749816745519638
Valid Loss:  0.07113040238618851
Epoch:  32  	Training Loss: 0.054559193551540375
Test Loss:  0.074981689453125
Valid Loss:  0.07113039493560791
Epoch:  33  	Training Loss: 0.05455916374921799
Test Loss:  0.074981689453125
Valid Loss:  0.07113039493560791
Epoch:  34  	Training Loss: 0.054559141397476196
Test Loss:  0.074981689453125
Valid Loss:  0.07113039493560791
Epoch:  35  	Training Loss: 0.05455911159515381
Test Loss:  0.074981689453125
Valid Loss:  0.07113039493560791
Epoch:  36  	Training Loss: 0.05455908924341202
Test Loss:  0.0749817043542862
Valid Loss:  0.07113039493560791
Epoch:  37  	Training Loss: 0.05455905944108963
Test Loss:  0.0749817043542862
Valid Loss:  0.07113039493560791
Epoch:  38  	Training Loss: 0.05455903336405754
Test Loss:  0.07498171180486679
Valid Loss:  0.07113039493560791
Epoch:  39  	Training Loss: 0.05455900728702545
Test Loss:  0.07498171925544739
Valid Loss:  0.07113039493560791
Epoch:  40  	Training Loss: 0.054558977484703064
Test Loss:  0.07498171925544739
Valid Loss:  0.07113039493560791
Epoch:  41  	Training Loss: 0.054558951407670975
Test Loss:  0.07498171925544739
Valid Loss:  0.07113039493560791
Epoch:  42  	Training Loss: 0.054558925330638885
Test Loss:  0.07498171925544739
Valid Loss:  0.07113038748502731
Epoch:  43  	Training Loss: 0.054558899253606796
Test Loss:  0.07498171925544739
Valid Loss:  0.07113038003444672
Epoch:  44  	Training Loss: 0.05455887317657471
Test Loss:  0.07498172670602798
Valid Loss:  0.07113038003444672
Epoch:  45  	Training Loss: 0.05455884337425232
Test Loss:  0.07498173415660858
Valid Loss:  0.07113038003444672
Epoch:  46  	Training Loss: 0.05455882102251053
Test Loss:  0.07498173415660858
Valid Loss:  0.07113038003444672
Epoch:  47  	Training Loss: 0.05455879122018814
Test Loss:  0.07498173415660858
Valid Loss:  0.07113036513328552
Epoch:  48  	Training Loss: 0.05455876141786575
Test Loss:  0.07498173415660858
Valid Loss:  0.07113036513328552
Epoch:  49  	Training Loss: 0.054558731615543365
Test Loss:  0.07498173415660858
Valid Loss:  0.07113036513328552
Epoch:  50  	Training Loss: 0.054558705538511276
Test Loss:  0.07498174905776978
Valid Loss:  0.07113036513328552
Epoch:  51  	Training Loss: 0.05455867946147919
Test Loss:  0.07498174905776978
Valid Loss:  0.07113036513328552
Epoch:  52  	Training Loss: 0.0545586496591568
Test Loss:  0.07498174905776978
Valid Loss:  0.07113036513328552
Epoch:  53  	Training Loss: 0.05455861985683441
Test Loss:  0.07498174905776978
Valid Loss:  0.07113035023212433
Epoch:  54  	Training Loss: 0.05455859377980232
Test Loss:  0.07498174905776978
Valid Loss:  0.07113035023212433
Epoch:  55  	Training Loss: 0.05455856770277023
Test Loss:  0.07498174905776978
Valid Loss:  0.07113035023212433
Epoch:  56  	Training Loss: 0.054558537900447845
Test Loss:  0.07498174905776978
Valid Loss:  0.07113033533096313
Epoch:  57  	Training Loss: 0.054558511823415756
Test Loss:  0.07498174905776978
Valid Loss:  0.07113033533096313
Epoch:  58  	Training Loss: 0.05455848574638367
Test Loss:  0.07498175650835037
Valid Loss:  0.07113033533096313
Epoch:  59  	Training Loss: 0.05455845221877098
Test Loss:  0.07498176395893097
Valid Loss:  0.07113032788038254
Epoch:  60  	Training Loss: 0.05455842614173889
Test Loss:  0.07498176395893097
Valid Loss:  0.07113032788038254
Epoch:  61  	Training Loss: 0.054558396339416504
Test Loss:  0.07498176395893097
Valid Loss:  0.07113032042980194
Epoch:  62  	Training Loss: 0.054558370262384415
Test Loss:  0.07498174905776978
Valid Loss:  0.07113032042980194
Epoch:  63  	Training Loss: 0.05455834046006203
Test Loss:  0.07498176395893097
Valid Loss:  0.07113031297922134
Epoch:  64  	Training Loss: 0.05455831065773964
Test Loss:  0.07498174905776978
Valid Loss:  0.07113030552864075
Epoch:  65  	Training Loss: 0.05455828085541725
Test Loss:  0.07498174905776978
Valid Loss:  0.07113029062747955
Epoch:  66  	Training Loss: 0.054558247327804565
Test Loss:  0.07498174905776978
Valid Loss:  0.07113028317689896
Epoch:  67  	Training Loss: 0.05455821752548218
Test Loss:  0.07498174905776978
Valid Loss:  0.07113028317689896
Epoch:  68  	Training Loss: 0.05455818772315979
Test Loss:  0.07498174905776978
Valid Loss:  0.07113027572631836
Epoch:  69  	Training Loss: 0.0545581579208374
Test Loss:  0.07498174905776978
Valid Loss:  0.07113026827573776
Epoch:  70  	Training Loss: 0.054558128118515015
Test Loss:  0.07498174160718918
Valid Loss:  0.07113026827573776
Epoch:  71  	Training Loss: 0.05455809459090233
Test Loss:  0.07498174160718918
Valid Loss:  0.07113026082515717
Epoch:  72  	Training Loss: 0.05455806851387024
Test Loss:  0.07498174160718918
Valid Loss:  0.07113026082515717
Epoch:  73  	Training Loss: 0.05455803498625755
Test Loss:   15%|█▍        | 73/500 [00:55<06:03,  1.18it/s] 15%|█▌        | 75/500 [00:55<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:14,  2.17it/s] 16%|█▌        | 79/500 [00:56<02:24,  2.91it/s] 16%|█▌        | 81/500 [01:02<08:16,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:02<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:02<03:06,  2.22it/s] 18%|█▊        | 89/500 [01:02<02:17,  2.98it/s] 18%|█▊        | 91/500 [01:09<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:09<05:49,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:09<03:03,  2.20it/s] 20%|█▉        | 99/500 [01:09<02:15,  2.96it/s] 20%|██        | 101/500 [01:16<07:52,  1.18s/it] 21%|██        | 103/500 [01:16<05:37,  1.18it/s] 21%|██        | 105/500 [01:16<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:16<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:16<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:22<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:23<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:23<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:23<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:23<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:29<07:34,  1.20s/it] 25%|██▍       | 123/500 [01:30<05:24,  1.16it/s] 25%|██▌       | 125/500 [01:30<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:30<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:30<02:05,  2.97it/s] 26%|██▌       | 131/500 [01:36<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:36<05:12,  1.18it/s] 27%|██▋       | 135/500 [01:37<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:37<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:37<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:43<07:07,  1.19s/it] 29%|██▊       | 143/500 [01:43<05:06,  1.17it/s]0.07498173415660858
Valid Loss:  0.07113024592399597
Epoch:  74  	Training Loss: 0.054558005183935165
Test Loss:  0.07498173415660858
Valid Loss:  0.07113023102283478
Epoch:  75  	Training Loss: 0.05455797165632248
Test Loss:  0.07498174160718918
Valid Loss:  0.07113023102283478
Epoch:  76  	Training Loss: 0.05455794185400009
Test Loss:  0.07498173415660858
Valid Loss:  0.07113022357225418
Epoch:  77  	Training Loss: 0.054557912051677704
Test Loss:  0.07498173415660858
Valid Loss:  0.07113021612167358
Epoch:  78  	Training Loss: 0.054557882249355316
Test Loss:  0.07498172670602798
Valid Loss:  0.07113021612167358
Epoch:  79  	Training Loss: 0.05455785244703293
Test Loss:  0.07498171925544739
Valid Loss:  0.07113021612167358
Epoch:  80  	Training Loss: 0.05455782264471054
Test Loss:  0.07498174160718918
Valid Loss:  0.07113021612167358
Epoch:  81  	Training Loss: 0.05455779284238815
Test Loss:  0.07498173415660858
Valid Loss:  0.07113020867109299
Epoch:  82  	Training Loss: 0.054557763040065765
Test Loss:  0.07498173415660858
Valid Loss:  0.07113020122051239
Epoch:  83  	Training Loss: 0.05455772578716278
Test Loss:  0.07498172670602798
Valid Loss:  0.0711301863193512
Epoch:  84  	Training Loss: 0.05455769598484039
Test Loss:  0.07498171925544739
Valid Loss:  0.07113017141819
Epoch:  85  	Training Loss: 0.05455765873193741
Test Loss:  0.07498171180486679
Valid Loss:  0.07113017141819
Epoch:  86  	Training Loss: 0.05455762892961502
Test Loss:  0.07498171180486679
Valid Loss:  0.07113015651702881
Epoch:  87  	Training Loss: 0.05455759912729263
Test Loss:  0.0749817043542862
Valid Loss:  0.07113014161586761
Epoch:  88  	Training Loss: 0.05455756187438965
Test Loss:  0.0749816969037056
Valid Loss:  0.07113013416528702
Epoch:  89  	Training Loss: 0.05455753207206726
Test Loss:  0.074981689453125
Valid Loss:  0.07113012671470642
Epoch:  90  	Training Loss: 0.054557494819164276
Test Loss:  0.074981689453125
Valid Loss:  0.07113011926412582
Epoch:  91  	Training Loss: 0.05455746501684189
Test Loss:  0.0749816745519638
Valid Loss:  0.07113011181354523
Epoch:  92  	Training Loss: 0.0545574352145195
Test Loss:  0.074981689453125
Valid Loss:  0.07113011181354523
Epoch:  93  	Training Loss: 0.05455740913748741
Test Loss:  0.074981689453125
Valid Loss:  0.07113011181354523
Epoch:  94  	Training Loss: 0.05455738306045532
Test Loss:  0.0749817043542862
Valid Loss:  0.07113011181354523
Epoch:  95  	Training Loss: 0.05455736070871353
Test Loss:  0.0749817043542862
Valid Loss:  0.07113011181354523
Epoch:  96  	Training Loss: 0.05455733463168144
Test Loss:  0.07498172670602798
Valid Loss:  0.07113012671470642
Epoch:  97  	Training Loss: 0.05455731227993965
Test Loss:  0.07498174160718918
Valid Loss:  0.07113012671470642
Epoch:  98  	Training Loss: 0.05455728620290756
Test Loss:  0.07498174905776978
Valid Loss:  0.07113012671470642
Epoch:  99  	Training Loss: 0.05455726012587547
Test Loss:  0.07498174905776978
Valid Loss:  0.07113012671470642
Epoch:  100  	Training Loss: 0.05455723777413368
Test Loss:  0.07498175650835037
Valid Loss:  0.07113012671470642
Epoch:  101  	Training Loss: 0.05455721169710159
Test Loss:  0.07498176395893097
Valid Loss:  0.07113012671470642
Epoch:  102  	Training Loss: 0.0545571893453598
Test Loss:  0.07498177140951157
Valid Loss:  0.07113012671470642
Epoch:  103  	Training Loss: 0.05455716699361801
Test Loss:  0.07498177886009216
Valid Loss:  0.07113013416528702
Epoch:  104  	Training Loss: 0.05455714464187622
Test Loss:  0.07498178631067276
Valid Loss:  0.07113012671470642
Epoch:  105  	Training Loss: 0.05455711856484413
Test Loss:  0.07498179376125336
Valid Loss:  0.07113013416528702
Epoch:  106  	Training Loss: 0.05455709993839264
Test Loss:  0.07498180121183395
Valid Loss:  0.07113014161586761
Epoch:  107  	Training Loss: 0.05455707758665085
Test Loss:  0.07498180866241455
Valid Loss:  0.07113014906644821
Epoch:  108  	Training Loss: 0.05455704778432846
Test Loss:  0.07498181611299515
Valid Loss:  0.07113014161586761
Epoch:  109  	Training Loss: 0.05455702543258667
Test Loss:  0.07498182356357574
Valid Loss:  0.07113014906644821
Epoch:  110  	Training Loss: 0.05455700308084488
Test Loss:  0.07498185336589813
Valid Loss:  0.0711301639676094
Epoch:  111  	Training Loss: 0.05455698072910309
Test Loss:  0.07498186081647873
Valid Loss:  0.07113017141819
Epoch:  112  	Training Loss: 0.0545569583773613
Test Loss:  0.07498185336589813
Valid Loss:  0.07113015651702881
Epoch:  113  	Training Loss: 0.05455692484974861
Test Loss:  0.07498185336589813
Valid Loss:  0.07113014906644821
Epoch:  114  	Training Loss: 0.05455689877271652
Test Loss:  0.07498186081647873
Valid Loss:  0.07113014906644821
Epoch:  115  	Training Loss: 0.054556868970394135
Test Loss:  0.07498185336589813
Valid Loss:  0.07113014161586761
Epoch:  116  	Training Loss: 0.05455683916807175
Test Loss:  0.07498185336589813
Valid Loss:  0.07113012671470642
Epoch:  117  	Training Loss: 0.05455680936574936
Test Loss:  0.07498185336589813
Valid Loss:  0.07113012671470642
Epoch:  118  	Training Loss: 0.05455677956342697
Test Loss:  0.07498184591531754
Valid Loss:  0.07113012671470642
Epoch:  119  	Training Loss: 0.054556749761104584
Test Loss:  0.07498185336589813
Valid Loss:  0.07113011181354523
Epoch:  120  	Training Loss: 0.054556719958782196
Test Loss:  0.07498184591531754
Valid Loss:  0.07113011181354523
Epoch:  121  	Training Loss: 0.05455669015645981
Test Loss:  0.07498184591531754
Valid Loss:  0.07113010436296463
Epoch:  122  	Training Loss: 0.05455666035413742
Test Loss:  0.07498184591531754
Valid Loss:  0.07113011181354523
Epoch:  123  	Training Loss: 0.05455663055181503
Test Loss:  0.07498186826705933
Valid Loss:  0.07113011181354523
Epoch:  124  	Training Loss: 0.05455660820007324
Test Loss:  0.07498186826705933
Valid Loss:  0.07113010436296463
Epoch:  125  	Training Loss: 0.054556578397750854
Test Loss:  0.07498187571763992
Valid Loss:  0.07113010436296463
Epoch:  126  	Training Loss: 0.054556556046009064
Test Loss:  0.07498187571763992
Valid Loss:  0.07113011181354523
Epoch:  127  	Training Loss: 0.054556529968976974
Test Loss:  0.07498187571763992
Valid Loss:  0.07113010436296463
Epoch:  128  	Training Loss: 0.054556503891944885
Test Loss:  0.07498188316822052
Valid Loss:  0.07113010436296463
Epoch:  129  	Training Loss: 0.0545564740896225
Test Loss:  0.07498188316822052
Valid Loss:  0.07113009691238403
Epoch:  130  	Training Loss: 0.05455644801259041
Test Loss:  0.07498188316822052
Valid Loss:  0.07113008946180344
Epoch:  131  	Training Loss: 0.05455641821026802
Test Loss:  0.07498189061880112
Valid Loss:  0.07113009691238403
Epoch:  132  	Training Loss: 0.05455639213323593
Test Loss:  0.07498189806938171
Valid Loss:  0.07113008946180344
Epoch:  133  	Training Loss: 0.054556362330913544
Test Loss:  0.07498189061880112
Valid Loss:  0.07113008201122284
Epoch:  134  	Training Loss: 0.054556332528591156
Test Loss:  0.07498189061880112
Valid Loss:  0.07113007456064224
Epoch:  135  	Training Loss: 0.05455630645155907
Test Loss:  0.07498189806938171
Valid Loss:  0.07113008201122284
Epoch:  136  	Training Loss: 0.05455627292394638
Test Loss:  0.07498190551996231
Valid Loss:  0.07113007456064224
Epoch:  137  	Training Loss: 0.05455624684691429
Test Loss:  0.07498190551996231
Valid Loss:  0.07113006711006165
Epoch:  138  	Training Loss: 0.054556217044591904
Test Loss:  0.07498189806938171
Valid Loss:  0.07113005965948105
Epoch:  139  	Training Loss: 0.05455618351697922
Test Loss:  0.07498189806938171
Valid Loss:  0.07113005220890045
Epoch:  140  	Training Loss: 0.05455615371465683
Test Loss:  0.07498189806938171
Valid Loss:  0.07113004475831985
Epoch:  141  	Training Loss: 0.05455612391233444
Test Loss:  0.07498189061880112
Valid Loss:  0.07113003730773926
Epoch:  142  	Training Loss: 0.054556094110012054
Test Loss:  0.07498190551996231
Valid Loss:  0.07113005220890045
Epoch:  143  	Training Loss: 0.05455607920885086
Test Loss:  0.0749819278717041
Valid Loss:  0.07113005965948105
Epoch:  144  	Training Loss: 0.05455606058239937
Test Loss:  0.0749819353222847
Valid Loss:  0.07113006711006165
Epoch:  145  	Training Loss: 0.054556041955947876
Test Loss:  0.07498197257518768
 29%|██▉       | 145/500 [01:43<03:40,  1.61it/s] 29%|██▉       | 147/500 [01:44<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:44<01:58,  2.96it/s] 30%|███       | 151/500 [01:50<06:51,  1.18s/it] 31%|███       | 153/500 [01:50<04:54,  1.18it/s] 31%|███       | 155/500 [01:50<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:50<02:34,  2.23it/s] 32%|███▏      | 159/500 [01:51<01:53,  2.99it/s] 32%|███▏      | 161/500 [01:57<06:44,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:27,  1.62it/s] 33%|███▎      | 167/500 [01:57<02:30,  2.21it/s] 34%|███▍      | 169/500 [01:57<01:51,  2.98it/s] 34%|███▍      | 171/500 [02:04<06:29,  1.19s/it] 35%|███▍      | 173/500 [02:04<04:38,  1.18it/s] 35%|███▌      | 175/500 [02:04<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:04<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:04<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:11<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:11<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:11<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:11<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:18<06:09,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:23,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:18<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:18<01:41,  2.97it/s] 40%|████      | 201/500 [02:25<05:56,  1.19s/it] 41%|████      | 203/500 [02:25<04:15,  1.16it/s] 41%|████      | 205/500 [02:25<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:25<02:16,  2.15it/s] 42%|████▏     | 209/500 [02:25<01:42,  2.84it/s] 42%|████▏     | 211/500 [02:32<05:56,  1.23s/it] 43%|████▎     | 213/500 [02:32<04:13,  1.13it/s] 43%|████▎     | 215/500 [02:32<03:02,  1.56it/s]Valid Loss:  0.07113009691238403
Epoch:  146  	Training Loss: 0.05455602705478668
Test Loss:  0.07498198747634888
Valid Loss:  0.07113010436296463
Epoch:  147  	Training Loss: 0.05455600842833519
Test Loss:  0.07498200237751007
Valid Loss:  0.07113011181354523
Epoch:  148  	Training Loss: 0.0545559898018837
Test Loss:  0.07498201727867126
Valid Loss:  0.07113011926412582
Epoch:  149  	Training Loss: 0.054555974900722504
Test Loss:  0.07498203217983246
Valid Loss:  0.07113012671470642
Epoch:  150  	Training Loss: 0.05455595254898071
Test Loss:  0.07498204708099365
Valid Loss:  0.07113014161586761
Epoch:  151  	Training Loss: 0.05455593392252922
Test Loss:  0.07498206198215485
Valid Loss:  0.07113014906644821
Epoch:  152  	Training Loss: 0.05455591902136803
Test Loss:  0.07498206198215485
Valid Loss:  0.07113015651702881
Epoch:  153  	Training Loss: 0.05455588921904564
Test Loss:  0.07498206943273544
Valid Loss:  0.07113015651702881
Epoch:  154  	Training Loss: 0.05455587059259415
Test Loss:  0.07498206943273544
Valid Loss:  0.07113014906644821
Epoch:  155  	Training Loss: 0.05455584079027176
Test Loss:  0.07498207688331604
Valid Loss:  0.07113015651702881
Epoch:  156  	Training Loss: 0.05455581843852997
Test Loss:  0.07498209923505783
Valid Loss:  0.07113017141819
Epoch:  157  	Training Loss: 0.05455579236149788
Test Loss:  0.07498210668563843
Valid Loss:  0.0711301639676094
Epoch:  158  	Training Loss: 0.05455577000975609
Test Loss:  0.07498210668563843
Valid Loss:  0.0711301639676094
Epoch:  159  	Training Loss: 0.0545557402074337
Test Loss:  0.07498211413621902
Valid Loss:  0.07113017141819
Epoch:  160  	Training Loss: 0.05455571413040161
Test Loss:  0.07498211413621902
Valid Loss:  0.0711301639676094
Epoch:  161  	Training Loss: 0.05455569177865982
Test Loss:  0.07498212158679962
Valid Loss:  0.0711301639676094
Epoch:  162  	Training Loss: 0.05455566942691803
Test Loss:  0.07498212158679962
Valid Loss:  0.07113017141819
Epoch:  163  	Training Loss: 0.05455564334988594
Test Loss:  0.07498212903738022
Valid Loss:  0.0711301639676094
Epoch:  164  	Training Loss: 0.05455561354756355
Test Loss:  0.07498213648796082
Valid Loss:  0.0711301639676094
Epoch:  165  	Training Loss: 0.05455559119582176
Test Loss:  0.07498215138912201
Valid Loss:  0.07113015651702881
Epoch:  166  	Training Loss: 0.054555557668209076
Test Loss:  0.07498215138912201
Valid Loss:  0.07113015651702881
Epoch:  167  	Training Loss: 0.054555535316467285
Test Loss:  0.0749821588397026
Valid Loss:  0.07113015651702881
Epoch:  168  	Training Loss: 0.0545555055141449
Test Loss:  0.0749821588397026
Valid Loss:  0.0711301639676094
Epoch:  169  	Training Loss: 0.05455548316240311
Test Loss:  0.0749821662902832
Valid Loss:  0.07113015651702881
Epoch:  170  	Training Loss: 0.054555460810661316
Test Loss:  0.0749821662902832
Valid Loss:  0.0711301639676094
Epoch:  171  	Training Loss: 0.05455543473362923
Test Loss:  0.0749821662902832
Valid Loss:  0.07113015651702881
Epoch:  172  	Training Loss: 0.05455540493130684
Test Loss:  0.0749821662902832
Valid Loss:  0.07113015651702881
Epoch:  173  	Training Loss: 0.05455537885427475
Test Loss:  0.0749821662902832
Valid Loss:  0.07113014161586761
Epoch:  174  	Training Loss: 0.054555345326662064
Test Loss:  0.0749821811914444
Valid Loss:  0.07113015651702881
Epoch:  175  	Training Loss: 0.05455532297492027
Test Loss:  0.07498219609260559
Valid Loss:  0.07113014161586761
Epoch:  176  	Training Loss: 0.05455528944730759
Test Loss:  0.074982188642025
Valid Loss:  0.07113014161586761
Epoch:  177  	Training Loss: 0.0545552633702755
Test Loss:  0.0749821811914444
Valid Loss:  0.07113013416528702
Epoch:  178  	Training Loss: 0.05455522984266281
Test Loss:  0.0749821737408638
Valid Loss:  0.07113011926412582
Epoch:  179  	Training Loss: 0.054555200040340424
Test Loss:  0.0749821737408638
Valid Loss:  0.07113011926412582
Epoch:  180  	Training Loss: 0.054555170238018036
Test Loss:  0.0749821662902832
Valid Loss:  0.07113011181354523
Epoch:  181  	Training Loss: 0.05455514043569565
Test Loss:  0.0749821662902832
Valid Loss:  0.07113009691238403
Epoch:  182  	Training Loss: 0.05455511063337326
Test Loss:  0.0749821662902832
Valid Loss:  0.07113009691238403
Epoch:  183  	Training Loss: 0.05455508083105087
Test Loss:  0.0749821811914444
Valid Loss:  0.07113009691238403
Epoch:  184  	Training Loss: 0.054555051028728485
Test Loss:  0.0749821811914444
Valid Loss:  0.07113008946180344
Epoch:  185  	Training Loss: 0.0545550212264061
Test Loss:  0.0749821811914444
Valid Loss:  0.07113008201122284
Epoch:  186  	Training Loss: 0.05455499142408371
Test Loss:  0.0749821811914444
Valid Loss:  0.07113008201122284
Epoch:  187  	Training Loss: 0.05455496162176132
Test Loss:  0.0749821662902832
Valid Loss:  0.07113008201122284
Epoch:  188  	Training Loss: 0.054554931819438934
Test Loss:  0.0749821737408638
Valid Loss:  0.07113006711006165
Epoch:  189  	Training Loss: 0.05455490201711655
Test Loss:  0.0749821737408638
Valid Loss:  0.07113006711006165
Epoch:  190  	Training Loss: 0.05455487594008446
Test Loss:  0.0749821662902832
Valid Loss:  0.07113005965948105
Epoch:  191  	Training Loss: 0.05455484613776207
Test Loss:  0.074982188642025
Valid Loss:  0.07113005965948105
Epoch:  192  	Training Loss: 0.05455481633543968
Test Loss:  0.074982188642025
Valid Loss:  0.07113005220890045
Epoch:  193  	Training Loss: 0.054554786533117294
Test Loss:  0.0749821811914444
Valid Loss:  0.07113005220890045
Epoch:  194  	Training Loss: 0.05455475673079491
Test Loss:  0.0749821811914444
Valid Loss:  0.07113004475831985
Epoch:  195  	Training Loss: 0.05455473065376282
Test Loss:  0.0749821811914444
Valid Loss:  0.07113003730773926
Epoch:  196  	Training Loss: 0.05455470085144043
Test Loss:  0.0749821811914444
Valid Loss:  0.07113003730773926
Epoch:  197  	Training Loss: 0.05455467477440834
Test Loss:  0.0749821811914444
Valid Loss:  0.07113003730773926
Epoch:  198  	Training Loss: 0.05455464497208595
Test Loss:  0.0749821811914444
Valid Loss:  0.07113002240657806
Epoch:  199  	Training Loss: 0.054554618895053864
Test Loss:  0.07498220354318619
Valid Loss:  0.07113002985715866
Epoch:  200  	Training Loss: 0.054554589092731476
Test Loss:  0.07498219609260559
Valid Loss:  0.07113002240657806
Epoch:  201  	Training Loss: 0.05455455929040909
Test Loss:  0.07498219609260559
Valid Loss:  0.07113002240657806
Epoch:  202  	Training Loss: 0.0545545294880867
Test Loss:  0.07498221099376678
Valid Loss:  0.07113002240657806
Epoch:  203  	Training Loss: 0.05455450713634491
Test Loss:  0.07498221099376678
Valid Loss:  0.07113002240657806
Epoch:  204  	Training Loss: 0.05455448478460312
Test Loss:  0.07498221099376678
Valid Loss:  0.07113002240657806
Epoch:  205  	Training Loss: 0.05455445870757103
Test Loss:  0.07498222589492798
Valid Loss:  0.07113002240657806
Epoch:  206  	Training Loss: 0.05455443263053894
Test Loss:  0.07498222589492798
Valid Loss:  0.07113002240657806
Epoch:  207  	Training Loss: 0.05455440655350685
Test Loss:  0.07498224079608917
Valid Loss:  0.07113002240657806
Epoch:  208  	Training Loss: 0.05455438047647476
Test Loss:  0.07498224079608917
Valid Loss:  0.07113002240657806
Epoch:  209  	Training Loss: 0.05455435812473297
Test Loss:  0.07498224824666977
Valid Loss:  0.07113002240657806
Epoch:  210  	Training Loss: 0.054554328322410583
Test Loss:  0.07498224824666977
Valid Loss:  0.07113002240657806
Epoch:  211  	Training Loss: 0.05455430597066879
Test Loss:  0.07498225569725037
Valid Loss:  0.07113002240657806
Epoch:  212  	Training Loss: 0.054554276168346405
Test Loss:  0.07498225569725037
Valid Loss:  0.07113002240657806
Epoch:  213  	Training Loss: 0.05455425754189491
Test Loss:  0.07498225569725037
Valid Loss:  0.07113002240657806
Epoch:  214  	Training Loss: 0.054554227739572525
Test Loss:  0.07498225569725037
Valid Loss:  0.07113002240657806
Epoch:  215  	Training Loss: 0.054554201662540436
Test Loss:  0.07498227059841156
Valid Loss:  0.07113002240657806
Epoch:  216  	Training Loss: 0.05455417186021805
Test Loss:  0.07498227059841156
Valid Loss:  0.07113001495599747
Epoch:  217  	Training Loss: 0.05455414950847626
Test Loss:  0.07498227804899216
Valid Loss:   43%|████▎     | 217/500 [02:32<02:14,  2.11it/s] 44%|████▍     | 219/500 [02:32<01:40,  2.80it/s] 44%|████▍     | 221/500 [02:39<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:39<02:52,  1.59it/s] 45%|████▌     | 227/500 [02:39<02:06,  2.15it/s] 46%|████▌     | 229/500 [02:39<01:34,  2.88it/s] 46%|████▌     | 231/500 [02:46<05:24,  1.21s/it] 47%|████▋     | 233/500 [02:46<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:46<02:46,  1.59it/s] 47%|████▋     | 237/500 [02:46<02:00,  2.18it/s] 48%|████▊     | 239/500 [02:46<01:29,  2.93it/s] 48%|████▊     | 241/500 [02:53<05:15,  1.22s/it] 49%|████▊     | 243/500 [02:53<03:44,  1.15it/s] 49%|████▉     | 245/500 [02:53<02:40,  1.59it/s] 49%|████▉     | 247/500 [02:53<01:57,  2.16it/s] 50%|████▉     | 249/500 [02:53<01:26,  2.91it/s] 50%|█████     | 251/500 [03:00<04:59,  1.20s/it] 51%|█████     | 253/500 [03:00<03:33,  1.16it/s] 51%|█████     | 255/500 [03:00<02:32,  1.60it/s] 51%|█████▏    | 257/500 [03:00<01:51,  2.19it/s] 52%|█████▏    | 259/500 [03:00<01:21,  2.95it/s] 52%|█████▏    | 261/500 [03:07<04:42,  1.18s/it] 53%|█████▎    | 263/500 [03:07<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:07<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:07<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:07<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:14<04:41,  1.23s/it] 55%|█████▍    | 273/500 [03:14<03:20,  1.13it/s] 55%|█████▌    | 275/500 [03:14<02:23,  1.57it/s] 55%|█████▌    | 277/500 [03:14<01:44,  2.14it/s] 56%|█████▌    | 279/500 [03:14<01:16,  2.89it/s] 56%|█████▌    | 281/500 [03:21<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:21<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:21<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:21<01:36,  2.21it/s]0.07113000750541687
Epoch:  218  	Training Loss: 0.05455411970615387
Test Loss:  0.07498228549957275
Valid Loss:  0.07113000750541687
Epoch:  219  	Training Loss: 0.05455408990383148
Test Loss:  0.07498228549957275
Valid Loss:  0.07113000750541687
Epoch:  220  	Training Loss: 0.05455406755208969
Test Loss:  0.07498229295015335
Valid Loss:  0.07113000750541687
Epoch:  221  	Training Loss: 0.0545540377497673
Test Loss:  0.07498228549957275
Valid Loss:  0.07113000750541687
Epoch:  222  	Training Loss: 0.05455401539802551
Test Loss:  0.07498230785131454
Valid Loss:  0.07113000750541687
Epoch:  223  	Training Loss: 0.054553985595703125
Test Loss:  0.07498230785131454
Valid Loss:  0.07113000750541687
Epoch:  224  	Training Loss: 0.054553963243961334
Test Loss:  0.07498230785131454
Valid Loss:  0.07113000750541687
Epoch:  225  	Training Loss: 0.054553937166929245
Test Loss:  0.07498231530189514
Valid Loss:  0.07113000750541687
Epoch:  226  	Training Loss: 0.054553911089897156
Test Loss:  0.07498231530189514
Valid Loss:  0.07113000750541687
Epoch:  227  	Training Loss: 0.054553888738155365
Test Loss:  0.07498233020305634
Valid Loss:  0.07113000750541687
Epoch:  228  	Training Loss: 0.054553862661123276
Test Loss:  0.07498233020305634
Valid Loss:  0.07113000750541687
Epoch:  229  	Training Loss: 0.054553836584091187
Test Loss:  0.07498234510421753
Valid Loss:  0.07113000750541687
Epoch:  230  	Training Loss: 0.0545538067817688
Test Loss:  0.07498234510421753
Valid Loss:  0.07113000750541687
Epoch:  231  	Training Loss: 0.05455378070473671
Test Loss:  0.07498235255479813
Valid Loss:  0.07113000750541687
Epoch:  232  	Training Loss: 0.05455375462770462
Test Loss:  0.07498235255479813
Valid Loss:  0.07113000750541687
Epoch:  233  	Training Loss: 0.05455373227596283
Test Loss:  0.07498236000537872
Valid Loss:  0.07113001495599747
Epoch:  234  	Training Loss: 0.05455370992422104
Test Loss:  0.07498236745595932
Valid Loss:  0.07113000750541687
Epoch:  235  	Training Loss: 0.05455368757247925
Test Loss:  0.07498236000537872
Valid Loss:  0.07113000750541687
Epoch:  236  	Training Loss: 0.05455365777015686
Test Loss:  0.07498238980770111
Valid Loss:  0.07113002240657806
Epoch:  237  	Training Loss: 0.05455363914370537
Test Loss:  0.0749824047088623
Valid Loss:  0.07113002240657806
Epoch:  238  	Training Loss: 0.05455361679196358
Test Loss:  0.0749824047088623
Valid Loss:  0.07113002240657806
Epoch:  239  	Training Loss: 0.05455358698964119
Test Loss:  0.0749824121594429
Valid Loss:  0.07113002240657806
Epoch:  240  	Training Loss: 0.0545535646378994
Test Loss:  0.0749824196100235
Valid Loss:  0.07113002240657806
Epoch:  241  	Training Loss: 0.05455354228615761
Test Loss:  0.0749824196100235
Valid Loss:  0.07113002240657806
Epoch:  242  	Training Loss: 0.05455351620912552
Test Loss:  0.0749824270606041
Valid Loss:  0.07113002240657806
Epoch:  243  	Training Loss: 0.054553478956222534
Test Loss:  0.0749824270606041
Valid Loss:  0.07113000750541687
Epoch:  244  	Training Loss: 0.05455345660448074
Test Loss:  0.0749824270606041
Valid Loss:  0.07113000750541687
Epoch:  245  	Training Loss: 0.054553426802158356
Test Loss:  0.0749824270606041
Valid Loss:  0.07113000750541687
Epoch:  246  	Training Loss: 0.05455339699983597
Test Loss:  0.07498243451118469
Valid Loss:  0.07113000005483627
Epoch:  247  	Training Loss: 0.05455336719751358
Test Loss:  0.0749824196100235
Valid Loss:  0.07112999260425568
Epoch:  248  	Training Loss: 0.05455334112048149
Test Loss:  0.0749824196100235
Valid Loss:  0.07112997770309448
Epoch:  249  	Training Loss: 0.0545533150434494
Test Loss:  0.07498243451118469
Valid Loss:  0.07112997770309448
Epoch:  250  	Training Loss: 0.05455327779054642
Test Loss:  0.0749824196100235
Valid Loss:  0.07112997025251389
Epoch:  251  	Training Loss: 0.05455324798822403
Test Loss:  0.0749824270606041
Valid Loss:  0.07112996280193329
Epoch:  252  	Training Loss: 0.05455321818590164
Test Loss:  0.07498243451118469
Valid Loss:  0.07112997025251389
Epoch:  253  	Training Loss: 0.05455319955945015
Test Loss:  0.07498244941234589
Valid Loss:  0.07112997025251389
Epoch:  254  	Training Loss: 0.05455318093299866
Test Loss:  0.07498245686292648
Valid Loss:  0.07112997770309448
Epoch:  255  	Training Loss: 0.054553158581256866
Test Loss:  0.07498247921466827
Valid Loss:  0.07112999260425568
Epoch:  256  	Training Loss: 0.054553136229515076
Test Loss:  0.07498248666524887
Valid Loss:  0.07113000005483627
Epoch:  257  	Training Loss: 0.054553113877773285
Test Loss:  0.07498249411582947
Valid Loss:  0.07112999260425568
Epoch:  258  	Training Loss: 0.054553091526031494
Test Loss:  0.07498250901699066
Valid Loss:  0.07113000750541687
Epoch:  259  	Training Loss: 0.05455307289958
Test Loss:  0.07498252391815186
Valid Loss:  0.07113000750541687
Epoch:  260  	Training Loss: 0.05455305427312851
Test Loss:  0.07498252391815186
Valid Loss:  0.07113002240657806
Epoch:  261  	Training Loss: 0.05455303192138672
Test Loss:  0.07498254626989365
Valid Loss:  0.07113002240657806
Epoch:  262  	Training Loss: 0.05455300584435463
Test Loss:  0.07498255372047424
Valid Loss:  0.07113002240657806
Epoch:  263  	Training Loss: 0.05455297976732254
Test Loss:  0.07498255372047424
Valid Loss:  0.07113001495599747
Epoch:  264  	Training Loss: 0.05455295369029045
Test Loss:  0.07498256117105484
Valid Loss:  0.07113002240657806
Epoch:  265  	Training Loss: 0.05455293133854866
Test Loss:  0.07498255372047424
Valid Loss:  0.07113000005483627
Epoch:  266  	Training Loss: 0.054552897810935974
Test Loss:  0.07498255372047424
Valid Loss:  0.07113000750541687
Epoch:  267  	Training Loss: 0.05455287545919418
Test Loss:  0.07498256862163544
Valid Loss:  0.07113001495599747
Epoch:  268  	Training Loss: 0.054552845656871796
Test Loss:  0.07498257607221603
Valid Loss:  0.07113000750541687
Epoch:  269  	Training Loss: 0.054552823305130005
Test Loss:  0.07498257607221603
Valid Loss:  0.07113000750541687
Epoch:  270  	Training Loss: 0.05455279350280762
Test Loss:  0.07498256862163544
Valid Loss:  0.07113000750541687
Epoch:  271  	Training Loss: 0.054552771151065826
Test Loss:  0.07498258352279663
Valid Loss:  0.07112999260425568
Epoch:  272  	Training Loss: 0.05455274134874344
Test Loss:  0.07498256862163544
Valid Loss:  0.07112999260425568
Epoch:  273  	Training Loss: 0.05455271527171135
Test Loss:  0.07498259842395782
Valid Loss:  0.07113000005483627
Epoch:  274  	Training Loss: 0.05455268919467926
Test Loss:  0.07498259842395782
Valid Loss:  0.07113000005483627
Epoch:  275  	Training Loss: 0.05455265939235687
Test Loss:  0.07498259842395782
Valid Loss:  0.07112999260425568
Epoch:  276  	Training Loss: 0.05455263331532478
Test Loss:  0.07498258352279663
Valid Loss:  0.07112999260425568
Epoch:  277  	Training Loss: 0.054552607238292694
Test Loss:  0.07498259842395782
Valid Loss:  0.07112997770309448
Epoch:  278  	Training Loss: 0.054552577435970306
Test Loss:  0.07498258352279663
Valid Loss:  0.07112997770309448
Epoch:  279  	Training Loss: 0.05455254763364792
Test Loss:  0.07498261332511902
Valid Loss:  0.07112999260425568
Epoch:  280  	Training Loss: 0.05455252528190613
Test Loss:  0.07498261332511902
Valid Loss:  0.07112997770309448
Epoch:  281  	Training Loss: 0.05455249547958374
Test Loss:  0.07498259842395782
Valid Loss:  0.07112997770309448
Epoch:  282  	Training Loss: 0.05455246567726135
Test Loss:  0.07498260587453842
Valid Loss:  0.07112997770309448
Epoch:  283  	Training Loss: 0.05455244332551956
Test Loss:  0.07498261332511902
Valid Loss:  0.07112997770309448
Epoch:  284  	Training Loss: 0.054552413523197174
Test Loss:  0.07498261332511902
Valid Loss:  0.07112997025251389
Epoch:  285  	Training Loss: 0.05455239117145538
Test Loss:  0.07498262822628021
Valid Loss:  0.07112997770309448
Epoch:  286  	Training Loss: 0.05455236881971359
Test Loss:  0.07498263567686081
Valid Loss:  0.07112998515367508
Epoch:  287  	Training Loss: 0.054552339017391205
Test Loss:  0.0749826431274414
Valid Loss:  0.07112997770309448
Epoch:  288  	Training Loss: 0.054552316665649414
Test Loss:  0.0749826431274414
Valid Loss:  0.07112997770309448
Epoch:  289  	Training Loss: 0.054552290588617325
Test Loss:   58%|█████▊    | 289/500 [03:21<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:28<04:09,  1.19s/it] 59%|█████▊    | 293/500 [03:28<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:28<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:28<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:28<01:07,  2.97it/s] 60%|██████    | 301/500 [03:35<03:58,  1.20s/it] 61%|██████    | 303/500 [03:35<02:48,  1.17it/s] 61%|██████    | 305/500 [03:35<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:35<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:41<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:42<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:42<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:42<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:42<01:01,  2.95it/s] 64%|██████▍   | 321/500 [03:49<03:35,  1.21s/it] 65%|██████▍   | 323/500 [03:49<02:33,  1.16it/s] 65%|██████▌   | 325/500 [03:49<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:49<01:19,  2.18it/s] 66%|██████▌   | 329/500 [03:49<00:59,  2.89it/s] 66%|██████▌   | 331/500 [03:56<03:29,  1.24s/it] 67%|██████▋   | 333/500 [03:56<02:28,  1.12it/s] 67%|██████▋   | 335/500 [03:56<01:45,  1.56it/s] 67%|██████▋   | 337/500 [03:56<01:16,  2.13it/s] 68%|██████▊   | 339/500 [03:56<00:56,  2.86it/s] 68%|██████▊   | 341/500 [04:03<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:03<02:17,  1.14it/s] 69%|██████▉   | 345/500 [04:03<01:38,  1.58it/s] 69%|██████▉   | 347/500 [04:03<01:10,  2.16it/s] 70%|██████▉   | 349/500 [04:03<00:51,  2.91it/s] 70%|███████   | 351/500 [04:10<02:57,  1.19s/it] 71%|███████   | 353/500 [04:10<02:05,  1.17it/s] 71%|███████   | 355/500 [04:10<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:10<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:10<00:47,  2.96it/s]0.074982650578022
Valid Loss:  0.07112997770309448
Epoch:  290  	Training Loss: 0.054552264511585236
Test Loss:  0.0749826654791832
Valid Loss:  0.07112997770309448
Epoch:  291  	Training Loss: 0.054552238434553146
Test Loss:  0.0749826729297638
Valid Loss:  0.07112997770309448
Epoch:  292  	Training Loss: 0.054552216082811356
Test Loss:  0.0749826654791832
Valid Loss:  0.07112997025251389
Epoch:  293  	Training Loss: 0.05455218255519867
Test Loss:  0.0749826654791832
Valid Loss:  0.07112996280193329
Epoch:  294  	Training Loss: 0.05455215275287628
Test Loss:  0.0749826580286026
Valid Loss:  0.07112996280193329
Epoch:  295  	Training Loss: 0.054552122950553894
Test Loss:  0.074982650578022
Valid Loss:  0.07112996280193329
Epoch:  296  	Training Loss: 0.054552093148231506
Test Loss:  0.0749826654791832
Valid Loss:  0.07112995535135269
Epoch:  297  	Training Loss: 0.05455206334590912
Test Loss:  0.0749826654791832
Valid Loss:  0.0711299479007721
Epoch:  298  	Training Loss: 0.05455203354358673
Test Loss:  0.0749826580286026
Valid Loss:  0.0711299329996109
Epoch:  299  	Training Loss: 0.05455200374126434
Test Loss:  0.0749826580286026
Valid Loss:  0.0711299329996109
Epoch:  300  	Training Loss: 0.054551973938941956
Test Loss:  0.0749826580286026
Valid Loss:  0.0711299255490303
Epoch:  301  	Training Loss: 0.05455194413661957
Test Loss:  0.0749826729297638
Valid Loss:  0.0711299255490303
Epoch:  302  	Training Loss: 0.05455191433429718
Test Loss:  0.0749826580286026
Valid Loss:  0.07112991809844971
Epoch:  303  	Training Loss: 0.05455188453197479
Test Loss:  0.074982650578022
Valid Loss:  0.07112991809844971
Epoch:  304  	Training Loss: 0.054551854729652405
Test Loss:  0.0749826580286026
Valid Loss:  0.07112990319728851
Epoch:  305  	Training Loss: 0.05455182492733002
Test Loss:  0.0749826431274414
Valid Loss:  0.07112989574670792
Epoch:  306  	Training Loss: 0.05455179512500763
Test Loss:  0.07498263567686081
Valid Loss:  0.07112988084554672
Epoch:  307  	Training Loss: 0.05455176159739494
Test Loss:  0.074982650578022
Valid Loss:  0.07112987339496613
Epoch:  308  	Training Loss: 0.05455172806978226
Test Loss:  0.0749826431274414
Valid Loss:  0.07112987339496613
Epoch:  309  	Training Loss: 0.05455169826745987
Test Loss:  0.07498263567686081
Valid Loss:  0.07112985849380493
Epoch:  310  	Training Loss: 0.05455166846513748
Test Loss:  0.07498262822628021
Valid Loss:  0.07112985104322433
Epoch:  311  	Training Loss: 0.054551634937524796
Test Loss:  0.07498262822628021
Valid Loss:  0.07112984359264374
Epoch:  312  	Training Loss: 0.05455160513520241
Test Loss:  0.0749826580286026
Valid Loss:  0.07112985104322433
Epoch:  313  	Training Loss: 0.05455157905817032
Test Loss:  0.0749826580286026
Valid Loss:  0.07112985104322433
Epoch:  314  	Training Loss: 0.05455155670642853
Test Loss:  0.0749826580286026
Valid Loss:  0.07112985849380493
Epoch:  315  	Training Loss: 0.05455153062939644
Test Loss:  0.0749826580286026
Valid Loss:  0.07112984359264374
Epoch:  316  	Training Loss: 0.05455150455236435
Test Loss:  0.0749826580286026
Valid Loss:  0.07112984359264374
Epoch:  317  	Training Loss: 0.05455147847533226
Test Loss:  0.0749826729297638
Valid Loss:  0.07112985849380493
Epoch:  318  	Training Loss: 0.05455145239830017
Test Loss:  0.07498268038034439
Valid Loss:  0.07112985849380493
Epoch:  319  	Training Loss: 0.05455143004655838
Test Loss:  0.07498268783092499
Valid Loss:  0.07112985104322433
Epoch:  320  	Training Loss: 0.05455140396952629
Test Loss:  0.07498268783092499
Valid Loss:  0.07112984359264374
Epoch:  321  	Training Loss: 0.0545513778924942
Test Loss:  0.07498268783092499
Valid Loss:  0.07112984359264374
Epoch:  322  	Training Loss: 0.05455135181546211
Test Loss:  0.07498270273208618
Valid Loss:  0.07112985104322433
Epoch:  323  	Training Loss: 0.054551322013139725
Test Loss:  0.07498269528150558
Valid Loss:  0.07112984359264374
Epoch:  324  	Training Loss: 0.05455129221081734
Test Loss:  0.07498270273208618
Valid Loss:  0.07112982869148254
Epoch:  325  	Training Loss: 0.05455126613378525
Test Loss:  0.07498268783092499
Valid Loss:  0.07112982869148254
Epoch:  326  	Training Loss: 0.05455123260617256
Test Loss:  0.07498268783092499
Valid Loss:  0.07112982124090195
Epoch:  327  	Training Loss: 0.05455120652914047
Test Loss:  0.07498270273208618
Valid Loss:  0.07112982124090195
Epoch:  328  	Training Loss: 0.054551176726818085
Test Loss:  0.07498270273208618
Valid Loss:  0.07112981379032135
Epoch:  329  	Training Loss: 0.0545511469244957
Test Loss:  0.07498270273208618
Valid Loss:  0.07112980633974075
Epoch:  330  	Training Loss: 0.05455111712217331
Test Loss:  0.07498270273208618
Valid Loss:  0.07112979888916016
Epoch:  331  	Training Loss: 0.05455108731985092
Test Loss:  0.07498268783092499
Valid Loss:  0.07112978398799896
Epoch:  332  	Training Loss: 0.05455106124281883
Test Loss:  0.07498270273208618
Valid Loss:  0.07112979888916016
Epoch:  333  	Training Loss: 0.054551031440496445
Test Loss:  0.07498270273208618
Valid Loss:  0.07112979143857956
Epoch:  334  	Training Loss: 0.054551005363464355
Test Loss:  0.07498270273208618
Valid Loss:  0.07112978398799896
Epoch:  335  	Training Loss: 0.05455097556114197
Test Loss:  0.07498270273208618
Valid Loss:  0.07112978398799896
Epoch:  336  	Training Loss: 0.05455094575881958
Test Loss:  0.07498270273208618
Valid Loss:  0.07112977653741837
Epoch:  337  	Training Loss: 0.05455091968178749
Test Loss:  0.07498271763324738
Valid Loss:  0.07112978398799896
Epoch:  338  	Training Loss: 0.0545508936047554
Test Loss:  0.07498271763324738
Valid Loss:  0.07112976908683777
Epoch:  339  	Training Loss: 0.05455086752772331
Test Loss:  0.07498271763324738
Valid Loss:  0.07112976908683777
Epoch:  340  	Training Loss: 0.05455084145069122
Test Loss:  0.07498271763324738
Valid Loss:  0.07112976163625717
Epoch:  341  	Training Loss: 0.054550811648368835
Test Loss:  0.07498273253440857
Valid Loss:  0.07112976908683777
Epoch:  342  	Training Loss: 0.05455078184604645
Test Loss:  0.07498273253440857
Valid Loss:  0.07112976908683777
Epoch:  343  	Training Loss: 0.05455075949430466
Test Loss:  0.07498273253440857
Valid Loss:  0.07112976908683777
Epoch:  344  	Training Loss: 0.05455073341727257
Test Loss:  0.07498273998498917
Valid Loss:  0.07112976908683777
Epoch:  345  	Training Loss: 0.05455070734024048
Test Loss:  0.07498273998498917
Valid Loss:  0.07112976908683777
Epoch:  346  	Training Loss: 0.05455068498849869
Test Loss:  0.07498276233673096
Valid Loss:  0.07112976908683777
Epoch:  347  	Training Loss: 0.0545506589114666
Test Loss:  0.07498276233673096
Valid Loss:  0.07112976908683777
Epoch:  348  	Training Loss: 0.05455063283443451
Test Loss:  0.07498276233673096
Valid Loss:  0.07112976908683777
Epoch:  349  	Training Loss: 0.05455061048269272
Test Loss:  0.07498277723789215
Valid Loss:  0.07112976908683777
Epoch:  350  	Training Loss: 0.05455058440566063
Test Loss:  0.07498277723789215
Valid Loss:  0.07112976908683777
Epoch:  351  	Training Loss: 0.05455055832862854
Test Loss:  0.07498279213905334
Valid Loss:  0.07112976908683777
Epoch:  352  	Training Loss: 0.05455052852630615
Test Loss:  0.07498278468847275
Valid Loss:  0.07112976908683777
Epoch:  353  	Training Loss: 0.05455050617456436
Test Loss:  0.07498279213905334
Valid Loss:  0.07112976908683777
Epoch:  354  	Training Loss: 0.054550476372241974
Test Loss:  0.07498279213905334
Valid Loss:  0.07112976908683777
Epoch:  355  	Training Loss: 0.05455045402050018
Test Loss:  0.07498280704021454
Valid Loss:  0.07112976908683777
Epoch:  356  	Training Loss: 0.054550427943468094
Test Loss:  0.07498280704021454
Valid Loss:  0.07112976908683777
Epoch:  357  	Training Loss: 0.054550401866436005
Test Loss:  0.07498279958963394
Valid Loss:  0.07112976908683777
Epoch:  358  	Training Loss: 0.054550375789403915
Test Loss:  0.07498280704021454
Valid Loss:  0.07112976163625717
Epoch:  359  	Training Loss: 0.054550349712371826
Test Loss:  0.07498281449079514
Valid Loss:  0.07112975418567657
Epoch:  360  	Training Loss: 0.05455031991004944
Test Loss:  0.07498282939195633
Valid Loss:  0.07112976908683777
Epoch:  361  	Training Loss: 0.05455029755830765
Test Loss:   72%|███████▏  | 361/500 [04:17<02:47,  1.20s/it] 73%|███████▎  | 363/500 [04:17<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:17<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:17<01:01,  2.16it/s] 74%|███████▍  | 369/500 [04:17<00:45,  2.86it/s] 74%|███████▍  | 371/500 [04:24<02:40,  1.24s/it] 75%|███████▍  | 373/500 [04:24<01:53,  1.12it/s] 75%|███████▌  | 375/500 [04:24<01:20,  1.55it/s] 75%|███████▌  | 377/500 [04:24<00:58,  2.12it/s] 76%|███████▌  | 379/500 [04:25<00:42,  2.84it/s] 76%|███████▌  | 381/500 [04:31<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:31<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:31<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:31<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:31<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:38<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:38<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:38<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:38<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:38<00:34,  2.96it/s] 80%|████████  | 401/500 [04:45<01:57,  1.19s/it] 81%|████████  | 403/500 [04:45<01:23,  1.16it/s] 81%|████████  | 405/500 [04:45<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:45<00:43,  2.16it/s] 82%|████████▏ | 409/500 [04:45<00:31,  2.87it/s] 82%|████████▏ | 411/500 [04:52<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:52<01:15,  1.16it/s] 83%|████████▎ | 415/500 [04:52<00:53,  1.59it/s] 83%|████████▎ | 417/500 [04:52<00:38,  2.15it/s] 84%|████████▍ | 419/500 [04:52<00:28,  2.88it/s] 84%|████████▍ | 421/500 [04:59<01:34,  1.20s/it] 85%|████████▍ | 423/500 [04:59<01:06,  1.16it/s] 85%|████████▌ | 425/500 [04:59<00:46,  1.61it/s] 85%|████████▌ | 427/500 [04:59<00:33,  2.20it/s] 86%|████████▌ | 429/500 [04:59<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:06<01:26,  1.25s/it]0.07498282939195633
Valid Loss:  0.07112976163625717
Epoch:  362  	Training Loss: 0.05455026775598526
Test Loss:  0.07498283684253693
Valid Loss:  0.07112976163625717
Epoch:  363  	Training Loss: 0.05455024540424347
Test Loss:  0.07498283684253693
Valid Loss:  0.07112976908683777
Epoch:  364  	Training Loss: 0.05455021932721138
Test Loss:  0.07498285919427872
Valid Loss:  0.07112976908683777
Epoch:  365  	Training Loss: 0.05455020070075989
Test Loss:  0.07498286664485931
Valid Loss:  0.07112976908683777
Epoch:  366  	Training Loss: 0.0545501746237278
Test Loss:  0.07498286664485931
Valid Loss:  0.07112976908683777
Epoch:  367  	Training Loss: 0.05455014854669571
Test Loss:  0.07498287409543991
Valid Loss:  0.07112976908683777
Epoch:  368  	Training Loss: 0.05455012619495392
Test Loss:  0.07498287409543991
Valid Loss:  0.07112976908683777
Epoch:  369  	Training Loss: 0.05455010384321213
Test Loss:  0.0749828964471817
Valid Loss:  0.07112977653741837
Epoch:  370  	Training Loss: 0.05455007776618004
Test Loss:  0.0749829038977623
Valid Loss:  0.07112976908683777
Epoch:  371  	Training Loss: 0.05455005541443825
Test Loss:  0.0749829038977623
Valid Loss:  0.07112978398799896
Epoch:  372  	Training Loss: 0.05455002933740616
Test Loss:  0.0749829113483429
Valid Loss:  0.07112976908683777
Epoch:  373  	Training Loss: 0.05455000698566437
Test Loss:  0.07498292624950409
Valid Loss:  0.07112978398799896
Epoch:  374  	Training Loss: 0.05454998090863228
Test Loss:  0.07498291879892349
Valid Loss:  0.07112976908683777
Epoch:  375  	Training Loss: 0.05454994738101959
Test Loss:  0.0749829113483429
Valid Loss:  0.07112976163625717
Epoch:  376  	Training Loss: 0.0545499213039875
Test Loss:  0.0749829113483429
Valid Loss:  0.07112975418567657
Epoch:  377  	Training Loss: 0.05454988777637482
Test Loss:  0.0749829038977623
Valid Loss:  0.07112975418567657
Epoch:  378  	Training Loss: 0.054549865424633026
Test Loss:  0.07498292624950409
Valid Loss:  0.07112976163625717
Epoch:  379  	Training Loss: 0.05454983562231064
Test Loss:  0.07498291879892349
Valid Loss:  0.07112973928451538
Epoch:  380  	Training Loss: 0.05454980581998825
Test Loss:  0.07498291879892349
Valid Loss:  0.07112974673509598
Epoch:  381  	Training Loss: 0.05454977601766586
Test Loss:  0.07498291879892349
Valid Loss:  0.07112973928451538
Epoch:  382  	Training Loss: 0.054549746215343475
Test Loss:  0.07498293370008469
Valid Loss:  0.07112973928451538
Epoch:  383  	Training Loss: 0.054549723863601685
Test Loss:  0.07498294115066528
Valid Loss:  0.07112973928451538
Epoch:  384  	Training Loss: 0.054549701511859894
Test Loss:  0.07498294115066528
Valid Loss:  0.07112973928451538
Epoch:  385  	Training Loss: 0.054549671709537506
Test Loss:  0.07498294115066528
Valid Loss:  0.07112973928451538
Epoch:  386  	Training Loss: 0.054549649357795715
Test Loss:  0.07498295605182648
Valid Loss:  0.07112974673509598
Epoch:  387  	Training Loss: 0.054549623280763626
Test Loss:  0.07498295605182648
Valid Loss:  0.07112973928451538
Epoch:  388  	Training Loss: 0.05454959720373154
Test Loss:  0.07498295605182648
Valid Loss:  0.07112973928451538
Epoch:  389  	Training Loss: 0.05454957112669945
Test Loss:  0.07498295605182648
Valid Loss:  0.07112973928451538
Epoch:  390  	Training Loss: 0.05454954504966736
Test Loss:  0.07498297840356827
Valid Loss:  0.07112974673509598
Epoch:  391  	Training Loss: 0.05454951897263527
Test Loss:  0.07498298585414886
Valid Loss:  0.07112973928451538
Epoch:  392  	Training Loss: 0.05454949289560318
Test Loss:  0.07498297840356827
Valid Loss:  0.07112973183393478
Epoch:  393  	Training Loss: 0.05454946681857109
Test Loss:  0.07498297095298767
Valid Loss:  0.07112973183393478
Epoch:  394  	Training Loss: 0.0545494370162487
Test Loss:  0.07498298585414886
Valid Loss:  0.07112973928451538
Epoch:  395  	Training Loss: 0.05454941466450691
Test Loss:  0.07498298585414886
Valid Loss:  0.07112972438335419
Epoch:  396  	Training Loss: 0.054549384862184525
Test Loss:  0.07498298585414886
Valid Loss:  0.07112972438335419
Epoch:  397  	Training Loss: 0.054549358785152435
Test Loss:  0.07498298585414886
Valid Loss:  0.07112972438335419
Epoch:  398  	Training Loss: 0.05454932898283005
Test Loss:  0.07498298585414886
Valid Loss:  0.07112971693277359
Epoch:  399  	Training Loss: 0.05454929918050766
Test Loss:  0.07498299330472946
Valid Loss:  0.07112972438335419
Epoch:  400  	Training Loss: 0.05454927310347557
Test Loss:  0.07498300075531006
Valid Loss:  0.07112971693277359
Epoch:  401  	Training Loss: 0.05454924330115318
Test Loss:  0.07498298585414886
Valid Loss:  0.071129709482193
Epoch:  402  	Training Loss: 0.054549217224121094
Test Loss:  0.07498298585414886
Valid Loss:  0.071129709482193
Epoch:  403  	Training Loss: 0.054549187421798706
Test Loss:  0.07498301565647125
Valid Loss:  0.071129709482193
Epoch:  404  	Training Loss: 0.054549165070056915
Test Loss:  0.07498301565647125
Valid Loss:  0.071129709482193
Epoch:  405  	Training Loss: 0.054549138993024826
Test Loss:  0.07498301565647125
Valid Loss:  0.071129709482193
Epoch:  406  	Training Loss: 0.05454911291599274
Test Loss:  0.07498301565647125
Valid Loss:  0.071129709482193
Epoch:  407  	Training Loss: 0.054549090564250946
Test Loss:  0.07498303055763245
Valid Loss:  0.071129709482193
Epoch:  408  	Training Loss: 0.05454906448721886
Test Loss:  0.07498303055763245
Valid Loss:  0.071129709482193
Epoch:  409  	Training Loss: 0.05454903841018677
Test Loss:  0.07498303055763245
Valid Loss:  0.071129709482193
Epoch:  410  	Training Loss: 0.05454900860786438
Test Loss:  0.07498303055763245
Valid Loss:  0.0711297020316124
Epoch:  411  	Training Loss: 0.05454898253083229
Test Loss:  0.07498305290937424
Valid Loss:  0.071129709482193
Epoch:  412  	Training Loss: 0.0545489601790905
Test Loss:  0.07498305290937424
Valid Loss:  0.071129709482193
Epoch:  413  	Training Loss: 0.05454893410205841
Test Loss:  0.07498305290937424
Valid Loss:  0.071129709482193
Epoch:  414  	Training Loss: 0.05454890802502632
Test Loss:  0.07498305290937424
Valid Loss:  0.0711297020316124
Epoch:  415  	Training Loss: 0.05454888194799423
Test Loss:  0.07498307526111603
Valid Loss:  0.071129709482193
Epoch:  416  	Training Loss: 0.05454885959625244
Test Loss:  0.07498307526111603
Valid Loss:  0.0711297020316124
Epoch:  417  	Training Loss: 0.05454883351922035
Test Loss:  0.07498307526111603
Valid Loss:  0.0711296945810318
Epoch:  418  	Training Loss: 0.05454880744218826
Test Loss:  0.07498307526111603
Valid Loss:  0.0711296945810318
Epoch:  419  	Training Loss: 0.054548781365156174
Test Loss:  0.07498309016227722
Valid Loss:  0.0711297020316124
Epoch:  420  	Training Loss: 0.054548755288124084
Test Loss:  0.07498309016227722
Valid Loss:  0.0711297020316124
Epoch:  421  	Training Loss: 0.054548729211091995
Test Loss:  0.07498309016227722
Valid Loss:  0.0711296945810318
Epoch:  422  	Training Loss: 0.054548703134059906
Test Loss:  0.07498310506343842
Valid Loss:  0.0711296945810318
Epoch:  423  	Training Loss: 0.05454867333173752
Test Loss:  0.07498309761285782
Valid Loss:  0.0711296871304512
Epoch:  424  	Training Loss: 0.05454864725470543
Test Loss:  0.07498309761285782
Valid Loss:  0.0711296796798706
Epoch:  425  	Training Loss: 0.05454861372709274
Test Loss:  0.07498308271169662
Valid Loss:  0.07112966477870941
Epoch:  426  	Training Loss: 0.054548583924770355
Test Loss:  0.07498310506343842
Valid Loss:  0.07112967222929001
Epoch:  427  	Training Loss: 0.05454855412244797
Test Loss:  0.07498309761285782
Valid Loss:  0.07112966477870941
Epoch:  428  	Training Loss: 0.05454852432012558
Test Loss:  0.07498309016227722
Valid Loss:  0.07112964987754822
Epoch:  429  	Training Loss: 0.05454849451780319
Test Loss:  0.07498309016227722
Valid Loss:  0.07112964987754822
Epoch:  430  	Training Loss: 0.054548464715480804
Test Loss:  0.07498310506343842
Valid Loss:  0.07112964987754822
Epoch:  431  	Training Loss: 0.05454843491315842
Test Loss:  0.07498309761285782
Valid Loss:  0.07112963497638702
Epoch:  432  	Training Loss: 0.05454840511083603
Test Loss:  0.07498309016227722
Valid Loss:  0.07112962007522583
Epoch:  433  	Training Loss: 0.05454837530851364
Test Loss:   87%|████████▋ | 433/500 [05:06<01:00,  1.10it/s] 87%|████████▋ | 435/500 [05:06<00:42,  1.52it/s] 87%|████████▋ | 437/500 [05:06<00:30,  2.07it/s] 88%|████████▊ | 439/500 [05:07<00:21,  2.80it/s] 88%|████████▊ | 441/500 [05:13<01:14,  1.26s/it] 89%|████████▊ | 443/500 [05:13<00:51,  1.10it/s] 89%|████████▉ | 445/500 [05:14<00:35,  1.53it/s] 89%|████████▉ | 447/500 [05:14<00:25,  2.10it/s] 90%|████████▉ | 449/500 [05:14<00:18,  2.83it/s] 90%|█████████ | 451/500 [05:20<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:20<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:21<00:28,  1.57it/s] 91%|█████████▏| 457/500 [05:21<00:20,  2.12it/s] 92%|█████████▏| 459/500 [05:21<00:14,  2.81it/s] 92%|█████████▏| 461/500 [05:28<00:48,  1.25s/it] 93%|█████████▎| 463/500 [05:28<00:33,  1.11it/s] 93%|█████████▎| 465/500 [05:28<00:22,  1.54it/s] 93%|█████████▎| 467/500 [05:28<00:15,  2.09it/s] 94%|█████████▍| 469/500 [05:28<00:11,  2.78it/s] 94%|█████████▍| 471/500 [05:35<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:35<00:23,  1.14it/s] 95%|█████████▌| 475/500 [05:35<00:15,  1.56it/s] 95%|█████████▌| 477/500 [05:35<00:10,  2.12it/s] 96%|█████████▌| 479/500 [05:35<00:07,  2.86it/s] 96%|█████████▌| 481/500 [05:42<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:42<00:14,  1.14it/s] 97%|█████████▋| 485/500 [05:42<00:09,  1.58it/s] 97%|█████████▋| 487/500 [05:42<00:06,  2.16it/s] 98%|█████████▊| 489/500 [05:42<00:03,  2.91it/s] 98%|█████████▊| 491/500 [05:49<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:49<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:49<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:49<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:49<00:00,  3.00it/s]100%|██████████| 500/500 [05:49<00:00,  1.43it/s]
0.07498307526111603
Valid Loss:  0.07112962007522583
Epoch:  434  	Training Loss: 0.054548345506191254
Test Loss:  0.07498309016227722
Valid Loss:  0.07112962752580643
Epoch:  435  	Training Loss: 0.054548315703868866
Test Loss:  0.07498309016227722
Valid Loss:  0.07112961262464523
Epoch:  436  	Training Loss: 0.05454828590154648
Test Loss:  0.07498308271169662
Valid Loss:  0.07112960517406464
Epoch:  437  	Training Loss: 0.05454825609922409
Test Loss:  0.07498307526111603
Valid Loss:  0.07112959772348404
Epoch:  438  	Training Loss: 0.0545482262969017
Test Loss:  0.07498309761285782
Valid Loss:  0.07112960517406464
Epoch:  439  	Training Loss: 0.054548196494579315
Test Loss:  0.07498309016227722
Valid Loss:  0.07112959027290344
Epoch:  440  	Training Loss: 0.05454816669225693
Test Loss:  0.07498307526111603
Valid Loss:  0.07112959027290344
Epoch:  441  	Training Loss: 0.05454814061522484
Test Loss:  0.07498309761285782
Valid Loss:  0.07112959027290344
Epoch:  442  	Training Loss: 0.05454811081290245
Test Loss:  0.07498309761285782
Valid Loss:  0.07112957537174225
Epoch:  443  	Training Loss: 0.05454808473587036
Test Loss:  0.07498309761285782
Valid Loss:  0.07112957537174225
Epoch:  444  	Training Loss: 0.054548054933547974
Test Loss:  0.07498310506343842
Valid Loss:  0.07112957537174225
Epoch:  445  	Training Loss: 0.05454803258180618
Test Loss:  0.07498310506343842
Valid Loss:  0.07112957537174225
Epoch:  446  	Training Loss: 0.054548002779483795
Test Loss:  0.07498311251401901
Valid Loss:  0.07112957537174225
Epoch:  447  	Training Loss: 0.05454797297716141
Test Loss:  0.07498310506343842
Valid Loss:  0.07112956047058105
Epoch:  448  	Training Loss: 0.05454795062541962
Test Loss:  0.07498310506343842
Valid Loss:  0.07112956047058105
Epoch:  449  	Training Loss: 0.05454792454838753
Test Loss:  0.0749831274151802
Valid Loss:  0.07112956792116165
Epoch:  450  	Training Loss: 0.05454789847135544
Test Loss:  0.07498311996459961
Valid Loss:  0.07112956047058105
Epoch:  451  	Training Loss: 0.05454787239432335
Test Loss:  0.07498311996459961
Valid Loss:  0.07112956047058105
Epoch:  452  	Training Loss: 0.05454784259200096
Test Loss:  0.0749831348657608
Valid Loss:  0.07112956047058105
Epoch:  453  	Training Loss: 0.05454781651496887
Test Loss:  0.0749831274151802
Valid Loss:  0.07112954556941986
Epoch:  454  	Training Loss: 0.05454777926206589
Test Loss:  0.07498311996459961
Valid Loss:  0.07112953811883926
Epoch:  455  	Training Loss: 0.0545477531850338
Test Loss:  0.07498311996459961
Valid Loss:  0.07112953811883926
Epoch:  456  	Training Loss: 0.05454772338271141
Test Loss:  0.07498311996459961
Valid Loss:  0.07112952321767807
Epoch:  457  	Training Loss: 0.054547689855098724
Test Loss:  0.07498311996459961
Valid Loss:  0.07112952321767807
Epoch:  458  	Training Loss: 0.05454766005277634
Test Loss:  0.07498310506343842
Valid Loss:  0.07112951576709747
Epoch:  459  	Training Loss: 0.05454763025045395
Test Loss:  0.07498310506343842
Valid Loss:  0.07112950086593628
Epoch:  460  	Training Loss: 0.05454760044813156
Test Loss:  0.07498311251401901
Valid Loss:  0.07112950086593628
Epoch:  461  	Training Loss: 0.054547570645809174
Test Loss:  0.07498310506343842
Valid Loss:  0.07112949341535568
Epoch:  462  	Training Loss: 0.054547540843486786
Test Loss:  0.07498310506343842
Valid Loss:  0.07112948596477509
Epoch:  463  	Training Loss: 0.0545475110411644
Test Loss:  0.07498311996459961
Valid Loss:  0.07112949341535568
Epoch:  464  	Training Loss: 0.05454748868942261
Test Loss:  0.0749831274151802
Valid Loss:  0.07112949341535568
Epoch:  465  	Training Loss: 0.05454746261239052
Test Loss:  0.07498311996459961
Valid Loss:  0.07112948596477509
Epoch:  466  	Training Loss: 0.05454743653535843
Test Loss:  0.07498311996459961
Valid Loss:  0.07112948596477509
Epoch:  467  	Training Loss: 0.05454740673303604
Test Loss:  0.0749831348657608
Valid Loss:  0.07112948596477509
Epoch:  468  	Training Loss: 0.05454738438129425
Test Loss:  0.0749831348657608
Valid Loss:  0.07112948596477509
Epoch:  469  	Training Loss: 0.05454735457897186
Test Loss:  0.0749831348657608
Valid Loss:  0.07112947851419449
Epoch:  470  	Training Loss: 0.054547324776649475
Test Loss:  0.074983149766922
Valid Loss:  0.07112947851419449
Epoch:  471  	Training Loss: 0.054547302424907684
Test Loss:  0.074983149766922
Valid Loss:  0.07112947106361389
Epoch:  472  	Training Loss: 0.0545472726225853
Test Loss:  0.0749831423163414
Valid Loss:  0.07112947851419449
Epoch:  473  	Training Loss: 0.05454724654555321
Test Loss:  0.0749831423163414
Valid Loss:  0.07112947106361389
Epoch:  474  	Training Loss: 0.05454722046852112
Test Loss:  0.074983149766922
Valid Loss:  0.07112947106361389
Epoch:  475  	Training Loss: 0.05454719066619873
Test Loss:  0.074983149766922
Valid Loss:  0.0711294636130333
Epoch:  476  	Training Loss: 0.05454716458916664
Test Loss:  0.074983149766922
Valid Loss:  0.0711294636130333
Epoch:  477  	Training Loss: 0.05454713851213455
Test Loss:  0.07498316466808319
Valid Loss:  0.07112947106361389
Epoch:  478  	Training Loss: 0.054547108709812164
Test Loss:  0.0749831572175026
Valid Loss:  0.07112947106361389
Epoch:  479  	Training Loss: 0.054547082632780075
Test Loss:  0.0749831572175026
Valid Loss:  0.0711294636130333
Epoch:  480  	Training Loss: 0.054547056555747986
Test Loss:  0.074983149766922
Valid Loss:  0.0711294561624527
Epoch:  481  	Training Loss: 0.054547034204006195
Test Loss:  0.07498317211866379
Valid Loss:  0.0711294561624527
Epoch:  482  	Training Loss: 0.05454700067639351
Test Loss:  0.07498316466808319
Valid Loss:  0.0711294487118721
Epoch:  483  	Training Loss: 0.05454697087407112
Test Loss:  0.07498316466808319
Valid Loss:  0.0711294412612915
Epoch:  484  	Training Loss: 0.05454694479703903
Test Loss:  0.07498317956924438
Valid Loss:  0.0711294487118721
Epoch:  485  	Training Loss: 0.054546914994716644
Test Loss:  0.07498316466808319
Valid Loss:  0.0711294412612915
Epoch:  486  	Training Loss: 0.054546888917684555
Test Loss:  0.07498316466808319
Valid Loss:  0.07112943381071091
Epoch:  487  	Training Loss: 0.05454685911536217
Test Loss:  0.07498317956924438
Valid Loss:  0.07112942636013031
Epoch:  488  	Training Loss: 0.05454682558774948
Test Loss:  0.07498317211866379
Valid Loss:  0.07112942636013031
Epoch:  489  	Training Loss: 0.054546795785427094
Test Loss:  0.07498316466808319
Valid Loss:  0.07112941890954971
Epoch:  490  	Training Loss: 0.054546769708395004
Test Loss:  0.07498316466808319
Valid Loss:  0.07112941145896912
Epoch:  491  	Training Loss: 0.05454673990607262
Test Loss:  0.07498317211866379
Valid Loss:  0.07112941145896912
Epoch:  492  	Training Loss: 0.05454671382904053
Test Loss:  0.07498316466808319
Valid Loss:  0.07112939655780792
Epoch:  493  	Training Loss: 0.05454668402671814
Test Loss:  0.07498316466808319
Valid Loss:  0.07112939655780792
Epoch:  494  	Training Loss: 0.05454665422439575
Test Loss:  0.07498317956924438
Valid Loss:  0.07112939655780792
Epoch:  495  	Training Loss: 0.054546624422073364
Test Loss:  0.07498316466808319
Valid Loss:  0.07112938910722733
Epoch:  496  	Training Loss: 0.054546598345041275
Test Loss:  0.07498316466808319
Valid Loss:  0.07112938165664673
Epoch:  497  	Training Loss: 0.05454656481742859
Test Loss:  0.07498317956924438
Valid Loss:  0.07112938165664673
Epoch:  498  	Training Loss: 0.0545465350151062
Test Loss:  0.07498317956924438
Valid Loss:  0.07112938165664673
Epoch:  499  	Training Loss: 0.05454650893807411
Test Loss:  0.07498316466808319
Valid Loss:  0.07112936675548553
Epoch:  500  	Training Loss: 0.054546479135751724
Test Loss:  0.0749831572175026
Valid Loss:  0.07112935930490494
seed is  16
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:58,  6.49s/it]  1%|          | 3/500 [00:06<14:27,  1.74s/it]  1%|          | 5/500 [00:06<07:17,  1.13it/s]  1%|▏         | 7/500 [00:06<04:24,  1.86it/s]  2%|▏         | 9/500 [00:07<02:55,  2.79it/s]  2%|▏         | 11/500 [00:13<11:04,  1.36s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:20<13:26,  1.66s/it]  3%|▎         | 17/500 [00:20<09:20,  1.16s/it]  4%|▍         | 19/500 [00:20<06:34,  1.22it/s]  4%|▍         | 21/500 [00:32<19:59,  2.50s/it]  5%|▍         | 23/500 [00:33<14:00,  1.76s/it]  5%|▌         | 25/500 [00:39<17:27,  2.20s/it]  5%|▌         | 27/500 [00:39<12:17,  1.56s/it]  6%|▌         | 29/500 [00:39<08:42,  1.11s/it]  6%|▌         | 31/500 [00:52<21:03,  2.69s/it]  7%|▋         | 33/500 [00:52<14:48,  1.90s/it]  7%|▋         | 35/500 [00:58<17:39,  2.28s/it]  7%|▋         | 37/500 [00:59<12:28,  1.62s/it]  8%|▊         | 39/500 [00:59<08:50,  1.15s/it]  8%|▊         | 41/500 [01:11<20:36,  2.69s/it]  9%|▊         | 43/500 [01:11<14:31,  1.91s/it]  9%|▉         | 45/500 [01:18<17:16,  2.28s/it]  9%|▉         | 47/500 [01:18<12:11,  1.61s/it] 10%|▉         | 49/500 [01:18<08:38,  1.15s/it] 10%|█         | 51/500 [01:31<20:20,  2.72s/it] 11%|█         | 53/500 [01:31<14:20,  1.92s/it] 11%|█         | 55/500 [01:37<17:17,  2.33s/it] 11%|█▏        | 57/500 [01:38<12:11,  1.65s/it] 12%|█▏        | 59/500 [01:38<08:38,  1.18s/it] 12%|█▏        | 61/500 [01:50<19:55,  2.72s/it] 13%|█▎        | 63/500 [01:51<14:02,  1.93s/it]Epoch:  1  	Training Loss: 0.5022580623626709
Test Loss:  2.2024130821228027
Valid Loss:  2.141897678375244
Epoch:  2  	Training Loss: 2.3633034229278564
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  3  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  4  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  5  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  6  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  7  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  8  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  9  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  10  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  11  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  12  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  13  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  14  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  15  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  17  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  18  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  19  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  20  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  22  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  23  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  24  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  25  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  27  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  28  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  29  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  30  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  32  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  33  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  34  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  35  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  37  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  38  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  39  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  40  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  42  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  43  	Training Loss: 0.47311025857925415
Test Loss:  0.5722423195838928
Valid Loss:  0.5474737286567688
Epoch:  44  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  45  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  47  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  48  	Training Loss: 0.47311022877693176
Test Loss:  0.5722423195838928
Valid Loss:  0.547473669052124
Epoch:  49  	Training Loss: 0.4731101989746094
Test Loss:  0.5722423195838928
Valid Loss:  0.547473669052124
Epoch:  50  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  52  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  53  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  54  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  55  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  57  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  58  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  59  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  60  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  62  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  63  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  64  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
 13%|█▎        | 65/500 [01:57<16:58,  2.34s/it] 13%|█▎        | 67/500 [01:57<12:00,  1.66s/it] 14%|█▍        | 69/500 [01:57<08:31,  1.19s/it] 14%|█▍        | 69/500 [02:08<08:31,  1.19s/it] 14%|█▍        | 71/500 [02:10<19:27,  2.72s/it] 15%|█▍        | 73/500 [02:10<13:42,  1.93s/it] 15%|█▌        | 75/500 [02:16<16:12,  2.29s/it] 15%|█▌        | 77/500 [02:17<11:26,  1.62s/it] 16%|█▌        | 79/500 [02:17<08:06,  1.15s/it] 16%|█▌        | 79/500 [02:28<08:06,  1.15s/it] 16%|█▌        | 81/500 [02:29<18:48,  2.69s/it] 17%|█▋        | 83/500 [02:29<13:17,  1.91s/it] 17%|█▋        | 85/500 [02:36<16:10,  2.34s/it] 17%|█▋        | 87/500 [02:36<11:24,  1.66s/it] 18%|█▊        | 89/500 [02:36<08:04,  1.18s/it] 18%|█▊        | 89/500 [02:48<08:04,  1.18s/it] 18%|█▊        | 91/500 [02:49<18:26,  2.71s/it] 19%|█▊        | 93/500 [02:49<12:59,  1.91s/it] 19%|█▉        | 95/500 [02:55<15:28,  2.29s/it] 19%|█▉        | 97/500 [02:56<10:54,  1.62s/it] 20%|█▉        | 99/500 [02:56<07:43,  1.16s/it] 20%|█▉        | 99/500 [03:08<07:43,  1.16s/it] 20%|██        | 101/500 [03:08<18:02,  2.71s/it] 21%|██        | 103/500 [03:09<12:44,  1.93s/it] 21%|██        | 105/500 [03:15<15:15,  2.32s/it] 21%|██▏       | 107/500 [03:15<10:46,  1.64s/it] 22%|██▏       | 109/500 [03:15<07:38,  1.17s/it] 22%|██▏       | 109/500 [03:28<07:38,  1.17s/it] 22%|██▏       | 111/500 [03:28<17:39,  2.72s/it] 23%|██▎       | 113/500 [03:28<12:26,  1.93s/it] 23%|██▎       | 115/500 [03:35<14:54,  2.32s/it] 23%|██▎       | 117/500 [03:35<10:33,  1.65s/it] 24%|██▍       | 119/500 [03:35<07:29,  1.18s/it] 24%|██▍       | 119/500 [03:48<07:29,  1.18s/it] 24%|██▍       | 121/500 [03:48<17:15,  2.73s/it] 25%|██▍       | 123/500 [03:48<12:11,  1.94s/it]Epoch:  65  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  67  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  68  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  69  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  70  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  72  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  73  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  74  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  75  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  77  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  78  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  79  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  80  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  82  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  83  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  84  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  85  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  87  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  88  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  89  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  90  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  92  	Training Loss: 0.47311022877693176
Test Loss:  0.5722423195838928
Valid Loss:  0.5474737286567688
Epoch:  93  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  94  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  95  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  97  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  98  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  99  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  100  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  102  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  103  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  104  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  105  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  107  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  108  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  109  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  110  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  112  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  113  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  114  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  115  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  117  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  118  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  119  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  120  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  122  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  123  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  124  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  125  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
 25%|██▌       | 125/500 [03:54<14:32,  2.33s/it] 25%|██▌       | 127/500 [03:54<10:15,  1.65s/it] 26%|██▌       | 129/500 [03:55<07:15,  1.17s/it] 26%|██▌       | 131/500 [04:08<17:03,  2.77s/it] 27%|██▋       | 133/500 [04:08<12:00,  1.96s/it] 27%|██▋       | 135/500 [04:14<14:05,  2.32s/it] 27%|██▋       | 137/500 [04:14<09:56,  1.64s/it] 28%|██▊       | 139/500 [04:14<07:01,  1.17s/it] 28%|██▊       | 141/500 [04:27<16:06,  2.69s/it] 29%|██▊       | 143/500 [04:27<11:20,  1.91s/it] 29%|██▉       | 145/500 [04:33<13:33,  2.29s/it] 29%|██▉       | 147/500 [04:33<09:34,  1.63s/it] 30%|██▉       | 149/500 [04:34<06:46,  1.16s/it] 30%|███       | 151/500 [04:46<15:48,  2.72s/it] 31%|███       | 153/500 [04:46<11:07,  1.92s/it] 31%|███       | 155/500 [04:53<13:15,  2.31s/it] 31%|███▏      | 157/500 [04:53<09:21,  1.64s/it] 32%|███▏      | 159/500 [04:53<06:37,  1.17s/it] 32%|███▏      | 161/500 [05:06<15:27,  2.74s/it] 33%|███▎      | 163/500 [05:06<10:52,  1.94s/it] 33%|███▎      | 165/500 [05:12<12:51,  2.30s/it] 33%|███▎      | 167/500 [05:12<09:03,  1.63s/it] 34%|███▍      | 169/500 [05:13<06:24,  1.16s/it] 34%|███▍      | 171/500 [05:26<15:10,  2.77s/it] 35%|███▍      | 173/500 [05:26<10:39,  1.96s/it] 35%|███▌      | 175/500 [05:32<12:30,  2.31s/it] 35%|███▌      | 177/500 [05:32<08:49,  1.64s/it] 36%|███▌      | 179/500 [05:32<06:14,  1.17s/it] 36%|███▌      | 181/500 [05:45<14:16,  2.69s/it] 37%|███▋      | 183/500 [05:45<10:03,  1.91s/it] 37%|███▋      | 185/500 [05:51<12:02,  2.29s/it]**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  127  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  128  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  129  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  130  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  132  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  133  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  134  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  135  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  137  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  138  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  139  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  140  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  142  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  143  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  144  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  145  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  147  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  148  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  149  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  150  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  152  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  153  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  154  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  155  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  157  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  158  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  159  	Training Loss: 0.4731101989746094
Test Loss:  0.5722423195838928
Valid Loss:  0.547473669052124
Epoch:  160  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  162  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  163  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  164  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  165  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  167  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  168  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  169  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  170  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  172  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  173  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  174  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  175  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  177  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  178  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  179  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  180  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  182  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  183  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  184  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  185  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
 37%|███▋      | 187/500 [05:51<08:29,  1.63s/it] 38%|███▊      | 189/500 [05:52<06:00,  1.16s/it] 38%|███▊      | 191/500 [06:05<14:13,  2.76s/it] 39%|███▊      | 193/500 [06:05<10:00,  1.95s/it] 39%|███▉      | 195/500 [06:11<11:47,  2.32s/it] 39%|███▉      | 197/500 [06:11<08:18,  1.65s/it] 40%|███▉      | 199/500 [06:11<05:52,  1.17s/it] 40%|████      | 201/500 [06:24<13:29,  2.71s/it] 41%|████      | 203/500 [06:24<09:30,  1.92s/it] 41%|████      | 205/500 [06:30<11:17,  2.30s/it] 41%|████▏     | 207/500 [06:31<07:56,  1.63s/it] 42%|████▏     | 209/500 [06:31<05:36,  1.16s/it] 42%|████▏     | 211/500 [06:43<12:56,  2.69s/it] 43%|████▎     | 213/500 [06:43<09:05,  1.90s/it] 43%|████▎     | 215/500 [06:50<10:45,  2.26s/it] 43%|████▎     | 217/500 [06:50<07:34,  1.61s/it] 44%|████▍     | 219/500 [06:50<05:21,  1.14s/it] 44%|████▍     | 221/500 [07:03<12:36,  2.71s/it] 45%|████▍     | 223/500 [07:03<08:53,  1.92s/it] 45%|████▌     | 225/500 [07:09<10:43,  2.34s/it] 45%|████▌     | 227/500 [07:10<07:32,  1.66s/it] 46%|████▌     | 229/500 [07:10<05:20,  1.18s/it] 46%|████▌     | 231/500 [07:23<12:27,  2.78s/it] 47%|████▋     | 233/500 [07:23<08:44,  1.97s/it] 47%|████▋     | 235/500 [07:29<10:17,  2.33s/it] 47%|████▋     | 237/500 [07:29<07:15,  1.65s/it] 48%|████▊     | 239/500 [07:30<05:09,  1.18s/it] 48%|████▊     | 241/500 [07:42<11:48,  2.74s/it] 49%|████▊     | 243/500 [07:42<08:17,  1.94s/it] 49%|████▉     | 245/500 [07:49<09:50,  2.32s/it]Epoch:  186  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  187  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  188  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  189  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  190  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  192  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  193  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  194  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  195  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  197  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  198  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  199  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  200  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  202  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  203  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  204  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  205  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  207  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  208  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  209  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  210  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  212  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  213  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  214  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  215  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  217  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  218  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  219  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  220  	Training Loss: 0.47311022877693176
Test Loss:  0.5722423195838928
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  222  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  223  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  224  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  225  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  227  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  228  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  229  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  230  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  232  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  233  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  234  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  235  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  237  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  238  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  239  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  240  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  242  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  243  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  244  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  245  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  247  	Training Loss: 0.4731101989746094
 49%|████▉     | 247/500 [07:49<06:55,  1.64s/it] 50%|████▉     | 249/500 [07:49<04:53,  1.17s/it] 50%|█████     | 251/500 [08:02<11:09,  2.69s/it] 51%|█████     | 253/500 [08:02<07:50,  1.90s/it] 51%|█████     | 255/500 [08:08<09:23,  2.30s/it] 51%|█████▏    | 257/500 [08:08<06:36,  1.63s/it] 52%|█████▏    | 259/500 [08:08<04:40,  1.16s/it] 52%|█████▏    | 261/500 [08:21<10:44,  2.70s/it] 53%|█████▎    | 263/500 [08:21<07:32,  1.91s/it] 53%|█████▎    | 265/500 [08:27<08:57,  2.29s/it] 53%|█████▎    | 267/500 [08:28<06:17,  1.62s/it] 54%|█████▍    | 269/500 [08:28<04:26,  1.15s/it] 54%|█████▍    | 269/500 [08:38<04:26,  1.15s/it] 54%|█████▍    | 271/500 [08:40<10:15,  2.69s/it] 55%|█████▍    | 273/500 [08:40<07:11,  1.90s/it] 55%|█████▌    | 275/500 [08:47<08:29,  2.26s/it] 55%|█████▌    | 277/500 [08:47<05:58,  1.61s/it] 56%|█████▌    | 279/500 [08:47<04:13,  1.15s/it] 56%|█████▌    | 279/500 [08:58<04:13,  1.15s/it] 56%|█████▌    | 281/500 [08:59<09:47,  2.68s/it] 57%|█████▋    | 283/500 [09:00<06:51,  1.90s/it] 57%|█████▋    | 285/500 [09:06<08:12,  2.29s/it] 57%|█████▋    | 287/500 [09:06<05:45,  1.62s/it] 58%|█████▊    | 289/500 [09:06<04:03,  1.16s/it] 58%|█████▊    | 289/500 [09:18<04:03,  1.16s/it] 58%|█████▊    | 291/500 [09:19<09:24,  2.70s/it] 59%|█████▊    | 293/500 [09:19<06:35,  1.91s/it] 59%|█████▉    | 295/500 [09:25<07:46,  2.28s/it] 59%|█████▉    | 297/500 [09:25<05:27,  1.62s/it] 60%|█████▉    | 299/500 [09:26<03:51,  1.15s/it] 60%|█████▉    | 299/500 [09:38<03:51,  1.15s/it] 60%|██████    | 301/500 [09:38<08:56,  2.70s/it] 61%|██████    | 303/500 [09:38<06:16,  1.91s/it] 61%|██████    | 305/500 [09:45<07:27,  2.29s/it] 61%|██████▏   | 307/500 [09:45<05:14,  1.63s/it]Test Loss:  0.5722423195838928
Valid Loss:  0.5474737286567688
Epoch:  248  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  249  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  250  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  252  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  253  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  254  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  255  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  257  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  258  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  259  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  260  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  262  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  263  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  264  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  265  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  267  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  268  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  269  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  270  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  272  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  273  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  274  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  275  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  277  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  278  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  279  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  280  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  282  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  283  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  284  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  285  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  287  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  288  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  289  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  290  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  292  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  293  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  294  	Training Loss: 0.47311022877693176
Test Loss:  0.5722423195838928
Valid Loss:  0.5474737286567688
Epoch:  295  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  297  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  298  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  299  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  300  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  302  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  303  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  304  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  305  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  307  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  308  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:   62%|██████▏   | 309/500 [09:45<03:42,  1.16s/it] 62%|██████▏   | 311/500 [09:57<08:25,  2.68s/it] 63%|██████▎   | 313/500 [09:58<05:54,  1.90s/it] 63%|██████▎   | 315/500 [10:04<07:03,  2.29s/it] 63%|██████▎   | 317/500 [10:04<04:56,  1.62s/it] 64%|██████▍   | 319/500 [10:04<03:29,  1.16s/it] 64%|██████▍   | 321/500 [10:17<08:03,  2.70s/it] 65%|██████▍   | 323/500 [10:17<05:38,  1.91s/it] 65%|██████▌   | 325/500 [10:23<06:41,  2.30s/it] 65%|██████▌   | 327/500 [10:23<04:41,  1.63s/it] 66%|██████▌   | 329/500 [10:24<03:18,  1.16s/it] 66%|██████▌   | 331/500 [10:36<07:38,  2.71s/it] 67%|██████▋   | 333/500 [10:36<05:20,  1.92s/it] 67%|██████▋   | 335/500 [10:43<06:19,  2.30s/it] 67%|██████▋   | 337/500 [10:43<04:26,  1.63s/it] 68%|██████▊   | 339/500 [10:43<03:07,  1.16s/it] 68%|██████▊   | 341/500 [10:56<07:07,  2.69s/it] 69%|██████▊   | 343/500 [10:56<04:59,  1.90s/it] 69%|██████▉   | 345/500 [11:02<05:52,  2.28s/it] 69%|██████▉   | 347/500 [11:02<04:07,  1.62s/it] 70%|██████▉   | 349/500 [11:02<02:53,  1.15s/it] 70%|███████   | 351/500 [11:15<06:45,  2.72s/it] 71%|███████   | 353/500 [11:15<04:42,  1.92s/it] 71%|███████   | 355/500 [11:22<05:33,  2.30s/it] 71%|███████▏  | 357/500 [11:22<03:52,  1.63s/it] 72%|███████▏  | 359/500 [11:22<02:43,  1.16s/it] 72%|███████▏  | 361/500 [11:35<06:27,  2.79s/it] 73%|███████▎  | 363/500 [11:35<04:30,  1.97s/it] 73%|███████▎  | 365/500 [11:41<05:14,  2.33s/it] 73%|███████▎  | 367/500 [11:42<03:39,  1.65s/it] 74%|███████▍  | 369/500 [11:42<02:34,  1.18s/it]0.5474737286567688
Epoch:  309  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  310  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  312  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  313  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  314  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  315  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  317  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  318  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  319  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  320  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  322  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  323  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  324  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  325  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  327  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  328  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  329  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  330  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  332  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  333  	Training Loss: 0.47311025857925415
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  334  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  335  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  337  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  338  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  339  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  340  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  342  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  343  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  344  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  345  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  347  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  348  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  349  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  350  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.4731101989746094
Test Loss:  0.5722423195838928
Valid Loss:  0.547473669052124
Epoch:  352  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  353  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  354  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  355  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  357  	Training Loss: 0.4731101989746094
Test Loss:  0.5722423195838928
Valid Loss:  0.5474737286567688
Epoch:  358  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  359  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  360  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  362  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  363  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  364  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  365  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  367  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  368  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  369  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
 74%|███████▍  | 371/500 [11:54<05:49,  2.71s/it] 75%|███████▍  | 373/500 [11:54<04:03,  1.92s/it] 75%|███████▌  | 375/500 [12:01<04:48,  2.30s/it] 75%|███████▌  | 377/500 [12:01<03:20,  1.63s/it] 76%|███████▌  | 379/500 [12:01<02:20,  1.16s/it] 76%|███████▌  | 381/500 [12:14<05:24,  2.73s/it] 77%|███████▋  | 383/500 [12:14<03:45,  1.93s/it] 77%|███████▋  | 385/500 [12:20<04:25,  2.31s/it] 77%|███████▋  | 387/500 [12:21<03:05,  1.64s/it] 78%|███████▊  | 389/500 [12:21<02:09,  1.17s/it] 78%|███████▊  | 391/500 [12:33<04:54,  2.70s/it] 79%|███████▊  | 393/500 [12:33<03:24,  1.91s/it] 79%|███████▉  | 395/500 [12:40<04:00,  2.29s/it] 79%|███████▉  | 397/500 [12:40<02:47,  1.63s/it] 80%|███████▉  | 399/500 [12:40<01:57,  1.17s/it] 80%|████████  | 401/500 [12:53<04:31,  2.75s/it] 81%|████████  | 403/500 [12:53<03:09,  1.95s/it] 81%|████████  | 405/500 [13:00<03:42,  2.34s/it] 81%|████████▏ | 407/500 [13:00<02:33,  1.66s/it] 82%|████████▏ | 409/500 [13:00<01:47,  1.18s/it] 82%|████████▏ | 411/500 [13:12<04:01,  2.71s/it] 83%|████████▎ | 413/500 [13:13<02:47,  1.92s/it] 83%|████████▎ | 415/500 [13:19<03:16,  2.31s/it] 83%|████████▎ | 417/500 [13:19<02:15,  1.64s/it] 84%|████████▍ | 419/500 [13:19<01:34,  1.17s/it] 84%|████████▍ | 421/500 [13:32<03:33,  2.70s/it] 85%|████████▍ | 423/500 [13:32<02:27,  1.91s/it] 85%|████████▌ | 425/500 [13:39<02:53,  2.31s/it] 85%|████████▌ | 427/500 [13:39<01:59,  1.64s/it] 86%|████████▌ | 429/500 [13:39<01:22,  1.17s/it]Epoch:  370  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.4731101989746094
Test Loss:  0.5722423195838928
Valid Loss:  0.547473669052124
Epoch:  372  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  373  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  374  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  375  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  377  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  378  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  379  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  380  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  382  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  383  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  384  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  385  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  387  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  388  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  389  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  390  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  392  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  393  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  394  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  395  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  397  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  398  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  399  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  400  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  402  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  403  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  404  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  405  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  407  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  408  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  409  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  410  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  412  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  413  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  414  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  415  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  417  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  418  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  419  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  420  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  422  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  423  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  424  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  425  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  427  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  428  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  429  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  430  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
 86%|████████▌ | 431/500 [13:52<03:08,  2.73s/it] 87%|████████▋ | 433/500 [13:52<02:09,  1.93s/it] 87%|████████▋ | 435/500 [13:58<02:28,  2.28s/it] 87%|████████▋ | 437/500 [13:58<01:41,  1.62s/it] 88%|████████▊ | 439/500 [13:58<01:10,  1.15s/it] 88%|████████▊ | 441/500 [14:11<02:43,  2.76s/it] 89%|████████▊ | 443/500 [14:11<01:51,  1.96s/it] 89%|████████▉ | 445/500 [14:18<02:08,  2.33s/it] 89%|████████▉ | 447/500 [14:18<01:27,  1.65s/it] 90%|████████▉ | 449/500 [14:18<01:00,  1.18s/it] 90%|█████████ | 451/500 [14:31<02:14,  2.74s/it] 91%|█████████ | 453/500 [14:31<01:31,  1.94s/it] 91%|█████████ | 455/500 [14:37<01:44,  2.33s/it] 91%|█████████▏| 457/500 [14:38<01:10,  1.65s/it] 92%|█████████▏| 459/500 [14:38<00:48,  1.17s/it] 92%|█████████▏| 459/500 [14:48<00:48,  1.17s/it] 92%|█████████▏| 461/500 [14:50<01:45,  2.70s/it] 93%|█████████▎| 463/500 [14:50<01:10,  1.91s/it] 93%|█████████▎| 465/500 [14:57<01:20,  2.29s/it] 93%|█████████▎| 466/500 [14:57<01:04,  1.91s/it] 94%|█████████▎| 468/500 [14:57<00:41,  1.30s/it] 94%|█████████▍| 470/500 [15:04<00:58,  1.94s/it] 94%|█████████▍| 471/500 [15:10<01:20,  2.77s/it] 95%|█████████▍| 473/500 [15:10<00:49,  1.83s/it] 95%|█████████▌| 475/500 [15:17<00:57,  2.29s/it] 95%|█████████▌| 477/500 [15:17<00:36,  1.58s/it] 96%|█████████▌| 479/500 [15:17<00:23,  1.10s/it] 96%|█████████▌| 480/500 [15:23<00:41,  2.07s/it] 96%|█████████▌| 481/500 [15:29<00:55,  2.95s/it] 97%|█████████▋| 483/500 [15:30<00:31,  1.87s/it] 97%|█████████▋| 485/500 [15:36<00:34,  2.30s/it] 97%|█████████▋| 487/500 [15:36<00:20,  1.56s/it] 98%|█████████▊| 489/500 [15:36<00:11,  1.08s/it]**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  432  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  433  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  434  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  435  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.47311025857925415
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  437  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  438  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  439  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  440  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  442  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  443  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  444  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  445  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  447  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  448  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  449  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  450  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  452  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  453  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  454  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  455  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  457  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  458  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  459  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  460  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  462  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  463  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  464  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  465  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  467  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  468  	Training Loss: 0.4731101989746094
Test Loss:  0.5722423195838928
Valid Loss:  0.547473669052124
Epoch:  469  	Training Loss: 0.4731101989746094
Test Loss:  0.5722423195838928
Valid Loss:  0.5474737286567688
Epoch:  470  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  472  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  473  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  474  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  475  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  477  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  478  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  479  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  480  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  482  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  483  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  484  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  485  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  487  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  488  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  489  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  490  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
 98%|█████████▊| 489/500 [15:48<00:11,  1.08s/it] 98%|█████████▊| 491/500 [15:49<00:24,  2.75s/it] 99%|█████████▊| 493/500 [15:49<00:13,  1.92s/it] 99%|█████████▉| 495/500 [15:55<00:11,  2.30s/it] 99%|█████████▉| 497/500 [15:55<00:04,  1.62s/it]100%|█████████▉| 499/500 [15:56<00:01,  1.15s/it]100%|██████████| 500/500 [16:02<00:00,  1.92s/it]
Epoch:  491  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.5474737882614136
Epoch:  492  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  493  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  494  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  495  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  497  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  498  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
Epoch:  499  	Training Loss: 0.4731101989746094
Test Loss:  0.572242259979248
Valid Loss:  0.5474737286567688
Epoch:  500  	Training Loss: 0.47311022877693176
Test Loss:  0.572242259979248
Valid Loss:  0.547473669052124
**************************************************learning rate decay**************************************************
seed is  17
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:33,  6.32s/it]  1%|          | 3/500 [00:06<13:57,  1.69s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:59,  1.35s/it]  3%|▎         | 13/500 [00:13<07:28,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:45,  2.90it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:20<05:01,  1.57it/s]  5%|▌         | 27/500 [00:20<03:41,  2.13it/s]  6%|▌         | 29/500 [00:20<02:46,  2.84it/s]  6%|▌         | 31/500 [00:27<09:26,  1.21s/it]  7%|▋         | 33/500 [00:27<06:44,  1.15it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:36,  2.95it/s]  8%|▊         | 41/500 [00:34<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:36,  1.15it/s]  9%|▉         | 45/500 [00:34<04:47,  1.58it/s]  9%|▉         | 47/500 [00:34<03:31,  2.14it/s] 10%|▉         | 49/500 [00:34<02:35,  2.89it/s] 10%|█         | 51/500 [00:41<08:58,  1.20s/it] 11%|█         | 53/500 [00:41<06:26,  1.16it/s] 11%|█         | 55/500 [00:41<04:40,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:26,  2.14it/s] 12%|█▏        | 59/500 [00:41<02:34,  2.85it/s] 12%|█▏        | 61/500 [00:48<08:50,  1.21s/it] 13%|█▎        | 63/500 [00:48<06:18,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:34,  1.59it/s] 13%|█▎        | 67/500 [00:48<03:20,  2.16it/s] 14%|█▍        | 69/500 [00:48<02:29,  2.89it/s]Epoch:  1  	Training Loss: 0.10601764172315598
Test Loss:  0.011923488229513168
Valid Loss:  0.019203132018446922
Epoch:  2  	Training Loss: 0.027081619948148727
Test Loss:  0.01514995377510786
Valid Loss:  0.018398456275463104
Epoch:  3  	Training Loss: 0.018516164273023605
Test Loss:  0.011057903990149498
Valid Loss:  0.013669883832335472
Epoch:  4  	Training Loss: 0.015147523954510689
Test Loss:  0.0092433737590909
Valid Loss:  0.010987715795636177
Epoch:  5  	Training Loss: 0.01254579983651638
Test Loss:  0.007646857760846615
Valid Loss:  0.008796140551567078
Epoch:  6  	Training Loss: 0.010478692129254341
Test Loss:  0.006418703589588404
Valid Loss:  0.007118074223399162
Epoch:  7  	Training Loss: 0.008835024200379848
Test Loss:  0.0054551600478589535
Valid Loss:  0.0058266171254217625
Epoch:  8  	Training Loss: 0.007528054062277079
Test Loss:  0.004703771788626909
Valid Loss:  0.004839752800762653
Epoch:  9  	Training Loss: 0.006488817278295755
Test Loss:  0.004119060002267361
Valid Loss:  0.004090532660484314
Epoch:  10  	Training Loss: 0.0056624701246619225
Test Loss:  0.003665568307042122
Valid Loss:  0.0035264682956039906
Epoch:  11  	Training Loss: 0.005005411338061094
Test Loss:  0.0033151691313833
Valid Loss:  0.0031061964109539986
Epoch:  12  	Training Loss: 0.004482964053750038
Test Loss:  0.003045717254281044
Valid Loss:  0.002797249238938093
Epoch:  13  	Training Loss: 0.004067613277584314
Test Loss:  0.002839520340785384
Valid Loss:  0.0025740291457623243
Epoch:  14  	Training Loss: 0.0037373481318354607
Test Loss:  0.002682790160179138
Valid Loss:  0.0024165494833141565
Epoch:  15  	Training Loss: 0.003474738448858261
Test Loss:  0.0025646043941378593
Valid Loss:  0.0023091756738722324
Epoch:  16  	Training Loss: 0.0032659259159117937
Test Loss:  0.002476372290402651
Valid Loss:  0.002239710884168744
Epoch:  17  	Training Loss: 0.0030998883303254843
Test Loss:  0.0024113343097269535
Valid Loss:  0.002198664704337716
Epoch:  18  	Training Loss: 0.002967862645164132
Test Loss:  0.0023641849402338266
Valid Loss:  0.002178681083023548
Epoch:  19  	Training Loss: 0.002862884197384119
Test Loss:  0.0023307621013373137
Valid Loss:  0.0021740717347711325
Epoch:  20  	Training Loss: 0.0027794092893600464
Test Loss:  0.0023078208323568106
Valid Loss:  0.002180468989536166
Epoch:  21  	Training Loss: 0.0027130357921123505
Test Loss:  0.0022928155958652496
Valid Loss:  0.0021945307962596416
Epoch:  22  	Training Loss: 0.002660256577655673
Test Loss:  0.002283751731738448
Valid Loss:  0.0022137132473289967
Epoch:  23  	Training Loss: 0.0026182914152741432
Test Loss:  0.002279138658195734
Valid Loss:  0.002236101543530822
Epoch:  24  	Training Loss: 0.002584922593086958
Test Loss:  0.0022777665872126818
Valid Loss:  0.0022602598182857037
Epoch:  25  	Training Loss: 0.0025583882816135883
Test Loss:  0.0022787204943597317
Valid Loss:  0.002285146387293935
Epoch:  26  	Training Loss: 0.0025372894015163183
Test Loss:  0.0022813035175204277
Valid Loss:  0.0023099882528185844
Epoch:  27  	Training Loss: 0.002520513255149126
Test Loss:  0.0022849864326417446
Valid Loss:  0.0023342552594840527
Epoch:  28  	Training Loss: 0.0025071720592677593
Test Loss:  0.0022893683053553104
Valid Loss:  0.002357571618631482
Epoch:  29  	Training Loss: 0.0024965652264654636
Test Loss:  0.002294145990163088
Valid Loss:  0.0023796972818672657
Epoch:  30  	Training Loss: 0.002488129772245884
Test Loss:  0.002299094572663307
Valid Loss:  0.002400487195700407
Epoch:  31  	Training Loss: 0.002481422619894147
Test Loss:  0.002304061083123088
Valid Loss:  0.002419872209429741
Epoch:  32  	Training Loss: 0.002476087538525462
Test Loss:  0.0023089395835995674
Valid Loss:  0.002437817631289363
Epoch:  33  	Training Loss: 0.0024718448985368013
Test Loss:  0.0023136227391660213
Valid Loss:  0.002454357920214534
Epoch:  34  	Training Loss: 0.0024684735108166933
Test Loss:  0.002318077255040407
Valid Loss:  0.0024695317260921
Epoch:  35  	Training Loss: 0.002465790370479226
Test Loss:  0.002322268905118108
Valid Loss:  0.0024834012147039175
Epoch:  36  	Training Loss: 0.002463656011968851
Test Loss:  0.0023261834867298603
Valid Loss:  0.0024960373993963003
Epoch:  37  	Training Loss: 0.0024619593750685453
Test Loss:  0.0023298109881579876
Valid Loss:  0.0025075178127735853
Epoch:  38  	Training Loss: 0.0024606087245047092
Test Loss:  0.0023331553675234318
Valid Loss:  0.0025179246440529823
Epoch:  39  	Training Loss: 0.002459535840898752
Test Loss:  0.0023362282663583755
Valid Loss:  0.0025273384526371956
Epoch:  40  	Training Loss: 0.00245868181809783
Test Loss:  0.0023390399292111397
Valid Loss:  0.0025358404964208603
Epoch:  41  	Training Loss: 0.002458001486957073
Test Loss:  0.0023415987379848957
Valid Loss:  0.002543507842347026
Epoch:  42  	Training Loss: 0.0024574599228799343
Test Loss:  0.0023439268115907907
Valid Loss:  0.0025504203513264656
Epoch:  43  	Training Loss: 0.0024570291861891747
Test Loss:  0.002346036722883582
Valid Loss:  0.002556632040068507
Epoch:  44  	Training Loss: 0.002456686459481716
Test Loss:  0.0023479496594518423
Valid Loss:  0.002562214620411396
Epoch:  45  	Training Loss: 0.002456414047628641
Test Loss:  0.002349673304706812
Valid Loss:  0.0025672258343547583
Epoch:  46  	Training Loss: 0.0024561970494687557
Test Loss:  0.0023512295447289944
Valid Loss:  0.002571720629930496
Epoch:  47  	Training Loss: 0.002456024056300521
Test Loss:  0.002352630253881216
Valid Loss:  0.0025757518596947193
Epoch:  48  	Training Loss: 0.0024558850564062595
Test Loss:  0.0023538926616311073
Valid Loss:  0.0025793625973165035
Epoch:  49  	Training Loss: 0.002455775160342455
Test Loss:  0.0023550246842205524
Valid Loss:  0.002582597080618143
Epoch:  50  	Training Loss: 0.0024556871503591537
Test Loss:  0.002356042852625251
Valid Loss:  0.0025854918640106916
Epoch:  51  	Training Loss: 0.002455616369843483
Test Loss:  0.002356954850256443
Valid Loss:  0.0025880802422761917
Epoch:  52  	Training Loss: 0.002455560490489006
Test Loss:  0.0023577739484608173
Valid Loss:  0.0025903922505676746
Epoch:  53  	Training Loss: 0.0024555164854973555
Test Loss:  0.002358504571020603
Valid Loss:  0.002592462347820401
Epoch:  54  	Training Loss: 0.002455479931086302
Test Loss:  0.002359162550419569
Valid Loss:  0.002594312885776162
Epoch:  55  	Training Loss: 0.002455450128763914
Test Loss:  0.0023597488179802895
Valid Loss:  0.0025959652848541737
Epoch:  56  	Training Loss: 0.0024554275441914797
Test Loss:  0.002360275946557522
Valid Loss:  0.002597440965473652
Epoch:  57  	Training Loss: 0.0024554086849093437
Test Loss:  0.0023607437033206224
Valid Loss:  0.002598758786916733
Epoch:  58  	Training Loss: 0.0024553928524255753
Test Loss:  0.002361164428293705
Valid Loss:  0.002599935047328472
Epoch:  59  	Training Loss: 0.002455380279570818
Test Loss:  0.002361539751291275
Valid Loss:  0.002600989071652293
Epoch:  60  	Training Loss: 0.002455370035022497
Test Loss:  0.0023618722334504128
Valid Loss:  0.0026019264478236437
Epoch:  61  	Training Loss: 0.0024553611874580383
Test Loss:  0.0023621725849807262
Valid Loss:  0.0026027625426650047
Epoch:  62  	Training Loss: 0.002455353969708085
Test Loss:  0.002362441271543503
Valid Loss:  0.0026035099290311337
Epoch:  63  	Training Loss: 0.0024553469847887754
Test Loss:  0.0023626801557838917
Valid Loss:  0.0026041767559945583
Epoch:  64  	Training Loss: 0.0024553416296839714
Test Loss:  0.0023628906346857548
Valid Loss:  0.002604769542813301
Epoch:  65  	Training Loss: 0.002455337904393673
Test Loss:  0.0023630806244909763
Valid Loss:  0.002605302957817912
Epoch:  66  	Training Loss: 0.0024553341791033745
Test Loss:  0.0023632487282156944
Valid Loss:  0.0026057737413793802
Epoch:  67  	Training Loss: 0.0024553306866437197
Test Loss:  0.002363399136811495
Valid Loss:  0.0026061953976750374
Epoch:  68  	Training Loss: 0.002455327194184065
Test Loss:  0.0023635353427380323
Valid Loss:  0.0026065718848258257
Epoch:  69  	Training Loss: 0.0024553232360631227
Test Loss:  0.002363654552027583
Valid Loss:  0.0026069062296301126
Epoch:  70  	Training Loss: 0.002455322304740548
Test Loss:  0.0023637611884623766
Valid Loss:   14%|█▍        | 71/500 [00:55<08:31,  1.19s/it] 15%|█▍        | 73/500 [00:55<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:55<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:02<08:15,  1.18s/it] 17%|█▋        | 83/500 [01:02<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:02<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:02<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:02<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:09<08:15,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:52,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.94it/s] 20%|██        | 101/500 [01:16<08:05,  1.22s/it] 21%|██        | 103/500 [01:16<05:45,  1.15it/s] 21%|██        | 105/500 [01:16<04:09,  1.59it/s] 21%|██▏       | 107/500 [01:16<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.92it/s] 22%|██▏       | 111/500 [01:23<07:51,  1.21s/it] 23%|██▎       | 113/500 [01:23<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:23<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:23<02:55,  2.18it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:30<07:41,  1.22s/it] 25%|██▍       | 123/500 [01:30<05:29,  1.14it/s] 25%|██▌       | 125/500 [01:30<03:56,  1.58it/s] 25%|██▌       | 127/500 [01:30<02:52,  2.16it/s] 26%|██▌       | 129/500 [01:30<02:09,  2.87it/s] 26%|██▌       | 131/500 [01:37<07:31,  1.22s/it] 27%|██▋       | 133/500 [01:37<05:22,  1.14it/s] 27%|██▋       | 135/500 [01:37<03:51,  1.58it/s] 27%|██▋       | 137/500 [01:37<02:48,  2.16it/s] 28%|██▊       | 139/500 [01:37<02:03,  2.91it/s]0.002607207279652357
Epoch:  71  	Training Loss: 0.002455319743603468
Test Loss:  0.002363857114687562
Valid Loss:  0.0026074713096022606
Epoch:  72  	Training Loss: 0.002455316483974457
Test Loss:  0.00236394046805799
Valid Loss:  0.002607709728181362
Epoch:  73  	Training Loss: 0.002455314854159951
Test Loss:  0.0023640156723558903
Valid Loss:  0.0026079202070832253
Epoch:  74  	Training Loss: 0.00245531159453094
Test Loss:  0.00236408319324255
Valid Loss:  0.0026081111282110214
Epoch:  75  	Training Loss: 0.002455310896039009
Test Loss:  0.0023641418665647507
Valid Loss:  0.0026082778349518776
Epoch:  76  	Training Loss: 0.002455309499055147
Test Loss:  0.0023641949519515038
Valid Loss:  0.00260842964053154
Epoch:  77  	Training Loss: 0.0024553057737648487
Test Loss:  0.0023642410524189472
Valid Loss:  0.0026085602585226297
Epoch:  78  	Training Loss: 0.0024553057737648487
Test Loss:  0.0023642838932573795
Valid Loss:  0.0026086762081831694
Epoch:  79  	Training Loss: 0.0024553025141358376
Test Loss:  0.0023643220774829388
Valid Loss:  0.0026087844744324684
Epoch:  80  	Training Loss: 0.0024553011171519756
Test Loss:  0.0023643551394343376
Valid Loss:  0.0026088785380125046
Epoch:  81  	Training Loss: 0.002455300185829401
Test Loss:  0.002364381682127714
Valid Loss:  0.0026089618913829327
Epoch:  82  	Training Loss: 0.002455297391861677
Test Loss:  0.0023644068278372288
Valid Loss:  0.00260903756134212
Epoch:  83  	Training Loss: 0.0024552959948778152
Test Loss:  0.002364430343732238
Valid Loss:  0.002609101589769125
Epoch:  84  	Training Loss: 0.0024552936665713787
Test Loss:  0.002364451065659523
Valid Loss:  0.002609160728752613
Epoch:  85  	Training Loss: 0.002455292269587517
Test Loss:  0.0023644689936190844
Valid Loss:  0.0026092128828167915
Epoch:  86  	Training Loss: 0.0024552897084504366
Test Loss:  0.002364485990256071
Valid Loss:  0.0026092587504535913
Epoch:  87  	Training Loss: 0.0024552883114665747
Test Loss:  0.0023645004257559776
Valid Loss:  0.0026093004271388054
Epoch:  88  	Training Loss: 0.0024552864488214254
Test Loss:  0.0023645106703042984
Valid Loss:  0.0026093353517353535
Epoch:  89  	Training Loss: 0.002455284586176276
Test Loss:  0.0023645213805139065
Valid Loss:  0.0026093716733157635
Epoch:  90  	Training Loss: 0.0024552831891924143
Test Loss:  0.0023645320907235146
Valid Loss:  0.002609400311484933
Epoch:  91  	Training Loss: 0.0024552824907004833
Test Loss:  0.0023645414039492607
Valid Loss:  0.0026094247587025166
Epoch:  92  	Training Loss: 0.002455278765410185
Test Loss:  0.0023645448964089155
Valid Loss:  0.0026094457134604454
Epoch:  93  	Training Loss: 0.0024552778340876102
Test Loss:  0.0023645535111427307
Valid Loss:  0.0026094666682183743
Epoch:  94  	Training Loss: 0.0024552743416279554
Test Loss:  0.0023645595647394657
Valid Loss:  0.002609485760331154
Epoch:  95  	Training Loss: 0.0024552736431360245
Test Loss:  0.002364566083997488
Valid Loss:  0.002609500428661704
Epoch:  96  	Training Loss: 0.00245527271181345
Test Loss:  0.0023645665496587753
Valid Loss:  0.002609512535855174
Epoch:  97  	Training Loss: 0.0024552708491683006
Test Loss:  0.0023645709734410048
Valid Loss:  0.0026095248758792877
Epoch:  98  	Training Loss: 0.0024552689865231514
Test Loss:  0.0023645698092877865
Valid Loss:  0.002609537448734045
Epoch:  99  	Training Loss: 0.002455267123878002
Test Loss:  0.002364576794207096
Valid Loss:  0.002609546296298504
Epoch:  100  	Training Loss: 0.002455264562740922
Test Loss:  0.002364575397223234
Valid Loss:  0.002609553746879101
Epoch:  101  	Training Loss: 0.0024552636314183474
Test Loss:  0.002364576794207096
Valid Loss:  0.0026095607317984104
Epoch:  102  	Training Loss: 0.0024552620016038418
Test Loss:  0.00236457958817482
Valid Loss:  0.0026095653884112835
Epoch:  103  	Training Loss: 0.002455261070281267
Test Loss:  0.002364580985158682
Valid Loss:  0.0026095702778548002
Epoch:  104  	Training Loss: 0.0024552580434828997
Test Loss:  0.0023645791225135326
Valid Loss:  0.002609574468806386
Epoch:  105  	Training Loss: 0.002455257112160325
Test Loss:  0.002364581683650613
Valid Loss:  0.002609577728435397
Epoch:  106  	Training Loss: 0.002455255016684532
Test Loss:  0.002364581683650613
Valid Loss:  0.002609583083540201
Epoch:  107  	Training Loss: 0.0024552536197006702
Test Loss:  0.002364580985158682
Valid Loss:  0.0026095856446772814
Epoch:  108  	Training Loss: 0.002455251757055521
Test Loss:  0.0023645784240216017
Valid Loss:  0.0026095863431692123
Epoch:  109  	Training Loss: 0.0024552498944103718
Test Loss:  0.002364581450819969
Valid Loss:  0.0026095896027982235
Epoch:  110  	Training Loss: 0.0024552480317652225
Test Loss:  0.0023645800538361073
Valid Loss:  0.0026095903012901545
Epoch:  111  	Training Loss: 0.002455246401950717
Test Loss:  0.00236457958817482
Valid Loss:  0.002609589835628867
Epoch:  112  	Training Loss: 0.0024552445393055677
Test Loss:  0.002364576794207096
Valid Loss:  0.002609593328088522
Epoch:  113  	Training Loss: 0.0024552412796765566
Test Loss:  0.002364576328545809
Valid Loss:  0.002609594725072384
Epoch:  114  	Training Loss: 0.002455241745337844
Test Loss:  0.0023645772598683834
Valid Loss:  0.0026095937937498093
Epoch:  115  	Training Loss: 0.0024552391842007637
Test Loss:  0.002364574698731303
Valid Loss:  0.00260959193110466
Epoch:  116  	Training Loss: 0.0024552373215556145
Test Loss:  0.002364573534578085
Valid Loss:  0.0026095921639353037
Epoch:  117  	Training Loss: 0.0024552359245717525
Test Loss:  0.0023645726032555103
Valid Loss:  0.002609592629596591
Epoch:  118  	Training Loss: 0.002455234294757247
Test Loss:  0.00236457004211843
Valid Loss:  0.0026095928624272346
Epoch:  119  	Training Loss: 0.0024552312679588795
Test Loss:  0.0023645698092877865
Valid Loss:  0.002609593328088522
Epoch:  120  	Training Loss: 0.002455230802297592
Test Loss:  0.002364568645134568
Valid Loss:  0.0026095907669514418
Epoch:  121  	Training Loss: 0.0024552284739911556
Test Loss:  0.0023645679466426373
Valid Loss:  0.0026095903012901545
Epoch:  122  	Training Loss: 0.002455226145684719
Test Loss:  0.0023645658511668444
Valid Loss:  0.0026095896027982235
Epoch:  123  	Training Loss: 0.002455224748700857
Test Loss:  0.002364566083997488
Valid Loss:  0.0026095882058143616
Epoch:  124  	Training Loss: 0.002455222886055708
Test Loss:  0.002364563290029764
Valid Loss:  0.0026095849461853504
Epoch:  125  	Training Loss: 0.002455221489071846
Test Loss:  0.0023645618930459023
Valid Loss:  0.0026095849461853504
Epoch:  126  	Training Loss: 0.0024552196264266968
Test Loss:  0.0023645611945539713
Valid Loss:  0.0026095854118466377
Epoch:  127  	Training Loss: 0.0024552172981202602
Test Loss:  0.002364558167755604
Valid Loss:  0.0026095823850482702
Epoch:  128  	Training Loss: 0.0024552156683057547
Test Loss:  0.002364557236433029
Valid Loss:  0.0026095809880644083
Epoch:  129  	Training Loss: 0.00245521473698318
Test Loss:  0.0023645558394491673
Valid Loss:  0.002609581919386983
Epoch:  130  	Training Loss: 0.0024552135728299618
Test Loss:  0.0023645537439733744
Valid Loss:  0.002609581220895052
Epoch:  131  	Training Loss: 0.0024552112445235252
Test Loss:  0.0023645535111427307
Valid Loss:  0.002609577961266041
Epoch:  132  	Training Loss: 0.0024552098475396633
Test Loss:  0.002364550717175007
Valid Loss:  0.0026095767971128225
Epoch:  133  	Training Loss: 0.0024552077520638704
Test Loss:  0.002364549320191145
Valid Loss:  0.0026095747016370296
Epoch:  134  	Training Loss: 0.002455206587910652
Test Loss:  0.0023645469918847084
Valid Loss:  0.002609573071822524
Epoch:  135  	Training Loss: 0.0024552042596042156
Test Loss:  0.002364545362070203
Valid Loss:  0.002609572373330593
Epoch:  136  	Training Loss: 0.0024552023969590664
Test Loss:  0.00236454326659441
Valid Loss:  0.0026095686480402946
Epoch:  137  	Training Loss: 0.0024552009999752045
Test Loss:  0.0023645421024411917
Valid Loss:  0.0026095646899193525
Epoch:  138  	Training Loss: 0.0024551991373300552
Test Loss:  0.0023645428009331226
Valid Loss:  0.002609565854072571
Epoch:  139  	Training Loss: 0.002455197274684906
Test Loss:  0.002364540006965399
Valid Loss:  0.00260956515558064
 28%|██▊       | 141/500 [01:44<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:44<05:04,  1.17it/s] 29%|██▉       | 145/500 [01:44<03:40,  1.61it/s] 29%|██▉       | 147/500 [01:44<02:40,  2.21it/s] 30%|██▉       | 149/500 [01:44<01:58,  2.97it/s] 30%|███       | 151/500 [01:51<07:04,  1.22s/it] 31%|███       | 153/500 [01:51<05:04,  1.14it/s] 31%|███       | 155/500 [01:51<03:40,  1.56it/s] 31%|███▏      | 157/500 [01:51<02:42,  2.11it/s] 32%|███▏      | 159/500 [01:51<02:01,  2.80it/s] 32%|███▏      | 161/500 [01:58<06:50,  1.21s/it] 33%|███▎      | 163/500 [01:58<04:54,  1.14it/s] 33%|███▎      | 165/500 [01:58<03:33,  1.57it/s] 33%|███▎      | 167/500 [01:58<02:37,  2.12it/s] 34%|███▍      | 169/500 [01:59<01:58,  2.80it/s] 34%|███▍      | 171/500 [02:05<06:44,  1.23s/it] 35%|███▍      | 173/500 [02:05<04:48,  1.13it/s] 35%|███▌      | 175/500 [02:05<03:27,  1.57it/s] 35%|███▌      | 177/500 [02:06<02:30,  2.14it/s] 36%|███▌      | 179/500 [02:06<01:52,  2.86it/s] 36%|███▌      | 181/500 [02:12<06:33,  1.23s/it] 36%|███▋      | 182/500 [02:12<05:28,  1.03s/it] 37%|███▋      | 184/500 [02:13<03:46,  1.40it/s] 37%|███▋      | 186/500 [02:13<02:40,  1.95it/s] 38%|███▊      | 188/500 [02:13<01:55,  2.70it/s] 38%|███▊      | 190/500 [02:13<01:25,  3.62it/s] 38%|███▊      | 192/500 [02:19<06:07,  1.19s/it] 39%|███▉      | 194/500 [02:20<04:21,  1.17it/s] 39%|███▉      | 196/500 [02:20<03:08,  1.61it/s] 40%|███▉      | 198/500 [02:20<02:18,  2.18it/s] 40%|████      | 200/500 [02:20<01:43,  2.89it/s] 40%|████      | 202/500 [02:27<05:58,  1.20s/it] 41%|████      | 204/500 [02:27<04:15,  1.16it/s] 41%|████      | 206/500 [02:27<03:02,  1.61it/s] 42%|████▏     | 208/500 [02:27<02:12,  2.20it/s]Epoch:  140  	Training Loss: 0.0024551954120397568
Test Loss:  0.0023645395413041115
Valid Loss:  0.002609563060104847
Epoch:  141  	Training Loss: 0.002455194015055895
Test Loss:  0.0023645376786589622
Valid Loss:  0.002609561663120985
Epoch:  142  	Training Loss: 0.002455191919580102
Test Loss:  0.0023645369801670313
Valid Loss:  0.0026095593348145485
Epoch:  143  	Training Loss: 0.002455189824104309
Test Loss:  0.0023645334877073765
Valid Loss:  0.0026095579378306866
Epoch:  144  	Training Loss: 0.00245518796145916
Test Loss:  0.002364532556384802
Valid Loss:  0.0026095565408468246
Epoch:  145  	Training Loss: 0.002455186564475298
Test Loss:  0.0023645313922315836
Valid Loss:  0.0026095546782016754
Epoch:  146  	Training Loss: 0.002455184468999505
Test Loss:  0.0023645306937396526
Valid Loss:  0.002609554212540388
Epoch:  147  	Training Loss: 0.0024551833048462868
Test Loss:  0.0023645281326025724
Valid Loss:  0.002609553746879101
Epoch:  148  	Training Loss: 0.0024551814422011375
Test Loss:  0.0023645267356187105
Valid Loss:  0.002609552349895239
Epoch:  149  	Training Loss: 0.0024551788810640574
Test Loss:  0.0023645227774977684
Valid Loss:  0.002609550952911377
Epoch:  150  	Training Loss: 0.0024551774840801954
Test Loss:  0.002364520914852619
Valid Loss:  0.002609547460451722
Epoch:  151  	Training Loss: 0.00245517585426569
Test Loss:  0.002364521147683263
Valid Loss:  0.0026095458306372166
Epoch:  152  	Training Loss: 0.0024551735259592533
Test Loss:  0.0023645188193768263
Valid Loss:  0.0026095430366694927
Epoch:  153  	Training Loss: 0.0024551714304834604
Test Loss:  0.0023645185865461826
Valid Loss:  0.0026095411740243435
Epoch:  154  	Training Loss: 0.002455169800668955
Test Loss:  0.002364518353715539
Valid Loss:  0.002609541639685631
Epoch:  155  	Training Loss: 0.0024551688693463802
Test Loss:  0.002364514395594597
Valid Loss:  0.002609538845717907
Epoch:  156  	Training Loss: 0.002455167006701231
Test Loss:  0.0023645134642720222
Valid Loss:  0.0026095351204276085
Epoch:  157  	Training Loss: 0.002455165609717369
Test Loss:  0.0023645127657800913
Valid Loss:  0.002609536051750183
Epoch:  158  	Training Loss: 0.0024551632814109325
Test Loss:  0.0023645092733204365
Valid Loss:  0.002609534189105034
Epoch:  159  	Training Loss: 0.0024551618844270706
Test Loss:  0.002364508341997862
Valid Loss:  0.0026095309294760227
Epoch:  160  	Training Loss: 0.0024551604874432087
Test Loss:  0.0023645060136914253
Valid Loss:  0.0026095309294760227
Epoch:  161  	Training Loss: 0.0024551590904593468
Test Loss:  0.0023645060136914253
Valid Loss:  0.0026095262728631496
Epoch:  162  	Training Loss: 0.0024551579263061285
Test Loss:  0.0023645032197237015
Valid Loss:  0.0026095262728631496
Epoch:  163  	Training Loss: 0.0024551553651690483
Test Loss:  0.002364502288401127
Valid Loss:  0.0026095237117260695
Epoch:  164  	Training Loss: 0.002455153502523899
Test Loss:  0.002364499494433403
Valid Loss:  0.002609522081911564
Epoch:  165  	Training Loss: 0.002455152338370681
Test Loss:  0.00236449739895761
Valid Loss:  0.0026095216162502766
Epoch:  166  	Training Loss: 0.002455150242894888
Test Loss:  0.0023644957691431046
Valid Loss:  0.002609517890959978
Epoch:  167  	Training Loss: 0.002455148147419095
Test Loss:  0.002364494139328599
Valid Loss:  0.002609516493976116
Epoch:  168  	Training Loss: 0.0024551472160965204
Test Loss:  0.002364490646868944
Valid Loss:  0.0026095130015164614
Epoch:  169  	Training Loss: 0.002455144189298153
Test Loss:  0.002364492043852806
Valid Loss:  0.0026095137000083923
Epoch:  170  	Training Loss: 0.0024551416281610727
Test Loss:  0.002364489948377013
Valid Loss:  0.002609514631330967
Epoch:  171  	Training Loss: 0.0024551404640078545
Test Loss:  0.002364488784223795
Valid Loss:  0.0026095083449035883
Epoch:  172  	Training Loss: 0.0024551390670239925
Test Loss:  0.0023644862230867147
Valid Loss:  0.0026095081120729446
Epoch:  173  	Training Loss: 0.0024551372043788433
Test Loss:  0.0023644855245947838
Valid Loss:  0.0026095067150890827
Epoch:  174  	Training Loss: 0.0024551362730562687
Test Loss:  0.0023644829634577036
Valid Loss:  0.0026095060165971518
Epoch:  175  	Training Loss: 0.0024551344104111195
Test Loss:  0.0023644794709980488
Valid Loss:  0.002609504386782646
Epoch:  176  	Training Loss: 0.0024551325477659702
Test Loss:  0.002364478539675474
Valid Loss:  0.0026095029897987843
Epoch:  177  	Training Loss: 0.002455131383612752
Test Loss:  0.002364478074014187
Valid Loss:  0.0026095027569681406
Epoch:  178  	Training Loss: 0.002455129288136959
Test Loss:  0.002364476677030325
Valid Loss:  0.002609498333185911
Epoch:  179  	Training Loss: 0.002455127192661166
Test Loss:  0.0023644776083528996
Valid Loss:  0.0026094969362020493
Epoch:  180  	Training Loss: 0.0024551255628466606
Test Loss:  0.0023644757457077503
Valid Loss:  0.0026094953063875437
Epoch:  181  	Training Loss: 0.002455123234540224
Test Loss:  0.002364471321925521
Valid Loss:  0.0026094941422343254
Epoch:  182  	Training Loss: 0.002455120673403144
Test Loss:  0.002364469924941659
Valid Loss:  0.002609491813927889
Epoch:  183  	Training Loss: 0.0024551195092499256
Test Loss:  0.0023644668981432915
Valid Loss:  0.002609489718452096
Epoch:  184  	Training Loss: 0.002455118577927351
Test Loss:  0.002364466432482004
Valid Loss:  0.0026094880886375904
Epoch:  185  	Training Loss: 0.002455116482451558
Test Loss:  0.0023644650354981422
Valid Loss:  0.002609486924484372
Epoch:  186  	Training Loss: 0.0024551143869757652
Test Loss:  0.0023644613102078438
Valid Loss:  0.0026094841305166483
Epoch:  187  	Training Loss: 0.0024551129899919033
Test Loss:  0.0023644594475626945
Valid Loss:  0.0026094841305166483
Epoch:  188  	Training Loss: 0.002455111127346754
Test Loss:  0.002364459913223982
Valid Loss:  0.00260948296636343
Epoch:  189  	Training Loss: 0.0024551106616854668
Test Loss:  0.002364460378885269
Valid Loss:  0.002609480172395706
Epoch:  190  	Training Loss: 0.002455107169225812
Test Loss:  0.0023644575849175453
Valid Loss:  0.0026094785425812006
Epoch:  191  	Training Loss: 0.0024551060050725937
Test Loss:  0.002364454325288534
Valid Loss:  0.002609476912766695
Epoch:  192  	Training Loss: 0.0024551041424274445
Test Loss:  0.0023644529283046722
Valid Loss:  0.002609476912766695
Epoch:  193  	Training Loss: 0.00245510321110487
Test Loss:  0.0023644519969820976
Valid Loss:  0.00260947342030704
Epoch:  194  	Training Loss: 0.0024551001843065023
Test Loss:  0.0023644492030143738
Valid Loss:  0.002609470160678029
Epoch:  195  	Training Loss: 0.002455098321661353
Test Loss:  0.002364447806030512
Valid Loss:  0.002609470160678029
Epoch:  196  	Training Loss: 0.002455096459016204
Test Loss:  0.0023644459433853626
Valid Loss:  0.002609469462186098
Epoch:  197  	Training Loss: 0.0024550952948629856
Test Loss:  0.0023644438479095697
Valid Loss:  0.0026094671338796616
Epoch:  198  	Training Loss: 0.00245509366504848
Test Loss:  0.002364441519603133
Valid Loss:  0.0026094638742506504
Epoch:  199  	Training Loss: 0.002455092268064618
Test Loss:  0.0023644398897886276
Valid Loss:  0.002609462710097432
Epoch:  200  	Training Loss: 0.002455090871080756
Test Loss:  0.0023644394241273403
Valid Loss:  0.0026094631757587194
Epoch:  201  	Training Loss: 0.002455088309943676
Test Loss:  0.002364440355449915
Valid Loss:  0.0026094592176377773
Epoch:  202  	Training Loss: 0.002455086214467883
Test Loss:  0.0023644373286515474
Valid Loss:  0.0026094592176377773
Epoch:  203  	Training Loss: 0.002455085050314665
Test Loss:  0.002364436164498329
Valid Loss:  0.002609455259516835
Epoch:  204  	Training Loss: 0.0024550831876695156
Test Loss:  0.002364432904869318
Valid Loss:  0.0026094522327184677
Epoch:  205  	Training Loss: 0.0024550817906856537
Test Loss:  0.002364430809393525
Valid Loss:  0.002609450602903962
Epoch:  206  	Training Loss: 0.002455079695209861
Test Loss:  0.002364429645240307
Valid Loss:  0.0026094517670571804
Epoch:  207  	Training Loss: 0.002455077599734068
Test Loss:  0.0023644287139177322
Valid Loss:  0.002609451301395893
Epoch:  208  	Training Loss: 0.0024550759699195623
Test Loss:  0.002364425454288721
Valid Loss:  0.0026094475761055946
 42%|████▏     | 210/500 [02:27<01:38,  2.94it/s] 42%|████▏     | 212/500 [02:33<05:43,  1.19s/it] 43%|████▎     | 214/500 [02:34<04:04,  1.17it/s] 43%|████▎     | 216/500 [02:34<02:55,  1.62it/s] 44%|████▎     | 218/500 [02:34<02:07,  2.20it/s] 44%|████▍     | 220/500 [02:34<01:35,  2.92it/s] 44%|████▍     | 222/500 [02:40<05:31,  1.19s/it] 45%|████▍     | 224/500 [02:40<03:55,  1.17it/s] 45%|████▌     | 226/500 [02:41<02:49,  1.62it/s] 46%|████▌     | 228/500 [02:41<02:03,  2.21it/s] 46%|████▌     | 230/500 [02:41<01:30,  2.97it/s] 46%|████▋     | 232/500 [02:47<05:18,  1.19s/it] 47%|████▋     | 234/500 [02:47<03:46,  1.17it/s] 47%|████▋     | 236/500 [02:48<02:42,  1.62it/s] 48%|████▊     | 238/500 [02:48<01:57,  2.22it/s] 48%|████▊     | 240/500 [02:48<01:26,  2.99it/s] 48%|████▊     | 242/500 [02:54<05:07,  1.19s/it] 49%|████▉     | 244/500 [02:54<03:38,  1.17it/s] 49%|████▉     | 246/500 [02:54<02:36,  1.62it/s] 50%|████▉     | 248/500 [02:55<01:53,  2.21it/s] 50%|█████     | 250/500 [02:55<01:23,  2.98it/s] 50%|█████     | 252/500 [03:01<04:54,  1.19s/it] 51%|█████     | 254/500 [03:01<03:29,  1.17it/s] 51%|█████     | 256/500 [03:01<02:30,  1.62it/s] 52%|█████▏    | 258/500 [03:01<01:48,  2.22it/s] 52%|█████▏    | 260/500 [03:02<01:20,  2.99it/s] 52%|█████▏    | 262/500 [03:08<04:43,  1.19s/it] 53%|█████▎    | 264/500 [03:08<03:22,  1.17it/s] 53%|█████▎    | 266/500 [03:08<02:25,  1.61it/s] 54%|█████▎    | 268/500 [03:08<01:45,  2.19it/s] 54%|█████▍    | 270/500 [03:08<01:17,  2.95it/s] 54%|█████▍    | 272/500 [03:15<04:34,  1.21s/it] 55%|█████▍    | 274/500 [03:15<03:16,  1.15it/s] 55%|█████▌    | 276/500 [03:15<02:22,  1.58it/s]Epoch:  209  	Training Loss: 0.0024550745729357004
Test Loss:  0.0023644245229661465
Valid Loss:  0.0026094454806298018
Epoch:  210  	Training Loss: 0.0024550724774599075
Test Loss:  0.002364420797675848
Valid Loss:  0.0026094457134604454
Epoch:  211  	Training Loss: 0.0024550706148147583
Test Loss:  0.0023644217289984226
Valid Loss:  0.0026094415225088596
Epoch:  212  	Training Loss: 0.0024550682865083218
Test Loss:  0.0023644198663532734
Valid Loss:  0.0026094415225088596
Epoch:  213  	Training Loss: 0.002455067588016391
Test Loss:  0.0023644191678613424
Valid Loss:  0.002609441289678216
Epoch:  214  	Training Loss: 0.002455065492540598
Test Loss:  0.002364418236538768
Valid Loss:  0.0026094382628798485
Epoch:  215  	Training Loss: 0.002455064095556736
Test Loss:  0.0023644156754016876
Valid Loss:  0.002609435934573412
Epoch:  216  	Training Loss: 0.0024550617672502995
Test Loss:  0.002364413347095251
Valid Loss:  0.002609433140605688
Epoch:  217  	Training Loss: 0.0024550610687583685
Test Loss:  0.0023644124157726765
Valid Loss:  0.0026094308122992516
Epoch:  218  	Training Loss: 0.0024550582747906446
Test Loss:  0.0023644096218049526
Valid Loss:  0.0026094301138073206
Epoch:  219  	Training Loss: 0.002455056644976139
Test Loss:  0.0023644082248210907
Valid Loss:  0.002609428483992815
Epoch:  220  	Training Loss: 0.0024550538510084152
Test Loss:  0.0023644075263291597
Valid Loss:  0.002609425922855735
Epoch:  221  	Training Loss: 0.0024550529196858406
Test Loss:  0.002364405430853367
Valid Loss:  0.0026094247587025166
Epoch:  222  	Training Loss: 0.0024550515227019787
Test Loss:  0.0023644007742404938
Valid Loss:  0.002609421731904149
Epoch:  223  	Training Loss: 0.0024550489615648985
Test Loss:  0.0023644003085792065
Valid Loss:  0.00260942243039608
Epoch:  224  	Training Loss: 0.0024550470989197493
Test Loss:  0.0023643989115953445
Valid Loss:  0.0026094228960573673
Epoch:  225  	Training Loss: 0.002455045934766531
Test Loss:  0.00236439798027277
Valid Loss:  0.002609419170767069
Epoch:  226  	Training Loss: 0.0024550440721213818
Test Loss:  0.0023643961176276207
Valid Loss:  0.002609417773783207
Epoch:  227  	Training Loss: 0.0024550417438149452
Test Loss:  0.0023643942549824715
Valid Loss:  0.0026094173081219196
Epoch:  228  	Training Loss: 0.0024550396483391523
Test Loss:  0.002364393323659897
Valid Loss:  0.0026094173081219196
Epoch:  229  	Training Loss: 0.0024550394155085087
Test Loss:  0.0023643909953534603
Valid Loss:  0.0026094126515090466
Epoch:  230  	Training Loss: 0.0024550375528633595
Test Loss:  0.0023643900640308857
Valid Loss:  0.0026094126515090466
Epoch:  231  	Training Loss: 0.0024550349917262793
Test Loss:  0.002364390529692173
Valid Loss:  0.0026094093918800354
Epoch:  232  	Training Loss: 0.0024550342932343483
Test Loss:  0.0023643886670470238
Valid Loss:  0.002609405666589737
Epoch:  233  	Training Loss: 0.0024550319649279118
Test Loss:  0.0023643854074180126
Valid Loss:  0.0026094033382833004
Epoch:  234  	Training Loss: 0.0024550296366214752
Test Loss:  0.0023643847089260817
Valid Loss:  0.0026094031054526567
Epoch:  235  	Training Loss: 0.002455029170960188
Test Loss:  0.0023643821477890015
Valid Loss:  0.002609402406960726
Epoch:  236  	Training Loss: 0.0024550273083150387
Test Loss:  0.0023643800523132086
Valid Loss:  0.002609401009976864
Epoch:  237  	Training Loss: 0.0024550240486860275
Test Loss:  0.0023643767926841974
Valid Loss:  0.0026093991473317146
Epoch:  238  	Training Loss: 0.0024550228845328093
Test Loss:  0.002364377025514841
Valid Loss:  0.0026093979831784964
Epoch:  239  	Training Loss: 0.002455021720379591
Test Loss:  0.00236437632702291
Valid Loss:  0.002609396353363991
Epoch:  240  	Training Loss: 0.0024550200905650854
Test Loss:  0.002364374464377761
Valid Loss:  0.0026093940250575542
Epoch:  241  	Training Loss: 0.0024550179950892925
Test Loss:  0.002364370971918106
Valid Loss:  0.002609390066936612
Epoch:  242  	Training Loss: 0.0024550158996134996
Test Loss:  0.002364369574934244
Valid Loss:  0.0026093884371221066
Epoch:  243  	Training Loss: 0.002455014968290925
Test Loss:  0.002364368410781026
Valid Loss:  0.0026093870401382446
Epoch:  244  	Training Loss: 0.0024550119414925575
Test Loss:  0.0023643681779503822
Valid Loss:  0.002609386807307601
Epoch:  245  	Training Loss: 0.0024550114758312702
Test Loss:  0.0023643644526600838
Valid Loss:  0.0026093819178640842
Epoch:  246  	Training Loss: 0.002455009613186121
Test Loss:  0.002364362822845578
Valid Loss:  0.002609382150694728
Epoch:  247  	Training Loss: 0.0024550072848796844
Test Loss:  0.0023643604945391417
Valid Loss:  0.002609381452202797
Epoch:  248  	Training Loss: 0.0024550054222345352
Test Loss:  0.0023643579334020615
Valid Loss:  0.0026093805208802223
Epoch:  249  	Training Loss: 0.0024550030939280987
Test Loss:  0.002364357002079487
Valid Loss:  0.0026093777269124985
Epoch:  250  	Training Loss: 0.0024550016969442368
Test Loss:  0.002364357467740774
Valid Loss:  0.0026093744672834873
Epoch:  251  	Training Loss: 0.002455000067129731
Test Loss:  0.0023643553722649813
Valid Loss:  0.0026093749329447746
Epoch:  252  	Training Loss: 0.0024549984373152256
Test Loss:  0.002364353509619832
Valid Loss:  0.0026093737687915564
Epoch:  253  	Training Loss: 0.00245499680750072
Test Loss:  0.002364350948482752
Valid Loss:  0.0026093709748238325
Epoch:  254  	Training Loss: 0.0024549956433475018
Test Loss:  0.0023643490858376026
Valid Loss:  0.0026093674823641777
Epoch:  255  	Training Loss: 0.0024549937807023525
Test Loss:  0.0023643462918698788
Valid Loss:  0.0026093628257513046
Epoch:  256  	Training Loss: 0.002454991452395916
Test Loss:  0.0023643451277166605
Valid Loss:  0.0026093614287674427
Epoch:  257  	Training Loss: 0.002454990055412054
Test Loss:  0.0023643430322408676
Valid Loss:  0.00260936189442873
Epoch:  258  	Training Loss: 0.00245498726144433
Test Loss:  0.002364342100918293
Valid Loss:  0.002609359100461006
Epoch:  259  	Training Loss: 0.0024549858644604683
Test Loss:  0.0023643432650715113
Valid Loss:  0.0026093609631061554
Epoch:  260  	Training Loss: 0.0024549835361540318
Test Loss:  0.0023643402382731438
Valid Loss:  0.002609358634799719
Epoch:  261  	Training Loss: 0.002454982604831457
Test Loss:  0.002364338142797351
Valid Loss:  0.0026093577034771442
Epoch:  262  	Training Loss: 0.0024549809750169516
Test Loss:  0.0023643365129828453
Valid Loss:  0.0026093563064932823
Epoch:  263  	Training Loss: 0.0024549788795411587
Test Loss:  0.0023643351159989834
Valid Loss:  0.002609354443848133
Epoch:  264  	Training Loss: 0.002454977249726653
Test Loss:  0.002364334650337696
Valid Loss:  0.0026093514170497656
Epoch:  265  	Training Loss: 0.002454976551234722
Test Loss:  0.0023643323220312595
Valid Loss:  0.0026093495544046164
Epoch:  266  	Training Loss: 0.0024549742229282856
Test Loss:  0.002364332787692547
Valid Loss:  0.0026093488559126854
Epoch:  267  	Training Loss: 0.0024549723602831364
Test Loss:  0.002364328596740961
Valid Loss:  0.002609346993267536
Epoch:  268  	Training Loss: 0.0024549702648073435
Test Loss:  0.0023643281310796738
Valid Loss:  0.0026093453634530306
Epoch:  269  	Training Loss: 0.002454969333484769
Test Loss:  0.0023643248714506626
Valid Loss:  0.0026093448977917433
Epoch:  270  	Training Loss: 0.0024549667723476887
Test Loss:  0.00236432533711195
Valid Loss:  0.002609340939670801
Epoch:  271  	Training Loss: 0.002454965142533183
Test Loss:  0.0023643230088055134
Valid Loss:  0.0026093388441950083
Epoch:  272  	Training Loss: 0.002454963745549321
Test Loss:  0.0023643197491765022
Valid Loss:  0.002609339077025652
Epoch:  273  	Training Loss: 0.0024549623485654593
Test Loss:  0.0023643188178539276
Valid Loss:  0.0026093358173966408
Epoch:  274  	Training Loss: 0.0024549609515815973
Test Loss:  0.002364319283515215
Valid Loss:  0.0026093339547514915
Epoch:  275  	Training Loss: 0.002454959787428379
Test Loss:  0.0023643174208700657
Valid Loss:  0.002609331626445055
Epoch:  276  	Training Loss: 0.002454956993460655
Test Loss:  0.0023643141612410545
Valid Loss:  0.0026093292981386185
Epoch:  277  	Training Loss: 0.0024549560621380806
Test Loss:  0.0023643127642571926
Valid Loss:   56%|█████▌    | 278/500 [03:15<01:45,  2.11it/s] 56%|█████▌    | 280/500 [03:16<01:17,  2.83it/s] 56%|█████▋    | 282/500 [03:22<04:25,  1.22s/it] 57%|█████▋    | 284/500 [03:22<03:08,  1.15it/s] 57%|█████▋    | 286/500 [03:22<02:14,  1.59it/s] 58%|█████▊    | 288/500 [03:22<01:37,  2.17it/s] 58%|█████▊    | 290/500 [03:23<01:11,  2.93it/s] 58%|█████▊    | 292/500 [03:29<04:08,  1.20s/it] 59%|█████▉    | 294/500 [03:29<02:56,  1.17it/s] 59%|█████▉    | 296/500 [03:29<02:06,  1.61it/s] 60%|█████▉    | 298/500 [03:29<01:31,  2.20it/s] 60%|██████    | 300/500 [03:30<01:07,  2.96it/s] 60%|██████    | 302/500 [03:36<03:55,  1.19s/it] 61%|██████    | 304/500 [03:36<02:46,  1.17it/s] 61%|██████    | 306/500 [03:36<01:59,  1.62it/s] 62%|██████▏   | 308/500 [03:36<01:26,  2.21it/s] 62%|██████▏   | 310/500 [03:36<01:03,  2.97it/s] 62%|██████▏   | 312/500 [03:43<03:45,  1.20s/it] 63%|██████▎   | 314/500 [03:43<02:40,  1.16it/s] 63%|██████▎   | 316/500 [03:43<01:54,  1.61it/s] 64%|██████▎   | 318/500 [03:43<01:23,  2.19it/s] 64%|██████▍   | 320/500 [03:43<01:00,  2.95it/s] 64%|██████▍   | 322/500 [03:50<03:29,  1.18s/it] 65%|██████▍   | 324/500 [03:50<02:28,  1.18it/s] 65%|██████▌   | 326/500 [03:50<01:46,  1.64it/s] 66%|██████▌   | 328/500 [03:50<01:16,  2.24it/s] 66%|██████▌   | 330/500 [03:50<00:56,  3.01it/s] 66%|██████▋   | 332/500 [03:57<03:21,  1.20s/it] 67%|██████▋   | 334/500 [03:57<02:22,  1.17it/s] 67%|██████▋   | 336/500 [03:57<01:41,  1.61it/s] 68%|██████▊   | 338/500 [03:57<01:13,  2.20it/s] 68%|██████▊   | 340/500 [03:57<00:54,  2.96it/s] 68%|██████▊   | 342/500 [04:04<03:08,  1.19s/it] 69%|██████▉   | 344/500 [04:04<02:13,  1.17it/s]0.0026093306951224804
Epoch:  278  	Training Loss: 0.002454951871186495
Test Loss:  0.0023643113672733307
Valid Loss:  0.0026093258056789637
Epoch:  279  	Training Loss: 0.002454950474202633
Test Loss:  0.0023643099702894688
Valid Loss:  0.002609324874356389
Epoch:  280  	Training Loss: 0.0024549481458961964
Test Loss:  0.002364308573305607
Valid Loss:  0.0026093237102031708
Epoch:  281  	Training Loss: 0.002454947680234909
Test Loss:  0.0023643067106604576
Valid Loss:  0.002609322080388665
Epoch:  282  	Training Loss: 0.002454945584759116
Test Loss:  0.002364304382354021
Valid Loss:  0.0026093197520822287
Epoch:  283  	Training Loss: 0.0024549446534365416
Test Loss:  0.002364303218200803
Valid Loss:  0.0026093176566064358
Epoch:  284  	Training Loss: 0.002454941626638174
Test Loss:  0.00236430112272501
Valid Loss:  0.0026093157939612865
Epoch:  285  	Training Loss: 0.0024549413938075304
Test Loss:  0.0023642992600798607
Valid Loss:  0.0026093153282999992
Epoch:  286  	Training Loss: 0.002454939065501094
Test Loss:  0.002364298328757286
Valid Loss:  0.00260931346565485
Epoch:  287  	Training Loss: 0.0024549374356865883
Test Loss:  0.002364296931773424
Valid Loss:  0.0026093104388564825
Epoch:  288  	Training Loss: 0.0024549365043640137
Test Loss:  0.0023642948362976313
Valid Loss:  0.0026093097403645515
Epoch:  289  	Training Loss: 0.002454934176057577
Test Loss:  0.002364292973652482
Valid Loss:  0.0026093083433806896
Epoch:  290  	Training Loss: 0.0024549318477511406
Test Loss:  0.002364290878176689
Valid Loss:  0.0026093055494129658
Epoch:  291  	Training Loss: 0.002454930916428566
Test Loss:  0.00236429157666862
Valid Loss:  0.002609304152429104
Epoch:  292  	Training Loss: 0.002454928355291486
Test Loss:  0.002364288317039609
Valid Loss:  0.0026093032211065292
Epoch:  293  	Training Loss: 0.0024549264926463366
Test Loss:  0.002364287618547678
Valid Loss:  0.002609304152429104
Epoch:  294  	Training Loss: 0.002454924862831831
Test Loss:  0.0023642852902412415
Valid Loss:  0.0026093001943081617
Epoch:  295  	Training Loss: 0.002454922767356038
Test Loss:  0.0023642831947654486
Valid Loss:  0.0026092990301549435
Epoch:  296  	Training Loss: 0.0024549211375415325
Test Loss:  0.002364280866459012
Valid Loss:  0.0026092957705259323
Epoch:  297  	Training Loss: 0.0024549192748963833
Test Loss:  0.0023642792366445065
Valid Loss:  0.002609295304864645
Epoch:  298  	Training Loss: 0.0024549178779125214
Test Loss:  0.002364278770983219
Valid Loss:  0.002609295304864645
Epoch:  299  	Training Loss: 0.002454915316775441
Test Loss:  0.0023642750456929207
Valid Loss:  0.002609292045235634
Epoch:  300  	Training Loss: 0.0024549143854528666
Test Loss:  0.0023642750456929207
Valid Loss:  0.0026092887856066227
Epoch:  301  	Training Loss: 0.002454912755638361
Test Loss:  0.0023642736487090588
Valid Loss:  0.0026092887856066227
Epoch:  302  	Training Loss: 0.0024549104273319244
Test Loss:  0.002364272251725197
Valid Loss:  0.002609286457300186
Epoch:  303  	Training Loss: 0.002454908797517419
Test Loss:  0.002364269457757473
Valid Loss:  0.0026092855259776115
Epoch:  304  	Training Loss: 0.002454906702041626
Test Loss:  0.002364266663789749
Valid Loss:  0.0026092841289937496
Epoch:  305  	Training Loss: 0.002454905305057764
Test Loss:  0.0023642645683139563
Valid Loss:  0.0026092827320098877
Epoch:  306  	Training Loss: 0.002454903908073902
Test Loss:  0.002364264102652669
Valid Loss:  0.002609281102195382
Epoch:  307  	Training Loss: 0.0024549015797674656
Test Loss:  0.0023642622400075197
Valid Loss:  0.0026092790067195892
Epoch:  308  	Training Loss: 0.0024549001827836037
Test Loss:  0.002364262007176876
Valid Loss:  0.002609278541058302
Epoch:  309  	Training Loss: 0.002454898087307811
Test Loss:  0.002364262007176876
Valid Loss:  0.002609274350106716
Epoch:  310  	Training Loss: 0.0024548962246626616
Test Loss:  0.0023642596788704395
Valid Loss:  0.0026092727202922106
Epoch:  311  	Training Loss: 0.002454895991832018
Test Loss:  0.002364255953580141
Valid Loss:  0.002609271090477705
Epoch:  312  	Training Loss: 0.002454893896356225
Test Loss:  0.0023642550222575665
Valid Loss:  0.002609269693493843
Epoch:  313  	Training Loss: 0.002454891335219145
Test Loss:  0.0023642536252737045
Valid Loss:  0.002609268296509981
Epoch:  314  	Training Loss: 0.0024548890069127083
Test Loss:  0.002364251296967268
Valid Loss:  0.002609265735372901
Epoch:  315  	Training Loss: 0.0024548880755901337
Test Loss:  0.0023642508313059807
Valid Loss:  0.0026092659682035446
Epoch:  316  	Training Loss: 0.0024548855144530535
Test Loss:  0.0023642475716769695
Valid Loss:  0.002609263639897108
Epoch:  317  	Training Loss: 0.002454883884638548
Test Loss:  0.002364244544878602
Valid Loss:  0.0026092620100826025
Epoch:  318  	Training Loss: 0.0024548827204853296
Test Loss:  0.002364242449402809
Valid Loss:  0.0026092594489455223
Epoch:  319  	Training Loss: 0.002454880392178893
Test Loss:  0.002364241750910878
Valid Loss:  0.002609259681776166
Epoch:  320  	Training Loss: 0.002454879228025675
Test Loss:  0.0023642401210963726
Valid Loss:  0.002609256189316511
Epoch:  321  	Training Loss: 0.0024548773653805256
Test Loss:  0.002364241750910878
Valid Loss:  0.002609254326671362
Epoch:  322  	Training Loss: 0.0024548755027353764
Test Loss:  0.002364239189773798
Valid Loss:  0.002609252231195569
Epoch:  323  	Training Loss: 0.0024548741057515144
Test Loss:  0.002364237792789936
Valid Loss:  0.0026092499028891325
Epoch:  324  	Training Loss: 0.002454872475937009
Test Loss:  0.002364235231652856
Valid Loss:  0.002609246876090765
Epoch:  325  	Training Loss: 0.002454870380461216
Test Loss:  0.0023642340674996376
Valid Loss:  0.002609246177598834
Epoch:  326  	Training Loss: 0.0024548685178160667
Test Loss:  0.0023642333690077066
Valid Loss:  0.0026092450134456158
Epoch:  327  	Training Loss: 0.00245486618950963
Test Loss:  0.0023642308078706264
Valid Loss:  0.0026092445477843285
Epoch:  328  	Training Loss: 0.0024548652581870556
Test Loss:  0.0023642294108867645
Valid Loss:  0.00260924082249403
Epoch:  329  	Training Loss: 0.0024548638612031937
Test Loss:  0.0023642266169190407
Valid Loss:  0.0026092384941875935
Epoch:  330  	Training Loss: 0.0024548613000661135
Test Loss:  0.002364224987104535
Valid Loss:  0.002609238028526306
Epoch:  331  	Training Loss: 0.0024548592045903206
Test Loss:  0.002364222425967455
Valid Loss:  0.002609234768897295
Epoch:  332  	Training Loss: 0.002454857574775815
Test Loss:  0.0023642219603061676
Valid Loss:  0.0026092329062521458
Epoch:  333  	Training Loss: 0.0024548559449613094
Test Loss:  0.0023642187006771564
Valid Loss:  0.002609232673421502
Epoch:  334  	Training Loss: 0.00245485408231616
Test Loss:  0.0023642187006771564
Valid Loss:  0.0026092296466231346
Epoch:  335  	Training Loss: 0.0024548531509935856
Test Loss:  0.0023642173036932945
Valid Loss:  0.002609230810776353
Epoch:  336  	Training Loss: 0.0024548517540097237
Test Loss:  0.0023642166052013636
Valid Loss:  0.0026092277839779854
Epoch:  337  	Training Loss: 0.0024548503570258617
Test Loss:  0.0023642140440642834
Valid Loss:  0.0026092277839779854
Epoch:  338  	Training Loss: 0.0024548484943807125
Test Loss:  0.002364213578402996
Valid Loss:  0.002609224058687687
Epoch:  339  	Training Loss: 0.002454846166074276
Test Loss:  0.0023642112500965595
Valid Loss:  0.0026092217303812504
Epoch:  340  	Training Loss: 0.0024548445362597704
Test Loss:  0.0023642100859433413
Valid Loss:  0.002609220566228032
Epoch:  341  	Training Loss: 0.0024548424407839775
Test Loss:  0.0023642072919756174
Valid Loss:  0.002609219402074814
Epoch:  342  	Training Loss: 0.0024548410438001156
Test Loss:  0.002364207524806261
Valid Loss:  0.00260921660810709
Epoch:  343  	Training Loss: 0.002454838715493679
Test Loss:  0.002364204963669181
Valid Loss:  0.0026092170737683773
Epoch:  344  	Training Loss: 0.00245483685284853
Test Loss:  0.002364203566685319
Valid Loss:  0.0026092135813087225
Epoch:  345  	Training Loss: 0.002454835921525955
Test Loss:  0.0023642005398869514
Valid Loss:  0.002609213814139366
Epoch:  346  	Training Loss: 0.0024548338260501623
Test Loss:  0.002364196814596653
Valid Loss:  0.0026092096231877804 69%|██████▉   | 346/500 [04:04<01:35,  1.61it/s] 70%|██████▉   | 348/500 [04:04<01:08,  2.20it/s] 70%|███████   | 350/500 [04:04<00:50,  2.94it/s] 70%|███████   | 352/500 [04:10<02:57,  1.20s/it] 71%|███████   | 354/500 [04:11<02:05,  1.16it/s] 71%|███████   | 356/500 [04:11<01:29,  1.61it/s] 72%|███████▏  | 358/500 [04:11<01:05,  2.17it/s] 72%|███████▏  | 360/500 [04:11<00:47,  2.93it/s] 72%|███████▏  | 362/500 [04:17<02:44,  1.19s/it] 73%|███████▎  | 364/500 [04:18<01:56,  1.17it/s] 73%|███████▎  | 366/500 [04:18<01:23,  1.61it/s] 74%|███████▎  | 368/500 [04:18<00:59,  2.21it/s] 74%|███████▍  | 370/500 [04:18<00:44,  2.94it/s] 74%|███████▍  | 372/500 [04:24<02:33,  1.20s/it] 75%|███████▍  | 374/500 [04:25<01:48,  1.16it/s] 75%|███████▌  | 376/500 [04:25<01:17,  1.61it/s] 76%|███████▌  | 378/500 [04:25<00:55,  2.20it/s] 76%|███████▌  | 380/500 [04:25<00:40,  2.96it/s] 76%|███████▋  | 382/500 [04:32<02:25,  1.23s/it] 77%|███████▋  | 384/500 [04:32<01:42,  1.13it/s] 77%|███████▋  | 386/500 [04:32<01:13,  1.55it/s] 78%|███████▊  | 388/500 [04:32<00:52,  2.12it/s] 78%|███████▊  | 390/500 [04:32<00:38,  2.86it/s] 78%|███████▊  | 392/500 [04:39<02:10,  1.21s/it] 79%|███████▉  | 394/500 [04:39<01:32,  1.15it/s] 79%|███████▉  | 396/500 [04:39<01:05,  1.59it/s] 80%|███████▉  | 398/500 [04:39<00:46,  2.17it/s] 80%|████████  | 400/500 [04:39<00:34,  2.93it/s] 80%|████████  | 402/500 [04:46<01:58,  1.21s/it] 81%|████████  | 404/500 [04:46<01:23,  1.15it/s] 81%|████████  | 406/500 [04:46<00:59,  1.58it/s] 82%|████████▏ | 408/500 [04:46<00:42,  2.17it/s] 82%|████████▏ | 410/500 [04:46<00:30,  2.91it/s] 82%|████████▏ | 412/500 [04:53<01:45,  1.20s/it] 83%|████████▎ | 414/500 [04:53<01:14,  1.16it/s]
Epoch:  347  	Training Loss: 0.0024548317305743694
Test Loss:  0.0023641963489353657
Valid Loss:  0.0026092070620507
Epoch:  348  	Training Loss: 0.002454830100759864
Test Loss:  0.002364196116104722
Valid Loss:  0.002609207993373275
Epoch:  349  	Training Loss: 0.00245482986792922
Test Loss:  0.0023641937877982855
Valid Loss:  0.0026092042680829763
Epoch:  350  	Training Loss: 0.0024548268411308527
Test Loss:  0.002364193554967642
Valid Loss:  0.0026092026382684708
Epoch:  351  	Training Loss: 0.00245482474565506
Test Loss:  0.0023641898296773434
Valid Loss:  0.002609201241284609
Epoch:  352  	Training Loss: 0.0024548228830099106
Test Loss:  0.0023641898296773434
Valid Loss:  0.002609198447316885
Epoch:  353  	Training Loss: 0.002454821951687336
Test Loss:  0.002364185405895114
Valid Loss:  0.0026091965846717358
Epoch:  354  	Training Loss: 0.002454820554703474
Test Loss:  0.002364183310419321
Valid Loss:  0.002609196351841092
Epoch:  355  	Training Loss: 0.00245481776073575
Test Loss:  0.0023641828447580338
Valid Loss:  0.002609195653349161
Epoch:  356  	Training Loss: 0.002454816596582532
Test Loss:  0.002364182146266103
Valid Loss:  0.0026091942563652992
Epoch:  357  	Training Loss: 0.0024548140354454517
Test Loss:  0.002364180516451597
Valid Loss:  0.0026091900654137135
Epoch:  358  	Training Loss: 0.0024548121728003025
Test Loss:  0.0023641791194677353
Valid Loss:  0.002609189134091139
Epoch:  359  	Training Loss: 0.0024548110086470842
Test Loss:  0.0023641774896532297
Valid Loss:  0.0026091882027685642
Epoch:  360  	Training Loss: 0.0024548089131712914
Test Loss:  0.002364177955314517
Valid Loss:  0.0026091840118169785
Epoch:  361  	Training Loss: 0.0024548072833567858
Test Loss:  0.002364175859838724
Valid Loss:  0.002609183080494404
Epoch:  362  	Training Loss: 0.0024548049550503492
Test Loss:  0.0023641737643629313
Valid Loss:  0.002609181683510542
Epoch:  363  	Training Loss: 0.002454804489389062
Test Loss:  0.0023641709703952074
Valid Loss:  0.0026091807521879673
Epoch:  364  	Training Loss: 0.0024548026267439127
Test Loss:  0.0023641688749194145
Valid Loss:  0.0026091793552041054
Epoch:  365  	Training Loss: 0.002454800298437476
Test Loss:  0.002364166546612978
Valid Loss:  0.002609177026897669
Epoch:  366  	Training Loss: 0.0024547986686229706
Test Loss:  0.0023641653824597597
Valid Loss:  0.0026091746985912323
Epoch:  367  	Training Loss: 0.0024547965731471777
Test Loss:  0.002364163752645254
Valid Loss:  0.0026091733016073704
Epoch:  368  	Training Loss: 0.002454794477671385
Test Loss:  0.002364162588492036
Valid Loss:  0.0026091723702847958
Epoch:  369  	Training Loss: 0.0024547926150262356
Test Loss:  0.002364161191508174
Valid Loss:  0.002609170973300934
Epoch:  370  	Training Loss: 0.0024547907523810863
Test Loss:  0.002364159794524312
Valid Loss:  0.00260916817933321
Epoch:  371  	Training Loss: 0.002454788889735937
Test Loss:  0.0023641567677259445
Valid Loss:  0.0026091679465025663
Epoch:  372  	Training Loss: 0.002454787725582719
Test Loss:  0.0023641549050807953
Valid Loss:  0.0026091639883816242
Epoch:  373  	Training Loss: 0.002454785630106926
Test Loss:  0.002364154439419508
Valid Loss:  0.0026091625913977623
Epoch:  374  	Training Loss: 0.0024547837674617767
Test Loss:  0.002364151645451784
Valid Loss:  0.002609163522720337
Epoch:  375  	Training Loss: 0.002454782370477915
Test Loss:  0.002364150248467922
Valid Loss:  0.0026091602630913258
Epoch:  376  	Training Loss: 0.0024547805078327656
Test Loss:  0.002364148385822773
Valid Loss:  0.002609158866107464
Epoch:  377  	Training Loss: 0.002454779576510191
Test Loss:  0.002364150248467922
Valid Loss:  0.00260915607213974
Epoch:  378  	Training Loss: 0.0024547777138650417
Test Loss:  0.002364145824685693
Valid Loss:  0.0026091563049703836
Epoch:  379  	Training Loss: 0.002454774919897318
Test Loss:  0.0023641460575163364
Valid Loss:  0.00260915607213974
Epoch:  380  	Training Loss: 0.002454774221405387
Test Loss:  0.0023641427978873253
Valid Loss:  0.002609154675155878
Epoch:  381  	Training Loss: 0.0024547716602683067
Test Loss:  0.002364142332226038
Valid Loss:  0.0026091488543897867
Epoch:  382  	Training Loss: 0.002454770030453801
Test Loss:  0.002364139538258314
Valid Loss:  0.0026091481558978558
Epoch:  383  	Training Loss: 0.0024547686334699392
Test Loss:  0.002364138374105096
Valid Loss:  0.0026091448962688446
Epoch:  384  	Training Loss: 0.0024547665379941463
Test Loss:  0.002364136278629303
Valid Loss:  0.0026091444306075573
Epoch:  385  	Training Loss: 0.002454765373840928
Test Loss:  0.002364134881645441
Valid Loss:  0.0026091402396559715
Epoch:  386  	Training Loss: 0.002454763278365135
Test Loss:  0.0023641325533390045
Valid Loss:  0.0026091388426721096
Epoch:  387  	Training Loss: 0.0024547625798732042
Test Loss:  0.002364128828048706
Valid Loss:  0.002609139308333397
Epoch:  388  	Training Loss: 0.0024547604843974113
Test Loss:  0.0023641290608793497
Valid Loss:  0.0026091355830430984
Epoch:  389  	Training Loss: 0.002454757923260331
Test Loss:  0.0023641264997422695
Valid Loss:  0.002609133953228593
Epoch:  390  	Training Loss: 0.0024547565262764692
Test Loss:  0.0023641253355890512
Valid Loss:  0.0026091323234140873
Epoch:  391  	Training Loss: 0.0024547544308006763
Test Loss:  0.0023641237057745457
Valid Loss:  0.002609130460768938
Epoch:  392  	Training Loss: 0.0024547530338168144
Test Loss:  0.002364120911806822
Valid Loss:  0.002609127899631858
Epoch:  393  	Training Loss: 0.0024547502398490906
Test Loss:  0.002364120911806822
Valid Loss:  0.0026091269683092833
Epoch:  394  	Training Loss: 0.002454748610034585
Test Loss:  0.0023641190491616726
Valid Loss:  0.0026091248728334904
Epoch:  395  	Training Loss: 0.002454747911542654
Test Loss:  0.0023641164880245924
Valid Loss:  0.0026091253384947777
Epoch:  396  	Training Loss: 0.0024547455832362175
Test Loss:  0.0023641157895326614
Valid Loss:  0.0026091234758496284
Epoch:  397  	Training Loss: 0.0024547444190829992
Test Loss:  0.0023641150910407305
Valid Loss:  0.0026091227773576975
Epoch:  398  	Training Loss: 0.00245474255643785
Test Loss:  0.002364114159718156
Valid Loss:  0.002609122544527054
Epoch:  399  	Training Loss: 0.0024547406937927008
Test Loss:  0.002364112064242363
Valid Loss:  0.0026091188192367554
Epoch:  400  	Training Loss: 0.002454738598316908
Test Loss:  0.0023641097359359264
Valid Loss:  0.0026091160252690315
Epoch:  401  	Training Loss: 0.0024547369685024023
Test Loss:  0.002364105312153697
Valid Loss:  0.002609114395454526
Epoch:  402  	Training Loss: 0.002454735804349184
Test Loss:  0.002364106010645628
Valid Loss:  0.002609113696962595
Epoch:  403  	Training Loss: 0.002454733941704035
Test Loss:  0.0023641055449843407
Valid Loss:  0.0026091139297932386
Epoch:  404  	Training Loss: 0.0024547316133975983
Test Loss:  0.0023641055449843407
Valid Loss:  0.002609111135825515
Epoch:  405  	Training Loss: 0.0024547302164137363
Test Loss:  0.0023641022853553295
Valid Loss:  0.002609110437333584
Epoch:  406  	Training Loss: 0.0024547278881073
Test Loss:  0.0023640987928956747
Valid Loss:  0.002609109506011009
Epoch:  407  	Training Loss: 0.002454727655276656
Test Loss:  0.002364098560065031
Valid Loss:  0.0026091081090271473
Epoch:  408  	Training Loss: 0.002454724395647645
Test Loss:  0.00236409530043602
Valid Loss:  0.0026091057807207108
Epoch:  409  	Training Loss: 0.002454722300171852
Test Loss:  0.0023640934377908707
Valid Loss:  0.002609101589769125
Epoch:  410  	Training Loss: 0.0024547213688492775
Test Loss:  0.0023640920408070087
Valid Loss:  0.002609100192785263
Epoch:  411  	Training Loss: 0.0024547188077121973
Test Loss:  0.0023640908766537905
Valid Loss:  0.0026090964674949646
Epoch:  412  	Training Loss: 0.002454719040542841
Test Loss:  0.0023640901781618595
Valid Loss:  0.0026090953033417463
Epoch:  413  	Training Loss: 0.00245471578091383
Test Loss:  0.0023640890140086412
Valid Loss:  0.0026090946048498154
Epoch:  414  	Training Loss: 0.002454714383929968
Test Loss:  0.0023640859872102737
Valid Loss:  0.0026090911123901606
Epoch:  415  	Training Loss: 0.0024547120556235313
Test Loss:  0.002364084590226412
Valid Loss:  0.0026090936735272408
 83%|████████▎ | 416/500 [04:59<02:11,  1.57s/it] 84%|████████▎ | 418/500 [04:59<01:31,  1.12s/it] 84%|████████▍ | 420/500 [04:59<01:04,  1.25it/s] 84%|████████▍ | 422/500 [05:06<01:58,  1.52s/it] 85%|████████▍ | 424/500 [05:06<01:22,  1.08s/it] 85%|████████▌ | 426/500 [05:06<00:57,  1.28it/s] 86%|████████▌ | 428/500 [05:06<00:40,  1.77it/s] 86%|████████▌ | 430/500 [05:06<00:28,  2.41it/s] 86%|████████▋ | 432/500 [05:13<01:25,  1.25s/it] 87%|████████▋ | 434/500 [05:13<00:59,  1.12it/s] 87%|████████▋ | 436/500 [05:13<00:41,  1.55it/s] 88%|████████▊ | 438/500 [05:13<00:29,  2.12it/s] 88%|████████▊ | 440/500 [05:13<00:21,  2.85it/s] 88%|████████▊ | 442/500 [05:20<01:09,  1.20s/it] 89%|████████▉ | 444/500 [05:20<00:48,  1.16it/s] 89%|████████▉ | 446/500 [05:20<00:33,  1.61it/s] 90%|████████▉ | 448/500 [05:20<00:23,  2.19it/s] 90%|█████████ | 450/500 [05:20<00:17,  2.93it/s] 90%|█████████ | 452/500 [05:27<00:57,  1.20s/it] 91%|█████████ | 454/500 [05:27<00:39,  1.16it/s] 91%|█████████ | 456/500 [05:27<00:27,  1.61it/s] 92%|█████████▏| 458/500 [05:27<00:19,  2.19it/s] 92%|█████████▏| 460/500 [05:33<00:50,  1.27s/it] 92%|█████████▏| 461/500 [05:40<01:24,  2.18s/it] 93%|█████████▎| 463/500 [05:40<00:54,  1.47s/it] 93%|█████████▎| 465/500 [05:40<00:35,  1.01s/it] 93%|█████████▎| 467/500 [05:40<00:23,  1.39it/s] 94%|█████████▍| 469/500 [05:40<00:16,  1.94it/s] 94%|█████████▍| 471/500 [05:53<01:07,  2.34s/it] 95%|█████████▍| 473/500 [05:53<00:44,  1.65s/it] 95%|█████████▌| 475/500 [05:53<00:29,  1.17s/it] 95%|█████████▌| 477/500 [05:54<00:19,  1.20it/s] 96%|█████████▌| 479/500 [05:54<00:12,  1.66it/s]**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0024547111243009567
Test Loss:  0.0023640827275812626
Valid Loss:  0.0026090899482369423
Epoch:  417  	Training Loss: 0.002454710192978382
Test Loss:  0.002364082494750619
Valid Loss:  0.002609089482575655
Epoch:  418  	Training Loss: 0.0024547099601477385
Test Loss:  0.0023640813305974007
Valid Loss:  0.0026090885512530804
Epoch:  419  	Training Loss: 0.00245470879599452
Test Loss:  0.002364081796258688
Valid Loss:  0.002609089482575655
Epoch:  420  	Training Loss: 0.002454706933349371
Test Loss:  0.0023640808649361134
Valid Loss:  0.002609085524454713
Epoch:  421  	Training Loss: 0.0024547064676880836
Test Loss:  0.002364080399274826
Valid Loss:  0.002609086688607931
Epoch:  422  	Training Loss: 0.002454705536365509
Test Loss:  0.002364080399274826
Valid Loss:  0.002609084825962782
Epoch:  423  	Training Loss: 0.0024547050707042217
Test Loss:  0.0023640792351216078
Valid Loss:  0.002609085990116
Epoch:  424  	Training Loss: 0.002454703440889716
Test Loss:  0.002364076441153884
Valid Loss:  0.0026090836618095636
Epoch:  425  	Training Loss: 0.0024547032080590725
Test Loss:  0.0023640762083232403
Valid Loss:  0.0026090824976563454
Epoch:  426  	Training Loss: 0.0024547020439058542
Test Loss:  0.0023640762083232403
Valid Loss:  0.0026090817991644144
Epoch:  427  	Training Loss: 0.0024547013454139233
Test Loss:  0.0023640752770006657
Valid Loss:  0.002609079238027334
Epoch:  428  	Training Loss: 0.0024547004140913486
Test Loss:  0.0023640752770006657
Valid Loss:  0.0026090762112289667
Epoch:  429  	Training Loss: 0.0024546990171074867
Test Loss:  0.0023640731815248728
Valid Loss:  0.0026090778410434723
Epoch:  430  	Training Loss: 0.002454698784276843
Test Loss:  0.0023640720173716545
Valid Loss:  0.002609077375382185
Epoch:  431  	Training Loss: 0.002454698085784912
Test Loss:  0.00236407108604908
Valid Loss:  0.002609075978398323
Epoch:  432  	Training Loss: 0.0024546971544623375
Test Loss:  0.0023640701547265053
Valid Loss:  0.00260907388292253
Epoch:  433  	Training Loss: 0.0024546957574784756
Test Loss:  0.002364068990573287
Valid Loss:  0.00260907132178545
Epoch:  434  	Training Loss: 0.0024546952918171883
Test Loss:  0.0023640659637749195
Valid Loss:  0.002609070623293519
Epoch:  435  	Training Loss: 0.00245469412766397
Test Loss:  0.002364066895097494
Valid Loss:  0.00260907132178545
Epoch:  436  	Training Loss: 0.0024546929635107517
Test Loss:  0.002364065498113632
Valid Loss:  0.0026090701576322317
Epoch:  437  	Training Loss: 0.002454692032188177
Test Loss:  0.0023640645667910576
Valid Loss:  0.0026090710889548063
Epoch:  438  	Training Loss: 0.002454690635204315
Test Loss:  0.002364065498113632
Valid Loss:  0.0026090703904628754
Epoch:  439  	Training Loss: 0.0024546897038817406
Test Loss:  0.0023640652652829885
Valid Loss:  0.002609068527817726
Epoch:  440  	Training Loss: 0.0024546883068978786
Test Loss:  0.0023640645667910576
Valid Loss:  0.002609068527817726
Epoch:  441  	Training Loss: 0.0024546883068978786
Test Loss:  0.0023640641011297703
Valid Loss:  0.002609068062156439
Epoch:  442  	Training Loss: 0.0024546878412365913
Test Loss:  0.0023640627041459084
Valid Loss:  0.002609067130833864
Epoch:  443  	Training Loss: 0.0024546862114220858
Test Loss:  0.0023640620056539774
Valid Loss:  0.002609065268188715
Epoch:  444  	Training Loss: 0.002454685512930155
Test Loss:  0.0023640613071620464
Valid Loss:  0.002609063871204853
Epoch:  445  	Training Loss: 0.002454685512930155
Test Loss:  0.002364060841500759
Valid Loss:  0.0026090643368661404
Epoch:  446  	Training Loss: 0.0024546838831156492
Test Loss:  0.002364059444516897
Valid Loss:  0.00260906177572906
Epoch:  447  	Training Loss: 0.0024546836502850056
Test Loss:  0.002364057581871748
Valid Loss:  0.00260906177572906
Epoch:  448  	Training Loss: 0.0024546822533011436
Test Loss:  0.0023640564177185297
Valid Loss:  0.0026090587489306927
Epoch:  449  	Training Loss: 0.0024546810891479254
Test Loss:  0.0023640557192265987
Valid Loss:  0.0026090582832694054
Epoch:  450  	Training Loss: 0.0024546803906559944
Test Loss:  0.002364055486395955
Valid Loss:  0.002609057817608118
Epoch:  451  	Training Loss: 0.0024546789936721325
Test Loss:  0.002364053623750806
Valid Loss:  0.0026090582832694054
Epoch:  452  	Training Loss: 0.002454678528010845
Test Loss:  0.002364053390920162
Valid Loss:  0.0026090568862855434
Epoch:  453  	Training Loss: 0.002454678062349558
Test Loss:  0.002364052925258875
Valid Loss:  0.002609056420624256
Epoch:  454  	Training Loss: 0.0024546771310269833
Test Loss:  0.002364050131291151
Valid Loss:  0.002609057817608118
Epoch:  455  	Training Loss: 0.0024546764325350523
Test Loss:  0.0023640491999685764
Valid Loss:  0.002609054557979107
Epoch:  456  	Training Loss: 0.002454675268381834
Test Loss:  0.0023640491999685764
Valid Loss:  0.0026090526953339577
Epoch:  457  	Training Loss: 0.0024546743370592594
Test Loss:  0.0023640496656298637
Valid Loss:  0.002609052462503314
Epoch:  458  	Training Loss: 0.002454673405736685
Test Loss:  0.0023640478029847145
Valid Loss:  0.0026090508326888084
Epoch:  459  	Training Loss: 0.0024546715430915356
Test Loss:  0.0023640464060008526
Valid Loss:  0.0026090508326888084
Epoch:  460  	Training Loss: 0.0024546717759221792
Test Loss:  0.0023640445433557034
Valid Loss:  0.0026090501341968775
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0024546708445996046
Test Loss:  0.0023640443105250597
Valid Loss:  0.002609051764011383
Epoch:  462  	Training Loss: 0.0024546708445996046
Test Loss:  0.0023640431463718414
Valid Loss:  0.002609050367027521
Epoch:  463  	Training Loss: 0.0024546703789383173
Test Loss:  0.002364042215049267
Valid Loss:  0.0026090508326888084
Epoch:  464  	Training Loss: 0.002454669214785099
Test Loss:  0.0023640436120331287
Valid Loss:  0.0026090512983500957
Epoch:  465  	Training Loss: 0.0024546682834625244
Test Loss:  0.002364042680710554
Valid Loss:  0.0026090519968420267
Epoch:  466  	Training Loss: 0.002454667817801237
Test Loss:  0.0023640431463718414
Valid Loss:  0.002609050367027521
Epoch:  467  	Training Loss: 0.002454667817801237
Test Loss:  0.002364043379202485
Valid Loss:  0.0026090494357049465
Epoch:  468  	Training Loss: 0.00245466735213995
Test Loss:  0.0023640436120331287
Valid Loss:  0.0026090494357049465
Epoch:  469  	Training Loss: 0.00245466735213995
Test Loss:  0.002364043379202485
Valid Loss:  0.0026090494357049465
Epoch:  470  	Training Loss: 0.002454667119309306
Test Loss:  0.0023640431463718414
Valid Loss:  0.0026090512983500957
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.002454666653648019
Test Loss:  0.0023640431463718414
Valid Loss:  0.0026090512983500957
Epoch:  472  	Training Loss: 0.0024546654894948006
Test Loss:  0.0023640417493879795
Valid Loss:  0.002609051764011383
Epoch:  473  	Training Loss: 0.0024546657223254442
Test Loss:  0.002364041283726692
Valid Loss:  0.0026090512983500957
Epoch:  474  	Training Loss: 0.002454665955156088
Test Loss:  0.002364041982218623
Valid Loss:  0.002609050599858165
Epoch:  475  	Training Loss: 0.002454665256664157
Test Loss:  0.0023640417493879795
Valid Loss:  0.002609049901366234
Epoch:  476  	Training Loss: 0.002454664558172226
Test Loss:  0.002364041283726692
Valid Loss:  0.002609048504382372
Epoch:  477  	Training Loss: 0.002454664558172226
Test Loss:  0.002364041283726692
Valid Loss:  0.002609049202874303
Epoch:  478  	Training Loss: 0.0024546650238335133
Test Loss:  0.002364041283726692
Valid Loss:  0.00260904966853559
Epoch:  479  	Training Loss: 0.002454664558172226
Test Loss:  0.002364041516557336
Valid Loss:  0.002609050367027521
Epoch:  480  	Training Loss: 0.002454665256664157
Test Loss:  0.002364040818065405
Valid Loss:  0.002609049901366234
**************************************************learning rate decay**************************************************
 96%|█████████▌| 481/500 [06:06<00:43,  2.31s/it] 97%|█████████▋| 483/500 [06:06<00:27,  1.64s/it] 97%|█████████▋| 485/500 [06:13<00:31,  2.08s/it] 97%|█████████▋| 487/500 [06:13<00:19,  1.48s/it] 98%|█████████▊| 489/500 [06:13<00:11,  1.06s/it] 98%|█████████▊| 491/500 [06:26<00:23,  2.66s/it] 99%|█████████▊| 493/500 [06:26<00:13,  1.88s/it] 99%|█████████▉| 495/500 [06:26<00:06,  1.34s/it] 99%|█████████▉| 497/500 [06:26<00:02,  1.04it/s]100%|█████████▉| 499/500 [06:26<00:00,  1.45it/s]100%|██████████| 500/500 [06:33<00:00,  1.27it/s]
Epoch:  481  	Training Loss: 0.002454664558172226
Test Loss:  0.0023640417493879795
Valid Loss:  0.002609050599858165
Epoch:  482  	Training Loss: 0.0024546640925109386
Test Loss:  0.002364040818065405
Valid Loss:  0.0026090508326888084
Epoch:  483  	Training Loss: 0.0024546640925109386
Test Loss:  0.0023640410508960485
Valid Loss:  0.00260904966853559
Epoch:  484  	Training Loss: 0.002454664558172226
Test Loss:  0.002364041283726692
Valid Loss:  0.002609048970043659
Epoch:  485  	Training Loss: 0.002454664558172226
Test Loss:  0.002364040818065405
Valid Loss:  0.002609049901366234
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0024546640925109386
Test Loss:  0.002364041283726692
Valid Loss:  0.00260904966853559
Epoch:  487  	Training Loss: 0.002454663859680295
Test Loss:  0.0023640410508960485
Valid Loss:  0.002609048970043659
Epoch:  488  	Training Loss: 0.002454663859680295
Test Loss:  0.0023640405852347612
Valid Loss:  0.002609048504382372
Epoch:  489  	Training Loss: 0.002454663859680295
Test Loss:  0.002364040818065405
Valid Loss:  0.0026090487372130156
Epoch:  490  	Training Loss: 0.0024546640925109386
Test Loss:  0.0023640398867428303
Valid Loss:  0.002609048970043659
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.002454663859680295
Test Loss:  0.0023640396539121866
Valid Loss:  0.002609048970043659
Epoch:  492  	Training Loss: 0.0024546640925109386
Test Loss:  0.0023640403524041176
Valid Loss:  0.002609048970043659
Epoch:  493  	Training Loss: 0.002454663859680295
Test Loss:  0.0023640403524041176
Valid Loss:  0.002609049202874303
Epoch:  494  	Training Loss: 0.0024546636268496513
Test Loss:  0.002364040119573474
Valid Loss:  0.002609049202874303
Epoch:  495  	Training Loss: 0.0024546640925109386
Test Loss:  0.002364040119573474
Valid Loss:  0.002609048970043659
Epoch:  496  	Training Loss: 0.0024546640925109386
Test Loss:  0.0023640398867428303
Valid Loss:  0.002609048504382372
Epoch:  497  	Training Loss: 0.002454663859680295
Test Loss:  0.002364040119573474
Valid Loss:  0.0026090487372130156
Epoch:  498  	Training Loss: 0.0024546640925109386
Test Loss:  0.0023640398867428303
Valid Loss:  0.002609048970043659
Epoch:  499  	Training Loss: 0.0024546640925109386
Test Loss:  0.0023640396539121866
Valid Loss:  0.002609048504382372
Epoch:  500  	Training Loss: 0.0024546636268496513
Test Loss:  0.0023640398867428303
Valid Loss:  0.002609048504382372
**************************************************learning rate decay**************************************************
seed is  18
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:39,  6.33s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:53,  1.34s/it]  3%|▎         | 13/500 [00:13<07:24,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:20<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:26<12:23,  1.57s/it]  5%|▌         | 27/500 [00:26<08:48,  1.12s/it]  6%|▌         | 29/500 [00:26<06:19,  1.24it/s]  6%|▌         | 31/500 [00:39<19:11,  2.46s/it]  7%|▋         | 33/500 [00:39<13:33,  1.74s/it]  7%|▋         | 35/500 [00:46<16:58,  2.19s/it]  7%|▋         | 37/500 [00:46<12:00,  1.56s/it]  8%|▊         | 39/500 [00:46<08:30,  1.11s/it]  8%|▊         | 41/500 [00:59<20:29,  2.68s/it]  9%|▊         | 43/500 [00:59<14:26,  1.90s/it]  9%|▉         | 45/500 [01:05<17:25,  2.30s/it]  9%|▉         | 47/500 [01:05<12:18,  1.63s/it] 10%|▉         | 49/500 [01:05<08:43,  1.16s/it] 10%|█         | 51/500 [01:18<20:19,  2.71s/it] 11%|█         | 53/500 [01:18<14:20,  1.93s/it] 11%|█         | 55/500 [01:25<17:11,  2.32s/it] 11%|█▏        | 57/500 [01:25<12:08,  1.64s/it] 12%|█▏        | 59/500 [01:25<08:36,  1.17s/it] 12%|█▏        | 61/500 [01:38<19:49,  2.71s/it] 13%|█▎        | 63/500 [01:38<13:57,  1.92s/it] 13%|█▎        | 65/500 [01:44<16:40,  2.30s/it]Epoch:  1  	Training Loss: 0.47964417934417725
Test Loss:  4.048425674438477
Valid Loss:  3.9265687465667725
Epoch:  2  	Training Loss: 4.20053243637085
Test Loss:  0.5853487253189087
Valid Loss:  0.5576927661895752
Epoch:  3  	Training Loss: 0.4876188039779663
Test Loss:  0.5853216648101807
Valid Loss:  0.5576669573783875
Epoch:  4  	Training Loss: 0.48759472370147705
Test Loss:  0.5852944850921631
Valid Loss:  0.5576411485671997
Epoch:  5  	Training Loss: 0.487570583820343
Test Loss:  0.5852673053741455
Valid Loss:  0.557615339756012
Epoch:  6  	Training Loss: 0.4875464141368866
Test Loss:  0.5852400660514832
Valid Loss:  0.5575893521308899
Epoch:  7  	Training Loss: 0.4875222146511078
Test Loss:  0.5852127075195312
Valid Loss:  0.5575634241104126
Epoch:  8  	Training Loss: 0.4874979555606842
Test Loss:  0.5851852893829346
Valid Loss:  0.557537317276001
Epoch:  9  	Training Loss: 0.48747360706329346
Test Loss:  0.5851578712463379
Valid Loss:  0.5575112700462341
Epoch:  10  	Training Loss: 0.4874492287635803
Test Loss:  0.5851303339004517
Valid Loss:  0.5574851036071777
Epoch:  11  	Training Loss: 0.4874247908592224
Test Loss:  0.5851062536239624
Valid Loss:  0.5574646592140198
Epoch:  12  	Training Loss: 0.4874032139778137
Test Loss:  0.5850986242294312
Valid Loss:  0.5574581623077393
Epoch:  13  	Training Loss: 0.48739367723464966
Test Loss:  0.585096538066864
Valid Loss:  0.5574558973312378
Epoch:  14  	Training Loss: 0.487390398979187
Test Loss:  0.5850959420204163
Valid Loss:  0.5574547052383423
Epoch:  15  	Training Loss: 0.4873889088630676
Test Loss:  0.5850957036018372
Valid Loss:  0.5574542284011841
Epoch:  16  	Training Loss: 0.4873882532119751
Test Loss:  0.5850956439971924
Valid Loss:  0.5574541091918945
Epoch:  17  	Training Loss: 0.48738792538642883
Test Loss:  0.5850956439971924
Valid Loss:  0.5574540495872498
Epoch:  18  	Training Loss: 0.4873877167701721
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  19  	Training Loss: 0.48738762736320496
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  20  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.5574540495872498
Epoch:  21  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  22  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  23  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  24  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  25  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  27  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  28  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  29  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  30  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  32  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  33  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  34  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  35  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  37  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  38  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  39  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  40  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  42  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  43  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  44  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  45  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  47  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  48  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  49  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  50  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  52  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  53  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  54  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  55  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  57  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  58  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  59  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  60  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  62  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  63  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  64  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  65  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
 13%|█▎        | 67/500 [01:44<11:48,  1.64s/it] 14%|█▍        | 69/500 [01:44<08:22,  1.17s/it] 14%|█▍        | 71/500 [01:57<19:33,  2.74s/it] 15%|█▍        | 73/500 [01:57<13:46,  1.94s/it] 15%|█▌        | 75/500 [02:04<16:24,  2.32s/it] 15%|█▌        | 77/500 [02:04<11:35,  1.64s/it] 16%|█▌        | 79/500 [02:04<08:13,  1.17s/it] 16%|█▌        | 81/500 [02:17<19:02,  2.73s/it] 17%|█▋        | 83/500 [02:17<13:24,  1.93s/it] 17%|█▋        | 85/500 [02:23<16:00,  2.32s/it] 17%|█▋        | 87/500 [02:24<11:18,  1.64s/it] 18%|█▊        | 89/500 [02:24<08:00,  1.17s/it] 18%|█▊        | 91/500 [02:36<18:28,  2.71s/it] 19%|█▊        | 93/500 [02:36<13:00,  1.92s/it] 19%|█▉        | 95/500 [02:43<15:37,  2.32s/it] 19%|█▉        | 97/500 [02:43<11:02,  1.64s/it] 20%|█▉        | 99/500 [02:43<07:49,  1.17s/it] 20%|██        | 101/500 [02:56<18:05,  2.72s/it] 21%|██        | 103/500 [02:56<12:44,  1.93s/it] 21%|██        | 105/500 [03:02<15:12,  2.31s/it] 21%|██▏       | 107/500 [03:03<10:43,  1.64s/it] 22%|██▏       | 109/500 [03:03<07:35,  1.17s/it] 22%|██▏       | 111/500 [03:15<17:42,  2.73s/it] 23%|██▎       | 113/500 [03:16<12:28,  1.93s/it] 23%|██▎       | 115/500 [03:22<14:49,  2.31s/it] 23%|██▎       | 117/500 [03:22<10:27,  1.64s/it] 24%|██▍       | 119/500 [03:22<07:24,  1.17s/it] 24%|██▍       | 121/500 [03:35<17:18,  2.74s/it] 25%|██▍       | 123/500 [03:35<12:11,  1.94s/it] 25%|██▌       | 125/500 [03:35<08:38,  1.38s/it] 25%|██▌       | 127/500 [03:35<06:08,  1.01it/s]Epoch:  66  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  67  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  68  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  69  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  70  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  72  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  73  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  74  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  75  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  77  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  78  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  79  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  80  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  82  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  83  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  84  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  85  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  87  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  88  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  89  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  90  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  92  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  93  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  94  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  95  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  97  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  98  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  99  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  100  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  102  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  103  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  104  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  105  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  107  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  108  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  109  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  110  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  112  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  113  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  114  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  115  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  117  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  118  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  119  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  120  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  122  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  123  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  124  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  125  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  126  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  127  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  128  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
 26%|██▌       | 129/500 [03:36<04:23,  1.41it/s] 26%|██▌       | 131/500 [03:48<14:41,  2.39s/it] 27%|██▋       | 133/500 [03:48<10:22,  1.70s/it] 27%|██▋       | 135/500 [03:55<13:02,  2.14s/it] 27%|██▋       | 137/500 [03:55<09:11,  1.52s/it] 28%|██▊       | 139/500 [03:55<06:31,  1.08s/it] 28%|██▊       | 141/500 [04:08<15:58,  2.67s/it] 29%|██▊       | 143/500 [04:08<11:14,  1.89s/it] 29%|██▉       | 145/500 [04:15<13:54,  2.35s/it] 29%|██▉       | 147/500 [04:15<09:48,  1.67s/it] 30%|██▉       | 149/500 [04:15<06:57,  1.19s/it] 30%|███       | 151/500 [04:28<16:03,  2.76s/it] 31%|███       | 153/500 [04:28<11:17,  1.95s/it] 31%|███       | 155/500 [04:35<13:29,  2.35s/it] 31%|███▏      | 157/500 [04:35<09:31,  1.67s/it] 32%|███▏      | 159/500 [04:35<06:44,  1.19s/it] 32%|███▏      | 161/500 [04:48<15:28,  2.74s/it] 33%|███▎      | 163/500 [04:48<10:53,  1.94s/it] 33%|███▎      | 165/500 [04:54<13:02,  2.34s/it] 33%|███▎      | 167/500 [04:54<09:11,  1.66s/it] 34%|███▍      | 169/500 [04:55<06:30,  1.18s/it] 34%|███▍      | 171/500 [05:07<14:58,  2.73s/it] 35%|███▍      | 173/500 [05:07<10:32,  1.93s/it] 35%|███▌      | 175/500 [05:14<12:32,  2.31s/it] 35%|███▌      | 177/500 [05:14<08:51,  1.65s/it] 36%|███▌      | 179/500 [05:14<06:16,  1.17s/it] 36%|███▌      | 181/500 [05:27<14:31,  2.73s/it] 37%|███▋      | 183/500 [05:27<10:12,  1.93s/it] 37%|███▋      | 185/500 [05:33<12:11,  2.32s/it] 37%|███▋      | 187/500 [05:34<08:36,  1.65s/it] 38%|███▊      | 189/500 [05:34<06:06,  1.18s/it]Valid Loss:  0.557453989982605
Epoch:  129  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  130  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  132  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  133  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  134  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  135  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  137  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  138  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  139  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  140  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  142  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  143  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  144  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  145  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  147  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  148  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  149  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  150  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  152  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  153  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  154  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  155  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  157  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  158  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  159  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  160  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  162  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  163  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  164  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  165  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  167  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  168  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
Epoch:  169  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  170  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  172  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  173  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  174  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  175  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  177  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  178  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  179  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  180  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  182  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  183  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  184  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  185  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  187  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  188  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  189  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
 38%|███▊      | 191/500 [05:47<14:06,  2.74s/it] 39%|███▊      | 193/500 [05:47<09:55,  1.94s/it] 39%|███▉      | 195/500 [05:53<11:50,  2.33s/it] 39%|███▉      | 197/500 [05:53<08:21,  1.65s/it] 40%|███▉      | 199/500 [05:53<05:54,  1.18s/it] 40%|████      | 201/500 [06:06<13:38,  2.74s/it] 41%|████      | 203/500 [06:06<09:35,  1.94s/it] 41%|████      | 205/500 [06:13<11:22,  2.31s/it] 41%|████▏     | 207/500 [06:13<08:02,  1.65s/it] 42%|████▏     | 209/500 [06:13<05:42,  1.18s/it] 42%|████▏     | 210/500 [06:19<09:55,  2.05s/it] 42%|████▏     | 211/500 [06:26<14:02,  2.92s/it] 43%|████▎     | 213/500 [06:26<08:58,  1.88s/it] 43%|████▎     | 215/500 [06:32<11:06,  2.34s/it] 43%|████▎     | 217/500 [06:32<07:31,  1.59s/it] 44%|████▍     | 219/500 [06:32<05:10,  1.11s/it] 44%|████▍     | 221/500 [06:45<12:39,  2.72s/it] 45%|████▍     | 223/500 [06:45<08:46,  1.90s/it] 45%|████▌     | 225/500 [06:51<10:29,  2.29s/it] 45%|████▌     | 227/500 [06:52<07:20,  1.61s/it] 46%|████▌     | 229/500 [06:52<05:10,  1.14s/it] 46%|████▌     | 231/500 [06:58<07:52,  1.76s/it] 47%|████▋     | 233/500 [06:58<05:33,  1.25s/it] 47%|████▋     | 235/500 [07:05<08:07,  1.84s/it] 47%|████▋     | 237/500 [07:05<05:43,  1.31s/it] 48%|████▊     | 239/500 [07:05<04:03,  1.07it/s] 48%|████▊     | 241/500 [07:18<11:02,  2.56s/it] 49%|████▊     | 243/500 [07:18<07:45,  1.81s/it] 49%|████▉     | 245/500 [07:24<09:25,  2.22s/it] 49%|████▉     | 247/500 [07:24<06:37,  1.57s/it] 50%|████▉     | 249/500 [07:24<04:41,  1.12s/it]Epoch:  190  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  192  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  193  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  194  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  195  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  197  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  198  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
Epoch:  199  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  200  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  202  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  203  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  204  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  205  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  207  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  208  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  209  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  210  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  212  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  213  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  214  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  215  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  217  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  218  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.5574540495872498
Epoch:  219  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  220  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  222  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  223  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  224  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  225  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
Epoch:  227  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  228  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  229  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  230  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  231  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  232  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  233  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  234  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  235  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  237  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  238  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  239  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  240  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  242  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  243  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  244  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  245  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  247  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  248  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  249  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  250  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
 50%|█████     | 251/500 [07:37<11:03,  2.66s/it] 51%|█████     | 253/500 [07:37<07:45,  1.89s/it] 51%|█████     | 255/500 [07:43<09:15,  2.27s/it] 51%|█████▏    | 257/500 [07:43<06:31,  1.61s/it] 52%|█████▏    | 259/500 [07:44<04:37,  1.15s/it] 52%|█████▏    | 261/500 [07:56<10:41,  2.69s/it] 53%|█████▎    | 263/500 [07:56<07:30,  1.90s/it] 53%|█████▎    | 265/500 [08:03<08:57,  2.29s/it] 53%|█████▎    | 267/500 [08:03<06:17,  1.62s/it] 54%|█████▍    | 269/500 [08:03<04:26,  1.15s/it] 54%|█████▍    | 271/500 [08:16<10:29,  2.75s/it] 55%|█████▍    | 273/500 [08:16<07:21,  1.94s/it] 55%|█████▌    | 275/500 [08:22<08:36,  2.30s/it] 55%|█████▌    | 277/500 [08:22<06:03,  1.63s/it] 56%|█████▌    | 279/500 [08:22<04:16,  1.16s/it] 56%|█████▌    | 281/500 [08:35<09:50,  2.70s/it] 57%|█████▋    | 283/500 [08:35<06:54,  1.91s/it] 57%|█████▋    | 285/500 [08:42<08:23,  2.34s/it] 57%|█████▋    | 287/500 [08:42<05:53,  1.66s/it] 58%|█████▊    | 289/500 [08:42<04:09,  1.18s/it] 58%|█████▊    | 291/500 [08:55<09:23,  2.70s/it] 59%|█████▊    | 293/500 [08:55<06:34,  1.91s/it] 59%|█████▉    | 295/500 [09:01<07:48,  2.28s/it] 59%|█████▉    | 297/500 [09:01<05:29,  1.62s/it] 60%|█████▉    | 299/500 [09:01<03:52,  1.16s/it] 60%|██████    | 301/500 [09:08<05:47,  1.75s/it] 61%|██████    | 303/500 [09:08<04:04,  1.24s/it] 61%|██████    | 305/500 [09:14<05:56,  1.83s/it] 61%|██████▏   | 307/500 [09:14<04:10,  1.30s/it] 62%|██████▏   | 309/500 [09:14<02:57,  1.08it/s] 62%|██████▏   | 311/500 [09:27<08:02,  2.55s/it]Epoch:  251  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  252  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  253  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  254  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  255  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  257  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  258  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  259  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  260  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  262  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  263  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  264  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  265  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  267  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  268  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  269  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  270  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  272  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  273  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  274  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  275  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  277  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  278  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  279  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  280  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  282  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  283  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  284  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  285  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  287  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  288  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  289  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  290  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  292  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  293  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  294  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  295  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  297  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  298  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
Epoch:  299  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  300  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  301  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  302  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  303  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  304  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  305  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  307  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  308  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  309  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  310  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  312  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
 63%|██████▎   | 313/500 [09:27<05:38,  1.81s/it] 63%|██████▎   | 315/500 [09:33<06:48,  2.21s/it] 63%|██████▎   | 317/500 [09:34<04:46,  1.57s/it] 64%|██████▍   | 319/500 [09:34<03:22,  1.12s/it] 64%|██████▍   | 321/500 [09:46<07:58,  2.67s/it] 65%|██████▍   | 323/500 [09:47<05:34,  1.89s/it] 65%|██████▌   | 325/500 [09:53<06:37,  2.27s/it] 65%|██████▌   | 327/500 [09:53<04:38,  1.61s/it] 66%|██████▌   | 329/500 [09:53<03:16,  1.15s/it] 66%|██████▌   | 331/500 [10:06<07:33,  2.69s/it] 67%|██████▋   | 333/500 [10:06<05:17,  1.90s/it] 67%|██████▋   | 335/500 [10:12<06:17,  2.29s/it] 67%|██████▋   | 337/500 [10:12<04:24,  1.62s/it] 68%|██████▊   | 339/500 [10:12<03:06,  1.16s/it] 68%|██████▊   | 341/500 [10:25<07:07,  2.69s/it] 69%|██████▊   | 343/500 [10:25<04:58,  1.90s/it] 69%|██████▉   | 345/500 [10:31<05:51,  2.27s/it] 69%|██████▉   | 347/500 [10:32<04:06,  1.61s/it] 70%|██████▉   | 349/500 [10:32<02:53,  1.15s/it] 70%|███████   | 351/500 [10:44<06:43,  2.71s/it] 71%|███████   | 353/500 [10:44<04:41,  1.92s/it] 71%|███████   | 355/500 [10:51<05:31,  2.28s/it] 71%|███████▏  | 357/500 [10:51<03:51,  1.62s/it] 72%|███████▏  | 359/500 [10:51<02:42,  1.15s/it] 72%|███████▏  | 361/500 [11:03<06:09,  2.66s/it] 73%|███████▎  | 363/500 [11:04<04:18,  1.89s/it] 73%|███████▎  | 365/500 [11:10<05:13,  2.32s/it] 73%|███████▎  | 367/500 [11:10<03:38,  1.65s/it] 74%|███████▍  | 369/500 [11:11<02:33,  1.17s/it] 74%|███████▍  | 369/500 [11:21<02:33,  1.17s/it] 74%|███████▍  | 371/500 [11:23<05:50,  2.72s/it] 75%|███████▍  | 373/500 [11:23<04:04,  1.92s/it]Epoch:  313  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  314  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  315  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  317  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  318  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  319  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  320  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  322  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  323  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  324  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  325  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  327  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  328  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  329  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  330  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  332  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  333  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  334  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  335  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  337  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  338  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  339  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  340  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  342  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  343  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  344  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  345  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  347  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  348  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  349  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  350  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  352  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  353  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  354  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
Epoch:  355  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  357  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  358  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  359  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  360  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  362  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  363  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  364  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  365  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  367  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  368  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  369  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  370  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  372  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  373  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
 75%|███████▌  | 375/500 [11:30<04:46,  2.29s/it] 75%|███████▌  | 377/500 [11:30<03:20,  1.63s/it] 76%|███████▌  | 379/500 [11:30<02:20,  1.16s/it] 76%|███████▌  | 379/500 [11:41<02:20,  1.16s/it] 76%|███████▌  | 381/500 [11:42<05:17,  2.67s/it] 77%|███████▋  | 383/500 [11:42<03:41,  1.89s/it] 77%|███████▋  | 385/500 [11:49<04:22,  2.28s/it] 77%|███████▋  | 387/500 [11:49<03:03,  1.62s/it] 78%|███████▊  | 389/500 [11:49<02:08,  1.15s/it] 78%|███████▊  | 389/500 [12:01<02:08,  1.15s/it] 78%|███████▊  | 391/500 [12:02<04:51,  2.67s/it] 79%|███████▊  | 393/500 [12:02<03:22,  1.89s/it] 79%|███████▉  | 395/500 [12:08<03:59,  2.28s/it] 79%|███████▉  | 397/500 [12:08<02:46,  1.61s/it] 80%|███████▉  | 399/500 [12:08<01:56,  1.15s/it] 80%|███████▉  | 399/500 [12:21<01:56,  1.15s/it] 80%|████████  | 401/500 [12:21<04:27,  2.70s/it] 81%|████████  | 403/500 [12:21<03:05,  1.91s/it] 81%|████████  | 405/500 [12:27<03:37,  2.29s/it] 81%|████████▏ | 407/500 [12:28<02:30,  1.62s/it] 82%|████████▏ | 409/500 [12:28<01:45,  1.16s/it] 82%|████████▏ | 411/500 [12:40<04:00,  2.70s/it] 83%|████████▎ | 413/500 [12:40<02:46,  1.91s/it] 83%|████████▎ | 415/500 [12:47<03:15,  2.30s/it] 83%|████████▎ | 417/500 [12:47<02:15,  1.64s/it] 84%|████████▍ | 419/500 [12:47<01:34,  1.16s/it] 84%|████████▍ | 421/500 [13:00<03:33,  2.70s/it] 85%|████████▍ | 423/500 [13:00<02:27,  1.91s/it] 85%|████████▌ | 425/500 [13:06<02:52,  2.30s/it] 85%|████████▌ | 427/500 [13:06<01:58,  1.63s/it] 86%|████████▌ | 429/500 [13:07<01:22,  1.16s/it] 86%|████████▌ | 431/500 [13:19<03:05,  2.68s/it] 87%|████████▋ | 433/500 [13:19<02:07,  1.90s/it]Epoch:  374  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  375  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  377  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  378  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  379  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  380  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  382  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  383  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  384  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  385  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  387  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  388  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  389  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  390  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  392  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  393  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  394  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  395  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  397  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  398  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  399  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  400  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  402  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  403  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  404  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  405  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  407  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  408  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  409  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  410  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  412  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  413  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.5574540495872498
Epoch:  414  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  415  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  417  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  418  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  419  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  420  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  422  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  423  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  424  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  425  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  427  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  428  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  429  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  430  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
Epoch:  432  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  433  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  434  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
 87%|████████▋ | 435/500 [13:26<02:32,  2.34s/it] 87%|████████▋ | 437/500 [13:26<01:44,  1.67s/it] 88%|████████▊ | 439/500 [13:26<01:12,  1.19s/it] 88%|████████▊ | 441/500 [13:39<02:42,  2.75s/it] 89%|████████▊ | 443/500 [13:39<01:50,  1.95s/it] 89%|████████▉ | 445/500 [13:45<02:06,  2.31s/it] 89%|████████▉ | 447/500 [13:46<01:26,  1.64s/it] 90%|████████▉ | 449/500 [13:46<00:59,  1.16s/it] 90%|█████████ | 451/500 [13:58<02:11,  2.69s/it] 91%|█████████ | 453/500 [13:58<01:29,  1.90s/it] 91%|█████████ | 455/500 [14:05<01:42,  2.28s/it] 91%|█████████▏| 457/500 [14:05<01:09,  1.62s/it] 92%|█████████▏| 459/500 [14:05<00:47,  1.15s/it] 92%|█████████▏| 461/500 [14:18<01:48,  2.78s/it] 93%|█████████▎| 463/500 [14:18<01:12,  1.96s/it] 93%|█████████▎| 465/500 [14:25<01:21,  2.32s/it] 93%|█████████▎| 467/500 [14:25<00:54,  1.65s/it] 94%|█████████▍| 469/500 [14:25<00:36,  1.17s/it] 94%|█████████▍| 471/500 [14:37<01:18,  2.71s/it] 95%|█████████▍| 473/500 [14:38<00:51,  1.92s/it] 95%|█████████▌| 475/500 [14:44<00:57,  2.29s/it] 95%|█████████▌| 477/500 [14:44<00:37,  1.62s/it] 96%|█████████▌| 479/500 [14:44<00:24,  1.15s/it] 96%|█████████▌| 481/500 [14:57<00:51,  2.73s/it] 97%|█████████▋| 483/500 [14:57<00:32,  1.93s/it] 97%|█████████▋| 485/500 [15:03<00:34,  2.31s/it] 97%|█████████▋| 487/500 [15:04<00:21,  1.64s/it] 98%|█████████▊| 489/500 [15:04<00:12,  1.17s/it] 98%|█████████▊| 491/500 [15:17<00:25,  2.79s/it] 99%|█████████▊| 493/500 [15:17<00:13,  1.98s/it]Epoch:  435  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  437  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  438  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  439  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  440  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  442  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  443  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  444  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  445  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  447  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  448  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  449  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  450  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  452  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  453  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  454  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  455  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  457  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  458  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  459  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  460  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  462  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  463  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  464  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  465  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  467  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  468  	Training Loss: 0.48738759756088257
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  469  	Training Loss: 0.48738759756088257
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  470  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  472  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  473  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  474  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  475  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
Epoch:  477  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  478  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  479  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  480  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  482  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  483  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  484  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  485  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  487  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  488  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  489  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.5574540495872498
Epoch:  490  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  492  	Training Loss: 0.4873875379562378
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
Epoch:  493  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  494  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  495  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955843925476
Valid Loss:  0.557453989982605
 99%|█████████▉| 495/500 [15:24<00:11,  2.37s/it] 99%|█████████▉| 497/500 [15:24<00:05,  1.68s/it]100%|█████████▉| 499/500 [15:24<00:01,  1.20s/it]100%|██████████| 500/500 [15:31<00:00,  1.86s/it]
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.4873875677585602
Test Loss:  0.5850955247879028
Valid Loss:  0.557453989982605
Epoch:  497  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  498  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  499  	Training Loss: 0.4873875379562378
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
Epoch:  500  	Training Loss: 0.4873875677585602
Test Loss:  0.5850956439971924
Valid Loss:  0.557453989982605
**************************************************learning rate decay**************************************************
seed is  19
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<55:49,  6.71s/it]  1%|          | 3/500 [00:06<14:48,  1.79s/it]  1%|          | 5/500 [00:06<07:26,  1.11it/s]  1%|▏         | 7/500 [00:07<04:29,  1.83it/s]  2%|▏         | 9/500 [00:07<02:59,  2.74it/s]  2%|▏         | 11/500 [00:13<11:03,  1.36s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:20<13:25,  1.66s/it]  3%|▎         | 17/500 [00:20<09:19,  1.16s/it]  4%|▍         | 19/500 [00:20<06:34,  1.22it/s]  4%|▍         | 21/500 [00:32<19:40,  2.46s/it]  5%|▍         | 23/500 [00:32<13:47,  1.73s/it]  5%|▌         | 25/500 [00:39<17:16,  2.18s/it]  5%|▌         | 27/500 [00:39<12:10,  1.54s/it]  6%|▌         | 29/500 [00:39<08:52,  1.13s/it]  6%|▌         | 30/500 [00:46<16:13,  2.07s/it]  6%|▌         | 31/500 [00:52<22:51,  2.92s/it]  7%|▋         | 33/500 [00:52<14:37,  1.88s/it]  7%|▋         | 35/500 [00:58<17:49,  2.30s/it]  7%|▋         | 37/500 [00:59<12:05,  1.57s/it]  8%|▊         | 39/500 [00:59<08:20,  1.09s/it]  8%|▊         | 41/500 [01:11<20:42,  2.71s/it]  9%|▊         | 43/500 [01:11<14:24,  1.89s/it]  9%|▉         | 45/500 [01:18<17:14,  2.27s/it]  9%|▉         | 47/500 [01:18<12:05,  1.60s/it] 10%|▉         | 49/500 [01:18<08:32,  1.14s/it] 10%|█         | 51/500 [01:30<19:56,  2.66s/it] 11%|█         | 53/500 [01:30<14:01,  1.88s/it] 11%|█         | 55/500 [01:37<16:59,  2.29s/it] 11%|█▏        | 57/500 [01:37<11:59,  1.62s/it] 12%|█▏        | 59/500 [01:37<08:29,  1.16s/it] 12%|█▏        | 61/500 [01:50<19:29,  2.66s/it]Epoch:  1  	Training Loss: 0.03900011256337166
Test Loss:  1.0715869665145874
Valid Loss:  1.0782315731048584
Epoch:  2  	Training Loss: 1.1048078536987305
Test Loss:  7.501903533935547
Valid Loss:  7.091712474822998
Epoch:  3  	Training Loss: 7.085400581359863
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  4  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  5  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  6  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  7  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  8  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  9  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  10  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  11  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  12  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  13  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  14  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  15  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  17  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  18  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  19  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  20  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  22  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  23  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  24  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  25  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  27  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801060795784
Epoch:  28  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  29  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  30  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  32  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  33  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  34  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  35  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  37  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  38  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  39  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  40  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  42  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  43  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  44  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  45  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  47  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  48  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  49  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  50  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  52  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  53  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  54  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  55  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  57  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  58  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  59  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  60  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  62  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:   13%|█▎        | 63/500 [01:50<13:43,  1.88s/it] 13%|█▎        | 65/500 [01:56<16:27,  2.27s/it] 13%|█▎        | 67/500 [01:56<11:36,  1.61s/it] 14%|█▍        | 69/500 [01:56<08:13,  1.15s/it] 14%|█▍        | 71/500 [02:09<19:01,  2.66s/it] 15%|█▍        | 73/500 [02:09<13:24,  1.88s/it] 15%|█▌        | 75/500 [02:15<15:56,  2.25s/it] 15%|█▌        | 77/500 [02:15<11:15,  1.60s/it] 16%|█▌        | 79/500 [02:15<07:58,  1.14s/it] 16%|█▌        | 81/500 [02:28<18:36,  2.66s/it] 17%|█▋        | 83/500 [02:28<13:05,  1.88s/it] 17%|█▋        | 85/500 [02:28<09:14,  1.34s/it] 17%|█▋        | 87/500 [02:28<06:34,  1.05it/s] 18%|█▊        | 89/500 [02:28<04:42,  1.45it/s] 18%|█▊        | 91/500 [02:41<16:47,  2.46s/it] 19%|█▊        | 93/500 [02:42<11:51,  1.75s/it] 19%|█▉        | 95/500 [02:49<15:24,  2.28s/it] 19%|█▉        | 97/500 [02:49<10:52,  1.62s/it] 20%|█▉        | 99/500 [02:49<07:42,  1.15s/it] 20%|██        | 101/500 [03:01<17:52,  2.69s/it] 21%|██        | 103/500 [03:02<12:34,  1.90s/it] 21%|██        | 105/500 [03:08<15:05,  2.29s/it] 21%|██▏       | 107/500 [03:08<10:38,  1.62s/it] 22%|██▏       | 109/500 [03:08<07:32,  1.16s/it] 22%|██▏       | 111/500 [03:21<17:28,  2.69s/it] 23%|██▎       | 113/500 [03:21<12:18,  1.91s/it] 23%|██▎       | 115/500 [03:28<14:58,  2.33s/it] 23%|██▎       | 117/500 [03:28<10:33,  1.65s/it] 24%|██▍       | 119/500 [03:28<07:28,  1.18s/it] 24%|██▍       | 121/500 [03:40<16:59,  2.69s/it]0.05355801433324814
Epoch:  63  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  64  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  65  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  67  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  68  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  69  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  70  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.042029641568660736
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  72  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  73  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801805853844
Epoch:  74  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801805853844
Epoch:  75  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  77  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  78  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  79  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  80  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  82  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  83  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  84  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  85  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  86  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  87  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  88  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  89  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  90  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  92  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  93  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  94  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  95  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  97  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  98  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  99  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  100  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  102  	Training Loss: 0.042029641568660736
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  103  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  104  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  105  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  107  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  108  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  109  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  110  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  112  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  113  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  114  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  115  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  117  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  118  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  119  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  120  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  122  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
 25%|██▍       | 123/500 [03:40<11:58,  1.90s/it] 25%|██▌       | 125/500 [03:47<14:37,  2.34s/it] 25%|██▌       | 127/500 [03:47<10:19,  1.66s/it] 26%|██▌       | 129/500 [03:47<07:18,  1.18s/it] 26%|██▌       | 131/500 [04:01<17:38,  2.87s/it] 27%|██▋       | 133/500 [04:01<12:24,  2.03s/it] 27%|██▋       | 135/500 [04:08<14:51,  2.44s/it] 27%|██▋       | 137/500 [04:08<10:27,  1.73s/it] 28%|██▊       | 139/500 [04:08<07:24,  1.23s/it] 28%|██▊       | 141/500 [04:21<16:16,  2.72s/it] 29%|██▊       | 143/500 [04:21<11:26,  1.92s/it] 29%|██▉       | 145/500 [04:27<13:32,  2.29s/it] 29%|██▉       | 147/500 [04:27<09:32,  1.62s/it] 30%|██▉       | 149/500 [04:27<06:45,  1.16s/it] 30%|███       | 151/500 [04:40<15:34,  2.68s/it] 31%|███       | 153/500 [04:40<10:57,  1.90s/it] 31%|███       | 155/500 [04:46<13:14,  2.30s/it] 31%|███▏      | 157/500 [04:47<09:20,  1.63s/it] 32%|███▏      | 159/500 [04:47<06:36,  1.16s/it] 32%|███▏      | 161/500 [04:59<15:24,  2.73s/it] 33%|███▎      | 163/500 [05:00<10:50,  1.93s/it] 33%|███▎      | 165/500 [05:06<12:46,  2.29s/it] 33%|███▎      | 167/500 [05:06<09:00,  1.62s/it] 34%|███▍      | 169/500 [05:06<06:22,  1.16s/it] 34%|███▍      | 171/500 [05:19<15:19,  2.80s/it] 35%|███▍      | 173/500 [05:20<10:46,  1.98s/it] 35%|███▌      | 175/500 [05:26<12:54,  2.38s/it] 35%|███▌      | 177/500 [05:26<09:05,  1.69s/it] 36%|███▌      | 179/500 [05:26<06:25,  1.20s/it] 36%|███▌      | 181/500 [05:39<14:43,  2.77s/it]Epoch:  123  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  124  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  125  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  127  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  128  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  129  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  130  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  132  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  133  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  134  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  135  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  137  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  138  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  139  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  140  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  142  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  143  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  144  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  145  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  147  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  148  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  149  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  150  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  152  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  153  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  154  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  155  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  157  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  158  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  159  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  160  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  162  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  163  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  164  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  165  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  167  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  168  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  169  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  170  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  172  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  173  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  174  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  175  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  177  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  178  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  179  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  180  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
 37%|███▋      | 183/500 [05:39<10:20,  1.96s/it] 37%|███▋      | 185/500 [05:46<12:11,  2.32s/it] 37%|███▋      | 187/500 [05:46<08:35,  1.65s/it] 38%|███▊      | 189/500 [05:46<06:04,  1.17s/it] 38%|███▊      | 191/500 [05:59<13:50,  2.69s/it] 39%|███▊      | 193/500 [05:59<09:44,  1.90s/it] 39%|███▉      | 195/500 [06:05<11:57,  2.35s/it] 39%|███▉      | 197/500 [06:06<08:25,  1.67s/it] 40%|███▉      | 199/500 [06:06<05:57,  1.19s/it] 40%|████      | 201/500 [06:18<13:27,  2.70s/it] 41%|████      | 203/500 [06:18<09:28,  1.91s/it] 41%|████      | 205/500 [06:25<11:09,  2.27s/it] 41%|████▏     | 207/500 [06:25<07:51,  1.61s/it] 42%|████▏     | 209/500 [06:25<05:33,  1.15s/it] 42%|████▏     | 211/500 [06:37<12:55,  2.68s/it] 43%|████▎     | 213/500 [06:38<09:05,  1.90s/it] 43%|████▎     | 215/500 [06:44<10:45,  2.27s/it] 43%|████▎     | 217/500 [06:44<07:36,  1.61s/it] 44%|████▍     | 219/500 [06:44<05:24,  1.15s/it] 44%|████▍     | 221/500 [06:57<12:44,  2.74s/it] 45%|████▍     | 223/500 [06:57<08:57,  1.94s/it] 45%|████▌     | 225/500 [07:03<10:32,  2.30s/it] 45%|████▌     | 227/500 [07:04<07:25,  1.63s/it] 46%|████▌     | 229/500 [07:04<05:14,  1.16s/it] 46%|████▌     | 229/500 [07:14<05:14,  1.16s/it] 46%|████▌     | 231/500 [07:16<12:09,  2.71s/it] 47%|████▋     | 233/500 [07:16<08:32,  1.92s/it] 47%|████▋     | 235/500 [07:23<10:03,  2.28s/it] 47%|████▋     | 237/500 [07:23<07:04,  1.61s/it] 48%|████▊     | 239/500 [07:23<05:00,  1.15s/it]Epoch:  182  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  183  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  184  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  185  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  187  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  188  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  189  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  190  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  192  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  193  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  194  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  195  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  197  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  198  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  199  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  200  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  202  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  203  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  204  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  205  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  207  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  208  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  209  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  210  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  212  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  213  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  214  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  215  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  217  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  218  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  219  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  220  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  222  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  223  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  224  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  225  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  227  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  228  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  229  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  230  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  232  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  233  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  234  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  235  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  237  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  238  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  239  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  240  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
 48%|████▊     | 239/500 [07:34<05:00,  1.15s/it] 48%|████▊     | 241/500 [07:35<11:33,  2.68s/it] 49%|████▊     | 243/500 [07:36<08:06,  1.89s/it] 49%|████▉     | 245/500 [07:42<09:38,  2.27s/it] 49%|████▉     | 247/500 [07:42<06:46,  1.61s/it] 50%|████▉     | 249/500 [07:42<04:47,  1.14s/it] 50%|████▉     | 249/500 [07:54<04:47,  1.14s/it] 50%|█████     | 251/500 [07:55<11:06,  2.68s/it] 51%|█████     | 253/500 [07:55<07:47,  1.89s/it] 51%|█████     | 255/500 [08:01<09:14,  2.26s/it] 51%|█████▏    | 257/500 [08:01<06:30,  1.61s/it] 52%|█████▏    | 259/500 [08:01<04:35,  1.14s/it] 52%|█████▏    | 261/500 [08:14<10:34,  2.65s/it] 53%|█████▎    | 263/500 [08:14<07:25,  1.88s/it] 53%|█████▎    | 265/500 [08:20<08:47,  2.24s/it] 53%|█████▎    | 267/500 [08:20<06:10,  1.59s/it] 54%|█████▍    | 269/500 [08:20<04:21,  1.13s/it] 54%|█████▍    | 269/500 [08:34<04:21,  1.13s/it] 54%|█████▍    | 271/500 [08:34<10:51,  2.85s/it] 55%|█████▍    | 273/500 [08:34<07:37,  2.01s/it] 55%|█████▌    | 275/500 [08:40<08:49,  2.35s/it] 55%|█████▌    | 277/500 [08:41<06:13,  1.67s/it] 56%|█████▌    | 279/500 [08:41<04:24,  1.20s/it] 56%|█████▌    | 281/500 [08:54<10:06,  2.77s/it] 57%|█████▋    | 283/500 [08:54<07:04,  1.96s/it] 57%|█████▋    | 285/500 [09:00<08:26,  2.36s/it] 57%|█████▋    | 287/500 [09:00<05:56,  1.67s/it] 58%|█████▊    | 289/500 [09:01<04:12,  1.20s/it] 58%|█████▊    | 291/500 [09:14<09:46,  2.81s/it] 59%|█████▊    | 293/500 [09:14<06:51,  1.99s/it] 59%|█████▉    | 295/500 [09:21<08:12,  2.40s/it] 59%|█████▉    | 296/500 [09:21<06:47,  2.00s/it] 60%|█████▉    | 298/500 [09:21<04:32,  1.35s/it]Epoch:  241  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  242  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  243  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  244  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  245  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  247  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  248  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  249  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  250  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  252  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  253  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  254  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  255  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  257  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  258  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  259  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  260  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  262  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  263  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  264  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  265  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  267  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  268  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  269  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  270  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  272  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  273  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  274  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  275  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  277  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  278  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  279  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  280  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  282  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  283  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  284  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  285  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  287  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  288  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  289  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  290  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  292  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  293  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  294  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  295  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  297  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  298  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  299  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  300  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
 60%|██████    | 300/500 [09:28<06:53,  2.07s/it] 60%|██████    | 301/500 [09:35<09:42,  2.93s/it] 61%|██████    | 303/500 [09:35<06:19,  1.93s/it] 61%|██████    | 305/500 [09:41<07:31,  2.31s/it] 61%|██████▏   | 307/500 [09:41<05:07,  1.59s/it] 62%|██████▏   | 309/500 [09:41<03:32,  1.11s/it] 62%|██████▏   | 311/500 [09:54<08:27,  2.69s/it] 63%|██████▎   | 313/500 [09:54<05:52,  1.89s/it] 63%|██████▎   | 315/500 [10:01<07:16,  2.36s/it] 63%|██████▎   | 317/500 [10:01<05:05,  1.67s/it] 64%|██████▍   | 319/500 [10:01<03:34,  1.18s/it] 64%|██████▍   | 319/500 [10:14<03:34,  1.18s/it] 64%|██████▍   | 321/500 [10:14<08:32,  2.86s/it] 65%|██████▍   | 323/500 [10:15<05:57,  2.02s/it] 65%|██████▌   | 325/500 [10:22<07:18,  2.50s/it] 65%|██████▌   | 327/500 [10:22<05:07,  1.78s/it] 66%|██████▌   | 329/500 [10:22<03:37,  1.27s/it] 66%|██████▌   | 330/500 [10:28<06:05,  2.15s/it] 66%|██████▌   | 331/500 [10:35<08:32,  3.03s/it] 67%|██████▋   | 333/500 [10:35<05:25,  1.95s/it] 67%|██████▋   | 335/500 [10:42<06:37,  2.41s/it] 67%|██████▋   | 337/500 [10:42<04:27,  1.64s/it] 68%|██████▊   | 339/500 [10:42<03:03,  1.14s/it] 68%|██████▊   | 339/500 [10:54<03:03,  1.14s/it] 68%|██████▊   | 341/500 [10:54<07:12,  2.72s/it] 69%|██████▊   | 343/500 [10:54<04:58,  1.90s/it] 69%|██████▉   | 345/500 [11:01<05:52,  2.28s/it] 69%|██████▉   | 347/500 [11:01<04:05,  1.61s/it] 70%|██████▉   | 349/500 [11:01<02:51,  1.14s/it] 70%|███████   | 351/500 [11:13<06:37,  2.66s/it] 71%|███████   | 353/500 [11:14<04:37,  1.89s/it] 71%|███████   | 355/500 [11:20<05:40,  2.35s/it] 71%|███████▏  | 357/500 [11:21<03:57,  1.66s/it] 72%|███████▏  | 359/500 [11:21<02:46,  1.18s/it]**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  302  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  303  	Training Loss: 0.042029641568660736
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  304  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  305  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  307  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  308  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  309  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  310  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801805853844
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  312  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  313  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  314  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  315  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  317  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  318  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  319  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  320  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  322  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  323  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  324  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  325  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  327  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  328  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  329  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  330  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  332  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  333  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  334  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  335  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  337  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  338  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  339  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  340  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  342  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  343  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  344  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  345  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  347  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  348  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  349  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  350  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  352  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  353  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  354  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  355  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  357  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  358  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  359  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
 72%|███████▏  | 361/500 [11:33<06:17,  2.72s/it] 73%|███████▎  | 363/500 [11:33<04:23,  1.92s/it] 73%|███████▎  | 365/500 [11:40<05:11,  2.31s/it] 73%|███████▎  | 367/500 [11:40<03:37,  1.64s/it] 74%|███████▍  | 369/500 [11:40<02:32,  1.16s/it] 74%|███████▍  | 371/500 [11:53<05:49,  2.71s/it] 75%|███████▍  | 373/500 [11:53<04:03,  1.92s/it] 75%|███████▌  | 375/500 [11:59<04:45,  2.29s/it] 75%|███████▌  | 377/500 [11:59<03:19,  1.62s/it] 76%|███████▌  | 379/500 [11:59<02:19,  1.15s/it] 76%|███████▌  | 381/500 [12:12<05:16,  2.66s/it] 77%|███████▋  | 383/500 [12:12<03:40,  1.89s/it] 77%|███████▋  | 385/500 [12:18<04:22,  2.28s/it] 77%|███████▋  | 387/500 [12:18<03:02,  1.62s/it] 78%|███████▊  | 389/500 [12:19<02:07,  1.15s/it] 78%|███████▊  | 391/500 [12:25<03:11,  1.76s/it] 79%|███████▊  | 393/500 [12:25<02:14,  1.25s/it] 79%|███████▉  | 395/500 [12:31<03:13,  1.84s/it] 79%|███████▉  | 397/500 [12:32<02:14,  1.31s/it] 80%|███████▉  | 399/500 [12:32<01:34,  1.07it/s] 80%|███████▉  | 399/500 [12:44<01:34,  1.07it/s] 80%|████████  | 401/500 [12:44<04:11,  2.54s/it] 81%|████████  | 403/500 [12:44<02:54,  1.80s/it] 81%|████████  | 405/500 [12:51<03:29,  2.20s/it] 81%|████████▏ | 407/500 [12:51<02:25,  1.56s/it] 82%|████████▏ | 409/500 [12:51<01:41,  1.11s/it] 82%|████████▏ | 409/500 [13:04<01:41,  1.11s/it] 82%|████████▏ | 411/500 [13:05<04:15,  2.87s/it] 83%|████████▎ | 413/500 [13:05<02:56,  2.03s/it] 83%|████████▎ | 415/500 [13:11<03:22,  2.38s/it] 83%|████████▎ | 417/500 [13:12<02:20,  1.69s/it] 84%|████████▍ | 419/500 [13:12<01:37,  1.20s/it]Epoch:  360  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  362  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  363  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  364  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  365  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  367  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  368  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  369  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  370  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  372  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  373  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  374  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  375  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  377  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  378  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801805853844
Epoch:  379  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  380  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  382  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  383  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  384  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  385  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  387  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  388  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  389  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  390  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  391  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  392  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  393  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  394  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  395  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  397  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  398  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  399  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  400  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  402  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  403  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  404  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  405  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  407  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  408  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  409  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  410  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  412  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  413  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  414  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  415  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  417  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  418  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  419  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801805853844
 84%|████████▍ | 419/500 [13:24<01:37,  1.20s/it] 84%|████████▍ | 421/500 [13:25<03:40,  2.79s/it] 85%|████████▍ | 423/500 [13:25<02:31,  1.97s/it] 85%|████████▌ | 425/500 [13:31<02:56,  2.35s/it] 85%|████████▌ | 427/500 [13:31<02:01,  1.67s/it] 86%|████████▌ | 429/500 [13:32<01:24,  1.19s/it] 86%|████████▌ | 429/500 [13:44<01:24,  1.19s/it] 86%|████████▌ | 431/500 [13:44<03:05,  2.69s/it] 87%|████████▋ | 433/500 [13:44<02:07,  1.91s/it] 87%|████████▋ | 435/500 [13:50<02:28,  2.29s/it] 87%|████████▋ | 437/500 [13:51<01:42,  1.63s/it] 88%|████████▊ | 439/500 [13:51<01:11,  1.16s/it] 88%|████████▊ | 439/500 [14:04<01:11,  1.16s/it] 88%|████████▊ | 441/500 [14:04<02:45,  2.81s/it] 89%|████████▊ | 443/500 [14:04<01:53,  1.99s/it] 89%|████████▉ | 445/500 [14:11<02:09,  2.35s/it] 89%|████████▉ | 447/500 [14:11<01:28,  1.66s/it] 90%|████████▉ | 449/500 [14:11<01:00,  1.18s/it] 90%|████████▉ | 449/500 [14:24<01:00,  1.18s/it] 90%|█████████ | 451/500 [14:24<02:18,  2.82s/it] 91%|█████████ | 453/500 [14:24<01:33,  2.00s/it] 91%|█████████ | 455/500 [14:31<01:51,  2.47s/it] 91%|█████████▏| 457/500 [14:32<01:15,  1.75s/it] 92%|█████████▏| 459/500 [14:32<00:51,  1.25s/it] 92%|█████████▏| 459/500 [14:44<00:51,  1.25s/it] 92%|█████████▏| 461/500 [14:46<01:56,  2.99s/it] 93%|█████████▎| 463/500 [14:46<01:18,  2.11s/it] 93%|█████████▎| 465/500 [14:52<01:24,  2.41s/it] 93%|█████████▎| 467/500 [14:52<00:56,  1.71s/it] 94%|█████████▍| 469/500 [14:53<00:37,  1.22s/it] 94%|█████████▍| 469/500 [15:04<00:37,  1.22s/it] 94%|█████████▍| 471/500 [15:05<01:18,  2.70s/it] 95%|█████████▍| 473/500 [15:05<00:51,  1.91s/it] 95%|█████████▌| 475/500 [15:05<00:33,  1.36s/it] 95%|█████████▌| 477/500 [15:05<00:22,  1.03it/s] 96%|█████████▌| 479/500 [15:05<00:14,  1.43it/s]Epoch:  420  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  422  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  423  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  424  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  425  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  427  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  428  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  429  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  430  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  432  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  433  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  434  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  435  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  437  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  438  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  439  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  440  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  442  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  443  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  444  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  445  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  447  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  448  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  449  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  450  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  452  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  453  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  454  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  455  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  457  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  458  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  459  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  460  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  462  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  463  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  464  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  465  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  467  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  468  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  469  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  470  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  472  	Training Loss: 0.042029641568660736
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  473  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  474  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  475  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  476  	Training Loss: 0.04202963411808014
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
Epoch:  477  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  478  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  479  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
 96%|█████████▌| 481/500 [15:18<00:44,  2.35s/it] 97%|█████████▋| 483/500 [15:18<00:28,  1.67s/it] 97%|█████████▋| 485/500 [15:24<00:31,  2.10s/it] 97%|█████████▋| 487/500 [15:24<00:19,  1.49s/it] 98%|█████████▊| 489/500 [15:24<00:11,  1.06s/it] 98%|█████████▊| 491/500 [15:37<00:23,  2.63s/it] 99%|█████████▊| 493/500 [15:37<00:13,  1.87s/it] 99%|█████████▉| 495/500 [15:44<00:11,  2.27s/it] 99%|█████████▉| 497/500 [15:44<00:04,  1.61s/it]100%|█████████▉| 499/500 [15:44<00:01,  1.14s/it]100%|██████████| 500/500 [15:50<00:00,  1.90s/it]
Epoch:  480  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  482  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  483  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  484  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  485  	Training Loss: 0.04202963784337044
Test Loss:  0.05766676366329193
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  487  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  488  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  489  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801060795784
Epoch:  490  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  492  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  493  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  494  	Training Loss: 0.04202963784337044
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
Epoch:  495  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.04202963411808014
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  497  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  498  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  499  	Training Loss: 0.04202963784337044
Test Loss:  0.05766675993800163
Valid Loss:  0.05355801433324814
Epoch:  500  	Training Loss: 0.04202963411808014
Test Loss:  0.057666756212711334
Valid Loss:  0.05355801433324814
**************************************************learning rate decay**************************************************
seed is  20
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:25,  6.18s/it]  1%|          | 3/500 [00:06<13:42,  1.66s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:47,  2.92it/s]  2%|▏         | 11/500 [00:12<10:39,  1.31s/it]  3%|▎         | 13/500 [00:13<07:16,  1.12it/s]  3%|▎         | 15/500 [00:19<13:17,  1.64s/it]  3%|▎         | 17/500 [00:19<09:14,  1.15s/it]  4%|▍         | 19/500 [00:19<06:29,  1.23it/s]  4%|▍         | 21/500 [00:32<19:38,  2.46s/it]  5%|▍         | 23/500 [00:32<13:45,  1.73s/it]  5%|▌         | 25/500 [00:38<16:58,  2.15s/it]  5%|▌         | 27/500 [00:38<11:57,  1.52s/it]  6%|▌         | 29/500 [00:38<08:28,  1.08s/it]  6%|▌         | 31/500 [00:51<21:25,  2.74s/it]  7%|▋         | 33/500 [00:52<15:07,  1.94s/it]  7%|▋         | 35/500 [00:58<17:50,  2.30s/it]  7%|▋         | 37/500 [00:58<12:34,  1.63s/it]  8%|▊         | 39/500 [00:58<08:54,  1.16s/it]  8%|▊         | 41/500 [01:11<20:39,  2.70s/it]  9%|▊         | 43/500 [01:11<14:33,  1.91s/it]  9%|▉         | 45/500 [01:17<17:13,  2.27s/it]  9%|▉         | 47/500 [01:17<12:10,  1.61s/it] 10%|▉         | 49/500 [01:17<08:37,  1.15s/it] 10%|█         | 51/500 [01:30<20:03,  2.68s/it] 11%|█         | 53/500 [01:30<14:08,  1.90s/it] 11%|█         | 55/500 [01:36<16:45,  2.26s/it] 11%|█▏        | 57/500 [01:36<11:52,  1.61s/it] 12%|█▏        | 59/500 [01:37<08:27,  1.15s/it] 12%|█▏        | 59/500 [01:47<08:27,  1.15s/it] 12%|█▏        | 61/500 [01:49<19:54,  2.72s/it]Epoch:  1  	Training Loss: 0.20486688613891602
Test Loss:  43.727325439453125
Valid Loss:  42.2665901184082
Epoch:  2  	Training Loss: 42.91593551635742
Test Loss:  0.2593851089477539
Valid Loss:  0.24426540732383728
Epoch:  3  	Training Loss: 0.2015458643436432
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  4  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  5  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  6  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  7  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  8  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  9  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  10  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  11  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  12  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  13  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  14  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  15  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  17  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  18  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  19  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  20  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  22  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  23  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  24  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  25  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  27  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  28  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  29  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  30  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  32  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041606485843658
Epoch:  33  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  34  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  35  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  37  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  38  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  39  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  40  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  42  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  43  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  44  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  45  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  47  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  48  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  49  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  50  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  52  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  53  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  54  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  55  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  57  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  58  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  59  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  60  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  62  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  63  	Training Loss: 0.1980835348367691
Test Loss:   13%|█▎        | 63/500 [01:49<14:01,  1.93s/it] 13%|█▎        | 65/500 [01:56<16:31,  2.28s/it] 13%|█▎        | 67/500 [01:56<11:39,  1.62s/it] 14%|█▍        | 69/500 [01:56<08:16,  1.15s/it] 14%|█▍        | 69/500 [02:07<08:16,  1.15s/it] 14%|█▍        | 71/500 [02:08<19:08,  2.68s/it] 15%|█▍        | 73/500 [02:09<13:29,  1.90s/it] 15%|█▌        | 75/500 [02:15<15:58,  2.26s/it] 15%|█▌        | 77/500 [02:15<11:17,  1.60s/it] 16%|█▌        | 79/500 [02:15<07:59,  1.14s/it] 16%|█▌        | 79/500 [02:27<07:59,  1.14s/it] 16%|█▌        | 81/500 [02:27<18:37,  2.67s/it] 17%|█▋        | 83/500 [02:28<13:06,  1.89s/it] 17%|█▋        | 85/500 [02:34<16:03,  2.32s/it] 17%|█▋        | 87/500 [02:34<11:21,  1.65s/it] 18%|█▊        | 89/500 [02:35<08:05,  1.18s/it] 18%|█▊        | 89/500 [02:47<08:05,  1.18s/it] 18%|█▊        | 91/500 [02:48<18:51,  2.77s/it] 19%|█▊        | 93/500 [02:48<13:16,  1.96s/it] 19%|█▉        | 95/500 [02:48<09:22,  1.39s/it] 19%|█▉        | 97/500 [02:48<06:39,  1.01it/s] 20%|█▉        | 99/500 [02:48<04:45,  1.40it/s] 20%|██        | 101/500 [03:00<15:38,  2.35s/it] 21%|██        | 103/500 [03:01<11:02,  1.67s/it] 21%|██        | 105/500 [03:07<14:00,  2.13s/it] 21%|██▏       | 107/500 [03:07<09:56,  1.52s/it] 22%|██▏       | 109/500 [03:07<07:05,  1.09s/it] 22%|██▏       | 109/500 [03:17<07:05,  1.09s/it] 22%|██▏       | 111/500 [03:20<17:09,  2.65s/it] 23%|██▎       | 113/500 [03:20<12:07,  1.88s/it] 23%|██▎       | 115/500 [03:27<14:44,  2.30s/it] 23%|██▎       | 117/500 [03:27<10:24,  1.63s/it] 24%|██▍       | 119/500 [03:27<07:21,  1.16s/it] 24%|██▍       | 119/500 [03:37<07:21,  1.16s/it] 24%|██▍       | 121/500 [03:40<17:20,  2.75s/it] 25%|██▍       | 123/500 [03:40<12:12,  1.94s/it]0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  64  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  65  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  67  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  68  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  69  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  70  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  72  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  73  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  74  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  75  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  77  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  78  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  79  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  80  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  82  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  83  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  84  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  85  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  87  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  88  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  89  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  90  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  92  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  93  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  94  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  95  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  96  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  97  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  98  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  99  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  100  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  102  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  103  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  104  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  105  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  107  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  108  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  109  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  110  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  112  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  113  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  114  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  115  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  117  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  118  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041606485843658
Epoch:  119  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  120  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  122  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  123  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  124  	Training Loss: 0.1980835199356079
Test Loss:   25%|██▌       | 125/500 [03:46<14:20,  2.29s/it] 25%|██▌       | 127/500 [03:46<10:08,  1.63s/it] 26%|██▌       | 129/500 [03:46<07:13,  1.17s/it] 26%|██▌       | 129/500 [03:57<07:13,  1.17s/it] 26%|██▌       | 131/500 [03:59<16:38,  2.71s/it] 27%|██▋       | 133/500 [03:59<11:45,  1.92s/it] 27%|██▋       | 135/500 [04:06<13:57,  2.30s/it] 27%|██▋       | 137/500 [04:06<09:50,  1.63s/it] 28%|██▊       | 139/500 [04:06<06:57,  1.16s/it] 28%|██▊       | 139/500 [04:17<06:57,  1.16s/it] 28%|██▊       | 141/500 [04:18<15:54,  2.66s/it] 29%|██▊       | 143/500 [04:18<11:11,  1.88s/it] 29%|██▉       | 145/500 [04:25<13:56,  2.36s/it] 29%|██▉       | 147/500 [04:25<09:49,  1.67s/it] 30%|██▉       | 149/500 [04:26<06:57,  1.19s/it] 30%|██▉       | 149/500 [04:37<06:57,  1.19s/it] 30%|███       | 151/500 [04:38<15:51,  2.73s/it] 31%|███       | 153/500 [04:38<11:09,  1.93s/it] 31%|███       | 155/500 [04:45<13:19,  2.32s/it] 31%|███▏      | 157/500 [04:45<09:23,  1.64s/it] 32%|███▏      | 159/500 [04:45<06:38,  1.17s/it] 32%|███▏      | 159/500 [04:57<06:38,  1.17s/it] 32%|███▏      | 161/500 [04:58<15:16,  2.70s/it] 33%|███▎      | 163/500 [04:58<10:44,  1.91s/it] 33%|███▎      | 165/500 [05:04<13:02,  2.34s/it] 33%|███▎      | 167/500 [05:04<09:11,  1.66s/it] 34%|███▍      | 169/500 [05:05<06:30,  1.18s/it] 34%|███▍      | 171/500 [05:17<14:53,  2.72s/it] 35%|███▍      | 173/500 [05:17<10:28,  1.92s/it] 35%|███▌      | 175/500 [05:24<12:32,  2.31s/it] 35%|███▌      | 177/500 [05:24<08:49,  1.64s/it] 36%|███▌      | 179/500 [05:24<06:14,  1.17s/it] 36%|███▌      | 181/500 [05:37<14:36,  2.75s/it] 37%|███▋      | 183/500 [05:37<10:16,  1.94s/it]0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  125  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  127  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  128  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  129  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  130  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  132  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  133  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  134  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  135  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  137  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  138  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  139  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  140  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  142  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  143  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  144  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  145  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  147  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  148  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  149  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  150  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  152  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  153  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  154  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  155  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  157  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  158  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  159  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  160  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  162  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  163  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  164  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  165  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  167  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  168  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  169  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  170  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  172  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  173  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  174  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  175  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  177  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  178  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  179  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  180  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  182  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  183  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
 37%|███▋      | 185/500 [05:43<12:06,  2.31s/it] 37%|███▋      | 187/500 [05:44<08:32,  1.64s/it] 38%|███▊      | 189/500 [05:44<06:02,  1.16s/it] 38%|███▊      | 191/500 [05:56<13:48,  2.68s/it] 39%|███▊      | 193/500 [05:56<09:42,  1.90s/it] 39%|███▉      | 195/500 [06:02<11:30,  2.26s/it] 39%|███▉      | 197/500 [06:03<08:06,  1.60s/it] 40%|███▉      | 199/500 [06:03<05:43,  1.14s/it] 40%|████      | 201/500 [06:15<13:25,  2.69s/it] 41%|████      | 203/500 [06:16<09:26,  1.91s/it] 41%|████      | 205/500 [06:22<11:06,  2.26s/it] 41%|████▏     | 207/500 [06:22<07:49,  1.60s/it] 42%|████▏     | 209/500 [06:22<05:32,  1.14s/it] 42%|████▏     | 211/500 [06:34<12:46,  2.65s/it] 43%|████▎     | 213/500 [06:34<08:59,  1.88s/it] 43%|████▎     | 215/500 [06:41<10:41,  2.25s/it] 43%|████▎     | 217/500 [06:41<07:31,  1.60s/it] 44%|████▍     | 219/500 [06:41<05:19,  1.14s/it] 44%|████▍     | 221/500 [06:54<12:27,  2.68s/it] 45%|████▍     | 223/500 [06:54<08:45,  1.90s/it] 45%|████▌     | 225/500 [07:00<10:23,  2.27s/it] 45%|████▌     | 227/500 [07:00<07:20,  1.61s/it] 46%|████▌     | 229/500 [07:00<05:13,  1.16s/it] 46%|████▌     | 231/500 [07:13<12:09,  2.71s/it] 47%|████▋     | 233/500 [07:13<08:31,  1.92s/it] 47%|████▋     | 235/500 [07:19<10:05,  2.28s/it] 47%|████▋     | 237/500 [07:20<07:07,  1.63s/it] 48%|████▊     | 239/500 [07:20<05:03,  1.16s/it] 48%|████▊     | 241/500 [07:33<11:57,  2.77s/it]Epoch:  184  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  185  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  187  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  188  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  189  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  190  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  192  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  193  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  194  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  195  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  197  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  198  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  199  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  200  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  202  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  203  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  204  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  205  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041606485843658
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  207  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  208  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  209  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  210  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  212  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  213  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  214  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  215  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  217  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  218  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  219  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  220  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  222  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  223  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  224  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  225  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  227  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  228  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  229  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  230  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  232  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  233  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  234  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  235  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  237  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  238  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  239  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  240  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  242  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  243  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
 49%|████▊     | 243/500 [07:33<08:23,  1.96s/it] 49%|████▉     | 245/500 [07:40<10:21,  2.44s/it] 49%|████▉     | 247/500 [07:40<07:17,  1.73s/it] 50%|████▉     | 249/500 [07:40<05:08,  1.23s/it] 50%|█████     | 251/500 [07:53<11:26,  2.76s/it] 51%|█████     | 253/500 [07:53<08:01,  1.95s/it] 51%|█████     | 255/500 [07:59<09:23,  2.30s/it] 51%|█████▏    | 257/500 [07:59<06:36,  1.63s/it] 52%|█████▏    | 259/500 [08:00<04:39,  1.16s/it] 52%|█████▏    | 261/500 [08:12<10:36,  2.66s/it] 53%|█████▎    | 263/500 [08:12<07:28,  1.89s/it] 53%|█████▎    | 265/500 [08:18<08:54,  2.28s/it] 53%|█████▎    | 267/500 [08:19<06:16,  1.61s/it] 54%|█████▍    | 269/500 [08:19<04:25,  1.15s/it] 54%|█████▍    | 271/500 [08:32<10:24,  2.73s/it] 55%|█████▍    | 273/500 [08:32<07:19,  1.94s/it] 55%|█████▌    | 275/500 [08:32<05:10,  1.38s/it] 55%|█████▌    | 277/500 [08:32<03:41,  1.01it/s] 56%|█████▌    | 279/500 [08:32<02:39,  1.39it/s] 56%|█████▌    | 281/500 [08:45<08:39,  2.37s/it] 57%|█████▋    | 283/500 [08:45<06:05,  1.68s/it] 57%|█████▋    | 285/500 [08:51<07:45,  2.16s/it] 57%|█████▋    | 287/500 [08:52<05:27,  1.54s/it] 58%|█████▊    | 289/500 [08:52<03:51,  1.09s/it] 58%|█████▊    | 291/500 [09:05<09:44,  2.80s/it] 59%|█████▊    | 293/500 [09:05<06:49,  1.98s/it] 59%|█████▉    | 295/500 [09:12<08:18,  2.43s/it] 59%|█████▉    | 297/500 [09:12<05:49,  1.72s/it] 60%|█████▉    | 299/500 [09:13<04:06,  1.22s/it] 60%|██████    | 301/500 [09:25<09:16,  2.79s/it] 61%|██████    | 303/500 [09:26<06:29,  1.98s/it]Valid Loss:  0.24041607975959778
Epoch:  244  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  245  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  247  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  248  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041606485843658
Epoch:  249  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  250  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  252  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  253  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  254  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  255  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  257  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  258  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  259  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  260  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  262  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  263  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  264  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  265  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  267  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  268  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  269  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  270  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  272  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  273  	Training Loss: 0.1980835497379303
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  274  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  275  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  276  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  277  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  278  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  279  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  280  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  282  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  283  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  284  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  285  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  287  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  288  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  289  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  290  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  292  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  293  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  294  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  295  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  297  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  298  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  299  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  300  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  302  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  303  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  304  	Training Loss: 0.1980835348367691
Test Loss:  61%|██████    | 305/500 [09:32<07:35,  2.34s/it] 61%|██████▏   | 307/500 [09:32<05:20,  1.66s/it] 62%|██████▏   | 309/500 [09:32<03:46,  1.19s/it] 62%|██████▏   | 311/500 [09:45<08:32,  2.71s/it] 63%|██████▎   | 313/500 [09:45<05:59,  1.92s/it] 63%|██████▎   | 315/500 [09:51<07:08,  2.32s/it] 63%|██████▎   | 317/500 [09:52<05:00,  1.64s/it] 64%|██████▍   | 319/500 [09:52<03:31,  1.17s/it] 64%|██████▍   | 321/500 [10:05<08:12,  2.75s/it] 65%|██████▍   | 323/500 [10:05<05:45,  1.95s/it] 65%|██████▌   | 325/500 [10:11<06:44,  2.31s/it] 65%|██████▌   | 327/500 [10:11<04:43,  1.64s/it] 66%|██████▌   | 329/500 [10:11<03:19,  1.17s/it] 66%|██████▌   | 331/500 [10:24<07:46,  2.76s/it] 67%|██████▋   | 333/500 [10:24<05:26,  1.95s/it] 67%|██████▋   | 335/500 [10:31<06:22,  2.32s/it] 67%|██████▋   | 337/500 [10:31<04:27,  1.64s/it] 68%|██████▊   | 339/500 [10:31<03:08,  1.17s/it] 68%|██████▊   | 341/500 [10:44<07:14,  2.73s/it] 69%|██████▊   | 343/500 [10:44<05:03,  1.94s/it] 69%|██████▉   | 345/500 [10:51<06:02,  2.34s/it] 69%|██████▉   | 347/500 [10:51<04:13,  1.66s/it] 70%|██████▉   | 349/500 [10:51<02:58,  1.18s/it] 70%|███████   | 351/500 [11:04<06:58,  2.81s/it] 71%|███████   | 353/500 [11:04<04:52,  1.99s/it] 71%|███████   | 355/500 [11:11<05:46,  2.39s/it] 71%|███████▏  | 357/500 [11:11<04:01,  1.69s/it] 72%|███████▏  | 359/500 [11:11<02:49,  1.20s/it] 72%|███████▏  | 361/500 [11:25<06:38,  2.87s/it] 73%|███████▎  | 363/500 [11:25<04:38,  2.03s/it] 0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  305  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  307  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  308  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  309  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  310  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  312  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  313  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  314  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  315  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  317  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  318  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  319  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  320  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  322  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  323  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  324  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  325  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  327  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  328  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  329  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  330  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  332  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  333  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  334  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  335  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  337  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  338  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041609466075897
Epoch:  339  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  340  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  342  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  343  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  344  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  345  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  347  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  348  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  349  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  350  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041609466075897
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  352  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  353  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  354  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  355  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  357  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  358  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  359  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  360  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  362  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  363  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
 73%|███████▎  | 365/500 [11:31<05:22,  2.39s/it] 73%|███████▎  | 367/500 [11:31<03:45,  1.69s/it] 74%|███████▍  | 369/500 [11:31<02:37,  1.20s/it] 74%|███████▍  | 371/500 [11:44<05:59,  2.79s/it] 75%|███████▍  | 373/500 [11:45<04:10,  1.97s/it] 75%|███████▌  | 375/500 [11:51<04:57,  2.38s/it] 75%|███████▌  | 377/500 [11:51<03:27,  1.69s/it] 76%|███████▌  | 379/500 [11:52<02:25,  1.20s/it] 76%|███████▌  | 381/500 [12:04<05:28,  2.76s/it] 77%|███████▋  | 383/500 [12:04<03:49,  1.96s/it] 77%|███████▋  | 385/500 [12:11<04:26,  2.32s/it] 77%|███████▋  | 387/500 [12:11<03:06,  1.65s/it] 78%|███████▊  | 389/500 [12:11<02:10,  1.17s/it] 78%|███████▊  | 391/500 [12:24<04:57,  2.73s/it] 79%|███████▊  | 393/500 [12:24<03:26,  1.93s/it] 79%|███████▉  | 395/500 [12:30<04:04,  2.33s/it] 79%|███████▉  | 397/500 [12:31<02:50,  1.66s/it] 80%|███████▉  | 399/500 [12:31<01:59,  1.19s/it] 80%|████████  | 400/500 [12:37<03:30,  2.11s/it] 80%|████████  | 401/500 [12:44<04:52,  2.95s/it] 81%|████████  | 403/500 [12:44<03:04,  1.90s/it] 81%|████████  | 405/500 [12:50<03:46,  2.39s/it] 81%|████████▏ | 407/500 [12:50<02:31,  1.63s/it] 82%|████████▏ | 409/500 [12:51<01:43,  1.13s/it] 82%|████████▏ | 410/500 [12:57<03:07,  2.09s/it] 82%|████████▏ | 411/500 [13:03<04:24,  2.97s/it] 83%|████████▎ | 413/500 [13:03<02:43,  1.88s/it] 83%|████████▎ | 415/500 [13:10<03:18,  2.34s/it] 83%|████████▎ | 417/500 [13:10<02:12,  1.59s/it] 84%|████████▍ | 419/500 [13:10<01:29,  1.11s/it] 84%|████████▍ | 420/500 [13:16<02:46,  2.08s/it] 84%|████████▍ | 421/500 [13:23<04:03,  3.09s/it]Epoch:  364  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  365  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  367  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  368  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  369  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  370  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  372  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  373  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  374  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  375  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  377  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  378  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  379  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041609466075897
Epoch:  380  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  382  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  383  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  384  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  385  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  387  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  388  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  389  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  390  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  392  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  393  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  394  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  395  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  397  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  398  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  399  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  400  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  402  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  403  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  404  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  405  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  407  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  408  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  409  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  410  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  412  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  413  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  414  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  415  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  417  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  418  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  419  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  420  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  422  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  423  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
 85%|████████▍ | 423/500 [13:23<02:30,  1.95s/it] 85%|████████▌ | 425/500 [13:30<03:04,  2.47s/it] 85%|████████▌ | 426/500 [13:30<02:27,  1.99s/it] 86%|████████▌ | 428/500 [13:30<01:33,  1.30s/it] 86%|████████▌ | 430/500 [13:37<02:18,  1.97s/it] 86%|████████▌ | 431/500 [13:43<03:15,  2.83s/it] 87%|████████▋ | 433/500 [13:44<02:03,  1.84s/it] 87%|████████▋ | 435/500 [13:50<02:30,  2.32s/it] 87%|████████▋ | 437/500 [13:50<01:40,  1.59s/it] 88%|████████▊ | 439/500 [13:50<01:07,  1.11s/it] 88%|████████▊ | 440/500 [13:57<02:04,  2.08s/it] 88%|████████▊ | 441/500 [14:03<02:54,  2.96s/it] 89%|████████▊ | 443/500 [14:03<01:47,  1.88s/it] 89%|████████▉ | 445/500 [14:10<02:09,  2.36s/it] 89%|████████▉ | 447/500 [14:10<01:24,  1.60s/it] 90%|████████▉ | 449/500 [14:10<00:56,  1.11s/it] 90%|█████████ | 450/500 [14:16<01:44,  2.10s/it] 90%|█████████ | 451/500 [14:23<02:30,  3.07s/it] 91%|█████████ | 453/500 [14:23<01:31,  1.94s/it] 91%|█████████ | 455/500 [14:30<01:50,  2.46s/it] 91%|█████████▏| 457/500 [14:30<01:11,  1.67s/it] 92%|█████████▏| 459/500 [14:30<00:47,  1.16s/it] 92%|█████████▏| 460/500 [14:37<01:24,  2.12s/it] 92%|█████████▏| 461/500 [14:43<01:58,  3.05s/it] 93%|█████████▎| 463/500 [14:43<01:11,  1.93s/it] 93%|█████████▎| 465/500 [14:50<01:23,  2.39s/it] 93%|█████████▎| 467/500 [14:50<00:53,  1.62s/it] 94%|█████████▍| 469/500 [14:50<00:34,  1.12s/it] 94%|█████████▍| 470/500 [14:57<01:03,  2.12s/it] 94%|█████████▍| 471/500 [15:03<01:29,  3.08s/it] 95%|█████████▍| 473/500 [15:03<00:52,  1.95s/it] 95%|█████████▌| 475/500 [15:10<01:00,  2.43s/it] 95%|█████████▌| 477/500 [15:10<00:37,  1.64s/it] 96%|█████████▌| 479/500 [15:10<00:23,  1.14s/it] 96%|█████████▌| 480/500 [15:17<00:43,  2.18s/it] 96%|█████████▌| 481/500 [15:23<00:58,  3.06s/it]Valid Loss:  0.24041607975959778
Epoch:  424  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  425  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  427  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  428  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041606485843658
Epoch:  429  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  430  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  432  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  433  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  434  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  435  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  437  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  438  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  439  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  440  	Training Loss: 0.1980835497379303
Test Loss:  0.25526759028434753
Valid Loss:  0.24041606485843658
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  442  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  443  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  444  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  445  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  447  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  448  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  449  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  450  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  452  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  453  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  454  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  455  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  457  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  458  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  459  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  460  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
Epoch:  462  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  463  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  464  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  465  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041606485843658
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.1980835497379303
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  467  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  468  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  469  	Training Loss: 0.1980835497379303
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  470  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  472  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  473  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  474  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  475  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  477  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  478  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  479  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  480  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041609466075897
Epoch:  482  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  483  	Training Loss: 0.1980835348367691
 97%|█████████▋| 483/500 [15:24<00:33,  1.95s/it] 97%|█████████▋| 484/500 [15:24<00:25,  1.57s/it] 97%|█████████▋| 485/500 [15:30<00:40,  2.70s/it] 97%|█████████▋| 487/500 [15:30<00:21,  1.65s/it] 98%|█████████▊| 489/500 [15:30<00:11,  1.07s/it] 98%|█████████▊| 490/500 [15:37<00:21,  2.12s/it] 98%|█████████▊| 491/500 [15:43<00:27,  3.06s/it] 99%|█████████▊| 493/500 [15:43<00:13,  1.88s/it] 99%|█████████▉| 495/500 [15:49<00:11,  2.36s/it] 99%|█████████▉| 497/500 [15:50<00:04,  1.59s/it]100%|█████████▉| 499/500 [15:50<00:01,  1.10s/it]100%|██████████| 500/500 [15:56<00:00,  2.08s/it]100%|██████████| 500/500 [15:56<00:00,  1.91s/it]
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  484  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  485  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  487  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  488  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  489  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  490  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  492  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  493  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  494  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  495  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  497  	Training Loss: 0.1980835348367691
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  498  	Training Loss: 0.1980835199356079
Test Loss:  0.25526756048202515
Valid Loss:  0.24041607975959778
Epoch:  499  	Training Loss: 0.1980835199356079
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
Epoch:  500  	Training Loss: 0.1980835348367691
Test Loss:  0.25526759028434753
Valid Loss:  0.24041607975959778
**************************************************learning rate decay**************************************************
