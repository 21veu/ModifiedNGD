train data shape torch.Size([256, 2])
train label shape torch.Size([256, 1])
torch.Size([256, 3])
train_data shape torch.Size([3])
seed is  1
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]/home/yuyi/Documents/ModifiedNGD/utils/readData.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
  0%|          | 1/500 [00:00<03:35,  2.32it/s]  1%|          | 3/500 [00:00<01:25,  5.78it/s]  1%|          | 5/500 [00:00<01:02,  7.95it/s]  1%|▏         | 7/500 [00:00<00:52,  9.34it/s]  2%|▏         | 9/500 [00:01<00:47, 10.25it/s]  2%|▏         | 11/500 [00:01<00:44, 10.87it/s]  3%|▎         | 13/500 [00:01<00:42, 11.33it/s]  3%|▎         | 15/500 [00:01<00:41, 11.64it/s]  3%|▎         | 17/500 [00:01<00:41, 11.77it/s]  4%|▍         | 19/500 [00:01<00:40, 11.94it/s]  4%|▍         | 21/500 [00:02<00:40, 11.96it/s]  5%|▍         | 23/500 [00:02<00:39, 11.93it/s]  5%|▌         | 25/500 [00:02<00:39, 11.98it/s]  5%|▌         | 27/500 [00:02<00:39, 12.08it/s]  6%|▌         | 29/500 [00:02<00:38, 12.15it/s]  6%|▌         | 31/500 [00:02<00:38, 12.22it/s]  7%|▋         | 33/500 [00:03<00:38, 12.25it/s]  7%|▋         | 35/500 [00:03<00:37, 12.27it/s]  7%|▋         | 37/500 [00:03<00:37, 12.30it/s]  8%|▊         | 39/500 [00:03<00:37, 12.32it/s]  8%|▊         | 41/500 [00:03<00:37, 12.30it/s]  9%|▊         | 43/500 [00:03<00:37, 12.32it/s]  9%|▉         | 45/500 [00:04<00:36, 12.33it/s]  9%|▉         | 47/500 [00:04<00:36, 12.32it/s] 10%|▉         | 49/500 [00:04<00:36, 12.33it/s] 10%|█         | 51/500 [00:04<00:36, 12.33it/s] 11%|█         | 53/500 [00:04<00:36, 12.31it/s] 11%|█         | 55/500 [00:04<00:36, 12.31it/s] 11%|█▏        | 57/500 [00:04<00:35, 12.31it/s] 12%|█▏        | 59/500 [00:05<00:35, 12.27it/s] 12%|█▏        | 61/500 [00:05<00:35, 12.30it/s] 13%|█▎        | 63/500 [00:05<00:35, 12.32it/s] 13%|█▎        | 65/500 [00:05<00:35, 12.27it/s] 13%|█▎        | 67/500 [00:05<00:35, 12.30it/s] 14%|█▍        | 69/500 [00:05<00:34, 12.32it/s] 14%|█▍        | 71/500 [00:06<00:34, 12.31it/s] 15%|█▍        | 73/500 [00:06<00:34, 12.30it/s] 15%|█▌        | 75/500 [00:06<00:34, 12.28it/s] 15%|█▌        | 77/500 [00:06<00:34, 12.27it/s] 16%|█▌        | 79/500 [00:06<00:34, 12.29it/s] 16%|█▌        | 81/500 [00:06<00:34, 12.22it/s] 17%|█▋        | 83/500 [00:07<00:34, 12.24it/s] 17%|█▋        | 85/500 [00:07<00:33, 12.23it/s] 17%|█▋        | 87/500 [00:07<00:33, 12.28it/s] 18%|█▊        | 89/500 [00:07<00:33, 12.29it/s] 18%|█▊        | 91/500 [00:07<00:33, 12.23it/s] 19%|█▊        | 93/500 [00:07<00:33, 12.26it/s] 19%|█▉        | 95/500 [00:08<00:32, 12.29it/s] 19%|█▉        | 97/500 [00:08<00:32, 12.24it/s] 20%|█▉        | 99/500 [00:08<00:32, 12.27it/s] 20%|██        | 101/500 [00:08<00:32, 12.30it/s] 21%|██        | 103/500 [00:08<00:32, 12.32it/s] 21%|██        | 105/500 [00:08<00:32, 12.33it/s] 21%|██▏       | 107/500 [00:09<00:32, 12.25it/s] 22%|██▏       | 109/500 [00:09<00:31, 12.28it/s] 22%|██▏       | 111/500 [00:09<00:31, 12.30it/s] 23%|██▎       | 113/500 [00:09<00:31, 12.31it/s] 23%|██▎       | 115/500 [00:09<00:31, 12.31it/s] 23%|██▎       | 117/500 [00:09<00:31, 12.27it/s] 24%|██▍       | 119/500 [00:10<00:30, 12.39it/s] 24%|██▍       | 121/500 [00:10<00:28, 13.30it/s] 25%|██▍       | 123/500 [00:10<00:26, 14.00it/s]Epoch:  1  	Training Loss: 0.030495241284370422
Test Loss:  43.26398849487305
Valid Loss:  42.856040954589844
Epoch:  2  	Training Loss: 42.51416778564453
Test Loss:  2084407040.0
Valid Loss:  2055306496.0
Epoch:  3  	Training Loss: 2058504832.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 125/500 [00:10<00:25, 14.55it/s] 25%|██▌       | 127/500 [00:10<00:24, 15.03it/s] 26%|██▌       | 129/500 [00:10<00:24, 15.20it/s] 26%|██▌       | 131/500 [00:10<00:23, 15.50it/s] 27%|██▋       | 133/500 [00:10<00:23, 15.59it/s] 27%|██▋       | 135/500 [00:11<00:23, 15.72it/s] 27%|██▋       | 137/500 [00:11<00:22, 15.87it/s] 28%|██▊       | 139/500 [00:11<00:22, 15.98it/s] 28%|██▊       | 141/500 [00:11<00:22, 15.95it/s] 29%|██▊       | 143/500 [00:11<00:22, 15.99it/s] 29%|██▉       | 145/500 [00:11<00:22, 16.05it/s] 29%|██▉       | 147/500 [00:11<00:21, 16.06it/s] 30%|██▉       | 149/500 [00:11<00:21, 16.09it/s] 30%|███       | 151/500 [00:12<00:21, 16.04it/s] 31%|███       | 153/500 [00:12<00:21, 16.06it/s] 31%|███       | 155/500 [00:12<00:21, 16.12it/s] 31%|███▏      | 157/500 [00:12<00:21, 16.11it/s] 32%|███▏      | 159/500 [00:12<00:21, 16.14it/s] 32%|███▏      | 161/500 [00:12<00:20, 16.16it/s] 33%|███▎      | 163/500 [00:12<00:20, 16.18it/s] 33%|███▎      | 165/500 [00:12<00:20, 16.19it/s] 33%|███▎      | 167/500 [00:13<00:20, 16.20it/s] 34%|███▍      | 169/500 [00:13<00:31, 10.52it/s] 34%|███▍      | 171/500 [00:13<00:43,  7.52it/s] 35%|███▍      | 173/500 [00:13<00:37,  8.71it/s] 35%|███▌      | 175/500 [00:14<00:33,  9.74it/s] 35%|███▌      | 177/500 [00:14<00:29, 10.94it/s] 36%|███▌      | 179/500 [00:14<00:26, 12.02it/s] 36%|███▌      | 181/500 [00:14<00:24, 12.94it/s] 37%|███▋      | 183/500 [00:14<00:23, 13.65it/s] 37%|███▋      | 185/500 [00:14<00:22, 14.25it/s] 37%|███▋      | 187/500 [00:14<00:21, 14.74it/s] 38%|███▊      | 189/500 [00:15<00:20, 14.91it/s] 38%|███▊      | 191/500 [00:15<00:20, 14.74it/s] 39%|███▊      | 193/500 [00:15<00:22, 13.82it/s] 39%|███▉      | 195/500 [00:15<00:22, 13.29it/s] 39%|███▉      | 197/500 [00:15<00:23, 12.97it/s] 40%|███▉      | 199/500 [00:15<00:23, 12.77it/s] 40%|████      | 201/500 [00:15<00:23, 12.63it/s] 41%|████      | 203/500 [00:16<00:23, 12.54it/s] 41%|████      | 205/500 [00:16<00:23, 12.49it/s] 41%|████▏     | 207/500 [00:16<00:23, 12.45it/s] 42%|████▏     | 209/500 [00:16<00:23, 12.33it/s] 42%|████▏     | 211/500 [00:16<00:23, 12.27it/s] 43%|████▎     | 213/500 [00:16<00:23, 12.27it/s] 43%|████▎     | 215/500 [00:17<00:23, 12.27it/s] 43%|████▎     | 217/500 [00:17<00:23, 12.27it/s] 44%|████▍     | 219/500 [00:17<00:22, 12.30it/s] 44%|████▍     | 221/500 [00:17<00:22, 12.31it/s] 45%|████▍     | 223/500 [00:17<00:21, 12.94it/s] 45%|████▌     | 225/500 [00:17<00:19, 13.77it/s] 45%|████▌     | 227/500 [00:17<00:18, 14.37it/s] 46%|████▌     | 229/500 [00:18<00:18, 14.77it/s] 46%|████▌     | 231/500 [00:18<00:17, 15.13it/s] 47%|████▋     | 233/500 [00:18<00:17, 15.30it/s] 47%|████▋     | 235/500 [00:18<00:17, 15.51it/s] 47%|████▋     | 237/500 [00:18<00:16, 15.70it/s] 48%|████▊     | 239/500 [00:18<00:16, 15.87it/s] 48%|████▊     | 241/500 [00:18<00:16, 15.83it/s] 49%|████▊     | 243/500 [00:18<00:16, 15.91it/s] 49%|████▉     | 245/500 [00:19<00:15, 16.02it/s] 49%|████▉     | 247/500 [00:19<00:15, 16.08it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|████▉     | 249/500 [00:19<00:15, 16.09it/s] 50%|█████     | 251/500 [00:19<00:15, 16.16it/s] 51%|█████     | 253/500 [00:19<00:15, 16.19it/s] 51%|█████     | 255/500 [00:19<00:15, 16.15it/s] 51%|█████▏    | 257/500 [00:19<00:15, 16.12it/s] 52%|█████▏    | 259/500 [00:19<00:14, 16.13it/s] 52%|█████▏    | 261/500 [00:20<00:14, 16.09it/s] 53%|█████▎    | 263/500 [00:20<00:14, 16.05it/s] 53%|█████▎    | 265/500 [00:20<00:14, 16.07it/s] 53%|█████▎    | 267/500 [00:20<00:14, 16.10it/s] 54%|█████▍    | 269/500 [00:20<00:14, 16.13it/s] 54%|█████▍    | 271/500 [00:20<00:14, 16.09it/s] 55%|█████▍    | 273/500 [00:20<00:14, 16.06it/s] 55%|█████▌    | 275/500 [00:20<00:15, 14.92it/s] 55%|█████▌    | 277/500 [00:21<00:15, 14.04it/s] 56%|█████▌    | 279/500 [00:21<00:16, 13.44it/s] 56%|█████▌    | 281/500 [00:21<00:15, 13.95it/s] 57%|█████▋    | 283/500 [00:21<00:15, 14.43it/s] 57%|█████▋    | 285/500 [00:21<00:14, 14.91it/s] 57%|█████▋    | 287/500 [00:21<00:14, 15.17it/s] 58%|█████▊    | 289/500 [00:21<00:13, 15.40it/s] 58%|█████▊    | 291/500 [00:22<00:17, 12.20it/s] 59%|█████▊    | 293/500 [00:22<00:15, 13.00it/s] 59%|█████▉    | 295/500 [00:22<00:14, 13.74it/s] 59%|█████▉    | 297/500 [00:22<00:14, 14.41it/s] 60%|█████▉    | 299/500 [00:22<00:13, 14.83it/s] 60%|██████    | 301/500 [00:22<00:13, 15.16it/s] 61%|██████    | 303/500 [00:22<00:12, 15.41it/s] 61%|██████    | 305/500 [00:23<00:12, 15.57it/s] 61%|██████▏   | 307/500 [00:23<00:12, 15.72it/s] 62%|██████▏   | 309/500 [00:23<00:12, 15.73it/s] 62%|██████▏   | 311/500 [00:23<00:11, 15.84it/s] 63%|██████▎   | 313/500 [00:23<00:11, 15.88it/s] 63%|██████▎   | 315/500 [00:23<00:11, 15.92it/s] 63%|██████▎   | 317/500 [00:23<00:11, 15.99it/s] 64%|██████▍   | 319/500 [00:23<00:11, 16.00it/s] 64%|██████▍   | 321/500 [00:24<00:11, 15.96it/s] 65%|██████▍   | 323/500 [00:24<00:11, 15.93it/s] 65%|██████▌   | 325/500 [00:24<00:17,  9.95it/s] 65%|██████▌   | 327/500 [00:24<00:21,  8.09it/s] 66%|██████▌   | 329/500 [00:25<00:19,  8.97it/s] 66%|██████▌   | 331/500 [00:25<00:16, 10.30it/s] 67%|██████▋   | 333/500 [00:25<00:14, 11.39it/s] 67%|██████▋   | 335/500 [00:25<00:13, 12.14it/s] 67%|██████▋   | 337/500 [00:25<00:12, 12.87it/s] 68%|██████▊   | 339/500 [00:25<00:11, 13.53it/s] 68%|██████▊   | 341/500 [00:25<00:11, 14.02it/s] 69%|██████▊   | 343/500 [00:26<00:10, 14.41it/s] 69%|██████▉   | 345/500 [00:26<00:10, 14.58it/s] 69%|██████▉   | 347/500 [00:26<00:10, 14.43it/s] 70%|██████▉   | 349/500 [00:26<00:11, 13.56it/s] 70%|███████   | 351/500 [00:26<00:11, 12.86it/s] 71%|███████   | 353/500 [00:26<00:10, 13.46it/s] 71%|███████   | 355/500 [00:26<00:10, 14.09it/s] 71%|███████▏  | 357/500 [00:27<00:09, 14.69it/s] 72%|███████▏  | 359/500 [00:27<00:09, 15.14it/s] 72%|███████▏  | 361/500 [00:27<00:08, 15.47it/s] 73%|███████▎  | 363/500 [00:27<00:08, 15.71it/s] 73%|███████▎  | 365/500 [00:27<00:08, 15.67it/s] 73%|███████▎  | 367/500 [00:27<00:08, 15.31it/s] 74%|███████▍  | 369/500 [00:27<00:08, 15.13it/s] 74%|███████▍  | 371/500 [00:27<00:08, 15.13it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 373/500 [00:28<00:08, 15.42it/s] 75%|███████▌  | 375/500 [00:28<00:08, 15.14it/s] 75%|███████▌  | 377/500 [00:28<00:08, 15.36it/s] 76%|███████▌  | 379/500 [00:28<00:07, 15.60it/s] 76%|███████▌  | 381/500 [00:28<00:07, 15.79it/s] 77%|███████▋  | 383/500 [00:28<00:07, 15.86it/s] 77%|███████▋  | 385/500 [00:28<00:07, 15.92it/s] 77%|███████▋  | 387/500 [00:28<00:07, 16.03it/s] 78%|███████▊  | 389/500 [00:29<00:06, 16.02it/s] 78%|███████▊  | 391/500 [00:29<00:06, 16.01it/s] 79%|███████▊  | 393/500 [00:29<00:06, 16.08it/s] 79%|███████▉  | 395/500 [00:29<00:06, 16.12it/s] 79%|███████▉  | 397/500 [00:29<00:06, 16.09it/s] 80%|███████▉  | 399/500 [00:29<00:06, 16.11it/s] 80%|████████  | 401/500 [00:29<00:06, 16.12it/s] 81%|████████  | 403/500 [00:29<00:05, 16.17it/s] 81%|████████  | 405/500 [00:30<00:05, 16.01it/s] 81%|████████▏ | 407/500 [00:30<00:05, 15.77it/s] 82%|████████▏ | 409/500 [00:30<00:05, 15.89it/s] 82%|████████▏ | 411/500 [00:30<00:05, 15.93it/s] 83%|████████▎ | 413/500 [00:30<00:05, 15.71it/s] 83%|████████▎ | 415/500 [00:30<00:05, 15.66it/s] 83%|████████▎ | 417/500 [00:30<00:05, 15.33it/s] 84%|████████▍ | 419/500 [00:30<00:05, 15.24it/s] 84%|████████▍ | 421/500 [00:31<00:05, 15.51it/s] 85%|████████▍ | 423/500 [00:31<00:04, 15.70it/s] 85%|████████▌ | 425/500 [00:31<00:04, 15.88it/s] 85%|████████▌ | 427/500 [00:31<00:04, 15.93it/s] 86%|████████▌ | 429/500 [00:31<00:04, 16.01it/s] 86%|████████▌ | 431/500 [00:31<00:04, 16.06it/s] 87%|████████▋ | 433/500 [00:31<00:04, 16.08it/s] 87%|████████▋ | 435/500 [00:31<00:04, 15.83it/s] 87%|████████▋ | 437/500 [00:32<00:04, 15.46it/s] 88%|████████▊ | 439/500 [00:32<00:03, 15.43it/s] 88%|████████▊ | 441/500 [00:32<00:03, 15.44it/s] 89%|████████▊ | 443/500 [00:32<00:03, 15.64it/s] 89%|████████▉ | 445/500 [00:32<00:03, 15.70it/s] 89%|████████▉ | 447/500 [00:32<00:03, 15.49it/s] 90%|████████▉ | 449/500 [00:32<00:03, 15.48it/s] 90%|█████████ | 451/500 [00:32<00:03, 15.43it/s] 91%|█████████ | 453/500 [00:33<00:03, 15.28it/s] 91%|█████████ | 455/500 [00:33<00:02, 15.17it/s] 91%|█████████▏| 457/500 [00:33<00:02, 14.87it/s] 92%|█████████▏| 459/500 [00:33<00:02, 14.65it/s] 92%|█████████▏| 461/500 [00:33<00:02, 15.00it/s] 93%|█████████▎| 463/500 [00:33<00:02, 15.31it/s] 93%|█████████▎| 465/500 [00:33<00:02, 15.35it/s] 93%|█████████▎| 467/500 [00:34<00:02, 15.60it/s] 94%|█████████▍| 469/500 [00:34<00:01, 15.77it/s] 94%|█████████▍| 471/500 [00:34<00:01, 15.87it/s] 95%|█████████▍| 473/500 [00:34<00:01, 15.92it/s] 95%|█████████▌| 475/500 [00:34<00:01, 15.97it/s] 95%|█████████▌| 477/500 [00:34<00:01, 16.04it/s] 96%|█████████▌| 479/500 [00:34<00:01, 16.10it/s] 96%|█████████▌| 481/500 [00:34<00:01, 16.12it/s] 97%|█████████▋| 483/500 [00:35<00:01, 15.92it/s] 97%|█████████▋| 485/500 [00:35<00:00, 16.01it/s] 97%|█████████▋| 487/500 [00:35<00:00, 15.80it/s] 98%|█████████▊| 489/500 [00:35<00:00, 15.70it/s] 98%|█████████▊| 491/500 [00:35<00:00, 15.63it/s] 99%|█████████▊| 493/500 [00:35<00:00, 15.73it/s] 99%|█████████▉| 495/500 [00:35<00:00, 15.73it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 99%|█████████▉| 497/500 [00:35<00:00, 15.51it/s]100%|█████████▉| 499/500 [00:36<00:00, 15.70it/s]100%|██████████| 500/500 [00:36<00:00, 13.84it/s]
/home/yuyi/anaconda3/envs/ng/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/autograd/engine.cpp:1151.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  1
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:49,  6.47s/it]  1%|          | 3/500 [00:06<14:26,  1.74s/it]  1%|          | 5/500 [00:06<07:20,  1.12it/s]  1%|▏         | 7/500 [00:06<04:30,  1.82it/s]  2%|▏         | 9/500 [00:07<03:03,  2.67it/s]  2%|▏         | 11/500 [00:13<11:16,  1.38s/it]  3%|▎         | 13/500 [00:13<07:40,  1.06it/s]  3%|▎         | 15/500 [00:13<05:21,  1.51it/s]  3%|▎         | 17/500 [00:14<03:48,  2.11it/s]  4%|▍         | 19/500 [00:14<02:46,  2.88it/s]  4%|▍         | 21/500 [00:20<09:37,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:21<02:37,  2.99it/s]  6%|▌         | 31/500 [00:27<09:30,  1.22s/it]  7%|▋         | 33/500 [00:27<06:49,  1.14it/s]  7%|▋         | 35/500 [00:27<04:56,  1.57it/s]  7%|▋         | 37/500 [00:28<03:38,  2.12it/s]  8%|▊         | 39/500 [00:28<02:42,  2.84it/s]  8%|▊         | 41/500 [00:34<09:20,  1.22s/it]  9%|▊         | 43/500 [00:34<06:42,  1.14it/s]  9%|▉         | 45/500 [00:35<04:51,  1.56it/s]  9%|▉         | 47/500 [00:35<03:34,  2.11it/s] 10%|▉         | 49/500 [00:35<02:41,  2.80it/s] 10%|█         | 51/500 [00:41<09:10,  1.23s/it] 11%|█         | 53/500 [00:42<06:33,  1.14it/s] 11%|█         | 55/500 [00:42<04:43,  1.57it/s] 11%|█▏        | 57/500 [00:42<03:26,  2.15it/s] 12%|█▏        | 59/500 [00:42<02:32,  2.89it/s] 12%|█▏        | 61/500 [00:48<08:56,  1.22s/it] 13%|█▎        | 63/500 [00:49<06:23,  1.14it/s] 13%|█▎        | 65/500 [00:49<04:35,  1.58it/s] 13%|█▎        | 67/500 [00:49<03:20,  2.16it/s] 14%|█▍        | 69/500 [00:49<02:28,  2.90it/s] 14%|█▍        | 71/500 [00:56<08:46,  1.23s/it]Epoch:  1  	Training Loss: 0.030495241284370422
Test Loss:  0.6618593335151672
Valid Loss:  0.5805250406265259
Epoch:  2  	Training Loss: 0.7085739970207214
Test Loss:  4.131908416748047
Valid Loss:  4.070051193237305
Epoch:  3  	Training Loss: 4.353453159332275
Test Loss:  0.01666122116148472
Valid Loss:  0.02785605378448963
Epoch:  4  	Training Loss: 0.042851559817790985
Test Loss:  0.016654418781399727
Valid Loss:  0.027843594551086426
Epoch:  5  	Training Loss: 0.04282477870583534
Test Loss:  0.016647638753056526
Valid Loss:  0.02783116139471531
Epoch:  6  	Training Loss: 0.04279803857207298
Test Loss:  0.016640879213809967
Valid Loss:  0.027818752452731133
Epoch:  7  	Training Loss: 0.042771339416503906
Test Loss:  0.0166341420263052
Valid Loss:  0.027806365862488747
Epoch:  8  	Training Loss: 0.042744673788547516
Test Loss:  0.016627425327897072
Valid Loss:  0.02779400162398815
Epoch:  9  	Training Loss: 0.04271804913878441
Test Loss:  0.016620729118585587
Valid Loss:  0.027781661599874496
Epoch:  10  	Training Loss: 0.04269145801663399
Test Loss:  0.016614053398370743
Valid Loss:  0.02776934951543808
Epoch:  11  	Training Loss: 0.042664915323257446
Test Loss:  0.01660740002989769
Valid Loss:  0.02775704860687256
Epoch:  12  	Training Loss: 0.04263840615749359
Test Loss:  0.016600478440523148
Valid Loss:  0.02774433046579361
Epoch:  13  	Training Loss: 0.0426114946603775
Test Loss:  0.0165935717523098
Valid Loss:  0.027731627225875854
Epoch:  14  	Training Loss: 0.0425846129655838
Test Loss:  0.016586679965257645
Valid Loss:  0.02771894633769989
Epoch:  15  	Training Loss: 0.04255777224898338
Test Loss:  0.01657981239259243
Valid Loss:  0.027706287801265717
Epoch:  16  	Training Loss: 0.04253097623586655
Test Loss:  0.016572965309023857
Valid Loss:  0.027693647891283035
Epoch:  17  	Training Loss: 0.0425042100250721
Test Loss:  0.01656612753868103
Valid Loss:  0.027681030333042145
Epoch:  18  	Training Loss: 0.04247748479247093
Test Loss:  0.016559313982725143
Valid Loss:  0.0276684258133173
Epoch:  19  	Training Loss: 0.04245079308748245
Test Loss:  0.01655251905322075
Valid Loss:  0.027655843645334244
Epoch:  20  	Training Loss: 0.042424146085977554
Test Loss:  0.016545739024877548
Valid Loss:  0.02764328569173813
Epoch:  21  	Training Loss: 0.042397528886795044
Test Loss:  0.01653898134827614
Valid Loss:  0.02763073705136776
Epoch:  22  	Training Loss: 0.04237095266580582
Test Loss:  0.016532257199287415
Valid Loss:  0.027618248015642166
Epoch:  23  	Training Loss: 0.04234447330236435
Test Loss:  0.016525547951459885
Valid Loss:  0.027605772018432617
Epoch:  24  	Training Loss: 0.042318038642406464
Test Loss:  0.016518861055374146
Valid Loss:  0.027593329548835754
Epoch:  25  	Training Loss: 0.04229164868593216
Test Loss:  0.0165121927857399
Valid Loss:  0.027580901980400085
Epoch:  26  	Training Loss: 0.04226529598236084
Test Loss:  0.016505546867847443
Valid Loss:  0.02756849303841591
Epoch:  27  	Training Loss: 0.0422389954328537
Test Loss:  0.01649891957640648
Valid Loss:  0.02755611203610897
Epoch:  28  	Training Loss: 0.04221273213624954
Test Loss:  0.016492312774062157
Valid Loss:  0.027543751522898674
Epoch:  29  	Training Loss: 0.04218649864196777
Test Loss:  0.01648571714758873
Valid Loss:  0.027531404048204422
Epoch:  30  	Training Loss: 0.04216032475233078
Test Loss:  0.016479142010211945
Valid Loss:  0.027519088238477707
Epoch:  31  	Training Loss: 0.04213417321443558
Test Loss:  0.01647258922457695
Valid Loss:  0.027506792917847633
Epoch:  32  	Training Loss: 0.04210808128118515
Test Loss:  0.01646607369184494
Valid Loss:  0.027494551613926888
Epoch:  33  	Training Loss: 0.042082078754901886
Test Loss:  0.01645958051085472
Valid Loss:  0.02748233824968338
Epoch:  34  	Training Loss: 0.042056113481521606
Test Loss:  0.016453105956315994
Valid Loss:  0.02747013047337532
Epoch:  35  	Training Loss: 0.04203019291162491
Test Loss:  0.01644665189087391
Valid Loss:  0.027457959949970245
Epoch:  36  	Training Loss: 0.04200431704521179
Test Loss:  0.016440212726593018
Valid Loss:  0.027445806190371513
Epoch:  37  	Training Loss: 0.04197847843170166
Test Loss:  0.016433794051408768
Valid Loss:  0.027433669194579124
Epoch:  38  	Training Loss: 0.04195267707109451
Test Loss:  0.016427388414740562
Valid Loss:  0.027421554550528526
Epoch:  39  	Training Loss: 0.041926927864551544
Test Loss:  0.016421005129814148
Valid Loss:  0.027409465983510017
Epoch:  40  	Training Loss: 0.04190121591091156
Test Loss:  0.016414642333984375
Valid Loss:  0.02739739418029785
Epoch:  41  	Training Loss: 0.04187554493546486
Test Loss:  0.016408292576670647
Valid Loss:  0.027385346591472626
Epoch:  42  	Training Loss: 0.04184991866350174
Test Loss:  0.01640196517109871
Valid Loss:  0.027373313903808594
Epoch:  43  	Training Loss: 0.041824307292699814
Test Loss:  0.016395660117268562
Valid Loss:  0.02736130729317665
Epoch:  44  	Training Loss: 0.04179874062538147
Test Loss:  0.016389360651373863
Valid Loss:  0.02734931744635105
Epoch:  45  	Training Loss: 0.04177321493625641
Test Loss:  0.016383087262511253
Valid Loss:  0.027337346225976944
Epoch:  46  	Training Loss: 0.04174773395061493
Test Loss:  0.016376830637454987
Valid Loss:  0.02732539363205433
Epoch:  47  	Training Loss: 0.04172228276729584
Test Loss:  0.016370592638850212
Valid Loss:  0.027313463389873505
Epoch:  48  	Training Loss: 0.041696880012750626
Test Loss:  0.016364365816116333
Valid Loss:  0.027301549911499023
Epoch:  49  	Training Loss: 0.0416715033352375
Test Loss:  0.016358163207769394
Valid Loss:  0.027289658784866333
Epoch:  50  	Training Loss: 0.04164617508649826
Test Loss:  0.01635197177529335
Valid Loss:  0.027277788147330284
Epoch:  51  	Training Loss: 0.0416208915412426
Test Loss:  0.016345800831913948
Valid Loss:  0.027265936136245728
Epoch:  52  	Training Loss: 0.04159563407301903
Test Loss:  0.01633964478969574
Valid Loss:  0.02725410647690296
Epoch:  53  	Training Loss: 0.04157041758298874
Test Loss:  0.016333511099219322
Valid Loss:  0.02724229171872139
Epoch:  54  	Training Loss: 0.04154524207115173
Test Loss:  0.0163273848593235
Valid Loss:  0.02723049931228161
Epoch:  55  	Training Loss: 0.04152008891105652
Test Loss:  0.01632128283381462
Valid Loss:  0.027218716219067574
Epoch:  56  	Training Loss: 0.041494980454444885
Test Loss:  0.016315193846821785
Valid Loss:  0.02720695361495018
Epoch:  57  	Training Loss: 0.04146990180015564
Test Loss:  0.016309117898344994
Valid Loss:  0.02719520777463913
Epoch:  58  	Training Loss: 0.04144486039876938
Test Loss:  0.016303060576319695
Valid Loss:  0.02718348242342472
Epoch:  59  	Training Loss: 0.0414198562502861
Test Loss:  0.01629701629281044
Valid Loss:  0.027171773836016655
Epoch:  60  	Training Loss: 0.041394881904125214
Test Loss:  0.016290992498397827
Valid Loss:  0.027160082012414932
Epoch:  61  	Training Loss: 0.04136994481086731
Test Loss:  0.01628497801721096
Valid Loss:  0.027148406952619553
Epoch:  62  	Training Loss: 0.04134504869580269
Test Loss:  0.016278976574540138
Valid Loss:  0.027136728167533875
Epoch:  63  	Training Loss: 0.041320089250802994
Test Loss:  0.01627299375832081
Valid Loss:  0.02712506614625454
Epoch:  64  	Training Loss: 0.041295163333415985
Test Loss:  0.016267022117972374
Valid Loss:  0.0271134190261364
Epoch:  65  	Training Loss: 0.041270267218351364
Test Loss:  0.01626107096672058
Valid Loss:  0.027101794257760048
Epoch:  66  	Training Loss: 0.041245415806770325
Test Loss:  0.016255132853984833
Valid Loss:  0.027090182527899742
Epoch:  67  	Training Loss: 0.041220590472221375
Test Loss:  0.01624920591711998
Valid Loss:  0.02707858756184578
Epoch:  68  	Training Loss: 0.041195809841156006
Test Loss:  0.016243301331996918
Valid Loss:  0.027067020535469055
Epoch:  69  	Training Loss: 0.041171059012413025
Test Loss:  0.01623741164803505
Valid Loss:  0.02705545723438263
Epoch:  70  	Training Loss: 0.04114633426070213
Test Loss:  0.016231533139944077
Valid Loss:  0.027043918147683144
Epoch:  71  	Training Loss: 0.04112165421247482
Test Loss:  0.016225675120949745
Valid Loss:  0.02703239396214485
Epoch:  72  	Training Loss: 0.0410970076918602
Test Loss:  0.016219843178987503
Valid Loss:   15%|█▍        | 73/500 [00:56<06:18,  1.13it/s] 15%|█▌        | 75/500 [00:56<04:34,  1.55it/s] 15%|█▌        | 77/500 [00:56<03:21,  2.09it/s] 16%|█▌        | 79/500 [00:56<02:31,  2.78it/s] 16%|█▌        | 81/500 [01:03<08:36,  1.23s/it] 17%|█▋        | 83/500 [01:03<06:08,  1.13it/s] 17%|█▋        | 85/500 [01:03<04:24,  1.57it/s] 17%|█▋        | 87/500 [01:03<03:12,  2.15it/s] 18%|█▊        | 89/500 [01:03<02:22,  2.89it/s] 18%|█▊        | 91/500 [01:10<08:14,  1.21s/it] 19%|█▊        | 93/500 [01:10<05:55,  1.14it/s] 19%|█▉        | 95/500 [01:10<04:17,  1.57it/s] 19%|█▉        | 97/500 [01:10<03:07,  2.15it/s] 20%|█▉        | 99/500 [01:10<02:18,  2.90it/s] 20%|██        | 101/500 [01:17<07:53,  1.19s/it] 21%|██        | 103/500 [01:17<05:37,  1.17it/s] 21%|██        | 105/500 [01:17<04:03,  1.63it/s] 21%|██▏       | 107/500 [01:17<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:17<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:24<07:46,  1.20s/it] 23%|██▎       | 113/500 [01:24<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:24<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:24<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:24<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:31<07:43,  1.22s/it] 25%|██▍       | 123/500 [01:31<05:31,  1.14it/s] 25%|██▌       | 125/500 [01:31<03:58,  1.57it/s] 25%|██▌       | 127/500 [01:31<02:53,  2.15it/s] 26%|██▌       | 129/500 [01:31<02:08,  2.90it/s] 26%|██▌       | 131/500 [01:38<07:27,  1.21s/it] 27%|██▋       | 133/500 [01:38<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:38<03:50,  1.59it/s] 27%|██▋       | 137/500 [01:38<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:38<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:45<07:18,  1.22s/it]0.027020925655961037
Epoch:  73  	Training Loss: 0.04107246547937393
Test Loss:  0.0162140354514122
Valid Loss:  0.027009475976228714
Epoch:  74  	Training Loss: 0.04104796051979065
Test Loss:  0.016208237037062645
Valid Loss:  0.026998041197657585
Epoch:  75  	Training Loss: 0.04102350026369095
Test Loss:  0.01620246097445488
Valid Loss:  0.026986626908183098
Epoch:  76  	Training Loss: 0.04099906608462334
Test Loss:  0.01619669795036316
Valid Loss:  0.026975229382514954
Epoch:  77  	Training Loss: 0.04097466915845871
Test Loss:  0.016190949827432632
Valid Loss:  0.02696385234594345
Epoch:  78  	Training Loss: 0.040950313210487366
Test Loss:  0.01618521474301815
Valid Loss:  0.026952490210533142
Epoch:  79  	Training Loss: 0.040925994515419006
Test Loss:  0.01617949642241001
Valid Loss:  0.026941144838929176
Epoch:  80  	Training Loss: 0.04090170934796333
Test Loss:  0.016173794865608215
Valid Loss:  0.026929821819067
Epoch:  81  	Training Loss: 0.040877461433410645
Test Loss:  0.016168110072612762
Valid Loss:  0.02691851556301117
Epoch:  82  	Training Loss: 0.04085324704647064
Test Loss:  0.016162462532520294
Valid Loss:  0.026907268911600113
Epoch:  83  	Training Loss: 0.04082915186882019
Test Loss:  0.016156833618879318
Valid Loss:  0.02689604088664055
Epoch:  84  	Training Loss: 0.040805090218782425
Test Loss:  0.01615121401846409
Valid Loss:  0.026884835213422775
Epoch:  85  	Training Loss: 0.04078106954693794
Test Loss:  0.016145620495080948
Valid Loss:  0.026873644441366196
Epoch:  86  	Training Loss: 0.04075708985328674
Test Loss:  0.016140030696988106
Valid Loss:  0.026862474158406258
Epoch:  87  	Training Loss: 0.04073314741253853
Test Loss:  0.016134463250637054
Valid Loss:  0.026851313188672066
Epoch:  88  	Training Loss: 0.0407092347741127
Test Loss:  0.016128908842802048
Valid Loss:  0.026840180158615112
Epoch:  89  	Training Loss: 0.04068536311388016
Test Loss:  0.016123365610837936
Valid Loss:  0.026829060167074203
Epoch:  90  	Training Loss: 0.0406615287065506
Test Loss:  0.016117848455905914
Valid Loss:  0.026817962527275085
Epoch:  91  	Training Loss: 0.04063773155212402
Test Loss:  0.01611233875155449
Valid Loss:  0.026806876063346863
Epoch:  92  	Training Loss: 0.040613967925310135
Test Loss:  0.016106830909848213
Valid Loss:  0.02679578587412834
Epoch:  93  	Training Loss: 0.04059015214443207
Test Loss:  0.01610134169459343
Valid Loss:  0.026784703135490417
Epoch:  94  	Training Loss: 0.04056636244058609
Test Loss:  0.01609586738049984
Valid Loss:  0.026773646473884583
Epoch:  95  	Training Loss: 0.040542613714933395
Test Loss:  0.016090402379631996
Valid Loss:  0.02676260471343994
Epoch:  96  	Training Loss: 0.040518905967473984
Test Loss:  0.016084957867860794
Valid Loss:  0.026751574128866196
Epoch:  97  	Training Loss: 0.04049522429704666
Test Loss:  0.016079528257250786
Valid Loss:  0.02674056962132454
Epoch:  98  	Training Loss: 0.040471579879522324
Test Loss:  0.01607411354780197
Valid Loss:  0.02672957256436348
Epoch:  99  	Training Loss: 0.04044796898961067
Test Loss:  0.016068706288933754
Valid Loss:  0.02671859972178936
Epoch:  100  	Training Loss: 0.04042439162731171
Test Loss:  0.016063321381807327
Valid Loss:  0.026707641780376434
Epoch:  101  	Training Loss: 0.04040084779262543
Test Loss:  0.016057949513196945
Valid Loss:  0.026696696877479553
Epoch:  102  	Training Loss: 0.04037734121084213
Test Loss:  0.016052577644586563
Valid Loss:  0.026685751974582672
Epoch:  103  	Training Loss: 0.040353789925575256
Test Loss:  0.01604723185300827
Valid Loss:  0.026674820110201836
Epoch:  104  	Training Loss: 0.04033026099205017
Test Loss:  0.016041891649365425
Valid Loss:  0.02666390873491764
Epoch:  105  	Training Loss: 0.04030677676200867
Test Loss:  0.016036570072174072
Valid Loss:  0.026653006672859192
Epoch:  106  	Training Loss: 0.04028332233428955
Test Loss:  0.016031261533498764
Valid Loss:  0.026642123237252235
Epoch:  107  	Training Loss: 0.04025990515947342
Test Loss:  0.01602596789598465
Valid Loss:  0.02663125842809677
Epoch:  108  	Training Loss: 0.04023651406168938
Test Loss:  0.01602068543434143
Valid Loss:  0.02662041038274765
Epoch:  109  	Training Loss: 0.040213167667388916
Test Loss:  0.01601542718708515
Valid Loss:  0.026609573513269424
Epoch:  110  	Training Loss: 0.04018985107541084
Test Loss:  0.016010170802474022
Valid Loss:  0.02659876085817814
Epoch:  111  	Training Loss: 0.04016657546162605
Test Loss:  0.016004931181669235
Valid Loss:  0.026587963104248047
Epoch:  112  	Training Loss: 0.04014332592487335
Test Loss:  0.01599971391260624
Valid Loss:  0.026577195152640343
Epoch:  113  	Training Loss: 0.04012013226747513
Test Loss:  0.015994511544704437
Valid Loss:  0.02656644582748413
Epoch:  114  	Training Loss: 0.04009697213768959
Test Loss:  0.01598932594060898
Valid Loss:  0.026555709540843964
Epoch:  115  	Training Loss: 0.04007384926080704
Test Loss:  0.015984151512384415
Valid Loss:  0.02654498815536499
Epoch:  116  	Training Loss: 0.04005075618624687
Test Loss:  0.015978984534740448
Valid Loss:  0.02653428353369236
Epoch:  117  	Training Loss: 0.04002769663929939
Test Loss:  0.01597384363412857
Valid Loss:  0.026523597538471222
Epoch:  118  	Training Loss: 0.0400046706199646
Test Loss:  0.01596871204674244
Valid Loss:  0.026512928307056427
Epoch:  119  	Training Loss: 0.03998168557882309
Test Loss:  0.015963587909936905
Valid Loss:  0.026502273976802826
Epoch:  120  	Training Loss: 0.03995872288942337
Test Loss:  0.015958480536937714
Valid Loss:  0.02649163454771042
Epoch:  121  	Training Loss: 0.03993579372763634
Test Loss:  0.015953388065099716
Valid Loss:  0.026481008157134056
Epoch:  122  	Training Loss: 0.03991290554404259
Test Loss:  0.01594829559326172
Valid Loss:  0.026470359414815903
Epoch:  123  	Training Loss: 0.03988991677761078
Test Loss:  0.015943216159939766
Valid Loss:  0.026459723711013794
Epoch:  124  	Training Loss: 0.03986695781350136
Test Loss:  0.015938153490424156
Valid Loss:  0.026449108496308327
Epoch:  125  	Training Loss: 0.039844028651714325
Test Loss:  0.015933100134134293
Valid Loss:  0.026438504457473755
Epoch:  126  	Training Loss: 0.039821140468120575
Test Loss:  0.015928057953715324
Valid Loss:  0.026427915319800377
Epoch:  127  	Training Loss: 0.039798278361558914
Test Loss:  0.01592303067445755
Valid Loss:  0.026417342945933342
Epoch:  128  	Training Loss: 0.03977543115615845
Test Loss:  0.01591802015900612
Valid Loss:  0.02640678361058235
Epoch:  129  	Training Loss: 0.03975262865424156
Test Loss:  0.015913013368844986
Valid Loss:  0.026396237313747406
Epoch:  130  	Training Loss: 0.039729855954647064
Test Loss:  0.015908025205135345
Valid Loss:  0.026385707780718803
Epoch:  131  	Training Loss: 0.03970711678266525
Test Loss:  0.01590305007994175
Valid Loss:  0.026375198736786842
Epoch:  132  	Training Loss: 0.03968441113829613
Test Loss:  0.01589815504848957
Valid Loss:  0.026364842429757118
Epoch:  133  	Training Loss: 0.03966205567121506
Test Loss:  0.015893273055553436
Valid Loss:  0.026354506611824036
Epoch:  134  	Training Loss: 0.039639733731746674
Test Loss:  0.015888402238488197
Valid Loss:  0.026344183832406998
Epoch:  135  	Training Loss: 0.03961744159460068
Test Loss:  0.015883542597293854
Valid Loss:  0.026333877816796303
Epoch:  136  	Training Loss: 0.039595190435647964
Test Loss:  0.015878699719905853
Valid Loss:  0.02632358856499195
Epoch:  137  	Training Loss: 0.03957297280430794
Test Loss:  0.015873869881033897
Valid Loss:  0.026313316076993942
Epoch:  138  	Training Loss: 0.039550792425870895
Test Loss:  0.015869051218032837
Valid Loss:  0.026303056627511978
Epoch:  139  	Training Loss: 0.03952863812446594
Test Loss:  0.01586424931883812
Valid Loss:  0.026292815804481506
Epoch:  140  	Training Loss: 0.039506517350673676
Test Loss:  0.0158594511449337
Valid Loss:  0.026282593607902527
Epoch:  141  	Training Loss: 0.039484426379203796
Test Loss:  0.015854671597480774
Valid Loss:  0.026272371411323547
Epoch:  142  	Training Loss: 0.0394623726606369
Test Loss:  0.015849918127059937
Valid Loss:  0.02626219019293785
Epoch:  143  	Training Loss: 0.0394403375685215
Test Loss:  0.01584516651928425
Valid Loss:   29%|██▊       | 143/500 [01:45<05:14,  1.14it/s] 29%|██▉       | 145/500 [01:45<03:45,  1.57it/s] 29%|██▉       | 147/500 [01:45<02:43,  2.15it/s] 30%|██▉       | 149/500 [01:45<02:01,  2.90it/s] 30%|███       | 151/500 [01:52<07:02,  1.21s/it] 31%|███       | 153/500 [01:52<05:03,  1.14it/s] 31%|███       | 155/500 [01:52<03:39,  1.57it/s] 31%|███▏      | 157/500 [01:52<02:41,  2.12it/s] 32%|███▏      | 159/500 [01:53<02:01,  2.81it/s] 32%|███▏      | 161/500 [01:59<06:55,  1.23s/it] 33%|███▎      | 163/500 [01:59<04:57,  1.13it/s] 33%|███▎      | 165/500 [01:59<03:35,  1.55it/s] 33%|███▎      | 167/500 [02:00<02:38,  2.10it/s] 34%|███▍      | 169/500 [02:00<01:58,  2.79it/s] 34%|███▍      | 171/500 [02:06<06:49,  1.24s/it] 35%|███▍      | 173/500 [02:07<04:53,  1.11it/s] 35%|███▌      | 175/500 [02:07<03:32,  1.53it/s] 35%|███▌      | 177/500 [02:07<02:33,  2.10it/s] 36%|███▌      | 179/500 [02:07<01:53,  2.82it/s] 36%|███▌      | 181/500 [02:13<06:27,  1.21s/it] 37%|███▋      | 183/500 [02:14<04:36,  1.15it/s] 37%|███▋      | 185/500 [02:14<03:19,  1.58it/s] 37%|███▋      | 187/500 [02:14<02:27,  2.13it/s] 38%|███▊      | 189/500 [02:14<01:49,  2.85it/s] 38%|███▊      | 191/500 [02:21<06:16,  1.22s/it] 39%|███▊      | 193/500 [02:21<04:28,  1.14it/s] 39%|███▉      | 195/500 [02:21<03:12,  1.58it/s] 39%|███▉      | 197/500 [02:21<02:20,  2.16it/s] 40%|███▉      | 199/500 [02:21<01:43,  2.90it/s] 40%|████      | 201/500 [02:28<06:05,  1.22s/it] 41%|████      | 203/500 [02:28<04:20,  1.14it/s] 41%|████      | 205/500 [02:28<03:07,  1.58it/s] 41%|████▏     | 207/500 [02:28<02:15,  2.16it/s] 42%|████▏     | 209/500 [02:28<01:40,  2.90it/s] 42%|████▏     | 211/500 [02:35<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:35<04:09,  1.15it/s]0.026252014562487602
Epoch:  144  	Training Loss: 0.03941832482814789
Test Loss:  0.015840429812669754
Valid Loss:  0.026241853833198547
Epoch:  145  	Training Loss: 0.03939634561538696
Test Loss:  0.015835709869861603
Valid Loss:  0.026231709867715836
Epoch:  146  	Training Loss: 0.039374396204948425
Test Loss:  0.015831002965569496
Valid Loss:  0.02622157707810402
Epoch:  147  	Training Loss: 0.03935248404741287
Test Loss:  0.015826309099793434
Valid Loss:  0.026211466640233994
Epoch:  148  	Training Loss: 0.039330609142780304
Test Loss:  0.015821615234017372
Valid Loss:  0.026201365515589714
Epoch:  149  	Training Loss: 0.039308760315179825
Test Loss:  0.01581694558262825
Valid Loss:  0.026191283017396927
Epoch:  150  	Training Loss: 0.03928694874048233
Test Loss:  0.015812281519174576
Valid Loss:  0.026181206107139587
Epoch:  151  	Training Loss: 0.039265166968107224
Test Loss:  0.015807636082172394
Valid Loss:  0.026171155273914337
Epoch:  152  	Training Loss: 0.03924340754747391
Test Loss:  0.015803033486008644
Valid Loss:  0.02616116777062416
Epoch:  153  	Training Loss: 0.03922175243496895
Test Loss:  0.015798449516296387
Valid Loss:  0.026151200756430626
Epoch:  154  	Training Loss: 0.03920013830065727
Test Loss:  0.015793871134519577
Valid Loss:  0.026141243055462837
Epoch:  155  	Training Loss: 0.039178550243377686
Test Loss:  0.01578930765390396
Valid Loss:  0.026131313294172287
Epoch:  156  	Training Loss: 0.039156995713710785
Test Loss:  0.01578475348651409
Valid Loss:  0.026121389120817184
Epoch:  157  	Training Loss: 0.03913548216223717
Test Loss:  0.015780214220285416
Valid Loss:  0.026111487299203873
Epoch:  158  	Training Loss: 0.03911399841308594
Test Loss:  0.015775691717863083
Valid Loss:  0.026101605966687202
Epoch:  159  	Training Loss: 0.039092548191547394
Test Loss:  0.01577117294073105
Valid Loss:  0.026091722771525383
Epoch:  160  	Training Loss: 0.039071135222911835
Test Loss:  0.015766670927405357
Valid Loss:  0.026081867516040802
Epoch:  161  	Training Loss: 0.03904975205659866
Test Loss:  0.01576218567788601
Valid Loss:  0.026072027161717415
Epoch:  162  	Training Loss: 0.03902840241789818
Test Loss:  0.015757722780108452
Valid Loss:  0.026062244549393654
Epoch:  163  	Training Loss: 0.03900718316435814
Test Loss:  0.015753276646137238
Valid Loss:  0.02605246938765049
Epoch:  164  	Training Loss: 0.038985997438430786
Test Loss:  0.01574883796274662
Valid Loss:  0.026042712852358818
Epoch:  165  	Training Loss: 0.03896484151482582
Test Loss:  0.015744414180517197
Valid Loss:  0.026032976806163788
Epoch:  166  	Training Loss: 0.03894371539354324
Test Loss:  0.01573999971151352
Valid Loss:  0.02602325938642025
Epoch:  167  	Training Loss: 0.03892263397574425
Test Loss:  0.015735602006316185
Valid Loss:  0.026013541966676712
Epoch:  168  	Training Loss: 0.03890157490968704
Test Loss:  0.015731211751699448
Valid Loss:  0.026003848761320114
Epoch:  169  	Training Loss: 0.03888054937124252
Test Loss:  0.015726830810308456
Valid Loss:  0.02599417418241501
Epoch:  170  	Training Loss: 0.03885956481099129
Test Loss:  0.01572246290743351
Valid Loss:  0.02598450891673565
Epoch:  171  	Training Loss: 0.03883861005306244
Test Loss:  0.015718109905719757
Valid Loss:  0.02597486972808838
Epoch:  172  	Training Loss: 0.03881768137216568
Test Loss:  0.0157137643545866
Valid Loss:  0.025965183973312378
Epoch:  173  	Training Loss: 0.03879666328430176
Test Loss:  0.015709422528743744
Valid Loss:  0.025955531746149063
Epoch:  174  	Training Loss: 0.038775671273469925
Test Loss:  0.015705088153481483
Valid Loss:  0.02594587951898575
Epoch:  175  	Training Loss: 0.03875471279025078
Test Loss:  0.015700768679380417
Valid Loss:  0.025936251506209373
Epoch:  176  	Training Loss: 0.038733791559934616
Test Loss:  0.015696458518505096
Valid Loss:  0.025926638394594193
Epoch:  177  	Training Loss: 0.03871290013194084
Test Loss:  0.01569216325879097
Valid Loss:  0.02591703087091446
Epoch:  178  	Training Loss: 0.038692034780979156
Test Loss:  0.015687884762883186
Valid Loss:  0.02590744011104107
Epoch:  179  	Training Loss: 0.038671206682920456
Test Loss:  0.0156836099922657
Valid Loss:  0.02589787170290947
Epoch:  180  	Training Loss: 0.038650400936603546
Test Loss:  0.015679344534873962
Valid Loss:  0.02588830143213272
Epoch:  181  	Training Loss: 0.03862963244318962
Test Loss:  0.01567508839070797
Valid Loss:  0.02587875910103321
Epoch:  182  	Training Loss: 0.03860888630151749
Test Loss:  0.015670854598283768
Valid Loss:  0.025869209319353104
Epoch:  183  	Training Loss: 0.038588061928749084
Test Loss:  0.015666630119085312
Valid Loss:  0.02585967630147934
Epoch:  184  	Training Loss: 0.03856725990772247
Test Loss:  0.01566241681575775
Valid Loss:  0.025850147008895874
Epoch:  185  	Training Loss: 0.03854649141430855
Test Loss:  0.015658212825655937
Valid Loss:  0.025840643793344498
Epoch:  186  	Training Loss: 0.03852576017379761
Test Loss:  0.015654025599360466
Valid Loss:  0.02583114616572857
Epoch:  187  	Training Loss: 0.03850505128502846
Test Loss:  0.015649843961000443
Valid Loss:  0.025821667164564133
Epoch:  188  	Training Loss: 0.038484375923871994
Test Loss:  0.015645671635866165
Valid Loss:  0.025812193751335144
Epoch:  189  	Training Loss: 0.03846372663974762
Test Loss:  0.01564151793718338
Valid Loss:  0.025802738964557648
Epoch:  190  	Training Loss: 0.03844311088323593
Test Loss:  0.015637364238500595
Valid Loss:  0.025793299078941345
Epoch:  191  	Training Loss: 0.038422517478466034
Test Loss:  0.015633227303624153
Valid Loss:  0.02578386291861534
Epoch:  192  	Training Loss: 0.03840196132659912
Test Loss:  0.015629123896360397
Valid Loss:  0.025774482637643814
Epoch:  193  	Training Loss: 0.03838145360350609
Test Loss:  0.015625029802322388
Valid Loss:  0.025765113532543182
Epoch:  194  	Training Loss: 0.038360968232154846
Test Loss:  0.015620946884155273
Valid Loss:  0.025755759328603745
Epoch:  195  	Training Loss: 0.038340527564287186
Test Loss:  0.015616873279213905
Valid Loss:  0.025746416300535202
Epoch:  196  	Training Loss: 0.03832010179758072
Test Loss:  0.015612813644111156
Valid Loss:  0.025737080723047256
Epoch:  197  	Training Loss: 0.03829970955848694
Test Loss:  0.015608759596943855
Valid Loss:  0.0257277674973011
Epoch:  198  	Training Loss: 0.03827935457229614
Test Loss:  0.015604719519615173
Valid Loss:  0.025718461722135544
Epoch:  199  	Training Loss: 0.03825902193784714
Test Loss:  0.015600684098899364
Valid Loss:  0.02570916898548603
Epoch:  200  	Training Loss: 0.03823871910572052
Test Loss:  0.015596667304635048
Valid Loss:  0.02569989487528801
Epoch:  201  	Training Loss: 0.03821844607591629
Test Loss:  0.015592653304338455
Valid Loss:  0.025690630078315735
Epoch:  202  	Training Loss: 0.03819820284843445
Test Loss:  0.015588616952300072
Valid Loss:  0.02568124234676361
Epoch:  203  	Training Loss: 0.03817759454250336
Test Loss:  0.015584580600261688
Valid Loss:  0.025671862065792084
Epoch:  204  	Training Loss: 0.03815701603889465
Test Loss:  0.015580560080707073
Valid Loss:  0.02566250041127205
Epoch:  205  	Training Loss: 0.03813646733760834
Test Loss:  0.015576552599668503
Valid Loss:  0.025653162971138954
Epoch:  206  	Training Loss: 0.03811594843864441
Test Loss:  0.015572553500533104
Valid Loss:  0.025643816217780113
Epoch:  207  	Training Loss: 0.038095444440841675
Test Loss:  0.015568560920655727
Valid Loss:  0.025634489953517914
Epoch:  208  	Training Loss: 0.03807497024536133
Test Loss:  0.015564583241939545
Valid Loss:  0.025625169277191162
Epoch:  209  	Training Loss: 0.038054510951042175
Test Loss:  0.015560610219836235
Valid Loss:  0.0256158709526062
Epoch:  210  	Training Loss: 0.03803408145904541
Test Loss:  0.015556653961539268
Valid Loss:  0.02560657635331154
Epoch:  211  	Training Loss: 0.03801368549466133
Test Loss:  0.0155527014285326
Valid Loss:  0.02559730038046837
Epoch:  212  	Training Loss: 0.03799331188201904
Test Loss:  0.015548834577202797
Valid Loss:  0.025588208809494972
Epoch:  213  	Training Loss: 0.037973370403051376
Test Loss:  0.01554497517645359
Valid Loss:  0.025579137727618217
Epoch:  214  	Training Loss: 0.037953466176986694
Test Loss:   43%|████▎     | 215/500 [02:35<02:58,  1.60it/s] 43%|████▎     | 217/500 [02:35<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:35<01:35,  2.93it/s] 44%|████▍     | 221/500 [02:42<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:42<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:42<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:42<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:42<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:49<05:23,  1.20s/it] 47%|████▋     | 233/500 [02:49<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:49<02:48,  1.58it/s] 47%|████▋     | 237/500 [02:49<02:03,  2.13it/s] 48%|████▊     | 239/500 [02:49<01:32,  2.82it/s] 48%|████▊     | 241/500 [02:56<05:15,  1.22s/it] 49%|████▊     | 243/500 [02:56<03:43,  1.15it/s] 49%|████▉     | 245/500 [02:56<02:40,  1.59it/s] 49%|████▉     | 247/500 [02:56<01:56,  2.17it/s] 50%|████▉     | 249/500 [02:56<01:25,  2.93it/s] 50%|█████     | 251/500 [03:03<04:57,  1.20s/it] 51%|█████     | 253/500 [03:03<03:32,  1.16it/s] 51%|█████     | 255/500 [03:03<02:32,  1.61it/s] 51%|█████▏    | 257/500 [03:03<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:03<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:10<04:48,  1.21s/it] 53%|█████▎    | 263/500 [03:10<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:10<02:26,  1.60it/s] 53%|█████▎    | 267/500 [03:10<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:10<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:17<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:17<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:17<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:17<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:17<01:15,  2.94it/s] 56%|█████▌    | 281/500 [03:23<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:23<03:03,  1.18it/s]0.015541130676865578
Valid Loss:  0.025570079684257507
Epoch:  215  	Training Loss: 0.0379335880279541
Test Loss:  0.015537295490503311
Valid Loss:  0.025561027228832245
Epoch:  216  	Training Loss: 0.037913739681243896
Test Loss:  0.015533468686044216
Valid Loss:  0.025551985949277878
Epoch:  217  	Training Loss: 0.037893928587436676
Test Loss:  0.015529653057456017
Valid Loss:  0.0255429707467556
Epoch:  218  	Training Loss: 0.03787413239479065
Test Loss:  0.015525844879448414
Valid Loss:  0.02553396299481392
Epoch:  219  	Training Loss: 0.03785436972975731
Test Loss:  0.015522047877311707
Valid Loss:  0.02552497200667858
Epoch:  220  	Training Loss: 0.037834640592336655
Test Loss:  0.015518263913691044
Valid Loss:  0.02551598660647869
Epoch:  221  	Training Loss: 0.037814944982528687
Test Loss:  0.015514488331973553
Valid Loss:  0.025507014244794846
Epoch:  222  	Training Loss: 0.03779527544975281
Test Loss:  0.015510735101997852
Valid Loss:  0.02549806982278824
Epoch:  223  	Training Loss: 0.037775613367557526
Test Loss:  0.015506993979215622
Valid Loss:  0.025489138439297676
Epoch:  224  	Training Loss: 0.03775597736239433
Test Loss:  0.015503251925110817
Valid Loss:  0.02548021450638771
Epoch:  225  	Training Loss: 0.03773636370897293
Test Loss:  0.015499530360102654
Valid Loss:  0.02547130361199379
Epoch:  226  	Training Loss: 0.03771677613258362
Test Loss:  0.01549581065773964
Valid Loss:  0.025462407618761063
Epoch:  227  	Training Loss: 0.03769722580909729
Test Loss:  0.015492104925215244
Valid Loss:  0.025453517213463783
Epoch:  228  	Training Loss: 0.03767769783735275
Test Loss:  0.015488404780626297
Valid Loss:  0.025444649159908295
Epoch:  229  	Training Loss: 0.037658195942640305
Test Loss:  0.015484718605875969
Valid Loss:  0.025435784831643105
Epoch:  230  	Training Loss: 0.037638723850250244
Test Loss:  0.015481038019061089
Valid Loss:  0.025426942855119705
Epoch:  231  	Training Loss: 0.03761927783489227
Test Loss:  0.015477366745471954
Valid Loss:  0.025418102741241455
Epoch:  232  	Training Loss: 0.037599850445985794
Test Loss:  0.015473736450076103
Valid Loss:  0.025409333407878876
Epoch:  233  	Training Loss: 0.03758059814572334
Test Loss:  0.015470116399228573
Valid Loss:  0.025400593876838684
Epoch:  234  	Training Loss: 0.03756137564778328
Test Loss:  0.015466500073671341
Valid Loss:  0.02539186179637909
Epoch:  235  	Training Loss: 0.03754217550158501
Test Loss:  0.015462894923985004
Valid Loss:  0.025383133441209793
Epoch:  236  	Training Loss: 0.03752300515770912
Test Loss:  0.015459299087524414
Valid Loss:  0.025374406948685646
Epoch:  237  	Training Loss: 0.03750384598970413
Test Loss:  0.015455709770321846
Valid Loss:  0.025365710258483887
Epoch:  238  	Training Loss: 0.037484727799892426
Test Loss:  0.015452131628990173
Valid Loss:  0.025357019156217575
Epoch:  239  	Training Loss: 0.03746562823653221
Test Loss:  0.0154485572129488
Valid Loss:  0.025348331779241562
Epoch:  240  	Training Loss: 0.037446554750204086
Test Loss:  0.01544499583542347
Valid Loss:  0.02533966861665249
Epoch:  241  	Training Loss: 0.03742750361561775
Test Loss:  0.015441441908478737
Valid Loss:  0.025331001728773117
Epoch:  242  	Training Loss: 0.03740847855806351
Test Loss:  0.015437943860888481
Valid Loss:  0.02532244846224785
Epoch:  243  	Training Loss: 0.03738965094089508
Test Loss:  0.015434461645781994
Valid Loss:  0.025313913822174072
Epoch:  244  	Training Loss: 0.03737085312604904
Test Loss:  0.015430979430675507
Valid Loss:  0.02530539035797119
Epoch:  245  	Training Loss: 0.037352077662944794
Test Loss:  0.015427513048052788
Valid Loss:  0.025296881794929504
Epoch:  246  	Training Loss: 0.03733334317803383
Test Loss:  0.015424052253365517
Valid Loss:  0.025288378819823265
Epoch:  247  	Training Loss: 0.03731462359428406
Test Loss:  0.015420600771903992
Valid Loss:  0.02527988702058792
Epoch:  248  	Training Loss: 0.03729594498872757
Test Loss:  0.015417162328958511
Valid Loss:  0.025271423161029816
Epoch:  249  	Training Loss: 0.03727729246020317
Test Loss:  0.015413728542625904
Valid Loss:  0.025262953713536263
Epoch:  250  	Training Loss: 0.03725866228342056
Test Loss:  0.01541029941290617
Valid Loss:  0.0252545066177845
Epoch:  251  	Training Loss: 0.03724007308483124
Test Loss:  0.015406887978315353
Valid Loss:  0.025246072560548782
Epoch:  252  	Training Loss: 0.037221506237983704
Test Loss:  0.015403562225401402
Valid Loss:  0.02523786574602127
Epoch:  253  	Training Loss: 0.03720350190997124
Test Loss:  0.015400243923068047
Valid Loss:  0.02522967755794525
Epoch:  254  	Training Loss: 0.03718552738428116
Test Loss:  0.015396926552057266
Valid Loss:  0.02522149682044983
Epoch:  255  	Training Loss: 0.03716757893562317
Test Loss:  0.015393621288239956
Valid Loss:  0.0252133309841156
Epoch:  256  	Training Loss: 0.03714967519044876
Test Loss:  0.015390332788228989
Valid Loss:  0.025205183774232864
Epoch:  257  	Training Loss: 0.03713178634643555
Test Loss:  0.01538704801350832
Valid Loss:  0.025197042152285576
Epoch:  258  	Training Loss: 0.03711393475532532
Test Loss:  0.015383773483335972
Valid Loss:  0.02518891543149948
Epoch:  259  	Training Loss: 0.03709610924124718
Test Loss:  0.015380505472421646
Valid Loss:  0.02518080361187458
Epoch:  260  	Training Loss: 0.037078309804201126
Test Loss:  0.01537723746150732
Valid Loss:  0.025172695517539978
Epoch:  261  	Training Loss: 0.03706054762005806
Test Loss:  0.01537399087101221
Valid Loss:  0.02516460418701172
Epoch:  262  	Training Loss: 0.03704281151294708
Test Loss:  0.015370705164968967
Valid Loss:  0.025156347081065178
Epoch:  263  	Training Loss: 0.037024542689323425
Test Loss:  0.015367429703474045
Valid Loss:  0.02514808624982834
Epoch:  264  	Training Loss: 0.03700629249215126
Test Loss:  0.015364157035946846
Valid Loss:  0.02513984963297844
Epoch:  265  	Training Loss: 0.03698807209730148
Test Loss:  0.015360899269580841
Valid Loss:  0.025131605565547943
Epoch:  266  	Training Loss: 0.03696988523006439
Test Loss:  0.015357651747763157
Valid Loss:  0.02512340061366558
Epoch:  267  	Training Loss: 0.03695172071456909
Test Loss:  0.015354408882558346
Valid Loss:  0.02511519379913807
Epoch:  268  	Training Loss: 0.03693358600139618
Test Loss:  0.01535117719322443
Valid Loss:  0.025106990709900856
Epoch:  269  	Training Loss: 0.03691547363996506
Test Loss:  0.015347951091825962
Valid Loss:  0.025098809972405434
Epoch:  270  	Training Loss: 0.03689739853143692
Test Loss:  0.015344728715717793
Valid Loss:  0.025090642273426056
Epoch:  271  	Training Loss: 0.03687933832406998
Test Loss:  0.015341519378125668
Valid Loss:  0.02508246898651123
Epoch:  272  	Training Loss: 0.03686131536960602
Test Loss:  0.015338286757469177
Valid Loss:  0.025074170902371407
Epoch:  273  	Training Loss: 0.03684283047914505
Test Loss:  0.01533507090061903
Valid Loss:  0.02506587840616703
Epoch:  274  	Training Loss: 0.036824364215135574
Test Loss:  0.015331847593188286
Valid Loss:  0.025057600811123848
Epoch:  275  	Training Loss: 0.03680592402815819
Test Loss:  0.015328638255596161
Valid Loss:  0.02504931017756462
Epoch:  276  	Training Loss: 0.03678751736879349
Test Loss:  0.01532544195652008
Valid Loss:  0.025041047483682632
Epoch:  277  	Training Loss: 0.03676912561058998
Test Loss:  0.015322253108024597
Valid Loss:  0.025032801553606987
Epoch:  278  	Training Loss: 0.03675076365470886
Test Loss:  0.015319074504077435
Valid Loss:  0.02502455934882164
Epoch:  279  	Training Loss: 0.036732420325279236
Test Loss:  0.015315893106162548
Valid Loss:  0.02501632273197174
Epoch:  280  	Training Loss: 0.0367140993475914
Test Loss:  0.015312733128666878
Valid Loss:  0.025008099153637886
Epoch:  281  	Training Loss: 0.036695804446935654
Test Loss:  0.015309575013816357
Valid Loss:  0.024999884888529778
Epoch:  282  	Training Loss: 0.036677539348602295
Test Loss:  0.015306446701288223
Valid Loss:  0.024991724640130997
Epoch:  283  	Training Loss: 0.03665934503078461
Test Loss:  0.01530333049595356
Valid Loss:  0.02498358115553856
Epoch:  284  	Training Loss: 0.03664116933941841
Test Loss:  0.015300219878554344
Valid Loss:  0.024975445121526718
 57%|█████▋    | 285/500 [03:24<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:24<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:24<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:30<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:30<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:31<02:09,  1.59it/s] 59%|█████▉    | 297/500 [03:31<01:34,  2.14it/s] 60%|█████▉    | 299/500 [03:31<01:10,  2.84it/s] 60%|██████    | 301/500 [03:37<03:58,  1.20s/it] 61%|██████    | 303/500 [03:37<02:49,  1.16it/s] 61%|██████    | 305/500 [03:38<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:38<01:28,  2.19it/s] 62%|██████▏   | 309/500 [03:38<01:04,  2.94it/s] 62%|██████▏   | 311/500 [03:44<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:44<02:40,  1.16it/s] 63%|██████▎   | 315/500 [03:45<01:56,  1.59it/s] 63%|██████▎   | 317/500 [03:45<01:25,  2.15it/s] 64%|██████▍   | 319/500 [03:45<01:03,  2.85it/s] 64%|██████▍   | 321/500 [03:51<03:36,  1.21s/it] 65%|██████▍   | 323/500 [03:51<02:33,  1.15it/s] 65%|██████▌   | 325/500 [03:52<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:52<01:19,  2.18it/s] 66%|██████▌   | 329/500 [03:52<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:58<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:58<02:23,  1.16it/s] 67%|██████▋   | 335/500 [03:59<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:59<01:14,  2.20it/s] 68%|██████▊   | 339/500 [03:59<00:54,  2.96it/s] 68%|██████▊   | 341/500 [04:05<03:14,  1.22s/it] 69%|██████▊   | 343/500 [04:06<02:17,  1.14it/s] 69%|██████▉   | 345/500 [04:06<01:38,  1.57it/s] 69%|██████▉   | 347/500 [04:06<01:11,  2.15it/s] 70%|██████▉   | 349/500 [04:06<00:52,  2.90it/s] 70%|███████   | 351/500 [04:12<03:00,  1.21s/it] 71%|███████   | 353/500 [04:13<02:07,  1.15it/s]Epoch:  285  	Training Loss: 0.0366230234503746
Test Loss:  0.015297116711735725
Valid Loss:  0.02496732771396637
Epoch:  286  	Training Loss: 0.036604899913072586
Test Loss:  0.015294034034013748
Valid Loss:  0.024959204718470573
Epoch:  287  	Training Loss: 0.03658680617809296
Test Loss:  0.015290943905711174
Valid Loss:  0.02495110221207142
Epoch:  288  	Training Loss: 0.03656872734427452
Test Loss:  0.015287872403860092
Valid Loss:  0.024943005293607712
Epoch:  289  	Training Loss: 0.03655067831277847
Test Loss:  0.015284795314073563
Valid Loss:  0.024934925138950348
Epoch:  290  	Training Loss: 0.036532655358314514
Test Loss:  0.015281743369996548
Valid Loss:  0.02492685616016388
Epoch:  291  	Training Loss: 0.03651465103030205
Test Loss:  0.015278690494596958
Valid Loss:  0.024918794631958008
Epoch:  292  	Training Loss: 0.03649668022990227
Test Loss:  0.015275674872100353
Valid Loss:  0.024910777807235718
Epoch:  293  	Training Loss: 0.03647874295711517
Test Loss:  0.01527266763150692
Valid Loss:  0.02490278333425522
Epoch:  294  	Training Loss: 0.03646083176136017
Test Loss:  0.015269661322236061
Valid Loss:  0.024894781410694122
Epoch:  295  	Training Loss: 0.03644295409321785
Test Loss:  0.015266673639416695
Valid Loss:  0.024886799976229668
Epoch:  296  	Training Loss: 0.03642509505152702
Test Loss:  0.015263691544532776
Valid Loss:  0.02487882971763611
Epoch:  297  	Training Loss: 0.03640725836157799
Test Loss:  0.015260715037584305
Valid Loss:  0.024870868772268295
Epoch:  298  	Training Loss: 0.03638945519924164
Test Loss:  0.015257741324603558
Valid Loss:  0.024862919002771378
Epoch:  299  	Training Loss: 0.036371663212776184
Test Loss:  0.015254780650138855
Valid Loss:  0.024854978546500206
Epoch:  300  	Training Loss: 0.036353908479213715
Test Loss:  0.015251824632287025
Valid Loss:  0.024847056716680527
Epoch:  301  	Training Loss: 0.03633618354797363
Test Loss:  0.01524888351559639
Valid Loss:  0.024839134886860847
Epoch:  302  	Training Loss: 0.03631847724318504
Test Loss:  0.015245962888002396
Valid Loss:  0.024831237271428108
Epoch:  303  	Training Loss: 0.03630075603723526
Test Loss:  0.015243059024214745
Valid Loss:  0.024823354557156563
Epoch:  304  	Training Loss: 0.036283060908317566
Test Loss:  0.015240157954394817
Valid Loss:  0.02481548860669136
Epoch:  305  	Training Loss: 0.03626537322998047
Test Loss:  0.015237269923090935
Valid Loss:  0.02480762079358101
Epoch:  306  	Training Loss: 0.036247722804546356
Test Loss:  0.015234377235174179
Valid Loss:  0.02479977160692215
Epoch:  307  	Training Loss: 0.03623010218143463
Test Loss:  0.015231508761644363
Valid Loss:  0.024791933596134186
Epoch:  308  	Training Loss: 0.0362124964594841
Test Loss:  0.015228642150759697
Valid Loss:  0.02478410303592682
Epoch:  309  	Training Loss: 0.036194901913404465
Test Loss:  0.015225773677229881
Valid Loss:  0.02477627620100975
Epoch:  310  	Training Loss: 0.03617734834551811
Test Loss:  0.015222923830151558
Valid Loss:  0.02476847544312477
Epoch:  311  	Training Loss: 0.036159809678792953
Test Loss:  0.01522007305175066
Valid Loss:  0.024760667234659195
Epoch:  312  	Training Loss: 0.036142293363809586
Test Loss:  0.015217257663607597
Valid Loss:  0.0247529074549675
Epoch:  313  	Training Loss: 0.03612483665347099
Test Loss:  0.015214458107948303
Valid Loss:  0.02474517747759819
Epoch:  314  	Training Loss: 0.03610740602016449
Test Loss:  0.015211663208901882
Valid Loss:  0.024737447500228882
Epoch:  315  	Training Loss: 0.036090001463890076
Test Loss:  0.015208875760436058
Valid Loss:  0.024729739874601364
Epoch:  316  	Training Loss: 0.03607262670993805
Test Loss:  0.015206098556518555
Valid Loss:  0.0247220266610384
Epoch:  317  	Training Loss: 0.03605526685714722
Test Loss:  0.01520332507789135
Valid Loss:  0.024714330211281776
Epoch:  318  	Training Loss: 0.03603793680667877
Test Loss:  0.015200558118522167
Valid Loss:  0.024706654250621796
Epoch:  319  	Training Loss: 0.036020636558532715
Test Loss:  0.015197806060314178
Valid Loss:  0.024698976427316666
Epoch:  320  	Training Loss: 0.03600335866212845
Test Loss:  0.015195055864751339
Valid Loss:  0.02469131350517273
Epoch:  321  	Training Loss: 0.03598610311746597
Test Loss:  0.015192309394478798
Valid Loss:  0.02468366175889969
Epoch:  322  	Training Loss: 0.03596886992454529
Test Loss:  0.015189586207270622
Valid Loss:  0.024676071479916573
Epoch:  323  	Training Loss: 0.035951800644397736
Test Loss:  0.015186866745352745
Valid Loss:  0.024668481200933456
Epoch:  324  	Training Loss: 0.035934753715991974
Test Loss:  0.015184156596660614
Valid Loss:  0.024660911411046982
Epoch:  325  	Training Loss: 0.0359177365899086
Test Loss:  0.015181460417807102
Valid Loss:  0.024653347209095955
Epoch:  326  	Training Loss: 0.03590074181556702
Test Loss:  0.015178760513663292
Valid Loss:  0.02464580163359642
Epoch:  327  	Training Loss: 0.03588377684354782
Test Loss:  0.015176071785390377
Valid Loss:  0.02463824674487114
Epoch:  328  	Training Loss: 0.035866811871528625
Test Loss:  0.015173389576375484
Valid Loss:  0.024630721658468246
Epoch:  329  	Training Loss: 0.035849884152412415
Test Loss:  0.015170715749263763
Valid Loss:  0.024623189121484756
Epoch:  330  	Training Loss: 0.0358329676091671
Test Loss:  0.015168044716119766
Valid Loss:  0.024615677073597908
Epoch:  331  	Training Loss: 0.03581608086824417
Test Loss:  0.015165382996201515
Valid Loss:  0.024608181789517403
Epoch:  332  	Training Loss: 0.03579922392964363
Test Loss:  0.015162649564445019
Valid Loss:  0.024600248783826828
Epoch:  333  	Training Loss: 0.0357811376452446
Test Loss:  0.015159927308559418
Valid Loss:  0.024592338129878044
Epoch:  334  	Training Loss: 0.03576306998729706
Test Loss:  0.01515720970928669
Valid Loss:  0.024584434926509857
Epoch:  335  	Training Loss: 0.03574502840638161
Test Loss:  0.01515449583530426
Valid Loss:  0.024576526135206223
Epoch:  336  	Training Loss: 0.03572699427604675
Test Loss:  0.015151791274547577
Valid Loss:  0.02456863410770893
Epoch:  337  	Training Loss: 0.03570898622274399
Test Loss:  0.015149088576436043
Valid Loss:  0.024560745805501938
Epoch:  338  	Training Loss: 0.03569098562002182
Test Loss:  0.015146397985517979
Valid Loss:  0.024552874267101288
Epoch:  339  	Training Loss: 0.03567301481962204
Test Loss:  0.015143717639148235
Valid Loss:  0.02454499900341034
Epoch:  340  	Training Loss: 0.03565505892038345
Test Loss:  0.015141047537326813
Valid Loss:  0.02453714609146118
Epoch:  341  	Training Loss: 0.03563711792230606
Test Loss:  0.015138376504182816
Valid Loss:  0.024529293179512024
Epoch:  342  	Training Loss: 0.035619184374809265
Test Loss:  0.015135783702135086
Valid Loss:  0.02452174387872219
Epoch:  343  	Training Loss: 0.035602085292339325
Test Loss:  0.015133192762732506
Valid Loss:  0.024514207616448402
Epoch:  344  	Training Loss: 0.03558500483632088
Test Loss:  0.015130612067878246
Valid Loss:  0.024506673216819763
Epoch:  345  	Training Loss: 0.03556794673204422
Test Loss:  0.015128039754927158
Valid Loss:  0.024499159306287766
Epoch:  346  	Training Loss: 0.035550907254219055
Test Loss:  0.015125475823879242
Valid Loss:  0.02449164167046547
Epoch:  347  	Training Loss: 0.03553389385342598
Test Loss:  0.015122909098863602
Valid Loss:  0.024484144523739815
Epoch:  348  	Training Loss: 0.03551691025495529
Test Loss:  0.015120361000299454
Valid Loss:  0.024476656690239906
Epoch:  349  	Training Loss: 0.0354999303817749
Test Loss:  0.015117814764380455
Valid Loss:  0.024469178169965744
Epoch:  350  	Training Loss: 0.0354829765856266
Test Loss:  0.015115270391106606
Valid Loss:  0.024461690336465836
Epoch:  351  	Training Loss: 0.0354660339653492
Test Loss:  0.015112737193703651
Valid Loss:  0.024454228579998016
Epoch:  352  	Training Loss: 0.03544912859797478
Test Loss:  0.015110266394913197
Valid Loss:  0.024446936324238777
Epoch:  353  	Training Loss: 0.03543262928724289
Test Loss:  0.015107803978025913
Valid Loss:  0.024439681321382523
Epoch:  354  	Training Loss: 0.03541615977883339
Test Loss:  0.01510534342378378
Valid Loss:  0.02443240024149418
Epoch:  355  	Training Loss: 0.03539970517158508
Test Loss:  0.015102900564670563
Valid Loss:   71%|███████   | 355/500 [04:13<01:30,  1.59it/s] 71%|███████▏  | 357/500 [04:13<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:13<00:48,  2.94it/s] 72%|███████▏  | 361/500 [04:19<02:45,  1.19s/it] 72%|███████▏  | 362/500 [04:19<02:17,  1.00it/s] 73%|███████▎  | 364/500 [04:20<01:34,  1.44it/s] 73%|███████▎  | 366/500 [04:20<01:05,  2.04it/s] 74%|███████▎  | 368/500 [04:20<00:47,  2.78it/s] 74%|███████▍  | 370/500 [04:20<00:35,  3.65it/s] 74%|███████▍  | 372/500 [04:26<02:32,  1.19s/it] 75%|███████▍  | 374/500 [04:27<01:46,  1.18it/s] 75%|███████▌  | 376/500 [04:27<01:15,  1.64it/s] 76%|███████▌  | 378/500 [04:27<00:54,  2.25it/s] 76%|███████▌  | 380/500 [04:27<00:39,  3.03it/s] 76%|███████▋  | 382/500 [04:34<02:24,  1.22s/it] 77%|███████▋  | 384/500 [04:34<01:41,  1.14it/s] 77%|███████▋  | 386/500 [04:34<01:11,  1.59it/s] 78%|███████▊  | 388/500 [04:34<00:51,  2.17it/s] 78%|███████▊  | 390/500 [04:34<00:37,  2.93it/s] 78%|███████▊  | 392/500 [04:41<02:13,  1.24s/it] 79%|███████▉  | 394/500 [04:41<01:34,  1.13it/s] 79%|███████▉  | 396/500 [04:41<01:06,  1.55it/s] 80%|███████▉  | 398/500 [04:41<00:47,  2.13it/s] 80%|████████  | 400/500 [04:41<00:34,  2.86it/s] 80%|████████  | 402/500 [04:48<01:59,  1.22s/it] 81%|████████  | 404/500 [04:48<01:23,  1.14it/s] 81%|████████  | 406/500 [04:48<00:59,  1.58it/s] 82%|████████▏ | 408/500 [04:48<00:42,  2.17it/s] 82%|████████▏ | 410/500 [04:48<00:30,  2.92it/s] 82%|████████▏ | 412/500 [04:55<01:48,  1.24s/it] 83%|████████▎ | 414/500 [04:55<01:16,  1.13it/s] 83%|████████▎ | 416/500 [04:55<00:53,  1.56it/s] 84%|████████▎ | 418/500 [04:55<00:38,  2.14it/s] 84%|████████▍ | 420/500 [04:56<00:27,  2.88it/s] 84%|████████▍ | 422/500 [05:02<01:36,  1.23s/it] 85%|████████▍ | 424/500 [05:02<01:07,  1.13it/s]0.024425139650702477
Epoch:  356  	Training Loss: 0.035383280366659164
Test Loss:  0.015100453980267048
Valid Loss:  0.024417903274297714
Epoch:  357  	Training Loss: 0.03536686673760414
Test Loss:  0.015098015777766705
Valid Loss:  0.024410657584667206
Epoch:  358  	Training Loss: 0.035350486636161804
Test Loss:  0.015095586888492107
Valid Loss:  0.024403437972068787
Epoch:  359  	Training Loss: 0.03533412516117096
Test Loss:  0.015093164518475533
Valid Loss:  0.02439621463418007
Epoch:  360  	Training Loss: 0.035317786037921906
Test Loss:  0.015090743079781532
Valid Loss:  0.024389004334807396
Epoch:  361  	Training Loss: 0.03530145436525345
Test Loss:  0.015088331885635853
Valid Loss:  0.024381812661886215
Epoch:  362  	Training Loss: 0.03528515249490738
Test Loss:  0.015085939317941666
Valid Loss:  0.024374516680836678
Epoch:  363  	Training Loss: 0.03526851534843445
Test Loss:  0.0150835532695055
Valid Loss:  0.024367250502109528
Epoch:  364  	Training Loss: 0.03525190055370331
Test Loss:  0.015081172809004784
Valid Loss:  0.024359993636608124
Epoch:  365  	Training Loss: 0.035235315561294556
Test Loss:  0.015078799799084663
Valid Loss:  0.02435273677110672
Epoch:  366  	Training Loss: 0.035218745470047
Test Loss:  0.01507643237709999
Valid Loss:  0.02434549108147621
Epoch:  367  	Training Loss: 0.03520219773054123
Test Loss:  0.015074066817760468
Valid Loss:  0.0243382565677166
Epoch:  368  	Training Loss: 0.035185668617486954
Test Loss:  0.015071716159582138
Valid Loss:  0.02433103695511818
Epoch:  369  	Training Loss: 0.035169169306755066
Test Loss:  0.01506936363875866
Valid Loss:  0.02432381734251976
Epoch:  370  	Training Loss: 0.035152681171894073
Test Loss:  0.015067026019096375
Valid Loss:  0.024316605180501938
Epoch:  371  	Training Loss: 0.03513621538877487
Test Loss:  0.015064690262079239
Valid Loss:  0.02430940791964531
Epoch:  372  	Training Loss: 0.03511976823210716
Test Loss:  0.015062419697642326
Valid Loss:  0.02430245652794838
Epoch:  373  	Training Loss: 0.03510396182537079
Test Loss:  0.015060151927173138
Valid Loss:  0.024295516312122345
Epoch:  374  	Training Loss: 0.03508817404508591
Test Loss:  0.015057886950671673
Valid Loss:  0.024288572371006012
Epoch:  375  	Training Loss: 0.03507241606712341
Test Loss:  0.015055633150041103
Valid Loss:  0.02428164705634117
Epoch:  376  	Training Loss: 0.03505668044090271
Test Loss:  0.015053384006023407
Valid Loss:  0.024274732917547226
Epoch:  377  	Training Loss: 0.0350409597158432
Test Loss:  0.015051138587296009
Valid Loss:  0.024267811328172684
Epoch:  378  	Training Loss: 0.03502526134252548
Test Loss:  0.01504889689385891
Valid Loss:  0.02426092140376568
Epoch:  379  	Training Loss: 0.03500960022211075
Test Loss:  0.015046671032905579
Valid Loss:  0.02425403892993927
Epoch:  380  	Training Loss: 0.03499395027756691
Test Loss:  0.015044435858726501
Valid Loss:  0.024247154593467712
Epoch:  381  	Training Loss: 0.03497832268476486
Test Loss:  0.01504222210496664
Valid Loss:  0.02424028143286705
Epoch:  382  	Training Loss: 0.034962721168994904
Test Loss:  0.01504000835120678
Valid Loss:  0.02423333190381527
Epoch:  383  	Training Loss: 0.03494683653116226
Test Loss:  0.015037795528769493
Valid Loss:  0.024226389825344086
Epoch:  384  	Training Loss: 0.03493097424507141
Test Loss:  0.015035594813525677
Valid Loss:  0.024219457060098648
Epoch:  385  	Training Loss: 0.034915126860141754
Test Loss:  0.015033401548862457
Valid Loss:  0.024212516844272614
Epoch:  386  	Training Loss: 0.03489929810166359
Test Loss:  0.015031205490231514
Valid Loss:  0.024205615743994713
Epoch:  387  	Training Loss: 0.03488348796963692
Test Loss:  0.015029018744826317
Valid Loss:  0.02419869601726532
Epoch:  388  	Training Loss: 0.03486771136522293
Test Loss:  0.015026843175292015
Valid Loss:  0.024191800504922867
Epoch:  389  	Training Loss: 0.03485194221138954
Test Loss:  0.015024663880467415
Valid Loss:  0.02418491058051586
Epoch:  390  	Training Loss: 0.03483620285987854
Test Loss:  0.015022492967545986
Valid Loss:  0.024178020656108856
Epoch:  391  	Training Loss: 0.03482048586010933
Test Loss:  0.015020335093140602
Valid Loss:  0.024171143770217896
Epoch:  392  	Training Loss: 0.03480478376150131
Test Loss:  0.015018166042864323
Valid Loss:  0.02416398376226425
Epoch:  393  	Training Loss: 0.03478814661502838
Test Loss:  0.015015995129942894
Valid Loss:  0.024156827479600906
Epoch:  394  	Training Loss: 0.03477150946855545
Test Loss:  0.015013836324214935
Valid Loss:  0.024149689823389053
Epoch:  395  	Training Loss: 0.034754909574985504
Test Loss:  0.015011686831712723
Valid Loss:  0.02414252981543541
Epoch:  396  	Training Loss: 0.03473832458257675
Test Loss:  0.015009542927145958
Valid Loss:  0.024135399609804153
Epoch:  397  	Training Loss: 0.0347217433154583
Test Loss:  0.015007405541837215
Valid Loss:  0.024128276854753494
Epoch:  398  	Training Loss: 0.03470519185066223
Test Loss:  0.015005272813141346
Valid Loss:  0.024121150374412537
Epoch:  399  	Training Loss: 0.03468865528702736
Test Loss:  0.0150031428784132
Valid Loss:  0.024114036932587624
Epoch:  400  	Training Loss: 0.034672126173973083
Test Loss:  0.015001017600297928
Valid Loss:  0.02410692721605301
Epoch:  401  	Training Loss: 0.0346556156873703
Test Loss:  0.01499890349805355
Valid Loss:  0.02409983240067959
Epoch:  402  	Training Loss: 0.0346391387283802
Test Loss:  0.014996780082583427
Valid Loss:  0.02409251779317856
Epoch:  403  	Training Loss: 0.03462197631597519
Test Loss:  0.014994654804468155
Valid Loss:  0.024085205048322678
Epoch:  404  	Training Loss: 0.034604839980602264
Test Loss:  0.014992546290159225
Valid Loss:  0.02407790534198284
Epoch:  405  	Training Loss: 0.034587714821100235
Test Loss:  0.014990441501140594
Valid Loss:  0.024070605635643005
Epoch:  406  	Training Loss: 0.0345706045627594
Test Loss:  0.014988331124186516
Valid Loss:  0.02406332828104496
Epoch:  407  	Training Loss: 0.03455352038145065
Test Loss:  0.014986238442361355
Valid Loss:  0.02405603602528572
Epoch:  408  	Training Loss: 0.03453643247485161
Test Loss:  0.014984147623181343
Valid Loss:  0.02404876984655857
Epoch:  409  	Training Loss: 0.034519366919994354
Test Loss:  0.014982074499130249
Valid Loss:  0.024041499942541122
Epoch:  410  	Training Loss: 0.034502312541007996
Test Loss:  0.014979993924498558
Valid Loss:  0.024034248664975166
Epoch:  411  	Training Loss: 0.03448528051376343
Test Loss:  0.014977920800447464
Valid Loss:  0.02402699738740921
Epoch:  412  	Training Loss: 0.03446826711297035
Test Loss:  0.014975949190557003
Valid Loss:  0.024020375683903694
Epoch:  413  	Training Loss: 0.03445303440093994
Test Loss:  0.014973979443311691
Valid Loss:  0.024013757705688477
Epoch:  414  	Training Loss: 0.03443782776594162
Test Loss:  0.014971999451518059
Valid Loss:  0.024007152765989304
Epoch:  415  	Training Loss: 0.03442264348268509
Test Loss:  0.01497004833072424
Valid Loss:  0.02400054782629013
Epoch:  416  	Training Loss: 0.034407470375299454
Test Loss:  0.014968091621994972
Valid Loss:  0.02399396523833275
Epoch:  417  	Training Loss: 0.03439231961965561
Test Loss:  0.014966133050620556
Valid Loss:  0.023987382650375366
Epoch:  418  	Training Loss: 0.034377194941043854
Test Loss:  0.014964188449084759
Valid Loss:  0.023980800062417984
Epoch:  419  	Training Loss: 0.03436208516359329
Test Loss:  0.014962245710194111
Valid Loss:  0.023974237963557243
Epoch:  420  	Training Loss: 0.034346990287303925
Test Loss:  0.014960311353206635
Valid Loss:  0.023967675864696503
Epoch:  421  	Training Loss: 0.034331925213336945
Test Loss:  0.014958382584154606
Valid Loss:  0.023961130529642105
Epoch:  422  	Training Loss: 0.03431687504053116
Test Loss:  0.014956450089812279
Valid Loss:  0.0239544864743948
Epoch:  423  	Training Loss: 0.0343015193939209
Test Loss:  0.014954524114727974
Valid Loss:  0.02394784614443779
Epoch:  424  	Training Loss: 0.03428618982434273
Test Loss:  0.014952598139643669
Valid Loss:  0.023941198363900185
Epoch:  425  	Training Loss: 0.03427087515592575
Test Loss:  0.014950674027204514
Valid Loss:  0.02393456920981407
Epoch:  426  	Training Loss: 0.034255579113960266
Test Loss:  0.01494876854121685
 85%|████████▌ | 426/500 [05:02<00:47,  1.57it/s] 86%|████████▌ | 428/500 [05:02<00:33,  2.15it/s] 86%|████████▌ | 430/500 [05:03<00:24,  2.89it/s] 86%|████████▋ | 432/500 [05:09<01:21,  1.20s/it] 87%|████████▋ | 434/500 [05:09<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:09<00:39,  1.61it/s] 88%|████████▊ | 438/500 [05:09<00:28,  2.20it/s] 88%|████████▊ | 440/500 [05:10<00:20,  2.96it/s] 88%|████████▊ | 442/500 [05:16<01:10,  1.22s/it] 89%|████████▉ | 444/500 [05:16<00:49,  1.14it/s] 89%|████████▉ | 446/500 [05:16<00:34,  1.58it/s] 90%|████████▉ | 448/500 [05:17<00:24,  2.15it/s] 90%|█████████ | 450/500 [05:17<00:17,  2.85it/s] 90%|█████████ | 452/500 [05:23<00:58,  1.22s/it] 91%|█████████ | 454/500 [05:23<00:40,  1.14it/s] 91%|█████████ | 456/500 [05:23<00:27,  1.57it/s] 92%|█████████▏| 458/500 [05:24<00:19,  2.15it/s] 92%|█████████▏| 460/500 [05:24<00:14,  2.85it/s] 92%|█████████▏| 462/500 [05:30<00:47,  1.24s/it] 93%|█████████▎| 464/500 [05:31<00:31,  1.13it/s] 93%|█████████▎| 466/500 [05:31<00:21,  1.56it/s] 94%|█████████▎| 468/500 [05:31<00:15,  2.13it/s] 94%|█████████▍| 470/500 [05:31<00:10,  2.87it/s] 94%|█████████▍| 472/500 [05:37<00:34,  1.22s/it] 95%|█████████▍| 474/500 [05:38<00:22,  1.14it/s] 95%|█████████▌| 476/500 [05:38<00:15,  1.58it/s] 96%|█████████▌| 478/500 [05:38<00:10,  2.16it/s] 96%|█████████▌| 480/500 [05:38<00:06,  2.92it/s] 96%|█████████▋| 482/500 [05:44<00:21,  1.20s/it] 97%|█████████▋| 484/500 [05:45<00:13,  1.16it/s] 97%|█████████▋| 486/500 [05:45<00:08,  1.60it/s] 98%|█████████▊| 488/500 [05:45<00:05,  2.19it/s] 98%|█████████▊| 490/500 [05:45<00:03,  2.94it/s] 98%|█████████▊| 492/500 [05:51<00:09,  1.20s/it] 99%|█████████▉| 494/500 [05:52<00:05,  1.16it/s] 99%|█████████▉| 496/500 [05:52<00:02,  1.60it/s]Valid Loss:  0.023927967995405197
Epoch:  427  	Training Loss: 0.034240301698446274
Test Loss:  0.01494685746729374
Valid Loss:  0.023921344429254532
Epoch:  428  	Training Loss: 0.034225039184093475
Test Loss:  0.014944955706596375
Valid Loss:  0.023914750665426254
Epoch:  429  	Training Loss: 0.03420979529619217
Test Loss:  0.014943055808544159
Valid Loss:  0.023908142000436783
Epoch:  430  	Training Loss: 0.034194570034742355
Test Loss:  0.014941161498427391
Valid Loss:  0.023901548236608505
Epoch:  431  	Training Loss: 0.03417937457561493
Test Loss:  0.014939280226826668
Valid Loss:  0.023894954472780228
Epoch:  432  	Training Loss: 0.03416416794061661
Test Loss:  0.014937414787709713
Valid Loss:  0.023888293653726578
Epoch:  433  	Training Loss: 0.03414859622716904
Test Loss:  0.014935573562979698
Valid Loss:  0.023881621658802032
Epoch:  434  	Training Loss: 0.03413303568959236
Test Loss:  0.014933725818991661
Valid Loss:  0.023874975740909576
Epoch:  435  	Training Loss: 0.03411749005317688
Test Loss:  0.014931872487068176
Valid Loss:  0.023868311196565628
Epoch:  436  	Training Loss: 0.034101974219083786
Test Loss:  0.014930048026144505
Valid Loss:  0.023861665278673172
Epoch:  437  	Training Loss: 0.03408646583557129
Test Loss:  0.014928216114640236
Valid Loss:  0.023855028674006462
Epoch:  438  	Training Loss: 0.03407098352909088
Test Loss:  0.014926380477845669
Valid Loss:  0.0238484013825655
Epoch:  439  	Training Loss: 0.03405551239848137
Test Loss:  0.014924566261470318
Valid Loss:  0.023841772228479385
Epoch:  440  	Training Loss: 0.034040067344903946
Test Loss:  0.014922750182449818
Valid Loss:  0.023835163563489914
Epoch:  441  	Training Loss: 0.034024640917778015
Test Loss:  0.014920941554009914
Valid Loss:  0.02382856234908104
Epoch:  442  	Training Loss: 0.03400922194123268
Test Loss:  0.014919154345989227
Valid Loss:  0.023821895942091942
Epoch:  443  	Training Loss: 0.033993590623140335
Test Loss:  0.01491739321500063
Valid Loss:  0.023815259337425232
Epoch:  444  	Training Loss: 0.03397798165678978
Test Loss:  0.014915607869625092
Valid Loss:  0.023808617144823074
Epoch:  445  	Training Loss: 0.03396238386631012
Test Loss:  0.014913850463926792
Valid Loss:  0.02380198985338211
Epoch:  446  	Training Loss: 0.03394680470228195
Test Loss:  0.014912085607647896
Valid Loss:  0.023795362561941147
Epoch:  447  	Training Loss: 0.03393123671412468
Test Loss:  0.01491033285856247
Valid Loss:  0.02378876321017742
Epoch:  448  	Training Loss: 0.033915694802999496
Test Loss:  0.014908581972122192
Valid Loss:  0.023782160133123398
Epoch:  449  	Training Loss: 0.03390016406774521
Test Loss:  0.01490684226155281
Valid Loss:  0.02377554588019848
Epoch:  450  	Training Loss: 0.03388465195894241
Test Loss:  0.014905108138918877
Valid Loss:  0.023768950253725052
Epoch:  451  	Training Loss: 0.03386915475130081
Test Loss:  0.014903360046446323
Valid Loss:  0.023762356489896774
Epoch:  452  	Training Loss: 0.033853679895401
Test Loss:  0.014901669695973396
Valid Loss:  0.023756118491292
Epoch:  453  	Training Loss: 0.03383917734026909
Test Loss:  0.014899974688887596
Valid Loss:  0.023749876767396927
Epoch:  454  	Training Loss: 0.03382468968629837
Test Loss:  0.014898285269737244
Valid Loss:  0.023743631318211555
Epoch:  455  	Training Loss: 0.033810220658779144
Test Loss:  0.014896601438522339
Valid Loss:  0.023737404495477676
Epoch:  456  	Training Loss: 0.03379576653242111
Test Loss:  0.014894915744662285
Valid Loss:  0.023731186985969543
Epoch:  457  	Training Loss: 0.03378133475780487
Test Loss:  0.014893248677253723
Valid Loss:  0.02372496761381626
Epoch:  458  	Training Loss: 0.03376691788434982
Test Loss:  0.014891575090587139
Valid Loss:  0.023718778043985367
Epoch:  459  	Training Loss: 0.033752523362636566
Test Loss:  0.014889905229210854
Valid Loss:  0.02371256798505783
Epoch:  460  	Training Loss: 0.0337381511926651
Test Loss:  0.014888251200318336
Valid Loss:  0.023706378415226936
Epoch:  461  	Training Loss: 0.033723801374435425
Test Loss:  0.01488659717142582
Valid Loss:  0.02370019629597664
Epoch:  462  	Training Loss: 0.03370947390794754
Test Loss:  0.014884930104017258
Valid Loss:  0.02369442954659462
Epoch:  463  	Training Loss: 0.033696435391902924
Test Loss:  0.014883281663060188
Valid Loss:  0.0236886627972126
Epoch:  464  	Training Loss: 0.03368343785405159
Test Loss:  0.014881635084748268
Valid Loss:  0.02368292398750782
Epoch:  465  	Training Loss: 0.03367046266794205
Test Loss:  0.01487999688833952
Valid Loss:  0.0236771609634161
Epoch:  466  	Training Loss: 0.0336574912071228
Test Loss:  0.01487836055457592
Valid Loss:  0.023671425879001617
Epoch:  467  	Training Loss: 0.03364455699920654
Test Loss:  0.014876719564199448
Valid Loss:  0.02366570010781288
Epoch:  468  	Training Loss: 0.03363163769245148
Test Loss:  0.014875082299113274
Valid Loss:  0.023659981787204742
Epoch:  469  	Training Loss: 0.0336187370121479
Test Loss:  0.014873459935188293
Valid Loss:  0.023654267191886902
Epoch:  470  	Training Loss: 0.03360585495829582
Test Loss:  0.01487183291465044
Valid Loss:  0.02364855259656906
Epoch:  471  	Training Loss: 0.03359299153089523
Test Loss:  0.01487020868808031
Valid Loss:  0.023642847314476967
Epoch:  472  	Training Loss: 0.033580150455236435
Test Loss:  0.014868644997477531
Valid Loss:  0.023636773228645325
Epoch:  473  	Training Loss: 0.033565931022167206
Test Loss:  0.014867076650261879
Valid Loss:  0.023630689829587936
Epoch:  474  	Training Loss: 0.033551737666130066
Test Loss:  0.01486552506685257
Valid Loss:  0.02362462505698204
Epoch:  475  	Training Loss: 0.03353755921125412
Test Loss:  0.014863969758152962
Valid Loss:  0.023618564009666443
Epoch:  476  	Training Loss: 0.03352339565753937
Test Loss:  0.014862416312098503
Valid Loss:  0.023612502962350845
Epoch:  477  	Training Loss: 0.033509254455566406
Test Loss:  0.014860877767205238
Valid Loss:  0.023606453090906143
Epoch:  478  	Training Loss: 0.03349512070417404
Test Loss:  0.014859339222311974
Valid Loss:  0.02360042743384838
Epoch:  479  	Training Loss: 0.033481013029813766
Test Loss:  0.01485779881477356
Valid Loss:  0.023594390600919724
Epoch:  480  	Training Loss: 0.03346692770719528
Test Loss:  0.014856267720460892
Valid Loss:  0.02358836680650711
Epoch:  481  	Training Loss: 0.03345286473631859
Test Loss:  0.014854740351438522
Valid Loss:  0.023582346737384796
Epoch:  482  	Training Loss: 0.03343881294131279
Test Loss:  0.014853229746222496
Valid Loss:  0.023576388135552406
Epoch:  483  	Training Loss: 0.03342495113611221
Test Loss:  0.014851709827780724
Valid Loss:  0.023570440709590912
Epoch:  484  	Training Loss: 0.033411093056201935
Test Loss:  0.01485019363462925
Valid Loss:  0.023564506322145462
Epoch:  485  	Training Loss: 0.033397264778614044
Test Loss:  0.014848684892058372
Valid Loss:  0.023558560758829117
Epoch:  486  	Training Loss: 0.03338344022631645
Test Loss:  0.014847179874777794
Valid Loss:  0.023552631959319115
Epoch:  487  	Training Loss: 0.03336963802576065
Test Loss:  0.014845694415271282
Valid Loss:  0.023546703159809113
Epoch:  488  	Training Loss: 0.03335586190223694
Test Loss:  0.014844182878732681
Valid Loss:  0.0235407967120409
Epoch:  489  	Training Loss: 0.03334209695458412
Test Loss:  0.014842690899968147
Valid Loss:  0.02353489212691784
Epoch:  490  	Training Loss: 0.0333283469080925
Test Loss:  0.014841211028397083
Valid Loss:  0.02352897822856903
Epoch:  491  	Training Loss: 0.03331461921334267
Test Loss:  0.014839725568890572
Valid Loss:  0.023523084819316864
Epoch:  492  	Training Loss: 0.03330090641975403
Test Loss:  0.014838255941867828
Valid Loss:  0.023516954854130745
Epoch:  493  	Training Loss: 0.033286407589912415
Test Loss:  0.014836793765425682
Valid Loss:  0.023510802537202835
Epoch:  494  	Training Loss: 0.03327193483710289
Test Loss:  0.01483533252030611
Valid Loss:  0.023504681885242462
Epoch:  495  	Training Loss: 0.03325746953487396
Test Loss:  0.014833868481218815
Valid Loss:  0.023498564958572388
Epoch:  496  	Training Loss: 0.033243026584386826
Test Loss:  0.014832403510808945
Valid Loss:  0.023492462933063507
Epoch:  497  	Training Loss: 0.033228591084480286
Test Loss:  100%|█████████▉| 498/500 [05:52<00:00,  2.19it/s]100%|██████████| 500/500 [05:52<00:00,  2.93it/s]100%|██████████| 500/500 [05:52<00:00,  1.42it/s]
0.014830967411398888
Valid Loss:  0.02348634973168373
Epoch:  498  	Training Loss: 0.033214181661605835
Test Loss:  0.014829523861408234
Valid Loss:  0.023480242118239403
Epoch:  499  	Training Loss: 0.03319977968931198
Test Loss:  0.014828081242740154
Valid Loss:  0.023474153131246567
Epoch:  500  	Training Loss: 0.03318540006875992
Test Loss:  0.01482664979994297
Valid Loss:  0.023468058556318283
seed is  1
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:43,  6.34s/it]  1%|          | 3/500 [00:06<14:02,  1.69s/it]  1%|          | 5/500 [00:06<07:04,  1.17it/s]  1%|▏         | 7/500 [00:06<04:17,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<11:03,  1.36s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:44,  2.93it/s]  4%|▍         | 21/500 [00:20<10:03,  1.26s/it]  5%|▍         | 23/500 [00:20<07:08,  1.11it/s]  5%|▌         | 25/500 [00:20<05:06,  1.55it/s]  5%|▌         | 27/500 [00:20<03:42,  2.13it/s]  6%|▌         | 29/500 [00:21<02:43,  2.87it/s]  6%|▌         | 31/500 [00:27<09:42,  1.24s/it]  7%|▋         | 33/500 [00:27<06:55,  1.12it/s]  7%|▋         | 35/500 [00:34<12:23,  1.60s/it]  7%|▋         | 37/500 [00:34<08:47,  1.14s/it]  8%|▊         | 39/500 [00:34<06:16,  1.22it/s]  8%|▊         | 41/500 [00:41<11:47,  1.54s/it]  9%|▊         | 43/500 [00:41<08:25,  1.11s/it]  9%|▉         | 45/500 [00:41<06:03,  1.25it/s]  9%|▉         | 47/500 [00:41<04:25,  1.71it/s] 10%|▉         | 49/500 [00:41<03:14,  2.32it/s] 10%|█         | 51/500 [00:48<09:32,  1.28s/it] 11%|█         | 53/500 [00:48<06:48,  1.09it/s] 11%|█         | 55/500 [00:48<04:53,  1.52it/s] 11%|█▏        | 57/500 [00:48<03:33,  2.07it/s] 12%|█▏        | 59/500 [00:48<02:37,  2.80it/s] 12%|█▏        | 61/500 [00:55<08:57,  1.22s/it] 13%|█▎        | 63/500 [00:55<06:23,  1.14it/s] 13%|█▎        | 65/500 [00:55<04:36,  1.58it/s] 13%|█▎        | 67/500 [00:55<03:20,  2.16it/s]Epoch:  1  	Training Loss: 0.030495241284370422
Test Loss:  0.08969590067863464
Valid Loss:  0.07613396644592285
Epoch:  2  	Training Loss: 0.06738024950027466
Test Loss:  1.1297101974487305
Valid Loss:  1.098071575164795
Epoch:  3  	Training Loss: 1.338985800743103
Test Loss:  0.10668160021305084
Valid Loss:  0.09160270541906357
Epoch:  4  	Training Loss: 0.07944509387016296
Test Loss:  0.04099947214126587
Valid Loss:  0.03692453354597092
Epoch:  5  	Training Loss: 0.029586344957351685
Test Loss:  0.03845109045505524
Valid Loss:  0.035354018211364746
Epoch:  6  	Training Loss: 0.02751205861568451
Test Loss:  0.037669599056243896
Valid Loss:  0.034703873097896576
Epoch:  7  	Training Loss: 0.026750020682811737
Test Loss:  0.03711889311671257
Valid Loss:  0.034200411289930344
Epoch:  8  	Training Loss: 0.02623811922967434
Test Loss:  0.03663768246769905
Valid Loss:  0.033759795129299164
Epoch:  9  	Training Loss: 0.025810232385993004
Test Loss:  0.03619956970214844
Valid Loss:  0.03335803374648094
Epoch:  10  	Training Loss: 0.02543741464614868
Test Loss:  0.03578326106071472
Valid Loss:  0.03297780081629753
Epoch:  11  	Training Loss: 0.025092467665672302
Test Loss:  0.035396941006183624
Valid Loss:  0.032618455588817596
Epoch:  12  	Training Loss: 0.024781515821814537
Test Loss:  0.007431739941239357
Valid Loss:  0.009672614745795727
Epoch:  13  	Training Loss: 0.011136556044220924
Test Loss:  0.005661730654537678
Valid Loss:  0.007250129245221615
Epoch:  14  	Training Loss: 0.007699562236666679
Test Loss:  0.004358288832008839
Valid Loss:  0.00526766199618578
Epoch:  15  	Training Loss: 0.005050293169915676
Test Loss:  0.004163241013884544
Valid Loss:  0.004421297460794449
Epoch:  16  	Training Loss: 0.004107749089598656
Test Loss:  0.00390824768692255
Valid Loss:  0.003910996485501528
Epoch:  17  	Training Loss: 0.0036428701132535934
Test Loss:  0.0036372484173625708
Valid Loss:  0.0034885259810835123
Epoch:  18  	Training Loss: 0.0033005811274051666
Test Loss:  0.0033334437757730484
Valid Loss:  0.0031312177889049053
Epoch:  19  	Training Loss: 0.0030163535848259926
Test Loss:  0.00307443062774837
Valid Loss:  0.002816853579133749
Epoch:  20  	Training Loss: 0.00276526203379035
Test Loss:  0.002834084676578641
Valid Loss:  0.0025505912490189075
Epoch:  21  	Training Loss: 0.00255018868483603
Test Loss:  0.0026275364216417074
Valid Loss:  0.0023223392199724913
Epoch:  22  	Training Loss: 0.0023638266138732433
Test Loss:  0.0017219424480572343
Valid Loss:  0.0012035418767482042
Epoch:  23  	Training Loss: 0.0010692962678149343
Test Loss:  0.0035297744907438755
Valid Loss:  0.004611841402947903
Epoch:  24  	Training Loss: 0.005556825548410416
Test Loss:  0.012003661133348942
Valid Loss:  0.010629911907017231
Epoch:  25  	Training Loss: 0.014038130640983582
Test Loss:  0.0037345336750149727
Valid Loss:  0.0047638630494475365
Epoch:  26  	Training Loss: 0.0066594090312719345
Test Loss:  0.0018662000074982643
Valid Loss:  0.0015141952317208052
Epoch:  27  	Training Loss: 0.0015881047584116459
Test Loss:  0.0018274172907695174
Valid Loss:  0.0013264388544484973
Epoch:  28  	Training Loss: 0.0012568878009915352
Test Loss:  0.0016486099921166897
Valid Loss:  0.0012027735356241465
Epoch:  29  	Training Loss: 0.001166095957159996
Test Loss:  0.0015554568963125348
Valid Loss:  0.0011264029890298843
Epoch:  30  	Training Loss: 0.0010971692390739918
Test Loss:  0.0014595394022762775
Valid Loss:  0.0010549637954682112
Epoch:  31  	Training Loss: 0.0010361378081142902
Test Loss:  0.0013779248110949993
Valid Loss:  0.0009955961722880602
Epoch:  32  	Training Loss: 0.0009827290195971727
Test Loss:  0.0005159098654985428
Valid Loss:  0.0007703817682340741
Epoch:  33  	Training Loss: 0.0010816496796905994
Test Loss:  0.0014752787537872791
Valid Loss:  0.0010028255637735128
Epoch:  34  	Training Loss: 0.0009913924150168896
Test Loss:  0.00044108362635597587
Valid Loss:  0.000726117636077106
Epoch:  35  	Training Loss: 0.000965563696809113
Test Loss:  0.001284316647797823
Valid Loss:  0.0008824225515127182
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0008674890850670636
Test Loss:  0.0008025544229894876
Valid Loss:  0.0005933159263804555
Epoch:  37  	Training Loss: 0.000595197023358196
Test Loss:  0.0007503692759200931
Valid Loss:  0.0005623592878691852
Epoch:  38  	Training Loss: 0.000545090064406395
Test Loss:  0.0007292375667020679
Valid Loss:  0.0005529503105208278
Epoch:  39  	Training Loss: 0.0005273551214486361
Test Loss:  0.0007208808674477041
Valid Loss:  0.0005489824106916785
Epoch:  40  	Training Loss: 0.0005194830591790378
Test Loss:  0.0007241923012770712
Valid Loss:  0.0005482982378453016
Epoch:  41  	Training Loss: 0.0005155282560735941
Test Loss:  0.0007161883404478431
Valid Loss:  0.0005441736429929733
Epoch:  42  	Training Loss: 0.0005120643181726336
Test Loss:  0.000676018069498241
Valid Loss:  0.0005185822956264019
Epoch:  43  	Training Loss: 0.00048636714927852154
Test Loss:  0.0006417408585548401
Valid Loss:  0.0004977162461727858
Epoch:  44  	Training Loss: 0.00046336997183971107
Test Loss:  0.0006113023264333606
Valid Loss:  0.00047945190453901887
Epoch:  45  	Training Loss: 0.0004424412618391216
Test Loss:  0.0005845057312399149
Valid Loss:  0.0004635402001440525
Epoch:  46  	Training Loss: 0.00042408081935718656
Test Loss:  0.0005594899994321167
Valid Loss:  0.00044924375833943486
Epoch:  47  	Training Loss: 0.00040710135363042355
Test Loss:  0.0005361310904845595
Valid Loss:  0.0004361465107649565
Epoch:  48  	Training Loss: 0.00039125350303947926
Test Loss:  0.0005148170748725533
Valid Loss:  0.0004244942683726549
Epoch:  49  	Training Loss: 0.0003765536530409008
Test Loss:  0.0004956851480528712
Valid Loss:  0.0004137049545533955
Epoch:  50  	Training Loss: 0.00036313373129814863
Test Loss:  0.00047772028483450413
Valid Loss:  0.0004036339814774692
Epoch:  51  	Training Loss: 0.0003511082613840699
Test Loss:  0.0004615865182131529
Valid Loss:  0.0003942360635846853
Epoch:  52  	Training Loss: 0.00033984743640758097
Test Loss:  0.0003963234485127032
Valid Loss:  0.0003625324461609125
Epoch:  53  	Training Loss: 0.00030568844522349536
Test Loss:  0.0003524220082908869
Valid Loss:  0.00034377677366137505
Epoch:  54  	Training Loss: 0.00028119373018853366
Test Loss:  0.0003231276641599834
Valid Loss:  0.0003340508555993438
Epoch:  55  	Training Loss: 0.00026712112594395876
Test Loss:  0.00030866629094816744
Valid Loss:  0.00032995743094943464
Epoch:  56  	Training Loss: 0.00025812501553446054
Test Loss:  0.0002957760007120669
Valid Loss:  0.0003273072652518749
Epoch:  57  	Training Loss: 0.00025157956406474113
Test Loss:  0.0002867305011022836
Valid Loss:  0.00032600894337520003
Epoch:  58  	Training Loss: 0.00024670365382917225
Test Loss:  0.00027952357777394354
Valid Loss:  0.0003253622562624514
Epoch:  59  	Training Loss: 0.00024301857047248632
Test Loss:  0.00027395429788157344
Valid Loss:  0.00032512133475393057
Epoch:  60  	Training Loss: 0.00024025485618039966
Test Loss:  0.0002696700394153595
Valid Loss:  0.00032510084565728903
Epoch:  61  	Training Loss: 0.0002381230442551896
Test Loss:  0.00026625304599292576
Valid Loss:  0.0003251948510296643
Epoch:  62  	Training Loss: 0.00023648279602639377
Test Loss:  0.0002633295371197164
Valid Loss:  0.00031974451849237084
Epoch:  63  	Training Loss: 0.00023333737044595182
Test Loss:  0.0002607223577797413
Valid Loss:  0.0003155420417897403
Epoch:  64  	Training Loss: 0.00023091827461030334
Test Loss:  0.0002595152473077178
Valid Loss:  0.0003134094295091927
Epoch:  65  	Training Loss: 0.00022983833332546055
Test Loss:  0.00025916725280694664
Valid Loss:  0.00031231416505761445
Epoch:  66  	Training Loss: 0.00022939330665394664
Test Loss:  0.00025886131334118545
Valid Loss:  0.0003120912879239768
Epoch:  67  	Training Loss: 0.00022925573284737766
Test Loss:  0.0002584432950243354
Valid Loss:  0.00031198468059301376
Epoch:  68  	Training Loss: 0.00022914647706784308
Test Loss:  0.00025811203522607684
Valid Loss:  0.00031193223549053073
 14%|█▍        | 69/500 [00:55<02:28,  2.90it/s] 14%|█▍        | 71/500 [01:02<08:35,  1.20s/it] 15%|█▍        | 73/500 [01:02<06:08,  1.16it/s] 15%|█▌        | 75/500 [01:02<04:25,  1.60it/s] 15%|█▌        | 77/500 [01:02<03:13,  2.19it/s] 16%|█▌        | 79/500 [01:02<02:23,  2.94it/s] 16%|█▌        | 81/500 [01:09<08:30,  1.22s/it] 17%|█▋        | 83/500 [01:09<06:04,  1.14it/s] 17%|█▋        | 85/500 [01:09<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:09<03:12,  2.14it/s] 18%|█▊        | 89/500 [01:09<02:24,  2.84it/s] 18%|█▊        | 91/500 [01:16<08:18,  1.22s/it] 19%|█▊        | 93/500 [01:16<05:56,  1.14it/s] 19%|█▉        | 95/500 [01:16<04:16,  1.58it/s] 19%|█▉        | 97/500 [01:16<03:07,  2.15it/s] 20%|█▉        | 99/500 [01:16<02:18,  2.89it/s] 20%|██        | 101/500 [01:23<08:02,  1.21s/it] 21%|██        | 103/500 [01:23<05:45,  1.15it/s] 21%|██        | 105/500 [01:23<04:10,  1.57it/s] 21%|██▏       | 107/500 [01:23<03:04,  2.13it/s] 22%|██▏       | 109/500 [01:24<02:17,  2.85it/s] 22%|██▏       | 111/500 [01:30<07:50,  1.21s/it] 23%|██▎       | 113/500 [01:30<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:30<04:02,  1.59it/s] 23%|██▎       | 117/500 [01:30<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:31<02:10,  2.93it/s] 24%|██▍       | 121/500 [01:37<07:34,  1.20s/it] 25%|██▍       | 123/500 [01:37<05:24,  1.16it/s] 25%|██▌       | 125/500 [01:37<03:53,  1.60it/s] 25%|██▌       | 127/500 [01:37<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:37<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:44<07:23,  1.20s/it] 27%|██▋       | 133/500 [01:44<05:17,  1.16it/s] 27%|██▋       | 135/500 [01:44<03:48,  1.60it/s]Epoch:  69  	Training Loss: 0.0002290451666340232
Test Loss:  0.00025782219017855823
Valid Loss:  0.0003119157627224922
Epoch:  70  	Training Loss: 0.0002289487747475505
Test Loss:  0.00025755682145245373
Valid Loss:  0.0003119066823273897
Epoch:  71  	Training Loss: 0.00022885366342961788
Test Loss:  0.0002573034435044974
Valid Loss:  0.00031190086156129837
Epoch:  72  	Training Loss: 0.00022876079310663044
Test Loss:  0.0002411356836091727
Valid Loss:  0.0003061555325984955
Epoch:  73  	Training Loss: 0.00022287634783424437
Test Loss:  0.00023417524062097073
Valid Loss:  0.0003017270064447075
Epoch:  74  	Training Loss: 0.00021809927420690656
Test Loss:  0.00022747370530851185
Valid Loss:  0.0002973428927361965
Epoch:  75  	Training Loss: 0.00021390337496995926
Test Loss:  0.00022150736185722053
Valid Loss:  0.0002930374466814101
Epoch:  76  	Training Loss: 0.00021007512987125665
Test Loss:  0.00021604202629532665
Valid Loss:  0.00028880403260700405
Epoch:  77  	Training Loss: 0.00020656653214246035
Test Loss:  0.0002110880013788119
Valid Loss:  0.00028467969968914986
Epoch:  78  	Training Loss: 0.0002033761702477932
Test Loss:  0.00020687405776698142
Valid Loss:  0.00028087294776923954
Epoch:  79  	Training Loss: 0.00020058697555214167
Test Loss:  0.00020280417811591178
Valid Loss:  0.0002773546730168164
Epoch:  80  	Training Loss: 0.000197991932509467
Test Loss:  0.00019904534565284848
Valid Loss:  0.0002740489726420492
Epoch:  81  	Training Loss: 0.00019557189079932868
Test Loss:  0.00019555201288312674
Valid Loss:  0.000270902703050524
Epoch:  82  	Training Loss: 0.0001933533640112728
Test Loss:  0.00019450346007943153
Valid Loss:  0.00026962789706885815
Epoch:  83  	Training Loss: 0.0001927014091052115
Test Loss:  0.0001932375889737159
Valid Loss:  0.0002683603670448065
Epoch:  84  	Training Loss: 0.0001920830982271582
Test Loss:  0.00019201947725377977
Valid Loss:  0.00026714347768574953
Epoch:  85  	Training Loss: 0.00019149410945829004
Test Loss:  0.00019090311252512038
Valid Loss:  0.000265990209300071
Epoch:  86  	Training Loss: 0.00019093224545940757
Test Loss:  0.00018984114285558462
Valid Loss:  0.00026493315817788243
Epoch:  87  	Training Loss: 0.00019039504695683718
Test Loss:  0.00018881847790908068
Valid Loss:  0.00026396309840492904
Epoch:  88  	Training Loss: 0.0001898822229122743
Test Loss:  0.0001878331386251375
Valid Loss:  0.000263052002992481
Epoch:  89  	Training Loss: 0.0001893907319754362
Test Loss:  0.00018696980259846896
Valid Loss:  0.00026220857398584485
Epoch:  90  	Training Loss: 0.00018890565843321383
Test Loss:  0.0001860381889855489
Valid Loss:  0.00026137605891563
Epoch:  91  	Training Loss: 0.0001884427183540538
Test Loss:  0.00018518889555707574
Valid Loss:  0.00026066257851198316
Epoch:  92  	Training Loss: 0.00018800076213665307
Test Loss:  0.00018429779447615147
Valid Loss:  0.0002592939417809248
Epoch:  93  	Training Loss: 0.00018616118177305907
Test Loss:  0.00018287109560333192
Valid Loss:  0.00025789847131818533
Epoch:  94  	Training Loss: 0.00018440227722749114
Test Loss:  0.00018149279640056193
Valid Loss:  0.0002565199974924326
Epoch:  95  	Training Loss: 0.00018271249427925795
Test Loss:  0.00018016296962741762
Valid Loss:  0.00025516224559396505
Epoch:  96  	Training Loss: 0.00018109686789102852
Test Loss:  0.00017890558228828013
Valid Loss:  0.0002538848202675581
Epoch:  97  	Training Loss: 0.00017955354996956885
Test Loss:  0.00017774214211385697
Valid Loss:  0.00025268059107474983
Epoch:  98  	Training Loss: 0.0001781019673217088
Test Loss:  0.00017653621034696698
Valid Loss:  0.00025147158885374665
Epoch:  99  	Training Loss: 0.00017672189278528094
Test Loss:  0.00017548829782754183
Valid Loss:  0.0002503401192370802
Epoch:  100  	Training Loss: 0.00017539950204081833
Test Loss:  0.00017450176528654993
Valid Loss:  0.0002492572530172765
Epoch:  101  	Training Loss: 0.00017412328452337533
Test Loss:  0.00017355853924527764
Valid Loss:  0.00024821757688187063
Epoch:  102  	Training Loss: 0.0001729045616229996
Test Loss:  0.00017325830413028598
Valid Loss:  0.00024773369659669697
Epoch:  103  	Training Loss: 0.00017211218073498458
Test Loss:  0.00017275741265621036
Valid Loss:  0.0002472077321726829
Epoch:  104  	Training Loss: 0.00017136275710072368
Test Loss:  0.00017228434444405138
Valid Loss:  0.0002466757141519338
Epoch:  105  	Training Loss: 0.00017065095016732812
Test Loss:  0.00017194953397847712
Valid Loss:  0.00024618295719847083
Epoch:  106  	Training Loss: 0.00016996546764858067
Test Loss:  0.0001715276448521763
Valid Loss:  0.00024566653883084655
Epoch:  107  	Training Loss: 0.00016932431026361883
Test Loss:  0.00017114401271101087
Valid Loss:  0.0002451547479722649
Epoch:  108  	Training Loss: 0.0001687214244157076
Test Loss:  0.0001709468342596665
Valid Loss:  0.00024471242795698345
Epoch:  109  	Training Loss: 0.00016813876572996378
Test Loss:  0.000170782208442688
Valid Loss:  0.0002442905097268522
Epoch:  110  	Training Loss: 0.00016757452976889908
Test Loss:  0.0001706389884930104
Valid Loss:  0.00024390529142692685
Epoch:  111  	Training Loss: 0.00016702768334653229
Test Loss:  0.0001705000177025795
Valid Loss:  0.00024354277411475778
Epoch:  112  	Training Loss: 0.00016649754252284765
Test Loss:  0.00017032335745170712
Valid Loss:  0.00024323005345650017
Epoch:  113  	Training Loss: 0.00016601363313384354
Test Loss:  0.00016902602510526776
Valid Loss:  0.00024266334366984665
Epoch:  114  	Training Loss: 0.0001655820815358311
Test Loss:  0.0001684386224951595
Valid Loss:  0.00024224200751632452
Epoch:  115  	Training Loss: 0.0001651849306654185
Test Loss:  0.00016761281585786492
Valid Loss:  0.0002417720970697701
Epoch:  116  	Training Loss: 0.0001648142351768911
Test Loss:  0.00016700229025445879
Valid Loss:  0.00024136144202202559
Epoch:  117  	Training Loss: 0.0001644789444981143
Test Loss:  0.0001663226867094636
Valid Loss:  0.00024094422406051308
Epoch:  118  	Training Loss: 0.0001641631533857435
Test Loss:  0.0001657388056628406
Valid Loss:  0.00024054621462710202
Epoch:  119  	Training Loss: 0.00016387240611948073
Test Loss:  0.0001651792845223099
Valid Loss:  0.00024015230883378536
Epoch:  120  	Training Loss: 0.00016360418521799147
Test Loss:  0.00016465771477669477
Valid Loss:  0.00023976777447387576
Epoch:  121  	Training Loss: 0.00016334943939000368
Test Loss:  0.00016422211774624884
Valid Loss:  0.0002394088514847681
Epoch:  122  	Training Loss: 0.00016311908257193863
Test Loss:  0.00016324431635439396
Valid Loss:  0.00023878796491771936
Epoch:  123  	Training Loss: 0.00016219276585616171
Test Loss:  0.00016247009625658393
Valid Loss:  0.00023823228548280895
Epoch:  124  	Training Loss: 0.00016131091979332268
Test Loss:  0.00016176988719962537
Valid Loss:  0.00023770668485667557
Epoch:  125  	Training Loss: 0.00016047267126850784
Test Loss:  0.00016112437879201025
Valid Loss:  0.0002372099261265248
Epoch:  126  	Training Loss: 0.00015968180377967656
Test Loss:  0.00016055638843681663
Valid Loss:  0.00023675488773733377
Epoch:  127  	Training Loss: 0.00015895852993708104
Test Loss:  0.00016002406482584774
Valid Loss:  0.00023631312069483101
Epoch:  128  	Training Loss: 0.00015826184244360775
Test Loss:  0.00015953416004776955
Valid Loss:  0.00023589085321873426
Epoch:  129  	Training Loss: 0.00015759309462737292
Test Loss:  0.0001590711617609486
Valid Loss:  0.0002354805765207857
Epoch:  130  	Training Loss: 0.00015695752517785877
Test Loss:  0.00015864736633375287
Valid Loss:  0.0002350886061321944
Epoch:  131  	Training Loss: 0.00015635386807844043
Test Loss:  0.00015823835565242916
Valid Loss:  0.0002347141271457076
Epoch:  132  	Training Loss: 0.00015577577869407833
Test Loss:  0.00015874559176154435
Valid Loss:  0.0002345301618333906
Epoch:  133  	Training Loss: 0.0001556403876747936
Test Loss:  0.00015896069817245007
Valid Loss:  0.00023430674627888948
Epoch:  134  	Training Loss: 0.00015553904813714325
Test Loss:  0.00015896203694865108
Valid Loss:  0.0002340484643355012
Epoch:  135  	Training Loss: 0.0001554554037284106
Test Loss:  0.00015892402734607458
Valid Loss:  0.00023380988568533212
Epoch:  136  	Training Loss: 0.00015537856961600482
 27%|██▋       | 137/500 [01:44<02:46,  2.18it/s] 28%|██▊       | 139/500 [01:44<02:03,  2.93it/s] 28%|██▊       | 141/500 [01:51<07:15,  1.21s/it] 29%|██▊       | 143/500 [01:51<05:12,  1.14it/s] 29%|██▉       | 145/500 [01:51<03:45,  1.57it/s] 29%|██▉       | 147/500 [01:51<02:44,  2.15it/s] 30%|██▉       | 149/500 [01:52<02:01,  2.90it/s] 30%|███       | 151/500 [01:58<07:01,  1.21s/it] 31%|███       | 153/500 [01:58<05:03,  1.14it/s] 31%|███       | 155/500 [01:58<03:40,  1.57it/s] 31%|███▏      | 157/500 [01:59<02:42,  2.12it/s] 32%|███▏      | 159/500 [01:59<02:01,  2.81it/s] 32%|███▏      | 161/500 [02:05<06:55,  1.23s/it] 33%|███▎      | 163/500 [02:05<04:56,  1.14it/s] 33%|███▎      | 165/500 [02:05<03:33,  1.57it/s] 33%|███▎      | 167/500 [02:06<02:34,  2.15it/s] 34%|███▍      | 169/500 [02:06<01:54,  2.90it/s] 34%|███▍      | 171/500 [02:12<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:12<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:12<03:25,  1.58it/s] 35%|███▌      | 177/500 [02:13<02:31,  2.14it/s] 36%|███▌      | 179/500 [02:13<01:53,  2.83it/s] 36%|███▌      | 181/500 [02:19<06:26,  1.21s/it] 37%|███▋      | 183/500 [02:19<04:37,  1.14it/s] 37%|███▋      | 185/500 [02:20<03:20,  1.57it/s] 37%|███▋      | 187/500 [02:20<02:26,  2.14it/s] 38%|███▊      | 189/500 [02:20<01:48,  2.87it/s] 38%|███▊      | 191/500 [02:26<06:14,  1.21s/it] 39%|███▊      | 193/500 [02:26<04:27,  1.15it/s] 39%|███▉      | 195/500 [02:27<03:12,  1.59it/s] 39%|███▉      | 197/500 [02:27<02:21,  2.14it/s] 40%|███▉      | 199/500 [02:27<01:46,  2.83it/s] 40%|████      | 201/500 [02:33<06:00,  1.21s/it]Test Loss:  0.00015886727487668395
Valid Loss:  0.00023359300394076854
Epoch:  137  	Training Loss: 0.00015530738164670765
Test Loss:  0.00015880170394666493
Valid Loss:  0.0002333972224732861
Epoch:  138  	Training Loss: 0.00015524201444350183
Test Loss:  0.0001586714352015406
Valid Loss:  0.00023319132742471993
Epoch:  139  	Training Loss: 0.00015518395230174065
Test Loss:  0.00015858327969908714
Valid Loss:  0.00023301478358916938
Epoch:  140  	Training Loss: 0.00015512941172346473
Test Loss:  0.00015851223724894226
Valid Loss:  0.0002328598638996482
Epoch:  141  	Training Loss: 0.00015507778152823448
Test Loss:  0.00015845533926039934
Valid Loss:  0.0002327316178707406
Epoch:  142  	Training Loss: 0.0001550281886011362
Test Loss:  0.00015693678869865835
Valid Loss:  0.00023219955619424582
Epoch:  143  	Training Loss: 0.00015471794176846743
Test Loss:  0.00015636481111869216
Valid Loss:  0.00023197950213216245
Epoch:  144  	Training Loss: 0.0001544609694974497
Test Loss:  0.00015604440704919398
Valid Loss:  0.00023183853772934526
Epoch:  145  	Training Loss: 0.00015421482385136187
Test Loss:  0.00015580191393382847
Valid Loss:  0.00023171756765805185
Epoch:  146  	Training Loss: 0.0001539752702228725
Test Loss:  0.0001556066854391247
Valid Loss:  0.0002316082245670259
Epoch:  147  	Training Loss: 0.00015374156646430492
Test Loss:  0.00015542451001238078
Valid Loss:  0.0002315047604497522
Epoch:  148  	Training Loss: 0.00015351289766840637
Test Loss:  0.00015524998889304698
Valid Loss:  0.00023140494886320084
Epoch:  149  	Training Loss: 0.00015329019515775144
Test Loss:  0.0001550964661873877
Valid Loss:  0.0002313143340870738
Epoch:  150  	Training Loss: 0.0001530855952296406
Test Loss:  0.0001549391308799386
Valid Loss:  0.0002312238939339295
Epoch:  151  	Training Loss: 0.00015288483700715005
Test Loss:  0.0001547850260976702
Valid Loss:  0.0002311353455297649
Epoch:  152  	Training Loss: 0.0001526886480860412
Test Loss:  0.00015544940833933651
Valid Loss:  0.00023123290156945586
Epoch:  153  	Training Loss: 0.00015202689974103123
Test Loss:  0.00015449163038283587
Valid Loss:  0.00023068174778018147
Epoch:  154  	Training Loss: 0.00015141702897381037
Test Loss:  0.00015401725249830633
Valid Loss:  0.00023031086311675608
Epoch:  155  	Training Loss: 0.00015082457684911788
Test Loss:  0.00015343209088314325
Valid Loss:  0.00022989010903984308
Epoch:  156  	Training Loss: 0.00015024826279841363
Test Loss:  0.0001528942957520485
Valid Loss:  0.00022948344121687114
Epoch:  157  	Training Loss: 0.0001496919576311484
Test Loss:  0.00015237880870699883
Valid Loss:  0.0002290797419846058
Epoch:  158  	Training Loss: 0.0001491503935540095
Test Loss:  0.00015187864482868463
Valid Loss:  0.00022867924417369068
Epoch:  159  	Training Loss: 0.0001486241235397756
Test Loss:  0.00015141282347030938
Valid Loss:  0.0002282897476106882
Epoch:  160  	Training Loss: 0.00014810898574069142
Test Loss:  0.0001509370922576636
Valid Loss:  0.00022789421200286597
Epoch:  161  	Training Loss: 0.0001476114266552031
Test Loss:  0.0001504824758740142
Valid Loss:  0.0002275054284837097
Epoch:  162  	Training Loss: 0.00014713012205902487
Test Loss:  0.0001480890205129981
Valid Loss:  0.0002239036839455366
Epoch:  163  	Training Loss: 0.0001453012228012085
Test Loss:  0.00014653873222414404
Valid Loss:  0.0002209629601566121
Epoch:  164  	Training Loss: 0.00014378516061697155
Test Loss:  0.00014574421220459044
Valid Loss:  0.0002193511463701725
Epoch:  165  	Training Loss: 0.00014284317148849368
Test Loss:  0.00014522428682539612
Valid Loss:  0.0002184043696615845
Epoch:  166  	Training Loss: 0.00014225913037080318
Test Loss:  0.00014482092228718102
Valid Loss:  0.00021769723389297724
Epoch:  167  	Training Loss: 0.00014184130122885108
Test Loss:  0.00014447903959080577
Valid Loss:  0.0002171739179175347
Epoch:  168  	Training Loss: 0.000141494267154485
Test Loss:  0.00014419305080082268
Valid Loss:  0.00021681241923943162
Epoch:  169  	Training Loss: 0.00014119214029051363
Test Loss:  0.00014395356993190944
Valid Loss:  0.0002164974866900593
Epoch:  170  	Training Loss: 0.00014092907076701522
Test Loss:  0.00014368831762112677
Valid Loss:  0.00021618550817947835
Epoch:  171  	Training Loss: 0.00014068758173380047
Test Loss:  0.0001434498408343643
Valid Loss:  0.00021587993251159787
Epoch:  172  	Training Loss: 0.00014045083662495017
Test Loss:  0.00014294903667178005
Valid Loss:  0.00021535123232752085
Epoch:  173  	Training Loss: 0.00013903179205954075
Test Loss:  0.0001423613866791129
Valid Loss:  0.0002148075873265043
Epoch:  174  	Training Loss: 0.00013769848737865686
Test Loss:  0.00014176264812704176
Valid Loss:  0.0002142908633686602
Epoch:  175  	Training Loss: 0.00013646137085743248
Test Loss:  0.00014117846149019897
Valid Loss:  0.00021381904662121087
Epoch:  176  	Training Loss: 0.00013533711899071932
Test Loss:  0.00014061937690712512
Valid Loss:  0.00021341278625186533
Epoch:  177  	Training Loss: 0.00013430160470306873
Test Loss:  0.00014009169535711408
Valid Loss:  0.0002130915381712839
Epoch:  178  	Training Loss: 0.00013337242125999182
Test Loss:  0.00013954873429611325
Valid Loss:  0.0002128104242729023
Epoch:  179  	Training Loss: 0.0001325505436398089
Test Loss:  0.00013903042417950928
Valid Loss:  0.00021258118795230985
Epoch:  180  	Training Loss: 0.00013181864051148295
Test Loss:  0.00013862346531823277
Valid Loss:  0.00021242637012619525
Epoch:  181  	Training Loss: 0.00013113871682435274
Test Loss:  0.00013810998643748462
Valid Loss:  0.0002122584992321208
Epoch:  182  	Training Loss: 0.00013057273463346064
Test Loss:  0.00013822191976942122
Valid Loss:  0.00021193549036979675
Epoch:  183  	Training Loss: 0.00013027209206484258
Test Loss:  0.00013828123337589204
Valid Loss:  0.00021164192003197968
Epoch:  184  	Training Loss: 0.0001300090370932594
Test Loss:  0.00013832157128490508
Valid Loss:  0.00021139602176845074
Epoch:  185  	Training Loss: 0.00012977579899597913
Test Loss:  0.00013835084973834455
Valid Loss:  0.00021117877622600645
Epoch:  186  	Training Loss: 0.00012956088175997138
Test Loss:  0.0001383689814247191
Valid Loss:  0.00021099466539453715
Epoch:  187  	Training Loss: 0.00012936357234138995
Test Loss:  0.00013838429003953934
Valid Loss:  0.00021083175670355558
Epoch:  188  	Training Loss: 0.00012917967978864908
Test Loss:  0.00013837181904818863
Valid Loss:  0.0002106816100422293
Epoch:  189  	Training Loss: 0.0001290096843149513
Test Loss:  0.0001383679627906531
Valid Loss:  0.00021054937678854913
Epoch:  190  	Training Loss: 0.00012884699390269816
Test Loss:  0.0001383664202876389
Valid Loss:  0.00021043377637397498
Epoch:  191  	Training Loss: 0.0001286907645408064
Test Loss:  0.0001383644703309983
Valid Loss:  0.0002103302686009556
Epoch:  192  	Training Loss: 0.000128537678392604
Test Loss:  0.0001384750648867339
Valid Loss:  0.00021022805594839156
Epoch:  193  	Training Loss: 0.00012850247730966657
Test Loss:  0.0001385569921694696
Valid Loss:  0.00021014909725636244
Epoch:  194  	Training Loss: 0.00012847495963796973
Test Loss:  0.00013861579645890743
Valid Loss:  0.00021009152987971902
Epoch:  195  	Training Loss: 0.00012845342280343175
Test Loss:  0.0001386615476803854
Valid Loss:  0.00021004973677918315
Epoch:  196  	Training Loss: 0.00012843424337916076
Test Loss:  0.0001386975054629147
Valid Loss:  0.00021001798450015485
Epoch:  197  	Training Loss: 0.0001284166210098192
Test Loss:  0.00013872521230950952
Valid Loss:  0.00020999391563236713
Epoch:  198  	Training Loss: 0.00012840039562433958
Test Loss:  0.0001387482334394008
Valid Loss:  0.00020997520186938345
Epoch:  199  	Training Loss: 0.00012838472321163863
Test Loss:  0.00013876700541004539
Valid Loss:  0.00020996108651161194
Epoch:  200  	Training Loss: 0.0001283693709410727
Test Loss:  0.00013878097524866462
Valid Loss:  0.00020994995429646224
Epoch:  201  	Training Loss: 0.00012835516827180982
Test Loss:  0.00013878935715183616
Valid Loss:  0.00020994379883632064
Epoch:  202  	Training Loss: 0.00012834236258640885
Test Loss:  0.0001380360045004636
Valid Loss:  0.00020958649110980332
Epoch:  203  	Training Loss: 0.00012796875671483576
Test Loss:   41%|████      | 203/500 [02:34<04:17,  1.15it/s] 41%|████      | 205/500 [02:34<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:34<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:34<01:40,  2.90it/s] 42%|████▏     | 211/500 [02:40<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:41<04:08,  1.16it/s] 43%|████▎     | 215/500 [02:41<03:00,  1.58it/s] 43%|████▎     | 217/500 [02:41<02:12,  2.13it/s] 44%|████▍     | 219/500 [02:41<01:39,  2.82it/s] 44%|████▍     | 221/500 [02:47<05:35,  1.20s/it] 45%|████▍     | 223/500 [02:48<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:48<02:54,  1.58it/s] 45%|████▌     | 227/500 [02:48<02:07,  2.15it/s] 46%|████▌     | 229/500 [02:48<01:34,  2.88it/s] 46%|████▌     | 231/500 [02:54<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:55<03:50,  1.16it/s] 47%|████▋     | 235/500 [02:55<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:55<02:00,  2.18it/s] 48%|████▊     | 239/500 [02:55<01:28,  2.93it/s] 48%|████▊     | 241/500 [03:01<05:11,  1.20s/it] 49%|████▊     | 243/500 [03:02<03:42,  1.16it/s] 49%|████▉     | 245/500 [03:02<02:39,  1.60it/s] 49%|████▉     | 247/500 [03:02<01:56,  2.18it/s] 50%|████▉     | 249/500 [03:02<01:25,  2.92it/s] 50%|█████     | 251/500 [03:08<04:54,  1.18s/it] 51%|█████     | 253/500 [03:08<03:29,  1.18it/s] 51%|█████     | 255/500 [03:09<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:09<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:09<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:15<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:15<03:25,  1.16it/s] 53%|█████▎    | 265/500 [03:16<02:28,  1.58it/s] 53%|█████▎    | 267/500 [03:16<01:48,  2.15it/s] 54%|█████▍    | 269/500 [03:16<01:19,  2.89it/s]0.00013738346751779318
Valid Loss:  0.00020925169519614428
Epoch:  204  	Training Loss: 0.00012762653932441026
Test Loss:  0.0001368736702715978
Valid Loss:  0.00020898116054013371
Epoch:  205  	Training Loss: 0.00012729584705084562
Test Loss:  0.00013643191778101027
Valid Loss:  0.0002087246102746576
Epoch:  206  	Training Loss: 0.0001269748026970774
Test Loss:  0.00013604463310912251
Valid Loss:  0.00020847617997787893
Epoch:  207  	Training Loss: 0.00012666259135585278
Test Loss:  0.00013567315181717277
Valid Loss:  0.00020824739476665854
Epoch:  208  	Training Loss: 0.0001263604935957119
Test Loss:  0.00013532114098779857
Valid Loss:  0.0002080246777040884
Epoch:  209  	Training Loss: 0.00012606926611624658
Test Loss:  0.0001349881786154583
Valid Loss:  0.0002078091201838106
Epoch:  210  	Training Loss: 0.00012578432506415993
Test Loss:  0.0001346758654108271
Valid Loss:  0.00020760379265993834
Epoch:  211  	Training Loss: 0.00012550692190416157
Test Loss:  0.00013439211761578918
Valid Loss:  0.00020740182662848383
Epoch:  212  	Training Loss: 0.00012523806071840227
Test Loss:  0.00013405492063611746
Valid Loss:  0.0002069688925985247
Epoch:  213  	Training Loss: 0.00012510991655290127
Test Loss:  0.0001339790760539472
Valid Loss:  0.00020666871569119394
Epoch:  214  	Training Loss: 0.00012499099830165505
Test Loss:  0.00013386915088631213
Valid Loss:  0.0002063751162495464
Epoch:  215  	Training Loss: 0.00012488043284974992
Test Loss:  0.00013377467985264957
Valid Loss:  0.00020610366482287645
Epoch:  216  	Training Loss: 0.00012477234122343361
Test Loss:  0.00013367290375754237
Valid Loss:  0.00020584369485732168
Epoch:  217  	Training Loss: 0.00012466605403460562
Test Loss:  0.0001335649285465479
Valid Loss:  0.0002055912627838552
Epoch:  218  	Training Loss: 0.0001245621097041294
Test Loss:  0.00013343204045668244
Valid Loss:  0.0002053344651358202
Epoch:  219  	Training Loss: 0.00012446216715034097
Test Loss:  0.0001333250547759235
Valid Loss:  0.00020509358728304505
Epoch:  220  	Training Loss: 0.00012436340330168605
Test Loss:  0.00013321542064659297
Valid Loss:  0.00020485615823417902
Epoch:  221  	Training Loss: 0.00012426527973730117
Test Loss:  0.00013310505892150104
Valid Loss:  0.0002046230947598815
Epoch:  222  	Training Loss: 0.00012416814570315182
Test Loss:  0.00013252560165710747
Valid Loss:  0.00020419969223439693
Epoch:  223  	Training Loss: 0.00012407198664732277
Test Loss:  0.00013247624156065285
Valid Loss:  0.00020401811343617737
Epoch:  224  	Training Loss: 0.00012398282706271857
Test Loss:  0.00013228104216977954
Valid Loss:  0.00020376643806230277
Epoch:  225  	Training Loss: 0.00012389571929816157
Test Loss:  0.00013213942293077707
Valid Loss:  0.00020353599393274635
Epoch:  226  	Training Loss: 0.00012381034321151674
Test Loss:  0.0001319914881605655
Valid Loss:  0.00020329969993326813
Epoch:  227  	Training Loss: 0.00012372765922918916
Test Loss:  0.0001318335416726768
Valid Loss:  0.00020305486395955086
Epoch:  228  	Training Loss: 0.0001236496609635651
Test Loss:  0.00013171424507163465
Valid Loss:  0.0002028263988904655
Epoch:  229  	Training Loss: 0.00012357259402051568
Test Loss:  0.00013158921501599252
Valid Loss:  0.0002025951980613172
Epoch:  230  	Training Loss: 0.00012349702592473477
Test Loss:  0.00013147368736099452
Valid Loss:  0.00020236913405824453
Epoch:  231  	Training Loss: 0.00012342390255071223
Test Loss:  0.00013135169865563512
Valid Loss:  0.0002021405380219221
Epoch:  232  	Training Loss: 0.00012335125938989222
Test Loss:  0.00013117498019710183
Valid Loss:  0.00020206111366860569
Epoch:  233  	Training Loss: 0.00012326589785516262
Test Loss:  0.0001310202933382243
Valid Loss:  0.00020199394202791154
Epoch:  234  	Training Loss: 0.00012318711378611624
Test Loss:  0.00013088484411127865
Valid Loss:  0.00020193777163513005
Epoch:  235  	Training Loss: 0.00012311375758145005
Test Loss:  0.00013076623145025223
Valid Loss:  0.0002018905070144683
Epoch:  236  	Training Loss: 0.00012304513074923307
Test Loss:  0.00013066345127299428
Valid Loss:  0.00020185155153740197
Epoch:  237  	Training Loss: 0.000122980767628178
Test Loss:  0.00013057464093435556
Valid Loss:  0.00020182009029667825
Epoch:  238  	Training Loss: 0.00012291973689571023
Test Loss:  0.00013049764675088227
Valid Loss:  0.00020179474086035043
Epoch:  239  	Training Loss: 0.0001228618493769318
Test Loss:  0.0001304315956076607
Valid Loss:  0.00020177483384031802
Epoch:  240  	Training Loss: 0.00012280694500077516
Test Loss:  0.00013037509052082896
Valid Loss:  0.00020176026737317443
Epoch:  241  	Training Loss: 0.00012275416520424187
Test Loss:  0.00013032660353928804
Valid Loss:  0.00020174981909804046
Epoch:  242  	Training Loss: 0.00012270361185073853
Test Loss:  0.0001320819865213707
Valid Loss:  0.00020240714366082102
Epoch:  243  	Training Loss: 0.00012229953426867723
Test Loss:  0.00013194489292800426
Valid Loss:  0.00020226823107805103
Epoch:  244  	Training Loss: 0.00012213198351673782
Test Loss:  0.00013194463099353015
Valid Loss:  0.00020220800070092082
Epoch:  245  	Training Loss: 0.00012197453179396689
Test Loss:  0.00013193087943363935
Valid Loss:  0.0002021544351009652
Epoch:  246  	Training Loss: 0.00012182816863059998
Test Loss:  0.00013188929005991668
Valid Loss:  0.00020208934438414872
Epoch:  247  	Training Loss: 0.00012169305409770459
Test Loss:  0.00013188316370360553
Valid Loss:  0.00020205062173772603
Epoch:  248  	Training Loss: 0.00012156400043750182
Test Loss:  0.00013186843716539443
Valid Loss:  0.00020201594452373683
Epoch:  249  	Training Loss: 0.00012143970525357872
Test Loss:  0.00013185027637518942
Valid Loss:  0.00020199762366246432
Epoch:  250  	Training Loss: 0.00012131920084357262
Test Loss:  0.00013182991824578494
Valid Loss:  0.00020198451238684356
Epoch:  251  	Training Loss: 0.00012120555038563907
Test Loss:  0.00013176430366002023
Valid Loss:  0.00020195016986690462
Epoch:  252  	Training Loss: 0.00012109931412851438
Test Loss:  0.00013172542094253004
Valid Loss:  0.00020189915085211396
Epoch:  253  	Training Loss: 0.00012106615758966655
Test Loss:  0.000131708467961289
Valid Loss:  0.00020186053006909788
Epoch:  254  	Training Loss: 0.00012103402696084231
Test Loss:  0.00013170207967050374
Valid Loss:  0.0002018288942053914
Epoch:  255  	Training Loss: 0.00012100255116820335
Test Loss:  0.00013169694284442812
Valid Loss:  0.00020180254068691283
Epoch:  256  	Training Loss: 0.00012097138096578419
Test Loss:  0.00013169352314434946
Valid Loss:  0.00020177848637104034
Epoch:  257  	Training Loss: 0.00012094032717868686
Test Loss:  0.00013168943405617028
Valid Loss:  0.0002017564111156389
Epoch:  258  	Training Loss: 0.00012090942618669942
Test Loss:  0.00013168553414288908
Valid Loss:  0.0002017354272538796
Epoch:  259  	Training Loss: 0.0001208787361974828
Test Loss:  0.0001316798443440348
Valid Loss:  0.0002017156803049147
Epoch:  260  	Training Loss: 0.00012084812624379992
Test Loss:  0.00013167090946808457
Valid Loss:  0.0002016971993725747
Epoch:  261  	Training Loss: 0.00012081780005246401
Test Loss:  0.0001316609705099836
Valid Loss:  0.0002016801299760118
Epoch:  262  	Training Loss: 0.00012078785221092403
Test Loss:  0.00013046388630755246
Valid Loss:  0.0002010614116443321
Epoch:  263  	Training Loss: 0.00012051494559273124
Test Loss:  0.00013021138147450984
Valid Loss:  0.00020090719044674188
Epoch:  264  	Training Loss: 0.000120279670227319
Test Loss:  0.00012993504060432315
Valid Loss:  0.0002007356088142842
Epoch:  265  	Training Loss: 0.00012005319877061993
Test Loss:  0.00012969589442946017
Valid Loss:  0.0002005675050895661
Epoch:  266  	Training Loss: 0.00011983473086729646
Test Loss:  0.00012949392839800566
Valid Loss:  0.00020040158415213227
Epoch:  267  	Training Loss: 0.00011962336429860443
Test Loss:  0.00012927435454912484
Valid Loss:  0.00020021434465888888
Epoch:  268  	Training Loss: 0.00011943420395255089
Test Loss:  0.00012907575001008809
Valid Loss:  0.00020003283862024546
Epoch:  269  	Training Loss: 0.00011925585567951202
Test Loss:  0.00012893610983155668
Valid Loss:  0.00019987487758044153
Epoch:  270  	Training Loss: 0.00011906559666385874
 54%|█████▍    | 271/500 [03:22<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:22<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:22<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:23<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:23<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:29<04:22,  1.20s/it] 57%|█████▋    | 283/500 [03:29<03:06,  1.16it/s] 57%|█████▋    | 285/500 [03:29<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:30<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:30<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:36<04:13,  1.21s/it] 59%|█████▊    | 293/500 [03:36<03:01,  1.14it/s] 59%|█████▉    | 295/500 [03:37<02:10,  1.57it/s] 59%|█████▉    | 297/500 [03:37<01:36,  2.11it/s] 60%|█████▉    | 299/500 [03:37<01:11,  2.80it/s] 60%|██████    | 301/500 [03:43<04:01,  1.21s/it] 61%|██████    | 303/500 [03:43<02:52,  1.14it/s] 61%|██████    | 305/500 [03:44<02:04,  1.57it/s] 61%|██████▏   | 307/500 [03:44<01:31,  2.12it/s] 62%|██████▏   | 309/500 [03:44<01:08,  2.81it/s] 62%|██████▏   | 311/500 [03:50<03:49,  1.21s/it] 63%|██████▎   | 313/500 [03:51<02:43,  1.14it/s] 63%|██████▎   | 315/500 [03:51<01:58,  1.57it/s] 63%|██████▎   | 317/500 [03:51<01:26,  2.11it/s] 64%|██████▍   | 319/500 [03:51<01:04,  2.82it/s] 64%|██████▍   | 321/500 [03:57<03:35,  1.20s/it] 65%|██████▍   | 323/500 [03:58<02:34,  1.15it/s] 65%|██████▌   | 325/500 [03:58<01:51,  1.57it/s] 65%|██████▌   | 327/500 [03:58<01:20,  2.14it/s] 66%|██████▌   | 329/500 [03:58<00:59,  2.88it/s] 66%|██████▌   | 331/500 [04:04<03:23,  1.20s/it] 67%|██████▋   | 333/500 [04:05<02:25,  1.15it/s] 67%|██████▋   | 335/500 [04:05<01:44,  1.57it/s]Test Loss:  0.00012798490934073925
Valid Loss:  0.00019931556016672403
Epoch:  271  	Training Loss: 0.00011858699872391298
Test Loss:  0.00012597058957908303
Valid Loss:  0.00019801949383690953
Epoch:  272  	Training Loss: 0.0001171347321360372
Test Loss:  0.00012682893429882824
Valid Loss:  0.00019810881349258125
Epoch:  273  	Training Loss: 0.00011697277659550309
Test Loss:  0.00012718178913928568
Valid Loss:  0.00019805558258667588
Epoch:  274  	Training Loss: 0.00011689827806549147
Test Loss:  0.0001273125526495278
Valid Loss:  0.00019793481624219567
Epoch:  275  	Training Loss: 0.00011684087803587317
Test Loss:  0.00012734343181364238
Valid Loss:  0.00019778384012170136
Epoch:  276  	Training Loss: 0.00011678789451252669
Test Loss:  0.00012732864706777036
Valid Loss:  0.00019762241572607309
Epoch:  277  	Training Loss: 0.00011673744302242994
Test Loss:  0.0001272942463401705
Valid Loss:  0.00019745891040656716
Epoch:  278  	Training Loss: 0.00011668849765555933
Test Loss:  0.00012725131819024682
Valid Loss:  0.00019729704945348203
Epoch:  279  	Training Loss: 0.00011664094927255064
Test Loss:  0.00012720449012704194
Valid Loss:  0.0001971378515008837
Epoch:  280  	Training Loss: 0.00011659454321488738
Test Loss:  0.00012715571210719645
Valid Loss:  0.00019698261166922748
Epoch:  281  	Training Loss: 0.00011654928675852716
Test Loss:  0.0001271059736609459
Valid Loss:  0.0001968307769857347
Epoch:  282  	Training Loss: 0.00011650501983240247
Test Loss:  0.00012726429849863052
Valid Loss:  0.00019690637418534607
Epoch:  283  	Training Loss: 0.00011637994612101465
Test Loss:  0.00012724354746751487
Valid Loss:  0.00019690759654622525
Epoch:  284  	Training Loss: 0.00011627146159298718
Test Loss:  0.0001271646178793162
Valid Loss:  0.00019688281463459134
Epoch:  285  	Training Loss: 0.00011616709525696933
Test Loss:  0.0001270711945835501
Valid Loss:  0.00019685181905515492
Epoch:  286  	Training Loss: 0.00011606613406911492
Test Loss:  0.00012697139754891396
Valid Loss:  0.00019681768026202917
Epoch:  287  	Training Loss: 0.00011596655531320721
Test Loss:  0.00012686192349065095
Valid Loss:  0.000196782813873142
Epoch:  288  	Training Loss: 0.00011586878827074543
Test Loss:  0.0001267532934434712
Valid Loss:  0.00019674983923323452
Epoch:  289  	Training Loss: 0.00011577229452086613
Test Loss:  0.00012664565292652696
Valid Loss:  0.000196719920495525
Epoch:  290  	Training Loss: 0.00011567752517294139
Test Loss:  0.0001265402534045279
Valid Loss:  0.00019669096218422055
Epoch:  291  	Training Loss: 0.00011558571713976562
Test Loss:  0.00012644287198781967
Valid Loss:  0.0001966648706002161
Epoch:  292  	Training Loss: 0.00011549704504432157
Test Loss:  0.00012234652240294963
Valid Loss:  0.00019455654546618462
Epoch:  293  	Training Loss: 0.00011385019752196968
Test Loss:  0.00012285786215215921
Valid Loss:  0.00019477569730952382
Epoch:  294  	Training Loss: 0.00011314091534586623
Test Loss:  0.0001227246830239892
Valid Loss:  0.00019473020802251995
Epoch:  295  	Training Loss: 0.00011286823428235948
Test Loss:  0.00012271691230125725
Valid Loss:  0.00019474056898616254
Epoch:  296  	Training Loss: 0.00011273124982835725
Test Loss:  0.00012266782869119197
Valid Loss:  0.00019470005645416677
Epoch:  297  	Training Loss: 0.00011262895714025944
Test Loss:  0.00012269531725905836
Valid Loss:  0.00019466241064947098
Epoch:  298  	Training Loss: 0.000112557114334777
Test Loss:  0.00012283919204492122
Valid Loss:  0.00019464787328615785
Epoch:  299  	Training Loss: 0.00011249510862398893
Test Loss:  0.00012283166870474815
Valid Loss:  0.00019456827430985868
Epoch:  300  	Training Loss: 0.00011243694461882114
Test Loss:  0.00012283411342650652
Valid Loss:  0.0001944974937941879
Epoch:  301  	Training Loss: 0.00011238130537094548
Test Loss:  0.0001228294859174639
Valid Loss:  0.00019442655320744962
Epoch:  302  	Training Loss: 0.00011232735414523631
Test Loss:  0.00012342300033196807
Valid Loss:  0.00019441216136328876
Epoch:  303  	Training Loss: 0.00011195244587725028
Test Loss:  0.00012282175885047764
Valid Loss:  0.00019383407197892666
Epoch:  304  	Training Loss: 0.0001116175262723118
Test Loss:  0.0001227921457029879
Valid Loss:  0.00019352897652424872
Epoch:  305  	Training Loss: 0.00011131764040328562
Test Loss:  0.00012259979848749936
Valid Loss:  0.00019314387463964522
Epoch:  306  	Training Loss: 0.00011103039287263528
Test Loss:  0.000122395547805354
Valid Loss:  0.0001927730190800503
Epoch:  307  	Training Loss: 0.0001107559073716402
Test Loss:  0.00012214102025609463
Valid Loss:  0.0001923864911077544
Epoch:  308  	Training Loss: 0.00011050383182009682
Test Loss:  0.00012197442993056029
Valid Loss:  0.00019204548152629286
Epoch:  309  	Training Loss: 0.00011026550782844424
Test Loss:  0.00012179926852695644
Valid Loss:  0.00019170540326740593
Epoch:  310  	Training Loss: 0.00011003623512806371
Test Loss:  0.00012162847997387871
Valid Loss:  0.00019138140487484634
Epoch:  311  	Training Loss: 0.00010981321975123137
Test Loss:  0.0001214395888382569
Valid Loss:  0.0001910555874928832
Epoch:  312  	Training Loss: 0.0001095989573514089
Test Loss:  0.00012187215179437771
Valid Loss:  0.00019065552623942494
Epoch:  313  	Training Loss: 0.00010932362056337297
Test Loss:  0.00012207214604131877
Valid Loss:  0.00019029114628210664
Epoch:  314  	Training Loss: 0.00010913003643509
Test Loss:  0.00012217786570545286
Valid Loss:  0.0001899858907563612
Epoch:  315  	Training Loss: 0.00010898518667090684
Test Loss:  0.00012222901568748057
Valid Loss:  0.0001897281181300059
Epoch:  316  	Training Loss: 0.00010886734526138753
Test Loss:  0.00012225465616211295
Valid Loss:  0.0001895000896183774
Epoch:  317  	Training Loss: 0.00010876156011363491
Test Loss:  0.00012225635873619467
Valid Loss:  0.0001892917207442224
Epoch:  318  	Training Loss: 0.0001086651100195013
Test Loss:  0.00012225571845192462
Valid Loss:  0.00018911065126303583
Epoch:  319  	Training Loss: 0.00010857750021386892
Test Loss:  0.00012221228098496795
Valid Loss:  0.00018893444212153554
Epoch:  320  	Training Loss: 0.00010849646059796214
Test Loss:  0.00012215175956953317
Valid Loss:  0.00018876511603593826
Epoch:  321  	Training Loss: 0.00010841901530511677
Test Loss:  0.00012208009138703346
Valid Loss:  0.00018860197451431304
Epoch:  322  	Training Loss: 0.00010834467684617266
Test Loss:  0.00012126032379455864
Valid Loss:  0.0001879982155514881
Epoch:  323  	Training Loss: 0.00010813476546900347
Test Loss:  0.00012110497482353821
Valid Loss:  0.00018769892631098628
Epoch:  324  	Training Loss: 0.0001079423091141507
Test Loss:  0.00012088362564099953
Valid Loss:  0.0001873706205515191
Epoch:  325  	Training Loss: 0.00010775822738651186
Test Loss:  0.0001206716478918679
Valid Loss:  0.000187044104677625
Epoch:  326  	Training Loss: 0.00010757789277704433
Test Loss:  0.00012046281335642561
Valid Loss:  0.00018671723955776542
Epoch:  327  	Training Loss: 0.00010740614379756153
Test Loss:  0.00012028906348859891
Valid Loss:  0.00018640808411873877
Epoch:  328  	Training Loss: 0.00010723982268245891
Test Loss:  0.00012010621139779687
Valid Loss:  0.0001860975316958502
Epoch:  329  	Training Loss: 0.00010707633919082582
Test Loss:  0.00011992383224423975
Valid Loss:  0.0001857892784755677
Epoch:  330  	Training Loss: 0.0001069152494892478
Test Loss:  0.00011974320659646764
Valid Loss:  0.00018548357184045017
Epoch:  331  	Training Loss: 0.00010675657540559769
Test Loss:  0.00011956710659433156
Valid Loss:  0.00018518084834795445
Epoch:  332  	Training Loss: 0.00010659945837687701
Test Loss:  0.00011928004823857918
Valid Loss:  0.0001849304826464504
Epoch:  333  	Training Loss: 0.00010650116018950939
Test Loss:  0.00011905712017323822
Valid Loss:  0.00018471077783033252
Epoch:  334  	Training Loss: 0.00010640825348673388
Test Loss:  0.00011885273124789819
Valid Loss:  0.0001844978833105415
Epoch:  335  	Training Loss: 0.00010631935583660379
Test Loss:  0.00011866363638546318
Valid Loss:  0.00018428958719596267
Epoch:  336  	Training Loss: 0.00010623379785101861
Test Loss:  0.00011848886060761288
Valid Loss:  0.00018408639880362898
Epoch:  337  	Training Loss: 0.00010615063365548849
 67%|██████▋   | 337/500 [04:05<01:16,  2.12it/s] 68%|██████▊   | 339/500 [04:05<00:57,  2.80it/s] 68%|██████▊   | 341/500 [04:12<03:19,  1.26s/it] 69%|██████▊   | 343/500 [04:12<02:21,  1.11it/s] 69%|██████▉   | 345/500 [04:12<01:40,  1.54it/s] 69%|██████▉   | 347/500 [04:12<01:12,  2.10it/s] 70%|██████▉   | 349/500 [04:12<00:53,  2.83it/s] 70%|███████   | 351/500 [04:19<02:58,  1.20s/it] 71%|███████   | 353/500 [04:19<02:07,  1.16it/s] 71%|███████   | 355/500 [04:19<01:31,  1.58it/s] 71%|███████▏  | 357/500 [04:19<01:06,  2.14it/s] 72%|███████▏  | 359/500 [04:19<00:49,  2.84it/s] 72%|███████▏  | 361/500 [04:26<02:50,  1.23s/it] 73%|███████▎  | 363/500 [04:26<02:00,  1.14it/s] 73%|███████▎  | 365/500 [04:26<01:25,  1.57it/s] 73%|███████▎  | 367/500 [04:26<01:01,  2.15it/s] 74%|███████▍  | 369/500 [04:27<00:45,  2.90it/s] 74%|███████▍  | 371/500 [04:33<02:37,  1.22s/it] 75%|███████▍  | 373/500 [04:33<01:51,  1.14it/s] 75%|███████▌  | 375/500 [04:33<01:18,  1.58it/s] 75%|███████▌  | 377/500 [04:33<00:56,  2.17it/s] 76%|███████▌  | 379/500 [04:34<00:41,  2.92it/s] 76%|███████▌  | 381/500 [04:40<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:40<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:40<01:12,  1.60it/s] 77%|███████▋  | 387/500 [04:40<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:41<00:37,  2.93it/s] 78%|███████▊  | 391/500 [04:47<02:12,  1.21s/it] 79%|███████▊  | 393/500 [04:47<01:33,  1.14it/s] 79%|███████▉  | 395/500 [04:47<01:07,  1.57it/s] 79%|███████▉  | 397/500 [04:48<00:48,  2.12it/s] 80%|███████▉  | 399/500 [04:48<00:36,  2.80it/s] 80%|████████  | 401/500 [04:54<02:02,  1.23s/it] 81%|████████  | 403/500 [04:55<01:26,  1.12it/s]Test Loss:  0.00011832554446300492
Valid Loss:  0.0001838865427998826
Epoch:  338  	Training Loss: 0.00010606940486468375
Test Loss:  0.00011817113409051672
Valid Loss:  0.0001836887386161834
Epoch:  339  	Training Loss: 0.00010599006782285869
Test Loss:  0.00011802473454736173
Valid Loss:  0.00018349409219808877
Epoch:  340  	Training Loss: 0.00010591183672659099
Test Loss:  0.00011788508709287271
Valid Loss:  0.00018330200691707432
Epoch:  341  	Training Loss: 0.00010583532275632024
Test Loss:  0.00011775096936617047
Valid Loss:  0.00018311143503524363
Epoch:  342  	Training Loss: 0.00010575985652394593
Test Loss:  0.00011790690768975765
Valid Loss:  0.0001831941626733169
Epoch:  343  	Training Loss: 0.0001057174158631824
Test Loss:  0.00011795651516877115
Valid Loss:  0.0001832180714700371
Epoch:  344  	Training Loss: 0.00010568069410510361
Test Loss:  0.00011797046317951754
Valid Loss:  0.00018322384858038276
Epoch:  345  	Training Loss: 0.00010564540571067482
Test Loss:  0.00011797394836321473
Valid Loss:  0.00018322250980418175
Epoch:  346  	Training Loss: 0.00010561069211689755
Test Loss:  0.00011797322804341093
Valid Loss:  0.00018321929383091629
Epoch:  347  	Training Loss: 0.00010557666246313602
Test Loss:  0.00011797102342825383
Valid Loss:  0.0001832150883274153
Epoch:  348  	Training Loss: 0.00010554349864833057
Test Loss:  0.00011796845501521602
Valid Loss:  0.0001832105335779488
Epoch:  349  	Training Loss: 0.00010551064042374492
Test Loss:  0.00011796503531513736
Valid Loss:  0.00018320519302506
Epoch:  350  	Training Loss: 0.00010547842975938693
Test Loss:  0.00011796145554399118
Valid Loss:  0.0001831998524721712
Epoch:  351  	Training Loss: 0.00010544677934376523
Test Loss:  0.00011795724276453257
Valid Loss:  0.0001831942645367235
Epoch:  352  	Training Loss: 0.00010541560914134607
Test Loss:  0.00011770085984608158
Valid Loss:  0.00018303480464965105
Epoch:  353  	Training Loss: 0.00010537024354562163
Test Loss:  0.00011751298734452575
Valid Loss:  0.00018291646847501397
Epoch:  354  	Training Loss: 0.00010533004387980327
Test Loss:  0.00011736863234546036
Valid Loss:  0.00018282426754012704
Epoch:  355  	Training Loss: 0.00010529237624723464
Test Loss:  0.00011725164949893951
Valid Loss:  0.0001827480737119913
Epoch:  356  	Training Loss: 0.00010525620746193454
Test Loss:  0.00011715268192347139
Valid Loss:  0.0001826827647164464
Epoch:  357  	Training Loss: 0.0001052210500347428
Test Loss:  0.00011706491932272911
Valid Loss:  0.00018262385856360197
Epoch:  358  	Training Loss: 0.00010518654016777873
Test Loss:  0.00011698511661961675
Valid Loss:  0.00018257035117130727
Epoch:  359  	Training Loss: 0.00010515256872167811
Test Loss:  0.00011691023246385157
Valid Loss:  0.0001825195358833298
Epoch:  360  	Training Loss: 0.00010511916480027139
Test Loss:  0.00011683970660669729
Valid Loss:  0.00018247138359583914
Epoch:  361  	Training Loss: 0.00010508677223697305
Test Loss:  0.00011677137081278488
Valid Loss:  0.00018242490477859974
Epoch:  362  	Training Loss: 0.00010505486716283485
Test Loss:  0.00011625030310824513
Valid Loss:  0.00018209320842288435
Epoch:  363  	Training Loss: 0.00010499072959646583
Test Loss:  0.00011612739763222635
Valid Loss:  0.00018199675832875073
Epoch:  364  	Training Loss: 0.00010494008893147111
Test Loss:  0.00011604409519350156
Valid Loss:  0.0001819243043428287
Epoch:  365  	Training Loss: 0.00010489109990885481
Test Loss:  0.00011596724652918056
Valid Loss:  0.000181856332346797
Epoch:  366  	Training Loss: 0.00010484366066521034
Test Loss:  0.00011589365021791309
Valid Loss:  0.00018179111066274345
Epoch:  367  	Training Loss: 0.00010479743650648743
Test Loss:  0.00011582241859287024
Valid Loss:  0.0001817273732740432
Epoch:  368  	Training Loss: 0.00010475277667865157
Test Loss:  0.00011575414100661874
Valid Loss:  0.00018166577501688153
Epoch:  369  	Training Loss: 0.00010470965935382992
Test Loss:  0.00011568845366127789
Valid Loss:  0.00018160669424105436
Epoch:  370  	Training Loss: 0.00010466824460308999
Test Loss:  0.00011562465806491673
Valid Loss:  0.0001815486466512084
Epoch:  371  	Training Loss: 0.00010462794307386503
Test Loss:  0.0001155625723185949
Valid Loss:  0.00018149212701246142
Epoch:  372  	Training Loss: 0.00010458847100380808
Test Loss:  0.00011582530714804307
Valid Loss:  0.00018143928900826722
Epoch:  373  	Training Loss: 0.00010448123794049025
Test Loss:  0.00011581452417885885
Valid Loss:  0.00018125787028111517
Epoch:  374  	Training Loss: 0.00010438411845825613
Test Loss:  0.00011579420970520005
Valid Loss:  0.000181078547029756
Epoch:  375  	Training Loss: 0.00010429015674162656
Test Loss:  0.00011576663382584229
Valid Loss:  0.00018090230878442526
Epoch:  376  	Training Loss: 0.0001041988653014414
Test Loss:  0.00011573132360354066
Valid Loss:  0.0001807287917472422
Epoch:  377  	Training Loss: 0.00010410926188342273
Test Loss:  0.00011568934860406443
Valid Loss:  0.00018055753025691956
Epoch:  378  	Training Loss: 0.00010402132465969771
Test Loss:  0.00011564188753254712
Valid Loss:  0.00018038747657556087
Epoch:  379  	Training Loss: 0.00010393567208666354
Test Loss:  0.00011557215475477278
Valid Loss:  0.00018020992865785956
Epoch:  380  	Training Loss: 0.00010385241330368444
Test Loss:  0.00011551566421985626
Valid Loss:  0.00018004253797698766
Epoch:  381  	Training Loss: 0.00010376978025306016
Test Loss:  0.00011545544111868367
Valid Loss:  0.00017987620958592743
Epoch:  382  	Training Loss: 0.00010368773655500263
Test Loss:  0.00011480299872346222
Valid Loss:  0.00017937037046067417
Epoch:  383  	Training Loss: 0.00010345917689846829
Test Loss:  0.00011451674799900502
Valid Loss:  0.000179047099663876
Epoch:  384  	Training Loss: 0.00010324800678063184
Test Loss:  0.00011410140723455697
Valid Loss:  0.00017864226538222283
Epoch:  385  	Training Loss: 0.00010306468902854249
Test Loss:  0.00011383831588318571
Valid Loss:  0.00017829693388193846
Epoch:  386  	Training Loss: 0.0001028981787385419
Test Loss:  0.00011360493226675317
Valid Loss:  0.00017796001338865608
Epoch:  387  	Training Loss: 0.00010273334191879258
Test Loss:  0.00011339742923155427
Valid Loss:  0.00017762643983587623
Epoch:  388  	Training Loss: 0.0001025707897497341
Test Loss:  0.00011319387704133987
Valid Loss:  0.00017729961837176234
Epoch:  389  	Training Loss: 0.00010241210111416876
Test Loss:  0.00011297332093818113
Valid Loss:  0.00017696304712444544
Epoch:  390  	Training Loss: 0.00010225870209978893
Test Loss:  0.00011281840852461755
Valid Loss:  0.00017665621999185532
Epoch:  391  	Training Loss: 0.00010210694745182991
Test Loss:  0.00011266439105384052
Valid Loss:  0.00017634460527915508
Epoch:  392  	Training Loss: 0.00010195795039180666
Test Loss:  0.00011309305409668013
Valid Loss:  0.0001764518383424729
Epoch:  393  	Training Loss: 0.00010181369725614786
Test Loss:  0.00011315827578073367
Valid Loss:  0.00017638951248954982
Epoch:  394  	Training Loss: 0.00010170237510465086
Test Loss:  0.00011313884169794619
Valid Loss:  0.00017628871137276292
Epoch:  395  	Training Loss: 0.00010159869270864874
Test Loss:  0.00011309651017654687
Valid Loss:  0.00017617714183870703
Epoch:  396  	Training Loss: 0.00010150152957066894
Test Loss:  0.00011305275256745517
Valid Loss:  0.00017606856999918818
Epoch:  397  	Training Loss: 0.00010140669473912567
Test Loss:  0.00011300706682959571
Valid Loss:  0.0001759624865371734
Epoch:  398  	Training Loss: 0.00010131443559657782
Test Loss:  0.00011295702279312536
Valid Loss:  0.00017585442401468754
Epoch:  399  	Training Loss: 0.00010123018000740558
Test Loss:  0.00011290993279544637
Valid Loss:  0.00017575043602846563
Epoch:  400  	Training Loss: 0.00010114764154423028
Test Loss:  0.00011286221706541255
Valid Loss:  0.0001756483397912234
Epoch:  401  	Training Loss: 0.00010106752597494051
Test Loss:  0.00011281033221166581
Valid Loss:  0.00017554379883222282
Epoch:  402  	Training Loss: 0.00010099363134941086
Test Loss:  0.0001122823596233502
Valid Loss:  0.00017496582586318254
Epoch:  403  	Training Loss: 0.00010080522042699158
Test Loss:  0.00011232012911932543
Valid Loss:  0.00017469799786340445
 81%|████████  | 405/500 [04:55<01:01,  1.54it/s] 81%|████████▏ | 407/500 [04:55<00:44,  2.08it/s] 82%|████████▏ | 409/500 [04:55<00:32,  2.77it/s] 82%|████████▏ | 411/500 [05:01<01:47,  1.21s/it] 82%|████████▏ | 412/500 [05:01<01:28,  1.01s/it] 83%|████████▎ | 414/500 [05:02<01:00,  1.43it/s] 83%|████████▎ | 416/500 [05:02<00:41,  2.03it/s] 84%|████████▎ | 418/500 [05:02<00:29,  2.79it/s] 84%|████████▍ | 420/500 [05:02<00:21,  3.74it/s] 84%|████████▍ | 422/500 [05:09<01:32,  1.19s/it] 85%|████████▍ | 424/500 [05:09<01:04,  1.19it/s] 85%|████████▌ | 426/500 [05:09<00:44,  1.65it/s] 86%|████████▌ | 428/500 [05:09<00:31,  2.26it/s] 86%|████████▌ | 430/500 [05:09<00:23,  3.04it/s] 86%|████████▋ | 432/500 [05:15<01:20,  1.19s/it] 87%|████████▋ | 434/500 [05:16<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:16<00:39,  1.62it/s] 88%|████████▊ | 438/500 [05:16<00:28,  2.21it/s] 88%|████████▊ | 440/500 [05:16<00:20,  2.97it/s] 88%|████████▊ | 442/500 [05:22<01:08,  1.19s/it] 89%|████████▉ | 444/500 [05:22<00:47,  1.17it/s] 89%|████████▉ | 446/500 [05:23<00:33,  1.62it/s] 90%|████████▉ | 448/500 [05:23<00:23,  2.21it/s] 90%|█████████ | 450/500 [05:23<00:16,  2.98it/s] 90%|█████████ | 452/500 [05:29<00:58,  1.22s/it] 91%|█████████ | 454/500 [05:30<00:40,  1.14it/s] 91%|█████████ | 456/500 [05:30<00:27,  1.58it/s] 92%|█████████▏| 458/500 [05:30<00:19,  2.16it/s] 92%|█████████▏| 460/500 [05:30<00:13,  2.92it/s] 92%|█████████▏| 462/500 [05:37<00:47,  1.24s/it] 93%|█████████▎| 464/500 [05:37<00:32,  1.12it/s] 93%|█████████▎| 466/500 [05:37<00:21,  1.55it/s] 94%|█████████▎| 468/500 [05:37<00:15,  2.12it/s] 94%|█████████▍| 470/500 [05:37<00:10,  2.86it/s]Epoch:  404  	Training Loss: 0.00010062758519779891
Test Loss:  0.00011202241876162589
Valid Loss:  0.0001742884051054716
Epoch:  405  	Training Loss: 0.00010046012175735086
Test Loss:  0.00011189970246050507
Valid Loss:  0.0001739856379572302
Epoch:  406  	Training Loss: 0.00010029874101746827
Test Loss:  0.00011167632328579202
Valid Loss:  0.00017363851657137275
Epoch:  407  	Training Loss: 0.00010014050349127501
Test Loss:  0.0001115104096243158
Valid Loss:  0.00017332688730675727
Epoch:  408  	Training Loss: 9.998522000387311e-05
Test Loss:  0.00011131396604469046
Valid Loss:  0.00017300437320955098
Epoch:  409  	Training Loss: 9.983207564800978e-05
Test Loss:  0.00011113492655567825
Valid Loss:  0.0001726956106722355
Epoch:  410  	Training Loss: 9.9682089057751e-05
Test Loss:  0.00011094139335909858
Valid Loss:  0.00017238670261576772
Epoch:  411  	Training Loss: 9.953508561011404e-05
Test Loss:  0.000110759494418744
Valid Loss:  0.00017208627832587808
Epoch:  412  	Training Loss: 9.938966832123697e-05
Test Loss:  0.0001103311515180394
Valid Loss:  0.000171743449755013
Epoch:  413  	Training Loss: 9.931193199008703e-05
Test Loss:  0.00011018894292647019
Valid Loss:  0.00017155930981971323
Epoch:  414  	Training Loss: 9.924478945322335e-05
Test Loss:  0.00011009417357854545
Valid Loss:  0.00017140043200924993
Epoch:  415  	Training Loss: 9.917886927723885e-05
Test Loss:  0.0001100087320082821
Valid Loss:  0.00017124653095379472
Epoch:  416  	Training Loss: 9.911331289913505e-05
Test Loss:  0.00010992690658895299
Valid Loss:  0.00017109507462009788
Epoch:  417  	Training Loss: 9.904854232445359e-05
Test Loss:  0.00010984788968926296
Valid Loss:  0.00017094463692046702
Epoch:  418  	Training Loss: 9.898419375531375e-05
Test Loss:  0.00010977064084727317
Valid Loss:  0.0001707954506855458
Epoch:  419  	Training Loss: 9.892043453874066e-05
Test Loss:  0.00010969516006298363
Valid Loss:  0.00017064841813407838
Epoch:  420  	Training Loss: 9.885723557090387e-05
Test Loss:  0.0001096215273719281
Valid Loss:  0.00017050204041879624
Epoch:  421  	Training Loss: 9.87946186796762e-05
Test Loss:  0.00010954953904729337
Valid Loss:  0.00017035732162185013
Epoch:  422  	Training Loss: 9.873236558632925e-05
Test Loss:  0.00010850910621229559
Valid Loss:  0.00016976540791802108
Epoch:  423  	Training Loss: 9.835302626015618e-05
Test Loss:  0.00010846655641216785
Valid Loss:  0.00016978051280602813
Epoch:  424  	Training Loss: 9.816369856707752e-05
Test Loss:  0.00010795873822644353
Valid Loss:  0.00016949015844147652
Epoch:  425  	Training Loss: 9.805740410229191e-05
Test Loss:  0.00010813807602971792
Valid Loss:  0.0001695859245955944
Epoch:  426  	Training Loss: 9.799641702556983e-05
Test Loss:  0.00010778516298159957
Valid Loss:  0.00016935549501795322
Epoch:  427  	Training Loss: 9.794659854378551e-05
Test Loss:  0.00010791030945256352
Valid Loss:  0.0001694108941592276
Epoch:  428  	Training Loss: 9.790596959646791e-05
Test Loss:  0.00010767050116555765
Valid Loss:  0.00016924849478527904
Epoch:  429  	Training Loss: 9.787340241018683e-05
Test Loss:  0.00010777858551591635
Valid Loss:  0.00016929123376030475
Epoch:  430  	Training Loss: 9.784195572137833e-05
Test Loss:  0.00010763669706648216
Valid Loss:  0.00016918734763748944
Epoch:  431  	Training Loss: 9.781165863387287e-05
Test Loss:  0.0001076863263733685
Valid Loss:  0.00016919596237130463
Epoch:  432  	Training Loss: 9.778352978173643e-05
Test Loss:  0.00010806483624037355
Valid Loss:  0.0001691016077529639
Epoch:  433  	Training Loss: 9.754661732586101e-05
Test Loss:  0.00010789512452902272
Valid Loss:  0.00016876263543963432
Epoch:  434  	Training Loss: 9.735971980262548e-05
Test Loss:  0.00010788220970425755
Valid Loss:  0.00016855305875651538
Epoch:  435  	Training Loss: 9.719596710056067e-05
Test Loss:  0.00010792911052703857
Valid Loss:  0.0001683936279732734
Epoch:  436  	Training Loss: 9.705382399260998e-05
Test Loss:  0.00010788545478135347
Valid Loss:  0.0001681991998339072
Epoch:  437  	Training Loss: 9.692770254332572e-05
Test Loss:  0.00010785675112856552
Valid Loss:  0.00016802691970951855
Epoch:  438  	Training Loss: 9.681884694145992e-05
Test Loss:  0.00010782525350805372
Valid Loss:  0.00016786990454420447
Epoch:  439  	Training Loss: 9.671715088188648e-05
Test Loss:  0.00010772816312965006
Valid Loss:  0.00016768756904639304
Epoch:  440  	Training Loss: 9.662621596362442e-05
Test Loss:  0.00010769681830424815
Valid Loss:  0.0001675516541581601
Epoch:  441  	Training Loss: 9.653793676989153e-05
Test Loss:  0.00010763311001937836
Valid Loss:  0.0001674079248914495
Epoch:  442  	Training Loss: 9.645119280321524e-05
Test Loss:  0.00010696182289393619
Valid Loss:  0.0001668940531089902
Epoch:  443  	Training Loss: 9.630418935557827e-05
Test Loss:  0.00010687510075513273
Valid Loss:  0.00016671464254613966
Epoch:  444  	Training Loss: 9.617459727451205e-05
Test Loss:  0.0001067751509253867
Valid Loss:  0.00016652571503072977
Epoch:  445  	Training Loss: 9.604672959540039e-05
Test Loss:  0.00010668135655578226
Valid Loss:  0.0001663368020672351
Epoch:  446  	Training Loss: 9.592306741978973e-05
Test Loss:  0.00010656143422238529
Valid Loss:  0.00016612910258118063
Epoch:  447  	Training Loss: 9.580510959494859e-05
Test Loss:  0.00010640761320246384
Valid Loss:  0.0001659073168411851
Epoch:  448  	Training Loss: 9.569920075591654e-05
Test Loss:  0.00010633848432917148
Valid Loss:  0.00016572937602177262
Epoch:  449  	Training Loss: 9.55991999944672e-05
Test Loss:  0.00010626988660078496
Valid Loss:  0.00016555427282582968
Epoch:  450  	Training Loss: 9.550334652885795e-05
Test Loss:  0.00010620454850140959
Valid Loss:  0.0001653819635976106
Epoch:  451  	Training Loss: 9.541404142510146e-05
Test Loss:  0.00010610377648845315
Valid Loss:  0.00016519453492946923
Epoch:  452  	Training Loss: 9.532837430015206e-05
Test Loss:  0.00010612144251354039
Valid Loss:  0.00016520294593647122
Epoch:  453  	Training Loss: 9.518666774965823e-05
Test Loss:  0.00010566468699835241
Valid Loss:  0.00016492010036017746
Epoch:  454  	Training Loss: 9.506198693998158e-05
Test Loss:  0.00010548331192694604
Valid Loss:  0.00016481442435178906
Epoch:  455  	Training Loss: 9.495089761912823e-05
Test Loss:  0.00010523338278289884
Valid Loss:  0.00016466795932501554
Epoch:  456  	Training Loss: 9.485312330070883e-05
Test Loss:  0.00010504836973268539
Valid Loss:  0.00016456100274808705
Epoch:  457  	Training Loss: 9.476135892327875e-05
Test Loss:  0.00010487177496543154
Valid Loss:  0.0001644536096137017
Epoch:  458  	Training Loss: 9.46739237406291e-05
Test Loss:  0.00010473764268681407
Valid Loss:  0.0001643747091293335
Epoch:  459  	Training Loss: 9.4593022367917e-05
Test Loss:  0.00010458256292622536
Valid Loss:  0.00016428461822215468
Epoch:  460  	Training Loss: 9.451806545257568e-05
Test Loss:  0.00010445836960570887
Valid Loss:  0.00016421412874478847
Epoch:  461  	Training Loss: 9.444991155760363e-05
Test Loss:  0.00010434209980303422
Valid Loss:  0.0001641500275582075
Epoch:  462  	Training Loss: 9.438776760362089e-05
Test Loss:  0.00010424779611639678
Valid Loss:  0.00016399749438278377
Epoch:  463  	Training Loss: 9.429998317500576e-05
Test Loss:  0.000104185011878144
Valid Loss:  0.00016386425704695284
Epoch:  464  	Training Loss: 9.421586582902819e-05
Test Loss:  0.0001041266368702054
Valid Loss:  0.00016373369726352394
Epoch:  465  	Training Loss: 9.413521911483258e-05
Test Loss:  0.00010406749788671732
Valid Loss:  0.00016360246809199452
Epoch:  466  	Training Loss: 9.405537275597453e-05
Test Loss:  0.00010400866449344903
Valid Loss:  0.00016347109340131283
Epoch:  467  	Training Loss: 9.397607209393755e-05
Test Loss:  0.00010395361459814012
Valid Loss:  0.00016334111569449306
Epoch:  468  	Training Loss: 9.389858314534649e-05
Test Loss:  0.00010389942326582968
Valid Loss:  0.00016321087605319917
Epoch:  469  	Training Loss: 9.382145799463615e-05
Test Loss:  0.00010384462075307965
Valid Loss:  0.00016307993791997433
Epoch:  470  	Training Loss: 9.374447108712047e-05
Test Loss:  0.0001037898036884144
Valid Loss:  0.00016294953820761293
Epoch:  471  	Training Loss: 9.366848826175556e-05
 94%|█████████▍| 472/500 [05:44<00:34,  1.22s/it] 95%|█████████▍| 474/500 [05:44<00:22,  1.14it/s] 95%|█████████▌| 476/500 [05:44<00:15,  1.56it/s] 96%|█████████▌| 478/500 [05:44<00:10,  2.11it/s] 96%|█████████▌| 480/500 [05:44<00:07,  2.80it/s] 96%|█████████▋| 482/500 [05:51<00:21,  1.22s/it] 97%|█████████▋| 484/500 [05:51<00:13,  1.15it/s] 97%|█████████▋| 486/500 [05:51<00:08,  1.59it/s] 98%|█████████▊| 488/500 [05:51<00:05,  2.17it/s] 98%|█████████▊| 490/500 [05:51<00:03,  2.92it/s] 98%|█████████▊| 492/500 [05:58<00:09,  1.18s/it] 99%|█████████▉| 494/500 [05:58<00:05,  1.18it/s] 99%|█████████▉| 496/500 [05:58<00:02,  1.61it/s]100%|█████████▉| 498/500 [05:58<00:00,  2.18it/s]100%|██████████| 500/500 [05:58<00:00,  2.93it/s]100%|██████████| 500/500 [05:58<00:00,  1.39it/s]
Test Loss:  0.00010373800614615902
Valid Loss:  0.00016282008436974138
Epoch:  472  	Training Loss: 9.359490650240332e-05
Test Loss:  0.00010388181544840336
Valid Loss:  0.00016242772107943892
Epoch:  473  	Training Loss: 9.336811490356922e-05
Test Loss:  0.00010389885574113578
Valid Loss:  0.00016204090206883848
Epoch:  474  	Training Loss: 9.318277443526313e-05
Test Loss:  0.00010386441863374785
Valid Loss:  0.0001616739173186943
Epoch:  475  	Training Loss: 9.302509715780616e-05
Test Loss:  0.00010381107131252065
Valid Loss:  0.00016133634198922664
Epoch:  476  	Training Loss: 9.289459558203816e-05
Test Loss:  0.00010374290286563337
Valid Loss:  0.00016103364760056138
Epoch:  477  	Training Loss: 9.27883229451254e-05
Test Loss:  0.00010368020593887195
Valid Loss:  0.00016076308384072036
Epoch:  478  	Training Loss: 9.269799920730293e-05
Test Loss:  0.00010363342880737036
Valid Loss:  0.00016052095452323556
Epoch:  479  	Training Loss: 9.262026287615299e-05
Test Loss:  0.00010359090083511546
Valid Loss:  0.00016030343249440193
Epoch:  480  	Training Loss: 9.255355689674616e-05
Test Loss:  0.00010355701670050621
Valid Loss:  0.00016010802937671542
Epoch:  481  	Training Loss: 9.249473077943549e-05
Test Loss:  0.00010352952813263983
Valid Loss:  0.00015993183478713036
Epoch:  482  	Training Loss: 9.244293323718011e-05
Test Loss:  0.00010287154145771638
Valid Loss:  0.00015952714602462947
Epoch:  483  	Training Loss: 9.223592496709898e-05
Test Loss:  0.00010277592809870839
Valid Loss:  0.00015936317504383624
Epoch:  484  	Training Loss: 9.210461576003581e-05
Test Loss:  0.00010276586544932798
Valid Loss:  0.00015923945466056466
Epoch:  485  	Training Loss: 9.200091153616086e-05
Test Loss:  0.00010274682426825166
Valid Loss:  0.00015911131049506366
Epoch:  486  	Training Loss: 9.191836579702795e-05
Test Loss:  0.00010274059604853392
Valid Loss:  0.00015898750280030072
Epoch:  487  	Training Loss: 9.184560622088611e-05
Test Loss:  0.00010270823258906603
Valid Loss:  0.00015885192260611802
Epoch:  488  	Training Loss: 9.177735773846507e-05
Test Loss:  0.00010264364391332492
Valid Loss:  0.00015869815251789987
Epoch:  489  	Training Loss: 9.171024430543184e-05
Test Loss:  0.00010257500252919272
Valid Loss:  0.00015854202501941472
Epoch:  490  	Training Loss: 9.164407674688846e-05
Test Loss:  0.00010250609193462878
Valid Loss:  0.0001583853445481509
Epoch:  491  	Training Loss: 9.157836029771715e-05
Test Loss:  0.00010243745055049658
Valid Loss:  0.0001582341647008434
Epoch:  492  	Training Loss: 9.151402628049254e-05
Test Loss:  0.00010279011621605605
Valid Loss:  0.000158297159941867
Epoch:  493  	Training Loss: 9.139148460235447e-05
Test Loss:  0.00010275557724526152
Valid Loss:  0.00015816325321793556
Epoch:  494  	Training Loss: 9.12987015908584e-05
Test Loss:  0.0001026703102979809
Valid Loss:  0.00015800358960404992
Epoch:  495  	Training Loss: 9.12133909878321e-05
Test Loss:  0.00010261128772981465
Valid Loss:  0.00015785693540237844
Epoch:  496  	Training Loss: 9.112891711993143e-05
Test Loss:  0.00010255944653181359
Valid Loss:  0.00015771602920722216
Epoch:  497  	Training Loss: 9.104632772505283e-05
Test Loss:  0.00010248956823488697
Valid Loss:  0.00015756695938762277
Epoch:  498  	Training Loss: 9.097030851989985e-05
Test Loss:  0.00010238199320156127
Valid Loss:  0.00015740390517748892
Epoch:  499  	Training Loss: 9.090240928344429e-05
Test Loss:  0.00010232246131636202
Valid Loss:  0.0001572694454807788
Epoch:  500  	Training Loss: 9.083743498194963e-05
Test Loss:  0.00010224364814348519
Valid Loss:  0.0001571287721162662
seed is  2
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 14.82it/s]  1%|          | 4/500 [00:00<00:31, 15.64it/s]  1%|          | 6/500 [00:00<00:31, 15.52it/s]  2%|▏         | 8/500 [00:00<00:30, 15.88it/s]  2%|▏         | 10/500 [00:00<00:30, 16.07it/s]  2%|▏         | 12/500 [00:00<00:29, 16.28it/s]  3%|▎         | 14/500 [00:00<00:29, 16.27it/s]  3%|▎         | 16/500 [00:00<00:29, 16.29it/s]  4%|▎         | 18/500 [00:01<00:29, 16.38it/s]  4%|▍         | 20/500 [00:01<00:29, 16.41it/s]  4%|▍         | 22/500 [00:01<00:29, 16.38it/s]  5%|▍         | 24/500 [00:01<00:30, 15.41it/s]  5%|▌         | 26/500 [00:01<00:32, 14.39it/s]  6%|▌         | 28/500 [00:01<00:34, 13.76it/s]  6%|▌         | 30/500 [00:01<00:35, 13.38it/s]  6%|▋         | 32/500 [00:02<00:35, 13.09it/s]  7%|▋         | 34/500 [00:02<00:36, 12.82it/s]  7%|▋         | 36/500 [00:02<00:36, 12.59it/s]  8%|▊         | 38/500 [00:02<00:36, 12.54it/s]  8%|▊         | 40/500 [00:02<00:36, 12.54it/s]  8%|▊         | 42/500 [00:02<00:36, 12.52it/s]  9%|▉         | 44/500 [00:03<00:36, 12.51it/s]  9%|▉         | 46/500 [00:03<00:36, 12.50it/s] 10%|▉         | 48/500 [00:03<00:34, 13.08it/s] 10%|█         | 50/500 [00:03<00:32, 13.85it/s] 10%|█         | 52/500 [00:03<00:30, 14.51it/s] 11%|█         | 54/500 [00:03<00:29, 15.02it/s] 11%|█         | 56/500 [00:03<00:28, 15.43it/s] 12%|█▏        | 58/500 [00:04<00:28, 15.71it/s] 12%|█▏        | 60/500 [00:04<00:27, 15.92it/s] 12%|█▏        | 62/500 [00:04<00:27, 16.08it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.22it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.28it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.13it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.13it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.18it/s] 15%|█▍        | 74/500 [00:05<00:26, 16.27it/s] 15%|█▌        | 76/500 [00:05<00:25, 16.36it/s] 16%|█▌        | 78/500 [00:05<00:25, 16.27it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.34it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.35it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.37it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.37it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.04it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.09it/s] 18%|█▊        | 92/500 [00:06<00:25, 16.23it/s] 19%|█▉        | 94/500 [00:06<00:24, 16.30it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.41it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.43it/s] 20%|██        | 100/500 [00:06<00:24, 16.52it/s] 20%|██        | 102/500 [00:06<00:24, 16.47it/s] 21%|██        | 104/500 [00:06<00:24, 16.50it/s] 21%|██        | 106/500 [00:06<00:23, 16.52it/s] 22%|██▏       | 108/500 [00:07<00:23, 16.48it/s] 22%|██▏       | 110/500 [00:07<00:26, 14.81it/s] 22%|██▏       | 112/500 [00:07<00:27, 14.04it/s] 23%|██▎       | 114/500 [00:07<00:28, 13.47it/s] 23%|██▎       | 116/500 [00:07<00:29, 13.18it/s] 24%|██▎       | 118/500 [00:07<00:29, 12.95it/s] 24%|██▍       | 120/500 [00:08<00:29, 12.79it/s] 24%|██▍       | 122/500 [00:08<00:29, 12.71it/s] 25%|██▍       | 124/500 [00:08<00:29, 12.65it/s]Epoch:  1  	Training Loss: 0.04824826493859291
Test Loss:  60.607696533203125
Valid Loss:  59.573341369628906
Epoch:  2  	Training Loss: 62.56832504272461
Test Loss:  509596992.0
Valid Loss:  502174720.0
Epoch:  3  	Training Loss: 507963776.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan 25%|██▌       | 126/500 [00:08<00:28, 13.25it/s] 26%|██▌       | 128/500 [00:08<00:26, 14.10it/s] 26%|██▌       | 130/500 [00:08<00:25, 14.47it/s] 26%|██▋       | 132/500 [00:08<00:26, 13.76it/s] 27%|██▋       | 134/500 [00:09<00:27, 13.28it/s] 27%|██▋       | 136/500 [00:09<00:28, 12.79it/s] 28%|██▊       | 138/500 [00:09<00:28, 12.66it/s] 28%|██▊       | 140/500 [00:09<00:28, 12.56it/s] 28%|██▊       | 142/500 [00:09<00:27, 13.17it/s] 29%|██▉       | 144/500 [00:09<00:25, 13.97it/s] 29%|██▉       | 146/500 [00:09<00:24, 14.65it/s] 30%|██▉       | 148/500 [00:10<00:23, 15.13it/s] 30%|███       | 150/500 [00:10<00:22, 15.49it/s] 30%|███       | 152/500 [00:10<00:22, 15.45it/s] 31%|███       | 154/500 [00:10<00:22, 15.59it/s] 31%|███       | 156/500 [00:10<00:21, 15.84it/s] 32%|███▏      | 158/500 [00:10<00:21, 15.99it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.14it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.17it/s] 33%|███▎      | 164/500 [00:11<00:20, 16.24it/s] 33%|███▎      | 166/500 [00:11<00:20, 16.30it/s] 34%|███▎      | 168/500 [00:11<00:20, 16.32it/s] 34%|███▍      | 170/500 [00:11<00:20, 16.24it/s] 34%|███▍      | 172/500 [00:11<00:20, 16.32it/s] 35%|███▍      | 174/500 [00:11<00:19, 16.34it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.41it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.44it/s] 36%|███▌      | 180/500 [00:12<00:19, 16.35it/s] 36%|███▋      | 182/500 [00:12<00:19, 16.23it/s] 37%|███▋      | 184/500 [00:12<00:19, 16.16it/s] 37%|███▋      | 186/500 [00:12<00:19, 16.29it/s] 38%|███▊      | 188/500 [00:12<00:19, 16.32it/s] 38%|███▊      | 190/500 [00:12<00:18, 16.37it/s] 38%|███▊      | 192/500 [00:12<00:18, 16.35it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.32it/s] 39%|███▉      | 196/500 [00:13<00:18, 16.24it/s] 40%|███▉      | 198/500 [00:13<00:18, 16.25it/s] 40%|████      | 200/500 [00:13<00:18, 16.29it/s] 40%|████      | 202/500 [00:13<00:18, 16.29it/s] 41%|████      | 204/500 [00:13<00:18, 16.36it/s] 41%|████      | 206/500 [00:13<00:17, 16.39it/s] 42%|████▏     | 208/500 [00:13<00:19, 15.29it/s] 42%|████▏     | 210/500 [00:13<00:19, 14.66it/s] 42%|████▏     | 212/500 [00:14<00:19, 15.02it/s] 43%|████▎     | 214/500 [00:14<00:19, 14.38it/s] 43%|████▎     | 216/500 [00:14<00:20, 13.71it/s] 44%|████▎     | 218/500 [00:14<00:21, 13.26it/s] 44%|████▍     | 220/500 [00:14<00:21, 13.01it/s] 44%|████▍     | 222/500 [00:14<00:21, 12.97it/s] 45%|████▍     | 224/500 [00:15<00:20, 13.22it/s] 45%|████▌     | 226/500 [00:15<00:20, 13.67it/s] 46%|████▌     | 228/500 [00:15<00:18, 14.44it/s] 46%|████▌     | 230/500 [00:15<00:18, 14.99it/s] 46%|████▋     | 232/500 [00:15<00:17, 15.38it/s] 47%|████▋     | 234/500 [00:15<00:17, 15.64it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.84it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.08it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.14it/s] 48%|████▊     | 242/500 [00:16<00:16, 15.86it/s] 49%|████▉     | 244/500 [00:16<00:15, 16.03it/s] 49%|████▉     | 246/500 [00:16<00:15, 16.21it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.32it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:16<00:16, 15.32it/s] 50%|█████     | 252/500 [00:16<00:16, 15.16it/s] 51%|█████     | 254/500 [00:16<00:15, 15.50it/s] 51%|█████     | 256/500 [00:17<00:15, 15.77it/s] 52%|█████▏    | 258/500 [00:17<00:15, 15.84it/s] 52%|█████▏    | 260/500 [00:17<00:15, 15.88it/s] 52%|█████▏    | 262/500 [00:17<00:14, 15.92it/s] 53%|█████▎    | 264/500 [00:17<00:14, 15.98it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.06it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.07it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.21it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.28it/s] 55%|█████▍    | 274/500 [00:18<00:13, 16.39it/s] 55%|█████▌    | 276/500 [00:18<00:13, 16.18it/s] 56%|█████▌    | 278/500 [00:18<00:13, 16.19it/s] 56%|█████▌    | 280/500 [00:18<00:13, 16.30it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.30it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.02it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.99it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.13it/s] 58%|█████▊    | 290/500 [00:19<00:14, 14.64it/s] 58%|█████▊    | 292/500 [00:19<00:15, 13.73it/s] 59%|█████▉    | 294/500 [00:19<00:14, 14.06it/s] 59%|█████▉    | 296/500 [00:19<00:14, 14.45it/s] 60%|█████▉    | 298/500 [00:19<00:14, 13.80it/s] 60%|██████    | 300/500 [00:19<00:15, 13.30it/s] 60%|██████    | 302/500 [00:20<00:15, 12.97it/s] 61%|██████    | 304/500 [00:20<00:15, 12.81it/s] 61%|██████    | 306/500 [00:20<00:15, 12.82it/s] 62%|██████▏   | 308/500 [00:20<00:14, 13.60it/s] 62%|██████▏   | 310/500 [00:20<00:13, 14.33it/s] 62%|██████▏   | 312/500 [00:20<00:13, 13.87it/s] 63%|██████▎   | 314/500 [00:20<00:13, 13.42it/s] 63%|██████▎   | 316/500 [00:21<00:14, 13.00it/s] 64%|██████▎   | 318/500 [00:21<00:14, 12.80it/s] 64%|██████▍   | 320/500 [00:21<00:14, 12.68it/s] 64%|██████▍   | 322/500 [00:21<00:14, 12.60it/s] 65%|██████▍   | 324/500 [00:21<00:14, 12.56it/s] 65%|██████▌   | 326/500 [00:21<00:13, 12.46it/s] 66%|██████▌   | 328/500 [00:22<00:13, 12.46it/s] 66%|██████▌   | 330/500 [00:22<00:13, 12.46it/s] 66%|██████▋   | 332/500 [00:22<00:13, 12.46it/s] 67%|██████▋   | 334/500 [00:22<00:13, 12.44it/s] 67%|██████▋   | 336/500 [00:22<00:13, 12.38it/s] 68%|██████▊   | 338/500 [00:22<00:13, 12.31it/s] 68%|██████▊   | 340/500 [00:23<00:12, 12.56it/s] 68%|██████▊   | 342/500 [00:23<00:12, 12.46it/s] 69%|██████▉   | 344/500 [00:23<00:12, 12.45it/s] 69%|██████▉   | 346/500 [00:23<00:12, 12.62it/s] 70%|██████▉   | 348/500 [00:23<00:11, 13.57it/s] 70%|███████   | 350/500 [00:23<00:11, 13.44it/s] 70%|███████   | 352/500 [00:23<00:10, 13.59it/s] 71%|███████   | 354/500 [00:24<00:10, 14.26it/s] 71%|███████   | 356/500 [00:24<00:09, 14.86it/s] 72%|███████▏  | 358/500 [00:24<00:09, 15.35it/s] 72%|███████▏  | 360/500 [00:24<00:08, 15.71it/s] 72%|███████▏  | 362/500 [00:24<00:08, 15.94it/s] 73%|███████▎  | 364/500 [00:24<00:08, 16.08it/s] 73%|███████▎  | 366/500 [00:24<00:08, 16.17it/s] 74%|███████▎  | 368/500 [00:24<00:08, 16.24it/s] 74%|███████▍  | 370/500 [00:25<00:08, 16.23it/s] 74%|███████▍  | 372/500 [00:25<00:07, 16.24it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:25<00:07, 16.21it/s] 75%|███████▌  | 376/500 [00:25<00:07, 16.26it/s] 76%|███████▌  | 378/500 [00:25<00:07, 16.07it/s] 76%|███████▌  | 380/500 [00:25<00:07, 16.08it/s] 76%|███████▋  | 382/500 [00:25<00:07, 16.16it/s] 77%|███████▋  | 384/500 [00:25<00:07, 16.26it/s] 77%|███████▋  | 386/500 [00:26<00:06, 16.30it/s] 78%|███████▊  | 388/500 [00:26<00:06, 16.29it/s] 78%|███████▊  | 390/500 [00:26<00:06, 16.24it/s] 78%|███████▊  | 392/500 [00:26<00:06, 16.26it/s] 79%|███████▉  | 394/500 [00:26<00:06, 16.37it/s] 79%|███████▉  | 396/500 [00:26<00:06, 16.36it/s] 80%|███████▉  | 398/500 [00:26<00:06, 16.00it/s] 80%|████████  | 400/500 [00:26<00:06, 14.69it/s] 80%|████████  | 402/500 [00:27<00:07, 13.95it/s] 81%|████████  | 404/500 [00:27<00:07, 13.46it/s] 81%|████████  | 406/500 [00:27<00:07, 13.14it/s] 82%|████████▏ | 408/500 [00:27<00:07, 12.88it/s] 82%|████████▏ | 410/500 [00:27<00:07, 12.76it/s] 82%|████████▏ | 412/500 [00:27<00:06, 12.64it/s] 83%|████████▎ | 414/500 [00:28<00:06, 12.49it/s] 83%|████████▎ | 416/500 [00:28<00:06, 12.47it/s] 84%|████████▎ | 418/500 [00:28<00:06, 12.44it/s] 84%|████████▍ | 420/500 [00:28<00:06, 12.41it/s] 84%|████████▍ | 422/500 [00:28<00:06, 12.31it/s] 85%|████████▍ | 424/500 [00:28<00:06, 12.66it/s] 85%|████████▌ | 426/500 [00:28<00:05, 13.34it/s] 86%|████████▌ | 428/500 [00:29<00:05, 12.88it/s] 86%|████████▌ | 430/500 [00:29<00:05, 12.63it/s] 86%|████████▋ | 432/500 [00:29<00:05, 12.56it/s] 87%|████████▋ | 434/500 [00:29<00:05, 12.51it/s] 87%|████████▋ | 436/500 [00:29<00:05, 12.48it/s] 88%|████████▊ | 438/500 [00:29<00:04, 12.47it/s] 88%|████████▊ | 440/500 [00:30<00:04, 12.75it/s] 88%|████████▊ | 442/500 [00:30<00:04, 13.71it/s] 89%|████████▉ | 444/500 [00:30<00:03, 14.43it/s] 89%|████████▉ | 446/500 [00:30<00:03, 15.02it/s] 90%|████████▉ | 448/500 [00:30<00:03, 15.40it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.71it/s] 90%|█████████ | 452/500 [00:30<00:03, 15.85it/s] 91%|█████████ | 454/500 [00:31<00:03, 14.43it/s] 91%|█████████ | 456/500 [00:31<00:03, 13.79it/s] 92%|█████████▏| 458/500 [00:31<00:03, 13.34it/s] 92%|█████████▏| 460/500 [00:31<00:03, 13.03it/s] 92%|█████████▏| 462/500 [00:31<00:02, 13.01it/s] 93%|█████████▎| 464/500 [00:31<00:02, 13.86it/s] 93%|█████████▎| 466/500 [00:31<00:02, 14.54it/s] 94%|█████████▎| 468/500 [00:32<00:02, 15.06it/s] 94%|█████████▍| 470/500 [00:32<00:01, 15.30it/s] 94%|█████████▍| 472/500 [00:32<00:01, 14.78it/s] 95%|█████████▍| 474/500 [00:32<00:01, 14.14it/s] 95%|█████████▌| 476/500 [00:32<00:01, 14.54it/s] 96%|█████████▌| 478/500 [00:32<00:01, 14.92it/s] 96%|█████████▌| 480/500 [00:32<00:01, 15.29it/s] 96%|█████████▋| 482/500 [00:32<00:01, 15.59it/s] 97%|█████████▋| 484/500 [00:33<00:01, 15.59it/s] 97%|█████████▋| 486/500 [00:33<00:00, 15.88it/s] 98%|█████████▊| 488/500 [00:33<00:00, 16.03it/s] 98%|█████████▊| 490/500 [00:33<00:00, 16.10it/s] 98%|█████████▊| 492/500 [00:33<00:00, 15.98it/s] 99%|█████████▉| 494/500 [00:33<00:00, 16.01it/s] 99%|█████████▉| 496/500 [00:33<00:00, 15.85it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:33<00:00, 15.89it/s]100%|██████████| 500/500 [00:34<00:00, 15.99it/s]100%|██████████| 500/500 [00:34<00:00, 14.68it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  2
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:19,  6.41s/it]  1%|          | 3/500 [00:06<14:12,  1.71s/it]  1%|          | 5/500 [00:06<07:09,  1.15it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<10:58,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:56,  1.24s/it]  5%|▍         | 23/500 [00:20<07:03,  1.13it/s]  5%|▌         | 25/500 [00:20<05:02,  1.57it/s]  5%|▌         | 27/500 [00:20<03:39,  2.15it/s]  6%|▌         | 29/500 [00:20<02:42,  2.91it/s]  6%|▌         | 31/500 [00:27<09:30,  1.22s/it]  7%|▋         | 33/500 [00:27<06:46,  1.15it/s]  7%|▋         | 35/500 [00:27<04:52,  1.59it/s]  7%|▋         | 37/500 [00:27<03:32,  2.18it/s]  8%|▊         | 39/500 [00:27<02:37,  2.93it/s]  8%|▊         | 41/500 [00:34<09:26,  1.24s/it]  9%|▊         | 43/500 [00:34<06:47,  1.12it/s]  9%|▉         | 45/500 [00:34<04:55,  1.54it/s]  9%|▉         | 47/500 [00:35<03:34,  2.11it/s] 10%|▉         | 49/500 [00:35<02:38,  2.84it/s] 10%|█         | 51/500 [00:41<09:04,  1.21s/it] 11%|█         | 53/500 [00:41<06:29,  1.15it/s] 11%|█         | 55/500 [00:41<04:40,  1.59it/s] 11%|█▏        | 57/500 [00:42<03:25,  2.16it/s] 12%|█▏        | 59/500 [00:42<02:31,  2.90it/s] 12%|█▏        | 61/500 [00:48<08:47,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:17,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:49<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:49<02:26,  2.95it/s] 14%|█▍        | 71/500 [00:55<08:35,  1.20s/it]Epoch:  1  	Training Loss: 0.04824826121330261
Test Loss:  1.9763298034667969
Valid Loss:  1.7954216003417969
Epoch:  2  	Training Loss: 2.156287670135498
Test Loss:  19.217487335205078
Valid Loss:  18.663846969604492
Epoch:  3  	Training Loss: 19.66756820678711
Test Loss:  0.025615127757191658
Valid Loss:  0.036167532205581665
Epoch:  4  	Training Loss: 0.03944068402051926
Test Loss:  0.02561509609222412
Valid Loss:  0.03616746887564659
Epoch:  5  	Training Loss: 0.0394405871629715
Test Loss:  0.025615070015192032
Valid Loss:  0.03616739809513092
Epoch:  6  	Training Loss: 0.03944048285484314
Test Loss:  0.025615040212869644
Valid Loss:  0.03616732731461525
Epoch:  7  	Training Loss: 0.03944038599729538
Test Loss:  0.025615014135837555
Valid Loss:  0.03616725653409958
Epoch:  8  	Training Loss: 0.03944028541445732
Test Loss:  0.025614984333515167
Valid Loss:  0.03616718575358391
Epoch:  9  	Training Loss: 0.039440177381038666
Test Loss:  0.025614958256483078
Valid Loss:  0.036167122423648834
Epoch:  10  	Training Loss: 0.039440084248781204
Test Loss:  0.025614913552999496
Valid Loss:  0.03616704046726227
Epoch:  11  	Training Loss: 0.03944002091884613
Test Loss:  0.02561483532190323
Valid Loss:  0.0361669547855854
Epoch:  12  	Training Loss: 0.03943996876478195
Test Loss:  0.025614753365516663
Valid Loss:  0.03616686165332794
Epoch:  13  	Training Loss: 0.03943992406129837
Test Loss:  0.025614675134420395
Valid Loss:  0.03616676479578018
Epoch:  14  	Training Loss: 0.03943987190723419
Test Loss:  0.02561459131538868
Valid Loss:  0.03616667538881302
Epoch:  15  	Training Loss: 0.03943982347846031
Test Loss:  0.025614507496356964
Valid Loss:  0.03616657853126526
Epoch:  16  	Training Loss: 0.03943977504968643
Test Loss:  0.025614425539970398
Valid Loss:  0.0361664853990078
Epoch:  17  	Training Loss: 0.03943973034620285
Test Loss:  0.025614341720938683
Valid Loss:  0.036166392266750336
Epoch:  18  	Training Loss: 0.03943968191742897
Test Loss:  0.025614259764552116
Valid Loss:  0.036166295409202576
Epoch:  19  	Training Loss: 0.03943963348865509
Test Loss:  0.0256141759455204
Valid Loss:  0.036166198551654816
Epoch:  20  	Training Loss: 0.03943957760930061
Test Loss:  0.025614093989133835
Valid Loss:  0.03616610914468765
Epoch:  21  	Training Loss: 0.03943952918052673
Test Loss:  0.02561401203274727
Valid Loss:  0.03616601601243019
Epoch:  22  	Training Loss: 0.03943948447704315
Test Loss:  0.025613930076360703
Valid Loss:  0.03616591915488243
Epoch:  23  	Training Loss: 0.03943943232297897
Test Loss:  0.025613851845264435
Valid Loss:  0.03616582229733467
Epoch:  24  	Training Loss: 0.039439380168914795
Test Loss:  0.025613773614168167
Valid Loss:  0.03616573289036751
Epoch:  25  	Training Loss: 0.03943932056427002
Test Loss:  0.02561369352042675
Valid Loss:  0.036165639758110046
Epoch:  26  	Training Loss: 0.03943926841020584
Test Loss:  0.025613613426685333
Valid Loss:  0.03616555035114288
Epoch:  27  	Training Loss: 0.03943921625614166
Test Loss:  0.025613535195589066
Valid Loss:  0.03616545349359512
Epoch:  28  	Training Loss: 0.03943916782736778
Test Loss:  0.0256134532392025
Valid Loss:  0.03616536036133766
Epoch:  29  	Training Loss: 0.039439111948013306
Test Loss:  0.025613371282815933
Valid Loss:  0.0361652635037899
Epoch:  30  	Training Loss: 0.03943905979394913
Test Loss:  0.025613296777009964
Valid Loss:  0.03616517782211304
Epoch:  31  	Training Loss: 0.03943900763988495
Test Loss:  0.0256132110953331
Valid Loss:  0.03616508096456528
Epoch:  32  	Training Loss: 0.03943895548582077
Test Loss:  0.025613125413656235
Valid Loss:  0.03616498038172722
Epoch:  33  	Training Loss: 0.03943890705704689
Test Loss:  0.02561304159462452
Valid Loss:  0.03616488352417946
Epoch:  34  	Training Loss: 0.03943885862827301
Test Loss:  0.025612957775592804
Valid Loss:  0.0361647866666317
Epoch:  35  	Training Loss: 0.03943881019949913
Test Loss:  0.02561287209391594
Valid Loss:  0.03616469353437424
Epoch:  36  	Training Loss: 0.03943876177072525
Test Loss:  0.025612782686948776
Valid Loss:  0.03616459667682648
Epoch:  37  	Training Loss: 0.03943870961666107
Test Loss:  0.02561270073056221
Valid Loss:  0.03616449981927872
Epoch:  38  	Training Loss: 0.03943866491317749
Test Loss:  0.025612616911530495
Valid Loss:  0.03616440296173096
Epoch:  39  	Training Loss: 0.03943861275911331
Test Loss:  0.02561252750456333
Valid Loss:  0.0361643061041832
Epoch:  40  	Training Loss: 0.03943856805562973
Test Loss:  0.025612443685531616
Valid Loss:  0.03616420924663544
Epoch:  41  	Training Loss: 0.03943851962685585
Test Loss:  0.02561235800385475
Valid Loss:  0.03616411238908768
Epoch:  42  	Training Loss: 0.03943847119808197
Test Loss:  0.025612272322177887
Valid Loss:  0.03616401553153992
Epoch:  43  	Training Loss: 0.03943842276930809
Test Loss:  0.02561218850314617
Valid Loss:  0.036163922399282455
Epoch:  44  	Training Loss: 0.03943836688995361
Test Loss:  0.025612108409404755
Valid Loss:  0.0361638218164444
Epoch:  45  	Training Loss: 0.039438314735889435
Test Loss:  0.02561201900243759
Valid Loss:  0.036163728684186935
Epoch:  46  	Training Loss: 0.039438262581825256
Test Loss:  0.025611938908696175
Valid Loss:  0.036163631826639175
Epoch:  47  	Training Loss: 0.03943821042776108
Test Loss:  0.02561185508966446
Valid Loss:  0.03616353124380112
Epoch:  48  	Training Loss: 0.0394381582736969
Test Loss:  0.025611769407987595
Valid Loss:  0.03616343438625336
Epoch:  49  	Training Loss: 0.03943810984492302
Test Loss:  0.02561168372631073
Valid Loss:  0.0361633375287056
Epoch:  50  	Training Loss: 0.03943805396556854
Test Loss:  0.025611601769924164
Valid Loss:  0.036163248121738434
Epoch:  51  	Training Loss: 0.039438001811504364
Test Loss:  0.025611519813537598
Valid Loss:  0.036163147538900375
Epoch:  52  	Training Loss: 0.039437953382730484
Test Loss:  0.02561143785715103
Valid Loss:  0.036163054406642914
Epoch:  53  	Training Loss: 0.03943789750337601
Test Loss:  0.025611355900764465
Valid Loss:  0.036162957549095154
Epoch:  54  	Training Loss: 0.03943784534931183
Test Loss:  0.025611277669668198
Valid Loss:  0.03616286814212799
Epoch:  55  	Training Loss: 0.03943779319524765
Test Loss:  0.02561119757592678
Valid Loss:  0.03616277500987053
Epoch:  56  	Training Loss: 0.03943774104118347
Test Loss:  0.025611117482185364
Valid Loss:  0.03616268187761307
Epoch:  57  	Training Loss: 0.03943768888711929
Test Loss:  0.025611042976379395
Valid Loss:  0.036162588745355606
Epoch:  58  	Training Loss: 0.039437633007764816
Test Loss:  0.02561096101999283
Valid Loss:  0.036162495613098145
Epoch:  59  	Training Loss: 0.03943757712841034
Test Loss:  0.02561088278889656
Valid Loss:  0.036162398755550385
Epoch:  60  	Training Loss: 0.03943752497434616
Test Loss:  0.025610800832509995
Valid Loss:  0.03616230562329292
Epoch:  61  	Training Loss: 0.03943747654557228
Test Loss:  0.02561071701347828
Valid Loss:  0.03616221249103546
Epoch:  62  	Training Loss: 0.039437420666217804
Test Loss:  0.02561064064502716
Valid Loss:  0.036162119358778
Epoch:  63  	Training Loss: 0.039437368512153625
Test Loss:  0.025610562413930893
Valid Loss:  0.03616202995181084
Epoch:  64  	Training Loss: 0.03943731635808945
Test Loss:  0.025610486045479774
Valid Loss:  0.036161936819553375
Epoch:  65  	Training Loss: 0.03943726420402527
Test Loss:  0.025610405951738358
Valid Loss:  0.036161843687295914
Epoch:  66  	Training Loss: 0.03943721204996109
Test Loss:  0.02561032772064209
Valid Loss:  0.03616175800561905
Epoch:  67  	Training Loss: 0.03943715989589691
Test Loss:  0.025610249489545822
Valid Loss:  0.03616166114807129
Epoch:  68  	Training Loss: 0.039437100291252136
Test Loss:  0.025610171258449554
Valid Loss:  0.03616156429052353
Epoch:  69  	Training Loss: 0.03943704813718796
Test Loss:  0.025610091164708138
Valid Loss:  0.036161474883556366
Epoch:  70  	Training Loss: 0.03943699598312378
Test Loss:  0.02561001479625702
Valid Loss:  0.0361613892018795
Epoch:  71  	Training Loss: 0.0394369475543499
Test Loss:  0.025609934702515602
Valid Loss:  0.03616129234433174
Epoch:  72  	Training Loss: 0.03943689167499542
Test Loss:  0.025609856471419334
Valid Loss:  0.03616119548678398
 15%|█▍        | 73/500 [00:55<06:10,  1.15it/s] 15%|█▌        | 75/500 [00:55<04:29,  1.58it/s] 15%|█▌        | 77/500 [00:56<03:18,  2.13it/s] 16%|█▌        | 79/500 [00:56<02:28,  2.84it/s] 16%|█▌        | 81/500 [01:02<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:03<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:03<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:09<08:04,  1.18s/it] 19%|█▊        | 93/500 [01:09<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:09<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:10<03:06,  2.16it/s] 20%|█▉        | 99/500 [01:10<02:20,  2.85it/s] 20%|██        | 101/500 [01:16<08:13,  1.24s/it] 21%|██        | 103/500 [01:16<05:52,  1.13it/s] 21%|██        | 105/500 [01:17<04:13,  1.56it/s] 21%|██▏       | 107/500 [01:17<03:06,  2.10it/s] 22%|██▏       | 109/500 [01:17<02:20,  2.79it/s] 22%|██▏       | 111/500 [01:23<07:55,  1.22s/it] 23%|██▎       | 113/500 [01:24<05:39,  1.14it/s] 23%|██▎       | 115/500 [01:24<04:03,  1.58it/s] 23%|██▎       | 117/500 [01:24<02:57,  2.16it/s] 24%|██▍       | 119/500 [01:24<02:10,  2.91it/s] 24%|██▍       | 121/500 [01:30<07:36,  1.20s/it] 25%|██▍       | 123/500 [01:30<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:31<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:31<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:31<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:37<07:13,  1.17s/it] 27%|██▋       | 133/500 [01:37<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:37<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:38<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:38<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:44<07:09,  1.20s/it] 29%|██▊       | 143/500 [01:44<05:06,  1.17it/s]Epoch:  73  	Training Loss: 0.039436839520931244
Test Loss:  0.025609774515032768
Valid Loss:  0.03616110235452652
Epoch:  74  	Training Loss: 0.039436787366867065
Test Loss:  0.0256096962839365
Valid Loss:  0.03616101294755936
Epoch:  75  	Training Loss: 0.03943673148751259
Test Loss:  0.025609618052840233
Valid Loss:  0.0361609160900116
Epoch:  76  	Training Loss: 0.03943667933344841
Test Loss:  0.025609534233808517
Valid Loss:  0.036160822957754135
Epoch:  77  	Training Loss: 0.03943662345409393
Test Loss:  0.025609459728002548
Valid Loss:  0.036160729825496674
Epoch:  78  	Training Loss: 0.039436571300029755
Test Loss:  0.025609377771615982
Valid Loss:  0.036160632967948914
Epoch:  79  	Training Loss: 0.039436519145965576
Test Loss:  0.025609299540519714
Valid Loss:  0.03616054356098175
Epoch:  80  	Training Loss: 0.0394364669919014
Test Loss:  0.025609221309423447
Valid Loss:  0.03616045042872429
Epoch:  81  	Training Loss: 0.03943641483783722
Test Loss:  0.02560913749039173
Valid Loss:  0.03616035729646683
Epoch:  82  	Training Loss: 0.03943636268377304
Test Loss:  0.025609061121940613
Valid Loss:  0.03616026043891907
Epoch:  83  	Training Loss: 0.03943631052970886
Test Loss:  0.025608975440263748
Valid Loss:  0.036160171031951904
Epoch:  84  	Training Loss: 0.039436258375644684
Test Loss:  0.02560889720916748
Valid Loss:  0.036160074174404144
Epoch:  85  	Training Loss: 0.03943620249629021
Test Loss:  0.025608817115426064
Valid Loss:  0.036159977316856384
Epoch:  86  	Training Loss: 0.03943615034222603
Test Loss:  0.025608737021684647
Valid Loss:  0.03615988790988922
Epoch:  87  	Training Loss: 0.03943609818816185
Test Loss:  0.02560865879058838
Valid Loss:  0.03615979477763176
Epoch:  88  	Training Loss: 0.03943604230880737
Test Loss:  0.025608576834201813
Valid Loss:  0.0361597016453743
Epoch:  89  	Training Loss: 0.039435990154743195
Test Loss:  0.025608498603105545
Valid Loss:  0.03615960478782654
Epoch:  90  	Training Loss: 0.039435938000679016
Test Loss:  0.025608418509364128
Valid Loss:  0.03615951165556908
Epoch:  91  	Training Loss: 0.03943588584661484
Test Loss:  0.025608336552977562
Valid Loss:  0.036159418523311615
Epoch:  92  	Training Loss: 0.03943583369255066
Test Loss:  0.025608256459236145
Valid Loss:  0.036159321665763855
Epoch:  93  	Training Loss: 0.03943578153848648
Test Loss:  0.025608178228139877
Valid Loss:  0.03615922853350639
Epoch:  94  	Training Loss: 0.039435725659132004
Test Loss:  0.02560809627175331
Valid Loss:  0.03615913540124893
Epoch:  95  	Training Loss: 0.03943566977977753
Test Loss:  0.025608014315366745
Valid Loss:  0.03615903854370117
Epoch:  96  	Training Loss: 0.03943561762571335
Test Loss:  0.02560793235898018
Valid Loss:  0.03615894541144371
Epoch:  97  	Training Loss: 0.03943556547164917
Test Loss:  0.02560785412788391
Valid Loss:  0.03615885227918625
Epoch:  98  	Training Loss: 0.03943551331758499
Test Loss:  0.025607772171497345
Valid Loss:  0.03615875542163849
Epoch:  99  	Training Loss: 0.039435453712940216
Test Loss:  0.02560769021511078
Valid Loss:  0.036158666014671326
Epoch:  100  	Training Loss: 0.03943540155887604
Test Loss:  0.025607610121369362
Valid Loss:  0.036158569157123566
Epoch:  101  	Training Loss: 0.03943534940481186
Test Loss:  0.025607530027627945
Valid Loss:  0.036158472299575806
Epoch:  102  	Training Loss: 0.03943529725074768
Test Loss:  0.02560744620859623
Valid Loss:  0.03615838289260864
Epoch:  103  	Training Loss: 0.039435241371393204
Test Loss:  0.025607366114854813
Valid Loss:  0.036158282309770584
Epoch:  104  	Training Loss: 0.039435189217329025
Test Loss:  0.025607286021113396
Valid Loss:  0.03615818917751312
Epoch:  105  	Training Loss: 0.03943513706326485
Test Loss:  0.02560720592737198
Valid Loss:  0.03615809231996536
Epoch:  106  	Training Loss: 0.03943508118391037
Test Loss:  0.025607123970985413
Valid Loss:  0.0361579954624176
Epoch:  107  	Training Loss: 0.03943503275513649
Test Loss:  0.025607040151953697
Valid Loss:  0.03615790605545044
Epoch:  108  	Training Loss: 0.03943497687578201
Test Loss:  0.02560696378350258
Valid Loss:  0.03615780919790268
Epoch:  109  	Training Loss: 0.03943492844700813
Test Loss:  0.025606881827116013
Valid Loss:  0.03615771234035492
Epoch:  110  	Training Loss: 0.039434876292943954
Test Loss:  0.025606799870729446
Valid Loss:  0.036157626658678055
Epoch:  111  	Training Loss: 0.039434824138879776
Test Loss:  0.02560671977698803
Valid Loss:  0.036157526075839996
Epoch:  112  	Training Loss: 0.0394347719848156
Test Loss:  0.02560664527118206
Valid Loss:  0.03615744039416313
Epoch:  113  	Training Loss: 0.03943471610546112
Test Loss:  0.025606568902730942
Valid Loss:  0.03615734726190567
Epoch:  114  	Training Loss: 0.03943466395139694
Test Loss:  0.025606490671634674
Valid Loss:  0.03615725785493851
Epoch:  115  	Training Loss: 0.039434608072042465
Test Loss:  0.025606414303183556
Valid Loss:  0.036157164722681046
Epoch:  116  	Training Loss: 0.03943455591797829
Test Loss:  0.025606337934732437
Valid Loss:  0.036157071590423584
Epoch:  117  	Training Loss: 0.03943450376391411
Test Loss:  0.02560626156628132
Valid Loss:  0.03615698590874672
Epoch:  118  	Training Loss: 0.03943444788455963
Test Loss:  0.0256061814725399
Valid Loss:  0.03615689277648926
Epoch:  119  	Training Loss: 0.03943439573049545
Test Loss:  0.025606106966733932
Valid Loss:  0.036156803369522095
Epoch:  120  	Training Loss: 0.039434343576431274
Test Loss:  0.025606032460927963
Valid Loss:  0.03615671396255493
Epoch:  121  	Training Loss: 0.0394342876970768
Test Loss:  0.025605954229831696
Valid Loss:  0.03615662455558777
Epoch:  122  	Training Loss: 0.03943423554301262
Test Loss:  0.02560587413609028
Valid Loss:  0.03615652397274971
Epoch:  123  	Training Loss: 0.03943418711423874
Test Loss:  0.02560579404234886
Valid Loss:  0.03615643084049225
Epoch:  124  	Training Loss: 0.03943413123488426
Test Loss:  0.025605712085962296
Valid Loss:  0.036156341433525085
Epoch:  125  	Training Loss: 0.03943408280611038
Test Loss:  0.02560563012957573
Valid Loss:  0.03615624085068703
Epoch:  126  	Training Loss: 0.039434030652046204
Test Loss:  0.025605548173189163
Valid Loss:  0.036156147718429565
Epoch:  127  	Training Loss: 0.039433978497982025
Test Loss:  0.025605469942092896
Valid Loss:  0.036156054586172104
Epoch:  128  	Training Loss: 0.03943392634391785
Test Loss:  0.02560538798570633
Valid Loss:  0.036155957728624344
Epoch:  129  	Training Loss: 0.03943387418985367
Test Loss:  0.025605304166674614
Valid Loss:  0.03615586459636688
Epoch:  130  	Training Loss: 0.03943382203578949
Test Loss:  0.025605225935578346
Valid Loss:  0.03615576773881912
Epoch:  131  	Training Loss: 0.03943376988172531
Test Loss:  0.025605138391256332
Valid Loss:  0.03615567833185196
Epoch:  132  	Training Loss: 0.03943371772766113
Test Loss:  0.025605063885450363
Valid Loss:  0.0361555851995945
Epoch:  133  	Training Loss: 0.03943365812301636
Test Loss:  0.025604985654354095
Valid Loss:  0.03615548834204674
Epoch:  134  	Training Loss: 0.03943360596895218
Test Loss:  0.025604909285902977
Valid Loss:  0.036155395209789276
Epoch:  135  	Training Loss: 0.0394335500895977
Test Loss:  0.02560482919216156
Valid Loss:  0.036155302077531815
Epoch:  136  	Training Loss: 0.039433494210243225
Test Loss:  0.02560475468635559
Valid Loss:  0.03615520894527435
Epoch:  137  	Training Loss: 0.03943343833088875
Test Loss:  0.025604672729969025
Valid Loss:  0.03615511581301689
Epoch:  138  	Training Loss: 0.03943338245153427
Test Loss:  0.025604596361517906
Valid Loss:  0.03615503013134003
Epoch:  139  	Training Loss: 0.039433326572179794
Test Loss:  0.02560451626777649
Valid Loss:  0.03615493327379227
Epoch:  140  	Training Loss: 0.03943327069282532
Test Loss:  0.02560444176197052
Valid Loss:  0.036154843866825104
Epoch:  141  	Training Loss: 0.03943321481347084
Test Loss:  0.025604359805583954
Valid Loss:  0.03615475073456764
Epoch:  142  	Training Loss: 0.039433158934116364
Test Loss:  0.025604285299777985
Valid Loss:  0.036154650151729584
Epoch:  143  	Training Loss: 0.039433106780052185
Test Loss:  0.025604207068681717
Valid Loss:  0.03615456447005272
 29%|██▉       | 145/500 [01:44<03:40,  1.61it/s] 29%|██▉       | 147/500 [01:45<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:45<01:58,  2.96it/s] 30%|███       | 151/500 [01:51<06:50,  1.18s/it] 31%|███       | 153/500 [01:51<04:54,  1.18it/s] 31%|███       | 155/500 [01:51<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:51<02:37,  2.18it/s] 32%|███▏      | 159/500 [01:52<01:57,  2.91it/s] 32%|███▏      | 161/500 [01:58<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:58<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:58<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:58<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:58<01:49,  3.01it/s] 34%|███▍      | 171/500 [02:05<06:35,  1.20s/it] 35%|███▍      | 173/500 [02:05<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:05<03:26,  1.58it/s] 35%|███▌      | 177/500 [02:05<02:31,  2.13it/s] 36%|███▌      | 179/500 [02:06<01:53,  2.82it/s] 36%|███▌      | 181/500 [02:12<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:12<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:12<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:12<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:12<01:43,  2.99it/s] 38%|███▊      | 191/500 [02:19<06:20,  1.23s/it] 39%|███▊      | 193/500 [02:19<04:30,  1.13it/s] 39%|███▉      | 195/500 [02:19<03:14,  1.57it/s] 39%|███▉      | 197/500 [02:19<02:21,  2.14it/s] 40%|███▉      | 199/500 [02:19<01:44,  2.89it/s] 40%|████      | 201/500 [02:26<05:50,  1.17s/it] 41%|████      | 203/500 [02:26<04:11,  1.18it/s] 41%|████      | 205/500 [02:26<03:02,  1.61it/s] 41%|████▏     | 207/500 [02:26<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:26<01:40,  2.89it/s] 42%|████▏     | 211/500 [02:33<05:54,  1.23s/it] 43%|████▎     | 213/500 [02:33<04:14,  1.13it/s]Epoch:  144  	Training Loss: 0.03943305462598801
Test Loss:  0.025604132562875748
Valid Loss:  0.036154478788375854
Epoch:  145  	Training Loss: 0.03943300247192383
Test Loss:  0.02560405433177948
Valid Loss:  0.03615438565611839
Epoch:  146  	Training Loss: 0.03943294659256935
Test Loss:  0.025603972375392914
Valid Loss:  0.03615429252386093
Epoch:  147  	Training Loss: 0.03943289443850517
Test Loss:  0.025603896006941795
Valid Loss:  0.03615419566631317
Epoch:  148  	Training Loss: 0.03943284600973129
Test Loss:  0.025603819638490677
Valid Loss:  0.03615410625934601
Epoch:  149  	Training Loss: 0.039432790130376816
Test Loss:  0.02560374327003956
Valid Loss:  0.036154016852378845
Epoch:  150  	Training Loss: 0.03943273797631264
Test Loss:  0.02560366690158844
Valid Loss:  0.03615392744541168
Epoch:  151  	Training Loss: 0.03943268954753876
Test Loss:  0.025603588670492172
Valid Loss:  0.03615383803844452
Epoch:  152  	Training Loss: 0.03943262994289398
Test Loss:  0.025603510439395905
Valid Loss:  0.03615374118089676
Epoch:  153  	Training Loss: 0.0394325777888298
Test Loss:  0.02560342848300934
Valid Loss:  0.036153651773929596
Epoch:  154  	Training Loss: 0.039432525634765625
Test Loss:  0.02560335397720337
Valid Loss:  0.036153558641672134
Epoch:  155  	Training Loss: 0.03943247348070145
Test Loss:  0.0256032757461071
Valid Loss:  0.036153458058834076
Epoch:  156  	Training Loss: 0.03943242132663727
Test Loss:  0.025603195652365685
Valid Loss:  0.03615336865186691
Epoch:  157  	Training Loss: 0.03943236917257309
Test Loss:  0.02560311369597912
Valid Loss:  0.03615327924489975
Epoch:  158  	Training Loss: 0.03943231701850891
Test Loss:  0.0256030336022377
Valid Loss:  0.03615318238735199
Epoch:  159  	Training Loss: 0.03943226486444473
Test Loss:  0.025602951645851135
Valid Loss:  0.03615309298038483
Epoch:  160  	Training Loss: 0.039432212710380554
Test Loss:  0.025602877140045166
Valid Loss:  0.036152999848127365
Epoch:  161  	Training Loss: 0.03943215683102608
Test Loss:  0.02560279704630375
Valid Loss:  0.036152906715869904
Epoch:  162  	Training Loss: 0.0394321009516716
Test Loss:  0.025602716952562332
Valid Loss:  0.036152809858322144
Epoch:  163  	Training Loss: 0.03943205252289772
Test Loss:  0.025602634996175766
Valid Loss:  0.03615272045135498
Epoch:  164  	Training Loss: 0.03943199664354324
Test Loss:  0.02560255490243435
Valid Loss:  0.03615262731909752
Epoch:  165  	Training Loss: 0.03943194821476936
Test Loss:  0.025602474808692932
Valid Loss:  0.03615252673625946
Epoch:  166  	Training Loss: 0.039431896060705185
Test Loss:  0.025602396577596664
Valid Loss:  0.0361524373292923
Epoch:  167  	Training Loss: 0.039431843906641006
Test Loss:  0.02560231275856495
Valid Loss:  0.036152344197034836
Epoch:  168  	Training Loss: 0.039431795477867126
Test Loss:  0.025602232664823532
Valid Loss:  0.036152247339487076
Epoch:  169  	Training Loss: 0.03943173959851265
Test Loss:  0.025602150708436966
Valid Loss:  0.036152154207229614
Epoch:  170  	Training Loss: 0.03943169116973877
Test Loss:  0.025602076202630997
Valid Loss:  0.03615206107497215
Epoch:  171  	Training Loss: 0.03943163529038429
Test Loss:  0.02560199610888958
Valid Loss:  0.03615196794271469
Epoch:  172  	Training Loss: 0.039431583136320114
Test Loss:  0.025601912289857864
Valid Loss:  0.03615187108516693
Epoch:  173  	Training Loss: 0.039431530982255936
Test Loss:  0.025601830333471298
Valid Loss:  0.03615178167819977
Epoch:  174  	Training Loss: 0.039431482553482056
Test Loss:  0.02560175023972988
Valid Loss:  0.03615168482065201
Epoch:  175  	Training Loss: 0.03943143039941788
Test Loss:  0.025601664558053017
Valid Loss:  0.03615158796310425
Epoch:  176  	Training Loss: 0.0394313782453537
Test Loss:  0.02560158260166645
Valid Loss:  0.036151498556137085
Epoch:  177  	Training Loss: 0.03943132609128952
Test Loss:  0.025601498782634735
Valid Loss:  0.036151401698589325
Epoch:  178  	Training Loss: 0.03943127393722534
Test Loss:  0.025601418688893318
Valid Loss:  0.03615131229162216
Epoch:  179  	Training Loss: 0.03943122178316116
Test Loss:  0.0256013385951519
Valid Loss:  0.0361512117087841
Epoch:  180  	Training Loss: 0.03943117707967758
Test Loss:  0.025601258501410484
Valid Loss:  0.03615111857652664
Epoch:  181  	Training Loss: 0.0394311249256134
Test Loss:  0.02560117281973362
Valid Loss:  0.03615102916955948
Epoch:  182  	Training Loss: 0.039431072771549225
Test Loss:  0.025601094588637352
Valid Loss:  0.03615093231201172
Epoch:  183  	Training Loss: 0.039431020617485046
Test Loss:  0.025601016357541084
Valid Loss:  0.036150842905044556
Epoch:  184  	Training Loss: 0.03943096846342087
Test Loss:  0.025600939989089966
Valid Loss:  0.036150749772787094
Epoch:  185  	Training Loss: 0.03943091630935669
Test Loss:  0.0256008580327034
Valid Loss:  0.03615065664052963
Epoch:  186  	Training Loss: 0.03943086415529251
Test Loss:  0.025600779801607132
Valid Loss:  0.03615055978298187
Epoch:  187  	Training Loss: 0.039430808275938034
Test Loss:  0.025600699707865715
Valid Loss:  0.03615047037601471
Epoch:  188  	Training Loss: 0.039430756121873856
Test Loss:  0.025600619614124298
Valid Loss:  0.03615037351846695
Epoch:  189  	Training Loss: 0.03943070396780968
Test Loss:  0.02560053952038288
Valid Loss:  0.03615027666091919
Epoch:  190  	Training Loss: 0.0394306480884552
Test Loss:  0.025600459426641464
Valid Loss:  0.03615018352866173
Epoch:  191  	Training Loss: 0.03943059593439102
Test Loss:  0.025600381195545197
Valid Loss:  0.03615009784698486
Epoch:  192  	Training Loss: 0.03943054378032684
Test Loss:  0.025600291788578033
Valid Loss:  0.036149993538856506
Epoch:  193  	Training Loss: 0.03943049907684326
Test Loss:  0.02560020610690117
Valid Loss:  0.036149896681308746
Epoch:  194  	Training Loss: 0.03943044692277908
Test Loss:  0.025600118562579155
Valid Loss:  0.036149799823760986
Epoch:  195  	Training Loss: 0.039430394768714905
Test Loss:  0.02560003660619259
Valid Loss:  0.03614969924092293
Epoch:  196  	Training Loss: 0.039430342614650726
Test Loss:  0.025599950924515724
Valid Loss:  0.036149606108665466
Epoch:  197  	Training Loss: 0.039430294185876846
Test Loss:  0.02559986151754856
Valid Loss:  0.036149509251117706
Epoch:  198  	Training Loss: 0.039430245757102966
Test Loss:  0.025599779561161995
Valid Loss:  0.03614940866827965
Epoch:  199  	Training Loss: 0.03943019360303879
Test Loss:  0.02559969574213028
Valid Loss:  0.03614931181073189
Epoch:  200  	Training Loss: 0.03943014144897461
Test Loss:  0.025599610060453415
Valid Loss:  0.03614921495318413
Epoch:  201  	Training Loss: 0.03943008929491043
Test Loss:  0.02559952437877655
Valid Loss:  0.03614911809563637
Epoch:  202  	Training Loss: 0.03943003714084625
Test Loss:  0.025599444285035133
Valid Loss:  0.036149024963378906
Epoch:  203  	Training Loss: 0.03942998871207237
Test Loss:  0.025599364191293716
Valid Loss:  0.03614893555641174
Epoch:  204  	Training Loss: 0.039429932832717896
Test Loss:  0.025599289685487747
Valid Loss:  0.03614884614944458
Epoch:  205  	Training Loss: 0.039429884403944016
Test Loss:  0.02559920772910118
Valid Loss:  0.03614874929189682
Epoch:  206  	Training Loss: 0.03942982852458954
Test Loss:  0.025599129498004913
Valid Loss:  0.03614865988492966
Epoch:  207  	Training Loss: 0.03942977637052536
Test Loss:  0.025599049404263496
Valid Loss:  0.0361485630273819
Epoch:  208  	Training Loss: 0.03942972794175148
Test Loss:  0.025598973035812378
Valid Loss:  0.036148473620414734
Epoch:  209  	Training Loss: 0.039429672062397
Test Loss:  0.025598891079425812
Valid Loss:  0.036148376762866974
Epoch:  210  	Training Loss: 0.039429619908332825
Test Loss:  0.025598816573619843
Valid Loss:  0.03614828735589981
Epoch:  211  	Training Loss: 0.039429567754268646
Test Loss:  0.025598736479878426
Valid Loss:  0.03614819794893265
Epoch:  212  	Training Loss: 0.03942951560020447
Test Loss:  0.02559865638613701
Valid Loss:  0.036148104816675186
Epoch:  213  	Training Loss: 0.03942946344614029
Test Loss:  0.025598574429750443
Valid Loss:  0.036148011684417725
Epoch:  214  	Training Loss: 0.03942941129207611
Test Loss:  0.025598496198654175
Valid Loss:  0.03614791855216026
 43%|████▎     | 215/500 [02:33<03:04,  1.55it/s] 43%|████▎     | 217/500 [02:33<02:15,  2.09it/s] 44%|████▍     | 219/500 [02:34<01:39,  2.82it/s] 44%|████▍     | 221/500 [02:40<05:37,  1.21s/it] 45%|████▍     | 223/500 [02:40<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:40<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:40<02:04,  2.18it/s] 46%|████▌     | 229/500 [02:41<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:47<05:22,  1.20s/it] 47%|████▋     | 233/500 [02:47<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:47<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:47<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:47<01:28,  2.95it/s] 48%|████▊     | 241/500 [02:54<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:54<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:54<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:54<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:54<01:24,  2.98it/s] 50%|█████     | 251/500 [03:01<04:55,  1.19s/it] 51%|█████     | 253/500 [03:01<03:30,  1.17it/s] 51%|█████     | 255/500 [03:01<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:01<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:01<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:08<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:08<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:08<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:08<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:08<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:15<04:42,  1.23s/it] 55%|█████▍    | 273/500 [03:15<03:21,  1.12it/s] 55%|█████▌    | 275/500 [03:15<02:25,  1.54it/s] 55%|█████▌    | 277/500 [03:15<01:45,  2.11it/s] 56%|█████▌    | 279/500 [03:15<01:17,  2.84it/s] 56%|█████▌    | 281/500 [03:22<04:28,  1.22s/it] 57%|█████▋    | 283/500 [03:22<03:10,  1.14it/s] 57%|█████▋    | 285/500 [03:22<02:16,  1.58it/s]Epoch:  215  	Training Loss: 0.03942935913801193
Test Loss:  0.025598417967557907
Valid Loss:  0.0361478254199028
Epoch:  216  	Training Loss: 0.039429306983947754
Test Loss:  0.02559833973646164
Valid Loss:  0.03614773601293564
Epoch:  217  	Training Loss: 0.039429254829883575
Test Loss:  0.02559826150536537
Valid Loss:  0.03614763915538788
Epoch:  218  	Training Loss: 0.0394292026758194
Test Loss:  0.025598181411623955
Valid Loss:  0.036147549748420715
Epoch:  219  	Training Loss: 0.03942915052175522
Test Loss:  0.025598105043172836
Valid Loss:  0.03614746034145355
Epoch:  220  	Training Loss: 0.03942909464240074
Test Loss:  0.02559802494943142
Valid Loss:  0.03614736348390579
Epoch:  221  	Training Loss: 0.03942904621362686
Test Loss:  0.02559794671833515
Valid Loss:  0.03614726662635803
Epoch:  222  	Training Loss: 0.039428986608982086
Test Loss:  0.025597864761948586
Valid Loss:  0.03614717721939087
Epoch:  223  	Training Loss: 0.03942893445491791
Test Loss:  0.02559778466820717
Valid Loss:  0.03614708036184311
Epoch:  224  	Training Loss: 0.03942888230085373
Test Loss:  0.02559770457446575
Valid Loss:  0.03614698350429535
Epoch:  225  	Training Loss: 0.03942882642149925
Test Loss:  0.025597624480724335
Valid Loss:  0.036146894097328186
Epoch:  226  	Training Loss: 0.03942876681685448
Test Loss:  0.02559754252433777
Valid Loss:  0.036146797239780426
Epoch:  227  	Training Loss: 0.0394287146627903
Test Loss:  0.0255974642932415
Valid Loss:  0.036146700382232666
Epoch:  228  	Training Loss: 0.03942865878343582
Test Loss:  0.025597382336854935
Valid Loss:  0.036146603524684906
Epoch:  229  	Training Loss: 0.039428602904081345
Test Loss:  0.02559729851782322
Valid Loss:  0.036146506667137146
Epoch:  230  	Training Loss: 0.03942854702472687
Test Loss:  0.02559722028672695
Valid Loss:  0.036146409809589386
Epoch:  231  	Training Loss: 0.03942849487066269
Test Loss:  0.025597138330340385
Valid Loss:  0.036146312952041626
Epoch:  232  	Training Loss: 0.039428435266017914
Test Loss:  0.02559705451130867
Valid Loss:  0.03614622354507446
Epoch:  233  	Training Loss: 0.039428386837244034
Test Loss:  0.02559697814285755
Valid Loss:  0.0361461266875267
Epoch:  234  	Training Loss: 0.03942833095788956
Test Loss:  0.025596899911761284
Valid Loss:  0.03614603355526924
Epoch:  235  	Training Loss: 0.03942827880382538
Test Loss:  0.025596821680665016
Valid Loss:  0.03614594414830208
Epoch:  236  	Training Loss: 0.0394282266497612
Test Loss:  0.0255967415869236
Valid Loss:  0.03614585101604462
Epoch:  237  	Training Loss: 0.03942817449569702
Test Loss:  0.02559666335582733
Valid Loss:  0.036145757883787155
Epoch:  238  	Training Loss: 0.03942812234163284
Test Loss:  0.025596585124731064
Valid Loss:  0.036145664751529694
Epoch:  239  	Training Loss: 0.039428070187568665
Test Loss:  0.025596505030989647
Valid Loss:  0.03614557534456253
Epoch:  240  	Training Loss: 0.03942801430821419
Test Loss:  0.02559642866253853
Valid Loss:  0.03614547848701477
Epoch:  241  	Training Loss: 0.03942796215415001
Test Loss:  0.025596346706151962
Valid Loss:  0.03614538908004761
Epoch:  242  	Training Loss: 0.03942790627479553
Test Loss:  0.025596261024475098
Valid Loss:  0.03614528477191925
Epoch:  243  	Training Loss: 0.03942785784602165
Test Loss:  0.025596171617507935
Valid Loss:  0.03614518791437149
Epoch:  244  	Training Loss: 0.03942780941724777
Test Loss:  0.025596078485250473
Valid Loss:  0.03614509105682373
Epoch:  245  	Training Loss: 0.03942776471376419
Test Loss:  0.02559598907828331
Valid Loss:  0.03614499047398567
Epoch:  246  	Training Loss: 0.03942771255970001
Test Loss:  0.025595903396606445
Valid Loss:  0.036144889891147614
Epoch:  247  	Training Loss: 0.039427660405635834
Test Loss:  0.02559581585228443
Valid Loss:  0.036144789308309555
Epoch:  248  	Training Loss: 0.03942761570215225
Test Loss:  0.025595728307962418
Valid Loss:  0.0361446887254715
Epoch:  249  	Training Loss: 0.039427563548088074
Test Loss:  0.025595635175704956
Valid Loss:  0.03614459186792374
Epoch:  250  	Training Loss: 0.03942751884460449
Test Loss:  0.02559554949402809
Valid Loss:  0.03614448755979538
Epoch:  251  	Training Loss: 0.039427466690540314
Test Loss:  0.025595463812351227
Valid Loss:  0.03614439070224762
Epoch:  252  	Training Loss: 0.039427418261766434
Test Loss:  0.02559538371860981
Valid Loss:  0.03614430129528046
Epoch:  253  	Training Loss: 0.039427369832992554
Test Loss:  0.025595303624868393
Valid Loss:  0.03614421188831329
Epoch:  254  	Training Loss: 0.039427321404218674
Test Loss:  0.025595225393772125
Valid Loss:  0.03614412248134613
Epoch:  255  	Training Loss: 0.039427269250154495
Test Loss:  0.025595149025321007
Valid Loss:  0.03614403307437897
Epoch:  256  	Training Loss: 0.039427220821380615
Test Loss:  0.02559507265686989
Valid Loss:  0.036143943667411804
Epoch:  257  	Training Loss: 0.03942716866731644
Test Loss:  0.02559499442577362
Valid Loss:  0.03614385426044464
Epoch:  258  	Training Loss: 0.03942712023854256
Test Loss:  0.02559491991996765
Valid Loss:  0.03614376485347748
Epoch:  259  	Training Loss: 0.03942707180976868
Test Loss:  0.025594837963581085
Valid Loss:  0.036143675446510315
Epoch:  260  	Training Loss: 0.0394270196557045
Test Loss:  0.025594763457775116
Valid Loss:  0.03614358603954315
Epoch:  261  	Training Loss: 0.03942697495222092
Test Loss:  0.025594688951969147
Valid Loss:  0.03614349663257599
Epoch:  262  	Training Loss: 0.03942692652344704
Test Loss:  0.02559460699558258
Valid Loss:  0.03614340350031853
Epoch:  263  	Training Loss: 0.03942687436938286
Test Loss:  0.025594525039196014
Valid Loss:  0.03614330664277077
Epoch:  264  	Training Loss: 0.03942682221531868
Test Loss:  0.025594443082809448
Valid Loss:  0.036143213510513306
Epoch:  265  	Training Loss: 0.0394267737865448
Test Loss:  0.025594361126422882
Valid Loss:  0.03614312410354614
Epoch:  266  	Training Loss: 0.03942672535777092
Test Loss:  0.025594281032681465
Valid Loss:  0.036143023520708084
Epoch:  267  	Training Loss: 0.03942666947841644
Test Loss:  0.0255941990762949
Valid Loss:  0.03614293038845062
Epoch:  268  	Training Loss: 0.03942662104964256
Test Loss:  0.025594118982553482
Valid Loss:  0.03614284098148346
Epoch:  269  	Training Loss: 0.03942657262086868
Test Loss:  0.025594038888812065
Valid Loss:  0.0361427441239357
Epoch:  270  	Training Loss: 0.039426520466804504
Test Loss:  0.02559395506978035
Valid Loss:  0.036142654716968536
Epoch:  271  	Training Loss: 0.039426468312740326
Test Loss:  0.025593876838684082
Valid Loss:  0.036142557859420776
Epoch:  272  	Training Loss: 0.039426419883966446
Test Loss:  0.025593793019652367
Valid Loss:  0.036142461001873016
Epoch:  273  	Training Loss: 0.03942636400461197
Test Loss:  0.0255937147885561
Valid Loss:  0.036142367869615555
Epoch:  274  	Training Loss: 0.03942630812525749
Test Loss:  0.02559363655745983
Valid Loss:  0.03614227473735809
Epoch:  275  	Training Loss: 0.039426252245903015
Test Loss:  0.025593560189008713
Valid Loss:  0.03614217787981033
Epoch:  276  	Training Loss: 0.03942619264125824
Test Loss:  0.025593478232622147
Valid Loss:  0.03614208847284317
Epoch:  277  	Training Loss: 0.03942614048719406
Test Loss:  0.02559339813888073
Valid Loss:  0.03614198789000511
Epoch:  278  	Training Loss: 0.039426080882549286
Test Loss:  0.025593319907784462
Valid Loss:  0.03614189475774765
Epoch:  279  	Training Loss: 0.03942602500319481
Test Loss:  0.025593239814043045
Valid Loss:  0.03614179790019989
Epoch:  280  	Training Loss: 0.03942596912384033
Test Loss:  0.025593161582946777
Valid Loss:  0.03614170849323273
Epoch:  281  	Training Loss: 0.039425916969776154
Test Loss:  0.02559308521449566
Valid Loss:  0.036141615360975266
Epoch:  282  	Training Loss: 0.03942585736513138
Test Loss:  0.025593005120754242
Valid Loss:  0.036141522228717804
Epoch:  283  	Training Loss: 0.0394258052110672
Test Loss:  0.025592925027012825
Valid Loss:  0.036141425371170044
Epoch:  284  	Training Loss: 0.03942575305700302
Test Loss:  0.025592848658561707
Valid Loss:  0.03614133596420288
Epoch:  285  	Training Loss: 0.03942570090293884
Test Loss:  0.02559276856482029
Valid Loss:  0.03614124283194542
 57%|█████▋    | 287/500 [03:22<01:38,  2.16it/s] 58%|█████▊    | 289/500 [03:22<01:12,  2.90it/s] 58%|█████▊    | 291/500 [03:29<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:29<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:29<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:29<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:29<01:07,  2.98it/s] 60%|██████    | 301/500 [03:36<03:54,  1.18s/it] 61%|██████    | 303/500 [03:36<02:46,  1.18it/s] 61%|██████    | 305/500 [03:36<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:36<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:36<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:43<03:52,  1.23s/it] 63%|██████▎   | 313/500 [03:43<02:46,  1.13it/s] 63%|██████▎   | 315/500 [03:43<01:59,  1.54it/s] 63%|██████▎   | 317/500 [03:43<01:27,  2.09it/s] 64%|██████▍   | 319/500 [03:43<01:05,  2.77it/s] 64%|██████▍   | 321/500 [03:50<03:41,  1.23s/it] 65%|██████▍   | 323/500 [03:50<02:36,  1.13it/s] 65%|██████▌   | 325/500 [03:50<01:52,  1.56it/s] 65%|██████▌   | 327/500 [03:50<01:20,  2.14it/s] 66%|██████▌   | 329/500 [03:51<00:59,  2.88it/s] 66%|██████▌   | 331/500 [03:57<03:24,  1.21s/it] 67%|██████▋   | 333/500 [03:57<02:24,  1.15it/s] 67%|██████▋   | 335/500 [03:57<01:43,  1.59it/s] 67%|██████▋   | 337/500 [03:57<01:14,  2.18it/s] 68%|██████▊   | 339/500 [03:58<00:54,  2.93it/s] 68%|██████▊   | 341/500 [04:04<03:11,  1.20s/it] 69%|██████▊   | 343/500 [04:04<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:04<01:36,  1.60it/s] 69%|██████▉   | 347/500 [04:04<01:09,  2.19it/s] 70%|██████▉   | 349/500 [04:04<00:51,  2.95it/s] 70%|███████   | 351/500 [04:11<02:59,  1.21s/it] 71%|███████   | 353/500 [04:11<02:07,  1.15it/s] 71%|███████   | 355/500 [04:11<01:30,  1.60it/s]Epoch:  286  	Training Loss: 0.039425648748874664
Test Loss:  0.025592688471078873
Valid Loss:  0.03614114969968796
Epoch:  287  	Training Loss: 0.039425596594810486
Test Loss:  0.025592608377337456
Valid Loss:  0.036141060292720795
Epoch:  288  	Training Loss: 0.03942554444074631
Test Loss:  0.02559252828359604
Valid Loss:  0.036140963435173035
Epoch:  289  	Training Loss: 0.03942549228668213
Test Loss:  0.025592448189854622
Valid Loss:  0.03614087775349617
Epoch:  290  	Training Loss: 0.03942544013261795
Test Loss:  0.025592371821403503
Valid Loss:  0.03614078462123871
Epoch:  291  	Training Loss: 0.03942538797855377
Test Loss:  0.025592293590307236
Valid Loss:  0.036140695214271545
Epoch:  292  	Training Loss: 0.039425335824489594
Test Loss:  0.025592215359210968
Valid Loss:  0.036140598356723785
Epoch:  293  	Training Loss: 0.03942527994513512
Test Loss:  0.025592133402824402
Valid Loss:  0.036140505224466324
Epoch:  294  	Training Loss: 0.03942522779107094
Test Loss:  0.025592057034373283
Valid Loss:  0.036140408366918564
Epoch:  295  	Training Loss: 0.03942517191171646
Test Loss:  0.025591976940631866
Valid Loss:  0.0361403189599514
Epoch:  296  	Training Loss: 0.03942511975765228
Test Loss:  0.02559189684689045
Valid Loss:  0.03614022582769394
Epoch:  297  	Training Loss: 0.039425063878297806
Test Loss:  0.02559182047843933
Valid Loss:  0.03614013269543648
Epoch:  298  	Training Loss: 0.03942501172423363
Test Loss:  0.025591740384697914
Valid Loss:  0.036140039563179016
Epoch:  299  	Training Loss: 0.03942495957016945
Test Loss:  0.0255916565656662
Valid Loss:  0.036139946430921555
Epoch:  300  	Training Loss: 0.03942490369081497
Test Loss:  0.02559158205986023
Valid Loss:  0.036139849573373795
Epoch:  301  	Training Loss: 0.03942485153675079
Test Loss:  0.025591500103473663
Valid Loss:  0.03613976016640663
Epoch:  302  	Training Loss: 0.039424799382686615
Test Loss:  0.02559141255915165
Valid Loss:  0.03613965958356857
Epoch:  303  	Training Loss: 0.039424750953912735
Test Loss:  0.025591328740119934
Valid Loss:  0.036139559000730515
Epoch:  304  	Training Loss: 0.039424702525138855
Test Loss:  0.025591235607862473
Valid Loss:  0.036139458417892456
Epoch:  305  	Training Loss: 0.039424650371074677
Test Loss:  0.025591149926185608
Valid Loss:  0.0361393578350544
Epoch:  306  	Training Loss: 0.039424601942300797
Test Loss:  0.025591060519218445
Valid Loss:  0.03613925725221634
Epoch:  307  	Training Loss: 0.03942454978823662
Test Loss:  0.02559097483754158
Valid Loss:  0.03613916039466858
Epoch:  308  	Training Loss: 0.03942450135946274
Test Loss:  0.025590883567929268
Valid Loss:  0.03613906353712082
Epoch:  309  	Training Loss: 0.03942445293068886
Test Loss:  0.025590799748897552
Valid Loss:  0.03613895922899246
Epoch:  310  	Training Loss: 0.03942440450191498
Test Loss:  0.02559071034193039
Valid Loss:  0.0361388623714447
Epoch:  311  	Training Loss: 0.0394243523478508
Test Loss:  0.025590620934963226
Valid Loss:  0.03613876551389694
Epoch:  312  	Training Loss: 0.03942430019378662
Test Loss:  0.025590546429157257
Valid Loss:  0.03613866865634918
Epoch:  313  	Training Loss: 0.03942424803972244
Test Loss:  0.02559046633541584
Valid Loss:  0.036138586699962616
Epoch:  314  	Training Loss: 0.039424195885658264
Test Loss:  0.02559039369225502
Valid Loss:  0.036138489842414856
Epoch:  315  	Training Loss: 0.03942413628101349
Test Loss:  0.0255903173238039
Valid Loss:  0.03613840043544769
Epoch:  316  	Training Loss: 0.03942408412694931
Test Loss:  0.025590242817997932
Valid Loss:  0.03613831102848053
Epoch:  317  	Training Loss: 0.03942402824759483
Test Loss:  0.025590166449546814
Valid Loss:  0.03613821417093277
Epoch:  318  	Training Loss: 0.039423972368240356
Test Loss:  0.025590093806385994
Valid Loss:  0.036138132214546204
Epoch:  319  	Training Loss: 0.03942391276359558
Test Loss:  0.025590015575289726
Valid Loss:  0.036138035356998444
Epoch:  320  	Training Loss: 0.0394238606095314
Test Loss:  0.025589939206838608
Valid Loss:  0.03613794595003128
Epoch:  321  	Training Loss: 0.039423808455467224
Test Loss:  0.02558986470103264
Valid Loss:  0.03613785281777382
Epoch:  322  	Training Loss: 0.03942374885082245
Test Loss:  0.02558978646993637
Valid Loss:  0.036137763410806656
Epoch:  323  	Training Loss: 0.03942370042204857
Test Loss:  0.025589708238840103
Valid Loss:  0.036137670278549194
Epoch:  324  	Training Loss: 0.03942364826798439
Test Loss:  0.025589626282453537
Valid Loss:  0.03613757714629173
Epoch:  325  	Training Loss: 0.03942359238862991
Test Loss:  0.02558954805135727
Valid Loss:  0.03613748401403427
Epoch:  326  	Training Loss: 0.03942354395985603
Test Loss:  0.02558947168290615
Valid Loss:  0.03613739460706711
Epoch:  327  	Training Loss: 0.039423491805791855
Test Loss:  0.025589391589164734
Valid Loss:  0.036137305200099945
Epoch:  328  	Training Loss: 0.039423439651727676
Test Loss:  0.025589311495423317
Valid Loss:  0.036137208342552185
Epoch:  329  	Training Loss: 0.039423391222953796
Test Loss:  0.0255892314016819
Valid Loss:  0.03613711893558502
Epoch:  330  	Training Loss: 0.03942333534359932
Test Loss:  0.025589153170585632
Valid Loss:  0.03613702207803726
Epoch:  331  	Training Loss: 0.03942328691482544
Test Loss:  0.025589073076844215
Valid Loss:  0.0361369326710701
Epoch:  332  	Training Loss: 0.03942323476076126
Test Loss:  0.025588996708393097
Valid Loss:  0.03613683953881264
Epoch:  333  	Training Loss: 0.03942318260669708
Test Loss:  0.02558891475200653
Valid Loss:  0.036136746406555176
Epoch:  334  	Training Loss: 0.039423130452632904
Test Loss:  0.025588838383555412
Valid Loss:  0.03613665699958801
Epoch:  335  	Training Loss: 0.039423078298568726
Test Loss:  0.025588758289813995
Valid Loss:  0.03613656014204025
Epoch:  336  	Training Loss: 0.03942302614450455
Test Loss:  0.02558867633342743
Valid Loss:  0.03613646700978279
Epoch:  337  	Training Loss: 0.03942297026515007
Test Loss:  0.025588594377040863
Valid Loss:  0.03613637387752533
Epoch:  338  	Training Loss: 0.03942292183637619
Test Loss:  0.025588516145944595
Valid Loss:  0.03613628074526787
Epoch:  339  	Training Loss: 0.03942286595702171
Test Loss:  0.025588437914848328
Valid Loss:  0.036136187613010406
Epoch:  340  	Training Loss: 0.03942281752824783
Test Loss:  0.02558835968375206
Valid Loss:  0.03613609820604324
Epoch:  341  	Training Loss: 0.039422765374183655
Test Loss:  0.025588279590010643
Valid Loss:  0.03613600134849548
Epoch:  342  	Training Loss: 0.03942270576953888
Test Loss:  0.025588197633624077
Valid Loss:  0.03613591194152832
Epoch:  343  	Training Loss: 0.039422657340765
Test Loss:  0.02558811940252781
Valid Loss:  0.03613581880927086
Epoch:  344  	Training Loss: 0.03942260146141052
Test Loss:  0.02558804303407669
Valid Loss:  0.0361357256770134
Epoch:  345  	Training Loss: 0.03942255303263664
Test Loss:  0.025587959215044975
Valid Loss:  0.036135636270046234
Epoch:  346  	Training Loss: 0.039422497153282166
Test Loss:  0.025587880983948708
Valid Loss:  0.036135539412498474
Epoch:  347  	Training Loss: 0.039422448724508286
Test Loss:  0.02558780461549759
Valid Loss:  0.03613544628024101
Epoch:  348  	Training Loss: 0.03942239657044411
Test Loss:  0.02558772638440132
Valid Loss:  0.03613534942269325
Epoch:  349  	Training Loss: 0.03942234069108963
Test Loss:  0.025587644428014755
Valid Loss:  0.03613525629043579
Epoch:  350  	Training Loss: 0.03942228853702545
Test Loss:  0.025587566196918488
Valid Loss:  0.03613516315817833
Epoch:  351  	Training Loss: 0.03942223638296127
Test Loss:  0.025587482377886772
Valid Loss:  0.03613507002592087
Epoch:  352  	Training Loss: 0.039422184228897095
Test Loss:  0.025587406009435654
Valid Loss:  0.036134976893663406
Epoch:  353  	Training Loss: 0.039422132074832916
Test Loss:  0.025587331503629684
Valid Loss:  0.03613489121198654
Epoch:  354  	Training Loss: 0.03942207992076874
Test Loss:  0.025587253272533417
Valid Loss:  0.03613480180501938
Epoch:  355  	Training Loss: 0.03942202776670456
Test Loss:  0.0255871769040823
Valid Loss:  0.03613470494747162
Epoch:  356  	Training Loss: 0.03942197561264038
Test Loss:  0.02558710053563118
Valid Loss:  0.036134619265794754
 71%|███████▏  | 357/500 [04:11<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:11<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:18<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:18<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:18<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:18<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:18<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:25<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:25<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:25<01:18,  1.60it/s] 75%|███████▌  | 377/500 [04:25<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:25<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:32<02:26,  1.23s/it] 77%|███████▋  | 383/500 [04:32<01:43,  1.14it/s] 77%|███████▋  | 385/500 [04:32<01:13,  1.57it/s] 77%|███████▋  | 387/500 [04:32<00:52,  2.15it/s] 78%|███████▊  | 389/500 [04:32<00:38,  2.90it/s] 78%|███████▊  | 391/500 [04:39<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:39<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:39<01:05,  1.59it/s] 79%|███████▉  | 397/500 [04:39<00:47,  2.17it/s] 80%|███████▉  | 399/500 [04:39<00:35,  2.86it/s] 80%|████████  | 401/500 [04:46<01:58,  1.20s/it] 81%|████████  | 403/500 [04:46<01:23,  1.16it/s] 81%|████████  | 405/500 [04:46<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:46<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:53<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:53<01:15,  1.15it/s] 83%|████████▎ | 415/500 [04:53<00:54,  1.57it/s] 83%|████████▎ | 417/500 [04:53<00:39,  2.12it/s] 84%|████████▍ | 419/500 [04:54<00:28,  2.80it/s] 84%|████████▍ | 421/500 [05:00<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:00<01:06,  1.17it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:00<00:33,  2.20it/s]Epoch:  357  	Training Loss: 0.0394219271838665
Test Loss:  0.025587022304534912
Valid Loss:  0.03613452613353729
Epoch:  358  	Training Loss: 0.039421871304512024
Test Loss:  0.025586944073438644
Valid Loss:  0.03613443672657013
Epoch:  359  	Training Loss: 0.039421819150447845
Test Loss:  0.025586867704987526
Valid Loss:  0.03613434359431267
Epoch:  360  	Training Loss: 0.03942176699638367
Test Loss:  0.02558678761124611
Valid Loss:  0.0361342579126358
Epoch:  361  	Training Loss: 0.03942171484231949
Test Loss:  0.02558671310544014
Valid Loss:  0.03613416850566864
Epoch:  362  	Training Loss: 0.03942166641354561
Test Loss:  0.025586631149053574
Valid Loss:  0.03613407164812088
Epoch:  363  	Training Loss: 0.03942161053419113
Test Loss:  0.025586549192667007
Valid Loss:  0.03613397479057312
Epoch:  364  	Training Loss: 0.03942155838012695
Test Loss:  0.02558646723628044
Valid Loss:  0.03613388165831566
Epoch:  365  	Training Loss: 0.039421506226062775
Test Loss:  0.025586385279893875
Valid Loss:  0.0361337848007679
Epoch:  366  	Training Loss: 0.039421454071998596
Test Loss:  0.02558630332350731
Valid Loss:  0.03613369166851044
Epoch:  367  	Training Loss: 0.03942140191793442
Test Loss:  0.025586221367120743
Valid Loss:  0.036133598536252975
Epoch:  368  	Training Loss: 0.03942134976387024
Test Loss:  0.025586141273379326
Valid Loss:  0.036133501678705215
Epoch:  369  	Training Loss: 0.03942129760980606
Test Loss:  0.02558605745434761
Valid Loss:  0.036133404821157455
Epoch:  370  	Training Loss: 0.039421241730451584
Test Loss:  0.025585977360606194
Valid Loss:  0.036133307963609695
Epoch:  371  	Training Loss: 0.039421189576387405
Test Loss:  0.025585897266864777
Valid Loss:  0.036133214831352234
Epoch:  372  	Training Loss: 0.039421141147613525
Test Loss:  0.02558581344783306
Valid Loss:  0.03613312169909477
Epoch:  373  	Training Loss: 0.03942108899354935
Test Loss:  0.025585731491446495
Valid Loss:  0.03613302856683731
Epoch:  374  	Training Loss: 0.03942103683948517
Test Loss:  0.025585651397705078
Valid Loss:  0.03613293170928955
Epoch:  375  	Training Loss: 0.03942098468542099
Test Loss:  0.02558557316660881
Valid Loss:  0.03613283485174179
Epoch:  376  	Training Loss: 0.03942092880606651
Test Loss:  0.025585489347577095
Valid Loss:  0.03613274544477463
Epoch:  377  	Training Loss: 0.039420872926712036
Test Loss:  0.025585409253835678
Valid Loss:  0.03613264858722687
Epoch:  378  	Training Loss: 0.039420824497938156
Test Loss:  0.02558533102273941
Valid Loss:  0.036132555454969406
Epoch:  379  	Training Loss: 0.03942076861858368
Test Loss:  0.025585247203707695
Valid Loss:  0.03613246604800224
Epoch:  380  	Training Loss: 0.0394207201898098
Test Loss:  0.025585167109966278
Valid Loss:  0.03613236919045448
Epoch:  381  	Training Loss: 0.03942067176103592
Test Loss:  0.02558508887887001
Valid Loss:  0.03613227605819702
Epoch:  382  	Training Loss: 0.039420612156391144
Test Loss:  0.025585008785128593
Valid Loss:  0.03613217920064926
Epoch:  383  	Training Loss: 0.039420563727617264
Test Loss:  0.025584930554032326
Valid Loss:  0.0361320897936821
Epoch:  384  	Training Loss: 0.03942050784826279
Test Loss:  0.025584854185581207
Valid Loss:  0.036132000386714935
Epoch:  385  	Training Loss: 0.03942045569419861
Test Loss:  0.025584779679775238
Valid Loss:  0.03613191097974777
Epoch:  386  	Training Loss: 0.03942040726542473
Test Loss:  0.025584697723388672
Valid Loss:  0.03613181412220001
Epoch:  387  	Training Loss: 0.03942035138607025
Test Loss:  0.025584619492292404
Valid Loss:  0.03613172471523285
Epoch:  388  	Training Loss: 0.03942029923200607
Test Loss:  0.025584544986486435
Valid Loss:  0.036131635308265686
Epoch:  389  	Training Loss: 0.039420247077941895
Test Loss:  0.025584466755390167
Valid Loss:  0.036131542176008224
Epoch:  390  	Training Loss: 0.039420194923877716
Test Loss:  0.0255843885242939
Valid Loss:  0.03613144904375076
Epoch:  391  	Training Loss: 0.03942014276981354
Test Loss:  0.02558431215584278
Valid Loss:  0.036131352186203
Epoch:  392  	Training Loss: 0.03942009061574936
Test Loss:  0.025584232062101364
Valid Loss:  0.03613126650452614
Epoch:  393  	Training Loss: 0.03942003846168518
Test Loss:  0.025584150105714798
Valid Loss:  0.03613117337226868
Epoch:  394  	Training Loss: 0.039419982582330704
Test Loss:  0.025584079325199127
Valid Loss:  0.036131083965301514
Epoch:  395  	Training Loss: 0.039419934153556824
Test Loss:  0.02558399736881256
Valid Loss:  0.03613099083304405
Epoch:  396  	Training Loss: 0.039419881999492645
Test Loss:  0.025583922863006592
Valid Loss:  0.03613089770078659
Epoch:  397  	Training Loss: 0.03941982239484787
Test Loss:  0.025583839043974876
Valid Loss:  0.03613080829381943
Epoch:  398  	Training Loss: 0.03941977396607399
Test Loss:  0.025583762675523758
Valid Loss:  0.036130715161561966
Epoch:  399  	Training Loss: 0.03941971808671951
Test Loss:  0.02558368444442749
Valid Loss:  0.036130622029304504
Epoch:  400  	Training Loss: 0.039419665932655334
Test Loss:  0.025583608075976372
Valid Loss:  0.03613052889704704
Epoch:  401  	Training Loss: 0.039419613778591156
Test Loss:  0.025583527982234955
Valid Loss:  0.03613043576478958
Epoch:  402  	Training Loss: 0.03941956162452698
Test Loss:  0.02558344602584839
Valid Loss:  0.03613034263253212
Epoch:  403  	Training Loss: 0.0394195131957531
Test Loss:  0.02558336965739727
Valid Loss:  0.036130256950855255
Epoch:  404  	Training Loss: 0.03941946476697922
Test Loss:  0.025583285838365555
Valid Loss:  0.036130160093307495
Epoch:  405  	Training Loss: 0.03941941261291504
Test Loss:  0.025583207607269287
Valid Loss:  0.03613007068634033
Epoch:  406  	Training Loss: 0.03941936045885086
Test Loss:  0.02558312378823757
Valid Loss:  0.03612997382879257
Epoch:  407  	Training Loss: 0.03941930830478668
Test Loss:  0.025583045557141304
Valid Loss:  0.03612987697124481
Epoch:  408  	Training Loss: 0.0394192598760128
Test Loss:  0.02558296173810959
Valid Loss:  0.03612978756427765
Epoch:  409  	Training Loss: 0.039419207721948624
Test Loss:  0.025582879781723022
Valid Loss:  0.03612969070672989
Epoch:  410  	Training Loss: 0.039419159293174744
Test Loss:  0.025582803413271904
Valid Loss:  0.036129605025053024
Epoch:  411  	Training Loss: 0.039419107139110565
Test Loss:  0.025582723319530487
Valid Loss:  0.036129508167505264
Epoch:  412  	Training Loss: 0.03941905498504639
Test Loss:  0.02558263950049877
Valid Loss:  0.0361294150352478
Epoch:  413  	Training Loss: 0.03941900283098221
Test Loss:  0.025582555681467056
Valid Loss:  0.036129314452409744
Epoch:  414  	Training Loss: 0.03941895812749863
Test Loss:  0.02558247372508049
Valid Loss:  0.036129217594861984
Epoch:  415  	Training Loss: 0.03941890224814415
Test Loss:  0.025582388043403625
Valid Loss:  0.03612912446260452
Epoch:  416  	Training Loss: 0.03941885381937027
Test Loss:  0.02558230608701706
Valid Loss:  0.03612902760505676
Epoch:  417  	Training Loss: 0.03941880166530609
Test Loss:  0.025582218542695045
Valid Loss:  0.036128930747509
Epoch:  418  	Training Loss: 0.03941875323653221
Test Loss:  0.02558213286101818
Valid Loss:  0.03612883388996124
Epoch:  419  	Training Loss: 0.039418697357177734
Test Loss:  0.025582052767276764
Valid Loss:  0.03612873703241348
Epoch:  420  	Training Loss: 0.03941865265369415
Test Loss:  0.02558196894824505
Valid Loss:  0.03612864390015602
Epoch:  421  	Training Loss: 0.039418596774339676
Test Loss:  0.025581883266568184
Valid Loss:  0.03612854331731796
Epoch:  422  	Training Loss: 0.039418548345565796
Test Loss:  0.025581805035471916
Valid Loss:  0.0361284539103508
Epoch:  423  	Training Loss: 0.03941849619150162
Test Loss:  0.025581730529665947
Valid Loss:  0.03612837195396423
Epoch:  424  	Training Loss: 0.03941844403743744
Test Loss:  0.025581656023859978
Valid Loss:  0.03612827509641647
Epoch:  425  	Training Loss: 0.03941839188337326
Test Loss:  0.02558157965540886
Valid Loss:  0.03612819314002991
Epoch:  426  	Training Loss: 0.03941833972930908
Test Loss:  0.025581499561667442
Valid Loss:  0.03612809628248215
Epoch:  427  	Training Loss: 0.039418287575244904
Test Loss:  0.025581426918506622
Valid Loss:  0.036128006875514984
 86%|████████▌ | 429/500 [05:00<00:24,  2.96it/s] 86%|████████▌ | 431/500 [05:07<01:23,  1.20s/it] 87%|████████▋ | 433/500 [05:07<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:07<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:07<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:14<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:14<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:14<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:14<00:24,  2.14it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.88it/s] 90%|█████████ | 451/500 [05:21<01:00,  1.23s/it] 91%|█████████ | 453/500 [05:21<00:41,  1.13it/s] 91%|█████████ | 455/500 [05:21<00:29,  1.55it/s] 91%|█████████▏| 457/500 [05:21<00:20,  2.11it/s] 92%|█████████▏| 459/500 [05:22<00:14,  2.85it/s] 92%|█████████▏| 461/500 [05:28<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:28<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:28<00:21,  1.59it/s] 93%|█████████▎| 467/500 [05:28<00:15,  2.18it/s] 94%|█████████▍| 469/500 [05:29<00:10,  2.93it/s] 94%|█████████▍| 471/500 [05:35<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:35<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:35<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:35<00:10,  2.20it/s] 96%|█████████▌| 479/500 [05:35<00:07,  2.97it/s] 96%|█████████▌| 481/500 [05:42<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:42<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:42<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:42<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:42<00:03,  2.95it/s] 98%|█████████▊| 491/500 [05:49<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:49<00:06,  1.14it/s] 99%|█████████▉| 495/500 [05:49<00:03,  1.58it/s] 99%|█████████▉| 497/500 [05:49<00:01,  2.16it/s]Epoch:  428  	Training Loss: 0.039418235421180725
Test Loss:  0.025581348687410355
Valid Loss:  0.03612791746854782
Epoch:  429  	Training Loss: 0.039418190717697144
Test Loss:  0.025581270456314087
Valid Loss:  0.03612782806158066
Epoch:  430  	Training Loss: 0.039418138563632965
Test Loss:  0.025581195950508118
Valid Loss:  0.03612774237990379
Epoch:  431  	Training Loss: 0.03941808268427849
Test Loss:  0.025581119582057
Valid Loss:  0.03612764924764633
Epoch:  432  	Training Loss: 0.03941803425550461
Test Loss:  0.02558104321360588
Valid Loss:  0.03612755984067917
Epoch:  433  	Training Loss: 0.03941798210144043
Test Loss:  0.025580964982509613
Valid Loss:  0.03612746670842171
Epoch:  434  	Training Loss: 0.039417922496795654
Test Loss:  0.025580890476703644
Valid Loss:  0.036127377301454544
Epoch:  435  	Training Loss: 0.03941787779331207
Test Loss:  0.025580808520317078
Valid Loss:  0.036127280443906784
Epoch:  436  	Training Loss: 0.039417821913957596
Test Loss:  0.02558073028922081
Valid Loss:  0.03612719103693962
Epoch:  437  	Training Loss: 0.03941776975989342
Test Loss:  0.025580650195479393
Valid Loss:  0.03612709790468216
Epoch:  438  	Training Loss: 0.03941771760582924
Test Loss:  0.025580575689673424
Valid Loss:  0.036127008497714996
Epoch:  439  	Training Loss: 0.03941766545176506
Test Loss:  0.025580499321222305
Valid Loss:  0.03612691909074783
Epoch:  440  	Training Loss: 0.03941761329770088
Test Loss:  0.02558041736483574
Valid Loss:  0.03612682595849037
Epoch:  441  	Training Loss: 0.039417557418346405
Test Loss:  0.02558034285902977
Valid Loss:  0.03612673282623291
Epoch:  442  	Training Loss: 0.03941750526428223
Test Loss:  0.025580260902643204
Valid Loss:  0.03612663596868515
Epoch:  443  	Training Loss: 0.039417460560798645
Test Loss:  0.025580180808901787
Valid Loss:  0.036126554012298584
Epoch:  444  	Training Loss: 0.03941740840673447
Test Loss:  0.02558010071516037
Valid Loss:  0.036126457154750824
Epoch:  445  	Training Loss: 0.03941735625267029
Test Loss:  0.025580018758773804
Valid Loss:  0.036126360297203064
Epoch:  446  	Training Loss: 0.03941730409860611
Test Loss:  0.025579940527677536
Valid Loss:  0.0361262708902359
Epoch:  447  	Training Loss: 0.03941725194454193
Test Loss:  0.02557985857129097
Valid Loss:  0.03612617775797844
Epoch:  448  	Training Loss: 0.03941719979047775
Test Loss:  0.025579780340194702
Valid Loss:  0.03612608462572098
Epoch:  449  	Training Loss: 0.03941715508699417
Test Loss:  0.025579698383808136
Valid Loss:  0.03612598776817322
Epoch:  450  	Training Loss: 0.03941710293292999
Test Loss:  0.025579622015357018
Valid Loss:  0.036125898361206055
Epoch:  451  	Training Loss: 0.039417050778865814
Test Loss:  0.025579538196325302
Valid Loss:  0.03612580522894859
Epoch:  452  	Training Loss: 0.039416998624801636
Test Loss:  0.025579458102583885
Valid Loss:  0.03612570837140083
Epoch:  453  	Training Loss: 0.039416953921318054
Test Loss:  0.025579378008842468
Valid Loss:  0.03612561896443367
Epoch:  454  	Training Loss: 0.039416901767253876
Test Loss:  0.025579296052455902
Valid Loss:  0.03612552583217621
Epoch:  455  	Training Loss: 0.0394168496131897
Test Loss:  0.025579219684004784
Valid Loss:  0.036125436425209045
Epoch:  456  	Training Loss: 0.03941679745912552
Test Loss:  0.025579139590263367
Valid Loss:  0.03612534701824188
Epoch:  457  	Training Loss: 0.03941674903035164
Test Loss:  0.0255790576338768
Valid Loss:  0.03612525388598442
Epoch:  458  	Training Loss: 0.03941670060157776
Test Loss:  0.025578979402780533
Valid Loss:  0.03612515330314636
Epoch:  459  	Training Loss: 0.03941664844751358
Test Loss:  0.025578895583748817
Valid Loss:  0.0361250638961792
Epoch:  460  	Training Loss: 0.0394165962934494
Test Loss:  0.0255788154900074
Valid Loss:  0.03612496703863144
Epoch:  461  	Training Loss: 0.03941655158996582
Test Loss:  0.02557874098420143
Valid Loss:  0.036124877631664276
Epoch:  462  	Training Loss: 0.03941649943590164
Test Loss:  0.025578659027814865
Valid Loss:  0.036124784499406815
Epoch:  463  	Training Loss: 0.039416443556547165
Test Loss:  0.025578578934073448
Valid Loss:  0.03612469509243965
Epoch:  464  	Training Loss: 0.039416391402482986
Test Loss:  0.02557850070297718
Valid Loss:  0.03612459823489189
Epoch:  465  	Training Loss: 0.039416342973709106
Test Loss:  0.025578420609235764
Valid Loss:  0.03612450510263443
Epoch:  466  	Training Loss: 0.03941628709435463
Test Loss:  0.025578342378139496
Valid Loss:  0.03612441569566727
Epoch:  467  	Training Loss: 0.03941623494029045
Test Loss:  0.02557826228439808
Valid Loss:  0.036124322563409805
Epoch:  468  	Training Loss: 0.03941618651151657
Test Loss:  0.025578182190656662
Valid Loss:  0.036124229431152344
Epoch:  469  	Training Loss: 0.039416126906871796
Test Loss:  0.025578103959560394
Valid Loss:  0.03612414002418518
Epoch:  470  	Training Loss: 0.03941607475280762
Test Loss:  0.025578025728464127
Valid Loss:  0.03612404316663742
Epoch:  471  	Training Loss: 0.03941602632403374
Test Loss:  0.02557794749736786
Valid Loss:  0.03612395375967026
Epoch:  472  	Training Loss: 0.03941597416996956
Test Loss:  0.025577867403626442
Valid Loss:  0.036123864352703094
Epoch:  473  	Training Loss: 0.03941591829061508
Test Loss:  0.025577791035175323
Valid Loss:  0.03612377122044563
Epoch:  474  	Training Loss: 0.0394158661365509
Test Loss:  0.025577712804079056
Valid Loss:  0.03612367808818817
Epoch:  475  	Training Loss: 0.039415813982486725
Test Loss:  0.025577634572982788
Valid Loss:  0.03612358495593071
Epoch:  476  	Training Loss: 0.039415761828422546
Test Loss:  0.02557755634188652
Valid Loss:  0.03612349182367325
Epoch:  477  	Training Loss: 0.03941570967435837
Test Loss:  0.025577478110790253
Valid Loss:  0.03612339869141579
Epoch:  478  	Training Loss: 0.03941565752029419
Test Loss:  0.025577396154403687
Valid Loss:  0.036123305559158325
Epoch:  479  	Training Loss: 0.03941560536623001
Test Loss:  0.02557731792330742
Valid Loss:  0.03612321615219116
Epoch:  480  	Training Loss: 0.03941555321216583
Test Loss:  0.02557723969221115
Valid Loss:  0.036123126745224
Epoch:  481  	Training Loss: 0.03941549360752106
Test Loss:  0.025577161461114883
Valid Loss:  0.03612302988767624
Epoch:  482  	Training Loss: 0.03941544517874718
Test Loss:  0.025577083230018616
Valid Loss:  0.036122940480709076
Epoch:  483  	Training Loss: 0.039415393024683
Test Loss:  0.0255770031362772
Valid Loss:  0.036122843623161316
Epoch:  484  	Training Loss: 0.03941533714532852
Test Loss:  0.02557692676782608
Valid Loss:  0.03612275794148445
Epoch:  485  	Training Loss: 0.03941528871655464
Test Loss:  0.025576844811439514
Valid Loss:  0.03612265735864639
Epoch:  486  	Training Loss: 0.039415232837200165
Test Loss:  0.025576768442988396
Valid Loss:  0.03612256795167923
Epoch:  487  	Training Loss: 0.039415184408426285
Test Loss:  0.02557668834924698
Valid Loss:  0.03612247854471207
Epoch:  488  	Training Loss: 0.039415132254362106
Test Loss:  0.02557661011815071
Valid Loss:  0.03612238168716431
Epoch:  489  	Training Loss: 0.03941507637500763
Test Loss:  0.025576531887054443
Valid Loss:  0.036122292280197144
Epoch:  490  	Training Loss: 0.03941502422094345
Test Loss:  0.025576449930667877
Valid Loss:  0.03612219914793968
Epoch:  491  	Training Loss: 0.03941497206687927
Test Loss:  0.02557637169957161
Valid Loss:  0.03612210229039192
Epoch:  492  	Training Loss: 0.039414919912815094
Test Loss:  0.025576289743185043
Valid Loss:  0.03612201288342476
Epoch:  493  	Training Loss: 0.039414867758750916
Test Loss:  0.025576215237379074
Valid Loss:  0.036121923476457596
Epoch:  494  	Training Loss: 0.03941481560468674
Test Loss:  0.025576138868927956
Valid Loss:  0.036121830344200134
Epoch:  495  	Training Loss: 0.03941476345062256
Test Loss:  0.02557605877518654
Valid Loss:  0.03612174093723297
Epoch:  496  	Training Loss: 0.03941471502184868
Test Loss:  0.025575978681445122
Valid Loss:  0.03612164407968521
Epoch:  497  	Training Loss: 0.0394146665930748
Test Loss:  0.025575898587703705
Valid Loss:  0.03612155467271805
Epoch:  498  	Training Loss: 0.03941461071372032
Test Loss:  0.025575822219252586
Valid Loss:  0.036121465265750885
100%|█████████▉| 499/500 [05:50<00:00,  2.91it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
Epoch:  499  	Training Loss: 0.03941456228494644
Test Loss:  0.02557574212551117
Valid Loss:  0.03612137213349342
Epoch:  500  	Training Loss: 0.03941451013088226
Test Loss:  0.0255756638944149
Valid Loss:  0.03612127527594566
seed is  2
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:50,  6.35s/it]  1%|          | 3/500 [00:06<14:12,  1.71s/it]  1%|          | 5/500 [00:06<07:13,  1.14it/s]  1%|▏         | 7/500 [00:06<04:26,  1.85it/s]  2%|▏         | 9/500 [00:07<03:01,  2.71it/s]  2%|▏         | 11/500 [00:13<11:22,  1.40s/it]  3%|▎         | 13/500 [00:13<07:44,  1.05it/s]  3%|▎         | 15/500 [00:13<05:23,  1.50it/s]  3%|▎         | 17/500 [00:14<03:50,  2.09it/s]  4%|▍         | 19/500 [00:14<02:48,  2.85it/s]  4%|▍         | 21/500 [00:20<09:49,  1.23s/it]  5%|▍         | 23/500 [00:20<06:58,  1.14it/s]  5%|▌         | 25/500 [00:26<12:14,  1.55s/it]  5%|▌         | 27/500 [00:27<08:40,  1.10s/it]  6%|▌         | 29/500 [00:27<06:13,  1.26it/s]  6%|▌         | 31/500 [00:33<11:44,  1.50s/it]  7%|▋         | 33/500 [00:33<08:20,  1.07s/it]  7%|▋         | 35/500 [00:33<05:57,  1.30it/s]  7%|▋         | 37/500 [00:33<04:18,  1.79it/s]  8%|▊         | 39/500 [00:34<03:09,  2.44it/s]  8%|▊         | 41/500 [00:40<09:24,  1.23s/it]  9%|▊         | 43/500 [00:40<06:44,  1.13it/s]  9%|▉         | 45/500 [00:40<04:51,  1.56it/s]  9%|▉         | 47/500 [00:40<03:31,  2.14it/s] 10%|▉         | 49/500 [00:40<02:36,  2.88it/s] 10%|█         | 51/500 [00:47<08:53,  1.19s/it] 11%|█         | 53/500 [00:47<06:21,  1.17it/s] 11%|█         | 55/500 [00:47<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:47<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:47<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:54<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:54<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:54<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:54<03:20,  2.16it/s] 14%|█▍        | 69/500 [00:54<02:30,  2.86it/s]Epoch:  1  	Training Loss: 0.04824826121330261
Test Loss:  0.32073619961738586
Valid Loss:  0.28207266330718994
Epoch:  2  	Training Loss: 0.273082435131073
Test Loss:  5.023266315460205
Valid Loss:  4.856995105743408
Epoch:  3  	Training Loss: 5.2998223304748535
Test Loss:  0.07445056736469269
Valid Loss:  0.06725385040044785
Epoch:  4  	Training Loss: 0.05528925731778145
Test Loss:  0.06902140378952026
Valid Loss:  0.06381923705339432
Epoch:  5  	Training Loss: 0.05043834447860718
Test Loss:  0.06812146306037903
Valid Loss:  0.0630856528878212
Epoch:  6  	Training Loss: 0.04940100014209747
Test Loss:  0.06767172366380692
Valid Loss:  0.06269397586584091
Epoch:  7  	Training Loss: 0.04887828603386879
Test Loss:  0.06733813881874084
Valid Loss:  0.0624040886759758
Epoch:  8  	Training Loss: 0.04850972071290016
Test Loss:  0.06707891821861267
Valid Loss:  0.06219527870416641
Epoch:  9  	Training Loss: 0.048241689801216125
Test Loss:  0.06686536222696304
Valid Loss:  0.062043655663728714
Epoch:  10  	Training Loss: 0.048035115003585815
Test Loss:  0.06669974327087402
Valid Loss:  0.061932921409606934
Epoch:  11  	Training Loss: 0.04786651208996773
Test Loss:  0.06656312197446823
Valid Loss:  0.06185508519411087
Epoch:  12  	Training Loss: 0.047732215374708176
Test Loss:  0.0335678830742836
Valid Loss:  0.03924759477376938
Epoch:  13  	Training Loss: 0.05459042638540268
Test Loss:  0.007009097840636969
Valid Loss:  0.010595828294754028
Epoch:  14  	Training Loss: 0.015331408008933067
Test Loss:  0.004979304037988186
Valid Loss:  0.007568731438368559
Epoch:  15  	Training Loss: 0.011091060936450958
Test Loss:  0.004123063758015633
Valid Loss:  0.005946589633822441
Epoch:  16  	Training Loss: 0.008822072297334671
Test Loss:  0.0038270335644483566
Valid Loss:  0.005114881321787834
Epoch:  17  	Training Loss: 0.007377434987574816
Test Loss:  0.00321792159229517
Valid Loss:  0.004228066653013229
Epoch:  18  	Training Loss: 0.006291583180427551
Test Loss:  0.00307495822198689
Valid Loss:  0.003751823678612709
Epoch:  19  	Training Loss: 0.005461808294057846
Test Loss:  0.0026305504143238068
Valid Loss:  0.0032389890402555466
Epoch:  20  	Training Loss: 0.004799933172762394
Test Loss:  0.002544370014220476
Valid Loss:  0.002930141519755125
Epoch:  21  	Training Loss: 0.004262158181518316
Test Loss:  0.0023064003325998783
Valid Loss:  0.002651672810316086
Epoch:  22  	Training Loss: 0.0038327707443386316
Test Loss:  0.008428461849689484
Valid Loss:  0.005594611167907715
Epoch:  23  	Training Loss: 0.005735699087381363
Test Loss:  0.004407807253301144
Valid Loss:  0.006728982552886009
Epoch:  24  	Training Loss: 0.007538177073001862
Test Loss:  0.005608513019979
Valid Loss:  0.003582419129088521
Epoch:  25  	Training Loss: 0.00379109475761652
Test Loss:  0.0014357112813740969
Valid Loss:  0.0020510046742856503
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.001619033282622695
Test Loss:  0.0013102341908961535
Valid Loss:  0.0015341262333095074
Epoch:  27  	Training Loss: 0.001232354436069727
Test Loss:  0.0012732053874060512
Valid Loss:  0.001348276506178081
Epoch:  28  	Training Loss: 0.0010559381917119026
Test Loss:  0.0012484733015298843
Valid Loss:  0.0011898194206878543
Epoch:  29  	Training Loss: 0.0009268358699046075
Test Loss:  0.0011765668168663979
Valid Loss:  0.001155098550952971
Epoch:  30  	Training Loss: 0.0008649296360090375
Test Loss:  0.0011400311486795545
Valid Loss:  0.0011066736187785864
Epoch:  31  	Training Loss: 0.0008314903825521469
Test Loss:  0.0011098777176812291
Valid Loss:  0.0011138466652482748
Epoch:  32  	Training Loss: 0.0008231085957959294
Test Loss:  0.0010824438650161028
Valid Loss:  0.0010904594091698527
Epoch:  33  	Training Loss: 0.0008014544146135449
Test Loss:  0.0010570003651082516
Valid Loss:  0.0010658291867002845
Epoch:  34  	Training Loss: 0.0007802132749930024
Test Loss:  0.0010323504684492946
Valid Loss:  0.0010451137786731124
Epoch:  35  	Training Loss: 0.0007607551524415612
Test Loss:  0.0009811253985390067
Valid Loss:  0.0010804745834320784
Epoch:  36  	Training Loss: 0.000753328378777951
Test Loss:  0.001005960744805634
Valid Loss:  0.0010419688187539577
Epoch:  37  	Training Loss: 0.0007441322086378932
Test Loss:  0.0009334368514828384
Valid Loss:  0.0010688849724829197
Epoch:  38  	Training Loss: 0.0007280622376129031
Test Loss:  0.0009510962991043925
Valid Loss:  0.000990286935120821
Epoch:  39  	Training Loss: 0.0007043029763735831
Test Loss:  0.000903977663256228
Valid Loss:  0.000998633331619203
Epoch:  40  	Training Loss: 0.0006883330643177032
Test Loss:  0.00088678696192801
Valid Loss:  0.0009703004034236073
Epoch:  41  	Training Loss: 0.0006707260617986321
Test Loss:  0.0008967103203758597
Valid Loss:  0.0009548490634188056
Epoch:  42  	Training Loss: 0.000665227766148746
Test Loss:  0.0008711728733032942
Valid Loss:  0.0009442749433219433
Epoch:  43  	Training Loss: 0.0006520983879454434
Test Loss:  0.000847626244649291
Valid Loss:  0.0009350197506137192
Epoch:  44  	Training Loss: 0.0006403064471669495
Test Loss:  0.0008261071634478867
Valid Loss:  0.000926606880966574
Epoch:  45  	Training Loss: 0.0006297259824350476
Test Loss:  0.0008060124237090349
Valid Loss:  0.0009186112438328564
Epoch:  46  	Training Loss: 0.000619734637439251
Test Loss:  0.0007872395217418671
Valid Loss:  0.0009114204440265894
Epoch:  47  	Training Loss: 0.000610445742495358
Test Loss:  0.000770019250921905
Valid Loss:  0.0009050356457009912
Epoch:  48  	Training Loss: 0.0006020106375217438
Test Loss:  0.0007537154015153646
Valid Loss:  0.0008992127841338515
Epoch:  49  	Training Loss: 0.0005940403789281845
Test Loss:  0.0007382234325632453
Valid Loss:  0.0008938522078096867
Epoch:  50  	Training Loss: 0.0005866372375749052
Test Loss:  0.0007236055098474026
Valid Loss:  0.0008882401743903756
Epoch:  51  	Training Loss: 0.0005795628530904651
Test Loss:  0.0007092455634847283
Valid Loss:  0.0008827251149341464
Epoch:  52  	Training Loss: 0.0005724490620195866
Test Loss:  0.0007028245599940419
Valid Loss:  0.0008425927953794599
Epoch:  53  	Training Loss: 0.0005557233234867454
Test Loss:  0.0006967389490455389
Valid Loss:  0.0008130393689498305
Epoch:  54  	Training Loss: 0.0005425454000942409
Test Loss:  0.0006899702129885554
Valid Loss:  0.0007891585119068623
Epoch:  55  	Training Loss: 0.0005309720290824771
Test Loss:  0.0006823508301749825
Valid Loss:  0.0007685828022658825
Epoch:  56  	Training Loss: 0.000520291505381465
Test Loss:  0.0006742189871147275
Valid Loss:  0.000750273815356195
Epoch:  57  	Training Loss: 0.0005103411967866123
Test Loss:  0.0006656878395006061
Valid Loss:  0.0007337369024753571
Epoch:  58  	Training Loss: 0.0005009318701922894
Test Loss:  0.0006568633252754807
Valid Loss:  0.0007185449940152466
Epoch:  59  	Training Loss: 0.000491934479214251
Test Loss:  0.0006476945709437132
Valid Loss:  0.0007043108344078064
Epoch:  60  	Training Loss: 0.00048314593732357025
Test Loss:  0.0006383939762599766
Valid Loss:  0.0006908034556545317
Epoch:  61  	Training Loss: 0.0004746592603623867
Test Loss:  0.0006289553130045533
Valid Loss:  0.0006779776304028928
Epoch:  62  	Training Loss: 0.00046634412137791514
Test Loss:  0.0006209211423993111
Valid Loss:  0.0006726956926286221
Epoch:  63  	Training Loss: 0.0004609781317412853
Test Loss:  0.0006135759176686406
Valid Loss:  0.0006669182330369949
Epoch:  64  	Training Loss: 0.0004561726818792522
Test Loss:  0.0006066740024834871
Valid Loss:  0.0006607811665162444
Epoch:  65  	Training Loss: 0.0004516604240052402
Test Loss:  0.0006001385627314448
Valid Loss:  0.0006544087082147598
Epoch:  66  	Training Loss: 0.0004473059088923037
Test Loss:  0.0005938358954153955
Valid Loss:  0.0006478705909103155
Epoch:  67  	Training Loss: 0.0004430011613294482
Test Loss:  0.0005877153016626835
Valid Loss:  0.000641247839666903
Epoch:  68  	Training Loss: 0.0004387543012853712
Test Loss:  0.0005817875498905778
Valid Loss:  0.0006346136797219515
Epoch:  69  	Training Loss: 0.00043458296568132937
Test Loss:  0.0005759830237366259
Valid Loss:  0.0006279635708779097
 14%|█▍        | 71/500 [01:01<08:33,  1.20s/it] 15%|█▍        | 73/500 [01:01<06:07,  1.16it/s] 15%|█▌        | 75/500 [01:01<04:24,  1.61it/s] 15%|█▌        | 77/500 [01:01<03:12,  2.20it/s] 16%|█▌        | 79/500 [01:01<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:08<08:23,  1.20s/it] 16%|█▋        | 82/500 [01:08<07:02,  1.01s/it] 17%|█▋        | 84/500 [01:08<04:51,  1.43it/s] 17%|█▋        | 86/500 [01:08<03:27,  1.99it/s] 18%|█▊        | 88/500 [01:08<02:32,  2.70it/s] 18%|█▊        | 90/500 [01:08<01:55,  3.56it/s] 18%|█▊        | 92/500 [01:15<08:02,  1.18s/it] 19%|█▉        | 94/500 [01:15<05:41,  1.19it/s] 19%|█▉        | 96/500 [01:15<04:04,  1.65it/s] 20%|█▉        | 98/500 [01:15<02:57,  2.26it/s] 20%|██        | 100/500 [01:15<02:11,  3.03it/s] 20%|██        | 102/500 [01:22<07:46,  1.17s/it] 21%|██        | 104/500 [01:22<05:32,  1.19it/s] 21%|██        | 106/500 [01:22<03:59,  1.65it/s] 22%|██▏       | 108/500 [01:22<02:54,  2.24it/s] 22%|██▏       | 110/500 [01:22<02:09,  3.00it/s] 22%|██▏       | 112/500 [01:29<07:44,  1.20s/it] 23%|██▎       | 114/500 [01:29<05:31,  1.17it/s] 23%|██▎       | 116/500 [01:29<03:58,  1.61it/s] 24%|██▎       | 118/500 [01:29<02:53,  2.20it/s] 24%|██▍       | 120/500 [01:29<02:08,  2.97it/s] 24%|██▍       | 122/500 [01:35<07:30,  1.19s/it] 25%|██▍       | 124/500 [01:36<05:21,  1.17it/s] 25%|██▌       | 126/500 [01:36<03:50,  1.62it/s] 26%|██▌       | 128/500 [01:36<02:48,  2.21it/s] 26%|██▌       | 130/500 [01:36<02:04,  2.97it/s] 26%|██▋       | 132/500 [01:43<07:27,  1.22s/it] 27%|██▋       | 134/500 [01:43<05:19,  1.15it/s] 27%|██▋       | 136/500 [01:43<03:49,  1.59it/s]Epoch:  70  	Training Loss: 0.00043048139195889235
Test Loss:  0.0005703154020011425
Valid Loss:  0.0006213391898199916
Epoch:  71  	Training Loss: 0.0004264374729245901
Test Loss:  0.000564725894946605
Valid Loss:  0.0006147632957436144
Epoch:  72  	Training Loss: 0.0004224415170028806
Test Loss:  0.0005305298836901784
Valid Loss:  0.0006149117834866047
Epoch:  73  	Training Loss: 0.0004129015433136374
Test Loss:  0.0005249102832749486
Valid Loss:  0.0005881441757082939
Epoch:  74  	Training Loss: 0.0004007153620477766
Test Loss:  0.0005043258424848318
Valid Loss:  0.0005924726137891412
Epoch:  75  	Training Loss: 0.0003960143949370831
Test Loss:  0.0005009646411053836
Valid Loss:  0.0005692854756489396
Epoch:  76  	Training Loss: 0.00038592127384617925
Test Loss:  0.00048024579882621765
Valid Loss:  0.0005767177208326757
Epoch:  77  	Training Loss: 0.0003823571023531258
Test Loss:  0.0004770166124217212
Valid Loss:  0.0005508830072358251
Epoch:  78  	Training Loss: 0.0003714216290973127
Test Loss:  0.0004589277086779475
Valid Loss:  0.0005567138432525098
Epoch:  79  	Training Loss: 0.0003680371737573296
Test Loss:  0.0004578234220389277
Valid Loss:  0.0005344727542251348
Epoch:  80  	Training Loss: 0.0003589704865589738
Test Loss:  0.00043923078919760883
Valid Loss:  0.0005395314074121416
Epoch:  81  	Training Loss: 0.00035528535954654217
Test Loss:  0.0004393726121634245
Valid Loss:  0.0005185687332414091
Epoch:  82  	Training Loss: 0.00034697394585236907
Test Loss:  0.00044198863906785846
Valid Loss:  0.0005059008835814893
Epoch:  83  	Training Loss: 0.00034212530590593815
Test Loss:  0.00044255360262468457
Valid Loss:  0.0004979384830221534
Epoch:  84  	Training Loss: 0.00033840120886452496
Test Loss:  0.0004423712962307036
Valid Loss:  0.0004918567719869316
Epoch:  85  	Training Loss: 0.00033524478203617036
Test Loss:  0.0004420224577188492
Valid Loss:  0.00048677611630409956
Epoch:  86  	Training Loss: 0.00033252884168177843
Test Loss:  0.0004416941956151277
Valid Loss:  0.0004823760245926678
Epoch:  87  	Training Loss: 0.00033018365502357483
Test Loss:  0.0004414549912326038
Valid Loss:  0.0004784989869222045
Epoch:  88  	Training Loss: 0.00032815244048833847
Test Loss:  0.0004413010028656572
Valid Loss:  0.00047506351256743073
Epoch:  89  	Training Loss: 0.0003263895050622523
Test Loss:  0.0004411863046698272
Valid Loss:  0.00047202123096212745
Epoch:  90  	Training Loss: 0.0003248603316023946
Test Loss:  0.0004411475092638284
Valid Loss:  0.0004692976945079863
Epoch:  91  	Training Loss: 0.0003235287149436772
Test Loss:  0.00044107629219070077
Valid Loss:  0.0004668857145588845
Epoch:  92  	Training Loss: 0.00032237404957413673
Test Loss:  0.0004273128870408982
Valid Loss:  0.0004633997450582683
Epoch:  93  	Training Loss: 0.0003163350047543645
Test Loss:  0.000416503578890115
Valid Loss:  0.0004594418569467962
Epoch:  94  	Training Loss: 0.0003109550743829459
Test Loss:  0.0004066270194016397
Valid Loss:  0.000455796136520803
Epoch:  95  	Training Loss: 0.0003060643211938441
Test Loss:  0.00039761903462931514
Valid Loss:  0.00045240423060022295
Epoch:  96  	Training Loss: 0.00030161120230332017
Test Loss:  0.00038938294164836407
Valid Loss:  0.00044921081280335784
Epoch:  97  	Training Loss: 0.00029750741668976843
Test Loss:  0.0003818145487457514
Valid Loss:  0.0004461934440769255
Epoch:  98  	Training Loss: 0.0002937047684099525
Test Loss:  0.0003748384187929332
Valid Loss:  0.0004432938003446907
Epoch:  99  	Training Loss: 0.00029014801839366555
Test Loss:  0.0003683917748276144
Valid Loss:  0.00044049188727512956
Epoch:  100  	Training Loss: 0.00028681353433057666
Test Loss:  0.000362386810593307
Valid Loss:  0.00043775609810836613
Epoch:  101  	Training Loss: 0.0002836451749317348
Test Loss:  0.00035678083077073097
Valid Loss:  0.0004350748495198786
Epoch:  102  	Training Loss: 0.0002806534175761044
Test Loss:  0.00035534260678105056
Valid Loss:  0.0004261521389707923
Epoch:  103  	Training Loss: 0.0002766148536466062
Test Loss:  0.00035390249104239047
Valid Loss:  0.00041867754771374166
Epoch:  104  	Training Loss: 0.00027312463498674333
Test Loss:  0.00035244098398834467
Valid Loss:  0.00041226742905564606
Epoch:  105  	Training Loss: 0.0002700552868191153
Test Loss:  0.00035103067057207227
Valid Loss:  0.0004066867695655674
Epoch:  106  	Training Loss: 0.0002673219423741102
Test Loss:  0.0003496161079965532
Valid Loss:  0.0004017705505248159
Epoch:  107  	Training Loss: 0.0002648665104061365
Test Loss:  0.00034821039298549294
Valid Loss:  0.0003973963321186602
Epoch:  108  	Training Loss: 0.0002626456553116441
Test Loss:  0.0003468237118795514
Valid Loss:  0.00039354784530587494
Epoch:  109  	Training Loss: 0.0002606336784083396
Test Loss:  0.00034551258431747556
Valid Loss:  0.0003901032614521682
Epoch:  110  	Training Loss: 0.00025883771013468504
Test Loss:  0.00034422698081471026
Valid Loss:  0.0003869853389915079
Epoch:  111  	Training Loss: 0.0002572063822299242
Test Loss:  0.00034306413726881146
Valid Loss:  0.00038418706390075386
Epoch:  112  	Training Loss: 0.0002557680709287524
Test Loss:  0.0003388809855096042
Valid Loss:  0.00038148683961480856
Epoch:  113  	Training Loss: 0.00025289185578003526
Test Loss:  0.0003334748325869441
Valid Loss:  0.0003803017898462713
Epoch:  114  	Training Loss: 0.0002506806922610849
Test Loss:  0.0003284045378677547
Valid Loss:  0.0003794743097387254
Epoch:  115  	Training Loss: 0.0002487747115083039
Test Loss:  0.0003238130593672395
Valid Loss:  0.0003787943860515952
Epoch:  116  	Training Loss: 0.000247094634687528
Test Loss:  0.0003196665202267468
Valid Loss:  0.00037824211176484823
Epoch:  117  	Training Loss: 0.0002456163929309696
Test Loss:  0.0003159719635732472
Valid Loss:  0.00037780150887556374
Epoch:  118  	Training Loss: 0.0002443140256218612
Test Loss:  0.0003126314841210842
Valid Loss:  0.00037745514418929815
Epoch:  119  	Training Loss: 0.0002431678440188989
Test Loss:  0.0003096076543442905
Valid Loss:  0.00037719320971518755
Epoch:  120  	Training Loss: 0.00024215861049015075
Test Loss:  0.00030690268613398075
Valid Loss:  0.0003770017356146127
Epoch:  121  	Training Loss: 0.00024126745120156556
Test Loss:  0.00030445109587162733
Valid Loss:  0.0003768574388232082
Epoch:  122  	Training Loss: 0.00024047517217695713
Test Loss:  0.00030089536448940635
Valid Loss:  0.00037471408722922206
Epoch:  123  	Training Loss: 0.00023869963479228318
Test Loss:  0.00029802124481648207
Valid Loss:  0.00037205504486337304
Epoch:  124  	Training Loss: 0.00023702005273662508
Test Loss:  0.0002953956718556583
Valid Loss:  0.0003694984479807317
Epoch:  125  	Training Loss: 0.00023541477276012301
Test Loss:  0.0002929221373051405
Valid Loss:  0.00036691129207611084
Epoch:  126  	Training Loss: 0.00023383420193567872
Test Loss:  0.0002905688888859004
Valid Loss:  0.00036443345015868545
Epoch:  127  	Training Loss: 0.00023230002261698246
Test Loss:  0.00028831444797106087
Valid Loss:  0.00036190691753290594
Epoch:  128  	Training Loss: 0.00023079401580616832
Test Loss:  0.0002861316315829754
Valid Loss:  0.00035945302806794643
Epoch:  129  	Training Loss: 0.00022931522107683122
Test Loss:  0.00028401034069247544
Valid Loss:  0.00035699643194675446
Epoch:  130  	Training Loss: 0.00022785815235693008
Test Loss:  0.00028189789736643434
Valid Loss:  0.0003545818035490811
Epoch:  131  	Training Loss: 0.00022642720432486385
Test Loss:  0.0002798353089019656
Valid Loss:  0.0003522461047396064
Epoch:  132  	Training Loss: 0.00022502188221551478
Test Loss:  0.00026508874725550413
Valid Loss:  0.00034411827800795436
Epoch:  133  	Training Loss: 0.00021793897030875087
Test Loss:  0.0002685105428099632
Valid Loss:  0.0003348480095155537
Epoch:  134  	Training Loss: 0.00021489894425030798
Test Loss:  0.0002556040999479592
Valid Loss:  0.00033670745324343443
Epoch:  135  	Training Loss: 0.00021287405979819596
Test Loss:  0.0002629340160638094
Valid Loss:  0.00032315897988155484
Epoch:  136  	Training Loss: 0.0002086446329485625
Test Loss:  0.0002530548954382539
Valid Loss:  0.0003229448921047151
Epoch:  137  	Training Loss: 0.00020576026872731745
Test Loss:  0.0002536142128519714
Valid Loss:   28%|██▊       | 138/500 [01:43<02:47,  2.16it/s] 28%|██▊       | 140/500 [01:43<02:04,  2.89it/s] 28%|██▊       | 142/500 [01:50<07:13,  1.21s/it] 29%|██▉       | 144/500 [01:50<05:08,  1.15it/s] 29%|██▉       | 146/500 [01:50<03:42,  1.59it/s] 30%|██▉       | 148/500 [01:50<02:41,  2.18it/s] 30%|███       | 150/500 [01:50<01:59,  2.93it/s] 30%|███       | 152/500 [01:56<06:55,  1.19s/it] 31%|███       | 154/500 [01:57<04:55,  1.17it/s] 31%|███       | 156/500 [01:57<03:32,  1.62it/s] 32%|███▏      | 158/500 [01:57<02:34,  2.21it/s] 32%|███▏      | 160/500 [01:57<01:54,  2.97it/s] 32%|███▏      | 162/500 [02:03<06:45,  1.20s/it] 33%|███▎      | 164/500 [02:04<04:48,  1.16it/s] 33%|███▎      | 166/500 [02:04<03:27,  1.61it/s] 34%|███▎      | 168/500 [02:04<02:30,  2.20it/s] 34%|███▍      | 170/500 [02:04<01:51,  2.96it/s] 34%|███▍      | 172/500 [02:10<06:36,  1.21s/it] 35%|███▍      | 174/500 [02:11<04:42,  1.16it/s] 35%|███▌      | 176/500 [02:11<03:23,  1.59it/s] 36%|███▌      | 178/500 [02:11<02:30,  2.15it/s] 36%|███▌      | 180/500 [02:11<01:52,  2.84it/s] 36%|███▋      | 182/500 [02:17<06:22,  1.20s/it] 37%|███▋      | 184/500 [02:18<04:32,  1.16it/s] 37%|███▋      | 186/500 [02:18<03:15,  1.60it/s] 38%|███▊      | 188/500 [02:18<02:22,  2.19it/s] 38%|███▊      | 190/500 [02:18<01:44,  2.95it/s] 38%|███▊      | 192/500 [02:24<06:05,  1.19s/it] 39%|███▉      | 194/500 [02:24<04:20,  1.18it/s] 39%|███▉      | 196/500 [02:25<03:06,  1.63it/s] 40%|███▉      | 198/500 [02:25<02:16,  2.22it/s] 40%|████      | 200/500 [02:25<01:40,  2.99it/s] 40%|████      | 202/500 [02:31<05:51,  1.18s/it]0.0003168467665091157
Epoch:  138  	Training Loss: 0.00020331770065240562
Test Loss:  0.0002489644684828818
Valid Loss:  0.0003144842921756208
Epoch:  139  	Training Loss: 0.00020107440650463104
Test Loss:  0.0002471903571859002
Valid Loss:  0.00031057445448823273
Epoch:  140  	Training Loss: 0.0001989754819078371
Test Loss:  0.00024409218167420477
Valid Loss:  0.00030772906029596925
Epoch:  141  	Training Loss: 0.00019701274868566543
Test Loss:  0.00024172328994609416
Valid Loss:  0.00030463666189461946
Epoch:  142  	Training Loss: 0.00019513053121045232
Test Loss:  0.00023057230282574892
Valid Loss:  0.00030445732409134507
Epoch:  143  	Training Loss: 0.0001930783619172871
Test Loss:  0.00023371468705590814
Valid Loss:  0.0002968023472931236
Epoch:  144  	Training Loss: 0.00019025421352125704
Test Loss:  0.00023033801699057221
Valid Loss:  0.00029732019174844027
Epoch:  145  	Training Loss: 0.00019000393513124436
Test Loss:  0.0002334589953534305
Valid Loss:  0.0002931867493316531
Epoch:  146  	Training Loss: 0.0001886337558971718
Test Loss:  0.00022925187658984214
Valid Loss:  0.00029363558860495687
Epoch:  147  	Training Loss: 0.00018822329002432525
Test Loss:  0.00023214600514620543
Valid Loss:  0.00028974656015634537
Epoch:  148  	Training Loss: 0.00018690444994717836
Test Loss:  0.00022807877394370735
Valid Loss:  0.000291087431833148
Epoch:  149  	Training Loss: 0.00018690255819819868
Test Loss:  0.00023075260105542839
Valid Loss:  0.0002866354479920119
Epoch:  150  	Training Loss: 0.0001853133289841935
Test Loss:  0.0002290201955474913
Valid Loss:  0.00028597278287634254
Epoch:  151  	Training Loss: 0.00018489545618649572
Test Loss:  0.00023129614419303834
Valid Loss:  0.0002848214062396437
Epoch:  152  	Training Loss: 0.00018459296552464366
Test Loss:  0.00023042346583679318
Valid Loss:  0.0002812726888805628
Epoch:  153  	Training Loss: 0.0001827717205742374
Test Loss:  0.00022835972777102143
Valid Loss:  0.00027865477022714913
Epoch:  154  	Training Loss: 0.00018129474483430386
Test Loss:  0.00022624703706242144
Valid Loss:  0.00027643539942801
Epoch:  155  	Training Loss: 0.0001800190075300634
Test Loss:  0.00022461690241470933
Valid Loss:  0.000274305057246238
Epoch:  156  	Training Loss: 0.0001788405206752941
Test Loss:  0.00022261592675931752
Valid Loss:  0.00027227430837228894
Epoch:  157  	Training Loss: 0.0001776219141902402
Test Loss:  0.00022114752209745347
Valid Loss:  0.00027030560886487365
Epoch:  158  	Training Loss: 0.00017651189409662038
Test Loss:  0.00021944309992250055
Valid Loss:  0.00026856415206566453
Epoch:  159  	Training Loss: 0.00017548717733006924
Test Loss:  0.0002183775941375643
Valid Loss:  0.0002668170491233468
Epoch:  160  	Training Loss: 0.00017452782776672393
Test Loss:  0.00021690323774237186
Valid Loss:  0.0002652847906574607
Epoch:  161  	Training Loss: 0.00017366297834087163
Test Loss:  0.00021603151981253177
Valid Loss:  0.00026372657157480717
Epoch:  162  	Training Loss: 0.00017284021305385977
Test Loss:  0.00021029042545706034
Valid Loss:  0.00026179084670729935
Epoch:  163  	Training Loss: 0.00017088931053876877
Test Loss:  0.00020663882605731487
Valid Loss:  0.000259721971815452
Epoch:  164  	Training Loss: 0.00016918720211833715
Test Loss:  0.00020254131231922656
Valid Loss:  0.0002580345026217401
Epoch:  165  	Training Loss: 0.0001676445681368932
Test Loss:  0.00019918728503398597
Valid Loss:  0.00025633437326177955
Epoch:  166  	Training Loss: 0.00016624166164547205
Test Loss:  0.00019590265583246946
Valid Loss:  0.00025478744646534324
Epoch:  167  	Training Loss: 0.00016495032468810678
Test Loss:  0.0001929741119965911
Valid Loss:  0.00025329808704555035
Epoch:  168  	Training Loss: 0.00016376034182030708
Test Loss:  0.00019021049956791103
Valid Loss:  0.0002519011322874576
Epoch:  169  	Training Loss: 0.00016265016165561974
Test Loss:  0.00018767792789731175
Valid Loss:  0.0002505222801119089
Epoch:  170  	Training Loss: 0.00016159587539732456
Test Loss:  0.00018526572966948152
Valid Loss:  0.00024919508723542094
Epoch:  171  	Training Loss: 0.00016059097833931446
Test Loss:  0.00018300874216947705
Valid Loss:  0.0002478951937519014
Epoch:  172  	Training Loss: 0.0001596306829014793
Test Loss:  0.00018183793872594833
Valid Loss:  0.00024715502513572574
Epoch:  173  	Training Loss: 0.00015885374159552157
Test Loss:  0.00018053309759125113
Valid Loss:  0.0002467067679390311
Epoch:  174  	Training Loss: 0.00015824333240743726
Test Loss:  0.00017924379790201783
Valid Loss:  0.0002463807468302548
Epoch:  175  	Training Loss: 0.00015770649770274758
Test Loss:  0.0001780442107701674
Valid Loss:  0.00024613182176835835
Epoch:  176  	Training Loss: 0.0001572375767864287
Test Loss:  0.0001769351656548679
Valid Loss:  0.0002459102834109217
Epoch:  177  	Training Loss: 0.00015681586228311062
Test Loss:  0.00017589781782589853
Valid Loss:  0.0002457008231431246
Epoch:  178  	Training Loss: 0.00015642974176444113
Test Loss:  0.00017495366046205163
Valid Loss:  0.0002455395879223943
Epoch:  179  	Training Loss: 0.00015609493129886687
Test Loss:  0.00017408700659871101
Valid Loss:  0.00024539732839912176
Epoch:  180  	Training Loss: 0.00015579513274133205
Test Loss:  0.00017331990238744766
Valid Loss:  0.000245269708102569
Epoch:  181  	Training Loss: 0.00015552769764326513
Test Loss:  0.00017261411994695663
Valid Loss:  0.00024513734388165176
Epoch:  182  	Training Loss: 0.00015527341747656465
Test Loss:  0.00017210000078193843
Valid Loss:  0.00024373916676267982
Epoch:  183  	Training Loss: 0.00015453029482159764
Test Loss:  0.00017135443340521306
Valid Loss:  0.00024264617240987718
Epoch:  184  	Training Loss: 0.00015381272532977164
Test Loss:  0.00017062833649106324
Valid Loss:  0.00024153466802090406
Epoch:  185  	Training Loss: 0.00015311212337110192
Test Loss:  0.0001698674459476024
Valid Loss:  0.0002404721744824201
Epoch:  186  	Training Loss: 0.00015242739755194634
Test Loss:  0.00016908935504034162
Valid Loss:  0.0002394387120148167
Epoch:  187  	Training Loss: 0.00015175991575233638
Test Loss:  0.00016830972163006663
Valid Loss:  0.00023843947565183043
Epoch:  188  	Training Loss: 0.00015111139509826899
Test Loss:  0.00016753174713812768
Valid Loss:  0.00023745771613903344
Epoch:  189  	Training Loss: 0.00015047784836497158
Test Loss:  0.00016676497762091458
Valid Loss:  0.00023650721414014697
Epoch:  190  	Training Loss: 0.00014986138558015227
Test Loss:  0.00016599849914200604
Valid Loss:  0.00023557033273391426
Epoch:  191  	Training Loss: 0.00014925561845302582
Test Loss:  0.00016523301019333303
Valid Loss:  0.0002346542023587972
Epoch:  192  	Training Loss: 0.00014866185665596277
Test Loss:  0.00016444086213596165
Valid Loss:  0.00023401129874400795
Epoch:  193  	Training Loss: 0.00014813106099609286
Test Loss:  0.00016368931392207742
Valid Loss:  0.00023338562459684908
Epoch:  194  	Training Loss: 0.0001476132165407762
Test Loss:  0.00016294934903271496
Valid Loss:  0.0002327637339476496
Epoch:  195  	Training Loss: 0.0001470956194680184
Test Loss:  0.000162220821948722
Valid Loss:  0.0002321497886441648
Epoch:  196  	Training Loss: 0.00014658745203632861
Test Loss:  0.00016152707394212484
Valid Loss:  0.0002315578458365053
Epoch:  197  	Training Loss: 0.00014609971549361944
Test Loss:  0.0001608443126315251
Valid Loss:  0.0002309640112798661
Epoch:  198  	Training Loss: 0.00014560161798726767
Test Loss:  0.00016016914742067456
Valid Loss:  0.0002303717628819868
Epoch:  199  	Training Loss: 0.00014510424807667732
Test Loss:  0.0001595021312823519
Valid Loss:  0.000229784898692742
Epoch:  200  	Training Loss: 0.00014460357488133013
Test Loss:  0.00015884167805779725
Valid Loss:  0.0002292032731929794
Epoch:  201  	Training Loss: 0.00014410560834221542
Test Loss:  0.00015818935935385525
Valid Loss:  0.0002286387316416949
Epoch:  202  	Training Loss: 0.0001436110760550946
Test Loss:  0.00015839654952287674
Valid Loss:  0.00022665690630674362
Epoch:  203  	Training Loss: 0.00014284552889876068
Test Loss:  0.00015853732475079596
Valid Loss:  0.00022516741591971368
Epoch:  204  	Training Loss: 0.00014225870836526155
Test Loss:  0.00015858071856200695
Valid Loss:   41%|████      | 204/500 [02:31<04:10,  1.18it/s] 41%|████      | 206/500 [02:31<02:59,  1.64it/s] 42%|████▏     | 208/500 [02:31<02:10,  2.23it/s] 42%|████▏     | 210/500 [02:32<01:36,  2.99it/s] 42%|████▏     | 212/500 [02:38<05:48,  1.21s/it] 43%|████▎     | 214/500 [02:38<04:08,  1.15it/s] 43%|████▎     | 216/500 [02:38<02:58,  1.59it/s] 44%|████▎     | 218/500 [02:39<02:09,  2.18it/s] 44%|████▍     | 220/500 [02:39<01:35,  2.93it/s] 44%|████▍     | 222/500 [02:45<05:30,  1.19s/it] 45%|████▍     | 224/500 [02:45<03:55,  1.17it/s] 45%|████▌     | 226/500 [02:45<02:49,  1.62it/s] 46%|████▌     | 228/500 [02:45<02:02,  2.21it/s] 46%|████▌     | 230/500 [02:46<01:30,  2.98it/s] 46%|████▋     | 232/500 [02:52<05:23,  1.21s/it] 47%|████▋     | 234/500 [02:52<03:49,  1.16it/s] 47%|████▋     | 236/500 [02:52<02:44,  1.60it/s] 48%|████▊     | 238/500 [02:52<02:00,  2.18it/s] 48%|████▊     | 240/500 [02:53<01:28,  2.93it/s] 48%|████▊     | 242/500 [02:59<05:15,  1.22s/it] 49%|████▉     | 244/500 [02:59<03:44,  1.14it/s] 49%|████▉     | 246/500 [02:59<02:41,  1.58it/s] 50%|████▉     | 248/500 [03:00<01:57,  2.15it/s] 50%|█████     | 250/500 [03:00<01:26,  2.89it/s] 50%|█████     | 252/500 [03:06<05:08,  1.24s/it] 51%|█████     | 254/500 [03:06<03:39,  1.12it/s] 51%|█████     | 256/500 [03:07<02:36,  1.56it/s] 52%|█████▏    | 258/500 [03:07<01:54,  2.12it/s] 52%|█████▏    | 260/500 [03:07<01:25,  2.81it/s] 52%|█████▏    | 262/500 [03:14<04:57,  1.25s/it] 53%|█████▎    | 264/500 [03:14<03:32,  1.11it/s] 53%|█████▎    | 266/500 [03:14<02:33,  1.52it/s] 54%|█████▎    | 268/500 [03:14<01:52,  2.06it/s] 54%|█████▍    | 270/500 [03:14<01:23,  2.74it/s]0.00022397219436243176
Epoch:  205  	Training Loss: 0.0001417659514117986
Test Loss:  0.00015853381773922592
Valid Loss:  0.00022296981478575617
Epoch:  206  	Training Loss: 0.00014133260992821306
Test Loss:  0.00015840705600567162
Valid Loss:  0.0002221014874521643
Epoch:  207  	Training Loss: 0.00014093666686676443
Test Loss:  0.0001582111872266978
Valid Loss:  0.00022133157472126186
Epoch:  208  	Training Loss: 0.00014056764484848827
Test Loss:  0.0001579566451255232
Valid Loss:  0.0002206323406426236
Epoch:  209  	Training Loss: 0.00014021812239661813
Test Loss:  0.00015765256830491126
Valid Loss:  0.00021998774900566787
Epoch:  210  	Training Loss: 0.00013988498540129513
Test Loss:  0.0001573115005157888
Valid Loss:  0.00021938470308668911
Epoch:  211  	Training Loss: 0.0001395666622556746
Test Loss:  0.0001569383020978421
Valid Loss:  0.00021881391876377165
Epoch:  212  	Training Loss: 0.00013925913663115352
Test Loss:  0.0001537942880531773
Valid Loss:  0.00021862509311176836
Epoch:  213  	Training Loss: 0.00013847672380506992
Test Loss:  0.00015279620129149407
Valid Loss:  0.00021820588153786957
Epoch:  214  	Training Loss: 0.00013813738769385964
Test Loss:  0.00015170151891652495
Valid Loss:  0.00021788149024359882
Epoch:  215  	Training Loss: 0.00013782994938082993
Test Loss:  0.00015069938672240824
Valid Loss:  0.0002175744011765346
Epoch:  216  	Training Loss: 0.00013754761312156916
Test Loss:  0.00014976333477534354
Valid Loss:  0.00021728756837546825
Epoch:  217  	Training Loss: 0.00013728663907386363
Test Loss:  0.0001488872803747654
Valid Loss:  0.0002170162770198658
Epoch:  218  	Training Loss: 0.00013704298180527985
Test Loss:  0.00014806477702222764
Valid Loss:  0.0002167586935684085
Epoch:  219  	Training Loss: 0.00013681492418982089
Test Loss:  0.00014729241956956685
Valid Loss:  0.00021651462884619832
Epoch:  220  	Training Loss: 0.00013660170952789485
Test Loss:  0.00014656537678092718
Valid Loss:  0.0002162806922569871
Epoch:  221  	Training Loss: 0.00013640057295560837
Test Loss:  0.00014587881742045283
Valid Loss:  0.0002160558069590479
Epoch:  222  	Training Loss: 0.0001362096081720665
Test Loss:  0.0001435991725884378
Valid Loss:  0.00021307621500454843
Epoch:  223  	Training Loss: 0.0001343641197308898
Test Loss:  0.0001402108755428344
Valid Loss:  0.00020904536359012127
Epoch:  224  	Training Loss: 0.0001320286828558892
Test Loss:  0.00013594779011327773
Valid Loss:  0.0002041966945398599
Epoch:  225  	Training Loss: 0.00012919330038130283
Test Loss:  0.000134347501443699
Valid Loss:  0.0002022060944000259
Epoch:  226  	Training Loss: 0.00012813425564672798
Test Loss:  0.0001347570214420557
Valid Loss:  0.00020047291764058173
Epoch:  227  	Training Loss: 0.0001272286899620667
Test Loss:  0.00013374723494052887
Valid Loss:  0.00019969943969044834
Epoch:  228  	Training Loss: 0.0001266093022422865
Test Loss:  0.00013391455286182463
Valid Loss:  0.00019866344518959522
Epoch:  229  	Training Loss: 0.00012594999861903489
Test Loss:  0.00013264038716442883
Valid Loss:  0.0001980510714929551
Epoch:  230  	Training Loss: 0.00012541364412754774
Test Loss:  0.00013275719538796693
Valid Loss:  0.00019670405890792608
Epoch:  231  	Training Loss: 0.0001246899482794106
Test Loss:  0.00013190822210162878
Valid Loss:  0.00019599770894274116
Epoch:  232  	Training Loss: 0.00012411964416969568
Test Loss:  0.00013153375766705722
Valid Loss:  0.00019517300825100392
Epoch:  233  	Training Loss: 0.00012367372983135283
Test Loss:  0.00013105793914292008
Valid Loss:  0.0001944224932231009
Epoch:  234  	Training Loss: 0.0001232439244631678
Test Loss:  0.00013061192294117063
Valid Loss:  0.00019367909408174455
Epoch:  235  	Training Loss: 0.00012282695388421416
Test Loss:  0.00013010889233555645
Valid Loss:  0.00019298077677376568
Epoch:  236  	Training Loss: 0.0001224219740834087
Test Loss:  0.0001296181872021407
Valid Loss:  0.0001922952214954421
Epoch:  237  	Training Loss: 0.00012202738435007632
Test Loss:  0.00012910057557746768
Valid Loss:  0.00019163725664839149
Epoch:  238  	Training Loss: 0.00012164199870312586
Test Loss:  0.00012859085109084845
Valid Loss:  0.00019099126802757382
Epoch:  239  	Training Loss: 0.00012126468209316954
Test Loss:  0.0001280665455851704
Valid Loss:  0.00019036588491871953
Epoch:  240  	Training Loss: 0.00012089517258573323
Test Loss:  0.0001275505346711725
Valid Loss:  0.0001897509500849992
Epoch:  241  	Training Loss: 0.00012053261161781847
Test Loss:  0.0001270292850676924
Valid Loss:  0.00018915164400823414
Epoch:  242  	Training Loss: 0.00012017723929602653
Test Loss:  0.0001268399355467409
Valid Loss:  0.00018848451145458966
Epoch:  243  	Training Loss: 0.00011977869144175202
Test Loss:  0.00012605887604877353
Valid Loss:  0.00018793693743646145
Epoch:  244  	Training Loss: 0.00011940539843635634
Test Loss:  0.00012581238115672022
Valid Loss:  0.0001872812572401017
Epoch:  245  	Training Loss: 0.00011902430560439825
Test Loss:  0.00012507749488577247
Valid Loss:  0.00018676635227166116
Epoch:  246  	Training Loss: 0.00011866838030982763
Test Loss:  0.00012479725410230458
Valid Loss:  0.00018633747822605073
Epoch:  247  	Training Loss: 0.00011834305769298226
Test Loss:  0.00012401817366480827
Valid Loss:  0.00018595372966956347
Epoch:  248  	Training Loss: 0.00011802291555795819
Test Loss:  0.00012386735761538148
Valid Loss:  0.0001854139700299129
Epoch:  249  	Training Loss: 0.00011768914555432275
Test Loss:  0.00012322154361754656
Valid Loss:  0.00018512850510887802
Epoch:  250  	Training Loss: 0.0001173868149635382
Test Loss:  0.00012303533731028438
Valid Loss:  0.00018465150787960738
Epoch:  251  	Training Loss: 0.00011706910299835727
Test Loss:  0.00012252922169864178
Valid Loss:  0.0001843256177380681
Epoch:  252  	Training Loss: 0.00011676517897285521
Test Loss:  0.00012152131967013702
Valid Loss:  0.00018330464081373066
Epoch:  253  	Training Loss: 0.00011631600500550121
Test Loss:  0.0001209045440191403
Valid Loss:  0.00018294487381353974
Epoch:  254  	Training Loss: 0.00011608000204432756
Test Loss:  0.00012027306365780532
Valid Loss:  0.00018254021415486932
Epoch:  255  	Training Loss: 0.00011583838204387575
Test Loss:  0.00011974079097853974
Valid Loss:  0.000182229996426031
Epoch:  256  	Training Loss: 0.00011563902080524713
Test Loss:  0.00011918851669179276
Valid Loss:  0.00018187938258051872
Epoch:  257  	Training Loss: 0.0001154225756181404
Test Loss:  0.00011872810136992484
Valid Loss:  0.0001815704454202205
Epoch:  258  	Training Loss: 0.00011524806905072182
Test Loss:  0.00011832157906610519
Valid Loss:  0.00018124087364412844
Epoch:  259  	Training Loss: 0.00011509577598189935
Test Loss:  0.00011788158735726029
Valid Loss:  0.0001808387169148773
Epoch:  260  	Training Loss: 0.00011492524936329573
Test Loss:  0.00011752000136766583
Valid Loss:  0.00018053049279842526
Epoch:  261  	Training Loss: 0.00011478527449071407
Test Loss:  0.0001171978801721707
Valid Loss:  0.00018026138423010707
Epoch:  262  	Training Loss: 0.00011466703290352598
Test Loss:  0.00011708975944202393
Valid Loss:  0.00017898614169098437
Epoch:  263  	Training Loss: 0.00011377871851436794
Test Loss:  0.00011707685189321637
Valid Loss:  0.00017823073721956462
Epoch:  264  	Training Loss: 0.00011318540055071935
Test Loss:  0.00011697899753926322
Valid Loss:  0.00017762475181370974
Epoch:  265  	Training Loss: 0.00011268183880019933
Test Loss:  0.000116838637040928
Valid Loss:  0.000177093839738518
Epoch:  266  	Training Loss: 0.00011222472676308826
Test Loss:  0.00011661099415505305
Valid Loss:  0.00017658344586379826
Epoch:  267  	Training Loss: 0.00011180764704477042
Test Loss:  0.00011634785187197849
Valid Loss:  0.00017610490613151342
Epoch:  268  	Training Loss: 0.00011141577851958573
Test Loss:  0.00011602514132391661
Valid Loss:  0.00017563445726409554
Epoch:  269  	Training Loss: 0.00011103828728664666
Test Loss:  0.00011569381604203954
Valid Loss:  0.00017516908701509237
Epoch:  270  	Training Loss: 0.00011066949809901416
Test Loss:  0.00011534274381119758
Valid Loss:  0.00017471396131440997
Epoch:  271  	Training Loss: 0.00011031042959075421
Test Loss:  0.00011496779188746586
Valid Loss:   54%|█████▍    | 272/500 [03:21<04:39,  1.23s/it] 55%|█████▍    | 274/500 [03:21<03:18,  1.14it/s] 55%|█████▌    | 276/500 [03:21<02:22,  1.57it/s] 56%|█████▌    | 278/500 [03:21<01:43,  2.15it/s] 56%|█████▌    | 280/500 [03:21<01:15,  2.90it/s] 56%|█████▋    | 282/500 [03:28<04:29,  1.24s/it] 57%|█████▋    | 284/500 [03:28<03:11,  1.13it/s] 57%|█████▋    | 286/500 [03:28<02:16,  1.56it/s] 58%|█████▊    | 288/500 [03:28<01:39,  2.14it/s] 58%|█████▊    | 290/500 [03:28<01:12,  2.89it/s] 58%|█████▊    | 292/500 [03:35<04:13,  1.22s/it] 59%|█████▉    | 294/500 [03:35<02:59,  1.15it/s] 59%|█████▉    | 296/500 [03:35<02:08,  1.59it/s] 60%|█████▉    | 298/500 [03:35<01:32,  2.17it/s] 60%|██████    | 300/500 [03:35<01:08,  2.93it/s] 60%|██████    | 302/500 [03:42<03:56,  1.20s/it] 61%|██████    | 304/500 [03:42<02:48,  1.16it/s] 61%|██████    | 306/500 [03:42<02:00,  1.61it/s] 62%|██████▏   | 308/500 [03:42<01:27,  2.20it/s] 62%|██████▏   | 310/500 [03:42<01:04,  2.96it/s] 62%|██████▏   | 312/500 [03:49<03:41,  1.18s/it] 63%|██████▎   | 314/500 [03:49<02:37,  1.18it/s] 63%|██████▎   | 316/500 [03:49<01:52,  1.63it/s] 64%|██████▎   | 318/500 [03:49<01:21,  2.23it/s] 64%|██████▍   | 320/500 [03:49<01:00,  3.00it/s] 64%|██████▍   | 322/500 [03:56<03:31,  1.19s/it] 65%|██████▍   | 324/500 [03:56<02:29,  1.18it/s] 65%|██████▌   | 326/500 [03:56<01:48,  1.61it/s] 66%|██████▌   | 328/500 [03:56<01:18,  2.19it/s] 66%|██████▌   | 330/500 [03:56<00:57,  2.94it/s] 66%|██████▋   | 332/500 [04:03<03:20,  1.20s/it] 67%|██████▋   | 334/500 [04:03<02:22,  1.17it/s] 67%|██████▋   | 336/500 [04:09<04:14,  1.55s/it]0.00017427295097149909
Epoch:  272  	Training Loss: 0.00010996212222380564
Test Loss:  0.00011492508201627061
Valid Loss:  0.0001739035069476813
Epoch:  273  	Training Loss: 0.00010976604244206101
Test Loss:  0.00011479083332233131
Valid Loss:  0.0001736438280204311
Epoch:  274  	Training Loss: 0.00010960433428408578
Test Loss:  0.00011460066889412701
Valid Loss:  0.00017344938532914966
Epoch:  275  	Training Loss: 0.0001094529579859227
Test Loss:  0.00011438603542046621
Valid Loss:  0.0001732734526740387
Epoch:  276  	Training Loss: 0.00010930540156550705
Test Loss:  0.00011415088374633342
Valid Loss:  0.00017311153351329267
Epoch:  277  	Training Loss: 0.00010916054452536628
Test Loss:  0.00011393131717341021
Valid Loss:  0.00017295015277341008
Epoch:  278  	Training Loss: 0.00010901731002377346
Test Loss:  0.00011371752771083266
Valid Loss:  0.0001727886265143752
Epoch:  279  	Training Loss: 0.00010887587268371135
Test Loss:  0.00011349989654263481
Valid Loss:  0.0001726316986605525
Epoch:  280  	Training Loss: 0.00010873774590436369
Test Loss:  0.00011329367407597601
Valid Loss:  0.00017249527445528656
Epoch:  281  	Training Loss: 0.00010860709880944341
Test Loss:  0.00011310515401419252
Valid Loss:  0.00017235861741937697
Epoch:  282  	Training Loss: 0.00010848316742340103
Test Loss:  0.00011246117355767637
Valid Loss:  0.00017210122314281762
Epoch:  283  	Training Loss: 0.00010820930037880316
Test Loss:  0.00011190139048267156
Valid Loss:  0.00017189621576108038
Epoch:  284  	Training Loss: 0.00010797956929309294
Test Loss:  0.00011139331036247313
Valid Loss:  0.00017170693899970502
Epoch:  285  	Training Loss: 0.00010777010174933821
Test Loss:  0.00011092289059888572
Valid Loss:  0.0001715275866445154
Epoch:  286  	Training Loss: 0.00010757138079497963
Test Loss:  0.0001104861221392639
Valid Loss:  0.00017135603411588818
Epoch:  287  	Training Loss: 0.00010738438868429512
Test Loss:  0.00011008116416633129
Valid Loss:  0.0001711937802610919
Epoch:  288  	Training Loss: 0.0001072094528353773
Test Loss:  0.00010969862341880798
Valid Loss:  0.000171036139363423
Epoch:  289  	Training Loss: 0.00010704256419558078
Test Loss:  0.00010933569865301251
Valid Loss:  0.00017088302411139011
Epoch:  290  	Training Loss: 0.00010688217298593372
Test Loss:  0.0001089907600544393
Valid Loss:  0.00017073359049391001
Epoch:  291  	Training Loss: 0.00010672776988940313
Test Loss:  0.00010866607772186399
Valid Loss:  0.00017058724188245833
Epoch:  292  	Training Loss: 0.00010658051178324968
Test Loss:  0.00010851514525711536
Valid Loss:  0.00017029113951139152
Epoch:  293  	Training Loss: 0.00010636066144797951
Test Loss:  0.00010849323734873906
Valid Loss:  0.00017000499065034091
Epoch:  294  	Training Loss: 0.00010619039676385
Test Loss:  0.00010851919068954885
Valid Loss:  0.00016974416212178767
Epoch:  295  	Training Loss: 0.00010605043644318357
Test Loss:  0.00010856264998437837
Valid Loss:  0.00016951296129263937
Epoch:  296  	Training Loss: 0.00010593255865387619
Test Loss:  0.00010860987822525203
Valid Loss:  0.00016930929268710315
Epoch:  297  	Training Loss: 0.00010583251423668116
Test Loss:  0.00010865538206417114
Valid Loss:  0.00016912983846850693
Epoch:  298  	Training Loss: 0.00010574651969363913
Test Loss:  0.00010869719699257985
Valid Loss:  0.0001689708442427218
Epoch:  299  	Training Loss: 0.00010567178105702624
Test Loss:  0.00010873334395000711
Valid Loss:  0.00016882919589988887
Epoch:  300  	Training Loss: 0.00010560594091657549
Test Loss:  0.00010876415035454556
Valid Loss:  0.00016870119725354016
Epoch:  301  	Training Loss: 0.00010554750770097598
Test Loss:  0.00010878931789193302
Valid Loss:  0.00016858632443472743
Epoch:  302  	Training Loss: 0.00010549477156018838
Test Loss:  0.00010880050831474364
Valid Loss:  0.000168521874002181
Epoch:  303  	Training Loss: 0.000105378741864115
Test Loss:  0.00010890358680626377
Valid Loss:  0.00016847456572577357
Epoch:  304  	Training Loss: 0.00010527303675189614
Test Loss:  0.00010878955072257668
Valid Loss:  0.00016844623314682394
Epoch:  305  	Training Loss: 0.00010517440387047827
Test Loss:  0.000108896623714827
Valid Loss:  0.0001683708978816867
Epoch:  306  	Training Loss: 0.00010507336264709011
Test Loss:  0.00010897110041696578
Valid Loss:  0.0001683187874732539
Epoch:  307  	Training Loss: 0.0001049812271958217
Test Loss:  0.0001089249926735647
Valid Loss:  0.00016829167725518346
Epoch:  308  	Training Loss: 0.00010489622945897281
Test Loss:  0.00010899443441303447
Valid Loss:  0.00016823876649141312
Epoch:  309  	Training Loss: 0.00010481057688593864
Test Loss:  0.00010904403461609036
Valid Loss:  0.00016820640303194523
Epoch:  310  	Training Loss: 0.00010473251313669607
Test Loss:  0.00010898015898419544
Valid Loss:  0.0001681844878476113
Epoch:  311  	Training Loss: 0.00010465671221027151
Test Loss:  0.00010903686779784039
Valid Loss:  0.0001681417488725856
Epoch:  312  	Training Loss: 0.00010458120959810913
Test Loss:  0.00010846865188796073
Valid Loss:  0.00016777930431999266
Epoch:  313  	Training Loss: 0.00010426907101646066
Test Loss:  0.0001078657660400495
Valid Loss:  0.00016748777125030756
Epoch:  314  	Training Loss: 0.00010403626947663724
Test Loss:  0.00010729744099080563
Valid Loss:  0.00016721978317946196
Epoch:  315  	Training Loss: 0.00010382362233940512
Test Loss:  0.00010677114187274128
Valid Loss:  0.00016696829698048532
Epoch:  316  	Training Loss: 0.00010362593457102776
Test Loss:  0.00010628534073475748
Valid Loss:  0.00016672986384946853
Epoch:  317  	Training Loss: 0.00010344042675569654
Test Loss:  0.000105838174931705
Valid Loss:  0.00016650097677484155
Epoch:  318  	Training Loss: 0.00010326530173188075
Test Loss:  0.0001054237800417468
Valid Loss:  0.0001662799622863531
Epoch:  319  	Training Loss: 0.00010309859499102458
Test Loss:  0.00010503869998501614
Valid Loss:  0.00016606517601758242
Epoch:  320  	Training Loss: 0.00010293920058757067
Test Loss:  0.00010467944957781583
Valid Loss:  0.00016585487173870206
Epoch:  321  	Training Loss: 0.0001027855760185048
Test Loss:  0.00010434251453261822
Valid Loss:  0.00016564951511099935
Epoch:  322  	Training Loss: 0.00010263727745041251
Test Loss:  0.00010420251783216372
Valid Loss:  0.00016536233306396753
Epoch:  323  	Training Loss: 0.00010251544154016301
Test Loss:  0.0001041129871737212
Valid Loss:  0.00016521679935976863
Epoch:  324  	Training Loss: 0.0001024449011310935
Test Loss:  0.00010402379848528653
Valid Loss:  0.00016508332919329405
Epoch:  325  	Training Loss: 0.00010237508831778541
Test Loss:  0.0001039339549606666
Valid Loss:  0.0001649519253987819
Epoch:  326  	Training Loss: 0.00010230551561107859
Test Loss:  0.00010384392226114869
Valid Loss:  0.00016482082719448954
Epoch:  327  	Training Loss: 0.00010223621211480349
Test Loss:  0.00010375322017353028
Valid Loss:  0.00016469054389744997
Epoch:  328  	Training Loss: 0.000102167010481935
Test Loss:  0.00010366234346292913
Valid Loss:  0.00016456114826723933
Epoch:  329  	Training Loss: 0.00010209819447482005
Test Loss:  0.00010357135033700615
Valid Loss:  0.00016443166532553732
Epoch:  330  	Training Loss: 0.000102029531262815
Test Loss:  0.00010348051728215069
Valid Loss:  0.0001643029390834272
Epoch:  331  	Training Loss: 0.00010196096263825893
Test Loss:  0.00010338988795410842
Valid Loss:  0.0001641742856008932
Epoch:  332  	Training Loss: 0.00010189261956838891
Test Loss:  0.0001045626777340658
Valid Loss:  0.00016795624105725437
Epoch:  333  	Training Loss: 0.00010641803237376735
Test Loss:  0.00016234410577453673
Valid Loss:  0.00021422229474410415
Epoch:  334  	Training Loss: 0.00014933114289306104
Test Loss:  0.000495480780955404
Valid Loss:  0.0005649680970236659
Epoch:  335  	Training Loss: 0.0005164274480193853
Test Loss:  0.0015915542608126998
Valid Loss:  0.001539409626275301
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.001722920686006546
Test Loss:  0.0009400436538271606
Valid Loss:  0.0008787121623754501
Epoch:  337  	Training Loss: 0.0009230319410562515
Test Loss:  0.000604106520768255
Valid Loss:   68%|██████▊   | 338/500 [04:09<02:59,  1.11s/it] 68%|██████▊   | 340/500 [04:09<02:07,  1.26it/s] 68%|██████▊   | 342/500 [04:16<04:00,  1.52s/it] 69%|██████▉   | 344/500 [04:16<02:49,  1.09s/it] 69%|██████▉   | 346/500 [04:16<02:00,  1.28it/s] 70%|██████▉   | 348/500 [04:16<01:26,  1.77it/s] 70%|███████   | 350/500 [04:16<01:02,  2.40it/s] 70%|███████   | 352/500 [04:23<03:03,  1.24s/it] 71%|███████   | 354/500 [04:23<02:10,  1.12it/s] 71%|███████   | 356/500 [04:23<01:33,  1.54it/s] 72%|███████▏  | 358/500 [04:23<01:08,  2.08it/s] 72%|███████▏  | 360/500 [04:23<00:50,  2.76it/s] 72%|███████▏  | 362/500 [04:30<02:49,  1.23s/it] 73%|███████▎  | 364/500 [04:30<02:00,  1.13it/s] 73%|███████▎  | 366/500 [04:30<01:26,  1.55it/s] 74%|███████▎  | 368/500 [04:30<01:02,  2.10it/s] 74%|███████▍  | 370/500 [04:30<00:46,  2.78it/s] 74%|███████▍  | 372/500 [04:37<02:36,  1.22s/it] 75%|███████▍  | 374/500 [04:37<01:50,  1.15it/s] 75%|███████▌  | 376/500 [04:37<01:18,  1.59it/s] 76%|███████▌  | 378/500 [04:37<00:56,  2.17it/s] 76%|███████▌  | 380/500 [04:37<00:41,  2.92it/s] 76%|███████▋  | 382/500 [04:44<02:20,  1.19s/it] 77%|███████▋  | 384/500 [04:44<01:38,  1.17it/s] 77%|███████▋  | 386/500 [04:44<01:10,  1.62it/s] 78%|███████▊  | 388/500 [04:44<00:50,  2.22it/s] 78%|███████▊  | 390/500 [04:44<00:36,  2.99it/s] 78%|███████▊  | 392/500 [04:51<02:08,  1.19s/it] 79%|███████▉  | 394/500 [04:51<01:30,  1.17it/s] 79%|███████▉  | 396/500 [04:51<01:04,  1.62it/s] 80%|███████▉  | 398/500 [04:51<00:46,  2.21it/s] 80%|████████  | 400/500 [04:51<00:33,  2.98it/s] 80%|████████  | 402/500 [04:58<01:59,  1.22s/it]0.0005603772005997598
Epoch:  338  	Training Loss: 0.000543767586350441
Test Loss:  0.00042271101847290993
Valid Loss:  0.00040126912062987685
Epoch:  339  	Training Loss: 0.00035714602563530207
Test Loss:  0.00032017409102991223
Valid Loss:  0.00031869515078142285
Epoch:  340  	Training Loss: 0.0002620017039589584
Test Loss:  0.0002605560002848506
Valid Loss:  0.00027464894810691476
Epoch:  341  	Training Loss: 0.00021266778639983386
Test Loss:  0.00022189643641468138
Valid Loss:  0.0002475893415976316
Epoch:  342  	Training Loss: 0.00018288323190063238
Test Loss:  0.00017798555199988186
Valid Loss:  0.0002217857399955392
Epoch:  343  	Training Loss: 0.0001502846134826541
Test Loss:  0.00016223997226916254
Valid Loss:  0.0002140997676178813
Epoch:  344  	Training Loss: 0.00014162069419398904
Test Loss:  0.00015468377387151122
Valid Loss:  0.0002106026659021154
Epoch:  345  	Training Loss: 0.00013821675383951515
Test Loss:  0.00015006065950728953
Valid Loss:  0.00020819384371861815
Epoch:  346  	Training Loss: 0.0001360749884042889
Test Loss:  0.000146706253872253
Valid Loss:  0.00020618810958694667
Epoch:  347  	Training Loss: 0.00013433017011266202
Test Loss:  0.00014406352420337498
Valid Loss:  0.00020443150424398482
Epoch:  348  	Training Loss: 0.0001327808276982978
Test Loss:  0.00014180634752847254
Valid Loss:  0.00020285104983486235
Epoch:  349  	Training Loss: 0.00013137806672602892
Test Loss:  0.00013981680967845023
Valid Loss:  0.00020143872825428843
Epoch:  350  	Training Loss: 0.0001301384181715548
Test Loss:  0.00013805160415358841
Valid Loss:  0.00020019582007080317
Epoch:  351  	Training Loss: 0.00012903788592666388
Test Loss:  0.00013647694140672684
Valid Loss:  0.00019906973466277122
Epoch:  352  	Training Loss: 0.00012803100980818272
Test Loss:  0.000132824745378457
Valid Loss:  0.00019494019215926528
Epoch:  353  	Training Loss: 0.0001243895385414362
Test Loss:  0.00012933135440107435
Valid Loss:  0.00019131519366055727
Epoch:  354  	Training Loss: 0.00012104250345146284
Test Loss:  0.00012596489978022873
Valid Loss:  0.0001883253426058218
Epoch:  355  	Training Loss: 0.00011833305325126275
Test Loss:  0.00012302045070100576
Valid Loss:  0.0001858177565736696
Epoch:  356  	Training Loss: 0.00011610508954618126
Test Loss:  0.00012046482879668474
Valid Loss:  0.0001836871961131692
Epoch:  357  	Training Loss: 0.00011421124509070069
Test Loss:  0.00011817853373941034
Valid Loss:  0.00018175719014834613
Epoch:  358  	Training Loss: 0.00011251363321207464
Test Loss:  0.00011618851567618549
Valid Loss:  0.0001800929894670844
Epoch:  359  	Training Loss: 0.00011109403567388654
Test Loss:  0.00011444908159319311
Valid Loss:  0.00017864216351881623
Epoch:  360  	Training Loss: 0.00010989281872753054
Test Loss:  0.00011292651470284909
Valid Loss:  0.0001773646945366636
Epoch:  361  	Training Loss: 0.00010886826203204691
Test Loss:  0.00011153084051329643
Valid Loss:  0.00017615026445128024
Epoch:  362  	Training Loss: 0.0001078818750102073
Test Loss:  0.00011146738688694313
Valid Loss:  0.0001760742743499577
Epoch:  363  	Training Loss: 0.00010780028969747946
Test Loss:  0.00011141192953800783
Valid Loss:  0.00017600345017854124
Epoch:  364  	Training Loss: 0.00010772640234790742
Test Loss:  0.000111364723125007
Valid Loss:  0.00017593635129742324
Epoch:  365  	Training Loss: 0.00010765921615529805
Test Loss:  0.00011132430518046021
Valid Loss:  0.00017587438924238086
Epoch:  366  	Training Loss: 0.00010759830183815211
Test Loss:  0.00011128385085612535
Valid Loss:  0.00017582015425432473
Epoch:  367  	Training Loss: 0.00010754434333648533
Test Loss:  0.00011124441516585648
Valid Loss:  0.00017577240942046046
Epoch:  368  	Training Loss: 0.0001074957981472835
Test Loss:  0.00011120812268927693
Valid Loss:  0.00017572804063092917
Epoch:  369  	Training Loss: 0.00010745149484137073
Test Loss:  0.00011117133544757962
Valid Loss:  0.0001756878336891532
Epoch:  370  	Training Loss: 0.00010741101141320542
Test Loss:  0.00011113994696643203
Valid Loss:  0.00017564835434313864
Epoch:  371  	Training Loss: 0.00010737316915765405
Test Loss:  0.00011110964987892658
Valid Loss:  0.00017561204731464386
Epoch:  372  	Training Loss: 0.0001073381572496146
Test Loss:  0.00011058778909500688
Valid Loss:  0.0001753294054651633
Epoch:  373  	Training Loss: 0.0001071093138307333
Test Loss:  0.00011015612108167261
Valid Loss:  0.00017507119628135115
Epoch:  374  	Training Loss: 0.00010691871284507215
Test Loss:  0.00010982548701576889
Valid Loss:  0.00017485472199041396
Epoch:  375  	Training Loss: 0.00010676239617168903
Test Loss:  0.00010952304728562012
Valid Loss:  0.00017464299162384123
Epoch:  376  	Training Loss: 0.00010661382111720741
Test Loss:  0.00010924710659310222
Valid Loss:  0.000174442189745605
Epoch:  377  	Training Loss: 0.00010647164890542626
Test Loss:  0.0001090039950213395
Valid Loss:  0.00017425467376597226
Epoch:  378  	Training Loss: 0.00010633881174726412
Test Loss:  0.00010879957699216902
Valid Loss:  0.0001740786829032004
Epoch:  379  	Training Loss: 0.00010621375986374915
Test Loss:  0.00010860602924367413
Valid Loss:  0.00017390630091540515
Epoch:  380  	Training Loss: 0.00010609198216116056
Test Loss:  0.00010842207848327234
Valid Loss:  0.00017373661103192717
Epoch:  381  	Training Loss: 0.00010597451910143718
Test Loss:  0.0001082497910829261
Valid Loss:  0.0001735700061544776
Epoch:  382  	Training Loss: 0.00010586206190055236
Test Loss:  0.00010804705379996449
Valid Loss:  0.00017344779917038977
Epoch:  383  	Training Loss: 0.00010574028419796377
Test Loss:  0.00010786989878397435
Valid Loss:  0.00017331988783553243
Epoch:  384  	Training Loss: 0.00010562457464402542
Test Loss:  0.00010770628432510421
Valid Loss:  0.00017319087055511773
Epoch:  385  	Training Loss: 0.00010551267041591927
Test Loss:  0.00010755308903753757
Valid Loss:  0.0001730602962197736
Epoch:  386  	Training Loss: 0.00010540234507061541
Test Loss:  0.00010740676225395873
Valid Loss:  0.00017292783013544977
Epoch:  387  	Training Loss: 0.00010529370047152042
Test Loss:  0.00010726564505603164
Valid Loss:  0.000172795495018363
Epoch:  388  	Training Loss: 0.00010518656927160919
Test Loss:  0.00010712933726608753
Valid Loss:  0.00017266275244764984
Epoch:  389  	Training Loss: 0.00010508071864023805
Test Loss:  0.00010699694394133985
Valid Loss:  0.0001725307374726981
Epoch:  390  	Training Loss: 0.00010497748735360801
Test Loss:  0.0001068685669451952
Valid Loss:  0.000172400803421624
Epoch:  391  	Training Loss: 0.00010487626423127949
Test Loss:  0.00010674347140593454
Valid Loss:  0.00017227005446329713
Epoch:  392  	Training Loss: 0.0001047759797074832
Test Loss:  0.00010577758075669408
Valid Loss:  0.0001711662916932255
Epoch:  393  	Training Loss: 0.00010412320261821151
Test Loss:  0.00010503685189178213
Valid Loss:  0.0001703839225228876
Epoch:  394  	Training Loss: 0.00010369299707235768
Test Loss:  0.00010441564518259838
Valid Loss:  0.000169764447491616
Epoch:  395  	Training Loss: 0.0001033551525324583
Test Loss:  0.00010385286441305652
Valid Loss:  0.00016923161456361413
Epoch:  396  	Training Loss: 0.00010305836622137576
Test Loss:  0.00010334137914469466
Valid Loss:  0.0001687515468802303
Epoch:  397  	Training Loss: 0.00010278594709234312
Test Loss:  0.00010286900942446664
Valid Loss:  0.00016830363892950118
Epoch:  398  	Training Loss: 0.00010252957144984975
Test Loss:  0.00010244482837151736
Valid Loss:  0.00016788431094028056
Epoch:  399  	Training Loss: 0.00010228939936496317
Test Loss:  0.00010206473962171003
Valid Loss:  0.00016748555935919285
Epoch:  400  	Training Loss: 0.00010206265142187476
Test Loss:  0.00010172395559493452
Valid Loss:  0.00016710173804312944
Epoch:  401  	Training Loss: 0.00010185015707975253
Test Loss:  0.00010142345854546875
Valid Loss:  0.0001667394390096888
Epoch:  402  	Training Loss: 0.00010165126877836883
Test Loss:  0.00010111596202477813
Valid Loss:  0.000166665471624583
Epoch:  403  	Training Loss: 0.00010148853471037
Test Loss:  0.00010095094330608845
Valid Loss:  0.00016661963309161365
Epoch:  404  	Training Loss: 0.00010140690574189648
Test Loss:  0.00010085495159728453
Valid Loss:   81%|████████  | 404/500 [04:58<01:23,  1.15it/s] 81%|████████  | 406/500 [04:58<00:59,  1.58it/s] 82%|████████▏ | 408/500 [04:58<00:42,  2.14it/s] 82%|████████▏ | 410/500 [04:58<00:31,  2.84it/s] 82%|████████▏ | 412/500 [05:05<01:50,  1.25s/it] 83%|████████▎ | 414/500 [05:05<01:17,  1.12it/s] 83%|████████▎ | 416/500 [05:05<00:54,  1.55it/s] 84%|████████▎ | 418/500 [05:05<00:38,  2.12it/s] 84%|████████▍ | 420/500 [05:06<00:28,  2.85it/s] 84%|████████▍ | 422/500 [05:12<01:33,  1.20s/it] 85%|████████▍ | 424/500 [05:12<01:05,  1.16it/s] 85%|████████▌ | 426/500 [05:12<00:46,  1.60it/s] 86%|████████▌ | 428/500 [05:12<00:32,  2.19it/s] 86%|████████▌ | 430/500 [05:12<00:23,  2.95it/s] 86%|████████▋ | 432/500 [05:19<01:21,  1.20s/it] 87%|████████▋ | 434/500 [05:19<00:56,  1.16it/s] 87%|████████▋ | 436/500 [05:19<00:39,  1.61it/s] 88%|████████▊ | 438/500 [05:19<00:28,  2.20it/s] 88%|████████▊ | 440/500 [05:19<00:20,  2.96it/s] 88%|████████▊ | 442/500 [05:26<01:09,  1.20s/it] 89%|████████▉ | 444/500 [05:26<00:48,  1.17it/s] 89%|████████▉ | 446/500 [05:26<00:33,  1.61it/s] 90%|████████▉ | 448/500 [05:26<00:23,  2.20it/s] 90%|█████████ | 450/500 [05:26<00:16,  2.97it/s] 90%|█████████ | 452/500 [05:33<00:57,  1.20s/it] 91%|█████████ | 454/500 [05:33<00:39,  1.17it/s] 91%|█████████ | 456/500 [05:33<00:27,  1.61it/s] 92%|█████████▏| 458/500 [05:33<00:19,  2.21it/s] 92%|█████████▏| 460/500 [05:33<00:13,  2.96it/s] 92%|█████████▏| 462/500 [05:40<00:45,  1.21s/it] 93%|█████████▎| 464/500 [05:40<00:31,  1.15it/s] 93%|█████████▎| 466/500 [05:40<00:21,  1.60it/s] 94%|█████████▎| 468/500 [05:40<00:14,  2.18it/s] 94%|█████████▍| 470/500 [05:40<00:10,  2.93it/s]0.00016657606465741992
Epoch:  405  	Training Loss: 0.0001013560249703005
Test Loss:  0.00010079517960548401
Valid Loss:  0.0001665291638346389
Epoch:  406  	Training Loss: 0.00010131727322004735
Test Loss:  0.00010075543104903772
Valid Loss:  0.00016647862503305078
Epoch:  407  	Training Loss: 0.00010128365829586983
Test Loss:  0.00010072745499201119
Valid Loss:  0.00016642546688672155
Epoch:  408  	Training Loss: 0.00010125232074642554
Test Loss:  0.00010070677672047168
Valid Loss:  0.00016637123189866543
Epoch:  409  	Training Loss: 0.0001012222419376485
Test Loss:  0.00010069014388136566
Valid Loss:  0.00016631641483400017
Epoch:  410  	Training Loss: 0.00010119315993506461
Test Loss:  0.00010067623225040734
Valid Loss:  0.00016626171418465674
Epoch:  411  	Training Loss: 0.00010116479825228453
Test Loss:  0.00010066391405416653
Valid Loss:  0.0001662072172621265
Epoch:  412  	Training Loss: 0.00010113678581546992
Test Loss:  0.00010059206397272646
Valid Loss:  0.00016608140140306205
Epoch:  413  	Training Loss: 0.00010108132846653461
Test Loss:  0.00010055528400698677
Valid Loss:  0.00016600200615357608
Epoch:  414  	Training Loss: 0.0001010522828437388
Test Loss:  0.0001005361118586734
Valid Loss:  0.0001659462577663362
Epoch:  415  	Training Loss: 0.00010103346721734852
Test Loss:  0.00010052612924482673
Valid Loss:  0.00016590405721217394
Epoch:  416  	Training Loss: 0.00010101862426381558
Test Loss:  0.00010052105062641203
Valid Loss:  0.00016587029676884413
Epoch:  417  	Training Loss: 0.00010100581857841462
Test Loss:  0.0001005187732516788
Valid Loss:  0.0001658406836213544
Epoch:  418  	Training Loss: 0.00010099363134941086
Test Loss:  0.00010051797289634123
Valid Loss:  0.00016581460658926517
Epoch:  419  	Training Loss: 0.00010098202619701624
Test Loss:  0.00010051814024336636
Valid Loss:  0.0001657900575082749
Epoch:  420  	Training Loss: 0.00010097047925228253
Test Loss:  0.00010051871504401788
Valid Loss:  0.0001657673274166882
Epoch:  421  	Training Loss: 0.00010095931065734476
Test Loss:  0.00010051963181467727
Valid Loss:  0.00016574523760937154
Epoch:  422  	Training Loss: 0.00010094817844219506
Test Loss:  0.00010035383456852287
Valid Loss:  0.00016568896535318345
Epoch:  423  	Training Loss: 0.00010086694965139031
Test Loss:  0.00010025772644439712
Valid Loss:  0.00016564255929552019
Epoch:  424  	Training Loss: 0.00010081577784148976
Test Loss:  0.00010019885667134076
Valid Loss:  0.00016559685172978789
Epoch:  425  	Training Loss: 0.00010077709157485515
Test Loss:  0.00010016129090217873
Valid Loss:  0.00016555035836063325
Epoch:  426  	Training Loss: 0.0001007435203064233
Test Loss:  0.00010013618157245219
Valid Loss:  0.0001655027735978365
Epoch:  427  	Training Loss: 0.00010071261203847826
Test Loss:  0.00010011930135078728
Valid Loss:  0.0001654548104852438
Epoch:  428  	Training Loss: 0.00010068317351397127
Test Loss:  0.00010010798723669723
Valid Loss:  0.0001654066873015836
Epoch:  429  	Training Loss: 0.0001006548700388521
Test Loss:  0.0001000993579509668
Valid Loss:  0.00016535977192688733
Epoch:  430  	Training Loss: 0.00010062773071695119
Test Loss:  0.00010009328252635896
Valid Loss:  0.0001653130748309195
Epoch:  431  	Training Loss: 0.00010060134809464216
Test Loss:  0.00010008872777689248
Valid Loss:  0.00016526774561498314
Epoch:  432  	Training Loss: 0.00010057551844511181
Test Loss:  0.000100036668300163
Valid Loss:  0.00016499211778864264
Epoch:  433  	Training Loss: 0.00010044372174888849
Test Loss:  9.998014138545841e-05
Valid Loss:  0.00016473844880238175
Epoch:  434  	Training Loss: 0.00010032299178419635
Test Loss:  9.99296607915312e-05
Valid Loss:  0.00016450483235530555
Epoch:  435  	Training Loss: 0.00010021809430327266
Test Loss:  9.988701640395448e-05
Valid Loss:  0.00016428949311375618
Epoch:  436  	Training Loss: 0.00010012528946390375
Test Loss:  9.986860095523298e-05
Valid Loss:  0.00016409606905654073
Epoch:  437  	Training Loss: 0.00010004853538703173
Test Loss:  9.985128417611122e-05
Valid Loss:  0.00016391102690249681
Epoch:  438  	Training Loss: 9.997622692026198e-05
Test Loss:  9.985017823055387e-05
Valid Loss:  0.00016373708785977215
Epoch:  439  	Training Loss: 9.99090843833983e-05
Test Loss:  9.985924407374114e-05
Valid Loss:  0.00016357397544197738
Epoch:  440  	Training Loss: 9.985026554204524e-05
Test Loss:  9.987889643525705e-05
Valid Loss:  0.0001634279906284064
Epoch:  441  	Training Loss: 9.979913738789037e-05
Test Loss:  9.990086255129427e-05
Valid Loss:  0.00016329495701938868
Epoch:  442  	Training Loss: 9.975238936021924e-05
Test Loss:  9.978967864299193e-05
Valid Loss:  0.00016318043344654143
Epoch:  443  	Training Loss: 9.969084931071848e-05
Test Loss:  9.967790538212284e-05
Valid Loss:  0.00016308645717799664
Epoch:  444  	Training Loss: 9.963821503333747e-05
Test Loss:  9.956675785360858e-05
Valid Loss:  0.00016300295828841627
Epoch:  445  	Training Loss: 9.95890295598656e-05
Test Loss:  9.945744386641309e-05
Valid Loss:  0.00016292573127429932
Epoch:  446  	Training Loss: 9.954195411410183e-05
Test Loss:  9.935055277310312e-05
Valid Loss:  0.00016285186575260013
Epoch:  447  	Training Loss: 9.949619561666623e-05
Test Loss:  9.924634650815278e-05
Valid Loss:  0.0001627809542696923
Epoch:  448  	Training Loss: 9.945151396095753e-05
Test Loss:  9.914530528476462e-05
Valid Loss:  0.000162712371093221
Epoch:  449  	Training Loss: 9.940793097484857e-05
Test Loss:  9.904688340611756e-05
Valid Loss:  0.00016264495206996799
Epoch:  450  	Training Loss: 9.936564310919493e-05
Test Loss:  9.895239782053977e-05
Valid Loss:  0.00016257942479569465
Epoch:  451  	Training Loss: 9.932440298143774e-05
Test Loss:  9.886026964522898e-05
Valid Loss:  0.00016251533816102892
Epoch:  452  	Training Loss: 9.928402141667902e-05
Test Loss:  9.846259490586817e-05
Valid Loss:  0.0001620934490347281
Epoch:  453  	Training Loss: 9.890811634249985e-05
Test Loss:  9.804024011828005e-05
Valid Loss:  0.00016164768021553755
Epoch:  454  	Training Loss: 9.847936598816887e-05
Test Loss:  9.76445444393903e-05
Valid Loss:  0.00016123481327667832
Epoch:  455  	Training Loss: 9.804825822357088e-05
Test Loss:  9.727436554385349e-05
Valid Loss:  0.00016084694652818143
Epoch:  456  	Training Loss: 9.763296111486852e-05
Test Loss:  9.693325409898534e-05
Valid Loss:  0.00016050007252488285
Epoch:  457  	Training Loss: 9.724208211991936e-05
Test Loss:  9.661754302214831e-05
Valid Loss:  0.0001601862459210679
Epoch:  458  	Training Loss: 9.691013110568747e-05
Test Loss:  9.631941793486476e-05
Valid Loss:  0.00015991501277312636
Epoch:  459  	Training Loss: 9.663712990004569e-05
Test Loss:  9.603718353901058e-05
Valid Loss:  0.00015968848310876638
Epoch:  460  	Training Loss: 9.642536315368488e-05
Test Loss:  9.577984747011214e-05
Valid Loss:  0.00015947841166052967
Epoch:  461  	Training Loss: 9.624937956687063e-05
Test Loss:  9.556631266605109e-05
Valid Loss:  0.00015930840163491666
Epoch:  462  	Training Loss: 9.610461711417884e-05
Test Loss:  9.538413723930717e-05
Valid Loss:  0.00015901470032986253
Epoch:  463  	Training Loss: 9.5964758656919e-05
Test Loss:  9.517647413304076e-05
Valid Loss:  0.0001587079168530181
Epoch:  464  	Training Loss: 9.58142991294153e-05
Test Loss:  9.498558938503265e-05
Valid Loss:  0.00015842902939766645
Epoch:  465  	Training Loss: 9.567862434778363e-05
Test Loss:  9.480929293204099e-05
Valid Loss:  0.00015816951054148376
Epoch:  466  	Training Loss: 9.555307769915089e-05
Test Loss:  9.464689355809242e-05
Valid Loss:  0.0001579250965733081
Epoch:  467  	Training Loss: 9.543537453282624e-05
Test Loss:  9.449628851143643e-05
Valid Loss:  0.0001576921931700781
Epoch:  468  	Training Loss: 9.532440890325233e-05
Test Loss:  9.435688843950629e-05
Valid Loss:  0.0001574693014845252
Epoch:  469  	Training Loss: 9.521874017082155e-05
Test Loss:  9.422709990758449e-05
Valid Loss:  0.00015725407865829766
Epoch:  470  	Training Loss: 9.511773532722145e-05
Test Loss:  9.410581697011366e-05
Valid Loss:  0.00015704595716670156
Epoch:  471  	Training Loss: 9.502093598712236e-05
Test Loss:  9.399257396580651e-05
Valid Loss:  0.00015684438403695822
 94%|█████████▍| 472/500 [05:47<00:33,  1.20s/it] 95%|█████████▍| 474/500 [05:47<00:22,  1.17it/s] 95%|█████████▌| 476/500 [05:47<00:14,  1.62it/s] 96%|█████████▌| 478/500 [05:47<00:09,  2.21it/s] 96%|█████████▌| 480/500 [05:47<00:06,  2.97it/s] 96%|█████████▋| 482/500 [05:54<00:21,  1.19s/it] 97%|█████████▋| 484/500 [05:54<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:54<00:08,  1.62it/s] 98%|█████████▊| 488/500 [05:54<00:05,  2.22it/s] 98%|█████████▊| 490/500 [05:54<00:03,  2.98it/s] 98%|█████████▊| 492/500 [06:00<00:09,  1.19s/it] 99%|█████████▉| 494/500 [06:01<00:05,  1.18it/s] 99%|█████████▉| 496/500 [06:01<00:02,  1.63it/s]100%|█████████▉| 498/500 [06:01<00:00,  2.22it/s]100%|██████████| 500/500 [06:01<00:00,  2.99it/s]100%|██████████| 500/500 [06:01<00:00,  1.38it/s]
Epoch:  472  	Training Loss: 9.492760000284761e-05
Test Loss:  9.398181282449514e-05
Valid Loss:  0.00015681004151701927
Epoch:  473  	Training Loss: 9.490465890849009e-05
Test Loss:  9.397244139108807e-05
Valid Loss:  0.00015677569899708033
Epoch:  474  	Training Loss: 9.488249634159729e-05
Test Loss:  9.396372479386628e-05
Valid Loss:  0.00015674153110012412
Epoch:  475  	Training Loss: 9.48612141655758e-05
Test Loss:  9.395582310389727e-05
Valid Loss:  0.00015670707216486335
Epoch:  476  	Training Loss: 9.484039037488401e-05
Test Loss:  9.39489109441638e-05
Valid Loss:  0.00015667345724068582
Epoch:  477  	Training Loss: 9.4819966761861e-05
Test Loss:  9.394231892656535e-05
Valid Loss:  0.00015663936210330576
Epoch:  478  	Training Loss: 9.48002198128961e-05
Test Loss:  9.393659274792299e-05
Valid Loss:  0.00015660568897146732
Epoch:  479  	Training Loss: 9.478078573010862e-05
Test Loss:  9.393096115672961e-05
Valid Loss:  0.00015657216135878116
Epoch:  480  	Training Loss: 9.476164996158332e-05
Test Loss:  9.392599167767912e-05
Valid Loss:  0.00015653886657673866
Epoch:  481  	Training Loss: 9.474308171775192e-05
Test Loss:  9.392139327246696e-05
Valid Loss:  0.00015650532441213727
Epoch:  482  	Training Loss: 9.472461533732712e-05
Test Loss:  9.38914017751813e-05
Valid Loss:  0.00015645340317860246
Epoch:  483  	Training Loss: 9.466732444707304e-05
Test Loss:  9.386279998579994e-05
Valid Loss:  0.0001564036647323519
Epoch:  484  	Training Loss: 9.461252193432301e-05
Test Loss:  9.383540600538254e-05
Valid Loss:  0.00015635440649930388
Epoch:  485  	Training Loss: 9.455915278522298e-05
Test Loss:  9.380892151966691e-05
Valid Loss:  0.0001563067635288462
Epoch:  486  	Training Loss: 9.450625657336786e-05
Test Loss:  9.378948016092181e-05
Valid Loss:  0.0001562650577398017
Epoch:  487  	Training Loss: 9.445404430152848e-05
Test Loss:  9.376391244586557e-05
Valid Loss:  0.0001562184188514948
Epoch:  488  	Training Loss: 9.44020866882056e-05
Test Loss:  9.374496585223824e-05
Valid Loss:  0.00015617770259268582
Epoch:  489  	Training Loss: 9.435127140022814e-05
Test Loss:  9.371979103889316e-05
Valid Loss:  0.00015613186405971646
Epoch:  490  	Training Loss: 9.430170757696033e-05
Test Loss:  9.370120824314654e-05
Valid Loss:  0.0001560916134621948
Epoch:  491  	Training Loss: 9.42524493439123e-05
Test Loss:  9.36826691031456e-05
Valid Loss:  0.00015605200314894319
Epoch:  492  	Training Loss: 9.420467540621758e-05
Test Loss:  9.370551561005414e-05
Valid Loss:  0.00015581469051539898
Epoch:  493  	Training Loss: 9.409776248503476e-05
Test Loss:  9.37292497837916e-05
Valid Loss:  0.0001556111965328455
Epoch:  494  	Training Loss: 9.400608541909605e-05
Test Loss:  9.374900400871411e-05
Valid Loss:  0.0001554309856146574
Epoch:  495  	Training Loss: 9.392378706252202e-05
Test Loss:  9.37637232709676e-05
Valid Loss:  0.0001552671892568469
Epoch:  496  	Training Loss: 9.38484663493e-05
Test Loss:  9.377659443998709e-05
Valid Loss:  0.00015511782839894295
Epoch:  497  	Training Loss: 9.377958485856652e-05
Test Loss:  9.378419781569391e-05
Valid Loss:  0.0001549778535263613
Epoch:  498  	Training Loss: 9.37145232455805e-05
Test Loss:  9.378657705383375e-05
Valid Loss:  0.0001548455620650202
Epoch:  499  	Training Loss: 9.365243022330105e-05
Test Loss:  9.378411050420254e-05
Valid Loss:  0.00015471939695999026
Epoch:  500  	Training Loss: 9.359381510876119e-05
Test Loss:  9.378313552588224e-05
Valid Loss:  0.00015460120630450547
seed is  3
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.12it/s]  1%|          | 4/500 [00:00<00:31, 15.74it/s]  1%|          | 6/500 [00:00<00:31, 15.92it/s]  2%|▏         | 8/500 [00:00<00:30, 15.99it/s]  2%|▏         | 10/500 [00:00<00:31, 15.73it/s]  2%|▏         | 12/500 [00:00<00:30, 15.89it/s]  3%|▎         | 14/500 [00:00<00:30, 16.04it/s]  3%|▎         | 16/500 [00:01<00:30, 16.07it/s]  4%|▎         | 18/500 [00:01<00:29, 16.16it/s]  4%|▍         | 20/500 [00:01<00:29, 16.28it/s]  4%|▍         | 22/500 [00:01<00:29, 16.27it/s]  5%|▍         | 24/500 [00:01<00:29, 16.28it/s]  5%|▌         | 26/500 [00:01<00:29, 16.21it/s]  6%|▌         | 28/500 [00:01<00:29, 16.04it/s]  6%|▌         | 30/500 [00:01<00:29, 15.79it/s]  6%|▋         | 32/500 [00:02<00:29, 15.85it/s]  7%|▋         | 34/500 [00:02<00:29, 15.87it/s]  7%|▋         | 36/500 [00:02<00:29, 15.98it/s]  8%|▊         | 38/500 [00:02<00:29, 15.81it/s]  8%|▊         | 40/500 [00:02<00:28, 15.88it/s]  8%|▊         | 42/500 [00:02<00:28, 15.93it/s]  9%|▉         | 44/500 [00:02<00:28, 15.85it/s]  9%|▉         | 46/500 [00:02<00:29, 15.48it/s] 10%|▉         | 48/500 [00:03<00:29, 15.23it/s] 10%|█         | 50/500 [00:03<00:29, 15.35it/s] 10%|█         | 52/500 [00:03<00:29, 15.36it/s] 11%|█         | 54/500 [00:03<00:28, 15.56it/s] 11%|█         | 56/500 [00:03<00:28, 15.69it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.53it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.68it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.83it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.81it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.84it/s] 14%|█▎        | 68/500 [00:04<00:28, 15.29it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.56it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.77it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.96it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.05it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.14it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.19it/s] 16%|█▋        | 82/500 [00:05<00:26, 16.05it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.15it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.23it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.22it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.29it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.29it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.32it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.33it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.20it/s] 20%|██        | 100/500 [00:06<00:24, 16.19it/s] 20%|██        | 102/500 [00:06<00:24, 16.25it/s] 21%|██        | 104/500 [00:06<00:24, 16.25it/s] 21%|██        | 106/500 [00:06<00:24, 16.23it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.23it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.23it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.23it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.11it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.96it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.91it/s] 24%|██▍       | 120/500 [00:07<00:23, 15.94it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.76it/s] 25%|██▍       | 124/500 [00:07<00:25, 14.56it/s]Epoch:  1  	Training Loss: 0.09565693140029907
Test Loss:  1818.319091796875
Valid Loss:  1814.8182373046875
Epoch:  2  	Training Loss: 1809.39990234375
Test Loss:  49670172704768.0
Valid Loss:  48705713471488.0
Epoch:  3  	Training Loss: 49487842115584.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:27, 13.83it/s] 26%|██▌       | 128/500 [00:08<00:27, 13.35it/s] 26%|██▌       | 130/500 [00:08<00:28, 13.03it/s] 26%|██▋       | 132/500 [00:08<00:28, 12.79it/s] 27%|██▋       | 134/500 [00:08<00:29, 12.57it/s] 27%|██▋       | 136/500 [00:08<00:28, 12.61it/s] 28%|██▊       | 138/500 [00:08<00:27, 13.30it/s] 28%|██▊       | 140/500 [00:09<00:26, 13.67it/s] 28%|██▊       | 142/500 [00:09<00:25, 14.14it/s] 29%|██▉       | 144/500 [00:09<00:24, 14.75it/s] 29%|██▉       | 146/500 [00:09<00:23, 15.23it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.51it/s] 30%|███       | 150/500 [00:09<00:22, 15.44it/s] 30%|███       | 152/500 [00:09<00:22, 15.53it/s] 31%|███       | 154/500 [00:09<00:22, 15.67it/s] 31%|███       | 156/500 [00:10<00:22, 15.48it/s] 32%|███▏      | 158/500 [00:10<00:23, 14.52it/s] 32%|███▏      | 160/500 [00:10<00:24, 13.63it/s] 32%|███▏      | 162/500 [00:10<00:26, 12.92it/s] 33%|███▎      | 164/500 [00:10<00:26, 12.53it/s] 33%|███▎      | 166/500 [00:10<00:26, 12.39it/s] 34%|███▎      | 168/500 [00:11<00:27, 12.27it/s] 34%|███▍      | 170/500 [00:11<00:27, 12.16it/s] 34%|███▍      | 172/500 [00:11<00:27, 12.09it/s] 35%|███▍      | 174/500 [00:11<00:26, 12.19it/s] 35%|███▌      | 176/500 [00:11<00:26, 12.25it/s] 36%|███▌      | 178/500 [00:11<00:26, 12.28it/s] 36%|███▌      | 180/500 [00:12<00:26, 12.30it/s] 36%|███▋      | 182/500 [00:12<00:25, 12.32it/s] 37%|███▋      | 184/500 [00:12<00:25, 12.33it/s] 37%|███▋      | 186/500 [00:12<00:25, 12.35it/s] 38%|███▊      | 188/500 [00:12<00:25, 12.38it/s] 38%|███▊      | 190/500 [00:12<00:25, 12.38it/s] 38%|███▊      | 192/500 [00:12<00:23, 12.88it/s] 39%|███▉      | 194/500 [00:13<00:22, 13.80it/s] 39%|███▉      | 196/500 [00:13<00:20, 14.50it/s] 40%|███▉      | 198/500 [00:13<00:20, 15.02it/s] 40%|████      | 200/500 [00:13<00:19, 15.37it/s] 40%|████      | 202/500 [00:13<00:19, 15.65it/s] 41%|████      | 204/500 [00:13<00:18, 15.90it/s] 41%|████      | 206/500 [00:13<00:18, 16.04it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.08it/s] 42%|████▏     | 210/500 [00:14<00:18, 16.10it/s] 42%|████▏     | 212/500 [00:14<00:17, 16.16it/s] 43%|████▎     | 214/500 [00:14<00:17, 16.18it/s] 43%|████▎     | 216/500 [00:14<00:17, 16.25it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.26it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.30it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.34it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.32it/s] 45%|████▌     | 226/500 [00:15<00:16, 16.25it/s] 46%|████▌     | 228/500 [00:15<00:16, 16.16it/s] 46%|████▌     | 230/500 [00:15<00:16, 16.10it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.08it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.04it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.67it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.46it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.43it/s] 48%|████▊     | 242/500 [00:16<00:16, 15.70it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.85it/s] 49%|████▉     | 246/500 [00:16<00:16, 15.77it/s] 50%|████▉     | 248/500 [00:16<00:17, 14.81it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:17, 14.26it/s] 50%|█████     | 252/500 [00:16<00:17, 13.94it/s] 51%|█████     | 254/500 [00:16<00:18, 13.22it/s] 51%|█████     | 256/500 [00:17<00:18, 13.43it/s] 52%|█████▏    | 258/500 [00:17<00:17, 14.13it/s] 52%|█████▏    | 260/500 [00:17<00:16, 14.75it/s] 52%|█████▏    | 262/500 [00:17<00:15, 15.03it/s] 53%|█████▎    | 264/500 [00:17<00:15, 14.86it/s] 53%|█████▎    | 266/500 [00:17<00:15, 15.04it/s] 54%|█████▎    | 268/500 [00:17<00:15, 15.21it/s] 54%|█████▍    | 270/500 [00:18<00:14, 15.45it/s] 54%|█████▍    | 272/500 [00:18<00:14, 15.57it/s] 55%|█████▍    | 274/500 [00:18<00:14, 15.71it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.90it/s] 56%|█████▌    | 278/500 [00:18<00:13, 16.05it/s] 56%|█████▌    | 280/500 [00:18<00:13, 16.11it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.20it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.29it/s] 57%|█████▋    | 286/500 [00:19<00:13, 16.30it/s] 58%|█████▊    | 288/500 [00:19<00:13, 16.23it/s] 58%|█████▊    | 290/500 [00:19<00:13, 16.01it/s] 58%|█████▊    | 292/500 [00:19<00:12, 16.02it/s] 59%|█████▉    | 294/500 [00:19<00:12, 15.91it/s] 59%|█████▉    | 296/500 [00:19<00:12, 15.71it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.66it/s] 60%|██████    | 300/500 [00:19<00:12, 15.70it/s] 60%|██████    | 302/500 [00:20<00:12, 15.61it/s] 61%|██████    | 304/500 [00:20<00:12, 15.55it/s] 61%|██████    | 306/500 [00:20<00:12, 15.77it/s] 62%|██████▏   | 308/500 [00:20<00:12, 15.93it/s] 62%|██████▏   | 310/500 [00:20<00:11, 15.93it/s] 62%|██████▏   | 312/500 [00:20<00:11, 16.02it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.07it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.99it/s] 64%|██████▎   | 318/500 [00:21<00:11, 16.15it/s] 64%|██████▍   | 320/500 [00:21<00:11, 16.07it/s] 64%|██████▍   | 322/500 [00:21<00:12, 14.44it/s] 65%|██████▍   | 324/500 [00:21<00:12, 13.67it/s] 65%|██████▌   | 326/500 [00:21<00:13, 13.34it/s] 66%|██████▌   | 328/500 [00:21<00:12, 14.08it/s] 66%|██████▌   | 330/500 [00:21<00:11, 14.68it/s] 66%|██████▋   | 332/500 [00:22<00:11, 15.14it/s] 67%|██████▋   | 334/500 [00:22<00:10, 15.50it/s] 67%|██████▋   | 336/500 [00:22<00:10, 15.81it/s] 68%|██████▊   | 338/500 [00:22<00:10, 15.96it/s] 68%|██████▊   | 340/500 [00:22<00:09, 16.02it/s] 68%|██████▊   | 342/500 [00:22<00:09, 15.87it/s] 69%|██████▉   | 344/500 [00:22<00:10, 15.01it/s] 69%|██████▉   | 346/500 [00:22<00:10, 14.10it/s] 70%|██████▉   | 348/500 [00:23<00:11, 13.52it/s] 70%|███████   | 350/500 [00:23<00:11, 13.15it/s] 70%|███████   | 352/500 [00:23<00:11, 12.89it/s] 71%|███████   | 354/500 [00:23<00:11, 12.65it/s] 71%|███████   | 356/500 [00:23<00:11, 12.42it/s] 72%|███████▏  | 358/500 [00:23<00:11, 12.38it/s] 72%|███████▏  | 360/500 [00:24<00:11, 12.39it/s] 72%|███████▏  | 362/500 [00:24<00:11, 12.37it/s] 73%|███████▎  | 364/500 [00:24<00:11, 11.93it/s] 73%|███████▎  | 366/500 [00:24<00:11, 11.99it/s] 74%|███████▎  | 368/500 [00:24<00:10, 12.10it/s] 74%|███████▍  | 370/500 [00:24<00:10, 12.16it/s] 74%|███████▍  | 372/500 [00:25<00:10, 12.20it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:25<00:10, 12.22it/s] 75%|███████▌  | 376/500 [00:25<00:10, 12.26it/s] 76%|███████▌  | 378/500 [00:25<00:09, 12.30it/s] 76%|███████▌  | 380/500 [00:25<00:09, 12.30it/s] 76%|███████▋  | 382/500 [00:25<00:09, 12.92it/s] 77%|███████▋  | 384/500 [00:25<00:08, 13.60it/s] 77%|███████▋  | 386/500 [00:26<00:07, 14.35it/s] 78%|███████▊  | 388/500 [00:26<00:07, 14.95it/s] 78%|███████▊  | 390/500 [00:26<00:07, 15.37it/s] 78%|███████▊  | 392/500 [00:26<00:06, 15.66it/s] 79%|███████▉  | 394/500 [00:26<00:06, 15.89it/s] 79%|███████▉  | 396/500 [00:26<00:06, 16.02it/s] 80%|███████▉  | 398/500 [00:26<00:06, 16.08it/s] 80%|████████  | 400/500 [00:26<00:06, 15.98it/s] 80%|████████  | 402/500 [00:27<00:06, 15.95it/s] 81%|████████  | 404/500 [00:27<00:06, 14.96it/s] 81%|████████  | 406/500 [00:27<00:06, 14.26it/s] 82%|████████▏ | 408/500 [00:27<00:06, 14.58it/s] 82%|████████▏ | 410/500 [00:27<00:05, 15.07it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.26it/s] 83%|████████▎ | 414/500 [00:27<00:06, 14.08it/s] 83%|████████▎ | 416/500 [00:28<00:06, 13.99it/s] 84%|████████▎ | 418/500 [00:28<00:05, 13.68it/s] 84%|████████▍ | 420/500 [00:28<00:06, 13.15it/s] 84%|████████▍ | 422/500 [00:28<00:06, 12.86it/s] 85%|████████▍ | 424/500 [00:28<00:05, 12.70it/s] 85%|████████▌ | 426/500 [00:28<00:05, 12.58it/s] 86%|████████▌ | 428/500 [00:29<00:05, 12.50it/s] 86%|████████▌ | 430/500 [00:29<00:05, 12.45it/s] 86%|████████▋ | 432/500 [00:29<00:05, 12.40it/s] 87%|████████▋ | 434/500 [00:29<00:05, 12.32it/s] 87%|████████▋ | 436/500 [00:29<00:04, 12.85it/s] 88%|████████▊ | 438/500 [00:29<00:04, 13.67it/s] 88%|████████▊ | 440/500 [00:29<00:04, 14.29it/s] 88%|████████▊ | 442/500 [00:30<00:03, 14.81it/s] 89%|████████▉ | 444/500 [00:30<00:03, 15.17it/s] 89%|████████▉ | 446/500 [00:30<00:03, 15.41it/s] 90%|████████▉ | 448/500 [00:30<00:03, 15.61it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.72it/s] 90%|█████████ | 452/500 [00:30<00:03, 15.41it/s] 91%|█████████ | 454/500 [00:30<00:02, 15.59it/s] 91%|█████████ | 456/500 [00:30<00:02, 15.38it/s] 92%|█████████▏| 458/500 [00:31<00:02, 15.65it/s] 92%|█████████▏| 460/500 [00:31<00:02, 15.77it/s] 92%|█████████▏| 462/500 [00:31<00:02, 15.95it/s] 93%|█████████▎| 464/500 [00:31<00:02, 15.89it/s] 93%|█████████▎| 466/500 [00:31<00:02, 15.89it/s] 94%|█████████▎| 468/500 [00:31<00:02, 15.95it/s] 94%|█████████▍| 470/500 [00:31<00:01, 15.98it/s] 94%|█████████▍| 472/500 [00:31<00:01, 16.10it/s] 95%|█████████▍| 474/500 [00:32<00:01, 16.18it/s] 95%|█████████▌| 476/500 [00:32<00:01, 16.24it/s] 96%|█████████▌| 478/500 [00:32<00:01, 16.27it/s] 96%|█████████▌| 480/500 [00:32<00:01, 16.25it/s] 96%|█████████▋| 482/500 [00:32<00:01, 16.30it/s] 97%|█████████▋| 484/500 [00:32<00:00, 16.28it/s] 97%|█████████▋| 486/500 [00:32<00:00, 16.25it/s] 98%|█████████▊| 488/500 [00:32<00:00, 16.15it/s] 98%|█████████▊| 490/500 [00:33<00:00, 16.23it/s] 98%|█████████▊| 492/500 [00:33<00:00, 16.24it/s] 99%|█████████▉| 494/500 [00:33<00:00, 16.20it/s] 99%|█████████▉| 496/500 [00:33<00:00, 16.18it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 15.14it/s]100%|██████████| 500/500 [00:33<00:00, 15.25it/s]100%|██████████| 500/500 [00:33<00:00, 14.83it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  3
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:03,  6.38s/it]  1%|          | 3/500 [00:06<14:08,  1.71s/it]  1%|          | 5/500 [00:06<07:06,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.84it/s]  2%|▏         | 11/500 [00:13<11:01,  1.35s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:13<05:14,  1.54it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:45,  2.90it/s]  4%|▍         | 21/500 [00:20<09:59,  1.25s/it]  5%|▍         | 23/500 [00:20<07:06,  1.12it/s]  5%|▌         | 25/500 [00:20<05:05,  1.56it/s]  5%|▌         | 27/500 [00:20<03:41,  2.13it/s]  6%|▌         | 29/500 [00:21<02:43,  2.88it/s]  6%|▌         | 31/500 [00:27<09:21,  1.20s/it]  7%|▋         | 33/500 [00:27<06:42,  1.16it/s]  7%|▋         | 35/500 [00:27<04:49,  1.61it/s]  7%|▋         | 37/500 [00:27<03:30,  2.20it/s]  8%|▊         | 39/500 [00:27<02:35,  2.97it/s]  8%|▊         | 41/500 [00:34<09:09,  1.20s/it]  9%|▊         | 43/500 [00:34<06:32,  1.16it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:25,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.97it/s] 10%|█         | 51/500 [00:41<09:01,  1.21s/it] 11%|█         | 53/500 [00:41<06:27,  1.15it/s] 11%|█         | 55/500 [00:41<04:38,  1.60it/s] 11%|█▏        | 57/500 [00:41<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.94it/s] 12%|█▏        | 61/500 [00:48<08:52,  1.21s/it] 13%|█▎        | 63/500 [00:48<06:20,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:48<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:48<02:27,  2.92it/s] 14%|█▍        | 71/500 [00:55<08:35,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:08,  1.16it/s]Epoch:  1  	Training Loss: 0.09565693140029907
Test Loss:  153.40460205078125
Valid Loss:  148.43072509765625
Epoch:  2  	Training Loss: 147.18731689453125
Test Loss:  0.19487851858139038
Valid Loss:  0.18687623739242554
Epoch:  3  	Training Loss: 0.14577540755271912
Test Loss:  0.1948150098323822
Valid Loss:  0.18681561946868896
Epoch:  4  	Training Loss: 0.14572523534297943
Test Loss:  0.19475150108337402
Valid Loss:  0.1867550015449524
Epoch:  5  	Training Loss: 0.14567506313323975
Test Loss:  0.19468796253204346
Valid Loss:  0.18669438362121582
Epoch:  6  	Training Loss: 0.14562487602233887
Test Loss:  0.19462446868419647
Valid Loss:  0.18663376569747925
Epoch:  7  	Training Loss: 0.14557470381259918
Test Loss:  0.1945609450340271
Valid Loss:  0.18657314777374268
Epoch:  8  	Training Loss: 0.1455245167016983
Test Loss:  0.19449743628501892
Valid Loss:  0.1865125596523285
Epoch:  9  	Training Loss: 0.14547434449195862
Test Loss:  0.19443394243717194
Valid Loss:  0.1864519715309143
Epoch:  10  	Training Loss: 0.14542418718338013
Test Loss:  0.19437046349048615
Valid Loss:  0.18639135360717773
Epoch:  11  	Training Loss: 0.14537402987480164
Test Loss:  0.19430693984031677
Valid Loss:  0.18633073568344116
Epoch:  12  	Training Loss: 0.14532385766506195
Test Loss:  0.19427743554115295
Valid Loss:  0.18630224466323853
Epoch:  13  	Training Loss: 0.1453007608652115
Test Loss:  0.19424794614315033
Valid Loss:  0.1862737536430359
Epoch:  14  	Training Loss: 0.14527766406536102
Test Loss:  0.1942184567451477
Valid Loss:  0.18624530732631683
Epoch:  15  	Training Loss: 0.14525458216667175
Test Loss:  0.19418899714946747
Valid Loss:  0.1862168312072754
Epoch:  16  	Training Loss: 0.14523150026798248
Test Loss:  0.19415950775146484
Valid Loss:  0.18618836998939514
Epoch:  17  	Training Loss: 0.1452084332704544
Test Loss:  0.194130077958107
Valid Loss:  0.1861599236726761
Epoch:  18  	Training Loss: 0.14518535137176514
Test Loss:  0.19410063326358795
Valid Loss:  0.18613149225711823
Epoch:  19  	Training Loss: 0.14516228437423706
Test Loss:  0.1940712034702301
Valid Loss:  0.18610306084156036
Epoch:  20  	Training Loss: 0.14513924717903137
Test Loss:  0.19404178857803345
Valid Loss:  0.1860746443271637
Epoch:  21  	Training Loss: 0.14511620998382568
Test Loss:  0.1940123736858368
Valid Loss:  0.18604621291160583
Epoch:  22  	Training Loss: 0.1450931578874588
Test Loss:  0.19398348033428192
Valid Loss:  0.18601831793785095
Epoch:  23  	Training Loss: 0.14507053792476654
Test Loss:  0.19395461678504944
Valid Loss:  0.18599039316177368
Epoch:  24  	Training Loss: 0.14504791796207428
Test Loss:  0.19392573833465576
Valid Loss:  0.1859624683856964
Epoch:  25  	Training Loss: 0.1450253129005432
Test Loss:  0.19389685988426208
Valid Loss:  0.18593457341194153
Epoch:  26  	Training Loss: 0.14500269293785095
Test Loss:  0.1938679814338684
Valid Loss:  0.18590663373470306
Epoch:  27  	Training Loss: 0.1449800729751587
Test Loss:  0.19383910298347473
Valid Loss:  0.1858787089586258
Epoch:  28  	Training Loss: 0.14495745301246643
Test Loss:  0.19381022453308105
Valid Loss:  0.18585079908370972
Epoch:  29  	Training Loss: 0.14493483304977417
Test Loss:  0.19378136098384857
Valid Loss:  0.18582287430763245
Epoch:  30  	Training Loss: 0.1449122428894043
Test Loss:  0.19375252723693848
Valid Loss:  0.18579497933387756
Epoch:  31  	Training Loss: 0.14488962292671204
Test Loss:  0.1937236338853836
Valid Loss:  0.1857670694589615
Epoch:  32  	Training Loss: 0.14486700296401978
Test Loss:  0.19369328022003174
Valid Loss:  0.1857377290725708
Epoch:  33  	Training Loss: 0.1448432207107544
Test Loss:  0.19366292655467987
Valid Loss:  0.1857084035873413
Epoch:  34  	Training Loss: 0.144819438457489
Test Loss:  0.1936325877904892
Valid Loss:  0.1856791228055954
Epoch:  35  	Training Loss: 0.14479565620422363
Test Loss:  0.19360224902629852
Valid Loss:  0.1856497973203659
Epoch:  36  	Training Loss: 0.14477187395095825
Test Loss:  0.19357192516326904
Valid Loss:  0.18562051653862
Epoch:  37  	Training Loss: 0.14474812150001526
Test Loss:  0.19354158639907837
Valid Loss:  0.1855912208557129
Epoch:  38  	Training Loss: 0.14472436904907227
Test Loss:  0.19351127743721008
Valid Loss:  0.18556195497512817
Epoch:  39  	Training Loss: 0.14470061659812927
Test Loss:  0.1934809684753418
Valid Loss:  0.18553265929222107
Epoch:  40  	Training Loss: 0.14467686414718628
Test Loss:  0.1934506744146347
Valid Loss:  0.18550339341163635
Epoch:  41  	Training Loss: 0.14465312659740448
Test Loss:  0.19342036545276642
Valid Loss:  0.18547412753105164
Epoch:  42  	Training Loss: 0.14462938904762268
Test Loss:  0.19339098036289215
Valid Loss:  0.18544575572013855
Epoch:  43  	Training Loss: 0.14460638165473938
Test Loss:  0.19336161017417908
Valid Loss:  0.18541735410690308
Epoch:  44  	Training Loss: 0.1445833444595337
Test Loss:  0.1933322250843048
Valid Loss:  0.1853889524936676
Epoch:  45  	Training Loss: 0.1445603370666504
Test Loss:  0.19330283999443054
Valid Loss:  0.18536056578159332
Epoch:  46  	Training Loss: 0.1445373296737671
Test Loss:  0.19327348470687866
Valid Loss:  0.18533217906951904
Epoch:  47  	Training Loss: 0.1445143222808838
Test Loss:  0.1932440996170044
Valid Loss:  0.18530377745628357
Epoch:  48  	Training Loss: 0.1444913148880005
Test Loss:  0.19321471452713013
Valid Loss:  0.18527542054653168
Epoch:  49  	Training Loss: 0.144468292593956
Test Loss:  0.19318535923957825
Valid Loss:  0.1852470338344574
Epoch:  50  	Training Loss: 0.1444452852010727
Test Loss:  0.19315601885318756
Valid Loss:  0.1852186620235443
Epoch:  51  	Training Loss: 0.14442229270935059
Test Loss:  0.1931266337633133
Valid Loss:  0.1851903200149536
Epoch:  52  	Training Loss: 0.14439930021762848
Test Loss:  0.19309696555137634
Valid Loss:  0.18516162037849426
Epoch:  53  	Training Loss: 0.14437606930732727
Test Loss:  0.1930672824382782
Valid Loss:  0.1851329505443573
Epoch:  54  	Training Loss: 0.14435282349586487
Test Loss:  0.19303761422634125
Valid Loss:  0.18510431051254272
Epoch:  55  	Training Loss: 0.14432957768440247
Test Loss:  0.19300797581672668
Valid Loss:  0.18507567048072815
Epoch:  56  	Training Loss: 0.14430639147758484
Test Loss:  0.19297835230827332
Valid Loss:  0.18504706025123596
Epoch:  57  	Training Loss: 0.14428316056728363
Test Loss:  0.19294869899749756
Valid Loss:  0.18501843512058258
Epoch:  58  	Training Loss: 0.144259974360466
Test Loss:  0.19291910529136658
Valid Loss:  0.1849898248910904
Epoch:  59  	Training Loss: 0.14423677325248718
Test Loss:  0.1928894966840744
Valid Loss:  0.1849612295627594
Epoch:  60  	Training Loss: 0.14421360194683075
Test Loss:  0.19285991787910461
Valid Loss:  0.184932678937912
Epoch:  61  	Training Loss: 0.14419043064117432
Test Loss:  0.19283035397529602
Valid Loss:  0.1849040985107422
Epoch:  62  	Training Loss: 0.14416727423667908
Test Loss:  0.19280089437961578
Valid Loss:  0.18487566709518433
Epoch:  63  	Training Loss: 0.144144207239151
Test Loss:  0.19277144968509674
Valid Loss:  0.18484722077846527
Epoch:  64  	Training Loss: 0.14412115514278412
Test Loss:  0.1927420198917389
Valid Loss:  0.1848187893629074
Epoch:  65  	Training Loss: 0.14409808814525604
Test Loss:  0.19271257519721985
Valid Loss:  0.18479035794734955
Epoch:  66  	Training Loss: 0.14407503604888916
Test Loss:  0.192683145403862
Valid Loss:  0.1847619265317917
Epoch:  67  	Training Loss: 0.14405198395252228
Test Loss:  0.19265371561050415
Valid Loss:  0.18473351001739502
Epoch:  68  	Training Loss: 0.1440289318561554
Test Loss:  0.1926243007183075
Valid Loss:  0.18470507860183716
Epoch:  69  	Training Loss: 0.1440058946609497
Test Loss:  0.19259488582611084
Valid Loss:  0.1846766620874405
Epoch:  70  	Training Loss: 0.14398282766342163
Test Loss:  0.19256547093391418
Valid Loss:  0.18464826047420502
Epoch:  71  	Training Loss: 0.14395979046821594
Test Loss:  0.19253608584403992
Valid Loss:  0.18461984395980835
Epoch:  72  	Training Loss: 0.14393675327301025
Test Loss:  0.19250914454460144
Valid Loss:  0.1845937818288803
Epoch:  73  	Training Loss: 0.14391571283340454
Test Loss:  0.19248223304748535
Valid Loss:  0.18456774950027466
 15%|█▌        | 75/500 [00:55<04:25,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:13,  2.19it/s] 16%|█▌        | 79/500 [00:55<02:23,  2.94it/s] 16%|█▌        | 81/500 [01:02<08:23,  1.20s/it] 17%|█▋        | 83/500 [01:02<05:59,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:18,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:09<08:11,  1.20s/it] 19%|█▊        | 93/500 [01:09<05:51,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:12,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.95it/s] 20%|██        | 101/500 [01:16<08:01,  1.21s/it] 21%|██        | 103/500 [01:16<05:43,  1.15it/s] 21%|██        | 105/500 [01:16<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:16<02:59,  2.18it/s] 22%|██▏       | 109/500 [01:16<02:12,  2.94it/s] 22%|██▏       | 111/500 [01:23<07:50,  1.21s/it] 23%|██▎       | 113/500 [01:23<05:38,  1.14it/s] 23%|██▎       | 115/500 [01:23<04:05,  1.57it/s] 23%|██▎       | 117/500 [01:23<03:00,  2.12it/s] 24%|██▍       | 119/500 [01:23<02:15,  2.81it/s] 24%|██▍       | 121/500 [01:30<07:55,  1.26s/it] 25%|██▍       | 123/500 [01:30<05:39,  1.11it/s] 25%|██▌       | 125/500 [01:30<04:03,  1.54it/s] 25%|██▌       | 127/500 [01:31<02:56,  2.11it/s] 26%|██▌       | 129/500 [01:31<02:10,  2.84it/s] 26%|██▌       | 131/500 [01:37<07:30,  1.22s/it] 27%|██▋       | 133/500 [01:37<05:21,  1.14it/s] 27%|██▋       | 135/500 [01:37<03:50,  1.58it/s] 27%|██▋       | 137/500 [01:38<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:38<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:44<07:13,  1.21s/it] 29%|██▊       | 143/500 [01:44<05:09,  1.15it/s] 29%|██▉       | 145/500 [01:44<03:42,  1.60it/s]Epoch:  74  	Training Loss: 0.14389468729496002
Test Loss:  0.19245532155036926
Valid Loss:  0.1845417022705078
Epoch:  75  	Training Loss: 0.1438736617565155
Test Loss:  0.19242842495441437
Valid Loss:  0.18451568484306335
Epoch:  76  	Training Loss: 0.14385263621807098
Test Loss:  0.19240151345729828
Valid Loss:  0.18448960781097412
Epoch:  77  	Training Loss: 0.14383161067962646
Test Loss:  0.19237461686134338
Valid Loss:  0.18446359038352966
Epoch:  78  	Training Loss: 0.14381060004234314
Test Loss:  0.1923477202653885
Valid Loss:  0.1844375729560852
Epoch:  79  	Training Loss: 0.14378958940505981
Test Loss:  0.1923208385705948
Valid Loss:  0.18441155552864075
Epoch:  80  	Training Loss: 0.1437685787677765
Test Loss:  0.1922939568758011
Valid Loss:  0.1843855082988739
Epoch:  81  	Training Loss: 0.14374756813049316
Test Loss:  0.19226707518100739
Valid Loss:  0.18435952067375183
Epoch:  82  	Training Loss: 0.14372655749320984
Test Loss:  0.19223816692829132
Valid Loss:  0.18433156609535217
Epoch:  83  	Training Loss: 0.14370393753051758
Test Loss:  0.19220927357673645
Valid Loss:  0.1843036413192749
Epoch:  84  	Training Loss: 0.14368130266666412
Test Loss:  0.19218038022518158
Valid Loss:  0.18427568674087524
Epoch:  85  	Training Loss: 0.14365866780281067
Test Loss:  0.1921514868736267
Valid Loss:  0.18424774706363678
Epoch:  86  	Training Loss: 0.14363601803779602
Test Loss:  0.19212257862091064
Valid Loss:  0.18421979248523712
Epoch:  87  	Training Loss: 0.14361338317394257
Test Loss:  0.1920936405658722
Valid Loss:  0.18419185280799866
Epoch:  88  	Training Loss: 0.14359071850776672
Test Loss:  0.19206473231315613
Valid Loss:  0.184163898229599
Epoch:  89  	Training Loss: 0.14356808364391327
Test Loss:  0.19203582406044006
Valid Loss:  0.18413592875003815
Epoch:  90  	Training Loss: 0.14354543387889862
Test Loss:  0.1920068860054016
Valid Loss:  0.18410798907279968
Epoch:  91  	Training Loss: 0.14352279901504517
Test Loss:  0.19197800755500793
Valid Loss:  0.18408003449440002
Epoch:  92  	Training Loss: 0.14350014925003052
Test Loss:  0.19194844365119934
Valid Loss:  0.1840514838695526
Epoch:  93  	Training Loss: 0.14347700774669647
Test Loss:  0.19191890954971313
Valid Loss:  0.1840229630470276
Epoch:  94  	Training Loss: 0.14345388114452362
Test Loss:  0.19188939034938812
Valid Loss:  0.18399444222450256
Epoch:  95  	Training Loss: 0.14343075454235077
Test Loss:  0.1918598711490631
Valid Loss:  0.18396593630313873
Epoch:  96  	Training Loss: 0.1434076428413391
Test Loss:  0.1918303668498993
Valid Loss:  0.1839374303817749
Epoch:  97  	Training Loss: 0.14338451623916626
Test Loss:  0.19180086255073547
Valid Loss:  0.18390893936157227
Epoch:  98  	Training Loss: 0.1433614194393158
Test Loss:  0.19177135825157166
Valid Loss:  0.18388044834136963
Epoch:  99  	Training Loss: 0.14333830773830414
Test Loss:  0.19174186885356903
Valid Loss:  0.183851957321167
Epoch:  100  	Training Loss: 0.14331521093845367
Test Loss:  0.1917123794555664
Valid Loss:  0.18382346630096436
Epoch:  101  	Training Loss: 0.1432921290397644
Test Loss:  0.1916828751564026
Valid Loss:  0.1837949901819229
Epoch:  102  	Training Loss: 0.14326903223991394
Test Loss:  0.19165688753128052
Valid Loss:  0.1837698072195053
Epoch:  103  	Training Loss: 0.14324872195720673
Test Loss:  0.19163087010383606
Valid Loss:  0.1837446093559265
Epoch:  104  	Training Loss: 0.1432284116744995
Test Loss:  0.1916048526763916
Valid Loss:  0.18371941149234772
Epoch:  105  	Training Loss: 0.1432080864906311
Test Loss:  0.19157882034778595
Valid Loss:  0.18369421362876892
Epoch:  106  	Training Loss: 0.1431877613067627
Test Loss:  0.19155281782150269
Valid Loss:  0.18366898596286774
Epoch:  107  	Training Loss: 0.1431674361228943
Test Loss:  0.19152678549289703
Valid Loss:  0.18364377319812775
Epoch:  108  	Training Loss: 0.14314711093902588
Test Loss:  0.19150075316429138
Valid Loss:  0.18361854553222656
Epoch:  109  	Training Loss: 0.14312678575515747
Test Loss:  0.19147470593452454
Valid Loss:  0.18359334766864777
Epoch:  110  	Training Loss: 0.14310644567012787
Test Loss:  0.19144868850708008
Valid Loss:  0.18356812000274658
Epoch:  111  	Training Loss: 0.14308610558509827
Test Loss:  0.19142261147499084
Valid Loss:  0.1835429072380066
Epoch:  112  	Training Loss: 0.14306576550006866
Test Loss:  0.1913941204547882
Valid Loss:  0.18351531028747559
Epoch:  113  	Training Loss: 0.14304344356060028
Test Loss:  0.19136561453342438
Valid Loss:  0.18348777294158936
Epoch:  114  	Training Loss: 0.1430211365222931
Test Loss:  0.19133710861206055
Valid Loss:  0.18346020579338074
Epoch:  115  	Training Loss: 0.1429988443851471
Test Loss:  0.19130858778953552
Valid Loss:  0.18343263864517212
Epoch:  116  	Training Loss: 0.1429765224456787
Test Loss:  0.1912800818681717
Valid Loss:  0.1834050714969635
Epoch:  117  	Training Loss: 0.14295421540737152
Test Loss:  0.19125157594680786
Valid Loss:  0.18337750434875488
Epoch:  118  	Training Loss: 0.14293187856674194
Test Loss:  0.19122305512428284
Valid Loss:  0.18334993720054626
Epoch:  119  	Training Loss: 0.14290958642959595
Test Loss:  0.1911945343017578
Valid Loss:  0.18332237005233765
Epoch:  120  	Training Loss: 0.14288726449012756
Test Loss:  0.19116604328155518
Valid Loss:  0.18329480290412903
Epoch:  121  	Training Loss: 0.14286494255065918
Test Loss:  0.19113750755786896
Valid Loss:  0.18326720595359802
Epoch:  122  	Training Loss: 0.1428426206111908
Test Loss:  0.19110870361328125
Valid Loss:  0.1832393854856491
Epoch:  123  	Training Loss: 0.1428200900554657
Test Loss:  0.19107989966869354
Valid Loss:  0.1832115650177002
Epoch:  124  	Training Loss: 0.1427975445985794
Test Loss:  0.19105111062526703
Valid Loss:  0.1831837296485901
Epoch:  125  	Training Loss: 0.1427750140428543
Test Loss:  0.19102232158184052
Valid Loss:  0.18315590918064117
Epoch:  126  	Training Loss: 0.1427524983882904
Test Loss:  0.1909935474395752
Valid Loss:  0.18312810361385345
Epoch:  127  	Training Loss: 0.1427299678325653
Test Loss:  0.19096477329730988
Valid Loss:  0.18310031294822693
Epoch:  128  	Training Loss: 0.1427074670791626
Test Loss:  0.19093599915504456
Valid Loss:  0.1830725073814392
Epoch:  129  	Training Loss: 0.1426849663257599
Test Loss:  0.19090722501277924
Valid Loss:  0.18304473161697388
Epoch:  130  	Training Loss: 0.14266245067119598
Test Loss:  0.1908784806728363
Valid Loss:  0.18301695585250854
Epoch:  131  	Training Loss: 0.14263996481895447
Test Loss:  0.19084975123405457
Valid Loss:  0.1829892098903656
Epoch:  132  	Training Loss: 0.14261746406555176
Test Loss:  0.1908208727836609
Valid Loss:  0.18296128511428833
Epoch:  133  	Training Loss: 0.14259487390518188
Test Loss:  0.1907920092344284
Valid Loss:  0.18293337523937225
Epoch:  134  	Training Loss: 0.142572283744812
Test Loss:  0.19076314568519592
Valid Loss:  0.18290548026561737
Epoch:  135  	Training Loss: 0.14254969358444214
Test Loss:  0.19073428213596344
Valid Loss:  0.18287760019302368
Epoch:  136  	Training Loss: 0.14252713322639465
Test Loss:  0.19070543348789215
Valid Loss:  0.1828497052192688
Epoch:  137  	Training Loss: 0.14250454306602478
Test Loss:  0.19067656993865967
Valid Loss:  0.18282181024551392
Epoch:  138  	Training Loss: 0.1424819827079773
Test Loss:  0.19064772129058838
Valid Loss:  0.18279394507408142
Epoch:  139  	Training Loss: 0.1424594223499298
Test Loss:  0.19061888754367828
Valid Loss:  0.18276607990264893
Epoch:  140  	Training Loss: 0.14243686199188232
Test Loss:  0.1905900537967682
Valid Loss:  0.18273821473121643
Epoch:  141  	Training Loss: 0.14241430163383484
Test Loss:  0.1905612051486969
Valid Loss:  0.18271034955978394
Epoch:  142  	Training Loss: 0.14239174127578735
Test Loss:  0.1905326545238495
Valid Loss:  0.18268275260925293
Epoch:  143  	Training Loss: 0.14236940443515778
Test Loss:  0.19050413370132446
Valid Loss:  0.18265517055988312
Epoch:  144  	Training Loss: 0.1423470824956894
Test Loss:  0.19047558307647705
Valid Loss:  0.18262755870819092
Epoch:  145  	Training Loss: 0.14232474565505981
Test Loss:  0.19044706225395203
Valid Loss:  0.1825999915599823
Epoch:  146  	Training Loss: 0.14230242371559143
Test Loss:  0.190418541431427
 29%|██▉       | 147/500 [01:45<02:42,  2.18it/s] 30%|██▉       | 149/500 [01:45<02:00,  2.92it/s] 30%|███       | 151/500 [01:51<06:54,  1.19s/it] 31%|███       | 153/500 [01:51<04:55,  1.17it/s] 31%|███       | 155/500 [01:51<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:51<02:34,  2.21it/s] 32%|███▏      | 159/500 [01:52<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:58<06:38,  1.18s/it] 33%|███▎      | 163/500 [01:58<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:58<03:27,  1.61it/s] 33%|███▎      | 167/500 [01:58<02:33,  2.18it/s] 34%|███▍      | 169/500 [01:59<01:55,  2.88it/s] 34%|███▍      | 171/500 [02:05<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:05<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:05<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:05<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:05<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:12<06:31,  1.23s/it] 37%|███▋      | 183/500 [02:12<04:39,  1.14it/s] 37%|███▋      | 185/500 [02:12<03:20,  1.57it/s] 37%|███▋      | 187/500 [02:12<02:25,  2.15it/s] 38%|███▊      | 189/500 [02:13<01:47,  2.89it/s] 38%|███▊      | 191/500 [02:19<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:19<04:25,  1.15it/s] 39%|███▉      | 195/500 [02:19<03:12,  1.59it/s] 39%|███▉      | 197/500 [02:19<02:20,  2.15it/s] 40%|███▉      | 199/500 [02:20<01:44,  2.89it/s] 40%|████      | 201/500 [02:26<06:06,  1.23s/it] 41%|████      | 203/500 [02:26<04:21,  1.14it/s] 41%|████      | 205/500 [02:26<03:07,  1.57it/s] 41%|████▏     | 207/500 [02:27<02:16,  2.15it/s] 42%|████▏     | 209/500 [02:27<01:40,  2.89it/s] 42%|████▏     | 211/500 [02:33<05:42,  1.19s/it] 43%|████▎     | 213/500 [02:33<04:04,  1.17it/s] 43%|████▎     | 215/500 [02:33<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:33<02:07,  2.22it/s]Valid Loss:  0.18257242441177368
Epoch:  147  	Training Loss: 0.14228011667728424
Test Loss:  0.19039000570774078
Valid Loss:  0.18254485726356506
Epoch:  148  	Training Loss: 0.14225780963897705
Test Loss:  0.19036148488521576
Valid Loss:  0.18251729011535645
Epoch:  149  	Training Loss: 0.14223550260066986
Test Loss:  0.19033297896385193
Valid Loss:  0.18248973786830902
Epoch:  150  	Training Loss: 0.14221319556236267
Test Loss:  0.1903044581413269
Valid Loss:  0.1824621856212616
Epoch:  151  	Training Loss: 0.14219090342521667
Test Loss:  0.19027596712112427
Valid Loss:  0.18243464827537537
Epoch:  152  	Training Loss: 0.14216861128807068
Test Loss:  0.19024866819381714
Valid Loss:  0.18240828812122345
Epoch:  153  	Training Loss: 0.14214730262756348
Test Loss:  0.1902213990688324
Valid Loss:  0.18238192796707153
Epoch:  154  	Training Loss: 0.14212597906589508
Test Loss:  0.19019415974617004
Valid Loss:  0.1823556125164032
Epoch:  155  	Training Loss: 0.14210468530654907
Test Loss:  0.1901668906211853
Valid Loss:  0.18232929706573486
Epoch:  156  	Training Loss: 0.14208339154720306
Test Loss:  0.19013965129852295
Valid Loss:  0.18230296671390533
Epoch:  157  	Training Loss: 0.14206209778785706
Test Loss:  0.1901124268770218
Valid Loss:  0.1822766661643982
Epoch:  158  	Training Loss: 0.14204084873199463
Test Loss:  0.19008520245552063
Valid Loss:  0.18225036561489105
Epoch:  159  	Training Loss: 0.142019584774971
Test Loss:  0.19005799293518066
Valid Loss:  0.1822240948677063
Epoch:  160  	Training Loss: 0.1419983208179474
Test Loss:  0.19003081321716309
Valid Loss:  0.18219783902168274
Epoch:  161  	Training Loss: 0.14197707176208496
Test Loss:  0.1900036334991455
Valid Loss:  0.18217158317565918
Epoch:  162  	Training Loss: 0.14195585250854492
Test Loss:  0.1899757981300354
Valid Loss:  0.1821446567773819
Epoch:  163  	Training Loss: 0.1419340819120407
Test Loss:  0.1899479478597641
Valid Loss:  0.18211770057678223
Epoch:  164  	Training Loss: 0.1419123113155365
Test Loss:  0.1899200975894928
Valid Loss:  0.18209078907966614
Epoch:  165  	Training Loss: 0.1418905109167099
Test Loss:  0.1898922473192215
Valid Loss:  0.18206383287906647
Epoch:  166  	Training Loss: 0.1418687254190445
Test Loss:  0.1898643970489502
Valid Loss:  0.182036891579628
Epoch:  167  	Training Loss: 0.14184695482254028
Test Loss:  0.1898365318775177
Valid Loss:  0.18200993537902832
Epoch:  168  	Training Loss: 0.1418251395225525
Test Loss:  0.189808651804924
Valid Loss:  0.18198297917842865
Epoch:  169  	Training Loss: 0.14180335402488708
Test Loss:  0.18978078663349152
Valid Loss:  0.18195600807666779
Epoch:  170  	Training Loss: 0.14178155362606049
Test Loss:  0.18975290656089783
Valid Loss:  0.18192905187606812
Epoch:  171  	Training Loss: 0.1417597532272339
Test Loss:  0.18972502648830414
Valid Loss:  0.18190208077430725
Epoch:  172  	Training Loss: 0.1417379379272461
Test Loss:  0.1896960735321045
Valid Loss:  0.1818741261959076
Epoch:  173  	Training Loss: 0.14171528816223145
Test Loss:  0.18966713547706604
Valid Loss:  0.18184617161750793
Epoch:  174  	Training Loss: 0.1416926383972168
Test Loss:  0.18963822722434998
Valid Loss:  0.18181821703910828
Epoch:  175  	Training Loss: 0.14167000353336334
Test Loss:  0.18960928916931152
Valid Loss:  0.181790292263031
Epoch:  176  	Training Loss: 0.14164738357067108
Test Loss:  0.18958035111427307
Valid Loss:  0.18176233768463135
Epoch:  177  	Training Loss: 0.14162474870681763
Test Loss:  0.189551442861557
Valid Loss:  0.18173441290855408
Epoch:  178  	Training Loss: 0.14160211384296417
Test Loss:  0.18952254951000214
Valid Loss:  0.181706503033638
Epoch:  179  	Training Loss: 0.1415795087814331
Test Loss:  0.18949365615844727
Valid Loss:  0.18167857825756073
Epoch:  180  	Training Loss: 0.14155688881874084
Test Loss:  0.1894647628068924
Valid Loss:  0.18165066838264465
Epoch:  181  	Training Loss: 0.14153428375720978
Test Loss:  0.18943586945533752
Valid Loss:  0.18162277340888977
Epoch:  182  	Training Loss: 0.1415116935968399
Test Loss:  0.18940791487693787
Valid Loss:  0.18159574270248413
Epoch:  183  	Training Loss: 0.14148983359336853
Test Loss:  0.1893799602985382
Valid Loss:  0.1815687119960785
Epoch:  184  	Training Loss: 0.14146798849105835
Test Loss:  0.18935202062129974
Valid Loss:  0.18154171109199524
Epoch:  185  	Training Loss: 0.14144614338874817
Test Loss:  0.18932408094406128
Valid Loss:  0.1815146952867508
Epoch:  186  	Training Loss: 0.141424298286438
Test Loss:  0.18929612636566162
Valid Loss:  0.18148766458034515
Epoch:  187  	Training Loss: 0.1414024531841278
Test Loss:  0.18926818668842316
Valid Loss:  0.1814606785774231
Epoch:  188  	Training Loss: 0.14138060808181763
Test Loss:  0.1892402619123459
Valid Loss:  0.18143367767333984
Epoch:  189  	Training Loss: 0.14135877788066864
Test Loss:  0.18921232223510742
Valid Loss:  0.1814066767692566
Epoch:  190  	Training Loss: 0.14133694767951965
Test Loss:  0.18918439745903015
Valid Loss:  0.18137966096401215
Epoch:  191  	Training Loss: 0.14131511747837067
Test Loss:  0.18915650248527527
Valid Loss:  0.18135268986225128
Epoch:  192  	Training Loss: 0.14129328727722168
Test Loss:  0.18912819027900696
Valid Loss:  0.18132534623146057
Epoch:  193  	Training Loss: 0.14127117395401
Test Loss:  0.18909992277622223
Valid Loss:  0.18129801750183105
Epoch:  194  	Training Loss: 0.14124906063079834
Test Loss:  0.1890716552734375
Valid Loss:  0.18127070367336273
Epoch:  195  	Training Loss: 0.14122697710990906
Test Loss:  0.18904340267181396
Valid Loss:  0.1812434047460556
Epoch:  196  	Training Loss: 0.14120489358901978
Test Loss:  0.18901515007019043
Valid Loss:  0.18121610581874847
Epoch:  197  	Training Loss: 0.1411828100681305
Test Loss:  0.18898692727088928
Valid Loss:  0.18118882179260254
Epoch:  198  	Training Loss: 0.1411607265472412
Test Loss:  0.18895870447158813
Valid Loss:  0.1811615526676178
Epoch:  199  	Training Loss: 0.14113867282867432
Test Loss:  0.188930481672287
Valid Loss:  0.18113428354263306
Epoch:  200  	Training Loss: 0.14111660420894623
Test Loss:  0.18890227377414703
Valid Loss:  0.18110701441764832
Epoch:  201  	Training Loss: 0.14109456539154053
Test Loss:  0.18887408077716827
Valid Loss:  0.18107977509498596
Epoch:  202  	Training Loss: 0.14107251167297363
Test Loss:  0.18884485960006714
Valid Loss:  0.1810515820980072
Epoch:  203  	Training Loss: 0.14104965329170227
Test Loss:  0.188815638422966
Valid Loss:  0.18102340400218964
Epoch:  204  	Training Loss: 0.1410267949104309
Test Loss:  0.18878646194934845
Valid Loss:  0.18099525570869446
Epoch:  205  	Training Loss: 0.14100396633148193
Test Loss:  0.1887572556734085
Valid Loss:  0.1809670776128769
Epoch:  206  	Training Loss: 0.14098112285137177
Test Loss:  0.18872809410095215
Valid Loss:  0.1809389442205429
Epoch:  207  	Training Loss: 0.1409582942724228
Test Loss:  0.18869894742965698
Valid Loss:  0.18091082572937012
Epoch:  208  	Training Loss: 0.140935480594635
Test Loss:  0.18866980075836182
Valid Loss:  0.18088269233703613
Epoch:  209  	Training Loss: 0.14091268181800842
Test Loss:  0.18864066898822784
Valid Loss:  0.18085458874702454
Epoch:  210  	Training Loss: 0.14088989794254303
Test Loss:  0.18861155211925507
Valid Loss:  0.18082651495933533
Epoch:  211  	Training Loss: 0.14086711406707764
Test Loss:  0.18858246505260468
Valid Loss:  0.18079844117164612
Epoch:  212  	Training Loss: 0.14084434509277344
Test Loss:  0.18855449557304382
Valid Loss:  0.18077141046524048
Epoch:  213  	Training Loss: 0.14082249999046326
Test Loss:  0.18852654099464417
Valid Loss:  0.18074439465999603
Epoch:  214  	Training Loss: 0.14080065488815308
Test Loss:  0.1884985864162445
Valid Loss:  0.1807173639535904
Epoch:  215  	Training Loss: 0.1407787948846817
Test Loss:  0.18847063183784485
Valid Loss:  0.18069034814834595
Epoch:  216  	Training Loss: 0.14075693488121033
Test Loss:  0.18844269216060638
Valid Loss:  0.1806633472442627
Epoch:  217  	Training Loss: 0.14073508977890015
Test Loss:  0.18841475248336792
Valid Loss:  0.18063631653785706
Epoch:  218  	Training Loss: 0.14071325957775116
Test Loss:  0.18838682770729065
Valid Loss:  0.1806093156337738
 44%|████▍     | 219/500 [02:34<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:40<05:37,  1.21s/it] 45%|████▍     | 223/500 [02:40<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:40<02:52,  1.59it/s] 45%|████▌     | 227/500 [02:40<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:41<01:32,  2.93it/s] 46%|████▌     | 231/500 [02:47<05:23,  1.20s/it] 47%|████▋     | 233/500 [02:47<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:47<02:48,  1.57it/s] 47%|████▋     | 237/500 [02:48<02:03,  2.14it/s] 48%|████▊     | 239/500 [02:48<01:30,  2.88it/s] 48%|████▊     | 241/500 [02:54<05:11,  1.20s/it] 49%|████▊     | 243/500 [02:54<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:54<02:39,  1.60it/s] 49%|████▉     | 247/500 [02:55<01:55,  2.18it/s] 50%|████▉     | 249/500 [02:55<01:25,  2.94it/s] 50%|█████     | 251/500 [03:01<04:57,  1.19s/it] 51%|█████     | 253/500 [03:01<03:33,  1.16it/s] 51%|█████     | 255/500 [03:01<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:01<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:02<01:21,  2.94it/s] 52%|█████▏    | 261/500 [03:08<04:48,  1.21s/it] 53%|█████▎    | 263/500 [03:08<03:26,  1.15it/s] 53%|█████▎    | 265/500 [03:08<02:28,  1.58it/s] 53%|█████▎    | 267/500 [03:09<01:48,  2.15it/s] 54%|█████▍    | 269/500 [03:09<01:19,  2.89it/s] 54%|█████▍    | 271/500 [03:15<04:39,  1.22s/it] 55%|█████▍    | 273/500 [03:15<03:19,  1.14it/s] 55%|█████▌    | 275/500 [03:15<02:23,  1.57it/s] 55%|█████▌    | 277/500 [03:16<01:43,  2.15it/s] 56%|█████▌    | 279/500 [03:16<01:16,  2.90it/s] 56%|█████▌    | 281/500 [03:22<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:22<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:22<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:22<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:23<01:11,  2.97it/s]Epoch:  219  	Training Loss: 0.14069141447544098
Test Loss:  0.18835890293121338
Valid Loss:  0.18058231472969055
Epoch:  220  	Training Loss: 0.140669584274292
Test Loss:  0.1883309781551361
Valid Loss:  0.1805553138256073
Epoch:  221  	Training Loss: 0.140647754073143
Test Loss:  0.18830305337905884
Valid Loss:  0.18052831292152405
Epoch:  222  	Training Loss: 0.14062592387199402
Test Loss:  0.188275545835495
Valid Loss:  0.18050172924995422
Epoch:  223  	Training Loss: 0.1406044363975525
Test Loss:  0.18824803829193115
Valid Loss:  0.1804751455783844
Epoch:  224  	Training Loss: 0.14058293402194977
Test Loss:  0.1882205605506897
Valid Loss:  0.18044856190681458
Epoch:  225  	Training Loss: 0.14056146144866943
Test Loss:  0.18819305300712585
Valid Loss:  0.18042200803756714
Epoch:  226  	Training Loss: 0.1405399590730667
Test Loss:  0.1881655752658844
Valid Loss:  0.18039542436599731
Epoch:  227  	Training Loss: 0.14051848649978638
Test Loss:  0.18813806772232056
Valid Loss:  0.1803688406944275
Epoch:  228  	Training Loss: 0.14049699902534485
Test Loss:  0.1881105899810791
Valid Loss:  0.18034228682518005
Epoch:  229  	Training Loss: 0.1404755413532257
Test Loss:  0.18808311223983765
Valid Loss:  0.18031570315361023
Epoch:  230  	Training Loss: 0.14045406877994537
Test Loss:  0.1880556344985962
Valid Loss:  0.1802891492843628
Epoch:  231  	Training Loss: 0.14043259620666504
Test Loss:  0.18802815675735474
Valid Loss:  0.18026258051395416
Epoch:  232  	Training Loss: 0.1404111087322235
Test Loss:  0.18799930810928345
Valid Loss:  0.18023474514484406
Epoch:  233  	Training Loss: 0.14038856327533722
Test Loss:  0.18797045946121216
Valid Loss:  0.18020689487457275
Epoch:  234  	Training Loss: 0.14036601781845093
Test Loss:  0.18794167041778564
Valid Loss:  0.18017908930778503
Epoch:  235  	Training Loss: 0.14034348726272583
Test Loss:  0.18791285157203674
Valid Loss:  0.18015128374099731
Epoch:  236  	Training Loss: 0.14032095670700073
Test Loss:  0.18788406252861023
Valid Loss:  0.18012350797653198
Epoch:  237  	Training Loss: 0.14029845595359802
Test Loss:  0.18785527348518372
Valid Loss:  0.18009573221206665
Epoch:  238  	Training Loss: 0.1402759552001953
Test Loss:  0.18782652914524078
Valid Loss:  0.18006795644760132
Epoch:  239  	Training Loss: 0.1402534544467926
Test Loss:  0.18779776990413666
Valid Loss:  0.18004021048545837
Epoch:  240  	Training Loss: 0.14023098349571228
Test Loss:  0.18776904046535492
Valid Loss:  0.18001249432563782
Epoch:  241  	Training Loss: 0.14020851254463196
Test Loss:  0.18774032592773438
Valid Loss:  0.17998476326465607
Epoch:  242  	Training Loss: 0.14018607139587402
Test Loss:  0.18771153688430786
Valid Loss:  0.17995700240135193
Epoch:  243  	Training Loss: 0.14016355574131012
Test Loss:  0.18768277764320374
Valid Loss:  0.1799292415380478
Epoch:  244  	Training Loss: 0.1401410698890686
Test Loss:  0.1876540333032608
Valid Loss:  0.17990151047706604
Epoch:  245  	Training Loss: 0.1401185691356659
Test Loss:  0.18762531876564026
Valid Loss:  0.17987380921840668
Epoch:  246  	Training Loss: 0.14009612798690796
Test Loss:  0.18759658932685852
Valid Loss:  0.17984610795974731
Epoch:  247  	Training Loss: 0.14007367193698883
Test Loss:  0.18756790459156036
Valid Loss:  0.17981842160224915
Epoch:  248  	Training Loss: 0.1400512307882309
Test Loss:  0.1875392347574234
Valid Loss:  0.17979076504707336
Epoch:  249  	Training Loss: 0.14002880454063416
Test Loss:  0.18751057982444763
Valid Loss:  0.17976312339305878
Epoch:  250  	Training Loss: 0.1400064080953598
Test Loss:  0.18748190999031067
Valid Loss:  0.179735466837883
Epoch:  251  	Training Loss: 0.13998401165008545
Test Loss:  0.18745329976081848
Valid Loss:  0.1797078549861908
Epoch:  252  	Training Loss: 0.1399616301059723
Test Loss:  0.18742480874061584
Valid Loss:  0.17968037724494934
Epoch:  253  	Training Loss: 0.1399393379688263
Test Loss:  0.1873963475227356
Valid Loss:  0.1796528846025467
Epoch:  254  	Training Loss: 0.13991709053516388
Test Loss:  0.18736788630485535
Valid Loss:  0.17962542176246643
Epoch:  255  	Training Loss: 0.13989481329917908
Test Loss:  0.1873394250869751
Valid Loss:  0.17959792912006378
Epoch:  256  	Training Loss: 0.13987256586551666
Test Loss:  0.18731099367141724
Valid Loss:  0.17957043647766113
Epoch:  257  	Training Loss: 0.13985031843185425
Test Loss:  0.187282532453537
Valid Loss:  0.17954298853874207
Epoch:  258  	Training Loss: 0.13982808589935303
Test Loss:  0.18725410103797913
Valid Loss:  0.1795155256986618
Epoch:  259  	Training Loss: 0.1398058384656906
Test Loss:  0.18722566962242126
Valid Loss:  0.17948809266090393
Epoch:  260  	Training Loss: 0.1397836059331894
Test Loss:  0.1871972382068634
Valid Loss:  0.17946062982082367
Epoch:  261  	Training Loss: 0.13976138830184937
Test Loss:  0.18716880679130554
Valid Loss:  0.1794331967830658
Epoch:  262  	Training Loss: 0.13973915576934814
Test Loss:  0.1871410310268402
Valid Loss:  0.17940634489059448
Epoch:  263  	Training Loss: 0.13971742987632751
Test Loss:  0.18711325526237488
Valid Loss:  0.17937952280044556
Epoch:  264  	Training Loss: 0.13969573378562927
Test Loss:  0.18708549439907074
Valid Loss:  0.17935270071029663
Epoch:  265  	Training Loss: 0.13967403769493103
Test Loss:  0.1870577335357666
Valid Loss:  0.1793258786201477
Epoch:  266  	Training Loss: 0.13965235650539398
Test Loss:  0.18702998757362366
Valid Loss:  0.17929907143115997
Epoch:  267  	Training Loss: 0.13963067531585693
Test Loss:  0.1870022565126419
Valid Loss:  0.17927226424217224
Epoch:  268  	Training Loss: 0.13960900902748108
Test Loss:  0.18697452545166016
Valid Loss:  0.1792454719543457
Epoch:  269  	Training Loss: 0.13958734273910522
Test Loss:  0.1869467943906784
Valid Loss:  0.17921869456768036
Epoch:  270  	Training Loss: 0.13956567645072937
Test Loss:  0.18691909313201904
Valid Loss:  0.17919191718101501
Epoch:  271  	Training Loss: 0.13954401016235352
Test Loss:  0.18689140677452087
Valid Loss:  0.17916516959667206
Epoch:  272  	Training Loss: 0.13952237367630005
Test Loss:  0.1868644803762436
Valid Loss:  0.1791391372680664
Epoch:  273  	Training Loss: 0.13950136303901672
Test Loss:  0.1868375688791275
Valid Loss:  0.17911311984062195
Epoch:  274  	Training Loss: 0.1394803524017334
Test Loss:  0.1868106573820114
Valid Loss:  0.1790871024131775
Epoch:  275  	Training Loss: 0.13945935666561127
Test Loss:  0.18678376078605652
Valid Loss:  0.17906109988689423
Epoch:  276  	Training Loss: 0.13943836092948914
Test Loss:  0.18675684928894043
Valid Loss:  0.17903509736061096
Epoch:  277  	Training Loss: 0.1394173800945282
Test Loss:  0.18672996759414673
Valid Loss:  0.1790090799331665
Epoch:  278  	Training Loss: 0.13939638435840607
Test Loss:  0.18670307099819183
Valid Loss:  0.17898309230804443
Epoch:  279  	Training Loss: 0.13937538862228394
Test Loss:  0.18667617440223694
Valid Loss:  0.17895710468292236
Epoch:  280  	Training Loss: 0.139354407787323
Test Loss:  0.18664930760860443
Valid Loss:  0.1789311170578003
Epoch:  281  	Training Loss: 0.13933342695236206
Test Loss:  0.18662244081497192
Valid Loss:  0.17890512943267822
Epoch:  282  	Training Loss: 0.13931246101856232
Test Loss:  0.18659478425979614
Valid Loss:  0.17887839674949646
Epoch:  283  	Training Loss: 0.13929085433483124
Test Loss:  0.18656712770462036
Valid Loss:  0.17885169386863708
Epoch:  284  	Training Loss: 0.13926924765110016
Test Loss:  0.18653948605060577
Valid Loss:  0.1788249909877777
Epoch:  285  	Training Loss: 0.13924764096736908
Test Loss:  0.18651185929775238
Valid Loss:  0.17879828810691833
Epoch:  286  	Training Loss: 0.1392260640859604
Test Loss:  0.18648424744606018
Valid Loss:  0.17877161502838135
Epoch:  287  	Training Loss: 0.1392044872045517
Test Loss:  0.18645663559436798
Valid Loss:  0.17874494194984436
Epoch:  288  	Training Loss: 0.1391828954219818
Test Loss:  0.18642902374267578
Valid Loss:  0.17871826887130737
Epoch:  289  	Training Loss: 0.13916133344173431
Test Loss:  0.18640142679214478
Valid Loss:  0.17869159579277039
Epoch:  290  	Training Loss: 0.13913977146148682
Test Loss:  0.18637385964393616
Valid Loss:  0.1786649525165558
Epoch:  291  	Training Loss: 0.1391182243824005
 58%|█████▊    | 291/500 [03:29<04:07,  1.19s/it] 59%|█████▊    | 293/500 [03:29<02:56,  1.18it/s] 59%|█████▉    | 295/500 [03:29<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:29<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:29<01:07,  2.99it/s] 60%|██████    | 301/500 [03:36<03:58,  1.20s/it] 61%|██████    | 303/500 [03:36<02:49,  1.16it/s] 61%|██████    | 305/500 [03:36<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:36<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:36<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:43<03:45,  1.20s/it] 63%|██████▎   | 313/500 [03:43<02:40,  1.16it/s] 63%|██████▎   | 315/500 [03:43<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:43<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:43<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:50<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:50<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:50<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:50<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:50<00:56,  3.00it/s] 66%|██████▌   | 331/500 [03:56<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:57<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:57<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:57<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:57<00:53,  3.01it/s] 68%|██████▊   | 341/500 [04:03<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:04<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:04<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:04<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:04<00:50,  2.96it/s] 70%|███████   | 351/500 [04:10<02:58,  1.20s/it] 71%|███████   | 353/500 [04:10<02:06,  1.16it/s] 71%|███████   | 355/500 [04:11<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:11<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:11<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:18<02:51,  1.23s/it]Test Loss:  0.18634626269340515
Valid Loss:  0.1786383092403412
Epoch:  292  	Training Loss: 0.1390966773033142
Test Loss:  0.18631835281848907
Valid Loss:  0.17861132323741913
Epoch:  293  	Training Loss: 0.13907483220100403
Test Loss:  0.186290442943573
Valid Loss:  0.17858436703681946
Epoch:  294  	Training Loss: 0.13905301690101624
Test Loss:  0.18626254796981812
Valid Loss:  0.1785574108362198
Epoch:  295  	Training Loss: 0.13903123140335083
Test Loss:  0.18623465299606323
Valid Loss:  0.1785304844379425
Epoch:  296  	Training Loss: 0.13900943100452423
Test Loss:  0.18620678782463074
Valid Loss:  0.17850357294082642
Epoch:  297  	Training Loss: 0.13898764550685883
Test Loss:  0.18617893755435944
Valid Loss:  0.17847666144371033
Epoch:  298  	Training Loss: 0.1389658898115158
Test Loss:  0.18615111708641052
Valid Loss:  0.17844977974891663
Epoch:  299  	Training Loss: 0.1389441192150116
Test Loss:  0.1861233115196228
Valid Loss:  0.17842289805412292
Epoch:  300  	Training Loss: 0.13892237842082977
Test Loss:  0.18609550595283508
Valid Loss:  0.1783960461616516
Epoch:  301  	Training Loss: 0.13890065252780914
Test Loss:  0.18606771528720856
Valid Loss:  0.1783691942691803
Epoch:  302  	Training Loss: 0.1388789415359497
Test Loss:  0.18604052066802979
Valid Loss:  0.17834292352199554
Epoch:  303  	Training Loss: 0.13885772228240967
Test Loss:  0.1860133707523346
Valid Loss:  0.1783166378736496
Epoch:  304  	Training Loss: 0.13883648812770844
Test Loss:  0.18598619103431702
Valid Loss:  0.17829035222530365
Epoch:  305  	Training Loss: 0.1388152837753296
Test Loss:  0.18595901131629944
Valid Loss:  0.1782640516757965
Epoch:  306  	Training Loss: 0.13879403471946716
Test Loss:  0.18593180179595947
Valid Loss:  0.17823775112628937
Epoch:  307  	Training Loss: 0.13877281546592712
Test Loss:  0.1859046220779419
Valid Loss:  0.17821145057678223
Epoch:  308  	Training Loss: 0.1387515664100647
Test Loss:  0.18587741255760193
Valid Loss:  0.17818515002727509
Epoch:  309  	Training Loss: 0.13873031735420227
Test Loss:  0.18585021793842316
Valid Loss:  0.17815883457660675
Epoch:  310  	Training Loss: 0.13870908319950104
Test Loss:  0.185822993516922
Valid Loss:  0.17813251912593842
Epoch:  311  	Training Loss: 0.13868781924247742
Test Loss:  0.18579579889774323
Valid Loss:  0.17810620367527008
Epoch:  312  	Training Loss: 0.138666570186615
Test Loss:  0.18576829135417938
Valid Loss:  0.17807962000370026
Epoch:  313  	Training Loss: 0.13864508271217346
Test Loss:  0.18574079871177673
Valid Loss:  0.17805305123329163
Epoch:  314  	Training Loss: 0.13862361013889313
Test Loss:  0.18571330606937408
Valid Loss:  0.17802652716636658
Epoch:  315  	Training Loss: 0.1386021375656128
Test Loss:  0.18568584322929382
Valid Loss:  0.17800000309944153
Epoch:  316  	Training Loss: 0.13858070969581604
Test Loss:  0.18565839529037476
Valid Loss:  0.17797347903251648
Epoch:  317  	Training Loss: 0.1385592520236969
Test Loss:  0.1856309324502945
Valid Loss:  0.17794695496559143
Epoch:  318  	Training Loss: 0.13853780925273895
Test Loss:  0.18560349941253662
Valid Loss:  0.17792044579982758
Epoch:  319  	Training Loss: 0.138516366481781
Test Loss:  0.18557606637477875
Valid Loss:  0.1778939664363861
Epoch:  320  	Training Loss: 0.13849496841430664
Test Loss:  0.18554863333702087
Valid Loss:  0.17786748707294464
Epoch:  321  	Training Loss: 0.1384735256433487
Test Loss:  0.1855212152004242
Valid Loss:  0.17784100770950317
Epoch:  322  	Training Loss: 0.13845212757587433
Test Loss:  0.18549396097660065
Valid Loss:  0.17781466245651245
Epoch:  323  	Training Loss: 0.13843084871768951
Test Loss:  0.1854667067527771
Valid Loss:  0.17778833210468292
Epoch:  324  	Training Loss: 0.1384095549583435
Test Loss:  0.18543946743011475
Valid Loss:  0.1777620017528534
Epoch:  325  	Training Loss: 0.1383882761001587
Test Loss:  0.1854122132062912
Valid Loss:  0.17773568630218506
Epoch:  326  	Training Loss: 0.13836699724197388
Test Loss:  0.18538498878479004
Valid Loss:  0.17770935595035553
Epoch:  327  	Training Loss: 0.13834573328495026
Test Loss:  0.1853577345609665
Valid Loss:  0.177683025598526
Epoch:  328  	Training Loss: 0.13832446932792664
Test Loss:  0.18533051013946533
Valid Loss:  0.17765673995018005
Epoch:  329  	Training Loss: 0.13830320537090302
Test Loss:  0.18530327081680298
Valid Loss:  0.1776304394006729
Epoch:  330  	Training Loss: 0.1382819414138794
Test Loss:  0.1852760761976242
Valid Loss:  0.17760413885116577
Epoch:  331  	Training Loss: 0.13826069235801697
Test Loss:  0.18524885177612305
Valid Loss:  0.17757783830165863
Epoch:  332  	Training Loss: 0.13823944330215454
Test Loss:  0.1852220594882965
Valid Loss:  0.17755192518234253
Epoch:  333  	Training Loss: 0.13821852207183838
Test Loss:  0.18519526720046997
Valid Loss:  0.17752602696418762
Epoch:  334  	Training Loss: 0.1381976306438446
Test Loss:  0.18516848981380463
Valid Loss:  0.17750011384487152
Epoch:  335  	Training Loss: 0.13817670941352844
Test Loss:  0.1851416975259781
Valid Loss:  0.17747420072555542
Epoch:  336  	Training Loss: 0.13815581798553467
Test Loss:  0.18511493504047394
Valid Loss:  0.17744828760623932
Epoch:  337  	Training Loss: 0.1381349265575409
Test Loss:  0.1850881576538086
Valid Loss:  0.17742237448692322
Epoch:  338  	Training Loss: 0.13811400532722473
Test Loss:  0.18506138026714325
Valid Loss:  0.1773964911699295
Epoch:  339  	Training Loss: 0.13809311389923096
Test Loss:  0.1850346028804779
Valid Loss:  0.1773705780506134
Epoch:  340  	Training Loss: 0.13807222247123718
Test Loss:  0.18500784039497375
Valid Loss:  0.1773446947336197
Epoch:  341  	Training Loss: 0.1380513310432434
Test Loss:  0.1849810779094696
Valid Loss:  0.17731879651546478
Epoch:  342  	Training Loss: 0.13803043961524963
Test Loss:  0.18495388329029083
Valid Loss:  0.17729254066944122
Epoch:  343  	Training Loss: 0.1380092203617096
Test Loss:  0.18492671847343445
Valid Loss:  0.17726624011993408
Epoch:  344  	Training Loss: 0.13798800110816956
Test Loss:  0.18489952385425568
Valid Loss:  0.17723995447158813
Epoch:  345  	Training Loss: 0.1379667967557907
Test Loss:  0.1848723292350769
Valid Loss:  0.1772136688232422
Epoch:  346  	Training Loss: 0.13794556260108948
Test Loss:  0.18484513461589813
Valid Loss:  0.17718738317489624
Epoch:  347  	Training Loss: 0.13792434334754944
Test Loss:  0.18481795489788055
Valid Loss:  0.1771610975265503
Epoch:  348  	Training Loss: 0.1379031240940094
Test Loss:  0.18479076027870178
Valid Loss:  0.17713481187820435
Epoch:  349  	Training Loss: 0.13788187503814697
Test Loss:  0.18476355075836182
Valid Loss:  0.177108496427536
Epoch:  350  	Training Loss: 0.13786065578460693
Test Loss:  0.18473635613918304
Valid Loss:  0.17708218097686768
Epoch:  351  	Training Loss: 0.1378394216299057
Test Loss:  0.18470914661884308
Valid Loss:  0.17705588042736053
Epoch:  352  	Training Loss: 0.13781817257404327
Test Loss:  0.1846817135810852
Valid Loss:  0.17702937126159668
Epoch:  353  	Training Loss: 0.13779674470424652
Test Loss:  0.18465426564216614
Valid Loss:  0.17700287699699402
Epoch:  354  	Training Loss: 0.13777533173561096
Test Loss:  0.18462681770324707
Valid Loss:  0.17697636783123016
Epoch:  355  	Training Loss: 0.1377539187669754
Test Loss:  0.1845993995666504
Valid Loss:  0.1769498586654663
Epoch:  356  	Training Loss: 0.13773250579833984
Test Loss:  0.1845719814300537
Valid Loss:  0.17692337930202484
Epoch:  357  	Training Loss: 0.13771109282970428
Test Loss:  0.18454454839229584
Valid Loss:  0.17689688503742218
Epoch:  358  	Training Loss: 0.13768967986106873
Test Loss:  0.18451713025569916
Valid Loss:  0.1768704056739807
Epoch:  359  	Training Loss: 0.13766828179359436
Test Loss:  0.18448972702026367
Valid Loss:  0.17684394121170044
Epoch:  360  	Training Loss: 0.13764688372612
Test Loss:  0.184462308883667
Valid Loss:  0.17681744694709778
Epoch:  361  	Training Loss: 0.13762548565864563
Test Loss:  0.1844349205493927
Valid Loss:  0.1767909824848175
Epoch:  362  	Training Loss: 0.13760408759117126
Test Loss:  0.1844075471162796
Valid Loss:  0.17676453292369843
Epoch:  363  	Training Loss: 0.1375827193260193
Test Loss:  0.1843801736831665
Valid Loss:   73%|███████▎  | 363/500 [04:18<02:01,  1.13it/s] 73%|███████▎  | 365/500 [04:18<01:26,  1.56it/s] 73%|███████▎  | 367/500 [04:18<01:02,  2.14it/s] 74%|███████▍  | 369/500 [04:18<00:45,  2.89it/s] 74%|███████▍  | 371/500 [04:24<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:25<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:25<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:25<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:31<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:32<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:32<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:32<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:39<02:14,  1.23s/it] 79%|███████▊  | 393/500 [04:39<01:34,  1.13it/s] 79%|███████▉  | 395/500 [04:39<01:07,  1.56it/s] 79%|███████▉  | 397/500 [04:39<00:48,  2.13it/s] 80%|███████▉  | 399/500 [04:39<00:35,  2.87it/s] 80%|████████  | 401/500 [04:45<01:58,  1.19s/it] 81%|████████  | 403/500 [04:46<01:22,  1.17it/s] 81%|████████  | 405/500 [04:46<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:46<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:52<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:53<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:53<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:53<00:37,  2.20it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.96it/s] 84%|████████▍ | 421/500 [04:59<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.63it/s] 85%|████████▌ | 427/500 [05:00<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:00<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:06<01:25,  1.24s/it] 87%|████████▋ | 433/500 [05:07<00:59,  1.12it/s] 87%|████████▋ | 435/500 [05:07<00:42,  1.53it/s]0.17673808336257935
Epoch:  364  	Training Loss: 0.1375613510608673
Test Loss:  0.1843528151512146
Valid Loss:  0.17671164870262146
Epoch:  365  	Training Loss: 0.13753998279571533
Test Loss:  0.1843254417181015
Valid Loss:  0.17668521404266357
Epoch:  366  	Training Loss: 0.13751859962940216
Test Loss:  0.1842980831861496
Valid Loss:  0.1766587793827057
Epoch:  367  	Training Loss: 0.13749724626541138
Test Loss:  0.1842707097530365
Valid Loss:  0.1766323298215866
Epoch:  368  	Training Loss: 0.1374758929014206
Test Loss:  0.1842433512210846
Valid Loss:  0.17660591006278992
Epoch:  369  	Training Loss: 0.13745450973510742
Test Loss:  0.1842159926891327
Valid Loss:  0.17657947540283203
Epoch:  370  	Training Loss: 0.13743317127227783
Test Loss:  0.18418866395950317
Valid Loss:  0.17655307054519653
Epoch:  371  	Training Loss: 0.13741180300712585
Test Loss:  0.18416130542755127
Valid Loss:  0.17652663588523865
Epoch:  372  	Training Loss: 0.13739044964313507
Test Loss:  0.18413400650024414
Valid Loss:  0.17650027573108673
Epoch:  373  	Training Loss: 0.13736914098262787
Test Loss:  0.1841067373752594
Valid Loss:  0.17647391557693481
Epoch:  374  	Training Loss: 0.13734784722328186
Test Loss:  0.18407946825027466
Valid Loss:  0.1764475703239441
Epoch:  375  	Training Loss: 0.13732656836509705
Test Loss:  0.18405219912528992
Valid Loss:  0.17642125487327576
Epoch:  376  	Training Loss: 0.13730527460575104
Test Loss:  0.18402495980262756
Valid Loss:  0.17639493942260742
Epoch:  377  	Training Loss: 0.13728401064872742
Test Loss:  0.18399770557880402
Valid Loss:  0.17636863887310028
Epoch:  378  	Training Loss: 0.1372627317905426
Test Loss:  0.18397048115730286
Valid Loss:  0.17634230852127075
Epoch:  379  	Training Loss: 0.13724146783351898
Test Loss:  0.1839432418346405
Valid Loss:  0.1763160228729248
Epoch:  380  	Training Loss: 0.13722023367881775
Test Loss:  0.18391603231430054
Valid Loss:  0.17628972232341766
Epoch:  381  	Training Loss: 0.13719898462295532
Test Loss:  0.18388882279396057
Valid Loss:  0.1762634515762329
Epoch:  382  	Training Loss: 0.1371777355670929
Test Loss:  0.18386152386665344
Valid Loss:  0.1762370616197586
Epoch:  383  	Training Loss: 0.1371564269065857
Test Loss:  0.1838342398405075
Valid Loss:  0.1762106716632843
Epoch:  384  	Training Loss: 0.1371351182460785
Test Loss:  0.1838068962097168
Valid Loss:  0.17618423700332642
Epoch:  385  	Training Loss: 0.1371138095855713
Test Loss:  0.18377959728240967
Valid Loss:  0.17615780234336853
Epoch:  386  	Training Loss: 0.1370924711227417
Test Loss:  0.18375225365161896
Valid Loss:  0.17613136768341064
Epoch:  387  	Training Loss: 0.1370711326599121
Test Loss:  0.18372491002082825
Valid Loss:  0.17610490322113037
Epoch:  388  	Training Loss: 0.13704976439476013
Test Loss:  0.18369755148887634
Valid Loss:  0.1760784536600113
Epoch:  389  	Training Loss: 0.13702842593193054
Test Loss:  0.18367019295692444
Valid Loss:  0.17605197429656982
Epoch:  390  	Training Loss: 0.13700705766677856
Test Loss:  0.18364278972148895
Valid Loss:  0.17602548003196716
Epoch:  391  	Training Loss: 0.1369856745004654
Test Loss:  0.18361540138721466
Valid Loss:  0.1759989857673645
Epoch:  392  	Training Loss: 0.13696429133415222
Test Loss:  0.18358850479125977
Valid Loss:  0.17597299814224243
Epoch:  393  	Training Loss: 0.13694331049919128
Test Loss:  0.18356162309646606
Valid Loss:  0.17594701051712036
Epoch:  394  	Training Loss: 0.13692232966423035
Test Loss:  0.18353474140167236
Valid Loss:  0.17592103779315948
Epoch:  395  	Training Loss: 0.1369013488292694
Test Loss:  0.18350784480571747
Valid Loss:  0.1758950650691986
Epoch:  396  	Training Loss: 0.13688036799430847
Test Loss:  0.18348097801208496
Valid Loss:  0.17586910724639893
Epoch:  397  	Training Loss: 0.13685940206050873
Test Loss:  0.18345409631729126
Valid Loss:  0.17584313452243805
Epoch:  398  	Training Loss: 0.13683843612670898
Test Loss:  0.18342721462249756
Valid Loss:  0.17581716179847717
Epoch:  399  	Training Loss: 0.13681748509407043
Test Loss:  0.18340036273002625
Valid Loss:  0.17579121887683868
Epoch:  400  	Training Loss: 0.1367965191602707
Test Loss:  0.18337349593639374
Valid Loss:  0.1757652461528778
Epoch:  401  	Training Loss: 0.13677556812763214
Test Loss:  0.18334664404392242
Valid Loss:  0.1757393181324005
Epoch:  402  	Training Loss: 0.1367546021938324
Test Loss:  0.18331973254680634
Valid Loss:  0.17571330070495605
Epoch:  403  	Training Loss: 0.13673362135887146
Test Loss:  0.18329283595085144
Valid Loss:  0.17568731307983398
Epoch:  404  	Training Loss: 0.13671262562274933
Test Loss:  0.18326595425605774
Valid Loss:  0.17566132545471191
Epoch:  405  	Training Loss: 0.13669165968894958
Test Loss:  0.18323904275894165
Valid Loss:  0.17563533782958984
Epoch:  406  	Training Loss: 0.13667064905166626
Test Loss:  0.18321217596530914
Valid Loss:  0.17560932040214539
Epoch:  407  	Training Loss: 0.1366496980190277
Test Loss:  0.18318527936935425
Valid Loss:  0.1755833625793457
Epoch:  408  	Training Loss: 0.13662871718406677
Test Loss:  0.18315839767456055
Valid Loss:  0.17555737495422363
Epoch:  409  	Training Loss: 0.13660773634910583
Test Loss:  0.18313153088092804
Valid Loss:  0.17553141713142395
Epoch:  410  	Training Loss: 0.1365867555141449
Test Loss:  0.18310466408729553
Valid Loss:  0.17550542950630188
Epoch:  411  	Training Loss: 0.13656580448150635
Test Loss:  0.18307778239250183
Valid Loss:  0.1754794716835022
Epoch:  412  	Training Loss: 0.1365448385477066
Test Loss:  0.18305066227912903
Valid Loss:  0.1754532754421234
Epoch:  413  	Training Loss: 0.13652369379997253
Test Loss:  0.1830235719680786
Valid Loss:  0.17542710900306702
Epoch:  414  	Training Loss: 0.13650253415107727
Test Loss:  0.182996466755867
Valid Loss:  0.17540091276168823
Epoch:  415  	Training Loss: 0.1364813894033432
Test Loss:  0.1829693615436554
Valid Loss:  0.17537473142147064
Epoch:  416  	Training Loss: 0.13646022975444794
Test Loss:  0.18294227123260498
Valid Loss:  0.17534857988357544
Epoch:  417  	Training Loss: 0.13643909990787506
Test Loss:  0.18291521072387695
Valid Loss:  0.17532241344451904
Epoch:  418  	Training Loss: 0.136417955160141
Test Loss:  0.18288812041282654
Valid Loss:  0.17529624700546265
Epoch:  419  	Training Loss: 0.13639682531356812
Test Loss:  0.18286103010177612
Valid Loss:  0.17527009546756744
Epoch:  420  	Training Loss: 0.13637569546699524
Test Loss:  0.1828339546918869
Valid Loss:  0.17524395883083344
Epoch:  421  	Training Loss: 0.13635456562042236
Test Loss:  0.18280689418315887
Valid Loss:  0.17521782219409943
Epoch:  422  	Training Loss: 0.1363334357738495
Test Loss:  0.18277987837791443
Valid Loss:  0.175191730260849
Epoch:  423  	Training Loss: 0.1363123655319214
Test Loss:  0.18275290727615356
Valid Loss:  0.17516565322875977
Epoch:  424  	Training Loss: 0.1362912952899933
Test Loss:  0.1827259063720703
Valid Loss:  0.17513957619667053
Epoch:  425  	Training Loss: 0.13627025485038757
Test Loss:  0.18269892036914825
Valid Loss:  0.1751135140657425
Epoch:  426  	Training Loss: 0.13624918460845947
Test Loss:  0.1826719492673874
Valid Loss:  0.17508748173713684
Epoch:  427  	Training Loss: 0.13622814416885376
Test Loss:  0.18264496326446533
Valid Loss:  0.1750614047050476
Epoch:  428  	Training Loss: 0.13620708882808685
Test Loss:  0.18261799216270447
Valid Loss:  0.17503535747528076
Epoch:  429  	Training Loss: 0.13618604838848114
Test Loss:  0.1825910359621048
Valid Loss:  0.17500931024551392
Epoch:  430  	Training Loss: 0.13616500794887543
Test Loss:  0.18256407976150513
Valid Loss:  0.17498327791690826
Epoch:  431  	Training Loss: 0.13614396750926971
Test Loss:  0.18253713846206665
Valid Loss:  0.1749572604894638
Epoch:  432  	Training Loss: 0.1361229419708252
Test Loss:  0.18251025676727295
Valid Loss:  0.17493131756782532
Epoch:  433  	Training Loss: 0.13610197603702545
Test Loss:  0.18248337507247925
Valid Loss:  0.17490535974502563
Epoch:  434  	Training Loss: 0.1360810101032257
Test Loss:  0.18245652318000793
Valid Loss:  0.17487946152687073
Epoch:  435  	Training Loss: 0.13606005907058716
Test Loss:  0.18242967128753662
Valid Loss:  0.17485353350639343
 87%|████████▋ | 437/500 [05:07<00:30,  2.07it/s] 88%|████████▊ | 439/500 [05:07<00:21,  2.78it/s] 88%|████████▊ | 441/500 [05:13<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:14<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:14<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:14<00:24,  2.20it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:20<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:21<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:21<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:21<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:27<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:28<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:28<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:28<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:34<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:34<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:35<00:15,  1.58it/s] 95%|█████████▌| 477/500 [05:35<00:10,  2.15it/s] 96%|█████████▌| 479/500 [05:35<00:07,  2.89it/s] 96%|█████████▌| 481/500 [05:41<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:42<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:42<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:42<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:48<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:48<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:49<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:49<00:00,  2.97it/s]100%|██████████| 500/500 [05:49<00:00,  1.43it/s]
Epoch:  436  	Training Loss: 0.1360391080379486
Test Loss:  0.1824028640985489
Valid Loss:  0.1748276650905609
Epoch:  437  	Training Loss: 0.13601818680763245
Test Loss:  0.18237604200839996
Valid Loss:  0.174801766872406
Epoch:  438  	Training Loss: 0.13599726557731628
Test Loss:  0.18234923481941223
Valid Loss:  0.17477592825889587
Epoch:  439  	Training Loss: 0.1359763741493225
Test Loss:  0.1823224574327469
Valid Loss:  0.17475007474422455
Epoch:  440  	Training Loss: 0.13595548272132874
Test Loss:  0.18229568004608154
Valid Loss:  0.17472422122955322
Epoch:  441  	Training Loss: 0.13593459129333496
Test Loss:  0.18226894736289978
Valid Loss:  0.17469841241836548
Epoch:  442  	Training Loss: 0.13591372966766357
Test Loss:  0.18224206566810608
Valid Loss:  0.1746724545955658
Epoch:  443  	Training Loss: 0.13589276373386383
Test Loss:  0.18221522867679596
Valid Loss:  0.1746464967727661
Epoch:  444  	Training Loss: 0.13587182760238647
Test Loss:  0.18218839168548584
Valid Loss:  0.17462056875228882
Epoch:  445  	Training Loss: 0.13585084676742554
Test Loss:  0.18216150999069214
Valid Loss:  0.17459462583065033
Epoch:  446  	Training Loss: 0.13582992553710938
Test Loss:  0.1821346879005432
Valid Loss:  0.17456871271133423
Epoch:  447  	Training Loss: 0.13580895960330963
Test Loss:  0.1821078658103943
Valid Loss:  0.17454278469085693
Epoch:  448  	Training Loss: 0.13578802347183228
Test Loss:  0.18208104372024536
Valid Loss:  0.17451687157154083
Epoch:  449  	Training Loss: 0.1357671022415161
Test Loss:  0.18205420672893524
Valid Loss:  0.17449095845222473
Epoch:  450  	Training Loss: 0.13574618101119995
Test Loss:  0.1820273995399475
Valid Loss:  0.17446506023406982
Epoch:  451  	Training Loss: 0.1357252597808838
Test Loss:  0.18200060725212097
Valid Loss:  0.17443916201591492
Epoch:  452  	Training Loss: 0.13570433855056763
Test Loss:  0.18197406828403473
Valid Loss:  0.1744135320186615
Epoch:  453  	Training Loss: 0.13568365573883057
Test Loss:  0.18194755911827087
Valid Loss:  0.17438790202140808
Epoch:  454  	Training Loss: 0.1356629729270935
Test Loss:  0.18192102015018463
Valid Loss:  0.17436225712299347
Epoch:  455  	Training Loss: 0.13564227521419525
Test Loss:  0.18189451098442078
Valid Loss:  0.17433664202690125
Epoch:  456  	Training Loss: 0.13562160730361938
Test Loss:  0.18186801671981812
Valid Loss:  0.17431104183197021
Epoch:  457  	Training Loss: 0.13560092449188232
Test Loss:  0.18184149265289307
Valid Loss:  0.174285426735878
Epoch:  458  	Training Loss: 0.13558025658130646
Test Loss:  0.1818149983882904
Valid Loss:  0.17425981163978577
Epoch:  459  	Training Loss: 0.1355595886707306
Test Loss:  0.18178851902484894
Valid Loss:  0.17423422634601593
Epoch:  460  	Training Loss: 0.13553892076015472
Test Loss:  0.18176203966140747
Valid Loss:  0.1742086112499237
Epoch:  461  	Training Loss: 0.13551826775074005
Test Loss:  0.1817355453968048
Valid Loss:  0.17418304085731506
Epoch:  462  	Training Loss: 0.13549761474132538
Test Loss:  0.18170872330665588
Valid Loss:  0.17415711283683777
Epoch:  463  	Training Loss: 0.1354767084121704
Test Loss:  0.18168191611766815
Valid Loss:  0.17413118481636047
Epoch:  464  	Training Loss: 0.13545578718185425
Test Loss:  0.18165509402751923
Valid Loss:  0.17410524189472198
Epoch:  465  	Training Loss: 0.13543486595153809
Test Loss:  0.1816282719373703
Valid Loss:  0.17407932877540588
Epoch:  466  	Training Loss: 0.13541394472122192
Test Loss:  0.18160143494606018
Valid Loss:  0.1740533709526062
Epoch:  467  	Training Loss: 0.13539302349090576
Test Loss:  0.18157462775707245
Valid Loss:  0.1740274429321289
Epoch:  468  	Training Loss: 0.1353721022605896
Test Loss:  0.18154779076576233
Valid Loss:  0.1740015149116516
Epoch:  469  	Training Loss: 0.13535118103027344
Test Loss:  0.1815209537744522
Valid Loss:  0.17397555708885193
Epoch:  470  	Training Loss: 0.13533025979995728
Test Loss:  0.1814941167831421
Valid Loss:  0.17394961416721344
Epoch:  471  	Training Loss: 0.1353093385696411
Test Loss:  0.18146727979183197
Valid Loss:  0.17392368614673615
Epoch:  472  	Training Loss: 0.13528841733932495
Test Loss:  0.18144011497497559
Valid Loss:  0.1738974153995514
Epoch:  473  	Training Loss: 0.1352672278881073
Test Loss:  0.1814129650592804
Valid Loss:  0.17387115955352783
Epoch:  474  	Training Loss: 0.13524603843688965
Test Loss:  0.1813858151435852
Valid Loss:  0.17384487390518188
Epoch:  475  	Training Loss: 0.135224848985672
Test Loss:  0.18135863542556763
Valid Loss:  0.17381861805915833
Epoch:  476  	Training Loss: 0.13520365953445435
Test Loss:  0.18133147060871124
Valid Loss:  0.17379234731197357
Epoch:  477  	Training Loss: 0.1351824700832367
Test Loss:  0.18130427598953247
Valid Loss:  0.17376607656478882
Epoch:  478  	Training Loss: 0.13516126573085785
Test Loss:  0.1812770962715149
Valid Loss:  0.17373980581760406
Epoch:  479  	Training Loss: 0.1351400762796402
Test Loss:  0.1812499314546585
Valid Loss:  0.1737135350704193
Epoch:  480  	Training Loss: 0.13511887192726135
Test Loss:  0.18122273683547974
Valid Loss:  0.17368724942207336
Epoch:  481  	Training Loss: 0.1350976824760437
Test Loss:  0.18119555711746216
Valid Loss:  0.17366094887256622
Epoch:  482  	Training Loss: 0.13507646322250366
Test Loss:  0.18116801977157593
Valid Loss:  0.17363432049751282
Epoch:  483  	Training Loss: 0.13505499064922333
Test Loss:  0.1811404824256897
Valid Loss:  0.17360764741897583
Epoch:  484  	Training Loss: 0.135033518075943
Test Loss:  0.18111295998096466
Valid Loss:  0.17358100414276123
Epoch:  485  	Training Loss: 0.13501203060150146
Test Loss:  0.18108542263507843
Valid Loss:  0.17355436086654663
Epoch:  486  	Training Loss: 0.13499054312705994
Test Loss:  0.1810578554868698
Valid Loss:  0.17352768778800964
Epoch:  487  	Training Loss: 0.1349690556526184
Test Loss:  0.1810303032398224
Valid Loss:  0.17350101470947266
Epoch:  488  	Training Loss: 0.13494755327701569
Test Loss:  0.18100275099277496
Valid Loss:  0.17347432672977448
Epoch:  489  	Training Loss: 0.13492605090141296
Test Loss:  0.18097516894340515
Valid Loss:  0.1734476387500763
Epoch:  490  	Training Loss: 0.13490454852581024
Test Loss:  0.18094760179519653
Valid Loss:  0.17342093586921692
Epoch:  491  	Training Loss: 0.13488303124904633
Test Loss:  0.18092001974582672
Valid Loss:  0.17339424788951874
Epoch:  492  	Training Loss: 0.1348615139722824
Test Loss:  0.18089309334754944
Valid Loss:  0.17336824536323547
Epoch:  493  	Training Loss: 0.13484053313732147
Test Loss:  0.18086621165275574
Valid Loss:  0.17334222793579102
Epoch:  494  	Training Loss: 0.13481955230236053
Test Loss:  0.18083930015563965
Valid Loss:  0.17331624031066895
Epoch:  495  	Training Loss: 0.1347985863685608
Test Loss:  0.18081240355968475
Valid Loss:  0.17329023778438568
Epoch:  496  	Training Loss: 0.13477760553359985
Test Loss:  0.18078550696372986
Valid Loss:  0.1732642650604248
Epoch:  497  	Training Loss: 0.13475662469863892
Test Loss:  0.18075862526893616
Valid Loss:  0.17323824763298035
Epoch:  498  	Training Loss: 0.13473565876483917
Test Loss:  0.18073174357414246
Valid Loss:  0.17321228981018066
Epoch:  499  	Training Loss: 0.13471469283103943
Test Loss:  0.18070487678050995
Valid Loss:  0.1731863021850586
Epoch:  500  	Training Loss: 0.13469374179840088
Test Loss:  0.18067802488803864
Valid Loss:  0.1731603443622589
seed is  3
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:13,  6.28s/it]  1%|          | 3/500 [00:06<13:52,  1.68s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:47,  2.88it/s]  4%|▍         | 21/500 [00:20<09:59,  1.25s/it]  5%|▍         | 23/500 [00:20<07:04,  1.12it/s]  5%|▌         | 25/500 [00:20<05:03,  1.56it/s]  5%|▌         | 27/500 [00:20<03:40,  2.15it/s]  6%|▌         | 29/500 [00:20<02:42,  2.90it/s]  6%|▌         | 31/500 [00:27<09:23,  1.20s/it]  7%|▋         | 33/500 [00:27<06:43,  1.16it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:33,  2.17it/s]  8%|▊         | 39/500 [00:27<02:40,  2.87it/s]  8%|▊         | 41/500 [00:34<09:33,  1.25s/it]  9%|▊         | 43/500 [00:34<06:49,  1.12it/s]  9%|▉         | 45/500 [00:34<04:54,  1.54it/s]  9%|▉         | 47/500 [00:34<03:34,  2.11it/s] 10%|▉         | 49/500 [00:35<02:38,  2.84it/s] 10%|▉         | 49/500 [00:46<02:38,  2.84it/s] 10%|█         | 51/500 [00:47<16:10,  2.16s/it] 11%|█         | 53/500 [00:48<11:25,  1.53s/it] 11%|█         | 55/500 [00:48<08:06,  1.09s/it] 11%|█▏        | 57/500 [00:48<05:47,  1.28it/s] 12%|█▏        | 59/500 [00:48<04:10,  1.76it/s] 12%|█▏        | 61/500 [00:54<10:05,  1.38s/it] 13%|█▎        | 63/500 [00:55<07:10,  1.02it/s] 13%|█▎        | 65/500 [00:55<05:08,  1.41it/s] 13%|█▎        | 67/500 [00:55<03:43,  1.94it/s] 14%|█▍        | 69/500 [00:55<02:44,  2.63it/s]Epoch:  1  	Training Loss: 0.09565693140029907
Test Loss:  5.10849666595459
Valid Loss:  5.081876277923584
Epoch:  2  	Training Loss: 4.738849639892578
Test Loss:  118.83393096923828
Valid Loss:  112.25468444824219
Epoch:  3  	Training Loss: 114.04509735107422
Test Loss:  0.12992222607135773
Valid Loss:  0.20036116242408752
Epoch:  4  	Training Loss: 0.32200613617897034
Test Loss:  0.1088547632098198
Valid Loss:  0.1794804036617279
Epoch:  5  	Training Loss: 0.2932727336883545
Test Loss:  0.09609508514404297
Valid Loss:  0.1652364432811737
Epoch:  6  	Training Loss: 0.27492523193359375
Test Loss:  0.08658144623041153
Valid Loss:  0.15440267324447632
Epoch:  7  	Training Loss: 0.26117146015167236
Test Loss:  0.0789443850517273
Valid Loss:  0.1458246260881424
Epoch:  8  	Training Loss: 0.2504238784313202
Test Loss:  0.07278904318809509
Valid Loss:  0.13862484693527222
Epoch:  9  	Training Loss: 0.241397887468338
Test Loss:  0.06760182976722717
Valid Loss:  0.1324554681777954
Epoch:  10  	Training Loss: 0.23363414406776428
Test Loss:  0.06322623044252396
Valid Loss:  0.12715685367584229
Epoch:  11  	Training Loss: 0.226944699883461
Test Loss:  0.05955585092306137
Valid Loss:  0.12249116599559784
Epoch:  12  	Training Loss: 0.22107505798339844
Test Loss:  3.2159223556518555
Valid Loss:  2.781219482421875
Epoch:  13  	Training Loss: 3.006869316101074
Test Loss:  1.7752082347869873
Valid Loss:  2.0670382976531982
Epoch:  14  	Training Loss: 1.5271120071411133
Test Loss:  0.06470051407814026
Valid Loss:  0.1169036254286766
Epoch:  15  	Training Loss: 0.17513929307460785
Test Loss:  0.037184618413448334
Valid Loss:  0.07896456867456436
Epoch:  16  	Training Loss: 0.14380832016468048
Test Loss:  0.036686673760414124
Valid Loss:  0.07713797688484192
Epoch:  17  	Training Loss: 0.14089134335517883
Test Loss:  0.03556246683001518
Valid Loss:  0.07457828521728516
Epoch:  18  	Training Loss: 0.1373162865638733
Test Loss:  0.03533485531806946
Valid Loss:  0.0735154002904892
Epoch:  19  	Training Loss: 0.1357969045639038
Test Loss:  0.03519761189818382
Valid Loss:  0.07327292859554291
Epoch:  20  	Training Loss: 0.1355498731136322
Test Loss:  0.035136785358190536
Valid Loss:  0.07315641641616821
Epoch:  21  	Training Loss: 0.1353977471590042
Test Loss:  0.035105738788843155
Valid Loss:  0.07308479398488998
Epoch:  22  	Training Loss: 0.13527905941009521
Test Loss:  0.03443344682455063
Valid Loss:  0.07009115815162659
Epoch:  23  	Training Loss: 0.12772385776042938
Test Loss:  0.03040594980120659
Valid Loss:  0.05976451188325882
Epoch:  24  	Training Loss: 0.10339221358299255
Test Loss:  0.014642748050391674
Valid Loss:  0.02734561823308468
Epoch:  25  	Training Loss: 0.05168411135673523
Test Loss:  0.01161296758800745
Valid Loss:  0.015561014413833618
Epoch:  26  	Training Loss: 0.030479080975055695
Test Loss:  0.013043873943388462
Valid Loss:  0.01402554102241993
Epoch:  27  	Training Loss: 0.027018502354621887
Test Loss:  0.011560887098312378
Valid Loss:  0.013003717176616192
Epoch:  28  	Training Loss: 0.02507437765598297
Test Loss:  0.011091366410255432
Valid Loss:  0.012495813891291618
Epoch:  29  	Training Loss: 0.023696530610322952
Test Loss:  0.009835057891905308
Valid Loss:  0.012214986607432365
Epoch:  30  	Training Loss: 0.02264558896422386
Test Loss:  0.010458792559802532
Valid Loss:  0.011970093473792076
Epoch:  31  	Training Loss: 0.02154884859919548
Test Loss:  0.010163949802517891
Valid Loss:  0.011756964959204197
Epoch:  32  	Training Loss: 0.020681682974100113
Test Loss:  0.010453103110194206
Valid Loss:  0.011374695226550102
Epoch:  33  	Training Loss: 0.020099205896258354
Test Loss:  0.009282056242227554
Valid Loss:  0.011146057397127151
Epoch:  34  	Training Loss: 0.019603069871664047
Test Loss:  0.009487820789217949
Valid Loss:  0.010766427963972092
Epoch:  35  	Training Loss: 0.018926195800304413
Test Loss:  0.009439505636692047
Valid Loss:  0.010474437847733498
Epoch:  36  	Training Loss: 0.01837145909667015
Test Loss:  0.009290991351008415
Valid Loss:  0.010212907567620277
Epoch:  37  	Training Loss: 0.01786092296242714
Test Loss:  0.009125549346208572
Valid Loss:  0.009991483762860298
Epoch:  38  	Training Loss: 0.01740517094731331
Test Loss:  0.008958790451288223
Valid Loss:  0.009794912301003933
Epoch:  39  	Training Loss: 0.017012786120176315
Test Loss:  0.008107248693704605
Valid Loss:  0.009664502926170826
Epoch:  40  	Training Loss: 0.01676824316382408
Test Loss:  0.00840449146926403
Valid Loss:  0.00944928452372551
Epoch:  41  	Training Loss: 0.016347523778676987
Test Loss:  0.008429289795458317
Valid Loss:  0.00928431935608387
Epoch:  42  	Training Loss: 0.016006849706172943
Test Loss:  0.008893096819519997
Valid Loss:  0.009056026116013527
Epoch:  43  	Training Loss: 0.014868403784930706
Test Loss:  0.00769247580319643
Valid Loss:  0.008950083516538143
Epoch:  44  	Training Loss: 0.014502370730042458
Test Loss:  0.009107647463679314
Valid Loss:  0.008877342566847801
Epoch:  45  	Training Loss: 0.0141699044033885
Test Loss:  0.007154701743274927
Valid Loss:  0.008901785127818584
Epoch:  46  	Training Loss: 0.01387184951454401
Test Loss:  0.009748157113790512
Valid Loss:  0.00887057650834322
Epoch:  47  	Training Loss: 0.013818689621984959
Test Loss:  0.006330164615064859
Valid Loss:  0.010419221594929695
Epoch:  48  	Training Loss: 0.014915971085429192
Test Loss:  0.015431562438607216
Valid Loss:  0.011106436140835285
Epoch:  49  	Training Loss: 0.01611318439245224
Test Loss:  0.007829852402210236
Valid Loss:  0.014518219977617264
Epoch:  50  	Training Loss: 0.018220506608486176
Test Loss:  0.008922649547457695
Valid Loss:  0.008433429524302483
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.012918507680296898
Test Loss:  0.008249275386333466
Valid Loss:  0.008322765119373798
Epoch:  52  	Training Loss: 0.012548918835818768
Test Loss:  0.007730111479759216
Valid Loss:  0.009027555584907532
Epoch:  53  	Training Loss: 0.01107536256313324
Test Loss:  0.009331725537776947
Valid Loss:  0.008040199987590313
Epoch:  54  	Training Loss: 0.010976588353514671
Test Loss:  0.007715930230915546
Valid Loss:  0.009741893038153648
Epoch:  55  	Training Loss: 0.010732638649642467
Test Loss:  0.008221768774092197
Valid Loss:  0.00702859228476882
Epoch:  56  	Training Loss: 0.009651281870901585
Test Loss:  0.006970338523387909
Valid Loss:  0.0076424190774559975
Epoch:  57  	Training Loss: 0.009198538027703762
Test Loss:  0.0076533532701432705
Valid Loss:  0.006258632056415081
Epoch:  58  	Training Loss: 0.00881035253405571
Test Loss:  0.006282199174165726
Valid Loss:  0.0069343894720077515
Epoch:  59  	Training Loss: 0.008471157401800156
Test Loss:  0.007084250450134277
Valid Loss:  0.005572083406150341
Epoch:  60  	Training Loss: 0.008170423097908497
Test Loss:  0.005704356823116541
Valid Loss:  0.006361879408359528
Epoch:  61  	Training Loss: 0.007883286103606224
Test Loss:  0.00656253844499588
Valid Loss:  0.005127598997205496
Epoch:  62  	Training Loss: 0.0076536452397704124
Test Loss:  0.006478377617895603
Valid Loss:  0.010526897385716438
Epoch:  63  	Training Loss: 0.011798679828643799
Test Loss:  0.016839947551488876
Valid Loss:  0.010192228481173515
Epoch:  64  	Training Loss: 0.01505074929445982
Test Loss:  0.005997992120683193
Valid Loss:  0.004880495369434357
Epoch:  65  	Training Loss: 0.007160831242799759
Test Loss:  0.0050945463590323925
Valid Loss:  0.005142441485077143
Epoch:  66  	Training Loss: 0.006623109802603722
Test Loss:  0.00492874626070261
Valid Loss:  0.004810711834579706
Epoch:  67  	Training Loss: 0.006436045281589031
Test Loss:  0.004895708058029413
Valid Loss:  0.004670452326536179
Epoch:  68  	Training Loss: 0.0063831740990281105
Test Loss:  0.004913615994155407
Valid Loss:  0.004948384128510952
Epoch:  69  	Training Loss: 0.006437120959162712
Test Loss:  0.004769687075167894
Valid Loss:  0.0046374378725886345
Epoch:  70  	Training Loss: 0.006264850497245789
Test Loss:  0.004725589416921139
Valid Loss:  0.00451855082064867
 14%|█▍        | 69/500 [01:06<02:44,  2.63it/s] 14%|█▍        | 71/500 [01:08<15:47,  2.21s/it] 15%|█▍        | 73/500 [01:08<11:11,  1.57s/it] 15%|█▌        | 75/500 [01:08<07:59,  1.13s/it] 15%|█▌        | 77/500 [01:08<05:43,  1.23it/s] 16%|█▌        | 79/500 [01:09<04:07,  1.70it/s] 16%|█▌        | 81/500 [01:15<09:36,  1.38s/it] 17%|█▋        | 83/500 [01:15<06:53,  1.01it/s] 17%|█▋        | 85/500 [01:15<04:58,  1.39it/s] 17%|█▋        | 87/500 [01:15<03:38,  1.89it/s] 18%|█▊        | 89/500 [01:16<02:40,  2.57it/s] 18%|█▊        | 91/500 [01:22<08:27,  1.24s/it] 19%|█▊        | 93/500 [01:22<06:02,  1.12it/s] 19%|█▉        | 95/500 [01:22<04:20,  1.56it/s] 19%|█▉        | 97/500 [01:22<03:09,  2.13it/s] 20%|█▉        | 99/500 [01:23<02:19,  2.87it/s] 20%|██        | 101/500 [01:29<07:53,  1.19s/it] 21%|██        | 103/500 [01:29<05:38,  1.17it/s] 21%|██        | 105/500 [01:29<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:29<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:29<02:11,  2.96it/s] 22%|██▏       | 111/500 [01:36<07:47,  1.20s/it] 23%|██▎       | 113/500 [01:36<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:36<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:36<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:36<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:43<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:43<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:43<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:43<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:43<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:50<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:50<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:50<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:50<02:42,  2.23it/s]**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.006207874044775963
Test Loss:  0.004687921144068241
Valid Loss:  0.004484758246690035
Epoch:  72  	Training Loss: 0.006197858601808548
Test Loss:  0.004677237011492252
Valid Loss:  0.004450613632798195
Epoch:  73  	Training Loss: 0.006180574186146259
Test Loss:  0.004657940939068794
Valid Loss:  0.004424085840582848
Epoch:  74  	Training Loss: 0.006163069978356361
Test Loss:  0.0046382928267121315
Valid Loss:  0.004399971570819616
Epoch:  75  	Training Loss: 0.006145070306956768
Test Loss:  0.004619105719029903
Valid Loss:  0.004377561621367931
Epoch:  76  	Training Loss: 0.006127051543444395
Test Loss:  0.004600868560373783
Valid Loss:  0.00435648811981082
Epoch:  77  	Training Loss: 0.006108387839049101
Test Loss:  0.004583248868584633
Valid Loss:  0.004336737096309662
Epoch:  78  	Training Loss: 0.006087977439165115
Test Loss:  0.00456603616476059
Valid Loss:  0.00431821821257472
Epoch:  79  	Training Loss: 0.006066963542252779
Test Loss:  0.004549358040094376
Valid Loss:  0.004300757311284542
Epoch:  80  	Training Loss: 0.0060427021235227585
Test Loss:  0.004532599821686745
Valid Loss:  0.004284418188035488
Epoch:  81  	Training Loss: 0.006017373874783516
Test Loss:  0.004515934735536575
Valid Loss:  0.0042688981629908085
Epoch:  82  	Training Loss: 0.0059885201044380665
Test Loss:  0.0045097703114151955
Valid Loss:  0.0042708562687039375
Epoch:  83  	Training Loss: 0.005988379009068012
Test Loss:  0.004505160730332136
Valid Loss:  0.0042723421938717365
Epoch:  84  	Training Loss: 0.005988289602100849
Test Loss:  0.004501712508499622
Valid Loss:  0.004273467231541872
Epoch:  85  	Training Loss: 0.0059882295317947865
Test Loss:  0.0044991327449679375
Valid Loss:  0.004274314269423485
Epoch:  86  	Training Loss: 0.005988183431327343
Test Loss:  0.004497198387980461
Valid Loss:  0.004274954088032246
Epoch:  87  	Training Loss: 0.005988148506730795
Test Loss:  0.004495744593441486
Valid Loss:  0.00427543418481946
Epoch:  88  	Training Loss: 0.005988116376101971
Test Loss:  0.004494655877351761
Valid Loss:  0.004275794606655836
Epoch:  89  	Training Loss: 0.0059880902990698814
Test Loss:  0.004493835382163525
Valid Loss:  0.004276065155863762
Epoch:  90  	Training Loss: 0.0059880646876990795
Test Loss:  0.004493220709264278
Valid Loss:  0.004276265390217304
Epoch:  91  	Training Loss: 0.005988039076328278
Test Loss:  0.004492754582315683
Valid Loss:  0.0042764171957969666
Epoch:  92  	Training Loss: 0.005988015793263912
Test Loss:  0.004548872821033001
Valid Loss:  0.004227879922837019
Epoch:  93  	Training Loss: 0.00584023492410779
Test Loss:  0.0045266589149832726
Valid Loss:  0.004215991590172052
Epoch:  94  	Training Loss: 0.0057222479954361916
Test Loss:  0.004489080980420113
Valid Loss:  0.004215945024043322
Epoch:  95  	Training Loss: 0.0056023551151156425
Test Loss:  0.004356608260422945
Valid Loss:  0.0042157722637057304
Epoch:  96  	Training Loss: 0.0053917597979307175
Test Loss:  0.004343170672655106
Valid Loss:  0.004334925673902035
Epoch:  97  	Training Loss: 0.0053021167404949665
Test Loss:  0.004332303535193205
Valid Loss:  0.0042064739391207695
Epoch:  98  	Training Loss: 0.0051871538162231445
Test Loss:  0.004319502040743828
Valid Loss:  0.004136959090828896
Epoch:  99  	Training Loss: 0.005105772987008095
Test Loss:  0.004294471815228462
Valid Loss:  0.004121583420783281
Epoch:  100  	Training Loss: 0.005025685299187899
Test Loss:  0.004263368900865316
Valid Loss:  0.004061291925609112
Epoch:  101  	Training Loss: 0.00494417455047369
Test Loss:  0.004226050805300474
Valid Loss:  0.004043156281113625
Epoch:  102  	Training Loss: 0.004860984161496162
Test Loss:  0.004017767962068319
Valid Loss:  0.00400584377348423
Epoch:  103  	Training Loss: 0.004779784940183163
Test Loss:  0.0039040164556354284
Valid Loss:  0.004000956192612648
Epoch:  104  	Training Loss: 0.0047396207228302956
Test Loss:  0.0038395067676901817
Valid Loss:  0.003937281668186188
Epoch:  105  	Training Loss: 0.004706316161900759
Test Loss:  0.00378145813010633
Valid Loss:  0.0039193034172058105
Epoch:  106  	Training Loss: 0.004678073804825544
Test Loss:  0.003747828770428896
Valid Loss:  0.0038670855574309826
Epoch:  107  	Training Loss: 0.0046554021537303925
Test Loss:  0.003710606601089239
Valid Loss:  0.003845436032861471
Epoch:  108  	Training Loss: 0.004635591525584459
Test Loss:  0.0036879738327115774
Valid Loss:  0.0037974505685269833
Epoch:  109  	Training Loss: 0.00462004728615284
Test Loss:  0.003658530069515109
Valid Loss:  0.0037818464916199446
Epoch:  110  	Training Loss: 0.004607371054589748
Test Loss:  0.0036417676601558924
Valid Loss:  0.0037359551060944796
Epoch:  111  	Training Loss: 0.00459635304287076
Test Loss:  0.003617465030401945
Valid Loss:  0.0037269005551934242
Epoch:  112  	Training Loss: 0.004586995579302311
Test Loss:  0.0035787560045719147
Valid Loss:  0.003660165471956134
Epoch:  113  	Training Loss: 0.004560650326311588
Test Loss:  0.0035432763397693634
Valid Loss:  0.0036010867916047573
Epoch:  114  	Training Loss: 0.004537175875157118
Test Loss:  0.003511365270242095
Valid Loss:  0.003548586741089821
Epoch:  115  	Training Loss: 0.0045161377638578415
Test Loss:  0.003482090076431632
Valid Loss:  0.003501585917547345
Epoch:  116  	Training Loss: 0.0044969916343688965
Test Loss:  0.0034552570432424545
Valid Loss:  0.0034592831507325172
Epoch:  117  	Training Loss: 0.0044794268906116486
Test Loss:  0.0034307928290218115
Valid Loss:  0.0034210272133350372
Epoch:  118  	Training Loss: 0.0044631874188780785
Test Loss:  0.003408571006730199
Valid Loss:  0.0033862912096083164
Epoch:  119  	Training Loss: 0.004448056221008301
Test Loss:  0.0033881128765642643
Valid Loss:  0.003354629036039114
Epoch:  120  	Training Loss: 0.004433856345713139
Test Loss:  0.0033692275173962116
Valid Loss:  0.0033256663009524345
Epoch:  121  	Training Loss: 0.004420261364430189
Test Loss:  0.0033517072442919016
Valid Loss:  0.003299086121842265
Epoch:  122  	Training Loss: 0.004406481049954891
Test Loss:  0.0034025427885353565
Valid Loss:  0.0032310993410646915
Epoch:  123  	Training Loss: 0.004249323159456253
Test Loss:  0.0033744839020073414
Valid Loss:  0.003192353527992964
Epoch:  124  	Training Loss: 0.004122763406485319
Test Loss:  0.0033146864734590054
Valid Loss:  0.0031605574768036604
Epoch:  125  	Training Loss: 0.004008032847195864
Test Loss:  0.003251034766435623
Valid Loss:  0.0031300331465899944
Epoch:  126  	Training Loss: 0.0038983782287687063
Test Loss:  0.003187228227034211
Valid Loss:  0.0030984391923993826
Epoch:  127  	Training Loss: 0.003786182263866067
Test Loss:  0.0031235343776643276
Valid Loss:  0.00306624174118042
Epoch:  128  	Training Loss: 0.003676438005641103
Test Loss:  0.0030610894318670034
Valid Loss:  0.003033665008842945
Epoch:  129  	Training Loss: 0.003569913562387228
Test Loss:  0.0030020372942090034
Valid Loss:  0.0029996242374181747
Epoch:  130  	Training Loss: 0.0034682583063840866
Test Loss:  0.0029335608705878258
Valid Loss:  0.0029666232876479626
Epoch:  131  	Training Loss: 0.003370706457644701
Test Loss:  0.002866956405341625
Valid Loss:  0.0029340048786252737
Epoch:  132  	Training Loss: 0.0032789758406579494
Test Loss:  0.0028512654826045036
Valid Loss:  0.0028342027217149734
Epoch:  133  	Training Loss: 0.003201149869710207
Test Loss:  0.0027708131819963455
Valid Loss:  0.0027581248432397842
Epoch:  134  	Training Loss: 0.0031199511140584946
Test Loss:  0.00273481709882617
Valid Loss:  0.0026844670064747334
Epoch:  135  	Training Loss: 0.0030486229807138443
Test Loss:  0.0026689469814300537
Valid Loss:  0.002623851876705885
Epoch:  136  	Training Loss: 0.002977344673126936
Test Loss:  0.0026316368021070957
Valid Loss:  0.002558942185714841
Epoch:  137  	Training Loss: 0.0029096249490976334
Test Loss:  0.0025684356223791838
Valid Loss:  0.0025034681893885136
Epoch:  138  	Training Loss: 0.0028410195372998714
Test Loss:  0.002522454597055912
Valid Loss:  0.0024420092813670635
Epoch:  139  	Training Loss: 0.002775939181447029
Test Loss:   28%|██▊       | 139/500 [01:50<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:56<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:57<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:57<03:37,  1.64it/s] 29%|██▉       | 147/500 [01:57<02:40,  2.21it/s] 30%|██▉       | 149/500 [01:57<02:00,  2.92it/s] 30%|███       | 151/500 [02:03<07:00,  1.20s/it] 31%|███       | 153/500 [02:04<05:00,  1.16it/s] 31%|███       | 155/500 [02:04<03:36,  1.60it/s] 31%|███▏      | 157/500 [02:04<02:37,  2.18it/s] 32%|███▏      | 159/500 [02:04<01:56,  2.94it/s] 32%|███▏      | 161/500 [02:10<06:45,  1.20s/it] 33%|███▎      | 163/500 [02:11<04:49,  1.16it/s] 33%|███▎      | 165/500 [02:11<03:27,  1.61it/s] 33%|███▎      | 167/500 [02:11<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:11<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:17<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:17<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:18<03:21,  1.62it/s] 35%|███▌      | 177/500 [02:18<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:18<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:24<06:25,  1.21s/it] 37%|███▋      | 183/500 [02:24<04:34,  1.15it/s] 37%|███▋      | 185/500 [02:25<03:17,  1.59it/s] 37%|███▋      | 187/500 [02:25<02:23,  2.18it/s] 38%|███▊      | 189/500 [02:25<01:46,  2.93it/s] 38%|███▊      | 191/500 [02:31<06:12,  1.20s/it] 39%|███▊      | 193/500 [02:31<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:32<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:32<02:18,  2.19it/s] 40%|███▉      | 199/500 [02:32<01:42,  2.95it/s] 40%|████      | 201/500 [02:38<06:08,  1.23s/it] 41%|████      | 203/500 [02:39<04:22,  1.13it/s] 41%|████      | 205/500 [02:39<03:08,  1.56it/s] 41%|████▏     | 207/500 [02:39<02:16,  2.14it/s]0.0024697245098650455
Valid Loss:  0.0023854547180235386
Epoch:  140  	Training Loss: 0.002713120775297284
Test Loss:  0.002422112738713622
Valid Loss:  0.0023291821125894785
Epoch:  141  	Training Loss: 0.0026493603363633156
Test Loss:  0.0023708848748356104
Valid Loss:  0.0022764448076486588
Epoch:  142  	Training Loss: 0.0025865836068987846
Test Loss:  0.00227925181388855
Valid Loss:  0.0022420589812099934
Epoch:  143  	Training Loss: 0.0025053624995052814
Test Loss:  0.0022135379258543253
Valid Loss:  0.002201353432610631
Epoch:  144  	Training Loss: 0.0024338047951459885
Test Loss:  0.0021606709342449903
Valid Loss:  0.002162893069908023
Epoch:  145  	Training Loss: 0.0023686853237450123
Test Loss:  0.002113606780767441
Valid Loss:  0.0021232827566564083
Epoch:  146  	Training Loss: 0.002305961912497878
Test Loss:  0.002069649053737521
Valid Loss:  0.002086566761136055
Epoch:  147  	Training Loss: 0.0022470755502581596
Test Loss:  0.0020282119512557983
Valid Loss:  0.002050035633146763
Epoch:  148  	Training Loss: 0.002190992934629321
Test Loss:  0.0019887336529791355
Valid Loss:  0.002014544792473316
Epoch:  149  	Training Loss: 0.002137335017323494
Test Loss:  0.001950618578121066
Valid Loss:  0.001980066066607833
Epoch:  150  	Training Loss: 0.0020859658252447844
Test Loss:  0.0019136681221425533
Valid Loss:  0.0019465440418571234
Epoch:  151  	Training Loss: 0.0020365556702017784
Test Loss:  0.0018774555064737797
Valid Loss:  0.001913680462166667
Epoch:  152  	Training Loss: 0.0019888035021722317
Test Loss:  0.0018644251395016909
Valid Loss:  0.0018723055254667997
Epoch:  153  	Training Loss: 0.0019746420439332724
Test Loss:  0.0018520053708925843
Valid Loss:  0.0018371370388194919
Epoch:  154  	Training Loss: 0.0019620731472969055
Test Loss:  0.0018399361288174987
Valid Loss:  0.0018069136422127485
Epoch:  155  	Training Loss: 0.0019507098477333784
Test Loss:  0.0018281020456925035
Valid Loss:  0.001780590508133173
Epoch:  156  	Training Loss: 0.0019402606412768364
Test Loss:  0.001816446427255869
Valid Loss:  0.0017573477234691381
Epoch:  157  	Training Loss: 0.001930530765093863
Test Loss:  0.0018049522768706083
Valid Loss:  0.001736548962071538
Epoch:  158  	Training Loss: 0.0019213970517739654
Test Loss:  0.0017936211079359055
Valid Loss:  0.0017179190181195736
Epoch:  159  	Training Loss: 0.001912800595164299
Test Loss:  0.001782471314072609
Valid Loss:  0.0017010257579386234
Epoch:  160  	Training Loss: 0.001904649892821908
Test Loss:  0.0017715254798531532
Valid Loss:  0.0016855807043612003
Epoch:  161  	Training Loss: 0.0018968862714245915
Test Loss:  0.001760804676450789
Valid Loss:  0.0016712300712242723
Epoch:  162  	Training Loss: 0.0018894674722105265
Test Loss:  0.0017344038933515549
Valid Loss:  0.0016719929408282042
Epoch:  163  	Training Loss: 0.0018807840533554554
Test Loss:  0.0017136519309133291
Valid Loss:  0.001672129612416029
Epoch:  164  	Training Loss: 0.0018740977393463254
Test Loss:  0.001697127241641283
Valid Loss:  0.001671572681516409
Epoch:  165  	Training Loss: 0.0018686610274016857
Test Loss:  0.0016837972216308117
Valid Loss:  0.0016703580040484667
Epoch:  166  	Training Loss: 0.0018640123307704926
Test Loss:  0.001672901213169098
Valid Loss:  0.0016685702139511704
Epoch:  167  	Training Loss: 0.0018598524620756507
Test Loss:  0.00166387390345335
Valid Loss:  0.0016663084970787168
Epoch:  168  	Training Loss: 0.001855972339399159
Test Loss:  0.0016562755918130279
Valid Loss:  0.001663669478148222
Epoch:  169  	Training Loss: 0.0018522607861086726
Test Loss:  0.0016497776377946138
Valid Loss:  0.001660747337155044
Epoch:  170  	Training Loss: 0.0018486985936760902
Test Loss:  0.0016441380139440298
Valid Loss:  0.0016576140187680721
Epoch:  171  	Training Loss: 0.0018452440854161978
Test Loss:  0.0016391699900850654
Valid Loss:  0.001654328079894185
Epoch:  172  	Training Loss: 0.0018418708350509405
Test Loss:  0.001639229478314519
Valid Loss:  0.001653285464271903
Epoch:  173  	Training Loss: 0.001841647201217711
Test Loss:  0.0016392929246649146
Valid Loss:  0.0016522493679076433
Epoch:  174  	Training Loss: 0.0018414256628602743
Test Loss:  0.0016393586993217468
Valid Loss:  0.0016512214206159115
Epoch:  175  	Training Loss: 0.0018412048229947686
Test Loss:  0.0016394243575632572
Valid Loss:  0.0016502004582434893
Epoch:  176  	Training Loss: 0.0018409878248348832
Test Loss:  0.0016394908307120204
Valid Loss:  0.0016491867136210203
Epoch:  177  	Training Loss: 0.001840772107243538
Test Loss:  0.0016395591665059328
Valid Loss:  0.0016481810016557574
Epoch:  178  	Training Loss: 0.0018405583687126637
Test Loss:  0.001639628317207098
Valid Loss:  0.0016471827402710915
Epoch:  179  	Training Loss: 0.0018403467256575823
Test Loss:  0.0016396979335695505
Valid Loss:  0.0016461898339912295
Epoch:  180  	Training Loss: 0.001840137760154903
Test Loss:  0.0016397687140852213
Valid Loss:  0.0016452055424451828
Epoch:  181  	Training Loss: 0.0018399303080514073
Test Loss:  0.0016398383304476738
Valid Loss:  0.001644226722419262
Epoch:  182  	Training Loss: 0.0018397249514237046
Test Loss:  0.001645624521188438
Valid Loss:  0.001616559806279838
Epoch:  183  	Training Loss: 0.0018153083510696888
Test Loss:  0.0016446231165900826
Valid Loss:  0.0016005600336939096
Epoch:  184  	Training Loss: 0.0017989007756114006
Test Loss:  0.0016390921082347631
Valid Loss:  0.0015904606552794576
Epoch:  185  	Training Loss: 0.001785834552720189
Test Loss:  0.0016308194026350975
Valid Loss:  0.001583442441187799
Epoch:  186  	Training Loss: 0.0017743110656738281
Test Loss:  0.001622826443053782
Valid Loss:  0.0015764888375997543
Epoch:  187  	Training Loss: 0.0017620616126805544
Test Loss:  0.0016131197335198522
Valid Loss:  0.001571271917782724
Epoch:  188  	Training Loss: 0.0017500745598226786
Test Loss:  0.0016044795047491789
Valid Loss:  0.0015655646566301584
Epoch:  189  	Training Loss: 0.001737986458465457
Test Loss:  0.001594498404301703
Valid Loss:  0.001561085693538189
Epoch:  190  	Training Loss: 0.0017267584335058928
Test Loss:  0.0015838748076930642
Valid Loss:  0.0015571992844343185
Epoch:  191  	Training Loss: 0.0017161178402602673
Test Loss:  0.0015730371233075857
Valid Loss:  0.0015535365091636777
Epoch:  192  	Training Loss: 0.0017059233505278826
Test Loss:  0.0015746892895549536
Valid Loss:  0.0015252050943672657
Epoch:  193  	Training Loss: 0.0017010339070111513
Test Loss:  0.001576181035488844
Valid Loss:  0.0015047877095639706
Epoch:  194  	Training Loss: 0.0016978372586891055
Test Loss:  0.0015770888421684504
Valid Loss:  0.0014892027247697115
Epoch:  195  	Training Loss: 0.001695424085482955
Test Loss:  0.0015775792999193072
Valid Loss:  0.0014766008825972676
Epoch:  196  	Training Loss: 0.0016934622544795275
Test Loss:  0.0015782634727656841
Valid Loss:  0.001465534558519721
Epoch:  197  	Training Loss: 0.0016918585170060396
Test Loss:  0.0015789465978741646
Valid Loss:  0.0014559368137270212
Epoch:  198  	Training Loss: 0.0016905271913856268
Test Loss:  0.001579283270984888
Valid Loss:  0.0014479728415608406
Epoch:  199  	Training Loss: 0.0016893644351512194
Test Loss:  0.0015794604551047087
Valid Loss:  0.0014410368166863918
Epoch:  200  	Training Loss: 0.0016883253119885921
Test Loss:  0.001579329022206366
Valid Loss:  0.0014351335121318698
Epoch:  201  	Training Loss: 0.0016873418353497982
Test Loss:  0.0015788518358021975
Valid Loss:  0.001430124742910266
Epoch:  202  	Training Loss: 0.0016863688360899687
Test Loss:  0.0015176128363236785
Valid Loss:  0.0014051009202376008
Epoch:  203  	Training Loss: 0.0016369386576116085
Test Loss:  0.001469156937673688
Valid Loss:  0.0013777496060356498
Epoch:  204  	Training Loss: 0.0015916015254333615
Test Loss:  0.0014270134270191193
Valid Loss:  0.0013506136601790786
Epoch:  205  	Training Loss: 0.001549162669107318
Test Loss:  0.001390189747326076
Valid Loss:  0.0013250611955299973
Epoch:  206  	Training Loss: 0.0015097081195563078
Test Loss:  0.0013557405909523368
Valid Loss:  0.0013025334337726235
Epoch:  207  	Training Loss: 0.001473111449740827
Test Loss:  0.0013274089433252811
Valid Loss:  0.0012799091637134552
 42%|████▏     | 209/500 [02:39<01:40,  2.88it/s] 42%|████▏     | 211/500 [02:45<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:46<04:08,  1.16it/s] 43%|████▎     | 215/500 [02:46<02:58,  1.60it/s] 43%|████▎     | 217/500 [02:46<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:46<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:52<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:52<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:53<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:53<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:53<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:59<05:26,  1.21s/it] 47%|████▋     | 233/500 [02:59<03:53,  1.14it/s] 47%|████▋     | 235/500 [03:00<02:49,  1.57it/s] 47%|████▋     | 237/500 [03:00<02:02,  2.14it/s] 48%|████▊     | 239/500 [03:00<01:30,  2.89it/s] 48%|████▊     | 241/500 [03:06<05:08,  1.19s/it] 49%|████▊     | 243/500 [03:06<03:40,  1.16it/s] 49%|████▉     | 245/500 [03:07<02:39,  1.60it/s] 49%|████▉     | 247/500 [03:07<01:57,  2.16it/s] 50%|████▉     | 249/500 [03:07<01:26,  2.90it/s] 50%|█████     | 251/500 [03:13<04:56,  1.19s/it] 51%|█████     | 253/500 [03:13<03:30,  1.17it/s] 51%|█████     | 255/500 [03:13<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:14<01:50,  2.21it/s] 52%|█████▏    | 259/500 [03:14<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:20<04:43,  1.18s/it] 53%|█████▎    | 263/500 [03:20<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:20<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:20<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:21<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:27<04:37,  1.21s/it] 55%|█████▍    | 273/500 [03:27<03:17,  1.15it/s] 55%|█████▌    | 275/500 [03:27<02:21,  1.59it/s]Epoch:  208  	Training Loss: 0.0014384002424776554
Test Loss:  0.0012983023189008236
Valid Loss:  0.0012602722272276878
Epoch:  209  	Training Loss: 0.0014063164126127958
Test Loss:  0.0012742856051772833
Valid Loss:  0.0012425691820681095
Epoch:  210  	Training Loss: 0.0013765417970716953
Test Loss:  0.0012487058993428946
Valid Loss:  0.001226184074766934
Epoch:  211  	Training Loss: 0.0013484533410519361
Test Loss:  0.0012275285553187132
Valid Loss:  0.0012110840762034059
Epoch:  212  	Training Loss: 0.0013223765417933464
Test Loss:  0.0011972874635830522
Valid Loss:  0.0012198041658848524
Epoch:  213  	Training Loss: 0.001316725043579936
Test Loss:  0.0011857303325086832
Valid Loss:  0.0012210027780383825
Epoch:  214  	Training Loss: 0.001313983229920268
Test Loss:  0.0011762632057070732
Valid Loss:  0.0012205506209284067
Epoch:  215  	Training Loss: 0.0013121619122102857
Test Loss:  0.0011711171828210354
Valid Loss:  0.0012178497854620218
Epoch:  216  	Training Loss: 0.0013106788974255323
Test Loss:  0.0011679462622851133
Valid Loss:  0.001214248826727271
Epoch:  217  	Training Loss: 0.0013093003071844578
Test Loss:  0.0011656694114208221
Valid Loss:  0.001210358226671815
Epoch:  218  	Training Loss: 0.0013080403441563249
Test Loss:  0.0011627755593508482
Valid Loss:  0.0012067325878888369
Epoch:  219  	Training Loss: 0.001306853024289012
Test Loss:  0.001160681014880538
Valid Loss:  0.001202888903208077
Epoch:  220  	Training Loss: 0.001305729034356773
Test Loss:  0.0011584676103666425
Valid Loss:  0.001199197955429554
Epoch:  221  	Training Loss: 0.0013046636013314128
Test Loss:  0.0011569614289328456
Valid Loss:  0.0011954044457525015
Epoch:  222  	Training Loss: 0.0013036432210355997
Test Loss:  0.0011572293005883694
Valid Loss:  0.0011952517088502645
Epoch:  223  	Training Loss: 0.0013034739531576633
Test Loss:  0.0011574960080906749
Valid Loss:  0.001195100718177855
Epoch:  224  	Training Loss: 0.0013033209834247828
Test Loss:  0.0011576844844967127
Valid Loss:  0.00119499652646482
Epoch:  225  	Training Loss: 0.0013032390270382166
Test Loss:  0.0011578593403100967
Valid Loss:  0.0011949127074331045
Epoch:  226  	Training Loss: 0.0013031864073127508
Test Loss:  0.0011580578284338117
Valid Loss:  0.0011948299361392856
Epoch:  227  	Training Loss: 0.0013031426351517439
Test Loss:  0.0011582088191062212
Valid Loss:  0.0011947682360187173
Epoch:  228  	Training Loss: 0.0013031130656599998
Test Loss:  0.0011583581799641252
Valid Loss:  0.0011947073508054018
Epoch:  229  	Training Loss: 0.0013030839618295431
Test Loss:  0.0011585060274228454
Valid Loss:  0.0011946470476686954
Epoch:  230  	Training Loss: 0.0013030627742409706
Test Loss:  0.0011586290784180164
Valid Loss:  0.0011946047889068723
Epoch:  231  	Training Loss: 0.0013030485715717077
Test Loss:  0.0011587543413043022
Valid Loss:  0.0011945629958063364
Epoch:  232  	Training Loss: 0.0013030348345637321
Test Loss:  0.0010954760946333408
Valid Loss:  0.0012257578782737255
Epoch:  233  	Training Loss: 0.0012693587923422456
Test Loss:  0.0010751134250313044
Valid Loss:  0.0012351196492090821
Epoch:  234  	Training Loss: 0.001252869376912713
Test Loss:  0.0010773614048957825
Valid Loss:  0.0012292898027226329
Epoch:  235  	Training Loss: 0.0012485510669648647
Test Loss:  0.001080410205759108
Valid Loss:  0.0012244583340361714
Epoch:  236  	Training Loss: 0.0012458048295229673
Test Loss:  0.001081996364519
Valid Loss:  0.0012213487643748522
Epoch:  237  	Training Loss: 0.001243246952071786
Test Loss:  0.0010833722772076726
Valid Loss:  0.0012183014769107103
Epoch:  238  	Training Loss: 0.0012408707989379764
Test Loss:  0.0010838431771844625
Valid Loss:  0.001216255477629602
Epoch:  239  	Training Loss: 0.0012385670561343431
Test Loss:  0.001083744689822197
Valid Loss:  0.0012147946981713176
Epoch:  240  	Training Loss: 0.0012363153509795666
Test Loss:  0.001084054703824222
Valid Loss:  0.001212569884955883
Epoch:  241  	Training Loss: 0.0012341472320258617
Test Loss:  0.0010851871920749545
Valid Loss:  0.0012090563541278243
Epoch:  242  	Training Loss: 0.00123205641284585
Test Loss:  0.0010629112366586924
Valid Loss:  0.0011605765903368592
Epoch:  243  	Training Loss: 0.0011948004830628633
Test Loss:  0.0010844790376722813
Valid Loss:  0.0010919504566118121
Epoch:  244  	Training Loss: 0.0011790909338742495
Test Loss:  0.0010587151627987623
Valid Loss:  0.0011197839630767703
Epoch:  245  	Training Loss: 0.001168999820947647
Test Loss:  0.0010603397386148572
Valid Loss:  0.00105126085691154
Epoch:  246  	Training Loss: 0.0011492271441966295
Test Loss:  0.0010565748671069741
Valid Loss:  0.0010258358670398593
Epoch:  247  	Training Loss: 0.0011385394027456641
Test Loss:  0.0010344624752178788
Valid Loss:  0.0010600639507174492
Epoch:  248  	Training Loss: 0.0011335854651406407
Test Loss:  0.0010336062405258417
Valid Loss:  0.001014062436297536
Epoch:  249  	Training Loss: 0.0011191079393029213
Test Loss:  0.001025538775138557
Valid Loss:  0.0009916009148582816
Epoch:  250  	Training Loss: 0.0011083509307354689
Test Loss:  0.0010078775230795145
Valid Loss:  0.0010059004416689277
Epoch:  251  	Training Loss: 0.0011018221266567707
Test Loss:  0.001003970974124968
Valid Loss:  0.0009746231371536851
Epoch:  252  	Training Loss: 0.0010904178488999605
Test Loss:  0.0009438236011192203
Valid Loss:  0.0009917928837239742
Epoch:  253  	Training Loss: 0.0010773052927106619
Test Loss:  0.0009449071949347854
Valid Loss:  0.000963980273809284
Epoch:  254  	Training Loss: 0.0010699124541133642
Test Loss:  0.0009339023381471634
Valid Loss:  0.0009516925783827901
Epoch:  255  	Training Loss: 0.0010639659594744444
Test Loss:  0.0009270879672840238
Valid Loss:  0.0009388669277541339
Epoch:  256  	Training Loss: 0.0010588756995275617
Test Loss:  0.0009207545081153512
Valid Loss:  0.0009284276748076081
Epoch:  257  	Training Loss: 0.001054602675139904
Test Loss:  0.0009155476000159979
Valid Loss:  0.0009192685829475522
Epoch:  258  	Training Loss: 0.0010510345455259085
Test Loss:  0.0009109217207878828
Valid Loss:  0.0009115952998399734
Epoch:  259  	Training Loss: 0.0010480131022632122
Test Loss:  0.0009069531224668026
Valid Loss:  0.0009049131767824292
Epoch:  260  	Training Loss: 0.0010453739669173956
Test Loss:  0.0009034284739755094
Valid Loss:  0.0008990330388769507
Epoch:  261  	Training Loss: 0.001043010619468987
Test Loss:  0.0009003656450659037
Valid Loss:  0.0008938844548538327
Epoch:  262  	Training Loss: 0.0010408938396722078
Test Loss:  0.0008591472287662327
Valid Loss:  0.0008938910905271769
Epoch:  263  	Training Loss: 0.001015112386085093
Test Loss:  0.0008714706636965275
Valid Loss:  0.0008592906524427235
Epoch:  264  	Training Loss: 0.0010058213956654072
Test Loss:  0.0008572707884013653
Valid Loss:  0.0008506304584443569
Epoch:  265  	Training Loss: 0.0009987354278564453
Test Loss:  0.0008521148120053113
Valid Loss:  0.0008374653989449143
Epoch:  266  	Training Loss: 0.0009926221100613475
Test Loss:  0.0008475430076941848
Valid Loss:  0.0008258873131126165
Epoch:  267  	Training Loss: 0.0009875188115984201
Test Loss:  0.0008409270085394382
Valid Loss:  0.0008171600056812167
Epoch:  268  	Training Loss: 0.0009829166810959578
Test Loss:  0.0008358373888768256
Valid Loss:  0.0008088488830253482
Epoch:  269  	Training Loss: 0.0009786724112927914
Test Loss:  0.000830486707855016
Valid Loss:  0.0008017691434361041
Epoch:  270  	Training Loss: 0.0009746683062985539
Test Loss:  0.000825529801659286
Valid Loss:  0.0007951825391501188
Epoch:  271  	Training Loss: 0.0009708626894280314
Test Loss:  0.0008209293009713292
Valid Loss:  0.0007890077540650964
Epoch:  272  	Training Loss: 0.0009672244777902961
Test Loss:  0.0008230300154536963
Valid Loss:  0.0007723274175077677
Epoch:  273  	Training Loss: 0.0009357165545225143
Test Loss:  0.0008121769060380757
Valid Loss:  0.000767635996453464
Epoch:  274  	Training Loss: 0.0009150611003860831
Test Loss:  0.0007984074763953686
Valid Loss:  0.0007665653247386217
Epoch:  275  	Training Loss: 0.0008984471787698567
Test Loss:  0.0007850209949538112
Valid Loss:  0.0007667147438041866
Epoch:  276  	Training Loss: 0.0008843549294397235
Test Loss:   55%|█████▌    | 277/500 [03:28<01:42,  2.17it/s] 56%|█████▌    | 279/500 [03:28<01:15,  2.91it/s] 56%|█████▌    | 281/500 [03:34<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:34<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:34<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:34<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:34<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:41<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:41<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:41<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:41<01:33,  2.16it/s] 60%|█████▉    | 299/500 [03:42<01:10,  2.87it/s] 60%|██████    | 301/500 [03:48<04:03,  1.22s/it] 61%|██████    | 303/500 [03:48<02:53,  1.13it/s] 61%|██████    | 305/500 [03:48<02:05,  1.55it/s] 61%|██████▏   | 307/500 [03:49<01:31,  2.10it/s] 62%|██████▏   | 309/500 [03:49<01:08,  2.78it/s] 62%|██████▏   | 311/500 [03:55<03:50,  1.22s/it] 63%|██████▎   | 313/500 [03:55<02:43,  1.14it/s] 63%|██████▎   | 315/500 [03:55<01:57,  1.58it/s] 63%|██████▎   | 317/500 [03:56<01:24,  2.16it/s] 64%|██████▍   | 319/500 [03:56<01:02,  2.91it/s] 64%|██████▍   | 321/500 [04:02<03:34,  1.20s/it] 65%|██████▍   | 323/500 [04:02<02:32,  1.16it/s] 65%|██████▌   | 325/500 [04:02<01:49,  1.60it/s] 65%|██████▌   | 327/500 [04:03<01:19,  2.18it/s] 66%|██████▌   | 329/500 [04:03<00:58,  2.92it/s] 66%|██████▌   | 331/500 [04:09<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:09<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:09<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:09<01:13,  2.22it/s] 68%|██████▊   | 339/500 [04:10<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:16<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:16<02:15,  1.16it/s]0.0007729657227173448
Valid Loss:  0.0007672446081414819
Epoch:  277  	Training Loss: 0.0008722555357962847
Test Loss:  0.000762506911996752
Valid Loss:  0.0007678976398892701
Epoch:  278  	Training Loss: 0.0008619260042905807
Test Loss:  0.0007536201155744493
Valid Loss:  0.0007683372823521495
Epoch:  279  	Training Loss: 0.0008526097517460585
Test Loss:  0.0007457109168171883
Valid Loss:  0.0007684997981414199
Epoch:  280  	Training Loss: 0.000844068534206599
Test Loss:  0.0007385644130408764
Valid Loss:  0.0007683612639084458
Epoch:  281  	Training Loss: 0.0008361298241652548
Test Loss:  0.0007320351433008909
Valid Loss:  0.0007679241243749857
Epoch:  282  	Training Loss: 0.0008287315140478313
Test Loss:  0.0007061416981741786
Valid Loss:  0.000750495120882988
Epoch:  283  	Training Loss: 0.000808867160230875
Test Loss:  0.0007065453100949526
Valid Loss:  0.0007276884280145168
Epoch:  284  	Training Loss: 0.0007941420190036297
Test Loss:  0.0006820620619691908
Valid Loss:  0.0007248747278936207
Epoch:  285  	Training Loss: 0.0007815859280526638
Test Loss:  0.0006900543812662363
Valid Loss:  0.0007057503098621964
Epoch:  286  	Training Loss: 0.0007697080145590007
Test Loss:  0.0006563591887243092
Valid Loss:  0.0007107838755473495
Epoch:  287  	Training Loss: 0.0007591152098029852
Test Loss:  0.0006799953407607973
Valid Loss:  0.0006857248372398317
Epoch:  288  	Training Loss: 0.0007497794576920569
Test Loss:  0.0006299491506069899
Valid Loss:  0.0007016579038463533
Epoch:  289  	Training Loss: 0.000740975490771234
Test Loss:  0.0006774957291781902
Valid Loss:  0.0006669097347185016
Epoch:  290  	Training Loss: 0.0007338589639402926
Test Loss:  0.0006044149049557745
Valid Loss:  0.0006963539053685963
Epoch:  291  	Training Loss: 0.0007270202622748911
Test Loss:  0.0006823671283200383
Valid Loss:  0.0006506709032692015
Epoch:  292  	Training Loss: 0.0007226945599541068
Test Loss:  0.0006262231036089361
Valid Loss:  0.000659275334328413
Epoch:  293  	Training Loss: 0.0007073244196362793
Test Loss:  0.0006230019498616457
Valid Loss:  0.0006579417386092246
Epoch:  294  	Training Loss: 0.0007048962288536131
Test Loss:  0.0006188001716509461
Valid Loss:  0.0006563603528775275
Epoch:  295  	Training Loss: 0.0007029144326224923
Test Loss:  0.0006187445251271129
Valid Loss:  0.0006535345455631614
Epoch:  296  	Training Loss: 0.0007011163979768753
Test Loss:  0.000617493933532387
Valid Loss:  0.000651410548016429
Epoch:  297  	Training Loss: 0.000699493451975286
Test Loss:  0.0006176131428219378
Valid Loss:  0.0006491156527772546
Epoch:  298  	Training Loss: 0.000698045885656029
Test Loss:  0.0006167392712086439
Valid Loss:  0.0006473991088569164
Epoch:  299  	Training Loss: 0.0006967029767110944
Test Loss:  0.0006164574297145009
Valid Loss:  0.0006456683622673154
Epoch:  300  	Training Loss: 0.0006954722921364009
Test Loss:  0.0006162581848911941
Valid Loss:  0.0006441125296987593
Epoch:  301  	Training Loss: 0.0006943291518837214
Test Loss:  0.0006157931056804955
Valid Loss:  0.0006427844054996967
Epoch:  302  	Training Loss: 0.0006932647665962577
Test Loss:  0.0006218673661351204
Valid Loss:  0.0006372065981850028
Epoch:  303  	Training Loss: 0.0006897894199937582
Test Loss:  0.0006220583454705775
Valid Loss:  0.0006350993644446135
Epoch:  304  	Training Loss: 0.0006869178032502532
Test Loss:  0.0006209773709997535
Valid Loss:  0.0006337453960441053
Epoch:  305  	Training Loss: 0.0006842256989330053
Test Loss:  0.0006194473244249821
Valid Loss:  0.0006327250739559531
Epoch:  306  	Training Loss: 0.0006816962268203497
Test Loss:  0.0006178270559757948
Valid Loss:  0.0006318535888567567
Epoch:  307  	Training Loss: 0.0006792998174205422
Test Loss:  0.0006161226192489266
Valid Loss:  0.000631054281257093
Epoch:  308  	Training Loss: 0.000677012256346643
Test Loss:  0.0006140185287222266
Valid Loss:  0.000630492577329278
Epoch:  309  	Training Loss: 0.0006748171872459352
Test Loss:  0.000612524279858917
Valid Loss:  0.0006296165520325303
Epoch:  310  	Training Loss: 0.0006726872525177896
Test Loss:  0.0006121530896052718
Valid Loss:  0.000628545880317688
Epoch:  311  	Training Loss: 0.000670208886731416
Test Loss:  0.0006111008115112782
Valid Loss:  0.0006276826607063413
Epoch:  312  	Training Loss: 0.0006678795325569808
Test Loss:  0.0006093423580750823
Valid Loss:  0.0006253223400563002
Epoch:  313  	Training Loss: 0.00066309270914644
Test Loss:  0.0006067667854949832
Valid Loss:  0.0006234662723727524
Epoch:  314  	Training Loss: 0.000658762757666409
Test Loss:  0.0006036101840436459
Valid Loss:  0.0006219517672434449
Epoch:  315  	Training Loss: 0.0006546200602315366
Test Loss:  0.0006006755866110325
Valid Loss:  0.0006202966324053705
Epoch:  316  	Training Loss: 0.0006506242789328098
Test Loss:  0.0005978581611998379
Valid Loss:  0.0006185784004628658
Epoch:  317  	Training Loss: 0.000646760337986052
Test Loss:  0.0005951232742518187
Valid Loss:  0.000616836070548743
Epoch:  318  	Training Loss: 0.0006430520443245769
Test Loss:  0.0005923979915678501
Valid Loss:  0.0006151081761345267
Epoch:  319  	Training Loss: 0.0006396271055564284
Test Loss:  0.0005897934315726161
Valid Loss:  0.0006133588030934334
Epoch:  320  	Training Loss: 0.0006362926214933395
Test Loss:  0.00058723398251459
Valid Loss:  0.0006116194999776781
Epoch:  321  	Training Loss: 0.0006330581381917
Test Loss:  0.0005847387365065515
Valid Loss:  0.0006099001038819551
Epoch:  322  	Training Loss: 0.0006299118394963443
Test Loss:  0.0005825397092849016
Valid Loss:  0.0006093606352806091
Epoch:  323  	Training Loss: 0.0006291112513281405
Test Loss:  0.0005809622816741467
Valid Loss:  0.0006087567890062928
Epoch:  324  	Training Loss: 0.000628522306215018
Test Loss:  0.0005798375932499766
Valid Loss:  0.0006081134197302163
Epoch:  325  	Training Loss: 0.0006280738161876798
Test Loss:  0.0005790443392470479
Valid Loss:  0.0006074556149542332
Epoch:  326  	Training Loss: 0.0006277251522988081
Test Loss:  0.0005784928216598928
Valid Loss:  0.0006068024085834622
Epoch:  327  	Training Loss: 0.0006274483166635036
Test Loss:  0.0005781186046078801
Valid Loss:  0.0006061665480956435
Epoch:  328  	Training Loss: 0.0006272235768847167
Test Loss:  0.0005778719205409288
Valid Loss:  0.0006055560661479831
Epoch:  329  	Training Loss: 0.0006270396988838911
Test Loss:  0.0005777172045782208
Valid Loss:  0.0006049785297363997
Epoch:  330  	Training Loss: 0.0006268862634897232
Test Loss:  0.0005776294274255633
Valid Loss:  0.0006044358597137034
Epoch:  331  	Training Loss: 0.000626756576821208
Test Loss:  0.0005775868194177747
Valid Loss:  0.0006039293948560953
Epoch:  332  	Training Loss: 0.0006266454583965242
Test Loss:  0.0005768670234829187
Valid Loss:  0.0006032169912941754
Epoch:  333  	Training Loss: 0.0006240674993023276
Test Loss:  0.0005765433888882399
Valid Loss:  0.0006021182052791119
Epoch:  334  	Training Loss: 0.0006221533985808492
Test Loss:  0.000575101119466126
Valid Loss:  0.0006015374092385173
Epoch:  335  	Training Loss: 0.000620636681560427
Test Loss:  0.0005748228868469596
Valid Loss:  0.0006002693553455174
Epoch:  336  	Training Loss: 0.0006192061118781567
Test Loss:  0.000574741221498698
Valid Loss:  0.0005988358752802014
Epoch:  337  	Training Loss: 0.000617854529991746
Test Loss:  0.0005729004042223096
Valid Loss:  0.0005982074071653187
Epoch:  338  	Training Loss: 0.0006165337399579585
Test Loss:  0.0005726690869778395
Valid Loss:  0.0005969097837805748
Epoch:  339  	Training Loss: 0.0006152944406494498
Test Loss:  0.0005714978324249387
Valid Loss:  0.0005960106500424445
Epoch:  340  	Training Loss: 0.0006141065387055278
Test Loss:  0.0005707925884053111
Valid Loss:  0.0005949428887106478
Epoch:  341  	Training Loss: 0.0006129557732492685
Test Loss:  0.0005701739573851228
Valid Loss:  0.0005938466638326645
Epoch:  342  	Training Loss: 0.0006118373712524772
Test Loss:  0.0005705421790480614
Valid Loss:  0.0005920983967371285
Epoch:  343  	Training Loss: 0.0006074496195651591
Test Loss:  0.0005660158349201083
Valid Loss:  0.0005913575878366828
Epoch:  344  	Training Loss: 0.0006042108288966119
Test Loss:  0.0005634500994347036
Valid Loss:  0.0005897004157304764
 69%|██████▉   | 345/500 [04:16<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:16<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:17<00:52,  2.87it/s] 70%|███████   | 351/500 [04:23<03:01,  1.22s/it] 71%|███████   | 353/500 [04:23<02:09,  1.13it/s] 71%|███████   | 355/500 [04:23<01:33,  1.56it/s] 71%|███████▏  | 357/500 [04:24<01:07,  2.11it/s] 72%|███████▏  | 359/500 [04:24<00:50,  2.79it/s] 72%|███████▏  | 361/500 [04:30<02:46,  1.19s/it] 73%|███████▎  | 363/500 [04:30<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:30<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:30<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:31<00:44,  2.94it/s] 74%|███████▍  | 371/500 [04:37<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:37<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:37<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:37<00:56,  2.20it/s] 76%|███████▌  | 379/500 [04:38<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:44<02:22,  1.19s/it] 77%|███████▋  | 383/500 [04:44<01:41,  1.16it/s] 77%|███████▋  | 385/500 [04:44<01:12,  1.59it/s] 77%|███████▋  | 387/500 [04:44<00:51,  2.17it/s] 78%|███████▊  | 389/500 [04:45<00:37,  2.93it/s] 78%|███████▊  | 391/500 [04:51<02:11,  1.20s/it] 78%|███████▊  | 392/500 [04:51<01:48,  1.01s/it] 79%|███████▉  | 394/500 [04:51<01:14,  1.43it/s] 79%|███████▉  | 396/500 [04:51<00:52,  2.00it/s] 80%|███████▉  | 398/500 [04:52<00:37,  2.71it/s] 80%|████████  | 400/500 [04:52<00:28,  3.56it/s] 80%|████████  | 402/500 [04:58<01:55,  1.17s/it] 81%|████████  | 404/500 [04:58<01:20,  1.19it/s] 81%|████████  | 406/500 [04:59<00:57,  1.63it/s] 82%|████████▏ | 408/500 [04:59<00:41,  2.22it/s] 82%|████████▏ | 410/500 [04:59<00:30,  2.99it/s] 82%|████████▏ | 412/500 [05:05<01:46,  1.21s/it]Epoch:  345  	Training Loss: 0.0006011630757711828
Test Loss:  0.0005620337324216962
Valid Loss:  0.0005884129786863923
Epoch:  346  	Training Loss: 0.0005982937873341143
Test Loss:  0.0005594168324023485
Valid Loss:  0.0005869737942703068
Epoch:  347  	Training Loss: 0.0005954699590802193
Test Loss:  0.0005582561134360731
Valid Loss:  0.000585360627155751
Epoch:  348  	Training Loss: 0.0005927796009927988
Test Loss:  0.0005567792686633766
Valid Loss:  0.0005838844808749855
Epoch:  349  	Training Loss: 0.0005901976255699992
Test Loss:  0.0005559205310419202
Valid Loss:  0.000582541455514729
Epoch:  350  	Training Loss: 0.0005877215880900621
Test Loss:  0.0005537657998502254
Valid Loss:  0.0005811635055579245
Epoch:  351  	Training Loss: 0.0005853518377989531
Test Loss:  0.0005533639341592789
Valid Loss:  0.0005798275233246386
Epoch:  352  	Training Loss: 0.0005832193419337273
Test Loss:  0.0005530730122700334
Valid Loss:  0.0005784981767646968
Epoch:  353  	Training Loss: 0.0005825659027323127
Test Loss:  0.0005529168411158025
Valid Loss:  0.0005773761658929288
Epoch:  354  	Training Loss: 0.0005820433143526316
Test Loss:  0.000552891637198627
Valid Loss:  0.0005763605586253107
Epoch:  355  	Training Loss: 0.0005815987242385745
Test Loss:  0.0005529336049221456
Valid Loss:  0.0005754500743933022
Epoch:  356  	Training Loss: 0.000581214320845902
Test Loss:  0.0005530049675144255
Valid Loss:  0.0005746364477090538
Epoch:  357  	Training Loss: 0.000580885331146419
Test Loss:  0.0005530808120965958
Valid Loss:  0.0005739089683629572
Epoch:  358  	Training Loss: 0.0005806232802569866
Test Loss:  0.000553067889995873
Valid Loss:  0.0005733362631872296
Epoch:  359  	Training Loss: 0.0005804114043712616
Test Loss:  0.0005530689959414303
Valid Loss:  0.0005728139076381922
Epoch:  360  	Training Loss: 0.0005802221712656319
Test Loss:  0.0005529391928575933
Valid Loss:  0.0005724906804971397
Epoch:  361  	Training Loss: 0.0005800960934720933
Test Loss:  0.0005528767942450941
Valid Loss:  0.0005721782799810171
Epoch:  362  	Training Loss: 0.0005799775244668126
Test Loss:  0.0005479506216943264
Valid Loss:  0.0005733456928282976
Epoch:  363  	Training Loss: 0.0005793757736682892
Test Loss:  0.0005500871920958161
Valid Loss:  0.0005726187955588102
Epoch:  364  	Training Loss: 0.0005789586575701833
Test Loss:  0.0005493857315741479
Valid Loss:  0.0005725876544602215
Epoch:  365  	Training Loss: 0.0005785624962300062
Test Loss:  0.0005492198979482055
Valid Loss:  0.0005724293878301978
Epoch:  366  	Training Loss: 0.0005781692452728748
Test Loss:  0.0005489558097906411
Valid Loss:  0.0005722928326576948
Epoch:  367  	Training Loss: 0.0005777928163297474
Test Loss:  0.0005491967312991619
Valid Loss:  0.0005719774635508657
Epoch:  368  	Training Loss: 0.0005774201126769185
Test Loss:  0.0005489119794219732
Valid Loss:  0.0005717893945984542
Epoch:  369  	Training Loss: 0.0005770508432760835
Test Loss:  0.0005487330490723252
Valid Loss:  0.000571583746932447
Epoch:  370  	Training Loss: 0.0005766844842582941
Test Loss:  0.0005485275178216398
Valid Loss:  0.0005713891005143523
Epoch:  371  	Training Loss: 0.0005763204535469413
Test Loss:  0.0005483239074237645
Valid Loss:  0.0005711981793865561
Epoch:  372  	Training Loss: 0.0005759584601037204
Test Loss:  0.000548971991520375
Valid Loss:  0.0005701548070646822
Epoch:  373  	Training Loss: 0.0005752446595579386
Test Loss:  0.0005488601746037602
Valid Loss:  0.0005693620769307017
Epoch:  374  	Training Loss: 0.0005745780654251575
Test Loss:  0.0005486891022883356
Valid Loss:  0.0005686862859874964
Epoch:  375  	Training Loss: 0.0005739566986449063
Test Loss:  0.0005486039444804192
Valid Loss:  0.0005680428585037589
Epoch:  376  	Training Loss: 0.0005733593716286123
Test Loss:  0.0005485299625433981
Valid Loss:  0.0005674399435520172
Epoch:  377  	Training Loss: 0.0005727840471081436
Test Loss:  0.0005484647117555141
Valid Loss:  0.0005668761441484094
Epoch:  378  	Training Loss: 0.0005722285714000463
Test Loss:  0.0005484092980623245
Valid Loss:  0.0005663495976477861
Epoch:  379  	Training Loss: 0.0005716910818591714
Test Loss:  0.0005483607528731227
Valid Loss:  0.0005658565787598491
Epoch:  380  	Training Loss: 0.0005711707635782659
Test Loss:  0.0005483193672262132
Valid Loss:  0.0005653948755934834
Epoch:  381  	Training Loss: 0.0005706660449504852
Test Loss:  0.0005482833948917687
Valid Loss:  0.0005649629165418446
Epoch:  382  	Training Loss: 0.0005701612681150436
Test Loss:  0.0005476095248013735
Valid Loss:  0.0005652948748320341
Epoch:  383  	Training Loss: 0.0005690671969205141
Test Loss:  0.0005474496865645051
Valid Loss:  0.000565282185561955
Epoch:  384  	Training Loss: 0.0005683410563506186
Test Loss:  0.0005473218625411391
Valid Loss:  0.0005650774110108614
Epoch:  385  	Training Loss: 0.0005677829030901194
Test Loss:  0.0005477134836837649
Valid Loss:  0.0005645412020385265
Epoch:  386  	Training Loss: 0.0005673329578712583
Test Loss:  0.0005476712249219418
Valid Loss:  0.0005640746094286442
Epoch:  387  	Training Loss: 0.0005669071106240153
Test Loss:  0.000548024894669652
Valid Loss:  0.0005634234403260052
Epoch:  388  	Training Loss: 0.0005664985510520637
Test Loss:  0.0005478800158016384
Valid Loss:  0.0005629363586194813
Epoch:  389  	Training Loss: 0.0005661120521835983
Test Loss:  0.0005464642308652401
Valid Loss:  0.0005629085935652256
Epoch:  390  	Training Loss: 0.0005657412111759186
Test Loss:  0.0005471871118061244
Valid Loss:  0.0005621310556307435
Epoch:  391  	Training Loss: 0.000565364258363843
Test Loss:  0.0005459457170218229
Valid Loss:  0.0005620467709377408
Epoch:  392  	Training Loss: 0.0005650202510878444
Test Loss:  0.0005432741600088775
Valid Loss:  0.0005627444479614496
Epoch:  393  	Training Loss: 0.0005647623329423368
Test Loss:  0.0005432752659544349
Valid Loss:  0.0005629963707178831
Epoch:  394  	Training Loss: 0.0005645497003570199
Test Loss:  0.0005435586208477616
Valid Loss:  0.0005633459659293294
Epoch:  395  	Training Loss: 0.0005641814204864204
Test Loss:  0.0005437126383185387
Valid Loss:  0.0005638555157929659
Epoch:  396  	Training Loss: 0.00056367990327999
Test Loss:  0.0005427129799500108
Valid Loss:  0.0005643630283884704
Epoch:  397  	Training Loss: 0.0005632718093693256
Test Loss:  0.0005423204274848104
Valid Loss:  0.0005648244405165315
Epoch:  398  	Training Loss: 0.000562964181881398
Test Loss:  0.0005408605793491006
Valid Loss:  0.0005650841630995274
Epoch:  399  	Training Loss: 0.0005626817001029849
Test Loss:  0.0005411998718045652
Valid Loss:  0.0005653224070556462
Epoch:  400  	Training Loss: 0.000562415283638984
Test Loss:  0.0005398535868152976
Valid Loss:  0.0005654809065163136
Epoch:  401  	Training Loss: 0.0005621777381747961
Test Loss:  0.0005401271628215909
Valid Loss:  0.0005655908025801182
Epoch:  402  	Training Loss: 0.0005619663279503584
Test Loss:  0.0005406076670624316
Valid Loss:  0.0005649719387292862
Epoch:  403  	Training Loss: 0.0005607756320387125
Test Loss:  0.0005396943306550384
Valid Loss:  0.0005648406804539263
Epoch:  404  	Training Loss: 0.0005597122944891453
Test Loss:  0.0005389319849200547
Valid Loss:  0.000564638408832252
Epoch:  405  	Training Loss: 0.0005587803898379207
Test Loss:  0.0005383443785831332
Valid Loss:  0.0005644062766805291
Epoch:  406  	Training Loss: 0.0005579248536378145
Test Loss:  0.0005376801127567887
Valid Loss:  0.0005643650074489415
Epoch:  407  	Training Loss: 0.0005571325891651213
Test Loss:  0.0005371879087761045
Valid Loss:  0.0005644622724503279
Epoch:  408  	Training Loss: 0.0005564159946516156
Test Loss:  0.000535544182639569
Valid Loss:  0.0005650749080814421
Epoch:  409  	Training Loss: 0.0005557273980230093
Test Loss:  0.0005362278898246586
Valid Loss:  0.000564764195587486
Epoch:  410  	Training Loss: 0.0005551547510549426
Test Loss:  0.0005346916732378304
Valid Loss:  0.0005652668187394738
Epoch:  411  	Training Loss: 0.0005545717431232333
Test Loss:  0.0005341763608157635
Valid Loss:  0.0005654822452925146
Epoch:  412  	Training Loss: 0.000554037222173065
Test Loss:  0.0005371521692723036
Valid Loss:  0.0005639364244416356
Epoch:  413  	Training Loss: 0.0005534900119528174
 83%|████████▎ | 414/500 [05:05<01:14,  1.15it/s] 83%|████████▎ | 416/500 [05:06<00:52,  1.60it/s] 84%|████████▎ | 418/500 [05:06<00:37,  2.19it/s] 84%|████████▍ | 420/500 [05:06<00:27,  2.94it/s] 84%|████████▍ | 422/500 [05:12<01:32,  1.18s/it] 85%|████████▍ | 424/500 [05:12<01:04,  1.18it/s] 85%|████████▌ | 426/500 [05:12<00:45,  1.63it/s] 86%|████████▌ | 428/500 [05:13<00:32,  2.23it/s] 86%|████████▌ | 430/500 [05:13<00:23,  3.00it/s] 86%|████████▋ | 432/500 [05:19<01:20,  1.19s/it] 87%|████████▋ | 434/500 [05:19<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:19<00:39,  1.62it/s] 88%|████████▊ | 438/500 [05:19<00:28,  2.21it/s] 88%|████████▊ | 440/500 [05:20<00:20,  2.97it/s] 88%|████████▊ | 442/500 [05:26<01:10,  1.21s/it] 89%|████████▉ | 444/500 [05:26<00:48,  1.15it/s] 89%|████████▉ | 446/500 [05:26<00:34,  1.58it/s] 90%|████████▉ | 448/500 [05:26<00:24,  2.16it/s] 90%|█████████ | 450/500 [05:27<00:17,  2.91it/s] 90%|█████████ | 452/500 [05:33<00:58,  1.23s/it] 91%|█████████ | 454/500 [05:33<00:40,  1.13it/s] 91%|█████████ | 456/500 [05:33<00:28,  1.57it/s] 92%|█████████▏| 458/500 [05:34<00:19,  2.14it/s] 92%|█████████▏| 460/500 [05:34<00:13,  2.89it/s] 92%|█████████▏| 462/500 [05:40<00:46,  1.21s/it] 93%|█████████▎| 464/500 [05:40<00:31,  1.15it/s] 93%|█████████▎| 466/500 [05:40<00:21,  1.59it/s] 94%|█████████▎| 468/500 [05:41<00:14,  2.18it/s] 94%|█████████▍| 470/500 [05:41<00:10,  2.93it/s] 94%|█████████▍| 472/500 [05:47<00:34,  1.25s/it] 95%|█████████▍| 474/500 [05:48<00:23,  1.12it/s] 95%|█████████▌| 476/500 [05:48<00:15,  1.55it/s] 96%|█████████▌| 478/500 [05:48<00:10,  2.13it/s] 96%|█████████▌| 480/500 [05:48<00:06,  2.87it/s]Test Loss:  0.0005359743372537196
Valid Loss:  0.0005639286828227341
Epoch:  414  	Training Loss: 0.0005530663765966892
Test Loss:  0.0005354906897991896
Valid Loss:  0.0005636568530462682
Epoch:  415  	Training Loss: 0.0005527820903807878
Test Loss:  0.0005351520958356559
Valid Loss:  0.0005635681445710361
Epoch:  416  	Training Loss: 0.0005525475717149675
Test Loss:  0.0005347869591787457
Valid Loss:  0.0005634103436022997
Epoch:  417  	Training Loss: 0.0005523165455088019
Test Loss:  0.0005348490085452795
Valid Loss:  0.000563133682589978
Epoch:  418  	Training Loss: 0.0005521122948266566
Test Loss:  0.0005344295641407371
Valid Loss:  0.0005628457292914391
Epoch:  419  	Training Loss: 0.0005519177066162229
Test Loss:  0.0005349115235731006
Valid Loss:  0.000562631874345243
Epoch:  420  	Training Loss: 0.0005517002427950501
Test Loss:  0.0005346327088773251
Valid Loss:  0.0005624733748845756
Epoch:  421  	Training Loss: 0.0005515014054253697
Test Loss:  0.0005342820659279823
Valid Loss:  0.0005625241319648921
Epoch:  422  	Training Loss: 0.000551288016140461
Test Loss:  0.0005354300374165177
Valid Loss:  0.0005611492088064551
Epoch:  423  	Training Loss: 0.000550478114746511
Test Loss:  0.0005345390527509153
Valid Loss:  0.0005605720216408372
Epoch:  424  	Training Loss: 0.0005497591919265687
Test Loss:  0.0005348239210434258
Valid Loss:  0.0005598415154963732
Epoch:  425  	Training Loss: 0.0005490884650498629
Test Loss:  0.0005339563358575106
Valid Loss:  0.000559481093659997
Epoch:  426  	Training Loss: 0.0005484496941789985
Test Loss:  0.0005345408571884036
Valid Loss:  0.0005588702624663711
Epoch:  427  	Training Loss: 0.0005478339153341949
Test Loss:  0.0005334729794412851
Valid Loss:  0.0005586894112639129
Epoch:  428  	Training Loss: 0.0005472449120134115
Test Loss:  0.0005341307260096073
Valid Loss:  0.0005581658333539963
Epoch:  429  	Training Loss: 0.0005466589354909956
Test Loss:  0.0005330960266292095
Valid Loss:  0.000558016006834805
Epoch:  430  	Training Loss: 0.0005460850661620498
Test Loss:  0.0005337797338142991
Valid Loss:  0.000557530322112143
Epoch:  431  	Training Loss: 0.000545526621863246
Test Loss:  0.000532760052010417
Valid Loss:  0.0005574070964939892
Epoch:  432  	Training Loss: 0.0005449724849313498
Test Loss:  0.000531161087565124
Valid Loss:  0.0005576140829361975
Epoch:  433  	Training Loss: 0.0005445154383778572
Test Loss:  0.0005317910108715296
Valid Loss:  0.0005569715285673738
Epoch:  434  	Training Loss: 0.000544278766028583
Test Loss:  0.0005321735516190529
Valid Loss:  0.0005565296160057187
Epoch:  435  	Training Loss: 0.0005440927343443036
Test Loss:  0.0005332791479304433
Valid Loss:  0.0005558975390158594
Epoch:  436  	Training Loss: 0.0005439583910629153
Test Loss:  0.0005329195992089808
Valid Loss:  0.0005558879347518086
Epoch:  437  	Training Loss: 0.0005438288790173829
Test Loss:  0.0005336531903594732
Valid Loss:  0.0005554429953917861
Epoch:  438  	Training Loss: 0.000543710426427424
Test Loss:  0.000533149519469589
Valid Loss:  0.0005555282114073634
Epoch:  439  	Training Loss: 0.0005436245119199157
Test Loss:  0.0005337131442502141
Valid Loss:  0.0005552108632400632
Epoch:  440  	Training Loss: 0.0005435285274870694
Test Loss:  0.0005340238567441702
Valid Loss:  0.0005550219211727381
Epoch:  441  	Training Loss: 0.000543448724783957
Test Loss:  0.0005332330474629998
Valid Loss:  0.0005552471848204732
Epoch:  442  	Training Loss: 0.0005433895858004689
Test Loss:  0.000534809660166502
Valid Loss:  0.0005553311202675104
Epoch:  443  	Training Loss: 0.0005431605968624353
Test Loss:  0.0005349112907424569
Valid Loss:  0.0005555686075240374
Epoch:  444  	Training Loss: 0.0005430052988231182
Test Loss:  0.0005347349215298891
Valid Loss:  0.0005558152915909886
Epoch:  445  	Training Loss: 0.0005428667645901442
Test Loss:  0.0005345800891518593
Valid Loss:  0.0005560560384765267
Epoch:  446  	Training Loss: 0.0005427376599982381
Test Loss:  0.0005343761877156794
Valid Loss:  0.0005562703590840101
Epoch:  447  	Training Loss: 0.0005426167626865208
Test Loss:  0.0005342836957424879
Valid Loss:  0.0005564750754274428
Epoch:  448  	Training Loss: 0.0005425016861408949
Test Loss:  0.0005341523210518062
Valid Loss:  0.0005566540639847517
Epoch:  449  	Training Loss: 0.0005423920811153948
Test Loss:  0.0005341258365660906
Valid Loss:  0.0005568260094150901
Epoch:  450  	Training Loss: 0.0005422858521342278
Test Loss:  0.0005340742645785213
Valid Loss:  0.0005569823551923037
Epoch:  451  	Training Loss: 0.0005421844543889165
Test Loss:  0.0005340786883607507
Valid Loss:  0.0005571318324655294
Epoch:  452  	Training Loss: 0.0005420868401415646
Test Loss:  0.0005353380693122745
Valid Loss:  0.0005568815395236015
Epoch:  453  	Training Loss: 0.0005417248466983438
Test Loss:  0.0005354898748919368
Valid Loss:  0.000556542887352407
Epoch:  454  	Training Loss: 0.0005415302002802491
Test Loss:  0.0005355674074962735
Valid Loss:  0.0005562480073422194
Epoch:  455  	Training Loss: 0.0005413530161604285
Test Loss:  0.0005354892928153276
Valid Loss:  0.000556090846657753
Epoch:  456  	Training Loss: 0.0005412113969214261
Test Loss:  0.0005354221211746335
Valid Loss:  0.0005559375858865678
Epoch:  457  	Training Loss: 0.0005410787998698652
Test Loss:  0.0005350902210921049
Valid Loss:  0.0005556922405958176
Epoch:  458  	Training Loss: 0.0005409411387518048
Test Loss:  0.0005357512272894382
Valid Loss:  0.0005558631382882595
Epoch:  459  	Training Loss: 0.0005407070275396109
Test Loss:  0.0005353842279873788
Valid Loss:  0.0005558129632845521
Epoch:  460  	Training Loss: 0.000540532695595175
Test Loss:  0.0005355741595849395
Valid Loss:  0.0005559315322898328
Epoch:  461  	Training Loss: 0.0005403303075581789
Test Loss:  0.0005353408050723374
Valid Loss:  0.0005559436976909637
Epoch:  462  	Training Loss: 0.0005401542293839157
Test Loss:  0.0005311061977408826
Valid Loss:  0.0005566147156059742
Epoch:  463  	Training Loss: 0.0005400073132477701
Test Loss:  0.0005333936423994601
Valid Loss:  0.0005562059232033789
Epoch:  464  	Training Loss: 0.0005399109795689583
Test Loss:  0.000532778212800622
Valid Loss:  0.0005563100567087531
Epoch:  465  	Training Loss: 0.0005398279754444957
Test Loss:  0.0005334386951290071
Valid Loss:  0.0005562049336731434
Epoch:  466  	Training Loss: 0.0005397518398240209
Test Loss:  0.0005334694287739694
Valid Loss:  0.0005561920115724206
Epoch:  467  	Training Loss: 0.0005396807100623846
Test Loss:  0.0005338478367775679
Valid Loss:  0.0005561413709074259
Epoch:  468  	Training Loss: 0.0005396109772846103
Test Loss:  0.0005340020288713276
Valid Loss:  0.0005561343859881163
Epoch:  469  	Training Loss: 0.0005395448533818126
Test Loss:  0.0005342178046703339
Valid Loss:  0.0005561087746173143
Epoch:  470  	Training Loss: 0.000539481989108026
Test Loss:  0.0005344350356608629
Valid Loss:  0.000556095561478287
Epoch:  471  	Training Loss: 0.0005394223262555897
Test Loss:  0.0005345668760128319
Valid Loss:  0.000556081417016685
Epoch:  472  	Training Loss: 0.0005393633618950844
Test Loss:  0.0005341185024008155
Valid Loss:  0.0005567896296270192
Epoch:  473  	Training Loss: 0.000538814754690975
Test Loss:  0.0005340495845302939
Valid Loss:  0.0005570065113715827
Epoch:  474  	Training Loss: 0.0005384841351769865
Test Loss:  0.0005333710578270257
Valid Loss:  0.0005570573266595602
Epoch:  475  	Training Loss: 0.0005381828523240983
Test Loss:  0.0005335097084753215
Valid Loss:  0.0005572100635617971
Epoch:  476  	Training Loss: 0.0005378645728342235
Test Loss:  0.0005330439889803529
Valid Loss:  0.000557274091988802
Epoch:  477  	Training Loss: 0.0005375728942453861
Test Loss:  0.0005329127889126539
Valid Loss:  0.0005573391099460423
Epoch:  478  	Training Loss: 0.0005372892483137548
Test Loss:  0.0005329016130417585
Valid Loss:  0.0005572425434365869
Epoch:  479  	Training Loss: 0.0005370040307752788
Test Loss:  0.0005323841469362378
Valid Loss:  0.000557213556021452
Epoch:  480  	Training Loss: 0.0005367230623960495
Test Loss:  0.0005323244258761406
Valid Loss:  0.0005571980145759881
Epoch:  481  	Training Loss: 0.0005364438984543085
Test Loss:  0.0005323911318555474
Valid Loss:   96%|█████████▋| 482/500 [05:54<00:21,  1.21s/it] 97%|█████████▋| 484/500 [05:55<00:13,  1.16it/s] 97%|█████████▋| 486/500 [05:55<00:08,  1.60it/s] 98%|█████████▊| 488/500 [05:55<00:05,  2.18it/s] 98%|█████████▊| 490/500 [05:55<00:03,  2.94it/s] 98%|█████████▊| 492/500 [06:01<00:09,  1.21s/it] 99%|█████████▉| 494/500 [06:02<00:05,  1.15it/s] 99%|█████████▉| 496/500 [06:02<00:02,  1.60it/s]100%|█████████▉| 498/500 [06:02<00:00,  2.19it/s]100%|██████████| 500/500 [06:02<00:00,  2.94it/s]100%|██████████| 500/500 [06:02<00:00,  1.38it/s]
0.0005570495268329978
Epoch:  482  	Training Loss: 0.0005361672956496477
Test Loss:  0.0005320771597325802
Valid Loss:  0.0005570980720221996
Epoch:  483  	Training Loss: 0.0005355239845812321
Test Loss:  0.0005316882743500173
Valid Loss:  0.0005571266519837081
Epoch:  484  	Training Loss: 0.0005348949925974011
Test Loss:  0.0005312722641974688
Valid Loss:  0.0005571289220824838
Epoch:  485  	Training Loss: 0.0005342765362001956
Test Loss:  0.0005308549734763801
Valid Loss:  0.0005571075016632676
Epoch:  486  	Training Loss: 0.0005336712347343564
Test Loss:  0.0005305876256898046
Valid Loss:  0.0005571381188929081
Epoch:  487  	Training Loss: 0.0005330767598934472
Test Loss:  0.0005301037454046309
Valid Loss:  0.0005570725188590586
Epoch:  488  	Training Loss: 0.0005324873491190374
Test Loss:  0.000529821845702827
Valid Loss:  0.0005570583743974566
Epoch:  489  	Training Loss: 0.0005319087067618966
Test Loss:  0.0005293491994962096
Valid Loss:  0.0005569501663558185
Epoch:  490  	Training Loss: 0.0005313375731930137
Test Loss:  0.0005290888366289437
Valid Loss:  0.0005568987689912319
Epoch:  491  	Training Loss: 0.0005307708634063601
Test Loss:  0.0005287831299938262
Valid Loss:  0.0005568340420722961
Epoch:  492  	Training Loss: 0.0005302114877849817
Test Loss:  0.0005283530335873365
Valid Loss:  0.0005560655845329165
Epoch:  493  	Training Loss: 0.0005295242881402373
Test Loss:  0.000528595584910363
Valid Loss:  0.0005553312366828322
Epoch:  494  	Training Loss: 0.0005289542023092508
Test Loss:  0.0005289678229019046
Valid Loss:  0.0005546866450458765
Epoch:  495  	Training Loss: 0.0005284458165988326
Test Loss:  0.0005293141584843397
Valid Loss:  0.0005541410646401346
Epoch:  496  	Training Loss: 0.0005279943579807878
Test Loss:  0.0005295330774970353
Valid Loss:  0.0005537326214835048
Epoch:  497  	Training Loss: 0.0005275829462334514
Test Loss:  0.000529768702108413
Valid Loss:  0.0005533702205866575
Epoch:  498  	Training Loss: 0.0005271924892440438
Test Loss:  0.0005299734184518456
Valid Loss:  0.0005530555499717593
Epoch:  499  	Training Loss: 0.0005268177483230829
Test Loss:  0.0005301446653902531
Valid Loss:  0.000552779994904995
Epoch:  500  	Training Loss: 0.0005264557548798621
Test Loss:  0.0005302856443449855
Valid Loss:  0.0005525361048057675
seed is  4
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:34, 14.58it/s]  1%|          | 4/500 [00:00<00:31, 15.55it/s]  1%|          | 6/500 [00:00<00:31, 15.89it/s]  2%|▏         | 8/500 [00:00<00:30, 15.98it/s]  2%|▏         | 10/500 [00:00<00:32, 14.95it/s]  2%|▏         | 12/500 [00:00<00:34, 13.97it/s]  3%|▎         | 14/500 [00:00<00:34, 14.11it/s]  3%|▎         | 16/500 [00:01<00:32, 14.72it/s]  4%|▎         | 18/500 [00:01<00:31, 15.16it/s]  4%|▍         | 20/500 [00:01<00:31, 15.41it/s]  4%|▍         | 22/500 [00:01<00:30, 15.66it/s]  5%|▍         | 24/500 [00:01<00:30, 15.86it/s]  5%|▌         | 26/500 [00:01<00:30, 15.67it/s]  6%|▌         | 28/500 [00:01<00:30, 15.72it/s]  6%|▌         | 30/500 [00:01<00:29, 15.86it/s]  6%|▋         | 32/500 [00:02<00:29, 15.99it/s]  7%|▋         | 34/500 [00:02<00:28, 16.11it/s]  7%|▋         | 36/500 [00:02<00:28, 16.18it/s]  8%|▊         | 38/500 [00:02<00:28, 16.22it/s]  8%|▊         | 40/500 [00:02<00:28, 16.22it/s]  8%|▊         | 42/500 [00:02<00:28, 16.21it/s]  9%|▉         | 44/500 [00:02<00:28, 16.07it/s]  9%|▉         | 46/500 [00:02<00:28, 15.88it/s] 10%|▉         | 48/500 [00:03<00:29, 15.16it/s] 10%|█         | 50/500 [00:03<00:29, 15.35it/s] 10%|█         | 52/500 [00:03<00:29, 15.06it/s] 11%|█         | 54/500 [00:03<00:29, 14.97it/s] 11%|█         | 56/500 [00:03<00:29, 15.07it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.39it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.62it/s] 12%|█▏        | 62/500 [00:04<00:28, 15.47it/s] 13%|█▎        | 64/500 [00:04<00:28, 15.27it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.28it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.55it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.68it/s] 14%|█▍        | 72/500 [00:04<00:28, 15.14it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.37it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.62it/s] 16%|█▌        | 78/500 [00:05<00:28, 14.57it/s] 16%|█▌        | 80/500 [00:05<00:28, 14.59it/s] 16%|█▋        | 82/500 [00:05<00:27, 15.04it/s] 17%|█▋        | 84/500 [00:05<00:27, 15.36it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.66it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.90it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.04it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.14it/s] 19%|█▉        | 94/500 [00:06<00:25, 16.19it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.20it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.29it/s] 20%|██        | 100/500 [00:06<00:24, 16.28it/s] 20%|██        | 102/500 [00:06<00:24, 16.24it/s] 21%|██        | 104/500 [00:06<00:24, 16.29it/s] 21%|██        | 106/500 [00:06<00:24, 16.32it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.81it/s] 22%|██▏       | 110/500 [00:07<00:24, 15.99it/s] 22%|██▏       | 112/500 [00:07<00:24, 16.02it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.11it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.15it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.22it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.22it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.24it/s] 25%|██▍       | 124/500 [00:07<00:24, 15.19it/s]Epoch:  1  	Training Loss: 0.07232363522052765
Test Loss:  1478.097412109375
Valid Loss:  1466.017578125
Epoch:  2  	Training Loss: 1454.38330078125
Test Loss:  2577248276185088.0
Valid Loss:  2524927521456128.0
Epoch:  3  	Training Loss: 2558762468507648.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:26, 14.18it/s] 26%|██▌       | 128/500 [00:08<00:27, 13.59it/s] 26%|██▌       | 130/500 [00:08<00:28, 13.10it/s] 26%|██▋       | 132/500 [00:08<00:26, 13.70it/s] 27%|██▋       | 134/500 [00:08<00:25, 14.31it/s] 27%|██▋       | 136/500 [00:08<00:24, 14.82it/s] 28%|██▊       | 138/500 [00:08<00:23, 15.22it/s] 28%|██▊       | 140/500 [00:09<00:23, 15.01it/s] 28%|██▊       | 142/500 [00:09<00:25, 14.03it/s] 29%|██▉       | 144/500 [00:09<00:26, 13.46it/s] 29%|██▉       | 146/500 [00:09<00:27, 13.11it/s] 30%|██▉       | 148/500 [00:09<00:27, 12.75it/s] 30%|███       | 150/500 [00:09<00:28, 12.48it/s] 30%|███       | 152/500 [00:10<00:27, 12.84it/s] 31%|███       | 154/500 [00:10<00:25, 13.69it/s] 31%|███       | 156/500 [00:10<00:24, 13.85it/s] 32%|███▏      | 158/500 [00:10<00:23, 14.47it/s] 32%|███▏      | 160/500 [00:10<00:22, 14.90it/s] 32%|███▏      | 162/500 [00:10<00:22, 15.23it/s] 33%|███▎      | 164/500 [00:10<00:22, 15.17it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.30it/s] 34%|███▎      | 168/500 [00:11<00:22, 14.49it/s] 34%|███▍      | 170/500 [00:11<00:23, 13.79it/s] 34%|███▍      | 172/500 [00:11<00:25, 13.04it/s] 35%|███▍      | 174/500 [00:11<00:25, 12.78it/s] 35%|███▌      | 176/500 [00:11<00:25, 12.63it/s] 36%|███▌      | 178/500 [00:11<00:25, 12.53it/s] 36%|███▌      | 180/500 [00:12<00:25, 12.46it/s] 36%|███▋      | 182/500 [00:12<00:25, 12.37it/s] 37%|███▋      | 184/500 [00:12<00:25, 12.35it/s] 37%|███▋      | 186/500 [00:12<00:25, 12.26it/s] 38%|███▊      | 188/500 [00:12<00:24, 12.83it/s] 38%|███▊      | 190/500 [00:12<00:23, 13.34it/s] 38%|███▊      | 192/500 [00:12<00:21, 14.05it/s] 39%|███▉      | 194/500 [00:13<00:20, 14.62it/s] 39%|███▉      | 196/500 [00:13<00:20, 15.02it/s] 40%|███▉      | 198/500 [00:13<00:19, 15.24it/s] 40%|████      | 200/500 [00:13<00:19, 15.40it/s] 40%|████      | 202/500 [00:13<00:19, 15.67it/s] 41%|████      | 204/500 [00:13<00:18, 15.84it/s] 41%|████      | 206/500 [00:13<00:18, 15.96it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.01it/s] 42%|████▏     | 210/500 [00:14<00:18, 16.10it/s] 42%|████▏     | 212/500 [00:14<00:17, 16.15it/s] 43%|████▎     | 214/500 [00:14<00:17, 16.19it/s] 43%|████▎     | 216/500 [00:14<00:17, 16.18it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.27it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.21it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.19it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.22it/s] 45%|████▌     | 226/500 [00:15<00:16, 16.20it/s] 46%|████▌     | 228/500 [00:15<00:17, 15.99it/s] 46%|████▌     | 230/500 [00:15<00:16, 15.99it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.03it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.12it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.18it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.22it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.22it/s] 48%|████▊     | 242/500 [00:16<00:15, 16.18it/s] 49%|████▉     | 244/500 [00:16<00:15, 16.12it/s] 49%|████▉     | 246/500 [00:16<00:15, 16.13it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.05it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.05it/s] 50%|█████     | 252/500 [00:16<00:15, 16.06it/s] 51%|█████     | 254/500 [00:16<00:15, 16.12it/s] 51%|█████     | 256/500 [00:16<00:15, 15.94it/s] 52%|█████▏    | 258/500 [00:17<00:15, 15.81it/s] 52%|█████▏    | 260/500 [00:17<00:15, 15.71it/s] 52%|█████▏    | 262/500 [00:17<00:15, 15.78it/s] 53%|█████▎    | 264/500 [00:17<00:14, 15.90it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.84it/s] 54%|█████▎    | 268/500 [00:17<00:15, 15.41it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.63it/s] 54%|█████▍    | 272/500 [00:17<00:15, 15.09it/s] 55%|█████▍    | 274/500 [00:18<00:16, 13.86it/s] 55%|█████▌    | 276/500 [00:18<00:15, 14.24it/s] 56%|█████▌    | 278/500 [00:18<00:15, 14.44it/s] 56%|█████▌    | 280/500 [00:18<00:16, 13.69it/s] 56%|█████▋    | 282/500 [00:18<00:16, 13.21it/s] 57%|█████▋    | 284/500 [00:18<00:16, 12.90it/s] 57%|█████▋    | 286/500 [00:19<00:16, 12.92it/s] 58%|█████▊    | 288/500 [00:19<00:15, 13.66it/s] 58%|█████▊    | 290/500 [00:19<00:14, 14.20it/s] 58%|█████▊    | 292/500 [00:19<00:14, 14.79it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.20it/s] 59%|█████▉    | 296/500 [00:19<00:13, 14.91it/s] 60%|█████▉    | 298/500 [00:19<00:13, 15.13it/s] 60%|██████    | 300/500 [00:19<00:12, 15.43it/s] 60%|██████    | 302/500 [00:20<00:12, 15.59it/s] 61%|██████    | 304/500 [00:20<00:12, 15.80it/s] 61%|██████    | 306/500 [00:20<00:12, 15.87it/s] 62%|██████▏   | 308/500 [00:20<00:12, 15.91it/s] 62%|██████▏   | 310/500 [00:20<00:11, 16.03it/s] 62%|██████▏   | 312/500 [00:20<00:11, 16.10it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.12it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.16it/s] 64%|██████▎   | 318/500 [00:21<00:11, 16.20it/s] 64%|██████▍   | 320/500 [00:21<00:11, 16.21it/s] 64%|██████▍   | 322/500 [00:21<00:10, 16.27it/s] 65%|██████▍   | 324/500 [00:21<00:10, 16.31it/s] 65%|██████▌   | 326/500 [00:21<00:10, 16.32it/s] 66%|██████▌   | 328/500 [00:21<00:10, 16.21it/s] 66%|██████▌   | 330/500 [00:21<00:10, 15.95it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.98it/s] 67%|██████▋   | 334/500 [00:22<00:10, 16.07it/s] 67%|██████▋   | 336/500 [00:22<00:10, 16.16it/s] 68%|██████▊   | 338/500 [00:22<00:10, 16.18it/s] 68%|██████▊   | 340/500 [00:22<00:09, 16.17it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.20it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.25it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.14it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.16it/s] 70%|███████   | 350/500 [00:23<00:09, 16.11it/s] 70%|███████   | 352/500 [00:23<00:09, 16.01it/s] 71%|███████   | 354/500 [00:23<00:09, 15.67it/s] 71%|███████   | 356/500 [00:23<00:09, 15.91it/s] 72%|███████▏  | 358/500 [00:23<00:08, 16.00it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.14it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.93it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.05it/s] 73%|███████▎  | 366/500 [00:24<00:08, 16.16it/s] 74%|███████▎  | 368/500 [00:24<00:08, 16.18it/s] 74%|███████▍  | 370/500 [00:24<00:08, 16.11it/s] 74%|███████▍  | 372/500 [00:24<00:07, 16.12it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 16.12it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.11it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.08it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.89it/s] 76%|███████▋  | 382/500 [00:25<00:07, 14.87it/s] 77%|███████▋  | 384/500 [00:25<00:08, 14.01it/s] 77%|███████▋  | 386/500 [00:25<00:08, 13.45it/s] 78%|███████▊  | 388/500 [00:25<00:08, 12.90it/s] 78%|███████▊  | 390/500 [00:25<00:08, 13.39it/s] 78%|███████▊  | 392/500 [00:25<00:08, 13.04it/s] 79%|███████▉  | 394/500 [00:26<00:08, 12.81it/s] 79%|███████▉  | 396/500 [00:26<00:08, 12.91it/s] 80%|███████▉  | 398/500 [00:26<00:07, 12.84it/s] 80%|████████  | 400/500 [00:26<00:07, 13.74it/s] 80%|████████  | 402/500 [00:26<00:07, 13.57it/s] 81%|████████  | 404/500 [00:26<00:07, 13.46it/s] 81%|████████  | 406/500 [00:26<00:06, 14.19it/s] 82%|████████▏ | 408/500 [00:27<00:06, 14.70it/s] 82%|████████▏ | 410/500 [00:27<00:05, 15.10it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.06it/s] 83%|████████▎ | 414/500 [00:27<00:05, 14.87it/s] 83%|████████▎ | 416/500 [00:27<00:06, 13.96it/s] 84%|████████▎ | 418/500 [00:27<00:06, 13.44it/s] 84%|████████▍ | 420/500 [00:27<00:06, 13.16it/s] 84%|████████▍ | 422/500 [00:28<00:05, 14.01it/s] 85%|████████▍ | 424/500 [00:28<00:05, 14.69it/s] 85%|████████▌ | 426/500 [00:28<00:04, 14.98it/s] 86%|████████▌ | 428/500 [00:28<00:04, 15.30it/s] 86%|████████▌ | 430/500 [00:28<00:04, 15.33it/s] 86%|████████▋ | 432/500 [00:28<00:04, 14.77it/s] 87%|████████▋ | 434/500 [00:28<00:04, 14.99it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.40it/s] 88%|████████▊ | 438/500 [00:29<00:03, 15.63it/s] 88%|████████▊ | 440/500 [00:29<00:03, 15.82it/s] 88%|████████▊ | 442/500 [00:29<00:03, 15.95it/s] 89%|████████▉ | 444/500 [00:29<00:03, 15.89it/s] 89%|████████▉ | 446/500 [00:29<00:03, 15.19it/s] 90%|████████▉ | 448/500 [00:29<00:03, 15.24it/s] 90%|█████████ | 450/500 [00:29<00:03, 15.33it/s] 90%|█████████ | 452/500 [00:29<00:03, 15.56it/s] 91%|█████████ | 454/500 [00:30<00:02, 15.76it/s] 91%|█████████ | 456/500 [00:30<00:02, 15.80it/s] 92%|█████████▏| 458/500 [00:30<00:02, 15.92it/s] 92%|█████████▏| 460/500 [00:30<00:02, 16.03it/s] 92%|█████████▏| 462/500 [00:30<00:02, 16.09it/s] 93%|█████████▎| 464/500 [00:30<00:02, 16.15it/s] 93%|█████████▎| 466/500 [00:30<00:02, 16.13it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.88it/s] 94%|█████████▍| 470/500 [00:31<00:01, 15.69it/s] 94%|█████████▍| 472/500 [00:31<00:01, 15.52it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.50it/s] 95%|█████████▌| 476/500 [00:31<00:01, 14.78it/s] 96%|█████████▌| 478/500 [00:31<00:01, 13.88it/s] 96%|█████████▌| 480/500 [00:31<00:01, 13.59it/s] 96%|█████████▋| 482/500 [00:31<00:01, 13.97it/s] 97%|█████████▋| 484/500 [00:32<00:01, 14.60it/s] 97%|█████████▋| 486/500 [00:32<00:00, 15.04it/s] 98%|█████████▊| 488/500 [00:32<00:00, 15.37it/s] 98%|█████████▊| 490/500 [00:32<00:00, 15.62it/s] 98%|█████████▊| 492/500 [00:32<00:00, 15.76it/s] 99%|█████████▉| 494/500 [00:32<00:00, 15.84it/s] 99%|█████████▉| 496/500 [00:32<00:00, 15.87it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 15.95it/s]100%|██████████| 500/500 [00:33<00:00, 16.00it/s]100%|██████████| 500/500 [00:33<00:00, 15.13it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  4
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:51,  6.48s/it]  1%|          | 3/500 [00:06<14:20,  1.73s/it]  1%|          | 5/500 [00:06<07:13,  1.14it/s]  1%|▏         | 7/500 [00:06<04:22,  1.88it/s]  2%|▏         | 9/500 [00:07<02:54,  2.81it/s]  2%|▏         | 11/500 [00:13<10:55,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:48,  2.12it/s]  4%|▍         | 19/500 [00:14<02:49,  2.84it/s]  4%|▍         | 21/500 [00:20<10:03,  1.26s/it]  5%|▍         | 23/500 [00:20<07:09,  1.11it/s]  5%|▌         | 25/500 [00:20<05:10,  1.53it/s]  5%|▌         | 27/500 [00:21<03:47,  2.08it/s]  6%|▌         | 29/500 [00:21<02:50,  2.77it/s]  6%|▌         | 31/500 [00:28<09:55,  1.27s/it]  7%|▋         | 33/500 [00:28<07:04,  1.10it/s]  7%|▋         | 35/500 [00:28<05:04,  1.53it/s]  7%|▋         | 37/500 [00:28<03:42,  2.08it/s]  8%|▊         | 39/500 [00:28<02:44,  2.80it/s]  8%|▊         | 41/500 [00:35<09:15,  1.21s/it]  9%|▊         | 43/500 [00:35<06:35,  1.15it/s]  9%|▉         | 45/500 [00:35<04:44,  1.60it/s]  9%|▉         | 47/500 [00:35<03:27,  2.19it/s] 10%|▉         | 49/500 [00:35<02:33,  2.95it/s] 10%|█         | 51/500 [00:41<08:57,  1.20s/it] 11%|█         | 53/500 [00:42<06:26,  1.16it/s] 11%|█         | 55/500 [00:42<04:40,  1.59it/s] 11%|█▏        | 57/500 [00:42<03:27,  2.14it/s] 12%|█▏        | 59/500 [00:42<02:35,  2.83it/s] 12%|█▏        | 61/500 [00:49<08:50,  1.21s/it] 13%|█▎        | 63/500 [00:49<06:20,  1.15it/s] 13%|█▎        | 65/500 [00:49<04:36,  1.57it/s] 13%|█▎        | 67/500 [00:49<03:24,  2.12it/s] 14%|█▍        | 69/500 [00:49<02:32,  2.83it/s] 14%|█▍        | 71/500 [00:56<08:39,  1.21s/it] 15%|█▍        | 73/500 [00:56<06:10,  1.15it/s]Epoch:  1  	Training Loss: 0.07232363522052765
Test Loss:  101.50831604003906
Valid Loss:  99.14395904541016
Epoch:  2  	Training Loss: 94.53443908691406
Test Loss:  0.1725722849369049
Valid Loss:  0.16663454473018646
Epoch:  3  	Training Loss: 0.12695738673210144
Test Loss:  0.1705191731452942
Valid Loss:  0.16470761597156525
Epoch:  4  	Training Loss: 0.1253640502691269
Test Loss:  0.1685119867324829
Valid Loss:  0.16282394528388977
Epoch:  5  	Training Loss: 0.12380862981081009
Test Loss:  0.16665244102478027
Valid Loss:  0.16108037531375885
Epoch:  6  	Training Loss: 0.1224169135093689
Test Loss:  0.16623781621456146
Valid Loss:  0.16050338745117188
Epoch:  7  	Training Loss: 0.12210498750209808
Test Loss:  0.16623744368553162
Valid Loss:  0.1605003923177719
Epoch:  8  	Training Loss: 0.12210428714752197
Test Loss:  0.16623744368553162
Valid Loss:  0.16050037741661072
Epoch:  9  	Training Loss: 0.12210428714752197
Test Loss:  0.1662374585866928
Valid Loss:  0.1605004072189331
Epoch:  10  	Training Loss: 0.12210429459810257
Test Loss:  0.16623744368553162
Valid Loss:  0.1605004072189331
Epoch:  11  	Training Loss: 0.12210429459810257
Test Loss:  0.166237473487854
Valid Loss:  0.1605003923177719
Epoch:  12  	Training Loss: 0.12210430204868317
Test Loss:  0.16623741388320923
Valid Loss:  0.16050036251544952
Epoch:  13  	Training Loss: 0.12210425734519958
Test Loss:  0.16623736917972565
Valid Loss:  0.16050031781196594
Epoch:  14  	Training Loss: 0.12210424244403839
Test Loss:  0.16623732447624207
Valid Loss:  0.16050027310848236
Epoch:  15  	Training Loss: 0.12210419774055481
Test Loss:  0.16623727977275848
Valid Loss:  0.16050022840499878
Epoch:  16  	Training Loss: 0.12210416793823242
Test Loss:  0.1662372350692749
Valid Loss:  0.1605001986026764
Epoch:  17  	Training Loss: 0.12210413813591003
Test Loss:  0.16623720526695251
Valid Loss:  0.1605001538991928
Epoch:  18  	Training Loss: 0.12210410088300705
Test Loss:  0.16623714566230774
Valid Loss:  0.16050010919570923
Epoch:  19  	Training Loss: 0.12210406363010406
Test Loss:  0.16623711585998535
Valid Loss:  0.16050007939338684
Epoch:  20  	Training Loss: 0.12210403382778168
Test Loss:  0.16623705625534058
Valid Loss:  0.16050001978874207
Epoch:  21  	Training Loss: 0.12210400402545929
Test Loss:  0.1662370264530182
Valid Loss:  0.16049998998641968
Epoch:  22  	Training Loss: 0.1221039742231369
Test Loss:  0.1662369668483734
Valid Loss:  0.1604999452829361
Epoch:  23  	Training Loss: 0.12210392951965332
Test Loss:  0.16623693704605103
Valid Loss:  0.16049990057945251
Epoch:  24  	Training Loss: 0.12210389971733093
Test Loss:  0.16623687744140625
Valid Loss:  0.16049985587596893
Epoch:  25  	Training Loss: 0.12210385501384735
Test Loss:  0.16623683273792267
Valid Loss:  0.16049981117248535
Epoch:  26  	Training Loss: 0.12210381776094437
Test Loss:  0.1662367880344391
Valid Loss:  0.16049975156784058
Epoch:  27  	Training Loss: 0.12210378050804138
Test Loss:  0.1662367433309555
Valid Loss:  0.1604997217655182
Epoch:  28  	Training Loss: 0.1221037432551384
Test Loss:  0.16623668372631073
Valid Loss:  0.1604996621608734
Epoch:  29  	Training Loss: 0.12210370600223541
Test Loss:  0.16623663902282715
Valid Loss:  0.16049961745738983
Epoch:  30  	Training Loss: 0.12210366874933243
Test Loss:  0.16623657941818237
Valid Loss:  0.16049957275390625
Epoch:  31  	Training Loss: 0.12210363149642944
Test Loss:  0.1662365347146988
Valid Loss:  0.16049952805042267
Epoch:  32  	Training Loss: 0.12210359424352646
Test Loss:  0.1662364900112152
Valid Loss:  0.1604994833469391
Epoch:  33  	Training Loss: 0.12210356444120407
Test Loss:  0.16623646020889282
Valid Loss:  0.1604994535446167
Epoch:  34  	Training Loss: 0.12210352718830109
Test Loss:  0.16623640060424805
Valid Loss:  0.16049940884113312
Epoch:  35  	Training Loss: 0.1221034824848175
Test Loss:  0.16623635590076447
Valid Loss:  0.16049934923648834
Epoch:  36  	Training Loss: 0.12210345268249512
Test Loss:  0.16623631119728088
Valid Loss:  0.16049930453300476
Epoch:  37  	Training Loss: 0.12210340797901154
Test Loss:  0.1662362515926361
Valid Loss:  0.16049927473068237
Epoch:  38  	Training Loss: 0.12210337817668915
Test Loss:  0.16623622179031372
Valid Loss:  0.1604992300271988
Epoch:  39  	Training Loss: 0.12210334837436676
Test Loss:  0.16623617708683014
Valid Loss:  0.1604991853237152
Epoch:  40  	Training Loss: 0.12210331112146378
Test Loss:  0.16623613238334656
Valid Loss:  0.16049912571907043
Epoch:  41  	Training Loss: 0.12210327386856079
Test Loss:  0.16623608767986298
Valid Loss:  0.16049909591674805
Epoch:  42  	Training Loss: 0.1221032440662384
Test Loss:  0.166236013174057
Valid Loss:  0.16049903631210327
Epoch:  43  	Training Loss: 0.12210318446159363
Test Loss:  0.16623593866825104
Valid Loss:  0.1604989618062973
Epoch:  44  	Training Loss: 0.12210313975811005
Test Loss:  0.16623586416244507
Valid Loss:  0.16049890220165253
Epoch:  45  	Training Loss: 0.12210308760404587
Test Loss:  0.1662358045578003
Valid Loss:  0.16049882769584656
Epoch:  46  	Training Loss: 0.12210302799940109
Test Loss:  0.16623573005199432
Valid Loss:  0.16049876809120178
Epoch:  47  	Training Loss: 0.12210298329591751
Test Loss:  0.16623568534851074
Valid Loss:  0.160498708486557
Epoch:  48  	Training Loss: 0.12210293114185333
Test Loss:  0.16623561084270477
Valid Loss:  0.16049863398075104
Epoch:  49  	Training Loss: 0.12210287153720856
Test Loss:  0.1662355363368988
Valid Loss:  0.16049855947494507
Epoch:  50  	Training Loss: 0.12210281938314438
Test Loss:  0.16623547673225403
Valid Loss:  0.1604984998703003
Epoch:  51  	Training Loss: 0.1221027672290802
Test Loss:  0.16623540222644806
Valid Loss:  0.16049844026565552
Epoch:  52  	Training Loss: 0.12210272252559662
Test Loss:  0.16623538732528687
Valid Loss:  0.16049841046333313
Epoch:  53  	Training Loss: 0.12210270017385483
Test Loss:  0.16623535752296448
Valid Loss:  0.16049839556217194
Epoch:  54  	Training Loss: 0.12210266292095184
Test Loss:  0.1662353128194809
Valid Loss:  0.16049835085868835
Epoch:  55  	Training Loss: 0.12210264801979065
Test Loss:  0.16623526811599731
Valid Loss:  0.16049832105636597
Epoch:  56  	Training Loss: 0.12210263311862946
Test Loss:  0.16623523831367493
Valid Loss:  0.16049829125404358
Epoch:  57  	Training Loss: 0.12210260331630707
Test Loss:  0.16623520851135254
Valid Loss:  0.16049827635288239
Epoch:  58  	Training Loss: 0.12210258841514587
Test Loss:  0.16623519361019135
Valid Loss:  0.1604982614517212
Epoch:  59  	Training Loss: 0.12210255861282349
Test Loss:  0.16623517870903015
Valid Loss:  0.1604982167482376
Epoch:  60  	Training Loss: 0.1221025362610817
Test Loss:  0.16623513400554657
Valid Loss:  0.16049818694591522
Epoch:  61  	Training Loss: 0.1221025139093399
Test Loss:  0.16623510420322418
Valid Loss:  0.16049817204475403
Epoch:  62  	Training Loss: 0.12210248410701752
Test Loss:  0.1662350594997406
Valid Loss:  0.16049811244010925
Epoch:  63  	Training Loss: 0.12210244685411453
Test Loss:  0.16623497009277344
Valid Loss:  0.16049805283546448
Epoch:  64  	Training Loss: 0.12210239470005035
Test Loss:  0.16623492538928986
Valid Loss:  0.1604979932308197
Epoch:  65  	Training Loss: 0.12210234999656677
Test Loss:  0.1662348508834839
Valid Loss:  0.16049793362617493
Epoch:  66  	Training Loss: 0.12210230529308319
Test Loss:  0.1662348061800003
Valid Loss:  0.16049787402153015
Epoch:  67  	Training Loss: 0.12210226058959961
Test Loss:  0.16623473167419434
Valid Loss:  0.16049781441688538
Epoch:  68  	Training Loss: 0.12210221588611603
Test Loss:  0.16623470187187195
Valid Loss:  0.1604977697134018
Epoch:  69  	Training Loss: 0.12210217118263245
Test Loss:  0.16623462736606598
Valid Loss:  0.1604977250099182
Epoch:  70  	Training Loss: 0.12210212647914886
Test Loss:  0.1662345826625824
Valid Loss:  0.16049766540527344
Epoch:  71  	Training Loss: 0.12210208177566528
Test Loss:  0.16623452305793762
Valid Loss:  0.16049760580062866
Epoch:  72  	Training Loss: 0.1221020370721817
Test Loss:  0.16623446345329285
Valid Loss:  0.1604975461959839
Epoch:  73  	Training Loss: 0.12210199236869812
Test Loss:  0.16623440384864807
Valid Loss:  0.1604975163936615
 15%|█▌        | 75/500 [00:56<04:26,  1.59it/s] 15%|█▌        | 77/500 [00:56<03:14,  2.18it/s] 16%|█▌        | 79/500 [00:56<02:23,  2.93it/s] 16%|█▌        | 81/500 [01:02<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:03<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:03<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:03<03:06,  2.22it/s] 18%|█▊        | 89/500 [01:03<02:17,  2.98it/s] 18%|█▊        | 91/500 [01:09<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:10<05:49,  1.17it/s] 19%|█▉        | 95/500 [01:10<04:10,  1.61it/s] 19%|█▉        | 97/500 [01:10<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:10<02:15,  2.96it/s] 20%|██        | 101/500 [01:17<08:14,  1.24s/it] 21%|██        | 103/500 [01:17<05:52,  1.13it/s] 21%|██        | 105/500 [01:17<04:13,  1.56it/s] 21%|██▏       | 107/500 [01:17<03:03,  2.14it/s] 22%|██▏       | 109/500 [01:17<02:15,  2.88it/s] 22%|██▏       | 111/500 [01:24<07:52,  1.21s/it] 23%|██▎       | 113/500 [01:24<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:24<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:24<02:55,  2.18it/s] 24%|██▍       | 119/500 [01:24<02:09,  2.93it/s] 24%|██▍       | 121/500 [01:31<07:33,  1.20s/it] 25%|██▍       | 123/500 [01:31<05:23,  1.16it/s] 25%|██▌       | 125/500 [01:31<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:31<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:31<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:37<07:17,  1.19s/it] 27%|██▋       | 133/500 [01:38<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:38<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:38<02:48,  2.15it/s] 28%|██▊       | 139/500 [01:38<02:06,  2.85it/s] 28%|██▊       | 141/500 [01:44<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:45<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:45<03:39,  1.62it/s]Epoch:  74  	Training Loss: 0.12210194766521454
Test Loss:  0.1662343442440033
Valid Loss:  0.16049745678901672
Epoch:  75  	Training Loss: 0.12210191786289215
Test Loss:  0.1662343144416809
Valid Loss:  0.16049741208553314
Epoch:  76  	Training Loss: 0.12210187315940857
Test Loss:  0.16623425483703613
Valid Loss:  0.16049736738204956
Epoch:  77  	Training Loss: 0.12210183590650558
Test Loss:  0.16623419523239136
Valid Loss:  0.16049730777740479
Epoch:  78  	Training Loss: 0.1221017986536026
Test Loss:  0.16623413562774658
Valid Loss:  0.1604972779750824
Epoch:  79  	Training Loss: 0.12210175395011902
Test Loss:  0.1662341058254242
Valid Loss:  0.16049721837043762
Epoch:  80  	Training Loss: 0.12210170924663544
Test Loss:  0.16623404622077942
Valid Loss:  0.16049715876579285
Epoch:  81  	Training Loss: 0.12210167944431305
Test Loss:  0.16623398661613464
Valid Loss:  0.16049711406230927
Epoch:  82  	Training Loss: 0.12210163474082947
Test Loss:  0.16623395681381226
Valid Loss:  0.16049706935882568
Epoch:  83  	Training Loss: 0.12210160493850708
Test Loss:  0.16623389720916748
Valid Loss:  0.1604970097541809
Epoch:  84  	Training Loss: 0.1221015602350235
Test Loss:  0.1662338376045227
Valid Loss:  0.16049697995185852
Epoch:  85  	Training Loss: 0.12210152298212051
Test Loss:  0.16623380780220032
Valid Loss:  0.16049692034721375
Epoch:  86  	Training Loss: 0.12210148572921753
Test Loss:  0.16623374819755554
Valid Loss:  0.16049687564373016
Epoch:  87  	Training Loss: 0.12210144102573395
Test Loss:  0.16623368859291077
Valid Loss:  0.16049683094024658
Epoch:  88  	Training Loss: 0.12210141122341156
Test Loss:  0.16623364388942719
Valid Loss:  0.1604967713356018
Epoch:  89  	Training Loss: 0.12210137397050858
Test Loss:  0.1662335991859436
Valid Loss:  0.16049674153327942
Epoch:  90  	Training Loss: 0.12210133671760559
Test Loss:  0.16623353958129883
Valid Loss:  0.16049668192863464
Epoch:  91  	Training Loss: 0.12210129201412201
Test Loss:  0.16623350977897644
Valid Loss:  0.16049663722515106
Epoch:  92  	Training Loss: 0.12210125476121902
Test Loss:  0.16623345017433167
Valid Loss:  0.16049659252166748
Epoch:  93  	Training Loss: 0.12210121005773544
Test Loss:  0.1662333905696869
Valid Loss:  0.1604965329170227
Epoch:  94  	Training Loss: 0.12210117280483246
Test Loss:  0.1662333607673645
Valid Loss:  0.16049648821353912
Epoch:  95  	Training Loss: 0.12210112810134888
Test Loss:  0.16623328626155853
Valid Loss:  0.16049644351005554
Epoch:  96  	Training Loss: 0.1221010833978653
Test Loss:  0.16623324155807495
Valid Loss:  0.16049638390541077
Epoch:  97  	Training Loss: 0.12210104614496231
Test Loss:  0.16623316705226898
Valid Loss:  0.16049633920192719
Epoch:  98  	Training Loss: 0.12210099399089813
Test Loss:  0.1662331223487854
Valid Loss:  0.1604962795972824
Epoch:  99  	Training Loss: 0.12210096418857574
Test Loss:  0.16623306274414062
Valid Loss:  0.16049623489379883
Epoch:  100  	Training Loss: 0.12210092693567276
Test Loss:  0.16623301804065704
Valid Loss:  0.16049617528915405
Epoch:  101  	Training Loss: 0.12210087478160858
Test Loss:  0.16623294353485107
Valid Loss:  0.16049613058567047
Epoch:  102  	Training Loss: 0.1221008449792862
Test Loss:  0.1662329137325287
Valid Loss:  0.1604960858821869
Epoch:  103  	Training Loss: 0.12210080027580261
Test Loss:  0.1662328541278839
Valid Loss:  0.1604960411787033
Epoch:  104  	Training Loss: 0.12210075557231903
Test Loss:  0.16623280942440033
Valid Loss:  0.16049598157405853
Epoch:  105  	Training Loss: 0.12210071831941605
Test Loss:  0.16623276472091675
Valid Loss:  0.16049593687057495
Epoch:  106  	Training Loss: 0.12210067361593246
Test Loss:  0.16623270511627197
Valid Loss:  0.16049589216709137
Epoch:  107  	Training Loss: 0.12210064381361008
Test Loss:  0.16623267531394958
Valid Loss:  0.1604958474636078
Epoch:  108  	Training Loss: 0.1221005991101265
Test Loss:  0.1662326157093048
Valid Loss:  0.1604958027601242
Epoch:  109  	Training Loss: 0.12210056185722351
Test Loss:  0.16623255610466003
Valid Loss:  0.16049575805664062
Epoch:  110  	Training Loss: 0.12210052460432053
Test Loss:  0.16623251140117645
Valid Loss:  0.16049569845199585
Epoch:  111  	Training Loss: 0.12210047990083694
Test Loss:  0.16623246669769287
Valid Loss:  0.16049566864967346
Epoch:  112  	Training Loss: 0.12210045009851456
Test Loss:  0.1662324070930481
Valid Loss:  0.1604956090450287
Epoch:  113  	Training Loss: 0.12210042029619217
Test Loss:  0.1662323772907257
Valid Loss:  0.1604955792427063
Epoch:  114  	Training Loss: 0.12210037559270859
Test Loss:  0.16623231768608093
Valid Loss:  0.16049551963806152
Epoch:  115  	Training Loss: 0.1221003457903862
Test Loss:  0.16623227298259735
Valid Loss:  0.16049548983573914
Epoch:  116  	Training Loss: 0.12210030853748322
Test Loss:  0.16623222827911377
Valid Loss:  0.16049543023109436
Epoch:  117  	Training Loss: 0.12210027873516083
Test Loss:  0.1662321835756302
Valid Loss:  0.16049538552761078
Epoch:  118  	Training Loss: 0.12210023403167725
Test Loss:  0.1662321388721466
Valid Loss:  0.1604953408241272
Epoch:  119  	Training Loss: 0.12210020422935486
Test Loss:  0.16623207926750183
Valid Loss:  0.16049529612064362
Epoch:  120  	Training Loss: 0.12210017442703247
Test Loss:  0.16623204946517944
Valid Loss:  0.16049525141716003
Epoch:  121  	Training Loss: 0.12210012972354889
Test Loss:  0.16623198986053467
Valid Loss:  0.16049522161483765
Epoch:  122  	Training Loss: 0.1221000924706459
Test Loss:  0.1662319451570511
Valid Loss:  0.16049516201019287
Epoch:  123  	Training Loss: 0.12210006266832352
Test Loss:  0.1662319004535675
Valid Loss:  0.16049513220787048
Epoch:  124  	Training Loss: 0.12210002541542053
Test Loss:  0.16623185575008392
Valid Loss:  0.1604950875043869
Epoch:  125  	Training Loss: 0.12209998816251755
Test Loss:  0.16623181104660034
Valid Loss:  0.16049502789974213
Epoch:  126  	Training Loss: 0.12209995090961456
Test Loss:  0.16623175144195557
Valid Loss:  0.16049498319625854
Epoch:  127  	Training Loss: 0.12209990620613098
Test Loss:  0.16623170673847198
Valid Loss:  0.16049495339393616
Epoch:  128  	Training Loss: 0.1220998764038086
Test Loss:  0.1662316620349884
Valid Loss:  0.16049489378929138
Epoch:  129  	Training Loss: 0.12209983170032501
Test Loss:  0.16623160243034363
Valid Loss:  0.160494863986969
Epoch:  130  	Training Loss: 0.12209980189800262
Test Loss:  0.16623157262802124
Valid Loss:  0.16049480438232422
Epoch:  131  	Training Loss: 0.12209976464509964
Test Loss:  0.16623152792453766
Valid Loss:  0.16049477458000183
Epoch:  132  	Training Loss: 0.12209973484277725
Test Loss:  0.16623148322105408
Valid Loss:  0.16049471497535706
Epoch:  133  	Training Loss: 0.12209969758987427
Test Loss:  0.1662314236164093
Valid Loss:  0.16049468517303467
Epoch:  134  	Training Loss: 0.12209965288639069
Test Loss:  0.16623137891292572
Valid Loss:  0.1604946255683899
Epoch:  135  	Training Loss: 0.1220996156334877
Test Loss:  0.16623133420944214
Valid Loss:  0.1604945957660675
Epoch:  136  	Training Loss: 0.12209958583116531
Test Loss:  0.16623127460479736
Valid Loss:  0.16049453616142273
Epoch:  137  	Training Loss: 0.12209954857826233
Test Loss:  0.16623124480247498
Valid Loss:  0.16049449145793915
Epoch:  138  	Training Loss: 0.12209951132535934
Test Loss:  0.1662311851978302
Valid Loss:  0.16049444675445557
Epoch:  139  	Training Loss: 0.12209947407245636
Test Loss:  0.1662311553955078
Valid Loss:  0.16049440205097198
Epoch:  140  	Training Loss: 0.12209944427013397
Test Loss:  0.16623109579086304
Valid Loss:  0.1604943573474884
Epoch:  141  	Training Loss: 0.12209939956665039
Test Loss:  0.16623105108737946
Valid Loss:  0.16049432754516602
Epoch:  142  	Training Loss: 0.1220993623137474
Test Loss:  0.16623100638389587
Valid Loss:  0.16049426794052124
Epoch:  143  	Training Loss: 0.12209932506084442
Test Loss:  0.1662309467792511
Valid Loss:  0.16049420833587646
Epoch:  144  	Training Loss: 0.12209928035736084
Test Loss:  0.16623088717460632
Valid Loss:  0.16049417853355408
Epoch:  145  	Training Loss: 0.12209925055503845
Test Loss:  0.16623084247112274
Valid Loss:  0.1604941189289093
Epoch:  146  	Training Loss: 0.12209920585155487
Test Loss:   29%|██▉       | 147/500 [01:45<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:45<01:59,  2.93it/s] 30%|███       | 151/500 [01:51<06:56,  1.19s/it] 31%|███       | 153/500 [01:52<04:58,  1.16it/s] 31%|███       | 155/500 [01:52<03:36,  1.59it/s] 31%|███▏      | 157/500 [01:52<02:39,  2.15it/s] 32%|███▏      | 159/500 [01:52<01:57,  2.90it/s] 32%|███▏      | 161/500 [01:58<06:46,  1.20s/it] 33%|███▎      | 163/500 [01:59<04:51,  1.16it/s] 33%|███▎      | 165/500 [01:59<03:31,  1.58it/s] 33%|███▎      | 167/500 [01:59<02:35,  2.14it/s] 34%|███▍      | 169/500 [01:59<01:56,  2.84it/s] 34%|███▍      | 171/500 [02:06<06:43,  1.23s/it] 35%|███▍      | 173/500 [02:06<04:47,  1.14it/s] 35%|███▌      | 175/500 [02:06<03:26,  1.57it/s] 35%|███▌      | 177/500 [02:06<02:30,  2.15it/s] 36%|███▌      | 179/500 [02:06<01:50,  2.90it/s] 36%|███▌      | 181/500 [02:12<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:13<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:13<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:13<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:13<01:45,  2.96it/s] 38%|███▊      | 191/500 [02:20<06:16,  1.22s/it] 39%|███▊      | 193/500 [02:20<04:28,  1.14it/s] 39%|███▉      | 195/500 [02:20<03:12,  1.58it/s] 39%|███▉      | 197/500 [02:20<02:19,  2.16it/s] 40%|███▉      | 199/500 [02:20<01:43,  2.91it/s] 40%|████      | 201/500 [02:27<05:58,  1.20s/it] 41%|████      | 203/500 [02:27<04:16,  1.16it/s] 41%|████      | 205/500 [02:27<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:27<02:15,  2.16it/s] 42%|████▏     | 209/500 [02:27<01:41,  2.86it/s] 42%|████▏     | 211/500 [02:33<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:34<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:34<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:34<02:08,  2.21it/s]0.16623079776763916
Valid Loss:  0.16049405932426453
Epoch:  147  	Training Loss: 0.12209916114807129
Test Loss:  0.16623075306415558
Valid Loss:  0.16049402952194214
Epoch:  148  	Training Loss: 0.1220991238951683
Test Loss:  0.1662306934595108
Valid Loss:  0.16049396991729736
Epoch:  149  	Training Loss: 0.12209908664226532
Test Loss:  0.16623063385486603
Valid Loss:  0.16049392521381378
Epoch:  150  	Training Loss: 0.12209905683994293
Test Loss:  0.16623058915138245
Valid Loss:  0.1604938805103302
Epoch:  151  	Training Loss: 0.12209901213645935
Test Loss:  0.16623054444789886
Valid Loss:  0.16049383580684662
Epoch:  152  	Training Loss: 0.12209896743297577
Test Loss:  0.16623049974441528
Valid Loss:  0.16049377620220184
Epoch:  153  	Training Loss: 0.12209893763065338
Test Loss:  0.1662304401397705
Valid Loss:  0.16049373149871826
Epoch:  154  	Training Loss: 0.1220989003777504
Test Loss:  0.16623038053512573
Valid Loss:  0.1604936718940735
Epoch:  155  	Training Loss: 0.12209885567426682
Test Loss:  0.16623035073280334
Valid Loss:  0.1604936420917511
Epoch:  156  	Training Loss: 0.12209881842136383
Test Loss:  0.16623029112815857
Valid Loss:  0.1604936122894287
Epoch:  157  	Training Loss: 0.12209877371788025
Test Loss:  0.166230246424675
Valid Loss:  0.16049355268478394
Epoch:  158  	Training Loss: 0.12209874391555786
Test Loss:  0.1662302017211914
Valid Loss:  0.16049349308013916
Epoch:  159  	Training Loss: 0.12209869921207428
Test Loss:  0.16623014211654663
Valid Loss:  0.16049344837665558
Epoch:  160  	Training Loss: 0.12209866940975189
Test Loss:  0.16623008251190186
Valid Loss:  0.160493403673172
Epoch:  161  	Training Loss: 0.12209862470626831
Test Loss:  0.16623005270957947
Valid Loss:  0.1604933738708496
Epoch:  162  	Training Loss: 0.12209859490394592
Test Loss:  0.1662299931049347
Valid Loss:  0.16049329936504364
Epoch:  163  	Training Loss: 0.12209855020046234
Test Loss:  0.16622993350028992
Valid Loss:  0.16049325466156006
Epoch:  164  	Training Loss: 0.12209851294755936
Test Loss:  0.16622987389564514
Valid Loss:  0.16049322485923767
Epoch:  165  	Training Loss: 0.12209847569465637
Test Loss:  0.16622984409332275
Valid Loss:  0.1604931801557541
Epoch:  166  	Training Loss: 0.12209843099117279
Test Loss:  0.16622978448867798
Valid Loss:  0.16049310564994812
Epoch:  167  	Training Loss: 0.1220983937382698
Test Loss:  0.1662297248840332
Valid Loss:  0.16049307584762573
Epoch:  168  	Training Loss: 0.12209835648536682
Test Loss:  0.16622969508171082
Valid Loss:  0.16049303114414215
Epoch:  169  	Training Loss: 0.12209831923246384
Test Loss:  0.16622963547706604
Valid Loss:  0.16049298644065857
Epoch:  170  	Training Loss: 0.12209827452898026
Test Loss:  0.16622957587242126
Valid Loss:  0.1604929268360138
Epoch:  171  	Training Loss: 0.12209823727607727
Test Loss:  0.16622954607009888
Valid Loss:  0.1604928970336914
Epoch:  172  	Training Loss: 0.12209820002317429
Test Loss:  0.1662295013666153
Valid Loss:  0.16049283742904663
Epoch:  173  	Training Loss: 0.1220981702208519
Test Loss:  0.1662294566631317
Valid Loss:  0.16049279272556305
Epoch:  174  	Training Loss: 0.12209813296794891
Test Loss:  0.16622939705848694
Valid Loss:  0.16049274802207947
Epoch:  175  	Training Loss: 0.12209809571504593
Test Loss:  0.16622936725616455
Valid Loss:  0.16049271821975708
Epoch:  176  	Training Loss: 0.12209806591272354
Test Loss:  0.16622930765151978
Valid Loss:  0.1604926586151123
Epoch:  177  	Training Loss: 0.12209802865982056
Test Loss:  0.1662292778491974
Valid Loss:  0.16049262881278992
Epoch:  178  	Training Loss: 0.12209799140691757
Test Loss:  0.1662292182445526
Valid Loss:  0.16049258410930634
Epoch:  179  	Training Loss: 0.12209796905517578
Test Loss:  0.16622918844223022
Valid Loss:  0.16049253940582275
Epoch:  180  	Training Loss: 0.1220979243516922
Test Loss:  0.16622914373874664
Valid Loss:  0.16049249470233917
Epoch:  181  	Training Loss: 0.12209789454936981
Test Loss:  0.16622909903526306
Valid Loss:  0.1604924499988556
Epoch:  182  	Training Loss: 0.12209784984588623
Test Loss:  0.1662290394306183
Valid Loss:  0.160492405295372
Epoch:  183  	Training Loss: 0.12209782004356384
Test Loss:  0.1662289947271347
Valid Loss:  0.16049236059188843
Epoch:  184  	Training Loss: 0.12209779024124146
Test Loss:  0.16622895002365112
Valid Loss:  0.16049233078956604
Epoch:  185  	Training Loss: 0.12209774553775787
Test Loss:  0.16622889041900635
Valid Loss:  0.16049227118492126
Epoch:  186  	Training Loss: 0.12209770828485489
Test Loss:  0.16622886061668396
Valid Loss:  0.16049224138259888
Epoch:  187  	Training Loss: 0.1220976710319519
Test Loss:  0.16622880101203918
Valid Loss:  0.1604921817779541
Epoch:  188  	Training Loss: 0.12209763377904892
Test Loss:  0.1662287563085556
Valid Loss:  0.1604921519756317
Epoch:  189  	Training Loss: 0.12209759652614594
Test Loss:  0.16622871160507202
Valid Loss:  0.16049209237098694
Epoch:  190  	Training Loss: 0.12209756672382355
Test Loss:  0.16622865200042725
Valid Loss:  0.16049204766750336
Epoch:  191  	Training Loss: 0.12209752202033997
Test Loss:  0.16622862219810486
Valid Loss:  0.16049200296401978
Epoch:  192  	Training Loss: 0.12209748476743698
Test Loss:  0.16622856259346008
Valid Loss:  0.1604919731616974
Epoch:  193  	Training Loss: 0.122097447514534
Test Loss:  0.1662285327911377
Valid Loss:  0.1604919135570526
Epoch:  194  	Training Loss: 0.12209741771221161
Test Loss:  0.16622847318649292
Valid Loss:  0.16049186885356903
Epoch:  195  	Training Loss: 0.12209738790988922
Test Loss:  0.16622842848300934
Valid Loss:  0.16049182415008545
Epoch:  196  	Training Loss: 0.12209734320640564
Test Loss:  0.16622838377952576
Valid Loss:  0.16049179434776306
Epoch:  197  	Training Loss: 0.12209730595350266
Test Loss:  0.16622833907604218
Valid Loss:  0.1604917347431183
Epoch:  198  	Training Loss: 0.12209727615118027
Test Loss:  0.1662282943725586
Valid Loss:  0.1604917049407959
Epoch:  199  	Training Loss: 0.12209723889827728
Test Loss:  0.16622823476791382
Valid Loss:  0.16049164533615112
Epoch:  200  	Training Loss: 0.1220972090959549
Test Loss:  0.16622820496559143
Valid Loss:  0.16049161553382874
Epoch:  201  	Training Loss: 0.12209716439247131
Test Loss:  0.16622814536094666
Valid Loss:  0.16049155592918396
Epoch:  202  	Training Loss: 0.12209713459014893
Test Loss:  0.16622810065746307
Valid Loss:  0.16049152612686157
Epoch:  203  	Training Loss: 0.12209710478782654
Test Loss:  0.1662280559539795
Valid Loss:  0.1604914665222168
Epoch:  204  	Training Loss: 0.12209706008434296
Test Loss:  0.16622799634933472
Valid Loss:  0.1604914367198944
Epoch:  205  	Training Loss: 0.12209701538085938
Test Loss:  0.16622796654701233
Valid Loss:  0.16049137711524963
Epoch:  206  	Training Loss: 0.12209698557853699
Test Loss:  0.16622790694236755
Valid Loss:  0.16049133241176605
Epoch:  207  	Training Loss: 0.122096948325634
Test Loss:  0.16622786223888397
Valid Loss:  0.16049128770828247
Epoch:  208  	Training Loss: 0.12209691107273102
Test Loss:  0.1662278175354004
Valid Loss:  0.1604912430047989
Epoch:  209  	Training Loss: 0.12209686636924744
Test Loss:  0.16622775793075562
Valid Loss:  0.1604911983013153
Epoch:  210  	Training Loss: 0.12209683656692505
Test Loss:  0.16622771322727203
Valid Loss:  0.16049113869667053
Epoch:  211  	Training Loss: 0.12209680676460266
Test Loss:  0.16622766852378845
Valid Loss:  0.16049110889434814
Epoch:  212  	Training Loss: 0.12209676206111908
Test Loss:  0.16622760891914368
Valid Loss:  0.16049104928970337
Epoch:  213  	Training Loss: 0.1220967173576355
Test Loss:  0.1662275791168213
Valid Loss:  0.16049101948738098
Epoch:  214  	Training Loss: 0.12209668755531311
Test Loss:  0.1662275195121765
Valid Loss:  0.1604909598827362
Epoch:  215  	Training Loss: 0.12209664285182953
Test Loss:  0.16622745990753174
Valid Loss:  0.16049093008041382
Epoch:  216  	Training Loss: 0.12209661304950714
Test Loss:  0.16622743010520935
Valid Loss:  0.16049087047576904
Epoch:  217  	Training Loss: 0.12209656834602356
Test Loss:  0.16622737050056458
Valid Loss:  0.16049082577228546
Epoch:  218  	Training Loss: 0.12209653854370117
Test Loss:  0.166227325797081
Valid Loss:   44%|████▍     | 219/500 [02:34<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:40<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:41<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:41<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:41<02:04,  2.18it/s] 46%|████▌     | 229/500 [02:41<01:34,  2.88it/s] 46%|████▌     | 231/500 [02:48<05:34,  1.24s/it] 47%|████▋     | 233/500 [02:48<03:59,  1.12it/s] 47%|████▋     | 235/500 [02:48<02:52,  1.53it/s] 47%|████▋     | 237/500 [02:48<02:06,  2.07it/s] 48%|████▊     | 239/500 [02:48<01:34,  2.76it/s] 48%|████▊     | 241/500 [02:55<05:16,  1.22s/it] 49%|████▊     | 243/500 [02:55<03:47,  1.13it/s] 49%|████▉     | 245/500 [02:55<02:44,  1.55it/s] 49%|████▉     | 247/500 [02:55<02:00,  2.09it/s] 50%|████▉     | 249/500 [02:55<01:30,  2.78it/s] 50%|█████     | 251/500 [03:02<04:59,  1.20s/it] 51%|█████     | 253/500 [03:02<03:34,  1.15it/s] 51%|█████     | 255/500 [03:02<02:35,  1.58it/s] 51%|█████▏    | 257/500 [03:02<01:53,  2.13it/s] 52%|█████▏    | 259/500 [03:02<01:23,  2.88it/s] 52%|█████▏    | 261/500 [03:09<04:45,  1.20s/it] 53%|█████▎    | 263/500 [03:09<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:09<02:28,  1.59it/s] 53%|█████▎    | 267/500 [03:09<01:48,  2.14it/s] 54%|█████▍    | 269/500 [03:10<01:21,  2.84it/s] 54%|█████▍    | 271/500 [03:16<04:38,  1.22s/it] 55%|█████▍    | 273/500 [03:16<03:18,  1.14it/s] 55%|█████▌    | 275/500 [03:16<02:22,  1.58it/s] 55%|█████▌    | 277/500 [03:16<01:43,  2.16it/s] 56%|█████▌    | 279/500 [03:17<01:15,  2.91it/s] 56%|█████▌    | 281/500 [03:23<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:23<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:23<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:23<01:38,  2.17it/s] 58%|█████▊    | 289/500 [03:24<01:13,  2.87it/s]0.16049078106880188
Epoch:  219  	Training Loss: 0.12209649384021759
Test Loss:  0.1662272810935974
Valid Loss:  0.1604907363653183
Epoch:  220  	Training Loss: 0.1220964640378952
Test Loss:  0.16622722148895264
Valid Loss:  0.16049069166183472
Epoch:  221  	Training Loss: 0.12209641933441162
Test Loss:  0.16622717678546906
Valid Loss:  0.16049061715602875
Epoch:  222  	Training Loss: 0.12209637463092804
Test Loss:  0.16622713208198547
Valid Loss:  0.16049060225486755
Epoch:  223  	Training Loss: 0.12209634482860565
Test Loss:  0.1662270724773407
Valid Loss:  0.16049054265022278
Epoch:  224  	Training Loss: 0.12209630012512207
Test Loss:  0.16622701287269592
Valid Loss:  0.160490483045578
Epoch:  225  	Training Loss: 0.12209626287221909
Test Loss:  0.16622696816921234
Valid Loss:  0.16049045324325562
Epoch:  226  	Training Loss: 0.1220962256193161
Test Loss:  0.16622692346572876
Valid Loss:  0.16049039363861084
Epoch:  227  	Training Loss: 0.12209619581699371
Test Loss:  0.16622686386108398
Valid Loss:  0.16049036383628845
Epoch:  228  	Training Loss: 0.12209614366292953
Test Loss:  0.1662268191576004
Valid Loss:  0.16049030423164368
Epoch:  229  	Training Loss: 0.12209611386060715
Test Loss:  0.16622677445411682
Valid Loss:  0.1604902744293213
Epoch:  230  	Training Loss: 0.12209606915712357
Test Loss:  0.16622671484947205
Valid Loss:  0.1604902148246765
Epoch:  231  	Training Loss: 0.12209603935480118
Test Loss:  0.16622668504714966
Valid Loss:  0.16049015522003174
Epoch:  232  	Training Loss: 0.1220959946513176
Test Loss:  0.16622662544250488
Valid Loss:  0.16049011051654816
Epoch:  233  	Training Loss: 0.12209595739841461
Test Loss:  0.1662265658378601
Valid Loss:  0.16049006581306458
Epoch:  234  	Training Loss: 0.12209592014551163
Test Loss:  0.16622650623321533
Valid Loss:  0.1604900062084198
Epoch:  235  	Training Loss: 0.12209586799144745
Test Loss:  0.16622646152973175
Valid Loss:  0.16048996150493622
Epoch:  236  	Training Loss: 0.12209583818912506
Test Loss:  0.16622640192508698
Valid Loss:  0.16048990190029144
Epoch:  237  	Training Loss: 0.12209579348564148
Test Loss:  0.1662263423204422
Valid Loss:  0.16048985719680786
Epoch:  238  	Training Loss: 0.1220957487821579
Test Loss:  0.16622629761695862
Valid Loss:  0.16048979759216309
Epoch:  239  	Training Loss: 0.12209570407867432
Test Loss:  0.16622625291347504
Valid Loss:  0.1604897677898407
Epoch:  240  	Training Loss: 0.12209566682577133
Test Loss:  0.16622617840766907
Valid Loss:  0.16048970818519592
Epoch:  241  	Training Loss: 0.12209561467170715
Test Loss:  0.16622614860534668
Valid Loss:  0.16048964858055115
Epoch:  242  	Training Loss: 0.12209556996822357
Test Loss:  0.1662260890007019
Valid Loss:  0.16048958897590637
Epoch:  243  	Training Loss: 0.12209554016590118
Test Loss:  0.16622602939605713
Valid Loss:  0.16048955917358398
Epoch:  244  	Training Loss: 0.1220955103635788
Test Loss:  0.16622599959373474
Valid Loss:  0.1604895144701004
Epoch:  245  	Training Loss: 0.12209547311067581
Test Loss:  0.16622593998908997
Valid Loss:  0.16048946976661682
Epoch:  246  	Training Loss: 0.12209543585777283
Test Loss:  0.16622591018676758
Valid Loss:  0.16048941016197205
Epoch:  247  	Training Loss: 0.12209539115428925
Test Loss:  0.1662258505821228
Valid Loss:  0.16048938035964966
Epoch:  248  	Training Loss: 0.12209536135196686
Test Loss:  0.16622580587863922
Valid Loss:  0.16048933565616608
Epoch:  249  	Training Loss: 0.12209531664848328
Test Loss:  0.16622576117515564
Valid Loss:  0.1604892909526825
Epoch:  250  	Training Loss: 0.12209528684616089
Test Loss:  0.16622570157051086
Valid Loss:  0.16048923134803772
Epoch:  251  	Training Loss: 0.12209524214267731
Test Loss:  0.16622567176818848
Valid Loss:  0.16048918664455414
Epoch:  252  	Training Loss: 0.12209521234035492
Test Loss:  0.1662256121635437
Valid Loss:  0.16048915684223175
Epoch:  253  	Training Loss: 0.12209518253803253
Test Loss:  0.1662255823612213
Valid Loss:  0.16048911213874817
Epoch:  254  	Training Loss: 0.12209515273571014
Test Loss:  0.16622552275657654
Valid Loss:  0.16048908233642578
Epoch:  255  	Training Loss: 0.12209511548280716
Test Loss:  0.16622549295425415
Valid Loss:  0.1604890525341034
Epoch:  256  	Training Loss: 0.12209508568048477
Test Loss:  0.16622544825077057
Valid Loss:  0.16048899292945862
Epoch:  257  	Training Loss: 0.12209504842758179
Test Loss:  0.166225403547287
Valid Loss:  0.16048896312713623
Epoch:  258  	Training Loss: 0.1220950186252594
Test Loss:  0.1662253588438034
Valid Loss:  0.16048893332481384
Epoch:  259  	Training Loss: 0.12209498137235641
Test Loss:  0.16622531414031982
Valid Loss:  0.16048888862133026
Epoch:  260  	Training Loss: 0.12209495902061462
Test Loss:  0.16622528433799744
Valid Loss:  0.16048882901668549
Epoch:  261  	Training Loss: 0.12209492176771164
Test Loss:  0.16622522473335266
Valid Loss:  0.1604887843132019
Epoch:  262  	Training Loss: 0.12209489196538925
Test Loss:  0.16622519493103027
Valid Loss:  0.16048875451087952
Epoch:  263  	Training Loss: 0.12209486216306686
Test Loss:  0.1662251353263855
Valid Loss:  0.16048870980739594
Epoch:  264  	Training Loss: 0.12209481745958328
Test Loss:  0.1662251055240631
Valid Loss:  0.16048866510391235
Epoch:  265  	Training Loss: 0.1220947802066803
Test Loss:  0.16622504591941833
Valid Loss:  0.16048863530158997
Epoch:  266  	Training Loss: 0.12209475040435791
Test Loss:  0.16622501611709595
Valid Loss:  0.1604885756969452
Epoch:  267  	Training Loss: 0.12209470570087433
Test Loss:  0.16622495651245117
Valid Loss:  0.1604885309934616
Epoch:  268  	Training Loss: 0.12209467589855194
Test Loss:  0.1662249118089676
Valid Loss:  0.16048848628997803
Epoch:  269  	Training Loss: 0.12209463864564896
Test Loss:  0.166224867105484
Valid Loss:  0.16048844158649445
Epoch:  270  	Training Loss: 0.12209460139274597
Test Loss:  0.16622480750083923
Valid Loss:  0.16048839688301086
Epoch:  271  	Training Loss: 0.12209457159042358
Test Loss:  0.16622477769851685
Valid Loss:  0.16048835217952728
Epoch:  272  	Training Loss: 0.1220945343375206
Test Loss:  0.16622471809387207
Valid Loss:  0.1604883074760437
Epoch:  273  	Training Loss: 0.12209449708461761
Test Loss:  0.16622468829154968
Valid Loss:  0.16048826277256012
Epoch:  274  	Training Loss: 0.12209445238113403
Test Loss:  0.1662246286869049
Valid Loss:  0.16048821806907654
Epoch:  275  	Training Loss: 0.12209441512823105
Test Loss:  0.16622456908226013
Valid Loss:  0.16048815846443176
Epoch:  276  	Training Loss: 0.12209437787532806
Test Loss:  0.16622450947761536
Valid Loss:  0.16048811376094818
Epoch:  277  	Training Loss: 0.12209434062242508
Test Loss:  0.16622447967529297
Valid Loss:  0.1604880690574646
Epoch:  278  	Training Loss: 0.1220943033695221
Test Loss:  0.1662244200706482
Valid Loss:  0.1604880392551422
Epoch:  279  	Training Loss: 0.12209425866603851
Test Loss:  0.16622436046600342
Valid Loss:  0.16048797965049744
Epoch:  280  	Training Loss: 0.12209422886371613
Test Loss:  0.16622431576251984
Valid Loss:  0.16048793494701385
Epoch:  281  	Training Loss: 0.12209417670965195
Test Loss:  0.16622427105903625
Valid Loss:  0.16048789024353027
Epoch:  282  	Training Loss: 0.12209413945674896
Test Loss:  0.16622421145439148
Valid Loss:  0.1604878306388855
Epoch:  283  	Training Loss: 0.12209410965442657
Test Loss:  0.1662241816520691
Valid Loss:  0.1604878008365631
Epoch:  284  	Training Loss: 0.122094064950943
Test Loss:  0.16622412204742432
Valid Loss:  0.16048774123191833
Epoch:  285  	Training Loss: 0.1220940351486206
Test Loss:  0.16622407734394073
Valid Loss:  0.16048771142959595
Epoch:  286  	Training Loss: 0.12209400534629822
Test Loss:  0.16622403264045715
Valid Loss:  0.16048765182495117
Epoch:  287  	Training Loss: 0.12209396064281464
Test Loss:  0.16622398793697357
Valid Loss:  0.16048762202262878
Epoch:  288  	Training Loss: 0.12209392338991165
Test Loss:  0.16622394323349
Valid Loss:  0.1604875773191452
Epoch:  289  	Training Loss: 0.12209388613700867
Test Loss:  0.16622388362884521
Valid Loss:  0.16048753261566162
Epoch:  290  	Training Loss: 0.12209385633468628
Test Loss:  0.16622385382652283
Valid Loss:  0.16048748791217804
 58%|█████▊    | 291/500 [03:30<04:20,  1.25s/it] 59%|█████▊    | 293/500 [03:30<03:05,  1.12it/s] 59%|█████▉    | 295/500 [03:30<02:12,  1.54it/s] 59%|█████▉    | 297/500 [03:31<01:36,  2.11it/s] 60%|█████▉    | 299/500 [03:31<01:10,  2.84it/s] 60%|██████    | 301/500 [03:37<03:58,  1.20s/it] 61%|██████    | 303/500 [03:37<02:50,  1.15it/s] 61%|██████    | 305/500 [03:37<02:03,  1.58it/s] 61%|██████▏   | 307/500 [03:38<01:30,  2.13it/s] 62%|██████▏   | 309/500 [03:38<01:06,  2.87it/s] 62%|██████▏   | 311/500 [03:44<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:44<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:44<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:44<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:45<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:51<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:51<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:51<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:51<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:51<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:58<03:20,  1.18s/it] 67%|██████▋   | 333/500 [03:58<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:58<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:58<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:58<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:05<03:08,  1.18s/it] 69%|██████▊   | 343/500 [04:05<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:05<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:05<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:05<00:51,  2.94it/s] 70%|███████   | 351/500 [04:12<02:59,  1.20s/it] 71%|███████   | 353/500 [04:12<02:06,  1.16it/s] 71%|███████   | 355/500 [04:12<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:12<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:12<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:19<02:53,  1.25s/it]Epoch:  291  	Training Loss: 0.12209382653236389
Test Loss:  0.16622379422187805
Valid Loss:  0.16048744320869446
Epoch:  292  	Training Loss: 0.12209378927946091
Test Loss:  0.16622376441955566
Valid Loss:  0.16048738360404968
Epoch:  293  	Training Loss: 0.12209375202655792
Test Loss:  0.1662237048149109
Valid Loss:  0.1604873538017273
Epoch:  294  	Training Loss: 0.12209372222423553
Test Loss:  0.1662236750125885
Valid Loss:  0.1604873239994049
Epoch:  295  	Training Loss: 0.12209368497133255
Test Loss:  0.1662236452102661
Valid Loss:  0.16048727929592133
Epoch:  296  	Training Loss: 0.12209364771842957
Test Loss:  0.16622358560562134
Valid Loss:  0.16048723459243774
Epoch:  297  	Training Loss: 0.12209361791610718
Test Loss:  0.16622352600097656
Valid Loss:  0.16048718988895416
Epoch:  298  	Training Loss: 0.1220935806632042
Test Loss:  0.16622349619865417
Valid Loss:  0.16048714518547058
Epoch:  299  	Training Loss: 0.1220935508608818
Test Loss:  0.1662234365940094
Valid Loss:  0.1604871153831482
Epoch:  300  	Training Loss: 0.12209351360797882
Test Loss:  0.166223406791687
Valid Loss:  0.16048705577850342
Epoch:  301  	Training Loss: 0.12209347635507584
Test Loss:  0.16622334718704224
Valid Loss:  0.16048702597618103
Epoch:  302  	Training Loss: 0.12209345400333405
Test Loss:  0.16622331738471985
Valid Loss:  0.16048698127269745
Epoch:  303  	Training Loss: 0.12209340184926987
Test Loss:  0.16622327268123627
Valid Loss:  0.16048693656921387
Epoch:  304  	Training Loss: 0.12209337204694748
Test Loss:  0.1662231981754303
Valid Loss:  0.1604868769645691
Epoch:  305  	Training Loss: 0.1220933347940445
Test Loss:  0.1662231683731079
Valid Loss:  0.1604868471622467
Epoch:  306  	Training Loss: 0.12209329754114151
Test Loss:  0.16622310876846313
Valid Loss:  0.16048678755760193
Epoch:  307  	Training Loss: 0.12209326028823853
Test Loss:  0.16622307896614075
Valid Loss:  0.16048675775527954
Epoch:  308  	Training Loss: 0.12209321558475494
Test Loss:  0.16622301936149597
Valid Loss:  0.16048671305179596
Epoch:  309  	Training Loss: 0.12209319323301315
Test Loss:  0.16622298955917358
Valid Loss:  0.16048666834831238
Epoch:  310  	Training Loss: 0.12209314107894897
Test Loss:  0.1662229299545288
Valid Loss:  0.1604866087436676
Epoch:  311  	Training Loss: 0.12209311127662659
Test Loss:  0.16622288525104523
Valid Loss:  0.16048657894134521
Epoch:  312  	Training Loss: 0.122093066573143
Test Loss:  0.16622282564640045
Valid Loss:  0.16048651933670044
Epoch:  313  	Training Loss: 0.12209302932024002
Test Loss:  0.16622278094291687
Valid Loss:  0.16048645973205566
Epoch:  314  	Training Loss: 0.12209299206733704
Test Loss:  0.1662227213382721
Valid Loss:  0.16048641502857208
Epoch:  315  	Training Loss: 0.12209294736385345
Test Loss:  0.16622266173362732
Valid Loss:  0.1604863703250885
Epoch:  316  	Training Loss: 0.12209291756153107
Test Loss:  0.16622260212898254
Valid Loss:  0.16048631072044373
Epoch:  317  	Training Loss: 0.12209286540746689
Test Loss:  0.16622254252433777
Valid Loss:  0.16048626601696014
Epoch:  318  	Training Loss: 0.1220928207039833
Test Loss:  0.16622251272201538
Valid Loss:  0.16048622131347656
Epoch:  319  	Training Loss: 0.12209278345108032
Test Loss:  0.1662224531173706
Valid Loss:  0.1604861617088318
Epoch:  320  	Training Loss: 0.12209273874759674
Test Loss:  0.16622239351272583
Valid Loss:  0.160486102104187
Epoch:  321  	Training Loss: 0.12209269404411316
Test Loss:  0.16622234880924225
Valid Loss:  0.16048605740070343
Epoch:  322  	Training Loss: 0.12209266424179077
Test Loss:  0.16622230410575867
Valid Loss:  0.16048601269721985
Epoch:  323  	Training Loss: 0.12209261953830719
Test Loss:  0.1662222445011139
Valid Loss:  0.16048595309257507
Epoch:  324  	Training Loss: 0.1220925822854042
Test Loss:  0.1662221997976303
Valid Loss:  0.1604859083890915
Epoch:  325  	Training Loss: 0.12209253758192062
Test Loss:  0.16622214019298553
Valid Loss:  0.1604858785867691
Epoch:  326  	Training Loss: 0.12209250777959824
Test Loss:  0.16622209548950195
Valid Loss:  0.16048580408096313
Epoch:  327  	Training Loss: 0.12209247052669525
Test Loss:  0.16622203588485718
Valid Loss:  0.16048577427864075
Epoch:  328  	Training Loss: 0.12209242582321167
Test Loss:  0.1662219911813736
Valid Loss:  0.16048572957515717
Epoch:  329  	Training Loss: 0.12209239602088928
Test Loss:  0.1662219613790512
Valid Loss:  0.16048568487167358
Epoch:  330  	Training Loss: 0.1220923587679863
Test Loss:  0.16622190177440643
Valid Loss:  0.1604856252670288
Epoch:  331  	Training Loss: 0.12209231406450272
Test Loss:  0.16622185707092285
Valid Loss:  0.16048559546470642
Epoch:  332  	Training Loss: 0.12209227681159973
Test Loss:  0.16622179746627808
Valid Loss:  0.16048553586006165
Epoch:  333  	Training Loss: 0.12209223955869675
Test Loss:  0.1662217527627945
Valid Loss:  0.16048549115657806
Epoch:  334  	Training Loss: 0.12209220230579376
Test Loss:  0.16622169315814972
Valid Loss:  0.16048544645309448
Epoch:  335  	Training Loss: 0.12209215760231018
Test Loss:  0.16622163355350494
Valid Loss:  0.1604853868484497
Epoch:  336  	Training Loss: 0.1220921128988266
Test Loss:  0.16622158885002136
Valid Loss:  0.16048534214496613
Epoch:  337  	Training Loss: 0.12209206819534302
Test Loss:  0.1662215292453766
Valid Loss:  0.16048529744148254
Epoch:  338  	Training Loss: 0.12209202349185944
Test Loss:  0.166221484541893
Valid Loss:  0.16048523783683777
Epoch:  339  	Training Loss: 0.12209199368953705
Test Loss:  0.16622142493724823
Valid Loss:  0.160485178232193
Epoch:  340  	Training Loss: 0.12209194898605347
Test Loss:  0.16622138023376465
Valid Loss:  0.1604851335287094
Epoch:  341  	Training Loss: 0.12209190428256989
Test Loss:  0.16622132062911987
Valid Loss:  0.16048508882522583
Epoch:  342  	Training Loss: 0.1220918744802475
Test Loss:  0.1662212610244751
Valid Loss:  0.16048502922058105
Epoch:  343  	Training Loss: 0.12209182232618332
Test Loss:  0.16622121632099152
Valid Loss:  0.16048498451709747
Epoch:  344  	Training Loss: 0.12209178507328033
Test Loss:  0.16622117161750793
Valid Loss:  0.1604849249124527
Epoch:  345  	Training Loss: 0.12209174782037735
Test Loss:  0.16622111201286316
Valid Loss:  0.16048488020896912
Epoch:  346  	Training Loss: 0.12209170311689377
Test Loss:  0.16622105240821838
Valid Loss:  0.16048482060432434
Epoch:  347  	Training Loss: 0.12209165841341019
Test Loss:  0.1662209928035736
Valid Loss:  0.16048476099967957
Epoch:  348  	Training Loss: 0.12209160625934601
Test Loss:  0.16622093319892883
Valid Loss:  0.16048471629619598
Epoch:  349  	Training Loss: 0.12209157645702362
Test Loss:  0.16622087359428406
Valid Loss:  0.1604846715927124
Epoch:  350  	Training Loss: 0.12209153175354004
Test Loss:  0.16622081398963928
Valid Loss:  0.16048462688922882
Epoch:  351  	Training Loss: 0.12209148705005646
Test Loss:  0.1662207841873169
Valid Loss:  0.16048456728458405
Epoch:  352  	Training Loss: 0.12209144234657288
Test Loss:  0.16622072458267212
Valid Loss:  0.16048450767993927
Epoch:  353  	Training Loss: 0.12209140509366989
Test Loss:  0.16622066497802734
Valid Loss:  0.1604844480752945
Epoch:  354  	Training Loss: 0.1220913678407669
Test Loss:  0.16622060537338257
Valid Loss:  0.1604844033718109
Epoch:  355  	Training Loss: 0.12209130823612213
Test Loss:  0.1662205457687378
Valid Loss:  0.16048434376716614
Epoch:  356  	Training Loss: 0.12209127098321915
Test Loss:  0.16622048616409302
Valid Loss:  0.16048428416252136
Epoch:  357  	Training Loss: 0.12209121882915497
Test Loss:  0.16622041165828705
Valid Loss:  0.1604842245578766
Epoch:  358  	Training Loss: 0.12209117412567139
Test Loss:  0.16622036695480347
Valid Loss:  0.1604841649532318
Epoch:  359  	Training Loss: 0.1220911294221878
Test Loss:  0.1662203073501587
Valid Loss:  0.16048412024974823
Epoch:  360  	Training Loss: 0.12209109216928482
Test Loss:  0.16622024774551392
Valid Loss:  0.16048407554626465
Epoch:  361  	Training Loss: 0.12209104001522064
Test Loss:  0.16622018814086914
Valid Loss:  0.16048401594161987
Epoch:  362  	Training Loss: 0.12209098786115646
Test Loss:  0.16622014343738556
Valid Loss:  0.1604839712381363
 73%|███████▎  | 363/500 [04:19<02:03,  1.11it/s] 73%|███████▎  | 365/500 [04:19<01:28,  1.53it/s] 73%|███████▎  | 367/500 [04:19<01:04,  2.08it/s] 74%|███████▍  | 369/500 [04:20<00:46,  2.79it/s] 74%|███████▍  | 371/500 [04:26<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:26<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:26<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:26<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:26<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:33<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:33<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:33<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:33<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:33<00:36,  3.00it/s] 78%|███████▊  | 391/500 [04:40<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:40<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:40<01:05,  1.59it/s] 79%|███████▉  | 397/500 [04:40<00:47,  2.15it/s] 80%|███████▉  | 399/500 [04:40<00:35,  2.85it/s] 80%|████████  | 401/500 [04:47<02:00,  1.21s/it] 81%|████████  | 403/500 [04:47<01:25,  1.14it/s] 81%|████████  | 405/500 [04:47<01:00,  1.57it/s] 81%|████████▏ | 407/500 [04:47<00:43,  2.15it/s] 82%|████████▏ | 409/500 [04:47<00:31,  2.89it/s] 82%|████████▏ | 411/500 [04:54<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:54<01:16,  1.14it/s] 83%|████████▎ | 415/500 [04:54<00:54,  1.57it/s] 83%|████████▎ | 417/500 [04:54<00:39,  2.13it/s] 84%|████████▍ | 419/500 [04:54<00:28,  2.82it/s] 84%|████████▍ | 421/500 [05:01<01:38,  1.25s/it] 85%|████████▍ | 423/500 [05:01<01:08,  1.12it/s] 85%|████████▌ | 425/500 [05:01<00:48,  1.55it/s] 85%|████████▌ | 427/500 [05:01<00:34,  2.12it/s] 86%|████████▌ | 429/500 [05:02<00:24,  2.86it/s] 86%|████████▌ | 431/500 [05:08<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:08<00:58,  1.15it/s]Epoch:  363  	Training Loss: 0.12209095805883408
Test Loss:  0.16622009873390198
Valid Loss:  0.1604839265346527
Epoch:  364  	Training Loss: 0.12209092080593109
Test Loss:  0.1662200391292572
Valid Loss:  0.16048386693000793
Epoch:  365  	Training Loss: 0.12209087610244751
Test Loss:  0.16621999442577362
Valid Loss:  0.16048380732536316
Epoch:  366  	Training Loss: 0.12209083884954453
Test Loss:  0.16621994972229004
Valid Loss:  0.16048377752304077
Epoch:  367  	Training Loss: 0.12209080159664154
Test Loss:  0.16621989011764526
Valid Loss:  0.1604837328195572
Epoch:  368  	Training Loss: 0.12209076434373856
Test Loss:  0.16621984541416168
Valid Loss:  0.16048367321491241
Epoch:  369  	Training Loss: 0.12209072709083557
Test Loss:  0.1662198007106781
Valid Loss:  0.16048362851142883
Epoch:  370  	Training Loss: 0.12209069728851318
Test Loss:  0.16621974110603333
Valid Loss:  0.16048358380794525
Epoch:  371  	Training Loss: 0.1220906525850296
Test Loss:  0.16621969640254974
Valid Loss:  0.16048353910446167
Epoch:  372  	Training Loss: 0.12209060788154602
Test Loss:  0.16621963679790497
Valid Loss:  0.1604834944009781
Epoch:  373  	Training Loss: 0.12209057062864304
Test Loss:  0.1662195920944214
Valid Loss:  0.1604834496974945
Epoch:  374  	Training Loss: 0.12209053337574005
Test Loss:  0.1662195473909378
Valid Loss:  0.16048339009284973
Epoch:  375  	Training Loss: 0.12209049612283707
Test Loss:  0.16621950268745422
Valid Loss:  0.16048336029052734
Epoch:  376  	Training Loss: 0.12209046632051468
Test Loss:  0.16621944308280945
Valid Loss:  0.16048331558704376
Epoch:  377  	Training Loss: 0.1220904290676117
Test Loss:  0.16621941328048706
Valid Loss:  0.16048327088356018
Epoch:  378  	Training Loss: 0.12209038436412811
Test Loss:  0.16621935367584229
Valid Loss:  0.1604832112789154
Epoch:  379  	Training Loss: 0.12209034711122513
Test Loss:  0.1662193089723587
Valid Loss:  0.16048318147659302
Epoch:  380  	Training Loss: 0.12209030985832214
Test Loss:  0.16621926426887512
Valid Loss:  0.16048313677310944
Epoch:  381  	Training Loss: 0.12209027260541916
Test Loss:  0.16621920466423035
Valid Loss:  0.16048307716846466
Epoch:  382  	Training Loss: 0.12209023535251617
Test Loss:  0.16621915996074677
Valid Loss:  0.16048303246498108
Epoch:  383  	Training Loss: 0.12209019809961319
Test Loss:  0.16621911525726318
Valid Loss:  0.1604830026626587
Epoch:  384  	Training Loss: 0.1220901682972908
Test Loss:  0.1662190556526184
Valid Loss:  0.16048294305801392
Epoch:  385  	Training Loss: 0.12209013104438782
Test Loss:  0.16621902585029602
Valid Loss:  0.16048291325569153
Epoch:  386  	Training Loss: 0.12209008634090424
Test Loss:  0.16621896624565125
Valid Loss:  0.16048285365104675
Epoch:  387  	Training Loss: 0.12209005653858185
Test Loss:  0.16621892154216766
Valid Loss:  0.16048280894756317
Epoch:  388  	Training Loss: 0.12209001928567886
Test Loss:  0.16621887683868408
Valid Loss:  0.1604827642440796
Epoch:  389  	Training Loss: 0.12208998203277588
Test Loss:  0.1662188172340393
Valid Loss:  0.160482719540596
Epoch:  390  	Training Loss: 0.1220899447798729
Test Loss:  0.16621878743171692
Valid Loss:  0.16048267483711243
Epoch:  391  	Training Loss: 0.12208990752696991
Test Loss:  0.16621872782707214
Valid Loss:  0.16048261523246765
Epoch:  392  	Training Loss: 0.12208986282348633
Test Loss:  0.16621866822242737
Valid Loss:  0.16048258543014526
Epoch:  393  	Training Loss: 0.12208983302116394
Test Loss:  0.16621863842010498
Valid Loss:  0.16048254072666168
Epoch:  394  	Training Loss: 0.12208978831768036
Test Loss:  0.1662185788154602
Valid Loss:  0.1604824811220169
Epoch:  395  	Training Loss: 0.12208975106477737
Test Loss:  0.16621851921081543
Valid Loss:  0.16048243641853333
Epoch:  396  	Training Loss: 0.12208971381187439
Test Loss:  0.16621848940849304
Valid Loss:  0.16048237681388855
Epoch:  397  	Training Loss: 0.122089684009552
Test Loss:  0.16621842980384827
Valid Loss:  0.16048233211040497
Epoch:  398  	Training Loss: 0.12208963930606842
Test Loss:  0.16621838510036469
Valid Loss:  0.1604822874069214
Epoch:  399  	Training Loss: 0.12208960205316544
Test Loss:  0.1662183254957199
Valid Loss:  0.160482257604599
Epoch:  400  	Training Loss: 0.12208956480026245
Test Loss:  0.16621828079223633
Valid Loss:  0.16048219799995422
Epoch:  401  	Training Loss: 0.12208952009677887
Test Loss:  0.16621823608875275
Valid Loss:  0.16048216819763184
Epoch:  402  	Training Loss: 0.12208949029445648
Test Loss:  0.16621819138526917
Valid Loss:  0.16048210859298706
Epoch:  403  	Training Loss: 0.1220894604921341
Test Loss:  0.1662181317806244
Valid Loss:  0.16048207879066467
Epoch:  404  	Training Loss: 0.12208942323923111
Test Loss:  0.166218101978302
Valid Loss:  0.1604820191860199
Epoch:  405  	Training Loss: 0.12208938598632812
Test Loss:  0.16621804237365723
Valid Loss:  0.1604819893836975
Epoch:  406  	Training Loss: 0.12208935618400574
Test Loss:  0.16621801257133484
Valid Loss:  0.16048194468021393
Epoch:  407  	Training Loss: 0.12208931148052216
Test Loss:  0.16621795296669006
Valid Loss:  0.16048189997673035
Epoch:  408  	Training Loss: 0.12208928167819977
Test Loss:  0.16621790826320648
Valid Loss:  0.16048185527324677
Epoch:  409  	Training Loss: 0.12208924442529678
Test Loss:  0.1662178635597229
Valid Loss:  0.16048181056976318
Epoch:  410  	Training Loss: 0.1220892146229744
Test Loss:  0.1662178337574005
Valid Loss:  0.1604817658662796
Epoch:  411  	Training Loss: 0.12208918482065201
Test Loss:  0.16621777415275574
Valid Loss:  0.16048173606395721
Epoch:  412  	Training Loss: 0.12208914756774902
Test Loss:  0.16621772944927216
Valid Loss:  0.16048169136047363
Epoch:  413  	Training Loss: 0.12208911031484604
Test Loss:  0.16621768474578857
Valid Loss:  0.16048164665699005
Epoch:  414  	Training Loss: 0.12208906561136246
Test Loss:  0.166217640042305
Valid Loss:  0.16048160195350647
Epoch:  415  	Training Loss: 0.12208902835845947
Test Loss:  0.1662175953388214
Valid Loss:  0.1604815423488617
Epoch:  416  	Training Loss: 0.12208899110555649
Test Loss:  0.16621753573417664
Valid Loss:  0.1604815125465393
Epoch:  417  	Training Loss: 0.1220889538526535
Test Loss:  0.16621749103069305
Valid Loss:  0.16048145294189453
Epoch:  418  	Training Loss: 0.12208891659975052
Test Loss:  0.16621744632720947
Valid Loss:  0.16048140823841095
Epoch:  419  	Training Loss: 0.12208887934684753
Test Loss:  0.1662173867225647
Valid Loss:  0.16048136353492737
Epoch:  420  	Training Loss: 0.12208884954452515
Test Loss:  0.1662173569202423
Valid Loss:  0.16048133373260498
Epoch:  421  	Training Loss: 0.12208879739046097
Test Loss:  0.16621729731559753
Valid Loss:  0.1604812741279602
Epoch:  422  	Training Loss: 0.12208877503871918
Test Loss:  0.16621723771095276
Valid Loss:  0.16048121452331543
Epoch:  423  	Training Loss: 0.1220887303352356
Test Loss:  0.16621720790863037
Valid Loss:  0.16048118472099304
Epoch:  424  	Training Loss: 0.12208869308233261
Test Loss:  0.1662171483039856
Valid Loss:  0.16048112511634827
Epoch:  425  	Training Loss: 0.12208865582942963
Test Loss:  0.16621708869934082
Valid Loss:  0.1604810655117035
Epoch:  426  	Training Loss: 0.12208861112594604
Test Loss:  0.16621705889701843
Valid Loss:  0.1604810357093811
Epoch:  427  	Training Loss: 0.12208858132362366
Test Loss:  0.16621699929237366
Valid Loss:  0.16048099100589752
Epoch:  428  	Training Loss: 0.12208853662014008
Test Loss:  0.16621696949005127
Valid Loss:  0.16048094630241394
Epoch:  429  	Training Loss: 0.12208850681781769
Test Loss:  0.1662169098854065
Valid Loss:  0.16048090159893036
Epoch:  430  	Training Loss: 0.1220884695649147
Test Loss:  0.1662168651819229
Valid Loss:  0.16048085689544678
Epoch:  431  	Training Loss: 0.12208843231201172
Test Loss:  0.16621680557727814
Valid Loss:  0.160480797290802
Epoch:  432  	Training Loss: 0.12208840250968933
Test Loss:  0.16621677577495575
Valid Loss:  0.16048076748847961
Epoch:  433  	Training Loss: 0.12208835780620575
Test Loss:  0.16621673107147217
Valid Loss:  0.16048072278499603
Epoch:  434  	Training Loss: 0.12208832800388336
Test Loss:  0.1662166863679886
Valid Loss:  0.16048067808151245
 87%|████████▋ | 435/500 [05:08<00:41,  1.57it/s] 87%|████████▋ | 437/500 [05:09<00:29,  2.13it/s] 88%|████████▊ | 439/500 [05:09<00:21,  2.81it/s] 88%|████████▊ | 441/500 [05:15<01:12,  1.22s/it] 89%|████████▊ | 443/500 [05:15<00:49,  1.14it/s] 89%|████████▉ | 445/500 [05:15<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:16<00:24,  2.17it/s] 90%|████████▉ | 449/500 [05:16<00:17,  2.92it/s] 90%|█████████ | 451/500 [05:22<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:22<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:22<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:22<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:23<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:29<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:29<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:29<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:29<00:15,  2.17it/s] 94%|█████████▍| 469/500 [05:30<00:10,  2.86it/s] 94%|█████████▍| 471/500 [05:36<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:36<00:23,  1.14it/s] 95%|█████████▌| 475/500 [05:36<00:16,  1.56it/s] 95%|█████████▌| 477/500 [05:37<00:10,  2.11it/s] 96%|█████████▌| 479/500 [05:37<00:07,  2.80it/s] 96%|█████████▌| 481/500 [05:43<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:43<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:43<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:44<00:05,  2.17it/s] 98%|█████████▊| 489/500 [05:44<00:03,  2.92it/s] 98%|█████████▊| 491/500 [05:50<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:50<00:06,  1.14it/s] 99%|█████████▉| 495/500 [05:51<00:03,  1.58it/s] 99%|█████████▉| 497/500 [05:51<00:01,  2.15it/s]100%|█████████▉| 499/500 [05:51<00:00,  2.90it/s]100%|██████████| 500/500 [05:51<00:00,  1.42it/s]
Epoch:  435  	Training Loss: 0.12208829820156097
Test Loss:  0.1662166267633438
Valid Loss:  0.16048061847686768
Epoch:  436  	Training Loss: 0.12208825349807739
Test Loss:  0.16621658205986023
Valid Loss:  0.1604805886745453
Epoch:  437  	Training Loss: 0.12208821624517441
Test Loss:  0.16621655225753784
Valid Loss:  0.1604805588722229
Epoch:  438  	Training Loss: 0.12208817899227142
Test Loss:  0.16621649265289307
Valid Loss:  0.16048049926757812
Epoch:  439  	Training Loss: 0.12208814173936844
Test Loss:  0.16621646285057068
Valid Loss:  0.16048045456409454
Epoch:  440  	Training Loss: 0.12208811938762665
Test Loss:  0.1662164032459259
Valid Loss:  0.16048040986061096
Epoch:  441  	Training Loss: 0.12208807468414307
Test Loss:  0.16621635854244232
Valid Loss:  0.16048038005828857
Epoch:  442  	Training Loss: 0.12208804488182068
Test Loss:  0.16621631383895874
Valid Loss:  0.1604803204536438
Epoch:  443  	Training Loss: 0.1220880001783371
Test Loss:  0.16621625423431396
Valid Loss:  0.1604802906513214
Epoch:  444  	Training Loss: 0.12208797037601471
Test Loss:  0.16621622443199158
Valid Loss:  0.16048024594783783
Epoch:  445  	Training Loss: 0.12208794057369232
Test Loss:  0.1662161648273468
Valid Loss:  0.16048020124435425
Epoch:  446  	Training Loss: 0.12208789587020874
Test Loss:  0.16621613502502441
Valid Loss:  0.16048014163970947
Epoch:  447  	Training Loss: 0.12208785861730576
Test Loss:  0.16621607542037964
Valid Loss:  0.16048011183738708
Epoch:  448  	Training Loss: 0.12208783626556396
Test Loss:  0.16621603071689606
Valid Loss:  0.1604800671339035
Epoch:  449  	Training Loss: 0.12208779156208038
Test Loss:  0.16621598601341248
Valid Loss:  0.16048002243041992
Epoch:  450  	Training Loss: 0.122087761759758
Test Loss:  0.1662159264087677
Valid Loss:  0.16047997772693634
Epoch:  451  	Training Loss: 0.12208771705627441
Test Loss:  0.1662158966064453
Valid Loss:  0.16047993302345276
Epoch:  452  	Training Loss: 0.12208767980337143
Test Loss:  0.16621583700180054
Valid Loss:  0.16047987341880798
Epoch:  453  	Training Loss: 0.12208764255046844
Test Loss:  0.16621579229831696
Valid Loss:  0.1604798436164856
Epoch:  454  	Training Loss: 0.12208759784698486
Test Loss:  0.16621573269367218
Valid Loss:  0.16047978401184082
Epoch:  455  	Training Loss: 0.12208756804466248
Test Loss:  0.1662156879901886
Valid Loss:  0.16047973930835724
Epoch:  456  	Training Loss: 0.1220875233411789
Test Loss:  0.16621562838554382
Valid Loss:  0.16047969460487366
Epoch:  457  	Training Loss: 0.12208747863769531
Test Loss:  0.16621558368206024
Valid Loss:  0.16047963500022888
Epoch:  458  	Training Loss: 0.12208744883537292
Test Loss:  0.16621553897857666
Valid Loss:  0.1604795753955841
Epoch:  459  	Training Loss: 0.12208740413188934
Test Loss:  0.16621547937393188
Valid Loss:  0.16047953069210052
Epoch:  460  	Training Loss: 0.12208736687898636
Test Loss:  0.1662154197692871
Valid Loss:  0.16047948598861694
Epoch:  461  	Training Loss: 0.12208732217550278
Test Loss:  0.16621537506580353
Valid Loss:  0.16047944128513336
Epoch:  462  	Training Loss: 0.12208728492259979
Test Loss:  0.16621533036231995
Valid Loss:  0.16047939658164978
Epoch:  463  	Training Loss: 0.12208724021911621
Test Loss:  0.16621525585651398
Valid Loss:  0.160479336977005
Epoch:  464  	Training Loss: 0.12208719551563263
Test Loss:  0.1662152111530304
Valid Loss:  0.16047929227352142
Epoch:  465  	Training Loss: 0.12208715826272964
Test Loss:  0.16621515154838562
Valid Loss:  0.16047923266887665
Epoch:  466  	Training Loss: 0.12208712100982666
Test Loss:  0.16621509194374084
Valid Loss:  0.16047917306423187
Epoch:  467  	Training Loss: 0.12208707630634308
Test Loss:  0.16621504724025726
Valid Loss:  0.1604791283607483
Epoch:  468  	Training Loss: 0.1220870316028595
Test Loss:  0.16621500253677368
Valid Loss:  0.16047906875610352
Epoch:  469  	Training Loss: 0.12208700180053711
Test Loss:  0.1662149429321289
Valid Loss:  0.16047903895378113
Epoch:  470  	Training Loss: 0.12208694964647293
Test Loss:  0.16621488332748413
Valid Loss:  0.16047897934913635
Epoch:  471  	Training Loss: 0.12208691239356995
Test Loss:  0.16621482372283936
Valid Loss:  0.16047891974449158
Epoch:  472  	Training Loss: 0.12208686769008636
Test Loss:  0.16621476411819458
Valid Loss:  0.160478875041008
Epoch:  473  	Training Loss: 0.12208682298660278
Test Loss:  0.1662147045135498
Valid Loss:  0.16047881543636322
Epoch:  474  	Training Loss: 0.1220867708325386
Test Loss:  0.16621464490890503
Valid Loss:  0.16047877073287964
Epoch:  475  	Training Loss: 0.12208672612905502
Test Loss:  0.16621460020542145
Valid Loss:  0.16047871112823486
Epoch:  476  	Training Loss: 0.12208668142557144
Test Loss:  0.16621454060077667
Valid Loss:  0.1604786515235901
Epoch:  477  	Training Loss: 0.12208664417266846
Test Loss:  0.1662144660949707
Valid Loss:  0.1604785919189453
Epoch:  478  	Training Loss: 0.12208659201860428
Test Loss:  0.16621440649032593
Valid Loss:  0.16047854721546173
Epoch:  479  	Training Loss: 0.1220865547657013
Test Loss:  0.16621436178684235
Valid Loss:  0.16047847270965576
Epoch:  480  	Training Loss: 0.12208651006221771
Test Loss:  0.16621430218219757
Valid Loss:  0.160478413105011
Epoch:  481  	Training Loss: 0.12208645045757294
Test Loss:  0.1662142276763916
Valid Loss:  0.1604783684015274
Epoch:  482  	Training Loss: 0.12208642065525055
Test Loss:  0.1662141978740692
Valid Loss:  0.16047832369804382
Epoch:  483  	Training Loss: 0.12208637595176697
Test Loss:  0.16621413826942444
Valid Loss:  0.16047827899456024
Epoch:  484  	Training Loss: 0.12208633124828339
Test Loss:  0.16621407866477966
Valid Loss:  0.16047823429107666
Epoch:  485  	Training Loss: 0.122086301445961
Test Loss:  0.16621404886245728
Valid Loss:  0.16047817468643188
Epoch:  486  	Training Loss: 0.12208625674247742
Test Loss:  0.1662139892578125
Valid Loss:  0.1604781299829483
Epoch:  487  	Training Loss: 0.12208622694015503
Test Loss:  0.1662139594554901
Valid Loss:  0.16047808527946472
Epoch:  488  	Training Loss: 0.12208618223667145
Test Loss:  0.16621389985084534
Valid Loss:  0.16047802567481995
Epoch:  489  	Training Loss: 0.12208615243434906
Test Loss:  0.16621384024620056
Valid Loss:  0.16047799587249756
Epoch:  490  	Training Loss: 0.12208610773086548
Test Loss:  0.16621379554271698
Valid Loss:  0.16047793626785278
Epoch:  491  	Training Loss: 0.1220860704779625
Test Loss:  0.1662137508392334
Valid Loss:  0.1604779064655304
Epoch:  492  	Training Loss: 0.12208603322505951
Test Loss:  0.16621370613574982
Valid Loss:  0.16047784686088562
Epoch:  493  	Training Loss: 0.12208599597215652
Test Loss:  0.16621367633342743
Valid Loss:  0.16047783195972443
Epoch:  494  	Training Loss: 0.12208596616983414
Test Loss:  0.16621361672878265
Valid Loss:  0.16047778725624084
Epoch:  495  	Training Loss: 0.12208593636751175
Test Loss:  0.16621358692646027
Valid Loss:  0.16047775745391846
Epoch:  496  	Training Loss: 0.12208590656518936
Test Loss:  0.16621354222297668
Valid Loss:  0.16047769784927368
Epoch:  497  	Training Loss: 0.12208587676286697
Test Loss:  0.1662134975194931
Valid Loss:  0.1604776680469513
Epoch:  498  	Training Loss: 0.12208583950996399
Test Loss:  0.16621345281600952
Valid Loss:  0.1604776382446289
Epoch:  499  	Training Loss: 0.1220858097076416
Test Loss:  0.16621340811252594
Valid Loss:  0.16047760844230652
Epoch:  500  	Training Loss: 0.12208577990531921
Test Loss:  0.16621336340904236
Valid Loss:  0.16047754883766174
seed is  4
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:07,  6.27s/it]  0%|          | 2/500 [00:06<21:54,  2.64s/it]  1%|          | 4/500 [00:06<08:34,  1.04s/it]  1%|          | 6/500 [00:06<04:50,  1.70it/s]  2%|▏         | 8/500 [00:06<03:09,  2.60it/s]  2%|▏         | 10/500 [00:07<02:15,  3.61it/s]  2%|▏         | 12/500 [00:13<10:29,  1.29s/it]  3%|▎         | 14/500 [00:13<07:11,  1.13it/s]  3%|▎         | 16/500 [00:13<05:02,  1.60it/s]  4%|▎         | 18/500 [00:13<03:36,  2.23it/s]  4%|▍         | 20/500 [00:14<02:38,  3.03it/s]  4%|▍         | 22/500 [00:20<09:43,  1.22s/it]  5%|▍         | 24/500 [00:20<06:56,  1.14it/s]  5%|▌         | 26/500 [00:20<05:01,  1.57it/s]  6%|▌         | 28/500 [00:21<03:41,  2.13it/s]  6%|▌         | 30/500 [00:21<02:43,  2.88it/s]  6%|▋         | 32/500 [00:27<09:30,  1.22s/it]  7%|▋         | 34/500 [00:27<06:46,  1.15it/s]  7%|▋         | 36/500 [00:27<04:51,  1.59it/s]  8%|▊         | 38/500 [00:28<03:32,  2.17it/s]  8%|▊         | 40/500 [00:28<02:38,  2.91it/s]  8%|▊         | 42/500 [00:34<09:04,  1.19s/it]  9%|▉         | 44/500 [00:34<06:28,  1.17it/s]  9%|▉         | 46/500 [00:34<04:39,  1.62it/s] 10%|▉         | 48/500 [00:34<03:23,  2.22it/s] 10%|█         | 50/500 [00:41<09:33,  1.27s/it] 10%|█         | 51/500 [00:47<16:26,  2.20s/it] 11%|█         | 53/500 [00:47<11:03,  1.48s/it] 11%|█         | 55/500 [00:48<07:36,  1.03s/it] 11%|█▏        | 57/500 [00:48<05:19,  1.39it/s] 12%|█▏        | 59/500 [00:48<03:48,  1.93it/s] 12%|█▏        | 61/500 [00:54<09:49,  1.34s/it] 13%|█▎        | 63/500 [00:54<06:57,  1.05it/s] 13%|█▎        | 65/500 [00:55<04:59,  1.45it/s] 13%|█▎        | 67/500 [00:55<03:39,  1.97it/s] 14%|█▍        | 69/500 [00:55<02:43,  2.63it/s]Epoch:  1  	Training Loss: 0.07232363522052765
Test Loss:  13.78780746459961
Valid Loss:  13.719427108764648
Epoch:  2  	Training Loss: 12.528324127197266
Test Loss:  303.3572998046875
Valid Loss:  288.607421875
Epoch:  3  	Training Loss: 305.76605224609375
Test Loss:  0.9533836841583252
Valid Loss:  1.0156221389770508
Epoch:  4  	Training Loss: 1.1286952495574951
Test Loss:  0.9525833129882812
Valid Loss:  1.0143482685089111
Epoch:  5  	Training Loss: 1.1274855136871338
Test Loss:  0.9517838358879089
Valid Loss:  1.013077735900879
Epoch:  6  	Training Loss: 1.126278281211853
Test Loss:  0.950985848903656
Valid Loss:  1.0118526220321655
Epoch:  7  	Training Loss: 1.1250745058059692
Test Loss:  0.950188934803009
Valid Loss:  1.0107223987579346
Epoch:  8  	Training Loss: 1.1238734722137451
Test Loss:  0.9493927955627441
Valid Loss:  1.0095946788787842
Epoch:  9  	Training Loss: 1.1226754188537598
Test Loss:  0.9485981464385986
Valid Loss:  1.008470058441162
Epoch:  10  	Training Loss: 1.121480941772461
Test Loss:  0.9478045701980591
Valid Loss:  1.0073485374450684
Epoch:  11  	Training Loss: 1.1202890872955322
Test Loss:  0.9470118284225464
Valid Loss:  1.0062296390533447
Epoch:  12  	Training Loss: 1.1190999746322632
Test Loss:  0.666559100151062
Valid Loss:  0.5613203644752502
Epoch:  13  	Training Loss: 0.6457456350326538
Test Loss:  0.07977944612503052
Valid Loss:  0.11715556681156158
Epoch:  14  	Training Loss: 0.1678318977355957
Test Loss:  0.06206435710191727
Valid Loss:  0.051725104451179504
Epoch:  15  	Training Loss: 0.07743565738201141
Test Loss:  0.017968803644180298
Valid Loss:  0.031130079180002213
Epoch:  16  	Training Loss: 0.059983301907777786
Test Loss:  0.02717803604900837
Valid Loss:  0.030590441077947617
Epoch:  17  	Training Loss: 0.056410979479551315
Test Loss:  0.02111782692372799
Valid Loss:  0.028814077377319336
Epoch:  18  	Training Loss: 0.05541008710861206
Test Loss:  0.023220911622047424
Valid Loss:  0.02895003743469715
Epoch:  19  	Training Loss: 0.05482728034257889
Test Loss:  0.0219818577170372
Valid Loss:  0.02849400043487549
Epoch:  20  	Training Loss: 0.05428915470838547
Test Loss:  0.022143341600894928
Valid Loss:  0.028328198939561844
Epoch:  21  	Training Loss: 0.05369583144783974
Test Loss:  0.021624336019158363
Valid Loss:  0.027951523661613464
Epoch:  22  	Training Loss: 0.05293074622750282
Test Loss:  0.020655013620853424
Valid Loss:  0.02794370800256729
Epoch:  23  	Training Loss: 0.052727654576301575
Test Loss:  0.020015351474285126
Valid Loss:  0.02745959162712097
Epoch:  24  	Training Loss: 0.05262898653745651
Test Loss:  0.019685834646224976
Valid Loss:  0.027046440169215202
Epoch:  25  	Training Loss: 0.05256113037467003
Test Loss:  0.0194336399435997
Valid Loss:  0.026741715148091316
Epoch:  26  	Training Loss: 0.05249826982617378
Test Loss:  0.019267454743385315
Valid Loss:  0.02652953565120697
Epoch:  27  	Training Loss: 0.05242683365941048
Test Loss:  0.019112419337034225
Valid Loss:  0.02635922096669674
Epoch:  28  	Training Loss: 0.052269481122493744
Test Loss:  0.019002534449100494
Valid Loss:  0.02622831054031849
Epoch:  29  	Training Loss: 0.05201363191008568
Test Loss:  0.018860183656215668
Valid Loss:  0.026096217334270477
Epoch:  30  	Training Loss: 0.05170990154147148
Test Loss:  0.01873261295258999
Valid Loss:  0.025978626683354378
Epoch:  31  	Training Loss: 0.05132167041301727
Test Loss:  0.018630335107445717
Valid Loss:  0.025877607986330986
Epoch:  32  	Training Loss: 0.0507826991379261
Test Loss:  0.022775106132030487
Valid Loss:  0.02296888455748558
Epoch:  33  	Training Loss: 0.027855293825268745
Test Loss:  0.019869893789291382
Valid Loss:  0.03389008715748787
Epoch:  34  	Training Loss: 0.02588837221264839
Test Loss:  0.01976785808801651
Valid Loss:  0.019728273153305054
Epoch:  35  	Training Loss: 0.020827051252126694
Test Loss:  0.013207749463617802
Valid Loss:  0.02245776355266571
Epoch:  36  	Training Loss: 0.01488534826785326
Test Loss:  0.011337608098983765
Valid Loss:  0.01541767455637455
Epoch:  37  	Training Loss: 0.01194772683084011
Test Loss:  0.010330729186534882
Valid Loss:  0.01740948110818863
Epoch:  38  	Training Loss: 0.01043480634689331
Test Loss:  0.00947453174740076
Valid Loss:  0.014448219910264015
Epoch:  39  	Training Loss: 0.009539108723402023
Test Loss:  0.009166263975203037
Valid Loss:  0.015115104615688324
Epoch:  40  	Training Loss: 0.008929898031055927
Test Loss:  0.008691761642694473
Valid Loss:  0.01365569606423378
Epoch:  41  	Training Loss: 0.008452448062598705
Test Loss:  0.008435615338385105
Valid Loss:  0.013689421117305756
Epoch:  42  	Training Loss: 0.00807274878025055
Test Loss:  0.006864060647785664
Valid Loss:  0.007206869311630726
Epoch:  43  	Training Loss: 0.006325220689177513
Test Loss:  0.006129234563559294
Valid Loss:  0.010662687011063099
Epoch:  44  	Training Loss: 0.006327151320874691
Test Loss:  0.008952891454100609
Valid Loss:  0.006205171812325716
Epoch:  45  	Training Loss: 0.007177287712693214
Test Loss:  0.008591880090534687
Valid Loss:  0.014494534581899643
Epoch:  46  	Training Loss: 0.009398841299116611
Test Loss:  0.017522921785712242
Valid Loss:  0.01162516325712204
Epoch:  47  	Training Loss: 0.01339174248278141
Test Loss:  0.01979246363043785
Valid Loss:  0.02874067798256874
Epoch:  48  	Training Loss: 0.02068355306982994
Test Loss:  0.04129577428102493
Valid Loss:  0.03075169026851654
Epoch:  49  	Training Loss: 0.032253798097372055
Test Loss:  0.05304273962974548
Valid Loss:  0.06733573228120804
Epoch:  50  	Training Loss: 0.052299901843070984
Test Loss:  0.1033068299293518
Valid Loss:  0.08536984026432037
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.08386114984750748
Test Loss:  0.6223397254943848
Valid Loss:  0.628162145614624
Epoch:  52  	Training Loss: 0.613633394241333
Test Loss:  0.06527820229530334
Valid Loss:  0.051729295402765274
Epoch:  53  	Training Loss: 0.05920279026031494
Test Loss:  0.004163969308137894
Valid Loss:  0.0023809405975043774
Epoch:  54  	Training Loss: 0.0031956126913428307
Test Loss:  0.0035578624811023474
Valid Loss:  0.0019814353436231613
Epoch:  55  	Training Loss: 0.002784219104796648
Test Loss:  0.003109494224190712
Valid Loss:  0.0017069156747311354
Epoch:  56  	Training Loss: 0.002489812206476927
Test Loss:  0.0027849923353642225
Valid Loss:  0.0015140629839152098
Epoch:  57  	Training Loss: 0.0022624502889811993
Test Loss:  0.0025410172529518604
Valid Loss:  0.0013766182819381356
Epoch:  58  	Training Loss: 0.0020712213590741158
Test Loss:  0.0023497529327869415
Valid Loss:  0.001280730008147657
Epoch:  59  	Training Loss: 0.0019160093506798148
Test Loss:  0.0021987154614180326
Valid Loss:  0.001218182034790516
Epoch:  60  	Training Loss: 0.0017959622200578451
Test Loss:  0.002078194636851549
Valid Loss:  0.0011812568409368396
Epoch:  61  	Training Loss: 0.0017052411567419767
Test Loss:  0.00198144163005054
Valid Loss:  0.0011601847363635898
Epoch:  62  	Training Loss: 0.0016350401565432549
Test Loss:  0.0009905510814860463
Valid Loss:  0.0011364197125658393
Epoch:  63  	Training Loss: 0.0010609895689412951
Test Loss:  0.0009251267183572054
Valid Loss:  0.0008165626786649227
Epoch:  64  	Training Loss: 0.0009416106040589511
Test Loss:  0.0008067834423854947
Valid Loss:  0.0007497128681279719
Epoch:  65  	Training Loss: 0.000875620637089014
Test Loss:  0.0007344075129367411
Valid Loss:  0.000658969976939261
Epoch:  66  	Training Loss: 0.0008209564257413149
Test Loss:  0.0006633379962295294
Valid Loss:  0.00059558916836977
Epoch:  67  	Training Loss: 0.0007763587636873126
Test Loss:  0.0006088694790378213
Valid Loss:  0.0005474678473547101
Epoch:  68  	Training Loss: 0.0007387771038338542
Test Loss:  0.0005634857807308435
Valid Loss:  0.0005100533599033952
Epoch:  69  	Training Loss: 0.0007058443734422326
Test Loss:  0.0005266957450658083
Valid Loss:  0.00048088456969708204
Epoch:  70  	Training Loss: 0.0006769171450287104
Test Loss:  0.0004942465457133949
Valid Loss:  0.0004510449944064021
Epoch:  71  	Training Loss: 0.0006500179297290742
Test Loss:   14%|█▍        | 71/500 [01:01<08:55,  1.25s/it] 15%|█▍        | 73/500 [01:02<06:21,  1.12it/s] 15%|█▌        | 75/500 [01:02<04:33,  1.55it/s] 15%|█▌        | 77/500 [01:02<03:19,  2.12it/s] 16%|█▌        | 79/500 [01:02<02:26,  2.86it/s] 16%|█▌        | 81/500 [01:08<08:24,  1.20s/it] 17%|█▋        | 83/500 [01:08<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:09<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:09<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:09<02:19,  2.94it/s] 18%|█▊        | 91/500 [01:15<08:08,  1.20s/it] 19%|█▊        | 93/500 [01:15<05:49,  1.17it/s] 19%|█▉        | 95/500 [01:16<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:16<03:02,  2.20it/s] 20%|█▉        | 99/500 [01:16<02:15,  2.96it/s] 20%|██        | 101/500 [01:22<07:57,  1.20s/it] 21%|██        | 103/500 [01:22<05:42,  1.16it/s] 21%|██        | 105/500 [01:22<04:06,  1.61it/s] 21%|██▏       | 107/500 [01:23<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:23<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:35<13:50,  2.14s/it] 23%|██▎       | 113/500 [01:36<09:48,  1.52s/it] 23%|██▎       | 115/500 [01:36<06:59,  1.09s/it] 23%|██▎       | 117/500 [01:36<05:01,  1.27it/s] 24%|██▍       | 119/500 [01:36<03:37,  1.75it/s] 24%|██▍       | 121/500 [01:42<08:31,  1.35s/it] 25%|██▍       | 123/500 [01:43<06:05,  1.03it/s] 25%|██▌       | 125/500 [01:43<04:23,  1.42it/s] 25%|██▌       | 127/500 [01:43<03:13,  1.93it/s] 26%|██▌       | 129/500 [01:43<02:23,  2.59it/s] 26%|██▌       | 131/500 [01:49<07:29,  1.22s/it] 27%|██▋       | 133/500 [01:50<05:23,  1.14it/s] 27%|██▋       | 135/500 [01:50<03:54,  1.56it/s] 27%|██▋       | 137/500 [01:50<02:52,  2.11it/s]0.00046427303459495306
Valid Loss:  0.00042618397856131196
Epoch:  72  	Training Loss: 0.0006259210640564561
Test Loss:  0.0004691212670877576
Valid Loss:  0.00042142425081692636
Epoch:  73  	Training Loss: 0.0006219044444151223
Test Loss:  0.00047073102905415
Valid Loss:  0.0004184726858511567
Epoch:  74  	Training Loss: 0.0006186555838212371
Test Loss:  0.0004709158092737198
Valid Loss:  0.00041638530092313886
Epoch:  75  	Training Loss: 0.0006159765762276947
Test Loss:  0.0004705091705545783
Valid Loss:  0.00041462271474301815
Epoch:  76  	Training Loss: 0.0006135363364592195
Test Loss:  0.000469920807518065
Valid Loss:  0.0004131654859520495
Epoch:  77  	Training Loss: 0.0006113365525379777
Test Loss:  0.00046917254803702235
Valid Loss:  0.0004119272343814373
Epoch:  78  	Training Loss: 0.0006094018463045359
Test Loss:  0.00046826593461446464
Valid Loss:  0.00041098572546616197
Epoch:  79  	Training Loss: 0.0006076914723962545
Test Loss:  0.00046744878636673093
Valid Loss:  0.00041005510138347745
Epoch:  80  	Training Loss: 0.0006061275489628315
Test Loss:  0.0004666014574468136
Valid Loss:  0.00040926458314061165
Epoch:  81  	Training Loss: 0.0006047124043107033
Test Loss:  0.0004657458048313856
Valid Loss:  0.0004085982800461352
Epoch:  82  	Training Loss: 0.0006034548860043287
Test Loss:  0.00043135235318914056
Valid Loss:  0.00037892634281888604
Epoch:  83  	Training Loss: 0.0005801304941996932
Test Loss:  0.0004020569322165102
Valid Loss:  0.0003565566730685532
Epoch:  84  	Training Loss: 0.0005592481466010213
Test Loss:  0.0003774876531679183
Valid Loss:  0.00033851811895146966
Epoch:  85  	Training Loss: 0.0005412384052760899
Test Loss:  0.0003572874120436609
Valid Loss:  0.00032500532688573003
Epoch:  86  	Training Loss: 0.0005255843279883265
Test Loss:  0.00034059438621625304
Valid Loss:  0.00031419581500813365
Epoch:  87  	Training Loss: 0.0005114973755553365
Test Loss:  0.00032622640719637275
Valid Loss:  0.00030355731723830104
Epoch:  88  	Training Loss: 0.0004980395315214992
Test Loss:  0.00031388417119160295
Valid Loss:  0.0002942053251899779
Epoch:  89  	Training Loss: 0.00048563905875198543
Test Loss:  0.00030325743136927485
Valid Loss:  0.0002860589593183249
Epoch:  90  	Training Loss: 0.0004740901931654662
Test Loss:  0.0002940357371699065
Valid Loss:  0.0002788066049106419
Epoch:  91  	Training Loss: 0.00046310212928801775
Test Loss:  0.0002854850608855486
Valid Loss:  0.00027164770290255547
Epoch:  92  	Training Loss: 0.0004523869720287621
Test Loss:  0.00028499908512458205
Valid Loss:  0.0002711763954721391
Epoch:  93  	Training Loss: 0.000449985614977777
Test Loss:  0.00028451625257730484
Valid Loss:  0.0002707648673094809
Epoch:  94  	Training Loss: 0.00044766394421458244
Test Loss:  0.0002840359229594469
Valid Loss:  0.00027035659877583385
Epoch:  95  	Training Loss: 0.0004454149166122079
Test Loss:  0.00028355317772366107
Valid Loss:  0.0002699521428439766
Epoch:  96  	Training Loss: 0.0004432325076777488
Test Loss:  0.00028306758031249046
Valid Loss:  0.00026954986969940364
Epoch:  97  	Training Loss: 0.0004411123809404671
Test Loss:  0.0002825703122653067
Valid Loss:  0.0002691487898118794
Epoch:  98  	Training Loss: 0.0004390440881252289
Test Loss:  0.0002820672816596925
Valid Loss:  0.0002687403466552496
Epoch:  99  	Training Loss: 0.00043702556286007166
Test Loss:  0.00028154405299574137
Valid Loss:  0.0002683224156498909
Epoch:  100  	Training Loss: 0.0004350509843789041
Test Loss:  0.000281081156572327
Valid Loss:  0.00026790506672114134
Epoch:  101  	Training Loss: 0.0004331399395596236
Test Loss:  0.0002806710253935307
Valid Loss:  0.00026749310200102627
Epoch:  102  	Training Loss: 0.0004313239478506148
Test Loss:  0.00024247250985354185
Valid Loss:  0.00026201619766652584
Epoch:  103  	Training Loss: 0.00035800409386865795
Test Loss:  0.0002470552863087505
Valid Loss:  0.0002566968323662877
Epoch:  104  	Training Loss: 0.0003477295394986868
Test Loss:  0.0002489078906364739
Valid Loss:  0.0002568687777966261
Epoch:  105  	Training Loss: 0.00034395925467833877
Test Loss:  0.0002493146457709372
Valid Loss:  0.0002596315462142229
Epoch:  106  	Training Loss: 0.0003426903276704252
Test Loss:  0.00024208401737269014
Valid Loss:  0.00027347152354195714
Epoch:  107  	Training Loss: 0.0003433384990785271
Test Loss:  0.00024813346681185067
Valid Loss:  0.0002629915834404528
Epoch:  108  	Training Loss: 0.00034031234099529684
Test Loss:  0.00024160328030120581
Valid Loss:  0.0002764512610156089
Epoch:  109  	Training Loss: 0.00034165437682531774
Test Loss:  0.00024777447106316686
Valid Loss:  0.0002638422301970422
Epoch:  110  	Training Loss: 0.0003385014715604484
Test Loss:  0.00024118299188558012
Valid Loss:  0.0002776776673272252
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.00034011935349553823
Test Loss:  0.0002633497351780534
Valid Loss:  0.0002479000831954181
Epoch:  112  	Training Loss: 0.0003337077214382589
Test Loss:  0.00025314599042758346
Valid Loss:  0.00023965451691765338
Epoch:  113  	Training Loss: 0.0003284567501395941
Test Loss:  0.0002450549800414592
Valid Loss:  0.00023203434830065817
Epoch:  114  	Training Loss: 0.00032377560273744166
Test Loss:  0.00023784596123732626
Valid Loss:  0.0002264701179228723
Epoch:  115  	Training Loss: 0.0003202949301339686
Test Loss:  0.0002319991181138903
Valid Loss:  0.00022240150428842753
Epoch:  116  	Training Loss: 0.0003177051548846066
Test Loss:  0.00022730257478542626
Valid Loss:  0.0002194297849200666
Epoch:  117  	Training Loss: 0.00031577833578921854
Test Loss:  0.00022351299412548542
Valid Loss:  0.0002172645617974922
Epoch:  118  	Training Loss: 0.00031434494303539395
Test Loss:  0.0002204431511927396
Valid Loss:  0.00021569087402895093
Epoch:  119  	Training Loss: 0.00031327828764915466
Test Loss:  0.00021793828636873513
Valid Loss:  0.00021455399109981954
Epoch:  120  	Training Loss: 0.00031238654628396034
Test Loss:  0.00021573013509623706
Valid Loss:  0.0002135800023097545
Epoch:  121  	Training Loss: 0.00031162233790382743
Test Loss:  0.00021386114531196654
Valid Loss:  0.00021293503232300282
Epoch:  122  	Training Loss: 0.00031105586094781756
Test Loss:  0.00019803787290584296
Valid Loss:  0.00019435002468526363
Epoch:  123  	Training Loss: 0.0002802549861371517
Test Loss:  0.00018319494847673923
Valid Loss:  0.00018058062414638698
Epoch:  124  	Training Loss: 0.0002552017103880644
Test Loss:  0.0001704140449874103
Valid Loss:  0.00017007160931825638
Epoch:  125  	Training Loss: 0.00023508566664531827
Test Loss:  0.0001596350921317935
Valid Loss:  0.00016184593550860882
Epoch:  126  	Training Loss: 0.00021901860600337386
Test Loss:  0.000150450156070292
Valid Loss:  0.00015533040277659893
Epoch:  127  	Training Loss: 0.0002062424027826637
Test Loss:  0.00014253013068810105
Valid Loss:  0.00015005763270892203
Epoch:  128  	Training Loss: 0.0001957083586603403
Test Loss:  0.00013574675540439785
Valid Loss:  0.00014554348308593035
Epoch:  129  	Training Loss: 0.00018693994206842035
Test Loss:  0.00012976837751921266
Valid Loss:  0.0001414549333276227
Epoch:  130  	Training Loss: 0.00017937601660378277
Test Loss:  0.00012460486323107034
Valid Loss:  0.00013776338892057538
Epoch:  131  	Training Loss: 0.00017266212671529502
Test Loss:  0.00012016664550174028
Valid Loss:  0.00013445546210277826
Epoch:  132  	Training Loss: 0.00016669847536832094
Test Loss:  0.00011521668056957424
Valid Loss:  0.00013665438746102154
Epoch:  133  	Training Loss: 0.00016440037870779634
Test Loss:  0.00011376949987607077
Valid Loss:  0.0001327113131992519
Epoch:  134  	Training Loss: 0.00016259157564491034
Test Loss:  0.00011133716907352209
Valid Loss:  0.00013311539078131318
Epoch:  135  	Training Loss: 0.00016107593546621501
Test Loss:  0.00011020519013982266
Valid Loss:  0.00013169707381166518
Epoch:  136  	Training Loss: 0.00015975115820765495
Test Loss:  0.00010884919902309775
Valid Loss:  0.00013170056627131999
Epoch:  137  	Training Loss: 0.00015855967649258673
Test Loss:  0.00010800541349453852
Valid Loss:  0.0001311698870267719
 28%|██▊       | 139/500 [01:50<02:09,  2.79it/s] 28%|██▊       | 141/500 [01:56<07:12,  1.21s/it] 29%|██▊       | 143/500 [01:57<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:57<03:42,  1.60it/s] 29%|██▉       | 147/500 [01:57<02:41,  2.18it/s] 30%|██▉       | 149/500 [01:57<01:59,  2.94it/s] 30%|███       | 151/500 [02:03<06:54,  1.19s/it] 31%|███       | 153/500 [02:03<04:55,  1.17it/s] 31%|███       | 155/500 [02:04<03:32,  1.62it/s] 31%|███▏      | 157/500 [02:04<02:34,  2.22it/s] 32%|███▏      | 159/500 [02:04<01:54,  2.97it/s] 32%|███▏      | 161/500 [02:10<06:49,  1.21s/it] 33%|███▎      | 163/500 [02:10<04:51,  1.15it/s] 33%|███▎      | 165/500 [02:11<03:29,  1.60it/s] 33%|███▎      | 167/500 [02:11<02:32,  2.18it/s] 34%|███▍      | 169/500 [02:11<01:52,  2.93it/s] 34%|███▍      | 171/500 [02:17<06:38,  1.21s/it] 35%|███▍      | 173/500 [02:17<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:18<03:23,  1.59it/s] 35%|███▌      | 177/500 [02:18<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:18<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:24<06:25,  1.21s/it] 37%|███▋      | 183/500 [02:24<04:34,  1.15it/s] 37%|███▋      | 185/500 [02:25<03:17,  1.60it/s] 37%|███▋      | 187/500 [02:25<02:23,  2.18it/s] 38%|███▊      | 189/500 [02:25<01:45,  2.94it/s] 38%|███▊      | 191/500 [02:31<06:08,  1.19s/it] 39%|███▊      | 193/500 [02:31<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:31<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:32<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:32<01:41,  2.97it/s] 40%|████      | 201/500 [02:38<05:57,  1.19s/it] 41%|████      | 203/500 [02:38<04:14,  1.17it/s]Epoch:  138  	Training Loss: 0.00015746787539683282
Test Loss:  0.000107163330540061
Valid Loss:  0.00013113267777953297
Epoch:  139  	Training Loss: 0.00015645541134290397
Test Loss:  0.00010654715151758865
Valid Loss:  0.00013095179747324437
Epoch:  140  	Training Loss: 0.00015550898388028145
Test Loss:  0.00010598312655929476
Valid Loss:  0.0001309566869167611
Epoch:  141  	Training Loss: 0.00015461942530237138
Test Loss:  0.00010553539323154837
Valid Loss:  0.00013093437883071601
Epoch:  142  	Training Loss: 0.00015378087118733674
Test Loss:  0.00010563792602624744
Valid Loss:  0.00013091032451484352
Epoch:  143  	Training Loss: 0.00015353335766121745
Test Loss:  0.00010572958854027092
Valid Loss:  0.00013091007713228464
Epoch:  144  	Training Loss: 0.00015319764497689903
Test Loss:  0.00010582064714981243
Valid Loss:  0.00013091049913782626
Epoch:  145  	Training Loss: 0.00015287625137716532
Test Loss:  0.0001059121495927684
Valid Loss:  0.00013091259461361915
Epoch:  146  	Training Loss: 0.00015256967162713408
Test Loss:  0.0001060024369508028
Valid Loss:  0.00013091601431369781
Epoch:  147  	Training Loss: 0.00015227586845867336
Test Loss:  0.00010609246965032071
Valid Loss:  0.00013092166045680642
Epoch:  148  	Training Loss: 0.00015199481276795268
Test Loss:  0.00010618112719384953
Valid Loss:  0.00013092871813569218
Epoch:  149  	Training Loss: 0.00015172595158219337
Test Loss:  0.00010627057054080069
Valid Loss:  0.000130937754875049
Epoch:  150  	Training Loss: 0.00015146832447499037
Test Loss:  0.0001063580421032384
Valid Loss:  0.00013094808673486114
Epoch:  151  	Training Loss: 0.00015122120385058224
Test Loss:  0.00010644529538694769
Valid Loss:  0.00013096031034365296
Epoch:  152  	Training Loss: 0.00015098528820089996
Test Loss:  0.00010536654008319601
Valid Loss:  0.00013009500980842859
Epoch:  153  	Training Loss: 0.00015013807569630444
Test Loss:  0.00010445834777783602
Valid Loss:  0.00012947381765116006
Epoch:  154  	Training Loss: 0.00014940275286789984
Test Loss:  0.00010368096263846382
Valid Loss:  0.0001290345098823309
Epoch:  155  	Training Loss: 0.00014875183114781976
Test Loss:  0.00010300393478246406
Valid Loss:  0.00012872929801233113
Epoch:  156  	Training Loss: 0.00014816460316069424
Test Loss:  0.00010240764822810888
Valid Loss:  0.00012852635700255632
Epoch:  157  	Training Loss: 0.00014762760838493705
Test Loss:  0.00010187577572651207
Valid Loss:  0.00012840039562433958
Epoch:  158  	Training Loss: 0.00014709148672409356
Test Loss:  0.00010128653957508504
Valid Loss:  0.000128251122077927
Epoch:  159  	Training Loss: 0.0001464600209146738
Test Loss:  0.00010076574835693464
Valid Loss:  0.00012818259710911661
Epoch:  160  	Training Loss: 0.00014587887562811375
Test Loss:  0.00010030017438111827
Valid Loss:  0.0001281739678233862
Epoch:  161  	Training Loss: 0.0001453375443816185
Test Loss:  9.988137753680348e-05
Valid Loss:  0.00012821191921830177
Epoch:  162  	Training Loss: 0.0001448300899937749
Test Loss:  9.984857024392113e-05
Valid Loss:  0.00012836980749852955
Epoch:  163  	Training Loss: 0.0001446938986191526
Test Loss:  9.989534737542272e-05
Valid Loss:  0.00012841427815146744
Epoch:  164  	Training Loss: 0.00014456597273238003
Test Loss:  9.996026346925646e-05
Valid Loss:  0.0001284368336200714
Epoch:  165  	Training Loss: 0.00014444332919083536
Test Loss:  0.00010002895578509197
Valid Loss:  0.00012845691526308656
Epoch:  166  	Training Loss: 0.0001443260844098404
Test Loss:  0.00010009850666392595
Valid Loss:  0.00012847917969338596
Epoch:  167  	Training Loss: 0.0001442138891434297
Test Loss:  0.00010016842861659825
Valid Loss:  0.00012850329221691936
Epoch:  168  	Training Loss: 0.00014410588482860476
Test Loss:  0.00010024005314335227
Valid Loss:  0.00012853021326009184
Epoch:  169  	Training Loss: 0.00014400303189177066
Test Loss:  0.00010031169222202152
Valid Loss:  0.0001285587204620242
Epoch:  170  	Training Loss: 0.00014390383148565888
Test Loss:  0.00010038413893198594
Valid Loss:  0.00012859032722190022
Epoch:  171  	Training Loss: 0.00014380918582901359
Test Loss:  0.00010045561793958768
Valid Loss:  0.0001286233018618077
Epoch:  172  	Training Loss: 0.00014371832367032766
Test Loss:  9.988009696826339e-05
Valid Loss:  0.00012835432426072657
Epoch:  173  	Training Loss: 0.00014296408335212618
Test Loss:  9.926463098963723e-05
Valid Loss:  0.00012813946523237973
Epoch:  174  	Training Loss: 0.00014215831470210105
Test Loss:  9.871595830190927e-05
Valid Loss:  0.00012804559082724154
Epoch:  175  	Training Loss: 0.00014141350402496755
Test Loss:  9.823021537158638e-05
Valid Loss:  0.00012801424600183964
Epoch:  176  	Training Loss: 0.00014071562327444553
Test Loss:  9.780216350918636e-05
Valid Loss:  0.0001280165888601914
Epoch:  177  	Training Loss: 0.0001400569308316335
Test Loss:  9.742322436068207e-05
Valid Loss:  0.00012803729623556137
Epoch:  178  	Training Loss: 0.00013942951045464724
Test Loss:  9.708788275020197e-05
Valid Loss:  0.00012806756421923637
Epoch:  179  	Training Loss: 0.00013882909843232483
Test Loss:  9.678970673121512e-05
Valid Loss:  0.00012787283048965037
Epoch:  180  	Training Loss: 0.00013825137284584343
Test Loss:  9.652288281358778e-05
Valid Loss:  0.000127649589558132
Epoch:  181  	Training Loss: 0.00013769335055258125
Test Loss:  9.628233237890527e-05
Valid Loss:  0.00012743953266181052
Epoch:  182  	Training Loss: 0.00013715280510950834
Test Loss:  9.682235395302996e-05
Valid Loss:  0.0001255779789062217
Epoch:  183  	Training Loss: 0.00013379134179558605
Test Loss:  9.718314686324447e-05
Valid Loss:  0.00012564921053126454
Epoch:  184  	Training Loss: 0.00013163709081709385
Test Loss:  9.79058095254004e-05
Valid Loss:  0.00012560546747408807
Epoch:  185  	Training Loss: 0.00013032706920057535
Test Loss:  9.856856195256114e-05
Valid Loss:  0.00012591230915859342
Epoch:  186  	Training Loss: 0.00012940005399286747
Test Loss:  9.915295231621712e-05
Valid Loss:  0.00012619016342796385
Epoch:  187  	Training Loss: 0.00012874291860498488
Test Loss:  9.969174425350502e-05
Valid Loss:  0.00012643540685530752
Epoch:  188  	Training Loss: 0.00012825048179365695
Test Loss:  0.00010013575956691056
Valid Loss:  0.00012672824959736317
Epoch:  189  	Training Loss: 0.00012788217281922698
Test Loss:  0.00010048757394542918
Valid Loss:  0.0001269372587557882
Epoch:  190  	Training Loss: 0.00012758307275362313
Test Loss:  0.00010078689956571907
Valid Loss:  0.00012706610141322017
Epoch:  191  	Training Loss: 0.00012732419418171048
Test Loss:  0.0001009778497973457
Valid Loss:  0.00012718398647848517
Epoch:  192  	Training Loss: 0.000127100181998685
Test Loss:  0.00010021872003562748
Valid Loss:  0.00012622022768482566
Epoch:  193  	Training Loss: 0.00012622997746802866
Test Loss:  9.971894905902445e-05
Valid Loss:  0.0001257785625057295
Epoch:  194  	Training Loss: 0.00012554062413983047
Test Loss:  9.937478898791596e-05
Valid Loss:  0.000125607693917118
Epoch:  195  	Training Loss: 0.00012496448471210897
Test Loss:  9.913432586472481e-05
Valid Loss:  0.00012558190792333335
Epoch:  196  	Training Loss: 0.00012446600885596126
Test Loss:  9.896580741042271e-05
Valid Loss:  0.00012563337804749608
Epoch:  197  	Training Loss: 0.00012402440188452601
Test Loss:  9.88500178209506e-05
Valid Loss:  0.0001257248077308759
Epoch:  198  	Training Loss: 0.000123627542052418
Test Loss:  9.877824049908668e-05
Valid Loss:  0.00012583400530274957
Epoch:  199  	Training Loss: 0.0001232679933309555
Test Loss:  9.87360836006701e-05
Valid Loss:  0.00012595084263011813
Epoch:  200  	Training Loss: 0.0001229350018547848
Test Loss:  9.871790825854987e-05
Valid Loss:  0.0001260673307115212
Epoch:  201  	Training Loss: 0.00012262281961739063
Test Loss:  9.871649672277272e-05
Valid Loss:  0.00012618009350262582
Epoch:  202  	Training Loss: 0.00012232827430125326
Test Loss:  9.872733789961785e-05
Valid Loss:  0.0001261592551600188
Epoch:  203  	Training Loss: 0.00012195624003652483
Test Loss:  9.872758528217673e-05
Valid Loss:  0.00012602363131009042
Epoch:  204  	Training Loss: 0.00012160747428424656
Test Loss:  9.87203893600963e-05
Valid Loss:  0.00012591360427904874
 41%|████      | 205/500 [02:38<03:02,  1.61it/s] 41%|████▏     | 207/500 [02:39<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:39<01:38,  2.97it/s] 42%|████▏     | 211/500 [02:45<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:45<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:45<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:45<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:46<01:37,  2.89it/s] 44%|████▍     | 221/500 [02:52<05:39,  1.22s/it] 45%|████▍     | 223/500 [02:52<04:01,  1.15it/s] 45%|████▌     | 225/500 [02:52<02:53,  1.59it/s] 45%|████▌     | 227/500 [02:52<02:05,  2.17it/s] 46%|████▌     | 229/500 [02:53<01:32,  2.92it/s] 46%|████▌     | 231/500 [02:59<05:27,  1.22s/it] 47%|████▋     | 233/500 [02:59<03:53,  1.14it/s] 47%|████▋     | 235/500 [02:59<02:47,  1.58it/s] 47%|████▋     | 237/500 [03:00<02:01,  2.17it/s] 48%|████▊     | 239/500 [03:00<01:29,  2.92it/s] 48%|████▊     | 241/500 [03:06<05:13,  1.21s/it] 49%|████▊     | 243/500 [03:06<03:42,  1.15it/s] 49%|████▉     | 245/500 [03:06<02:39,  1.60it/s] 49%|████▉     | 247/500 [03:07<01:56,  2.18it/s] 50%|████▉     | 249/500 [03:07<01:25,  2.93it/s] 50%|█████     | 251/500 [03:13<04:56,  1.19s/it] 51%|█████     | 253/500 [03:13<03:32,  1.16it/s] 51%|█████     | 255/500 [03:13<02:34,  1.59it/s] 51%|█████▏    | 257/500 [03:14<01:53,  2.15it/s] 52%|█████▏    | 259/500 [03:14<01:24,  2.84it/s] 52%|█████▏    | 261/500 [03:20<04:55,  1.23s/it] 53%|█████▎    | 263/500 [03:20<03:29,  1.13it/s] 53%|█████▎    | 265/500 [03:21<02:30,  1.56it/s] 53%|█████▎    | 267/500 [03:21<01:49,  2.14it/s] 54%|█████▍    | 269/500 [03:21<01:20,  2.88it/s] 54%|█████▍    | 271/500 [03:27<04:35,  1.21s/it]Epoch:  205  	Training Loss: 0.0001212743081850931
Test Loss:  9.870564826996997e-05
Valid Loss:  0.00012580183101817966
Epoch:  206  	Training Loss: 0.00012095829879399389
Test Loss:  9.868424967862666e-05
Valid Loss:  0.00012569724640343338
Epoch:  207  	Training Loss: 0.00012065611372236162
Test Loss:  9.865187894320115e-05
Valid Loss:  0.00012559740571305156
Epoch:  208  	Training Loss: 0.00012036217958666384
Test Loss:  9.861516446107998e-05
Valid Loss:  0.00012550229439511895
Epoch:  209  	Training Loss: 0.00012008176418021321
Test Loss:  9.856832912191749e-05
Valid Loss:  0.00012540230818558484
Epoch:  210  	Training Loss: 0.00011980832641711459
Test Loss:  9.851322101894766e-05
Valid Loss:  0.00012530136154964566
Epoch:  211  	Training Loss: 0.00011954440560657531
Test Loss:  9.846365719567984e-05
Valid Loss:  0.00012521169264800847
Epoch:  212  	Training Loss: 0.00011929564789170399
Test Loss:  9.81177290668711e-05
Valid Loss:  0.0001247882901225239
Epoch:  213  	Training Loss: 0.00011879023804794997
Test Loss:  9.788294119061902e-05
Valid Loss:  0.00012453070667106658
Epoch:  214  	Training Loss: 0.00011834243196062744
Test Loss:  9.771913755685091e-05
Valid Loss:  0.00012438349949661642
Epoch:  215  	Training Loss: 0.00011793577868957072
Test Loss:  9.760618559084833e-05
Valid Loss:  0.00012431164213921875
Epoch:  216  	Training Loss: 0.00011755945888580754
Test Loss:  9.75315342657268e-05
Valid Loss:  0.0001242907892446965
Epoch:  217  	Training Loss: 0.00011720792826963589
Test Loss:  9.74858266999945e-05
Valid Loss:  0.00012430624337866902
Epoch:  218  	Training Loss: 0.00011684834316838533
Test Loss:  9.742342808749527e-05
Valid Loss:  0.00012428675836417824
Epoch:  219  	Training Loss: 0.00011634832480922341
Test Loss:  9.737303480505943e-05
Valid Loss:  0.00012427910405676812
Epoch:  220  	Training Loss: 0.00011577281111385673
Test Loss:  9.738071821630001e-05
Valid Loss:  0.0001243492151843384
Epoch:  221  	Training Loss: 0.00011524466390255839
Test Loss:  9.742905967868865e-05
Valid Loss:  0.00012447027256712317
Epoch:  222  	Training Loss: 0.00011475365317892283
Test Loss:  9.755521023180336e-05
Valid Loss:  0.00012440228601917624
Epoch:  223  	Training Loss: 0.00011439329682616517
Test Loss:  9.771423356141895e-05
Valid Loss:  0.00012459585559554398
Epoch:  224  	Training Loss: 0.00011405871191527694
Test Loss:  9.78900061454624e-05
Valid Loss:  0.00012474803952500224
Epoch:  225  	Training Loss: 0.00011374363384675235
Test Loss:  9.808056347537786e-05
Valid Loss:  0.00012490851804614067
Epoch:  226  	Training Loss: 0.00011344442464178428
Test Loss:  9.828257316257805e-05
Valid Loss:  0.00012506707571446896
Epoch:  227  	Training Loss: 0.00011315940355416387
Test Loss:  9.849366324488074e-05
Valid Loss:  0.00012522506585810333
Epoch:  228  	Training Loss: 0.00011288654059171677
Test Loss:  9.865532774711028e-05
Valid Loss:  0.00012538081500679255
Epoch:  229  	Training Loss: 0.00011262480256846175
Test Loss:  9.867730841506273e-05
Valid Loss:  0.00012553548731375486
Epoch:  230  	Training Loss: 0.00011237341823289171
Test Loss:  9.871154907159507e-05
Valid Loss:  0.00012562029587570578
Epoch:  231  	Training Loss: 0.00011213110701646656
Test Loss:  9.875764953903854e-05
Valid Loss:  0.0001255835813935846
Epoch:  232  	Training Loss: 0.00011189782526344061
Test Loss:  9.895819675875828e-05
Valid Loss:  0.00012581310875248164
Epoch:  233  	Training Loss: 0.00011163963790750131
Test Loss:  9.906996274366975e-05
Valid Loss:  0.00012582702038343996
Epoch:  234  	Training Loss: 0.00011142579023726285
Test Loss:  9.912975656334311e-05
Valid Loss:  0.00012575282016769052
Epoch:  235  	Training Loss: 0.00011123035801574588
Test Loss:  9.916604903992265e-05
Valid Loss:  0.0001256500545423478
Epoch:  236  	Training Loss: 0.000111052104330156
Test Loss:  9.918211435433477e-05
Valid Loss:  0.00012553455599118024
Epoch:  237  	Training Loss: 0.00011088413884863257
Test Loss:  9.918365685734898e-05
Valid Loss:  0.0001254179369425401
Epoch:  238  	Training Loss: 0.00011072472261730582
Test Loss:  9.917261195369065e-05
Valid Loss:  0.00012530130334198475
Epoch:  239  	Training Loss: 0.0001105729752453044
Test Loss:  9.915148257277906e-05
Valid Loss:  0.00012518673611339182
Epoch:  240  	Training Loss: 0.00011042712139897048
Test Loss:  9.911959932651371e-05
Valid Loss:  0.0001250735076609999
Epoch:  241  	Training Loss: 0.00011028687003999949
Test Loss:  9.907888306770474e-05
Valid Loss:  0.00012496150156948715
Epoch:  242  	Training Loss: 0.00011015264317393303
Test Loss:  9.910406515700743e-05
Valid Loss:  0.0001249527558684349
Epoch:  243  	Training Loss: 0.00010994728654623032
Test Loss:  9.911971574183553e-05
Valid Loss:  0.0001249258202733472
Epoch:  244  	Training Loss: 0.00010974978795275092
Test Loss:  9.9127646535635e-05
Valid Loss:  0.00012488572974689305
Epoch:  245  	Training Loss: 0.00010955786274280399
Test Loss:  9.912868699757382e-05
Valid Loss:  0.0001248382031917572
Epoch:  246  	Training Loss: 0.00010937082697637379
Test Loss:  9.91264678305015e-05
Valid Loss:  0.00012478727148845792
Epoch:  247  	Training Loss: 0.00010918939369730651
Test Loss:  9.912310633808374e-05
Valid Loss:  0.0001247361651621759
Epoch:  248  	Training Loss: 0.00010901511996053159
Test Loss:  9.911920642480254e-05
Valid Loss:  0.0001246850297320634
Epoch:  249  	Training Loss: 0.00010884600487770513
Test Loss:  9.911316737998277e-05
Valid Loss:  0.00012463306484278291
Epoch:  250  	Training Loss: 0.00010868172103073448
Test Loss:  9.910833614412695e-05
Valid Loss:  0.0001245828898390755
Epoch:  251  	Training Loss: 0.00010852288687601686
Test Loss:  9.910085645969957e-05
Valid Loss:  0.00012453171075321734
Epoch:  252  	Training Loss: 0.00010836850560735911
Test Loss:  9.904055332299322e-05
Valid Loss:  0.00012451082875486463
Epoch:  253  	Training Loss: 0.00010826620564330369
Test Loss:  9.896117262542248e-05
Valid Loss:  0.00012446340406313539
Epoch:  254  	Training Loss: 0.00010816645226441324
Test Loss:  9.887437772704288e-05
Valid Loss:  0.00012440433783922344
Epoch:  255  	Training Loss: 0.00010807175567606464
Test Loss:  9.877846605377272e-05
Valid Loss:  0.00012433138908818364
Epoch:  256  	Training Loss: 0.00010797793220262975
Test Loss:  9.867511107586324e-05
Valid Loss:  0.00012424925807863474
Epoch:  257  	Training Loss: 0.0001078849527402781
Test Loss:  9.857139230007306e-05
Valid Loss:  0.0001241607533302158
Epoch:  258  	Training Loss: 0.00010779280273709446
Test Loss:  9.846885222941637e-05
Valid Loss:  0.00012406830501277
Epoch:  259  	Training Loss: 0.00010770108201541007
Test Loss:  9.836433309828863e-05
Valid Loss:  0.00012397213140502572
Epoch:  260  	Training Loss: 0.00010760982695501298
Test Loss:  9.825841698329896e-05
Valid Loss:  0.00012387447350192815
Epoch:  261  	Training Loss: 0.00010751927038654685
Test Loss:  9.815172234084457e-05
Valid Loss:  0.00012377521488815546
Epoch:  262  	Training Loss: 0.00010742913582362235
Test Loss:  9.788088209461421e-05
Valid Loss:  0.00012260768562555313
Epoch:  263  	Training Loss: 0.00010686453606467694
Test Loss:  9.77974123088643e-05
Valid Loss:  0.0001223291183123365
Epoch:  264  	Training Loss: 0.00010644158464856446
Test Loss:  9.779290849110112e-05
Valid Loss:  0.0001220898557221517
Epoch:  265  	Training Loss: 0.00010605578427203
Test Loss:  9.78213720372878e-05
Valid Loss:  0.0001217617464135401
Epoch:  266  	Training Loss: 0.00010570545418886468
Test Loss:  9.784726717043668e-05
Valid Loss:  0.00012148357200203463
Epoch:  267  	Training Loss: 0.00010538661445025355
Test Loss:  9.789391333470121e-05
Valid Loss:  0.00012122057523811236
Epoch:  268  	Training Loss: 0.00010509021376492456
Test Loss:  9.795595542527735e-05
Valid Loss:  0.00012097983562853187
Epoch:  269  	Training Loss: 0.0001048138365149498
Test Loss:  9.802838030736893e-05
Valid Loss:  0.00012076464190613478
Epoch:  270  	Training Loss: 0.0001045547251123935
Test Loss:  9.810904157347977e-05
Valid Loss:  0.000120579257782083
Epoch:  271  	Training Loss: 0.0001043113661580719
Test Loss:  9.819330443860963e-05
Valid Loss:  0.00012040745059493929
Epoch:  272  	Training Loss: 0.00010408183152321726
 55%|█████▍    | 273/500 [03:27<03:17,  1.15it/s] 55%|█████▌    | 275/500 [03:28<02:22,  1.57it/s] 55%|█████▌    | 277/500 [03:28<01:44,  2.13it/s] 56%|█████▌    | 279/500 [03:28<01:18,  2.82it/s] 56%|█████▌    | 281/500 [03:34<04:27,  1.22s/it] 57%|█████▋    | 283/500 [03:35<03:10,  1.14it/s] 57%|█████▋    | 285/500 [03:35<02:15,  1.58it/s] 57%|█████▋    | 287/500 [03:35<01:38,  2.16it/s] 58%|█████▊    | 289/500 [03:35<01:12,  2.91it/s] 58%|█████▊    | 291/500 [03:41<04:11,  1.20s/it] 59%|█████▊    | 293/500 [03:42<02:59,  1.16it/s] 59%|█████▉    | 295/500 [03:42<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:42<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:42<01:08,  2.94it/s] 60%|██████    | 301/500 [03:48<03:57,  1.19s/it] 61%|██████    | 303/500 [03:48<02:48,  1.17it/s] 61%|██████    | 305/500 [03:49<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:49<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:49<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:55<03:43,  1.19s/it] 63%|██████▎   | 313/500 [03:55<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:55<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:56<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:56<01:00,  2.97it/s] 64%|██████▍   | 321/500 [04:02<03:32,  1.19s/it] 65%|██████▍   | 323/500 [04:02<02:31,  1.17it/s] 65%|██████▌   | 325/500 [04:02<01:49,  1.60it/s] 65%|██████▌   | 327/500 [04:03<01:20,  2.16it/s] 66%|██████▌   | 329/500 [04:03<00:59,  2.87it/s] 66%|██████▌   | 331/500 [04:09<03:23,  1.20s/it] 67%|██████▋   | 333/500 [04:09<02:24,  1.16it/s] 67%|██████▋   | 335/500 [04:09<01:42,  1.60it/s] 67%|██████▋   | 337/500 [04:10<01:14,  2.19it/s] 68%|██████▊   | 339/500 [04:10<00:54,  2.94it/s]Test Loss:  9.822397259995341e-05
Valid Loss:  0.00012046938354615122
Epoch:  273  	Training Loss: 0.0001037374822772108
Test Loss:  9.81375778792426e-05
Valid Loss:  0.0001201933846459724
Epoch:  274  	Training Loss: 0.00010341538290958852
Test Loss:  9.80805853032507e-05
Valid Loss:  0.00011995664681307971
Epoch:  275  	Training Loss: 0.00010310691868653521
Test Loss:  9.797111852094531e-05
Valid Loss:  0.00011972997890552506
Epoch:  276  	Training Loss: 0.00010280734568368644
Test Loss:  9.780465916264802e-05
Valid Loss:  0.00011943637946387753
Epoch:  277  	Training Loss: 0.0001025163583108224
Test Loss:  9.765355207491666e-05
Valid Loss:  0.00011909494787687436
Epoch:  278  	Training Loss: 0.00010223212302662432
Test Loss:  9.751530888024718e-05
Valid Loss:  0.0001187426969408989
Epoch:  279  	Training Loss: 0.00010195450158789754
Test Loss:  9.738713561091572e-05
Valid Loss:  0.00011830279254354537
Epoch:  280  	Training Loss: 0.00010168265725951642
Test Loss:  9.72682173596695e-05
Valid Loss:  0.00011787820403696969
Epoch:  281  	Training Loss: 0.00010141675011254847
Test Loss:  9.715635678730905e-05
Valid Loss:  0.00011746601376216859
Epoch:  282  	Training Loss: 0.00010115659097209573
Test Loss:  9.747190051712096e-05
Valid Loss:  0.00011787987023126334
Epoch:  283  	Training Loss: 0.00010099742212332785
Test Loss:  9.761610999703407e-05
Valid Loss:  0.00011811212607426569
Epoch:  284  	Training Loss: 0.00010089483839692548
Test Loss:  9.764885908225551e-05
Valid Loss:  0.00011822291708085686
Epoch:  285  	Training Loss: 0.00010081019718199968
Test Loss:  9.761683759279549e-05
Valid Loss:  0.00011826062109321356
Epoch:  286  	Training Loss: 0.00010073090379592031
Test Loss:  9.754710481502116e-05
Valid Loss:  0.00011825727415271103
Epoch:  287  	Training Loss: 0.0001006546153803356
Test Loss:  9.74575086729601e-05
Valid Loss:  0.00011823166278190911
Epoch:  288  	Training Loss: 0.00010057968029286712
Test Loss:  9.735672210808843e-05
Valid Loss:  0.00011820018698927015
Epoch:  289  	Training Loss: 0.00010050550918094814
Test Loss:  9.725014388095587e-05
Valid Loss:  0.00011816258484032005
Epoch:  290  	Training Loss: 0.00010043263318948448
Test Loss:  9.714112093206495e-05
Valid Loss:  0.00011812229786301032
Epoch:  291  	Training Loss: 0.00010036052844952792
Test Loss:  9.703005343908444e-05
Valid Loss:  0.00011808056297013536
Epoch:  292  	Training Loss: 0.00010028937686001882
Test Loss:  9.681858500698581e-05
Valid Loss:  0.00011745838128263131
Epoch:  293  	Training Loss: 0.00010010955884354189
Test Loss:  9.70581459114328e-05
Valid Loss:  0.00011745202937163413
Epoch:  294  	Training Loss: 9.997195593314245e-05
Test Loss:  9.724101983010769e-05
Valid Loss:  0.00011741831258405
Epoch:  295  	Training Loss: 9.985103679355234e-05
Test Loss:  9.740393579704687e-05
Valid Loss:  0.00011739647015929222
Epoch:  296  	Training Loss: 9.974294516723603e-05
Test Loss:  9.754777420312166e-05
Valid Loss:  0.00011738078319467604
Epoch:  297  	Training Loss: 9.964451601263136e-05
Test Loss:  9.767324809217826e-05
Valid Loss:  0.00011736882152035832
Epoch:  298  	Training Loss: 9.955417772289366e-05
Test Loss:  9.778380626812577e-05
Valid Loss:  0.0001173600903712213
Epoch:  299  	Training Loss: 9.947019862011075e-05
Test Loss:  9.788067836780101e-05
Valid Loss:  0.000117352647066582
Epoch:  300  	Training Loss: 9.936239803209901e-05
Test Loss:  9.79657779680565e-05
Valid Loss:  0.00011734552390407771
Epoch:  301  	Training Loss: 9.919929289026186e-05
Test Loss:  9.80391341727227e-05
Valid Loss:  0.00011733300925698131
Epoch:  302  	Training Loss: 9.90448024822399e-05
Test Loss:  9.772571502253413e-05
Valid Loss:  0.00011636861017905176
Epoch:  303  	Training Loss: 9.871858492260799e-05
Test Loss:  9.757634688867256e-05
Valid Loss:  0.00011572407674975693
Epoch:  304  	Training Loss: 9.843036241363734e-05
Test Loss:  9.750248864293098e-05
Valid Loss:  0.00011520551925059408
Epoch:  305  	Training Loss: 9.816509555093944e-05
Test Loss:  9.747434523887932e-05
Valid Loss:  0.0001147567672887817
Epoch:  306  	Training Loss: 9.791833872441202e-05
Test Loss:  9.747709555085748e-05
Valid Loss:  0.00011435347551014274
Epoch:  307  	Training Loss: 9.768795280251652e-05
Test Loss:  9.750120807439089e-05
Valid Loss:  0.0001139832311309874
Epoch:  308  	Training Loss: 9.747191506903619e-05
Test Loss:  9.754247730597854e-05
Valid Loss:  0.00011363875091774389
Epoch:  309  	Training Loss: 9.726914868224412e-05
Test Loss:  9.7594631370157e-05
Valid Loss:  0.00011331617861287668
Epoch:  310  	Training Loss: 9.707834396976978e-05
Test Loss:  9.765554568730295e-05
Valid Loss:  0.0001130122400354594
Epoch:  311  	Training Loss: 9.689875150797889e-05
Test Loss:  9.772214980330318e-05
Valid Loss:  0.00011272412666585296
Epoch:  312  	Training Loss: 9.672917803982273e-05
Test Loss:  9.777431841939688e-05
Valid Loss:  0.00011275922588538378
Epoch:  313  	Training Loss: 9.663142554927617e-05
Test Loss:  9.781972039490938e-05
Valid Loss:  0.00011278408055659384
Epoch:  314  	Training Loss: 9.653995221015066e-05
Test Loss:  9.785959264263511e-05
Valid Loss:  0.00011280115722911432
Epoch:  315  	Training Loss: 9.645408135838807e-05
Test Loss:  9.789600153453648e-05
Valid Loss:  0.00011281242041150108
Epoch:  316  	Training Loss: 9.637276525609195e-05
Test Loss:  9.792900527827442e-05
Valid Loss:  0.00011281805927865207
Epoch:  317  	Training Loss: 9.629616397432983e-05
Test Loss:  9.795877849683166e-05
Valid Loss:  0.00011282046034466475
Epoch:  318  	Training Loss: 9.622378274798393e-05
Test Loss:  9.798718383535743e-05
Valid Loss:  0.00011282043851679191
Epoch:  319  	Training Loss: 9.61552286753431e-05
Test Loss:  9.801366832107306e-05
Valid Loss:  0.00011281706974841654
Epoch:  320  	Training Loss: 9.609045082470402e-05
Test Loss:  9.80386248556897e-05
Valid Loss:  0.00011281254410278052
Epoch:  321  	Training Loss: 9.60289835347794e-05
Test Loss:  9.806340676732361e-05
Valid Loss:  0.00011280730541329831
Epoch:  322  	Training Loss: 9.597065218258649e-05
Test Loss:  9.798772953217849e-05
Valid Loss:  0.00011274826829321682
Epoch:  323  	Training Loss: 9.5852927188389e-05
Test Loss:  9.791192860575393e-05
Valid Loss:  0.00011268706293776631
Epoch:  324  	Training Loss: 9.573799616191536e-05
Test Loss:  9.783577115740627e-05
Valid Loss:  0.00011262500629527494
Epoch:  325  	Training Loss: 9.562494233250618e-05
Test Loss:  9.775973740033805e-05
Valid Loss:  0.00011256242578383535
Epoch:  326  	Training Loss: 9.551454422762617e-05
Test Loss:  9.768416202859953e-05
Valid Loss:  0.00011249918316025287
Epoch:  327  	Training Loss: 9.54058050410822e-05
Test Loss:  9.760897955857217e-05
Valid Loss:  0.00011243621702305973
Epoch:  328  	Training Loss: 9.529918315820396e-05
Test Loss:  9.753443009685725e-05
Valid Loss:  0.00011237969738431275
Epoch:  329  	Training Loss: 9.519439481664449e-05
Test Loss:  9.746037540026009e-05
Valid Loss:  0.0001123248366639018
Epoch:  330  	Training Loss: 9.509249503025785e-05
Test Loss:  9.738704829942435e-05
Valid Loss:  0.00011227026698179543
Epoch:  331  	Training Loss: 9.499451698502526e-05
Test Loss:  9.731405589263886e-05
Valid Loss:  0.00011221610475331545
Epoch:  332  	Training Loss: 9.489819058217108e-05
Test Loss:  9.735477215144783e-05
Valid Loss:  0.00011213160178158432
Epoch:  333  	Training Loss: 9.472384408582002e-05
Test Loss:  9.73487040027976e-05
Valid Loss:  0.00011201418237760663
Epoch:  334  	Training Loss: 9.455603867536411e-05
Test Loss:  9.732560283737257e-05
Valid Loss:  0.00011189471842953935
Epoch:  335  	Training Loss: 9.43952618399635e-05
Test Loss:  9.729607700137421e-05
Valid Loss:  0.00011178103886777535
Epoch:  336  	Training Loss: 9.424101153854281e-05
Test Loss:  9.72556445049122e-05
Valid Loss:  0.00011166562762809917
Epoch:  337  	Training Loss: 9.409055928699672e-05
Test Loss:  9.720503294374794e-05
Valid Loss:  0.00011155025276821107
Epoch:  338  	Training Loss: 9.394329390488565e-05
Test Loss:  9.71464833128266e-05
Valid Loss:  0.00011143494339194149
Epoch:  339  	Training Loss: 9.379893890582025e-05
Test Loss:  9.70809196587652e-05
Valid Loss:  0.0001113191683543846
 68%|██████▊   | 341/500 [04:16<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:16<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:16<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:17<01:10,  2.18it/s] 70%|██████▉   | 349/500 [04:17<00:51,  2.91it/s] 70%|███████   | 351/500 [04:23<02:57,  1.19s/it] 71%|███████   | 353/500 [04:23<02:05,  1.17it/s] 71%|███████   | 355/500 [04:23<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:23<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:24<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:30<02:47,  1.21s/it] 73%|███████▎  | 363/500 [04:30<01:59,  1.15it/s] 73%|███████▎  | 365/500 [04:30<01:25,  1.58it/s] 73%|███████▎  | 367/500 [04:31<01:02,  2.13it/s] 74%|███████▍  | 369/500 [04:31<00:45,  2.87it/s] 74%|███████▍  | 371/500 [04:37<02:36,  1.22s/it] 75%|███████▍  | 373/500 [04:37<01:51,  1.14it/s] 75%|███████▌  | 375/500 [04:37<01:19,  1.58it/s] 75%|███████▌  | 377/500 [04:38<00:57,  2.16it/s] 76%|███████▌  | 379/500 [04:38<00:41,  2.91it/s] 76%|███████▌  | 381/500 [04:44<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:44<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:44<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:44<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:45<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:51<02:11,  1.21s/it] 79%|███████▊  | 393/500 [04:51<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:51<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:51<00:47,  2.16it/s] 80%|███████▉  | 399/500 [04:52<00:35,  2.86it/s] 80%|████████  | 401/500 [04:58<01:57,  1.19s/it] 81%|████████  | 403/500 [04:58<01:22,  1.17it/s] 81%|████████  | 405/500 [04:58<00:58,  1.61it/s]Epoch:  340  	Training Loss: 9.365714504383504e-05
Test Loss:  9.701072121970356e-05
Valid Loss:  0.0001112037425627932
Epoch:  341  	Training Loss: 9.351751941721886e-05
Test Loss:  9.694152686279267e-05
Valid Loss:  0.00011108848411822692
Epoch:  342  	Training Loss: 9.337980736745521e-05
Test Loss:  9.678683272795752e-05
Valid Loss:  0.00011092590284533799
Epoch:  343  	Training Loss: 9.331299224868417e-05
Test Loss:  9.665977995609865e-05
Valid Loss:  0.00011080526746809483
Epoch:  344  	Training Loss: 9.3247348559089e-05
Test Loss:  9.654543828219175e-05
Valid Loss:  0.00011070196342188865
Epoch:  345  	Training Loss: 9.318239608546719e-05
Test Loss:  9.643672092352062e-05
Valid Loss:  0.00011060644465032965
Epoch:  346  	Training Loss: 9.311785106547177e-05
Test Loss:  9.633153968024999e-05
Valid Loss:  0.0001105144910980016
Epoch:  347  	Training Loss: 9.305372077506036e-05
Test Loss:  9.622854122426361e-05
Valid Loss:  0.0001104243565350771
Epoch:  348  	Training Loss: 9.299004886997864e-05
Test Loss:  9.613043221179396e-05
Valid Loss:  0.0001103355607483536
Epoch:  349  	Training Loss: 9.292681352235377e-05
Test Loss:  9.603875514585525e-05
Valid Loss:  0.00011024760897271335
Epoch:  350  	Training Loss: 9.286482236348093e-05
Test Loss:  9.595340088708326e-05
Valid Loss:  0.00011016501957783476
Epoch:  351  	Training Loss: 9.28062800085172e-05
Test Loss:  9.586895612301305e-05
Valid Loss:  0.00011008216824848205
Epoch:  352  	Training Loss: 9.274762851418927e-05
Test Loss:  9.593755385139957e-05
Valid Loss:  0.0001101366724469699
Epoch:  353  	Training Loss: 9.27416404010728e-05
Test Loss:  9.59839962888509e-05
Valid Loss:  0.00011015146446879953
Epoch:  354  	Training Loss: 9.273581235902384e-05
Test Loss:  9.60269826464355e-05
Valid Loss:  0.00011016523785656318
Epoch:  355  	Training Loss: 9.273085743188858e-05
Test Loss:  9.606796083971858e-05
Valid Loss:  0.00011017806536983699
Epoch:  356  	Training Loss: 9.272584429709241e-05
Test Loss:  9.610620327293873e-05
Valid Loss:  0.0001101901798392646
Epoch:  357  	Training Loss: 9.272131137549877e-05
Test Loss:  9.61419937084429e-05
Valid Loss:  0.0001102016685763374
Epoch:  358  	Training Loss: 9.27170185605064e-05
Test Loss:  9.617587784305215e-05
Valid Loss:  0.00011021298996638507
Epoch:  359  	Training Loss: 9.27131695789285e-05
Test Loss:  9.620828495826572e-05
Valid Loss:  0.00011022340913768858
Epoch:  360  	Training Loss: 9.270924783777446e-05
Test Loss:  9.623832011129707e-05
Valid Loss:  0.00011023328988812864
Epoch:  361  	Training Loss: 9.270569717045873e-05
Test Loss:  9.626656537875533e-05
Valid Loss:  0.00011024301056750119
Epoch:  362  	Training Loss: 9.27023429539986e-05
Test Loss:  9.612696885596961e-05
Valid Loss:  0.00011010441812686622
Epoch:  363  	Training Loss: 9.264296386390924e-05
Test Loss:  9.600635530659929e-05
Valid Loss:  0.00010999733058270067
Epoch:  364  	Training Loss: 9.258447244064882e-05
Test Loss:  9.589363617124036e-05
Valid Loss:  0.00010990018199663609
Epoch:  365  	Training Loss: 9.252804738935083e-05
Test Loss:  9.579042671248317e-05
Valid Loss:  0.00010981231753248721
Epoch:  366  	Training Loss: 9.247459092875943e-05
Test Loss:  9.568980021867901e-05
Valid Loss:  0.00010972631571348757
Epoch:  367  	Training Loss: 9.242156374966726e-05
Test Loss:  9.559147292748094e-05
Valid Loss:  0.00010964128887280822
Epoch:  368  	Training Loss: 9.236922778654844e-05
Test Loss:  9.549502283334732e-05
Valid Loss:  0.00010955700417980552
Epoch:  369  	Training Loss: 9.231736476067454e-05
Test Loss:  9.540046448819339e-05
Valid Loss:  0.00010947405826300383
Epoch:  370  	Training Loss: 9.226561815012246e-05
Test Loss:  9.530787792755291e-05
Valid Loss:  0.00010939190542558208
Epoch:  371  	Training Loss: 9.221430809702724e-05
Test Loss:  9.521782340016216e-05
Valid Loss:  0.00010931087308563292
Epoch:  372  	Training Loss: 9.216388571076095e-05
Test Loss:  9.520192543277517e-05
Valid Loss:  0.00010932549776043743
Epoch:  373  	Training Loss: 9.203152148984373e-05
Test Loss:  9.516315185464919e-05
Valid Loss:  0.00010930611460935324
Epoch:  374  	Training Loss: 9.190211858367547e-05
Test Loss:  9.51091933529824e-05
Valid Loss:  0.00010926803952315822
Epoch:  375  	Training Loss: 9.177422907669097e-05
Test Loss:  9.504757326794788e-05
Valid Loss:  0.00010921875946223736
Epoch:  376  	Training Loss: 9.164772200165316e-05
Test Loss:  9.498072904534638e-05
Valid Loss:  0.00010916365135926753
Epoch:  377  	Training Loss: 9.152275742962956e-05
Test Loss:  9.491115633863956e-05
Valid Loss:  0.00010910534911090508
Epoch:  378  	Training Loss: 9.139892063103616e-05
Test Loss:  9.483948815613985e-05
Valid Loss:  0.00010904485679930076
Epoch:  379  	Training Loss: 9.127640078077093e-05
Test Loss:  9.476647392148152e-05
Valid Loss:  0.00010898323671426624
Epoch:  380  	Training Loss: 9.115503053180873e-05
Test Loss:  9.469277574680746e-05
Valid Loss:  0.00010892173304455355
Epoch:  381  	Training Loss: 9.103624324779958e-05
Test Loss:  9.462088928557932e-05
Valid Loss:  0.00010886116069741547
Epoch:  382  	Training Loss: 9.092078835237771e-05
Test Loss:  9.458970453124493e-05
Valid Loss:  0.00010879023466259241
Epoch:  383  	Training Loss: 9.089884406421334e-05
Test Loss:  9.457687701797113e-05
Valid Loss:  0.00010876347369048744
Epoch:  384  	Training Loss: 9.087826765608042e-05
Test Loss:  9.457086707698181e-05
Valid Loss:  0.00010875163570744917
Epoch:  385  	Training Loss: 9.085868805414066e-05
Test Loss:  9.456630505155772e-05
Valid Loss:  0.00010874477447941899
Epoch:  386  	Training Loss: 9.083902841666713e-05
Test Loss:  9.456262341700494e-05
Valid Loss:  0.00010873982682824135
Epoch:  387  	Training Loss: 9.082027827389538e-05
Test Loss:  9.455971303395927e-05
Valid Loss:  0.00010873502469621599
Epoch:  388  	Training Loss: 9.080154995899647e-05
Test Loss:  9.4556700787507e-05
Valid Loss:  0.000108731648651883
Epoch:  389  	Training Loss: 9.078363655135036e-05
Test Loss:  9.455381950829178e-05
Valid Loss:  0.00010872757411561906
Epoch:  390  	Training Loss: 9.076598507817835e-05
Test Loss:  9.45511128520593e-05
Valid Loss:  0.00010872427810681984
Epoch:  391  	Training Loss: 9.074861009139568e-05
Test Loss:  9.454840619582683e-05
Valid Loss:  0.0001087205673684366
Epoch:  392  	Training Loss: 9.073191904462874e-05
Test Loss:  9.439156565349549e-05
Valid Loss:  0.00010858308814931661
Epoch:  393  	Training Loss: 9.059622971108183e-05
Test Loss:  9.425007738173008e-05
Valid Loss:  0.00010846984514500946
Epoch:  394  	Training Loss: 9.046271588886157e-05
Test Loss:  9.411570499651134e-05
Valid Loss:  0.0001083664974430576
Epoch:  395  	Training Loss: 9.033134847413749e-05
Test Loss:  9.399348346050829e-05
Valid Loss:  0.00010827037476701662
Epoch:  396  	Training Loss: 9.020202560350299e-05
Test Loss:  9.387618047185242e-05
Valid Loss:  0.00010817967995535582
Epoch:  397  	Training Loss: 9.007676999317482e-05
Test Loss:  9.376170055475086e-05
Valid Loss:  0.00010809178638737649
Epoch:  398  	Training Loss: 8.995299140224233e-05
Test Loss:  9.365017467644066e-05
Valid Loss:  0.00010800748714245856
Epoch:  399  	Training Loss: 8.98302678251639e-05
Test Loss:  9.354184294352308e-05
Valid Loss:  0.00010792608372867107
Epoch:  400  	Training Loss: 8.970872295321897e-05
Test Loss:  9.343487181467935e-05
Valid Loss:  0.00010784715414047241
Epoch:  401  	Training Loss: 8.958826947491616e-05
Test Loss:  9.333037451142445e-05
Valid Loss:  0.00010777062561828643
Epoch:  402  	Training Loss: 8.946907473728061e-05
Test Loss:  9.33153205551207e-05
Valid Loss:  0.00010773605026770383
Epoch:  403  	Training Loss: 8.946067828219384e-05
Test Loss:  9.331990440841764e-05
Valid Loss:  0.00010774719703476876
Epoch:  404  	Training Loss: 8.945245645008981e-05
Test Loss:  9.331973706139252e-05
Valid Loss:  0.00010774793918244541
Epoch:  405  	Training Loss: 8.944421279011294e-05
Test Loss:  9.332103218184784e-05
Valid Loss:  0.000107750907773152
Epoch:  406  	Training Loss: 8.943617285694927e-05
Test Loss:  9.332161425845698e-05
Valid Loss:  0.00010775358532555401
Epoch:  407  	Training Loss: 8.94280819920823e-05
Test Loss:  9.332302579423413e-05
Valid Loss:   81%|████████▏ | 407/500 [04:58<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:59<00:30,  2.96it/s] 82%|████████▏ | 411/500 [05:05<01:47,  1.21s/it] 83%|████████▎ | 413/500 [05:05<01:16,  1.14it/s] 83%|████████▎ | 415/500 [05:05<00:53,  1.58it/s] 83%|████████▎ | 417/500 [05:05<00:38,  2.16it/s] 84%|████████▍ | 419/500 [05:06<00:27,  2.91it/s] 84%|████████▍ | 421/500 [05:12<01:35,  1.21s/it] 85%|████████▍ | 423/500 [05:12<01:06,  1.15it/s] 85%|████████▌ | 425/500 [05:12<00:47,  1.59it/s] 85%|████████▌ | 427/500 [05:12<00:33,  2.17it/s] 86%|████████▌ | 429/500 [05:13<00:24,  2.92it/s] 86%|████████▌ | 431/500 [05:19<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:19<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:19<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:19<00:28,  2.18it/s] 88%|████████▊ | 439/500 [05:20<00:20,  2.93it/s] 88%|████████▊ | 441/500 [05:26<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:26<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:26<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:26<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:26<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:33<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:33<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:33<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:33<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:33<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:40<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:40<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:40<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:40<00:14,  2.20it/s] 94%|█████████▍| 469/500 [05:40<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:46<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:47<00:22,  1.18it/s]0.0001077558845281601
Epoch:  408  	Training Loss: 8.942005661083385e-05
Test Loss:  9.332364425063133e-05
Valid Loss:  0.000107758300146088
Epoch:  409  	Training Loss: 8.941214764490724e-05
Test Loss:  9.332459740107879e-05
Valid Loss:  0.0001077604538295418
Epoch:  410  	Training Loss: 8.940449333749712e-05
Test Loss:  9.33255287236534e-05
Valid Loss:  0.00010776310227811337
Epoch:  411  	Training Loss: 8.939628605730832e-05
Test Loss:  9.332632907899097e-05
Valid Loss:  0.0001077658380381763
Epoch:  412  	Training Loss: 8.938845712691545e-05
Test Loss:  9.342763223685324e-05
Valid Loss:  0.00010785418271552771
Epoch:  413  	Training Loss: 8.936475205700845e-05
Test Loss:  9.347323793917894e-05
Valid Loss:  0.00010785428457893431
Epoch:  414  	Training Loss: 8.934234210755676e-05
Test Loss:  9.35212810873054e-05
Valid Loss:  0.00010786607163026929
Epoch:  415  	Training Loss: 8.93212272785604e-05
Test Loss:  9.35644784476608e-05
Valid Loss:  0.00010787576320581138
Epoch:  416  	Training Loss: 8.930082549341023e-05
Test Loss:  9.360416152048856e-05
Valid Loss:  0.00010788441431941465
Epoch:  417  	Training Loss: 8.928155875764787e-05
Test Loss:  9.3639682745561e-05
Valid Loss:  0.0001078923451132141
Epoch:  418  	Training Loss: 8.926267037168145e-05
Test Loss:  9.367259917780757e-05
Valid Loss:  0.0001078995264833793
Epoch:  419  	Training Loss: 8.924472786020488e-05
Test Loss:  9.370229963678867e-05
Valid Loss:  0.00010790565283969045
Epoch:  420  	Training Loss: 8.922733832150698e-05
Test Loss:  9.372956992592663e-05
Valid Loss:  0.00010791131353471428
Epoch:  421  	Training Loss: 8.92107273102738e-05
Test Loss:  9.375459922011942e-05
Valid Loss:  0.00010791653039632365
Epoch:  422  	Training Loss: 8.919471292756498e-05
Test Loss:  9.341654367744923e-05
Valid Loss:  0.00010720499267335981
Epoch:  423  	Training Loss: 8.908654126571491e-05
Test Loss:  9.314370981883258e-05
Valid Loss:  0.00010662389104254544
Epoch:  424  	Training Loss: 8.900378452381119e-05
Test Loss:  9.29213420022279e-05
Valid Loss:  0.00010614644270390272
Epoch:  425  	Training Loss: 8.893989434000105e-05
Test Loss:  9.273823525290936e-05
Valid Loss:  0.00010574935731710866
Epoch:  426  	Training Loss: 8.888947195373476e-05
Test Loss:  9.258689533453435e-05
Valid Loss:  0.00010541769734118134
Epoch:  427  	Training Loss: 8.884986891644076e-05
Test Loss:  9.246051195077598e-05
Valid Loss:  0.00010513843153603375
Epoch:  428  	Training Loss: 8.881775283953175e-05
Test Loss:  9.235453035216779e-05
Valid Loss:  0.00010490151180420071
Epoch:  429  	Training Loss: 8.879213419277221e-05
Test Loss:  9.226468682754785e-05
Valid Loss:  0.00010469993867445737
Epoch:  430  	Training Loss: 8.877117943484336e-05
Test Loss:  9.218859486281872e-05
Valid Loss:  0.00010452696005813777
Epoch:  431  	Training Loss: 8.875425555743277e-05
Test Loss:  9.212303848471493e-05
Valid Loss:  0.0001043779484461993
Epoch:  432  	Training Loss: 8.874027116689831e-05
Test Loss:  9.213435259880498e-05
Valid Loss:  0.0001045286117005162
Epoch:  433  	Training Loss: 8.864172559697181e-05
Test Loss:  9.200768545269966e-05
Valid Loss:  0.00010441386257298291
Epoch:  434  	Training Loss: 8.855338819557801e-05
Test Loss:  9.189554839394987e-05
Valid Loss:  0.00010432379349367693
Epoch:  435  	Training Loss: 8.846775745041668e-05
Test Loss:  9.178473555948585e-05
Valid Loss:  0.00010423325875308365
Epoch:  436  	Training Loss: 8.83830725797452e-05
Test Loss:  9.167478128802031e-05
Valid Loss:  0.00010414341522846371
Epoch:  437  	Training Loss: 8.829869329929352e-05
Test Loss:  9.156625310424715e-05
Valid Loss:  0.00010405417560832575
Epoch:  438  	Training Loss: 8.82152744452469e-05
Test Loss:  9.145864169113338e-05
Valid Loss:  0.00010396567813586444
Epoch:  439  	Training Loss: 8.813243039185181e-05
Test Loss:  9.135488653555512e-05
Valid Loss:  0.0001038775299093686
Epoch:  440  	Training Loss: 8.80500883795321e-05
Test Loss:  9.125541691901162e-05
Valid Loss:  0.00010379026207374409
Epoch:  441  	Training Loss: 8.796848123893142e-05
Test Loss:  9.115686407312751e-05
Valid Loss:  0.00010370348900323734
Epoch:  442  	Training Loss: 8.78873688634485e-05
Test Loss:  9.129777026828378e-05
Valid Loss:  0.00010378958540968597
Epoch:  443  	Training Loss: 8.785321551840752e-05
Test Loss:  9.140486508840695e-05
Valid Loss:  0.00010383297922089696
Epoch:  444  	Training Loss: 8.782374789007008e-05
Test Loss:  9.149328252533451e-05
Valid Loss:  0.00010385473433416337
Epoch:  445  	Training Loss: 8.779660856816918e-05
Test Loss:  9.157062595477328e-05
Valid Loss:  0.00010386637586634606
Epoch:  446  	Training Loss: 8.777142647886649e-05
Test Loss:  9.164067159872502e-05
Valid Loss:  0.00010387209476903081
Epoch:  447  	Training Loss: 8.774804882705212e-05
Test Loss:  9.170628618448973e-05
Valid Loss:  0.00010387611109763384
Epoch:  448  	Training Loss: 8.772608998697251e-05
Test Loss:  9.176797902910039e-05
Valid Loss:  0.00010387950896983966
Epoch:  449  	Training Loss: 8.77056154422462e-05
Test Loss:  9.182670328300446e-05
Valid Loss:  0.00010388226655777544
Epoch:  450  	Training Loss: 8.768655243329704e-05
Test Loss:  9.188242256641388e-05
Valid Loss:  0.0001038851187331602
Epoch:  451  	Training Loss: 8.766823157202452e-05
Test Loss:  9.193576988764107e-05
Valid Loss:  0.00010388795635662973
Epoch:  452  	Training Loss: 8.765103848418221e-05
Test Loss:  9.187772957375273e-05
Valid Loss:  0.0001038116606650874
Epoch:  453  	Training Loss: 8.762402285356075e-05
Test Loss:  9.183387737721205e-05
Valid Loss:  0.00010375836427556351
Epoch:  454  	Training Loss: 8.759790216572583e-05
Test Loss:  9.179914195556194e-05
Valid Loss:  0.0001037182955769822
Epoch:  455  	Training Loss: 8.757168689044192e-05
Test Loss:  9.176887397188693e-05
Valid Loss:  0.00010368580842623487
Epoch:  456  	Training Loss: 8.754604641580954e-05
Test Loss:  9.174206934403628e-05
Valid Loss:  0.00010365696653025225
Epoch:  457  	Training Loss: 8.752040594117716e-05
Test Loss:  9.171818965114653e-05
Valid Loss:  0.00010363106412114576
Epoch:  458  	Training Loss: 8.74945180839859e-05
Test Loss:  9.169543045572937e-05
Valid Loss:  0.00010360588203184307
Epoch:  459  	Training Loss: 8.746901585254818e-05
Test Loss:  9.167307143798098e-05
Valid Loss:  0.00010358197323512286
Epoch:  460  	Training Loss: 8.744320075493306e-05
Test Loss:  9.165140363620594e-05
Valid Loss:  0.00010355874110246077
Epoch:  461  	Training Loss: 8.74175748322159e-05
Test Loss:  9.162985224975273e-05
Valid Loss:  0.00010353504330851138
Epoch:  462  	Training Loss: 8.739204349694774e-05
Test Loss:  9.180505003314465e-05
Valid Loss:  0.00010365609341533855
Epoch:  463  	Training Loss: 8.732041897019371e-05
Test Loss:  9.181365021504462e-05
Valid Loss:  0.00010354990808991715
Epoch:  464  	Training Loss: 8.725492807570845e-05
Test Loss:  9.19054145924747e-05
Valid Loss:  0.00010359198495279998
Epoch:  465  	Training Loss: 8.719481411390007e-05
Test Loss:  9.192128345603123e-05
Valid Loss:  0.00010353662946727127
Epoch:  466  	Training Loss: 8.713762508705258e-05
Test Loss:  9.196613973472267e-05
Valid Loss:  0.00010354224650654942
Epoch:  467  	Training Loss: 8.708222594577819e-05
Test Loss:  9.197409235639498e-05
Valid Loss:  0.00010350515367463231
Epoch:  468  	Training Loss: 8.702863124199212e-05
Test Loss:  9.198984480462968e-05
Valid Loss:  0.00010349297372158617
Epoch:  469  	Training Loss: 8.697617158759385e-05
Test Loss:  9.198722545988858e-05
Valid Loss:  0.00010346307681174949
Epoch:  470  	Training Loss: 8.692487608641386e-05
Test Loss:  9.198530460707843e-05
Valid Loss:  0.00010344212932977825
Epoch:  471  	Training Loss: 8.68745701154694e-05
Test Loss:  9.197299368679523e-05
Valid Loss:  0.00010341315646655858
Epoch:  472  	Training Loss: 8.682485349709168e-05
Test Loss:  9.165498340735212e-05
Valid Loss:  0.00010281943832524121
Epoch:  473  	Training Loss: 8.672910917084664e-05
Test Loss:  9.142555063590407e-05
Valid Loss:  0.00010238165850751102
Epoch:  474  	Training Loss: 8.665207133162767e-05
Test Loss:  9.12478135433048e-05
Valid Loss:  0.00010203500278294086
Epoch:  475  	Training Loss: 8.65869369590655e-05
Test Loss:  9.110297833103687e-05
 95%|█████████▌| 475/500 [05:47<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:47<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:47<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:53<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:54<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:54<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:54<00:05,  2.20it/s] 98%|█████████▊| 489/500 [05:54<00:03,  2.92it/s] 98%|█████████▊| 491/500 [06:00<00:10,  1.21s/it] 99%|█████████▊| 493/500 [06:01<00:06,  1.15it/s] 99%|█████████▉| 495/500 [06:01<00:03,  1.57it/s] 99%|█████████▉| 497/500 [06:01<00:01,  2.12it/s]100%|█████████▉| 499/500 [06:01<00:00,  2.83it/s]100%|██████████| 500/500 [06:01<00:00,  1.38it/s]
Valid Loss:  0.00010174709314014763
Epoch:  476  	Training Loss: 8.653000986669213e-05
Test Loss:  9.09817244973965e-05
Valid Loss:  0.00010149983427254483
Epoch:  477  	Training Loss: 8.647949289297685e-05
Test Loss:  9.087802027352154e-05
Valid Loss:  0.00010128450230695307
Epoch:  478  	Training Loss: 8.64341709529981e-05
Test Loss:  9.078749280888587e-05
Valid Loss:  0.00010109372669830918
Epoch:  479  	Training Loss: 8.63925160956569e-05
Test Loss:  9.070867236005142e-05
Valid Loss:  0.00010092263983096927
Epoch:  480  	Training Loss: 8.635358972242102e-05
Test Loss:  9.063882316695526e-05
Valid Loss:  0.00010076917533297092
Epoch:  481  	Training Loss: 8.631753735244274e-05
Test Loss:  9.057729766936973e-05
Valid Loss:  0.00010062948422273621
Epoch:  482  	Training Loss: 8.628321666037664e-05
Test Loss:  9.068317012861371e-05
Valid Loss:  0.0001008509862003848
Epoch:  483  	Training Loss: 8.62257438711822e-05
Test Loss:  9.07676003407687e-05
Valid Loss:  0.0001010276100714691
Epoch:  484  	Training Loss: 8.618900028523058e-05
Test Loss:  9.083308395929635e-05
Valid Loss:  0.00010116644261870533
Epoch:  485  	Training Loss: 8.616462582722306e-05
Test Loss:  9.088274964597076e-05
Valid Loss:  0.00010127421410288662
Epoch:  486  	Training Loss: 8.61475127749145e-05
Test Loss:  9.092097752727568e-05
Valid Loss:  0.00010135878983419389
Epoch:  487  	Training Loss: 8.613503450760618e-05
Test Loss:  9.094974666368216e-05
Valid Loss:  0.00010142403334612027
Epoch:  488  	Training Loss: 8.612594683654606e-05
Test Loss:  9.097197471419349e-05
Valid Loss:  0.00010147505963686854
Epoch:  489  	Training Loss: 8.611884550191462e-05
Test Loss:  9.098940063267946e-05
Valid Loss:  0.00010151601600227877
Epoch:  490  	Training Loss: 8.611367229605094e-05
Test Loss:  9.100324678001925e-05
Valid Loss:  0.00010154872870771214
Epoch:  491  	Training Loss: 8.610945951659232e-05
Test Loss:  9.101453179027885e-05
Valid Loss:  0.0001015753805404529
Epoch:  492  	Training Loss: 8.610635268269107e-05
Test Loss:  9.089341619983315e-05
Valid Loss:  0.00010149151785299182
Epoch:  493  	Training Loss: 8.603907190263271e-05
Test Loss:  9.077844151761383e-05
Valid Loss:  0.0001014136360026896
Epoch:  494  	Training Loss: 8.597320265835151e-05
Test Loss:  9.067075734492391e-05
Valid Loss:  0.00010134236072190106
Epoch:  495  	Training Loss: 8.59093270264566e-05
Test Loss:  9.056804265128449e-05
Valid Loss:  0.00010127460700459778
Epoch:  496  	Training Loss: 8.584621537011117e-05
Test Loss:  9.046860941452906e-05
Valid Loss:  0.00010121062950929627
Epoch:  497  	Training Loss: 8.578394044889137e-05
Test Loss:  9.037271956913173e-05
Valid Loss:  0.00010114941687788814
Epoch:  498  	Training Loss: 8.572261140216142e-05
Test Loss:  9.028025669977069e-05
Valid Loss:  0.00010108984133694321
Epoch:  499  	Training Loss: 8.566184260416776e-05
Test Loss:  9.018978744279593e-05
Valid Loss:  0.00010103281238116324
Epoch:  500  	Training Loss: 8.560208516428247e-05
Test Loss:  9.010253415908664e-05
Valid Loss:  0.00010097711492562667
seed is  5
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.09it/s]  1%|          | 4/500 [00:00<00:31, 15.70it/s]  1%|          | 6/500 [00:00<00:35, 13.88it/s]  2%|▏         | 8/500 [00:00<00:37, 13.26it/s]  2%|▏         | 10/500 [00:00<00:37, 13.14it/s]  2%|▏         | 12/500 [00:00<00:37, 13.12it/s]  3%|▎         | 14/500 [00:01<00:37, 12.88it/s]  3%|▎         | 16/500 [00:01<00:38, 12.72it/s]  4%|▎         | 18/500 [00:01<00:38, 12.62it/s]  4%|▍         | 20/500 [00:01<00:38, 12.55it/s]  4%|▍         | 22/500 [00:01<00:36, 13.11it/s]  5%|▍         | 24/500 [00:01<00:34, 13.99it/s]  5%|▌         | 26/500 [00:01<00:32, 14.64it/s]  6%|▌         | 28/500 [00:02<00:31, 15.10it/s]  6%|▌         | 30/500 [00:02<00:30, 15.46it/s]  6%|▋         | 32/500 [00:02<00:29, 15.71it/s]  7%|▋         | 34/500 [00:02<00:29, 15.81it/s]  7%|▋         | 36/500 [00:02<00:29, 15.97it/s]  8%|▊         | 38/500 [00:02<00:28, 16.13it/s]  8%|▊         | 40/500 [00:02<00:28, 16.22it/s]  8%|▊         | 42/500 [00:02<00:28, 16.27it/s]  9%|▉         | 44/500 [00:03<00:28, 15.99it/s]  9%|▉         | 46/500 [00:03<00:28, 15.96it/s] 10%|▉         | 48/500 [00:03<00:28, 15.79it/s] 10%|█         | 50/500 [00:03<00:28, 15.94it/s] 10%|█         | 52/500 [00:03<00:27, 16.10it/s] 11%|█         | 54/500 [00:03<00:27, 16.19it/s] 11%|█         | 56/500 [00:03<00:27, 16.25it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.30it/s] 12%|█▏        | 60/500 [00:04<00:27, 16.26it/s] 12%|█▏        | 62/500 [00:04<00:26, 16.23it/s] 13%|█▎        | 64/500 [00:04<00:27, 16.13it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.21it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.18it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.28it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.34it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.35it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.37it/s] 16%|█▌        | 78/500 [00:05<00:25, 16.39it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.40it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.45it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.49it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.50it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.99it/s] 18%|█▊        | 90/500 [00:05<00:27, 14.71it/s] 18%|█▊        | 92/500 [00:06<00:29, 13.95it/s] 19%|█▉        | 94/500 [00:06<00:30, 13.47it/s] 19%|█▉        | 96/500 [00:06<00:30, 13.13it/s] 20%|█▉        | 98/500 [00:06<00:31, 12.91it/s] 20%|██        | 100/500 [00:06<00:31, 12.74it/s] 20%|██        | 102/500 [00:06<00:31, 12.65it/s] 21%|██        | 104/500 [00:07<00:31, 12.57it/s] 21%|██        | 106/500 [00:07<00:31, 12.55it/s] 22%|██▏       | 108/500 [00:07<00:31, 12.50it/s] 22%|██▏       | 110/500 [00:07<00:31, 12.48it/s] 22%|██▏       | 112/500 [00:07<00:31, 12.46it/s] 23%|██▎       | 114/500 [00:07<00:30, 12.50it/s] 23%|██▎       | 116/500 [00:07<00:29, 13.12it/s] 24%|██▎       | 118/500 [00:08<00:27, 13.89it/s] 24%|██▍       | 120/500 [00:08<00:26, 14.60it/s] 24%|██▍       | 122/500 [00:08<00:25, 15.09it/s] 25%|██▍       | 124/500 [00:08<00:24, 15.24it/s]Epoch:  1  	Training Loss: 0.18019041419029236
Test Loss:  4218.0888671875
Valid Loss:  4214.4482421875
Epoch:  2  	Training Loss: 4200.0126953125
Test Loss:  1.3269174759456768e+16
Valid Loss:  1.2999644086796288e+16
Epoch:  3  	Training Loss: 1.3172141784563712e+16
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:24, 15.33it/s] 26%|██▌       | 128/500 [00:08<00:26, 14.26it/s] 26%|██▌       | 130/500 [00:08<00:27, 13.64it/s] 26%|██▋       | 132/500 [00:09<00:27, 13.28it/s] 27%|██▋       | 134/500 [00:09<00:28, 13.01it/s] 27%|██▋       | 136/500 [00:09<00:28, 12.82it/s] 28%|██▊       | 138/500 [00:09<00:28, 12.72it/s] 28%|██▊       | 140/500 [00:09<00:28, 12.65it/s] 28%|██▊       | 142/500 [00:09<00:27, 13.13it/s] 29%|██▉       | 144/500 [00:09<00:25, 13.88it/s] 29%|██▉       | 146/500 [00:10<00:24, 14.52it/s] 30%|██▉       | 148/500 [00:10<00:23, 15.02it/s] 30%|███       | 150/500 [00:10<00:22, 15.25it/s] 30%|███       | 152/500 [00:10<00:22, 15.54it/s] 31%|███       | 154/500 [00:10<00:21, 15.81it/s] 31%|███       | 156/500 [00:10<00:21, 15.98it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.06it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.17it/s] 32%|███▏      | 162/500 [00:11<00:20, 16.23it/s] 33%|███▎      | 164/500 [00:11<00:20, 16.25it/s] 33%|███▎      | 166/500 [00:11<00:20, 16.29it/s] 34%|███▎      | 168/500 [00:11<00:20, 16.30it/s] 34%|███▍      | 170/500 [00:11<00:20, 16.31it/s] 34%|███▍      | 172/500 [00:11<00:20, 16.35it/s] 35%|███▍      | 174/500 [00:11<00:19, 16.36it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.39it/s] 36%|███▌      | 178/500 [00:12<00:19, 16.41it/s] 36%|███▌      | 180/500 [00:12<00:19, 16.38it/s] 36%|███▋      | 182/500 [00:12<00:19, 16.39it/s] 37%|███▋      | 184/500 [00:12<00:19, 16.24it/s] 37%|███▋      | 186/500 [00:12<00:19, 16.17it/s] 38%|███▊      | 188/500 [00:12<00:19, 16.04it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.13it/s] 38%|███▊      | 192/500 [00:12<00:18, 16.24it/s] 39%|███▉      | 194/500 [00:13<00:18, 16.27it/s] 39%|███▉      | 196/500 [00:13<00:18, 16.33it/s] 40%|███▉      | 198/500 [00:13<00:18, 16.35it/s] 40%|████      | 200/500 [00:13<00:18, 16.34it/s] 40%|████      | 202/500 [00:13<00:18, 16.35it/s] 41%|████      | 204/500 [00:13<00:18, 16.39it/s] 41%|████      | 206/500 [00:13<00:17, 16.45it/s] 42%|████▏     | 208/500 [00:13<00:17, 16.42it/s] 42%|████▏     | 210/500 [00:14<00:17, 16.40it/s] 42%|████▏     | 212/500 [00:14<00:17, 16.40it/s] 43%|████▎     | 214/500 [00:14<00:17, 16.16it/s] 43%|████▎     | 216/500 [00:14<00:17, 16.11it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.15it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.30it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.12it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.04it/s] 45%|████▌     | 226/500 [00:15<00:17, 15.87it/s] 46%|████▌     | 228/500 [00:15<00:16, 16.01it/s] 46%|████▌     | 230/500 [00:15<00:16, 16.17it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.25it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.32it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.39it/s] 48%|████▊     | 238/500 [00:15<00:15, 16.42it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.47it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.49it/s] 49%|████▉     | 244/500 [00:16<00:15, 16.47it/s] 49%|████▉     | 246/500 [00:16<00:15, 16.37it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.39it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.17it/s] 50%|█████     | 252/500 [00:16<00:15, 16.30it/s] 51%|█████     | 254/500 [00:16<00:15, 16.12it/s] 51%|█████     | 256/500 [00:16<00:15, 16.22it/s] 52%|█████▏    | 258/500 [00:16<00:15, 16.11it/s] 52%|█████▏    | 260/500 [00:17<00:14, 16.08it/s] 52%|█████▏    | 262/500 [00:17<00:15, 15.82it/s] 53%|█████▎    | 264/500 [00:17<00:15, 15.58it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.69it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.62it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.85it/s] 54%|█████▍    | 272/500 [00:17<00:14, 15.66it/s] 55%|█████▍    | 274/500 [00:18<00:15, 14.55it/s] 55%|█████▌    | 276/500 [00:18<00:16, 13.87it/s] 56%|█████▌    | 278/500 [00:18<00:16, 13.40it/s] 56%|█████▌    | 280/500 [00:18<00:16, 13.48it/s] 56%|█████▋    | 282/500 [00:18<00:15, 14.16it/s] 57%|█████▋    | 284/500 [00:18<00:14, 14.77it/s] 57%|█████▋    | 286/500 [00:18<00:15, 13.74it/s] 58%|█████▊    | 288/500 [00:19<00:15, 13.33it/s] 58%|█████▊    | 290/500 [00:19<00:15, 13.76it/s] 58%|█████▊    | 292/500 [00:19<00:14, 14.43it/s] 59%|█████▉    | 294/500 [00:19<00:13, 14.93it/s] 59%|█████▉    | 296/500 [00:19<00:13, 15.35it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.67it/s] 60%|██████    | 300/500 [00:19<00:12, 15.81it/s] 60%|██████    | 302/500 [00:19<00:12, 15.53it/s] 61%|██████    | 304/500 [00:20<00:12, 15.81it/s] 61%|██████    | 306/500 [00:20<00:12, 16.01it/s] 62%|██████▏   | 308/500 [00:20<00:11, 16.11it/s] 62%|██████▏   | 310/500 [00:20<00:11, 16.21it/s] 62%|██████▏   | 312/500 [00:20<00:11, 16.23it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.34it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.33it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.34it/s] 64%|██████▍   | 320/500 [00:21<00:11, 16.33it/s] 64%|██████▍   | 322/500 [00:21<00:10, 16.30it/s] 65%|██████▍   | 324/500 [00:21<00:10, 16.33it/s] 65%|██████▌   | 326/500 [00:21<00:10, 16.16it/s] 66%|██████▌   | 328/500 [00:21<00:10, 16.18it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.21it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.04it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.17it/s] 67%|██████▋   | 336/500 [00:22<00:10, 16.25it/s] 68%|██████▊   | 338/500 [00:22<00:09, 16.28it/s] 68%|██████▊   | 340/500 [00:22<00:09, 16.15it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.26it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.13it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.21it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.20it/s] 70%|███████   | 350/500 [00:22<00:09, 16.22it/s] 70%|███████   | 352/500 [00:23<00:09, 15.92it/s] 71%|███████   | 354/500 [00:23<00:09, 16.05it/s] 71%|███████   | 356/500 [00:23<00:09, 15.96it/s] 72%|███████▏  | 358/500 [00:23<00:08, 16.11it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.13it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.15it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.21it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.25it/s] 74%|███████▎  | 368/500 [00:24<00:08, 16.29it/s] 74%|███████▍  | 370/500 [00:24<00:07, 16.36it/s] 74%|███████▍  | 372/500 [00:24<00:07, 16.25it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:08, 15.19it/s] 75%|███████▌  | 376/500 [00:24<00:08, 14.18it/s] 76%|███████▌  | 378/500 [00:24<00:09, 13.44it/s] 76%|███████▌  | 380/500 [00:24<00:09, 13.06it/s] 76%|███████▋  | 382/500 [00:25<00:09, 12.88it/s] 77%|███████▋  | 384/500 [00:25<00:09, 12.74it/s] 77%|███████▋  | 386/500 [00:25<00:08, 12.85it/s] 78%|███████▊  | 388/500 [00:25<00:08, 12.70it/s] 78%|███████▊  | 390/500 [00:25<00:08, 12.66it/s] 78%|███████▊  | 392/500 [00:25<00:08, 13.46it/s] 79%|███████▉  | 394/500 [00:25<00:07, 14.03it/s] 79%|███████▉  | 396/500 [00:26<00:07, 14.72it/s] 80%|███████▉  | 398/500 [00:26<00:06, 15.21it/s] 80%|████████  | 400/500 [00:26<00:06, 15.50it/s] 80%|████████  | 402/500 [00:26<00:06, 15.78it/s] 81%|████████  | 404/500 [00:26<00:05, 16.00it/s] 81%|████████  | 406/500 [00:26<00:05, 16.17it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.14it/s] 82%|████████▏ | 410/500 [00:26<00:06, 14.71it/s] 82%|████████▏ | 412/500 [00:27<00:06, 13.97it/s] 83%|████████▎ | 414/500 [00:27<00:06, 13.47it/s] 83%|████████▎ | 416/500 [00:27<00:06, 13.11it/s] 84%|████████▎ | 418/500 [00:27<00:06, 12.84it/s] 84%|████████▍ | 420/500 [00:27<00:06, 12.70it/s] 84%|████████▍ | 422/500 [00:27<00:06, 12.61it/s] 85%|████████▍ | 424/500 [00:28<00:06, 12.55it/s] 85%|████████▌ | 426/500 [00:28<00:05, 12.52it/s] 86%|████████▌ | 428/500 [00:28<00:05, 12.50it/s] 86%|████████▌ | 430/500 [00:28<00:05, 12.46it/s] 86%|████████▋ | 432/500 [00:28<00:05, 12.44it/s] 87%|████████▋ | 434/500 [00:28<00:05, 12.42it/s] 87%|████████▋ | 436/500 [00:29<00:05, 12.39it/s] 88%|████████▊ | 438/500 [00:29<00:04, 12.40it/s] 88%|████████▊ | 440/500 [00:29<00:04, 12.41it/s] 88%|████████▊ | 442/500 [00:29<00:04, 12.41it/s] 89%|████████▉ | 444/500 [00:29<00:04, 12.42it/s] 89%|████████▉ | 446/500 [00:29<00:04, 12.42it/s] 90%|████████▉ | 448/500 [00:30<00:04, 12.41it/s] 90%|█████████ | 450/500 [00:30<00:03, 12.52it/s] 90%|█████████ | 452/500 [00:30<00:03, 13.28it/s] 91%|█████████ | 454/500 [00:30<00:03, 13.95it/s] 91%|█████████ | 456/500 [00:30<00:03, 14.62it/s] 92%|█████████▏| 458/500 [00:30<00:02, 15.09it/s] 92%|█████████▏| 460/500 [00:30<00:02, 14.39it/s] 92%|█████████▏| 462/500 [00:31<00:02, 13.71it/s] 93%|█████████▎| 464/500 [00:31<00:02, 13.68it/s] 93%|█████████▎| 466/500 [00:31<00:02, 13.25it/s] 94%|█████████▎| 468/500 [00:31<00:02, 12.99it/s] 94%|█████████▍| 470/500 [00:31<00:02, 12.78it/s] 94%|█████████▍| 472/500 [00:31<00:02, 12.68it/s] 95%|█████████▍| 474/500 [00:31<00:02, 12.57it/s] 95%|█████████▌| 476/500 [00:32<00:01, 12.58it/s] 96%|█████████▌| 478/500 [00:32<00:01, 13.51it/s] 96%|█████████▌| 480/500 [00:32<00:01, 14.25it/s] 96%|█████████▋| 482/500 [00:32<00:01, 14.81it/s] 97%|█████████▋| 484/500 [00:32<00:01, 15.25it/s] 97%|█████████▋| 486/500 [00:32<00:00, 15.63it/s] 98%|█████████▊| 488/500 [00:32<00:00, 15.86it/s] 98%|█████████▊| 490/500 [00:32<00:00, 16.10it/s] 98%|█████████▊| 492/500 [00:33<00:00, 16.29it/s] 99%|█████████▉| 494/500 [00:33<00:00, 16.37it/s] 99%|█████████▉| 496/500 [00:33<00:00, 16.15it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 15.95it/s]100%|██████████| 500/500 [00:33<00:00, 16.13it/s]100%|██████████| 500/500 [00:33<00:00, 14.88it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  5
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:10,  6.39s/it]  1%|          | 3/500 [00:06<14:10,  1.71s/it]  1%|          | 5/500 [00:06<07:12,  1.14it/s]  1%|▏         | 7/500 [00:06<04:26,  1.85it/s]  2%|▏         | 9/500 [00:07<03:01,  2.70it/s]  2%|▏         | 11/500 [00:13<11:03,  1.36s/it]  3%|▎         | 13/500 [00:13<07:33,  1.07it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:29,  1.19s/it]  5%|▍         | 23/500 [00:20<06:44,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.64it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:27<09:13,  1.18s/it]  7%|▋         | 33/500 [00:27<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:34<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:43,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.19it/s] 10%|▉         | 49/500 [00:34<02:35,  2.90it/s] 10%|█         | 51/500 [00:41<09:06,  1.22s/it] 11%|█         | 53/500 [00:41<06:30,  1.15it/s] 11%|█         | 55/500 [00:41<04:40,  1.58it/s] 11%|█▏        | 57/500 [00:41<03:24,  2.16it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.90it/s] 12%|█▏        | 61/500 [00:47<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:48<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:48<03:20,  2.16it/s] 14%|█▍        | 69/500 [00:48<02:30,  2.86it/s]Epoch:  1  	Training Loss: 0.18019041419029236
Test Loss:  0.014492902904748917
Valid Loss:  0.020685385912656784
Epoch:  2  	Training Loss: 0.023421011865139008
Test Loss:  0.01442948542535305
Valid Loss:  0.018375495448708534
Epoch:  3  	Training Loss: 0.018843187019228935
Test Loss:  0.011433370411396027
Valid Loss:  0.014435794204473495
Epoch:  4  	Training Loss: 0.015601913444697857
Test Loss:  0.009587646462023258
Valid Loss:  0.011684272438287735
Epoch:  5  	Training Loss: 0.012959832325577736
Test Loss:  0.007885046303272247
Valid Loss:  0.009384537115693092
Epoch:  6  	Training Loss: 0.01086297444999218
Test Loss:  0.006687916815280914
Valid Loss:  0.007668491452932358
Epoch:  7  	Training Loss: 0.009177763015031815
Test Loss:  0.005628351122140884
Valid Loss:  0.006269557401537895
Epoch:  8  	Training Loss: 0.007822997868061066
Test Loss:  0.004875478334724903
Valid Loss:  0.005221214145421982
Epoch:  9  	Training Loss: 0.006734552793204784
Test Loss:  0.004198284819722176
Valid Loss:  0.004374335985630751
Epoch:  10  	Training Loss: 0.005871213041245937
Test Loss:  0.003693784587085247
Valid Loss:  0.0037385430186986923
Epoch:  11  	Training Loss: 0.005175696685910225
Test Loss:  0.003310991683974862
Valid Loss:  0.0032565253786742687
Epoch:  12  	Training Loss: 0.004612641874700785
Test Loss:  0.0030121374875307083
Valid Loss:  0.002890055300667882
Epoch:  13  	Training Loss: 0.0041571566835045815
Test Loss:  0.002775989007204771
Valid Loss:  0.00261271302588284
Epoch:  14  	Training Loss: 0.0037878481671214104
Test Loss:  0.0025939117185771465
Valid Loss:  0.0024062437005341053
Epoch:  15  	Training Loss: 0.003488376969471574
Test Loss:  0.0024507585912942886
Valid Loss:  0.0022544427774846554
Epoch:  16  	Training Loss: 0.0032454237807542086
Test Loss:  0.002339073456823826
Valid Loss:  0.00214562751352787
Epoch:  17  	Training Loss: 0.003048176411539316
Test Loss:  0.002253312384709716
Valid Loss:  0.0020703414920717478
Epoch:  18  	Training Loss: 0.0028880236204713583
Test Loss:  0.002193569904193282
Valid Loss:  0.0020207297056913376
Epoch:  19  	Training Loss: 0.002758118323981762
Test Loss:  0.002143430057913065
Valid Loss:  0.001990561606362462
Epoch:  20  	Training Loss: 0.002652582712471485
Test Loss:  0.0021065729670226574
Valid Loss:  0.001975404564291239
Epoch:  21  	Training Loss: 0.0025667818263173103
Test Loss:  0.0020818342454731464
Valid Loss:  0.001971192890778184
Epoch:  22  	Training Loss: 0.0024970751255750656
Test Loss:  0.00206425366923213
Valid Loss:  0.0019749803468585014
Epoch:  23  	Training Loss: 0.002440257463604212
Test Loss:  0.002050548791885376
Valid Loss:  0.0019849156960844994
Epoch:  24  	Training Loss: 0.002393980510532856
Test Loss:  0.002043668646365404
Valid Loss:  0.001998582389205694
Epoch:  25  	Training Loss: 0.002356313169002533
Test Loss:  0.002038046717643738
Valid Loss:  0.0020153848454356194
Epoch:  26  	Training Loss: 0.0023255725391209126
Test Loss:  0.0020353354047983885
Valid Loss:  0.0020338911563158035
Epoch:  27  	Training Loss: 0.002300421940162778
Test Loss:  0.0020345693919807673
Valid Loss:  0.002053242176771164
Epoch:  28  	Training Loss: 0.002279797103255987
Test Loss:  0.0020352841820567846
Valid Loss:  0.002072783187031746
Epoch:  29  	Training Loss: 0.0022628959268331528
Test Loss:  0.002038900274783373
Valid Loss:  0.0020916357170790434
Epoch:  30  	Training Loss: 0.0022491016425192356
Test Loss:  0.0020424220710992813
Valid Loss:  0.002110258676111698
Epoch:  31  	Training Loss: 0.002237881999462843
Test Loss:  0.002050066366791725
Valid Loss:  0.0021272413432598114
Epoch:  32  	Training Loss: 0.002228733617812395
Test Loss:  0.0020506749860942364
Valid Loss:  0.0021457283291965723
Epoch:  33  	Training Loss: 0.0022211656905710697
Test Loss:  0.002056590747088194
Valid Loss:  0.002161441370844841
Epoch:  34  	Training Loss: 0.0022149712312966585
Test Loss:  0.002059943974018097
Valid Loss:  0.0021771197207272053
Epoch:  35  	Training Loss: 0.002209865488111973
Test Loss:  0.0020623640157282352
Valid Loss:  0.0021919487044215202
Epoch:  36  	Training Loss: 0.0022056172601878643
Test Loss:  0.002067944733425975
Valid Loss:  0.002204546006396413
Epoch:  37  	Training Loss: 0.0022020875476300716
Test Loss:  0.002071040216833353
Valid Loss:  0.002217143075540662
Epoch:  38  	Training Loss: 0.002199148992076516
Test Loss:  0.0020741745829582214
Valid Loss:  0.0022286255843937397
Epoch:  39  	Training Loss: 0.0021966909989714622
Test Loss:  0.002077106386423111
Valid Loss:  0.00223916070535779
Epoch:  40  	Training Loss: 0.0021946034394204617
Test Loss:  0.0020798444747924805
Valid Loss:  0.002248798031359911
Epoch:  41  	Training Loss: 0.0021928176283836365
Test Loss:  0.002083483152091503
Valid Loss:  0.002257248619571328
Epoch:  42  	Training Loss: 0.0021912867669016123
Test Loss:  0.0020855546463280916
Valid Loss:  0.0022656330838799477
Epoch:  43  	Training Loss: 0.0021900248248130083
Test Loss:  0.0020889798179268837
Valid Loss:  0.0022726429160684347
Epoch:  44  	Training Loss: 0.0021889705676585436
Test Loss:  0.002090695546939969
Valid Loss:  0.0022796844132244587
Epoch:  45  	Training Loss: 0.0021880739368498325
Test Loss:  0.0020931928884238005
Valid Loss:  0.0022856511641293764
Epoch:  46  	Training Loss: 0.002187298145145178
Test Loss:  0.0020950506441295147
Valid Loss:  0.0022912872955203056
Epoch:  47  	Training Loss: 0.002186622004956007
Test Loss:  0.002096783835440874
Valid Loss:  0.0022963648661971092
Epoch:  48  	Training Loss: 0.002186036203056574
Test Loss:  0.0020983596332371235
Valid Loss:  0.002300952561199665
Epoch:  49  	Training Loss: 0.002185526769608259
Test Loss:  0.0020997917745262384
Valid Loss:  0.0023051011376082897
Epoch:  50  	Training Loss: 0.002185089746490121
Test Loss:  0.002101066056638956
Valid Loss:  0.0023088513407856226
Epoch:  51  	Training Loss: 0.002184709534049034
Test Loss:  0.0021022094879299402
Valid Loss:  0.002312222495675087
Epoch:  52  	Training Loss: 0.0021843593567609787
Test Loss:  0.0021031962241977453
Valid Loss:  0.0023152418434619904
Epoch:  53  	Training Loss: 0.0021840184926986694
Test Loss:  0.00210408098064363
Valid Loss:  0.00231793150305748
Epoch:  54  	Training Loss: 0.0021836927626281977
Test Loss:  0.002104886807501316
Valid Loss:  0.00232034083455801
Epoch:  55  	Training Loss: 0.0021833975333720446
Test Loss:  0.0021055974066257477
Valid Loss:  0.002322504995390773
Epoch:  56  	Training Loss: 0.002183124888688326
Test Loss:  0.0021061974111944437
Valid Loss:  0.0023244391195476055
Epoch:  57  	Training Loss: 0.002182862488552928
Test Loss:  0.002107123378664255
Valid Loss:  0.002326013520359993
Epoch:  58  	Training Loss: 0.0021826177835464478
Test Loss:  0.0021085976622998714
Valid Loss:  0.00232725334353745
Epoch:  59  	Training Loss: 0.0021823816932737827
Test Loss:  0.0021085862535983324
Valid Loss:  0.002329053357243538
Epoch:  60  	Training Loss: 0.0021821565460413694
Test Loss:  0.002109357388690114
Valid Loss:  0.0023302659392356873
Epoch:  61  	Training Loss: 0.002181941643357277
Test Loss:  0.0021087746135890484
Valid Loss:  0.0023318941239267588
Epoch:  62  	Training Loss: 0.0021817341912537813
Test Loss:  0.002110065193846822
Valid Loss:  0.0023324647918343544
Epoch:  63  	Training Loss: 0.002181533258408308
Test Loss:  0.002109868684783578
Valid Loss:  0.0023336992599070072
Epoch:  64  	Training Loss: 0.002181347692385316
Test Loss:  0.0021105483174324036
Valid Loss:  0.0023344068322330713
Epoch:  65  	Training Loss: 0.002181178890168667
Test Loss:  0.002110679168254137
Valid Loss:  0.00233530905097723
Epoch:  66  	Training Loss: 0.002181020099669695
Test Loss:  0.0021109359804540873
Valid Loss:  0.0023360473569482565
Epoch:  67  	Training Loss: 0.002180874813348055
Test Loss:  0.002110147848725319
Valid Loss:  0.0023370948620140553
Epoch:  68  	Training Loss: 0.0021807372104376554
Test Loss:  0.0021112733520567417
Valid Loss:  0.0023371349088847637
Epoch:  69  	Training Loss: 0.0021805991418659687
Test Loss:  0.002111328300088644
Valid Loss:  0.0023377491161227226
Epoch:  70  	Training Loss: 0.002180465729907155
Test Loss:  0.002111450070515275
Valid Loss:   14%|█▍        | 71/500 [00:55<08:51,  1.24s/it] 15%|█▍        | 73/500 [00:55<06:22,  1.12it/s] 15%|█▌        | 75/500 [00:55<04:37,  1.53it/s] 15%|█▌        | 77/500 [00:55<03:24,  2.07it/s] 16%|█▌        | 79/500 [00:55<02:30,  2.79it/s] 16%|█▌        | 81/500 [01:02<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:02<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:21,  1.59it/s] 17%|█▋        | 87/500 [01:02<03:11,  2.16it/s] 18%|█▊        | 89/500 [01:02<02:22,  2.89it/s] 18%|█▊        | 91/500 [01:09<08:17,  1.22s/it] 19%|█▊        | 93/500 [01:09<05:57,  1.14it/s] 19%|█▉        | 95/500 [01:09<04:19,  1.56it/s] 19%|█▉        | 97/500 [01:09<03:10,  2.11it/s] 20%|█▉        | 99/500 [01:10<02:23,  2.80it/s] 20%|██        | 101/500 [01:16<08:05,  1.22s/it] 21%|██        | 103/500 [01:16<05:46,  1.15it/s] 21%|██        | 105/500 [01:16<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:16<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.92it/s] 22%|██▏       | 111/500 [01:23<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:23<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:23<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:23<02:56,  2.18it/s] 24%|██▍       | 119/500 [01:23<02:11,  2.90it/s] 24%|██▍       | 121/500 [01:30<07:32,  1.20s/it] 25%|██▍       | 123/500 [01:30<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:30<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:30<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:30<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:37<07:19,  1.19s/it] 27%|██▋       | 133/500 [01:37<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:37<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:37<02:48,  2.15it/s] 28%|██▊       | 139/500 [01:37<02:06,  2.85it/s]0.0023382422514259815
Epoch:  71  	Training Loss: 0.002180335111916065
Test Loss:  0.0021115506533533335
Valid Loss:  0.0023386788088828325
Epoch:  72  	Training Loss: 0.0021802070550620556
Test Loss:  0.0021112272515892982
Valid Loss:  0.0023392196744680405
Epoch:  73  	Training Loss: 0.002180077601224184
Test Loss:  0.002111713867634535
Valid Loss:  0.002339322352781892
Epoch:  74  	Training Loss: 0.002179947681725025
Test Loss:  0.0021117543801665306
Valid Loss:  0.0023396494798362255
Epoch:  75  	Training Loss: 0.0021798210218548775
Test Loss:  0.002111828653141856
Valid Loss:  0.0023399179335683584
Epoch:  76  	Training Loss: 0.002179700182750821
Test Loss:  0.0021118787117302418
Valid Loss:  0.0023401561193168163
Epoch:  77  	Training Loss: 0.0021795814391225576
Test Loss:  0.002111923648044467
Valid Loss:  0.00234035961329937
Epoch:  78  	Training Loss: 0.0021794666536152363
Test Loss:  0.0021119583398103714
Valid Loss:  0.0023405426181852818
Epoch:  79  	Training Loss: 0.002179353730753064
Test Loss:  0.002111926209181547
Valid Loss:  0.002340717473998666
Epoch:  80  	Training Loss: 0.0021792431361973286
Test Loss:  0.002111998153850436
Valid Loss:  0.002340818289667368
Epoch:  81  	Training Loss: 0.002179136034101248
Test Loss:  0.0021120032761245966
Valid Loss:  0.002340937964618206
Epoch:  82  	Training Loss: 0.002179030328989029
Test Loss:  0.0021119979210197926
Valid Loss:  0.0023410366848111153
Epoch:  83  	Training Loss: 0.00217892462387681
Test Loss:  0.0021119972225278616
Valid Loss:  0.0023411158472299576
Epoch:  84  	Training Loss: 0.0021788207814097404
Test Loss:  0.0021119865123182535
Valid Loss:  0.002341188956052065
Epoch:  85  	Training Loss: 0.002178716938942671
Test Loss:  0.002111969515681267
Valid Loss:  0.002341237384825945
Epoch:  86  	Training Loss: 0.002178614493459463
Test Loss:  0.0021119494922459126
Valid Loss:  0.0023412699811160564
Epoch:  87  	Training Loss: 0.0021785120479762554
Test Loss:  0.002111932262778282
Valid Loss:  0.002341301180422306
Epoch:  88  	Training Loss: 0.002178414026275277
Test Loss:  0.0021118968725204468
Valid Loss:  0.0023413291200995445
Epoch:  89  	Training Loss: 0.0021783155389130116
Test Loss:  0.002111859619617462
Valid Loss:  0.00234134029597044
Epoch:  90  	Training Loss: 0.0021782172843813896
Test Loss:  0.00211181933991611
Valid Loss:  0.002341342391446233
Epoch:  91  	Training Loss: 0.0021781190298497677
Test Loss:  0.002111777663230896
Valid Loss:  0.002341336105018854
Epoch:  92  	Training Loss: 0.002178018679842353
Test Loss:  0.0021117273718118668
Valid Loss:  0.002341323299333453
Epoch:  93  	Training Loss: 0.0021779220551252365
Test Loss:  0.0021116789430379868
Valid Loss:  0.0023412988521158695
Epoch:  94  	Training Loss: 0.002177825663238764
Test Loss:  0.002111629582941532
Valid Loss:  0.0023412718437612057
Epoch:  95  	Training Loss: 0.0021777309011667967
Test Loss:  0.002111574402078986
Valid Loss:  0.0023412425071001053
Epoch:  96  	Training Loss: 0.002177633810788393
Test Loss:  0.0021115161944180727
Valid Loss:  0.0023412038572132587
Epoch:  97  	Training Loss: 0.0021775364875793457
Test Loss:  0.002111459616571665
Valid Loss:  0.002341163344681263
Epoch:  98  	Training Loss: 0.002177440794184804
Test Loss:  0.0021114011760801077
Valid Loss:  0.002341116778552532
Epoch:  99  	Training Loss: 0.0021773444022983313
Test Loss:  0.0021113413386046886
Valid Loss:  0.002341063227504492
Epoch:  100  	Training Loss: 0.002177247777581215
Test Loss:  0.0021112775430083275
Valid Loss:  0.0023410154972225428
Epoch:  101  	Training Loss: 0.002177152317017317
Test Loss:  0.002111216774210334
Valid Loss:  0.002340959385037422
Epoch:  102  	Training Loss: 0.002177056623622775
Test Loss:  0.0021111550740897655
Valid Loss:  0.0023408951237797737
Epoch:  103  	Training Loss: 0.0021769595332443714
Test Loss:  0.002111096866428852
Valid Loss:  0.0023408341221511364
Epoch:  104  	Training Loss: 0.0021768647711724043
Test Loss:  0.002111033070832491
Valid Loss:  0.0023407703265547752
Epoch:  105  	Training Loss: 0.002176768146455288
Test Loss:  0.0021109688095748425
Valid Loss:  0.002340701874345541
Epoch:  106  	Training Loss: 0.002176673384383321
Test Loss:  0.0021109057124704123
Valid Loss:  0.0023406296968460083
Epoch:  107  	Training Loss: 0.0021765772253274918
Test Loss:  0.0021108430810272694
Valid Loss:  0.002340558683499694
Epoch:  108  	Training Loss: 0.002176480134949088
Test Loss:  0.0021107797510921955
Valid Loss:  0.0023404881358146667
Epoch:  109  	Training Loss: 0.0021763844415545464
Test Loss:  0.0021107145585119724
Valid Loss:  0.0023404122330248356
Epoch:  110  	Training Loss: 0.0021762882824987173
Test Loss:  0.002110646106302738
Valid Loss:  0.0023403442464768887
Epoch:  111  	Training Loss: 0.0021761921234428883
Test Loss:  0.0021105841733515263
Valid Loss:  0.0023402690421789885
Epoch:  112  	Training Loss: 0.0021760957315564156
Test Loss:  0.0021105241030454636
Valid Loss:  0.0023401924408972263
Epoch:  113  	Training Loss: 0.0021760016679763794
Test Loss:  0.002110462635755539
Valid Loss:  0.0023401121143251657
Epoch:  114  	Training Loss: 0.002175909001380205
Test Loss:  0.0021103976760059595
Valid Loss:  0.002340038539841771
Epoch:  115  	Training Loss: 0.0021758137736469507
Test Loss:  0.0021103331819176674
Valid Loss:  0.0023399670608341694
Epoch:  116  	Training Loss: 0.00217572133988142
Test Loss:  0.0021102656610310078
Valid Loss:  0.0023398911580443382
Epoch:  117  	Training Loss: 0.0021756270434707403
Test Loss:  0.0021102027967572212
Valid Loss:  0.0023398185148835182
Epoch:  118  	Training Loss: 0.002175533678382635
Test Loss:  0.00211013644002378
Valid Loss:  0.00233973516151309
Epoch:  119  	Training Loss: 0.002175441477447748
Test Loss:  0.002110071713104844
Valid Loss:  0.0023396573960781097
Epoch:  120  	Training Loss: 0.0021753469482064247
Test Loss:  0.002110003959387541
Valid Loss:  0.002339579164981842
Epoch:  121  	Training Loss: 0.0021752542816102505
Test Loss:  0.0021099396981298923
Valid Loss:  0.0023395000025629997
Epoch:  122  	Training Loss: 0.0021751606836915016
Test Loss:  0.0021098703145980835
Valid Loss:  0.0023394240997731686
Epoch:  123  	Training Loss: 0.0021750705782324076
Test Loss:  0.002109803492203355
Valid Loss:  0.0023393495939671993
Epoch:  124  	Training Loss: 0.0021749776788055897
Test Loss:  0.0021097357384860516
Valid Loss:  0.0023392715957015753
Epoch:  125  	Training Loss: 0.0021748882718384266
Test Loss:  0.0021096649579703808
Valid Loss:  0.0023391905706375837
Epoch:  126  	Training Loss: 0.002174796536564827
Test Loss:  0.0021095951087772846
Valid Loss:  0.0023391132708638906
Epoch:  127  	Training Loss: 0.0021747052669525146
Test Loss:  0.0021095278207212687
Valid Loss:  0.002339037135243416
Epoch:  128  	Training Loss: 0.002174614230170846
Test Loss:  0.0021094572730362415
Valid Loss:  0.002338951686397195
Epoch:  129  	Training Loss: 0.0021745217964053154
Test Loss:  0.0021093906834721565
Valid Loss:  0.0023388750851154327
Epoch:  130  	Training Loss: 0.0021744307596236467
Test Loss:  0.002109322464093566
Valid Loss:  0.002338795457035303
Epoch:  131  	Training Loss: 0.00217434111982584
Test Loss:  0.002109252382069826
Valid Loss:  0.002338712103664875
Epoch:  132  	Training Loss: 0.0021742500830441713
Test Loss:  0.0021091799717396498
Valid Loss:  0.002338634803891182
Epoch:  133  	Training Loss: 0.0021741585806012154
Test Loss:  0.0021091129165142775
Valid Loss:  0.0023385498207062483
Epoch:  134  	Training Loss: 0.002174068009480834
Test Loss:  0.002109043300151825
Valid Loss:  0.0023384718224406242
Epoch:  135  	Training Loss: 0.0021739783696830273
Test Loss:  0.0021089750807732344
Valid Loss:  0.002338389866054058
Epoch:  136  	Training Loss: 0.0021738880313932896
Test Loss:  0.0021089091897010803
Valid Loss:  0.002338307909667492
Epoch:  137  	Training Loss: 0.002173799090087414
Test Loss:  0.0021088356152176857
Valid Loss:  0.0023382254876196384
Epoch:  138  	Training Loss: 0.0021737085189670324
Test Loss:  0.0021087676286697388
Valid Loss:  0.002338148420676589
Epoch:  139  	Training Loss: 0.0021736188791692257
Test Loss:  0.00210869824513793
Valid Loss:  0.0023380639031529427
 28%|██▊       | 141/500 [01:44<07:13,  1.21s/it] 29%|██▊       | 143/500 [01:44<05:12,  1.14it/s] 29%|██▉       | 145/500 [01:44<03:46,  1.57it/s] 29%|██▉       | 147/500 [01:44<02:46,  2.12it/s] 30%|██▉       | 149/500 [01:44<02:05,  2.80it/s] 30%|███       | 151/500 [01:51<07:04,  1.22s/it] 31%|███       | 153/500 [01:51<05:03,  1.14it/s] 31%|███       | 155/500 [01:51<03:37,  1.58it/s] 31%|███▏      | 157/500 [01:51<02:38,  2.17it/s] 32%|███▏      | 159/500 [01:51<01:56,  2.92it/s] 32%|███▏      | 161/500 [01:58<06:46,  1.20s/it] 33%|███▎      | 163/500 [01:58<04:49,  1.16it/s] 33%|███▎      | 165/500 [01:58<03:28,  1.61it/s] 33%|███▎      | 167/500 [01:58<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:58<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:05<06:33,  1.20s/it] 35%|███▍      | 173/500 [02:05<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:05<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:05<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:05<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:12<06:24,  1.21s/it] 37%|███▋      | 183/500 [02:12<04:35,  1.15it/s] 37%|███▋      | 185/500 [02:12<03:19,  1.58it/s] 37%|███▋      | 187/500 [02:12<02:24,  2.16it/s] 38%|███▊      | 189/500 [02:12<01:46,  2.91it/s] 38%|███▊      | 191/500 [02:19<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:19<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:19<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:19<02:16,  2.21it/s] 40%|███▉      | 199/500 [02:19<01:41,  2.98it/s] 40%|████      | 201/500 [02:26<05:52,  1.18s/it] 41%|████      | 203/500 [02:26<04:11,  1.18it/s] 41%|████      | 205/500 [02:26<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:26<02:11,  2.23it/s]Epoch:  140  	Training Loss: 0.0021735276095569134
Test Loss:  0.002108630258589983
Valid Loss:  0.0023379838094115257
Epoch:  141  	Training Loss: 0.002173437736928463
Test Loss:  0.002108559710904956
Valid Loss:  0.002337900921702385
Epoch:  142  	Training Loss: 0.002173346932977438
Test Loss:  0.0021084919571876526
Valid Loss:  0.0023378203622996807
Epoch:  143  	Training Loss: 0.002173258690163493
Test Loss:  0.0021084214095026255
Valid Loss:  0.0023377398028969765
Epoch:  144  	Training Loss: 0.002173167420551181
Test Loss:  0.0021083534229546785
Valid Loss:  0.002337655983865261
Epoch:  145  	Training Loss: 0.002173081273213029
Test Loss:  0.0021082889288663864
Valid Loss:  0.0023375735618174076
Epoch:  146  	Training Loss: 0.0021729893051087856
Test Loss:  0.002108217217028141
Valid Loss:  0.0023374920710921288
Epoch:  147  	Training Loss: 0.0021729017607867718
Test Loss:  0.002108149230480194
Valid Loss:  0.002337405923753977
Epoch:  148  	Training Loss: 0.0021728125866502523
Test Loss:  0.002108080079779029
Valid Loss:  0.0023373274598270655
Epoch:  149  	Training Loss: 0.002172723412513733
Test Loss:  0.002108008833602071
Valid Loss:  0.0023372466675937176
Epoch:  150  	Training Loss: 0.002172635169699788
Test Loss:  0.0021079424768686295
Valid Loss:  0.0023371647112071514
Epoch:  151  	Training Loss: 0.0021725469268858433
Test Loss:  0.00210787495598197
Valid Loss:  0.0023370799608528614
Epoch:  152  	Training Loss: 0.0021724561229348183
Test Loss:  0.002107808366417885
Valid Loss:  0.00233699893578887
Epoch:  153  	Training Loss: 0.0021723685786128044
Test Loss:  0.0021077373530715704
Valid Loss:  0.0023369165137410164
Epoch:  154  	Training Loss: 0.0021722805686295033
Test Loss:  0.002107667736709118
Valid Loss:  0.0023368378169834614
Epoch:  155  	Training Loss: 0.0021721941884607077
Test Loss:  0.0021076020784676075
Valid Loss:  0.0023367528337985277
Epoch:  156  	Training Loss: 0.0021721061784774065
Test Loss:  0.002107535256072879
Valid Loss:  0.002336673904210329
Epoch:  157  	Training Loss: 0.0021720179356634617
Test Loss:  0.0021074656397104263
Valid Loss:  0.0023365896195173264
Epoch:  158  	Training Loss: 0.0021719299256801605
Test Loss:  0.0021073976531624794
Valid Loss:  0.0023365095257759094
Epoch:  159  	Training Loss: 0.002171844244003296
Test Loss:  0.0021073324605822563
Valid Loss:  0.0023364312946796417
Epoch:  160  	Training Loss: 0.00217175530269742
Test Loss:  0.0021072612144052982
Valid Loss:  0.002336348406970501
Epoch:  161  	Training Loss: 0.002171666594222188
Test Loss:  0.0021071939263492823
Valid Loss:  0.002336266916245222
Epoch:  162  	Training Loss: 0.002171579049900174
Test Loss:  0.002107123378664255
Valid Loss:  0.002336195670068264
Epoch:  163  	Training Loss: 0.002171493135392666
Test Loss:  0.0021070586517453194
Valid Loss:  0.002336110919713974
Epoch:  164  	Training Loss: 0.0021714051254093647
Test Loss:  0.002106987638399005
Valid Loss:  0.0023360331542789936
Epoch:  165  	Training Loss: 0.0021713189780712128
Test Loss:  0.002106925006955862
Valid Loss:  0.002335958182811737
Epoch:  166  	Training Loss: 0.0021712337620556355
Test Loss:  0.0021068579517304897
Valid Loss:  0.00233587552793324
Epoch:  167  	Training Loss: 0.0021711469162255526
Test Loss:  0.002106792526319623
Valid Loss:  0.002335792640224099
Epoch:  168  	Training Loss: 0.0021710600703954697
Test Loss:  0.0021067289635539055
Valid Loss:  0.0023357197642326355
Epoch:  169  	Training Loss: 0.0021709753200411797
Test Loss:  0.0021066595800220966
Valid Loss:  0.002335641998797655
Epoch:  170  	Training Loss: 0.002170889638364315
Test Loss:  0.0021065962500870228
Valid Loss:  0.002335562137886882
Epoch:  171  	Training Loss: 0.002170802094042301
Test Loss:  0.002106530126184225
Valid Loss:  0.002335487399250269
Epoch:  172  	Training Loss: 0.0021707159467041492
Test Loss:  0.0021064705215394497
Valid Loss:  0.002335402648895979
Epoch:  173  	Training Loss: 0.0021706297993659973
Test Loss:  0.002106404397636652
Valid Loss:  0.002335322555154562
Epoch:  174  	Training Loss: 0.002170545980334282
Test Loss:  0.0021063387393951416
Valid Loss:  0.0023352447897195816
Epoch:  175  	Training Loss: 0.002170460531488061
Test Loss:  0.0021062702871859074
Valid Loss:  0.0023351649288088083
Epoch:  176  	Training Loss: 0.0021703753154724836
Test Loss:  0.00210620928555727
Valid Loss:  0.002335089026018977
Epoch:  177  	Training Loss: 0.0021702907979488373
Test Loss:  0.002106143394485116
Valid Loss:  0.002335004974156618
Epoch:  178  	Training Loss: 0.0021702058147639036
Test Loss:  0.002106079598888755
Valid Loss:  0.0023349239490926266
Epoch:  179  	Training Loss: 0.0021701212972402573
Test Loss:  0.002106014871969819
Valid Loss:  0.002334847114980221
Epoch:  180  	Training Loss: 0.0021700358483940363
Test Loss:  0.0021059485152363777
Valid Loss:  0.002334767486900091
Epoch:  181  	Training Loss: 0.0021699508652091026
Test Loss:  0.002105885883793235
Valid Loss:  0.0023346906527876854
Epoch:  182  	Training Loss: 0.002169865183532238
Test Loss:  0.002105819061398506
Valid Loss:  0.0023346177767962217
Epoch:  183  	Training Loss: 0.002169783692806959
Test Loss:  0.002105755265802145
Valid Loss:  0.0023345421068370342
Epoch:  184  	Training Loss: 0.0021696998737752438
Test Loss:  0.0021056849509477615
Valid Loss:  0.002334467601031065
Epoch:  185  	Training Loss: 0.002169617684558034
Test Loss:  0.002105619292706251
Valid Loss:  0.0023343979846686125
Epoch:  186  	Training Loss: 0.002169534796848893
Test Loss:  0.0021055471152067184
Valid Loss:  0.0023343232460319996
Epoch:  187  	Training Loss: 0.002169450744986534
Test Loss:  0.0021054798271507025
Valid Loss:  0.002334246877580881
Epoch:  188  	Training Loss: 0.0021693690214306116
Test Loss:  0.0021054111421108246
Valid Loss:  0.002334172371774912
Epoch:  189  	Training Loss: 0.002169286133721471
Test Loss:  0.002105340361595154
Valid Loss:  0.0023340978659689426
Epoch:  190  	Training Loss: 0.0021692044101655483
Test Loss:  0.002105269581079483
Valid Loss:  0.002334021031856537
Epoch:  191  	Training Loss: 0.0021691215224564075
Test Loss:  0.0021051992662250996
Valid Loss:  0.002333944197744131
Epoch:  192  	Training Loss: 0.002169037703424692
Test Loss:  0.0021051305811852217
Valid Loss:  0.002333870157599449
Epoch:  193  	Training Loss: 0.002168954350054264
Test Loss:  0.002105063060298562
Valid Loss:  0.0023337961174547672
Epoch:  194  	Training Loss: 0.002168874256312847
Test Loss:  0.002104994608089328
Valid Loss:  0.002333724172785878
Epoch:  195  	Training Loss: 0.0021687925327569246
Test Loss:  0.0021049226634204388
Valid Loss:  0.0023336431477218866
Epoch:  196  	Training Loss: 0.0021687105763703585
Test Loss:  0.0021048549097031355
Valid Loss:  0.002333571668714285
Epoch:  197  	Training Loss: 0.0021686286199837923
Test Loss:  0.0021047834306955338
Valid Loss:  0.0023334939032793045
Epoch:  198  	Training Loss: 0.00216854689642787
Test Loss:  0.002104715444147587
Valid Loss:  0.0023334170691668987
Epoch:  199  	Training Loss: 0.0021684651728719473
Test Loss:  0.0021046451292932034
Valid Loss:  0.002333336276933551
Epoch:  200  	Training Loss: 0.002168383914977312
Test Loss:  0.002104573417454958
Valid Loss:  0.0023332629352808
Epoch:  201  	Training Loss: 0.002168299863114953
Test Loss:  0.0021045091561973095
Valid Loss:  0.002333185402676463
Epoch:  202  	Training Loss: 0.0021682181395590305
Test Loss:  0.0021044393070042133
Valid Loss:  0.002333107404410839
Epoch:  203  	Training Loss: 0.0021681375801563263
Test Loss:  0.002104369457811117
Valid Loss:  0.0023330338299274445
Epoch:  204  	Training Loss: 0.0021680574864149094
Test Loss:  0.0021042998414486647
Valid Loss:  0.0023329583927989006
Epoch:  205  	Training Loss: 0.0021679766941815615
Test Loss:  0.002104230457916856
Valid Loss:  0.002332880860194564
Epoch:  206  	Training Loss: 0.0021678940393030643
Test Loss:  0.002104161772876978
Valid Loss:  0.002332806121557951
Epoch:  207  	Training Loss: 0.002167814876884222
Test Loss:  0.002104093786329031
Valid Loss:  0.0023327285889536142
Epoch:  208  	Training Loss: 0.002167733618989587
Test Loss:  0.002104024402797222
Valid Loss:  0.002332654781639576
 42%|████▏     | 209/500 [02:26<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:32<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:33<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:33<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:33<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:33<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:39<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:39<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:39<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:40<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:40<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:46<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:46<03:45,  1.19it/s] 47%|████▋     | 235/500 [02:46<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:46<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:47<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:53<05:04,  1.17s/it] 48%|████▊     | 242/500 [02:53<04:14,  1.01it/s] 49%|████▉     | 244/500 [02:53<02:55,  1.46it/s] 49%|████▉     | 246/500 [02:53<02:03,  2.06it/s] 50%|████▉     | 248/500 [02:53<01:29,  2.83it/s] 50%|█████     | 250/500 [02:54<01:06,  3.78it/s] 50%|█████     | 252/500 [03:00<04:49,  1.17s/it] 51%|█████     | 254/500 [03:00<03:24,  1.20it/s] 51%|█████     | 256/500 [03:00<02:26,  1.67it/s] 52%|█████▏    | 258/500 [03:00<01:45,  2.29it/s] 52%|█████▏    | 260/500 [03:00<01:17,  3.08it/s] 52%|█████▏    | 262/500 [03:07<04:40,  1.18s/it] 53%|█████▎    | 264/500 [03:07<03:19,  1.18it/s] 53%|█████▎    | 266/500 [03:07<02:22,  1.64it/s] 54%|█████▎    | 268/500 [03:07<01:43,  2.24it/s] 54%|█████▍    | 270/500 [03:07<01:16,  3.01it/s] 54%|█████▍    | 272/500 [03:14<04:30,  1.18s/it] 55%|█████▍    | 274/500 [03:14<03:12,  1.18it/s] 55%|█████▌    | 276/500 [03:14<02:17,  1.63it/s]Epoch:  209  	Training Loss: 0.0021676509641110897
Test Loss:  0.0021039522252976894
Valid Loss:  0.0023325770162045956
Epoch:  210  	Training Loss: 0.0021675722673535347
Test Loss:  0.0021038861013948917
Valid Loss:  0.002332498552277684
Epoch:  211  	Training Loss: 0.002167490078136325
Test Loss:  0.0021038202103227377
Valid Loss:  0.002332421252503991
Epoch:  212  	Training Loss: 0.0021674088202416897
Test Loss:  0.002103750128298998
Valid Loss:  0.0023323451168835163
Epoch:  213  	Training Loss: 0.002167328028008342
Test Loss:  0.0021036798134446144
Valid Loss:  0.0023322675842791796
Epoch:  214  	Training Loss: 0.0021672495640814304
Test Loss:  0.002103612758219242
Valid Loss:  0.0023321914486587048
Epoch:  215  	Training Loss: 0.002167169936001301
Test Loss:  0.0021035405807197094
Valid Loss:  0.0023321148473769426
Epoch:  216  	Training Loss: 0.002167088445276022
Test Loss:  0.002103473525494337
Valid Loss:  0.002332040574401617
Epoch:  217  	Training Loss: 0.002167009748518467
Test Loss:  0.0021034025121480227
Valid Loss:  0.0023319614119827747
Epoch:  218  	Training Loss: 0.0021669301204383373
Test Loss:  0.0021033380180597305
Valid Loss:  0.0023318852763623
Epoch:  219  	Training Loss: 0.0021668490953743458
Test Loss:  0.002103267703205347
Valid Loss:  0.002331809140741825
Epoch:  220  	Training Loss: 0.002166768303140998
Test Loss:  0.0021032006479799747
Valid Loss:  0.0023317330051213503
Epoch:  221  	Training Loss: 0.0021666898392140865
Test Loss:  0.0021031307987868786
Valid Loss:  0.0023316550068557262
Epoch:  222  	Training Loss: 0.0021666097454726696
Test Loss:  0.0021030630450695753
Valid Loss:  0.0023315821308642626
Epoch:  223  	Training Loss: 0.0021665298845618963
Test Loss:  0.002102995291352272
Valid Loss:  0.002331498544663191
Epoch:  224  	Training Loss: 0.0021664509549736977
Test Loss:  0.0021029263734817505
Valid Loss:  0.00233142520301044
Epoch:  225  	Training Loss: 0.0021663708612322807
Test Loss:  0.00210285815410316
Valid Loss:  0.0023313493002206087
Epoch:  226  	Training Loss: 0.0021662916988134384
Test Loss:  0.00210278807207942
Valid Loss:  0.0023312706034630537
Epoch:  227  	Training Loss: 0.002166212536394596
Test Loss:  0.002102717524394393
Valid Loss:  0.002331191673874855
Epoch:  228  	Training Loss: 0.002166133839637041
Test Loss:  0.002102650236338377
Valid Loss:  0.002331117633730173
Epoch:  229  	Training Loss: 0.0021660542115569115
Test Loss:  0.0021025813184678555
Valid Loss:  0.0023310368414968252
Epoch:  230  	Training Loss: 0.002165974583476782
Test Loss:  0.002102513797581196
Valid Loss:  0.002330962335690856
Epoch:  231  	Training Loss: 0.0021658961195498705
Test Loss:  0.0021024427842348814
Valid Loss:  0.002330885734409094
Epoch:  232  	Training Loss: 0.0021658167243003845
Test Loss:  0.0021023782901465893
Valid Loss:  0.002330808900296688
Epoch:  233  	Training Loss: 0.002165738958865404
Test Loss:  0.0021023082081228495
Valid Loss:  0.002330731600522995
Epoch:  234  	Training Loss: 0.002165658865123987
Test Loss:  0.0021022441796958447
Valid Loss:  0.0023306577932089567
Epoch:  235  	Training Loss: 0.002165580401197076
Test Loss:  0.0021021717693656683
Valid Loss:  0.0023305860813707113
Epoch:  236  	Training Loss: 0.0021655037999153137
Test Loss:  0.0021021077409386635
Valid Loss:  0.0023305080831050873
Epoch:  237  	Training Loss: 0.002165424870327115
Test Loss:  0.0021020378917455673
Valid Loss:  0.0023304354399442673
Epoch:  238  	Training Loss: 0.0021653478033840656
Test Loss:  0.0021019717678427696
Valid Loss:  0.002330357674509287
Epoch:  239  	Training Loss: 0.0021652693394571543
Test Loss:  0.0021019065752625465
Valid Loss:  0.0023302845656871796
Epoch:  240  	Training Loss: 0.002165189478546381
Test Loss:  0.002101839752867818
Valid Loss:  0.002330210991203785
Epoch:  241  	Training Loss: 0.002165112178772688
Test Loss:  0.0021017729304730892
Valid Loss:  0.0023301339242607355
Epoch:  242  	Training Loss: 0.00216503394767642
Test Loss:  0.0021017007529735565
Valid Loss:  0.0023300661705434322
Epoch:  243  	Training Loss: 0.002164956647902727
Test Loss:  0.0021016362588852644
Valid Loss:  0.0023299907334148884
Epoch:  244  	Training Loss: 0.002164877951145172
Test Loss:  0.0021015703678131104
Valid Loss:  0.0023299213498830795
Epoch:  245  	Training Loss: 0.0021648025140166283
Test Loss:  0.0021015037782490253
Valid Loss:  0.0023298480082303286
Epoch:  246  	Training Loss: 0.0021647228859364986
Test Loss:  0.002101439516991377
Valid Loss:  0.002329777227714658
Epoch:  247  	Training Loss: 0.002164646051824093
Test Loss:  0.0021013710647821426
Valid Loss:  0.002329702954739332
Epoch:  248  	Training Loss: 0.0021645689848810434
Test Loss:  0.0021013005170971155
Valid Loss:  0.0023296307772397995
Epoch:  249  	Training Loss: 0.0021644909866154194
Test Loss:  0.00210123835131526
Valid Loss:  0.002329559065401554
Epoch:  250  	Training Loss: 0.0021644134540110826
Test Loss:  0.0021011694334447384
Valid Loss:  0.0023294868879020214
Epoch:  251  	Training Loss: 0.0021643368527293205
Test Loss:  0.0021011049393564463
Valid Loss:  0.0023294135462492704
Epoch:  252  	Training Loss: 0.002164259320124984
Test Loss:  0.0021010381169617176
Valid Loss:  0.0023293406702578068
Epoch:  253  	Training Loss: 0.002164181089028716
Test Loss:  0.002100971294566989
Valid Loss:  0.0023292619735002518
Epoch:  254  	Training Loss: 0.0021641061175614595
Test Loss:  0.0021009077318012714
Valid Loss:  0.0023291967809200287
Epoch:  255  	Training Loss: 0.0021640295162796974
Test Loss:  0.0021008411422371864
Valid Loss:  0.0023291222751140594
Epoch:  256  	Training Loss: 0.002163951750844717
Test Loss:  0.002100772690027952
Valid Loss:  0.002329047303646803
Epoch:  257  	Training Loss: 0.0021638760808855295
Test Loss:  0.0021007093600928783
Valid Loss:  0.00232897512614727
Epoch:  258  	Training Loss: 0.00216379901394248
Test Loss:  0.002100640442222357
Valid Loss:  0.0023289062082767487
Epoch:  259  	Training Loss: 0.0021637240424752235
Test Loss:  0.002100575715303421
Valid Loss:  0.002328831935301423
Epoch:  260  	Training Loss: 0.002163647674024105
Test Loss:  0.0021005035378038883
Valid Loss:  0.002328762784600258
Epoch:  261  	Training Loss: 0.0021635694429278374
Test Loss:  0.002100441139191389
Valid Loss:  0.002328689442947507
Epoch:  262  	Training Loss: 0.002163494937121868
Test Loss:  0.002100372454151511
Valid Loss:  0.0023286216892302036
Epoch:  263  	Training Loss: 0.0021634181030094624
Test Loss:  0.002100306563079357
Valid Loss:  0.002328549511730671
Epoch:  264  	Training Loss: 0.002163341734558344
Test Loss:  0.0021002350840717554
Valid Loss:  0.002328478032723069
Epoch:  265  	Training Loss: 0.0021632662974298
Test Loss:  0.002100172219797969
Valid Loss:  0.00232840608805418
Epoch:  266  	Training Loss: 0.0021631910931319
Test Loss:  0.002100103534758091
Valid Loss:  0.002328332979232073
Epoch:  267  	Training Loss: 0.0021631144918501377
Test Loss:  0.0021000360138714314
Valid Loss:  0.002328264992684126
Epoch:  268  	Training Loss: 0.0021630381233990192
Test Loss:  0.0020999626722186804
Valid Loss:  0.002328193746507168
Epoch:  269  	Training Loss: 0.002162962919101119
Test Loss:  0.002099903067573905
Valid Loss:  0.0023281173780560493
Epoch:  270  	Training Loss: 0.002162884920835495
Test Loss:  0.002099829027429223
Valid Loss:  0.002328045666217804
Epoch:  271  	Training Loss: 0.002162810880690813
Test Loss:  0.002099764533340931
Valid Loss:  0.0023279779125005007
Epoch:  272  	Training Loss: 0.002162734977900982
Test Loss:  0.002099699107930064
Valid Loss:  0.0023279013112187386
Epoch:  273  	Training Loss: 0.0021626597736030817
Test Loss:  0.0020996364764869213
Valid Loss:  0.002327830297872424
Epoch:  274  	Training Loss: 0.002162585500627756
Test Loss:  0.002099565928801894
Valid Loss:  0.0023277606815099716
Epoch:  275  	Training Loss: 0.0021625100634992123
Test Loss:  0.0020994977094233036
Valid Loss:  0.0023276894353330135
Epoch:  276  	Training Loss: 0.002162434160709381
Test Loss:  0.0020994306541979313
Valid Loss:  0.002327611902728677
Epoch:  277  	Training Loss: 0.0021623591892421246
Test Loss:  0.002099367091432214
Valid Loss:  0.002327545080333948
 56%|█████▌    | 278/500 [03:14<01:39,  2.22it/s] 56%|█████▌    | 280/500 [03:14<01:14,  2.97it/s] 56%|█████▋    | 282/500 [03:20<04:15,  1.17s/it] 57%|█████▋    | 284/500 [03:21<03:01,  1.19it/s] 57%|█████▋    | 286/500 [03:21<02:11,  1.63it/s] 58%|█████▊    | 288/500 [03:21<01:35,  2.22it/s] 58%|█████▊    | 290/500 [03:21<01:10,  2.99it/s] 58%|█████▊    | 292/500 [03:27<04:06,  1.19s/it] 59%|█████▉    | 294/500 [03:27<02:55,  1.18it/s] 59%|█████▉    | 296/500 [03:28<02:05,  1.63it/s] 60%|█████▉    | 298/500 [03:28<01:30,  2.22it/s] 60%|██████    | 300/500 [03:28<01:06,  2.99it/s] 60%|██████    | 302/500 [03:34<03:52,  1.17s/it] 61%|██████    | 304/500 [03:34<02:45,  1.19it/s] 61%|██████    | 306/500 [03:34<01:58,  1.64it/s] 62%|██████▏   | 308/500 [03:35<01:25,  2.24it/s] 62%|██████▏   | 310/500 [03:35<01:03,  3.00it/s] 62%|██████▏   | 312/500 [03:41<03:45,  1.20s/it] 63%|██████▎   | 314/500 [03:41<02:39,  1.17it/s] 63%|██████▎   | 316/500 [03:41<01:54,  1.61it/s] 64%|██████▎   | 318/500 [03:42<01:22,  2.20it/s] 64%|██████▍   | 320/500 [03:42<01:00,  2.96it/s] 64%|██████▍   | 322/500 [03:48<03:32,  1.19s/it] 65%|██████▍   | 324/500 [03:48<02:30,  1.17it/s] 65%|██████▌   | 326/500 [03:48<01:47,  1.61it/s] 66%|██████▌   | 328/500 [03:48<01:18,  2.20it/s] 66%|██████▌   | 330/500 [03:49<00:57,  2.94it/s] 66%|██████▋   | 332/500 [03:56<03:35,  1.28s/it] 67%|██████▋   | 334/500 [03:56<02:32,  1.09it/s] 67%|██████▋   | 336/500 [03:56<01:48,  1.51it/s] 68%|██████▊   | 338/500 [03:56<01:18,  2.07it/s] 68%|██████▊   | 340/500 [03:56<00:58,  2.75it/s] 68%|██████▊   | 342/500 [04:02<03:11,  1.21s/it] 69%|██████▉   | 344/500 [04:03<02:16,  1.14it/s]Epoch:  278  	Training Loss: 0.002162284217774868
Test Loss:  0.0020992993377149105
Valid Loss:  0.00232747127301991
Epoch:  279  	Training Loss: 0.0021622092463076115
Test Loss:  0.002099227625876665
Valid Loss:  0.0023274002596735954
Epoch:  280  	Training Loss: 0.0021621331106871367
Test Loss:  0.002099159173667431
Valid Loss:  0.002327327150851488
Epoch:  281  	Training Loss: 0.0021620579063892365
Test Loss:  0.0020990960765630007
Valid Loss:  0.0023272549733519554
Epoch:  282  	Training Loss: 0.002161984099075198
Test Loss:  0.0020990297198295593
Valid Loss:  0.002327184658497572
Epoch:  283  	Training Loss: 0.002161906799301505
Test Loss:  0.002098959404975176
Valid Loss:  0.0023271115496754646
Epoch:  284  	Training Loss: 0.0021618339233100414
Test Loss:  0.0020988916512578726
Valid Loss:  0.0023270384408533573
Epoch:  285  	Training Loss: 0.002161758951842785
Test Loss:  0.0020988271571695805
Valid Loss:  0.0023269648663699627
Epoch:  286  	Training Loss: 0.002161683514714241
Test Loss:  0.0020987619645893574
Valid Loss:  0.0023268964141607285
Epoch:  287  	Training Loss: 0.002161609008908272
Test Loss:  0.002098693512380123
Valid Loss:  0.002326823305338621
Epoch:  288  	Training Loss: 0.0021615331061184406
Test Loss:  0.0020986241288483143
Valid Loss:  0.002326750196516514
Epoch:  289  	Training Loss: 0.002161458833143115
Test Loss:  0.0020985601004213095
Valid Loss:  0.002326677553355694
Epoch:  290  	Training Loss: 0.0021613831631839275
Test Loss:  0.0020984956063330173
Valid Loss:  0.0023266070056706667
Epoch:  291  	Training Loss: 0.0021613077260553837
Test Loss:  0.0020984255243092775
Valid Loss:  0.0023265352938324213
Epoch:  292  	Training Loss: 0.0021612343844026327
Test Loss:  0.0020983589347451925
Valid Loss:  0.0023264640476554632
Epoch:  293  	Training Loss: 0.002161158714443445
Test Loss:  0.002098296768963337
Valid Loss:  0.002326390240341425
Epoch:  294  	Training Loss: 0.002161085605621338
Test Loss:  0.0020982290152460337
Valid Loss:  0.002326320856809616
Epoch:  295  	Training Loss: 0.002161010168492794
Test Loss:  0.0020981626585125923
Valid Loss:  0.0023262477479875088
Epoch:  296  	Training Loss: 0.0021609365940093994
Test Loss:  0.0020980946719646454
Valid Loss:  0.002326174871996045
Epoch:  297  	Training Loss: 0.0021608611568808556
Test Loss:  0.0020980339031666517
Valid Loss:  0.002326103625819087
Epoch:  298  	Training Loss: 0.0021607885137200356
Test Loss:  0.002097963821142912
Valid Loss:  0.0023260326124727726
Epoch:  299  	Training Loss: 0.0021607154048979282
Test Loss:  0.0020978995598852634
Valid Loss:  0.002325962297618389
Epoch:  300  	Training Loss: 0.0021606406662613153
Test Loss:  0.002097825985401869
Valid Loss:  0.002325889654457569
Epoch:  301  	Training Loss: 0.0021605677902698517
Test Loss:  0.0020977682434022427
Valid Loss:  0.0023258167784661055
Epoch:  302  	Training Loss: 0.0021604937501251698
Test Loss:  0.0020977011881768703
Valid Loss:  0.0023257480934262276
Epoch:  303  	Training Loss: 0.002160420175641775
Test Loss:  0.0020976332016289234
Valid Loss:  0.0023256775457412004
Epoch:  304  	Training Loss: 0.002160344971343875
Test Loss:  0.002097565680742264
Valid Loss:  0.0023256069980561733
Epoch:  305  	Training Loss: 0.0021602713968604803
Test Loss:  0.0020975000225007534
Valid Loss:  0.002325535286217928
Epoch:  306  	Training Loss: 0.0021601985208690166
Test Loss:  0.0020974345970898867
Valid Loss:  0.0023254621773958206
Epoch:  307  	Training Loss: 0.002160124946385622
Test Loss:  0.002097372431308031
Valid Loss:  0.0023253937251865864
Epoch:  308  	Training Loss: 0.0021600513719022274
Test Loss:  0.002097302582114935
Valid Loss:  0.0023253215476870537
Epoch:  309  	Training Loss: 0.0021599787287414074
Test Loss:  0.00209723855368793
Valid Loss:  0.0023252475075423717
Epoch:  310  	Training Loss: 0.002159903757274151
Test Loss:  0.0020971731282770634
Valid Loss:  0.002325178124010563
Epoch:  311  	Training Loss: 0.002159829717129469
Test Loss:  0.0020971070043742657
Valid Loss:  0.0023251082748174667
Epoch:  312  	Training Loss: 0.002159756375476718
Test Loss:  0.0020970399491488934
Valid Loss:  0.002325036097317934
Epoch:  313  	Training Loss: 0.002159684896469116
Test Loss:  0.0020969780161976814
Valid Loss:  0.002324966248124838
Epoch:  314  	Training Loss: 0.0021596106234937906
Test Loss:  0.0020969128236174583
Valid Loss:  0.002324895467609167
Epoch:  315  	Training Loss: 0.002159539144486189
Test Loss:  0.0020968476310372353
Valid Loss:  0.0023248265497386456
Epoch:  316  	Training Loss: 0.0021594660356640816
Test Loss:  0.002096782438457012
Valid Loss:  0.0023247585631906986
Epoch:  317  	Training Loss: 0.0021593929268419743
Test Loss:  0.0020967156160622835
Valid Loss:  0.0023246859200298786
Epoch:  318  	Training Loss: 0.0021593214478343725
Test Loss:  0.0020966515876352787
Valid Loss:  0.0023246195632964373
Epoch:  319  	Training Loss: 0.0021592474076896906
Test Loss:  0.002096585463732481
Valid Loss:  0.0023245476186275482
Epoch:  320  	Training Loss: 0.0021591740660369396
Test Loss:  0.002096516080200672
Valid Loss:  0.002324477769434452
Epoch:  321  	Training Loss: 0.0021591016557067633
Test Loss:  0.0020964564755558968
Valid Loss:  0.002324404427781701
Epoch:  322  	Training Loss: 0.0021590283140540123
Test Loss:  0.0020963887218385935
Valid Loss:  0.002324339933693409
Epoch:  323  	Training Loss: 0.0021589575335383415
Test Loss:  0.0020963239949196577
Valid Loss:  0.0023242707829922438
Epoch:  324  	Training Loss: 0.002158885821700096
Test Loss:  0.0020962620619684458
Valid Loss:  0.0023241990711539984
Epoch:  325  	Training Loss: 0.002158813178539276
Test Loss:  0.002096199430525303
Valid Loss:  0.0023241343442350626
Epoch:  326  	Training Loss: 0.002158740535378456
Test Loss:  0.0020961323752999306
Valid Loss:  0.002324069384485483
Epoch:  327  	Training Loss: 0.0021586681250482798
Test Loss:  0.002096067648380995
Valid Loss:  0.0023239976726472378
Epoch:  328  	Training Loss: 0.002158595249056816
Test Loss:  0.00209600618109107
Valid Loss:  0.0023239292204380035
Epoch:  329  	Training Loss: 0.0021585249342024326
Test Loss:  0.00209594308398664
Valid Loss:  0.0023238621652126312
Epoch:  330  	Training Loss: 0.002158451359719038
Test Loss:  0.002095879288390279
Valid Loss:  0.0023237892892211676
Epoch:  331  	Training Loss: 0.0021583796478807926
Test Loss:  0.002095811301842332
Valid Loss:  0.0023237208370119333
Epoch:  332  	Training Loss: 0.0021583065390586853
Test Loss:  0.002095753327012062
Valid Loss:  0.0023236479610204697
Epoch:  333  	Training Loss: 0.002158236224204302
Test Loss:  0.0020956839434802532
Valid Loss:  0.0023235813714563847
Epoch:  334  	Training Loss: 0.0021581638138741255
Test Loss:  0.0020956252701580524
Valid Loss:  0.0023235133849084377
Epoch:  335  	Training Loss: 0.0021580930333584547
Test Loss:  0.0020955526269972324
Valid Loss:  0.002323442604392767
Epoch:  336  	Training Loss: 0.0021580210886895657
Test Loss:  0.0020954948849976063
Valid Loss:  0.0023233715910464525
Epoch:  337  	Training Loss: 0.0021579498425126076
Test Loss:  0.002095429925248027
Valid Loss:  0.002323304768651724
Epoch:  338  	Training Loss: 0.0021578771993517876
Test Loss:  0.0020953600760549307
Valid Loss:  0.002323235385119915
Epoch:  339  	Training Loss: 0.002157805487513542
Test Loss:  0.0020953002385795116
Valid Loss:  0.0023231646046042442
Epoch:  340  	Training Loss: 0.002157733542844653
Test Loss:  0.002095236908644438
Valid Loss:  0.0023230963852256536
Epoch:  341  	Training Loss: 0.0021576634608209133
Test Loss:  0.0020951740443706512
Valid Loss:  0.002323028165847063
Epoch:  342  	Training Loss: 0.002157591748982668
Test Loss:  0.002095109550282359
Valid Loss:  0.002322958316653967
Epoch:  343  	Training Loss: 0.002157519804313779
Test Loss:  0.0020950455218553543
Valid Loss:  0.0023228898644447327
Epoch:  344  	Training Loss: 0.0021574494894593954
Test Loss:  0.0020949796307832003
Valid Loss:  0.002322823740541935
Epoch:  345  	Training Loss: 0.002157377079129219
Test Loss:  0.002094920724630356
Valid Loss:  0.0023227562196552753
Epoch:  346  	Training Loss: 0.002157306531444192
Test Loss:  0.0020948529709130526
Valid Loss:   69%|██████▉   | 346/500 [04:03<01:38,  1.57it/s] 70%|██████▉   | 348/500 [04:03<01:11,  2.12it/s] 70%|███████   | 350/500 [04:03<00:53,  2.81it/s] 70%|███████   | 352/500 [04:10<03:02,  1.23s/it] 71%|███████   | 354/500 [04:10<02:09,  1.13it/s] 71%|███████   | 356/500 [04:10<01:33,  1.55it/s] 72%|███████▏  | 358/500 [04:10<01:07,  2.09it/s] 72%|███████▏  | 360/500 [04:10<00:50,  2.78it/s] 72%|███████▏  | 362/500 [04:17<02:46,  1.21s/it] 73%|███████▎  | 364/500 [04:17<01:57,  1.15it/s] 73%|███████▎  | 366/500 [04:17<01:23,  1.60it/s] 74%|███████▎  | 368/500 [04:17<01:00,  2.19it/s] 74%|███████▍  | 370/500 [04:17<00:44,  2.95it/s] 74%|███████▍  | 372/500 [04:24<02:35,  1.21s/it] 75%|███████▍  | 374/500 [04:24<01:49,  1.15it/s] 75%|███████▌  | 376/500 [04:24<01:17,  1.59it/s] 76%|███████▌  | 378/500 [04:24<00:55,  2.18it/s] 76%|███████▌  | 380/500 [04:24<00:40,  2.93it/s] 76%|███████▋  | 382/500 [04:31<02:21,  1.20s/it] 77%|███████▋  | 384/500 [04:31<01:39,  1.16it/s] 77%|███████▋  | 386/500 [04:31<01:10,  1.61it/s] 78%|███████▊  | 388/500 [04:31<00:50,  2.20it/s] 78%|███████▊  | 390/500 [04:31<00:37,  2.96it/s] 78%|███████▊  | 392/500 [04:38<02:09,  1.20s/it] 79%|███████▉  | 394/500 [04:38<01:31,  1.16it/s] 79%|███████▉  | 396/500 [04:38<01:04,  1.61it/s] 80%|███████▉  | 398/500 [04:38<00:46,  2.20it/s] 80%|████████  | 400/500 [04:38<00:33,  2.96it/s] 80%|████████  | 402/500 [04:45<01:57,  1.20s/it] 81%|████████  | 404/500 [04:45<01:22,  1.16it/s] 81%|████████  | 406/500 [04:45<00:58,  1.61it/s] 82%|████████▏ | 408/500 [04:45<00:41,  2.20it/s] 82%|████████▏ | 410/500 [04:45<00:30,  2.95it/s] 82%|████████▏ | 412/500 [04:52<01:45,  1.20s/it] 83%|████████▎ | 414/500 [04:52<01:13,  1.16it/s]0.0023226875346153975
Epoch:  347  	Training Loss: 0.0021572348196059465
Test Loss:  0.002094794064760208
Valid Loss:  0.0023226160556077957
Epoch:  348  	Training Loss: 0.002157165203243494
Test Loss:  0.0020947307348251343
Valid Loss:  0.002322552725672722
Epoch:  349  	Training Loss: 0.002157093258574605
Test Loss:  0.002094665542244911
Valid Loss:  0.0023224831093102694
Epoch:  350  	Training Loss: 0.0021570229437202215
Test Loss:  0.002094605937600136
Valid Loss:  0.0023224116303026676
Epoch:  351  	Training Loss: 0.002156951930373907
Test Loss:  0.0020945370197296143
Valid Loss:  0.0023223450407385826
Epoch:  352  	Training Loss: 0.0021568797528743744
Test Loss:  0.0020944755524396896
Valid Loss:  0.002322277519851923
Epoch:  353  	Training Loss: 0.0021568099036812782
Test Loss:  0.0020944089628756046
Valid Loss:  0.0023222039453685284
Epoch:  354  	Training Loss: 0.002156739355996251
Test Loss:  0.0020943493582308292
Valid Loss:  0.002322134096175432
Epoch:  355  	Training Loss: 0.0021566683426499367
Test Loss:  0.0020942888222634792
Valid Loss:  0.002322068903595209
Epoch:  356  	Training Loss: 0.002156597562134266
Test Loss:  0.0020942213013768196
Valid Loss:  0.002322000917047262
Epoch:  357  	Training Loss: 0.0021565272472798824
Test Loss:  0.0020941593684256077
Valid Loss:  0.002321929670870304
Epoch:  358  	Training Loss: 0.0021564564667642117
Test Loss:  0.0020940969698131084
Valid Loss:  0.002321861684322357
Epoch:  359  	Training Loss: 0.002156386384740472
Test Loss:  0.0020940315444022417
Valid Loss:  0.0023217974230647087
Epoch:  360  	Training Loss: 0.0021563158370554447
Test Loss:  0.002093970077112317
Valid Loss:  0.002321721753105521
Epoch:  361  	Training Loss: 0.002156245056539774
Test Loss:  0.0020939079113304615
Valid Loss:  0.002321657259017229
Epoch:  362  	Training Loss: 0.0021561733447015285
Test Loss:  0.002093840390443802
Valid Loss:  0.002321588806807995
Epoch:  363  	Training Loss: 0.0021561041940003633
Test Loss:  0.0020937793888151646
Valid Loss:  0.0023215196561068296
Epoch:  364  	Training Loss: 0.0021560336463153362
Test Loss:  0.002093719784170389
Valid Loss:  0.0023214532993733883
Epoch:  365  	Training Loss: 0.0021559628657996655
Test Loss:  0.002093654591590166
Valid Loss:  0.002321387641131878
Epoch:  366  	Training Loss: 0.0021558934822678566
Test Loss:  0.002093588700518012
Valid Loss:  0.002321322215721011
Epoch:  367  	Training Loss: 0.002155822468921542
Test Loss:  0.0020935272332280874
Valid Loss:  0.0023212535306811333
Epoch:  368  	Training Loss: 0.0021557535510510206
Test Loss:  0.0020934692583978176
Valid Loss:  0.002321186475455761
Epoch:  369  	Training Loss: 0.0021556823048740625
Test Loss:  0.002093402436003089
Valid Loss:  0.0023211180232465267
Epoch:  370  	Training Loss: 0.002155613387003541
Test Loss:  0.002093341201543808
Valid Loss:  0.0023210488725453615
Epoch:  371  	Training Loss: 0.0021555423736572266
Test Loss:  0.0020932808984071016
Valid Loss:  0.002320982748642564
Epoch:  372  	Training Loss: 0.0021554732229560614
Test Loss:  0.0020932122133672237
Valid Loss:  0.002320917323231697
Epoch:  373  	Training Loss: 0.0021554038394242525
Test Loss:  0.0020931551698595285
Valid Loss:  0.0023208502680063248
Epoch:  374  	Training Loss: 0.002155333524569869
Test Loss:  0.0020930925384163857
Valid Loss:  0.0023207836784422398
Epoch:  375  	Training Loss: 0.0021552639082074165
Test Loss:  0.002093029208481312
Valid Loss:  0.002320716856047511
Epoch:  376  	Training Loss: 0.002155194990336895
Test Loss:  0.002092968672513962
Valid Loss:  0.0023206500336527824
Epoch:  377  	Training Loss: 0.0021551253739744425
Test Loss:  0.0020929058082401752
Valid Loss:  0.00232058297842741
Epoch:  378  	Training Loss: 0.0021550569217652082
Test Loss:  0.0020928415469825268
Valid Loss:  0.0023205161560326815
Epoch:  379  	Training Loss: 0.0021549861412495375
Test Loss:  0.0020927810110151768
Valid Loss:  0.0023204474709928036
Epoch:  380  	Training Loss: 0.0021549169905483723
Test Loss:  0.002092719078063965
Valid Loss:  0.0023203836753964424
Epoch:  381  	Training Loss: 0.0021548476070165634
Test Loss:  0.0020926548168063164
Valid Loss:  0.002320314757525921
Epoch:  382  	Training Loss: 0.002154775895178318
Test Loss:  0.002092595910653472
Valid Loss:  0.002320249332115054
Epoch:  383  	Training Loss: 0.0021547102369368076
Test Loss:  0.002092531882226467
Valid Loss:  0.00232018087990582
Epoch:  384  	Training Loss: 0.002154639456421137
Test Loss:  0.0020924757700413465
Valid Loss:  0.0023201173171401024
Epoch:  385  	Training Loss: 0.0021545710042119026
Test Loss:  0.00209241290576756
Valid Loss:  0.002320048399269581
Epoch:  386  	Training Loss: 0.0021545018535107374
Test Loss:  0.0020923481788486242
Valid Loss:  0.0023199841380119324
Epoch:  387  	Training Loss: 0.0021544331684708595
Test Loss:  0.0020922902040183544
Valid Loss:  0.0023199180141091347
Epoch:  388  	Training Loss: 0.0021543644834309816
Test Loss:  0.002092227339744568
Valid Loss:  0.002319851191714406
Epoch:  389  	Training Loss: 0.002154294867068529
Test Loss:  0.002092160750180483
Valid Loss:  0.002319785999134183
Epoch:  390  	Training Loss: 0.002154225716367364
Test Loss:  0.0020921058021485806
Valid Loss:  0.0023197182454168797
Epoch:  391  	Training Loss: 0.002154155168682337
Test Loss:  0.002092036884278059
Valid Loss:  0.0023196530528366566
Epoch:  392  	Training Loss: 0.00215408718213439
Test Loss:  0.002091976348310709
Valid Loss:  0.0023195864632725716
Epoch:  393  	Training Loss: 0.002154018497094512
Test Loss:  0.0020919176749885082
Valid Loss:  0.002319520805031061
Epoch:  394  	Training Loss: 0.0021539507433772087
Test Loss:  0.00209185597486794
Valid Loss:  0.0023194528184831142
Epoch:  395  	Training Loss: 0.0021538808941841125
Test Loss:  0.0020917903166264296
Valid Loss:  0.002319389721378684
Epoch:  396  	Training Loss: 0.002153812674805522
Test Loss:  0.0020917346701025963
Valid Loss:  0.002319322433322668
Epoch:  397  	Training Loss: 0.002153744688257575
Test Loss:  0.002091673668473959
Valid Loss:  0.0023192577064037323
Epoch:  398  	Training Loss: 0.0021536764688789845
Test Loss:  0.0020916154608130455
Valid Loss:  0.002319192513823509
Epoch:  399  	Training Loss: 0.0021536063868552446
Test Loss:  0.002091552596539259
Valid Loss:  0.0023191289510577917
Epoch:  400  	Training Loss: 0.002153538167476654
Test Loss:  0.002091487869620323
Valid Loss:  0.0023190616630017757
Epoch:  401  	Training Loss: 0.002153468783944845
Test Loss:  0.002091429429128766
Valid Loss:  0.0023189957719296217
Epoch:  402  	Training Loss: 0.0021534007973968983
Test Loss:  0.0020913714542984962
Valid Loss:  0.002318926155567169
Epoch:  403  	Training Loss: 0.0021533328108489513
Test Loss:  0.0020913048647344112
Valid Loss:  0.002318859566003084
Epoch:  404  	Training Loss: 0.0021532652899622917
Test Loss:  0.002091249218210578
Valid Loss:  0.002318788319826126
Epoch:  405  	Training Loss: 0.00215319637209177
Test Loss:  0.0020911835599690676
Valid Loss:  0.002318726386874914
Epoch:  406  	Training Loss: 0.002153129316866398
Test Loss:  0.002091125352308154
Valid Loss:  0.0023186556063592434
Epoch:  407  	Training Loss: 0.0021530594676733017
Test Loss:  0.0020910610910505056
Valid Loss:  0.002318591345101595
Epoch:  408  	Training Loss: 0.0021529924124479294
Test Loss:  0.0020909947343170643
Valid Loss:  0.0023185256868600845
Epoch:  409  	Training Loss: 0.002152924193069339
Test Loss:  0.0020909383893013
Valid Loss:  0.0023184544406831264
Epoch:  410  	Training Loss: 0.002152855973690748
Test Loss:  0.002090876456350088
Valid Loss:  0.002318394836038351
Epoch:  411  	Training Loss: 0.0021527872886508703
Test Loss:  0.0020908173173666
Valid Loss:  0.0023183252196758986
Epoch:  412  	Training Loss: 0.0021527204662561417
Test Loss:  0.002090754918754101
Valid Loss:  0.0023182604927569628
Epoch:  413  	Training Loss: 0.00215265154838562
Test Loss:  0.0020906911231577396
Valid Loss:  0.0023181953001767397
Epoch:  414  	Training Loss: 0.0021525833290070295
Test Loss:  0.002090635010972619
Valid Loss:  0.0023181310389190912
Epoch:  415  	Training Loss: 0.0021525153424590826
Test Loss:  0.002090572379529476
Valid Loss:   83%|████████▎ | 416/500 [04:52<00:52,  1.61it/s] 84%|████████▎ | 418/500 [04:52<00:37,  2.20it/s] 84%|████████▍ | 420/500 [04:52<00:26,  2.97it/s] 84%|████████▍ | 422/500 [04:59<01:34,  1.21s/it] 85%|████████▍ | 424/500 [04:59<01:05,  1.15it/s] 85%|████████▌ | 426/500 [04:59<00:46,  1.59it/s] 86%|████████▌ | 428/500 [04:59<00:33,  2.18it/s] 86%|████████▌ | 430/500 [04:59<00:23,  2.93it/s] 86%|████████▋ | 432/500 [05:05<01:20,  1.19s/it] 87%|████████▋ | 434/500 [05:06<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:06<00:39,  1.60it/s] 88%|████████▊ | 438/500 [05:06<00:28,  2.16it/s] 88%|████████▊ | 440/500 [05:06<00:20,  2.87it/s] 88%|████████▊ | 442/500 [05:13<01:09,  1.20s/it] 89%|████████▉ | 444/500 [05:13<00:48,  1.16it/s] 89%|████████▉ | 446/500 [05:13<00:33,  1.61it/s] 90%|████████▉ | 448/500 [05:13<00:23,  2.18it/s] 90%|█████████ | 450/500 [05:13<00:17,  2.92it/s] 90%|█████████ | 452/500 [05:20<00:58,  1.21s/it] 91%|█████████ | 454/500 [05:20<00:40,  1.14it/s] 91%|█████████ | 456/500 [05:20<00:28,  1.57it/s] 92%|█████████▏| 458/500 [05:20<00:19,  2.12it/s] 92%|█████████▏| 460/500 [05:20<00:14,  2.81it/s] 92%|█████████▏| 462/500 [05:27<00:48,  1.27s/it] 93%|█████████▎| 464/500 [05:27<00:32,  1.10it/s] 93%|█████████▎| 466/500 [05:27<00:22,  1.51it/s] 94%|█████████▎| 468/500 [05:28<00:15,  2.04it/s] 94%|█████████▍| 470/500 [05:28<00:11,  2.72it/s] 94%|█████████▍| 472/500 [05:34<00:33,  1.21s/it] 95%|█████████▍| 474/500 [05:34<00:22,  1.15it/s] 95%|█████████▌| 476/500 [05:34<00:15,  1.59it/s] 96%|█████████▌| 478/500 [05:34<00:10,  2.18it/s] 96%|█████████▌| 480/500 [05:35<00:06,  2.93it/s] 96%|█████████▋| 482/500 [05:41<00:21,  1.21s/it]0.0023180635180324316
Epoch:  416  	Training Loss: 0.002152447123080492
Test Loss:  0.00209051207639277
Valid Loss:  0.0023179990239441395
Epoch:  417  	Training Loss: 0.0021523796021938324
Test Loss:  0.0020904531702399254
Valid Loss:  0.0023179366253316402
Epoch:  418  	Training Loss: 0.0021523130126297474
Test Loss:  0.002090388908982277
Valid Loss:  0.0023178700357675552
Epoch:  419  	Training Loss: 0.0021522457245737314
Test Loss:  0.0020903339609503746
Valid Loss:  0.002317806240171194
Epoch:  420  	Training Loss: 0.0021521770395338535
Test Loss:  0.0020902701653540134
Valid Loss:  0.0023177426774054766
Epoch:  421  	Training Loss: 0.002152107423171401
Test Loss:  0.002090213354676962
Valid Loss:  0.0023176756221801043
Epoch:  422  	Training Loss: 0.002152041532099247
Test Loss:  0.0020901476964354515
Valid Loss:  0.002317610662430525
Epoch:  423  	Training Loss: 0.0021519737783819437
Test Loss:  0.0020900908857584
Valid Loss:  0.0023175436072051525
Epoch:  424  	Training Loss: 0.0021519060246646404
Test Loss:  0.002090027555823326
Valid Loss:  0.00231748353689909
Epoch:  425  	Training Loss: 0.00215184036642313
Test Loss:  0.0020899674855172634
Valid Loss:  0.002317418111488223
Epoch:  426  	Training Loss: 0.002151773078367114
Test Loss:  0.0020899127703160048
Valid Loss:  0.0023173531517386436
Epoch:  427  	Training Loss: 0.002151705091819167
Test Loss:  0.0020898478105664253
Valid Loss:  0.0023172867950052023
Epoch:  428  	Training Loss: 0.002151638735085726
Test Loss:  0.0020897933281958103
Valid Loss:  0.002317223232239485
Epoch:  429  	Training Loss: 0.00215157144702971
Test Loss:  0.0020897281356155872
Valid Loss:  0.0023171589709818363
Epoch:  430  	Training Loss: 0.0021515036933124065
Test Loss:  0.0020896741189062595
Valid Loss:  0.0023170930799096823
Epoch:  431  	Training Loss: 0.002151436870917678
Test Loss:  0.002089608693495393
Valid Loss:  0.0023170295171439648
Epoch:  432  	Training Loss: 0.0021513691172003746
Test Loss:  0.002089552115648985
Valid Loss:  0.0023169629275798798
Epoch:  433  	Training Loss: 0.002151303458958864
Test Loss:  0.0020894911140203476
Valid Loss:  0.002316902857273817
Epoch:  434  	Training Loss: 0.002151236869394779
Test Loss:  0.0020894277840852737
Valid Loss:  0.002316834405064583
Epoch:  435  	Training Loss: 0.0021511681843549013
Test Loss:  0.002089371904730797
Valid Loss:  0.0023167715407907963
Epoch:  436  	Training Loss: 0.0021511020604521036
Test Loss:  0.0020893116015940905
Valid Loss:  0.002316707745194435
Epoch:  437  	Training Loss: 0.002151035936549306
Test Loss:  0.0020892522297799587
Valid Loss:  0.002316639292985201
Epoch:  438  	Training Loss: 0.0021509691141545773
Test Loss:  0.0020891905296593904
Valid Loss:  0.0023165778256952763
Epoch:  439  	Training Loss: 0.0021509015932679176
Test Loss:  0.0020891318563371897
Valid Loss:  0.0023165105376392603
Epoch:  440  	Training Loss: 0.002150834072381258
Test Loss:  0.002089068992063403
Valid Loss:  0.0023164472077041864
Epoch:  441  	Training Loss: 0.0021507670171558857
Test Loss:  0.002089011250063777
Valid Loss:  0.0023163817822933197
Epoch:  442  	Training Loss: 0.0021507004275918007
Test Loss:  0.0020889476872980595
Valid Loss:  0.0023163212463259697
Epoch:  443  	Training Loss: 0.0021506338380277157
Test Loss:  0.0020888918079435825
Valid Loss:  0.0023162588477134705
Epoch:  444  	Training Loss: 0.0021505660843104124
Test Loss:  0.0020888345316052437
Valid Loss:  0.00231619318947196
Epoch:  445  	Training Loss: 0.0021505006588995457
Test Loss:  0.0020887735299766064
Valid Loss:  0.00231613265350461
Epoch:  446  	Training Loss: 0.0021504347678273916
Test Loss:  0.0020887132268399
Valid Loss:  0.0023160665296018124
Epoch:  447  	Training Loss: 0.0021503688767552376
Test Loss:  0.0020886543206870556
Valid Loss:  0.002316004829481244
Epoch:  448  	Training Loss: 0.0021503018215298653
Test Loss:  0.0020885944832116365
Valid Loss:  0.0023159398697316647
Epoch:  449  	Training Loss: 0.002150235464796424
Test Loss:  0.002088538371026516
Valid Loss:  0.0023158772382885218
Epoch:  450  	Training Loss: 0.0021501684095710516
Test Loss:  0.0020884780678898096
Valid Loss:  0.0023158174008131027
Epoch:  451  	Training Loss: 0.002150104148313403
Test Loss:  0.002088419161736965
Valid Loss:  0.0023157522082328796
Epoch:  452  	Training Loss: 0.002150035696104169
Test Loss:  0.002088358858600259
Valid Loss:  0.0023156870156526566
Epoch:  453  	Training Loss: 0.002149969572201371
Test Loss:  0.0020882957614958286
Valid Loss:  0.0023156253155320883
Epoch:  454  	Training Loss: 0.0021499022841453552
Test Loss:  0.0020882426761090755
Valid Loss:  0.002315564313903451
Epoch:  455  	Training Loss: 0.002149836625903845
Test Loss:  0.002088181208819151
Valid Loss:  0.0023154993541538715
Epoch:  456  	Training Loss: 0.002149771898984909
Test Loss:  0.0020881241653114557
Valid Loss:  0.002315436489880085
Epoch:  457  	Training Loss: 0.002149706007912755
Test Loss:  0.002088063396513462
Valid Loss:  0.002315373159945011
Epoch:  458  	Training Loss: 0.0021496391855180264
Test Loss:  0.00208800146356225
Valid Loss:  0.0023153075017035007
Epoch:  459  	Training Loss: 0.0021495744585990906
Test Loss:  0.0020879486110061407
Valid Loss:  0.002315241377800703
Epoch:  460  	Training Loss: 0.0021495074033737183
Test Loss:  0.0020878855139017105
Valid Loss:  0.002315180841833353
Epoch:  461  	Training Loss: 0.0021494398824870586
Test Loss:  0.002087830100208521
Valid Loss:  0.0023151144850999117
Epoch:  462  	Training Loss: 0.002149375155568123
Test Loss:  0.0020877693314105272
Valid Loss:  0.0023150555789470673
Epoch:  463  	Training Loss: 0.002149310428649187
Test Loss:  0.0020877132192254066
Valid Loss:  0.0023149889893829823
Epoch:  464  	Training Loss: 0.0021492429077625275
Test Loss:  0.0020876522175967693
Valid Loss:  0.0023149296175688505
Epoch:  465  	Training Loss: 0.002149177948012948
Test Loss:  0.002087594708427787
Valid Loss:  0.002314864657819271
Epoch:  466  	Training Loss: 0.0021491115912795067
Test Loss:  0.002087533939629793
Valid Loss:  0.0023148052860051394
Epoch:  467  	Training Loss: 0.0021490477956831455
Test Loss:  0.0020874738693237305
Valid Loss:  0.002314737532287836
Epoch:  468  	Training Loss: 0.002148981671780348
Test Loss:  0.002087412402033806
Valid Loss:  0.0023146746680140495
Epoch:  469  	Training Loss: 0.0021489153150469065
Test Loss:  0.002087357919663191
Valid Loss:  0.002314612502232194
Epoch:  470  	Training Loss: 0.0021488508209586143
Test Loss:  0.0020872983150184155
Valid Loss:  0.00231454661116004
Epoch:  471  	Training Loss: 0.002148783067241311
Test Loss:  0.0020872417371720076
Valid Loss:  0.0023144870065152645
Epoch:  472  	Training Loss: 0.002148718573153019
Test Loss:  0.00208717817440629
Valid Loss:  0.002314423443749547
Epoch:  473  	Training Loss: 0.002148653846234083
Test Loss:  0.002087126951664686
Valid Loss:  0.0023143624421209097
Epoch:  474  	Training Loss: 0.00214858865365386
Test Loss:  0.002087061293423176
Valid Loss:  0.0023142986465245485
Epoch:  475  	Training Loss: 0.0021485211327672005
Test Loss:  0.0020870037842541933
Valid Loss:  0.0023142353165894747
Epoch:  476  	Training Loss: 0.0021484573371708393
Test Loss:  0.0020869493018835783
Valid Loss:  0.0023141754791140556
Epoch:  477  	Training Loss: 0.00214839237742126
Test Loss:  0.0020868873689323664
Valid Loss:  0.002314109355211258
Epoch:  478  	Training Loss: 0.002148325089365244
Test Loss:  0.0020868314895778894
Valid Loss:  0.0023140469565987587
Epoch:  479  	Training Loss: 0.002148259896785021
Test Loss:  0.002086772583425045
Valid Loss:  0.002313983626663685
Epoch:  480  	Training Loss: 0.002148196566849947
Test Loss:  0.0020867171697318554
Valid Loss:  0.0023139184340834618
Epoch:  481  	Training Loss: 0.0021481295116245747
Test Loss:  0.0020866533741354942
Valid Loss:  0.0023138616234064102
Epoch:  482  	Training Loss: 0.0021480643190443516
Test Loss:  0.002086600521579385
Valid Loss:  0.0023137943353503942
Epoch:  483  	Training Loss: 0.002148000756278634
Test Loss:  0.0020865367259830236
Valid Loss:  0.002313737291842699
Epoch:  484  	Training Loss: 0.0021479357965290546
Test Loss:  0.0020864822436124086
Valid Loss:   97%|█████████▋| 484/500 [05:41<00:13,  1.15it/s] 97%|█████████▋| 486/500 [05:41<00:08,  1.59it/s] 98%|█████████▊| 488/500 [05:41<00:05,  2.18it/s] 98%|█████████▊| 490/500 [05:42<00:03,  2.93it/s] 98%|█████████▊| 492/500 [05:48<00:09,  1.21s/it] 99%|█████████▉| 494/500 [05:48<00:05,  1.16it/s] 99%|█████████▉| 496/500 [05:48<00:02,  1.60it/s]100%|█████████▉| 498/500 [05:48<00:00,  2.19it/s]100%|██████████| 500/500 [05:49<00:00,  2.94it/s]100%|██████████| 500/500 [05:49<00:00,  1.43it/s]
0.0023136711679399014
Epoch:  485  	Training Loss: 0.002147869672626257
Test Loss:  0.002086423337459564
Valid Loss:  0.0023136099334806204
Epoch:  486  	Training Loss: 0.002147804945707321
Test Loss:  0.0020863669924438
Valid Loss:  0.0023135459050536156
Epoch:  487  	Training Loss: 0.0021477409172803164
Test Loss:  0.0020863115787506104
Valid Loss:  0.002313487231731415
Epoch:  488  	Training Loss: 0.0021476750262081623
Test Loss:  0.002086248015984893
Valid Loss:  0.0023134215734899044
Epoch:  489  	Training Loss: 0.002147610066458583
Test Loss:  0.002086196793243289
Valid Loss:  0.002313358709216118
Epoch:  490  	Training Loss: 0.0021475469693541527
Test Loss:  0.0020861346274614334
Valid Loss:  0.002313295379281044
Epoch:  491  	Training Loss: 0.0021474803797900677
Test Loss:  0.0020860752556473017
Valid Loss:  0.0023132357746362686
Epoch:  492  	Training Loss: 0.0021474165841937065
Test Loss:  0.0020860203076153994
Valid Loss:  0.0023131701163947582
Epoch:  493  	Training Loss: 0.0021473513916134834
Test Loss:  0.002085962099954486
Valid Loss:  0.0023131079506129026
Epoch:  494  	Training Loss: 0.0021472868975251913
Test Loss:  0.002085902262479067
Valid Loss:  0.0023130448535084724
Epoch:  495  	Training Loss: 0.0021472210064530373
Test Loss:  0.0020858407951891422
Valid Loss:  0.002312984550371766
Epoch:  496  	Training Loss: 0.0021471581421792507
Test Loss:  0.00208578584715724
Valid Loss:  0.0023129195906221867
Epoch:  497  	Training Loss: 0.0021470915526151657
Test Loss:  0.00208572787232697
Valid Loss:  0.0023128592874854803
Epoch:  498  	Training Loss: 0.00214702682569623
Test Loss:  0.002085670130327344
Valid Loss:  0.002312798285856843
Epoch:  499  	Training Loss: 0.0021469625644385815
Test Loss:  0.0020856133196502924
Valid Loss:  0.0023127300664782524
Epoch:  500  	Training Loss: 0.0021468978375196457
Test Loss:  0.0020855527836829424
Valid Loss:  0.0023126709274947643
seed is  5
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:30,  6.31s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:48,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:20<09:43,  1.22s/it]  5%|▍         | 23/500 [00:20<06:54,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:26<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:41,  1.16it/s]  7%|▋         | 35/500 [00:27<04:51,  1.59it/s]  7%|▋         | 37/500 [00:27<03:35,  2.15it/s]  8%|▊         | 39/500 [00:27<02:41,  2.85it/s]  8%|▊         | 41/500 [00:34<09:19,  1.22s/it]  9%|▊         | 43/500 [00:34<06:39,  1.14it/s]  9%|▉         | 45/500 [00:34<04:47,  1.58it/s]  9%|▉         | 47/500 [00:34<03:29,  2.17it/s] 10%|▉         | 49/500 [00:34<02:34,  2.92it/s] 10%|█         | 51/500 [00:41<08:55,  1.19s/it] 11%|█         | 53/500 [00:41<06:22,  1.17it/s] 11%|█         | 55/500 [00:41<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.90it/s] 12%|█▏        | 61/500 [00:48<08:51,  1.21s/it] 13%|█▎        | 63/500 [00:48<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:48<03:18,  2.18it/s] 14%|█▍        | 69/500 [00:48<02:28,  2.90it/s]Epoch:  1  	Training Loss: 0.18019041419029236
Test Loss:  0.15103566646575928
Valid Loss:  0.1455388069152832
Epoch:  2  	Training Loss: 0.11130295693874359
Test Loss:  0.11439403891563416
Valid Loss:  0.1114099770784378
Epoch:  3  	Training Loss: 0.08309109508991241
Test Loss:  0.09278757870197296
Valid Loss:  0.09139393270015717
Epoch:  4  	Training Loss: 0.06709568202495575
Test Loss:  0.07631261646747589
Valid Loss:  0.076151542365551
Epoch:  5  	Training Loss: 0.05528790131211281
Test Loss:  0.06363071501255035
Valid Loss:  0.0643981322646141
Epoch:  6  	Training Loss: 0.04644583910703659
Test Loss:  0.053746215999126434
Valid Loss:  0.055172331631183624
Epoch:  7  	Training Loss: 0.039695076644420624
Test Loss:  0.04597984999418259
Valid Loss:  0.04783646762371063
Epoch:  8  	Training Loss: 0.03447866439819336
Test Loss:  0.039770226925611496
Valid Loss:  0.04196754842996597
Epoch:  9  	Training Loss: 0.030426429584622383
Test Loss:  0.03474115580320358
Valid Loss:  0.03720828518271446
Epoch:  10  	Training Loss: 0.027239931747317314
Test Loss:  0.030691027641296387
Valid Loss:  0.033283185213804245
Epoch:  11  	Training Loss: 0.024672601372003555
Test Loss:  0.027306830510497093
Valid Loss:  0.030029350891709328
Epoch:  12  	Training Loss: 0.022599298506975174
Test Loss:  0.022390421479940414
Valid Loss:  0.02508581429719925
Epoch:  13  	Training Loss: 0.01921253278851509
Test Loss:  0.01951252855360508
Valid Loss:  0.021914366632699966
Epoch:  14  	Training Loss: 0.0168084017932415
Test Loss:  0.0172390379011631
Valid Loss:  0.019398588687181473
Epoch:  15  	Training Loss: 0.015008280985057354
Test Loss:  0.015052802860736847
Valid Loss:  0.017110969871282578
Epoch:  16  	Training Loss: 0.013534593395888805
Test Loss:  0.013393737375736237
Valid Loss:  0.015259664505720139
Epoch:  17  	Training Loss: 0.012307337485253811
Test Loss:  0.012056147679686546
Valid Loss:  0.013680877164006233
Epoch:  18  	Training Loss: 0.011255682446062565
Test Loss:  0.010846320539712906
Valid Loss:  0.012299548834562302
Epoch:  19  	Training Loss: 0.010329848155379295
Test Loss:  0.009843390434980392
Valid Loss:  0.011099554598331451
Epoch:  20  	Training Loss: 0.00951045285910368
Test Loss:  0.008954343385994434
Valid Loss:  0.0100427670404315
Epoch:  21  	Training Loss: 0.008778227493166924
Test Loss:  0.008170035667717457
Valid Loss:  0.009107640013098717
Epoch:  22  	Training Loss: 0.008121049031615257
Test Loss:  0.0075261760503053665
Valid Loss:  0.008530361577868462
Epoch:  23  	Training Loss: 0.007805004715919495
Test Loss:  0.007236558012664318
Valid Loss:  0.008233536966145039
Epoch:  24  	Training Loss: 0.00761420326307416
Test Loss:  0.007006760686635971
Valid Loss:  0.007984321564435959
Epoch:  25  	Training Loss: 0.007451621349900961
Test Loss:  0.006802277639508247
Valid Loss:  0.007761179935187101
Epoch:  26  	Training Loss: 0.007307686842978001
Test Loss:  0.006623611785471439
Valid Loss:  0.00755726732313633
Epoch:  27  	Training Loss: 0.007176952436566353
Test Loss:  0.006455989088863134
Valid Loss:  0.0073723746463656425
Epoch:  28  	Training Loss: 0.00705538596957922
Test Loss:  0.006306051276624203
Valid Loss:  0.007204683963209391
Epoch:  29  	Training Loss: 0.006941286381334066
Test Loss:  0.006167392246425152
Valid Loss:  0.007050198502838612
Epoch:  30  	Training Loss: 0.006833367981016636
Test Loss:  0.006041390355676413
Valid Loss:  0.006906109396368265
Epoch:  31  	Training Loss: 0.0067288680002093315
Test Loss:  0.0059274365194141865
Valid Loss:  0.006772320251911879
Epoch:  32  	Training Loss: 0.006628116127103567
Test Loss:  0.00527935428544879
Valid Loss:  0.0060819778591394424
Epoch:  33  	Training Loss: 0.006155573297291994
Test Loss:  0.004846461117267609
Valid Loss:  0.00560653954744339
Epoch:  34  	Training Loss: 0.005791147239506245
Test Loss:  0.0045485300943255424
Valid Loss:  0.005256461910903454
Epoch:  35  	Training Loss: 0.005503277759999037
Test Loss:  0.004320465959608555
Valid Loss:  0.004976687021553516
Epoch:  36  	Training Loss: 0.0052578747272491455
Test Loss:  0.0041153826750814915
Valid Loss:  0.00472148135304451
Epoch:  37  	Training Loss: 0.005031514912843704
Test Loss:  0.003926481585949659
Valid Loss:  0.004482427146285772
Epoch:  38  	Training Loss: 0.0048192525282502174
Test Loss:  0.0037482953630387783
Valid Loss:  0.00425652926787734
Epoch:  39  	Training Loss: 0.0046183867380023
Test Loss:  0.0035794456489384174
Valid Loss:  0.004043397027999163
Epoch:  40  	Training Loss: 0.004427695646882057
Test Loss:  0.00341937318444252
Valid Loss:  0.003842070000246167
Epoch:  41  	Training Loss: 0.004246331751346588
Test Loss:  0.0032676593400537968
Valid Loss:  0.0036516739055514336
Epoch:  42  	Training Loss: 0.004073975142091513
Test Loss:  0.003175383200868964
Valid Loss:  0.0034601930528879166
Epoch:  43  	Training Loss: 0.0038930331356823444
Test Loss:  0.0029982044361531734
Valid Loss:  0.0032249637879431248
Epoch:  44  	Training Loss: 0.003705813316628337
Test Loss:  0.002840273082256317
Valid Loss:  0.0030247760005295277
Epoch:  45  	Training Loss: 0.003545147366821766
Test Loss:  0.0026977378875017166
Valid Loss:  0.0028488249517977238
Epoch:  46  	Training Loss: 0.00340077793225646
Test Loss:  0.0025689697358757257
Valid Loss:  0.0026921434327960014
Epoch:  47  	Training Loss: 0.0032689247746020555
Test Loss:  0.0024519506841897964
Valid Loss:  0.0025504014920443296
Epoch:  48  	Training Loss: 0.0031477254815399647
Test Loss:  0.0023466465063393116
Valid Loss:  0.0024225462693721056
Epoch:  49  	Training Loss: 0.0030360855162143707
Test Loss:  0.002250279998406768
Valid Loss:  0.002306169830262661
Epoch:  50  	Training Loss: 0.002933097304776311
Test Loss:  0.0021623442880809307
Valid Loss:  0.0022016800940036774
Epoch:  51  	Training Loss: 0.0028384693432599306
Test Loss:  0.002084416337311268
Valid Loss:  0.002108541550114751
Epoch:  52  	Training Loss: 0.0027520647272467613
Test Loss:  0.0020745997317135334
Valid Loss:  0.002003191038966179
Epoch:  53  	Training Loss: 0.002566481474786997
Test Loss:  0.0018722685053944588
Valid Loss:  0.001840009936131537
Epoch:  54  	Training Loss: 0.0024144314229488373
Test Loss:  0.0017390178982168436
Valid Loss:  0.0017177738482132554
Epoch:  55  	Training Loss: 0.0022931648418307304
Test Loss:  0.0016328198835253716
Valid Loss:  0.0016128498828038573
Epoch:  56  	Training Loss: 0.00218529743142426
Test Loss:  0.001544755301438272
Valid Loss:  0.001521256286650896
Epoch:  57  	Training Loss: 0.0020883972756564617
Test Loss:  0.0014688598457723856
Valid Loss:  0.0014418481150642037
Epoch:  58  	Training Loss: 0.002000960987061262
Test Loss:  0.0013997671194374561
Valid Loss:  0.0013730654027312994
Epoch:  59  	Training Loss: 0.0019203675910830498
Test Loss:  0.0013393010012805462
Valid Loss:  0.0013115403708070517
Epoch:  60  	Training Loss: 0.0018456405960023403
Test Loss:  0.0012833635555580258
Valid Loss:  0.0012548977974802256
Epoch:  61  	Training Loss: 0.0017768058460205793
Test Loss:  0.001232171431183815
Valid Loss:  0.0012026994954794645
Epoch:  62  	Training Loss: 0.0017119625117629766
Test Loss:  0.0012485722545534372
Valid Loss:  0.0011538569815456867
Epoch:  63  	Training Loss: 0.001640868023969233
Test Loss:  0.0012360629625618458
Valid Loss:  0.0011100971605628729
Epoch:  64  	Training Loss: 0.0015860965941101313
Test Loss:  0.0012097156140953302
Valid Loss:  0.001069935504347086
Epoch:  65  	Training Loss: 0.0015385475708171725
Test Loss:  0.0011763193178921938
Valid Loss:  0.0010322672314941883
Epoch:  66  	Training Loss: 0.0014949364122003317
Test Loss:  0.0011427265126258135
Valid Loss:  0.0009973027044907212
Epoch:  67  	Training Loss: 0.0014544465811923146
Test Loss:  0.001112573896534741
Valid Loss:  0.0009654310997575521
Epoch:  68  	Training Loss: 0.0014170368667691946
Test Loss:  0.0010798684088513255
Valid Loss:  0.0009365071309730411
Epoch:  69  	Training Loss: 0.0013820950407534838
Test Loss:  0.001048667123541236
Valid Loss:  0.0009096662979573011
Epoch:  70  	Training Loss: 0.0013495960738509893
Test Loss:  0.0010194429196417332
Valid Loss:  0.0008843665709719062
Epoch:  71  	Training Loss: 0.0013191502075642347
 14%|█▍        | 71/500 [00:55<08:37,  1.21s/it] 15%|█▍        | 73/500 [00:55<06:09,  1.15it/s] 15%|█▌        | 75/500 [00:55<04:26,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:15,  2.17it/s] 16%|█▌        | 79/500 [00:55<02:24,  2.92it/s] 16%|█▌        | 81/500 [01:02<08:23,  1.20s/it] 17%|█▋        | 83/500 [01:02<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:09<08:14,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:53,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:14,  1.59it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.18it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.93it/s] 20%|██        | 101/500 [01:15<07:53,  1.19s/it] 21%|██        | 103/500 [01:16<05:39,  1.17it/s] 21%|██        | 105/500 [01:16<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:16<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:16<02:15,  2.89it/s] 22%|██▏       | 111/500 [01:23<07:51,  1.21s/it] 23%|██▎       | 113/500 [01:23<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:23<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:23<02:55,  2.18it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.93it/s] 24%|██▍       | 121/500 [01:30<07:42,  1.22s/it] 25%|██▍       | 123/500 [01:30<05:29,  1.14it/s] 25%|██▌       | 125/500 [01:30<03:56,  1.58it/s] 25%|██▌       | 127/500 [01:30<02:52,  2.16it/s] 26%|██▌       | 129/500 [01:30<02:07,  2.92it/s] 26%|██▌       | 131/500 [01:37<07:25,  1.21s/it] 27%|██▋       | 133/500 [01:37<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:37<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:47,  2.17it/s]Test Loss:  0.0009940264280885458
Valid Loss:  0.0008605785551480949
Epoch:  72  	Training Loss: 0.0012906065676361322
Test Loss:  0.00085874751675874
Valid Loss:  0.00079465372255072
Epoch:  73  	Training Loss: 0.0012226002290844917
Test Loss:  0.000781758688390255
Valid Loss:  0.0007532613817602396
Epoch:  74  	Training Loss: 0.0011736643500626087
Test Loss:  0.0007247269386425614
Valid Loss:  0.000720667652785778
Epoch:  75  	Training Loss: 0.0011316356249153614
Test Loss:  0.0006791737978346646
Valid Loss:  0.0006930677918717265
Epoch:  76  	Training Loss: 0.0010942199733108282
Test Loss:  0.0006387269240804017
Valid Loss:  0.0006690649897791445
Epoch:  77  	Training Loss: 0.0010606290306895971
Test Loss:  0.0006055833073332906
Valid Loss:  0.0006481710588559508
Epoch:  78  	Training Loss: 0.0010296034161001444
Test Loss:  0.0005772348958998919
Valid Loss:  0.0006291631725616753
Epoch:  79  	Training Loss: 0.0010006806114688516
Test Loss:  0.0005529363406822085
Valid Loss:  0.0006122075719758868
Epoch:  80  	Training Loss: 0.0009736313950270414
Test Loss:  0.0005328370025381446
Valid Loss:  0.0005970626953057945
Epoch:  81  	Training Loss: 0.0009484431939199567
Test Loss:  0.0005146649200469255
Valid Loss:  0.0005830246955156326
Epoch:  82  	Training Loss: 0.000924403895623982
Test Loss:  0.0005171038210391998
Valid Loss:  0.0005568782798945904
Epoch:  83  	Training Loss: 0.0008795768953859806
Test Loss:  0.0005112728103995323
Valid Loss:  0.0005354147870093584
Epoch:  84  	Training Loss: 0.0008436638745479286
Test Loss:  0.0005012972978875041
Valid Loss:  0.0005166864721104503
Epoch:  85  	Training Loss: 0.0008127944893203676
Test Loss:  0.0004888265393674374
Valid Loss:  0.0005003197584301233
Epoch:  86  	Training Loss: 0.0007856932352297008
Test Loss:  0.00047529058065265417
Valid Loss:  0.00048614127445034683
Epoch:  87  	Training Loss: 0.0007614717469550669
Test Loss:  0.0004614040954038501
Valid Loss:  0.000473871361464262
Epoch:  88  	Training Loss: 0.0007396033615805209
Test Loss:  0.0004483591765165329
Valid Loss:  0.0004630766052287072
Epoch:  89  	Training Loss: 0.0007195752114057541
Test Loss:  0.00043647445272654295
Valid Loss:  0.00045370403677225113
Epoch:  90  	Training Loss: 0.0007012193091213703
Test Loss:  0.00042485579615458846
Valid Loss:  0.00044560141395777464
Epoch:  91  	Training Loss: 0.0006843119044788182
Test Loss:  0.0004142437828704715
Valid Loss:  0.0004386862274259329
Epoch:  92  	Training Loss: 0.0006685799453407526
Test Loss:  0.0004055006429553032
Valid Loss:  0.00043119199108332396
Epoch:  93  	Training Loss: 0.0006514715496450663
Test Loss:  0.0003951688122469932
Valid Loss:  0.00042498589027673006
Epoch:  94  	Training Loss: 0.000636994547676295
Test Loss:  0.00038582159322686493
Valid Loss:  0.00041939373477362096
Epoch:  95  	Training Loss: 0.0006235703476704657
Test Loss:  0.0003769566537812352
Valid Loss:  0.0004141594108659774
Epoch:  96  	Training Loss: 0.0006108575616963208
Test Loss:  0.0003687925054691732
Valid Loss:  0.0004092570161446929
Epoch:  97  	Training Loss: 0.0005988184129819274
Test Loss:  0.00036115647526457906
Valid Loss:  0.0004046604735776782
Epoch:  98  	Training Loss: 0.0005873722839169204
Test Loss:  0.00035399975604377687
Valid Loss:  0.000400308461394161
Epoch:  99  	Training Loss: 0.0005764898378401995
Test Loss:  0.0003475090197753161
Valid Loss:  0.00039622755139134824
Epoch:  100  	Training Loss: 0.0005661715986207128
Test Loss:  0.0003414301318116486
Valid Loss:  0.00039238721365109086
Epoch:  101  	Training Loss: 0.0005562311853282154
Test Loss:  0.0003355948138050735
Valid Loss:  0.00038870787830092013
Epoch:  102  	Training Loss: 0.0005466287839226425
Test Loss:  0.000331609247950837
Valid Loss:  0.0003860040451399982
Epoch:  103  	Training Loss: 0.0005399814108386636
Test Loss:  0.00032884994288906455
Valid Loss:  0.0003833341470453888
Epoch:  104  	Training Loss: 0.000533693702891469
Test Loss:  0.00032627934706397355
Valid Loss:  0.00038071180460974574
Epoch:  105  	Training Loss: 0.000527611467987299
Test Loss:  0.00032351899426430464
Valid Loss:  0.00037818728014826775
Epoch:  106  	Training Loss: 0.0005217032739892602
Test Loss:  0.00032070468296296895
Valid Loss:  0.0003757294616661966
Epoch:  107  	Training Loss: 0.0005159861175343394
Test Loss:  0.00031766557367518544
Valid Loss:  0.00037333997897803783
Epoch:  108  	Training Loss: 0.0005104194860905409
Test Loss:  0.00031446877983398736
Valid Loss:  0.00037099322071298957
Epoch:  109  	Training Loss: 0.0005049488390795887
Test Loss:  0.00031126366229727864
Valid Loss:  0.000368708570022136
Epoch:  110  	Training Loss: 0.0004996095667593181
Test Loss:  0.0003083786286879331
Valid Loss:  0.0003664329124148935
Epoch:  111  	Training Loss: 0.0004944232059642673
Test Loss:  0.00030548626091331244
Valid Loss:  0.00036424538120627403
Epoch:  112  	Training Loss: 0.0004893776495009661
Test Loss:  0.0002947867033071816
Valid Loss:  0.0003581164637580514
Epoch:  113  	Training Loss: 0.00047705642646178603
Test Loss:  0.00028660031966865063
Valid Loss:  0.00035217884578742087
Epoch:  114  	Training Loss: 0.0004653054056689143
Test Loss:  0.00027842039708048105
Valid Loss:  0.00034663945552892983
Epoch:  115  	Training Loss: 0.0004540418740361929
Test Loss:  0.00027162794140167534
Valid Loss:  0.0003413065569475293
Epoch:  116  	Training Loss: 0.0004432208079379052
Test Loss:  0.0002650451206136495
Valid Loss:  0.00033633463317528367
Epoch:  117  	Training Loss: 0.0004328135692048818
Test Loss:  0.0002589697833172977
Valid Loss:  0.00033153576077893376
Epoch:  118  	Training Loss: 0.0004228168400004506
Test Loss:  0.00025323190493509173
Valid Loss:  0.000326928828144446
Epoch:  119  	Training Loss: 0.0004132429021410644
Test Loss:  0.0002477786620147526
Valid Loss:  0.0003225301916245371
Epoch:  120  	Training Loss: 0.00040402045124210417
Test Loss:  0.00024266615218948573
Valid Loss:  0.00031828106148168445
Epoch:  121  	Training Loss: 0.0003951279213652015
Test Loss:  0.00023783434880897403
Valid Loss:  0.0003141674096696079
Epoch:  122  	Training Loss: 0.00038654665695503354
Test Loss:  0.00023368574329651892
Valid Loss:  0.0003109790850430727
Epoch:  123  	Training Loss: 0.00037847444764338434
Test Loss:  0.00022957161127123982
Valid Loss:  0.0003079696907661855
Epoch:  124  	Training Loss: 0.00037076108856126666
Test Loss:  0.0002256251755170524
Valid Loss:  0.00030506111215800047
Epoch:  125  	Training Loss: 0.0003633696469478309
Test Loss:  0.00022180798987392336
Valid Loss:  0.0003022516320925206
Epoch:  126  	Training Loss: 0.0003563255013432354
Test Loss:  0.00021818582899868488
Valid Loss:  0.0002995552495121956
Epoch:  127  	Training Loss: 0.0003496188437566161
Test Loss:  0.00021471819491125643
Valid Loss:  0.00029694955446757376
Epoch:  128  	Training Loss: 0.00034316774690523744
Test Loss:  0.00021140967146493495
Valid Loss:  0.0002943997678812593
Epoch:  129  	Training Loss: 0.0003369548940099776
Test Loss:  0.00020829730783589184
Valid Loss:  0.00029192422516644
Epoch:  130  	Training Loss: 0.0003309997555334121
Test Loss:  0.0002053859643638134
Valid Loss:  0.00028956207097508013
Epoch:  131  	Training Loss: 0.00032527459552511573
Test Loss:  0.0002026354195550084
Valid Loss:  0.00028731580823659897
Epoch:  132  	Training Loss: 0.0003197492042090744
Test Loss:  0.00020083304843865335
Valid Loss:  0.0002847572322934866
Epoch:  133  	Training Loss: 0.000314805016387254
Test Loss:  0.00019879682804457843
Valid Loss:  0.00028229696908965707
Epoch:  134  	Training Loss: 0.00031001970637589693
Test Loss:  0.000196675697225146
Valid Loss:  0.00027991965180262923
Epoch:  135  	Training Loss: 0.00030539309955202043
Test Loss:  0.00019457167945802212
Valid Loss:  0.0002776174806058407
Epoch:  136  	Training Loss: 0.00030089510255493224
Test Loss:  0.00019250684999860823
Valid Loss:  0.0002754054730758071
Epoch:  137  	Training Loss: 0.0002965233870781958
Test Loss:  0.0001904990349430591
Valid Loss:  0.0002732737339101732
Epoch:  138  	Training Loss: 0.0002922914281953126
Test Loss:  0.00018853993969969451
Valid Loss:  0.0002712025889195502
Epoch:  139  	Training Loss: 0.0002881861000787467
Test Loss:   28%|██▊       | 139/500 [01:37<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:44<07:19,  1.22s/it] 29%|██▊       | 143/500 [01:44<05:15,  1.13it/s] 29%|██▉       | 145/500 [01:44<03:48,  1.55it/s] 29%|██▉       | 147/500 [01:44<02:48,  2.10it/s] 30%|██▉       | 149/500 [01:44<02:06,  2.78it/s] 30%|███       | 151/500 [01:51<07:06,  1.22s/it] 31%|███       | 153/500 [01:51<05:04,  1.14it/s] 31%|███       | 155/500 [01:51<03:38,  1.58it/s] 31%|███▏      | 157/500 [01:51<02:38,  2.16it/s] 32%|███▏      | 159/500 [01:51<01:57,  2.91it/s] 32%|███▏      | 161/500 [01:58<06:50,  1.21s/it] 33%|███▎      | 163/500 [01:58<04:53,  1.15it/s] 33%|███▎      | 165/500 [01:58<03:30,  1.59it/s] 33%|███▎      | 167/500 [01:58<02:32,  2.18it/s] 34%|███▍      | 169/500 [01:58<01:52,  2.93it/s] 34%|███▍      | 171/500 [02:05<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:05<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:05<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:05<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:05<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:12<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:12<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:12<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:12<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:12<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:19<06:20,  1.23s/it] 39%|███▊      | 193/500 [02:19<04:32,  1.13it/s] 39%|███▉      | 195/500 [02:19<03:17,  1.54it/s] 39%|███▉      | 197/500 [02:19<02:25,  2.09it/s] 40%|███▉      | 199/500 [02:20<01:48,  2.77it/s] 40%|████      | 201/500 [02:26<06:03,  1.22s/it] 41%|████      | 203/500 [02:26<04:19,  1.15it/s] 41%|████      | 205/500 [02:26<03:06,  1.59it/s]0.00018663841183297336
Valid Loss:  0.00026918796356767416
Epoch:  140  	Training Loss: 0.00028419579030014575
Test Loss:  0.00018482677114661783
Valid Loss:  0.0002672359114512801
Epoch:  141  	Training Loss: 0.0002803313545882702
Test Loss:  0.000183080745046027
Valid Loss:  0.0002653344417922199
Epoch:  142  	Training Loss: 0.000276573293376714
Test Loss:  0.00018307880964130163
Valid Loss:  0.0002638357400428504
Epoch:  143  	Training Loss: 0.0002735791786108166
Test Loss:  0.0001824014470912516
Valid Loss:  0.0002624910557642579
Epoch:  144  	Training Loss: 0.0002707840467337519
Test Loss:  0.000181439274456352
Valid Loss:  0.0002612151438370347
Epoch:  145  	Training Loss: 0.00026809610426425934
Test Loss:  0.0001804125204216689
Valid Loss:  0.0002599950530566275
Epoch:  146  	Training Loss: 0.0002654987620189786
Test Loss:  0.00017936545191332698
Valid Loss:  0.0002588120405562222
Epoch:  147  	Training Loss: 0.0002629695809446275
Test Loss:  0.00017833008314482868
Valid Loss:  0.0002576675033196807
Epoch:  148  	Training Loss: 0.0002605025365483016
Test Loss:  0.0001773361291270703
Valid Loss:  0.00025655009085312486
Epoch:  149  	Training Loss: 0.00025809361250139773
Test Loss:  0.00017641174781601876
Valid Loss:  0.00025548646226525307
Epoch:  150  	Training Loss: 0.0002557385596446693
Test Loss:  0.00017556699458509684
Valid Loss:  0.00025446407380513847
Epoch:  151  	Training Loss: 0.00025343577726744115
Test Loss:  0.00017481423856224865
Valid Loss:  0.00025347358314320445
Epoch:  152  	Training Loss: 0.0002512045903131366
Test Loss:  0.00017375823517795652
Valid Loss:  0.0002529789926484227
Epoch:  153  	Training Loss: 0.0002499295223969966
Test Loss:  0.0001728200732031837
Valid Loss:  0.0002524970332160592
Epoch:  154  	Training Loss: 0.00024867907632142305
Test Loss:  0.00017198408022522926
Valid Loss:  0.0002520482230465859
Epoch:  155  	Training Loss: 0.00024747304269112647
Test Loss:  0.0001712129742372781
Valid Loss:  0.0002516245294827968
Epoch:  156  	Training Loss: 0.0002462925622239709
Test Loss:  0.00017049249436240643
Valid Loss:  0.0002512052305974066
Epoch:  157  	Training Loss: 0.00024513862445019186
Test Loss:  0.00016980280634015799
Valid Loss:  0.0002507881436031312
Epoch:  158  	Training Loss: 0.00024400159600190818
Test Loss:  0.00016914852312766016
Valid Loss:  0.0002503737050574273
Epoch:  159  	Training Loss: 0.00024288924760185182
Test Loss:  0.00016851788677740842
Valid Loss:  0.00024996267165988684
Epoch:  160  	Training Loss: 0.00024179968750104308
Test Loss:  0.00016795106057543308
Valid Loss:  0.000249560660449788
Epoch:  161  	Training Loss: 0.00024074342218227684
Test Loss:  0.00016740095452405512
Valid Loss:  0.0002491614723112434
Epoch:  162  	Training Loss: 0.00023970549227669835
Test Loss:  0.00016667591989971697
Valid Loss:  0.00024879074771888554
Epoch:  163  	Training Loss: 0.00023855696781538427
Test Loss:  0.00016608592704869807
Valid Loss:  0.00024840771220624447
Epoch:  164  	Training Loss: 0.00023742621124256402
Test Loss:  0.00016558945935685188
Valid Loss:  0.00024802167899906635
Epoch:  165  	Training Loss: 0.00023632454394828528
Test Loss:  0.00016514415619894862
Valid Loss:  0.0002476347144693136
Epoch:  166  	Training Loss: 0.00023524343851022422
Test Loss:  0.0001648151082918048
Valid Loss:  0.00024722941452637315
Epoch:  167  	Training Loss: 0.0002341946674278006
Test Loss:  0.00016465212684124708
Valid Loss:  0.00024679850321263075
Epoch:  168  	Training Loss: 0.00023317620798479766
Test Loss:  0.00016425983631052077
Valid Loss:  0.0002464349090587348
Epoch:  169  	Training Loss: 0.00023219823196996003
Test Loss:  0.00016405474161729217
Valid Loss:  0.0002460388350300491
Epoch:  170  	Training Loss: 0.00023123566643334925
Test Loss:  0.00016377762949559838
Valid Loss:  0.00024566188221797347
Epoch:  171  	Training Loss: 0.00023029315343592316
Test Loss:  0.0001634550280869007
Valid Loss:  0.000245290226303041
Epoch:  172  	Training Loss: 0.00022935947345104069
Test Loss:  0.0001631486666155979
Valid Loss:  0.0002447724691592157
Epoch:  173  	Training Loss: 0.00022849971719551831
Test Loss:  0.00016279840201605111
Valid Loss:  0.00024425581796094775
Epoch:  174  	Training Loss: 0.0002276425075251609
Test Loss:  0.00016243966820184141
Valid Loss:  0.00024373276391997933
Epoch:  175  	Training Loss: 0.0002267908857902512
Test Loss:  0.0001620660477783531
Valid Loss:  0.00024320678494405001
Epoch:  176  	Training Loss: 0.00022593920584768057
Test Loss:  0.00016167989815585315
Valid Loss:  0.00024267390836030245
Epoch:  177  	Training Loss: 0.00022508917027153075
Test Loss:  0.00016126452828757465
Valid Loss:  0.0002421364770270884
Epoch:  178  	Training Loss: 0.0002242354239569977
Test Loss:  0.00016086039249785244
Valid Loss:  0.0002415851631667465
Epoch:  179  	Training Loss: 0.00022338327835313976
Test Loss:  0.00016044646326918155
Valid Loss:  0.00024104266776703298
Epoch:  180  	Training Loss: 0.00022253919451031834
Test Loss:  0.00016003417840693146
Valid Loss:  0.00024050669162534177
Epoch:  181  	Training Loss: 0.0002217030560132116
Test Loss:  0.00015963456826284528
Valid Loss:  0.00023998180404305458
Epoch:  182  	Training Loss: 0.0002208778605563566
Test Loss:  0.00015804024587851018
Valid Loss:  0.00023910040908958763
Epoch:  183  	Training Loss: 0.00021928208298049867
Test Loss:  0.0001566537539474666
Valid Loss:  0.00023823803348932415
Epoch:  184  	Training Loss: 0.00021776059293188155
Test Loss:  0.00015543625340797007
Valid Loss:  0.00023739240714348853
Epoch:  185  	Training Loss: 0.00021629604452755302
Test Loss:  0.00015434398665092885
Valid Loss:  0.00023654743563383818
Epoch:  186  	Training Loss: 0.00021487096091732383
Test Loss:  0.0001533455797471106
Valid Loss:  0.00023570719349663705
Epoch:  187  	Training Loss: 0.0002134793030563742
Test Loss:  0.00015243439702317119
Valid Loss:  0.0002348939306102693
Epoch:  188  	Training Loss: 0.0002121200377587229
Test Loss:  0.0001515931508038193
Valid Loss:  0.00023410693393088877
Epoch:  189  	Training Loss: 0.00021080896840430796
Test Loss:  0.00015083815378602594
Valid Loss:  0.0002333511656615883
Epoch:  190  	Training Loss: 0.00020954162755515426
Test Loss:  0.00015013136726338416
Valid Loss:  0.00023261539172381163
Epoch:  191  	Training Loss: 0.00020830488938372582
Test Loss:  0.00014948062016628683
Valid Loss:  0.00023188992054201663
Epoch:  192  	Training Loss: 0.00020710162061732262
Test Loss:  0.0001496758486609906
Valid Loss:  0.00023132096976041794
Epoch:  193  	Training Loss: 0.00020607979968190193
Test Loss:  0.00014971874770708382
Valid Loss:  0.00023079507809598
Epoch:  194  	Training Loss: 0.0002050944312941283
Test Loss:  0.00014965585432946682
Valid Loss:  0.0002302901993971318
Epoch:  195  	Training Loss: 0.00020413963648024946
Test Loss:  0.00014951229968573898
Valid Loss:  0.00022980257926974446
Epoch:  196  	Training Loss: 0.00020320250769145787
Test Loss:  0.00014931205078028142
Valid Loss:  0.00022932930733077228
Epoch:  197  	Training Loss: 0.00020228815264999866
Test Loss:  0.00014907428703736514
Valid Loss:  0.00022886686201673
Epoch:  198  	Training Loss: 0.00020138896070420742
Test Loss:  0.00014880840899422765
Valid Loss:  0.0002284160873387009
Epoch:  199  	Training Loss: 0.00020050104649271816
Test Loss:  0.00014852355525363237
Valid Loss:  0.00022797106066718698
Epoch:  200  	Training Loss: 0.00019962455553468317
Test Loss:  0.00014823264791630208
Valid Loss:  0.00022753413941245526
Epoch:  201  	Training Loss: 0.0001987632131204009
Test Loss:  0.00014793284935876727
Valid Loss:  0.00022710682242177427
Epoch:  202  	Training Loss: 0.0001979115477297455
Test Loss:  0.00014845846453681588
Valid Loss:  0.00022677470406051725
Epoch:  203  	Training Loss: 0.000197109067812562
Test Loss:  0.00014846079284325242
Valid Loss:  0.0002264784707222134
Epoch:  204  	Training Loss: 0.00019634008640423417
Test Loss:  0.00014827956329099834
Valid Loss:  0.0002261917106807232
Epoch:  205  	Training Loss: 0.00019558967323973775
Test Loss:  0.00014818093040958047
Valid Loss:  0.0002258901804452762
Epoch:  206  	Training Loss: 0.00019484900985844433
Test Loss:  0.00014796527102589607
 41%|████▏     | 207/500 [02:26<02:15,  2.17it/s] 42%|████▏     | 209/500 [02:27<01:39,  2.92it/s] 42%|████▏     | 211/500 [02:33<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:33<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:33<02:55,  1.63it/s] 43%|████▎     | 217/500 [02:33<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:33<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:40<05:38,  1.21s/it] 45%|████▍     | 223/500 [02:40<04:03,  1.14it/s] 45%|████▌     | 225/500 [02:40<02:55,  1.56it/s] 45%|████▌     | 227/500 [02:40<02:07,  2.14it/s] 46%|████▌     | 229/500 [02:40<01:33,  2.89it/s] 46%|████▌     | 231/500 [02:47<05:29,  1.22s/it] 47%|████▋     | 233/500 [02:47<03:54,  1.14it/s] 47%|████▋     | 235/500 [02:47<02:48,  1.58it/s] 47%|████▋     | 237/500 [02:47<02:01,  2.16it/s] 48%|████▊     | 239/500 [02:48<01:30,  2.90it/s] 48%|████▊     | 241/500 [02:54<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:54<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:54<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:54<01:53,  2.22it/s] 50%|████▉     | 249/500 [02:54<01:23,  2.99it/s] 50%|█████     | 251/500 [03:01<05:03,  1.22s/it] 51%|█████     | 253/500 [03:01<03:36,  1.14it/s] 51%|█████     | 255/500 [03:01<02:35,  1.58it/s] 51%|█████▏    | 257/500 [03:01<01:52,  2.16it/s] 52%|█████▏    | 259/500 [03:01<01:22,  2.91it/s] 52%|█████▏    | 261/500 [03:08<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:08<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:08<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:08<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:08<01:16,  3.00it/s] 54%|█████▍    | 271/500 [03:15<04:33,  1.19s/it]Valid Loss:  0.00022559406352229416
Epoch:  207  	Training Loss: 0.00019411738321650773
Test Loss:  0.00014771569112781435
Valid Loss:  0.00022530344722326845
Epoch:  208  	Training Loss: 0.00019339495338499546
Test Loss:  0.00014745448424946517
Valid Loss:  0.0002250138932140544
Epoch:  209  	Training Loss: 0.00019268240430392325
Test Loss:  0.00014718621969223022
Valid Loss:  0.00022472829732578248
Epoch:  210  	Training Loss: 0.0001919764035847038
Test Loss:  0.0001469183771405369
Valid Loss:  0.00022444552450906485
Epoch:  211  	Training Loss: 0.0001912792504299432
Test Loss:  0.00014667089271824807
Valid Loss:  0.00022416483261622488
Epoch:  212  	Training Loss: 0.0001905917888507247
Test Loss:  0.0001452370488550514
Valid Loss:  0.0002221760805696249
Epoch:  213  	Training Loss: 0.00018605636432766914
Test Loss:  0.00014372871373780072
Valid Loss:  0.00022009285748936236
Epoch:  214  	Training Loss: 0.00018155688303522766
Test Loss:  0.00014212296810001135
Valid Loss:  0.00021805998403578997
Epoch:  215  	Training Loss: 0.00017723848577588797
Test Loss:  0.00014051566540729254
Valid Loss:  0.0002161561424145475
Epoch:  216  	Training Loss: 0.0001732094824546948
Test Loss:  0.0001389045501127839
Valid Loss:  0.0002143814053852111
Epoch:  217  	Training Loss: 0.00016949874407146126
Test Loss:  0.00013730977661907673
Valid Loss:  0.00021276857296470553
Epoch:  218  	Training Loss: 0.00016610987950116396
Test Loss:  0.0001358225563308224
Valid Loss:  0.00021128416119609028
Epoch:  219  	Training Loss: 0.0001630484330235049
Test Loss:  0.00013447647506836802
Valid Loss:  0.00020992234931327403
Epoch:  220  	Training Loss: 0.00016039420734159648
Test Loss:  0.00013325412874110043
Valid Loss:  0.00020865989790763706
Epoch:  221  	Training Loss: 0.00015805993461981416
Test Loss:  0.00013210970791988075
Valid Loss:  0.00020751485135406256
Epoch:  222  	Training Loss: 0.0001558978110551834
Test Loss:  0.0001316259294981137
Valid Loss:  0.00020728098752442747
Epoch:  223  	Training Loss: 0.00015578088641632348
Test Loss:  0.00013126470730639994
Valid Loss:  0.00020706972281914204
Epoch:  224  	Training Loss: 0.00015567982336506248
Test Loss:  0.00013099113130010664
Valid Loss:  0.000206872820854187
Epoch:  225  	Training Loss: 0.00015558977611362934
Test Loss:  0.0001307798083871603
Valid Loss:  0.00020668806973844767
Epoch:  226  	Training Loss: 0.00015550677198916674
Test Loss:  0.00013061444042250514
Valid Loss:  0.00020651367958635092
Epoch:  227  	Training Loss: 0.0001554270857013762
Test Loss:  0.00013048236723989248
Valid Loss:  0.0002063484862446785
Epoch:  228  	Training Loss: 0.00015534981503151357
Test Loss:  0.0001303750032093376
Valid Loss:  0.00020619118004105985
Epoch:  229  	Training Loss: 0.00015527474170085043
Test Loss:  0.00013029025285504758
Valid Loss:  0.00020604241581168026
Epoch:  230  	Training Loss: 0.00015520278248004615
Test Loss:  0.00013021934137213975
Valid Loss:  0.00020590148051269352
Epoch:  231  	Training Loss: 0.00015513240941800177
Test Loss:  0.00013015573495067656
Valid Loss:  0.00020576463430188596
Epoch:  232  	Training Loss: 0.00015506331692449749
Test Loss:  0.00012893517850898206
Valid Loss:  0.00020498498633969575
Epoch:  233  	Training Loss: 0.00015410949708893895
Test Loss:  0.00012811509077437222
Valid Loss:  0.00020429841242730618
Epoch:  234  	Training Loss: 0.00015323091065511107
Test Loss:  0.00012751301983371377
Valid Loss:  0.00020366586977615952
Epoch:  235  	Training Loss: 0.00015238614287227392
Test Loss:  0.00012702035019174218
Valid Loss:  0.00020305813814047724
Epoch:  236  	Training Loss: 0.00015155912842601538
Test Loss:  0.00012660230277106166
Valid Loss:  0.0002024758287006989
Epoch:  237  	Training Loss: 0.0001507490815129131
Test Loss:  0.00012623300426639616
Valid Loss:  0.00020190852228552103
Epoch:  238  	Training Loss: 0.00014995542005635798
Test Loss:  0.0001258911652257666
Valid Loss:  0.00020135758677497506
Epoch:  239  	Training Loss: 0.0001491764560341835
Test Loss:  0.00012557851732708514
Valid Loss:  0.000200823022169061
Epoch:  240  	Training Loss: 0.00014841298980172724
Test Loss:  0.00012528026127256453
Valid Loss:  0.00020029957522638142
Epoch:  241  	Training Loss: 0.00014766192180104554
Test Loss:  0.0001249915803782642
Valid Loss:  0.00019978720229119062
Epoch:  242  	Training Loss: 0.00014692488184664398
Test Loss:  0.00012497500574681908
Valid Loss:  0.00019942950166296214
Epoch:  243  	Training Loss: 0.00014633065438829362
Test Loss:  0.0001245745224878192
Valid Loss:  0.0001990756281884387
Epoch:  244  	Training Loss: 0.0001457356702303514
Test Loss:  0.00012453335511963814
Valid Loss:  0.00019872590200975537
Epoch:  245  	Training Loss: 0.00014515456859953701
Test Loss:  0.00012412546493578702
Valid Loss:  0.0001983821566682309
Epoch:  246  	Training Loss: 0.0001445867819711566
Test Loss:  0.0001241533609572798
Valid Loss:  0.00019803919713012874
Epoch:  247  	Training Loss: 0.00014402202214114368
Test Loss:  0.00012371857883408666
Valid Loss:  0.0001976999337784946
Epoch:  248  	Training Loss: 0.00014347198884934187
Test Loss:  0.00012373490608297288
Valid Loss:  0.0001973707985598594
Epoch:  249  	Training Loss: 0.00014292307605501264
Test Loss:  0.0001233680814038962
Valid Loss:  0.00019703572615981102
Epoch:  250  	Training Loss: 0.00014238854055292904
Test Loss:  0.00012334046186879277
Valid Loss:  0.00019670897745527327
Epoch:  251  	Training Loss: 0.00014185713371261954
Test Loss:  0.00012288789730519056
Valid Loss:  0.0001963786780834198
Epoch:  252  	Training Loss: 0.00014133809600025415
Test Loss:  0.00012294128828216344
Valid Loss:  0.00019593382603488863
Epoch:  253  	Training Loss: 0.00014073462807573378
Test Loss:  0.0001228656037710607
Valid Loss:  0.00019550989964045584
Epoch:  254  	Training Loss: 0.00014014908811077476
Test Loss:  0.00012271605373825878
Valid Loss:  0.00019509960839059204
Epoch:  255  	Training Loss: 0.00013957868213765323
Test Loss:  0.00012253609020262957
Valid Loss:  0.00019470469851512462
Epoch:  256  	Training Loss: 0.00013902016507927328
Test Loss:  0.00012234525638632476
Valid Loss:  0.00019432342378422618
Epoch:  257  	Training Loss: 0.00013847257650922984
Test Loss:  0.00012215241440571845
Valid Loss:  0.00019395246636122465
Epoch:  258  	Training Loss: 0.00013793646940030158
Test Loss:  0.00012195366434752941
Valid Loss:  0.00019359239377081394
Epoch:  259  	Training Loss: 0.00013740653230343014
Test Loss:  0.0001217630342580378
Valid Loss:  0.00019324308959767222
Epoch:  260  	Training Loss: 0.0001368868543067947
Test Loss:  0.00012157030869275331
Valid Loss:  0.00019290336058475077
Epoch:  261  	Training Loss: 0.00013637548545375466
Test Loss:  0.00012137791054556146
Valid Loss:  0.0001925685937749222
Epoch:  262  	Training Loss: 0.0001358658482786268
Test Loss:  0.00012132470874348655
Valid Loss:  0.0001924461976159364
Epoch:  263  	Training Loss: 0.00013565132394433022
Test Loss:  0.00012126345245633274
Valid Loss:  0.00019232463091611862
Epoch:  264  	Training Loss: 0.00013543895329348743
Test Loss:  0.00012119237362639979
Valid Loss:  0.00019219954265281558
Epoch:  265  	Training Loss: 0.00013522781955543905
Test Loss:  0.00012116177822463214
Valid Loss:  0.00019208060984965414
Epoch:  266  	Training Loss: 0.0001350182283204049
Test Loss:  0.00012111778050893918
Valid Loss:  0.0001919597270898521
Epoch:  267  	Training Loss: 0.00013481162022799253
Test Loss:  0.00012106323265470564
Valid Loss:  0.00019183827680535614
Epoch:  268  	Training Loss: 0.00013460664195008576
Test Loss:  0.00012099882587790489
Valid Loss:  0.0001917160116136074
Epoch:  269  	Training Loss: 0.00013440294424071908
Test Loss:  0.00012093233817722648
Valid Loss:  0.0001915960747282952
Epoch:  270  	Training Loss: 0.0001342018658760935
Test Loss:  0.000120863041956909
Valid Loss:  0.0001914752065204084
Epoch:  271  	Training Loss: 0.00013400224270299077
Test Loss:  0.00012079173029633239
Valid Loss:  0.00019135455659125
Epoch:  272  	Training Loss: 0.00013380478776525706
Test Loss:  0.00012067134957760572
Valid Loss:  0.00019121650257147849
Epoch:  273  	Training Loss: 0.00013360455341171473
Test Loss:  0.00012056522973580286
 55%|█████▍    | 273/500 [03:15<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:15<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:15<01:41,  2.21it/s] 56%|█████▌    | 279/500 [03:15<01:15,  2.93it/s] 56%|█████▌    | 281/500 [03:22<04:28,  1.23s/it] 57%|█████▋    | 283/500 [03:22<03:10,  1.14it/s] 57%|█████▋    | 285/500 [03:22<02:16,  1.58it/s] 57%|█████▋    | 287/500 [03:22<01:38,  2.15it/s] 58%|█████▊    | 289/500 [03:22<01:12,  2.90it/s] 58%|█████▊    | 291/500 [03:29<04:09,  1.20s/it] 59%|█████▊    | 293/500 [03:29<02:57,  1.16it/s] 59%|█████▉    | 295/500 [03:29<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:29<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:29<01:07,  2.96it/s] 60%|██████    | 301/500 [03:36<04:01,  1.21s/it] 61%|██████    | 303/500 [03:36<02:51,  1.15it/s] 61%|██████    | 305/500 [03:36<02:02,  1.59it/s] 61%|██████▏   | 307/500 [03:36<01:28,  2.17it/s] 62%|██████▏   | 309/500 [03:36<01:05,  2.92it/s] 62%|██████▏   | 311/500 [03:43<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:43<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:43<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:43<01:24,  2.15it/s] 64%|██████▍   | 319/500 [03:43<01:03,  2.85it/s] 64%|██████▍   | 321/500 [03:50<03:37,  1.21s/it] 65%|██████▍   | 323/500 [03:50<02:34,  1.15it/s] 65%|██████▌   | 325/500 [03:50<01:50,  1.59it/s] 65%|██████▌   | 327/500 [03:50<01:19,  2.17it/s] 66%|██████▌   | 329/500 [03:50<00:58,  2.92it/s] 66%|██████▌   | 331/500 [03:57<03:25,  1.22s/it] 67%|██████▋   | 333/500 [03:57<02:26,  1.14it/s] 67%|██████▋   | 335/500 [03:57<01:44,  1.58it/s] 67%|██████▋   | 337/500 [03:57<01:15,  2.16it/s] 68%|██████▊   | 339/500 [03:57<00:55,  2.90it/s]Valid Loss:  0.00019108147535007447
Epoch:  274  	Training Loss: 0.00013340558507479727
Test Loss:  0.00012046814663335681
Valid Loss:  0.00019094835442956537
Epoch:  275  	Training Loss: 0.0001332071697106585
Test Loss:  0.0001203798019560054
Valid Loss:  0.00019081676146015525
Epoch:  276  	Training Loss: 0.00013301106810104102
Test Loss:  0.00012029572098981589
Valid Loss:  0.0001906874094856903
Epoch:  277  	Training Loss: 0.0001328164362348616
Test Loss:  0.0001202143175760284
Valid Loss:  0.0001905604440253228
Epoch:  278  	Training Loss: 0.000132623448735103
Test Loss:  0.00012013930245302618
Valid Loss:  0.00019043459906242788
Epoch:  279  	Training Loss: 0.0001324306649621576
Test Loss:  0.00012006533506792039
Valid Loss:  0.00019030956900678575
Epoch:  280  	Training Loss: 0.00013223917630966753
Test Loss:  0.00011999296839348972
Valid Loss:  0.0001901857031043619
Epoch:  281  	Training Loss: 0.00013204829883761704
Test Loss:  0.00011992171494057402
Valid Loss:  0.00019006287038791925
Epoch:  282  	Training Loss: 0.00013185813440941274
Test Loss:  0.00011989824997726828
Valid Loss:  0.00018993848061654717
Epoch:  283  	Training Loss: 0.0001316814450547099
Test Loss:  0.00011986611207248643
Valid Loss:  0.0001898140471894294
Epoch:  284  	Training Loss: 0.00013150539598427713
Test Loss:  0.00011982717842329293
Valid Loss:  0.0001896924222819507
Epoch:  285  	Training Loss: 0.00013133160246070474
Test Loss:  0.0001197845849674195
Valid Loss:  0.0001895702735055238
Epoch:  286  	Training Loss: 0.00013115924957673997
Test Loss:  0.00011973770597251132
Valid Loss:  0.00018944831390399486
Epoch:  287  	Training Loss: 0.00013098640192765743
Test Loss:  0.0001196890152641572
Valid Loss:  0.00018932786770164967
Epoch:  288  	Training Loss: 0.0001308156206505373
Test Loss:  0.00011963842553086579
Valid Loss:  0.0001892083091661334
Epoch:  289  	Training Loss: 0.00013064606173429638
Test Loss:  0.000119585391075816
Valid Loss:  0.00018908799393102527
Epoch:  290  	Training Loss: 0.00013047389802522957
Test Loss:  0.0001195328077301383
Valid Loss:  0.0001889679697342217
Epoch:  291  	Training Loss: 0.00013030366972088814
Test Loss:  0.00011947828897973523
Valid Loss:  0.0001888499828055501
Epoch:  292  	Training Loss: 0.00013013393618166447
Test Loss:  0.00011949989857384935
Valid Loss:  0.0001888039114419371
Epoch:  293  	Training Loss: 0.00013002968626096845
Test Loss:  0.0001194901269627735
Valid Loss:  0.00018874896341003478
Epoch:  294  	Training Loss: 0.00012992610572837293
Test Loss:  0.00011946395534323528
Valid Loss:  0.00018868868937715888
Epoch:  295  	Training Loss: 0.00012982434418518096
Test Loss:  0.00011949760664720088
Valid Loss:  0.0001886379177449271
Epoch:  296  	Training Loss: 0.00012972374679520726
Test Loss:  0.00011949947656830773
Valid Loss:  0.00018857857503462583
Epoch:  297  	Training Loss: 0.000129623367683962
Test Loss:  0.00011948543397011235
Valid Loss:  0.00018851537606678903
Epoch:  298  	Training Loss: 0.0001295242109335959
Test Loss:  0.00011946253653150052
Valid Loss:  0.00018845158047042787
Epoch:  299  	Training Loss: 0.00012942682951688766
Test Loss:  0.00011943536810576916
Valid Loss:  0.0001883844961412251
Epoch:  300  	Training Loss: 0.00012932802201248705
Test Loss:  0.00011940711556235328
Valid Loss:  0.0001883190416265279
Epoch:  301  	Training Loss: 0.00012923034955747426
Test Loss:  0.00011937723320443183
Valid Loss:  0.00018825131701305509
Epoch:  302  	Training Loss: 0.00012913427781313658
Test Loss:  0.00011899374658241868
Valid Loss:  0.00018768507288768888
Epoch:  303  	Training Loss: 0.00012803380377590656
Test Loss:  0.00011864264524774626
Valid Loss:  0.00018715935584623367
Epoch:  304  	Training Loss: 0.00012708768190350384
Test Loss:  0.00011831142182927579
Valid Loss:  0.00018665948300622404
Epoch:  305  	Training Loss: 0.0001262150180991739
Test Loss:  0.00011801031359937042
Valid Loss:  0.00018617609748616815
Epoch:  306  	Training Loss: 0.0001253918744623661
Test Loss:  0.00011773833830375224
Valid Loss:  0.00018571215332485735
Epoch:  307  	Training Loss: 0.0001246233587153256
Test Loss:  0.00011748163524316624
Valid Loss:  0.0001852782443165779
Epoch:  308  	Training Loss: 0.00012395356316119432
Test Loss:  0.00011725353397196159
Valid Loss:  0.0001848566607804969
Epoch:  309  	Training Loss: 0.00012332625919952989
Test Loss:  0.00011703842028509825
Valid Loss:  0.00018445876776240766
Epoch:  310  	Training Loss: 0.00012277468340471387
Test Loss:  0.0001168248854810372
Valid Loss:  0.00018410178017802536
Epoch:  311  	Training Loss: 0.00012228242121636868
Test Loss:  0.00011662985343718901
Valid Loss:  0.000183768046554178
Epoch:  312  	Training Loss: 0.00012181356578366831
Test Loss:  0.00011641164746833965
Valid Loss:  0.00018355996871832758
Epoch:  313  	Training Loss: 0.00012161876657046378
Test Loss:  0.00011622684542089701
Valid Loss:  0.00018336399807594717
Epoch:  314  	Training Loss: 0.00012142925697844476
Test Loss:  0.00011606697080424055
Valid Loss:  0.0001831763656809926
Epoch:  315  	Training Loss: 0.00012124386557843536
Test Loss:  0.00011592797818593681
Valid Loss:  0.0001829960528993979
Epoch:  316  	Training Loss: 0.00012106075882911682
Test Loss:  0.00011580379214137793
Valid Loss:  0.00018282287055626512
Epoch:  317  	Training Loss: 0.00012088083167327568
Test Loss:  0.00011569324851734564
Valid Loss:  0.00018265307880938053
Epoch:  318  	Training Loss: 0.00012070249795215204
Test Loss:  0.0001155912468675524
Valid Loss:  0.0001824880891945213
Epoch:  319  	Training Loss: 0.00012052649981342256
Test Loss:  0.00011549759801710024
Valid Loss:  0.00018232758156955242
Epoch:  320  	Training Loss: 0.00012035213876515627
Test Loss:  0.00011540920240804553
Valid Loss:  0.00018217205069959164
Epoch:  321  	Training Loss: 0.00012018036795780063
Test Loss:  0.00011532750067999586
Valid Loss:  0.00018201983766630292
Epoch:  322  	Training Loss: 0.00012000901915598661
Test Loss:  0.00011560566781554371
Valid Loss:  0.00018205694505013525
Epoch:  323  	Training Loss: 0.00011994916712865233
Test Loss:  0.00011570878268685192
Valid Loss:  0.00018204806838184595
Epoch:  324  	Training Loss: 0.00011990044004051015
Test Loss:  0.00011572871881071478
Valid Loss:  0.00018201692728325725
Epoch:  325  	Training Loss: 0.00011985381570411846
Test Loss:  0.00011571511276997626
Valid Loss:  0.00018197490135207772
Epoch:  326  	Training Loss: 0.00011980852286797017
Test Loss:  0.00011568725312827155
Valid Loss:  0.00018192834977526218
Epoch:  327  	Training Loss: 0.00011976250971201807
Test Loss:  0.0001156494181486778
Valid Loss:  0.000181878698640503
Epoch:  328  	Training Loss: 0.00011971720959991217
Test Loss:  0.00011561073188204318
Valid Loss:  0.0001818290475057438
Epoch:  329  	Training Loss: 0.00011967236787313595
Test Loss:  0.00011557106336113065
Valid Loss:  0.00018177868332713842
Epoch:  330  	Training Loss: 0.00011962727876380086
Test Loss:  0.0001155319478129968
Valid Loss:  0.00018172909040004015
Epoch:  331  	Training Loss: 0.00011958183313254267
Test Loss:  0.00011549273040145636
Valid Loss:  0.00018167871166951954
Epoch:  332  	Training Loss: 0.00011953651846852154
Test Loss:  0.00011527298192959279
Valid Loss:  0.00018133080448023975
Epoch:  333  	Training Loss: 0.000119301192171406
Test Loss:  0.0001150899042841047
Valid Loss:  0.00018100255692843348
Epoch:  334  	Training Loss: 0.00011907436419278383
Test Loss:  0.00011493058991618454
Valid Loss:  0.0001806981017580256
Epoch:  335  	Training Loss: 0.00011885528510902077
Test Loss:  0.00011479502427391708
Valid Loss:  0.00018040792201645672
Epoch:  336  	Training Loss: 0.00011864100815728307
Test Loss:  0.0001146719150710851
Valid Loss:  0.0001801366452127695
Epoch:  337  	Training Loss: 0.00011843299580505118
Test Loss:  0.0001145611095125787
Valid Loss:  0.0001798811717890203
Epoch:  338  	Training Loss: 0.00011822971282526851
Test Loss:  0.00011445493146311492
Valid Loss:  0.00017963789287023246
Epoch:  339  	Training Loss: 0.00011802550579886883
Test Loss:  0.00011435399937909096
Valid Loss:  0.00017940743418876082
Epoch:  340  	Training Loss: 0.00011782216461142525
Test Loss:  0.00011426021228544414
 68%|██████▊   | 341/500 [04:04<03:15,  1.23s/it] 69%|██████▊   | 343/500 [04:04<02:18,  1.13it/s] 69%|██████▉   | 345/500 [04:04<01:38,  1.57it/s] 69%|██████▉   | 347/500 [04:04<01:11,  2.14it/s] 70%|██████▉   | 349/500 [04:05<00:52,  2.88it/s] 70%|███████   | 351/500 [04:11<02:58,  1.20s/it] 70%|███████   | 352/500 [04:11<02:28,  1.00s/it] 71%|███████   | 354/500 [04:11<01:40,  1.45it/s] 71%|███████   | 356/500 [04:11<01:10,  2.04it/s] 72%|███████▏  | 358/500 [04:11<00:50,  2.81it/s] 72%|███████▏  | 360/500 [04:12<00:37,  3.77it/s] 72%|███████▏  | 362/500 [04:18<02:41,  1.17s/it] 73%|███████▎  | 364/500 [04:18<01:54,  1.19it/s] 73%|███████▎  | 366/500 [04:18<01:21,  1.65it/s] 74%|███████▎  | 368/500 [04:18<00:58,  2.26it/s] 74%|███████▍  | 370/500 [04:19<00:42,  3.04it/s] 74%|███████▍  | 372/500 [04:25<02:34,  1.21s/it] 75%|███████▍  | 374/500 [04:25<01:49,  1.15it/s] 75%|███████▌  | 376/500 [04:25<01:18,  1.59it/s] 76%|███████▌  | 378/500 [04:25<00:56,  2.17it/s] 76%|███████▌  | 380/500 [04:26<00:41,  2.92it/s] 76%|███████▋  | 382/500 [04:32<02:23,  1.22s/it] 77%|███████▋  | 384/500 [04:32<01:41,  1.14it/s] 77%|███████▋  | 386/500 [04:32<01:12,  1.56it/s] 78%|███████▊  | 388/500 [04:33<00:52,  2.12it/s] 78%|███████▊  | 390/500 [04:33<00:38,  2.85it/s] 78%|███████▊  | 392/500 [04:39<02:09,  1.20s/it] 79%|███████▉  | 394/500 [04:39<01:31,  1.15it/s] 79%|███████▉  | 396/500 [04:39<01:05,  1.59it/s] 80%|███████▉  | 398/500 [04:40<00:47,  2.16it/s] 80%|████████  | 400/500 [04:40<00:35,  2.85it/s] 80%|████████  | 402/500 [04:46<01:57,  1.20s/it] 81%|████████  | 404/500 [04:46<01:22,  1.16it/s] 81%|████████  | 406/500 [04:46<00:59,  1.59it/s]Valid Loss:  0.00017918451339937747
Epoch:  341  	Training Loss: 0.00011762167559936643
Test Loss:  0.00011416999041102827
Valid Loss:  0.0001789752277545631
Epoch:  342  	Training Loss: 0.00011742525384761393
Test Loss:  0.00011418099165894091
Valid Loss:  0.0001788990048225969
Epoch:  343  	Training Loss: 0.0001172926786239259
Test Loss:  0.00011417420319048688
Valid Loss:  0.00017881696112453938
Epoch:  344  	Training Loss: 0.00011716208973666653
Test Loss:  0.0001141547691076994
Valid Loss:  0.00017873560136649758
Epoch:  345  	Training Loss: 0.00011703246855176985
Test Loss:  0.00011412386811571196
Valid Loss:  0.0001786505017662421
Epoch:  346  	Training Loss: 0.00011690487735904753
Test Loss:  0.00011408577847760171
Valid Loss:  0.00017856518388725817
Epoch:  347  	Training Loss: 0.00011677785369101912
Test Loss:  0.0001140395543188788
Valid Loss:  0.0001784775813575834
Epoch:  348  	Training Loss: 0.00011665111378533766
Test Loss:  0.00011398780770832673
Valid Loss:  0.00017838981875684112
Epoch:  349  	Training Loss: 0.00011652555986074731
Test Loss:  0.00011393145541660488
Valid Loss:  0.00017830225988291204
Epoch:  350  	Training Loss: 0.00011640077718766406
Test Loss:  0.00011387364793336019
Valid Loss:  0.0001782150357030332
Epoch:  351  	Training Loss: 0.00011627691856119782
Test Loss:  0.00011381306103430688
Valid Loss:  0.00017812798614613712
Epoch:  352  	Training Loss: 0.00011615319817792624
Test Loss:  0.00011353140871506184
Valid Loss:  0.0001779767917469144
Epoch:  353  	Training Loss: 0.00011604263272602111
Test Loss:  0.0001133479381678626
Valid Loss:  0.0001778511214070022
Epoch:  354  	Training Loss: 0.00011593841918511316
Test Loss:  0.00011322404316160828
Valid Loss:  0.00017773783474694937
Epoch:  355  	Training Loss: 0.00011583649029489607
Test Loss:  0.000113133923150599
Valid Loss:  0.00017763435607776046
Epoch:  356  	Training Loss: 0.00011573614028748125
Test Loss:  0.0001130658492911607
Valid Loss:  0.0001775372220436111
Epoch:  357  	Training Loss: 0.00011563621228560805
Test Loss:  0.00011300919140921906
Valid Loss:  0.00017743899661581963
Epoch:  358  	Training Loss: 0.00011553725926205516
Test Loss:  0.00011296008597128093
Valid Loss:  0.00017734723223838955
Epoch:  359  	Training Loss: 0.00011543839354999363
Test Loss:  0.00011291878763586283
Valid Loss:  0.00017725618090480566
Epoch:  360  	Training Loss: 0.00011534085206221789
Test Loss:  0.00011287756206002086
Valid Loss:  0.00017716664297040552
Epoch:  361  	Training Loss: 0.00011524338333401829
Test Loss:  0.00011283892672508955
Valid Loss:  0.00017707915685605258
Epoch:  362  	Training Loss: 0.00011514718789840117
Test Loss:  0.00011292871204204857
Valid Loss:  0.00017700492753647268
Epoch:  363  	Training Loss: 0.00011502252891659737
Test Loss:  0.00011294982687104493
Valid Loss:  0.00017691687389742583
Epoch:  364  	Training Loss: 0.00011490048927953467
Test Loss:  0.00011292911949567497
Valid Loss:  0.00017682209727354348
Epoch:  365  	Training Loss: 0.00011478018132038414
Test Loss:  0.00011288542009424418
Valid Loss:  0.00017672372632659972
Epoch:  366  	Training Loss: 0.00011466030264273286
Test Loss:  0.00011283147614449263
Valid Loss:  0.0001766218338161707
Epoch:  367  	Training Loss: 0.0001145411079050973
Test Loss:  0.00011277096200501546
Valid Loss:  0.000176517540239729
Epoch:  368  	Training Loss: 0.000114421833131928
Test Loss:  0.00011270758113823831
Valid Loss:  0.00017641362501308322
Epoch:  369  	Training Loss: 0.00011430255108280107
Test Loss:  0.00011264183558523655
Valid Loss:  0.00017630841466598213
Epoch:  370  	Training Loss: 0.00011418403300922364
Test Loss:  0.00011257448204560205
Valid Loss:  0.00017620259313844144
Epoch:  371  	Training Loss: 0.00011406504199840128
Test Loss:  0.00011252102558501065
Valid Loss:  0.00017610003123991191
Epoch:  372  	Training Loss: 0.0001139448577305302
Test Loss:  0.00011247704242123291
Valid Loss:  0.0001760448794811964
Epoch:  373  	Training Loss: 0.00011381283547962084
Test Loss:  0.00011241867468925193
Valid Loss:  0.00017598620615899563
Epoch:  374  	Training Loss: 0.00011368571722414345
Test Loss:  0.00011237266880925745
Valid Loss:  0.00017593194206710905
Epoch:  375  	Training Loss: 0.00011355815513525158
Test Loss:  0.00011231710232095793
Valid Loss:  0.00017587700858712196
Epoch:  376  	Training Loss: 0.0001134329941123724
Test Loss:  0.00011225308844586834
Valid Loss:  0.00017581903375685215
Epoch:  377  	Training Loss: 0.00011331032146699727
Test Loss:  0.00011218775762245059
Valid Loss:  0.00017576044774614275
Epoch:  378  	Training Loss: 0.0001131884491769597
Test Loss:  0.00011212439130758867
Valid Loss:  0.00017570299678482115
Epoch:  379  	Training Loss: 0.00011306898522889242
Test Loss:  0.0001120611559599638
Valid Loss:  0.00017564601148478687
Epoch:  380  	Training Loss: 0.0001129500160459429
Test Loss:  0.00011199987784493715
Valid Loss:  0.00017559115076437593
Epoch:  381  	Training Loss: 0.00011283159255981445
Test Loss:  0.00011193772661499679
Valid Loss:  0.00017553394718561321
Epoch:  382  	Training Loss: 0.00011271421681158245
Test Loss:  0.00011181537411175668
Valid Loss:  0.00017537979874759912
Epoch:  383  	Training Loss: 0.00011249702947679907
Test Loss:  0.00011169799836352468
Valid Loss:  0.00017523011774756014
Epoch:  384  	Training Loss: 0.00011228171206312254
Test Loss:  0.00011158699635416269
Valid Loss:  0.00017509146709926426
Epoch:  385  	Training Loss: 0.00011206878843950108
Test Loss:  0.00011147843179060146
Valid Loss:  0.00017495370411779732
Epoch:  386  	Training Loss: 0.00011185832408955321
Test Loss:  0.00011137237015645951
Valid Loss:  0.00017481882241554558
Epoch:  387  	Training Loss: 0.00011164935131091624
Test Loss:  0.0001112685858970508
Valid Loss:  0.00017468778241891414
Epoch:  388  	Training Loss: 0.00011144558084197342
Test Loss:  0.00011114879453089088
Valid Loss:  0.00017455170745961368
Epoch:  389  	Training Loss: 0.00011124117008876055
Test Loss:  0.00011103773431386799
Valid Loss:  0.0001744164910633117
Epoch:  390  	Training Loss: 0.00011104058648925275
Test Loss:  0.00011091408669017255
Valid Loss:  0.00017427795683033764
Epoch:  391  	Training Loss: 0.00011083934805355966
Test Loss:  0.0001108011492760852
Valid Loss:  0.00017414145986549556
Epoch:  392  	Training Loss: 0.00011064053978770971
Test Loss:  0.00011086877202615142
Valid Loss:  0.00017397997726220638
Epoch:  393  	Training Loss: 0.00011034045746782795
Test Loss:  0.0001108612195821479
Valid Loss:  0.00017380052304361016
Epoch:  394  	Training Loss: 0.0001100614681490697
Test Loss:  0.00011081903357990086
Valid Loss:  0.0001736272097332403
Epoch:  395  	Training Loss: 0.00010979453509207815
Test Loss:  0.00011075772636104375
Valid Loss:  0.0001734468969516456
Epoch:  396  	Training Loss: 0.00010953831224469468
Test Loss:  0.00011068178719142452
Valid Loss:  0.00017326748638879508
Epoch:  397  	Training Loss: 0.00010929212294286117
Test Loss:  0.00011059028474846855
Valid Loss:  0.00017308550013694912
Epoch:  398  	Training Loss: 0.0001090483638108708
Test Loss:  0.00011050865577999502
Valid Loss:  0.0001729113282635808
Epoch:  399  	Training Loss: 0.00010880835179705173
Test Loss:  0.00011041460675187409
Valid Loss:  0.00017273744742851704
Epoch:  400  	Training Loss: 0.00010857077722903341
Test Loss:  0.00011033257760573179
Valid Loss:  0.00017257228319067508
Epoch:  401  	Training Loss: 0.00010833921260200441
Test Loss:  0.00011024633568013087
Valid Loss:  0.00017240599845536053
Epoch:  402  	Training Loss: 0.00010811588435899466
Test Loss:  0.00010994698823196813
Valid Loss:  0.0001722771703498438
Epoch:  403  	Training Loss: 0.00010804050543811172
Test Loss:  0.00010978824138874188
Valid Loss:  0.0001721937005640939
Epoch:  404  	Training Loss: 0.00010797171853482723
Test Loss:  0.00010967042908305302
Valid Loss:  0.0001721191219985485
Epoch:  405  	Training Loss: 0.00010790390660986304
Test Loss:  0.00010957600170513615
Valid Loss:  0.00017205426411237568
Epoch:  406  	Training Loss: 0.00010783548350445926
Test Loss:  0.00010948935232590884
Valid Loss:  0.00017198966816067696
Epoch:  407  	Training Loss: 0.00010776780982268974
Test Loss:   82%|████████▏ | 408/500 [04:47<00:42,  2.16it/s] 82%|████████▏ | 410/500 [04:47<00:30,  2.92it/s] 82%|████████▏ | 412/500 [04:53<01:44,  1.19s/it] 83%|████████▎ | 414/500 [04:53<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:53<00:51,  1.62it/s] 84%|████████▎ | 418/500 [04:53<00:37,  2.21it/s] 84%|████████▍ | 420/500 [04:54<00:26,  2.98it/s] 84%|████████▍ | 422/500 [05:00<01:32,  1.19s/it] 85%|████████▍ | 424/500 [05:00<01:05,  1.17it/s] 85%|████████▌ | 426/500 [05:00<00:45,  1.61it/s] 86%|████████▌ | 428/500 [05:00<00:32,  2.20it/s] 86%|████████▌ | 430/500 [05:01<00:23,  2.97it/s] 86%|████████▋ | 432/500 [05:07<01:21,  1.19s/it] 87%|████████▋ | 434/500 [05:07<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:07<00:39,  1.62it/s] 88%|████████▊ | 438/500 [05:07<00:28,  2.20it/s] 88%|████████▊ | 440/500 [05:07<00:20,  2.96it/s] 88%|████████▊ | 442/500 [05:14<01:10,  1.21s/it] 89%|████████▉ | 444/500 [05:14<00:48,  1.15it/s] 89%|████████▉ | 446/500 [05:14<00:33,  1.60it/s] 90%|████████▉ | 448/500 [05:14<00:23,  2.18it/s] 90%|█████████ | 450/500 [05:14<00:17,  2.93it/s] 90%|█████████ | 452/500 [05:21<00:57,  1.21s/it] 91%|█████████ | 454/500 [05:21<00:39,  1.16it/s] 91%|█████████ | 456/500 [05:21<00:27,  1.60it/s] 92%|█████████▏| 458/500 [05:21<00:19,  2.18it/s] 92%|█████████▏| 460/500 [05:21<00:13,  2.94it/s] 92%|█████████▏| 462/500 [05:28<00:45,  1.20s/it] 93%|█████████▎| 464/500 [05:28<00:31,  1.16it/s] 93%|█████████▎| 466/500 [05:28<00:21,  1.60it/s] 94%|█████████▎| 468/500 [05:28<00:14,  2.18it/s] 94%|█████████▍| 470/500 [05:28<00:10,  2.93it/s] 94%|█████████▍| 472/500 [05:35<00:34,  1.22s/it]0.00010939901403617114
Valid Loss:  0.0001719237770885229
Epoch:  408  	Training Loss: 0.00010770020162453875
Test Loss:  0.0001093171740649268
Valid Loss:  0.00017185852630063891
Epoch:  409  	Training Loss: 0.00010763340105768293
Test Loss:  0.00010923952504526824
Valid Loss:  0.00017179686983581632
Epoch:  410  	Training Loss: 0.0001075668988050893
Test Loss:  0.00010916816972894594
Valid Loss:  0.000171735038748011
Epoch:  411  	Training Loss: 0.00010750239744083956
Test Loss:  0.00010909277625614777
Valid Loss:  0.0001716717961244285
Epoch:  412  	Training Loss: 0.00010743753227870911
Test Loss:  0.00010896618914557621
Valid Loss:  0.00017157768888864666
Epoch:  413  	Training Loss: 0.000107350162579678
Test Loss:  0.00010886152449529618
Valid Loss:  0.0001714883401291445
Epoch:  414  	Training Loss: 0.00010726406617322937
Test Loss:  0.00010877370368689299
Valid Loss:  0.00017140404088422656
Epoch:  415  	Training Loss: 0.00010718022531364113
Test Loss:  0.00010869766992982477
Valid Loss:  0.00017132337961811572
Epoch:  416  	Training Loss: 0.0001070981816155836
Test Loss:  0.00010862695489777252
Valid Loss:  0.00017124292207881808
Epoch:  417  	Training Loss: 0.00010701757855713367
Test Loss:  0.00010856006701942533
Valid Loss:  0.00017116304661612958
Epoch:  418  	Training Loss: 0.00010693656804505736
Test Loss:  0.00010849534737644717
Valid Loss:  0.00017108640167862177
Epoch:  419  	Training Loss: 0.00010685643064789474
Test Loss:  0.0001084344694390893
Valid Loss:  0.000171009567566216
Epoch:  420  	Training Loss: 0.00010677593672880903
Test Loss:  0.00010837538866326213
Valid Loss:  0.000170931700267829
Epoch:  421  	Training Loss: 0.00010669615585356951
Test Loss:  0.0001083183306036517
Valid Loss:  0.00017085594299715012
Epoch:  422  	Training Loss: 0.00010661625128705055
Test Loss:  0.00010825404024217278
Valid Loss:  0.0001707348710624501
Epoch:  423  	Training Loss: 0.00010652185301296413
Test Loss:  0.00010818686860147864
Valid Loss:  0.0001706173934508115
Epoch:  424  	Training Loss: 0.00010642856068443507
Test Loss:  0.00010812390246428549
Valid Loss:  0.0001705021713860333
Epoch:  425  	Training Loss: 0.00010633566125761718
Test Loss:  0.00010806133650476113
Valid Loss:  0.0001703863963484764
Epoch:  426  	Training Loss: 0.00010624167771311477
Test Loss:  0.00010802675387822092
Valid Loss:  0.00017028136062435806
Epoch:  427  	Training Loss: 0.00010615013889037073
Test Loss:  0.00010798389848787338
Valid Loss:  0.00017017638310790062
Epoch:  428  	Training Loss: 0.00010605754505377263
Test Loss:  0.00010793729597935453
Valid Loss:  0.00017007184214890003
Epoch:  429  	Training Loss: 0.00010596612264635041
Test Loss:  0.000107886953628622
Valid Loss:  0.00016996683552861214
Epoch:  430  	Training Loss: 0.00010587586439214647
Test Loss:  0.00010783705511130393
Valid Loss:  0.000169864681083709
Epoch:  431  	Training Loss: 0.0001057872868841514
Test Loss:  0.00010778452269732952
Valid Loss:  0.00016976450569927692
Epoch:  432  	Training Loss: 0.0001056988985510543
Test Loss:  0.00010774648399092257
Valid Loss:  0.00016957183834165335
Epoch:  433  	Training Loss: 0.00010527540871407837
Test Loss:  0.0001076004482456483
Valid Loss:  0.0001693640515441075
Epoch:  434  	Training Loss: 0.00010487291729077697
Test Loss:  0.0001074025931302458
Valid Loss:  0.00016914858133532107
Epoch:  435  	Training Loss: 0.00010449042019899935
Test Loss:  0.00010719343117671087
Valid Loss:  0.00016894265718292445
Epoch:  436  	Training Loss: 0.00010412388655822724
Test Loss:  0.00010697585821617395
Valid Loss:  0.00016874042921699584
Epoch:  437  	Training Loss: 0.00010379181185271591
Test Loss:  0.0001067665871232748
Valid Loss:  0.00016853927809279412
Epoch:  438  	Training Loss: 0.00010347551869926974
Test Loss:  0.00010656347876647487
Valid Loss:  0.00016833795234560966
Epoch:  439  	Training Loss: 0.00010317453416064382
Test Loss:  0.00010636160732246935
Valid Loss:  0.0001681371359154582
Epoch:  440  	Training Loss: 0.0001028882252285257
Test Loss:  0.00010616293729981408
Valid Loss:  0.00016793776012491435
Epoch:  441  	Training Loss: 0.00010261409624945372
Test Loss:  0.0001059656569850631
Valid Loss:  0.00016773861716501415
Epoch:  442  	Training Loss: 0.00010235082299914211
Test Loss:  0.00010582592221908271
Valid Loss:  0.0001675728999543935
Epoch:  443  	Training Loss: 0.00010221684351563454
Test Loss:  0.00010571161692496389
Valid Loss:  0.00016741696163080633
Epoch:  444  	Training Loss: 0.00010209073661826551
Test Loss:  0.00010562874376773834
Valid Loss:  0.00016727173351682723
Epoch:  445  	Training Loss: 0.00010196823859587312
Test Loss:  0.00010555566404946148
Valid Loss:  0.0001671335776336491
Epoch:  446  	Training Loss: 0.00010184891289100051
Test Loss:  0.00010549716535024345
Valid Loss:  0.00016699964180588722
Epoch:  447  	Training Loss: 0.00010173095506615937
Test Loss:  0.00010544396354816854
Valid Loss:  0.00016687187599018216
Epoch:  448  	Training Loss: 0.00010161559475818649
Test Loss:  0.00010539618961047381
Valid Loss:  0.00016674556536599994
Epoch:  449  	Training Loss: 0.00010150123853236437
Test Loss:  0.00010535083129070699
Valid Loss:  0.00016662347479723394
Epoch:  450  	Training Loss: 0.00010138820653082803
Test Loss:  0.00010530737927183509
Valid Loss:  0.00016650224279146641
Epoch:  451  	Training Loss: 0.00010127642599400133
Test Loss:  0.00010524874960538
Valid Loss:  0.0001663773728068918
Epoch:  452  	Training Loss: 0.0001011631975416094
Test Loss:  0.00010520881914999336
Valid Loss:  0.0001662963768467307
Epoch:  453  	Training Loss: 0.00010103516979143023
Test Loss:  0.00010515623580431566
Valid Loss:  0.00016621212125755847
Epoch:  454  	Training Loss: 0.00010090798605233431
Test Loss:  0.00010509378626011312
Valid Loss:  0.00016612577019259334
Epoch:  455  	Training Loss: 0.00010078119521494955
Test Loss:  0.0001050288847181946
Valid Loss:  0.00016603876429144293
Epoch:  456  	Training Loss: 0.00010065562673844397
Test Loss:  0.00010495919559616596
Valid Loss:  0.00016595012857578695
Epoch:  457  	Training Loss: 0.0001005309313768521
Test Loss:  0.00010488634143257514
Valid Loss:  0.00016586174024268985
Epoch:  458  	Training Loss: 0.00010040664346888661
Test Loss:  0.00010481331992195919
Valid Loss:  0.00016577282804064453
Epoch:  459  	Training Loss: 0.00010028356336988509
Test Loss:  0.00010474021837580949
Valid Loss:  0.00016568426508456469
Epoch:  460  	Training Loss: 0.00010016135638579726
Test Loss:  0.00010466705134604126
Valid Loss:  0.00016559715732000768
Epoch:  461  	Training Loss: 0.00010003989154938608
Test Loss:  0.00010459408804308623
Valid Loss:  0.0001655103114899248
Epoch:  462  	Training Loss: 9.991976548917592e-05
Test Loss:  0.00010450849367771298
Valid Loss:  0.00016541744116693735
Epoch:  463  	Training Loss: 9.983281051972881e-05
Test Loss:  0.00010442612983752042
Valid Loss:  0.00016532547306269407
Epoch:  464  	Training Loss: 9.974683780455962e-05
Test Loss:  0.00010434499563416466
Valid Loss:  0.000165233708685264
Epoch:  465  	Training Loss: 9.966017387341708e-05
Test Loss:  0.00010426562221255153
Valid Loss:  0.00016514179878868163
Epoch:  466  	Training Loss: 9.957439033314586e-05
Test Loss:  0.0001041862997226417
Valid Loss:  0.00016505074745509773
Epoch:  467  	Training Loss: 9.948905790224671e-05
Test Loss:  0.00010410765389679
Valid Loss:  0.00016495968156959862
Epoch:  468  	Training Loss: 9.940371819538996e-05
Test Loss:  0.0001040292700054124
Valid Loss:  0.00016486778622493148
Epoch:  469  	Training Loss: 9.9319098808337e-05
Test Loss:  0.00010395082063041627
Valid Loss:  0.00016477650206070393
Epoch:  470  	Training Loss: 9.923421021085232e-05
Test Loss:  0.00010386669600848109
Valid Loss:  0.0001646826131036505
Epoch:  471  	Training Loss: 9.915010014083236e-05
Test Loss:  0.00010377907165093347
Valid Loss:  0.00016458873869851232
Epoch:  472  	Training Loss: 9.906554623739794e-05
Test Loss:  0.0001036656612996012
Valid Loss:  0.00016451200644951314
Epoch:  473  	Training Loss: 9.903479076456279e-05
Test Loss:  0.00010357552673667669
Valid Loss:  0.00016444141510874033
Epoch:  474  	Training Loss: 9.900509030558169e-05
Test Loss:   95%|█████████▍| 474/500 [05:35<00:22,  1.14it/s] 95%|█████████▌| 476/500 [05:35<00:15,  1.57it/s] 96%|█████████▌| 478/500 [05:35<00:10,  2.15it/s] 96%|█████████▌| 480/500 [05:36<00:06,  2.90it/s] 96%|█████████▋| 482/500 [05:42<00:21,  1.21s/it] 97%|█████████▋| 484/500 [05:42<00:13,  1.15it/s] 97%|█████████▋| 486/500 [05:42<00:08,  1.57it/s] 98%|█████████▊| 488/500 [05:42<00:05,  2.12it/s] 98%|█████████▊| 490/500 [05:43<00:03,  2.81it/s] 98%|█████████▊| 492/500 [05:49<00:09,  1.22s/it] 99%|█████████▉| 494/500 [05:49<00:05,  1.15it/s] 99%|█████████▉| 496/500 [05:49<00:02,  1.59it/s]100%|█████████▉| 498/500 [05:50<00:00,  2.17it/s]100%|██████████| 500/500 [05:50<00:00,  2.91it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
0.00010350108641432598
Valid Loss:  0.00016437658632639796
Epoch:  475  	Training Loss: 9.897529525915161e-05
Test Loss:  0.00010343857866246253
Valid Loss:  0.00016431344556622207
Epoch:  476  	Training Loss: 9.894650429487228e-05
Test Loss:  0.00010338344873161986
Valid Loss:  0.0001642542047193274
Epoch:  477  	Training Loss: 9.891689842334017e-05
Test Loss:  0.00010333368845749646
Valid Loss:  0.00016419653547927737
Epoch:  478  	Training Loss: 9.888819477055222e-05
Test Loss:  0.00010328961070626974
Valid Loss:  0.00016413864796049893
Epoch:  479  	Training Loss: 9.885903273243457e-05
Test Loss:  0.00010324790491722524
Valid Loss:  0.0001640825648792088
Epoch:  480  	Training Loss: 9.882947779260576e-05
Test Loss:  0.00010320823639631271
Valid Loss:  0.00016402652545366436
Epoch:  481  	Training Loss: 9.88004103419371e-05
Test Loss:  0.00010316965926904231
Valid Loss:  0.00016397105355281383
Epoch:  482  	Training Loss: 9.877124830381945e-05
Test Loss:  0.00010316180851077661
Valid Loss:  0.0001638601825106889
Epoch:  483  	Training Loss: 9.865861647995189e-05
Test Loss:  0.00010313575330656022
Valid Loss:  0.00016374820552300662
Epoch:  484  	Training Loss: 9.854778909357265e-05
Test Loss:  0.00010309816570952535
Valid Loss:  0.00016363541362807155
Epoch:  485  	Training Loss: 9.843903535511345e-05
Test Loss:  0.00010305063187843189
Valid Loss:  0.00016352289821952581
Epoch:  486  	Training Loss: 9.833165677264333e-05
Test Loss:  0.00010299860150553286
Valid Loss:  0.00016341087757609785
Epoch:  487  	Training Loss: 9.822480205912143e-05
Test Loss:  0.00010294018284184858
Valid Loss:  0.0001633009233046323
Epoch:  488  	Training Loss: 9.811905329115689e-05
Test Loss:  0.00010287840268574655
Valid Loss:  0.0001631902123335749
Epoch:  489  	Training Loss: 9.80148179223761e-05
Test Loss:  0.00010281632421538234
Valid Loss:  0.00016308188787661493
Epoch:  490  	Training Loss: 9.791148477233946e-05
Test Loss:  0.0001027525431709364
Valid Loss:  0.0001629748148843646
Epoch:  491  	Training Loss: 9.780883556231856e-05
Test Loss:  0.00010268719051964581
Valid Loss:  0.00016286839672829956
Epoch:  492  	Training Loss: 9.770752512849867e-05
Test Loss:  0.00010261620627716184
Valid Loss:  0.00016267949831672013
Epoch:  493  	Training Loss: 9.759693057276309e-05
Test Loss:  0.00010253970685880631
Valid Loss:  0.00016249985492322594
Epoch:  494  	Training Loss: 9.748821321409196e-05
Test Loss:  0.00010246076271869242
Valid Loss:  0.00016232773486990482
Epoch:  495  	Training Loss: 9.738128574099392e-05
Test Loss:  0.0001023787772282958
Valid Loss:  0.0001621615665499121
Epoch:  496  	Training Loss: 9.727668657433242e-05
Test Loss:  0.00010229708277620375
Valid Loss:  0.00016200376558117568
Epoch:  497  	Training Loss: 9.717369539430365e-05
Test Loss:  0.00010221255797659978
Valid Loss:  0.00016185070853680372
Epoch:  498  	Training Loss: 9.707127173896879e-05
Test Loss:  0.00010212873166892678
Valid Loss:  0.00016170417075045407
Epoch:  499  	Training Loss: 9.697010682430118e-05
Test Loss:  0.0001020422059809789
Valid Loss:  0.0001615603396203369
Epoch:  500  	Training Loss: 9.686959674581885e-05
Test Loss:  0.00010195693175774068
Valid Loss:  0.0001614190696272999
seed is  6
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 15.87it/s]  1%|          | 4/500 [00:00<00:30, 16.07it/s]  1%|          | 6/500 [00:00<00:30, 16.23it/s]  2%|▏         | 8/500 [00:00<00:30, 16.19it/s]  2%|▏         | 10/500 [00:00<00:30, 16.12it/s]  2%|▏         | 12/500 [00:00<00:30, 16.17it/s]  3%|▎         | 14/500 [00:00<00:29, 16.27it/s]  3%|▎         | 16/500 [00:00<00:29, 16.36it/s]  4%|▎         | 18/500 [00:01<00:29, 16.33it/s]  4%|▍         | 20/500 [00:01<00:29, 16.32it/s]  4%|▍         | 22/500 [00:01<00:29, 16.34it/s]  5%|▍         | 24/500 [00:01<00:29, 16.30it/s]  5%|▌         | 26/500 [00:01<00:29, 16.33it/s]  6%|▌         | 28/500 [00:01<00:28, 16.34it/s]  6%|▌         | 30/500 [00:01<00:28, 16.35it/s]  6%|▋         | 32/500 [00:01<00:28, 16.34it/s]  7%|▋         | 34/500 [00:02<00:28, 16.39it/s]  7%|▋         | 36/500 [00:02<00:28, 16.40it/s]  8%|▊         | 38/500 [00:02<00:28, 16.40it/s]  8%|▊         | 40/500 [00:02<00:28, 16.37it/s]  8%|▊         | 42/500 [00:02<00:27, 16.41it/s]  9%|▉         | 44/500 [00:02<00:27, 16.39it/s]  9%|▉         | 46/500 [00:02<00:27, 16.35it/s] 10%|▉         | 48/500 [00:02<00:27, 16.35it/s] 10%|█         | 50/500 [00:03<00:27, 16.35it/s] 10%|█         | 52/500 [00:03<00:27, 16.43it/s] 11%|█         | 54/500 [00:03<00:27, 16.40it/s] 11%|█         | 56/500 [00:03<00:27, 16.37it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.27it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.27it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.30it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.30it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.33it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.34it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.30it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.86it/s] 15%|█▍        | 74/500 [00:04<00:29, 14.58it/s] 15%|█▌        | 76/500 [00:04<00:30, 13.86it/s] 16%|█▌        | 78/500 [00:04<00:31, 13.36it/s] 16%|█▌        | 80/500 [00:05<00:32, 13.05it/s] 16%|█▋        | 82/500 [00:05<00:30, 13.53it/s] 17%|█▋        | 84/500 [00:05<00:29, 14.30it/s] 17%|█▋        | 86/500 [00:05<00:27, 14.85it/s] 18%|█▊        | 88/500 [00:05<00:27, 15.24it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.55it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.80it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.73it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.86it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.69it/s] 20%|██        | 100/500 [00:06<00:25, 15.88it/s] 20%|██        | 102/500 [00:06<00:25, 15.83it/s] 21%|██        | 104/500 [00:06<00:24, 15.98it/s] 21%|██        | 106/500 [00:06<00:24, 16.16it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.22it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.22it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.24it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.27it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.31it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.31it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.33it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.27it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.27it/s]Epoch:  1  	Training Loss: 0.0236221831291914
Test Loss:  15.708338737487793
Valid Loss:  15.91786003112793
Epoch:  2  	Training Loss: 15.622446060180664
Test Loss:  345842368.0
Valid Loss:  338500160.0
Epoch:  3  	Training Loss: 342492032.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
 25%|██▌       | 126/500 [00:07<00:23, 16.25it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.25it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.24it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.23it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.25it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.23it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.24it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.27it/s] 28%|██▊       | 142/500 [00:08<00:22, 15.77it/s] 29%|██▉       | 144/500 [00:09<00:23, 15.44it/s] 29%|██▉       | 146/500 [00:09<00:23, 14.89it/s] 30%|██▉       | 148/500 [00:09<00:23, 15.24it/s] 30%|███       | 150/500 [00:09<00:22, 15.37it/s] 30%|███       | 152/500 [00:09<00:22, 15.68it/s] 31%|███       | 154/500 [00:09<00:21, 15.87it/s] 31%|███       | 156/500 [00:09<00:21, 15.97it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.08it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.12it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.23it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.26it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.31it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.18it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.15it/s] 34%|███▍      | 172/500 [00:10<00:20, 15.98it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.08it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.12it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.89it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.06it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.11it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.19it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.20it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.26it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.12it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.07it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.15it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.96it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.85it/s] 40%|████      | 200/500 [00:12<00:19, 15.69it/s] 40%|████      | 202/500 [00:12<00:19, 15.66it/s] 41%|████      | 204/500 [00:12<00:18, 15.81it/s] 41%|████      | 206/500 [00:12<00:18, 15.94it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.05it/s] 42%|████▏     | 210/500 [00:13<00:18, 16.03it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.10it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.19it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.97it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.17it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.24it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.33it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.32it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.33it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.29it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.24it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.30it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.28it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.22it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.26it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.31it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.13it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.85it/s] 49%|████▉     | 246/500 [00:15<00:15, 15.88it/s] 50%|████▉     | 248/500 [00:15<00:15, 15.76it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:15<00:15, 15.72it/s] 50%|█████     | 252/500 [00:15<00:15, 15.71it/s] 51%|█████     | 254/500 [00:15<00:15, 15.79it/s] 51%|█████     | 256/500 [00:16<00:15, 15.94it/s] 52%|█████▏    | 258/500 [00:16<00:15, 16.09it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.20it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.30it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.31it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.28it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.31it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.35it/s] 54%|█████▍    | 272/500 [00:17<00:13, 16.35it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.28it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.11it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.17it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.14it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.16it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.16it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.22it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.28it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.27it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.30it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.28it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.33it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.30it/s] 60%|██████    | 300/500 [00:18<00:12, 16.28it/s] 60%|██████    | 302/500 [00:18<00:12, 16.18it/s] 61%|██████    | 304/500 [00:18<00:12, 16.16it/s] 61%|██████    | 306/500 [00:19<00:12, 16.10it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.17it/s] 62%|██████▏   | 310/500 [00:19<00:12, 15.78it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.70it/s] 63%|██████▎   | 314/500 [00:19<00:11, 15.91it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.11it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.20it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.22it/s] 64%|██████▍   | 322/500 [00:20<00:11, 16.00it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.05it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.09it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.14it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.21it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.22it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.28it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.31it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.31it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.27it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.27it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.33it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.30it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.34it/s] 70%|███████   | 350/500 [00:21<00:09, 16.32it/s] 70%|███████   | 352/500 [00:21<00:09, 16.36it/s] 71%|███████   | 354/500 [00:22<00:08, 16.37it/s] 71%|███████   | 356/500 [00:22<00:08, 16.41it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.33it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.32it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.36it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.41it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.39it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.41it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.42it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.44it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:23<00:08, 15.71it/s] 75%|███████▌  | 376/500 [00:23<00:07, 15.79it/s] 76%|███████▌  | 378/500 [00:23<00:07, 15.93it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.08it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.17it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.27it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.19it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.01it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.09it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.15it/s] 79%|███████▉  | 394/500 [00:24<00:06, 15.77it/s] 79%|███████▉  | 396/500 [00:24<00:06, 15.95it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.03it/s] 80%|████████  | 400/500 [00:24<00:06, 15.69it/s] 80%|████████  | 402/500 [00:25<00:06, 14.44it/s] 81%|████████  | 404/500 [00:25<00:06, 14.30it/s] 81%|████████  | 406/500 [00:25<00:06, 14.87it/s] 82%|████████▏ | 408/500 [00:25<00:06, 15.31it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.58it/s] 82%|████████▏ | 412/500 [00:25<00:05, 15.82it/s] 83%|████████▎ | 414/500 [00:25<00:05, 15.98it/s] 83%|████████▎ | 416/500 [00:25<00:05, 15.91it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.06it/s] 84%|████████▍ | 420/500 [00:26<00:05, 15.97it/s] 84%|████████▍ | 422/500 [00:26<00:05, 14.89it/s] 85%|████████▍ | 424/500 [00:26<00:05, 14.03it/s] 85%|████████▌ | 426/500 [00:26<00:05, 13.47it/s] 86%|████████▌ | 428/500 [00:26<00:05, 13.11it/s] 86%|████████▌ | 430/500 [00:27<00:05, 12.87it/s] 86%|████████▋ | 432/500 [00:27<00:05, 13.25it/s] 87%|████████▋ | 434/500 [00:27<00:04, 14.05it/s] 87%|████████▋ | 436/500 [00:27<00:04, 14.72it/s] 88%|████████▊ | 438/500 [00:27<00:04, 15.09it/s] 88%|████████▊ | 440/500 [00:27<00:03, 15.46it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.77it/s] 89%|████████▉ | 444/500 [00:27<00:03, 15.93it/s] 89%|████████▉ | 446/500 [00:28<00:03, 15.89it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.04it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.07it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.10it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.13it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.20it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.23it/s] 92%|█████████▏| 460/500 [00:28<00:02, 15.13it/s] 92%|█████████▏| 462/500 [00:29<00:02, 14.34it/s] 93%|█████████▎| 464/500 [00:29<00:02, 14.85it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.19it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.50it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.76it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.97it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.09it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.24it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.24it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.26it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.29it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.28it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.35it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.17it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.07it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.20it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.23it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.20it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:31<00:00, 16.20it/s]100%|██████████| 500/500 [00:31<00:00, 16.14it/s]100%|██████████| 500/500 [00:31<00:00, 15.91it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  6
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:36,  6.21s/it]  1%|          | 3/500 [00:06<13:46,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<11:02,  1.35s/it]  3%|▎         | 13/500 [00:13<07:34,  1.07it/s]  3%|▎         | 15/500 [00:13<05:19,  1.52it/s]  3%|▎         | 17/500 [00:13<03:50,  2.09it/s]  4%|▍         | 19/500 [00:13<02:51,  2.81it/s]  4%|▍         | 21/500 [00:20<09:47,  1.23s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:36,  2.18it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:27<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:38,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.62it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:34<06:25,  1.19it/s]  9%|▉         | 45/500 [00:34<04:37,  1.64it/s]  9%|▉         | 47/500 [00:34<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:43,  1.17s/it] 11%|█         | 53/500 [00:40<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:41<03:16,  2.26it/s] 12%|█▏        | 59/500 [00:41<02:25,  3.03it/s] 12%|█▏        | 61/500 [00:47<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.22it/s] 14%|█▍        | 69/500 [00:48<02:24,  2.99it/s] 14%|█▍        | 71/500 [00:54<08:37,  1.21s/it]Epoch:  1  	Training Loss: 0.0236221831291914
Test Loss:  0.08338497579097748
Valid Loss:  0.09987175464630127
Epoch:  2  	Training Loss: 0.07755014300346375
Test Loss:  1.5209615230560303
Valid Loss:  1.4017877578735352
Epoch:  3  	Training Loss: 1.4035776853561401
Test Loss:  0.03926249220967293
Valid Loss:  0.04076152667403221
Epoch:  4  	Training Loss: 0.032602667808532715
Test Loss:  0.03915063291788101
Valid Loss:  0.04065840318799019
Epoch:  5  	Training Loss: 0.03253724053502083
Test Loss:  0.03903938829898834
Valid Loss:  0.040555842220783234
Epoch:  6  	Training Loss: 0.03247220814228058
Test Loss:  0.03892872482538223
Valid Loss:  0.04045381397008896
Epoch:  7  	Training Loss: 0.03240755945444107
Test Loss:  0.03881865739822388
Valid Loss:  0.04035232961177826
Epoch:  8  	Training Loss: 0.0323433019220829
Test Loss:  0.03870919346809387
Valid Loss:  0.040251392871141434
Epoch:  9  	Training Loss: 0.03227942809462547
Test Loss:  0.03860030323266983
Valid Loss:  0.04015098139643669
Epoch:  10  	Training Loss: 0.03221593052148819
Test Loss:  0.03849199414253235
Valid Loss:  0.04005109891295433
Epoch:  11  	Training Loss: 0.03215280920267105
Test Loss:  0.038384273648262024
Valid Loss:  0.03995174169540405
Epoch:  12  	Training Loss: 0.03209006413817406
Test Loss:  0.03826963156461716
Valid Loss:  0.03984520211815834
Epoch:  13  	Training Loss: 0.03202258050441742
Test Loss:  0.03815557062625885
Valid Loss:  0.03973918408155441
Epoch:  14  	Training Loss: 0.031955473124980927
Test Loss:  0.0380420908331871
Valid Loss:  0.03963370621204376
Epoch:  15  	Training Loss: 0.031888749450445175
Test Loss:  0.03792918473482132
Valid Loss:  0.039528749883174896
Epoch:  16  	Training Loss: 0.03182239830493927
Test Loss:  0.0378168523311615
Valid Loss:  0.039424315094947815
Epoch:  17  	Training Loss: 0.03175642341375351
Test Loss:  0.037705086171627045
Valid Loss:  0.03932040184736252
Epoch:  18  	Training Loss: 0.0316908173263073
Test Loss:  0.03759388253092766
Valid Loss:  0.03921700641512871
Epoch:  19  	Training Loss: 0.03162558376789093
Test Loss:  0.03748323768377304
Valid Loss:  0.03911411762237549
Epoch:  20  	Training Loss: 0.031560707837343216
Test Loss:  0.03737315535545349
Valid Loss:  0.03901175037026405
Epoch:  21  	Training Loss: 0.03149619698524475
Test Loss:  0.03726363182067871
Valid Loss:  0.03890988230705261
Epoch:  22  	Training Loss: 0.03143204748630524
Test Loss:  0.03715645521879196
Valid Loss:  0.03881034627556801
Epoch:  23  	Training Loss: 0.03136944770812988
Test Loss:  0.037049829959869385
Valid Loss:  0.0387113094329834
Epoch:  24  	Training Loss: 0.03130719065666199
Test Loss:  0.03694372996687889
Valid Loss:  0.03861275315284729
Epoch:  25  	Training Loss: 0.031245283782482147
Test Loss:  0.036838166415691376
Valid Loss:  0.03851468116044998
Epoch:  26  	Training Loss: 0.031183719635009766
Test Loss:  0.03673312067985535
Valid Loss:  0.03841709718108177
Epoch:  27  	Training Loss: 0.031122492626309395
Test Loss:  0.0366286039352417
Valid Loss:  0.03831998631358147
Epoch:  28  	Training Loss: 0.031061602756381035
Test Loss:  0.03652461618185043
Valid Loss:  0.038223352283239365
Epoch:  29  	Training Loss: 0.031001050025224686
Test Loss:  0.03642113879323006
Valid Loss:  0.03812719136476517
Epoch:  30  	Training Loss: 0.03094082698225975
Test Loss:  0.03631817549467087
Valid Loss:  0.03803149610757828
Epoch:  31  	Training Loss: 0.030880935490131378
Test Loss:  0.036215730011463165
Valid Loss:  0.03793627768754959
Epoch:  32  	Training Loss: 0.03082137368619442
Test Loss:  0.03611444681882858
Valid Loss:  0.03784224018454552
Epoch:  33  	Training Loss: 0.030762627720832825
Test Loss:  0.036013659089803696
Valid Loss:  0.03774865344166756
Epoch:  34  	Training Loss: 0.030704203993082047
Test Loss:  0.035913366824388504
Valid Loss:  0.03765552118420601
Epoch:  35  	Training Loss: 0.030646096915006638
Test Loss:  0.03581357002258301
Valid Loss:  0.037562835961580276
Epoch:  36  	Training Loss: 0.030588295310735703
Test Loss:  0.03571426123380661
Valid Loss:  0.03747059032320976
Epoch:  37  	Training Loss: 0.030530808493494987
Test Loss:  0.035615429282188416
Valid Loss:  0.037378787994384766
Epoch:  38  	Training Loss: 0.030473630875349045
Test Loss:  0.03551708534359932
Valid Loss:  0.03728742152452469
Epoch:  39  	Training Loss: 0.030416764318943024
Test Loss:  0.03541921451687813
Valid Loss:  0.03719649463891983
Epoch:  40  	Training Loss: 0.03036019764840603
Test Loss:  0.03532182425260544
Valid Loss:  0.037105999886989594
Epoch:  41  	Training Loss: 0.03030393458902836
Test Loss:  0.035224903374910355
Valid Loss:  0.03701593354344368
Epoch:  42  	Training Loss: 0.030247971415519714
Test Loss:  0.035128992050886154
Valid Loss:  0.036926865577697754
Epoch:  43  	Training Loss: 0.030192693695425987
Test Loss:  0.03503355383872986
Valid Loss:  0.03683822602033615
Epoch:  44  	Training Loss: 0.030137712135910988
Test Loss:  0.03493858128786087
Valid Loss:  0.03675001859664917
Epoch:  45  	Training Loss: 0.030083030462265015
Test Loss:  0.03484408184885979
Valid Loss:  0.03666223585605621
Epoch:  46  	Training Loss: 0.03002864122390747
Test Loss:  0.03475004434585571
Valid Loss:  0.03657486289739609
Epoch:  47  	Training Loss: 0.029974542558193207
Test Loss:  0.03465646505355835
Valid Loss:  0.03648792579770088
Epoch:  48  	Training Loss: 0.029920736327767372
Test Loss:  0.034563351422548294
Valid Loss:  0.03640139102935791
Epoch:  49  	Training Loss: 0.029867220669984818
Test Loss:  0.034470684826374054
Valid Loss:  0.03631528094410896
Epoch:  50  	Training Loss: 0.029813984408974648
Test Loss:  0.034378476440906525
Valid Loss:  0.03622958064079285
Epoch:  51  	Training Loss: 0.029761040583252907
Test Loss:  0.034286707639694214
Valid Loss:  0.036144278943538666
Epoch:  52  	Training Loss: 0.029708370566368103
Test Loss:  0.03419610112905502
Valid Loss:  0.03606008365750313
Epoch:  53  	Training Loss: 0.029656413942575455
Test Loss:  0.03410591185092926
Valid Loss:  0.03597626835107803
Epoch:  54  	Training Loss: 0.029604721814393997
Test Loss:  0.03401615098118782
Valid Loss:  0.035892847925424576
Epoch:  55  	Training Loss: 0.02955329790711403
Test Loss:  0.03392680734395981
Valid Loss:  0.035809800028800964
Epoch:  56  	Training Loss: 0.02950213849544525
Test Loss:  0.03383788466453552
Valid Loss:  0.035727135837078094
Epoch:  57  	Training Loss: 0.029451236128807068
Test Loss:  0.03374938666820526
Valid Loss:  0.03564484789967537
Epoch:  58  	Training Loss: 0.029400594532489777
Test Loss:  0.033661291003227234
Valid Loss:  0.03556293249130249
Epoch:  59  	Training Loss: 0.029350213706493378
Test Loss:  0.033573612570762634
Valid Loss:  0.03548138961195946
Epoch:  60  	Training Loss: 0.029300086200237274
Test Loss:  0.03348633274435997
Valid Loss:  0.03540021926164627
Epoch:  61  	Training Loss: 0.029250212013721466
Test Loss:  0.033399470150470734
Valid Loss:  0.03531941771507263
Epoch:  62  	Training Loss: 0.029200591146945953
Test Loss:  0.03331282362341881
Valid Loss:  0.035238854587078094
Epoch:  63  	Training Loss: 0.029151177033782005
Test Loss:  0.033226579427719116
Valid Loss:  0.0351586639881134
Epoch:  64  	Training Loss: 0.029102012515068054
Test Loss:  0.03314073383808136
Valid Loss:  0.03507883846759796
Epoch:  65  	Training Loss: 0.02905309572815895
Test Loss:  0.033055298030376434
Valid Loss:  0.03499937802553177
Epoch:  66  	Training Loss: 0.029004434123635292
Test Loss:  0.032970257103443146
Valid Loss:  0.03492027148604393
Epoch:  67  	Training Loss: 0.028956012800335884
Test Loss:  0.032885607331991196
Valid Loss:  0.03484151512384415
Epoch:  68  	Training Loss: 0.028907831758260727
Test Loss:  0.032801344990730286
Valid Loss:  0.034763120114803314
Epoch:  69  	Training Loss: 0.02885989099740982
Test Loss:  0.03271748125553131
Valid Loss:  0.034685079008340836
Epoch:  70  	Training Loss: 0.028812194243073463
Test Loss:  0.032634008675813675
Valid Loss:  0.03460739552974701
Epoch:  71  	Training Loss: 0.028764741495251656
Test Loss:  0.03255091607570648
Valid Loss:  0.03453005850315094
Epoch:  72  	Training Loss: 0.0287175215780735
Test Loss:  0.03246864676475525
Valid Loss:   15%|█▍        | 73/500 [00:54<06:10,  1.15it/s] 15%|█▌        | 75/500 [00:54<04:26,  1.60it/s] 15%|█▌        | 77/500 [00:54<03:13,  2.18it/s] 16%|█▌        | 79/500 [00:55<02:23,  2.93it/s] 16%|█▌        | 81/500 [01:01<08:16,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:01<03:11,  2.15it/s] 18%|█▊        | 89/500 [01:02<02:23,  2.86it/s] 18%|█▊        | 91/500 [01:08<08:18,  1.22s/it] 19%|█▊        | 93/500 [01:08<05:56,  1.14it/s] 19%|█▉        | 95/500 [01:08<04:16,  1.58it/s] 19%|█▉        | 97/500 [01:09<03:07,  2.15it/s] 20%|█▉        | 99/500 [01:09<02:20,  2.85it/s] 20%|██        | 101/500 [01:15<08:08,  1.22s/it] 20%|██        | 102/500 [01:15<06:48,  1.03s/it] 21%|██        | 104/500 [01:16<04:41,  1.41it/s] 21%|██        | 106/500 [01:16<03:18,  1.98it/s] 22%|██▏       | 108/500 [01:16<02:23,  2.73it/s] 22%|██▏       | 110/500 [01:16<01:46,  3.67it/s] 22%|██▏       | 112/500 [01:22<07:36,  1.18s/it] 23%|██▎       | 114/500 [01:23<05:25,  1.19it/s] 23%|██▎       | 116/500 [01:23<03:55,  1.63it/s] 24%|██▎       | 118/500 [01:23<02:53,  2.21it/s] 24%|██▍       | 120/500 [01:23<02:11,  2.90it/s] 24%|██▍       | 122/500 [01:29<07:30,  1.19s/it] 25%|██▍       | 124/500 [01:29<05:20,  1.17it/s] 25%|██▌       | 126/500 [01:30<03:50,  1.62it/s] 26%|██▌       | 128/500 [01:30<02:47,  2.22it/s] 26%|██▌       | 130/500 [01:30<02:04,  2.98it/s] 26%|██▋       | 132/500 [01:36<07:16,  1.19s/it] 27%|██▋       | 134/500 [01:36<05:10,  1.18it/s] 27%|██▋       | 136/500 [01:36<03:43,  1.63it/s] 28%|██▊       | 138/500 [01:37<02:42,  2.22it/s] 28%|██▊       | 140/500 [01:37<02:00,  2.99it/s] 28%|██▊       | 142/500 [01:43<07:06,  1.19s/it]0.034453485161066055
Epoch:  73  	Training Loss: 0.028670798987150192
Test Loss:  0.03238674998283386
Valid Loss:  0.03437726944684982
Epoch:  74  	Training Loss: 0.028624314814805984
Test Loss:  0.032305240631103516
Valid Loss:  0.034301381558179855
Epoch:  75  	Training Loss: 0.02857806161046028
Test Loss:  0.032224107533693314
Valid Loss:  0.034225836396217346
Epoch:  76  	Training Loss: 0.028532039374113083
Test Loss:  0.03214334696531296
Valid Loss:  0.034150633960962296
Epoch:  77  	Training Loss: 0.02848624251782894
Test Loss:  0.03206295147538185
Valid Loss:  0.03407575935125351
Epoch:  78  	Training Loss: 0.028440672904253006
Test Loss:  0.03198293596506119
Valid Loss:  0.03400123119354248
Epoch:  79  	Training Loss: 0.028395328670740128
Test Loss:  0.03190327435731888
Valid Loss:  0.03392701968550682
Epoch:  80  	Training Loss: 0.028350209817290306
Test Loss:  0.03182399272918701
Valid Loss:  0.03385315090417862
Epoch:  81  	Training Loss: 0.02830531820654869
Test Loss:  0.0317450612783432
Valid Loss:  0.03377959877252579
Epoch:  82  	Training Loss: 0.02826063334941864
Test Loss:  0.03166692331433296
Valid Loss:  0.033706799149513245
Epoch:  83  	Training Loss: 0.02821643278002739
Test Loss:  0.03158916160464287
Valid Loss:  0.033634331077337265
Epoch:  84  	Training Loss: 0.028172452002763748
Test Loss:  0.03151174262166023
Valid Loss:  0.033562175929546356
Epoch:  85  	Training Loss: 0.02812868356704712
Test Loss:  0.03143467381596565
Valid Loss:  0.033490344882011414
Epoch:  86  	Training Loss: 0.0280851311981678
Test Loss:  0.03135796636343002
Valid Loss:  0.03341883048415184
Epoch:  87  	Training Loss: 0.028041793033480644
Test Loss:  0.03128160908818245
Valid Loss:  0.033347636461257935
Epoch:  88  	Training Loss: 0.02799866534769535
Test Loss:  0.031205615028738976
Valid Loss:  0.0332767590880394
Epoch:  89  	Training Loss: 0.027955755591392517
Test Loss:  0.031129969283938408
Valid Loss:  0.033206209540367126
Epoch:  90  	Training Loss: 0.027913054451346397
Test Loss:  0.031054668128490448
Valid Loss:  0.03313596174120903
Epoch:  91  	Training Loss: 0.027870560064911842
Test Loss:  0.030979707837104797
Valid Loss:  0.033066026866436005
Epoch:  92  	Training Loss: 0.027828272432088852
Test Loss:  0.03090507537126541
Valid Loss:  0.03299642354249954
Epoch:  93  	Training Loss: 0.027786223217844963
Test Loss:  0.030830789357423782
Valid Loss:  0.032927125692367554
Epoch:  94  	Training Loss: 0.02774437889456749
Test Loss:  0.03075682371854782
Valid Loss:  0.032858122140169144
Epoch:  95  	Training Loss: 0.027702733874320984
Test Loss:  0.030683202669024467
Valid Loss:  0.032789431512355804
Epoch:  96  	Training Loss: 0.027661286294460297
Test Loss:  0.030609911307692528
Valid Loss:  0.03272102773189545
Epoch:  97  	Training Loss: 0.027620036154985428
Test Loss:  0.030536949634552002
Valid Loss:  0.032652925699949265
Epoch:  98  	Training Loss: 0.027578985318541527
Test Loss:  0.030464299023151398
Valid Loss:  0.032585106790065765
Epoch:  99  	Training Loss: 0.02753812074661255
Test Loss:  0.03039199486374855
Valid Loss:  0.03251759335398674
Epoch:  100  	Training Loss: 0.027497462928295135
Test Loss:  0.030319999903440475
Valid Loss:  0.0324503630399704
Epoch:  101  	Training Loss: 0.027456985786557198
Test Loss:  0.030248334631323814
Valid Loss:  0.032383427023887634
Epoch:  102  	Training Loss: 0.027416706085205078
Test Loss:  0.030177250504493713
Valid Loss:  0.03231704980134964
Epoch:  103  	Training Loss: 0.02737678587436676
Test Loss:  0.03010648488998413
Valid Loss:  0.03225095570087433
Epoch:  104  	Training Loss: 0.027337051928043365
Test Loss:  0.030036039650440216
Valid Loss:  0.0321851447224617
Epoch:  105  	Training Loss: 0.027297504246234894
Test Loss:  0.029965903609991074
Valid Loss:  0.03211962804198265
Epoch:  106  	Training Loss: 0.027258148416876793
Test Loss:  0.029896073043346405
Valid Loss:  0.03205437958240509
Epoch:  107  	Training Loss: 0.027218971401453018
Test Loss:  0.029826564714312553
Valid Loss:  0.031989410519599915
Epoch:  108  	Training Loss: 0.027179976925253868
Test Loss:  0.029757365584373474
Valid Loss:  0.03192473202943802
Epoch:  109  	Training Loss: 0.02714116871356964
Test Loss:  0.02968846634030342
Valid Loss:  0.031860318034887314
Epoch:  110  	Training Loss: 0.02710253931581974
Test Loss:  0.02961987629532814
Valid Loss:  0.031796179711818695
Epoch:  111  	Training Loss: 0.027064088732004166
Test Loss:  0.02955159731209278
Valid Loss:  0.03173232078552246
Epoch:  112  	Training Loss: 0.027025822550058365
Test Loss:  0.029483437538146973
Valid Loss:  0.03166859596967697
Epoch:  113  	Training Loss: 0.026987679302692413
Test Loss:  0.029415585100650787
Valid Loss:  0.031605154275894165
Epoch:  114  	Training Loss: 0.026949722319841385
Test Loss:  0.02934805117547512
Valid Loss:  0.031541988253593445
Epoch:  115  	Training Loss: 0.026911942288279533
Test Loss:  0.02928081899881363
Valid Loss:  0.03147910162806511
Epoch:  116  	Training Loss: 0.026874344795942307
Test Loss:  0.02921389974653721
Valid Loss:  0.03141649439930916
Epoch:  117  	Training Loss: 0.026836924254894257
Test Loss:  0.02914729341864586
Valid Loss:  0.03135417029261589
Epoch:  118  	Training Loss: 0.02679969184100628
Test Loss:  0.029080985113978386
Valid Loss:  0.031292106956243515
Epoch:  119  	Training Loss: 0.02676262892782688
Test Loss:  0.02901497110724449
Valid Loss:  0.03123031184077263
Epoch:  120  	Training Loss: 0.026725739240646362
Test Loss:  0.028949256986379623
Valid Loss:  0.031168796122074127
Epoch:  121  	Training Loss: 0.02668902464210987
Test Loss:  0.02888384647667408
Valid Loss:  0.031107541173696518
Epoch:  122  	Training Loss: 0.02665247954428196
Test Loss:  0.02881920151412487
Valid Loss:  0.031046979129314423
Epoch:  123  	Training Loss: 0.02661633864045143
Test Loss:  0.028754837810993195
Valid Loss:  0.030986670404672623
Epoch:  124  	Training Loss: 0.026580359786748886
Test Loss:  0.028690749779343605
Valid Loss:  0.030926600098609924
Epoch:  125  	Training Loss: 0.026544535532593727
Test Loss:  0.028626948595046997
Valid Loss:  0.030866798013448715
Epoch:  126  	Training Loss: 0.026508882641792297
Test Loss:  0.02856343612074852
Valid Loss:  0.030807245522737503
Epoch:  127  	Training Loss: 0.02647339180111885
Test Loss:  0.028500188142061234
Valid Loss:  0.030747950077056885
Epoch:  128  	Training Loss: 0.02643805742263794
Test Loss:  0.028437217697501183
Valid Loss:  0.030688880011439323
Epoch:  129  	Training Loss: 0.026402879506349564
Test Loss:  0.02837452106177807
Valid Loss:  0.030630074441432953
Epoch:  130  	Training Loss: 0.026367859914898872
Test Loss:  0.02831210568547249
Valid Loss:  0.03057151287794113
Epoch:  131  	Training Loss: 0.026333002373576164
Test Loss:  0.02824995666742325
Valid Loss:  0.030513186007738113
Epoch:  132  	Training Loss: 0.026298295706510544
Test Loss:  0.02818673849105835
Valid Loss:  0.030453886836767197
Epoch:  133  	Training Loss: 0.02626303769648075
Test Loss:  0.028123775497078896
Valid Loss:  0.030394811183214188
Epoch:  134  	Training Loss: 0.0262279249727726
Test Loss:  0.028061065822839737
Valid Loss:  0.030335962772369385
Epoch:  135  	Training Loss: 0.026192955672740936
Test Loss:  0.027998603880405426
Valid Loss:  0.030277349054813385
Epoch:  136  	Training Loss: 0.026158137246966362
Test Loss:  0.027936402708292007
Valid Loss:  0.03021896257996559
Epoch:  137  	Training Loss: 0.02612346038222313
Test Loss:  0.027874447405338287
Valid Loss:  0.03016078658401966
Epoch:  138  	Training Loss: 0.026088925078511238
Test Loss:  0.027812747284770012
Valid Loss:  0.030102841556072235
Epoch:  139  	Training Loss: 0.026054536923766136
Test Loss:  0.027751294896006584
Valid Loss:  0.030045121908187866
Epoch:  140  	Training Loss: 0.026020286604762077
Test Loss:  0.027690080925822258
Valid Loss:  0.029987622052431107
Epoch:  141  	Training Loss: 0.025986183434724808
Test Loss:  0.027629118412733078
Valid Loss:  0.02993032895028591
Epoch:  142  	Training Loss: 0.025952214375138283
Test Loss:  0.027569608762860298
Valid Loss:  0.029874393716454506
Epoch:  143  	Training Loss: 0.025919053703546524
Test Loss:  0.027510346844792366
Valid Loss:   29%|██▉       | 144/500 [01:43<05:04,  1.17it/s] 29%|██▉       | 146/500 [01:43<03:38,  1.62it/s] 30%|██▉       | 148/500 [01:44<02:39,  2.21it/s] 30%|███       | 150/500 [01:44<01:57,  2.98it/s] 30%|███       | 152/500 [01:50<06:52,  1.18s/it] 31%|███       | 154/500 [01:50<04:53,  1.18it/s] 31%|███       | 156/500 [01:50<03:30,  1.63it/s] 32%|███▏      | 158/500 [01:50<02:33,  2.23it/s] 32%|███▏      | 160/500 [01:51<01:53,  3.00it/s] 32%|███▏      | 162/500 [01:57<06:51,  1.22s/it] 33%|███▎      | 164/500 [01:57<04:52,  1.15it/s] 33%|███▎      | 166/500 [01:57<03:31,  1.58it/s] 34%|███▎      | 168/500 [01:58<02:35,  2.13it/s] 34%|███▍      | 170/500 [01:58<01:56,  2.82it/s] 34%|███▍      | 172/500 [02:04<06:35,  1.21s/it] 35%|███▍      | 174/500 [02:04<04:41,  1.16it/s] 35%|███▌      | 176/500 [02:04<03:22,  1.60it/s] 36%|███▌      | 178/500 [02:04<02:27,  2.18it/s] 36%|███▌      | 180/500 [02:05<01:49,  2.93it/s] 36%|███▋      | 182/500 [02:11<06:19,  1.19s/it] 37%|███▋      | 184/500 [02:11<04:30,  1.17it/s] 37%|███▋      | 186/500 [02:11<03:14,  1.62it/s] 38%|███▊      | 188/500 [02:11<02:21,  2.21it/s] 38%|███▊      | 190/500 [02:12<01:44,  2.96it/s] 38%|███▊      | 192/500 [02:18<06:04,  1.18s/it] 39%|███▉      | 194/500 [02:18<04:21,  1.17it/s] 39%|███▉      | 196/500 [02:18<03:09,  1.61it/s] 40%|███▉      | 198/500 [02:18<02:19,  2.17it/s] 40%|████      | 200/500 [02:19<01:44,  2.86it/s] 40%|████      | 202/500 [02:25<06:05,  1.23s/it] 41%|████      | 204/500 [02:25<04:19,  1.14it/s] 41%|████      | 206/500 [02:25<03:06,  1.58it/s] 42%|████▏     | 208/500 [02:25<02:15,  2.16it/s] 42%|████▏     | 210/500 [02:26<01:39,  2.90it/s] 42%|████▏     | 212/500 [02:32<05:53,  1.23s/it]0.029818683862686157
Epoch:  144  	Training Loss: 0.025886032730340958
Test Loss:  0.027451343834400177
Valid Loss:  0.029763195663690567
Epoch:  145  	Training Loss: 0.02585316076874733
Test Loss:  0.027392586693167686
Valid Loss:  0.029707934707403183
Epoch:  146  	Training Loss: 0.025820426642894745
Test Loss:  0.027334081009030342
Valid Loss:  0.02965288981795311
Epoch:  147  	Training Loss: 0.0257878378033638
Test Loss:  0.027275823056697845
Valid Loss:  0.029598070308566093
Epoch:  148  	Training Loss: 0.0257553830742836
Test Loss:  0.02721780352294445
Valid Loss:  0.029543472453951836
Epoch:  149  	Training Loss: 0.025723066180944443
Test Loss:  0.027160033583641052
Valid Loss:  0.02948909066617489
Epoch:  150  	Training Loss: 0.02569088712334633
Test Loss:  0.02710251323878765
Valid Loss:  0.0294349305331707
Epoch:  151  	Training Loss: 0.025658849626779556
Test Loss:  0.0270452331751585
Valid Loss:  0.02938098832964897
Epoch:  152  	Training Loss: 0.02562694624066353
Test Loss:  0.026987917721271515
Valid Loss:  0.02932700887322426
Epoch:  153  	Training Loss: 0.02559504099190235
Test Loss:  0.026930825784802437
Valid Loss:  0.02927325665950775
Epoch:  154  	Training Loss: 0.02556326985359192
Test Loss:  0.026873981580138206
Valid Loss:  0.029219694435596466
Epoch:  155  	Training Loss: 0.025531627237796783
Test Loss:  0.02681736648082733
Valid Loss:  0.02916635386645794
Epoch:  156  	Training Loss: 0.02550012245774269
Test Loss:  0.026760999113321304
Valid Loss:  0.029113229364156723
Epoch:  157  	Training Loss: 0.025468748062849045
Test Loss:  0.02670486830174923
Valid Loss:  0.02906031720340252
Epoch:  158  	Training Loss: 0.025437505915760994
Test Loss:  0.02664896845817566
Valid Loss:  0.02900760993361473
Epoch:  159  	Training Loss: 0.02540639042854309
Test Loss:  0.026593297719955444
Valid Loss:  0.028955109417438507
Epoch:  160  	Training Loss: 0.02537541091442108
Test Loss:  0.026537852361798286
Valid Loss:  0.0289028137922287
Epoch:  161  	Training Loss: 0.025344548746943474
Test Loss:  0.026482637971639633
Valid Loss:  0.028850719332695007
Epoch:  162  	Training Loss: 0.025313816964626312
Test Loss:  0.026428235694766045
Valid Loss:  0.02879936434328556
Epoch:  163  	Training Loss: 0.02528351917862892
Test Loss:  0.026374049484729767
Valid Loss:  0.028748217970132828
Epoch:  164  	Training Loss: 0.02525334618985653
Test Loss:  0.026320084929466248
Valid Loss:  0.02869725227355957
Epoch:  165  	Training Loss: 0.025223292410373688
Test Loss:  0.026266351342201233
Valid Loss:  0.028646500781178474
Epoch:  166  	Training Loss: 0.025193365290760994
Test Loss:  0.026212839409708977
Valid Loss:  0.028595948591828346
Epoch:  167  	Training Loss: 0.025163553655147552
Test Loss:  0.02615955099463463
Valid Loss:  0.028545590117573738
Epoch:  168  	Training Loss: 0.025133870542049408
Test Loss:  0.026106471195816994
Valid Loss:  0.02849542163312435
Epoch:  169  	Training Loss: 0.025104306638240814
Test Loss:  0.026053622364997864
Valid Loss:  0.02844545990228653
Epoch:  170  	Training Loss: 0.02507486194372177
Test Loss:  0.0260009802877903
Valid Loss:  0.028395678848028183
Epoch:  171  	Training Loss: 0.025045529007911682
Test Loss:  0.02594856545329094
Valid Loss:  0.02834610641002655
Epoch:  172  	Training Loss: 0.02501632273197174
Test Loss:  0.025896860286593437
Valid Loss:  0.02829718589782715
Epoch:  173  	Training Loss: 0.024987511336803436
Test Loss:  0.02584538236260414
Valid Loss:  0.028248462826013565
Epoch:  174  	Training Loss: 0.024958815425634384
Test Loss:  0.02579410932958126
Valid Loss:  0.0281999371945858
Epoch:  175  	Training Loss: 0.024930236861109734
Test Loss:  0.025743059813976288
Valid Loss:  0.02815159596502781
Epoch:  176  	Training Loss: 0.024901773780584335
Test Loss:  0.02569221518933773
Valid Loss:  0.028103448450565338
Epoch:  177  	Training Loss: 0.02487342804670334
Test Loss:  0.025641582906246185
Valid Loss:  0.02805548906326294
Epoch:  178  	Training Loss: 0.024845197796821594
Test Loss:  0.025591162964701653
Valid Loss:  0.028007712215185165
Epoch:  179  	Training Loss: 0.024817079305648804
Test Loss:  0.02554095722734928
Valid Loss:  0.02796013280749321
Epoch:  180  	Training Loss: 0.024789076298475266
Test Loss:  0.025490954518318176
Valid Loss:  0.027912728488445282
Epoch:  181  	Training Loss: 0.024761181324720383
Test Loss:  0.025441158562898636
Valid Loss:  0.027865517884492874
Epoch:  182  	Training Loss: 0.0247334036976099
Test Loss:  0.025391187518835068
Valid Loss:  0.027818143367767334
Epoch:  183  	Training Loss: 0.024705544114112854
Test Loss:  0.02534141018986702
Valid Loss:  0.02777094580233097
Epoch:  184  	Training Loss: 0.024677790701389313
Test Loss:  0.025291839614510536
Valid Loss:  0.02772391587495804
Epoch:  185  	Training Loss: 0.024650149047374725
Test Loss:  0.025242464616894722
Valid Loss:  0.027677075937390327
Epoch:  186  	Training Loss: 0.024622609838843346
Test Loss:  0.025193290784955025
Valid Loss:  0.027630414813756943
Epoch:  187  	Training Loss: 0.02459518238902092
Test Loss:  0.025144316256046295
Valid Loss:  0.027583923190832138
Epoch:  188  	Training Loss: 0.02456786297261715
Test Loss:  0.025095544755458832
Valid Loss:  0.027537615969777107
Epoch:  189  	Training Loss: 0.024540644139051437
Test Loss:  0.02504695951938629
Valid Loss:  0.027491483837366104
Epoch:  190  	Training Loss: 0.02451353520154953
Test Loss:  0.024998579174280167
Valid Loss:  0.027445513755083084
Epoch:  191  	Training Loss: 0.024486524984240532
Test Loss:  0.024950383231043816
Valid Loss:  0.02739972621202469
Epoch:  192  	Training Loss: 0.02445961907505989
Test Loss:  0.024902496486902237
Valid Loss:  0.027354223653674126
Epoch:  193  	Training Loss: 0.02443290874361992
Test Loss:  0.02485480345785618
Valid Loss:  0.027308903634548187
Epoch:  194  	Training Loss: 0.024406304582953453
Test Loss:  0.024807311594486237
Valid Loss:  0.02726374752819538
Epoch:  195  	Training Loss: 0.024379804730415344
Test Loss:  0.024759996682405472
Valid Loss:  0.027218768373131752
Epoch:  196  	Training Loss: 0.02435341104865074
Test Loss:  0.02471289038658142
Valid Loss:  0.027173962444067
Epoch:  197  	Training Loss: 0.0243271142244339
Test Loss:  0.024665968492627144
Valid Loss:  0.02712932787835598
Epoch:  198  	Training Loss: 0.024300919845700264
Test Loss:  0.024619247764348984
Valid Loss:  0.027084864675998688
Epoch:  199  	Training Loss: 0.024274833500385284
Test Loss:  0.0245727077126503
Valid Loss:  0.027040567249059677
Epoch:  200  	Training Loss: 0.024248840287327766
Test Loss:  0.024526352062821388
Valid Loss:  0.026996441185474396
Epoch:  201  	Training Loss: 0.024222947657108307
Test Loss:  0.024480197578668594
Valid Loss:  0.026952475309371948
Epoch:  202  	Training Loss: 0.024197155609726906
Test Loss:  0.024434110149741173
Valid Loss:  0.026908576488494873
Epoch:  203  	Training Loss: 0.024171387776732445
Test Loss:  0.024388208985328674
Valid Loss:  0.02686484530568123
Epoch:  204  	Training Loss: 0.02414572238922119
Test Loss:  0.02434248849749565
Valid Loss:  0.02682127244770527
Epoch:  205  	Training Loss: 0.02412015199661255
Test Loss:  0.024296948686242104
Valid Loss:  0.026777848601341248
Epoch:  206  	Training Loss: 0.02409467101097107
Test Loss:  0.02425159141421318
Valid Loss:  0.026734596118330956
Epoch:  207  	Training Loss: 0.0240692887455225
Test Loss:  0.024206407368183136
Valid Loss:  0.026691503822803497
Epoch:  208  	Training Loss: 0.02404400147497654
Test Loss:  0.02416140027344227
Valid Loss:  0.026648562401533127
Epoch:  209  	Training Loss: 0.024018796160817146
Test Loss:  0.024116575717926025
Valid Loss:  0.02660578303039074
Epoch:  210  	Training Loss: 0.02399369329214096
Test Loss:  0.02407192811369896
Valid Loss:  0.02656315267086029
Epoch:  211  	Training Loss: 0.023968681693077087
Test Loss:  0.024027444422245026
Valid Loss:  0.026520688086748123
Epoch:  212  	Training Loss: 0.023943757638335228
Test Loss:  0.023983165621757507
Valid Loss:  0.02647838182747364
Epoch:  213  	Training Loss: 0.023918915539979935
Test Loss:  0.023939061909914017
Valid Loss:  0.026436228305101395
Epoch:  214  	Training Loss: 0.023894155398011208
Test Loss:   43%|████▎     | 214/500 [02:32<04:11,  1.14it/s] 43%|████▎     | 216/500 [02:32<03:01,  1.56it/s] 44%|████▎     | 218/500 [02:33<02:13,  2.11it/s] 44%|████▍     | 220/500 [02:33<01:40,  2.79it/s] 44%|████▍     | 222/500 [02:39<05:37,  1.21s/it] 45%|████▍     | 224/500 [02:39<03:59,  1.15it/s] 45%|████▌     | 226/500 [02:39<02:52,  1.59it/s] 46%|████▌     | 228/500 [02:40<02:05,  2.17it/s] 46%|████▌     | 230/500 [02:40<01:32,  2.92it/s] 46%|████▋     | 232/500 [02:46<05:19,  1.19s/it] 47%|████▋     | 234/500 [02:46<03:48,  1.17it/s] 47%|████▋     | 236/500 [02:46<02:45,  1.60it/s] 48%|████▊     | 238/500 [02:47<02:01,  2.15it/s] 48%|████▊     | 240/500 [02:47<01:31,  2.85it/s] 48%|████▊     | 242/500 [02:53<05:13,  1.21s/it] 49%|████▉     | 244/500 [02:53<03:42,  1.15it/s] 49%|████▉     | 246/500 [02:53<02:39,  1.59it/s] 50%|████▉     | 248/500 [02:54<01:55,  2.17it/s] 50%|█████     | 250/500 [02:54<01:25,  2.93it/s] 50%|█████     | 252/500 [03:00<04:56,  1.20s/it] 51%|█████     | 254/500 [03:00<03:30,  1.17it/s] 51%|█████     | 256/500 [03:00<02:31,  1.61it/s] 52%|█████▏    | 258/500 [03:01<01:49,  2.21it/s] 52%|█████▏    | 260/500 [03:01<01:21,  2.96it/s] 52%|█████▏    | 262/500 [03:07<04:45,  1.20s/it] 53%|█████▎    | 264/500 [03:07<03:22,  1.16it/s] 53%|█████▎    | 266/500 [03:07<02:25,  1.61it/s] 54%|█████▎    | 268/500 [03:07<01:45,  2.19it/s] 54%|█████▍    | 270/500 [03:08<01:17,  2.95it/s] 54%|█████▍    | 272/500 [03:14<04:30,  1.19s/it] 55%|█████▍    | 274/500 [03:14<03:12,  1.18it/s] 55%|█████▌    | 276/500 [03:14<02:17,  1.63it/s] 56%|█████▌    | 278/500 [03:14<01:39,  2.22it/s] 56%|█████▌    | 280/500 [03:14<01:13,  2.99it/s] 56%|█████▋    | 282/500 [03:21<04:15,  1.17s/it] 57%|█████▋    | 284/500 [03:21<03:01,  1.19it/s]0.023895107209682465
Valid Loss:  0.02639421448111534
Epoch:  215  	Training Loss: 0.023869486525654793
Test Loss:  0.02385132387280464
Valid Loss:  0.026352357119321823
Epoch:  216  	Training Loss: 0.023844901472330093
Test Loss:  0.023807715624570847
Valid Loss:  0.02631063386797905
Epoch:  217  	Training Loss: 0.02382040023803711
Test Loss:  0.023764271289110184
Valid Loss:  0.026269076392054558
Epoch:  218  	Training Loss: 0.023795992136001587
Test Loss:  0.02372099459171295
Valid Loss:  0.026227660477161407
Epoch:  219  	Training Loss: 0.02377166599035263
Test Loss:  0.02367788925766945
Valid Loss:  0.026186391711235046
Epoch:  220  	Training Loss: 0.023747427389025688
Test Loss:  0.023634934797883034
Valid Loss:  0.026145268231630325
Epoch:  221  	Training Loss: 0.023723270744085312
Test Loss:  0.023592155426740646
Valid Loss:  0.026104293763637543
Epoch:  222  	Training Loss: 0.02369920164346695
Test Loss:  0.02355068176984787
Valid Loss:  0.02606450766324997
Epoch:  223  	Training Loss: 0.023675795644521713
Test Loss:  0.023509353399276733
Valid Loss:  0.026024868711829185
Epoch:  224  	Training Loss: 0.02365247718989849
Test Loss:  0.023468179628252983
Valid Loss:  0.025985360145568848
Epoch:  225  	Training Loss: 0.023629233241081238
Test Loss:  0.02342718094587326
Valid Loss:  0.0259459987282753
Epoch:  226  	Training Loss: 0.023606078699231148
Test Loss:  0.02338632568717003
Valid Loss:  0.025906775146722794
Epoch:  227  	Training Loss: 0.023582998663187027
Test Loss:  0.023345638066530228
Valid Loss:  0.02586769498884678
Epoch:  228  	Training Loss: 0.02356000430881977
Test Loss:  0.023305099457502365
Valid Loss:  0.02582874521613121
Epoch:  229  	Training Loss: 0.023537084460258484
Test Loss:  0.023264706134796143
Valid Loss:  0.025789940729737282
Epoch:  230  	Training Loss: 0.023514240980148315
Test Loss:  0.023224474862217903
Valid Loss:  0.025751261040568352
Epoch:  231  	Training Loss: 0.023491477593779564
Test Loss:  0.0231843963265419
Valid Loss:  0.02571272850036621
Epoch:  232  	Training Loss: 0.02346878871321678
Test Loss:  0.02314327470958233
Valid Loss:  0.025673242285847664
Epoch:  233  	Training Loss: 0.023445619270205498
Test Loss:  0.023102302104234695
Valid Loss:  0.02563389576971531
Epoch:  234  	Training Loss: 0.023422526195645332
Test Loss:  0.023061487823724747
Valid Loss:  0.02559470385313034
Epoch:  235  	Training Loss: 0.023399515077471733
Test Loss:  0.023020830005407333
Valid Loss:  0.02555563673377037
Epoch:  236  	Training Loss: 0.02337658405303955
Test Loss:  0.022980334237217903
Valid Loss:  0.025516711175441742
Epoch:  237  	Training Loss: 0.023353733122348785
Test Loss:  0.02293998748064041
Valid Loss:  0.02547791600227356
Epoch:  238  	Training Loss: 0.02333095483481884
Test Loss:  0.022899793460965157
Valid Loss:  0.02543926239013672
Epoch:  239  	Training Loss: 0.02330825664103031
Test Loss:  0.022859744727611542
Valid Loss:  0.025400733575224876
Epoch:  240  	Training Loss: 0.023285631090402603
Test Loss:  0.02281985618174076
Valid Loss:  0.025362350046634674
Epoch:  241  	Training Loss: 0.02326308563351631
Test Loss:  0.02278011664748192
Valid Loss:  0.025324100628495216
Epoch:  242  	Training Loss: 0.02324061468243599
Test Loss:  0.022741828113794327
Valid Loss:  0.025287164375185966
Epoch:  243  	Training Loss: 0.023218873888254166
Test Loss:  0.02270367369055748
Valid Loss:  0.025250360369682312
Epoch:  244  	Training Loss: 0.02319720759987831
Test Loss:  0.022665686905384064
Valid Loss:  0.0252136941999197
Epoch:  245  	Training Loss: 0.023175612092018127
Test Loss:  0.02262784168124199
Valid Loss:  0.025177164003252983
Epoch:  246  	Training Loss: 0.02315409854054451
Test Loss:  0.022590145468711853
Valid Loss:  0.025140758603811264
Epoch:  247  	Training Loss: 0.023132655769586563
Test Loss:  0.022552594542503357
Valid Loss:  0.025104481726884842
Epoch:  248  	Training Loss: 0.023111283779144287
Test Loss:  0.022515185177326202
Valid Loss:  0.025068335235118866
Epoch:  249  	Training Loss: 0.02308998629450798
Test Loss:  0.022477924823760986
Valid Loss:  0.025032322853803635
Epoch:  250  	Training Loss: 0.023068763315677643
Test Loss:  0.02244080975651741
Valid Loss:  0.024996429681777954
Epoch:  251  	Training Loss: 0.023047611117362976
Test Loss:  0.022403836250305176
Valid Loss:  0.024960678070783615
Epoch:  252  	Training Loss: 0.02302652969956398
Test Loss:  0.022366436198353767
Valid Loss:  0.024924516677856445
Epoch:  253  	Training Loss: 0.02300521731376648
Test Loss:  0.02232915721833706
Valid Loss:  0.02488846704363823
Epoch:  254  	Training Loss: 0.0229839775711298
Test Loss:  0.02229202538728714
Valid Loss:  0.02485254593193531
Epoch:  255  	Training Loss: 0.022962801158428192
Test Loss:  0.022255029529333115
Valid Loss:  0.02481674589216709
Epoch:  256  	Training Loss: 0.022941691800951958
Test Loss:  0.022218164056539536
Valid Loss:  0.024781059473752975
Epoch:  257  	Training Loss: 0.022920653223991394
Test Loss:  0.022181443870067596
Valid Loss:  0.024745499715209007
Epoch:  258  	Training Loss: 0.022899683564901352
Test Loss:  0.022144857794046402
Valid Loss:  0.024710066616535187
Epoch:  259  	Training Loss: 0.022878777235746384
Test Loss:  0.022108400240540504
Valid Loss:  0.02467474713921547
Epoch:  260  	Training Loss: 0.022857937961816788
Test Loss:  0.02207208052277565
Valid Loss:  0.0246395505964756
Epoch:  261  	Training Loss: 0.022837167605757713
Test Loss:  0.022035900503396988
Valid Loss:  0.02460446208715439
Epoch:  262  	Training Loss: 0.022816460579633713
Test Loss:  0.021999668329954147
Valid Loss:  0.024569332599639893
Epoch:  263  	Training Loss: 0.02279573306441307
Test Loss:  0.021963562816381454
Valid Loss:  0.0245343204587698
Epoch:  264  	Training Loss: 0.0227750726044178
Test Loss:  0.021927595138549805
Valid Loss:  0.02449943497776985
Epoch:  265  	Training Loss: 0.022754479199647903
Test Loss:  0.02189176343381405
Valid Loss:  0.024464664980769157
Epoch:  266  	Training Loss: 0.02273394912481308
Test Loss:  0.021856054663658142
Valid Loss:  0.024430006742477417
Epoch:  267  	Training Loss: 0.02271348237991333
Test Loss:  0.02182048186659813
Valid Loss:  0.024395454674959183
Epoch:  268  	Training Loss: 0.022693078964948654
Test Loss:  0.02178504504263401
Valid Loss:  0.024361032992601395
Epoch:  269  	Training Loss: 0.022672738879919052
Test Loss:  0.02174972929060459
Valid Loss:  0.024326717481017113
Epoch:  270  	Training Loss: 0.022652463987469673
Test Loss:  0.02171454392373562
Valid Loss:  0.024292517453432083
Epoch:  271  	Training Loss: 0.02263224683701992
Test Loss:  0.021679487079381943
Valid Loss:  0.024258427321910858
Epoch:  272  	Training Loss: 0.02261209487915039
Test Loss:  0.02164445072412491
Valid Loss:  0.024224374443292618
Epoch:  273  	Training Loss: 0.022591974586248398
Test Loss:  0.02160954289138317
Valid Loss:  0.024190420284867287
Epoch:  274  	Training Loss: 0.02257191389799118
Test Loss:  0.021574757993221283
Valid Loss:  0.024156585335731506
Epoch:  275  	Training Loss: 0.02255191095173359
Test Loss:  0.02154010534286499
Valid Loss:  0.02412286400794983
Epoch:  276  	Training Loss: 0.02253197506070137
Test Loss:  0.0215055663138628
Valid Loss:  0.024089239537715912
Epoch:  277  	Training Loss: 0.02251209132373333
Test Loss:  0.021471155807375908
Valid Loss:  0.024055736139416695
Epoch:  278  	Training Loss: 0.022492270916700363
Test Loss:  0.021436871960759163
Valid Loss:  0.024022340774536133
Epoch:  279  	Training Loss: 0.02247251383960247
Test Loss:  0.021402716636657715
Valid Loss:  0.02398904599249363
Epoch:  280  	Training Loss: 0.022452814504504204
Test Loss:  0.02136867493391037
Valid Loss:  0.023955881595611572
Epoch:  281  	Training Loss: 0.022433171048760414
Test Loss:  0.02133476361632347
Valid Loss:  0.02392280101776123
Epoch:  282  	Training Loss: 0.02241358906030655
Test Loss:  0.02130098268389702
Valid Loss:  0.023889856413006783
Epoch:  283  	Training Loss: 0.022394075989723206
Test Loss:  0.021267324686050415
Valid Loss:  0.02385701611638069
Epoch:  284  	Training Loss: 0.02237461507320404
Test Loss:  0.021233778446912766
Valid Loss:  0.023824280127882957
 57%|█████▋    | 286/500 [03:21<02:10,  1.64it/s] 58%|█████▊    | 288/500 [03:21<01:34,  2.24it/s] 58%|█████▊    | 290/500 [03:21<01:09,  3.01it/s] 58%|█████▊    | 292/500 [03:28<04:08,  1.20s/it] 59%|█████▉    | 294/500 [03:28<02:58,  1.16it/s] 59%|█████▉    | 296/500 [03:28<02:08,  1.59it/s] 60%|█████▉    | 298/500 [03:28<01:34,  2.14it/s] 60%|██████    | 300/500 [03:28<01:10,  2.83it/s] 60%|██████    | 302/500 [03:35<04:02,  1.22s/it] 61%|██████    | 304/500 [03:35<02:51,  1.14it/s] 61%|██████    | 306/500 [03:35<02:02,  1.58it/s] 62%|██████▏   | 308/500 [03:35<01:28,  2.16it/s] 62%|██████▏   | 310/500 [03:35<01:05,  2.91it/s] 62%|██████▏   | 312/500 [03:42<03:49,  1.22s/it] 63%|██████▎   | 314/500 [03:42<02:42,  1.15it/s] 63%|██████▎   | 316/500 [03:42<01:56,  1.58it/s] 64%|██████▎   | 318/500 [03:42<01:24,  2.17it/s] 64%|██████▍   | 320/500 [03:42<01:01,  2.92it/s] 64%|██████▍   | 322/500 [03:49<03:30,  1.18s/it] 65%|██████▍   | 324/500 [03:49<02:29,  1.18it/s] 65%|██████▌   | 326/500 [03:49<01:46,  1.63it/s] 66%|██████▌   | 328/500 [03:49<01:17,  2.22it/s] 66%|██████▌   | 330/500 [03:49<00:56,  2.99it/s] 66%|██████▋   | 332/500 [03:56<03:19,  1.19s/it] 67%|██████▋   | 334/500 [03:56<02:21,  1.17it/s] 67%|██████▋   | 336/500 [03:56<01:40,  1.62it/s] 68%|██████▊   | 338/500 [03:56<01:13,  2.22it/s] 68%|██████▊   | 340/500 [03:56<00:53,  2.98it/s] 68%|██████▊   | 342/500 [04:03<03:07,  1.19s/it] 69%|██████▉   | 344/500 [04:03<02:12,  1.17it/s] 69%|██████▉   | 346/500 [04:03<01:34,  1.62it/s] 70%|██████▉   | 348/500 [04:03<01:08,  2.22it/s] 70%|███████   | 350/500 [04:03<00:50,  2.98it/s] 70%|███████   | 352/500 [04:10<02:57,  1.20s/it] 71%|███████   | 354/500 [04:10<02:06,  1.15it/s]Epoch:  285  	Training Loss: 0.02235521376132965
Test Loss:  0.021200362592935562
Valid Loss:  0.02379165217280388
Epoch:  286  	Training Loss: 0.022335868328809738
Test Loss:  0.021167054772377014
Valid Loss:  0.02375911921262741
Epoch:  287  	Training Loss: 0.022316578775644302
Test Loss:  0.021133873611688614
Valid Loss:  0.023726698011159897
Epoch:  288  	Training Loss: 0.022297345101833344
Test Loss:  0.021100813522934914
Valid Loss:  0.02369437925517559
Epoch:  289  	Training Loss: 0.02227816730737686
Test Loss:  0.02106785960495472
Valid Loss:  0.02366216853260994
Epoch:  290  	Training Loss: 0.022259049117565155
Test Loss:  0.021035026758909225
Valid Loss:  0.0236300528049469
Epoch:  291  	Training Loss: 0.022239981219172478
Test Loss:  0.021002300083637238
Valid Loss:  0.023598037660121918
Epoch:  292  	Training Loss: 0.022220972925424576
Test Loss:  0.02096908539533615
Valid Loss:  0.023565569892525673
Epoch:  293  	Training Loss: 0.022201713174581528
Test Loss:  0.020935973152518272
Valid Loss:  0.023533198982477188
Epoch:  294  	Training Loss: 0.022182513028383255
Test Loss:  0.020902980118989944
Valid Loss:  0.02350093424320221
Epoch:  295  	Training Loss: 0.02216336503624916
Test Loss:  0.020870108157396317
Valid Loss:  0.023468762636184692
Epoch:  296  	Training Loss: 0.022144276648759842
Test Loss:  0.020837336778640747
Valid Loss:  0.023436689749360085
Epoch:  297  	Training Loss: 0.022125232964754105
Test Loss:  0.020804692059755325
Valid Loss:  0.023404721170663834
Epoch:  298  	Training Loss: 0.022106247022747993
Test Loss:  0.020772157236933708
Valid Loss:  0.023372847586870193
Epoch:  299  	Training Loss: 0.02208731323480606
Test Loss:  0.020739728584885597
Valid Loss:  0.02334107831120491
Epoch:  300  	Training Loss: 0.022068433463573456
Test Loss:  0.020707417279481888
Valid Loss:  0.023309415206313133
Epoch:  301  	Training Loss: 0.02204960212111473
Test Loss:  0.020675214007496834
Valid Loss:  0.023277824744582176
Epoch:  302  	Training Loss: 0.022030821070075035
Test Loss:  0.020643258467316628
Valid Loss:  0.023246485739946365
Epoch:  303  	Training Loss: 0.022012177854776382
Test Loss:  0.020611414685845375
Valid Loss:  0.023215245455503464
Epoch:  304  	Training Loss: 0.02199358493089676
Test Loss:  0.020579684525728226
Valid Loss:  0.02318408712744713
Epoch:  305  	Training Loss: 0.021975036710500717
Test Loss:  0.020548060536384583
Valid Loss:  0.023153020069003105
Epoch:  306  	Training Loss: 0.021956540644168854
Test Loss:  0.020516537129878998
Valid Loss:  0.023122064769268036
Epoch:  307  	Training Loss: 0.021938098594546318
Test Loss:  0.02048512175679207
Valid Loss:  0.023091189563274384
Epoch:  308  	Training Loss: 0.021919701248407364
Test Loss:  0.020453818142414093
Valid Loss:  0.02306041680276394
Epoch:  309  	Training Loss: 0.02190135046839714
Test Loss:  0.020422622561454773
Valid Loss:  0.023029733449220657
Epoch:  310  	Training Loss: 0.021883055567741394
Test Loss:  0.020391525700688362
Valid Loss:  0.022999145090579987
Epoch:  311  	Training Loss: 0.02186480723321438
Test Loss:  0.020360536873340607
Valid Loss:  0.02296864613890648
Epoch:  312  	Training Loss: 0.021846603602170944
Test Loss:  0.02033037319779396
Valid Loss:  0.022938895970582962
Epoch:  313  	Training Loss: 0.021828794851899147
Test Loss:  0.02030032128095627
Valid Loss:  0.02290923520922661
Epoch:  314  	Training Loss: 0.02181103453040123
Test Loss:  0.02027038112282753
Valid Loss:  0.022879673168063164
Epoch:  315  	Training Loss: 0.021793320775032043
Test Loss:  0.02024053782224655
Valid Loss:  0.02285020612180233
Epoch:  316  	Training Loss: 0.021775659173727036
Test Loss:  0.02021080255508423
Valid Loss:  0.02282082661986351
Epoch:  317  	Training Loss: 0.02175804041326046
Test Loss:  0.020181167870759964
Valid Loss:  0.022791529074311256
Epoch:  318  	Training Loss: 0.021740473806858063
Test Loss:  0.02015163004398346
Valid Loss:  0.02276233583688736
Epoch:  319  	Training Loss: 0.021722953766584396
Test Loss:  0.02012220211327076
Valid Loss:  0.02273321896791458
Epoch:  320  	Training Loss: 0.021705474704504013
Test Loss:  0.02009287104010582
Valid Loss:  0.02270420454442501
Epoch:  321  	Training Loss: 0.021688047796487808
Test Loss:  0.020063648000359535
Valid Loss:  0.022675268352031708
Epoch:  322  	Training Loss: 0.021670667454600334
Test Loss:  0.020034251734614372
Valid Loss:  0.022646211087703705
Epoch:  323  	Training Loss: 0.021653231233358383
Test Loss:  0.02000497095286846
Valid Loss:  0.022617241367697716
Epoch:  324  	Training Loss: 0.021635841578245163
Test Loss:  0.019975770264863968
Valid Loss:  0.022588344290852547
Epoch:  325  	Training Loss: 0.021618492901325226
Test Loss:  0.01994667947292328
Valid Loss:  0.02255954034626484
Epoch:  326  	Training Loss: 0.021601196378469467
Test Loss:  0.019917692989110947
Valid Loss:  0.022530831396579742
Epoch:  327  	Training Loss: 0.021583938971161842
Test Loss:  0.01988878846168518
Valid Loss:  0.022502195090055466
Epoch:  328  	Training Loss: 0.0215667262673378
Test Loss:  0.01985999569296837
Valid Loss:  0.02247365564107895
Epoch:  329  	Training Loss: 0.021549556404352188
Test Loss:  0.019831283017992973
Valid Loss:  0.022445183247327805
Epoch:  330  	Training Loss: 0.02153243124485016
Test Loss:  0.019802676513791084
Valid Loss:  0.02241680771112442
Epoch:  331  	Training Loss: 0.02151534892618656
Test Loss:  0.019774165004491806
Valid Loss:  0.022388514131307602
Epoch:  332  	Training Loss: 0.021498315036296844
Test Loss:  0.01974555291235447
Valid Loss:  0.022360127419233322
Epoch:  333  	Training Loss: 0.021481238305568695
Test Loss:  0.01971704140305519
Valid Loss:  0.0223318412899971
Epoch:  334  	Training Loss: 0.021464210003614426
Test Loss:  0.019688613712787628
Valid Loss:  0.022303633391857147
Epoch:  335  	Training Loss: 0.02144721895456314
Test Loss:  0.01966029405593872
Valid Loss:  0.02227550372481346
Epoch:  336  	Training Loss: 0.02143027074635029
Test Loss:  0.01963205635547638
Valid Loss:  0.02224746160209179
Epoch:  337  	Training Loss: 0.021413367241621017
Test Loss:  0.019603904336690903
Valid Loss:  0.022219480946660042
Epoch:  338  	Training Loss: 0.02139650285243988
Test Loss:  0.019575858488678932
Valid Loss:  0.022191595286130905
Epoch:  339  	Training Loss: 0.021379677578806877
Test Loss:  0.019547905772924423
Valid Loss:  0.02216380089521408
Epoch:  340  	Training Loss: 0.021362897008657455
Test Loss:  0.01952003873884678
Valid Loss:  0.022136077284812927
Epoch:  341  	Training Loss: 0.021346163004636765
Test Loss:  0.019492262974381447
Valid Loss:  0.022108426317572594
Epoch:  342  	Training Loss: 0.02132946066558361
Test Loss:  0.019465191289782524
Valid Loss:  0.022081419825553894
Epoch:  343  	Training Loss: 0.021313097327947617
Test Loss:  0.01943819783627987
Valid Loss:  0.022054485976696014
Epoch:  344  	Training Loss: 0.021296769380569458
Test Loss:  0.019411306828260422
Valid Loss:  0.022027637809515
Epoch:  345  	Training Loss: 0.02128048613667488
Test Loss:  0.01938449591398239
Valid Loss:  0.02200087159872055
Epoch:  346  	Training Loss: 0.021264243870973587
Test Loss:  0.019357774406671524
Valid Loss:  0.021974172443151474
Epoch:  347  	Training Loss: 0.021248038858175278
Test Loss:  0.01933114603161812
Valid Loss:  0.021947553381323814
Epoch:  348  	Training Loss: 0.021231871098279953
Test Loss:  0.019304592162370682
Valid Loss:  0.021921008825302124
Epoch:  349  	Training Loss: 0.021215740591287613
Test Loss:  0.019278142601251602
Valid Loss:  0.02189454436302185
Epoch:  350  	Training Loss: 0.021199652925133705
Test Loss:  0.019251767545938492
Valid Loss:  0.021868156269192696
Epoch:  351  	Training Loss: 0.021183602511882782
Test Loss:  0.019225480034947395
Valid Loss:  0.021841850131750107
Epoch:  352  	Training Loss: 0.021167587488889694
Test Loss:  0.01919909194111824
Valid Loss:  0.021815413609147072
Epoch:  353  	Training Loss: 0.02115151472389698
Test Loss:  0.019172778353095055
Valid Loss:  0.021789085119962692
Epoch:  354  	Training Loss: 0.021135473623871803
Test Loss:  0.01914655789732933
Valid Loss:  0.021762816235423088
Epoch:  355  	Training Loss: 0.021119466051459312
Test Loss:   71%|███████   | 356/500 [04:10<01:31,  1.58it/s] 72%|███████▏  | 358/500 [04:10<01:06,  2.13it/s] 72%|███████▏  | 360/500 [04:10<00:49,  2.83it/s] 72%|███████▏  | 362/500 [04:17<02:46,  1.21s/it] 73%|███████▎  | 364/500 [04:17<01:58,  1.15it/s] 73%|███████▎  | 366/500 [04:17<01:25,  1.57it/s] 74%|███████▎  | 368/500 [04:17<01:01,  2.15it/s] 74%|███████▍  | 370/500 [04:17<00:44,  2.90it/s] 74%|███████▍  | 372/500 [04:24<02:35,  1.21s/it] 75%|███████▍  | 374/500 [04:24<01:49,  1.15it/s] 75%|███████▌  | 376/500 [04:24<01:17,  1.59it/s] 76%|███████▌  | 378/500 [04:24<00:56,  2.15it/s] 76%|███████▌  | 380/500 [04:24<00:42,  2.84it/s] 76%|███████▋  | 382/500 [04:31<02:25,  1.23s/it] 77%|███████▋  | 384/500 [04:31<01:43,  1.12it/s] 77%|███████▋  | 386/500 [04:31<01:14,  1.54it/s] 78%|███████▊  | 388/500 [04:31<00:53,  2.11it/s] 78%|███████▊  | 390/500 [04:32<00:38,  2.83it/s] 78%|███████▊  | 392/500 [04:38<02:10,  1.21s/it] 79%|███████▉  | 394/500 [04:38<01:32,  1.15it/s] 79%|███████▉  | 396/500 [04:38<01:06,  1.57it/s] 80%|███████▉  | 398/500 [04:38<00:48,  2.12it/s] 80%|████████  | 400/500 [04:39<00:35,  2.85it/s] 80%|████████  | 402/500 [04:45<01:59,  1.22s/it] 81%|████████  | 404/500 [04:45<01:24,  1.14it/s] 81%|████████  | 406/500 [04:45<01:00,  1.57it/s] 82%|████████▏ | 408/500 [04:46<00:43,  2.12it/s] 82%|████████▏ | 410/500 [04:46<00:31,  2.86it/s] 82%|████████▏ | 412/500 [04:52<01:45,  1.19s/it] 83%|████████▎ | 414/500 [04:52<01:14,  1.16it/s] 83%|████████▎ | 416/500 [04:52<00:52,  1.59it/s] 84%|████████▎ | 418/500 [04:53<00:38,  2.15it/s] 84%|████████▍ | 420/500 [04:53<00:28,  2.85it/s] 84%|████████▍ | 422/500 [04:59<01:36,  1.24s/it] 85%|████████▍ | 424/500 [04:59<01:07,  1.12it/s]0.019120419397950172
Valid Loss:  0.021736610680818558
Epoch:  356  	Training Loss: 0.021103501319885254
Test Loss:  0.019094347953796387
Valid Loss:  0.021710481494665146
Epoch:  357  	Training Loss: 0.02108757197856903
Test Loss:  0.019068382680416107
Valid Loss:  0.021684428676962852
Epoch:  358  	Training Loss: 0.021071676164865494
Test Loss:  0.019042490050196648
Valid Loss:  0.02165845036506653
Epoch:  359  	Training Loss: 0.02105581946671009
Test Loss:  0.01901666820049286
Valid Loss:  0.021632539108395576
Epoch:  360  	Training Loss: 0.021039996296167374
Test Loss:  0.01899094507098198
Valid Loss:  0.021606706082820892
Epoch:  361  	Training Loss: 0.021024208515882492
Test Loss:  0.018965288996696472
Valid Loss:  0.02158093824982643
Epoch:  362  	Training Loss: 0.021008457988500595
Test Loss:  0.018939923495054245
Valid Loss:  0.021555444225668907
Epoch:  363  	Training Loss: 0.020992863923311234
Test Loss:  0.018914639949798584
Valid Loss:  0.021530020982027054
Epoch:  364  	Training Loss: 0.020977307111024857
Test Loss:  0.01888943277299404
Valid Loss:  0.021504666656255722
Epoch:  365  	Training Loss: 0.020961780101060867
Test Loss:  0.01886431872844696
Valid Loss:  0.021479390561580658
Epoch:  366  	Training Loss: 0.02094629406929016
Test Loss:  0.018839271739125252
Valid Loss:  0.021454177796840668
Epoch:  367  	Training Loss: 0.02093084156513214
Test Loss:  0.01881430856883526
Valid Loss:  0.02142903581261635
Epoch:  368  	Training Loss: 0.020915428176522255
Test Loss:  0.018789419904351234
Valid Loss:  0.02140396647155285
Epoch:  369  	Training Loss: 0.020900040864944458
Test Loss:  0.018764618784189224
Valid Loss:  0.02137896791100502
Epoch:  370  	Training Loss: 0.020884692668914795
Test Loss:  0.018739894032478333
Valid Loss:  0.021354034543037415
Epoch:  371  	Training Loss: 0.02086937613785267
Test Loss:  0.018715238198637962
Valid Loss:  0.021329166367650032
Epoch:  372  	Training Loss: 0.02085408940911293
Test Loss:  0.018690623342990875
Valid Loss:  0.02130432426929474
Epoch:  373  	Training Loss: 0.02083880640566349
Test Loss:  0.018666088581085205
Valid Loss:  0.02127954177558422
Epoch:  374  	Training Loss: 0.02082355134189129
Test Loss:  0.018641622737050056
Valid Loss:  0.021254831925034523
Epoch:  375  	Training Loss: 0.020808331668376923
Test Loss:  0.018617238849401474
Valid Loss:  0.021230187267065048
Epoch:  376  	Training Loss: 0.020793147385120392
Test Loss:  0.01859293319284916
Valid Loss:  0.021205615252256393
Epoch:  377  	Training Loss: 0.0207779910415411
Test Loss:  0.018568705767393112
Valid Loss:  0.02118111215531826
Epoch:  378  	Training Loss: 0.02076287381350994
Test Loss:  0.018544554710388184
Valid Loss:  0.021156668663024902
Epoch:  379  	Training Loss: 0.02074778452515602
Test Loss:  0.018520472571253777
Valid Loss:  0.02113228850066662
Epoch:  380  	Training Loss: 0.020732730627059937
Test Loss:  0.018496470525860786
Valid Loss:  0.021107977256178856
Epoch:  381  	Training Loss: 0.020717710256576538
Test Loss:  0.01847253367304802
Valid Loss:  0.021083740517497063
Epoch:  382  	Training Loss: 0.02070271596312523
Test Loss:  0.01844862475991249
Valid Loss:  0.021059513092041016
Epoch:  383  	Training Loss: 0.020687732845544815
Test Loss:  0.01842479407787323
Valid Loss:  0.02103535085916519
Epoch:  384  	Training Loss: 0.020672788843512535
Test Loss:  0.01840103417634964
Valid Loss:  0.02101125568151474
Epoch:  385  	Training Loss: 0.020657867193222046
Test Loss:  0.01837734878063202
Valid Loss:  0.02098722942173481
Epoch:  386  	Training Loss: 0.02064298465847969
Test Loss:  0.018353726714849472
Valid Loss:  0.020963259041309357
Epoch:  387  	Training Loss: 0.020628131926059723
Test Loss:  0.01833018660545349
Valid Loss:  0.020939365029335022
Epoch:  388  	Training Loss: 0.020613308995962143
Test Loss:  0.018306728452444077
Valid Loss:  0.020915521308779716
Epoch:  389  	Training Loss: 0.02059851959347725
Test Loss:  0.018283333629369736
Valid Loss:  0.020891759544610977
Epoch:  390  	Training Loss: 0.020583756268024445
Test Loss:  0.018260011449456215
Valid Loss:  0.02086804062128067
Epoch:  391  	Training Loss: 0.020569026470184326
Test Loss:  0.018236756324768066
Valid Loss:  0.02084440551698208
Epoch:  392  	Training Loss: 0.020554326474666595
Test Loss:  0.018212847411632538
Valid Loss:  0.020820163190364838
Epoch:  393  	Training Loss: 0.02053934521973133
Test Loss:  0.018189020454883575
Valid Loss:  0.02079600840806961
Epoch:  394  	Training Loss: 0.020524397492408752
Test Loss:  0.018165264278650284
Valid Loss:  0.020771902054548264
Epoch:  395  	Training Loss: 0.020509477704763412
Test Loss:  0.01814158260822296
Valid Loss:  0.020747875794768333
Epoch:  396  	Training Loss: 0.02049459144473076
Test Loss:  0.018117964267730713
Valid Loss:  0.02072390913963318
Epoch:  397  	Training Loss: 0.020479733124375343
Test Loss:  0.01809442788362503
Valid Loss:  0.020699994638562202
Epoch:  398  	Training Loss: 0.020464910194277763
Test Loss:  0.018070971593260765
Valid Loss:  0.020676154643297195
Epoch:  399  	Training Loss: 0.020450115203857422
Test Loss:  0.018047574907541275
Valid Loss:  0.020652370527386665
Epoch:  400  	Training Loss: 0.020435351878404617
Test Loss:  0.018024256452918053
Valid Loss:  0.020628664642572403
Epoch:  401  	Training Loss: 0.020420614629983902
Test Loss:  0.0180010087788105
Valid Loss:  0.02060500904917717
Epoch:  402  	Training Loss: 0.020405909046530724
Test Loss:  0.017978476360440254
Valid Loss:  0.020582005381584167
Epoch:  403  	Training Loss: 0.02039152756333351
Test Loss:  0.017956027761101723
Valid Loss:  0.02055906131863594
Epoch:  404  	Training Loss: 0.020377174019813538
Test Loss:  0.017933638766407967
Valid Loss:  0.02053617499768734
Epoch:  405  	Training Loss: 0.020362846553325653
Test Loss:  0.017911309376358986
Valid Loss:  0.020513344556093216
Epoch:  406  	Training Loss: 0.020348548889160156
Test Loss:  0.017889048904180527
Valid Loss:  0.020490575581789017
Epoch:  407  	Training Loss: 0.020334281027317047
Test Loss:  0.017866862937808037
Valid Loss:  0.02046786993741989
Epoch:  408  	Training Loss: 0.02032003551721573
Test Loss:  0.017844732850790024
Valid Loss:  0.0204452071338892
Epoch:  409  	Training Loss: 0.020305819809436798
Test Loss:  0.01782267540693283
Valid Loss:  0.020422611385583878
Epoch:  410  	Training Loss: 0.020291630178689957
Test Loss:  0.017800677567720413
Valid Loss:  0.020400065928697586
Epoch:  411  	Training Loss: 0.020277472212910652
Test Loss:  0.01777873933315277
Valid Loss:  0.02037758007645607
Epoch:  412  	Training Loss: 0.020263338461518288
Test Loss:  0.017757104709744453
Valid Loss:  0.02035536617040634
Epoch:  413  	Training Loss: 0.02024933323264122
Test Loss:  0.01773553341627121
Valid Loss:  0.020333193242549896
Epoch:  414  	Training Loss: 0.020235354080796242
Test Loss:  0.01771402359008789
Valid Loss:  0.020311087369918823
Epoch:  415  	Training Loss: 0.020221399143338203
Test Loss:  0.01769256964325905
Valid Loss:  0.020289026200771332
Epoch:  416  	Training Loss: 0.020207475870847702
Test Loss:  0.01767117902636528
Valid Loss:  0.020267022773623466
Epoch:  417  	Training Loss: 0.020193573087453842
Test Loss:  0.017649851739406586
Valid Loss:  0.020245080813765526
Epoch:  418  	Training Loss: 0.02017970010638237
Test Loss:  0.017628591507673264
Valid Loss:  0.020223181694746017
Epoch:  419  	Training Loss: 0.02016584947705269
Test Loss:  0.01760738715529442
Valid Loss:  0.020201338455080986
Epoch:  420  	Training Loss: 0.020152028650045395
Test Loss:  0.017586249858140945
Valid Loss:  0.02017955854535103
Epoch:  421  	Training Loss: 0.020138230174779892
Test Loss:  0.01756516844034195
Valid Loss:  0.020157821476459503
Epoch:  422  	Training Loss: 0.02012445777654648
Test Loss:  0.017543379217386246
Valid Loss:  0.020135462284088135
Epoch:  423  	Training Loss: 0.020110372453927994
Test Loss:  0.017521653324365616
Valid Loss:  0.020113153383135796
Epoch:  424  	Training Loss: 0.0200963132083416
Test Loss:  0.017499983310699463
Valid Loss:  0.020090898498892784
Epoch:  425  	Training Loss: 0.020082276314496994
Test Loss:  0.01747838594019413
Valid Loss:  0.020068690180778503
 85%|████████▌ | 426/500 [05:00<00:48,  1.53it/s] 86%|████████▌ | 428/500 [05:00<00:34,  2.07it/s] 86%|████████▌ | 430/500 [05:00<00:25,  2.75it/s] 86%|████████▋ | 432/500 [05:07<01:24,  1.24s/it] 87%|████████▋ | 434/500 [05:07<00:58,  1.13it/s] 87%|████████▋ | 436/500 [05:07<00:41,  1.55it/s] 88%|████████▊ | 438/500 [05:07<00:29,  2.09it/s] 88%|████████▊ | 440/500 [05:07<00:21,  2.78it/s] 88%|████████▊ | 442/500 [05:14<01:11,  1.23s/it] 89%|████████▉ | 444/500 [05:14<00:49,  1.13it/s] 89%|████████▉ | 446/500 [05:14<00:34,  1.56it/s] 90%|████████▉ | 448/500 [05:14<00:24,  2.14it/s] 90%|█████████ | 450/500 [05:14<00:17,  2.89it/s] 90%|█████████ | 452/500 [05:21<00:57,  1.19s/it] 91%|█████████ | 454/500 [05:21<00:39,  1.17it/s] 91%|█████████ | 456/500 [05:21<00:27,  1.62it/s] 92%|█████████▏| 458/500 [05:21<00:19,  2.21it/s] 92%|█████████▏| 460/500 [05:21<00:13,  2.97it/s] 92%|█████████▏| 462/500 [05:28<00:45,  1.19s/it] 93%|█████████▎| 464/500 [05:28<00:30,  1.17it/s] 93%|█████████▎| 466/500 [05:28<00:20,  1.62it/s] 94%|█████████▎| 468/500 [05:28<00:14,  2.21it/s] 94%|█████████▍| 470/500 [05:28<00:10,  2.96it/s] 94%|█████████▍| 472/500 [05:34<00:33,  1.19s/it] 95%|█████████▍| 474/500 [05:35<00:22,  1.17it/s] 95%|█████████▌| 476/500 [05:35<00:14,  1.60it/s] 96%|█████████▌| 478/500 [05:35<00:10,  2.16it/s] 96%|█████████▌| 480/500 [05:35<00:07,  2.86it/s] 96%|█████████▋| 482/500 [05:41<00:21,  1.20s/it] 97%|█████████▋| 484/500 [05:42<00:13,  1.16it/s] 97%|█████████▋| 486/500 [05:42<00:08,  1.61it/s] 98%|█████████▊| 488/500 [05:42<00:05,  2.19it/s] 98%|█████████▊| 490/500 [05:42<00:03,  2.95it/s] 98%|█████████▊| 492/500 [05:48<00:09,  1.20s/it] 99%|█████████▉| 494/500 [05:49<00:05,  1.16it/s]Epoch:  426  	Training Loss: 0.02006826549768448
Test Loss:  0.017456835135817528
Valid Loss:  0.02004653960466385
Epoch:  427  	Training Loss: 0.020054278895258904
Test Loss:  0.017435356974601746
Valid Loss:  0.02002444490790367
Epoch:  428  	Training Loss: 0.020040318369865417
Test Loss:  0.01741393655538559
Valid Loss:  0.02000240609049797
Epoch:  429  	Training Loss: 0.02002638205885887
Test Loss:  0.017392583191394806
Valid Loss:  0.01998041197657585
Epoch:  430  	Training Loss: 0.020012469962239265
Test Loss:  0.01737128756940365
Valid Loss:  0.019958481192588806
Epoch:  431  	Training Loss: 0.019998585805296898
Test Loss:  0.017350047826766968
Valid Loss:  0.01993660256266594
Epoch:  432  	Training Loss: 0.01998472586274147
Test Loss:  0.01732948049902916
Valid Loss:  0.01991531439125538
Epoch:  433  	Training Loss: 0.019971154630184174
Test Loss:  0.01730896532535553
Valid Loss:  0.019894065335392952
Epoch:  434  	Training Loss: 0.01995760388672352
Test Loss:  0.017288509756326675
Valid Loss:  0.019872866570949554
Epoch:  435  	Training Loss: 0.019944075495004654
Test Loss:  0.01726810820400715
Valid Loss:  0.01985173672437668
Epoch:  436  	Training Loss: 0.01993057318031788
Test Loss:  0.017247766256332397
Valid Loss:  0.019830642268061638
Epoch:  437  	Training Loss: 0.019917096942663193
Test Loss:  0.01722748950123787
Valid Loss:  0.019809618592262268
Epoch:  438  	Training Loss: 0.019903643056750298
Test Loss:  0.01720726117491722
Valid Loss:  0.019788628444075584
Epoch:  439  	Training Loss: 0.01989021524786949
Test Loss:  0.0171870905905962
Valid Loss:  0.019767694175243378
Epoch:  440  	Training Loss: 0.019876807928085327
Test Loss:  0.017166972160339355
Valid Loss:  0.019746800884604454
Epoch:  441  	Training Loss: 0.019863422960042953
Test Loss:  0.017146922647953033
Valid Loss:  0.019725961610674858
Epoch:  442  	Training Loss: 0.019850056618452072
Test Loss:  0.01712682470679283
Valid Loss:  0.019705096259713173
Epoch:  443  	Training Loss: 0.01983669213950634
Test Loss:  0.017106788232922554
Valid Loss:  0.019684281200170517
Epoch:  444  	Training Loss: 0.019823342561721802
Test Loss:  0.017086807638406754
Valid Loss:  0.01966351643204689
Epoch:  445  	Training Loss: 0.019810017198324203
Test Loss:  0.01706688478589058
Valid Loss:  0.019642800092697144
Epoch:  446  	Training Loss: 0.019796714186668396
Test Loss:  0.017047014087438583
Valid Loss:  0.019622130319476128
Epoch:  447  	Training Loss: 0.01978343352675438
Test Loss:  0.017027202993631363
Valid Loss:  0.019601505249738693
Epoch:  448  	Training Loss: 0.019770175218582153
Test Loss:  0.017007432878017426
Valid Loss:  0.019580939784646034
Epoch:  449  	Training Loss: 0.019756939262151718
Test Loss:  0.016987740993499756
Valid Loss:  0.01956041157245636
Epoch:  450  	Training Loss: 0.019743729382753372
Test Loss:  0.016968082636594772
Valid Loss:  0.019539933651685715
Epoch:  451  	Training Loss: 0.01973053626716137
Test Loss:  0.016948485746979713
Valid Loss:  0.01951950415968895
Epoch:  452  	Training Loss: 0.019717365503311157
Test Loss:  0.01692943274974823
Valid Loss:  0.01949956640601158
Epoch:  453  	Training Loss: 0.01970444992184639
Test Loss:  0.016910411417484283
Valid Loss:  0.019479673355817795
Epoch:  454  	Training Loss: 0.019691558554768562
Test Loss:  0.01689145900309086
Valid Loss:  0.01945982128381729
Epoch:  455  	Training Loss: 0.019678689539432526
Test Loss:  0.01687256060540676
Valid Loss:  0.019440019503235817
Epoch:  456  	Training Loss: 0.01966583915054798
Test Loss:  0.016853714361786842
Valid Loss:  0.019420264288783073
Epoch:  457  	Training Loss: 0.019653011113405228
Test Loss:  0.016834918409585953
Valid Loss:  0.01940055936574936
Epoch:  458  	Training Loss: 0.019640209153294563
Test Loss:  0.016816172748804092
Valid Loss:  0.019380897283554077
Epoch:  459  	Training Loss: 0.019627422094345093
Test Loss:  0.016797468066215515
Valid Loss:  0.019361276179552078
Epoch:  460  	Training Loss: 0.019614657387137413
Test Loss:  0.01677882671356201
Valid Loss:  0.01934169977903366
Epoch:  461  	Training Loss: 0.019601913169026375
Test Loss:  0.016760237514972687
Valid Loss:  0.019322175532579422
Epoch:  462  	Training Loss: 0.019589189440011978
Test Loss:  0.016741402447223663
Valid Loss:  0.019302424043416977
Epoch:  463  	Training Loss: 0.019576361402869225
Test Loss:  0.016722621396183968
Valid Loss:  0.01928272657096386
Epoch:  464  	Training Loss: 0.019563548266887665
Test Loss:  0.01670389249920845
Valid Loss:  0.019263075664639473
Epoch:  465  	Training Loss: 0.019550763070583344
Test Loss:  0.016685225069522858
Valid Loss:  0.01924346573650837
Epoch:  466  	Training Loss: 0.019537996500730515
Test Loss:  0.016666598618030548
Valid Loss:  0.019223907962441444
Epoch:  467  	Training Loss: 0.01952524669468403
Test Loss:  0.01664801687002182
Valid Loss:  0.0192043986171484
Epoch:  468  	Training Loss: 0.019512515515089035
Test Loss:  0.01662949100136757
Valid Loss:  0.019184917211532593
Epoch:  469  	Training Loss: 0.01949981041252613
Test Loss:  0.01661101169884205
Valid Loss:  0.01916549541056156
Epoch:  470  	Training Loss: 0.01948712393641472
Test Loss:  0.016592582687735558
Valid Loss:  0.019146112725138664
Epoch:  471  	Training Loss: 0.01947445422410965
Test Loss:  0.016574203968048096
Valid Loss:  0.019126757979393005
Epoch:  472  	Training Loss: 0.019461805000901222
Test Loss:  0.01655571162700653
Valid Loss:  0.019107317551970482
Epoch:  473  	Training Loss: 0.019449099898338318
Test Loss:  0.016537269577383995
Valid Loss:  0.019087910652160645
Epoch:  474  	Training Loss: 0.019436413422226906
Test Loss:  0.016518879681825638
Valid Loss:  0.019068550318479538
Epoch:  475  	Training Loss: 0.019423749297857285
Test Loss:  0.01650054007768631
Valid Loss:  0.019049230962991714
Epoch:  476  	Training Loss: 0.019411101937294006
Test Loss:  0.016482247039675713
Valid Loss:  0.01902996376156807
Epoch:  477  	Training Loss: 0.01939847320318222
Test Loss:  0.016463998705148697
Valid Loss:  0.01901073381304741
Epoch:  478  	Training Loss: 0.019385864958167076
Test Loss:  0.016445793211460114
Valid Loss:  0.018991544842720032
Epoch:  479  	Training Loss: 0.019373279064893723
Test Loss:  0.016427651047706604
Valid Loss:  0.01897239498794079
Epoch:  480  	Training Loss: 0.019360706210136414
Test Loss:  0.01640954799950123
Valid Loss:  0.018953297287225723
Epoch:  481  	Training Loss: 0.019348159432411194
Test Loss:  0.01639149710536003
Valid Loss:  0.018934238702058792
Epoch:  482  	Training Loss: 0.01933562569320202
Test Loss:  0.016373787075281143
Valid Loss:  0.018915483728051186
Epoch:  483  	Training Loss: 0.019323255866765976
Test Loss:  0.016356123611330986
Valid Loss:  0.018896769732236862
Epoch:  484  	Training Loss: 0.019310900941491127
Test Loss:  0.016338493674993515
Valid Loss:  0.01887810230255127
Epoch:  485  	Training Loss: 0.01929856464266777
Test Loss:  0.01632091775536537
Valid Loss:  0.018859464675188065
Epoch:  486  	Training Loss: 0.019286245107650757
Test Loss:  0.016303380951285362
Valid Loss:  0.018840879201889038
Epoch:  487  	Training Loss: 0.019273947924375534
Test Loss:  0.01628590002655983
Valid Loss:  0.018822327256202698
Epoch:  488  	Training Loss: 0.019261663779616356
Test Loss:  0.01626845821738243
Valid Loss:  0.01880382001399994
Epoch:  489  	Training Loss: 0.01924940198659897
Test Loss:  0.01625106669962406
Valid Loss:  0.01878533512353897
Epoch:  490  	Training Loss: 0.019237156957387924
Test Loss:  0.016233719885349274
Valid Loss:  0.018766913563013077
Epoch:  491  	Training Loss: 0.019224930554628372
Test Loss:  0.016216415911912918
Valid Loss:  0.018748527392745018
Epoch:  492  	Training Loss: 0.01921272464096546
Test Loss:  0.01619896851480007
Valid Loss:  0.018730001524090767
Epoch:  493  	Training Loss: 0.01920045167207718
Test Loss:  0.016181563958525658
Valid Loss:  0.018711522221565247
Epoch:  494  	Training Loss: 0.01918819546699524
Test Loss:  0.016164211556315422
Valid Loss:  0.018693087622523308
Epoch:  495  	Training Loss: 0.01917596347630024
Test Loss:  0.016146894544363022
Valid Loss:  0.018674679100513458
Epoch:  496  	Training Loss: 0.019163746386766434
Test Loss:   99%|█████████▉| 496/500 [05:49<00:02,  1.60it/s]100%|█████████▉| 498/500 [05:49<00:00,  2.19it/s]100%|██████████| 500/500 [05:49<00:00,  2.93it/s]100%|██████████| 500/500 [05:49<00:00,  1.43it/s]
0.01612963154911995
Valid Loss:  0.018656320869922638
Epoch:  497  	Training Loss: 0.01915154419839382
Test Loss:  0.016112402081489563
Valid Loss:  0.018637996166944504
Epoch:  498  	Training Loss: 0.019139360636472702
Test Loss:  0.016095221042633057
Valid Loss:  0.018619712442159653
Epoch:  499  	Training Loss: 0.019127193838357925
Test Loss:  0.016078080981969833
Valid Loss:  0.018601469695568085
Epoch:  500  	Training Loss: 0.01911504752933979
Test Loss:  0.016060996800661087
Valid Loss:  0.0185832642018795
seed is  6
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<55:32,  6.68s/it]  1%|          | 3/500 [00:06<14:53,  1.80s/it]  1%|          | 5/500 [00:06<07:30,  1.10it/s]  1%|▏         | 7/500 [00:07<04:32,  1.81it/s]  2%|▏         | 9/500 [00:07<03:01,  2.71it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:14<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:46,  1.23s/it]  5%|▍         | 23/500 [00:20<06:56,  1.15it/s]  5%|▌         | 25/500 [00:26<12:24,  1.57s/it]  5%|▌         | 27/500 [00:27<08:49,  1.12s/it]  6%|▌         | 29/500 [00:27<06:17,  1.25it/s]  6%|▌         | 31/500 [00:33<12:00,  1.54s/it]  7%|▋         | 33/500 [00:33<08:31,  1.09s/it]  7%|▋         | 35/500 [00:34<06:05,  1.27it/s]  7%|▋         | 37/500 [00:34<04:23,  1.76it/s]  8%|▊         | 39/500 [00:34<03:12,  2.39it/s]  8%|▊         | 41/500 [00:40<09:39,  1.26s/it]  9%|▊         | 43/500 [00:40<06:53,  1.10it/s]  9%|▉         | 45/500 [00:41<04:57,  1.53it/s]  9%|▉         | 47/500 [00:41<03:36,  2.09it/s] 10%|▉         | 49/500 [00:41<02:39,  2.83it/s] 10%|█         | 51/500 [00:47<09:04,  1.21s/it] 11%|█         | 53/500 [00:47<06:29,  1.15it/s] 11%|█         | 55/500 [00:48<04:40,  1.59it/s] 11%|█▏        | 57/500 [00:48<03:23,  2.17it/s] 12%|█▏        | 59/500 [00:48<02:30,  2.93it/s] 12%|█▏        | 61/500 [00:54<08:50,  1.21s/it] 13%|█▎        | 63/500 [00:54<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:55<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:55<03:18,  2.18it/s] 14%|█▍        | 69/500 [00:55<02:27,  2.93it/s]Epoch:  1  	Training Loss: 0.0236221831291914
Test Loss:  0.0075849504210054874
Valid Loss:  0.011486958712339401
Epoch:  2  	Training Loss: 0.017023185268044472
Test Loss:  0.012626606971025467
Valid Loss:  0.011572902090847492
Epoch:  3  	Training Loss: 0.011792118661105633
Test Loss:  0.004709371831268072
Valid Loss:  0.008335519582033157
Epoch:  4  	Training Loss: 0.012279698625206947
Test Loss:  0.025205131620168686
Valid Loss:  0.01879485696554184
Epoch:  5  	Training Loss: 0.018116850405931473
Test Loss:  0.016420233994722366
Valid Loss:  0.023177089169621468
Epoch:  6  	Training Loss: 0.022424060851335526
Test Loss:  0.036639146506786346
Valid Loss:  0.027525274083018303
Epoch:  7  	Training Loss: 0.027361523360013962
Test Loss:  0.02697822079062462
Valid Loss:  0.035758279263973236
Epoch:  8  	Training Loss: 0.03172799199819565
Test Loss:  0.04534480720758438
Valid Loss:  0.03457475081086159
Epoch:  9  	Training Loss: 0.03444325178861618
Test Loss:  0.03151053190231323
Valid Loss:  0.04136382043361664
Epoch:  10  	Training Loss: 0.03517935425043106
Test Loss:  0.03640812635421753
Valid Loss:  0.02725645899772644
Epoch:  11  	Training Loss: 0.027118507772684097
Test Loss:  0.01691157929599285
Valid Loss:  0.02450980618596077
Epoch:  12  	Training Loss: 0.019989658147096634
Test Loss:  0.029303722083568573
Valid Loss:  0.020519670099020004
Epoch:  13  	Training Loss: 0.02063537947833538
Test Loss:  0.006198798306286335
Valid Loss:  0.005441940389573574
Epoch:  14  	Training Loss: 0.007656892295926809
Test Loss:  0.004765721969306469
Valid Loss:  0.005058621987700462
Epoch:  15  	Training Loss: 0.006727738305926323
Test Loss:  0.003927687183022499
Valid Loss:  0.004778651520609856
Epoch:  16  	Training Loss: 0.006085362285375595
Test Loss:  0.003566737286746502
Valid Loss:  0.004550701007246971
Epoch:  17  	Training Loss: 0.005672922357916832
Test Loss:  0.003533430164679885
Valid Loss:  0.004338514991104603
Epoch:  18  	Training Loss: 0.005413577891886234
Test Loss:  0.00354068074375391
Valid Loss:  0.004177893977612257
Epoch:  19  	Training Loss: 0.005215448327362537
Test Loss:  0.003488758113235235
Valid Loss:  0.004053897224366665
Epoch:  20  	Training Loss: 0.005032789893448353
Test Loss:  0.00342049659229815
Valid Loss:  0.003949892707169056
Epoch:  21  	Training Loss: 0.004869340918958187
Test Loss:  0.0034126457758247852
Valid Loss:  0.0038338303565979004
Epoch:  22  	Training Loss: 0.0047306399792432785
Test Loss:  0.005458588246256113
Valid Loss:  0.004009248688817024
Epoch:  23  	Training Loss: 0.004731286782771349
Test Loss:  0.003454970195889473
Valid Loss:  0.006272422149777412
Epoch:  24  	Training Loss: 0.006680767983198166
Test Loss:  0.015392636880278587
Valid Loss:  0.009932294487953186
Epoch:  25  	Training Loss: 0.011388946324586868
Test Loss:  0.007112135179340839
Valid Loss:  0.012135920114815235
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.012087278068065643
Test Loss:  0.0026348340325057507
Valid Loss:  0.004593337886035442
Epoch:  27  	Training Loss: 0.005528694950044155
Test Loss:  0.0024156305007636547
Valid Loss:  0.0034435817506164312
Epoch:  28  	Training Loss: 0.00457806047052145
Test Loss:  0.0024366111028939486
Valid Loss:  0.003121643327176571
Epoch:  29  	Training Loss: 0.004267741926014423
Test Loss:  0.002434832276776433
Valid Loss:  0.00294973561540246
Epoch:  30  	Training Loss: 0.004058255814015865
Test Loss:  0.002443350153043866
Valid Loss:  0.002849167212843895
Epoch:  31  	Training Loss: 0.003908277489244938
Test Loss:  0.0024459066335111856
Valid Loss:  0.002780011622235179
Epoch:  32  	Training Loss: 0.0037806183099746704
Test Loss:  0.0026371160056442022
Valid Loss:  0.002656005322933197
Epoch:  33  	Training Loss: 0.003528315108269453
Test Loss:  0.002631380222737789
Valid Loss:  0.0026308814994990826
Epoch:  34  	Training Loss: 0.003383846487849951
Test Loss:  0.0026221242733299732
Valid Loss:  0.002631828188896179
Epoch:  35  	Training Loss: 0.003275305265560746
Test Loss:  0.002621486783027649
Valid Loss:  0.0026485181879252195
Epoch:  36  	Training Loss: 0.003193273674696684
Test Loss:  0.00262764235958457
Valid Loss:  0.0026763351634144783
Epoch:  37  	Training Loss: 0.0031312787905335426
Test Loss:  0.002635696204379201
Valid Loss:  0.0027097840793430805
Epoch:  38  	Training Loss: 0.0030857480596750975
Test Loss:  0.0026428382843732834
Valid Loss:  0.0027455308008939028
Epoch:  39  	Training Loss: 0.0030516297556459904
Test Loss:  0.0026561254635453224
Valid Loss:  0.002779677975922823
Epoch:  40  	Training Loss: 0.0030256062746047974
Test Loss:  0.002670163754373789
Valid Loss:  0.0028123948723077774
Epoch:  41  	Training Loss: 0.003005612874403596
Test Loss:  0.0026839557103812695
Valid Loss:  0.0028433038387447596
Epoch:  42  	Training Loss: 0.002990207402035594
Test Loss:  0.0026691965758800507
Valid Loss:  0.0028050504624843597
Epoch:  43  	Training Loss: 0.0029334104619920254
Test Loss:  0.002698610071092844
Valid Loss:  0.0027995812706649303
Epoch:  44  	Training Loss: 0.002921306062489748
Test Loss:  0.00270227063447237
Valid Loss:  0.0028031403198838234
Epoch:  45  	Training Loss: 0.0029105679132044315
Test Loss:  0.002699122531339526
Valid Loss:  0.0028077643364667892
Epoch:  46  	Training Loss: 0.0028997263871133327
Test Loss:  0.0026922188699245453
Valid Loss:  0.0028110980056226254
Epoch:  47  	Training Loss: 0.002888001501560211
Test Loss:  0.00268244999460876
Valid Loss:  0.0028094477020204067
Epoch:  48  	Training Loss: 0.0028748312033712864
Test Loss:  0.002671455964446068
Valid Loss:  0.002805591793730855
Epoch:  49  	Training Loss: 0.002860973123461008
Test Loss:  0.0026591462083160877
Valid Loss:  0.0028002564795315266
Epoch:  50  	Training Loss: 0.002846473129466176
Test Loss:  0.0026460429653525352
Valid Loss:  0.002792551415041089
Epoch:  51  	Training Loss: 0.002831288380548358
Test Loss:  0.002632621442899108
Valid Loss:  0.002783627947792411
Epoch:  52  	Training Loss: 0.0028159688226878643
Test Loss:  0.0026291802059859037
Valid Loss:  0.002780065406113863
Epoch:  53  	Training Loss: 0.002793032443150878
Test Loss:  0.0026019106153398752
Valid Loss:  0.0027814891654998064
Epoch:  54  	Training Loss: 0.0027825047727674246
Test Loss:  0.002600919920951128
Valid Loss:  0.002777429297566414
Epoch:  55  	Training Loss: 0.0027737589552998543
Test Loss:  0.0025981387589126825
Valid Loss:  0.002774935681372881
Epoch:  56  	Training Loss: 0.0027663721702992916
Test Loss:  0.0025983317755162716
Valid Loss:  0.002773445099592209
Epoch:  57  	Training Loss: 0.0027600815519690514
Test Loss:  0.0025949026457965374
Valid Loss:  0.0027736248448491096
Epoch:  58  	Training Loss: 0.00275458674877882
Test Loss:  0.0025948411785066128
Valid Loss:  0.002773591782897711
Epoch:  59  	Training Loss: 0.0027496807742863894
Test Loss:  0.002592820208519697
Valid Loss:  0.002773914486169815
Epoch:  60  	Training Loss: 0.0027452679350972176
Test Loss:  0.0025942400097846985
Valid Loss:  0.0027743633836507797
Epoch:  61  	Training Loss: 0.0027413126081228256
Test Loss:  0.002592486795037985
Valid Loss:  0.0027755398768931627
Epoch:  62  	Training Loss: 0.002737556118518114
Test Loss:  0.0025991376023739576
Valid Loss:  0.00278277974575758
Epoch:  63  	Training Loss: 0.0027361419051885605
Test Loss:  0.002602720633149147
Valid Loss:  0.002790872473269701
Epoch:  64  	Training Loss: 0.0027349197771400213
Test Loss:  0.002605377696454525
Valid Loss:  0.002798879984766245
Epoch:  65  	Training Loss: 0.0027338522486388683
Test Loss:  0.0026077106595039368
Valid Loss:  0.002806551055982709
Epoch:  66  	Training Loss: 0.0027329165022820234
Test Loss:  0.0026098834350705147
Valid Loss:  0.0028138323687016964
Epoch:  67  	Training Loss: 0.0027320964727550745
Test Loss:  0.0026119432877749205
Valid Loss:  0.0028207218274474144
Epoch:  68  	Training Loss: 0.002731379121541977
Test Loss:  0.0026139048859477043
Valid Loss:  0.002827226184308529
Epoch:  69  	Training Loss: 0.002730750013142824
Test Loss:  0.0026157712563872337
Valid Loss:  0.0028333663940429688
 14%|█▍        | 71/500 [01:01<08:38,  1.21s/it] 15%|█▍        | 73/500 [01:01<06:10,  1.15it/s] 15%|█▌        | 75/500 [01:02<04:26,  1.60it/s] 15%|█▌        | 77/500 [01:02<03:13,  2.18it/s] 16%|█▌        | 79/500 [01:02<02:23,  2.94it/s] 16%|█▌        | 81/500 [01:08<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:08<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:08<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:09<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:09<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:15<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:15<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:15<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:16<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:16<02:14,  2.98it/s] 20%|██        | 101/500 [01:22<07:53,  1.19s/it] 21%|██        | 103/500 [01:22<05:40,  1.17it/s] 21%|██        | 105/500 [01:22<04:04,  1.61it/s] 21%|██▏       | 107/500 [01:22<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:23<02:12,  2.96it/s] 22%|██▏       | 111/500 [01:29<07:39,  1.18s/it] 23%|██▎       | 113/500 [01:29<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:29<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:29<02:52,  2.23it/s] 24%|██▍       | 119/500 [01:29<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:36<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:36<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:42<09:52,  1.58s/it] 25%|██▌       | 127/500 [01:43<07:02,  1.13s/it] 26%|██▌       | 129/500 [01:43<05:02,  1.22it/s] 26%|██▌       | 131/500 [01:49<09:31,  1.55s/it] 27%|██▋       | 133/500 [01:49<06:47,  1.11s/it] 27%|██▋       | 135/500 [01:50<04:53,  1.24it/s] 27%|██▋       | 137/500 [01:50<03:33,  1.70it/s]Epoch:  70  	Training Loss: 0.002730198670178652
Test Loss:  0.0026175444945693016
Valid Loss:  0.0028391527011990547
Epoch:  71  	Training Loss: 0.0027297157794237137
Test Loss:  0.0026192301884293556
Valid Loss:  0.002844609785825014
Epoch:  72  	Training Loss: 0.002729292493313551
Test Loss:  0.0026193419471383095
Valid Loss:  0.0028493162244558334
Epoch:  73  	Training Loss: 0.0027288978453725576
Test Loss:  0.0026213228702545166
Valid Loss:  0.002853134647011757
Epoch:  74  	Training Loss: 0.002728547202423215
Test Loss:  0.002622644416987896
Valid Loss:  0.0028570350259542465
Epoch:  75  	Training Loss: 0.0027282279916107655
Test Loss:  0.002623759675770998
Valid Loss:  0.002860824577510357
Epoch:  76  	Training Loss: 0.0027279371861368418
Test Loss:  0.0026247892528772354
Valid Loss:  0.0028644606936722994
Epoch:  77  	Training Loss: 0.002727669896557927
Test Loss:  0.0026257717981934547
Valid Loss:  0.0028679375536739826
Epoch:  78  	Training Loss: 0.0027274261228740215
Test Loss:  0.002626718021929264
Valid Loss:  0.002871226752176881
Epoch:  79  	Training Loss: 0.0027272047009319067
Test Loss:  0.0026276148855686188
Valid Loss:  0.0028743711300194263
Epoch:  80  	Training Loss: 0.0027270112186670303
Test Loss:  0.0026296298019587994
Valid Loss:  0.002876994898542762
Epoch:  81  	Training Loss: 0.0027268286794424057
Test Loss:  0.002629633527249098
Valid Loss:  0.0028802223969250917
Epoch:  82  	Training Loss: 0.0027266712859272957
Test Loss:  0.0026181526482105255
Valid Loss:  0.002869762945920229
Epoch:  83  	Training Loss: 0.002715102396905422
Test Loss:  0.00261708558537066
Valid Loss:  0.0028661685064435005
Epoch:  84  	Training Loss: 0.0027109445072710514
Test Loss:  0.0026171046774834394
Valid Loss:  0.002864166861400008
Epoch:  85  	Training Loss: 0.002707584761083126
Test Loss:  0.0026179200503975153
Valid Loss:  0.002864195965230465
Epoch:  86  	Training Loss: 0.0027060373686254025
Test Loss:  0.002619160106405616
Valid Loss:  0.0028655624482780695
Epoch:  87  	Training Loss: 0.0027052275836467743
Test Loss:  0.002620358718559146
Valid Loss:  0.002867826260626316
Epoch:  88  	Training Loss: 0.0027047372423112392
Test Loss:  0.0026214865501970053
Valid Loss:  0.002870176685974002
Epoch:  89  	Training Loss: 0.0027044066227972507
Test Loss:  0.002622468862682581
Valid Loss:  0.0028725028969347477
Epoch:  90  	Training Loss: 0.002704132813960314
Test Loss:  0.002623348729684949
Valid Loss:  0.002874657977372408
Epoch:  91  	Training Loss: 0.0027038720436394215
Test Loss:  0.0026242206804454327
Valid Loss:  0.0028766514733433723
Epoch:  92  	Training Loss: 0.002703646197915077
Test Loss:  0.0026256979908794165
Valid Loss:  0.002877674764022231
Epoch:  93  	Training Loss: 0.0027034974191337824
Test Loss:  0.0026262972969561815
Valid Loss:  0.002879026811569929
Epoch:  94  	Training Loss: 0.002703361213207245
Test Loss:  0.002626705914735794
Valid Loss:  0.002880371641367674
Epoch:  95  	Training Loss: 0.002703229198232293
Test Loss:  0.0026270621456205845
Valid Loss:  0.002881653606891632
Epoch:  96  	Training Loss: 0.0027031120844185352
Test Loss:  0.002626152243465185
Valid Loss:  0.0028832859825342894
Epoch:  97  	Training Loss: 0.0027030063793063164
Test Loss:  0.002627419074997306
Valid Loss:  0.0028839618898928165
Epoch:  98  	Training Loss: 0.0027029085904359818
Test Loss:  0.002627904526889324
Valid Loss:  0.0028849528171122074
Epoch:  99  	Training Loss: 0.002702824305742979
Test Loss:  0.00262822350487113
Valid Loss:  0.0028859528247267008
Epoch:  100  	Training Loss: 0.0027027432806789875
Test Loss:  0.002628493122756481
Valid Loss:  0.0028869053348898888
Epoch:  101  	Training Loss: 0.0027026620227843523
Test Loss:  0.0026287417858839035
Valid Loss:  0.0028878096491098404
Epoch:  102  	Training Loss: 0.002702583558857441
Test Loss:  0.0025873053818941116
Valid Loss:  0.002898317528888583
Epoch:  103  	Training Loss: 0.0026795356534421444
Test Loss:  0.002577416365966201
Valid Loss:  0.00289542437531054
Epoch:  104  	Training Loss: 0.0026653653476387262
Test Loss:  0.0025799511931836605
Valid Loss:  0.0028901835903525352
Epoch:  105  	Training Loss: 0.002659448655322194
Test Loss:  0.002591729164123535
Valid Loss:  0.0028819655999541283
Epoch:  106  	Training Loss: 0.00265745772048831
Test Loss:  0.002596460282802582
Valid Loss:  0.002878236584365368
Epoch:  107  	Training Loss: 0.002656307304278016
Test Loss:  0.002598439110442996
Valid Loss:  0.0028762330766767263
Epoch:  108  	Training Loss: 0.002655697287991643
Test Loss:  0.002605690620839596
Valid Loss:  0.002872624434530735
Epoch:  109  	Training Loss: 0.0026555785443633795
Test Loss:  0.0026075956411659718
Valid Loss:  0.0028718041721731424
Epoch:  110  	Training Loss: 0.002655530348420143
Test Loss:  0.0026081446558237076
Valid Loss:  0.002871678676456213
Epoch:  111  	Training Loss: 0.002655486110597849
Test Loss:  0.002608349546790123
Valid Loss:  0.0028717326931655407
Epoch:  112  	Training Loss: 0.002655444433912635
Test Loss:  0.0025983904488384724
Valid Loss:  0.002875608392059803
Epoch:  113  	Training Loss: 0.002653992734849453
Test Loss:  0.002601494314149022
Valid Loss:  0.002872257027775049
Epoch:  114  	Training Loss: 0.002653779461979866
Test Loss:  0.0026033795438706875
Valid Loss:  0.0028705247677862644
Epoch:  115  	Training Loss: 0.0026536097284406424
Test Loss:  0.0026045653503388166
Valid Loss:  0.0028696926310658455
Epoch:  116  	Training Loss: 0.0026534544304013252
Test Loss:  0.002605352085083723
Valid Loss:  0.002869355259463191
Epoch:  117  	Training Loss: 0.002653310541063547
Test Loss:  0.0026059001684188843
Valid Loss:  0.0028692991472780704
Epoch:  118  	Training Loss: 0.002653182717040181
Test Loss:  0.0026063062250614166
Valid Loss:  0.0028693899512290955
Epoch:  119  	Training Loss: 0.0026530653703957796
Test Loss:  0.0026066286955028772
Valid Loss:  0.0028695620130747557
Epoch:  120  	Training Loss: 0.002652965486049652
Test Loss:  0.0026068987790495157
Valid Loss:  0.002869776915758848
Epoch:  121  	Training Loss: 0.002652872819453478
Test Loss:  0.002607126720249653
Valid Loss:  0.002870000433176756
Epoch:  122  	Training Loss: 0.0026527780573815107
Test Loss:  0.0027297278866171837
Valid Loss:  0.0028979352209717035
Epoch:  123  	Training Loss: 0.002671921392902732
Test Loss:  0.0025609128642827272
Valid Loss:  0.0029004355892539024
Epoch:  124  	Training Loss: 0.0026518856175243855
Test Loss:  0.0027149810921400785
Valid Loss:  0.0029087234288454056
Epoch:  125  	Training Loss: 0.002671526512131095
Test Loss:  0.0025501239579170942
Valid Loss:  0.002901563886553049
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.0026469009462743998
Test Loss:  0.0026055409107357264
Valid Loss:  0.0028680171817541122
Epoch:  127  	Training Loss: 0.0026441728696227074
Test Loss:  0.002602938562631607
Valid Loss:  0.0028693987987935543
Epoch:  128  	Training Loss: 0.0026441155932843685
Test Loss:  0.0026030177250504494
Valid Loss:  0.0028693429194390774
Epoch:  129  	Training Loss: 0.002644064836204052
Test Loss:  0.0026030014269053936
Valid Loss:  0.00286933989264071
Epoch:  130  	Training Loss: 0.0026440166402608156
Test Loss:  0.002602988388389349
Valid Loss:  0.002869335236027837
Epoch:  131  	Training Loss: 0.0026439689099788666
Test Loss:  0.0026029713917523623
Valid Loss:  0.0028693298809230328
Epoch:  132  	Training Loss: 0.002643928397446871
Test Loss:  0.0025918299797922373
Valid Loss:  0.002869874704629183
Epoch:  133  	Training Loss: 0.0026297648437321186
Test Loss:  0.002583809196949005
Valid Loss:  0.002870265394449234
Epoch:  134  	Training Loss: 0.0026210425421595573
Test Loss:  0.0025793169625103474
Valid Loss:  0.0028693871572613716
Epoch:  135  	Training Loss: 0.0026156106032431126
Test Loss:  0.0025764615274965763
Valid Loss:  0.002868009265512228
Epoch:  136  	Training Loss: 0.002613174496218562
Test Loss:  0.002575348364189267
Valid Loss:  0.002865538466721773
Epoch:  137  	Training Loss: 0.0026120070833712816
Test Loss:  0.0025747623294591904
Valid Loss:  0.002862658817321062
 28%|██▊       | 139/500 [01:50<02:37,  2.29it/s] 28%|██▊       | 141/500 [01:56<07:34,  1.27s/it] 29%|██▊       | 143/500 [01:57<05:24,  1.10it/s] 29%|██▉       | 145/500 [01:57<03:52,  1.53it/s] 29%|██▉       | 147/500 [01:57<02:48,  2.09it/s] 30%|██▉       | 149/500 [01:57<02:04,  2.82it/s] 30%|███       | 151/500 [02:03<06:59,  1.20s/it] 31%|███       | 153/500 [02:03<04:59,  1.16it/s] 31%|███       | 155/500 [02:04<03:35,  1.60it/s] 31%|███▏      | 157/500 [02:04<02:36,  2.19it/s] 32%|███▏      | 159/500 [02:04<01:55,  2.95it/s] 32%|███▏      | 161/500 [02:10<06:47,  1.20s/it] 33%|███▎      | 163/500 [02:10<04:52,  1.15it/s] 33%|███▎      | 165/500 [02:11<03:32,  1.58it/s] 33%|███▎      | 167/500 [02:11<02:36,  2.13it/s] 34%|███▍      | 169/500 [02:11<01:57,  2.82it/s] 34%|███▍      | 171/500 [02:17<06:36,  1.21s/it] 35%|███▍      | 173/500 [02:17<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:18<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:18<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:18<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:24<06:30,  1.22s/it] 37%|███▋      | 183/500 [02:25<04:38,  1.14it/s] 37%|███▋      | 185/500 [02:25<03:19,  1.58it/s] 37%|███▋      | 187/500 [02:25<02:25,  2.16it/s] 38%|███▊      | 189/500 [02:25<01:47,  2.90it/s] 38%|███▊      | 191/500 [02:32<06:22,  1.24s/it] 39%|███▊      | 193/500 [02:32<04:32,  1.13it/s] 39%|███▉      | 195/500 [02:32<03:15,  1.56it/s] 39%|███▉      | 197/500 [02:32<02:21,  2.14it/s] 40%|███▉      | 199/500 [02:32<01:44,  2.88it/s] 40%|████      | 201/500 [02:38<05:56,  1.19s/it] 41%|████      | 203/500 [02:39<04:15,  1.16it/s] 41%|████      | 205/500 [02:39<03:05,  1.59it/s]Epoch:  138  	Training Loss: 0.0026112496852874756
Test Loss:  0.002574439626187086
Valid Loss:  0.0028599309735000134
Epoch:  139  	Training Loss: 0.002610577503219247
Test Loss:  0.002574366517364979
Valid Loss:  0.002857394516468048
Epoch:  140  	Training Loss: 0.002610084367915988
Test Loss:  0.0025755895767360926
Valid Loss:  0.002854631282389164
Epoch:  141  	Training Loss: 0.0026097565423697233
Test Loss:  0.002576273400336504
Valid Loss:  0.002852505771443248
Epoch:  142  	Training Loss: 0.002609451999887824
Test Loss:  0.0025777576956897974
Valid Loss:  0.002850546734407544
Epoch:  143  	Training Loss: 0.002609436633065343
Test Loss:  0.002578557701781392
Valid Loss:  0.0028492300771176815
Epoch:  144  	Training Loss: 0.0026094289496541023
Test Loss:  0.0025789598003029823
Valid Loss:  0.002848298056051135
Epoch:  145  	Training Loss: 0.0026094254571944475
Test Loss:  0.002579128136858344
Valid Loss:  0.0028476014267653227
Epoch:  146  	Training Loss: 0.002609421731904149
Test Loss:  0.0025791670195758343
Valid Loss:  0.0028470526449382305
Epoch:  147  	Training Loss: 0.002609419170767069
Test Loss:  0.002579126972705126
Valid Loss:  0.002846597693860531
Epoch:  148  	Training Loss: 0.0026094173081219196
Test Loss:  0.0025790452491492033
Valid Loss:  0.002846206072717905
Epoch:  149  	Training Loss: 0.0026094154454767704
Test Loss:  0.0025789460632950068
Valid Loss:  0.002845859620720148
Epoch:  150  	Training Loss: 0.002609414514154196
Test Loss:  0.002578835701569915
Valid Loss:  0.002845545532181859
Epoch:  151  	Training Loss: 0.00260941288433969
Test Loss:  0.002578724641352892
Valid Loss:  0.002845254959538579
Epoch:  152  	Training Loss: 0.0026094119530171156
Test Loss:  0.002593778306618333
Valid Loss:  0.002830110490322113
Epoch:  153  	Training Loss: 0.002566663548350334
Test Loss:  0.002591686323285103
Valid Loss:  0.0028338278643786907
Epoch:  154  	Training Loss: 0.0025500538758933544
Test Loss:  0.0025774785317480564
Valid Loss:  0.00284211291000247
Epoch:  155  	Training Loss: 0.0025430757086724043
Test Loss:  0.0025636418722569942
Valid Loss:  0.00284997234120965
Epoch:  156  	Training Loss: 0.0025377413257956505
Test Loss:  0.002551793120801449
Valid Loss:  0.002857144922018051
Epoch:  157  	Training Loss: 0.002533660503104329
Test Loss:  0.002540438901633024
Valid Loss:  0.002863402711227536
Epoch:  158  	Training Loss: 0.002530541503801942
Test Loss:  0.0025315904058516026
Valid Loss:  0.002868819050490856
Epoch:  159  	Training Loss: 0.0025281114503741264
Test Loss:  0.0025228001177310944
Valid Loss:  0.0028733140788972378
Epoch:  160  	Training Loss: 0.0025264720898121595
Test Loss:  0.0025138435885310173
Valid Loss:  0.002876757178455591
Epoch:  161  	Training Loss: 0.002525156829506159
Test Loss:  0.002509345533326268
Valid Loss:  0.0028794636018574238
Epoch:  162  	Training Loss: 0.0025239652022719383
Test Loss:  0.00249089440330863
Valid Loss:  0.0028716044034808874
Epoch:  163  	Training Loss: 0.0025143895763903856
Test Loss:  0.002479140181094408
Valid Loss:  0.0028622897807508707
Epoch:  164  	Training Loss: 0.0025064244400709867
Test Loss:  0.0024709689896553755
Valid Loss:  0.0028522666543722153
Epoch:  165  	Training Loss: 0.0024995908606797457
Test Loss:  0.0024652290157973766
Valid Loss:  0.002842172048985958
Epoch:  166  	Training Loss: 0.0024938080459833145
Test Loss:  0.002461183350533247
Valid Loss:  0.00283224880695343
Epoch:  167  	Training Loss: 0.002488598460331559
Test Loss:  0.0024581102188676596
Valid Loss:  0.0028225844725966454
Epoch:  168  	Training Loss: 0.0024836964439600706
Test Loss:  0.00245592906139791
Valid Loss:  0.0028133061714470387
Epoch:  169  	Training Loss: 0.0024792987387627363
Test Loss:  0.002454090630635619
Valid Loss:  0.002804690506309271
Epoch:  170  	Training Loss: 0.0024753129109740257
Test Loss:  0.0024525607004761696
Valid Loss:  0.002796534914523363
Epoch:  171  	Training Loss: 0.002471680287271738
Test Loss:  0.002451397478580475
Valid Loss:  0.0027887842152267694
Epoch:  172  	Training Loss: 0.002468300983309746
Test Loss:  0.0024519390426576138
Valid Loss:  0.0027862826827913523
Epoch:  173  	Training Loss: 0.002468154300004244
Test Loss:  0.0024522114545106888
Valid Loss:  0.0027839895337820053
Epoch:  174  	Training Loss: 0.0024680166970938444
Test Loss:  0.002452288754284382
Valid Loss:  0.0027818731032311916
Epoch:  175  	Training Loss: 0.002467886544764042
Test Loss:  0.002452217973768711
Valid Loss:  0.002779889851808548
Epoch:  176  	Training Loss: 0.0024677615147083998
Test Loss:  0.0024520449806004763
Valid Loss:  0.0027780095115303993
Epoch:  177  	Training Loss: 0.002467644866555929
Test Loss:  0.002451820531859994
Valid Loss:  0.0027762025129050016
Epoch:  178  	Training Loss: 0.0024675382301211357
Test Loss:  0.002451531123369932
Valid Loss:  0.0027744784019887447
Epoch:  179  	Training Loss: 0.00246743718162179
Test Loss:  0.0024512060917913914
Valid Loss:  0.00277280667796731
Epoch:  180  	Training Loss: 0.002467341488227248
Test Loss:  0.0024508442729711533
Valid Loss:  0.0027711973525583744
Epoch:  181  	Training Loss: 0.0024672471918165684
Test Loss:  0.0024504526518285275
Valid Loss:  0.002769637852907181
Epoch:  182  	Training Loss: 0.00246715871617198
Test Loss:  0.0024484978057444096
Valid Loss:  0.0027606990188360214
Epoch:  183  	Training Loss: 0.002462976612150669
Test Loss:  0.002446959260851145
Valid Loss:  0.002753071952611208
Epoch:  184  	Training Loss: 0.002459968440234661
Test Loss:  0.0024457813706249
Valid Loss:  0.0027463026344776154
Epoch:  185  	Training Loss: 0.0024574906565248966
Test Loss:  0.002444631652906537
Valid Loss:  0.00274018757045269
Epoch:  186  	Training Loss: 0.002455230336636305
Test Loss:  0.002443514298647642
Valid Loss:  0.0027346292044967413
Epoch:  187  	Training Loss: 0.002453206805512309
Test Loss:  0.00244258064776659
Valid Loss:  0.0027297877240926027
Epoch:  188  	Training Loss: 0.002451456617563963
Test Loss:  0.002441639080643654
Valid Loss:  0.0027253455482423306
Epoch:  189  	Training Loss: 0.0024498251732438803
Test Loss:  0.0024407259188592434
Valid Loss:  0.002721264958381653
Epoch:  190  	Training Loss: 0.002448325976729393
Test Loss:  0.002439917530864477
Valid Loss:  0.0027174893766641617
Epoch:  191  	Training Loss: 0.002446959260851145
Test Loss:  0.0024391235783696175
Valid Loss:  0.002714070025831461
Epoch:  192  	Training Loss: 0.002445732243359089
Test Loss:  0.0024452018551528454
Valid Loss:  0.002708492334932089
Epoch:  193  	Training Loss: 0.002432580105960369
Test Loss:  0.002438540803268552
Valid Loss:  0.0027109161019325256
Epoch:  194  	Training Loss: 0.0024248037952929735
Test Loss:  0.0024292839225381613
Valid Loss:  0.002713905181735754
Epoch:  195  	Training Loss: 0.002419279655441642
Test Loss:  0.002421904355287552
Valid Loss:  0.0027156358119100332
Epoch:  196  	Training Loss: 0.0024146665818989277
Test Loss:  0.0024154535494744778
Valid Loss:  0.0027163466438651085
Epoch:  197  	Training Loss: 0.002410904038697481
Test Loss:  0.002408339874818921
Valid Loss:  0.0027161859907209873
Epoch:  198  	Training Loss: 0.002408275380730629
Test Loss:  0.0024040585849434137
Valid Loss:  0.0027147489599883556
Epoch:  199  	Training Loss: 0.002405778970569372
Test Loss:  0.00240081874653697
Valid Loss:  0.0027127524372190237
Epoch:  200  	Training Loss: 0.0024038120172917843
Test Loss:  0.0023937963414937258
Valid Loss:  0.0027103624306619167
Epoch:  201  	Training Loss: 0.0024026227183640003
Test Loss:  0.0023897166829556227
Valid Loss:  0.00270653422921896
Epoch:  202  	Training Loss: 0.00240151584148407
Test Loss:  0.002384396269917488
Valid Loss:  0.0027042487636208534
Epoch:  203  	Training Loss: 0.0024007561150938272
Test Loss:  0.0023809289559721947
Valid Loss:  0.0027010852936655283
Epoch:  204  	Training Loss: 0.0024000948760658503
Test Loss:  0.0023784947115927935
Valid Loss:  0.0026976182125508785
Epoch:  205  	Training Loss: 0.002399533987045288
Test Loss:  0.002376608084887266
Valid Loss:  0.0026940335519611835
Epoch:  206  	Training Loss: 0.0023990159388631582
Test Loss:  0.0023750741966068745
Valid Loss:  0.002690482884645462
 41%|████▏     | 207/500 [02:39<02:16,  2.15it/s] 42%|████▏     | 209/500 [02:39<01:42,  2.85it/s] 42%|████▏     | 211/500 [02:46<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:46<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:46<02:59,  1.58it/s] 43%|████▎     | 217/500 [02:46<02:12,  2.14it/s] 44%|████▍     | 219/500 [02:46<01:39,  2.83it/s] 44%|████▍     | 221/500 [02:53<05:35,  1.20s/it] 45%|████▍     | 223/500 [02:53<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:53<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:53<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:53<01:31,  2.95it/s] 46%|████▌     | 231/500 [03:00<05:23,  1.20s/it] 47%|████▋     | 233/500 [03:00<03:51,  1.15it/s] 47%|████▋     | 235/500 [03:00<02:47,  1.58it/s] 47%|████▋     | 237/500 [03:00<02:03,  2.13it/s] 48%|████▊     | 239/500 [03:00<01:32,  2.83it/s] 48%|████▊     | 241/500 [03:07<05:12,  1.21s/it] 49%|████▊     | 243/500 [03:07<03:42,  1.16it/s] 49%|████▉     | 245/500 [03:07<02:39,  1.60it/s] 49%|████▉     | 247/500 [03:07<01:55,  2.19it/s] 50%|████▉     | 249/500 [03:07<01:25,  2.94it/s] 50%|█████     | 251/500 [03:14<04:59,  1.20s/it] 51%|█████     | 253/500 [03:14<03:33,  1.16it/s] 51%|█████     | 255/500 [03:14<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:14<01:51,  2.19it/s] 52%|█████▏    | 259/500 [03:14<01:21,  2.94it/s] 52%|█████▏    | 261/500 [03:21<04:49,  1.21s/it] 53%|█████▎    | 263/500 [03:21<03:25,  1.15it/s] 53%|█████▎    | 265/500 [03:21<02:27,  1.59it/s] 53%|█████▎    | 267/500 [03:21<01:46,  2.18it/s] 54%|█████▍    | 269/500 [03:21<01:18,  2.93it/s] 54%|█████▍    | 271/500 [03:27<04:33,  1.19s/it] 55%|█████▍    | 273/500 [03:28<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:28<02:21,  1.59it/s]Epoch:  207  	Training Loss: 0.002398562617599964
Test Loss:  0.002373740077018738
Valid Loss:  0.002687032101675868
Epoch:  208  	Training Loss: 0.0023981621488928795
Test Loss:  0.0023725370410829782
Valid Loss:  0.002683712635189295
Epoch:  209  	Training Loss: 0.002397802658379078
Test Loss:  0.00237144622951746
Valid Loss:  0.0026805547531694174
Epoch:  210  	Training Loss: 0.002397483214735985
Test Loss:  0.0023704601917415857
Valid Loss:  0.0026775728911161423
Epoch:  211  	Training Loss: 0.002397209173068404
Test Loss:  0.002369516994804144
Valid Loss:  0.0026747281663119793
Epoch:  212  	Training Loss: 0.002396955620497465
Test Loss:  0.002378983423113823
Valid Loss:  0.002668876200914383
Epoch:  213  	Training Loss: 0.002384620951488614
Test Loss:  0.0023746471852064133
Valid Loss:  0.002669030334800482
Epoch:  214  	Training Loss: 0.002377950120717287
Test Loss:  0.0023675868287682533
Valid Loss:  0.002669797744601965
Epoch:  215  	Training Loss: 0.0023726781364530325
Test Loss:  0.0023602459114044905
Valid Loss:  0.002669908571988344
Epoch:  216  	Training Loss: 0.002367730252444744
Test Loss:  0.0023535694926977158
Valid Loss:  0.0026692915707826614
Epoch:  217  	Training Loss: 0.0023630638606846333
Test Loss:  0.0023474963381886482
Valid Loss:  0.0026680289302021265
Epoch:  218  	Training Loss: 0.0023585243616253138
Test Loss:  0.0023427866399288177
Valid Loss:  0.002666299697011709
Epoch:  219  	Training Loss: 0.002354088006541133
Test Loss:  0.002335985191166401
Valid Loss:  0.0026640614960342646
Epoch:  220  	Training Loss: 0.0023498523514717817
Test Loss:  0.0023311874829232693
Valid Loss:  0.0026612114161252975
Epoch:  221  	Training Loss: 0.0023456369526684284
Test Loss:  0.0023260205052793026
Valid Loss:  0.0026581063866615295
Epoch:  222  	Training Loss: 0.002341440413147211
Test Loss:  0.0023104825522750616
Valid Loss:  0.0026550493203103542
Epoch:  223  	Training Loss: 0.0023354305885732174
Test Loss:  0.002301902277395129
Valid Loss:  0.002648988738656044
Epoch:  224  	Training Loss: 0.0023305201902985573
Test Loss:  0.00229712319560349
Valid Loss:  0.002642226405441761
Epoch:  225  	Training Loss: 0.002326888032257557
Test Loss:  0.0022936686873435974
Valid Loss:  0.0026353427674621344
Epoch:  226  	Training Loss: 0.0023233280517160892
Test Loss:  0.0022908421233296394
Valid Loss:  0.0026285683270543814
Epoch:  227  	Training Loss: 0.0023198663257062435
Test Loss:  0.002288730116561055
Valid Loss:  0.002622046507894993
Epoch:  228  	Training Loss: 0.0023166867904365063
Test Loss:  0.002286907285451889
Valid Loss:  0.0026158930268138647
Epoch:  229  	Training Loss: 0.0023139372933655977
Test Loss:  0.002285188063979149
Valid Loss:  0.002610092516988516
Epoch:  230  	Training Loss: 0.0023113929200917482
Test Loss:  0.002283768728375435
Valid Loss:  0.0026045595295727253
Epoch:  231  	Training Loss: 0.0023088916204869747
Test Loss:  0.0022826194763183594
Valid Loss:  0.0025992507580667734
Epoch:  232  	Training Loss: 0.0023064776323735714
Test Loss:  0.0022835072595626116
Valid Loss:  0.002596195787191391
Epoch:  233  	Training Loss: 0.0023063565604388714
Test Loss:  0.0022840083111077547
Valid Loss:  0.002593511715531349
Epoch:  234  	Training Loss: 0.0023062496911734343
Test Loss:  0.0022842255420982838
Valid Loss:  0.002591113094240427
Epoch:  235  	Training Loss: 0.002306153066456318
Test Loss:  0.0022842339240014553
Valid Loss:  0.0025889351963996887
Epoch:  236  	Training Loss: 0.0023060650564730167
Test Loss:  0.002284090267494321
Valid Loss:  0.002586939837783575
Epoch:  237  	Training Loss: 0.002305983565747738
Test Loss:  0.0022838390432298183
Valid Loss:  0.002585084643214941
Epoch:  238  	Training Loss: 0.0023059078957885504
Test Loss:  0.0022835126146674156
Valid Loss:  0.0025833442341536283
Epoch:  239  	Training Loss: 0.002305836882442236
Test Loss:  0.0022831314709037542
Valid Loss:  0.0025817048735916615
Epoch:  240  	Training Loss: 0.002305768895894289
Test Loss:  0.0022827174980193377
Valid Loss:  0.0025801449082791805
Epoch:  241  	Training Loss: 0.002305706962943077
Test Loss:  0.002282281406223774
Valid Loss:  0.0025786603800952435
Epoch:  242  	Training Loss: 0.0023056466598063707
Test Loss:  0.0022997246123850346
Valid Loss:  0.002574507612735033
Epoch:  243  	Training Loss: 0.0022895336151123047
Test Loss:  0.002284195041283965
Valid Loss:  0.002575988881289959
Epoch:  244  	Training Loss: 0.0022889338433742523
Test Loss:  0.0022862227633595467
Valid Loss:  0.0025776505935937166
Epoch:  245  	Training Loss: 0.002288550604134798
Test Loss:  0.0022759682033210993
Valid Loss:  0.002578199375420809
Epoch:  246  	Training Loss: 0.002288072369992733
Test Loss:  0.0022759062703698874
Valid Loss:  0.002578629180788994
Epoch:  247  	Training Loss: 0.0022878709714859724
Test Loss:  0.0022693912032991648
Valid Loss:  0.0025786005426198244
Epoch:  248  	Training Loss: 0.0022877915762364864
Test Loss:  0.0022710119374096394
Valid Loss:  0.002578500658273697
Epoch:  249  	Training Loss: 0.002287638606503606
Test Loss:  0.0022656985092908144
Valid Loss:  0.0025780063588172197
Epoch:  250  	Training Loss: 0.002287494018673897
Test Loss:  0.002267446368932724
Valid Loss:  0.0025776615366339684
Epoch:  251  	Training Loss: 0.0022874537389725447
Test Loss:  0.002262961817905307
Valid Loss:  0.0025768589694052935
Epoch:  252  	Training Loss: 0.0022872674744576216
Test Loss:  0.002259686356410384
Valid Loss:  0.0025741802528500557
Epoch:  253  	Training Loss: 0.0022838879376649857
Test Loss:  0.0022530355490744114
Valid Loss:  0.00257109384983778
Epoch:  254  	Training Loss: 0.002281059743836522
Test Loss:  0.002254154533147812
Valid Loss:  0.0025673797354102135
Epoch:  255  	Training Loss: 0.002278601983562112
Test Loss:  0.0022492236457765102
Valid Loss:  0.002564165275543928
Epoch:  256  	Training Loss: 0.0022762930020689964
Test Loss:  0.0022498704493045807
Valid Loss:  0.0025604842230677605
Epoch:  257  	Training Loss: 0.0022743623703718185
Test Loss:  0.0022466429509222507
Valid Loss:  0.0025571018923074007
Epoch:  258  	Training Loss: 0.002272483194246888
Test Loss:  0.0022479200270026922
Valid Loss:  0.002553537953644991
Epoch:  259  	Training Loss: 0.0022707313764840364
Test Loss:  0.0022451276890933514
Valid Loss:  0.0025503430515527725
Epoch:  260  	Training Loss: 0.0022689851466566324
Test Loss:  0.002246180083602667
Valid Loss:  0.002547069452702999
Epoch:  261  	Training Loss: 0.00226757675409317
Test Loss:  0.0022439819294959307
Valid Loss:  0.002544238232076168
Epoch:  262  	Training Loss: 0.0022663259878754616
Test Loss:  0.0022512716241180897
Valid Loss:  0.0025388114154338837
Epoch:  263  	Training Loss: 0.0022573804017156363
Test Loss:  0.0022553473245352507
Valid Loss:  0.002537011168897152
Epoch:  264  	Training Loss: 0.0022511519491672516
Test Loss:  0.00225424044765532
Valid Loss:  0.002538135042414069
Epoch:  265  	Training Loss: 0.002249297685921192
Test Loss:  0.0022510397247970104
Valid Loss:  0.002539165085181594
Epoch:  266  	Training Loss: 0.0022477111779153347
Test Loss:  0.0022496883757412434
Valid Loss:  0.002539960667490959
Epoch:  267  	Training Loss: 0.0022462287452071905
Test Loss:  0.0022461810149252415
Valid Loss:  0.002540400717407465
Epoch:  268  	Training Loss: 0.0022451472468674183
Test Loss:  0.0022417097352445126
Valid Loss:  0.0025403122417628765
Epoch:  269  	Training Loss: 0.002244533272460103
Test Loss:  0.002237261738628149
Valid Loss:  0.0025395299308001995
Epoch:  270  	Training Loss: 0.0022440203465521336
Test Loss:  0.002235127380117774
Valid Loss:  0.0025383210740983486
Epoch:  271  	Training Loss: 0.002243529772385955
Test Loss:  0.002231711521744728
Valid Loss:  0.002536806743592024
Epoch:  272  	Training Loss: 0.002243074821308255
Test Loss:  0.0022220597602427006
Valid Loss:  0.0025363576132804155
Epoch:  273  	Training Loss: 0.0022414959967136383
Test Loss:  0.0022167933639138937
Valid Loss:  0.002533817198127508
Epoch:  274  	Training Loss: 0.0022401604801416397
Test Loss:  0.002213694853708148
Valid Loss:  0.0025303736329078674
Epoch:  275  	Training Loss: 0.0022389665246009827
Test Loss:  0.0022117081098258495
Valid Loss:  0.0025267628952860832
 55%|█████▌    | 277/500 [03:28<01:43,  2.15it/s] 56%|█████▌    | 279/500 [03:28<01:17,  2.84it/s] 56%|█████▌    | 281/500 [03:35<04:25,  1.21s/it] 57%|█████▋    | 283/500 [03:35<03:09,  1.14it/s] 57%|█████▋    | 285/500 [03:35<02:17,  1.57it/s] 57%|█████▋    | 287/500 [03:35<01:40,  2.12it/s] 58%|█████▊    | 289/500 [03:35<01:15,  2.80it/s] 58%|█████▊    | 291/500 [03:42<04:13,  1.21s/it] 59%|█████▊    | 293/500 [03:42<03:00,  1.15it/s] 59%|█████▉    | 295/500 [03:42<02:09,  1.59it/s] 59%|█████▉    | 297/500 [03:42<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:42<01:08,  2.92it/s] 60%|██████    | 301/500 [03:49<03:58,  1.20s/it] 61%|██████    | 303/500 [03:49<02:50,  1.16it/s] 61%|██████    | 305/500 [03:49<02:02,  1.59it/s] 61%|██████▏   | 307/500 [03:49<01:30,  2.14it/s] 62%|██████▏   | 309/500 [03:49<01:06,  2.86it/s] 62%|██████▏   | 311/500 [03:56<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:56<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:56<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:56<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:56<01:01,  2.96it/s] 64%|██████▍   | 321/500 [04:03<03:33,  1.19s/it] 65%|██████▍   | 323/500 [04:03<02:31,  1.17it/s] 65%|██████▌   | 325/500 [04:03<01:48,  1.62it/s] 65%|██████▌   | 327/500 [04:03<01:18,  2.21it/s] 66%|██████▌   | 329/500 [04:03<00:57,  2.97it/s] 66%|██████▌   | 331/500 [04:09<03:21,  1.19s/it] 67%|██████▋   | 333/500 [04:10<02:23,  1.16it/s] 67%|██████▋   | 335/500 [04:10<01:43,  1.60it/s] 67%|██████▋   | 337/500 [04:10<01:14,  2.18it/s] 68%|██████▊   | 339/500 [04:10<00:54,  2.94it/s] 68%|██████▊   | 341/500 [04:16<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:16<02:12,  1.19it/s]Epoch:  276  	Training Loss: 0.0022379481233656406
Test Loss:  0.0022102068178355694
Valid Loss:  0.002523076720535755
Epoch:  277  	Training Loss: 0.002236980479210615
Test Loss:  0.0022090040147304535
Valid Loss:  0.0025194548070430756
Epoch:  278  	Training Loss: 0.002236101310700178
Test Loss:  0.002207972574979067
Valid Loss:  0.0025159644428640604
Epoch:  279  	Training Loss: 0.0022352985106408596
Test Loss:  0.0022070053964853287
Valid Loss:  0.00251260818913579
Epoch:  280  	Training Loss: 0.002234554849565029
Test Loss:  0.002206165576353669
Valid Loss:  0.002509424928575754
Epoch:  281  	Training Loss: 0.0022339136339724064
Test Loss:  0.002205332973971963
Valid Loss:  0.0025063876528292894
Epoch:  282  	Training Loss: 0.002233310369774699
Test Loss:  0.0022054044529795647
Valid Loss:  0.002502575283870101
Epoch:  283  	Training Loss: 0.0022327180486172438
Test Loss:  0.0022052950225770473
Valid Loss:  0.002499275840818882
Epoch:  284  	Training Loss: 0.002232200698927045
Test Loss:  0.0022050258703529835
Valid Loss:  0.002496329601854086
Epoch:  285  	Training Loss: 0.002231735736131668
Test Loss:  0.0022046116646379232
Valid Loss:  0.0024936427362263203
Epoch:  286  	Training Loss: 0.002231294522061944
Test Loss:  0.002204138319939375
Valid Loss:  0.002491174265742302
Epoch:  287  	Training Loss: 0.0022308980114758015
Test Loss:  0.0022036032751202583
Valid Loss:  0.002488880418241024
Epoch:  288  	Training Loss: 0.002230512909591198
Test Loss:  0.0022030347026884556
Valid Loss:  0.0024867281317710876
Epoch:  289  	Training Loss: 0.0022301352582871914
Test Loss:  0.0022024516947567463
Valid Loss:  0.002484702505171299
Epoch:  290  	Training Loss: 0.002229767618700862
Test Loss:  0.002201871247962117
Valid Loss:  0.002482782583683729
Epoch:  291  	Training Loss: 0.002229407662525773
Test Loss:  0.002201301511377096
Valid Loss:  0.0024809595197439194
Epoch:  292  	Training Loss: 0.0022290567867457867
Test Loss:  0.0022016107104718685
Valid Loss:  0.002478470094501972
Epoch:  293  	Training Loss: 0.00222888495773077
Test Loss:  0.0022016833536326885
Valid Loss:  0.002476364839822054
Epoch:  294  	Training Loss: 0.002228721510618925
Test Loss:  0.002201586030423641
Valid Loss:  0.0024745487608015537
Epoch:  295  	Training Loss: 0.0022285659797489643
Test Loss:  0.0022013699635863304
Valid Loss:  0.0024729541037231684
Epoch:  296  	Training Loss: 0.0022284139413386583
Test Loss:  0.00220107426866889
Valid Loss:  0.002471533138304949
Epoch:  297  	Training Loss: 0.0022282670252025127
Test Loss:  0.0022007268853485584
Valid Loss:  0.00247024605050683
Epoch:  298  	Training Loss: 0.00222812220454216
Test Loss:  0.0022003459744155407
Valid Loss:  0.0024690693244338036
Epoch:  299  	Training Loss: 0.0022279880940914154
Test Loss:  0.002199959009885788
Valid Loss:  0.002467985264956951
Epoch:  300  	Training Loss: 0.0022278623655438423
Test Loss:  0.0021995846182107925
Valid Loss:  0.0024669768754392862
Epoch:  301  	Training Loss: 0.0022277389653027058
Test Loss:  0.002199206966906786
Valid Loss:  0.002466033212840557
Epoch:  302  	Training Loss: 0.002227621152997017
Test Loss:  0.002197429072111845
Valid Loss:  0.0024656662717461586
Epoch:  303  	Training Loss: 0.002227594144642353
Test Loss:  0.0021964283660054207
Valid Loss:  0.002464889781549573
Epoch:  304  	Training Loss: 0.0022275736555457115
Test Loss:  0.0021957773715257645
Valid Loss:  0.00246397964656353
Epoch:  305  	Training Loss: 0.0022275573574006557
Test Loss:  0.0021952898241579533
Valid Loss:  0.002463046694174409
Epoch:  306  	Training Loss: 0.002227542456239462
Test Loss:  0.0021948879584670067
Valid Loss:  0.002462141215801239
Epoch:  307  	Training Loss: 0.0022275298833847046
Test Loss:  0.002194533124566078
Valid Loss:  0.0024612797424197197
Epoch:  308  	Training Loss: 0.002227518241852522
Test Loss:  0.0021942120511084795
Valid Loss:  0.002460470888763666
Epoch:  309  	Training Loss: 0.002227508695796132
Test Loss:  0.002193915657699108
Valid Loss:  0.0024597076699137688
Epoch:  310  	Training Loss: 0.0022274998482316732
Test Loss:  0.002193641383200884
Valid Loss:  0.0024589933454990387
Epoch:  311  	Training Loss: 0.0022274923976510763
Test Loss:  0.002193386433646083
Valid Loss:  0.0024583269841969013
Epoch:  312  	Training Loss: 0.0022274856455624104
Test Loss:  0.0021993578411638737
Valid Loss:  0.0024580766912549734
Epoch:  313  	Training Loss: 0.002226518699899316
Test Loss:  0.0021981934551149607
Valid Loss:  0.002458800794556737
Epoch:  314  	Training Loss: 0.0022259270772337914
Test Loss:  0.0021959803998470306
Valid Loss:  0.0024594436399638653
Epoch:  315  	Training Loss: 0.0022255193907767534
Test Loss:  0.0021958760917186737
Valid Loss:  0.002459997311234474
Epoch:  316  	Training Loss: 0.0022251885384321213
Test Loss:  0.0021927636116743088
Valid Loss:  0.002460283925756812
Epoch:  317  	Training Loss: 0.002224849071353674
Test Loss:  0.0021930269431322813
Valid Loss:  0.0024604247882962227
Epoch:  318  	Training Loss: 0.0022245640866458416
Test Loss:  0.002189628779888153
Valid Loss:  0.0024602669291198254
Epoch:  319  	Training Loss: 0.0022242439445108175
Test Loss:  0.0021891777869313955
Valid Loss:  0.002459774725139141
Epoch:  320  	Training Loss: 0.0022239568643271923
Test Loss:  0.002190658589825034
Valid Loss:  0.0024595698341727257
Epoch:  321  	Training Loss: 0.0022236763034015894
Test Loss:  0.002187766134738922
Valid Loss:  0.0024592503905296326
Epoch:  322  	Training Loss: 0.002223365008831024
Test Loss:  0.002185533754527569
Valid Loss:  0.002452573738992214
Epoch:  323  	Training Loss: 0.0022049015387892723
Test Loss:  0.002178739756345749
Valid Loss:  0.002452326938509941
Epoch:  324  	Training Loss: 0.0021945741027593613
Test Loss:  0.0021697827614843845
Valid Loss:  0.0024543392937630415
Epoch:  325  	Training Loss: 0.0021875316742807627
Test Loss:  0.0021616797894239426
Valid Loss:  0.002456875052303076
Epoch:  326  	Training Loss: 0.00218274537473917
Test Loss:  0.00215613073669374
Valid Loss:  0.0024589821696281433
Epoch:  327  	Training Loss: 0.0021788328886032104
Test Loss:  0.0021514631807804108
Valid Loss:  0.002461111405864358
Epoch:  328  	Training Loss: 0.0021758798975497484
Test Loss:  0.002146999118849635
Valid Loss:  0.002462946344166994
Epoch:  329  	Training Loss: 0.002173859626054764
Test Loss:  0.0021438312251120806
Valid Loss:  0.0024642283096909523
Epoch:  330  	Training Loss: 0.0021720677614212036
Test Loss:  0.0021421071141958237
Valid Loss:  0.002465176861733198
Epoch:  331  	Training Loss: 0.0021704360842704773
Test Loss:  0.0021393131464719772
Valid Loss:  0.0024659449700266123
Epoch:  332  	Training Loss: 0.002169564366340637
Test Loss:  0.00215075071901083
Valid Loss:  0.0024591225665062666
Epoch:  333  	Training Loss: 0.0021578394807875156
Test Loss:  0.0021502177696675062
Valid Loss:  0.002458295552060008
Epoch:  334  	Training Loss: 0.002156187780201435
Test Loss:  0.0021464386954903603
Valid Loss:  0.0024573386181145906
Epoch:  335  	Training Loss: 0.0021554220002144575
Test Loss:  0.0021394016221165657
Valid Loss:  0.002455595415085554
Epoch:  336  	Training Loss: 0.0021547419019043446
Test Loss:  0.002135086338967085
Valid Loss:  0.0024530841037631035
Epoch:  337  	Training Loss: 0.002154179150238633
Test Loss:  0.0021311528980731964
Valid Loss:  0.0024501848965883255
Epoch:  338  	Training Loss: 0.00215367553755641
Test Loss:  0.002128136344254017
Valid Loss:  0.0024470379576087
Epoch:  339  	Training Loss: 0.002153212670236826
Test Loss:  0.002125701867043972
Valid Loss:  0.002443815115839243
Epoch:  340  	Training Loss: 0.0021527879871428013
Test Loss:  0.002122350502759218
Valid Loss:  0.00244052242487669
Epoch:  341  	Training Loss: 0.00215239729732275
Test Loss:  0.0021210513077676296
Valid Loss:  0.0024371854960918427
Epoch:  342  	Training Loss: 0.002152038738131523
Test Loss:  0.0021174494177103043
Valid Loss:  0.002434203866869211
Epoch:  343  	Training Loss: 0.002151654101908207
Test Loss:  0.0021145546343177557
Valid Loss:  0.002430945634841919
Epoch:  344  	Training Loss: 0.002151310443878174
Test Loss:  0.0021121359895914793
Valid Loss:  0.0024275805335491896
 69%|██████▉   | 345/500 [04:17<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:17<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:17<00:50,  3.00it/s] 70%|███████   | 351/500 [04:23<02:55,  1.18s/it] 71%|███████   | 353/500 [04:23<02:04,  1.18it/s] 71%|███████   | 355/500 [04:23<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:24<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:24<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:30<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:30<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:30<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:30<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:31<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:37<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:37<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:37<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:37<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:37<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:44<02:22,  1.19s/it] 77%|███████▋  | 383/500 [04:44<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:44<01:12,  1.59it/s] 77%|███████▋  | 387/500 [04:44<00:52,  2.15it/s] 78%|███████▊  | 389/500 [04:44<00:39,  2.83it/s] 78%|███████▊  | 391/500 [04:51<02:14,  1.23s/it] 79%|███████▊  | 393/500 [04:51<01:34,  1.13it/s] 79%|███████▉  | 395/500 [04:51<01:07,  1.56it/s] 79%|███████▉  | 397/500 [04:51<00:48,  2.14it/s] 80%|███████▉  | 399/500 [04:52<00:35,  2.86it/s] 80%|████████  | 401/500 [04:58<01:59,  1.20s/it] 81%|████████  | 403/500 [04:58<01:23,  1.16it/s] 81%|████████  | 405/500 [04:58<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:58<00:42,  2.19it/s] 82%|████████▏ | 409/500 [04:59<00:30,  2.95it/s] 82%|████████▏ | 411/500 [05:05<01:46,  1.19s/it] 83%|████████▎ | 413/500 [05:05<01:14,  1.17it/s]Epoch:  345  	Training Loss: 0.0021509993821382523
Test Loss:  0.0021100505255162716
Valid Loss:  0.0024242079816758633
Epoch:  346  	Training Loss: 0.002150716492906213
Test Loss:  0.0021082069724798203
Valid Loss:  0.0024208873510360718
Epoch:  347  	Training Loss: 0.002150456653907895
Test Loss:  0.0021065426990389824
Valid Loss:  0.0024176593869924545
Epoch:  348  	Training Loss: 0.002150219166651368
Test Loss:  0.0021050162613391876
Valid Loss:  0.0024145408533513546
Epoch:  349  	Training Loss: 0.002150001935660839
Test Loss:  0.0021035978570580482
Valid Loss:  0.0024115401320159435
Epoch:  350  	Training Loss: 0.0021498026326298714
Test Loss:  0.0021022697910666466
Valid Loss:  0.0024086679331958294
Epoch:  351  	Training Loss: 0.0021496210247278214
Test Loss:  0.002101019723340869
Valid Loss:  0.002405919134616852
Epoch:  352  	Training Loss: 0.0021494554821401834
Test Loss:  0.0020980113185942173
Valid Loss:  0.0024063745513558388
Epoch:  353  	Training Loss: 0.0021491595543920994
Test Loss:  0.0020959426183253527
Valid Loss:  0.0024064737372100353
Epoch:  354  	Training Loss: 0.0021489164792001247
Test Loss:  0.0020945374853909016
Valid Loss:  0.0024063531309366226
Epoch:  355  	Training Loss: 0.0021487311460077763
Test Loss:  0.0020935542415827513
Valid Loss:  0.0024060779251158237
Epoch:  356  	Training Loss: 0.00214854977093637
Test Loss:  0.0020928424783051014
Valid Loss:  0.002405700273811817
Epoch:  357  	Training Loss: 0.002148372121155262
Test Loss:  0.0020923304837197065
Valid Loss:  0.002405258361250162
Epoch:  358  	Training Loss: 0.002148205181583762
Test Loss:  0.0020919430535286665
Valid Loss:  0.0024047796614468098
Epoch:  359  	Training Loss: 0.0021480577997863293
Test Loss:  0.0020916324574500322
Valid Loss:  0.0024042802397161722
Epoch:  360  	Training Loss: 0.0021479190327227116
Test Loss:  0.002091385889798403
Valid Loss:  0.0024037635885179043
Epoch:  361  	Training Loss: 0.002147780731320381
Test Loss:  0.002091181231662631
Valid Loss:  0.0024032369256019592
Epoch:  362  	Training Loss: 0.0021476447582244873
Test Loss:  0.0020933756604790688
Valid Loss:  0.0024002722930163145
Epoch:  363  	Training Loss: 0.0021473956294357777
Test Loss:  0.0020911572501063347
Valid Loss:  0.002397734671831131
Epoch:  364  	Training Loss: 0.00214719888754189
Test Loss:  0.002093501854687929
Valid Loss:  0.002395392395555973
Epoch:  365  	Training Loss: 0.002146976999938488
Test Loss:  0.002090689493343234
Valid Loss:  0.0023933411575853825
Epoch:  366  	Training Loss: 0.002146758371964097
Test Loss:  0.002092139795422554
Valid Loss:  0.0023913183249533176
Epoch:  367  	Training Loss: 0.0021465476602315903
Test Loss:  0.0020895362831652164
Valid Loss:  0.0023894833866506815
Epoch:  368  	Training Loss: 0.00214637559838593
Test Loss:  0.0020917055662721395
Valid Loss:  0.002387760207056999
Epoch:  369  	Training Loss: 0.002146209590137005
Test Loss:  0.002088807290419936
Valid Loss:  0.00238618697039783
Epoch:  370  	Training Loss: 0.0021460000425577164
Test Loss:  0.0020902343094348907
Valid Loss:  0.0023846749681979418
Epoch:  371  	Training Loss: 0.0021458840928971767
Test Loss:  0.0020876112394034863
Valid Loss:  0.0023831836879253387
Epoch:  372  	Training Loss: 0.002145698992535472
Test Loss:  0.00208824360743165
Valid Loss:  0.0023803168442100286
Epoch:  373  	Training Loss: 0.002145612146705389
Test Loss:  0.0020884997211396694
Valid Loss:  0.002377935219556093
Epoch:  374  	Training Loss: 0.0021455402020365
Test Loss:  0.0020885136909782887
Valid Loss:  0.00237590866163373
Epoch:  375  	Training Loss: 0.0021454759407788515
Test Loss:  0.002088377717882395
Valid Loss:  0.002374151488766074
Epoch:  376  	Training Loss: 0.0021454207599163055
Test Loss:  0.002088146982714534
Valid Loss:  0.0023726015351712704
Epoch:  377  	Training Loss: 0.0021453695371747017
Test Loss:  0.0020878585055470467
Valid Loss:  0.0023712236434221268
Epoch:  378  	Training Loss: 0.002145321574062109
Test Loss:  0.002087540691718459
Valid Loss:  0.0023699807934463024
Epoch:  379  	Training Loss: 0.00214527640491724
Test Loss:  0.0020872026216238737
Valid Loss:  0.0023688520304858685
Epoch:  380  	Training Loss: 0.0021452337969094515
Test Loss:  0.0020868596620857716
Valid Loss:  0.002367819659411907
Epoch:  381  	Training Loss: 0.0021451932843774557
Test Loss:  0.0020865118131041527
Valid Loss:  0.002366873435676098
Epoch:  382  	Training Loss: 0.0021451544016599655
Test Loss:  0.0020843511447310448
Valid Loss:  0.0023668124340474606
Epoch:  383  	Training Loss: 0.0021451222710311413
Test Loss:  0.002083148807287216
Valid Loss:  0.002366282045841217
Epoch:  384  	Training Loss: 0.002145100152119994
Test Loss:  0.002082410268485546
Valid Loss:  0.0023655504919588566
Epoch:  385  	Training Loss: 0.002145081292837858
Test Loss:  0.0020818987395614386
Valid Loss:  0.0023647467605769634
Epoch:  386  	Training Loss: 0.002145065227523446
Test Loss:  0.0020814992021769285
Valid Loss:  0.002363931853324175
Epoch:  387  	Training Loss: 0.0021450496278703213
Test Loss:  0.002081167884171009
Valid Loss:  0.002363130683079362
Epoch:  388  	Training Loss: 0.002145035658031702
Test Loss:  0.0020808710251003504
Valid Loss:  0.0023623567540198565
Epoch:  389  	Training Loss: 0.002145023550838232
Test Loss:  0.002080596284940839
Valid Loss:  0.002361612394452095
Epoch:  390  	Training Loss: 0.0021450119093060493
Test Loss:  0.0020803443621844053
Valid Loss:  0.0023609036579728127
Epoch:  391  	Training Loss: 0.0021450016647577286
Test Loss:  0.002080101054161787
Valid Loss:  0.002360226586461067
Epoch:  392  	Training Loss: 0.002144991885870695
Test Loss:  0.002079582307487726
Valid Loss:  0.002355556935071945
Epoch:  393  	Training Loss: 0.0021336509380489588
Test Loss:  0.0020767534151673317
Valid Loss:  0.0023530989419668913
Epoch:  394  	Training Loss: 0.0021256012842059135
Test Loss:  0.0020717564038932323
Valid Loss:  0.002351689850911498
Epoch:  395  	Training Loss: 0.0021196859888732433
Test Loss:  0.002067056018859148
Valid Loss:  0.0023504705168306828
Epoch:  396  	Training Loss: 0.0021150922402739525
Test Loss:  0.002062876708805561
Valid Loss:  0.0023491678293794394
Epoch:  397  	Training Loss: 0.0021111066453158855
Test Loss:  0.0020592156797647476
Valid Loss:  0.0023476583883166313
Epoch:  398  	Training Loss: 0.00210741488263011
Test Loss:  0.0020559339318424463
Valid Loss:  0.002345893532037735
Epoch:  399  	Training Loss: 0.002103951061144471
Test Loss:  0.0020526526495814323
Valid Loss:  0.002343973610550165
Epoch:  400  	Training Loss: 0.0021009407937526703
Test Loss:  0.00204979139380157
Valid Loss:  0.002341932151466608
Epoch:  401  	Training Loss: 0.002098395023494959
Test Loss:  0.0020473613403737545
Valid Loss:  0.0023397556506097317
Epoch:  402  	Training Loss: 0.002095988718792796
Test Loss:  0.0020480360835790634
Valid Loss:  0.002336222678422928
Epoch:  403  	Training Loss: 0.0020959042012691498
Test Loss:  0.002048150636255741
Valid Loss:  0.0023334636352956295
Epoch:  404  	Training Loss: 0.0020958376117050648
Test Loss:  0.0020479289814829826
Valid Loss:  0.002331218682229519
Epoch:  405  	Training Loss: 0.002095781033858657
Test Loss:  0.0020475166384130716
Valid Loss:  0.0023293171543627977
Epoch:  406  	Training Loss: 0.002095733769237995
Test Loss:  0.002046995796263218
Valid Loss:  0.002327659633010626
Epoch:  407  	Training Loss: 0.002095690229907632
Test Loss:  0.002046426059678197
Valid Loss:  0.0023261806927621365
Epoch:  408  	Training Loss: 0.0020956529770046473
Test Loss:  0.0020458376966416836
Valid Loss:  0.0023248381912708282
Epoch:  409  	Training Loss: 0.00209561875090003
Test Loss:  0.002045250963419676
Valid Loss:  0.002323603956028819
Epoch:  410  	Training Loss: 0.0020955889485776424
Test Loss:  0.002044679131358862
Valid Loss:  0.00232245703227818
Epoch:  411  	Training Loss: 0.0020955626387149096
Test Loss:  0.0020441277883946896
Valid Loss:  0.0023213899694383144
Epoch:  412  	Training Loss: 0.002095538889989257
Test Loss:  0.0020458907820284367
Valid Loss:  0.002321123844012618
Epoch:  413  	Training Loss: 0.0020951982587575912
Test Loss:  0.002044747117906809
Valid Loss:  0.002320702653378248
 83%|████████▎ | 415/500 [05:05<00:52,  1.61it/s] 83%|████████▎ | 417/500 [05:05<00:37,  2.20it/s] 84%|████████▍ | 419/500 [05:05<00:27,  2.96it/s] 84%|████████▍ | 421/500 [05:12<01:32,  1.18s/it] 85%|████████▍ | 423/500 [05:12<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:12<00:45,  1.63it/s] 85%|████████▌ | 427/500 [05:12<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:12<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:19<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:19<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:19<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:19<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:19<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:26<01:09,  1.19s/it] 89%|████████▊ | 443/500 [05:26<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:26<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:26<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:26<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:32<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:33<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:33<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:33<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:33<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:39<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:40<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:40<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:40<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:40<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:46<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:46<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:47<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:47<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:47<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:53<00:22,  1.21s/it]Epoch:  414  	Training Loss: 0.0020949216559529305
Test Loss:  0.0020449890289455652
Valid Loss:  0.0023204239550977945
Epoch:  415  	Training Loss: 0.002094685100018978
Test Loss:  0.002043941058218479
Valid Loss:  0.0023200656287372112
Epoch:  416  	Training Loss: 0.0020945111755281687
Test Loss:  0.0020460402593016624
Valid Loss:  0.0023200497962534428
Epoch:  417  	Training Loss: 0.002094344235956669
Test Loss:  0.0020445799455046654
Valid Loss:  0.002319736173376441
Epoch:  418  	Training Loss: 0.002094157040119171
Test Loss:  0.002044612541794777
Valid Loss:  0.0023195361718535423
Epoch:  419  	Training Loss: 0.0020940324757248163
Test Loss:  0.0020434590987861156
Valid Loss:  0.0023192341905087233
Epoch:  420  	Training Loss: 0.0020939474925398827
Test Loss:  0.0020454046316444874
Valid Loss:  0.002319234423339367
Epoch:  421  	Training Loss: 0.0020938809029757977
Test Loss:  0.00204380601644516
Valid Loss:  0.0023189461790025234
Epoch:  422  	Training Loss: 0.0020937882363796234
Test Loss:  0.0020312198903411627
Valid Loss:  0.0023177701514214277
Epoch:  423  	Training Loss: 0.002088340697810054
Test Loss:  0.0020304620265960693
Valid Loss:  0.0023134772200137377
Epoch:  424  	Training Loss: 0.002085309475660324
Test Loss:  0.002030238974839449
Valid Loss:  0.0023098778910934925
Epoch:  425  	Training Loss: 0.002082966733723879
Test Loss:  0.0020300941541790962
Valid Loss:  0.0023067237343639135
Epoch:  426  	Training Loss: 0.0020809206180274487
Test Loss:  0.002030119998380542
Valid Loss:  0.002304116263985634
Epoch:  427  	Training Loss: 0.0020792968571186066
Test Loss:  0.0020301872864365578
Valid Loss:  0.002302016830071807
Epoch:  428  	Training Loss: 0.002078103367239237
Test Loss:  0.0020301123149693012
Valid Loss:  0.002300327643752098
Epoch:  429  	Training Loss: 0.002077150857076049
Test Loss:  0.0020300522446632385
Valid Loss:  0.002298880834132433
Epoch:  430  	Training Loss: 0.0020764481741935015
Test Loss:  0.0020300322212278843
Valid Loss:  0.0022977390326559544
Epoch:  431  	Training Loss: 0.002075907774269581
Test Loss:  0.0020300692413002253
Valid Loss:  0.0022968007251620293
Epoch:  432  	Training Loss: 0.0020755031146109104
Test Loss:  0.002030806615948677
Valid Loss:  0.0022965394891798496
Epoch:  433  	Training Loss: 0.00207547377794981
Test Loss:  0.0020305984653532505
Valid Loss:  0.0022964393720030785
Epoch:  434  	Training Loss: 0.002075467724353075
Test Loss:  0.0020304606296122074
Valid Loss:  0.002296315971761942
Epoch:  435  	Training Loss: 0.0020754605066031218
Test Loss:  0.002030357951298356
Valid Loss:  0.002296179998666048
Epoch:  436  	Training Loss: 0.002075456315651536
Test Loss:  0.0020302743650972843
Valid Loss:  0.0022960416972637177
Epoch:  437  	Training Loss: 0.0020754504948854446
Test Loss:  0.0020302000921219587
Valid Loss:  0.0022959017660468817
Epoch:  438  	Training Loss: 0.002075444906949997
Test Loss:  0.002030133968219161
Valid Loss:  0.0022957674227654934
Epoch:  439  	Training Loss: 0.0020754397846758366
Test Loss:  0.0020300608593970537
Valid Loss:  0.0022956368047744036
Epoch:  440  	Training Loss: 0.0020754374563694
Test Loss:  0.002029996830970049
Valid Loss:  0.00229550595395267
Epoch:  441  	Training Loss: 0.0020754330325871706
Test Loss:  0.002029934898018837
Valid Loss:  0.0022953792940825224
Epoch:  442  	Training Loss: 0.002075431402772665
Test Loss:  0.0020310208201408386
Valid Loss:  0.0022953092120587826
Epoch:  443  	Training Loss: 0.0020753720309585333
Test Loss:  0.0020307607483118773
Valid Loss:  0.0022953241132199764
Epoch:  444  	Training Loss: 0.002075351309031248
Test Loss:  0.002030530944466591
Valid Loss:  0.00229532178491354
Epoch:  445  	Training Loss: 0.002075339201837778
Test Loss:  0.0020302976481616497
Valid Loss:  0.0022952938452363014
Epoch:  446  	Training Loss: 0.002075334545224905
Test Loss:  0.0020300420001149178
Valid Loss:  0.0022952365688979626
Epoch:  447  	Training Loss: 0.0020753329154103994
Test Loss:  0.0020298524759709835
Valid Loss:  0.002295155543833971
Epoch:  448  	Training Loss: 0.0020753322169184685
Test Loss:  0.0020297092851251364
Valid Loss:  0.0022950605489313602
Epoch:  449  	Training Loss: 0.0020753308199346066
Test Loss:  0.0020295963622629642
Valid Loss:  0.002294957172125578
Epoch:  450  	Training Loss: 0.0020753294229507446
Test Loss:  0.0020295034628361464
Valid Loss:  0.0022948510013520718
Epoch:  451  	Training Loss: 0.002075329190120101
Test Loss:  0.0020294231362640858
Valid Loss:  0.00229474576190114
Epoch:  452  	Training Loss: 0.0020753280259668827
Test Loss:  0.0020221008453518152
Valid Loss:  0.0022909853141754866
Epoch:  453  	Training Loss: 0.0020682355388998985
Test Loss:  0.002017396502196789
Valid Loss:  0.00228739227168262
Epoch:  454  	Training Loss: 0.0020624762400984764
Test Loss:  0.002014265861362219
Valid Loss:  0.0022836863063275814
Epoch:  455  	Training Loss: 0.002057333942502737
Test Loss:  0.002012206008657813
Valid Loss:  0.002280091168358922
Epoch:  456  	Training Loss: 0.0020531355403363705
Test Loss:  0.0020109086763113737
Valid Loss:  0.00227664178237319
Epoch:  457  	Training Loss: 0.0020493261981755495
Test Loss:  0.0020099738612771034
Valid Loss:  0.002273252932354808
Epoch:  458  	Training Loss: 0.0020455685444176197
Test Loss:  0.002009171061217785
Valid Loss:  0.0022699222899973392
Epoch:  459  	Training Loss: 0.002041872125118971
Test Loss:  0.0020086090080440044
Valid Loss:  0.0022666756995022297
Epoch:  460  	Training Loss: 0.0020383531227707863
Test Loss:  0.0020082946866750717
Valid Loss:  0.002263477537781
Epoch:  461  	Training Loss: 0.002034999430179596
Test Loss:  0.0020082397386431694
Valid Loss:  0.002260418375954032
Epoch:  462  	Training Loss: 0.002031936775892973
Test Loss:  0.0020114511717110872
Valid Loss:  0.0022576292976737022
Epoch:  463  	Training Loss: 0.002030284609645605
Test Loss:  0.0020129974000155926
Valid Loss:  0.0022559580393135548
Epoch:  464  	Training Loss: 0.0020287372171878815
Test Loss:  0.002013877732679248
Valid Loss:  0.00225478014908731
Epoch:  465  	Training Loss: 0.002027355134487152
Test Loss:  0.002014347119256854
Valid Loss:  0.0022538388147950172
Epoch:  466  	Training Loss: 0.0020260291639715433
Test Loss:  0.002014605328440666
Valid Loss:  0.0022530490532517433
Epoch:  467  	Training Loss: 0.002024770015850663
Test Loss:  0.0020146556198596954
Valid Loss:  0.0022523151710629463
Epoch:  468  	Training Loss: 0.0020235655829310417
Test Loss:  0.0020146691240370274
Valid Loss:  0.0022516227327287197
Epoch:  469  	Training Loss: 0.002022429369390011
Test Loss:  0.0020146872848272324
Valid Loss:  0.0022509333211928606
Epoch:  470  	Training Loss: 0.0020212975796312094
Test Loss:  0.002014709170907736
Valid Loss:  0.002250270452350378
Epoch:  471  	Training Loss: 0.002020214218646288
Test Loss:  0.00201480183750391
Valid Loss:  0.0022497924510389566
Epoch:  472  	Training Loss: 0.002019246108829975
Test Loss:  0.0020211413502693176
Valid Loss:  0.00224959384649992
Epoch:  473  	Training Loss: 0.0020153853110969067
Test Loss:  0.0020218854770064354
Valid Loss:  0.002252186182886362
Epoch:  474  	Training Loss: 0.0020129128824919462
Test Loss:  0.0020213411189615726
Valid Loss:  0.0022551484871655703
Epoch:  475  	Training Loss: 0.002010826952755451
Test Loss:  0.002019630977883935
Valid Loss:  0.002257798332720995
Epoch:  476  	Training Loss: 0.002009663265198469
Test Loss:  0.0020164605230093002
Valid Loss:  0.0022598481737077236
Epoch:  477  	Training Loss: 0.002008998766541481
Test Loss:  0.0020140078850090504
Valid Loss:  0.002260905923321843
Epoch:  478  	Training Loss: 0.0020085321739315987
Test Loss:  0.00201145326718688
Valid Loss:  0.002261365996673703
Epoch:  479  	Training Loss: 0.0020082558039575815
Test Loss:  0.0020093286875635386
Valid Loss:  0.002261295448988676
Epoch:  480  	Training Loss: 0.0020080709364265203
Test Loss:  0.0020070199389010668
Valid Loss:  0.0022607462015002966
Epoch:  481  	Training Loss: 0.002007958712056279
Test Loss:  0.0020051393657922745
Valid Loss:  0.002259728265926242
Epoch:  482  	Training Loss: 0.002007878851145506
Test Loss:  0.002003689296543598
Valid Loss:  0.0022599296644330025
 97%|█████████▋| 483/500 [05:53<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:54<00:09,  1.57it/s] 97%|█████████▋| 487/500 [05:54<00:06,  2.12it/s] 98%|█████████▊| 489/500 [05:54<00:03,  2.81it/s] 98%|█████████▊| 491/500 [06:01<00:11,  1.23s/it] 99%|█████████▊| 493/500 [06:01<00:06,  1.12it/s] 99%|█████████▉| 495/500 [06:01<00:03,  1.54it/s] 99%|█████████▉| 497/500 [06:01<00:01,  2.08it/s]100%|█████████▉| 499/500 [06:01<00:00,  2.76it/s]100%|██████████| 500/500 [06:01<00:00,  1.38it/s]
Epoch:  483  	Training Loss: 0.0020077305380254984
Test Loss:  0.0020007281564176083
Valid Loss:  0.002259783912450075
Epoch:  484  	Training Loss: 0.0020076544024050236
Test Loss:  0.0020005640108138323
Valid Loss:  0.002259142231196165
Epoch:  485  	Training Loss: 0.002007590839639306
Test Loss:  0.0019988473504781723
Valid Loss:  0.0022584369871765375
Epoch:  486  	Training Loss: 0.0020075347274541855
Test Loss:  0.001999255269765854
Valid Loss:  0.002257563639432192
Epoch:  487  	Training Loss: 0.0020074904896318913
Test Loss:  0.0019980575889348984
Valid Loss:  0.0022567720152437687
Epoch:  488  	Training Loss: 0.0020074425265192986
Test Loss:  0.0019982042722404003
Valid Loss:  0.0022558686323463917
Epoch:  489  	Training Loss: 0.0020074087660759687
Test Loss:  0.001997720217332244
Valid Loss:  0.002255086787045002
Epoch:  490  	Training Loss: 0.0020073670893907547
Test Loss:  0.0019977472256869078
Valid Loss:  0.002254311228170991
Epoch:  491  	Training Loss: 0.002007328439503908
Test Loss:  0.0019968203268945217
Valid Loss:  0.002253567101433873
Epoch:  492  	Training Loss: 0.0020072960760444403
Test Loss:  0.001992359757423401
Valid Loss:  0.0022507505491375923
Epoch:  493  	Training Loss: 0.0020027889404445887
Test Loss:  0.0019895366858690977
Valid Loss:  0.002248171716928482
Epoch:  494  	Training Loss: 0.0019993698224425316
Test Loss:  0.0019874738063663244
Valid Loss:  0.0022455756552517414
Epoch:  495  	Training Loss: 0.0019964114762842655
Test Loss:  0.0019856179133057594
Valid Loss:  0.002242948394268751
Epoch:  496  	Training Loss: 0.001993779093027115
Test Loss:  0.0019844563212245703
Valid Loss:  0.002240539761260152
Epoch:  497  	Training Loss: 0.0019917553290724754
Test Loss:  0.0019835615530610085
Valid Loss:  0.0022382577881217003
Epoch:  498  	Training Loss: 0.001989824464544654
Test Loss:  0.0019828910008072853
Valid Loss:  0.0022360594011843204
Epoch:  499  	Training Loss: 0.001987908501178026
Test Loss:  0.001982196466997266
Valid Loss:  0.0022339278366416693
Epoch:  500  	Training Loss: 0.0019860239699482918
Test Loss:  0.0019818206783384085
Valid Loss:  0.0022318914998322725
seed is  7
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:40, 12.17it/s]  1%|          | 4/500 [00:00<00:40, 12.36it/s]  1%|          | 6/500 [00:00<00:39, 12.49it/s]  2%|▏         | 8/500 [00:00<00:35, 13.75it/s]  2%|▏         | 10/500 [00:00<00:33, 14.59it/s]  2%|▏         | 12/500 [00:00<00:32, 15.16it/s]  3%|▎         | 14/500 [00:00<00:31, 15.60it/s]  3%|▎         | 16/500 [00:01<00:30, 15.89it/s]  4%|▎         | 18/500 [00:01<00:29, 16.07it/s]  4%|▍         | 20/500 [00:01<00:29, 16.16it/s]  4%|▍         | 22/500 [00:01<00:29, 16.26it/s]  5%|▍         | 24/500 [00:01<00:29, 16.25it/s]  5%|▌         | 26/500 [00:01<00:29, 16.29it/s]  6%|▌         | 28/500 [00:01<00:28, 16.31it/s]  6%|▌         | 30/500 [00:01<00:28, 16.32it/s]  6%|▋         | 32/500 [00:02<00:28, 16.14it/s]  7%|▋         | 34/500 [00:02<00:28, 16.18it/s]  7%|▋         | 36/500 [00:02<00:28, 16.23it/s]  8%|▊         | 38/500 [00:02<00:28, 16.30it/s]  8%|▊         | 40/500 [00:02<00:28, 16.24it/s]  8%|▊         | 42/500 [00:02<00:28, 16.21it/s]  9%|▉         | 44/500 [00:02<00:28, 16.24it/s]  9%|▉         | 46/500 [00:02<00:27, 16.29it/s] 10%|▉         | 48/500 [00:03<00:27, 16.40it/s] 10%|█         | 50/500 [00:03<00:27, 16.40it/s] 10%|█         | 52/500 [00:03<00:27, 16.21it/s] 11%|█         | 54/500 [00:03<00:27, 16.31it/s] 11%|█         | 56/500 [00:03<00:27, 16.24it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.28it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.30it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.38it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.39it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.39it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.39it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.46it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.90it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.06it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.22it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.30it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.41it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.98it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.07it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.13it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.25it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.23it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.36it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.41it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.44it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.42it/s] 20%|██        | 100/500 [00:06<00:24, 16.45it/s] 20%|██        | 102/500 [00:06<00:24, 16.47it/s] 21%|██        | 104/500 [00:06<00:24, 16.49it/s] 21%|██        | 106/500 [00:06<00:23, 16.43it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.44it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.44it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.40it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.39it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.38it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.38it/s] 24%|██▍       | 120/500 [00:07<00:24, 15.22it/s] 24%|██▍       | 122/500 [00:07<00:26, 14.30it/s] 25%|██▍       | 124/500 [00:07<00:27, 13.63it/s]Epoch:  1  	Training Loss: 0.2261407971382141
Test Loss:  4990.6591796875
Valid Loss:  5009.65673828125
Epoch:  2  	Training Loss: 4922.8271484375
Test Loss:  2.945163227824128e+16
Valid Loss:  2.884454938836992e+16
Epoch:  3  	Training Loss: 2.930584176086221e+16
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:28, 13.26it/s] 26%|██▌       | 128/500 [00:08<00:28, 12.99it/s] 26%|██▌       | 130/500 [00:08<00:28, 12.82it/s] 26%|██▋       | 132/500 [00:08<00:28, 12.76it/s] 27%|██▋       | 134/500 [00:08<00:28, 12.90it/s] 27%|██▋       | 136/500 [00:08<00:26, 13.70it/s] 28%|██▊       | 138/500 [00:08<00:25, 14.28it/s] 28%|██▊       | 140/500 [00:08<00:24, 14.76it/s] 28%|██▊       | 142/500 [00:09<00:23, 15.24it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.58it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.69it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.95it/s] 30%|███       | 150/500 [00:09<00:21, 16.07it/s] 30%|███       | 152/500 [00:09<00:21, 16.22it/s] 31%|███       | 154/500 [00:09<00:21, 16.24it/s] 31%|███       | 156/500 [00:09<00:21, 16.25it/s] 32%|███▏      | 158/500 [00:10<00:20, 16.33it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.35it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.32it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.29it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.28it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.31it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.19it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.05it/s] 35%|███▍      | 174/500 [00:11<00:20, 16.07it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.00it/s] 36%|███▌      | 178/500 [00:11<00:20, 16.01it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.16it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.00it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.11it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.21it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.27it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.31it/s] 38%|███▊      | 192/500 [00:12<00:18, 16.32it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.25it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.29it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.29it/s] 40%|████      | 200/500 [00:12<00:18, 16.31it/s] 40%|████      | 202/500 [00:12<00:18, 16.05it/s] 41%|████      | 204/500 [00:12<00:18, 16.12it/s] 41%|████      | 206/500 [00:13<00:18, 16.20it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.04it/s] 42%|████▏     | 210/500 [00:13<00:18, 16.07it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.10it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.11it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.20it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.30it/s] 44%|████▍     | 220/500 [00:13<00:18, 15.19it/s] 44%|████▍     | 222/500 [00:14<00:19, 14.06it/s] 45%|████▍     | 224/500 [00:14<00:20, 13.50it/s] 45%|████▌     | 226/500 [00:14<00:20, 13.15it/s] 46%|████▌     | 228/500 [00:14<00:21, 12.91it/s] 46%|████▌     | 230/500 [00:14<00:20, 12.94it/s] 46%|████▋     | 232/500 [00:14<00:19, 13.80it/s] 47%|████▋     | 234/500 [00:14<00:18, 14.44it/s] 47%|████▋     | 236/500 [00:15<00:17, 14.99it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.47it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.78it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.97it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.12it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.19it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.22it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.24it/s] 50%|█████     | 252/500 [00:16<00:15, 16.27it/s] 51%|█████     | 254/500 [00:16<00:15, 16.34it/s] 51%|█████     | 256/500 [00:16<00:14, 16.32it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.21it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.29it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.28it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.29it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.28it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.11it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.09it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.18it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.15it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.25it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.25it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.26it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.32it/s] 57%|█████▋    | 284/500 [00:18<00:14, 15.24it/s] 57%|█████▋    | 286/500 [00:18<00:15, 14.17it/s] 58%|█████▊    | 288/500 [00:18<00:15, 13.67it/s] 58%|█████▊    | 290/500 [00:18<00:14, 14.36it/s] 58%|█████▊    | 292/500 [00:18<00:13, 14.91it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.37it/s] 59%|█████▉    | 296/500 [00:18<00:13, 15.54it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.59it/s] 60%|██████    | 300/500 [00:19<00:12, 15.61it/s] 60%|██████    | 302/500 [00:19<00:12, 15.73it/s] 61%|██████    | 304/500 [00:19<00:12, 15.85it/s] 61%|██████    | 306/500 [00:19<00:12, 15.97it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.05it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.03it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.98it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.91it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.02it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.07it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.12it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.94it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.61it/s] 65%|██████▌   | 326/500 [00:20<00:12, 14.48it/s] 66%|██████▌   | 328/500 [00:20<00:12, 13.79it/s] 66%|██████▌   | 330/500 [00:21<00:12, 13.36it/s] 66%|██████▋   | 332/500 [00:21<00:12, 13.05it/s] 67%|██████▋   | 334/500 [00:21<00:12, 12.86it/s] 67%|██████▋   | 336/500 [00:21<00:12, 12.72it/s] 68%|██████▊   | 338/500 [00:21<00:12, 12.63it/s] 68%|██████▊   | 340/500 [00:21<00:12, 12.55it/s] 68%|██████▊   | 342/500 [00:22<00:12, 12.51it/s] 69%|██████▉   | 344/500 [00:22<00:12, 12.45it/s] 69%|██████▉   | 346/500 [00:22<00:12, 12.45it/s] 70%|██████▉   | 348/500 [00:22<00:12, 12.44it/s] 70%|███████   | 350/500 [00:22<00:12, 12.44it/s] 70%|███████   | 352/500 [00:22<00:11, 12.43it/s] 71%|███████   | 354/500 [00:23<00:11, 12.46it/s] 71%|███████   | 356/500 [00:23<00:11, 12.45it/s] 72%|███████▏  | 358/500 [00:23<00:11, 12.33it/s] 72%|███████▏  | 360/500 [00:23<00:11, 12.33it/s] 72%|███████▏  | 362/500 [00:23<00:11, 12.36it/s] 73%|███████▎  | 364/500 [00:23<00:10, 12.88it/s] 73%|███████▎  | 366/500 [00:23<00:09, 13.69it/s] 74%|███████▎  | 368/500 [00:24<00:09, 14.39it/s] 74%|███████▍  | 370/500 [00:24<00:08, 14.89it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.31it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:08, 15.37it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.64it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.82it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.94it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.02it/s] 77%|███████▋  | 384/500 [00:25<00:07, 16.14it/s] 77%|███████▋  | 386/500 [00:25<00:07, 16.19it/s] 78%|███████▊  | 388/500 [00:25<00:06, 16.32it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.33it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.21it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.17it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.26it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.26it/s] 80%|████████  | 400/500 [00:26<00:06, 16.31it/s] 80%|████████  | 402/500 [00:26<00:05, 16.40it/s] 81%|████████  | 404/500 [00:26<00:05, 16.41it/s] 81%|████████  | 406/500 [00:26<00:05, 16.38it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.23it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.27it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.31it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.27it/s] 83%|████████▎ | 416/500 [00:27<00:05, 16.35it/s] 84%|████████▎ | 418/500 [00:27<00:05, 16.38it/s] 84%|████████▍ | 420/500 [00:27<00:04, 16.28it/s] 84%|████████▍ | 422/500 [00:27<00:04, 16.35it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.34it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.38it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.39it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.39it/s] 86%|████████▋ | 432/500 [00:28<00:04, 16.37it/s] 87%|████████▋ | 434/500 [00:28<00:04, 16.19it/s] 87%|████████▋ | 436/500 [00:28<00:03, 16.16it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.15it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.13it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.17it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.20it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.24it/s] 90%|████████▉ | 448/500 [00:29<00:03, 16.24it/s] 90%|█████████ | 450/500 [00:29<00:03, 16.37it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.38it/s] 91%|█████████ | 454/500 [00:29<00:02, 16.37it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.35it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.33it/s] 92%|█████████▏| 460/500 [00:29<00:02, 16.36it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.38it/s] 93%|█████████▎| 464/500 [00:30<00:02, 16.33it/s] 93%|█████████▎| 466/500 [00:30<00:02, 16.42it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.42it/s] 94%|█████████▍| 470/500 [00:30<00:01, 16.37it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.23it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.02it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.06it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.12it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.20it/s] 96%|█████████▋| 482/500 [00:31<00:01, 16.17it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.02it/s] 97%|█████████▋| 486/500 [00:31<00:00, 16.11it/s] 98%|█████████▊| 488/500 [00:31<00:00, 16.09it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.11it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.02it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.99it/s] 99%|█████████▉| 496/500 [00:32<00:00, 15.95it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 15.98it/s]100%|██████████| 500/500 [00:32<00:00, 16.11it/s]100%|██████████| 500/500 [00:32<00:00, 15.51it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  7
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:08,  6.15s/it]  1%|          | 3/500 [00:06<13:38,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:14,  1.54it/s]  3%|▎         | 17/500 [00:13<03:48,  2.12it/s]  4%|▍         | 19/500 [00:13<02:49,  2.84it/s]  4%|▍         | 21/500 [00:20<09:48,  1.23s/it]  5%|▍         | 23/500 [00:20<06:58,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.58it/s]  5%|▌         | 27/500 [00:20<03:37,  2.17it/s]  6%|▌         | 29/500 [00:20<02:40,  2.93it/s]  6%|▌         | 31/500 [00:27<09:25,  1.20s/it]  7%|▋         | 33/500 [00:27<06:44,  1.16it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:37,  2.94it/s]  8%|▊         | 41/500 [00:34<09:05,  1.19s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:45,  1.59it/s]  9%|▉         | 47/500 [00:34<03:28,  2.17it/s] 10%|▉         | 49/500 [00:34<02:34,  2.92it/s] 10%|█         | 51/500 [00:41<09:06,  1.22s/it] 11%|█         | 53/500 [00:41<06:32,  1.14it/s] 11%|█         | 55/500 [00:41<04:43,  1.57it/s] 11%|█▏        | 57/500 [00:41<03:26,  2.15it/s] 12%|█▏        | 59/500 [00:41<02:32,  2.89it/s] 12%|█▏        | 61/500 [00:48<08:41,  1.19s/it] 13%|█▎        | 63/500 [00:48<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:24,  2.98it/s] 14%|█▍        | 71/500 [00:54<08:29,  1.19s/it] 15%|█▍        | 73/500 [00:55<06:06,  1.17it/s]Epoch:  1  	Training Loss: 0.2261407971382141
Test Loss:  6.386614799499512
Valid Loss:  6.20271635055542
Epoch:  2  	Training Loss: 6.549951553344727
Test Loss:  0.3191840350627899
Valid Loss:  0.3049441874027252
Epoch:  3  	Training Loss: 0.2490459382534027
Test Loss:  0.3187902867794037
Valid Loss:  0.30457186698913574
Epoch:  4  	Training Loss: 0.24871475994586945
Test Loss:  0.3183971643447876
Valid Loss:  0.3042001724243164
Epoch:  5  	Training Loss: 0.24838411808013916
Test Loss:  0.3180045783519745
Valid Loss:  0.30382898449897766
Epoch:  6  	Training Loss: 0.24805396795272827
Test Loss:  0.31761258840560913
Valid Loss:  0.3034583330154419
Epoch:  7  	Training Loss: 0.24772435426712036
Test Loss:  0.31722116470336914
Valid Loss:  0.3030882477760315
Epoch:  8  	Training Loss: 0.24739526212215424
Test Loss:  0.3170931041240692
Valid Loss:  0.3029813766479492
Epoch:  9  	Training Loss: 0.24726983904838562
Test Loss:  0.3170931041240692
Valid Loss:  0.3029814064502716
Epoch:  10  	Training Loss: 0.24726982414722443
Test Loss:  0.3170931041240692
Valid Loss:  0.3029813766479492
Epoch:  11  	Training Loss: 0.24726979434490204
Test Loss:  0.3170930743217468
Valid Loss:  0.30298131704330444
Epoch:  12  	Training Loss: 0.24726977944374084
Test Loss:  0.3170929551124573
Valid Loss:  0.30298125743865967
Epoch:  13  	Training Loss: 0.24726973474025726
Test Loss:  0.3170928955078125
Valid Loss:  0.3029811382293701
Epoch:  14  	Training Loss: 0.2472696602344513
Test Loss:  0.31709277629852295
Valid Loss:  0.30298104882240295
Epoch:  15  	Training Loss: 0.24726957082748413
Test Loss:  0.3170926868915558
Valid Loss:  0.3029809296131134
Epoch:  16  	Training Loss: 0.24726949632167816
Test Loss:  0.3170925974845886
Valid Loss:  0.30298084020614624
Epoch:  17  	Training Loss: 0.2472694218158722
Test Loss:  0.3170924782752991
Valid Loss:  0.30298078060150146
Epoch:  18  	Training Loss: 0.24726936221122742
Test Loss:  0.3170924186706543
Valid Loss:  0.3029806613922119
Epoch:  19  	Training Loss: 0.24726927280426025
Test Loss:  0.31709229946136475
Valid Loss:  0.30298054218292236
Epoch:  20  	Training Loss: 0.24726921319961548
Test Loss:  0.3170921802520752
Valid Loss:  0.3029804825782776
Epoch:  21  	Training Loss: 0.2472691386938095
Test Loss:  0.3170921206474304
Valid Loss:  0.30298033356666565
Epoch:  22  	Training Loss: 0.24726906418800354
Test Loss:  0.31709200143814087
Valid Loss:  0.3029802441596985
Epoch:  23  	Training Loss: 0.24726900458335876
Test Loss:  0.3170919120311737
Valid Loss:  0.3029801547527313
Epoch:  24  	Training Loss: 0.2472689151763916
Test Loss:  0.31709182262420654
Valid Loss:  0.30298006534576416
Epoch:  25  	Training Loss: 0.24726884067058563
Test Loss:  0.3170917332172394
Valid Loss:  0.302979975938797
Epoch:  26  	Training Loss: 0.24726879596710205
Test Loss:  0.31709161400794983
Valid Loss:  0.30297985672950745
Epoch:  27  	Training Loss: 0.2472686916589737
Test Loss:  0.31709152460098267
Valid Loss:  0.3029797673225403
Epoch:  28  	Training Loss: 0.2472686469554901
Test Loss:  0.3170914649963379
Valid Loss:  0.30297964811325073
Epoch:  29  	Training Loss: 0.24726855754852295
Test Loss:  0.31709134578704834
Valid Loss:  0.30297955870628357
Epoch:  30  	Training Loss: 0.24726849794387817
Test Loss:  0.3170912265777588
Valid Loss:  0.3029794692993164
Epoch:  31  	Training Loss: 0.247268408536911
Test Loss:  0.3170911371707916
Valid Loss:  0.30297935009002686
Epoch:  32  	Training Loss: 0.24726834893226624
Test Loss:  0.31709104776382446
Valid Loss:  0.3029792904853821
Epoch:  33  	Training Loss: 0.24726825952529907
Test Loss:  0.3170909881591797
Valid Loss:  0.30297917127609253
Epoch:  34  	Training Loss: 0.2472681999206543
Test Loss:  0.31709086894989014
Valid Loss:  0.302979052066803
Epoch:  35  	Training Loss: 0.24726812541484833
Test Loss:  0.3170907497406006
Valid Loss:  0.3029789626598358
Epoch:  36  	Training Loss: 0.24726805090904236
Test Loss:  0.3170906603336334
Valid Loss:  0.30297887325286865
Epoch:  37  	Training Loss: 0.24726799130439758
Test Loss:  0.31709057092666626
Valid Loss:  0.3029787540435791
Epoch:  38  	Training Loss: 0.24726790189743042
Test Loss:  0.3170904517173767
Valid Loss:  0.30297866463661194
Epoch:  39  	Training Loss: 0.24726782739162445
Test Loss:  0.31709039211273193
Valid Loss:  0.3029785752296448
Epoch:  40  	Training Loss: 0.24726776778697968
Test Loss:  0.31709030270576477
Valid Loss:  0.3029784858226776
Epoch:  41  	Training Loss: 0.2472676932811737
Test Loss:  0.3170901834964752
Valid Loss:  0.30297839641571045
Epoch:  42  	Training Loss: 0.24726763367652893
Test Loss:  0.31709009408950806
Valid Loss:  0.3029782772064209
Epoch:  43  	Training Loss: 0.24726755917072296
Test Loss:  0.3170900046825409
Valid Loss:  0.30297818779945374
Epoch:  44  	Training Loss: 0.2472674548625946
Test Loss:  0.31708991527557373
Valid Loss:  0.3029780685901642
Epoch:  45  	Training Loss: 0.24726741015911102
Test Loss:  0.3170897960662842
Valid Loss:  0.302977979183197
Epoch:  46  	Training Loss: 0.24726733565330505
Test Loss:  0.317089706659317
Valid Loss:  0.30297785997390747
Epoch:  47  	Training Loss: 0.24726726114749908
Test Loss:  0.31708961725234985
Valid Loss:  0.3029778003692627
Epoch:  48  	Training Loss: 0.24726717174053192
Test Loss:  0.3170894980430603
Valid Loss:  0.30297768115997314
Epoch:  49  	Training Loss: 0.24726712703704834
Test Loss:  0.3170894384384155
Valid Loss:  0.302977591753006
Epoch:  50  	Training Loss: 0.24726703763008118
Test Loss:  0.317089319229126
Valid Loss:  0.30297747254371643
Epoch:  51  	Training Loss: 0.2472669780254364
Test Loss:  0.3170892298221588
Valid Loss:  0.30297738313674927
Epoch:  52  	Training Loss: 0.24726690351963043
Test Loss:  0.31708914041519165
Valid Loss:  0.3029773235321045
Epoch:  53  	Training Loss: 0.24726682901382446
Test Loss:  0.3170890212059021
Valid Loss:  0.30297717452049255
Epoch:  54  	Training Loss: 0.2472667396068573
Test Loss:  0.31708890199661255
Valid Loss:  0.3029770851135254
Epoch:  55  	Training Loss: 0.24726668000221252
Test Loss:  0.3170888423919678
Valid Loss:  0.3029769957065582
Epoch:  56  	Training Loss: 0.24726660549640656
Test Loss:  0.3170887529850006
Valid Loss:  0.30297690629959106
Epoch:  57  	Training Loss: 0.24726654589176178
Test Loss:  0.31708863377571106
Valid Loss:  0.3029767870903015
Epoch:  58  	Training Loss: 0.24726645648479462
Test Loss:  0.3170885443687439
Valid Loss:  0.30297669768333435
Epoch:  59  	Training Loss: 0.24726639688014984
Test Loss:  0.3170884847640991
Valid Loss:  0.3029766082763672
Epoch:  60  	Training Loss: 0.24726629257202148
Test Loss:  0.31708836555480957
Valid Loss:  0.30297648906707764
Epoch:  61  	Training Loss: 0.2472662329673767
Test Loss:  0.31708824634552
Valid Loss:  0.3029763996601105
Epoch:  62  	Training Loss: 0.24726618826389313
Test Loss:  0.31708815693855286
Valid Loss:  0.3029763102531433
Epoch:  63  	Training Loss: 0.24726609885692596
Test Loss:  0.3170880973339081
Valid Loss:  0.30297619104385376
Epoch:  64  	Training Loss: 0.2472660094499588
Test Loss:  0.31708797812461853
Valid Loss:  0.3029761016368866
Epoch:  65  	Training Loss: 0.24726594984531403
Test Loss:  0.31708788871765137
Valid Loss:  0.30297601222991943
Epoch:  66  	Training Loss: 0.24726587533950806
Test Loss:  0.3170877695083618
Valid Loss:  0.3029758930206299
Epoch:  67  	Training Loss: 0.24726581573486328
Test Loss:  0.31708770990371704
Valid Loss:  0.3029758036136627
Epoch:  68  	Training Loss: 0.2472657412290573
Test Loss:  0.3170875906944275
Valid Loss:  0.30297571420669556
Epoch:  69  	Training Loss: 0.24726566672325134
Test Loss:  0.3170875012874603
Valid Loss:  0.302975594997406
Epoch:  70  	Training Loss: 0.24726559221744537
Test Loss:  0.31708741188049316
Valid Loss:  0.30297553539276123
Epoch:  71  	Training Loss: 0.2472655177116394
Test Loss:  0.3170872926712036
Valid Loss:  0.3029754161834717
Epoch:  72  	Training Loss: 0.24726542830467224
Test Loss:  0.31708723306655884
Valid Loss:  0.3029753267765045
Epoch:  73  	Training Loss: 0.24726536870002747
Test Loss:  0.3170871138572693
Valid Loss:  0.3029751777648926
Epoch:  74  	Training Loss: 0.2472653090953827
Test Loss:   15%|█▌        | 75/500 [00:55<04:25,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:16,  2.15it/s] 16%|█▌        | 79/500 [00:55<02:28,  2.84it/s] 16%|█▌        | 81/500 [01:02<08:30,  1.22s/it] 17%|█▋        | 83/500 [01:02<06:06,  1.14it/s] 17%|█▋        | 85/500 [01:02<04:25,  1.56it/s] 17%|█▋        | 87/500 [01:02<03:15,  2.11it/s] 18%|█▊        | 89/500 [01:02<02:26,  2.80it/s] 18%|█▊        | 91/500 [01:09<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:09<05:49,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:09<03:03,  2.20it/s] 20%|█▉        | 99/500 [01:09<02:15,  2.96it/s] 20%|██        | 101/500 [01:15<07:53,  1.19s/it] 21%|██        | 103/500 [01:16<05:38,  1.17it/s] 21%|██        | 105/500 [01:16<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:16<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.96it/s] 22%|██▏       | 111/500 [01:22<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:23<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:23<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:23<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:29<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:29<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:30<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:30<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:36<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:36<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:36<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:36<02:43,  2.21it/s] 28%|██▊       | 139/500 [01:37<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:43<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:43<05:01,  1.19it/s] 29%|██▉       | 145/500 [01:43<03:36,  1.64it/s]0.31708699464797974
Valid Loss:  0.3029751181602478
Epoch:  75  	Training Loss: 0.24726523458957672
Test Loss:  0.3170869052410126
Valid Loss:  0.30297502875328064
Epoch:  76  	Training Loss: 0.24726517498493195
Test Loss:  0.3170868158340454
Valid Loss:  0.3029749393463135
Epoch:  77  	Training Loss: 0.2472650706768036
Test Loss:  0.31708675622940063
Valid Loss:  0.3029748201370239
Epoch:  78  	Training Loss: 0.2472650110721588
Test Loss:  0.3170866370201111
Valid Loss:  0.3029747009277344
Epoch:  79  	Training Loss: 0.24726495146751404
Test Loss:  0.31708651781082153
Valid Loss:  0.3029746115207672
Epoch:  80  	Training Loss: 0.24726486206054688
Test Loss:  0.31708645820617676
Valid Loss:  0.30297452211380005
Epoch:  81  	Training Loss: 0.2472647875547409
Test Loss:  0.3170863389968872
Valid Loss:  0.3029744029045105
Epoch:  82  	Training Loss: 0.24726472795009613
Test Loss:  0.31708627939224243
Valid Loss:  0.3029743432998657
Epoch:  83  	Training Loss: 0.24726465344429016
Test Loss:  0.3170861601829529
Valid Loss:  0.30297422409057617
Epoch:  84  	Training Loss: 0.2472645789384842
Test Loss:  0.31708604097366333
Valid Loss:  0.302974134683609
Epoch:  85  	Training Loss: 0.24726450443267822
Test Loss:  0.31708598136901855
Valid Loss:  0.30297404527664185
Epoch:  86  	Training Loss: 0.24726442992687225
Test Loss:  0.317085862159729
Valid Loss:  0.3029739260673523
Epoch:  87  	Training Loss: 0.24726435542106628
Test Loss:  0.31708577275276184
Valid Loss:  0.30297380685806274
Epoch:  88  	Training Loss: 0.24726428091526031
Test Loss:  0.3170856833457947
Valid Loss:  0.30297374725341797
Epoch:  89  	Training Loss: 0.24726422131061554
Test Loss:  0.3170855641365051
Valid Loss:  0.3029736280441284
Epoch:  90  	Training Loss: 0.24726414680480957
Test Loss:  0.31708547472953796
Valid Loss:  0.30297353863716125
Epoch:  91  	Training Loss: 0.2472640722990036
Test Loss:  0.3170853853225708
Valid Loss:  0.3029734194278717
Epoch:  92  	Training Loss: 0.24726399779319763
Test Loss:  0.31708529591560364
Valid Loss:  0.30297333002090454
Epoch:  93  	Training Loss: 0.24726392328739166
Test Loss:  0.3170852065086365
Valid Loss:  0.3029732406139374
Epoch:  94  	Training Loss: 0.2472638487815857
Test Loss:  0.3170850872993469
Valid Loss:  0.3029731512069702
Epoch:  95  	Training Loss: 0.24726378917694092
Test Loss:  0.31708499789237976
Valid Loss:  0.30297303199768066
Epoch:  96  	Training Loss: 0.24726371467113495
Test Loss:  0.3170849084854126
Valid Loss:  0.3029729127883911
Epoch:  97  	Training Loss: 0.24726364016532898
Test Loss:  0.31708478927612305
Valid Loss:  0.30297285318374634
Epoch:  98  	Training Loss: 0.247263565659523
Test Loss:  0.31708472967147827
Valid Loss:  0.3029727339744568
Epoch:  99  	Training Loss: 0.24726349115371704
Test Loss:  0.3170846104621887
Valid Loss:  0.3029726445674896
Epoch:  100  	Training Loss: 0.24726341664791107
Test Loss:  0.31708455085754395
Valid Loss:  0.30297255516052246
Epoch:  101  	Training Loss: 0.2472633421421051
Test Loss:  0.3170844316482544
Valid Loss:  0.3029724359512329
Epoch:  102  	Training Loss: 0.24726328253746033
Test Loss:  0.31708434224128723
Valid Loss:  0.30297234654426575
Epoch:  103  	Training Loss: 0.24726319313049316
Test Loss:  0.31708425283432007
Valid Loss:  0.3029722571372986
Epoch:  104  	Training Loss: 0.2472631186246872
Test Loss:  0.3170841336250305
Valid Loss:  0.30297213792800903
Epoch:  105  	Training Loss: 0.24726305902004242
Test Loss:  0.31708404421806335
Valid Loss:  0.30297204852104187
Epoch:  106  	Training Loss: 0.24726296961307526
Test Loss:  0.3170839548110962
Valid Loss:  0.3029719591140747
Epoch:  107  	Training Loss: 0.24726291000843048
Test Loss:  0.31708383560180664
Valid Loss:  0.30297183990478516
Epoch:  108  	Training Loss: 0.2472628355026245
Test Loss:  0.3170837461948395
Valid Loss:  0.302971750497818
Epoch:  109  	Training Loss: 0.24726276099681854
Test Loss:  0.3170836567878723
Valid Loss:  0.30297166109085083
Epoch:  110  	Training Loss: 0.24726268649101257
Test Loss:  0.31708359718322754
Valid Loss:  0.3029715418815613
Epoch:  111  	Training Loss: 0.2472626268863678
Test Loss:  0.317083477973938
Valid Loss:  0.3029714822769165
Epoch:  112  	Training Loss: 0.24726253747940063
Test Loss:  0.31708335876464844
Valid Loss:  0.30297136306762695
Epoch:  113  	Training Loss: 0.24726249277591705
Test Loss:  0.3170832693576813
Valid Loss:  0.3029712736606598
Epoch:  114  	Training Loss: 0.2472624033689499
Test Loss:  0.3170831799507141
Valid Loss:  0.3029711842536926
Epoch:  115  	Training Loss: 0.24726232886314392
Test Loss:  0.31708306074142456
Valid Loss:  0.3029710650444031
Epoch:  116  	Training Loss: 0.24726226925849915
Test Loss:  0.3170830011367798
Valid Loss:  0.3029709756374359
Epoch:  117  	Training Loss: 0.24726217985153198
Test Loss:  0.3170829117298126
Valid Loss:  0.30297088623046875
Epoch:  118  	Training Loss: 0.2472621202468872
Test Loss:  0.31708282232284546
Valid Loss:  0.3029707670211792
Epoch:  119  	Training Loss: 0.24726204574108124
Test Loss:  0.3170827031135559
Valid Loss:  0.30297067761421204
Epoch:  120  	Training Loss: 0.24726197123527527
Test Loss:  0.31708264350891113
Valid Loss:  0.3029705882072449
Epoch:  121  	Training Loss: 0.2472618967294693
Test Loss:  0.3170824944972992
Valid Loss:  0.3029704689979553
Epoch:  122  	Training Loss: 0.24726183712482452
Test Loss:  0.31708240509033203
Valid Loss:  0.30297037959098816
Epoch:  123  	Training Loss: 0.24726176261901855
Test Loss:  0.31708234548568726
Valid Loss:  0.302970290184021
Epoch:  124  	Training Loss: 0.2472616732120514
Test Loss:  0.3170822262763977
Valid Loss:  0.30297017097473145
Epoch:  125  	Training Loss: 0.24726159870624542
Test Loss:  0.31708213686943054
Valid Loss:  0.3029700815677643
Epoch:  126  	Training Loss: 0.24726153910160065
Test Loss:  0.317082017660141
Valid Loss:  0.30296996235847473
Epoch:  127  	Training Loss: 0.24726146459579468
Test Loss:  0.31708192825317383
Valid Loss:  0.30296987295150757
Epoch:  128  	Training Loss: 0.2472613900899887
Test Loss:  0.3170818090438843
Valid Loss:  0.3029697835445404
Epoch:  129  	Training Loss: 0.24726131558418274
Test Loss:  0.3170817494392395
Valid Loss:  0.30296969413757324
Epoch:  130  	Training Loss: 0.24726125597953796
Test Loss:  0.31708166003227234
Valid Loss:  0.3029695749282837
Epoch:  131  	Training Loss: 0.2472611665725708
Test Loss:  0.3170815408229828
Valid Loss:  0.30296948552131653
Epoch:  132  	Training Loss: 0.24726109206676483
Test Loss:  0.3170814514160156
Valid Loss:  0.30296939611434937
Epoch:  133  	Training Loss: 0.24726103246212006
Test Loss:  0.31708139181137085
Valid Loss:  0.3029692769050598
Epoch:  134  	Training Loss: 0.2472609579563141
Test Loss:  0.3170812726020813
Valid Loss:  0.30296918749809265
Epoch:  135  	Training Loss: 0.24726088345050812
Test Loss:  0.31708115339279175
Valid Loss:  0.3029690980911255
Epoch:  136  	Training Loss: 0.24726080894470215
Test Loss:  0.317081093788147
Valid Loss:  0.3029690086841583
Epoch:  137  	Training Loss: 0.24726073443889618
Test Loss:  0.3170809745788574
Valid Loss:  0.3029688894748688
Epoch:  138  	Training Loss: 0.2472606599330902
Test Loss:  0.31708085536956787
Valid Loss:  0.3029688000679016
Epoch:  139  	Training Loss: 0.24726060032844543
Test Loss:  0.3170807957649231
Valid Loss:  0.30296868085861206
Epoch:  140  	Training Loss: 0.24726052582263947
Test Loss:  0.31708067655563354
Valid Loss:  0.3029686212539673
Epoch:  141  	Training Loss: 0.2472604513168335
Test Loss:  0.3170805871486664
Valid Loss:  0.30296850204467773
Epoch:  142  	Training Loss: 0.24726037681102753
Test Loss:  0.3170804977416992
Valid Loss:  0.3029683828353882
Epoch:  143  	Training Loss: 0.24726030230522156
Test Loss:  0.31708037853240967
Valid Loss:  0.302968293428421
Epoch:  144  	Training Loss: 0.2472602128982544
Test Loss:  0.3170803189277649
Valid Loss:  0.30296820402145386
Epoch:  145  	Training Loss: 0.24726015329360962
Test Loss:  0.31708019971847534
Valid Loss:  0.3029680848121643
Epoch:  146  	Training Loss: 0.24726007878780365
Test Loss:  0.3170801103115082
Valid Loss:  0.30296802520751953
Epoch:  147  	Training Loss: 0.24726000428199768
Test Loss:   29%|██▉       | 147/500 [01:43<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:43<01:56,  3.01it/s] 30%|███       | 151/500 [01:50<06:55,  1.19s/it] 31%|███       | 153/500 [01:50<04:56,  1.17it/s] 31%|███       | 155/500 [01:50<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:50<02:34,  2.21it/s] 32%|███▏      | 159/500 [01:50<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:57<06:49,  1.21s/it] 33%|███▎      | 163/500 [01:57<04:54,  1.14it/s] 33%|███▎      | 165/500 [01:57<03:32,  1.58it/s] 33%|███▎      | 167/500 [01:57<02:33,  2.16it/s] 34%|███▍      | 169/500 [01:57<01:53,  2.91it/s] 34%|███▍      | 171/500 [02:04<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:04<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:04<03:18,  1.63it/s] 35%|███▌      | 177/500 [02:04<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:04<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:11<06:29,  1.22s/it] 37%|███▋      | 183/500 [02:11<04:37,  1.14it/s] 37%|███▋      | 185/500 [02:11<03:19,  1.58it/s] 37%|███▋      | 187/500 [02:11<02:24,  2.16it/s] 38%|███▊      | 189/500 [02:11<01:47,  2.91it/s] 38%|███▊      | 191/500 [02:18<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:18<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:18<01:42,  2.95it/s] 40%|████      | 201/500 [02:25<05:55,  1.19s/it] 41%|████      | 203/500 [02:25<04:14,  1.17it/s] 41%|████      | 205/500 [02:25<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:25<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:25<01:38,  2.94it/s] 42%|████▏     | 211/500 [02:31<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:32<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:32<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:32<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:32<01:33,  2.99it/s]0.317080020904541
Valid Loss:  0.30296790599823
Epoch:  148  	Training Loss: 0.2472599446773529
Test Loss:  0.31707993149757385
Valid Loss:  0.3029678165912628
Epoch:  149  	Training Loss: 0.24725987017154694
Test Loss:  0.3170798122882843
Valid Loss:  0.30296772718429565
Epoch:  150  	Training Loss: 0.24725978076457977
Test Loss:  0.31707972288131714
Valid Loss:  0.3029676079750061
Epoch:  151  	Training Loss: 0.2472597360610962
Test Loss:  0.31707963347435
Valid Loss:  0.30296748876571655
Epoch:  152  	Training Loss: 0.24725964665412903
Test Loss:  0.3170795440673828
Valid Loss:  0.3029674291610718
Epoch:  153  	Training Loss: 0.24725957214832306
Test Loss:  0.31707945466041565
Valid Loss:  0.3029673099517822
Epoch:  154  	Training Loss: 0.2472594976425171
Test Loss:  0.3170793652534485
Valid Loss:  0.3029671907424927
Epoch:  155  	Training Loss: 0.24725943803787231
Test Loss:  0.31707924604415894
Valid Loss:  0.3029671311378479
Epoch:  156  	Training Loss: 0.24725936353206635
Test Loss:  0.3170791566371918
Valid Loss:  0.30296701192855835
Epoch:  157  	Training Loss: 0.24725928902626038
Test Loss:  0.3170790672302246
Valid Loss:  0.3029668927192688
Epoch:  158  	Training Loss: 0.2472592294216156
Test Loss:  0.31707894802093506
Valid Loss:  0.30296680331230164
Epoch:  159  	Training Loss: 0.24725914001464844
Test Loss:  0.3170788586139679
Valid Loss:  0.30296674370765686
Epoch:  160  	Training Loss: 0.24725908041000366
Test Loss:  0.31707876920700073
Valid Loss:  0.3029665946960449
Epoch:  161  	Training Loss: 0.2472589910030365
Test Loss:  0.31707867980003357
Valid Loss:  0.30296653509140015
Epoch:  162  	Training Loss: 0.24725893139839172
Test Loss:  0.3170785903930664
Valid Loss:  0.3029664158821106
Epoch:  163  	Training Loss: 0.24725885689258575
Test Loss:  0.31707847118377686
Valid Loss:  0.30296632647514343
Epoch:  164  	Training Loss: 0.24725878238677979
Test Loss:  0.3170784115791321
Valid Loss:  0.3029662072658539
Epoch:  165  	Training Loss: 0.24725869297981262
Test Loss:  0.31707829236984253
Valid Loss:  0.3029661476612091
Epoch:  166  	Training Loss: 0.24725863337516785
Test Loss:  0.31707820296287537
Valid Loss:  0.30296602845191956
Epoch:  167  	Training Loss: 0.24725855886936188
Test Loss:  0.3170780837535858
Valid Loss:  0.3029659390449524
Epoch:  168  	Training Loss: 0.2472584992647171
Test Loss:  0.31707799434661865
Valid Loss:  0.30296584963798523
Epoch:  169  	Training Loss: 0.24725842475891113
Test Loss:  0.3170779049396515
Valid Loss:  0.3029657304286957
Epoch:  170  	Training Loss: 0.24725835025310516
Test Loss:  0.3170778155326843
Valid Loss:  0.3029656410217285
Epoch:  171  	Training Loss: 0.2472582757472992
Test Loss:  0.3170776963233948
Valid Loss:  0.30296552181243896
Epoch:  172  	Training Loss: 0.24725820124149323
Test Loss:  0.3170776069164276
Valid Loss:  0.3029654324054718
Epoch:  173  	Training Loss: 0.24725812673568726
Test Loss:  0.31707751750946045
Valid Loss:  0.30296534299850464
Epoch:  174  	Training Loss: 0.24725806713104248
Test Loss:  0.3170774281024933
Valid Loss:  0.3029652237892151
Epoch:  175  	Training Loss: 0.2472579926252365
Test Loss:  0.3170773386955261
Valid Loss:  0.3029651641845703
Epoch:  176  	Training Loss: 0.24725791811943054
Test Loss:  0.3170772194862366
Valid Loss:  0.30296504497528076
Epoch:  177  	Training Loss: 0.24725784361362457
Test Loss:  0.3170771598815918
Valid Loss:  0.3029649257659912
Epoch:  178  	Training Loss: 0.2472577691078186
Test Loss:  0.31707704067230225
Valid Loss:  0.30296486616134644
Epoch:  179  	Training Loss: 0.24725769460201263
Test Loss:  0.3170769512653351
Valid Loss:  0.3029647469520569
Epoch:  180  	Training Loss: 0.24725762009620667
Test Loss:  0.3170768618583679
Valid Loss:  0.30296462774276733
Epoch:  181  	Training Loss: 0.2472575604915619
Test Loss:  0.31707674264907837
Valid Loss:  0.30296456813812256
Epoch:  182  	Training Loss: 0.24725747108459473
Test Loss:  0.3170766830444336
Valid Loss:  0.302964448928833
Epoch:  183  	Training Loss: 0.24725741147994995
Test Loss:  0.31707656383514404
Valid Loss:  0.30296435952186584
Epoch:  184  	Training Loss: 0.24725733697414398
Test Loss:  0.3170764446258545
Valid Loss:  0.3029642701148987
Epoch:  185  	Training Loss: 0.247257262468338
Test Loss:  0.3170763850212097
Valid Loss:  0.3029641807079315
Epoch:  186  	Training Loss: 0.24725717306137085
Test Loss:  0.31707626581192017
Valid Loss:  0.30296406149864197
Epoch:  187  	Training Loss: 0.24725711345672607
Test Loss:  0.3170762062072754
Valid Loss:  0.3029639720916748
Epoch:  188  	Training Loss: 0.2472570538520813
Test Loss:  0.31707608699798584
Valid Loss:  0.30296385288238525
Epoch:  189  	Training Loss: 0.24725696444511414
Test Loss:  0.3170759677886963
Valid Loss:  0.3029637634754181
Epoch:  190  	Training Loss: 0.24725690484046936
Test Loss:  0.3170758783817291
Valid Loss:  0.3029636740684509
Epoch:  191  	Training Loss: 0.24725684523582458
Test Loss:  0.31707578897476196
Valid Loss:  0.3029635548591614
Epoch:  192  	Training Loss: 0.24725675582885742
Test Loss:  0.3170756995677948
Valid Loss:  0.3029634356498718
Epoch:  193  	Training Loss: 0.24725666642189026
Test Loss:  0.31707561016082764
Valid Loss:  0.30296337604522705
Epoch:  194  	Training Loss: 0.24725662171840668
Test Loss:  0.3170755207538605
Valid Loss:  0.3029632568359375
Epoch:  195  	Training Loss: 0.24725653231143951
Test Loss:  0.3170754313468933
Valid Loss:  0.30296316742897034
Epoch:  196  	Training Loss: 0.24725645780563354
Test Loss:  0.31707531213760376
Valid Loss:  0.3029630780220032
Epoch:  197  	Training Loss: 0.24725639820098877
Test Loss:  0.3170751929283142
Valid Loss:  0.302962988615036
Epoch:  198  	Training Loss: 0.2472563236951828
Test Loss:  0.31707513332366943
Valid Loss:  0.3029628396034241
Epoch:  199  	Training Loss: 0.24725624918937683
Test Loss:  0.31707504391670227
Valid Loss:  0.3029627799987793
Epoch:  200  	Training Loss: 0.24725617468357086
Test Loss:  0.3170749247074127
Valid Loss:  0.30296266078948975
Epoch:  201  	Training Loss: 0.2472561001777649
Test Loss:  0.31707483530044556
Valid Loss:  0.3029625713825226
Epoch:  202  	Training Loss: 0.24725604057312012
Test Loss:  0.317074716091156
Valid Loss:  0.3029624819755554
Epoch:  203  	Training Loss: 0.24725595116615295
Test Loss:  0.31707465648651123
Valid Loss:  0.30296236276626587
Epoch:  204  	Training Loss: 0.24725589156150818
Test Loss:  0.3170745372772217
Valid Loss:  0.3029622733592987
Epoch:  205  	Training Loss: 0.2472558170557022
Test Loss:  0.3170744478702545
Valid Loss:  0.30296218395233154
Epoch:  206  	Training Loss: 0.24725574254989624
Test Loss:  0.31707435846328735
Valid Loss:  0.302962064743042
Epoch:  207  	Training Loss: 0.24725565314292908
Test Loss:  0.3170742392539978
Valid Loss:  0.30296197533607483
Epoch:  208  	Training Loss: 0.2472555786371231
Test Loss:  0.317074179649353
Valid Loss:  0.30296188592910767
Epoch:  209  	Training Loss: 0.24725553393363953
Test Loss:  0.3170740604400635
Valid Loss:  0.3029617965221405
Epoch:  210  	Training Loss: 0.24725545942783356
Test Loss:  0.3170739710330963
Valid Loss:  0.30296170711517334
Epoch:  211  	Training Loss: 0.2472553849220276
Test Loss:  0.31707388162612915
Valid Loss:  0.3029615879058838
Epoch:  212  	Training Loss: 0.24725529551506042
Test Loss:  0.317073792219162
Valid Loss:  0.30296146869659424
Epoch:  213  	Training Loss: 0.24725523591041565
Test Loss:  0.3170737028121948
Valid Loss:  0.30296140909194946
Epoch:  214  	Training Loss: 0.24725516140460968
Test Loss:  0.3170735836029053
Valid Loss:  0.3029612898826599
Epoch:  215  	Training Loss: 0.2472550868988037
Test Loss:  0.3170734941959381
Valid Loss:  0.30296117067337036
Epoch:  216  	Training Loss: 0.24725502729415894
Test Loss:  0.31707340478897095
Valid Loss:  0.3029611110687256
Epoch:  217  	Training Loss: 0.24725495278835297
Test Loss:  0.3170732855796814
Valid Loss:  0.30296099185943604
Epoch:  218  	Training Loss: 0.247254878282547
Test Loss:  0.3170732259750366
Valid Loss:  0.3029608726501465
Epoch:  219  	Training Loss: 0.24725481867790222
Test Loss:  0.31707310676574707
Valid Loss:  0.3029608130455017
Epoch:  220  	Training Loss: 0.24725471436977386
 44%|████▍     | 221/500 [02:38<05:36,  1.20s/it] 45%|████▍     | 223/500 [02:39<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:39<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:39<02:04,  2.18it/s] 46%|████▌     | 229/500 [02:39<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:45<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:45<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:46<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:46<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:52<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:52<03:42,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:40,  1.58it/s] 49%|████▉     | 247/500 [02:53<01:58,  2.14it/s] 50%|████▉     | 249/500 [02:53<01:28,  2.84it/s] 50%|█████     | 251/500 [02:59<04:55,  1.19s/it] 51%|█████     | 253/500 [02:59<03:30,  1.17it/s] 51%|█████     | 255/500 [03:00<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:00<01:49,  2.21it/s] 52%|█████▏    | 259/500 [03:00<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:06<04:49,  1.21s/it] 53%|█████▎    | 263/500 [03:06<03:25,  1.15it/s] 53%|█████▎    | 265/500 [03:07<02:27,  1.59it/s] 53%|█████▎    | 267/500 [03:07<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:07<01:18,  2.93it/s] 54%|█████▍    | 271/500 [03:13<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:13<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:13<02:19,  1.62it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.21it/s] 56%|█████▌    | 279/500 [03:14<01:14,  2.97it/s] 56%|█████▌    | 281/500 [03:20<04:22,  1.20s/it] 57%|█████▋    | 283/500 [03:20<03:08,  1.15it/s] 57%|█████▋    | 285/500 [03:20<02:16,  1.58it/s] 57%|█████▋    | 287/500 [03:21<01:40,  2.13it/s] 58%|█████▊    | 289/500 [03:21<01:15,  2.81it/s] 58%|█████▊    | 291/500 [03:27<04:18,  1.24s/it]Test Loss:  0.3170730173587799
Valid Loss:  0.30296069383621216
Epoch:  221  	Training Loss: 0.2472546547651291
Test Loss:  0.31707292795181274
Valid Loss:  0.302960604429245
Epoch:  222  	Training Loss: 0.24725458025932312
Test Loss:  0.3170728385448456
Valid Loss:  0.30296048521995544
Epoch:  223  	Training Loss: 0.24725450575351715
Test Loss:  0.31707271933555603
Valid Loss:  0.3029603958129883
Epoch:  224  	Training Loss: 0.24725443124771118
Test Loss:  0.31707262992858887
Valid Loss:  0.3029603064060211
Epoch:  225  	Training Loss: 0.2472543567419052
Test Loss:  0.3170725405216217
Valid Loss:  0.30296018719673157
Epoch:  226  	Training Loss: 0.24725428223609924
Test Loss:  0.31707245111465454
Valid Loss:  0.3029600977897644
Epoch:  227  	Training Loss: 0.24725422263145447
Test Loss:  0.317072331905365
Valid Loss:  0.30296000838279724
Epoch:  228  	Training Loss: 0.2472541332244873
Test Loss:  0.3170722424983978
Valid Loss:  0.3029598891735077
Epoch:  229  	Training Loss: 0.24725407361984253
Test Loss:  0.31707215309143066
Valid Loss:  0.3029597997665405
Epoch:  230  	Training Loss: 0.24725398421287537
Test Loss:  0.3170720338821411
Valid Loss:  0.30295971035957336
Epoch:  231  	Training Loss: 0.2472539246082306
Test Loss:  0.31707197427749634
Valid Loss:  0.3029596209526062
Epoch:  232  	Training Loss: 0.24725386500358582
Test Loss:  0.3170718550682068
Valid Loss:  0.30295953154563904
Epoch:  233  	Training Loss: 0.24725377559661865
Test Loss:  0.31707173585891724
Valid Loss:  0.3029594123363495
Epoch:  234  	Training Loss: 0.24725371599197388
Test Loss:  0.31707167625427246
Valid Loss:  0.3029593229293823
Epoch:  235  	Training Loss: 0.2472536414861679
Test Loss:  0.3170715570449829
Valid Loss:  0.3029592037200928
Epoch:  236  	Training Loss: 0.24725356698036194
Test Loss:  0.31707149744033813
Valid Loss:  0.302959144115448
Epoch:  237  	Training Loss: 0.24725349247455597
Test Loss:  0.3170713782310486
Valid Loss:  0.30295902490615845
Epoch:  238  	Training Loss: 0.24725341796875
Test Loss:  0.3170712888240814
Valid Loss:  0.3029589056968689
Epoch:  239  	Training Loss: 0.24725334346294403
Test Loss:  0.31707119941711426
Valid Loss:  0.30295881628990173
Epoch:  240  	Training Loss: 0.24725328385829926
Test Loss:  0.3170711100101471
Valid Loss:  0.30295872688293457
Epoch:  241  	Training Loss: 0.2472532093524933
Test Loss:  0.31707102060317993
Valid Loss:  0.302958607673645
Epoch:  242  	Training Loss: 0.24725313484668732
Test Loss:  0.3170709013938904
Valid Loss:  0.30295851826667786
Epoch:  243  	Training Loss: 0.24725306034088135
Test Loss:  0.3170708119869232
Valid Loss:  0.3029584288597107
Epoch:  244  	Training Loss: 0.24725297093391418
Test Loss:  0.31707072257995605
Valid Loss:  0.30295830965042114
Epoch:  245  	Training Loss: 0.2472529113292694
Test Loss:  0.3170706033706665
Valid Loss:  0.302958220243454
Epoch:  246  	Training Loss: 0.24725283682346344
Test Loss:  0.31707051396369934
Valid Loss:  0.3029581308364868
Epoch:  247  	Training Loss: 0.24725274741649628
Test Loss:  0.3170704245567322
Valid Loss:  0.30295801162719727
Epoch:  248  	Training Loss: 0.2472527027130127
Test Loss:  0.317070335149765
Valid Loss:  0.3029579222202301
Epoch:  249  	Training Loss: 0.24725264310836792
Test Loss:  0.31707024574279785
Valid Loss:  0.30295783281326294
Epoch:  250  	Training Loss: 0.24725255370140076
Test Loss:  0.3170701265335083
Valid Loss:  0.3029577136039734
Epoch:  251  	Training Loss: 0.2472524791955948
Test Loss:  0.31707000732421875
Valid Loss:  0.3029576241970062
Epoch:  252  	Training Loss: 0.24725240468978882
Test Loss:  0.317069947719574
Valid Loss:  0.30295753479003906
Epoch:  253  	Training Loss: 0.24725234508514404
Test Loss:  0.3170698285102844
Valid Loss:  0.3029574453830719
Epoch:  254  	Training Loss: 0.24725225567817688
Test Loss:  0.31706976890563965
Valid Loss:  0.30295735597610474
Epoch:  255  	Training Loss: 0.2472521960735321
Test Loss:  0.3170696496963501
Valid Loss:  0.3029572367668152
Epoch:  256  	Training Loss: 0.24725212156772614
Test Loss:  0.31706956028938293
Valid Loss:  0.30295711755752563
Epoch:  257  	Training Loss: 0.24725204706192017
Test Loss:  0.31706947088241577
Valid Loss:  0.30295705795288086
Epoch:  258  	Training Loss: 0.247251957654953
Test Loss:  0.3170693516731262
Valid Loss:  0.3029569387435913
Epoch:  259  	Training Loss: 0.24725189805030823
Test Loss:  0.31706926226615906
Valid Loss:  0.30295687913894653
Epoch:  260  	Training Loss: 0.24725182354450226
Test Loss:  0.3170691728591919
Valid Loss:  0.302956759929657
Epoch:  261  	Training Loss: 0.24725176393985748
Test Loss:  0.31706908345222473
Valid Loss:  0.30295664072036743
Epoch:  262  	Training Loss: 0.24725167453289032
Test Loss:  0.31706899404525757
Valid Loss:  0.3029565215110779
Epoch:  263  	Training Loss: 0.24725161492824554
Test Loss:  0.3170689046382904
Valid Loss:  0.3029564321041107
Epoch:  264  	Training Loss: 0.24725155532360077
Test Loss:  0.31706878542900085
Valid Loss:  0.30295634269714355
Epoch:  265  	Training Loss: 0.2472514510154724
Test Loss:  0.3170686960220337
Valid Loss:  0.302956223487854
Epoch:  266  	Training Loss: 0.24725139141082764
Test Loss:  0.31706857681274414
Valid Loss:  0.30295613408088684
Epoch:  267  	Training Loss: 0.24725133180618286
Test Loss:  0.317068487405777
Valid Loss:  0.3029560446739197
Epoch:  268  	Training Loss: 0.24725127220153809
Test Loss:  0.3170683979988098
Valid Loss:  0.3029559552669525
Epoch:  269  	Training Loss: 0.24725118279457092
Test Loss:  0.31706830859184265
Valid Loss:  0.30295586585998535
Epoch:  270  	Training Loss: 0.24725110828876495
Test Loss:  0.3170682191848755
Valid Loss:  0.3029557466506958
Epoch:  271  	Training Loss: 0.24725103378295898
Test Loss:  0.31706809997558594
Valid Loss:  0.302955687046051
Epoch:  272  	Training Loss: 0.24725095927715302
Test Loss:  0.31706804037094116
Valid Loss:  0.3029555678367615
Epoch:  273  	Training Loss: 0.24725088477134705
Test Loss:  0.3170679211616516
Valid Loss:  0.3029554486274719
Epoch:  274  	Training Loss: 0.24725082516670227
Test Loss:  0.31706783175468445
Valid Loss:  0.30295538902282715
Epoch:  275  	Training Loss: 0.2472507357597351
Test Loss:  0.3170677423477173
Valid Loss:  0.3029552698135376
Epoch:  276  	Training Loss: 0.24725066125392914
Test Loss:  0.31706762313842773
Valid Loss:  0.30295515060424805
Epoch:  277  	Training Loss: 0.24725058674812317
Test Loss:  0.31706753373146057
Valid Loss:  0.30295509099960327
Epoch:  278  	Training Loss: 0.2472505271434784
Test Loss:  0.3170674443244934
Valid Loss:  0.3029549717903137
Epoch:  279  	Training Loss: 0.24725045263767242
Test Loss:  0.31706735491752625
Valid Loss:  0.30295488238334656
Epoch:  280  	Training Loss: 0.24725037813186646
Test Loss:  0.3170672655105591
Valid Loss:  0.302954763174057
Epoch:  281  	Training Loss: 0.24725031852722168
Test Loss:  0.3170671761035919
Valid Loss:  0.30295467376708984
Epoch:  282  	Training Loss: 0.24725022912025452
Test Loss:  0.31706708669662476
Valid Loss:  0.3029545545578003
Epoch:  283  	Training Loss: 0.24725016951560974
Test Loss:  0.3170669674873352
Valid Loss:  0.3029544949531555
Epoch:  284  	Training Loss: 0.24725008010864258
Test Loss:  0.31706687808036804
Valid Loss:  0.30295437574386597
Epoch:  285  	Training Loss: 0.2472500205039978
Test Loss:  0.3170667886734009
Valid Loss:  0.3029542863368988
Epoch:  286  	Training Loss: 0.24724994599819183
Test Loss:  0.31706666946411133
Valid Loss:  0.30295419692993164
Epoch:  287  	Training Loss: 0.24724987149238586
Test Loss:  0.31706660985946655
Valid Loss:  0.3029540777206421
Epoch:  288  	Training Loss: 0.2472497969865799
Test Loss:  0.317066490650177
Valid Loss:  0.30295395851135254
Epoch:  289  	Training Loss: 0.24724972248077393
Test Loss:  0.31706637144088745
Valid Loss:  0.30295389890670776
Epoch:  290  	Training Loss: 0.24724964797496796
Test Loss:  0.3170663118362427
Valid Loss:  0.3029537796974182
Epoch:  291  	Training Loss: 0.247249573469162
Test Loss:  0.3170661926269531
Valid Loss:  0.30295372009277344
Epoch:  292  	Training Loss: 0.2472495138645172
Test Loss:  0.31706610321998596
Valid Loss:  0.3029535710811615
 59%|█████▊    | 293/500 [03:28<03:03,  1.13it/s] 59%|█████▉    | 295/500 [03:28<02:11,  1.56it/s] 59%|█████▉    | 297/500 [03:28<01:35,  2.13it/s] 60%|█████▉    | 299/500 [03:28<01:09,  2.87it/s] 60%|██████    | 301/500 [03:34<04:00,  1.21s/it] 61%|██████    | 303/500 [03:35<02:51,  1.15it/s] 61%|██████    | 305/500 [03:35<02:02,  1.59it/s] 61%|██████▏   | 307/500 [03:35<01:28,  2.17it/s] 62%|██████▏   | 309/500 [03:35<01:05,  2.92it/s] 62%|██████▏   | 311/500 [03:41<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:41<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:42<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:42<01:24,  2.17it/s] 64%|██████▍   | 319/500 [03:42<01:01,  2.92it/s] 64%|██████▍   | 321/500 [03:48<03:36,  1.21s/it] 65%|██████▍   | 323/500 [03:49<02:34,  1.14it/s] 65%|██████▌   | 325/500 [03:49<01:51,  1.57it/s] 65%|██████▌   | 327/500 [03:49<01:21,  2.12it/s] 66%|██████▌   | 329/500 [03:49<01:00,  2.81it/s] 66%|██████▌   | 331/500 [03:55<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:56<02:24,  1.16it/s] 67%|██████▋   | 335/500 [03:56<01:43,  1.60it/s] 67%|██████▋   | 337/500 [03:56<01:14,  2.18it/s] 68%|██████▊   | 339/500 [03:56<00:54,  2.94it/s] 68%|██████▊   | 341/500 [04:02<03:08,  1.18s/it] 69%|██████▊   | 343/500 [04:02<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:03<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:03<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:03<00:50,  2.96it/s] 70%|███████   | 351/500 [04:09<02:55,  1.18s/it] 71%|███████   | 353/500 [04:09<02:04,  1.18it/s] 71%|███████   | 355/500 [04:09<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:10<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:10<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:16<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:16<01:56,  1.18it/s]Epoch:  293  	Training Loss: 0.24724945425987244
Test Loss:  0.3170660138130188
Valid Loss:  0.30295348167419434
Epoch:  294  	Training Loss: 0.24724934995174408
Test Loss:  0.31706592440605164
Valid Loss:  0.3029533624649048
Epoch:  295  	Training Loss: 0.2472492903470993
Test Loss:  0.3170658051967621
Valid Loss:  0.30295330286026
Epoch:  296  	Training Loss: 0.24724921584129333
Test Loss:  0.3170657157897949
Valid Loss:  0.30295318365097046
Epoch:  297  	Training Loss: 0.24724915623664856
Test Loss:  0.31706559658050537
Valid Loss:  0.3029530942440033
Epoch:  298  	Training Loss: 0.2472490817308426
Test Loss:  0.3170655369758606
Valid Loss:  0.30295297503471375
Epoch:  299  	Training Loss: 0.24724902212619781
Test Loss:  0.31706541776657104
Valid Loss:  0.3029528856277466
Epoch:  300  	Training Loss: 0.24724893271923065
Test Loss:  0.31706535816192627
Valid Loss:  0.3029527962207794
Epoch:  301  	Training Loss: 0.24724885821342468
Test Loss:  0.3170652389526367
Valid Loss:  0.30295270681381226
Epoch:  302  	Training Loss: 0.2472487837076187
Test Loss:  0.31706511974334717
Valid Loss:  0.3029525876045227
Epoch:  303  	Training Loss: 0.24724870920181274
Test Loss:  0.3170650601387024
Valid Loss:  0.30295249819755554
Epoch:  304  	Training Loss: 0.24724863469600677
Test Loss:  0.31706494092941284
Valid Loss:  0.3029524087905884
Epoch:  305  	Training Loss: 0.247248575091362
Test Loss:  0.3170648515224457
Valid Loss:  0.30295228958129883
Epoch:  306  	Training Loss: 0.24724850058555603
Test Loss:  0.3170647621154785
Valid Loss:  0.30295220017433167
Epoch:  307  	Training Loss: 0.24724841117858887
Test Loss:  0.31706464290618896
Valid Loss:  0.3029521107673645
Epoch:  308  	Training Loss: 0.2472483515739441
Test Loss:  0.3170645833015442
Valid Loss:  0.30295199155807495
Epoch:  309  	Training Loss: 0.24724827706813812
Test Loss:  0.31706446409225464
Valid Loss:  0.3029519319534302
Epoch:  310  	Training Loss: 0.24724820256233215
Test Loss:  0.31706440448760986
Valid Loss:  0.3029518127441406
Epoch:  311  	Training Loss: 0.24724814295768738
Test Loss:  0.3170642852783203
Valid Loss:  0.3029516935348511
Epoch:  312  	Training Loss: 0.24724805355072021
Test Loss:  0.31706416606903076
Valid Loss:  0.3029516041278839
Epoch:  313  	Training Loss: 0.24724799394607544
Test Loss:  0.3170640766620636
Valid Loss:  0.30295151472091675
Epoch:  314  	Training Loss: 0.24724791944026947
Test Loss:  0.31706398725509644
Valid Loss:  0.3029513955116272
Epoch:  315  	Training Loss: 0.2472478449344635
Test Loss:  0.31706392765045166
Valid Loss:  0.3029513359069824
Epoch:  316  	Training Loss: 0.24724778532981873
Test Loss:  0.3170638084411621
Valid Loss:  0.3029511868953705
Epoch:  317  	Training Loss: 0.24724771082401276
Test Loss:  0.31706368923187256
Valid Loss:  0.3029511272907257
Epoch:  318  	Training Loss: 0.2472476363182068
Test Loss:  0.3170636296272278
Valid Loss:  0.30295103788375854
Epoch:  319  	Training Loss: 0.24724754691123962
Test Loss:  0.31706351041793823
Valid Loss:  0.302950918674469
Epoch:  320  	Training Loss: 0.24724748730659485
Test Loss:  0.31706342101097107
Valid Loss:  0.30295079946517944
Epoch:  321  	Training Loss: 0.24724741280078888
Test Loss:  0.3170633316040039
Valid Loss:  0.30295073986053467
Epoch:  322  	Training Loss: 0.2472473382949829
Test Loss:  0.31706321239471436
Valid Loss:  0.3029506206512451
Epoch:  323  	Training Loss: 0.24724726378917694
Test Loss:  0.3170631527900696
Valid Loss:  0.30295050144195557
Epoch:  324  	Training Loss: 0.24724718928337097
Test Loss:  0.31706303358078003
Valid Loss:  0.3029504418373108
Epoch:  325  	Training Loss: 0.2472471296787262
Test Loss:  0.31706294417381287
Valid Loss:  0.30295032262802124
Epoch:  326  	Training Loss: 0.24724704027175903
Test Loss:  0.3170628547668457
Valid Loss:  0.3029502034187317
Epoch:  327  	Training Loss: 0.24724696576595306
Test Loss:  0.31706273555755615
Valid Loss:  0.3029501438140869
Epoch:  328  	Training Loss: 0.2472469061613083
Test Loss:  0.317062646150589
Valid Loss:  0.30295002460479736
Epoch:  329  	Training Loss: 0.24724681675434113
Test Loss:  0.3170625567436218
Valid Loss:  0.3029499650001526
Epoch:  330  	Training Loss: 0.24724674224853516
Test Loss:  0.31706246733665466
Valid Loss:  0.30294984579086304
Epoch:  331  	Training Loss: 0.24724668264389038
Test Loss:  0.3170623779296875
Valid Loss:  0.3029497265815735
Epoch:  332  	Training Loss: 0.2472466230392456
Test Loss:  0.31706225872039795
Valid Loss:  0.3029496669769287
Epoch:  333  	Training Loss: 0.24724653363227844
Test Loss:  0.3170621693134308
Valid Loss:  0.30294954776763916
Epoch:  334  	Training Loss: 0.24724647402763367
Test Loss:  0.3170620799064636
Valid Loss:  0.3029494285583496
Epoch:  335  	Training Loss: 0.2472463995218277
Test Loss:  0.3170619606971741
Valid Loss:  0.30294930934906006
Epoch:  336  	Training Loss: 0.24724633991718292
Test Loss:  0.3170619010925293
Valid Loss:  0.3029492497444153
Epoch:  337  	Training Loss: 0.24724625051021576
Test Loss:  0.31706181168556213
Valid Loss:  0.3029491603374481
Epoch:  338  	Training Loss: 0.2472461760044098
Test Loss:  0.3170616924762726
Valid Loss:  0.30294904112815857
Epoch:  339  	Training Loss: 0.24724610149860382
Test Loss:  0.3170616030693054
Valid Loss:  0.3029489517211914
Epoch:  340  	Training Loss: 0.24724602699279785
Test Loss:  0.31706151366233826
Valid Loss:  0.30294886231422424
Epoch:  341  	Training Loss: 0.24724596738815308
Test Loss:  0.3170613944530487
Valid Loss:  0.3029487729072571
Epoch:  342  	Training Loss: 0.2472458928823471
Test Loss:  0.31706130504608154
Valid Loss:  0.30294862389564514
Epoch:  343  	Training Loss: 0.24724581837654114
Test Loss:  0.3170612156391144
Valid Loss:  0.302948534488678
Epoch:  344  	Training Loss: 0.24724574387073517
Test Loss:  0.3170611262321472
Valid Loss:  0.3029484450817108
Epoch:  345  	Training Loss: 0.2472456693649292
Test Loss:  0.31706100702285767
Valid Loss:  0.30294835567474365
Epoch:  346  	Training Loss: 0.24724560976028442
Test Loss:  0.3170608878135681
Valid Loss:  0.3029482364654541
Epoch:  347  	Training Loss: 0.24724552035331726
Test Loss:  0.31706082820892334
Valid Loss:  0.3029481768608093
Epoch:  348  	Training Loss: 0.2472454458475113
Test Loss:  0.3170607388019562
Valid Loss:  0.3029480576515198
Epoch:  349  	Training Loss: 0.24724537134170532
Test Loss:  0.3170606195926666
Valid Loss:  0.3029479384422302
Epoch:  350  	Training Loss: 0.24724531173706055
Test Loss:  0.31706055998802185
Valid Loss:  0.30294784903526306
Epoch:  351  	Training Loss: 0.24724523723125458
Test Loss:  0.3170604407787323
Valid Loss:  0.3029477596282959
Epoch:  352  	Training Loss: 0.2472451776266098
Test Loss:  0.31706035137176514
Valid Loss:  0.30294767022132874
Epoch:  353  	Training Loss: 0.24724510312080383
Test Loss:  0.3170602321624756
Valid Loss:  0.3029475510120392
Epoch:  354  	Training Loss: 0.24724502861499786
Test Loss:  0.3170601725578308
Valid Loss:  0.302947461605072
Epoch:  355  	Training Loss: 0.2472449392080307
Test Loss:  0.31706002354621887
Valid Loss:  0.30294737219810486
Epoch:  356  	Training Loss: 0.24724486470222473
Test Loss:  0.3170599639415741
Valid Loss:  0.3029472827911377
Epoch:  357  	Training Loss: 0.24724480509757996
Test Loss:  0.31705987453460693
Valid Loss:  0.30294716358184814
Epoch:  358  	Training Loss: 0.2472447156906128
Test Loss:  0.31705978512763977
Valid Loss:  0.302947074174881
Epoch:  359  	Training Loss: 0.24724465608596802
Test Loss:  0.3170596957206726
Valid Loss:  0.30294695496559143
Epoch:  360  	Training Loss: 0.24724456667900085
Test Loss:  0.31705957651138306
Valid Loss:  0.30294686555862427
Epoch:  361  	Training Loss: 0.24724450707435608
Test Loss:  0.3170594573020935
Valid Loss:  0.3029467463493347
Epoch:  362  	Training Loss: 0.2472444325685501
Test Loss:  0.31705939769744873
Valid Loss:  0.30294665694236755
Epoch:  363  	Training Loss: 0.24724437296390533
Test Loss:  0.3170592784881592
Valid Loss:  0.3029465675354004
Epoch:  364  	Training Loss: 0.24724428355693817
Test Loss:  0.3170592188835144
Valid Loss:  0.3029464781284332
Epoch:  365  	Training Loss: 0.2472442239522934
Test Loss:  0.31705909967422485
Valid Loss:   73%|███████▎  | 365/500 [04:16<01:23,  1.63it/s] 73%|███████▎  | 367/500 [04:16<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:17<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:23<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:23<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:23<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:23<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:24<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:30<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:30<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:30<01:12,  1.59it/s] 77%|███████▋  | 387/500 [04:30<00:52,  2.17it/s] 78%|███████▊  | 389/500 [04:31<00:38,  2.92it/s] 78%|███████▊  | 391/500 [04:37<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:37<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:37<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:37<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:37<00:34,  2.97it/s] 80%|████████  | 401/500 [04:44<02:01,  1.23s/it] 81%|████████  | 403/500 [04:44<01:25,  1.14it/s] 81%|████████  | 405/500 [04:44<01:00,  1.57it/s] 81%|████████▏ | 407/500 [04:44<00:43,  2.15it/s] 82%|████████▏ | 409/500 [04:45<00:31,  2.89it/s] 82%|████████▏ | 411/500 [04:51<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:51<01:15,  1.15it/s] 83%|████████▎ | 415/500 [04:51<00:53,  1.57it/s] 83%|████████▎ | 417/500 [04:52<00:39,  2.13it/s] 84%|████████▍ | 419/500 [04:52<00:28,  2.82it/s] 84%|████████▍ | 421/500 [04:58<01:36,  1.22s/it] 85%|████████▍ | 423/500 [04:58<01:07,  1.14it/s] 85%|████████▌ | 425/500 [04:58<00:47,  1.58it/s] 85%|████████▌ | 427/500 [04:59<00:33,  2.16it/s] 86%|████████▌ | 429/500 [04:59<00:24,  2.91it/s] 86%|████████▌ | 431/500 [05:05<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:05<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:05<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:06<00:28,  2.20it/s]0.3029463589191437
Epoch:  366  	Training Loss: 0.24724416434764862
Test Loss:  0.3170589804649353
Valid Loss:  0.3029462695121765
Epoch:  367  	Training Loss: 0.24724408984184265
Test Loss:  0.3170589208602905
Valid Loss:  0.30294618010520935
Epoch:  368  	Training Loss: 0.2472440004348755
Test Loss:  0.317058801651001
Valid Loss:  0.3029460906982422
Epoch:  369  	Training Loss: 0.2472439408302307
Test Loss:  0.3170587122440338
Valid Loss:  0.30294597148895264
Epoch:  370  	Training Loss: 0.24724386632442474
Test Loss:  0.31705862283706665
Valid Loss:  0.3029458820819855
Epoch:  371  	Training Loss: 0.24724379181861877
Test Loss:  0.3170585334300995
Valid Loss:  0.3029457926750183
Epoch:  372  	Training Loss: 0.2472437024116516
Test Loss:  0.3170584440231323
Valid Loss:  0.30294567346572876
Epoch:  373  	Training Loss: 0.24724364280700684
Test Loss:  0.3170583248138428
Valid Loss:  0.3029455840587616
Epoch:  374  	Training Loss: 0.24724356830120087
Test Loss:  0.3170582354068756
Valid Loss:  0.30294549465179443
Epoch:  375  	Training Loss: 0.2472434937953949
Test Loss:  0.31705814599990845
Valid Loss:  0.3029453754425049
Epoch:  376  	Training Loss: 0.24724343419075012
Test Loss:  0.3170580267906189
Valid Loss:  0.3029452860355377
Epoch:  377  	Training Loss: 0.24724334478378296
Test Loss:  0.31705793738365173
Valid Loss:  0.30294519662857056
Epoch:  378  	Training Loss: 0.24724328517913818
Test Loss:  0.31705784797668457
Valid Loss:  0.302945077419281
Epoch:  379  	Training Loss: 0.24724319577217102
Test Loss:  0.3170577585697174
Valid Loss:  0.30294498801231384
Epoch:  380  	Training Loss: 0.24724313616752625
Test Loss:  0.31705766916275024
Valid Loss:  0.3029448986053467
Epoch:  381  	Training Loss: 0.24724306166172028
Test Loss:  0.3170575499534607
Valid Loss:  0.30294477939605713
Epoch:  382  	Training Loss: 0.2472430020570755
Test Loss:  0.31705746054649353
Valid Loss:  0.30294471979141235
Epoch:  383  	Training Loss: 0.24724291265010834
Test Loss:  0.31705737113952637
Valid Loss:  0.3029446005821228
Epoch:  384  	Training Loss: 0.24724283814430237
Test Loss:  0.3170572519302368
Valid Loss:  0.30294448137283325
Epoch:  385  	Training Loss: 0.2472427785396576
Test Loss:  0.31705719232559204
Valid Loss:  0.3029443919658661
Epoch:  386  	Training Loss: 0.24724268913269043
Test Loss:  0.3170571029186249
Valid Loss:  0.3029443025588989
Epoch:  387  	Training Loss: 0.24724262952804565
Test Loss:  0.3170570135116577
Valid Loss:  0.3029441833496094
Epoch:  388  	Training Loss: 0.24724255502223969
Test Loss:  0.31705689430236816
Valid Loss:  0.3029441237449646
Epoch:  389  	Training Loss: 0.24724248051643372
Test Loss:  0.3170567750930786
Valid Loss:  0.30294400453567505
Epoch:  390  	Training Loss: 0.24724239110946655
Test Loss:  0.31705668568611145
Valid Loss:  0.3029438853263855
Epoch:  391  	Training Loss: 0.24724233150482178
Test Loss:  0.3170565962791443
Valid Loss:  0.3029438257217407
Epoch:  392  	Training Loss: 0.247242271900177
Test Loss:  0.3170565366744995
Valid Loss:  0.30294370651245117
Epoch:  393  	Training Loss: 0.24724218249320984
Test Loss:  0.31705641746520996
Valid Loss:  0.302943617105484
Epoch:  394  	Training Loss: 0.24724212288856506
Test Loss:  0.3170563280582428
Valid Loss:  0.30294352769851685
Epoch:  395  	Training Loss: 0.2472420632839203
Test Loss:  0.31705620884895325
Valid Loss:  0.3029434084892273
Epoch:  396  	Training Loss: 0.24724197387695312
Test Loss:  0.3170561194419861
Valid Loss:  0.30294331908226013
Epoch:  397  	Training Loss: 0.24724189937114716
Test Loss:  0.3170560300350189
Valid Loss:  0.3029431998729706
Epoch:  398  	Training Loss: 0.24724185466766357
Test Loss:  0.31705594062805176
Valid Loss:  0.3029431104660034
Epoch:  399  	Training Loss: 0.2472417652606964
Test Loss:  0.3170558214187622
Valid Loss:  0.30294302105903625
Epoch:  400  	Training Loss: 0.24724169075489044
Test Loss:  0.31705576181411743
Valid Loss:  0.3029429316520691
Epoch:  401  	Training Loss: 0.24724160134792328
Test Loss:  0.3170556426048279
Valid Loss:  0.30294281244277954
Epoch:  402  	Training Loss: 0.2472415268421173
Test Loss:  0.3170555531978607
Valid Loss:  0.30294269323349
Epoch:  403  	Training Loss: 0.24724145233631134
Test Loss:  0.31705546379089355
Valid Loss:  0.3029426336288452
Epoch:  404  	Training Loss: 0.24724140763282776
Test Loss:  0.317055344581604
Valid Loss:  0.30294251441955566
Epoch:  405  	Training Loss: 0.2472413182258606
Test Loss:  0.31705525517463684
Valid Loss:  0.3029423952102661
Epoch:  406  	Training Loss: 0.24724125862121582
Test Loss:  0.3170551657676697
Valid Loss:  0.30294233560562134
Epoch:  407  	Training Loss: 0.24724116921424866
Test Loss:  0.3170550465583801
Valid Loss:  0.3029422163963318
Epoch:  408  	Training Loss: 0.24724110960960388
Test Loss:  0.31705498695373535
Valid Loss:  0.3029421269893646
Epoch:  409  	Training Loss: 0.2472410351037979
Test Loss:  0.3170548677444458
Valid Loss:  0.30294203758239746
Epoch:  410  	Training Loss: 0.24724096059799194
Test Loss:  0.317054808139801
Valid Loss:  0.3029419183731079
Epoch:  411  	Training Loss: 0.24724088609218597
Test Loss:  0.3170546889305115
Valid Loss:  0.30294182896614075
Epoch:  412  	Training Loss: 0.24724081158638
Test Loss:  0.3170545697212219
Valid Loss:  0.3029417395591736
Epoch:  413  	Training Loss: 0.24724075198173523
Test Loss:  0.31705448031425476
Valid Loss:  0.30294162034988403
Epoch:  414  	Training Loss: 0.24724067747592926
Test Loss:  0.3170543909072876
Valid Loss:  0.30294156074523926
Epoch:  415  	Training Loss: 0.2472405880689621
Test Loss:  0.31705427169799805
Valid Loss:  0.3029414415359497
Epoch:  416  	Training Loss: 0.24724052846431732
Test Loss:  0.31705421209335327
Valid Loss:  0.30294135212898254
Epoch:  417  	Training Loss: 0.24724045395851135
Test Loss:  0.3170540928840637
Valid Loss:  0.302941232919693
Epoch:  418  	Training Loss: 0.2472403645515442
Test Loss:  0.31705403327941895
Valid Loss:  0.30294114351272583
Epoch:  419  	Training Loss: 0.2472403198480606
Test Loss:  0.3170539140701294
Valid Loss:  0.3029410243034363
Epoch:  420  	Training Loss: 0.24724024534225464
Test Loss:  0.3170538544654846
Valid Loss:  0.3029409348964691
Epoch:  421  	Training Loss: 0.24724017083644867
Test Loss:  0.31705373525619507
Valid Loss:  0.30294084548950195
Epoch:  422  	Training Loss: 0.2472400963306427
Test Loss:  0.3170536458492279
Valid Loss:  0.3029407262802124
Epoch:  423  	Training Loss: 0.24724000692367554
Test Loss:  0.31705352663993835
Valid Loss:  0.30294063687324524
Epoch:  424  	Training Loss: 0.24723994731903076
Test Loss:  0.3170534372329712
Valid Loss:  0.3029405474662781
Epoch:  425  	Training Loss: 0.2472398728132248
Test Loss:  0.31705334782600403
Valid Loss:  0.3029404282569885
Epoch:  426  	Training Loss: 0.2472398281097412
Test Loss:  0.31705325841903687
Valid Loss:  0.30294033885002136
Epoch:  427  	Training Loss: 0.24723973870277405
Test Loss:  0.3170531392097473
Valid Loss:  0.3029402494430542
Epoch:  428  	Training Loss: 0.24723964929580688
Test Loss:  0.31705307960510254
Valid Loss:  0.30294016003608704
Epoch:  429  	Training Loss: 0.2472395896911621
Test Loss:  0.317052960395813
Valid Loss:  0.3029400706291199
Epoch:  430  	Training Loss: 0.24723951518535614
Test Loss:  0.3170529007911682
Valid Loss:  0.3029399514198303
Epoch:  431  	Training Loss: 0.24723944067955017
Test Loss:  0.3170527517795563
Valid Loss:  0.30293983221054077
Epoch:  432  	Training Loss: 0.2472393661737442
Test Loss:  0.3170526623725891
Valid Loss:  0.302939772605896
Epoch:  433  	Training Loss: 0.24723929166793823
Test Loss:  0.31705260276794434
Valid Loss:  0.30293965339660645
Epoch:  434  	Training Loss: 0.24723923206329346
Test Loss:  0.3170524835586548
Valid Loss:  0.3029395341873169
Epoch:  435  	Training Loss: 0.2472391575574875
Test Loss:  0.3170523941516876
Valid Loss:  0.3029394745826721
Epoch:  436  	Training Loss: 0.24723908305168152
Test Loss:  0.31705230474472046
Valid Loss:  0.30293935537338257
Epoch:  437  	Training Loss: 0.24723899364471436
Test Loss:  0.3170521855354309
Valid Loss:  0.3029392659664154
Epoch:  438  	Training Loss: 0.24723893404006958
Test Loss:  0.31705206632614136
 88%|████████▊ | 439/500 [05:06<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:12<01:12,  1.23s/it] 89%|████████▊ | 443/500 [05:12<00:50,  1.14it/s] 89%|████████▉ | 445/500 [05:13<00:34,  1.57it/s] 89%|████████▉ | 447/500 [05:13<00:24,  2.15it/s] 90%|████████▉ | 449/500 [05:13<00:17,  2.88it/s] 90%|█████████ | 451/500 [05:19<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:19<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:20<00:28,  1.59it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.17it/s] 92%|█████████▏| 459/500 [05:20<00:14,  2.92it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:27<00:15,  2.20it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:33<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.59it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.14it/s] 96%|█████████▌| 479/500 [05:34<00:07,  2.83it/s] 96%|█████████▌| 481/500 [05:40<00:23,  1.23s/it] 97%|█████████▋| 483/500 [05:40<00:15,  1.13it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.55it/s] 97%|█████████▋| 487/500 [05:41<00:06,  2.10it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.78it/s] 98%|█████████▊| 491/500 [05:48<00:11,  1.23s/it] 99%|█████████▊| 493/500 [05:48<00:06,  1.13it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.55it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.09it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.76it/s]100%|██████████| 500/500 [05:48<00:00,  1.43it/s]
Valid Loss:  0.30293917655944824
Epoch:  439  	Training Loss: 0.2472388744354248
Test Loss:  0.3170520067214966
Valid Loss:  0.3029390573501587
Epoch:  440  	Training Loss: 0.24723879992961884
Test Loss:  0.31705188751220703
Valid Loss:  0.30293896794319153
Epoch:  441  	Training Loss: 0.24723872542381287
Test Loss:  0.31705182790756226
Valid Loss:  0.30293887853622437
Epoch:  442  	Training Loss: 0.2472386360168457
Test Loss:  0.3170517086982727
Valid Loss:  0.3029387593269348
Epoch:  443  	Training Loss: 0.24723857641220093
Test Loss:  0.31705161929130554
Valid Loss:  0.30293866991996765
Epoch:  444  	Training Loss: 0.24723851680755615
Test Loss:  0.3170515298843384
Valid Loss:  0.3029385805130005
Epoch:  445  	Training Loss: 0.247238427400589
Test Loss:  0.31705141067504883
Valid Loss:  0.3029384911060333
Epoch:  446  	Training Loss: 0.24723835289478302
Test Loss:  0.31705135107040405
Valid Loss:  0.3029383718967438
Epoch:  447  	Training Loss: 0.24723827838897705
Test Loss:  0.3170512318611145
Valid Loss:  0.3029382824897766
Epoch:  448  	Training Loss: 0.2472381889820099
Test Loss:  0.31705114245414734
Valid Loss:  0.30293819308280945
Epoch:  449  	Training Loss: 0.2472381293773651
Test Loss:  0.3170510530471802
Valid Loss:  0.3029380738735199
Epoch:  450  	Training Loss: 0.24723806977272034
Test Loss:  0.3170509338378906
Valid Loss:  0.30293798446655273
Epoch:  451  	Training Loss: 0.24723798036575317
Test Loss:  0.31705084443092346
Valid Loss:  0.3029378652572632
Epoch:  452  	Training Loss: 0.2472379207611084
Test Loss:  0.3170507550239563
Valid Loss:  0.302937775850296
Epoch:  453  	Training Loss: 0.24723784625530243
Test Loss:  0.31705066561698914
Valid Loss:  0.30293768644332886
Epoch:  454  	Training Loss: 0.24723778665065765
Test Loss:  0.317050576210022
Valid Loss:  0.3029375672340393
Epoch:  455  	Training Loss: 0.24723771214485168
Test Loss:  0.3170504570007324
Valid Loss:  0.30293750762939453
Epoch:  456  	Training Loss: 0.24723762273788452
Test Loss:  0.31705033779144287
Valid Loss:  0.302937388420105
Epoch:  457  	Training Loss: 0.24723756313323975
Test Loss:  0.3170502781867981
Valid Loss:  0.30293726921081543
Epoch:  458  	Training Loss: 0.24723748862743378
Test Loss:  0.31705015897750854
Valid Loss:  0.30293720960617065
Epoch:  459  	Training Loss: 0.247237429022789
Test Loss:  0.31705009937286377
Valid Loss:  0.3029370903968811
Epoch:  460  	Training Loss: 0.24723735451698303
Test Loss:  0.3170499801635742
Valid Loss:  0.30293700098991394
Epoch:  461  	Training Loss: 0.24723728001117706
Test Loss:  0.31704986095428467
Valid Loss:  0.3029369115829468
Epoch:  462  	Training Loss: 0.2472371906042099
Test Loss:  0.3170498013496399
Valid Loss:  0.3029367923736572
Epoch:  463  	Training Loss: 0.24723711609840393
Test Loss:  0.31704968214035034
Valid Loss:  0.3029366731643677
Epoch:  464  	Training Loss: 0.24723705649375916
Test Loss:  0.31704962253570557
Valid Loss:  0.3029366135597229
Epoch:  465  	Training Loss: 0.247236967086792
Test Loss:  0.317049503326416
Valid Loss:  0.30293649435043335
Epoch:  466  	Training Loss: 0.24723690748214722
Test Loss:  0.31704941391944885
Valid Loss:  0.3029364049434662
Epoch:  467  	Training Loss: 0.24723683297634125
Test Loss:  0.3170493245124817
Valid Loss:  0.302936315536499
Epoch:  468  	Training Loss: 0.24723675847053528
Test Loss:  0.31704920530319214
Valid Loss:  0.3029361963272095
Epoch:  469  	Training Loss: 0.24723666906356812
Test Loss:  0.31704914569854736
Valid Loss:  0.3029360771179199
Epoch:  470  	Training Loss: 0.24723660945892334
Test Loss:  0.3170490264892578
Valid Loss:  0.30293601751327515
Epoch:  471  	Training Loss: 0.24723654985427856
Test Loss:  0.31704890727996826
Valid Loss:  0.3029358983039856
Epoch:  472  	Training Loss: 0.2472364604473114
Test Loss:  0.3170488178730011
Valid Loss:  0.30293580889701843
Epoch:  473  	Training Loss: 0.24723640084266663
Test Loss:  0.31704872846603394
Valid Loss:  0.30293571949005127
Epoch:  474  	Training Loss: 0.24723631143569946
Test Loss:  0.3170486390590668
Valid Loss:  0.3029356002807617
Epoch:  475  	Training Loss: 0.2472362518310547
Test Loss:  0.3170485496520996
Valid Loss:  0.30293551087379456
Epoch:  476  	Training Loss: 0.2472361922264099
Test Loss:  0.31704843044281006
Valid Loss:  0.3029354214668274
Epoch:  477  	Training Loss: 0.24723610281944275
Test Loss:  0.3170483410358429
Valid Loss:  0.30293533205986023
Epoch:  478  	Training Loss: 0.24723604321479797
Test Loss:  0.31704825162887573
Valid Loss:  0.30293524265289307
Epoch:  479  	Training Loss: 0.2472359538078308
Test Loss:  0.31704816222190857
Valid Loss:  0.3029351234436035
Epoch:  480  	Training Loss: 0.24723589420318604
Test Loss:  0.3170480728149414
Valid Loss:  0.30293500423431396
Epoch:  481  	Training Loss: 0.24723583459854126
Test Loss:  0.31704795360565186
Valid Loss:  0.3029349148273468
Epoch:  482  	Training Loss: 0.2472357451915741
Test Loss:  0.3170478641986847
Valid Loss:  0.30293482542037964
Epoch:  483  	Training Loss: 0.24723567068576813
Test Loss:  0.31704777479171753
Valid Loss:  0.3029347062110901
Epoch:  484  	Training Loss: 0.24723559617996216
Test Loss:  0.31704768538475037
Valid Loss:  0.3029346168041229
Epoch:  485  	Training Loss: 0.24723555147647858
Test Loss:  0.3170475959777832
Valid Loss:  0.30293452739715576
Epoch:  486  	Training Loss: 0.2472354769706726
Test Loss:  0.31704750657081604
Valid Loss:  0.3029344081878662
Epoch:  487  	Training Loss: 0.24723538756370544
Test Loss:  0.3170473575592041
Valid Loss:  0.30293431878089905
Epoch:  488  	Training Loss: 0.24723531305789948
Test Loss:  0.3170472979545593
Valid Loss:  0.3029342293739319
Epoch:  489  	Training Loss: 0.2472352534532547
Test Loss:  0.3170471787452698
Valid Loss:  0.3029341399669647
Epoch:  490  	Training Loss: 0.24723514914512634
Test Loss:  0.3170470893383026
Valid Loss:  0.30293405055999756
Epoch:  491  	Training Loss: 0.24723508954048157
Test Loss:  0.31704699993133545
Valid Loss:  0.302933931350708
Epoch:  492  	Training Loss: 0.2472350299358368
Test Loss:  0.3170469105243683
Valid Loss:  0.30293381214141846
Epoch:  493  	Training Loss: 0.24723495543003082
Test Loss:  0.3170468211174011
Valid Loss:  0.3029337227344513
Epoch:  494  	Training Loss: 0.24723488092422485
Test Loss:  0.31704673171043396
Valid Loss:  0.30293363332748413
Epoch:  495  	Training Loss: 0.24723480641841888
Test Loss:  0.3170466423034668
Valid Loss:  0.3029335141181946
Epoch:  496  	Training Loss: 0.24723473191261292
Test Loss:  0.31704655289649963
Valid Loss:  0.3029334247112274
Epoch:  497  	Training Loss: 0.24723467230796814
Test Loss:  0.3170464336872101
Valid Loss:  0.30293333530426025
Epoch:  498  	Training Loss: 0.24723458290100098
Test Loss:  0.3170463442802429
Valid Loss:  0.3029332160949707
Epoch:  499  	Training Loss: 0.2472345232963562
Test Loss:  0.31704622507095337
Valid Loss:  0.30293312668800354
Epoch:  500  	Training Loss: 0.24723444879055023
Test Loss:  0.3170461356639862
Valid Loss:  0.3029330372810364
seed is  7
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:46,  6.47s/it]  1%|          | 3/500 [00:06<14:19,  1.73s/it]  1%|          | 5/500 [00:06<07:12,  1.14it/s]  1%|▏         | 7/500 [00:06<04:21,  1.88it/s]  2%|▏         | 9/500 [00:06<02:54,  2.81it/s]  2%|▏         | 11/500 [00:13<11:22,  1.40s/it]  3%|▎         | 13/500 [00:13<07:47,  1.04it/s]  3%|▎         | 15/500 [00:13<05:25,  1.49it/s]  3%|▎         | 17/500 [00:14<03:52,  2.08it/s]  4%|▍         | 19/500 [00:14<02:49,  2.85it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:21<03:36,  2.19it/s]  6%|▌         | 29/500 [00:21<02:39,  2.95it/s]  6%|▌         | 31/500 [00:27<09:29,  1.21s/it]  7%|▋         | 33/500 [00:27<06:46,  1.15it/s]  7%|▋         | 35/500 [00:34<12:05,  1.56s/it]  7%|▋         | 37/500 [00:34<08:37,  1.12s/it]  8%|▊         | 39/500 [00:34<06:12,  1.24it/s]  8%|▊         | 41/500 [00:40<11:45,  1.54s/it]  9%|▊         | 43/500 [00:41<08:21,  1.10s/it]  9%|▉         | 45/500 [00:47<12:57,  1.71s/it]  9%|▉         | 47/500 [00:47<09:14,  1.22s/it] 10%|▉         | 49/500 [00:47<06:37,  1.13it/s] 10%|█         | 51/500 [00:54<11:48,  1.58s/it] 11%|█         | 53/500 [00:54<08:23,  1.13s/it] 11%|█         | 55/500 [00:54<05:59,  1.24it/s] 11%|█▏        | 57/500 [00:54<04:19,  1.71it/s] 12%|█▏        | 59/500 [00:54<03:09,  2.33it/s] 12%|█▏        | 61/500 [01:01<09:11,  1.26s/it] 13%|█▎        | 63/500 [01:01<06:36,  1.10it/s] 13%|█▎        | 65/500 [01:01<04:47,  1.51it/s] 13%|█▎        | 67/500 [01:01<03:31,  2.05it/s]Epoch:  1  	Training Loss: 0.2261407971382141
Test Loss:  0.1312427967786789
Valid Loss:  0.14598707854747772
Epoch:  2  	Training Loss: 0.21149274706840515
Test Loss:  0.08771531283855438
Valid Loss:  0.11908914148807526
Epoch:  3  	Training Loss: 0.09070463478565216
Test Loss:  0.023357123136520386
Valid Loss:  0.036976512521505356
Epoch:  4  	Training Loss: 0.041997700929641724
Test Loss:  0.01636645384132862
Valid Loss:  0.02306433767080307
Epoch:  5  	Training Loss: 0.023573487997055054
Test Loss:  0.011318068951368332
Valid Loss:  0.015362927690148354
Epoch:  6  	Training Loss: 0.016519416123628616
Test Loss:  0.008079945109784603
Valid Loss:  0.010492734611034393
Epoch:  7  	Training Loss: 0.011989586055278778
Test Loss:  0.005774961318820715
Valid Loss:  0.007316692266613245
Epoch:  8  	Training Loss: 0.00894403550773859
Test Loss:  0.004486006684601307
Valid Loss:  0.0053242649883031845
Epoch:  9  	Training Loss: 0.0067655108869075775
Test Loss:  0.003454929916188121
Valid Loss:  0.003911028150469065
Epoch:  10  	Training Loss: 0.005270690191537142
Test Loss:  0.0028028124943375587
Valid Loss:  0.0030162003822624683
Epoch:  11  	Training Loss: 0.0042213439010083675
Test Loss:  0.0023937546648085117
Valid Loss:  0.002438478171825409
Epoch:  12  	Training Loss: 0.003482185071334243
Test Loss:  0.002405355451628566
Valid Loss:  0.0021357634104788303
Epoch:  13  	Training Loss: 0.002936369739472866
Test Loss:  0.0019202993717044592
Valid Loss:  0.0018325680866837502
Epoch:  14  	Training Loss: 0.0025683240965008736
Test Loss:  0.0020041821990162134
Valid Loss:  0.0017574004596099257
Epoch:  15  	Training Loss: 0.002385792089626193
Test Loss:  0.001426550792530179
Valid Loss:  0.0017779248300939798
Epoch:  16  	Training Loss: 0.002355907578021288
Test Loss:  0.0022077830508351326
Valid Loss:  0.0016954808961600065
Epoch:  17  	Training Loss: 0.002166152000427246
Test Loss:  0.001356563763692975
Valid Loss:  0.0017987070605158806
Epoch:  18  	Training Loss: 0.002167000900954008
Test Loss:  0.0020889819134026766
Valid Loss:  0.001630881568416953
Epoch:  19  	Training Loss: 0.0019911648705601692
Test Loss:  0.001458456739783287
Valid Loss:  0.0016829426167532802
Epoch:  20  	Training Loss: 0.001883425866253674
Test Loss:  0.001805283478461206
Valid Loss:  0.001604636199772358
Epoch:  21  	Training Loss: 0.0018243404338136315
Test Loss:  0.0014188825152814388
Valid Loss:  0.001780163962393999
Epoch:  22  	Training Loss: 0.0018603827338665724
Test Loss:  0.002020426793023944
Valid Loss:  0.0016537304036319256
Epoch:  23  	Training Loss: 0.0018337660003453493
Test Loss:  0.0014374451711773872
Valid Loss:  0.00180139415897429
Epoch:  24  	Training Loss: 0.0018106424249708652
Test Loss:  0.0019617893267422915
Valid Loss:  0.0016649174503982067
Epoch:  25  	Training Loss: 0.00179028301499784
Test Loss:  0.0014557044487446547
Valid Loss:  0.0018137891311198473
Epoch:  26  	Training Loss: 0.001773574622347951
Test Loss:  0.0019109733402729034
Valid Loss:  0.0016776480479165912
Epoch:  27  	Training Loss: 0.0017592464573681355
Test Loss:  0.0014745206572115421
Valid Loss:  0.001827470725402236
Epoch:  28  	Training Loss: 0.0017492338083684444
Test Loss:  0.0018777830991894007
Valid Loss:  0.0016969835851341486
Epoch:  29  	Training Loss: 0.001739769708365202
Test Loss:  0.0014958883402869105
Valid Loss:  0.001843258272856474
Epoch:  30  	Training Loss: 0.001733478158712387
Test Loss:  0.0018507338827475905
Valid Loss:  0.0017161737196147442
Epoch:  31  	Training Loss: 0.0017261796165257692
Test Loss:  0.0014968446921557188
Valid Loss:  0.0018710583681240678
Epoch:  32  	Training Loss: 0.0017326370580121875
Test Loss:  0.0018679669592529535
Valid Loss:  0.001690939418040216
Epoch:  33  	Training Loss: 0.0017301454208791256
Test Loss:  0.0015380379045382142
Valid Loss:  0.0019450184190645814
Epoch:  34  	Training Loss: 0.0017076844815164804
Test Loss:  0.0017914040945470333
Valid Loss:  0.001731338445097208
Epoch:  35  	Training Loss: 0.0016929093981161714
Test Loss:  0.001578698167577386
Valid Loss:  0.0019113619346171618
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0016829553060233593
Test Loss:  0.0018098106374964118
Valid Loss:  0.0018238467164337635
Epoch:  37  	Training Loss: 0.0016629350138828158
Test Loss:  0.0015149525133892894
Valid Loss:  0.0019717388786375523
Epoch:  38  	Training Loss: 0.0016958309570327401
Test Loss:  0.0018777430523186922
Valid Loss:  0.0018136515282094479
Epoch:  39  	Training Loss: 0.0016817195573821664
Test Loss:  0.001482109073549509
Valid Loss:  0.0020085214637219906
Epoch:  40  	Training Loss: 0.0017136374954134226
Test Loss:  0.0019078338518738747
Valid Loss:  0.0017954882932826877
Epoch:  41  	Training Loss: 0.001680097309872508
Test Loss:  0.0014600756112486124
Valid Loss:  0.0020063421688973904
Epoch:  42  	Training Loss: 0.0017038816586136818
Test Loss:  0.0015911177033558488
Valid Loss:  0.0017867236165329814
Epoch:  43  	Training Loss: 0.0015608316753059626
Test Loss:  0.0015224230010062456
Valid Loss:  0.0017945555737242103
Epoch:  44  	Training Loss: 0.0015459578717127442
Test Loss:  0.0015684524551033974
Valid Loss:  0.001755794626660645
Epoch:  45  	Training Loss: 0.0015298898797482252
Test Loss:  0.0015382471028715372
Valid Loss:  0.0017481790855526924
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.0015169563703238964
Test Loss:  0.0015429550549015403
Valid Loss:  0.0017428031424060464
Epoch:  47  	Training Loss: 0.001513737952336669
Test Loss:  0.001540342578664422
Valid Loss:  0.0017397444462403655
Epoch:  48  	Training Loss: 0.0015117580769583583
Test Loss:  0.001536817173473537
Valid Loss:  0.0017366268439218402
Epoch:  49  	Training Loss: 0.001509833033196628
Test Loss:  0.0015325805870816112
Valid Loss:  0.0017334803706035018
Epoch:  50  	Training Loss: 0.001508090877905488
Test Loss:  0.0015288072172552347
Valid Loss:  0.0017302451888099313
Epoch:  51  	Training Loss: 0.0015065298648551106
Test Loss:  0.0015258872881531715
Valid Loss:  0.0017272434197366238
Epoch:  52  	Training Loss: 0.00150522671174258
Test Loss:  0.0015145207289606333
Valid Loss:  0.0017239823937416077
Epoch:  53  	Training Loss: 0.0014983357395976782
Test Loss:  0.0015077616553753614
Valid Loss:  0.0017187152989208698
Epoch:  54  	Training Loss: 0.0014927322044968605
Test Loss:  0.001503324368968606
Valid Loss:  0.0017129587940871716
Epoch:  55  	Training Loss: 0.0014879422960802913
Test Loss:  0.0014995557721704245
Valid Loss:  0.0017071705078706145
Epoch:  56  	Training Loss: 0.0014832637971267104
Test Loss:  0.0014968947507441044
Valid Loss:  0.0017019764054566622
Epoch:  57  	Training Loss: 0.00147920660674572
Test Loss:  0.0014953454956412315
Valid Loss:  0.0016974923200905323
Epoch:  58  	Training Loss: 0.0014758845791220665
Test Loss:  0.0014949488686397672
Valid Loss:  0.0016933991573750973
Epoch:  59  	Training Loss: 0.0014729272807016969
Test Loss:  0.0014943464193493128
Valid Loss:  0.0016897855093702674
Epoch:  60  	Training Loss: 0.0014701845357194543
Test Loss:  0.0014935156796127558
Valid Loss:  0.0016865431098267436
Epoch:  61  	Training Loss: 0.001467675669118762
Test Loss:  0.0014925298746675253
Valid Loss:  0.0016835639253258705
Epoch:  62  	Training Loss: 0.0014652706449851394
Test Loss:  0.0014928060118108988
Valid Loss:  0.0016731797950342298
Epoch:  63  	Training Loss: 0.0014563251752406359
Test Loss:  0.0014886712888255715
Valid Loss:  0.0016653623897582293
Epoch:  64  	Training Loss: 0.001448949915356934
Test Loss:  0.0014822708908468485
Valid Loss:  0.0016595760826021433
Epoch:  65  	Training Loss: 0.0014432002790272236
Test Loss:  0.001476825913414359
Valid Loss:  0.0016564670950174332
Epoch:  66  	Training Loss: 0.0014389676507562399
Test Loss:  0.001472347998060286
Valid Loss:  0.0016555015463382006
Epoch:  67  	Training Loss: 0.0014368377160280943
Test Loss:  0.0014678051229566336
Valid Loss:  0.0016559953801333904
Epoch:  68  	Training Loss: 0.0014361018547788262
Test Loss:   14%|█▍        | 69/500 [01:01<02:38,  2.72it/s] 14%|█▍        | 71/500 [01:08<08:44,  1.22s/it] 15%|█▍        | 73/500 [01:08<06:15,  1.14it/s] 15%|█▌        | 75/500 [01:08<04:32,  1.56it/s] 15%|█▌        | 77/500 [01:08<03:20,  2.11it/s] 16%|█▌        | 79/500 [01:08<02:28,  2.83it/s] 16%|█▌        | 81/500 [01:15<08:33,  1.23s/it] 17%|█▋        | 83/500 [01:15<06:06,  1.14it/s] 17%|█▋        | 85/500 [01:15<04:26,  1.56it/s] 17%|█▋        | 87/500 [01:15<03:16,  2.10it/s] 18%|█▊        | 89/500 [01:15<02:27,  2.79it/s] 18%|█▊        | 91/500 [01:22<08:23,  1.23s/it] 18%|█▊        | 92/500 [01:22<07:01,  1.03s/it] 19%|█▉        | 94/500 [01:22<04:50,  1.40it/s] 19%|█▉        | 96/500 [01:22<03:26,  1.96it/s] 20%|█▉        | 98/500 [01:23<02:29,  2.68it/s] 20%|██        | 100/500 [01:23<01:50,  3.61it/s] 20%|██        | 102/500 [01:29<07:38,  1.15s/it] 21%|██        | 104/500 [01:29<05:24,  1.22it/s] 21%|██        | 106/500 [01:29<03:52,  1.69it/s] 22%|██▏       | 108/500 [01:29<02:49,  2.31it/s] 22%|██▏       | 110/500 [01:29<02:05,  3.11it/s] 22%|██▏       | 112/500 [01:36<07:48,  1.21s/it] 23%|██▎       | 114/500 [01:36<05:36,  1.15it/s] 23%|██▎       | 116/500 [01:36<04:03,  1.58it/s] 24%|██▎       | 118/500 [01:36<02:56,  2.16it/s] 24%|██▍       | 120/500 [01:37<02:10,  2.91it/s] 24%|██▍       | 122/500 [01:43<07:39,  1.22s/it] 25%|██▍       | 124/500 [01:43<05:27,  1.15it/s] 25%|██▌       | 126/500 [01:43<03:55,  1.59it/s] 26%|██▌       | 128/500 [01:44<02:50,  2.18it/s] 26%|██▌       | 130/500 [01:44<02:06,  2.93it/s] 26%|██▋       | 132/500 [01:50<07:27,  1.22s/it] 27%|██▋       | 134/500 [01:50<05:20,  1.14it/s] 27%|██▋       | 136/500 [01:50<03:51,  1.57it/s]0.001464385655708611
Valid Loss:  0.001656502136029303
Epoch:  69  	Training Loss: 0.0014356824103742838
Test Loss:  0.0014611206715926528
Valid Loss:  0.001656512962654233
Epoch:  70  	Training Loss: 0.0014353821752592921
Test Loss:  0.001458978746086359
Valid Loss:  0.0016560191288590431
Epoch:  71  	Training Loss: 0.0014351331628859043
Test Loss:  0.0014569733757525682
Valid Loss:  0.0016553077148273587
Epoch:  72  	Training Loss: 0.0014349198900163174
Test Loss:  0.0014553951332345605
Valid Loss:  0.0016520402859896421
Epoch:  73  	Training Loss: 0.0014327531680464745
Test Loss:  0.0014535258524119854
Valid Loss:  0.0016495630843564868
Epoch:  74  	Training Loss: 0.001431382610462606
Test Loss:  0.0014515455113723874
Valid Loss:  0.001647471566684544
Epoch:  75  	Training Loss: 0.0014305266086012125
Test Loss:  0.0014496722724288702
Valid Loss:  0.0016454431461170316
Epoch:  76  	Training Loss: 0.0014298800379037857
Test Loss:  0.001448090304620564
Valid Loss:  0.0016433880664408207
Epoch:  77  	Training Loss: 0.0014293421991169453
Test Loss:  0.0014466543216258287
Valid Loss:  0.0016413514968007803
Epoch:  78  	Training Loss: 0.0014289014507085085
Test Loss:  0.0014451993629336357
Valid Loss:  0.001639342401176691
Epoch:  79  	Training Loss: 0.0014285760698840022
Test Loss:  0.0014439739752560854
Valid Loss:  0.0016373202670365572
Epoch:  80  	Training Loss: 0.0014282879419624805
Test Loss:  0.0014427566202357411
Valid Loss:  0.0016353505197912455
Epoch:  81  	Training Loss: 0.0014280593022704124
Test Loss:  0.0014416368212550879
Valid Loss:  0.001633410225622356
Epoch:  82  	Training Loss: 0.0014278637245297432
Test Loss:  0.0014397883787751198
Valid Loss:  0.001628856174647808
Epoch:  83  	Training Loss: 0.0014212732203304768
Test Loss:  0.0014358765911310911
Valid Loss:  0.0016247164458036423
Epoch:  84  	Training Loss: 0.0014144920278340578
Test Loss:  0.001431475393474102
Valid Loss:  0.0016203977866098285
Epoch:  85  	Training Loss: 0.001407621894031763
Test Loss:  0.001426749862730503
Valid Loss:  0.0016159641090780497
Epoch:  86  	Training Loss: 0.001400606008246541
Test Loss:  0.0014217684511095285
Valid Loss:  0.0016115024918690324
Epoch:  87  	Training Loss: 0.0013936436735093594
Test Loss:  0.001417133491486311
Valid Loss:  0.0016070192214101553
Epoch:  88  	Training Loss: 0.0013867730740457773
Test Loss:  0.0014116413658484817
Valid Loss:  0.0016026149969547987
Epoch:  89  	Training Loss: 0.0013800235465168953
Test Loss:  0.0014067369047552347
Valid Loss:  0.0015981246251612902
Epoch:  90  	Training Loss: 0.0013734367676079273
Test Loss:  0.0014016469940543175
Valid Loss:  0.001593678374774754
Epoch:  91  	Training Loss: 0.00136702717281878
Test Loss:  0.0013965503312647343
Valid Loss:  0.0015892607625573874
Epoch:  92  	Training Loss: 0.0013609162997454405
Test Loss:  0.0013934201560914516
Valid Loss:  0.001587186474353075
Epoch:  93  	Training Loss: 0.0013599961530417204
Test Loss:  0.0013910168781876564
Valid Loss:  0.0015847779577597976
Epoch:  94  	Training Loss: 0.0013591843890026212
Test Loss:  0.001389045501127839
Valid Loss:  0.0015822574496269226
Epoch:  95  	Training Loss: 0.0013584326952695847
Test Loss:  0.0013873405987396836
Valid Loss:  0.0015797305386513472
Epoch:  96  	Training Loss: 0.0013577609788626432
Test Loss:  0.0013858082238584757
Valid Loss:  0.0015772435581311584
Epoch:  97  	Training Loss: 0.00135712674818933
Test Loss:  0.0013843595515936613
Valid Loss:  0.0015748180449008942
Epoch:  98  	Training Loss: 0.0013565090484917164
Test Loss:  0.0013830101815983653
Valid Loss:  0.0015725040575489402
Epoch:  99  	Training Loss: 0.0013559410581365228
Test Loss:  0.0013817239087074995
Valid Loss:  0.0015702822711318731
Epoch:  100  	Training Loss: 0.0013554326724261045
Test Loss:  0.0013804746558889747
Valid Loss:  0.001568144652992487
Epoch:  101  	Training Loss: 0.0013549807481467724
Test Loss:  0.0013792794197797775
Valid Loss:  0.001566105056554079
Epoch:  102  	Training Loss: 0.0013545616529881954
Test Loss:  0.0013796633575111628
Valid Loss:  0.0015573720447719097
Epoch:  103  	Training Loss: 0.0013438647147268057
Test Loss:  0.0013716696994379163
Valid Loss:  0.001555944443680346
Epoch:  104  	Training Loss: 0.0013404230121523142
Test Loss:  0.0013675144873559475
Valid Loss:  0.0015542209148406982
Epoch:  105  	Training Loss: 0.0013385815545916557
Test Loss:  0.0013638004893437028
Valid Loss:  0.0015522880712524056
Epoch:  106  	Training Loss: 0.0013374581467360258
Test Loss:  0.0013597020879387856
Valid Loss:  0.0015499350847676396
Epoch:  107  	Training Loss: 0.0013364640763029456
Test Loss:  0.0013577989302575588
Valid Loss:  0.0015469779027625918
Epoch:  108  	Training Loss: 0.001335506560280919
Test Loss:  0.0013556539779528975
Valid Loss:  0.0015441486611962318
Epoch:  109  	Training Loss: 0.0013345754705369473
Test Loss:  0.0013536745682358742
Valid Loss:  0.0015413316432386637
Epoch:  110  	Training Loss: 0.0013336788397282362
Test Loss:  0.001351729268208146
Valid Loss:  0.0015385536244139075
Epoch:  111  	Training Loss: 0.0013328087516129017
Test Loss:  0.0013505720999091864
Valid Loss:  0.001535948133096099
Epoch:  112  	Training Loss: 0.0013319600839167833
Test Loss:  0.001341714058071375
Valid Loss:  0.0015304058324545622
Epoch:  113  	Training Loss: 0.0013158891815692186
Test Loss:  0.001336675719358027
Valid Loss:  0.0015292020980268717
Epoch:  114  	Training Loss: 0.0013125427067279816
Test Loss:  0.001332476851530373
Valid Loss:  0.001527725369669497
Epoch:  115  	Training Loss: 0.0013101068325340748
Test Loss:  0.0013309656642377377
Valid Loss:  0.001526065170764923
Epoch:  116  	Training Loss: 0.0013078951742500067
Test Loss:  0.001328818965703249
Valid Loss:  0.0015242930967360735
Epoch:  117  	Training Loss: 0.0013057319447398186
Test Loss:  0.001327605452388525
Valid Loss:  0.001522398553788662
Epoch:  118  	Training Loss: 0.00130376685410738
Test Loss:  0.001326850731857121
Valid Loss:  0.0015205082017928362
Epoch:  119  	Training Loss: 0.001302078366279602
Test Loss:  0.001326399389654398
Valid Loss:  0.0015186493983492255
Epoch:  120  	Training Loss: 0.0013005062937736511
Test Loss:  0.0013261643471196294
Valid Loss:  0.0015168101526796818
Epoch:  121  	Training Loss: 0.0012989502865821123
Test Loss:  0.0013261591084301472
Valid Loss:  0.0015149987302720547
Epoch:  122  	Training Loss: 0.0012974754208698869
Test Loss:  0.0013311116490513086
Valid Loss:  0.0015030610375106335
Epoch:  123  	Training Loss: 0.001283730729483068
Test Loss:  0.0013182081747800112
Valid Loss:  0.0015002804575487971
Epoch:  124  	Training Loss: 0.0012723016552627087
Test Loss:  0.001308562932536006
Valid Loss:  0.0014957666862756014
Epoch:  125  	Training Loss: 0.0012618936598300934
Test Loss:  0.0012990351533517241
Valid Loss:  0.0014909744495525956
Epoch:  126  	Training Loss: 0.0012523876503109932
Test Loss:  0.0012906680349260569
Valid Loss:  0.0014853421598672867
Epoch:  127  	Training Loss: 0.001243301318027079
Test Loss:  0.0012829974293708801
Valid Loss:  0.0014793039299547672
Epoch:  128  	Training Loss: 0.0012345382710918784
Test Loss:  0.0012756698997691274
Valid Loss:  0.0014733070274814963
Epoch:  129  	Training Loss: 0.0012263430980965495
Test Loss:  0.0012685891706496477
Valid Loss:  0.0014671857934445143
Epoch:  130  	Training Loss: 0.0012185786617919803
Test Loss:  0.0012615658342838287
Valid Loss:  0.0014611869119107723
Epoch:  131  	Training Loss: 0.001211216440424323
Test Loss:  0.0012549518141895533
Valid Loss:  0.0014551131753250957
Epoch:  132  	Training Loss: 0.0012041120789945126
Test Loss:  0.0012534901034086943
Valid Loss:  0.0014518158277496696
Epoch:  133  	Training Loss: 0.0012011299841105938
Test Loss:  0.0012494364054873586
Valid Loss:  0.0014498650562018156
Epoch:  134  	Training Loss: 0.0011996058747172356
Test Loss:  0.0012461752630770206
Valid Loss:  0.0014475233620032668
Epoch:  135  	Training Loss: 0.0011984618613496423
Test Loss:  0.0012433751253411174
Valid Loss:  0.001444888999685645
Epoch:  136  	Training Loss: 0.0011976221576333046
Test Loss:  0.00123997638002038
Valid Loss:  0.0014420043444260955
Epoch:  137  	Training Loss: 0.0011970021296292543
 28%|██▊       | 138/500 [01:51<02:48,  2.15it/s] 28%|██▊       | 140/500 [01:51<02:04,  2.89it/s] 28%|██▊       | 142/500 [01:57<07:04,  1.19s/it] 29%|██▉       | 144/500 [01:57<05:02,  1.18it/s] 29%|██▉       | 146/500 [01:57<03:37,  1.63it/s] 30%|██▉       | 148/500 [01:57<02:38,  2.22it/s] 30%|███       | 150/500 [01:58<01:57,  2.98it/s] 30%|███       | 152/500 [02:04<07:02,  1.21s/it] 31%|███       | 154/500 [02:04<05:00,  1.15it/s] 31%|███       | 156/500 [02:04<03:36,  1.59it/s] 32%|███▏      | 158/500 [02:04<02:37,  2.18it/s] 32%|███▏      | 160/500 [02:05<01:56,  2.93it/s] 32%|███▏      | 162/500 [02:11<06:40,  1.19s/it] 33%|███▎      | 164/500 [02:11<04:45,  1.17it/s] 33%|███▎      | 166/500 [02:11<03:25,  1.62it/s] 34%|███▎      | 168/500 [02:11<02:30,  2.21it/s] 34%|███▍      | 170/500 [02:12<01:52,  2.92it/s] 34%|███▍      | 172/500 [02:18<06:44,  1.23s/it] 35%|███▍      | 174/500 [02:18<04:48,  1.13it/s] 35%|███▌      | 176/500 [02:18<03:26,  1.57it/s] 36%|███▌      | 178/500 [02:19<02:30,  2.14it/s] 36%|███▌      | 180/500 [02:19<01:50,  2.89it/s] 36%|███▋      | 182/500 [02:25<06:19,  1.19s/it] 37%|███▋      | 184/500 [02:25<04:30,  1.17it/s] 37%|███▋      | 186/500 [02:25<03:15,  1.60it/s] 38%|███▊      | 188/500 [02:25<02:24,  2.16it/s] 38%|███▊      | 190/500 [02:26<01:47,  2.89it/s] 38%|███▊      | 192/500 [02:32<06:10,  1.20s/it] 39%|███▉      | 194/500 [02:32<04:24,  1.16it/s] 39%|███▉      | 196/500 [02:32<03:10,  1.60it/s] 40%|███▉      | 198/500 [02:32<02:18,  2.18it/s] 40%|████      | 200/500 [02:33<01:42,  2.94it/s] 40%|████      | 202/500 [02:39<05:52,  1.18s/it] 41%|████      | 204/500 [02:39<04:11,  1.18it/s]Test Loss:  0.0012374392244964838
Valid Loss:  0.0014386833645403385
Epoch:  138  	Training Loss: 0.001196454861201346
Test Loss:  0.0012356018414720893
Valid Loss:  0.001435204641893506
Epoch:  139  	Training Loss: 0.0011959561379626393
Test Loss:  0.0012339309323579073
Valid Loss:  0.0014317849418148398
Epoch:  140  	Training Loss: 0.0011955040972679853
Test Loss:  0.0012323346454650164
Valid Loss:  0.0014284393982961774
Epoch:  141  	Training Loss: 0.001195102697238326
Test Loss:  0.0012310573365539312
Valid Loss:  0.0014251719694584608
Epoch:  142  	Training Loss: 0.0011947366874665022
Test Loss:  0.0012359372340142727
Valid Loss:  0.001417719409801066
Epoch:  143  	Training Loss: 0.0011872099712491035
Test Loss:  0.0012289849109947681
Valid Loss:  0.0014166283654049039
Epoch:  144  	Training Loss: 0.0011832955060526729
Test Loss:  0.00122176599688828
Valid Loss:  0.0014148387126624584
Epoch:  145  	Training Loss: 0.001180807244963944
Test Loss:  0.0012169722467660904
Valid Loss:  0.0014115524245426059
Epoch:  146  	Training Loss: 0.0011785831302404404
Test Loss:  0.0012131344992667437
Valid Loss:  0.0014077608939260244
Epoch:  147  	Training Loss: 0.0011764795053750277
Test Loss:  0.0012094939593225718
Valid Loss:  0.0014038307126611471
Epoch:  148  	Training Loss: 0.0011744620278477669
Test Loss:  0.0012058940483257174
Valid Loss:  0.0013997671194374561
Epoch:  149  	Training Loss: 0.0011725344229489565
Test Loss:  0.001202786574140191
Valid Loss:  0.001395577099174261
Epoch:  150  	Training Loss: 0.001170664792880416
Test Loss:  0.0011992529034614563
Valid Loss:  0.001391455065459013
Epoch:  151  	Training Loss: 0.0011688504600897431
Test Loss:  0.0011965625453740358
Valid Loss:  0.001387199154123664
Epoch:  152  	Training Loss: 0.0011670594103634357
Test Loss:  0.0011933124624192715
Valid Loss:  0.001381794223561883
Epoch:  153  	Training Loss: 0.0011634641559794545
Test Loss:  0.0011917173396795988
Valid Loss:  0.0013767381897196174
Epoch:  154  	Training Loss: 0.001160179846920073
Test Loss:  0.0011897401418536901
Valid Loss:  0.001372191938571632
Epoch:  155  	Training Loss: 0.0011569373309612274
Test Loss:  0.0011879745870828629
Valid Loss:  0.0013680430129170418
Epoch:  156  	Training Loss: 0.0011538367252796888
Test Loss:  0.00118719891179353
Valid Loss:  0.0013643730198964477
Epoch:  157  	Training Loss: 0.0011508085299283266
Test Loss:  0.001185681321658194
Valid Loss:  0.0013611851027235389
Epoch:  158  	Training Loss: 0.0011478160740807652
Test Loss:  0.0011841533705592155
Valid Loss:  0.0013583141844719648
Epoch:  159  	Training Loss: 0.0011448442237451673
Test Loss:  0.0011817377526313066
Valid Loss:  0.0013556197518482804
Epoch:  160  	Training Loss: 0.0011418911162763834
Test Loss:  0.001179670449346304
Valid Loss:  0.0013530096039175987
Epoch:  161  	Training Loss: 0.001138949883170426
Test Loss:  0.0011773711303249002
Valid Loss:  0.0013504906091839075
Epoch:  162  	Training Loss: 0.0011360215721651912
Test Loss:  0.0011722738854587078
Valid Loss:  0.0013486829120665789
Epoch:  163  	Training Loss: 0.0011325196828693151
Test Loss:  0.0011679923627525568
Valid Loss:  0.0013460991904139519
Epoch:  164  	Training Loss: 0.0011292451526969671
Test Loss:  0.0011636321432888508
Valid Loss:  0.001343081588856876
Epoch:  165  	Training Loss: 0.001126071554608643
Test Loss:  0.0011598232667893171
Valid Loss:  0.0013396720169112086
Epoch:  166  	Training Loss: 0.0011229398660361767
Test Loss:  0.0011558866826817393
Valid Loss:  0.0013360881712287664
Epoch:  167  	Training Loss: 0.0011198323918506503
Test Loss:  0.0011526349699124694
Valid Loss:  0.0013323139864951372
Epoch:  168  	Training Loss: 0.0011167353950440884
Test Loss:  0.001149241579696536
Valid Loss:  0.001328593585640192
Epoch:  169  	Training Loss: 0.0011136510875076056
Test Loss:  0.001146001392044127
Valid Loss:  0.0013248655013740063
Epoch:  170  	Training Loss: 0.0011105744633823633
Test Loss:  0.0011428134748712182
Valid Loss:  0.001321187475696206
Epoch:  171  	Training Loss: 0.0011075085494667292
Test Loss:  0.0011396313784644008
Valid Loss:  0.0013176251668483019
Epoch:  172  	Training Loss: 0.0011044604470953345
Test Loss:  0.001133510610088706
Valid Loss:  0.0013150540180504322
Epoch:  173  	Training Loss: 0.0011010020971298218
Test Loss:  0.0011303729843348265
Valid Loss:  0.001311340369284153
Epoch:  174  	Training Loss: 0.0010976013727486134
Test Loss:  0.0011266637593507767
Valid Loss:  0.0013077018084004521
Epoch:  175  	Training Loss: 0.00109423091635108
Test Loss:  0.0011232509277760983
Valid Loss:  0.0013040152844041586
Epoch:  176  	Training Loss: 0.0010908974800258875
Test Loss:  0.0011201330926269293
Valid Loss:  0.0013002713676542044
Epoch:  177  	Training Loss: 0.0010875908192247152
Test Loss:  0.0011165053583681583
Valid Loss:  0.0012966272188350558
Epoch:  178  	Training Loss: 0.0010843127965927124
Test Loss:  0.0011135695967823267
Valid Loss:  0.0012929844669997692
Epoch:  179  	Training Loss: 0.0010810538660734892
Test Loss:  0.0011104369768872857
Valid Loss:  0.0012893967796117067
Epoch:  180  	Training Loss: 0.0010778242722153664
Test Loss:  0.0011071475455537438
Valid Loss:  0.0012859688140451908
Epoch:  181  	Training Loss: 0.0010746128391474485
Test Loss:  0.0011036860523745418
Valid Loss:  0.0012824006844311953
Epoch:  182  	Training Loss: 0.00107141537591815
Test Loss:  0.001100332709029317
Valid Loss:  0.0012800270924344659
Epoch:  183  	Training Loss: 0.001068497309461236
Test Loss:  0.0010974864708259702
Valid Loss:  0.0012775982031598687
Epoch:  184  	Training Loss: 0.00106573267839849
Test Loss:  0.00109473941847682
Valid Loss:  0.0012752453330904245
Epoch:  185  	Training Loss: 0.0010632649064064026
Test Loss:  0.0010921286884695292
Valid Loss:  0.0012728264555335045
Epoch:  186  	Training Loss: 0.001060895505361259
Test Loss:  0.0010895966552197933
Valid Loss:  0.0012704632245004177
Epoch:  187  	Training Loss: 0.001058571389876306
Test Loss:  0.001087065553292632
Valid Loss:  0.001268182066269219
Epoch:  188  	Training Loss: 0.0010564140975475311
Test Loss:  0.0010845428332686424
Valid Loss:  0.001265933969989419
Epoch:  189  	Training Loss: 0.0010544676333665848
Test Loss:  0.0010822400217875838
Valid Loss:  0.0012636613100767136
Epoch:  190  	Training Loss: 0.0010526038240641356
Test Loss:  0.0010799865704029799
Valid Loss:  0.0012613810831680894
Epoch:  191  	Training Loss: 0.0010508062550798059
Test Loss:  0.0010778019204735756
Valid Loss:  0.00125909224152565
Epoch:  192  	Training Loss: 0.0010490196291357279
Test Loss:  0.0010754815302789211
Valid Loss:  0.001257268595509231
Epoch:  193  	Training Loss: 0.0010486480314284563
Test Loss:  0.001073908992111683
Valid Loss:  0.0012550720712170005
Epoch:  194  	Training Loss: 0.001048312522470951
Test Loss:  0.0010728688212111592
Valid Loss:  0.0012527795042842627
Epoch:  195  	Training Loss: 0.001048003789037466
Test Loss:  0.0010719449492171407
Valid Loss:  0.0012505841441452503
Epoch:  196  	Training Loss: 0.001047715893946588
Test Loss:  0.0010710542555898428
Valid Loss:  0.0012484944891184568
Epoch:  197  	Training Loss: 0.0010474568698555231
Test Loss:  0.0010700523853302002
Valid Loss:  0.0012464961037039757
Epoch:  198  	Training Loss: 0.001047224272042513
Test Loss:  0.0010692268842831254
Valid Loss:  0.0012445376487448812
Epoch:  199  	Training Loss: 0.0010470119304955006
Test Loss:  0.0010684709995985031
Valid Loss:  0.0012426658067852259
Epoch:  200  	Training Loss: 0.0010468203108757734
Test Loss:  0.0010677764657884836
Valid Loss:  0.001240892568603158
Epoch:  201  	Training Loss: 0.0010466366074979305
Test Loss:  0.001066975761204958
Valid Loss:  0.0012392029166221619
Epoch:  202  	Training Loss: 0.0010464638471603394
Test Loss:  0.0010670202318578959
Valid Loss:  0.0012376365484669805
Epoch:  203  	Training Loss: 0.0010435889707878232
Test Loss:  0.0010640111286193132
Valid Loss:  0.0012365547008812428
Epoch:  204  	Training Loss: 0.001040749717503786
Test Loss:  0.001062038354575634
Valid Loss:  0.00123525969684124
Epoch:  205  	Training Loss: 0.0010379289742559195
Test Loss:  0.0010596142383292317
Valid Loss:  0.0012339953100308776
 41%|████      | 206/500 [02:39<03:00,  1.63it/s] 42%|████▏     | 208/500 [02:39<02:11,  2.23it/s] 42%|████▏     | 210/500 [02:39<01:36,  2.99it/s] 42%|████▏     | 212/500 [02:46<05:42,  1.19s/it] 43%|████▎     | 214/500 [02:46<04:03,  1.17it/s] 43%|████▎     | 216/500 [02:46<02:55,  1.62it/s] 44%|████▎     | 218/500 [02:46<02:07,  2.22it/s] 44%|████▍     | 220/500 [02:46<01:34,  2.97it/s] 44%|████▍     | 222/500 [02:53<05:31,  1.19s/it] 45%|████▍     | 224/500 [02:53<03:56,  1.17it/s] 45%|████▌     | 226/500 [02:53<02:49,  1.62it/s] 46%|████▌     | 228/500 [02:53<02:03,  2.21it/s] 46%|████▌     | 230/500 [02:53<01:31,  2.96it/s] 46%|████▋     | 232/500 [03:00<05:22,  1.20s/it] 47%|████▋     | 234/500 [03:00<03:49,  1.16it/s] 47%|████▋     | 236/500 [03:00<02:44,  1.60it/s] 48%|████▊     | 238/500 [03:00<01:59,  2.19it/s] 48%|████▊     | 240/500 [03:00<01:28,  2.95it/s] 48%|████▊     | 242/500 [03:07<05:07,  1.19s/it] 49%|████▉     | 244/500 [03:07<03:38,  1.17it/s] 49%|████▉     | 246/500 [03:07<02:37,  1.62it/s] 50%|████▉     | 248/500 [03:07<01:54,  2.20it/s] 50%|█████     | 250/500 [03:07<01:24,  2.96it/s] 50%|█████     | 252/500 [03:13<04:54,  1.19s/it] 51%|█████     | 254/500 [03:14<03:29,  1.17it/s] 51%|█████     | 256/500 [03:14<02:31,  1.62it/s] 52%|█████▏    | 258/500 [03:14<01:50,  2.19it/s] 52%|█████▏    | 260/500 [03:14<01:23,  2.88it/s] 52%|█████▏    | 262/500 [03:20<04:45,  1.20s/it] 53%|█████▎    | 264/500 [03:21<03:23,  1.16it/s] 53%|█████▎    | 266/500 [03:21<02:25,  1.60it/s] 54%|█████▎    | 268/500 [03:21<01:45,  2.19it/s] 54%|█████▍    | 270/500 [03:21<01:17,  2.95it/s] 54%|█████▍    | 272/500 [03:27<04:35,  1.21s/it]Epoch:  206  	Training Loss: 0.001035129651427269
Test Loss:  0.0010576602071523666
Valid Loss:  0.00123267387971282
Epoch:  207  	Training Loss: 0.0010323519818484783
Test Loss:  0.0010551672894507647
Valid Loss:  0.0012313725892454386
Epoch:  208  	Training Loss: 0.0010295945685356855
Test Loss:  0.0010534195462241769
Valid Loss:  0.0012300218222662807
Epoch:  209  	Training Loss: 0.0010268550831824541
Test Loss:  0.0010505827376618981
Valid Loss:  0.0012287123827263713
Epoch:  210  	Training Loss: 0.0010241287527605891
Test Loss:  0.0010489290580153465
Valid Loss:  0.0012272772146388888
Epoch:  211  	Training Loss: 0.0010214245412498713
Test Loss:  0.0010459759505465627
Valid Loss:  0.0012258952483534813
Epoch:  212  	Training Loss: 0.0010187379084527493
Test Loss:  0.0010464442893862724
Valid Loss:  0.0012253333115950227
Epoch:  213  	Training Loss: 0.0010179474484175444
Test Loss:  0.0010442452039569616
Valid Loss:  0.0012252317974343896
Epoch:  214  	Training Loss: 0.0010174086783081293
Test Loss:  0.0010429366957396269
Valid Loss:  0.0012247683480381966
Epoch:  215  	Training Loss: 0.001016885624267161
Test Loss:  0.0010418244637548923
Valid Loss:  0.001224190928041935
Epoch:  216  	Training Loss: 0.0010163993574678898
Test Loss:  0.001040476723574102
Valid Loss:  0.0012235705507919192
Epoch:  217  	Training Loss: 0.0010159588418900967
Test Loss:  0.0010394477285444736
Valid Loss:  0.0012228081468492746
Epoch:  218  	Training Loss: 0.0010155497584491968
Test Loss:  0.0010379101149737835
Valid Loss:  0.001222002785652876
Epoch:  219  	Training Loss: 0.0010152059840038419
Test Loss:  0.0010370045201852918
Valid Loss:  0.0012209713459014893
Epoch:  220  	Training Loss: 0.001014878274872899
Test Loss:  0.0010359428124502301
Valid Loss:  0.0012199071934446692
Epoch:  221  	Training Loss: 0.0010145865380764008
Test Loss:  0.001035211025737226
Valid Loss:  0.001218765857629478
Epoch:  222  	Training Loss: 0.001014301902614534
Test Loss:  0.0010330546647310257
Valid Loss:  0.0012150914408266544
Epoch:  223  	Training Loss: 0.0010096575133502483
Test Loss:  0.0010308821219950914
Valid Loss:  0.0012117123696953058
Epoch:  224  	Training Loss: 0.0010054665617644787
Test Loss:  0.001028545550070703
Valid Loss:  0.0012085188645869493
Epoch:  225  	Training Loss: 0.0010015019215643406
Test Loss:  0.0010260861599817872
Valid Loss:  0.0012055092956870794
Epoch:  226  	Training Loss: 0.0009977563749998808
Test Loss:  0.0010239825351163745
Valid Loss:  0.0012027764460071921
Epoch:  227  	Training Loss: 0.000994622241705656
Test Loss:  0.0010217679664492607
Valid Loss:  0.0012001906288787723
Epoch:  228  	Training Loss: 0.0009917396819218993
Test Loss:  0.001019761897623539
Valid Loss:  0.0011976729147136211
Epoch:  229  	Training Loss: 0.0009889695793390274
Test Loss:  0.0010176467476412654
Valid Loss:  0.001195212360471487
Epoch:  230  	Training Loss: 0.0009862843435257673
Test Loss:  0.0010155183263123035
Valid Loss:  0.0011927580926567316
Epoch:  231  	Training Loss: 0.0009836644167080522
Test Loss:  0.0010135604534298182
Valid Loss:  0.001190328854136169
Epoch:  232  	Training Loss: 0.0009810992050915956
Test Loss:  0.0010115865152329206
Valid Loss:  0.0011858277721330523
Epoch:  233  	Training Loss: 0.0009768364252522588
Test Loss:  0.0010086091933771968
Valid Loss:  0.001181981642730534
Epoch:  234  	Training Loss: 0.0009730614838190377
Test Loss:  0.0010056772734969854
Valid Loss:  0.001178364735096693
Epoch:  235  	Training Loss: 0.0009694548789411783
Test Loss:  0.0010027125244960189
Valid Loss:  0.001174864824861288
Epoch:  236  	Training Loss: 0.0009659782517701387
Test Loss:  0.0009998393943533301
Valid Loss:  0.001171459211036563
Epoch:  237  	Training Loss: 0.0009625977254472673
Test Loss:  0.0009970017708837986
Valid Loss:  0.0011681105243042111
Epoch:  238  	Training Loss: 0.0009592807618901134
Test Loss:  0.000994149362668395
Valid Loss:  0.0011647982755675912
Epoch:  239  	Training Loss: 0.0009559999452903867
Test Loss:  0.0009914262918755412
Valid Loss:  0.0011615058174356818
Epoch:  240  	Training Loss: 0.000952760805375874
Test Loss:  0.0009887268533930182
Valid Loss:  0.0011583110317587852
Epoch:  241  	Training Loss: 0.0009496188722550869
Test Loss:  0.0009860279969871044
Valid Loss:  0.0011551714269444346
Epoch:  242  	Training Loss: 0.0009465634357184172
Test Loss:  0.0009845932945609093
Valid Loss:  0.0011524339206516743
Epoch:  243  	Training Loss: 0.0009447960765101016
Test Loss:  0.0009820414707064629
Valid Loss:  0.0011503469431772828
Epoch:  244  	Training Loss: 0.000943515042308718
Test Loss:  0.0009796640370041132
Valid Loss:  0.0011482426198199391
Epoch:  245  	Training Loss: 0.000942436046898365
Test Loss:  0.0009772651828825474
Valid Loss:  0.0011460697278380394
Epoch:  246  	Training Loss: 0.0009415719541721046
Test Loss:  0.0009754652855917811
Valid Loss:  0.0011437649372965097
Epoch:  247  	Training Loss: 0.0009408215992152691
Test Loss:  0.0009730862802825868
Valid Loss:  0.0011414596810936928
Epoch:  248  	Training Loss: 0.0009402561699971557
Test Loss:  0.0009710827725939453
Valid Loss:  0.0011389832943677902
Epoch:  249  	Training Loss: 0.0009397699614055455
Test Loss:  0.000969289627391845
Valid Loss:  0.0011364738456904888
Epoch:  250  	Training Loss: 0.0009393317741341889
Test Loss:  0.0009677871130406857
Valid Loss:  0.0011339625343680382
Epoch:  251  	Training Loss: 0.0009389318292960525
Test Loss:  0.0009664412937127054
Valid Loss:  0.0011315171141177416
Epoch:  252  	Training Loss: 0.0009385613957419991
Test Loss:  0.0009666252881288528
Valid Loss:  0.0011290325783193111
Epoch:  253  	Training Loss: 0.0009362181299366057
Test Loss:  0.0009652316221036017
Valid Loss:  0.0011274395510554314
Epoch:  254  	Training Loss: 0.0009342409903183579
Test Loss:  0.0009632536093704402
Valid Loss:  0.00112604396417737
Epoch:  255  	Training Loss: 0.0009327692678198218
Test Loss:  0.0009600664488971233
Valid Loss:  0.001124527771025896
Epoch:  256  	Training Loss: 0.0009316122159361839
Test Loss:  0.0009582036873325706
Valid Loss:  0.0011224854970350862
Epoch:  257  	Training Loss: 0.0009305287967436016
Test Loss:  0.0009566709632053971
Valid Loss:  0.0011203925823792815
Epoch:  258  	Training Loss: 0.0009295297786593437
Test Loss:  0.0009552728151902556
Valid Loss:  0.0011183526366949081
Epoch:  259  	Training Loss: 0.0009285921696573496
Test Loss:  0.0009536941070109606
Valid Loss:  0.001116370316594839
Epoch:  260  	Training Loss: 0.0009277132339775562
Test Loss:  0.0009524027118459344
Valid Loss:  0.0011143656447529793
Epoch:  261  	Training Loss: 0.0009269301081076264
Test Loss:  0.0009506386704742908
Valid Loss:  0.0011124145239591599
Epoch:  262  	Training Loss: 0.0009262149687856436
Test Loss:  0.0009470646036788821
Valid Loss:  0.0011114501394331455
Epoch:  263  	Training Loss: 0.0009225002722814679
Test Loss:  0.0009441904840059578
Valid Loss:  0.0011103907600045204
Epoch:  264  	Training Loss: 0.0009190835407935083
Test Loss:  0.0009414525702595711
Valid Loss:  0.0011093495413661003
Epoch:  265  	Training Loss: 0.0009159462642855942
Test Loss:  0.0009385508019477129
Valid Loss:  0.0011082555865868926
Epoch:  266  	Training Loss: 0.0009129983955062926
Test Loss:  0.000936357828322798
Valid Loss:  0.001107015646994114
Epoch:  267  	Training Loss: 0.0009102452313527465
Test Loss:  0.0009334573987871408
Valid Loss:  0.0011057532392442226
Epoch:  268  	Training Loss: 0.0009076515561901033
Test Loss:  0.0009310822933912277
Valid Loss:  0.0011042486876249313
Epoch:  269  	Training Loss: 0.0009051223751157522
Test Loss:  0.0009285970591008663
Valid Loss:  0.00110263517126441
Epoch:  270  	Training Loss: 0.0009026734624058008
Test Loss:  0.0009271369781345129
Valid Loss:  0.0011009470326825976
Epoch:  271  	Training Loss: 0.0009002878796309233
Test Loss:  0.0009248985443264246
Valid Loss:  0.0010993748437613249
Epoch:  272  	Training Loss: 0.000897927675396204
Test Loss:  0.0009238073253072798
Valid Loss:  0.0010957499034702778
Epoch:  273  	Training Loss: 0.0008942054118961096
Test Loss:  0.0009229329880326986
Valid Loss:  0.0010925090173259377
Epoch:  274  	Training Loss: 0.0008908885065466166
Test Loss:   55%|█████▍    | 274/500 [03:28<03:15,  1.16it/s] 55%|█████▌    | 276/500 [03:28<02:20,  1.60it/s] 56%|█████▌    | 278/500 [03:28<01:41,  2.18it/s] 56%|█████▌    | 280/500 [03:28<01:15,  2.93it/s] 56%|█████▋    | 282/500 [03:35<04:26,  1.22s/it] 57%|█████▋    | 284/500 [03:35<03:10,  1.13it/s] 57%|█████▋    | 286/500 [03:35<02:17,  1.55it/s] 58%|█████▊    | 288/500 [03:35<01:41,  2.10it/s] 58%|█████▊    | 290/500 [03:35<01:14,  2.80it/s] 58%|█████▊    | 292/500 [03:42<04:18,  1.24s/it] 59%|█████▉    | 294/500 [03:42<03:03,  1.12it/s] 59%|█████▉    | 296/500 [03:42<02:11,  1.55it/s] 60%|█████▉    | 298/500 [03:42<01:35,  2.12it/s] 60%|██████    | 300/500 [03:42<01:10,  2.86it/s] 60%|██████    | 302/500 [03:49<04:04,  1.23s/it] 61%|██████    | 304/500 [03:49<02:53,  1.13it/s] 61%|██████    | 306/500 [03:49<02:03,  1.57it/s] 62%|██████▏   | 308/500 [03:49<01:29,  2.14it/s] 62%|██████▏   | 310/500 [03:50<01:05,  2.88it/s] 62%|██████▏   | 312/500 [03:56<03:48,  1.22s/it] 63%|██████▎   | 314/500 [03:56<02:42,  1.15it/s] 63%|██████▎   | 316/500 [03:56<01:55,  1.59it/s] 64%|██████▎   | 318/500 [03:56<01:23,  2.17it/s] 64%|██████▍   | 320/500 [03:57<01:01,  2.92it/s] 64%|██████▍   | 322/500 [04:03<03:30,  1.18s/it] 65%|██████▍   | 324/500 [04:03<02:30,  1.17it/s] 65%|██████▌   | 326/500 [04:03<01:48,  1.60it/s] 66%|██████▌   | 328/500 [04:03<01:19,  2.17it/s] 66%|██████▌   | 330/500 [04:04<00:58,  2.92it/s] 66%|██████▋   | 332/500 [04:10<03:20,  1.20s/it] 67%|██████▋   | 334/500 [04:10<02:22,  1.16it/s] 67%|██████▋   | 336/500 [04:10<01:42,  1.60it/s] 68%|██████▊   | 338/500 [04:10<01:14,  2.19it/s] 68%|██████▊   | 340/500 [04:10<00:54,  2.93it/s] 68%|██████▊   | 342/500 [04:17<03:08,  1.19s/it]0.0009219772182404995
Valid Loss:  0.001089553814381361
Epoch:  275  	Training Loss: 0.0008878507651388645
Test Loss:  0.0009208415867760777
Valid Loss:  0.0010867646196857095
Epoch:  276  	Training Loss: 0.0008848594734445214
Test Loss:  0.0009195727179758251
Valid Loss:  0.001084117335267365
Epoch:  277  	Training Loss: 0.0008819632930681109
Test Loss:  0.0009182385983876884
Valid Loss:  0.001081601600162685
Epoch:  278  	Training Loss: 0.000879177765455097
Test Loss:  0.000917149125598371
Valid Loss:  0.0010792035609483719
Epoch:  279  	Training Loss: 0.000876427220646292
Test Loss:  0.0009159294422715902
Valid Loss:  0.001076901564374566
Epoch:  280  	Training Loss: 0.0008737400639802217
Test Loss:  0.0009145766962319613
Valid Loss:  0.0010746752377599478
Epoch:  281  	Training Loss: 0.0008710905094631016
Test Loss:  0.0009131619008257985
Valid Loss:  0.0010724990861490369
Epoch:  282  	Training Loss: 0.0008684630738571286
Test Loss:  0.0009102568728849292
Valid Loss:  0.0010725150350481272
Epoch:  283  	Training Loss: 0.0008680945029482245
Test Loss:  0.000908017042092979
Valid Loss:  0.00107223866507411
Epoch:  284  	Training Loss: 0.0008677937439642847
Test Loss:  0.0009063048055395484
Valid Loss:  0.0010717486729845405
Epoch:  285  	Training Loss: 0.0008675227290950716
Test Loss:  0.0009049485670402646
Valid Loss:  0.0010711078066378832
Epoch:  286  	Training Loss: 0.0008672716794535518
Test Loss:  0.0009038667194545269
Valid Loss:  0.0010703635634854436
Epoch:  287  	Training Loss: 0.0008670309907756746
Test Loss:  0.0009029892389662564
Valid Loss:  0.0010695484234020114
Epoch:  288  	Training Loss: 0.0008667981019243598
Test Loss:  0.0009022103622555733
Valid Loss:  0.0010686882305890322
Epoch:  289  	Training Loss: 0.0008665950153954327
Test Loss:  0.0009014838142320514
Valid Loss:  0.0010678026592358947
Epoch:  290  	Training Loss: 0.0008664124761708081
Test Loss:  0.0009008639608509839
Valid Loss:  0.0010668905451893806
Epoch:  291  	Training Loss: 0.0008662353502586484
Test Loss:  0.0009003006853163242
Valid Loss:  0.0010659662075340748
Epoch:  292  	Training Loss: 0.0008660670137032866
Test Loss:  0.0008978190599009395
Valid Loss:  0.0010633986676111817
Epoch:  293  	Training Loss: 0.0008633870165795088
Test Loss:  0.0008955997182056308
Valid Loss:  0.0010608588345348835
Epoch:  294  	Training Loss: 0.0008608733769506216
Test Loss:  0.0008936903905123472
Valid Loss:  0.0010583963012322783
Epoch:  295  	Training Loss: 0.0008584515890106559
Test Loss:  0.000891810399480164
Valid Loss:  0.0010559604270383716
Epoch:  296  	Training Loss: 0.0008561101858504117
Test Loss:  0.0008901000255718827
Valid Loss:  0.0010535629699006677
Epoch:  297  	Training Loss: 0.0008538140682503581
Test Loss:  0.0008884971612133086
Valid Loss:  0.0010512196458876133
Epoch:  298  	Training Loss: 0.0008515871013514698
Test Loss:  0.0008869480807334185
Valid Loss:  0.0010489103151485324
Epoch:  299  	Training Loss: 0.0008494047215208411
Test Loss:  0.0008854101761244237
Valid Loss:  0.001046640332788229
Epoch:  300  	Training Loss: 0.0008472901536151767
Test Loss:  0.0008840163936838508
Valid Loss:  0.0010444469517096877
Epoch:  301  	Training Loss: 0.0008453130722045898
Test Loss:  0.0008826813427731395
Valid Loss:  0.0010423350613564253
Epoch:  302  	Training Loss: 0.0008433807524852455
Test Loss:  0.0008852372993715107
Valid Loss:  0.0010401031468063593
Epoch:  303  	Training Loss: 0.0008417874341830611
Test Loss:  0.0008849616278894246
Valid Loss:  0.0010390256065875292
Epoch:  304  	Training Loss: 0.0008404718828387558
Test Loss:  0.0008837314671836793
Valid Loss:  0.001038288464769721
Epoch:  305  	Training Loss: 0.0008392863092012703
Test Loss:  0.0008822583477012813
Valid Loss:  0.0010376095306128263
Epoch:  306  	Training Loss: 0.0008381594670936465
Test Loss:  0.00088070600759238
Valid Loss:  0.0010368961375206709
Epoch:  307  	Training Loss: 0.0008370667928829789
Test Loss:  0.0008793746819719672
Valid Loss:  0.0010361254680901766
Epoch:  308  	Training Loss: 0.0008359944331459701
Test Loss:  0.0008779959753155708
Valid Loss:  0.0010352993849664927
Epoch:  309  	Training Loss: 0.0008349713170900941
Test Loss:  0.0008764712838456035
Valid Loss:  0.0010344028705731034
Epoch:  310  	Training Loss: 0.0008340738713741302
Test Loss:  0.0008742606150917709
Valid Loss:  0.0010333687532693148
Epoch:  311  	Training Loss: 0.0008333681616932154
Test Loss:  0.0008725532679818571
Valid Loss:  0.001032101223245263
Epoch:  312  	Training Loss: 0.000832741498015821
Test Loss:  0.0008707382949069142
Valid Loss:  0.0010315978433936834
Epoch:  313  	Training Loss: 0.0008321030181832612
Test Loss:  0.0008693083073012531
Valid Loss:  0.001030924846418202
Epoch:  314  	Training Loss: 0.000831476179882884
Test Loss:  0.0008680321625433862
Valid Loss:  0.0010301582515239716
Epoch:  315  	Training Loss: 0.000830864708404988
Test Loss:  0.0008668424561619759
Valid Loss:  0.0010293376399204135
Epoch:  316  	Training Loss: 0.000830270117148757
Test Loss:  0.0008654961711727083
Valid Loss:  0.0010284781455993652
Epoch:  317  	Training Loss: 0.0008297256426885724
Test Loss:  0.0008643310284242034
Valid Loss:  0.0010275370441377163
Epoch:  318  	Training Loss: 0.0008292075362987816
Test Loss:  0.0008632142562419176
Valid Loss:  0.0010265508899465203
Epoch:  319  	Training Loss: 0.0008287177188321948
Test Loss:  0.000862176064401865
Valid Loss:  0.001025536796078086
Epoch:  320  	Training Loss: 0.0008282515336759388
Test Loss:  0.0008609851356595755
Valid Loss:  0.0010244871955364943
Epoch:  321  	Training Loss: 0.0008278306340798736
Test Loss:  0.0008597751730121672
Valid Loss:  0.0010233739158138633
Epoch:  322  	Training Loss: 0.0008274296997115016
Test Loss:  0.0008598536951467395
Valid Loss:  0.001021333271637559
Epoch:  323  	Training Loss: 0.0008271592669188976
Test Loss:  0.000859789433889091
Valid Loss:  0.0010195006616413593
Epoch:  324  	Training Loss: 0.0008269029203802347
Test Loss:  0.0008596111438237131
Valid Loss:  0.0010178376687690616
Epoch:  325  	Training Loss: 0.0008266572840511799
Test Loss:  0.0008593456586822867
Valid Loss:  0.0010163113474845886
Epoch:  326  	Training Loss: 0.0008264197967946529
Test Loss:  0.0008590202196501195
Valid Loss:  0.0010148963192477822
Epoch:  327  	Training Loss: 0.0008261885377578437
Test Loss:  0.0008586463518440723
Valid Loss:  0.0010135734919458628
Epoch:  328  	Training Loss: 0.0008259640890173614
Test Loss:  0.000858236278872937
Valid Loss:  0.0010123323881998658
Epoch:  329  	Training Loss: 0.0008257454028353095
Test Loss:  0.0008577955886721611
Valid Loss:  0.001011160435155034
Epoch:  330  	Training Loss: 0.0008255339926108718
Test Loss:  0.0008573358063586056
Valid Loss:  0.0010100426152348518
Epoch:  331  	Training Loss: 0.0008253284031525254
Test Loss:  0.0008568669436499476
Valid Loss:  0.0010089767165482044
Epoch:  332  	Training Loss: 0.000825127586722374
Test Loss:  0.0008525193552486598
Valid Loss:  0.0010069952113553882
Epoch:  333  	Training Loss: 0.0008226084755733609
Test Loss:  0.0008503988501615822
Valid Loss:  0.0010043727234005928
Epoch:  334  	Training Loss: 0.0008202475728467107
Test Loss:  0.0008484577992931008
Valid Loss:  0.0010017689783126116
Epoch:  335  	Training Loss: 0.0008179032593034208
Test Loss:  0.0008464741404168308
Valid Loss:  0.0009992176201194525
Epoch:  336  	Training Loss: 0.0008155795512720942
Test Loss:  0.0008446588180959225
Valid Loss:  0.000996701419353485
Epoch:  337  	Training Loss: 0.0008133006049320102
Test Loss:  0.0008430411107838154
Valid Loss:  0.000994275906123221
Epoch:  338  	Training Loss: 0.0008110377239063382
Test Loss:  0.0008412080351263285
Valid Loss:  0.0009919797303155065
Epoch:  339  	Training Loss: 0.0008087888127192855
Test Loss:  0.000839133863337338
Valid Loss:  0.0009897083509713411
Epoch:  340  	Training Loss: 0.0008065566071309149
Test Loss:  0.0008374663884751499
Valid Loss:  0.0009874310344457626
Epoch:  341  	Training Loss: 0.0008043439593166113
Test Loss:  0.0008355360478162766
Valid Loss:  0.0009852397488430142
Epoch:  342  	Training Loss: 0.0008021451067179441
Test Loss:  0.0008318245527334511
Valid Loss:  0.0009827923495322466
 69%|██████▉   | 344/500 [04:17<02:13,  1.17it/s] 69%|██████▉   | 346/500 [04:17<01:35,  1.62it/s] 70%|██████▉   | 348/500 [04:17<01:08,  2.21it/s] 70%|███████   | 350/500 [04:17<00:50,  2.97it/s] 70%|███████   | 352/500 [04:24<02:55,  1.18s/it] 71%|███████   | 354/500 [04:24<02:03,  1.18it/s] 71%|███████   | 356/500 [04:24<01:28,  1.63it/s] 72%|███████▏  | 358/500 [04:24<01:03,  2.23it/s] 72%|███████▏  | 360/500 [04:24<00:46,  2.99it/s] 72%|███████▏  | 362/500 [04:31<02:50,  1.24s/it] 73%|███████▎  | 364/500 [04:31<02:00,  1.13it/s] 73%|███████▎  | 366/500 [04:31<01:25,  1.56it/s] 74%|███████▎  | 368/500 [04:31<01:01,  2.14it/s] 74%|███████▍  | 370/500 [04:31<00:45,  2.88it/s] 74%|███████▍  | 372/500 [04:38<02:35,  1.21s/it] 75%|███████▍  | 374/500 [04:38<01:49,  1.15it/s] 75%|███████▌  | 376/500 [04:38<01:17,  1.59it/s] 76%|███████▌  | 378/500 [04:38<00:56,  2.18it/s] 76%|███████▌  | 380/500 [04:38<00:40,  2.93it/s] 76%|███████▋  | 382/500 [04:45<02:23,  1.22s/it] 77%|███████▋  | 384/500 [04:45<01:41,  1.15it/s] 77%|███████▋  | 386/500 [04:45<01:11,  1.59it/s] 78%|███████▊  | 388/500 [04:45<00:51,  2.17it/s] 78%|███████▊  | 390/500 [04:45<00:37,  2.92it/s] 78%|███████▊  | 392/500 [04:52<02:09,  1.20s/it] 79%|███████▉  | 394/500 [04:52<01:31,  1.16it/s] 79%|███████▉  | 396/500 [04:52<01:04,  1.60it/s] 80%|███████▉  | 398/500 [04:52<00:46,  2.19it/s] 80%|████████  | 400/500 [04:52<00:34,  2.94it/s] 80%|████████  | 402/500 [04:59<01:56,  1.19s/it] 81%|████████  | 404/500 [04:59<01:22,  1.16it/s] 81%|████████  | 406/500 [04:59<00:59,  1.59it/s] 82%|████████▏ | 408/500 [04:59<00:42,  2.15it/s] 82%|████████▏ | 410/500 [04:59<00:31,  2.84it/s]Epoch:  343  	Training Loss: 0.0007964791147969663
Test Loss:  0.0008275564759969711
Valid Loss:  0.0009808412287384272
Epoch:  344  	Training Loss: 0.0007918886840343475
Test Loss:  0.0008234361885115504
Valid Loss:  0.0009791126940399408
Epoch:  345  	Training Loss: 0.0007885061204433441
Test Loss:  0.0008197752176783979
Valid Loss:  0.0009773453930392861
Epoch:  346  	Training Loss: 0.0007857077289372683
Test Loss:  0.0008164423052221537
Valid Loss:  0.0009754067286849022
Epoch:  347  	Training Loss: 0.000783198862336576
Test Loss:  0.0008137560216709971
Valid Loss:  0.000973269809037447
Epoch:  348  	Training Loss: 0.0007808437803760171
Test Loss:  0.0008113340591080487
Valid Loss:  0.0009710216545499861
Epoch:  349  	Training Loss: 0.000778611225541681
Test Loss:  0.0008090739138424397
Valid Loss:  0.0009686967823654413
Epoch:  350  	Training Loss: 0.0007765388581901789
Test Loss:  0.000807348929811269
Valid Loss:  0.0009662929223850369
Epoch:  351  	Training Loss: 0.0007744909962639213
Test Loss:  0.0008055382058955729
Valid Loss:  0.0009639247437007725
Epoch:  352  	Training Loss: 0.0007726167095825076
Test Loss:  0.0008065578294917941
Valid Loss:  0.00096088059945032
Epoch:  353  	Training Loss: 0.0007724396418780088
Test Loss:  0.000807307893410325
Valid Loss:  0.0009584082290530205
Epoch:  354  	Training Loss: 0.0007723105372861028
Test Loss:  0.0008078407263383269
Valid Loss:  0.000956373754888773
Epoch:  355  	Training Loss: 0.000772211467847228
Test Loss:  0.0008081946289166808
Valid Loss:  0.0009546850342303514
Epoch:  356  	Training Loss: 0.0007721299189142883
Test Loss:  0.0008084066212177277
Valid Loss:  0.0009532629628665745
Epoch:  357  	Training Loss: 0.0007720624562352896
Test Loss:  0.0008085058652795851
Valid Loss:  0.0009520553867332637
Epoch:  358  	Training Loss: 0.0007720038993284106
Test Loss:  0.0008085179142653942
Valid Loss:  0.0009510109084658325
Epoch:  359  	Training Loss: 0.0007719508139416575
Test Loss:  0.0008084567962214351
Valid Loss:  0.0009501007152721286
Epoch:  360  	Training Loss: 0.0007719023851677775
Test Loss:  0.000808345852419734
Valid Loss:  0.0009492994286119938
Epoch:  361  	Training Loss: 0.000771857681684196
Test Loss:  0.000808191136457026
Valid Loss:  0.0009485816117376089
Epoch:  362  	Training Loss: 0.000771815946791321
Test Loss:  0.0008020756067708135
Valid Loss:  0.0009500176529400051
Epoch:  363  	Training Loss: 0.0007709622150287032
Test Loss:  0.0007999932859092951
Valid Loss:  0.000949992798268795
Epoch:  364  	Training Loss: 0.0007702719885855913
Test Loss:  0.0007983621908351779
Valid Loss:  0.000949727138504386
Epoch:  365  	Training Loss: 0.0007696708780713379
Test Loss:  0.0007968681748025119
Valid Loss:  0.0009493159595876932
Epoch:  366  	Training Loss: 0.0007691509672440588
Test Loss:  0.0007953925523906946
Valid Loss:  0.0009487858624197543
Epoch:  367  	Training Loss: 0.0007686659810133278
Test Loss:  0.0007943661767058074
Valid Loss:  0.000948091153986752
Epoch:  368  	Training Loss: 0.0007682100404053926
Test Loss:  0.0007933643064461648
Valid Loss:  0.0009473891695961356
Epoch:  369  	Training Loss: 0.0007677953108213842
Test Loss:  0.0007924899109639227
Valid Loss:  0.0009466579067520797
Epoch:  370  	Training Loss: 0.0007673832005821168
Test Loss:  0.0007916259928606451
Valid Loss:  0.0009459283901378512
Epoch:  371  	Training Loss: 0.0007669717306271195
Test Loss:  0.0007907676626928151
Valid Loss:  0.0009452033555135131
Epoch:  372  	Training Loss: 0.0007665633456781507
Test Loss:  0.0007927907863631845
Valid Loss:  0.0009442443842999637
Epoch:  373  	Training Loss: 0.0007654544315300882
Test Loss:  0.0007931842701509595
Valid Loss:  0.0009438666747882962
Epoch:  374  	Training Loss: 0.0007645013392902911
Test Loss:  0.0007927658734843135
Valid Loss:  0.0009437247645109892
Epoch:  375  	Training Loss: 0.0007636104710400105
Test Loss:  0.0007919481722638011
Valid Loss:  0.0009436559630557895
Epoch:  376  	Training Loss: 0.0007627576123923063
Test Loss:  0.0007910036947578192
Valid Loss:  0.0009436006657779217
Epoch:  377  	Training Loss: 0.0007619366515427828
Test Loss:  0.0007899465272203088
Valid Loss:  0.0009435262181796134
Epoch:  378  	Training Loss: 0.000761185772716999
Test Loss:  0.0007886489620432258
Valid Loss:  0.0009433984523639083
Epoch:  379  	Training Loss: 0.0007605366408824921
Test Loss:  0.000786885037086904
Valid Loss:  0.0009431400103494525
Epoch:  380  	Training Loss: 0.0007600245298817754
Test Loss:  0.0007853439310565591
Valid Loss:  0.0009427146869711578
Epoch:  381  	Training Loss: 0.0007595701608806849
Test Loss:  0.0007839453173801303
Valid Loss:  0.0009421588038094342
Epoch:  382  	Training Loss: 0.000759151647798717
Test Loss:  0.0007787463837303221
Valid Loss:  0.0009409295744262636
Epoch:  383  	Training Loss: 0.0007569478475488722
Test Loss:  0.0007767018978483975
Valid Loss:  0.0009387902682647109
Epoch:  384  	Training Loss: 0.0007548510329797864
Test Loss:  0.0007754564867354929
Valid Loss:  0.0009366534068249166
Epoch:  385  	Training Loss: 0.0007528154528699815
Test Loss:  0.00077382120070979
Valid Loss:  0.0009346908191218972
Epoch:  386  	Training Loss: 0.000750791048631072
Test Loss:  0.0007720582070760429
Valid Loss:  0.0009327242150902748
Epoch:  387  	Training Loss: 0.0007487846305593848
Test Loss:  0.0007706586038693786
Valid Loss:  0.0009308239677920938
Epoch:  388  	Training Loss: 0.0007468093535862863
Test Loss:  0.0007691363571211696
Valid Loss:  0.0009290095185860991
Epoch:  389  	Training Loss: 0.0007448541582562029
Test Loss:  0.0007675044471397996
Valid Loss:  0.0009272908209823072
Epoch:  390  	Training Loss: 0.0007429098477587104
Test Loss:  0.0007657776586711407
Valid Loss:  0.0009255572804249823
Epoch:  391  	Training Loss: 0.0007409718236885965
Test Loss:  0.0007639228133484721
Valid Loss:  0.0009238450438715518
Epoch:  392  	Training Loss: 0.0007390414248220623
Test Loss:  0.0007615401409566402
Valid Loss:  0.000922362320125103
Epoch:  393  	Training Loss: 0.0007382292533293366
Test Loss:  0.0007605357095599174
Valid Loss:  0.0009205287788063288
Epoch:  394  	Training Loss: 0.0007374424603767693
Test Loss:  0.0007594466442242265
Valid Loss:  0.0009188011754304171
Epoch:  395  	Training Loss: 0.0007366632926277816
Test Loss:  0.0007583503611385822
Valid Loss:  0.0009171442361548543
Epoch:  396  	Training Loss: 0.0007358896546065807
Test Loss:  0.0007572501199319959
Valid Loss:  0.000915538752451539
Epoch:  397  	Training Loss: 0.0007351217791438103
Test Loss:  0.0007561723468825221
Valid Loss:  0.0009139837929978967
Epoch:  398  	Training Loss: 0.0007343581528402865
Test Loss:  0.0007550982991233468
Valid Loss:  0.0009124771459028125
Epoch:  399  	Training Loss: 0.0007336025591939688
Test Loss:  0.0007540010847151279
Valid Loss:  0.0009110100800171494
Epoch:  400  	Training Loss: 0.0007328604115173221
Test Loss:  0.0007528612622991204
Valid Loss:  0.0009095618152059615
Epoch:  401  	Training Loss: 0.0007321233861148357
Test Loss:  0.0007519327336922288
Valid Loss:  0.0009081291500478983
Epoch:  402  	Training Loss: 0.0007313932292163372
Test Loss:  0.0007508803973905742
Valid Loss:  0.0009059349540621042
Epoch:  403  	Training Loss: 0.0007302762242034078
Test Loss:  0.000750223349314183
Valid Loss:  0.0009039233555085957
Epoch:  404  	Training Loss: 0.0007293429225683212
Test Loss:  0.0007493168814107776
Valid Loss:  0.0009020424331538379
Epoch:  405  	Training Loss: 0.0007285166066139936
Test Loss:  0.0007487109978683293
Valid Loss:  0.0009003067389130592
Epoch:  406  	Training Loss: 0.0007278345292434096
Test Loss:  0.0007480254280380905
Valid Loss:  0.0008986782049760222
Epoch:  407  	Training Loss: 0.0007271673530340195
Test Loss:  0.0007474210578948259
Valid Loss:  0.0008971244096755981
Epoch:  408  	Training Loss: 0.0007265155436471105
Test Loss:  0.0007468946278095245
Valid Loss:  0.0008956566452980042
Epoch:  409  	Training Loss: 0.0007259061676450074
Test Loss:  0.000746404635719955
Valid Loss:  0.000894280441571027
Epoch:  410  	Training Loss: 0.0007253509829752147
Test Loss:  0.0007459488697350025
Valid Loss:  0.0008929897448979318
Epoch:  411  	Training Loss: 0.0007248179754242301
 82%|████████▏ | 412/500 [05:06<01:46,  1.21s/it] 83%|████████▎ | 414/500 [05:06<01:14,  1.15it/s] 83%|████████▎ | 416/500 [05:06<00:52,  1.59it/s] 84%|████████▎ | 418/500 [05:06<00:38,  2.16it/s] 84%|████████▍ | 420/500 [05:07<00:27,  2.86it/s] 84%|████████▍ | 422/500 [05:13<01:33,  1.20s/it] 85%|████████▍ | 424/500 [05:13<01:05,  1.16it/s] 85%|████████▌ | 426/500 [05:13<00:46,  1.60it/s] 86%|████████▌ | 428/500 [05:13<00:32,  2.19it/s] 86%|████████▌ | 430/500 [05:13<00:23,  2.95it/s] 86%|████████▋ | 432/500 [05:20<01:21,  1.19s/it] 87%|████████▋ | 434/500 [05:20<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:20<00:39,  1.61it/s] 88%|████████▊ | 438/500 [05:20<00:28,  2.20it/s] 88%|████████▊ | 440/500 [05:20<00:20,  2.96it/s] 88%|████████▊ | 442/500 [05:27<01:10,  1.22s/it] 89%|████████▉ | 444/500 [05:27<00:49,  1.14it/s] 89%|████████▉ | 446/500 [05:27<00:34,  1.58it/s] 90%|████████▉ | 448/500 [05:27<00:24,  2.16it/s] 90%|█████████ | 450/500 [05:27<00:17,  2.90it/s] 90%|█████████ | 452/500 [05:34<00:58,  1.21s/it] 91%|█████████ | 454/500 [05:34<00:40,  1.14it/s] 91%|█████████ | 456/500 [05:34<00:28,  1.57it/s] 92%|█████████▏| 458/500 [05:34<00:19,  2.13it/s] 92%|█████████▏| 460/500 [05:35<00:14,  2.82it/s] 92%|█████████▏| 462/500 [05:41<00:45,  1.21s/it] 93%|█████████▎| 464/500 [05:41<00:31,  1.15it/s] 93%|█████████▎| 466/500 [05:41<00:21,  1.57it/s] 94%|█████████▎| 468/500 [05:42<00:15,  2.13it/s] 94%|█████████▍| 470/500 [05:42<00:10,  2.86it/s] 94%|█████████▍| 472/500 [05:48<00:34,  1.23s/it] 95%|█████████▍| 474/500 [05:48<00:22,  1.13it/s] 95%|█████████▌| 476/500 [05:49<00:15,  1.55it/s] 96%|█████████▌| 478/500 [05:49<00:10,  2.11it/s]Test Loss:  0.0007455135346390307
Valid Loss:  0.0008917711093090475
Epoch:  412  	Training Loss: 0.0007242962019518018
Test Loss:  0.0007450454868376255
Valid Loss:  0.0008912341436371207
Epoch:  413  	Training Loss: 0.0007222320418804884
Test Loss:  0.0007428440731018782
Valid Loss:  0.0008909575408324599
Epoch:  414  	Training Loss: 0.0007202255073934793
Test Loss:  0.000741048192139715
Valid Loss:  0.0008905403083190322
Epoch:  415  	Training Loss: 0.0007182483095675707
Test Loss:  0.0007393094711005688
Valid Loss:  0.0008900688262656331
Epoch:  416  	Training Loss: 0.0007163129630498588
Test Loss:  0.0007375390268862247
Valid Loss:  0.0008895451901480556
Epoch:  417  	Training Loss: 0.00071441795444116
Test Loss:  0.0007358985021710396
Valid Loss:  0.0008889525197446346
Epoch:  418  	Training Loss: 0.0007125443080440164
Test Loss:  0.0007342977914959192
Valid Loss:  0.0008883215487003326
Epoch:  419  	Training Loss: 0.0007106912089511752
Test Loss:  0.0007327029597945511
Valid Loss:  0.0008876537904143333
Epoch:  420  	Training Loss: 0.000708859646692872
Test Loss:  0.0007311257068067789
Valid Loss:  0.0008869438315741718
Epoch:  421  	Training Loss: 0.0007070517167448997
Test Loss:  0.0007297866977751255
Valid Loss:  0.0008862153626978397
Epoch:  422  	Training Loss: 0.0007052639266476035
Test Loss:  0.0007310428190976381
Valid Loss:  0.000883630127646029
Epoch:  423  	Training Loss: 0.0007035991875454783
Test Loss:  0.0007289787172339857
Valid Loss:  0.0008820859366096556
Epoch:  424  	Training Loss: 0.0007020733319222927
Test Loss:  0.0007271765498444438
Valid Loss:  0.0008803950622677803
Epoch:  425  	Training Loss: 0.0007005962543189526
Test Loss:  0.0007253400981426239
Valid Loss:  0.0008786868420429528
Epoch:  426  	Training Loss: 0.0006991499685682356
Test Loss:  0.0007233131909742951
Valid Loss:  0.0008769692503847182
Epoch:  427  	Training Loss: 0.0006977380253374577
Test Loss:  0.000721597985830158
Valid Loss:  0.000875102705322206
Epoch:  428  	Training Loss: 0.0006963342311792076
Test Loss:  0.0007198015227913857
Valid Loss:  0.0008732958813197911
Epoch:  429  	Training Loss: 0.0006949426606297493
Test Loss:  0.000718217808753252
Valid Loss:  0.0008714199648238719
Epoch:  430  	Training Loss: 0.0006935678538866341
Test Loss:  0.0007161620305851102
Valid Loss:  0.0008695569704286754
Epoch:  431  	Training Loss: 0.0006922236643731594
Test Loss:  0.0007145570125430822
Valid Loss:  0.0008676373981870711
Epoch:  432  	Training Loss: 0.000690885994117707
Test Loss:  0.0007133384933695197
Valid Loss:  0.0008648402290418744
Epoch:  433  	Training Loss: 0.0006884821923449636
Test Loss:  0.0007119760266505182
Valid Loss:  0.0008622331661172211
Epoch:  434  	Training Loss: 0.0006861233850941062
Test Loss:  0.0007107111159712076
Valid Loss:  0.0008597992127761245
Epoch:  435  	Training Loss: 0.0006838192930445075
Test Loss:  0.0007092890446074307
Valid Loss:  0.0008575000683777034
Epoch:  436  	Training Loss: 0.0006815358065068722
Test Loss:  0.0007077456102706492
Valid Loss:  0.0008552951621823013
Epoch:  437  	Training Loss: 0.0006792803178541362
Test Loss:  0.0007061618962325156
Valid Loss:  0.0008531550411134958
Epoch:  438  	Training Loss: 0.0006770442705601454
Test Loss:  0.0007045711390674114
Valid Loss:  0.0008510713814757764
Epoch:  439  	Training Loss: 0.0006748299347236753
Test Loss:  0.0007031650748103857
Valid Loss:  0.0008490656036883593
Epoch:  440  	Training Loss: 0.0006726703140884638
Test Loss:  0.0007018707692623138
Valid Loss:  0.0008471575565636158
Epoch:  441  	Training Loss: 0.0006705539999529719
Test Loss:  0.0007003875216469169
Valid Loss:  0.0008453155751340091
Epoch:  442  	Training Loss: 0.0006684637628495693
Test Loss:  0.0006993787246756256
Valid Loss:  0.0008448524749837816
Epoch:  443  	Training Loss: 0.0006678845384158194
Test Loss:  0.0006980997277423739
Valid Loss:  0.0008443835540674627
Epoch:  444  	Training Loss: 0.0006673673633486032
Test Loss:  0.0006967143854126334
Valid Loss:  0.0008438251097686589
Epoch:  445  	Training Loss: 0.0006668956484645605
Test Loss:  0.0006953358533792198
Valid Loss:  0.0008431498426944017
Epoch:  446  	Training Loss: 0.0006664597312919796
Test Loss:  0.0006941282190382481
Valid Loss:  0.0008423870895057917
Epoch:  447  	Training Loss: 0.0006660339422523975
Test Loss:  0.0006930357776582241
Valid Loss:  0.0008415790507569909
Epoch:  448  	Training Loss: 0.0006656139739789069
Test Loss:  0.0006919937441125512
Valid Loss:  0.0008407396962866187
Epoch:  449  	Training Loss: 0.0006652012816630304
Test Loss:  0.000691013119649142
Valid Loss:  0.0008398594800382853
Epoch:  450  	Training Loss: 0.0006648111157119274
Test Loss:  0.0006900395383127034
Valid Loss:  0.0008389975409954786
Epoch:  451  	Training Loss: 0.0006644288077950478
Test Loss:  0.000689101405441761
Valid Loss:  0.0008380875224247575
Epoch:  452  	Training Loss: 0.0006640563369728625
Test Loss:  0.0006881598965264857
Valid Loss:  0.0008353884331882
Epoch:  453  	Training Loss: 0.0006622379878535867
Test Loss:  0.0006872799131087959
Valid Loss:  0.0008328963303938508
Epoch:  454  	Training Loss: 0.0006604518857784569
Test Loss:  0.000686453131493181
Valid Loss:  0.000830593635328114
Epoch:  455  	Training Loss: 0.0006586952949874103
Test Loss:  0.0006855543470010161
Valid Loss:  0.0008284533978439867
Epoch:  456  	Training Loss: 0.0006570483092218637
Test Loss:  0.0006847443291917443
Valid Loss:  0.0008264894131571054
Epoch:  457  	Training Loss: 0.0006555829895660281
Test Loss:  0.0006838977569714189
Valid Loss:  0.0008246738580055535
Epoch:  458  	Training Loss: 0.0006542136543430388
Test Loss:  0.0006830366910435259
Valid Loss:  0.000822966918349266
Epoch:  459  	Training Loss: 0.0006528841331601143
Test Loss:  0.0006821983843110502
Valid Loss:  0.0008213723776862025
Epoch:  460  	Training Loss: 0.0006515964632853866
Test Loss:  0.0006814670050516725
Valid Loss:  0.0008198650320991874
Epoch:  461  	Training Loss: 0.0006503222975879908
Test Loss:  0.000680669560097158
Valid Loss:  0.0008184185717254877
Epoch:  462  	Training Loss: 0.0006490621599368751
Test Loss:  0.0006761284312233329
Valid Loss:  0.0008179671131074429
Epoch:  463  	Training Loss: 0.0006479618605226278
Test Loss:  0.0006736383074894547
Valid Loss:  0.0008166985353454947
Epoch:  464  	Training Loss: 0.0006470998050644994
Test Loss:  0.0006720596575178206
Valid Loss:  0.0008150922949425876
Epoch:  465  	Training Loss: 0.0006463326280936599
Test Loss:  0.0006709960289299488
Valid Loss:  0.0008134293602779508
Epoch:  466  	Training Loss: 0.0006457068957388401
Test Loss:  0.0006701828679069877
Valid Loss:  0.0008117994293570518
Epoch:  467  	Training Loss: 0.0006451111403293908
Test Loss:  0.0006695100455544889
Valid Loss:  0.0008102370775304735
Epoch:  468  	Training Loss: 0.0006445301696658134
Test Loss:  0.000668922089971602
Valid Loss:  0.0008087485330179334
Epoch:  469  	Training Loss: 0.000643970153760165
Test Loss:  0.0006684146355837584
Valid Loss:  0.0008073480566963553
Epoch:  470  	Training Loss: 0.0006434484967030585
Test Loss:  0.0006679430953226984
Valid Loss:  0.0008060409454628825
Epoch:  471  	Training Loss: 0.0006429834757000208
Test Loss:  0.0006675058975815773
Valid Loss:  0.0008048140443861485
Epoch:  472  	Training Loss: 0.0006425447063520551
Test Loss:  0.0006701465463265777
Valid Loss:  0.0008041966357268393
Epoch:  473  	Training Loss: 0.0006414138479158282
Test Loss:  0.0006707941647619009
Valid Loss:  0.000804274866823107
Epoch:  474  	Training Loss: 0.000640510581433773
Test Loss:  0.000670440262183547
Valid Loss:  0.0008045693393796682
Epoch:  475  	Training Loss: 0.0006397140095941722
Test Loss:  0.000669485074467957
Valid Loss:  0.0008048766176216304
Epoch:  476  	Training Loss: 0.0006390224443748593
Test Loss:  0.0006682739476673305
Valid Loss:  0.0008050864562392235
Epoch:  477  	Training Loss: 0.0006384440348483622
Test Loss:  0.0006668518763035536
Valid Loss:  0.0008051490294747055
Epoch:  478  	Training Loss: 0.0006379596889019012
Test Loss:  0.0006655308534391224
Valid Loss:  0.0008050463511608541
Epoch:  479  	Training Loss: 0.0006375295342877507
Test Loss:  0.0006642757798545063
Valid Loss:   96%|█████████▌| 480/500 [05:49<00:07,  2.85it/s] 96%|█████████▋| 482/500 [05:56<00:22,  1.26s/it] 97%|█████████▋| 484/500 [05:56<00:14,  1.10it/s] 97%|█████████▋| 486/500 [05:56<00:09,  1.52it/s] 98%|█████████▊| 488/500 [05:56<00:05,  2.07it/s] 98%|█████████▊| 490/500 [05:56<00:03,  2.80it/s] 98%|█████████▊| 492/500 [06:03<00:09,  1.20s/it] 99%|█████████▉| 494/500 [06:03<00:05,  1.15it/s] 99%|█████████▉| 496/500 [06:03<00:02,  1.58it/s]100%|█████████▉| 498/500 [06:03<00:00,  2.13it/s]100%|██████████| 500/500 [06:03<00:00,  2.81it/s]100%|██████████| 500/500 [06:03<00:00,  1.37it/s]
0.0008048007148317993
Epoch:  480  	Training Loss: 0.0006371277268044651
Test Loss:  0.0006632182630710304
Valid Loss:  0.0008044368587434292
Epoch:  481  	Training Loss: 0.0006367363384924829
Test Loss:  0.0006622630171477795
Valid Loss:  0.0008039992535486817
Epoch:  482  	Training Loss: 0.0006363506545312703
Test Loss:  0.0006587511161342263
Valid Loss:  0.0008036366780288517
Epoch:  483  	Training Loss: 0.0006345015717670321
Test Loss:  0.0006563913193531334
Valid Loss:  0.0008030559401959181
Epoch:  484  	Training Loss: 0.000632710347417742
Test Loss:  0.000654617790132761
Valid Loss:  0.0008023533155210316
Epoch:  485  	Training Loss: 0.0006309435120783746
Test Loss:  0.0006531435064971447
Valid Loss:  0.0008015799685381353
Epoch:  486  	Training Loss: 0.0006291961180977523
Test Loss:  0.0006518199807032943
Valid Loss:  0.000800770241767168
Epoch:  487  	Training Loss: 0.0006274626357480884
Test Loss:  0.0006505956407636404
Valid Loss:  0.0007999418303370476
Epoch:  488  	Training Loss: 0.0006257521454244852
Test Loss:  0.000649579509627074
Valid Loss:  0.0007991202874109149
Epoch:  489  	Training Loss: 0.0006240627262741327
Test Loss:  0.0006484912591986358
Valid Loss:  0.000798306311480701
Epoch:  490  	Training Loss: 0.0006223901291377842
Test Loss:  0.0006475222180597484
Valid Loss:  0.0007975201006047428
Epoch:  491  	Training Loss: 0.0006207351107150316
Test Loss:  0.0006464467151090503
Valid Loss:  0.0007967501296661794
Epoch:  492  	Training Loss: 0.0006190941203385592
Test Loss:  0.0006450735963881016
Valid Loss:  0.0007946669356897473
Epoch:  493  	Training Loss: 0.0006169424159452319
Test Loss:  0.0006437042029574513
Valid Loss:  0.0007926376420073211
Epoch:  494  	Training Loss: 0.0006148298271000385
Test Loss:  0.0006424906896427274
Valid Loss:  0.0007906797109171748
Epoch:  495  	Training Loss: 0.0006127711967565119
Test Loss:  0.0006411448121070862
Valid Loss:  0.0007887883111834526
Epoch:  496  	Training Loss: 0.0006107364315539598
Test Loss:  0.0006397797842510045
Valid Loss:  0.0007869362598285079
Epoch:  497  	Training Loss: 0.0006087250076234341
Test Loss:  0.0006384148728102446
Valid Loss:  0.0007851131958886981
Epoch:  498  	Training Loss: 0.0006067316862754524
Test Loss:  0.0006372270872816443
Valid Loss:  0.0007833307608962059
Epoch:  499  	Training Loss: 0.000604756292887032
Test Loss:  0.0006357901729643345
Valid Loss:  0.0007815725402906537
Epoch:  500  	Training Loss: 0.0006028093048371375
Test Loss:  0.0006344225257635117
Valid Loss:  0.0007798174046911299
seed is  8
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:40, 12.18it/s]  1%|          | 4/500 [00:00<00:40, 12.22it/s]  1%|          | 6/500 [00:00<00:40, 12.28it/s]  2%|▏         | 8/500 [00:00<00:39, 12.32it/s]  2%|▏         | 10/500 [00:00<00:39, 12.28it/s]  2%|▏         | 12/500 [00:00<00:40, 12.19it/s]  3%|▎         | 14/500 [00:01<00:39, 12.31it/s]  3%|▎         | 16/500 [00:01<00:36, 13.33it/s]  4%|▎         | 18/500 [00:01<00:34, 14.14it/s]  4%|▍         | 20/500 [00:01<00:32, 14.73it/s]  4%|▍         | 22/500 [00:01<00:31, 15.08it/s]  5%|▍         | 24/500 [00:01<00:30, 15.46it/s]  5%|▌         | 26/500 [00:01<00:30, 15.71it/s]  6%|▌         | 28/500 [00:02<00:30, 15.65it/s]  6%|▌         | 30/500 [00:02<00:29, 15.85it/s]  6%|▋         | 32/500 [00:02<00:29, 15.90it/s]  7%|▋         | 34/500 [00:02<00:28, 16.08it/s]  7%|▋         | 36/500 [00:02<00:28, 16.14it/s]  8%|▊         | 38/500 [00:02<00:28, 16.14it/s]  8%|▊         | 40/500 [00:02<00:28, 16.19it/s]  8%|▊         | 42/500 [00:02<00:28, 16.19it/s]  9%|▉         | 44/500 [00:02<00:28, 16.20it/s]  9%|▉         | 46/500 [00:03<00:27, 16.27it/s] 10%|▉         | 48/500 [00:03<00:27, 16.33it/s] 10%|█         | 50/500 [00:03<00:27, 16.32it/s] 10%|█         | 52/500 [00:03<00:27, 16.19it/s] 11%|█         | 54/500 [00:03<00:27, 16.24it/s] 11%|█         | 56/500 [00:03<00:27, 16.25it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.29it/s] 12%|█▏        | 60/500 [00:04<00:30, 14.28it/s] 12%|█▏        | 62/500 [00:04<00:32, 13.64it/s] 13%|█▎        | 64/500 [00:04<00:32, 13.23it/s] 13%|█▎        | 66/500 [00:04<00:33, 12.96it/s] 14%|█▎        | 68/500 [00:04<00:33, 12.75it/s] 14%|█▍        | 70/500 [00:04<00:33, 12.65it/s] 14%|█▍        | 72/500 [00:05<00:34, 12.56it/s] 15%|█▍        | 74/500 [00:05<00:34, 12.49it/s] 15%|█▌        | 76/500 [00:05<00:34, 12.45it/s] 16%|█▌        | 78/500 [00:05<00:33, 12.50it/s] 16%|█▌        | 80/500 [00:05<00:31, 13.43it/s] 16%|█▋        | 82/500 [00:05<00:29, 14.18it/s] 17%|█▋        | 84/500 [00:05<00:28, 14.70it/s] 17%|█▋        | 86/500 [00:05<00:27, 14.95it/s] 18%|█▊        | 88/500 [00:06<00:26, 15.28it/s] 18%|█▊        | 90/500 [00:06<00:26, 15.57it/s] 18%|█▊        | 92/500 [00:06<00:25, 15.82it/s] 19%|█▉        | 94/500 [00:06<00:25, 16.02it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.17it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.31it/s] 20%|██        | 100/500 [00:06<00:24, 16.31it/s] 20%|██        | 102/500 [00:06<00:24, 16.16it/s] 21%|██        | 104/500 [00:07<00:24, 16.16it/s] 21%|██        | 106/500 [00:07<00:24, 16.15it/s] 22%|██▏       | 108/500 [00:07<00:24, 16.13it/s] 22%|██▏       | 110/500 [00:07<00:24, 16.17it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.17it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.11it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.18it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.15it/s] 24%|██▍       | 120/500 [00:08<00:23, 16.25it/s] 24%|██▍       | 122/500 [00:08<00:23, 16.27it/s]Epoch:  1  	Training Loss: 0.029436573386192322
Test Loss:  2.5333800315856934
Valid Loss:  2.593545436859131
Epoch:  2  	Training Loss: 2.7875542640686035
Test Loss:  60507.2265625
Valid Loss:  59082.90625
Epoch:  3  	Training Loss: 58584.140625
Test Loss:  2.036160257767345e+23
Valid Loss:  1.999470692611053e+23
Epoch:  4  	Training Loss: 2.0040270744260564e+23
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
 25%|██▍       | 124/500 [00:08<00:23, 16.16it/s] 25%|██▌       | 126/500 [00:08<00:23, 16.26it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.26it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.13it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.14it/s] 27%|██▋       | 134/500 [00:08<00:22, 15.99it/s] 27%|██▋       | 136/500 [00:09<00:22, 16.00it/s] 28%|██▊       | 138/500 [00:09<00:22, 16.09it/s] 28%|██▊       | 140/500 [00:09<00:22, 16.06it/s] 28%|██▊       | 142/500 [00:09<00:22, 16.06it/s] 29%|██▉       | 144/500 [00:09<00:22, 16.08it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.19it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.83it/s] 30%|███       | 150/500 [00:09<00:21, 15.95it/s] 30%|███       | 152/500 [00:10<00:21, 16.06it/s] 31%|███       | 154/500 [00:10<00:21, 16.14it/s] 31%|███       | 156/500 [00:10<00:21, 16.10it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.17it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.14it/s] 32%|███▏      | 162/500 [00:10<00:21, 16.00it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.09it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.15it/s] 34%|███▎      | 168/500 [00:11<00:20, 16.23it/s] 34%|███▍      | 170/500 [00:11<00:20, 16.24it/s] 34%|███▍      | 172/500 [00:11<00:20, 16.33it/s] 35%|███▍      | 174/500 [00:11<00:19, 16.34it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.38it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.19it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.26it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.45it/s] 37%|███▋      | 184/500 [00:12<00:22, 14.36it/s] 37%|███▋      | 186/500 [00:12<00:22, 13.69it/s] 38%|███▊      | 188/500 [00:12<00:23, 13.27it/s] 38%|███▊      | 190/500 [00:12<00:23, 13.00it/s] 38%|███▊      | 192/500 [00:12<00:24, 12.79it/s] 39%|███▉      | 194/500 [00:12<00:24, 12.64it/s] 39%|███▉      | 196/500 [00:13<00:24, 12.48it/s] 40%|███▉      | 198/500 [00:13<00:24, 12.38it/s] 40%|████      | 200/500 [00:13<00:24, 12.38it/s] 40%|████      | 202/500 [00:13<00:24, 12.39it/s] 41%|████      | 204/500 [00:13<00:23, 12.39it/s] 41%|████      | 206/500 [00:13<00:22, 12.96it/s] 42%|████▏     | 208/500 [00:13<00:21, 13.83it/s] 42%|████▏     | 210/500 [00:14<00:20, 14.49it/s] 42%|████▏     | 212/500 [00:14<00:19, 14.88it/s] 43%|████▎     | 214/500 [00:14<00:18, 15.24it/s] 43%|████▎     | 216/500 [00:14<00:18, 15.51it/s] 44%|████▎     | 218/500 [00:14<00:17, 15.74it/s] 44%|████▍     | 220/500 [00:14<00:17, 15.89it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.82it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.74it/s] 45%|████▌     | 226/500 [00:15<00:17, 15.87it/s] 46%|████▌     | 228/500 [00:15<00:17, 15.89it/s] 46%|████▌     | 230/500 [00:15<00:16, 15.98it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.11it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.00it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.07it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.84it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.70it/s] 48%|████▊     | 242/500 [00:16<00:16, 15.81it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.82it/s] 49%|████▉     | 246/500 [00:16<00:15, 15.94it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
 50%|████▉     | 248/500 [00:16<00:15, 16.05it/s] 50%|█████     | 250/500 [00:16<00:15, 16.15it/s] 50%|█████     | 252/500 [00:16<00:15, 16.20it/s] 51%|█████     | 254/500 [00:16<00:15, 16.21it/s] 51%|█████     | 256/500 [00:16<00:15, 16.12it/s] 52%|█████▏    | 258/500 [00:17<00:15, 16.09it/s] 52%|█████▏    | 260/500 [00:17<00:14, 16.05it/s] 52%|█████▏    | 262/500 [00:17<00:14, 15.98it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.06it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.16it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.23it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.49it/s] 54%|█████▍    | 272/500 [00:17<00:14, 15.72it/s] 55%|█████▍    | 274/500 [00:18<00:14, 15.89it/s] 55%|█████▌    | 276/500 [00:18<00:13, 16.04it/s] 56%|█████▌    | 278/500 [00:18<00:13, 16.19it/s] 56%|█████▌    | 280/500 [00:18<00:13, 16.23it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.24it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.25it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.27it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.32it/s] 58%|█████▊    | 290/500 [00:19<00:12, 16.34it/s] 58%|█████▊    | 292/500 [00:19<00:12, 16.32it/s] 59%|█████▉    | 294/500 [00:19<00:12, 16.31it/s] 59%|█████▉    | 296/500 [00:19<00:12, 16.32it/s] 60%|█████▉    | 298/500 [00:19<00:12, 16.32it/s] 60%|██████    | 300/500 [00:19<00:12, 16.04it/s] 60%|██████    | 302/500 [00:19<00:12, 16.14it/s] 61%|██████    | 304/500 [00:19<00:12, 16.07it/s] 61%|██████    | 306/500 [00:20<00:12, 16.02it/s] 62%|██████▏   | 308/500 [00:20<00:11, 16.16it/s] 62%|██████▏   | 310/500 [00:20<00:11, 16.21it/s] 62%|██████▏   | 312/500 [00:20<00:11, 16.28it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.28it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.36it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.38it/s] 64%|██████▍   | 320/500 [00:20<00:10, 16.39it/s] 64%|██████▍   | 322/500 [00:21<00:10, 16.37it/s] 65%|██████▍   | 324/500 [00:21<00:10, 16.29it/s] 65%|██████▌   | 326/500 [00:21<00:10, 16.25it/s] 66%|██████▌   | 328/500 [00:21<00:10, 16.00it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.13it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.18it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.26it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.29it/s] 68%|██████▊   | 338/500 [00:22<00:10, 15.98it/s] 68%|██████▊   | 340/500 [00:22<00:09, 16.11it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.07it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.10it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.17it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.94it/s] 70%|███████   | 350/500 [00:22<00:09, 16.05it/s] 70%|███████   | 352/500 [00:22<00:09, 16.15it/s] 71%|███████   | 354/500 [00:23<00:09, 16.19it/s] 71%|███████   | 356/500 [00:23<00:08, 16.22it/s] 72%|███████▏  | 358/500 [00:23<00:08, 16.24it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.07it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.19it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.29it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.32it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.30it/s] 74%|███████▍  | 370/500 [00:24<00:07, 16.30it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
 74%|███████▍  | 372/500 [00:24<00:07, 16.25it/s] 75%|███████▍  | 374/500 [00:24<00:07, 16.26it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.28it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.32it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.29it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.31it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.34it/s] 77%|███████▋  | 386/500 [00:25<00:06, 16.41it/s] 78%|███████▊  | 388/500 [00:25<00:06, 16.35it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.37it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.34it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.35it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.37it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.38it/s] 80%|████████  | 400/500 [00:25<00:06, 16.39it/s] 80%|████████  | 402/500 [00:25<00:06, 16.33it/s] 81%|████████  | 404/500 [00:26<00:05, 16.33it/s] 81%|████████  | 406/500 [00:26<00:05, 16.34it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.36it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.33it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.38it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.38it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.24it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.26it/s] 84%|████████▍ | 420/500 [00:27<00:04, 16.37it/s] 84%|████████▍ | 422/500 [00:27<00:04, 16.15it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.97it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.13it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.13it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.17it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.23it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.29it/s] 87%|████████▋ | 436/500 [00:28<00:03, 16.28it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.27it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.17it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.13it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.15it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.16it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.21it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.27it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.27it/s] 91%|█████████ | 454/500 [00:29<00:02, 15.88it/s] 91%|█████████ | 456/500 [00:29<00:02, 15.95it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.95it/s] 92%|█████████▏| 460/500 [00:29<00:02, 16.10it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.19it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.25it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.35it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.32it/s] 94%|█████████▍| 470/500 [00:30<00:01, 16.35it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.25it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.23it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.26it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.27it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.27it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.26it/s] 97%|█████████▋| 484/500 [00:31<00:01, 15.30it/s] 97%|█████████▋| 486/500 [00:31<00:00, 15.14it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.53it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.66it/s] 98%|█████████▊| 492/500 [00:31<00:00, 15.79it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.61it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
 99%|█████████▉| 496/500 [00:31<00:00, 14.46it/s]100%|█████████▉| 498/500 [00:32<00:00, 13.77it/s]100%|██████████| 500/500 [00:32<00:00, 13.30it/s]100%|██████████| 500/500 [00:32<00:00, 15.53it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  8
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:28,  6.19s/it]  0%|          | 2/500 [00:06<21:38,  2.61s/it]  1%|          | 4/500 [00:06<08:29,  1.03s/it]  1%|          | 6/500 [00:06<04:47,  1.72it/s]  2%|▏         | 8/500 [00:06<03:08,  2.62it/s]  2%|▏         | 10/500 [00:06<02:14,  3.65it/s]  2%|▏         | 12/500 [00:13<10:28,  1.29s/it]  3%|▎         | 14/500 [00:13<07:10,  1.13it/s]  3%|▎         | 16/500 [00:13<05:01,  1.60it/s]  4%|▎         | 18/500 [00:13<03:36,  2.23it/s]  4%|▍         | 20/500 [00:13<02:38,  3.03it/s]  4%|▍         | 22/500 [00:20<09:45,  1.22s/it]  5%|▍         | 24/500 [00:20<06:58,  1.14it/s]  5%|▌         | 26/500 [00:20<05:02,  1.57it/s]  6%|▌         | 28/500 [00:20<03:42,  2.12it/s]  6%|▌         | 30/500 [00:21<02:46,  2.83it/s]  6%|▋         | 32/500 [00:27<09:32,  1.22s/it]  7%|▋         | 34/500 [00:27<06:50,  1.14it/s]  7%|▋         | 36/500 [00:27<04:57,  1.56it/s]  8%|▊         | 38/500 [00:28<03:39,  2.11it/s]  8%|▊         | 40/500 [00:28<02:44,  2.80it/s]  8%|▊         | 42/500 [00:34<09:15,  1.21s/it]  9%|▉         | 44/500 [00:34<06:38,  1.14it/s]  9%|▉         | 46/500 [00:35<04:49,  1.57it/s] 10%|▉         | 48/500 [00:35<03:33,  2.12it/s] 10%|█         | 50/500 [00:35<02:39,  2.81it/s] 10%|█         | 52/500 [00:41<09:01,  1.21s/it] 11%|█         | 54/500 [00:41<06:26,  1.15it/s] 11%|█         | 56/500 [00:42<04:37,  1.60it/s] 12%|█▏        | 58/500 [00:42<03:22,  2.18it/s] 12%|█▏        | 60/500 [00:42<02:29,  2.94it/s] 12%|█▏        | 62/500 [00:48<08:42,  1.19s/it] 13%|█▎        | 64/500 [00:48<06:12,  1.17it/s] 13%|█▎        | 66/500 [00:48<04:28,  1.62it/s] 14%|█▎        | 68/500 [00:49<03:15,  2.21it/s] 14%|█▍        | 70/500 [00:49<02:24,  2.98it/s]Epoch:  1  	Training Loss: 0.029436571523547173
Test Loss:  0.08507678657770157
Valid Loss:  0.09598872065544128
Epoch:  2  	Training Loss: 0.07430452108383179
Test Loss:  3.6781795024871826
Valid Loss:  3.3923428058624268
Epoch:  3  	Training Loss: 3.6998417377471924
Test Loss:  0.016517216339707375
Valid Loss:  0.02533463016152382
Epoch:  4  	Training Loss: 0.033868350088596344
Test Loss:  0.01653353124856949
Valid Loss:  0.025312907993793488
Epoch:  5  	Training Loss: 0.03378204256296158
Test Loss:  0.016500068828463554
Valid Loss:  0.02524065226316452
Epoch:  6  	Training Loss: 0.033675942569971085
Test Loss:  0.016456596553325653
Valid Loss:  0.02515963837504387
Epoch:  7  	Training Loss: 0.03357124328613281
Test Loss:  0.01646902784705162
Valid Loss:  0.025127755478024483
Epoch:  8  	Training Loss: 0.03348276764154434
Test Loss:  0.01641039550304413
Valid Loss:  0.025026962161064148
Epoch:  9  	Training Loss: 0.03335646912455559
Test Loss:  0.016362730413675308
Valid Loss:  0.02494361251592636
Epoch:  10  	Training Loss: 0.03324292227625847
Test Loss:  0.01632106676697731
Valid Loss:  0.02486620470881462
Epoch:  11  	Training Loss: 0.033121660351753235
Test Loss:  0.016273774206638336
Valid Loss:  0.024785568937659264
Epoch:  12  	Training Loss: 0.0329979732632637
Test Loss:  0.01620328798890114
Valid Loss:  0.024645987898111343
Epoch:  13  	Training Loss: 0.03277590125799179
Test Loss:  0.01616915874183178
Valid Loss:  0.02458462119102478
Epoch:  14  	Training Loss: 0.03269582241773605
Test Loss:  0.016135459765791893
Valid Loss:  0.024523695930838585
Epoch:  15  	Training Loss: 0.03261597827076912
Test Loss:  0.016101766377687454
Valid Loss:  0.024462856352329254
Epoch:  16  	Training Loss: 0.03253638744354248
Test Loss:  0.016068078577518463
Valid Loss:  0.024402109906077385
Epoch:  17  	Training Loss: 0.032457172870635986
Test Loss:  0.016033820807933807
Valid Loss:  0.024341512471437454
Epoch:  18  	Training Loss: 0.03238028287887573
Test Loss:  0.015999529510736465
Valid Loss:  0.024281563237309456
Epoch:  19  	Training Loss: 0.03230508044362068
Test Loss:  0.015965130180120468
Valid Loss:  0.024221695959568024
Epoch:  20  	Training Loss: 0.032230302691459656
Test Loss:  0.01593049429357052
Valid Loss:  0.02416370064020157
Epoch:  21  	Training Loss: 0.03216542303562164
Test Loss:  0.015892796218395233
Valid Loss:  0.024106867611408234
Epoch:  22  	Training Loss: 0.03210917487740517
Test Loss:  0.015863072127103806
Valid Loss:  0.02406022697687149
Epoch:  23  	Training Loss: 0.03206028789281845
Test Loss:  0.015833310782909393
Valid Loss:  0.02401394583284855
Epoch:  24  	Training Loss: 0.03201155364513397
Test Loss:  0.015803635120391846
Valid Loss:  0.023967882618308067
Epoch:  25  	Training Loss: 0.031962938606739044
Test Loss:  0.01577387936413288
Valid Loss:  0.023921994492411613
Epoch:  26  	Training Loss: 0.03191511332988739
Test Loss:  0.01574321836233139
Valid Loss:  0.023876836523413658
Epoch:  27  	Training Loss: 0.03187485784292221
Test Loss:  0.015711527317762375
Valid Loss:  0.023833952844142914
Epoch:  28  	Training Loss: 0.031841736286878586
Test Loss:  0.01567773148417473
Valid Loss:  0.023790990933775902
Epoch:  29  	Training Loss: 0.031812235713005066
Test Loss:  0.0156431682407856
Valid Loss:  0.023747853934764862
Epoch:  30  	Training Loss: 0.031783923506736755
Test Loss:  0.015608995221555233
Valid Loss:  0.023704908788204193
Epoch:  31  	Training Loss: 0.03175593167543411
Test Loss:  0.015574865974485874
Valid Loss:  0.023662149906158447
Epoch:  32  	Training Loss: 0.0317283570766449
Test Loss:  0.015543497167527676
Valid Loss:  0.02362286113202572
Epoch:  33  	Training Loss: 0.031703002750873566
Test Loss:  0.015512162819504738
Valid Loss:  0.02358374558389187
Epoch:  34  	Training Loss: 0.03167780488729477
Test Loss:  0.015480873174965382
Valid Loss:  0.023544806987047195
Epoch:  35  	Training Loss: 0.031652793288230896
Test Loss:  0.01544980052858591
Valid Loss:  0.02350609004497528
Epoch:  36  	Training Loss: 0.031627874821424484
Test Loss:  0.015418946743011475
Valid Loss:  0.02346760407090187
Epoch:  37  	Training Loss: 0.03160305321216583
Test Loss:  0.015387949533760548
Valid Loss:  0.023429030552506447
Epoch:  38  	Training Loss: 0.03157834708690643
Test Loss:  0.015357485972344875
Valid Loss:  0.023390933871269226
Epoch:  39  	Training Loss: 0.03155379369854927
Test Loss:  0.015326851978898048
Valid Loss:  0.02335274964570999
Epoch:  40  	Training Loss: 0.03152933716773987
Test Loss:  0.015296438708901405
Valid Loss:  0.02331479638814926
Epoch:  41  	Training Loss: 0.031504981219768524
Test Loss:  0.015266246162354946
Valid Loss:  0.023277059197425842
Epoch:  42  	Training Loss: 0.03148071467876434
Test Loss:  0.015237083658576012
Valid Loss:  0.023240532726049423
Epoch:  43  	Training Loss: 0.03145712986588478
Test Loss:  0.01520812138915062
Valid Loss:  0.023204252123832703
Epoch:  44  	Training Loss: 0.03143363818526268
Test Loss:  0.015179323963820934
Valid Loss:  0.02316834032535553
Epoch:  45  	Training Loss: 0.031410228461027145
Test Loss:  0.015150723047554493
Valid Loss:  0.023132646456360817
Epoch:  46  	Training Loss: 0.03138689696788788
Test Loss:  0.01512230932712555
Valid Loss:  0.02309715747833252
Epoch:  47  	Training Loss: 0.03136364370584488
Test Loss:  0.015094082802534103
Valid Loss:  0.023061860352754593
Epoch:  48  	Training Loss: 0.031340472400188446
Test Loss:  0.015066048130393028
Valid Loss:  0.023026758804917336
Epoch:  49  	Training Loss: 0.03131738677620888
Test Loss:  0.01503745373338461
Valid Loss:  0.022991271689534187
Epoch:  50  	Training Loss: 0.03129437193274498
Test Loss:  0.01500979345291853
Valid Loss:  0.02295655943453312
Epoch:  51  	Training Loss: 0.03127143532037735
Test Loss:  0.014981675893068314
Valid Loss:  0.022921539843082428
Epoch:  52  	Training Loss: 0.031248612329363823
Test Loss:  0.014954797923564911
Valid Loss:  0.022887758910655975
Epoch:  53  	Training Loss: 0.03122614324092865
Test Loss:  0.014927275478839874
Valid Loss:  0.022853611037135124
Epoch:  54  	Training Loss: 0.0312037356197834
Test Loss:  0.014900118112564087
Valid Loss:  0.02281980589032173
Epoch:  55  	Training Loss: 0.031181413680315018
Test Loss:  0.014873092994093895
Valid Loss:  0.022786155343055725
Epoch:  56  	Training Loss: 0.031159164384007454
Test Loss:  0.014846645295619965
Valid Loss:  0.022753002122044563
Epoch:  57  	Training Loss: 0.031137002632021904
Test Loss:  0.014819761738181114
Valid Loss:  0.022719569504261017
Epoch:  58  	Training Loss: 0.031114935874938965
Test Loss:  0.01479276828467846
Valid Loss:  0.022686097770929337
Epoch:  59  	Training Loss: 0.03109295479953289
Test Loss:  0.014766691252589226
Valid Loss:  0.022653384134173393
Epoch:  60  	Training Loss: 0.031071042641997337
Test Loss:  0.014740043319761753
Valid Loss:  0.022620318457484245
Epoch:  61  	Training Loss: 0.03104919195175171
Test Loss:  0.014713692478835583
Valid Loss:  0.022587575018405914
Epoch:  62  	Training Loss: 0.031027421355247498
Test Loss:  0.01468794234097004
Valid Loss:  0.022555578500032425
Epoch:  63  	Training Loss: 0.0310060977935791
Test Loss:  0.014662418514490128
Valid Loss:  0.02252380922436714
Epoch:  64  	Training Loss: 0.030984845012426376
Test Loss:  0.014637062326073647
Valid Loss:  0.022492218762636185
Epoch:  65  	Training Loss: 0.03096366859972477
Test Loss:  0.014611870050430298
Valid Loss:  0.022460803389549255
Epoch:  66  	Training Loss: 0.030942566692829132
Test Loss:  0.01458684727549553
Valid Loss:  0.022429561242461205
Epoch:  67  	Training Loss: 0.030921533703804016
Test Loss:  0.014561982825398445
Valid Loss:  0.022398505359888077
Epoch:  68  	Training Loss: 0.030900582671165466
Test Loss:  0.014536919072270393
Valid Loss:  0.022367306053638458
Epoch:  69  	Training Loss: 0.030879758298397064
Test Loss:  0.014512015506625175
Valid Loss:  0.02233627811074257
Epoch:  70  	Training Loss: 0.03085901029407978
Test Loss:  0.014487095177173615
Valid Loss:  0.022305279970169067
Epoch:  71  	Training Loss: 0.030838344246149063
Test Loss:  0.01446234155446291
Valid Loss:  0.022274451330304146
Epoch:  72  	Training Loss: 0.030817752704024315
Test Loss:  14%|█▍        | 72/500 [00:55<08:26,  1.18s/it] 15%|█▍        | 74/500 [00:55<06:03,  1.17it/s] 15%|█▌        | 76/500 [00:55<04:22,  1.61it/s] 16%|█▌        | 78/500 [00:55<03:11,  2.20it/s] 16%|█▌        | 80/500 [00:56<02:21,  2.96it/s] 16%|█▋        | 82/500 [01:02<08:19,  1.20s/it] 17%|█▋        | 84/500 [01:02<05:56,  1.17it/s] 17%|█▋        | 86/500 [01:02<04:16,  1.61it/s] 18%|█▊        | 88/500 [01:02<03:06,  2.21it/s] 18%|█▊        | 90/500 [01:03<02:18,  2.97it/s] 18%|█▊        | 92/500 [01:09<08:01,  1.18s/it] 19%|█▉        | 94/500 [01:09<05:43,  1.18it/s] 19%|█▉        | 96/500 [01:09<04:07,  1.64it/s] 20%|█▉        | 98/500 [01:09<03:00,  2.23it/s] 20%|██        | 100/500 [01:09<02:13,  3.00it/s] 20%|██        | 102/500 [01:16<08:02,  1.21s/it] 21%|██        | 104/500 [01:16<05:46,  1.14it/s] 21%|██        | 106/500 [01:16<04:11,  1.57it/s] 22%|██▏       | 108/500 [01:16<03:05,  2.12it/s] 22%|██▏       | 110/500 [01:17<02:19,  2.81it/s] 22%|██▏       | 112/500 [01:23<07:53,  1.22s/it] 23%|██▎       | 114/500 [01:23<05:39,  1.14it/s] 23%|██▎       | 116/500 [01:23<04:05,  1.56it/s] 24%|██▎       | 118/500 [01:23<02:59,  2.13it/s] 24%|██▍       | 120/500 [01:24<02:12,  2.87it/s] 24%|██▍       | 122/500 [01:30<07:30,  1.19s/it] 25%|██▍       | 124/500 [01:30<05:21,  1.17it/s] 25%|██▌       | 126/500 [01:30<03:51,  1.62it/s] 26%|██▌       | 128/500 [01:30<02:48,  2.21it/s] 26%|██▌       | 130/500 [01:30<02:04,  2.97it/s] 26%|██▋       | 132/500 [01:37<07:14,  1.18s/it] 27%|██▋       | 134/500 [01:37<05:09,  1.18it/s] 27%|██▋       | 136/500 [01:37<03:42,  1.64it/s] 28%|██▊       | 138/500 [01:37<02:42,  2.23it/s] 28%|██▊       | 140/500 [01:37<02:00,  3.00it/s] 28%|██▊       | 142/500 [01:44<06:59,  1.17s/it] 0.014438094571232796
Valid Loss:  0.02224421314895153
Epoch:  73  	Training Loss: 0.030797481536865234
Test Loss:  0.014414006844162941
Valid Loss:  0.02221413515508175
Epoch:  74  	Training Loss: 0.030777279287576675
Test Loss:  0.014390071853995323
Valid Loss:  0.022184252738952637
Epoch:  75  	Training Loss: 0.03075714409351349
Test Loss:  0.014366294257342815
Valid Loss:  0.022154550999403
Epoch:  76  	Training Loss: 0.030737079679965973
Test Loss:  0.014342664740979671
Valid Loss:  0.02212502807378769
Epoch:  77  	Training Loss: 0.030717089772224426
Test Loss:  0.014318685978651047
Valid Loss:  0.022095225751399994
Epoch:  78  	Training Loss: 0.030697181820869446
Test Loss:  0.014294863678514957
Valid Loss:  0.022065596655011177
Epoch:  79  	Training Loss: 0.030677340924739838
Test Loss:  0.014271077699959278
Valid Loss:  0.022036030888557434
Epoch:  80  	Training Loss: 0.0306575745344162
Test Loss:  0.01424730010330677
Valid Loss:  0.022006504237651825
Epoch:  81  	Training Loss: 0.03063788078725338
Test Loss:  0.014223802834749222
Valid Loss:  0.021977262571454048
Epoch:  82  	Training Loss: 0.030618255957961082
Test Loss:  0.0142003009095788
Valid Loss:  0.0219480711966753
Epoch:  83  	Training Loss: 0.030598755925893784
Test Loss:  0.01417713426053524
Valid Loss:  0.021919218823313713
Epoch:  84  	Training Loss: 0.03057931922376156
Test Loss:  0.014153674244880676
Valid Loss:  0.02189013734459877
Epoch:  85  	Training Loss: 0.0305599607527256
Test Loss:  0.014130784198641777
Valid Loss:  0.021861586719751358
Epoch:  86  	Training Loss: 0.03054065629839897
Test Loss:  0.01410759799182415
Valid Loss:  0.02183280512690544
Epoch:  87  	Training Loss: 0.030521418899297714
Test Loss:  0.014084904454648495
Valid Loss:  0.02180449292063713
Epoch:  88  	Training Loss: 0.03050224855542183
Test Loss:  0.014062130823731422
Valid Loss:  0.02177613228559494
Epoch:  89  	Training Loss: 0.03048313595354557
Test Loss:  0.014039386995136738
Valid Loss:  0.021747831255197525
Epoch:  90  	Training Loss: 0.030464092269539833
Test Loss:  0.014016788452863693
Valid Loss:  0.021719682961702347
Epoch:  91  	Training Loss: 0.03044511191546917
Test Loss:  0.01399433333426714
Valid Loss:  0.02169169671833515
Epoch:  92  	Training Loss: 0.03042619489133358
Test Loss:  0.01397215947508812
Valid Loss:  0.02166403830051422
Epoch:  93  	Training Loss: 0.030407460406422615
Test Loss:  0.013950120657682419
Valid Loss:  0.02163652330636978
Epoch:  94  	Training Loss: 0.030388787388801575
Test Loss:  0.01392822153866291
Valid Loss:  0.02160916104912758
Epoch:  95  	Training Loss: 0.03037017583847046
Test Loss:  0.013906452804803848
Valid Loss:  0.02158193662762642
Epoch:  96  	Training Loss: 0.030351612716913223
Test Loss:  0.013884816318750381
Valid Loss:  0.021554863080382347
Epoch:  97  	Training Loss: 0.030333111062645912
Test Loss:  0.013862894847989082
Valid Loss:  0.02152755856513977
Epoch:  98  	Training Loss: 0.030314670875668526
Test Loss:  0.013841522857546806
Valid Loss:  0.02150077000260353
Epoch:  99  	Training Loss: 0.030296284705400467
Test Loss:  0.013819844461977482
Valid Loss:  0.021473735570907593
Epoch:  100  	Training Loss: 0.030277960002422333
Test Loss:  0.013798710890114307
Valid Loss:  0.021447211503982544
Epoch:  101  	Training Loss: 0.030259685590863228
Test Loss:  0.013777312822639942
Valid Loss:  0.02142047882080078
Epoch:  102  	Training Loss: 0.03024146892130375
Test Loss:  0.013756177388131618
Valid Loss:  0.02139401063323021
Epoch:  103  	Training Loss: 0.0302233025431633
Test Loss:  0.013735167682170868
Valid Loss:  0.02136768028140068
Epoch:  104  	Training Loss: 0.030205190181732178
Test Loss:  0.01371428556740284
Valid Loss:  0.021341491490602493
Epoch:  105  	Training Loss: 0.030187129974365234
Test Loss:  0.013693524524569511
Valid Loss:  0.02131543681025505
Epoch:  106  	Training Loss: 0.03016912192106247
Test Loss:  0.013672892935574055
Valid Loss:  0.021289516240358353
Epoch:  107  	Training Loss: 0.03015117347240448
Test Loss:  0.013652386143803596
Valid Loss:  0.0212637297809124
Epoch:  108  	Training Loss: 0.030133269727230072
Test Loss:  0.013631997630000114
Valid Loss:  0.021238069981336594
Epoch:  109  	Training Loss: 0.030115419998764992
Test Loss:  0.013611729256808758
Valid Loss:  0.02121254988014698
Epoch:  110  	Training Loss: 0.030097616836428642
Test Loss:  0.013591578230261803
Valid Loss:  0.021187150850892067
Epoch:  111  	Training Loss: 0.030079863965511322
Test Loss:  0.013571545481681824
Valid Loss:  0.0211618822067976
Epoch:  112  	Training Loss: 0.030062159523367882
Test Loss:  0.013551713898777962
Valid Loss:  0.021136872470378876
Epoch:  113  	Training Loss: 0.03004465624690056
Test Loss:  0.013531994074583054
Valid Loss:  0.02111198380589485
Epoch:  114  	Training Loss: 0.030027193948626518
Test Loss:  0.013512389734387398
Valid Loss:  0.021087219938635826
Epoch:  115  	Training Loss: 0.030009781941771507
Test Loss:  0.013492895290255547
Valid Loss:  0.02106257528066635
Epoch:  116  	Training Loss: 0.029992422088980675
Test Loss:  0.013473372906446457
Valid Loss:  0.02103794738650322
Epoch:  117  	Training Loss: 0.029975123703479767
Test Loss:  0.013453961350023746
Valid Loss:  0.02101343870162964
Epoch:  118  	Training Loss: 0.02995787002146244
Test Loss:  0.013434657827019691
Valid Loss:  0.02098904550075531
Epoch:  119  	Training Loss: 0.029940664768218994
Test Loss:  0.013415465131402016
Valid Loss:  0.020964769646525383
Epoch:  120  	Training Loss: 0.02992350608110428
Test Loss:  0.013396380469202995
Valid Loss:  0.020940613001585007
Epoch:  121  	Training Loss: 0.029906395822763443
Test Loss:  0.013377400115132332
Valid Loss:  0.020916573703289032
Epoch:  122  	Training Loss: 0.02988932654261589
Test Loss:  0.013358515687286854
Valid Loss:  0.020892612636089325
Epoch:  123  	Training Loss: 0.02987222746014595
Test Loss:  0.013339732773602009
Valid Loss:  0.02086876891553402
Epoch:  124  	Training Loss: 0.02985517308115959
Test Loss:  0.013321052305400372
Valid Loss:  0.02084503136575222
Epoch:  125  	Training Loss: 0.029838159680366516
Test Loss:  0.013302473351359367
Valid Loss:  0.020821411162614822
Epoch:  126  	Training Loss: 0.029821190983057022
Test Loss:  0.013283992186188698
Valid Loss:  0.020797893404960632
Epoch:  127  	Training Loss: 0.02980426698923111
Test Loss:  0.013265611603856087
Valid Loss:  0.020774487406015396
Epoch:  128  	Training Loss: 0.029787376523017883
Test Loss:  0.013247327879071236
Valid Loss:  0.020751183852553368
Epoch:  129  	Training Loss: 0.029770534485578537
Test Loss:  0.013229139149188995
Valid Loss:  0.020727992057800293
Epoch:  130  	Training Loss: 0.029753731563687325
Test Loss:  0.013210912235081196
Valid Loss:  0.020704789087176323
Epoch:  131  	Training Loss: 0.029736988246440887
Test Loss:  0.013192382641136646
Valid Loss:  0.020681360736489296
Epoch:  132  	Training Loss: 0.029720304533839226
Test Loss:  0.013173902407288551
Valid Loss:  0.020658044144511223
Epoch:  133  	Training Loss: 0.029703818261623383
Test Loss:  0.013155519962310791
Valid Loss:  0.020634841173887253
Epoch:  134  	Training Loss: 0.029687384143471718
Test Loss:  0.013137150555849075
Valid Loss:  0.020611699670553207
Epoch:  135  	Training Loss: 0.02967100590467453
Test Loss:  0.013118863105773926
Valid Loss:  0.02058866247534752
Epoch:  136  	Training Loss: 0.029654666781425476
Test Loss:  0.013100676238536835
Valid Loss:  0.02056574821472168
Epoch:  137  	Training Loss: 0.0296383798122406
Test Loss:  0.0130825936794281
Valid Loss:  0.02054295316338539
Epoch:  138  	Training Loss: 0.02962213009595871
Test Loss:  0.013064614497125149
Valid Loss:  0.020520266145467758
Epoch:  139  	Training Loss: 0.029605930671095848
Test Loss:  0.013046727515757084
Valid Loss:  0.020497698336839676
Epoch:  140  	Training Loss: 0.02958977408707142
Test Loss:  0.013028943911194801
Valid Loss:  0.02047523856163025
Epoch:  141  	Training Loss: 0.029573656618595123
Test Loss:  0.013011256232857704
Valid Loss:  0.020452890545129776
Epoch:  142  	Training Loss: 0.02955758571624756
Test Loss:  0.012993711046874523
Valid Loss:  0.020430654287338257
Epoch:  143  	Training Loss: 0.029541436582803726
 29%|██▉       | 144/500 [01:44<04:58,  1.19it/s] 29%|██▉       | 146/500 [01:44<03:34,  1.65it/s] 30%|██▉       | 148/500 [01:44<02:36,  2.25it/s] 30%|███       | 150/500 [01:44<01:55,  3.02it/s] 30%|███       | 152/500 [01:51<07:10,  1.24s/it] 31%|███       | 154/500 [01:51<05:08,  1.12it/s] 31%|███       | 156/500 [01:51<03:43,  1.54it/s] 32%|███▏      | 158/500 [01:51<02:42,  2.11it/s] 32%|███▏      | 160/500 [01:51<01:59,  2.85it/s] 32%|███▏      | 162/500 [01:58<06:51,  1.22s/it] 33%|███▎      | 164/500 [01:58<04:54,  1.14it/s] 33%|███▎      | 166/500 [01:58<03:34,  1.56it/s] 34%|███▎      | 168/500 [01:58<02:37,  2.11it/s] 34%|███▍      | 170/500 [01:59<01:58,  2.79it/s] 34%|███▍      | 172/500 [02:05<06:45,  1.24s/it] 35%|███▍      | 174/500 [02:05<04:49,  1.13it/s] 35%|███▌      | 176/500 [02:05<03:28,  1.55it/s] 36%|███▌      | 178/500 [02:06<02:32,  2.11it/s] 36%|███▌      | 180/500 [02:06<01:53,  2.82it/s] 36%|███▋      | 182/500 [02:12<06:27,  1.22s/it] 37%|███▋      | 184/500 [02:12<04:37,  1.14it/s] 37%|███▋      | 186/500 [02:13<03:21,  1.56it/s] 38%|███▊      | 188/500 [02:13<02:27,  2.11it/s] 38%|███▊      | 190/500 [02:13<01:49,  2.84it/s] 38%|███▊      | 192/500 [02:19<06:14,  1.22s/it] 39%|███▉      | 194/500 [02:19<04:26,  1.15it/s] 39%|███▉      | 196/500 [02:20<03:11,  1.59it/s] 40%|███▉      | 198/500 [02:20<02:20,  2.15it/s] 40%|████      | 200/500 [02:20<01:45,  2.84it/s] 40%|████      | 202/500 [02:26<05:58,  1.20s/it] 41%|████      | 204/500 [02:26<04:15,  1.16it/s] 41%|████      | 206/500 [02:27<03:03,  1.60it/s] 42%|████▏     | 208/500 [02:27<02:13,  2.19it/s] 42%|████▏     | 210/500 [02:27<01:38,  2.94it/s] 42%|████▏     | 212/500 [02:33<05:51,  1.22s/it]Test Loss:  0.012976261787116528
Valid Loss:  0.02040852978825569
Epoch:  144  	Training Loss: 0.029525339603424072
Test Loss:  0.012958652339875698
Valid Loss:  0.02038624882698059
Epoch:  145  	Training Loss: 0.0295092910528183
Test Loss:  0.012941140681505203
Valid Loss:  0.020364081487059593
Epoch:  146  	Training Loss: 0.029493285343050957
Test Loss:  0.012923631817102432
Valid Loss:  0.02034192904829979
Epoch:  147  	Training Loss: 0.029477322474122047
Test Loss:  0.01290622167289257
Valid Loss:  0.02031988464295864
Epoch:  148  	Training Loss: 0.02946140244603157
Test Loss:  0.0128888925537467
Valid Loss:  0.020297929644584656
Epoch:  149  	Training Loss: 0.029445528984069824
Test Loss:  0.012871655635535717
Valid Loss:  0.020276080816984177
Epoch:  150  	Training Loss: 0.02942969650030136
Test Loss:  0.012854514643549919
Valid Loss:  0.020254341885447502
Epoch:  151  	Training Loss: 0.029413899406790733
Test Loss:  0.012837465852499008
Valid Loss:  0.020232705399394035
Epoch:  152  	Training Loss: 0.029398147016763687
Test Loss:  0.012820424512028694
Valid Loss:  0.02021113410592079
Epoch:  153  	Training Loss: 0.029382534325122833
Test Loss:  0.012803475372493267
Valid Loss:  0.020189661532640457
Epoch:  154  	Training Loss: 0.029366960749030113
Test Loss:  0.012786619365215302
Valid Loss:  0.020168298855423927
Epoch:  155  	Training Loss: 0.029351431876420975
Test Loss:  0.012769851833581924
Valid Loss:  0.020147033035755157
Epoch:  156  	Training Loss: 0.02933594025671482
Test Loss:  0.012753171846270561
Valid Loss:  0.020125873386859894
Epoch:  157  	Training Loss: 0.029320495203137398
Test Loss:  0.012736341916024685
Valid Loss:  0.02010456845164299
Epoch:  158  	Training Loss: 0.029305094853043556
Test Loss:  0.012719603255391121
Valid Loss:  0.020083362236618996
Epoch:  159  	Training Loss: 0.029289735481142998
Test Loss:  0.01270286738872528
Valid Loss:  0.020062170922756195
Epoch:  160  	Training Loss: 0.02927442081272602
Test Loss:  0.012686224654316902
Valid Loss:  0.0200410857796669
Epoch:  161  	Training Loss: 0.029259148985147476
Test Loss:  0.012669650837779045
Valid Loss:  0.020020104944705963
Epoch:  162  	Training Loss: 0.029243919998407364
Test Loss:  0.012653125450015068
Valid Loss:  0.019999150186777115
Epoch:  163  	Training Loss: 0.029228581115603447
Test Loss:  0.012636682018637657
Valid Loss:  0.019978301599621773
Epoch:  164  	Training Loss: 0.029213277623057365
Test Loss:  0.012620327062904835
Valid Loss:  0.019957561045885086
Epoch:  165  	Training Loss: 0.029198013246059418
Test Loss:  0.012604058720171452
Valid Loss:  0.01993691921234131
Epoch:  166  	Training Loss: 0.029182786121964455
Test Loss:  0.012587874196469784
Valid Loss:  0.01991637796163559
Epoch:  167  	Training Loss: 0.029167596250772476
Test Loss:  0.012571771629154682
Valid Loss:  0.01989593543112278
Epoch:  168  	Training Loss: 0.029152441769838333
Test Loss:  0.012555752880871296
Valid Loss:  0.01987558789551258
Epoch:  169  	Training Loss: 0.029137322679162025
Test Loss:  0.012539819814264774
Valid Loss:  0.01985533908009529
Epoch:  170  	Training Loss: 0.0291222482919693
Test Loss:  0.012523852288722992
Valid Loss:  0.019835082814097404
Epoch:  171  	Training Loss: 0.029107213020324707
Test Loss:  0.01250796765089035
Valid Loss:  0.01981492154300213
Epoch:  172  	Training Loss: 0.029092218726873398
Test Loss:  0.012492042034864426
Valid Loss:  0.019794752821326256
Epoch:  173  	Training Loss: 0.029077261686325073
Test Loss:  0.01247620303183794
Valid Loss:  0.019774673506617546
Epoch:  174  	Training Loss: 0.029062340036034584
Test Loss:  0.012460448779165745
Valid Loss:  0.019754700362682343
Epoch:  175  	Training Loss: 0.02904745377600193
Test Loss:  0.012444771826267242
Valid Loss:  0.019734811037778854
Epoch:  176  	Training Loss: 0.029032602906227112
Test Loss:  0.01242917962372303
Valid Loss:  0.01971503347158432
Epoch:  177  	Training Loss: 0.029017798602581024
Test Loss:  0.012413442134857178
Valid Loss:  0.01969507522881031
Epoch:  178  	Training Loss: 0.02900303527712822
Test Loss:  0.012397491373121738
Valid Loss:  0.019674865528941154
Epoch:  179  	Training Loss: 0.02898830734193325
Test Loss:  0.012381847947835922
Valid Loss:  0.0196550190448761
Epoch:  180  	Training Loss: 0.028973616659641266
Test Loss:  0.012366270646452904
Valid Loss:  0.01963524892926216
Epoch:  181  	Training Loss: 0.02895897440612316
Test Loss:  0.012350465171039104
Valid Loss:  0.019615206867456436
Epoch:  182  	Training Loss: 0.028944358229637146
Test Loss:  0.012335010804235935
Valid Loss:  0.019595585763454437
Epoch:  183  	Training Loss: 0.028929777443408966
Test Loss:  0.012319326400756836
Valid Loss:  0.01957569643855095
Epoch:  184  	Training Loss: 0.028915230184793472
Test Loss:  0.012303728610277176
Valid Loss:  0.01955590583384037
Epoch:  185  	Training Loss: 0.028900720179080963
Test Loss:  0.012288522906601429
Valid Loss:  0.01953657902777195
Epoch:  186  	Training Loss: 0.028886251151561737
Test Loss:  0.012273086234927177
Valid Loss:  0.019516978412866592
Epoch:  187  	Training Loss: 0.0288718082010746
Test Loss:  0.012257736176252365
Valid Loss:  0.019497474655508995
Epoch:  188  	Training Loss: 0.028857408091425896
Test Loss:  0.012242460623383522
Valid Loss:  0.01947806589305401
Epoch:  189  	Training Loss: 0.02884303778409958
Test Loss:  0.012227272614836693
Valid Loss:  0.01945875771343708
Epoch:  190  	Training Loss: 0.028828710317611694
Test Loss:  0.012212058529257774
Valid Loss:  0.019439438357949257
Epoch:  191  	Training Loss: 0.028814412653446198
Test Loss:  0.012196922674775124
Valid Loss:  0.019420217722654343
Epoch:  192  	Training Loss: 0.028800154104828835
Test Loss:  0.012181900441646576
Valid Loss:  0.01940114051103592
Epoch:  193  	Training Loss: 0.028785986825823784
Test Loss:  0.012166958302259445
Valid Loss:  0.019382156431674957
Epoch:  194  	Training Loss: 0.02877185121178627
Test Loss:  0.012152093462646008
Valid Loss:  0.0193632785230875
Epoch:  195  	Training Loss: 0.028757749125361443
Test Loss:  0.012137306854128838
Valid Loss:  0.019344497472047806
Epoch:  196  	Training Loss: 0.02874368242919445
Test Loss:  0.012122595682740211
Valid Loss:  0.01932580955326557
Epoch:  197  	Training Loss: 0.028729651123285294
Test Loss:  0.01210795808583498
Valid Loss:  0.0193072147667408
Epoch:  198  	Training Loss: 0.02871566079556942
Test Loss:  0.012093394994735718
Valid Loss:  0.01928871124982834
Epoch:  199  	Training Loss: 0.028701698407530785
Test Loss:  0.012078710831701756
Valid Loss:  0.019270021468400955
Epoch:  200  	Training Loss: 0.028687771409749985
Test Loss:  0.012064225971698761
Valid Loss:  0.019251598045229912
Epoch:  201  	Training Loss: 0.02867387980222702
Test Loss:  0.012049672193825245
Valid Loss:  0.01923307217657566
Epoch:  202  	Training Loss: 0.028660021722316742
Test Loss:  0.012035075575113297
Valid Loss:  0.019214486703276634
Epoch:  203  	Training Loss: 0.028646184131503105
Test Loss:  0.012020755559206009
Valid Loss:  0.019196268171072006
Epoch:  204  	Training Loss: 0.028632380068302155
Test Loss:  0.012006323784589767
Valid Loss:  0.019177885726094246
Epoch:  205  	Training Loss: 0.028618603944778442
Test Loss:  0.011992023326456547
Valid Loss:  0.019159678369760513
Epoch:  206  	Training Loss: 0.028604866936802864
Test Loss:  0.011977722868323326
Valid Loss:  0.019141454249620438
Epoch:  207  	Training Loss: 0.02859116531908512
Test Loss:  0.01196349784731865
Valid Loss:  0.019123326987028122
Epoch:  208  	Training Loss: 0.028577491641044617
Test Loss:  0.011949343606829643
Valid Loss:  0.019105279818177223
Epoch:  209  	Training Loss: 0.028563853353261948
Test Loss:  0.011935260146856308
Valid Loss:  0.019087322056293488
Epoch:  210  	Training Loss: 0.028550244867801666
Test Loss:  0.011921251192688942
Valid Loss:  0.019069453701376915
Epoch:  211  	Training Loss: 0.028536668047308922
Test Loss:  0.011907309293746948
Valid Loss:  0.019051669165492058
Epoch:  212  	Training Loss: 0.028523121029138565
Test Loss:  0.011893508955836296
Valid Loss:  0.019034072756767273
Epoch:  213  	Training Loss: 0.02850968949496746
Test Loss:  0.011879777535796165
Valid Loss:   43%|████▎     | 214/500 [02:34<04:10,  1.14it/s] 43%|████▎     | 216/500 [02:34<02:59,  1.58it/s] 44%|████▎     | 218/500 [02:34<02:11,  2.15it/s] 44%|████▍     | 220/500 [02:34<01:37,  2.88it/s] 44%|████▍     | 222/500 [02:40<05:33,  1.20s/it] 45%|████▍     | 224/500 [02:40<03:57,  1.16it/s] 45%|████▌     | 226/500 [02:41<02:50,  1.60it/s] 46%|████▌     | 228/500 [02:41<02:04,  2.19it/s] 46%|████▌     | 230/500 [02:41<01:31,  2.95it/s] 46%|████▋     | 232/500 [02:47<05:16,  1.18s/it] 47%|████▋     | 234/500 [02:47<03:45,  1.18it/s] 47%|████▋     | 236/500 [02:47<02:41,  1.63it/s] 48%|████▊     | 238/500 [02:48<01:57,  2.22it/s] 48%|████▊     | 240/500 [02:48<01:27,  2.96it/s] 48%|████▊     | 242/500 [02:54<05:10,  1.20s/it] 49%|████▉     | 244/500 [02:54<03:40,  1.16it/s] 49%|████▉     | 246/500 [02:54<02:38,  1.60it/s] 50%|████▉     | 248/500 [02:55<01:55,  2.19it/s] 50%|█████     | 250/500 [02:55<01:24,  2.94it/s] 50%|█████     | 252/500 [03:01<04:58,  1.20s/it] 51%|█████     | 254/500 [03:01<03:32,  1.16it/s] 51%|█████     | 256/500 [03:01<02:32,  1.60it/s] 52%|█████▏    | 258/500 [03:02<01:50,  2.19it/s] 52%|█████▏    | 260/500 [03:02<01:21,  2.94it/s] 52%|█████▏    | 262/500 [03:08<04:42,  1.19s/it] 53%|█████▎    | 264/500 [03:08<03:21,  1.17it/s] 53%|█████▎    | 266/500 [03:08<02:26,  1.60it/s] 54%|█████▎    | 268/500 [03:08<01:46,  2.18it/s] 54%|█████▍    | 270/500 [03:09<01:18,  2.92it/s] 54%|█████▍    | 272/500 [03:15<04:35,  1.21s/it] 55%|█████▍    | 274/500 [03:15<03:15,  1.15it/s] 55%|█████▌    | 276/500 [03:15<02:20,  1.60it/s] 56%|█████▌    | 278/500 [03:15<01:41,  2.18it/s] 56%|█████▌    | 280/500 [03:16<01:15,  2.91it/s] 56%|█████▋    | 282/500 [03:22<04:22,  1.20s/it]0.019016548991203308
Epoch:  214  	Training Loss: 0.028496291488409042
Test Loss:  0.011866113170981407
Valid Loss:  0.018999114632606506
Epoch:  215  	Training Loss: 0.028482917696237564
Test Loss:  0.011852516792714596
Valid Loss:  0.01898176595568657
Epoch:  216  	Training Loss: 0.02846957929432392
Test Loss:  0.011838988400995731
Valid Loss:  0.018964499235153198
Epoch:  217  	Training Loss: 0.028456274420022964
Test Loss:  0.011825526133179665
Valid Loss:  0.018947310745716095
Epoch:  218  	Training Loss: 0.02844299003481865
Test Loss:  0.011812126263976097
Valid Loss:  0.01893020048737526
Epoch:  219  	Training Loss: 0.02842974290251732
Test Loss:  0.011798791587352753
Valid Loss:  0.01891317218542099
Epoch:  220  	Training Loss: 0.028416519984602928
Test Loss:  0.011785521171987057
Valid Loss:  0.01889622211456299
Epoch:  221  	Training Loss: 0.028403326869010925
Test Loss:  0.011772314086556435
Valid Loss:  0.018879346549510956
Epoch:  222  	Training Loss: 0.02839016169309616
Test Loss:  0.011759069748222828
Valid Loss:  0.0188624057918787
Epoch:  223  	Training Loss: 0.028376877307891846
Test Loss:  0.011745885014533997
Valid Loss:  0.018845533952116966
Epoch:  224  	Training Loss: 0.02836361713707447
Test Loss:  0.011732760816812515
Valid Loss:  0.0188287366181612
Epoch:  225  	Training Loss: 0.028350383043289185
Test Loss:  0.01171969622373581
Valid Loss:  0.018812015652656555
Epoch:  226  	Training Loss: 0.028337176889181137
Test Loss:  0.011706691235303879
Valid Loss:  0.018795371055603027
Epoch:  227  	Training Loss: 0.028323998674750328
Test Loss:  0.011693747714161873
Valid Loss:  0.01877879723906517
Epoch:  228  	Training Loss: 0.02831084653735161
Test Loss:  0.011680856347084045
Valid Loss:  0.018762297928333282
Epoch:  229  	Training Loss: 0.02829771488904953
Test Loss:  0.011668025515973568
Valid Loss:  0.01874586194753647
Epoch:  230  	Training Loss: 0.02828461304306984
Test Loss:  0.011655251495540142
Valid Loss:  0.018729496747255325
Epoch:  231  	Training Loss: 0.028271537274122238
Test Loss:  0.011642532423138618
Valid Loss:  0.018713202327489853
Epoch:  232  	Training Loss: 0.028258483856916428
Test Loss:  0.011629702523350716
Valid Loss:  0.018696792423725128
Epoch:  233  	Training Loss: 0.02824537456035614
Test Loss:  0.011616930365562439
Valid Loss:  0.018680451437830925
Epoch:  234  	Training Loss: 0.028232285752892494
Test Loss:  0.01160421408712864
Valid Loss:  0.018664173781871796
Epoch:  235  	Training Loss: 0.02821922115981579
Test Loss:  0.011591548100113869
Valid Loss:  0.018647968769073486
Epoch:  236  	Training Loss: 0.02820618823170662
Test Loss:  0.01157893892377615
Valid Loss:  0.01863183081150055
Epoch:  237  	Training Loss: 0.02819318138062954
Test Loss:  0.01156620867550373
Valid Loss:  0.018615512177348137
Epoch:  238  	Training Loss: 0.028180211782455444
Test Loss:  0.011553470976650715
Valid Loss:  0.01859917677938938
Epoch:  239  	Training Loss: 0.02816726826131344
Test Loss:  0.011540794745087624
Valid Loss:  0.01858290284872055
Epoch:  240  	Training Loss: 0.028154361993074417
Test Loss:  0.01152815856039524
Valid Loss:  0.018566686660051346
Epoch:  241  	Training Loss: 0.02814146876335144
Test Loss:  0.011515578255057335
Valid Loss:  0.018550541251897812
Epoch:  242  	Training Loss: 0.02812860533595085
Test Loss:  0.01150311529636383
Valid Loss:  0.01853456161916256
Epoch:  243  	Training Loss: 0.02811589278280735
Test Loss:  0.011490708217024803
Valid Loss:  0.01851864904165268
Epoch:  244  	Training Loss: 0.02810320258140564
Test Loss:  0.011478354223072529
Valid Loss:  0.01850280910730362
Epoch:  245  	Training Loss: 0.028090549632906914
Test Loss:  0.011466055177152157
Valid Loss:  0.01848703809082508
Epoch:  246  	Training Loss: 0.02807791531085968
Test Loss:  0.011453812010586262
Valid Loss:  0.018471328541636467
Epoch:  247  	Training Loss: 0.028065305203199387
Test Loss:  0.011441620998084545
Valid Loss:  0.018455691635608673
Epoch:  248  	Training Loss: 0.02805272303521633
Test Loss:  0.011429483070969582
Valid Loss:  0.018440119922161102
Epoch:  249  	Training Loss: 0.028040170669555664
Test Loss:  0.011417398229241371
Valid Loss:  0.018424607813358307
Epoch:  250  	Training Loss: 0.02802763506770134
Test Loss:  0.01140536554157734
Valid Loss:  0.018409166485071182
Epoch:  251  	Training Loss: 0.028015127405524254
Test Loss:  0.011393385007977486
Valid Loss:  0.01839378848671913
Epoch:  252  	Training Loss: 0.02800264209508896
Test Loss:  0.01138143241405487
Valid Loss:  0.01837843470275402
Epoch:  253  	Training Loss: 0.027990126982331276
Test Loss:  0.011369528248906136
Valid Loss:  0.018363144248723984
Epoch:  254  	Training Loss: 0.027977637946605682
Test Loss:  0.011357679963111877
Valid Loss:  0.018347911536693573
Epoch:  255  	Training Loss: 0.02796516939997673
Test Loss:  0.011345875449478626
Valid Loss:  0.018332747742533684
Epoch:  256  	Training Loss: 0.027952736243605614
Test Loss:  0.011333961971104145
Valid Loss:  0.018317412585020065
Epoch:  257  	Training Loss: 0.027940327301621437
Test Loss:  0.011322103440761566
Valid Loss:  0.01830214448273182
Epoch:  258  	Training Loss: 0.027927950024604797
Test Loss:  0.011310221627354622
Valid Loss:  0.018286827951669693
Epoch:  259  	Training Loss: 0.027915596961975098
Test Loss:  0.01129839662462473
Valid Loss:  0.018271587789058685
Epoch:  260  	Training Loss: 0.02790326252579689
Test Loss:  0.01128662284463644
Valid Loss:  0.018256403505802155
Epoch:  261  	Training Loss: 0.02789095602929592
Test Loss:  0.011274900287389755
Valid Loss:  0.018241293728351593
Epoch:  262  	Training Loss: 0.027878671884536743
Test Loss:  0.011263107880949974
Valid Loss:  0.018226081505417824
Epoch:  263  	Training Loss: 0.027866287156939507
Test Loss:  0.011251365765929222
Valid Loss:  0.018210940062999725
Epoch:  264  	Training Loss: 0.02785392478108406
Test Loss:  0.011239667423069477
Valid Loss:  0.018195848912000656
Epoch:  265  	Training Loss: 0.027841582894325256
Test Loss:  0.011227943934500217
Valid Loss:  0.01818075031042099
Epoch:  266  	Training Loss: 0.027829285711050034
Test Loss:  0.011216115206480026
Valid Loss:  0.01816549152135849
Epoch:  267  	Training Loss: 0.027817007154226303
Test Loss:  0.011204339563846588
Valid Loss:  0.018150299787521362
Epoch:  268  	Training Loss: 0.027804750949144363
Test Loss:  0.011192712932825089
Valid Loss:  0.01813530921936035
Epoch:  269  	Training Loss: 0.02779252454638481
Test Loss:  0.011180983856320381
Valid Loss:  0.018120160326361656
Epoch:  270  	Training Loss: 0.02778032049536705
Test Loss:  0.011169293895363808
Valid Loss:  0.01810506545007229
Epoch:  271  	Training Loss: 0.02776813879609108
Test Loss:  0.01115766167640686
Valid Loss:  0.018090061843395233
Epoch:  272  	Training Loss: 0.0277559794485569
Test Loss:  0.01114610768854618
Valid Loss:  0.018075190484523773
Epoch:  273  	Training Loss: 0.02774396538734436
Test Loss:  0.011134608648717403
Valid Loss:  0.018060388043522835
Epoch:  274  	Training Loss: 0.02773197367787361
Test Loss:  0.011123159900307655
Valid Loss:  0.018045645207166672
Epoch:  275  	Training Loss: 0.02772001177072525
Test Loss:  0.011111763305962086
Valid Loss:  0.018030963838100433
Epoch:  276  	Training Loss: 0.027708064764738083
Test Loss:  0.01110041607171297
Valid Loss:  0.018016349524259567
Epoch:  277  	Training Loss: 0.027696147561073303
Test Loss:  0.011089116334915161
Valid Loss:  0.018001794815063477
Epoch:  278  	Training Loss: 0.027684247121214867
Test Loss:  0.011077865026891232
Valid Loss:  0.01798729971051216
Epoch:  279  	Training Loss: 0.027672365307807922
Test Loss:  0.011066663078963757
Valid Loss:  0.01797286793589592
Epoch:  280  	Training Loss: 0.027660513296723366
Test Loss:  0.011055510491132736
Valid Loss:  0.017958493903279305
Epoch:  281  	Training Loss: 0.0276486799120903
Test Loss:  0.011044403538107872
Valid Loss:  0.017944183200597763
Epoch:  282  	Training Loss: 0.027636868879199028
Test Loss:  0.01103336364030838
Valid Loss:  0.017929963767528534
Epoch:  283  	Training Loss: 0.02762514539062977
Test Loss:  0.011022372171282768
Valid Loss:  0.017915809527039528
Epoch:  284  	Training Loss: 0.02761344239115715
 57%|█████▋    | 284/500 [03:22<03:07,  1.15it/s] 57%|█████▋    | 286/500 [03:22<02:15,  1.58it/s] 58%|█████▊    | 288/500 [03:23<01:39,  2.13it/s] 58%|█████▊    | 290/500 [03:23<01:13,  2.86it/s] 58%|█████▊    | 292/500 [03:29<04:08,  1.19s/it] 59%|█████▉    | 294/500 [03:29<02:56,  1.17it/s] 59%|█████▉    | 296/500 [03:29<02:06,  1.62it/s] 60%|█████▉    | 298/500 [03:29<01:31,  2.20it/s] 60%|██████    | 300/500 [03:30<01:07,  2.95it/s] 60%|██████    | 302/500 [03:36<03:56,  1.20s/it] 61%|██████    | 304/500 [03:36<02:48,  1.16it/s] 61%|██████    | 306/500 [03:36<02:00,  1.61it/s] 62%|██████▏   | 308/500 [03:36<01:27,  2.20it/s] 62%|██████▏   | 310/500 [03:37<01:04,  2.95it/s] 62%|██████▏   | 312/500 [03:43<03:44,  1.20s/it] 63%|██████▎   | 314/500 [03:43<02:39,  1.17it/s] 63%|██████▎   | 316/500 [03:43<01:54,  1.61it/s] 64%|██████▎   | 318/500 [03:43<01:22,  2.20it/s] 64%|██████▍   | 320/500 [03:43<01:00,  2.96it/s] 64%|██████▍   | 322/500 [03:50<03:34,  1.20s/it] 65%|██████▍   | 324/500 [03:50<02:32,  1.15it/s] 65%|██████▌   | 326/500 [03:50<01:50,  1.58it/s] 66%|██████▌   | 328/500 [03:50<01:20,  2.13it/s] 66%|██████▌   | 330/500 [03:51<01:00,  2.82it/s] 66%|██████▋   | 332/500 [03:57<03:25,  1.22s/it] 67%|██████▋   | 334/500 [03:57<02:25,  1.14it/s] 67%|██████▋   | 336/500 [03:57<01:43,  1.58it/s] 68%|██████▊   | 338/500 [03:57<01:15,  2.15it/s] 68%|██████▊   | 340/500 [03:58<00:55,  2.90it/s] 68%|██████▊   | 342/500 [04:04<03:09,  1.20s/it] 69%|██████▉   | 344/500 [04:04<02:14,  1.16it/s] 69%|██████▉   | 346/500 [04:04<01:35,  1.61it/s] 70%|██████▉   | 348/500 [04:04<01:09,  2.19it/s] 70%|███████   | 350/500 [04:05<00:50,  2.95it/s] 70%|███████   | 352/500 [04:11<03:00,  1.22s/it] 71%|███████   | 354/500 [04:11<02:07,  1.14it/s]Test Loss:  0.011011427268385887
Valid Loss:  0.017901713028550148
Epoch:  285  	Training Loss: 0.027601759880781174
Test Loss:  0.011000526137650013
Valid Loss:  0.017887674272060394
Epoch:  286  	Training Loss: 0.02759009785950184
Test Loss:  0.010989670641720295
Valid Loss:  0.017873691394925117
Epoch:  287  	Training Loss: 0.027578460052609444
Test Loss:  0.010978862643241882
Valid Loss:  0.017859764397144318
Epoch:  288  	Training Loss: 0.02756684087216854
Test Loss:  0.010968096554279327
Valid Loss:  0.017845895141363144
Epoch:  289  	Training Loss: 0.02755524404346943
Test Loss:  0.010957375168800354
Valid Loss:  0.01783207431435585
Epoch:  290  	Training Loss: 0.02754366770386696
Test Loss:  0.010946698486804962
Valid Loss:  0.01781831681728363
Epoch:  291  	Training Loss: 0.02753211185336113
Test Loss:  0.010936064645648003
Valid Loss:  0.017804613336920738
Epoch:  292  	Training Loss: 0.02752058580517769
Test Loss:  0.01092531904578209
Valid Loss:  0.0177907757461071
Epoch:  293  	Training Loss: 0.027508992701768875
Test Loss:  0.010914618149399757
Valid Loss:  0.01777699589729309
Epoch:  294  	Training Loss: 0.027497418224811554
Test Loss:  0.010903965681791306
Valid Loss:  0.01776326820254326
Epoch:  295  	Training Loss: 0.027485869824886322
Test Loss:  0.01089334674179554
Valid Loss:  0.017749596387147903
Epoch:  296  	Training Loss: 0.027474336326122284
Test Loss:  0.010882777161896229
Valid Loss:  0.017735974863171577
Epoch:  297  	Training Loss: 0.02746281959116459
Test Loss:  0.010872245766222477
Valid Loss:  0.01772240921854973
Epoch:  298  	Training Loss: 0.027451321482658386
Test Loss:  0.010861758142709732
Valid Loss:  0.01770889200270176
Epoch:  299  	Training Loss: 0.027439843863248825
Test Loss:  0.010851309634745121
Valid Loss:  0.01769542507827282
Epoch:  300  	Training Loss: 0.027428383007645607
Test Loss:  0.010840902104973793
Valid Loss:  0.01768200844526291
Epoch:  301  	Training Loss: 0.027416937053203583
Test Loss:  0.010830535553395748
Valid Loss:  0.017668645828962326
Epoch:  302  	Training Loss: 0.0274055115878582
Test Loss:  0.0108201764523983
Valid Loss:  0.017655299976468086
Epoch:  303  	Training Loss: 0.027394097298383713
Test Loss:  0.010809853672981262
Valid Loss:  0.017641998827457428
Epoch:  304  	Training Loss: 0.02738269977271557
Test Loss:  0.01079957652837038
Valid Loss:  0.0176287479698658
Epoch:  305  	Training Loss: 0.027371324598789215
Test Loss:  0.01078933384269476
Valid Loss:  0.01761554926633835
Epoch:  306  	Training Loss: 0.027359958738088608
Test Loss:  0.010779131203889847
Valid Loss:  0.017602425068616867
Epoch:  307  	Training Loss: 0.02734861895442009
Test Loss:  0.010768964886665344
Valid Loss:  0.017589367926120758
Epoch:  308  	Training Loss: 0.027337295934557915
Test Loss:  0.010758836753666401
Valid Loss:  0.017576374113559723
Epoch:  309  	Training Loss: 0.027325987815856934
Test Loss:  0.010748748667538166
Valid Loss:  0.017563441768288612
Epoch:  310  	Training Loss: 0.027314702048897743
Test Loss:  0.01073869876563549
Valid Loss:  0.017550554126501083
Epoch:  311  	Training Loss: 0.027303433045744896
Test Loss:  0.010728685185313225
Valid Loss:  0.017537716776132584
Epoch:  312  	Training Loss: 0.027292177081108093
Test Loss:  0.010718660429120064
Valid Loss:  0.017524849623441696
Epoch:  313  	Training Loss: 0.027280863374471664
Test Loss:  0.010708674788475037
Valid Loss:  0.01751203089952469
Epoch:  314  	Training Loss: 0.027269557118415833
Test Loss:  0.01069872360676527
Valid Loss:  0.01749926246702671
Epoch:  315  	Training Loss: 0.02725828066468239
Test Loss:  0.01068873517215252
Valid Loss:  0.017486466094851494
Epoch:  316  	Training Loss: 0.027247026562690735
Test Loss:  0.010678787715733051
Valid Loss:  0.01747371442615986
Epoch:  317  	Training Loss: 0.027235785499215126
Test Loss:  0.01066887378692627
Valid Loss:  0.017461009323596954
Epoch:  318  	Training Loss: 0.027224557474255562
Test Loss:  0.010658999904990196
Valid Loss:  0.01744835451245308
Epoch:  319  	Training Loss: 0.027213353663682938
Test Loss:  0.010649159550666809
Valid Loss:  0.01743575558066368
Epoch:  320  	Training Loss: 0.02720216102898121
Test Loss:  0.010639354586601257
Valid Loss:  0.01742321439087391
Epoch:  321  	Training Loss: 0.027190983295440674
Test Loss:  0.010629587806761265
Valid Loss:  0.017410721629858017
Epoch:  322  	Training Loss: 0.02717982977628708
Test Loss:  0.010619748383760452
Valid Loss:  0.01739809289574623
Epoch:  323  	Training Loss: 0.02716854214668274
Test Loss:  0.010609978809952736
Valid Loss:  0.01738550513982773
Epoch:  324  	Training Loss: 0.027157261967658997
Test Loss:  0.010600250214338303
Valid Loss:  0.017372971400618553
Epoch:  325  	Training Loss: 0.027146000415086746
Test Loss:  0.01059058029204607
Valid Loss:  0.01736048236489296
Epoch:  326  	Training Loss: 0.027134772390127182
Test Loss:  0.010580824688076973
Valid Loss:  0.01734783686697483
Epoch:  327  	Training Loss: 0.027123577892780304
Test Loss:  0.010571110993623734
Valid Loss:  0.017335258424282074
Epoch:  328  	Training Loss: 0.02711239829659462
Test Loss:  0.010561389848589897
Valid Loss:  0.017322653904557228
Epoch:  329  	Training Loss: 0.027101244777441025
Test Loss:  0.010551712475717068
Valid Loss:  0.01731010712683201
Epoch:  330  	Training Loss: 0.027090108022093773
Test Loss:  0.010542066767811775
Valid Loss:  0.017297595739364624
Epoch:  331  	Training Loss: 0.027078989893198013
Test Loss:  0.01053246296942234
Valid Loss:  0.017285138368606567
Epoch:  332  	Training Loss: 0.027067886665463448
Test Loss:  0.010522903874516487
Valid Loss:  0.017272772267460823
Epoch:  333  	Training Loss: 0.027056917548179626
Test Loss:  0.010513389483094215
Valid Loss:  0.01726045459508896
Epoch:  334  	Training Loss: 0.02704596519470215
Test Loss:  0.010503912344574928
Valid Loss:  0.017248185351490974
Epoch:  335  	Training Loss: 0.027035025879740715
Test Loss:  0.010494474321603775
Valid Loss:  0.01723596639931202
Epoch:  336  	Training Loss: 0.02702411264181137
Test Loss:  0.010485073551535606
Valid Loss:  0.017223788425326347
Epoch:  337  	Training Loss: 0.027013204991817474
Test Loss:  0.010475708171725273
Valid Loss:  0.017211660742759705
Epoch:  338  	Training Loss: 0.02700231969356537
Test Loss:  0.010466383770108223
Valid Loss:  0.017199581488966942
Epoch:  339  	Training Loss: 0.02699144557118416
Test Loss:  0.01045709103345871
Valid Loss:  0.01718754693865776
Epoch:  340  	Training Loss: 0.02698059007525444
Test Loss:  0.010447840206325054
Valid Loss:  0.01717555895447731
Epoch:  341  	Training Loss: 0.026969747617840767
Test Loss:  0.010438621044158936
Valid Loss:  0.017163611948490143
Epoch:  342  	Training Loss: 0.026958923786878586
Test Loss:  0.010429402813315392
Valid Loss:  0.017151664942502975
Epoch:  343  	Training Loss: 0.026948092505335808
Test Loss:  0.010420046746730804
Valid Loss:  0.017139526084065437
Epoch:  344  	Training Loss: 0.026937294751405716
Test Loss:  0.010410727933049202
Valid Loss:  0.017127439379692078
Epoch:  345  	Training Loss: 0.026926517486572266
Test Loss:  0.010401450097560883
Valid Loss:  0.0171153973788023
Epoch:  346  	Training Loss: 0.026915762573480606
Test Loss:  0.010391972959041595
Valid Loss:  0.01710309088230133
Epoch:  347  	Training Loss: 0.026905028149485588
Test Loss:  0.010382539592683315
Valid Loss:  0.017090830951929092
Epoch:  348  	Training Loss: 0.026894312351942062
Test Loss:  0.010373069904744625
Valid Loss:  0.017078522592782974
Epoch:  349  	Training Loss: 0.02688361145555973
Test Loss:  0.010363634675741196
Valid Loss:  0.017066245898604393
Epoch:  350  	Training Loss: 0.02687293291091919
Test Loss:  0.010354232043027878
Valid Loss:  0.01705402135848999
Epoch:  351  	Training Loss: 0.02686227113008499
Test Loss:  0.01034487783908844
Valid Loss:  0.017041854560375214
Epoch:  352  	Training Loss: 0.026851629838347435
Test Loss:  0.010335460305213928
Valid Loss:  0.017029600217938423
Epoch:  353  	Training Loss: 0.02684088423848152
Test Loss:  0.010326085612177849
Valid Loss:  0.017017394304275513
Epoch:  354  	Training Loss: 0.026830147951841354
Test Loss:  0.010316748172044754
Valid Loss:  0.017005231231451035
 71%|███████   | 356/500 [04:11<01:31,  1.58it/s] 72%|███████▏  | 358/500 [04:12<01:05,  2.16it/s] 72%|███████▏  | 360/500 [04:12<00:48,  2.90it/s] 72%|███████▏  | 362/500 [04:18<02:49,  1.22s/it] 73%|███████▎  | 364/500 [04:18<01:59,  1.14it/s] 73%|███████▎  | 366/500 [04:18<01:25,  1.57it/s] 74%|███████▎  | 368/500 [04:19<01:01,  2.14it/s] 74%|███████▍  | 370/500 [04:19<00:45,  2.84it/s] 74%|███████▍  | 372/500 [04:25<02:36,  1.22s/it] 75%|███████▍  | 374/500 [04:25<01:50,  1.14it/s] 75%|███████▌  | 376/500 [04:26<01:18,  1.58it/s] 76%|███████▌  | 378/500 [04:26<00:56,  2.16it/s] 76%|███████▌  | 380/500 [04:26<00:41,  2.91it/s] 76%|███████▋  | 382/500 [04:32<02:20,  1.19s/it] 77%|███████▋  | 384/500 [04:32<01:39,  1.17it/s] 77%|███████▋  | 386/500 [04:32<01:10,  1.61it/s] 78%|███████▊  | 388/500 [04:33<00:51,  2.17it/s] 78%|███████▊  | 390/500 [04:33<00:38,  2.88it/s] 78%|███████▊  | 392/500 [04:39<02:10,  1.21s/it] 79%|███████▉  | 394/500 [04:39<01:31,  1.16it/s] 79%|███████▉  | 396/500 [04:39<01:04,  1.60it/s] 80%|███████▉  | 398/500 [04:40<00:46,  2.19it/s] 80%|████████  | 400/500 [04:40<00:33,  2.94it/s] 80%|████████  | 402/500 [04:46<01:57,  1.20s/it] 81%|████████  | 404/500 [04:46<01:22,  1.16it/s] 81%|████████  | 406/500 [04:46<00:59,  1.59it/s] 82%|████████▏ | 408/500 [04:47<00:42,  2.15it/s] 82%|████████▏ | 410/500 [04:47<00:31,  2.85it/s] 82%|████████▏ | 412/500 [04:53<01:46,  1.21s/it] 83%|████████▎ | 414/500 [04:53<01:14,  1.15it/s] 83%|████████▎ | 416/500 [04:54<00:52,  1.59it/s] 84%|████████▎ | 418/500 [04:54<00:37,  2.17it/s] 84%|████████▍ | 420/500 [04:54<00:27,  2.90it/s] 84%|████████▍ | 422/500 [05:00<01:33,  1.19s/it] 85%|████████▍ | 424/500 [05:00<01:05,  1.17it/s]Epoch:  355  	Training Loss: 0.026819434016942978
Test Loss:  0.010307448916137218
Valid Loss:  0.016993127763271332
Epoch:  356  	Training Loss: 0.026808734983205795
Test Loss:  0.010298194363713264
Valid Loss:  0.016981065273284912
Epoch:  357  	Training Loss: 0.026798052713274956
Test Loss:  0.010288909077644348
Valid Loss:  0.01696898229420185
Epoch:  358  	Training Loss: 0.026787394657731056
Test Loss:  0.010279668495059013
Valid Loss:  0.01695694401860237
Epoch:  359  	Training Loss: 0.026776757091283798
Test Loss:  0.010270463302731514
Valid Loss:  0.01694495603442192
Epoch:  360  	Training Loss: 0.026766130700707436
Test Loss:  0.010261297225952148
Valid Loss:  0.0169330146163702
Epoch:  361  	Training Loss: 0.026755528524518013
Test Loss:  0.010252108797430992
Valid Loss:  0.016921041533350945
Epoch:  362  	Training Loss: 0.026744935661554337
Test Loss:  0.010243041440844536
Valid Loss:  0.016909277066588402
Epoch:  363  	Training Loss: 0.026734601706266403
Test Loss:  0.010233793407678604
Valid Loss:  0.016897257417440414
Epoch:  364  	Training Loss: 0.026724273338913918
Test Loss:  0.010224797762930393
Valid Loss:  0.016885576769709587
Epoch:  365  	Training Loss: 0.02671397104859352
Test Loss:  0.010215629823505878
Valid Loss:  0.01687365584075451
Epoch:  366  	Training Loss: 0.02670368365943432
Test Loss:  0.01020655408501625
Valid Loss:  0.016861852258443832
Epoch:  367  	Training Loss: 0.02669341489672661
Test Loss:  0.010197620838880539
Valid Loss:  0.016850236803293228
Epoch:  368  	Training Loss: 0.02668316662311554
Test Loss:  0.01018857304006815
Valid Loss:  0.016838479787111282
Epoch:  369  	Training Loss: 0.026672933250665665
Test Loss:  0.010179614648222923
Valid Loss:  0.01682683825492859
Epoch:  370  	Training Loss: 0.026662714779376984
Test Loss:  0.01017063856124878
Valid Loss:  0.01681516319513321
Epoch:  371  	Training Loss: 0.026652513071894646
Test Loss:  0.010161860845983028
Valid Loss:  0.016803760081529617
Epoch:  372  	Training Loss: 0.026642337441444397
Test Loss:  0.010152945294976234
Valid Loss:  0.016792166978120804
Epoch:  373  	Training Loss: 0.02663217857480049
Test Loss:  0.010144067928195
Valid Loss:  0.016780629754066467
Epoch:  374  	Training Loss: 0.02662203647196293
Test Loss:  0.010135229676961899
Valid Loss:  0.016769129782915115
Epoch:  375  	Training Loss: 0.02661190927028656
Test Loss:  0.010126428678631783
Valid Loss:  0.01675768941640854
Epoch:  376  	Training Loss: 0.026601802557706833
Test Loss:  0.01011766865849495
Valid Loss:  0.016746293753385544
Epoch:  377  	Training Loss: 0.0265917107462883
Test Loss:  0.0101089458912611
Valid Loss:  0.01673494465649128
Epoch:  378  	Training Loss: 0.026581639423966408
Test Loss:  0.010100259445607662
Valid Loss:  0.016723647713661194
Epoch:  379  	Training Loss: 0.02657158114016056
Test Loss:  0.01009160652756691
Valid Loss:  0.016712388023734093
Epoch:  380  	Training Loss: 0.026561539620161057
Test Loss:  0.010082937777042389
Valid Loss:  0.016701098531484604
Epoch:  381  	Training Loss: 0.026551518589258194
Test Loss:  0.010074306279420853
Valid Loss:  0.016689855605363846
Epoch:  382  	Training Loss: 0.026541514322161674
Test Loss:  0.01006569154560566
Valid Loss:  0.016678668558597565
Epoch:  383  	Training Loss: 0.02653159573674202
Test Loss:  0.010057112202048302
Valid Loss:  0.016667526215314865
Epoch:  384  	Training Loss: 0.02652168646454811
Test Loss:  0.010048571042716503
Valid Loss:  0.0166564229875803
Epoch:  385  	Training Loss: 0.026511792093515396
Test Loss:  0.010040068998932838
Valid Loss:  0.016645371913909912
Epoch:  386  	Training Loss: 0.026501920074224472
Test Loss:  0.010031599551439285
Valid Loss:  0.016634361818432808
Epoch:  387  	Training Loss: 0.026492055505514145
Test Loss:  0.010023163631558418
Valid Loss:  0.016623396426439285
Epoch:  388  	Training Loss: 0.02648220956325531
Test Loss:  0.01001476589590311
Valid Loss:  0.016612473875284195
Epoch:  389  	Training Loss: 0.02647237852215767
Test Loss:  0.01000639982521534
Valid Loss:  0.016601596027612686
Epoch:  390  	Training Loss: 0.026462556794285774
Test Loss:  0.009998069144785404
Valid Loss:  0.01659075915813446
Epoch:  391  	Training Loss: 0.026452751830220222
Test Loss:  0.009989770129323006
Valid Loss:  0.016579965129494667
Epoch:  392  	Training Loss: 0.026442956179380417
Test Loss:  0.00998149998486042
Valid Loss:  0.01656915992498398
Epoch:  393  	Training Loss: 0.026433035731315613
Test Loss:  0.009973259642720222
Valid Loss:  0.016558390110731125
Epoch:  394  	Training Loss: 0.0264231339097023
Test Loss:  0.00996505469083786
Valid Loss:  0.016547664999961853
Epoch:  395  	Training Loss: 0.026413241401314735
Test Loss:  0.009956877678632736
Valid Loss:  0.016536977142095566
Epoch:  396  	Training Loss: 0.026403360068798065
Test Loss:  0.009948736056685448
Valid Loss:  0.01652633398771286
Epoch:  397  	Training Loss: 0.026393501088023186
Test Loss:  0.009940478019416332
Valid Loss:  0.016515526920557022
Epoch:  398  	Training Loss: 0.02638365887105465
Test Loss:  0.009932201355695724
Valid Loss:  0.016504686325788498
Epoch:  399  	Training Loss: 0.026373837143182755
Test Loss:  0.009923949837684631
Valid Loss:  0.01649387553334236
Epoch:  400  	Training Loss: 0.026364030316472054
Test Loss:  0.009915729984641075
Valid Loss:  0.016483109444379807
Epoch:  401  	Training Loss: 0.026354238390922546
Test Loss:  0.009907545521855354
Valid Loss:  0.016472384333610535
Epoch:  402  	Training Loss: 0.026344463229179382
Test Loss:  0.009899403899908066
Valid Loss:  0.016461703926324844
Epoch:  403  	Training Loss: 0.02633468247950077
Test Loss:  0.009891295805573463
Valid Loss:  0.016451068222522736
Epoch:  404  	Training Loss: 0.026324918493628502
Test Loss:  0.009883223101496696
Valid Loss:  0.01644046977162361
Epoch:  405  	Training Loss: 0.026315173134207726
Test Loss:  0.009875175543129444
Valid Loss:  0.016429919749498367
Epoch:  406  	Training Loss: 0.026305442675948143
Test Loss:  0.009867165237665176
Valid Loss:  0.01641940325498581
Epoch:  407  	Training Loss: 0.026295725256204605
Test Loss:  0.009859185665845871
Valid Loss:  0.016408927738666534
Epoch:  408  	Training Loss: 0.026286020874977112
Test Loss:  0.009851236827671528
Valid Loss:  0.016398495063185692
Epoch:  409  	Training Loss: 0.02627633512020111
Test Loss:  0.009843321517109871
Valid Loss:  0.016388103365898132
Epoch:  410  	Training Loss: 0.026266664266586304
Test Loss:  0.009835436008870602
Valid Loss:  0.016377748921513557
Epoch:  411  	Training Loss: 0.026257002726197243
Test Loss:  0.00982758030295372
Valid Loss:  0.016367431730031967
Epoch:  412  	Training Loss: 0.026247356086969376
Test Loss:  0.00981973297894001
Valid Loss:  0.0163571797311306
Epoch:  413  	Training Loss: 0.02623787522315979
Test Loss:  0.009811913594603539
Valid Loss:  0.016346966847777367
Epoch:  414  	Training Loss: 0.02622840367257595
Test Loss:  0.009804124012589455
Valid Loss:  0.016336794942617416
Epoch:  415  	Training Loss: 0.026218950748443604
Test Loss:  0.009796368889510632
Valid Loss:  0.016326654702425003
Epoch:  416  	Training Loss: 0.026209503412246704
Test Loss:  0.009788639843463898
Valid Loss:  0.016316551715135574
Epoch:  417  	Training Loss: 0.026200074702501297
Test Loss:  0.009780941531062126
Valid Loss:  0.016306497156620026
Epoch:  418  	Training Loss: 0.026190659031271935
Test Loss:  0.00977327674627304
Valid Loss:  0.016296474263072014
Epoch:  419  	Training Loss: 0.026181261986494064
Test Loss:  0.009765638038516045
Valid Loss:  0.016286486759781837
Epoch:  420  	Training Loss: 0.02617187425494194
Test Loss:  0.009758027270436287
Valid Loss:  0.016276555135846138
Epoch:  421  	Training Loss: 0.02616250328719616
Test Loss:  0.009750445373356342
Valid Loss:  0.01626667194068432
Epoch:  422  	Training Loss: 0.026153139770030975
Test Loss:  0.009742865338921547
Valid Loss:  0.01625676639378071
Epoch:  423  	Training Loss: 0.026143701747059822
Test Loss:  0.009735308587551117
Valid Loss:  0.016246894374489784
Epoch:  424  	Training Loss: 0.026134271174669266
Test Loss:  0.00972778256982565
Valid Loss:  0.016237057745456696
Epoch:  425  	Training Loss: 0.026124855503439903
Test Loss:   85%|████████▌ | 426/500 [05:00<00:45,  1.61it/s] 86%|████████▌ | 428/500 [05:01<00:32,  2.20it/s] 86%|████████▌ | 430/500 [05:01<00:23,  2.95it/s] 86%|████████▋ | 432/500 [05:07<01:21,  1.20s/it] 87%|████████▋ | 434/500 [05:07<00:56,  1.17it/s] 87%|████████▋ | 436/500 [05:07<00:39,  1.61it/s] 88%|████████▊ | 438/500 [05:08<00:28,  2.20it/s] 88%|████████▊ | 440/500 [05:08<00:20,  2.96it/s] 88%|████████▊ | 442/500 [05:14<01:09,  1.19s/it] 89%|████████▉ | 444/500 [05:14<00:47,  1.17it/s] 89%|████████▉ | 446/500 [05:14<00:33,  1.62it/s] 90%|████████▉ | 448/500 [05:14<00:23,  2.21it/s] 90%|█████████ | 450/500 [05:15<00:16,  2.97it/s] 90%|█████████ | 452/500 [05:21<00:57,  1.20s/it] 91%|█████████ | 454/500 [05:21<00:39,  1.15it/s] 91%|█████████ | 456/500 [05:21<00:27,  1.59it/s] 92%|█████████▏| 458/500 [05:21<00:19,  2.15it/s] 92%|█████████▏| 460/500 [05:22<00:14,  2.85it/s] 92%|█████████▏| 462/500 [05:28<00:46,  1.22s/it] 93%|█████████▎| 464/500 [05:28<00:31,  1.14it/s] 93%|█████████▎| 466/500 [05:28<00:21,  1.57it/s] 94%|█████████▎| 468/500 [05:29<00:15,  2.13it/s] 94%|█████████▍| 470/500 [05:29<00:10,  2.87it/s] 94%|█████████▍| 472/500 [05:35<00:33,  1.19s/it] 95%|█████████▍| 474/500 [05:35<00:22,  1.17it/s] 95%|█████████▌| 476/500 [05:35<00:14,  1.61it/s] 96%|█████████▌| 478/500 [05:35<00:09,  2.20it/s] 96%|█████████▌| 480/500 [05:36<00:06,  2.96it/s] 96%|█████████▋| 482/500 [05:42<00:21,  1.19s/it] 97%|█████████▋| 484/500 [05:42<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:42<00:08,  1.62it/s] 98%|█████████▊| 488/500 [05:42<00:05,  2.21it/s] 98%|█████████▊| 490/500 [05:43<00:03,  2.93it/s] 98%|█████████▊| 492/500 [05:49<00:09,  1.21s/it] 99%|█████████▉| 494/500 [05:49<00:05,  1.15it/s]0.009720288217067719
Valid Loss:  0.01622726581990719
Epoch:  426  	Training Loss: 0.026115451008081436
Test Loss:  0.009712811559438705
Valid Loss:  0.01621750369668007
Epoch:  427  	Training Loss: 0.026106063276529312
Test Loss:  0.00970536656677723
Valid Loss:  0.016207780689001083
Epoch:  428  	Training Loss: 0.026096684858202934
Test Loss:  0.009697949513792992
Valid Loss:  0.016198085620999336
Epoch:  429  	Training Loss: 0.026087312027812004
Test Loss:  0.009690556675195694
Valid Loss:  0.016188427805900574
Epoch:  430  	Training Loss: 0.026077959686517715
Test Loss:  0.009683189913630486
Valid Loss:  0.016178805381059647
Epoch:  431  	Training Loss: 0.026068611070513725
Test Loss:  0.009675845503807068
Valid Loss:  0.016169212758541107
Epoch:  432  	Training Loss: 0.02605927549302578
Test Loss:  0.009668507613241673
Valid Loss:  0.016159653663635254
Epoch:  433  	Training Loss: 0.026050034910440445
Test Loss:  0.009661193937063217
Valid Loss:  0.016150128096342087
Epoch:  434  	Training Loss: 0.026040807366371155
Test Loss:  0.009653901681303978
Valid Loss:  0.016140637919306755
Epoch:  435  	Training Loss: 0.02603159099817276
Test Loss:  0.009646639227867126
Valid Loss:  0.01613118126988411
Epoch:  436  	Training Loss: 0.02602238953113556
Test Loss:  0.009639399126172066
Valid Loss:  0.01612175814807415
Epoch:  437  	Training Loss: 0.026013193652033806
Test Loss:  0.009632186032831669
Valid Loss:  0.016112366691231728
Epoch:  438  	Training Loss: 0.026004016399383545
Test Loss:  0.009624997153878212
Valid Loss:  0.01610301062464714
Epoch:  439  	Training Loss: 0.02599484845995903
Test Loss:  0.009617703035473824
Valid Loss:  0.016093477606773376
Epoch:  440  	Training Loss: 0.025985699146986008
Test Loss:  0.009610388427972794
Valid Loss:  0.01608389988541603
Epoch:  441  	Training Loss: 0.025976575911045074
Test Loss:  0.009603090584278107
Valid Loss:  0.016074344515800476
Epoch:  442  	Training Loss: 0.02596745826303959
Test Loss:  0.009595738723874092
Valid Loss:  0.01606469228863716
Epoch:  443  	Training Loss: 0.025958212092518806
Test Loss:  0.009588412940502167
Valid Loss:  0.01605508290231228
Epoch:  444  	Training Loss: 0.02594897337257862
Test Loss:  0.009581116028130054
Valid Loss:  0.016045495867729187
Epoch:  445  	Training Loss: 0.02593974769115448
Test Loss:  0.009573845192790031
Valid Loss:  0.016035955399274826
Epoch:  446  	Training Loss: 0.025930531322956085
Test Loss:  0.009566599503159523
Valid Loss:  0.0160264503210783
Epoch:  447  	Training Loss: 0.025921327993273735
Test Loss:  0.009559378027915955
Valid Loss:  0.016016971319913864
Epoch:  448  	Training Loss: 0.02591213583946228
Test Loss:  0.009552184492349625
Valid Loss:  0.016007527709007263
Epoch:  449  	Training Loss: 0.02590295672416687
Test Loss:  0.009545013308525085
Valid Loss:  0.01599811762571335
Epoch:  450  	Training Loss: 0.025893790647387505
Test Loss:  0.009537741541862488
Valid Loss:  0.015988532453775406
Epoch:  451  	Training Loss: 0.02588462457060814
Test Loss:  0.009530450217425823
Valid Loss:  0.01597890630364418
Epoch:  452  	Training Loss: 0.025875478982925415
Test Loss:  0.009523426182568073
Valid Loss:  0.01596970483660698
Epoch:  453  	Training Loss: 0.025866497308015823
Test Loss:  0.009516261518001556
Valid Loss:  0.01596026122570038
Epoch:  454  	Training Loss: 0.02585752308368683
Test Loss:  0.00950913317501545
Valid Loss:  0.01595086231827736
Epoch:  455  	Training Loss: 0.02584856189787388
Test Loss:  0.009502140805125237
Valid Loss:  0.015941690653562546
Epoch:  456  	Training Loss: 0.025839608162641525
Test Loss:  0.009495049715042114
Valid Loss:  0.015932343900203705
Epoch:  457  	Training Loss: 0.025830667465925217
Test Loss:  0.00948803499341011
Valid Loss:  0.015923112630844116
Epoch:  458  	Training Loss: 0.0258217453956604
Test Loss:  0.00948099885135889
Valid Loss:  0.015913834795355797
Epoch:  459  	Training Loss: 0.025812823325395584
Test Loss:  0.00947398692369461
Valid Loss:  0.015904590487480164
Epoch:  460  	Training Loss: 0.02580391615629196
Test Loss:  0.009467002004384995
Valid Loss:  0.015895385295152664
Epoch:  461  	Training Loss: 0.025795020163059235
Test Loss:  0.009460043162107468
Valid Loss:  0.015886209905147552
Epoch:  462  	Training Loss: 0.0257861390709877
Test Loss:  0.00945311225950718
Valid Loss:  0.015877079218626022
Epoch:  463  	Training Loss: 0.025777291506528854
Test Loss:  0.009446205571293831
Valid Loss:  0.01586798205971718
Epoch:  464  	Training Loss: 0.025768451392650604
Test Loss:  0.009439320303499699
Valid Loss:  0.01585891842842102
Epoch:  465  	Training Loss: 0.025759633630514145
Test Loss:  0.009432419203221798
Valid Loss:  0.015849824994802475
Epoch:  466  	Training Loss: 0.02575082890689373
Test Loss:  0.009425540454685688
Valid Loss:  0.015840761363506317
Epoch:  467  	Training Loss: 0.02574203908443451
Test Loss:  0.009418687783181667
Valid Loss:  0.015831731259822845
Epoch:  468  	Training Loss: 0.025733256712555885
Test Loss:  0.00941186212003231
Valid Loss:  0.01582273095846176
Epoch:  469  	Training Loss: 0.025724485516548157
Test Loss:  0.00940505787730217
Valid Loss:  0.015813766047358513
Epoch:  470  	Training Loss: 0.025715727359056473
Test Loss:  0.009398277848958969
Valid Loss:  0.0158048328012228
Epoch:  471  	Training Loss: 0.025706978514790535
Test Loss:  0.009391523897647858
Valid Loss:  0.015795929357409477
Epoch:  472  	Training Loss: 0.02569824457168579
Test Loss:  0.009384742006659508
Valid Loss:  0.015786970034241676
Epoch:  473  	Training Loss: 0.02568938210606575
Test Loss:  0.009377984330058098
Valid Loss:  0.015778042376041412
Epoch:  474  	Training Loss: 0.025680527091026306
Test Loss:  0.00937124714255333
Valid Loss:  0.015769142657518387
Epoch:  475  	Training Loss: 0.025671683251857758
Test Loss:  0.00936453603208065
Valid Loss:  0.0157602708786726
Epoch:  476  	Training Loss: 0.025662846863269806
Test Loss:  0.009357847273349762
Valid Loss:  0.0157514326274395
Epoch:  477  	Training Loss: 0.02565402165055275
Test Loss:  0.009351177141070366
Valid Loss:  0.015742622315883636
Epoch:  478  	Training Loss: 0.025645211338996887
Test Loss:  0.009344534948468208
Valid Loss:  0.015733839944005013
Epoch:  479  	Training Loss: 0.02563640847802162
Test Loss:  0.009337909519672394
Valid Loss:  0.015725091099739075
Epoch:  480  	Training Loss: 0.025627614930272102
Test Loss:  0.00933130830526352
Valid Loss:  0.015716366469860077
Epoch:  481  	Training Loss: 0.02561883069574833
Test Loss:  0.009324727579951286
Valid Loss:  0.015707669779658318
Epoch:  482  	Training Loss: 0.025610053911805153
Test Loss:  0.009318286553025246
Valid Loss:  0.015699172392487526
Epoch:  483  	Training Loss: 0.025601472705602646
Test Loss:  0.009311872534453869
Valid Loss:  0.015690701082348824
Epoch:  484  	Training Loss: 0.025592898949980736
Test Loss:  0.009305475279688835
Valid Loss:  0.01568225957453251
Epoch:  485  	Training Loss: 0.02558434009552002
Test Loss:  0.009299100376665592
Valid Loss:  0.015673842281103134
Epoch:  486  	Training Loss: 0.02557578682899475
Test Loss:  0.009292742237448692
Valid Loss:  0.015665460377931595
Epoch:  487  	Training Loss: 0.025567246600985527
Test Loss:  0.009286407381296158
Valid Loss:  0.0156570915132761
Epoch:  488  	Training Loss: 0.0255587138235569
Test Loss:  0.009280091151595116
Valid Loss:  0.01564875990152359
Epoch:  489  	Training Loss: 0.025550197809934616
Test Loss:  0.009273798204958439
Valid Loss:  0.01564045622944832
Epoch:  490  	Training Loss: 0.025541692972183228
Test Loss:  0.009267520159482956
Valid Loss:  0.015632178634405136
Epoch:  491  	Training Loss: 0.025533199310302734
Test Loss:  0.009261267259716988
Valid Loss:  0.015623919665813446
Epoch:  492  	Training Loss: 0.02552470937371254
Test Loss:  0.009254968725144863
Valid Loss:  0.015615655109286308
Epoch:  493  	Training Loss: 0.02551627904176712
Test Loss:  0.009248699992895126
Valid Loss:  0.015607410110533237
Epoch:  494  	Training Loss: 0.02550785429775715
Test Loss:  0.009242447093129158
Valid Loss:  0.015599193051457405
Epoch:  495  	Training Loss: 0.025499433279037476
Test Loss:  0.009236209094524384
Valid Loss:  0.015591002069413662
 99%|█████████▉| 496/500 [05:49<00:02,  1.59it/s]100%|█████████▉| 498/500 [05:49<00:00,  2.18it/s]100%|██████████| 500/500 [05:50<00:00,  2.92it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
Epoch:  496  	Training Loss: 0.025491030886769295
Test Loss:  0.009229994378983974
Valid Loss:  0.015582838095724583
Epoch:  497  	Training Loss: 0.025482632219791412
Test Loss:  0.009223800152540207
Valid Loss:  0.015574697405099869
Epoch:  498  	Training Loss: 0.025474246591329575
Test Loss:  0.009217618964612484
Valid Loss:  0.015566580928862095
Epoch:  499  	Training Loss: 0.025465872138738632
Test Loss:  0.00921146385371685
Valid Loss:  0.015558488667011261
Epoch:  500  	Training Loss: 0.02545749768614769
Test Loss:  0.009205322712659836
Valid Loss:  0.015550423413515091
seed is  8
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:46,  6.35s/it]  1%|          | 3/500 [00:06<14:03,  1.70s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.90it/s]  2%|▏         | 9/500 [00:06<02:57,  2.77it/s]  2%|▏         | 11/500 [00:13<10:57,  1.34s/it]  3%|▎         | 13/500 [00:13<07:30,  1.08it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:46,  2.13it/s]  4%|▍         | 19/500 [00:13<02:47,  2.87it/s]  4%|▍         | 21/500 [00:20<09:44,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:26<12:33,  1.59s/it]  5%|▌         | 27/500 [00:27<08:53,  1.13s/it]  6%|▌         | 29/500 [00:27<06:20,  1.24it/s]  6%|▌         | 31/500 [00:33<12:03,  1.54s/it]  7%|▋         | 33/500 [00:33<08:33,  1.10s/it]  7%|▋         | 35/500 [00:40<13:29,  1.74s/it]  7%|▋         | 37/500 [00:40<09:33,  1.24s/it]  8%|▊         | 39/500 [00:40<06:48,  1.13it/s]  8%|▊         | 41/500 [00:46<12:07,  1.59s/it]  9%|▊         | 43/500 [00:47<08:39,  1.14s/it]  9%|▉         | 45/500 [00:47<06:12,  1.22it/s]  9%|▉         | 47/500 [00:47<04:29,  1.68it/s] 10%|▉         | 49/500 [00:47<03:17,  2.28it/s] 10%|█         | 51/500 [00:54<09:33,  1.28s/it] 11%|█         | 53/500 [00:54<06:49,  1.09it/s] 11%|█         | 55/500 [00:54<04:54,  1.51it/s] 11%|█▏        | 57/500 [00:54<03:35,  2.05it/s] 12%|█▏        | 59/500 [00:54<02:41,  2.73it/s] 12%|█▏        | 61/500 [01:01<09:00,  1.23s/it] 13%|█▎        | 63/500 [01:01<06:25,  1.13it/s] 13%|█▎        | 65/500 [01:01<04:37,  1.57it/s] 13%|█▎        | 67/500 [01:01<03:21,  2.15it/s]Epoch:  1  	Training Loss: 0.029436571523547173
Test Loss:  0.009880593046545982
Valid Loss:  0.01199309527873993
Epoch:  2  	Training Loss: 0.013985118828713894
Test Loss:  0.01586250588297844
Valid Loss:  0.010918689891695976
Epoch:  3  	Training Loss: 0.011317507363855839
Test Loss:  0.0821094959974289
Valid Loss:  0.09365524351596832
Epoch:  4  	Training Loss: 0.12295915186405182
Test Loss:  0.08829143643379211
Valid Loss:  0.07424844801425934
Epoch:  5  	Training Loss: 0.06729579716920853
Test Loss:  0.008922559209167957
Valid Loss:  0.010537901893258095
Epoch:  6  	Training Loss: 0.012776718474924564
Test Loss:  0.009035272523760796
Valid Loss:  0.009743506088852882
Epoch:  7  	Training Loss: 0.011306794360280037
Test Loss:  0.008202844299376011
Valid Loss:  0.008590037003159523
Epoch:  8  	Training Loss: 0.010167114436626434
Test Loss:  0.007407563738524914
Valid Loss:  0.00757100572809577
Epoch:  9  	Training Loss: 0.009181821718811989
Test Loss:  0.006707041524350643
Valid Loss:  0.006699665449559689
Epoch:  10  	Training Loss: 0.008324999362230301
Test Loss:  0.0061087035574018955
Valid Loss:  0.005964633077383041
Epoch:  11  	Training Loss: 0.007581812795251608
Test Loss:  0.005589834414422512
Valid Loss:  0.005342880263924599
Epoch:  12  	Training Loss: 0.006938911508768797
Test Loss:  0.008827709592878819
Valid Loss:  0.005739743355661631
Epoch:  13  	Training Loss: 0.006682022474706173
Test Loss:  0.003930896986275911
Valid Loss:  0.006595544517040253
Epoch:  14  	Training Loss: 0.010694322176277637
Test Loss:  0.009690595790743828
Valid Loss:  0.006124300882220268
Epoch:  15  	Training Loss: 0.007189392577856779
Test Loss:  0.0030657006427645683
Valid Loss:  0.0042807236313819885
Epoch:  16  	Training Loss: 0.006759009324014187
Test Loss:  0.008064906112849712
Valid Loss:  0.005071854218840599
Epoch:  17  	Training Loss: 0.006097061559557915
Test Loss:  0.0024886883329600096
Valid Loss:  0.0035461841616779566
Epoch:  18  	Training Loss: 0.005627325735986233
Test Loss:  0.006887434981763363
Valid Loss:  0.004358617588877678
Epoch:  19  	Training Loss: 0.005376233719289303
Test Loss:  0.002214382868260145
Valid Loss:  0.003118218155577779
Epoch:  20  	Training Loss: 0.004969663918018341
Test Loss:  0.005670351441949606
Valid Loss:  0.0036742468364536762
Epoch:  21  	Training Loss: 0.004693209193646908
Test Loss:  0.0021799388341605663
Valid Loss:  0.0028008294757455587
Epoch:  22  	Training Loss: 0.004420214332640171
Test Loss:  0.00517266895622015
Valid Loss:  0.0033308491110801697
Epoch:  23  	Training Loss: 0.004347061738371849
Test Loss:  0.001964251510798931
Valid Loss:  0.0029162042774260044
Epoch:  24  	Training Loss: 0.004504061304032803
Test Loss:  0.006021751090884209
Valid Loss:  0.003622782649472356
Epoch:  25  	Training Loss: 0.004637160338461399
Test Loss:  0.0020567597821354866
Valid Loss:  0.003321901196613908
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.005054399371147156
Test Loss:  0.002097994089126587
Valid Loss:  0.00201409962028265
Epoch:  27  	Training Loss: 0.002926223911345005
Test Loss:  0.0016350087244063616
Valid Loss:  0.0018033147789537907
Epoch:  28  	Training Loss: 0.0025302115827798843
Test Loss:  0.0015916028060019016
Valid Loss:  0.0017637629061937332
Epoch:  29  	Training Loss: 0.0023249047808349133
Test Loss:  0.0015837947139516473
Valid Loss:  0.001801719656214118
Epoch:  30  	Training Loss: 0.0022560297511518
Test Loss:  0.0016931758727878332
Valid Loss:  0.001808568136766553
Epoch:  31  	Training Loss: 0.0022083274088799953
Test Loss:  0.0016753770178183913
Valid Loss:  0.0018549325177446008
Epoch:  32  	Training Loss: 0.0021929116919636726
Test Loss:  0.0019445933867245913
Valid Loss:  0.0018428713083267212
Epoch:  33  	Training Loss: 0.002056065946817398
Test Loss:  0.0013659955002367496
Valid Loss:  0.001939785317517817
Epoch:  34  	Training Loss: 0.002068426925688982
Test Loss:  0.0022121102083474398
Valid Loss:  0.0019430516986176372
Epoch:  35  	Training Loss: 0.0021704542450606823
Test Loss:  0.0013021398335695267
Valid Loss:  0.0022733593359589577
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0024555493146181107
Test Loss:  0.0012814768124371767
Valid Loss:  0.0019113804446533322
Epoch:  37  	Training Loss: 0.002104496117681265
Test Loss:  0.0013477324973791838
Valid Loss:  0.0018070032820105553
Epoch:  38  	Training Loss: 0.0020034140907227993
Test Loss:  0.0014056595973670483
Valid Loss:  0.001765577937476337
Epoch:  39  	Training Loss: 0.001964564435184002
Test Loss:  0.0014414740726351738
Valid Loss:  0.0017461495008319616
Epoch:  40  	Training Loss: 0.0019472657004371285
Test Loss:  0.0014635879779234529
Valid Loss:  0.0017341175116598606
Epoch:  41  	Training Loss: 0.0019365621265023947
Test Loss:  0.001474930439144373
Valid Loss:  0.0017245797207579017
Epoch:  42  	Training Loss: 0.0019281203858554363
Test Loss:  0.0015095819253474474
Valid Loss:  0.0017112246714532375
Epoch:  43  	Training Loss: 0.0019083949737250805
Test Loss:  0.0015145625220611691
Valid Loss:  0.0017077254597097635
Epoch:  44  	Training Loss: 0.0019003415945917368
Test Loss:  0.0015139037277549505
Valid Loss:  0.0017070656176656485
Epoch:  45  	Training Loss: 0.0018963583279401064
Test Loss:  0.0015108056832104921
Valid Loss:  0.0017068501329049468
Epoch:  46  	Training Loss: 0.001893279142677784
Test Loss:  0.0015109836822375655
Valid Loss:  0.0017071240581572056
Epoch:  47  	Training Loss: 0.0018907198682427406
Test Loss:  0.001511822221800685
Valid Loss:  0.0017078237142413855
Epoch:  48  	Training Loss: 0.0018883817829191685
Test Loss:  0.0015115832211449742
Valid Loss:  0.0017087692394852638
Epoch:  49  	Training Loss: 0.0018861157586798072
Test Loss:  0.0015118429437279701
Valid Loss:  0.0017099768156185746
Epoch:  50  	Training Loss: 0.0018839839613065124
Test Loss:  0.001512282295152545
Valid Loss:  0.0017113392241299152
Epoch:  51  	Training Loss: 0.0018819763790816069
Test Loss:  0.0015131152467802167
Valid Loss:  0.0017129312036558986
Epoch:  52  	Training Loss: 0.0018800735706463456
Test Loss:  0.0014854947803542018
Valid Loss:  0.001700213411822915
Epoch:  53  	Training Loss: 0.0018561024917289615
Test Loss:  0.0014623242896050215
Valid Loss:  0.0016875416040420532
Epoch:  54  	Training Loss: 0.0018334034830331802
Test Loss:  0.0014432469615712762
Valid Loss:  0.0016750539653003216
Epoch:  55  	Training Loss: 0.00181185407564044
Test Loss:  0.0014272475382313132
Valid Loss:  0.0016638239612802863
Epoch:  56  	Training Loss: 0.0017908266745507717
Test Loss:  0.0014126123860478401
Valid Loss:  0.0016533907037228346
Epoch:  57  	Training Loss: 0.0017702914774417877
Test Loss:  0.001401241053827107
Valid Loss:  0.0016437979647889733
Epoch:  58  	Training Loss: 0.0017502338159829378
Test Loss:  0.001393984304741025
Valid Loss:  0.0016351735685020685
Epoch:  59  	Training Loss: 0.0017306350637227297
Test Loss:  0.0013896918389946222
Valid Loss:  0.0016271356726065278
Epoch:  60  	Training Loss: 0.0017120031407102942
Test Loss:  0.00138636224437505
Valid Loss:  0.0016196486540138721
Epoch:  61  	Training Loss: 0.001695278799161315
Test Loss:  0.0013834760757163167
Valid Loss:  0.0016126311384141445
Epoch:  62  	Training Loss: 0.0016798251308500767
Test Loss:  0.0013550773728638887
Valid Loss:  0.0016242281999439
Epoch:  63  	Training Loss: 0.001671485137194395
Test Loss:  0.0013672823552042246
Valid Loss:  0.0016246566083282232
Epoch:  64  	Training Loss: 0.0016688238829374313
Test Loss:  0.0013726097531616688
Valid Loss:  0.001626678160391748
Epoch:  65  	Training Loss: 0.0016670410986989737
Test Loss:  0.0013678811956197023
Valid Loss:  0.0016302253352478147
Epoch:  66  	Training Loss: 0.0016650240868330002
Test Loss:  0.0013714738888666034
Valid Loss:  0.0016306241741403937
Epoch:  67  	Training Loss: 0.0016623212723061442
Test Loss:  0.0013644784921780229
Valid Loss:  0.0016299511771649122
Epoch:  68  	Training Loss: 0.001658161636441946
Test Loss:  0.0013644807040691376
Valid Loss:   14%|█▍        | 69/500 [01:01<02:29,  2.89it/s] 14%|█▍        | 71/500 [01:08<08:38,  1.21s/it] 15%|█▍        | 73/500 [01:08<06:10,  1.15it/s] 15%|█▌        | 75/500 [01:08<04:26,  1.59it/s] 15%|█▌        | 77/500 [01:08<03:14,  2.18it/s] 16%|█▌        | 79/500 [01:08<02:23,  2.93it/s] 16%|█▌        | 81/500 [01:15<08:24,  1.20s/it] 17%|█▋        | 83/500 [01:15<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:15<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:15<03:09,  2.18it/s] 18%|█▊        | 89/500 [01:15<02:20,  2.92it/s] 18%|█▊        | 91/500 [01:22<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:22<05:49,  1.16it/s] 19%|█▉        | 95/500 [01:22<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:22<03:03,  2.19it/s] 20%|█▉        | 99/500 [01:22<02:16,  2.95it/s] 20%|█▉        | 99/500 [01:33<02:16,  2.95it/s] 20%|██        | 101/500 [01:35<14:11,  2.14s/it] 21%|██        | 103/500 [01:35<10:02,  1.52s/it] 21%|██        | 105/500 [01:35<07:07,  1.08s/it] 21%|██▏       | 107/500 [01:35<05:07,  1.28it/s] 22%|██▏       | 109/500 [01:35<03:43,  1.75it/s] 22%|██▏       | 111/500 [01:42<08:44,  1.35s/it] 23%|██▎       | 113/500 [01:42<06:15,  1.03it/s] 23%|██▎       | 115/500 [01:42<04:31,  1.42it/s] 23%|██▎       | 117/500 [01:42<03:18,  1.93it/s] 24%|██▍       | 119/500 [01:42<02:28,  2.56it/s] 24%|██▍       | 121/500 [01:49<07:40,  1.22s/it] 25%|██▍       | 123/500 [01:49<05:28,  1.15it/s] 25%|██▌       | 125/500 [01:49<03:56,  1.59it/s] 25%|██▌       | 127/500 [01:49<02:51,  2.17it/s] 26%|██▌       | 129/500 [01:49<02:07,  2.92it/s] 26%|██▌       | 131/500 [01:56<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:56<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:56<03:49,  1.59it/s]0.0016255187802016735
Epoch:  69  	Training Loss: 0.0016530598513782024
Test Loss:  0.001354485866613686
Valid Loss:  0.001621718518435955
Epoch:  70  	Training Loss: 0.0016472290735691786
Test Loss:  0.0013539150822907686
Valid Loss:  0.0016159650404006243
Epoch:  71  	Training Loss: 0.001641604001633823
Test Loss:  0.0013467443641275167
Valid Loss:  0.0016144649125635624
Epoch:  72  	Training Loss: 0.0016372394748032093
Test Loss:  0.0013642904814332724
Valid Loss:  0.0016177021898329258
Epoch:  73  	Training Loss: 0.0016222211997956038
Test Loss:  0.0013739706482738256
Valid Loss:  0.0016254556830972433
Epoch:  74  	Training Loss: 0.0016138411592692137
Test Loss:  0.0013773180544376373
Valid Loss:  0.001634764252230525
Epoch:  75  	Training Loss: 0.0016091238940134645
Test Loss:  0.0013797166757285595
Valid Loss:  0.001643423456698656
Epoch:  76  	Training Loss: 0.0016057369066402316
Test Loss:  0.0013804645277559757
Valid Loss:  0.0016516963951289654
Epoch:  77  	Training Loss: 0.0016036586603149772
Test Loss:  0.0013779244618490338
Valid Loss:  0.00165849132463336
Epoch:  78  	Training Loss: 0.0016026621451601386
Test Loss:  0.0013768207281827927
Valid Loss:  0.0016640473622828722
Epoch:  79  	Training Loss: 0.0016019206959754229
Test Loss:  0.0013759132707491517
Valid Loss:  0.0016684597358107567
Epoch:  80  	Training Loss: 0.0016013996209949255
Test Loss:  0.0013744058087468147
Valid Loss:  0.0016719391569495201
Epoch:  81  	Training Loss: 0.0016010832041501999
Test Loss:  0.001373903825879097
Valid Loss:  0.0016746066976338625
Epoch:  82  	Training Loss: 0.0016008386155590415
Test Loss:  0.0013308748602867126
Valid Loss:  0.0016527066472917795
Epoch:  83  	Training Loss: 0.0015761938411742449
Test Loss:  0.001317702466621995
Valid Loss:  0.0016342820599675179
Epoch:  84  	Training Loss: 0.0015568087110295892
Test Loss:  0.0013113344321027398
Valid Loss:  0.0016177587676793337
Epoch:  85  	Training Loss: 0.001539825927466154
Test Loss:  0.001305833226069808
Valid Loss:  0.0016035233857110143
Epoch:  86  	Training Loss: 0.0015244135865941644
Test Loss:  0.0013021937338635325
Valid Loss:  0.001590166473761201
Epoch:  87  	Training Loss: 0.0015105832135304809
Test Loss:  0.0012962670298293233
Valid Loss:  0.0015795865328982472
Epoch:  88  	Training Loss: 0.0014976048842072487
Test Loss:  0.0012914869002997875
Valid Loss:  0.0015685866819694638
Epoch:  89  	Training Loss: 0.0014852082822471857
Test Loss:  0.0012848771875724196
Valid Loss:  0.0015597392339259386
Epoch:  90  	Training Loss: 0.0014732059789821506
Test Loss:  0.0012790944892913103
Valid Loss:  0.0015500725712627172
Epoch:  91  	Training Loss: 0.0014615838881582022
Test Loss:  0.0012629629345610738
Valid Loss:  0.001543319784104824
Epoch:  92  	Training Loss: 0.0014504676219075918
Test Loss:  0.0012554635759443045
Valid Loss:  0.0015462497249245644
Epoch:  93  	Training Loss: 0.0014479908859357238
Test Loss:  0.001248275162652135
Valid Loss:  0.0015485025942325592
Epoch:  94  	Training Loss: 0.0014464800478890538
Test Loss:  0.0012403703294694424
Valid Loss:  0.001550324959680438
Epoch:  95  	Training Loss: 0.0014459260273724794
Test Loss:  0.0012428818736225367
Valid Loss:  0.0015487202908843756
Epoch:  96  	Training Loss: 0.0014452262548729777
Test Loss:  0.0012299008667469025
Valid Loss:  0.001552185625769198
Epoch:  97  	Training Loss: 0.0014453819021582603
Test Loss:  0.0012391767231747508
Valid Loss:  0.0015480127185583115
Epoch:  98  	Training Loss: 0.0014443009858950973
Test Loss:  0.001230624970048666
Valid Loss:  0.0015503063332289457
Epoch:  99  	Training Loss: 0.001444426248781383
Test Loss:  0.0012424665037542582
Valid Loss:  0.001545564504340291
Epoch:  100  	Training Loss: 0.0014443588443100452
Test Loss:  0.0012176267337054014
Valid Loss:  0.0015536302234977484
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.0014457881916314363
Test Loss:  0.001229626126587391
Valid Loss:  0.0015501521993428469
Epoch:  102  	Training Loss: 0.001443105167709291
Test Loss:  0.0012292928295210004
Valid Loss:  0.0015375670045614243
Epoch:  103  	Training Loss: 0.0014314842410385609
Test Loss:  0.0012279959628358483
Valid Loss:  0.0015308253932744265
Epoch:  104  	Training Loss: 0.00142291106749326
Test Loss:  0.0012274566106498241
Valid Loss:  0.0015264926478266716
Epoch:  105  	Training Loss: 0.0014154799282550812
Test Loss:  0.0012264291290193796
Valid Loss:  0.0015229792334139347
Epoch:  106  	Training Loss: 0.00140842713881284
Test Loss:  0.0012266546254977584
Valid Loss:  0.0015193894505500793
Epoch:  107  	Training Loss: 0.0014015717897564173
Test Loss:  0.001224631443619728
Valid Loss:  0.0015166939701884985
Epoch:  108  	Training Loss: 0.0013951120199635625
Test Loss:  0.0012242759112268686
Valid Loss:  0.001513677416369319
Epoch:  109  	Training Loss: 0.0013889374677091837
Test Loss:  0.0012218786869198084
Valid Loss:  0.0015112198889255524
Epoch:  110  	Training Loss: 0.001382946502417326
Test Loss:  0.0012210765853524208
Valid Loss:  0.0015084522310644388
Epoch:  111  	Training Loss: 0.0013771485537290573
Test Loss:  0.0012198938056826591
Valid Loss:  0.0015059441793709993
Epoch:  112  	Training Loss: 0.001371549442410469
Test Loss:  0.0012209129054099321
Valid Loss:  0.001502098049968481
Epoch:  113  	Training Loss: 0.0013701217249035835
Test Loss:  0.001221127575263381
Valid Loss:  0.001499353675171733
Epoch:  114  	Training Loss: 0.0013688607141375542
Test Loss:  0.0012211577268317342
Valid Loss:  0.0014968211762607098
Epoch:  115  	Training Loss: 0.0013676261296495795
Test Loss:  0.0012209359556436539
Valid Loss:  0.0014945848379284143
Epoch:  116  	Training Loss: 0.0013664118014276028
Test Loss:  0.0012205872917547822
Valid Loss:  0.0014924871502444148
Epoch:  117  	Training Loss: 0.001365207601338625
Test Loss:  0.0012200337368994951
Valid Loss:  0.0014906232245266438
Epoch:  118  	Training Loss: 0.0013640164397656918
Test Loss:  0.001219302648678422
Valid Loss:  0.0014889613958075643
Epoch:  119  	Training Loss: 0.0013628307497128844
Test Loss:  0.0012186134699732065
Valid Loss:  0.001487242174334824
Epoch:  120  	Training Loss: 0.0013616487849503756
Test Loss:  0.0012177671305835247
Valid Loss:  0.001485703163780272
Epoch:  121  	Training Loss: 0.0013604687992483377
Test Loss:  0.0012168802786618471
Valid Loss:  0.0014842045493423939
Epoch:  122  	Training Loss: 0.0013592917239293456
Test Loss:  0.001204863889142871
Valid Loss:  0.0014809982385486364
Epoch:  123  	Training Loss: 0.0013461119960993528
Test Loss:  0.0011917235096916556
Valid Loss:  0.0014777075266465545
Epoch:  124  	Training Loss: 0.0013319854624569416
Test Loss:  0.0011779663618654013
Valid Loss:  0.001474012853577733
Epoch:  125  	Training Loss: 0.0013170699821785092
Test Loss:  0.0011635753326117992
Valid Loss:  0.0014700269093737006
Epoch:  126  	Training Loss: 0.0013012879062443972
Test Loss:  0.0011504166759550571
Valid Loss:  0.0014658058062195778
Epoch:  127  	Training Loss: 0.0012856237590312958
Test Loss:  0.0011385618709027767
Valid Loss:  0.0014617566484957933
Epoch:  128  	Training Loss: 0.0012709579896181822
Test Loss:  0.0011297859018668532
Valid Loss:  0.001458341022953391
Epoch:  129  	Training Loss: 0.001258279662579298
Test Loss:  0.001122377347201109
Valid Loss:  0.0014553857035934925
Epoch:  130  	Training Loss: 0.0012465664185583591
Test Loss:  0.0011173776583746076
Valid Loss:  0.0014517558738589287
Epoch:  131  	Training Loss: 0.0012372564524412155
Test Loss:  0.0011155232787132263
Valid Loss:  0.0014477877411991358
Epoch:  132  	Training Loss: 0.0012305834097787738
Test Loss:  0.0011110780760645866
Valid Loss:  0.0014401213265955448
Epoch:  133  	Training Loss: 0.0012211931170895696
Test Loss:  0.0011076848022639751
Valid Loss:  0.001432707067579031
Epoch:  134  	Training Loss: 0.0012121491599828005
Test Loss:  0.001105265924707055
Valid Loss:  0.0014257407747209072
Epoch:  135  	Training Loss: 0.0012035367544740438
Test Loss:  0.0011027440195903182
Valid Loss:  0.0014192003291100264
Epoch:  136  	Training Loss: 0.0011954535730183125
Test Loss:  0.0011006128042936325 27%|██▋       | 137/500 [01:56<02:48,  2.16it/s] 28%|██▊       | 139/500 [01:56<02:04,  2.91it/s] 28%|██▊       | 141/500 [02:03<07:05,  1.19s/it] 29%|██▊       | 143/500 [02:03<05:05,  1.17it/s] 29%|██▉       | 145/500 [02:03<03:39,  1.62it/s] 29%|██▉       | 147/500 [02:03<02:39,  2.21it/s] 30%|██▉       | 149/500 [02:03<01:58,  2.97it/s] 30%|███       | 151/500 [02:09<06:57,  1.20s/it] 31%|███       | 153/500 [02:10<04:57,  1.17it/s] 31%|███       | 155/500 [02:10<03:33,  1.61it/s] 31%|███▏      | 157/500 [02:10<02:35,  2.20it/s] 32%|███▏      | 159/500 [02:10<01:54,  2.97it/s] 32%|███▏      | 161/500 [02:16<06:47,  1.20s/it] 33%|███▎      | 163/500 [02:17<04:52,  1.15it/s] 33%|███▎      | 165/500 [02:17<03:32,  1.58it/s] 33%|███▎      | 167/500 [02:17<02:35,  2.14it/s] 34%|███▍      | 169/500 [02:17<01:54,  2.89it/s] 34%|███▍      | 171/500 [02:23<06:36,  1.20s/it] 35%|███▍      | 173/500 [02:24<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:24<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:24<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:24<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:31<06:27,  1.22s/it] 36%|███▋      | 182/500 [02:31<05:23,  1.02s/it] 37%|███▋      | 184/500 [02:31<03:40,  1.43it/s] 37%|███▋      | 186/500 [02:31<02:36,  2.01it/s] 38%|███▊      | 188/500 [02:31<01:54,  2.72it/s] 38%|███▊      | 190/500 [02:31<01:26,  3.57it/s] 38%|███▊      | 192/500 [02:38<06:04,  1.18s/it] 39%|███▉      | 194/500 [02:38<04:19,  1.18it/s] 39%|███▉      | 196/500 [02:38<03:06,  1.63it/s] 40%|███▉      | 198/500 [02:38<02:15,  2.22it/s] 40%|████      | 200/500 [02:38<01:40,  2.97it/s] 40%|████      | 202/500 [02:45<05:53,  1.19s/it] 41%|████      | 204/500 [02:45<04:11,  1.18it/s]
Valid Loss:  0.0014129012124612927
Epoch:  137  	Training Loss: 0.0011878050863742828
Test Loss:  0.0010999356163665652
Valid Loss:  0.0014065768336877227
Epoch:  138  	Training Loss: 0.001180758816190064
Test Loss:  0.0010973496828228235
Valid Loss:  0.0014011950697749853
Epoch:  139  	Training Loss: 0.001174186822026968
Test Loss:  0.001096494379453361
Valid Loss:  0.0013957344926893711
Epoch:  140  	Training Loss: 0.0011679541785269976
Test Loss:  0.0010951792355626822
Valid Loss:  0.001390669378452003
Epoch:  141  	Training Loss: 0.0011619514552876353
Test Loss:  0.001093149185180664
Valid Loss:  0.0013862585183233023
Epoch:  142  	Training Loss: 0.0011562968138605356
Test Loss:  0.001096805790439248
Valid Loss:  0.001384202390909195
Epoch:  143  	Training Loss: 0.0011542807333171368
Test Loss:  0.0010990421287715435
Valid Loss:  0.001382490387186408
Epoch:  144  	Training Loss: 0.0011524938745424151
Test Loss:  0.0011001138482242823
Valid Loss:  0.001380962086841464
Epoch:  145  	Training Loss: 0.0011508578900247812
Test Loss:  0.0011004316620528698
Valid Loss:  0.0013795385602861643
Epoch:  146  	Training Loss: 0.0011493016500025988
Test Loss:  0.0011005403939634562
Valid Loss:  0.0013782118912786245
Epoch:  147  	Training Loss: 0.0011478087399154902
Test Loss:  0.0011003452818840742
Valid Loss:  0.0013769360957667232
Epoch:  148  	Training Loss: 0.0011463348055258393
Test Loss:  0.001099889981560409
Valid Loss:  0.0013756848638877273
Epoch:  149  	Training Loss: 0.0011449186131358147
Test Loss:  0.0010993975447490811
Valid Loss:  0.0013744961470365524
Epoch:  150  	Training Loss: 0.001143597299233079
Test Loss:  0.0010986051056534052
Valid Loss:  0.0013733070809394121
Epoch:  151  	Training Loss: 0.0011423013638705015
Test Loss:  0.0010978628415614367
Valid Loss:  0.00137214339338243
Epoch:  152  	Training Loss: 0.001141062006354332
Test Loss:  0.001093793660402298
Valid Loss:  0.001370939426124096
Epoch:  153  	Training Loss: 0.0011380200739949942
Test Loss:  0.001091912155970931
Valid Loss:  0.001369417179375887
Epoch:  154  	Training Loss: 0.0011351930443197489
Test Loss:  0.0010902154026553035
Valid Loss:  0.001367904362268746
Epoch:  155  	Training Loss: 0.0011324319057166576
Test Loss:  0.0010886432137340307
Valid Loss:  0.0013664227444678545
Epoch:  156  	Training Loss: 0.0011298127938061953
Test Loss:  0.0010870108380913734
Valid Loss:  0.001364925061352551
Epoch:  157  	Training Loss: 0.0011272730771452188
Test Loss:  0.0010854682186618447
Valid Loss:  0.0013634155038744211
Epoch:  158  	Training Loss: 0.001124769914895296
Test Loss:  0.001083996845409274
Valid Loss:  0.001361907459795475
Epoch:  159  	Training Loss: 0.0011223170440644026
Test Loss:  0.0010826719226315618
Valid Loss:  0.0013604192063212395
Epoch:  160  	Training Loss: 0.0011199384462088346
Test Loss:  0.001081421971321106
Valid Loss:  0.0013589384034276009
Epoch:  161  	Training Loss: 0.0011175768449902534
Test Loss:  0.001080228015780449
Valid Loss:  0.0013574648182839155
Epoch:  162  	Training Loss: 0.0011152310762554407
Test Loss:  0.001081506721675396
Valid Loss:  0.00135514116846025
Epoch:  163  	Training Loss: 0.001110853161662817
Test Loss:  0.0010818066075444221
Valid Loss:  0.001353233470581472
Epoch:  164  	Training Loss: 0.001106915296986699
Test Loss:  0.0010809812229126692
Valid Loss:  0.001351532293483615
Epoch:  165  	Training Loss: 0.0011032037436962128
Test Loss:  0.0010795126436278224
Valid Loss:  0.0013497951440513134
Epoch:  166  	Training Loss: 0.0010996810160577297
Test Loss:  0.0010776919079944491
Valid Loss:  0.0013480932684615254
Epoch:  167  	Training Loss: 0.0010962322121486068
Test Loss:  0.0010760414879769087
Valid Loss:  0.0013464773073792458
Epoch:  168  	Training Loss: 0.0010929206619039178
Test Loss:  0.0010743981692939997
Valid Loss:  0.0013449490070343018
Epoch:  169  	Training Loss: 0.001089743571355939
Test Loss:  0.0010723625309765339
Valid Loss:  0.0013433992862701416
Epoch:  170  	Training Loss: 0.001086607575416565
Test Loss:  0.001070421189069748
Valid Loss:  0.0013418832095339894
Epoch:  171  	Training Loss: 0.0010835492284968495
Test Loss:  0.0010684350272640586
Valid Loss:  0.001340378075838089
Epoch:  172  	Training Loss: 0.0010805381461977959
Test Loss:  0.0010667715687304735
Valid Loss:  0.0013396281283348799
Epoch:  173  	Training Loss: 0.0010789819061756134
Test Loss:  0.0010651221964508295
Valid Loss:  0.0013388261431828141
Epoch:  174  	Training Loss: 0.0010774537222459912
Test Loss:  0.001063646050170064
Valid Loss:  0.0013380029704421759
Epoch:  175  	Training Loss: 0.0010759548749774694
Test Loss:  0.001062014838680625
Valid Loss:  0.0013371030800044537
Epoch:  176  	Training Loss: 0.0010745130712166429
Test Loss:  0.0010606757132336497
Valid Loss:  0.0013361991150304675
Epoch:  177  	Training Loss: 0.0010731129441410303
Test Loss:  0.0010594691848382354
Valid Loss:  0.0013352764071896672
Epoch:  178  	Training Loss: 0.001071725389920175
Test Loss:  0.0010582214454188943
Valid Loss:  0.001334319356828928
Epoch:  179  	Training Loss: 0.0010703920852392912
Test Loss:  0.0010571388993412256
Valid Loss:  0.0013333822134882212
Epoch:  180  	Training Loss: 0.0010691341012716293
Test Loss:  0.001056135050021112
Valid Loss:  0.00133243459276855
Epoch:  181  	Training Loss: 0.0010678922990337014
Test Loss:  0.0010550476144999266
Valid Loss:  0.0013314556563273072
Epoch:  182  	Training Loss: 0.0010666883317753673
Test Loss:  0.0010559112997725606
Valid Loss:  0.0013313187519088387
Epoch:  183  	Training Loss: 0.0010661574779078364
Test Loss:  0.001055932487361133
Valid Loss:  0.0013312262017279863
Epoch:  184  	Training Loss: 0.0010657223174348474
Test Loss:  0.0010556307388469577
Valid Loss:  0.0013311649672687054
Epoch:  185  	Training Loss: 0.001065305434167385
Test Loss:  0.0010551133891567588
Valid Loss:  0.0013311151415109634
Epoch:  186  	Training Loss: 0.0010649275500327349
Test Loss:  0.0010542155941948295
Valid Loss:  0.001331006409600377
Epoch:  187  	Training Loss: 0.00106460927054286
Test Loss:  0.0010533242020756006
Valid Loss:  0.0013308735797181726
Epoch:  188  	Training Loss: 0.0010642954148352146
Test Loss:  0.0010524411918595433
Valid Loss:  0.0013307168846949935
Epoch:  189  	Training Loss: 0.0010639866814017296
Test Loss:  0.0010516317561268806
Valid Loss:  0.001330536906607449
Epoch:  190  	Training Loss: 0.0010636835359036922
Test Loss:  0.0010506707476451993
Valid Loss:  0.0013303005835041404
Epoch:  191  	Training Loss: 0.0010634145000949502
Test Loss:  0.0010497833136469126
Valid Loss:  0.0013300329446792603
Epoch:  192  	Training Loss: 0.001063148258253932
Test Loss:  0.0010462981881573796
Valid Loss:  0.0013261218555271626
Epoch:  193  	Training Loss: 0.001061330083757639
Test Loss:  0.0010435429867357016
Valid Loss:  0.0013223711866885424
Epoch:  194  	Training Loss: 0.0010597442742437124
Test Loss:  0.0010411017574369907
Valid Loss:  0.0013187543954700232
Epoch:  195  	Training Loss: 0.0010583825642243028
Test Loss:  0.0010395116405561566
Valid Loss:  0.0013152742758393288
Epoch:  196  	Training Loss: 0.0010572418104857206
Test Loss:  0.0010385693749412894
Valid Loss:  0.001311780302785337
Epoch:  197  	Training Loss: 0.0010561852250248194
Test Loss:  0.0010375964920967817
Valid Loss:  0.0013084704987704754
Epoch:  198  	Training Loss: 0.0010551924351602793
Test Loss:  0.0010366166243329644
Valid Loss:  0.0013053861912339926
Epoch:  199  	Training Loss: 0.001054293243214488
Test Loss:  0.001035887049511075
Valid Loss:  0.0013024031650274992
Epoch:  200  	Training Loss: 0.0010534686734899879
Test Loss:  0.0010351646924391389
Valid Loss:  0.0012995483120903373
Epoch:  201  	Training Loss: 0.0010526683181524277
Test Loss:  0.0010344722541049123
Valid Loss:  0.0012968052178621292
Epoch:  202  	Training Loss: 0.0010519033530727029
Test Loss:  0.001036480418406427
Valid Loss:  0.001296123256906867
Epoch:  203  	Training Loss: 0.0010514984605833888
Test Loss:  0.0010376038262620568
Valid Loss:  0.0012956664431840181
Epoch:  204  	Training Loss: 0.00105117610655725
Test Loss:  0.001037853886373341
Valid Loss:  0.0012952821562066674
Epoch:  205  	Training Loss: 0.0010509502608329058
 41%|████      | 206/500 [02:45<03:00,  1.63it/s] 42%|████▏     | 208/500 [02:45<02:11,  2.22it/s] 42%|████▏     | 210/500 [02:45<01:37,  2.98it/s] 42%|████▏     | 212/500 [02:52<05:42,  1.19s/it] 43%|████▎     | 214/500 [02:52<04:04,  1.17it/s] 43%|████▎     | 216/500 [02:52<02:56,  1.61it/s] 44%|████▎     | 218/500 [02:52<02:08,  2.19it/s] 44%|████▍     | 220/500 [02:52<01:34,  2.95it/s] 44%|████▍     | 222/500 [02:59<05:37,  1.21s/it] 45%|████▍     | 224/500 [02:59<04:00,  1.15it/s] 45%|████▌     | 226/500 [02:59<02:54,  1.57it/s] 46%|████▌     | 228/500 [02:59<02:08,  2.12it/s] 46%|████▌     | 230/500 [02:59<01:36,  2.80it/s] 46%|████▋     | 232/500 [03:06<05:27,  1.22s/it] 47%|████▋     | 234/500 [03:06<03:53,  1.14it/s] 47%|████▋     | 236/500 [03:06<02:48,  1.57it/s] 48%|████▊     | 238/500 [03:06<02:02,  2.14it/s] 48%|████▊     | 240/500 [03:06<01:30,  2.88it/s] 48%|████▊     | 242/500 [03:13<05:12,  1.21s/it] 49%|████▉     | 244/500 [03:13<03:42,  1.15it/s] 49%|████▉     | 246/500 [03:13<02:39,  1.59it/s] 50%|████▉     | 248/500 [03:13<01:56,  2.17it/s] 50%|█████     | 250/500 [03:13<01:26,  2.91it/s] 50%|█████     | 252/500 [03:20<04:52,  1.18s/it] 51%|█████     | 254/500 [03:20<03:28,  1.18it/s] 51%|█████     | 256/500 [03:20<02:29,  1.63it/s] 52%|█████▏    | 258/500 [03:20<01:48,  2.23it/s] 52%|█████▏    | 260/500 [03:20<01:20,  2.98it/s] 52%|█████▏    | 262/500 [03:27<04:48,  1.21s/it] 53%|█████▎    | 264/500 [03:27<03:24,  1.15it/s] 53%|█████▎    | 266/500 [03:27<02:26,  1.60it/s] 54%|█████▎    | 268/500 [03:27<01:46,  2.17it/s] 54%|█████▍    | 270/500 [03:27<01:18,  2.92it/s] 54%|█████▍    | 272/500 [03:34<04:33,  1.20s/it]Test Loss:  0.0010375280398875475
Valid Loss:  0.001294896937906742
Epoch:  206  	Training Loss: 0.001050763763487339
Test Loss:  0.0010370928794145584
Valid Loss:  0.0012945156777277589
Epoch:  207  	Training Loss: 0.0010505813406780362
Test Loss:  0.0010365862399339676
Valid Loss:  0.0012941304594278336
Epoch:  208  	Training Loss: 0.0010504001984372735
Test Loss:  0.0010360341984778643
Valid Loss:  0.0012937347637489438
Epoch:  209  	Training Loss: 0.001050221617333591
Test Loss:  0.0010354546830058098
Valid Loss:  0.001293326262384653
Epoch:  210  	Training Loss: 0.0010500489734113216
Test Loss:  0.0010347688803449273
Valid Loss:  0.0012928901705890894
Epoch:  211  	Training Loss: 0.0010498820338398218
Test Loss:  0.0010341096203774214
Valid Loss:  0.0012924345210194588
Epoch:  212  	Training Loss: 0.0010497167240828276
Test Loss:  0.001028446713462472
Valid Loss:  0.0012919751461595297
Epoch:  213  	Training Loss: 0.0010477220639586449
Test Loss:  0.0010247717145830393
Valid Loss:  0.0012912432430312037
Epoch:  214  	Training Loss: 0.0010458569740876555
Test Loss:  0.001022011274471879
Valid Loss:  0.001290303422138095
Epoch:  215  	Training Loss: 0.0010440575424581766
Test Loss:  0.0010200146352872252
Valid Loss:  0.0012892431113868952
Epoch:  216  	Training Loss: 0.0010422938503324986
Test Loss:  0.0010183980921283364
Valid Loss:  0.0012881376314908266
Epoch:  217  	Training Loss: 0.0010406144428998232
Test Loss:  0.0010169313754886389
Valid Loss:  0.0012869759229943156
Epoch:  218  	Training Loss: 0.0010390195529907942
Test Loss:  0.0010156516218557954
Valid Loss:  0.0012857820838689804
Epoch:  219  	Training Loss: 0.001037515583448112
Test Loss:  0.0010145740816369653
Valid Loss:  0.0012845884775742888
Epoch:  220  	Training Loss: 0.0010360809974372387
Test Loss:  0.0010134810581803322
Valid Loss:  0.0012833966175094247
Epoch:  221  	Training Loss: 0.00103469705209136
Test Loss:  0.0010123263346031308
Valid Loss:  0.0012821697164326906
Epoch:  222  	Training Loss: 0.0010333294048905373
Test Loss:  0.0010121329687535763
Valid Loss:  0.0012797733070328832
Epoch:  223  	Training Loss: 0.0010302145965397358
Test Loss:  0.0010113047901540995
Valid Loss:  0.0012777021620422602
Epoch:  224  	Training Loss: 0.0010273251682519913
Test Loss:  0.0010100874351337552
Valid Loss:  0.0012757531367242336
Epoch:  225  	Training Loss: 0.0010245682206004858
Test Loss:  0.0010086558759212494
Valid Loss:  0.0012738609220832586
Epoch:  226  	Training Loss: 0.0010218609822914004
Test Loss:  0.0010071576107293367
Valid Loss:  0.0012720063095912337
Epoch:  227  	Training Loss: 0.0010192443151026964
Test Loss:  0.001005687052384019
Valid Loss:  0.0012702064123004675
Epoch:  228  	Training Loss: 0.0010167394066229463
Test Loss:  0.0010042272042483091
Valid Loss:  0.0012684296816587448
Epoch:  229  	Training Loss: 0.001014268258586526
Test Loss:  0.0010027408134192228
Valid Loss:  0.0012666652910411358
Epoch:  230  	Training Loss: 0.001011833781376481
Test Loss:  0.0010011392878368497
Valid Loss:  0.0012648904230445623
Epoch:  231  	Training Loss: 0.0010094434255734086
Test Loss:  0.000999411684460938
Valid Loss:  0.0012630792334675789
Epoch:  232  	Training Loss: 0.0010071565629914403
Test Loss:  0.0009983114432543516
Valid Loss:  0.0012618994805961847
Epoch:  233  	Training Loss: 0.0010065512033179402
Test Loss:  0.000997403752990067
Valid Loss:  0.001260747667402029
Epoch:  234  	Training Loss: 0.0010060160420835018
Test Loss:  0.0009966311044991016
Valid Loss:  0.0012595949228852987
Epoch:  235  	Training Loss: 0.0010055280290544033
Test Loss:  0.0009959455346688628
Valid Loss:  0.0012584510259330273
Epoch:  236  	Training Loss: 0.0010050577111542225
Test Loss:  0.000995321199297905
Valid Loss:  0.0012573124840855598
Epoch:  237  	Training Loss: 0.0010046132374554873
Test Loss:  0.0009947787038981915
Valid Loss:  0.0012562074698507786
Epoch:  238  	Training Loss: 0.0010042230132967234
Test Loss:  0.0009942897595465183
Valid Loss:  0.0012551253894343972
Epoch:  239  	Training Loss: 0.0010038451291620731
Test Loss:  0.0009938383009284735
Valid Loss:  0.0012540617026388645
Epoch:  240  	Training Loss: 0.0010034721344709396
Test Loss:  0.0009934180416166782
Valid Loss:  0.0012530215317383409
Epoch:  241  	Training Loss: 0.00100310321431607
Test Loss:  0.000993015943095088
Valid Loss:  0.0012520018499344587
Epoch:  242  	Training Loss: 0.0010027398820966482
Test Loss:  0.0009902874007821083
Valid Loss:  0.001247858046554029
Epoch:  243  	Training Loss: 0.0009966460056602955
Test Loss:  0.0009874824900180101
Valid Loss:  0.0012440236750990152
Epoch:  244  	Training Loss: 0.0009908068459481
Test Loss:  0.0009850552305579185
Valid Loss:  0.0012409912887960672
Epoch:  245  	Training Loss: 0.0009858303237706423
Test Loss:  0.0009830385679379106
Valid Loss:  0.0012384539004415274
Epoch:  246  	Training Loss: 0.000982664991170168
Test Loss:  0.0009813265642151237
Valid Loss:  0.0012361076660454273
Epoch:  247  	Training Loss: 0.0009807393653318286
Test Loss:  0.0009799173567444086
Valid Loss:  0.0012337584048509598
Epoch:  248  	Training Loss: 0.0009789860341697931
Test Loss:  0.0009787353919818997
Valid Loss:  0.0012314262567088008
Epoch:  249  	Training Loss: 0.0009772730991244316
Test Loss:  0.0009777522645890713
Valid Loss:  0.001229140325449407
Epoch:  250  	Training Loss: 0.0009756156941875815
Test Loss:  0.0009769457392394543
Valid Loss:  0.001226911786943674
Epoch:  251  	Training Loss: 0.0009740152163431048
Test Loss:  0.0009762222180142999
Valid Loss:  0.0012247420381754637
Epoch:  252  	Training Loss: 0.0009724490810185671
Test Loss:  0.0009793374920263886
Valid Loss:  0.0012240512296557426
Epoch:  253  	Training Loss: 0.000971514149568975
Test Loss:  0.000981348566710949
Valid Loss:  0.0012237149057909846
Epoch:  254  	Training Loss: 0.0009707587887533009
Test Loss:  0.0009825389133766294
Valid Loss:  0.0012235919712111354
Epoch:  255  	Training Loss: 0.0009701070957817137
Test Loss:  0.000983130419626832
Valid Loss:  0.0012235945323482156
Epoch:  256  	Training Loss: 0.0009695171611383557
Test Loss:  0.000983306672424078
Valid Loss:  0.0012236624024808407
Epoch:  257  	Training Loss: 0.0009689684375189245
Test Loss:  0.0009832625510171056
Valid Loss:  0.0012237573973834515
Epoch:  258  	Training Loss: 0.0009684500400908291
Test Loss:  0.0009829882765188813
Valid Loss:  0.00122385798022151
Epoch:  259  	Training Loss: 0.0009679524227976799
Test Loss:  0.0009825567249208689
Valid Loss:  0.001223943312652409
Epoch:  260  	Training Loss: 0.0009674719185568392
Test Loss:  0.0009820089908316731
Valid Loss:  0.001224002568051219
Epoch:  261  	Training Loss: 0.0009670063736848533
Test Loss:  0.0009812630014494061
Valid Loss:  0.001224009320139885
Epoch:  262  	Training Loss: 0.0009665883844718337
Test Loss:  0.0009782933630049229
Valid Loss:  0.0012239794014021754
Epoch:  263  	Training Loss: 0.0009639799827709794
Test Loss:  0.0009756566723808646
Valid Loss:  0.0012237305054441094
Epoch:  264  	Training Loss: 0.0009614823502488434
Test Loss:  0.0009731653844937682
Valid Loss:  0.001223309081979096
Epoch:  265  	Training Loss: 0.0009590808185748756
Test Loss:  0.0009707990102469921
Valid Loss:  0.0012226731050759554
Epoch:  266  	Training Loss: 0.0009568019304424524
Test Loss:  0.0009686204721219838
Valid Loss:  0.0012218919582664967
Epoch:  267  	Training Loss: 0.0009545813081786036
Test Loss:  0.0009664501412771642
Valid Loss:  0.0012209999840706587
Epoch:  268  	Training Loss: 0.0009524526540189981
Test Loss:  0.0009642813820391893
Valid Loss:  0.0012200240744277835
Epoch:  269  	Training Loss: 0.000950378249399364
Test Loss:  0.0009624412632547319
Valid Loss:  0.0012188637629151344
Epoch:  270  	Training Loss: 0.0009484278270974755
Test Loss:  0.000960754114203155
Valid Loss:  0.0012175957672297955
Epoch:  271  	Training Loss: 0.0009465284529142082
Test Loss:  0.0009590905392542481
Valid Loss:  0.0012162894709035754
Epoch:  272  	Training Loss: 0.0009446712210774422
Test Loss:  0.0009586705127730966
Valid Loss:  0.0012133644195273519
Epoch:  273  	Training Loss: 0.0009435100946575403
Test Loss:  0.0009581104386597872
Valid Loss:  0.0012106320355087519
 55%|█████▍    | 274/500 [03:34<03:14,  1.16it/s] 55%|█████▌    | 276/500 [03:34<02:19,  1.61it/s] 56%|█████▌    | 278/500 [03:34<01:42,  2.17it/s] 56%|█████▌    | 280/500 [03:34<01:15,  2.91it/s] 56%|█████▋    | 282/500 [03:41<04:21,  1.20s/it] 57%|█████▋    | 284/500 [03:41<03:05,  1.16it/s] 57%|█████▋    | 286/500 [03:41<02:12,  1.61it/s] 58%|█████▊    | 288/500 [03:41<01:36,  2.19it/s] 58%|█████▊    | 290/500 [03:41<01:11,  2.94it/s] 58%|█████▊    | 292/500 [03:48<04:07,  1.19s/it] 59%|█████▉    | 294/500 [03:48<02:55,  1.17it/s] 59%|█████▉    | 296/500 [03:48<02:06,  1.62it/s] 60%|█████▉    | 298/500 [03:48<01:31,  2.21it/s] 60%|██████    | 300/500 [03:48<01:07,  2.97it/s] 60%|██████    | 302/500 [03:54<03:57,  1.20s/it] 61%|██████    | 304/500 [03:55<02:48,  1.16it/s] 61%|██████    | 306/500 [03:55<02:00,  1.61it/s] 62%|██████▏   | 308/500 [03:55<01:27,  2.19it/s] 62%|██████▏   | 310/500 [03:55<01:04,  2.95it/s] 62%|██████▏   | 312/500 [04:01<03:46,  1.21s/it] 63%|██████▎   | 314/500 [04:02<02:40,  1.16it/s] 63%|██████▎   | 316/500 [04:02<01:55,  1.60it/s] 64%|██████▎   | 318/500 [04:02<01:23,  2.19it/s] 64%|██████▍   | 320/500 [04:02<01:01,  2.90it/s] 64%|██████▍   | 322/500 [04:08<03:31,  1.19s/it] 65%|██████▍   | 324/500 [04:08<02:29,  1.18it/s] 65%|██████▌   | 326/500 [04:09<01:47,  1.61it/s] 66%|██████▌   | 328/500 [04:09<01:18,  2.19it/s] 66%|██████▌   | 330/500 [04:09<00:57,  2.95it/s] 66%|██████▋   | 332/500 [04:15<03:23,  1.21s/it] 67%|██████▋   | 334/500 [04:16<02:25,  1.14it/s] 67%|██████▋   | 336/500 [04:16<01:44,  1.58it/s] 68%|██████▊   | 338/500 [04:16<01:15,  2.15it/s] 68%|██████▊   | 340/500 [04:16<00:55,  2.89it/s]Epoch:  274  	Training Loss: 0.0009423805749975145
Test Loss:  0.0009574466967023909
Valid Loss:  0.0012079905718564987
Epoch:  275  	Training Loss: 0.0009412660729140043
Test Loss:  0.0009565787622705102
Valid Loss:  0.0012054085964336991
Epoch:  276  	Training Loss: 0.0009401761926710606
Test Loss:  0.0009555555880069733
Valid Loss:  0.0012030359357595444
Epoch:  277  	Training Loss: 0.0009391087223775685
Test Loss:  0.0009543887572363019
Valid Loss:  0.0012008509365841746
Epoch:  278  	Training Loss: 0.0009380541741847992
Test Loss:  0.0009532071999274194
Valid Loss:  0.001198711572214961
Epoch:  279  	Training Loss: 0.000937004922889173
Test Loss:  0.0009520146995782852
Valid Loss:  0.0011966130696237087
Epoch:  280  	Training Loss: 0.0009359607356600463
Test Loss:  0.0009507533395662904
Valid Loss:  0.0011946153827011585
Epoch:  281  	Training Loss: 0.0009349201573058963
Test Loss:  0.0009494879050180316
Valid Loss:  0.0011926485458388925
Epoch:  282  	Training Loss: 0.0009338840609416366
Test Loss:  0.0009470799122937024
Valid Loss:  0.0011922632111236453
Epoch:  283  	Training Loss: 0.0009328111773356795
Test Loss:  0.0009450700599700212
Valid Loss:  0.0011918646050617099
Epoch:  284  	Training Loss: 0.0009318054653704166
Test Loss:  0.000943364342674613
Valid Loss:  0.0011914505157619715
Epoch:  285  	Training Loss: 0.0009308404405601323
Test Loss:  0.0009418886038474739
Valid Loss:  0.0011910193134099245
Epoch:  286  	Training Loss: 0.0009299080702476203
Test Loss:  0.0009406073950231075
Valid Loss:  0.001190622104331851
Epoch:  287  	Training Loss: 0.0009290171437896788
Test Loss:  0.0009394543012604117
Valid Loss:  0.0011902074329555035
Epoch:  288  	Training Loss: 0.0009281499078497291
Test Loss:  0.0009386654128320515
Valid Loss:  0.0011897430522367358
Epoch:  289  	Training Loss: 0.0009273296454921365
Test Loss:  0.0009379390394315124
Valid Loss:  0.0011892887996509671
Epoch:  290  	Training Loss: 0.0009265548433177173
Test Loss:  0.0009372377535328269
Valid Loss:  0.0011888329172506928
Epoch:  291  	Training Loss: 0.0009257971541956067
Test Loss:  0.0009365736041218042
Valid Loss:  0.0011883771512657404
Epoch:  292  	Training Loss: 0.0009250574512407184
Test Loss:  0.0009364120196551085
Valid Loss:  0.001188061200082302
Epoch:  293  	Training Loss: 0.0009247115231119096
Test Loss:  0.0009359396644867957
Valid Loss:  0.0011877546785399318
Epoch:  294  	Training Loss: 0.0009243959793820977
Test Loss:  0.0009353627683594823
Valid Loss:  0.0011874544434249401
Epoch:  295  	Training Loss: 0.0009240853833034635
Test Loss:  0.000934719922952354
Valid Loss:  0.0011871499009430408
Epoch:  296  	Training Loss: 0.0009237790945917368
Test Loss:  0.0009340332471765578
Valid Loss:  0.0011868394212797284
Epoch:  297  	Training Loss: 0.0009234771132469177
Test Loss:  0.0009333222405984998
Valid Loss:  0.0011865179985761642
Epoch:  298  	Training Loss: 0.0009231788571923971
Test Loss:  0.0009326481958851218
Valid Loss:  0.0011861854000017047
Epoch:  299  	Training Loss: 0.0009228845010511577
Test Loss:  0.0009319673990830779
Valid Loss:  0.0011858402285724878
Epoch:  300  	Training Loss: 0.0009225938119925559
Test Loss:  0.0009312817710451782
Valid Loss:  0.00118548097088933
Epoch:  301  	Training Loss: 0.0009223057422786951
Test Loss:  0.0009305963176302612
Valid Loss:  0.0011851100716739893
Epoch:  302  	Training Loss: 0.0009220212232321501
Test Loss:  0.0009267493151128292
Valid Loss:  0.0011843795655295253
Epoch:  303  	Training Loss: 0.0009200740605592728
Test Loss:  0.0009242626838386059
Valid Loss:  0.0011832728050649166
Epoch:  304  	Training Loss: 0.000918202509637922
Test Loss:  0.0009222635999321938
Valid Loss:  0.0011820313520729542
Epoch:  305  	Training Loss: 0.0009163489448837936
Test Loss:  0.0009204758680425584
Valid Loss:  0.0011807032860815525
Epoch:  306  	Training Loss: 0.0009145285584963858
Test Loss:  0.0009187759133055806
Valid Loss:  0.0011792766163125634
Epoch:  307  	Training Loss: 0.0009127432713285089
Test Loss:  0.0009172316640615463
Valid Loss:  0.0011777421459555626
Epoch:  308  	Training Loss: 0.000911023176740855
Test Loss:  0.0009156501037068665
Valid Loss:  0.001176181947812438
Epoch:  309  	Training Loss: 0.0009093901026062667
Test Loss:  0.0009140301845036447
Valid Loss:  0.0011745559750124812
Epoch:  310  	Training Loss: 0.0009078343864530325
Test Loss:  0.0009124954231083393
Valid Loss:  0.0011729173129424453
Epoch:  311  	Training Loss: 0.0009063754114322364
Test Loss:  0.000911070907022804
Valid Loss:  0.0011712335981428623
Epoch:  312  	Training Loss: 0.000904980581253767
Test Loss:  0.0009113975102081895
Valid Loss:  0.0011692624539136887
Epoch:  313  	Training Loss: 0.0009035167749971151
Test Loss:  0.0009115252178162336
Valid Loss:  0.0011673921253532171
Epoch:  314  	Training Loss: 0.0009020782890729606
Test Loss:  0.0009114855201914907
Valid Loss:  0.0011656066635623574
Epoch:  315  	Training Loss: 0.0009006583131849766
Test Loss:  0.0009113049018196762
Valid Loss:  0.0011638910509645939
Epoch:  316  	Training Loss: 0.0008992519578896463
Test Loss:  0.0009110082173720002
Valid Loss:  0.001162238884717226
Epoch:  317  	Training Loss: 0.0008978576515801251
Test Loss:  0.0009106140932999551
Valid Loss:  0.0011606387561187148
Epoch:  318  	Training Loss: 0.0008964744629338384
Test Loss:  0.0009102622279897332
Valid Loss:  0.0011591200018301606
Epoch:  319  	Training Loss: 0.0008951142663136125
Test Loss:  0.0009098206064663827
Valid Loss:  0.0011576440883800387
Epoch:  320  	Training Loss: 0.0008937629172578454
Test Loss:  0.0009093041880987585
Valid Loss:  0.0011562076397240162
Epoch:  321  	Training Loss: 0.0008924193098209798
Test Loss:  0.0009087247308343649
Valid Loss:  0.001154804602265358
Epoch:  322  	Training Loss: 0.0008910819888114929
Test Loss:  0.0009076219284906983
Valid Loss:  0.001149914227426052
Epoch:  323  	Training Loss: 0.0008885768475010991
Test Loss:  0.0009062113240361214
Valid Loss:  0.0011455824133008718
Epoch:  324  	Training Loss: 0.0008862071554176509
Test Loss:  0.0009045929182320833
Valid Loss:  0.0011416343040764332
Epoch:  325  	Training Loss: 0.0008839283837005496
Test Loss:  0.0009028578642755747
Valid Loss:  0.0011379588395357132
Epoch:  326  	Training Loss: 0.0008817173657007515
Test Loss:  0.0009010619833134115
Valid Loss:  0.0011346477549523115
Epoch:  327  	Training Loss: 0.000879616301972419
Test Loss:  0.000899287813808769
Valid Loss:  0.0011315243318676949
Epoch:  328  	Training Loss: 0.0008775474852882326
Test Loss:  0.0008975379751063883
Valid Loss:  0.00112853292375803
Epoch:  329  	Training Loss: 0.0008754977025091648
Test Loss:  0.000895804085303098
Valid Loss:  0.001125652575865388
Epoch:  330  	Training Loss: 0.0008734700968489051
Test Loss:  0.0008940444095060229
Valid Loss:  0.0011228631483390927
Epoch:  331  	Training Loss: 0.0008714778814464808
Test Loss:  0.0008923393907025456
Valid Loss:  0.0011201957240700722
Epoch:  332  	Training Loss: 0.0008695097640156746
Test Loss:  0.0008882335387170315
Valid Loss:  0.0011198082938790321
Epoch:  333  	Training Loss: 0.0008675990393385291
Test Loss:  0.000885260640643537
Valid Loss:  0.0011192422825843096
Epoch:  334  	Training Loss: 0.0008657461730763316
Test Loss:  0.0008828970021568239
Valid Loss:  0.001118553220294416
Epoch:  335  	Training Loss: 0.000863943132571876
Test Loss:  0.0008808675338514149
Valid Loss:  0.0011177804553881288
Epoch:  336  	Training Loss: 0.0008621782762929797
Test Loss:  0.0008790123974904418
Valid Loss:  0.001116936793550849
Epoch:  337  	Training Loss: 0.0008604354225099087
Test Loss:  0.000877262675203383
Valid Loss:  0.0011160335270687938
Epoch:  338  	Training Loss: 0.0008587039774283767
Test Loss:  0.0008755815215408802
Valid Loss:  0.0011150776408612728
Epoch:  339  	Training Loss: 0.0008569823112338781
Test Loss:  0.0008739418117329478
Valid Loss:  0.0011140750721096992
Epoch:  340  	Training Loss: 0.0008552762446925044
Test Loss:  0.0008722564089111984
Valid Loss:  0.0011130135972052813
Epoch:  341  	Training Loss: 0.000853588804602623
Test Loss:  0.0008706540102139115
Valid Loss:  0.0011119088158011436
Epoch:  342  	Training Loss: 0.0008519096882082522
 68%|██████▊   | 342/500 [04:22<03:08,  1.20s/it] 69%|██████▉   | 344/500 [04:23<02:14,  1.16it/s] 69%|██████▉   | 346/500 [04:23<01:35,  1.61it/s] 70%|██████▉   | 348/500 [04:23<01:09,  2.20it/s] 70%|███████   | 350/500 [04:23<00:50,  2.96it/s] 70%|███████   | 352/500 [04:29<02:57,  1.20s/it] 71%|███████   | 354/500 [04:29<02:05,  1.16it/s] 71%|███████   | 356/500 [04:30<01:29,  1.60it/s] 72%|███████▏  | 358/500 [04:30<01:04,  2.19it/s] 72%|███████▏  | 360/500 [04:30<00:47,  2.95it/s] 72%|███████▏  | 362/500 [04:36<02:44,  1.19s/it] 73%|███████▎  | 364/500 [04:36<01:56,  1.17it/s] 73%|███████▎  | 366/500 [04:36<01:22,  1.62it/s] 74%|███████▎  | 368/500 [04:37<00:59,  2.21it/s] 74%|███████▍  | 370/500 [04:37<00:43,  2.96it/s] 74%|███████▍  | 372/500 [04:43<02:31,  1.19s/it] 75%|███████▍  | 374/500 [04:43<01:47,  1.18it/s] 75%|███████▌  | 376/500 [04:43<01:16,  1.62it/s] 76%|███████▌  | 378/500 [04:44<00:55,  2.22it/s] 76%|███████▌  | 380/500 [04:44<00:40,  2.98it/s] 76%|███████▋  | 382/500 [04:50<02:23,  1.21s/it] 77%|███████▋  | 384/500 [04:50<01:40,  1.15it/s] 77%|███████▋  | 386/500 [04:50<01:11,  1.59it/s] 78%|███████▊  | 388/500 [04:51<00:51,  2.17it/s] 78%|███████▊  | 390/500 [04:51<00:37,  2.93it/s] 78%|███████▊  | 392/500 [04:57<02:10,  1.21s/it] 79%|███████▉  | 394/500 [04:57<01:31,  1.16it/s] 79%|███████▉  | 396/500 [04:57<01:04,  1.60it/s] 80%|███████▉  | 398/500 [04:58<00:46,  2.19it/s] 80%|████████  | 400/500 [04:58<00:34,  2.94it/s] 80%|████████  | 402/500 [05:04<01:56,  1.19s/it] 81%|████████  | 404/500 [05:04<01:21,  1.18it/s] 81%|████████  | 406/500 [05:04<00:57,  1.63it/s] 82%|████████▏ | 408/500 [05:04<00:41,  2.22it/s]Test Loss:  0.000868209230247885
Valid Loss:  0.0011100824922323227
Epoch:  343  	Training Loss: 0.0008488165913149714
Test Loss:  0.0008658911101520061
Valid Loss:  0.0011082314886152744
Epoch:  344  	Training Loss: 0.0008458575466647744
Test Loss:  0.0008636016864329576
Valid Loss:  0.001106427051126957
Epoch:  345  	Training Loss: 0.0008430960588157177
Test Loss:  0.0008614878170192242
Valid Loss:  0.0011045917635783553
Epoch:  346  	Training Loss: 0.0008403887622989714
Test Loss:  0.0008594614919275045
Valid Loss:  0.0011027290020138025
Epoch:  347  	Training Loss: 0.0008377681951969862
Test Loss:  0.0008575007086619735
Valid Loss:  0.0011008998844772577
Epoch:  348  	Training Loss: 0.0008352912263944745
Test Loss:  0.0008556892280466855
Valid Loss:  0.0010990751907229424
Epoch:  349  	Training Loss: 0.0008329319534823298
Test Loss:  0.000853997771628201
Valid Loss:  0.001097248517908156
Epoch:  350  	Training Loss: 0.0008306927629746497
Test Loss:  0.0008524238364771008
Valid Loss:  0.0010954190511256456
Epoch:  351  	Training Loss: 0.0008284808718599379
Test Loss:  0.0008509440813213587
Valid Loss:  0.0010936043690890074
Epoch:  352  	Training Loss: 0.0008263140916824341
Test Loss:  0.0008517386158928275
Valid Loss:  0.0010932818986475468
Epoch:  353  	Training Loss: 0.0008257359731942415
Test Loss:  0.0008523628930561244
Valid Loss:  0.001092975726351142
Epoch:  354  	Training Loss: 0.0008252213010564446
Test Loss:  0.000852877798024565
Valid Loss:  0.0010926774702966213
Epoch:  355  	Training Loss: 0.0008247509831562638
Test Loss:  0.0008532904321327806
Valid Loss:  0.0010923936497420073
Epoch:  356  	Training Loss: 0.0008242978947237134
Test Loss:  0.0008536516688764095
Valid Loss:  0.0010921191424131393
Epoch:  357  	Training Loss: 0.000823859591037035
Test Loss:  0.0008539316477254033
Valid Loss:  0.001091853016987443
Epoch:  358  	Training Loss: 0.0008234332781285048
Test Loss:  0.0008541042916476727
Valid Loss:  0.0010915829334408045
Epoch:  359  	Training Loss: 0.0008230312378145754
Test Loss:  0.0008542221621610224
Valid Loss:  0.0010913151782006025
Epoch:  360  	Training Loss: 0.0008226388017646968
Test Loss:  0.0008542091818526387
Valid Loss:  0.0010910299606621265
Epoch:  361  	Training Loss: 0.0008222806500270963
Test Loss:  0.0008541635470464826
Valid Loss:  0.0010907517280429602
Epoch:  362  	Training Loss: 0.0008219340816140175
Test Loss:  0.0008548771729692817
Valid Loss:  0.0010865546064451337
Epoch:  363  	Training Loss: 0.0008200545562431216
Test Loss:  0.0008553832885809243
Valid Loss:  0.0010828556260094047
Epoch:  364  	Training Loss: 0.0008182855090126395
Test Loss:  0.000855716411024332
Valid Loss:  0.0010795511770993471
Epoch:  365  	Training Loss: 0.0008165854378603399
Test Loss:  0.0008559274720028043
Valid Loss:  0.001076558488421142
Epoch:  366  	Training Loss: 0.0008149357745423913
Test Loss:  0.0008560136193409562
Valid Loss:  0.0010738251730799675
Epoch:  367  	Training Loss: 0.000813321559689939
Test Loss:  0.000856011058203876
Valid Loss:  0.0010713156079873443
Epoch:  368  	Training Loss: 0.0008117479155771434
Test Loss:  0.0008559044799767435
Valid Loss:  0.0010690265335142612
Epoch:  369  	Training Loss: 0.000810213852673769
Test Loss:  0.0008557121618650854
Valid Loss:  0.0010669258190318942
Epoch:  370  	Training Loss: 0.0008087087771855295
Test Loss:  0.0008554551750421524
Valid Loss:  0.0010649642208591104
Epoch:  371  	Training Loss: 0.0008072220953181386
Test Loss:  0.0008551498176530004
Valid Loss:  0.0010631401091814041
Epoch:  372  	Training Loss: 0.0008057615486904979
Test Loss:  0.0008482091361656785
Valid Loss:  0.001063984353095293
Epoch:  373  	Training Loss: 0.0008047331357374787
Test Loss:  0.0008428544970229268
Valid Loss:  0.0010644529247656465
Epoch:  374  	Training Loss: 0.0008039610111154616
Test Loss:  0.0008387402631342411
Valid Loss:  0.0010645807487890124
Epoch:  375  	Training Loss: 0.0008033624617382884
Test Loss:  0.0008355292957276106
Valid Loss:  0.0010644278954714537
Epoch:  376  	Training Loss: 0.0008028544252738357
Test Loss:  0.0008329199627041817
Valid Loss:  0.0010640695691108704
Epoch:  377  	Training Loss: 0.0008023983100429177
Test Loss:  0.0008307850803248584
Valid Loss:  0.0010635367361828685
Epoch:  378  	Training Loss: 0.0008019963279366493
Test Loss:  0.0008290636469610035
Valid Loss:  0.0010628600139170885
Epoch:  379  	Training Loss: 0.000801633286755532
Test Loss:  0.0008276015287265182
Valid Loss:  0.0010620884131640196
Epoch:  380  	Training Loss: 0.0008012905018404126
Test Loss:  0.0008263250347226858
Valid Loss:  0.0010612632613629103
Epoch:  381  	Training Loss: 0.0008009529556147754
Test Loss:  0.000825191498734057
Valid Loss:  0.001060396316461265
Epoch:  382  	Training Loss: 0.0008006199495866895
Test Loss:  0.000824645278044045
Valid Loss:  0.001058440189808607
Epoch:  383  	Training Loss: 0.0007995741325430572
Test Loss:  0.000824062037281692
Valid Loss:  0.001056578941643238
Epoch:  384  	Training Loss: 0.0007985392585396767
Test Loss:  0.0008234335109591484
Valid Loss:  0.0010547987185418606
Epoch:  385  	Training Loss: 0.0007975168991833925
Test Loss:  0.0008227709331549704
Valid Loss:  0.0010530895087867975
Epoch:  386  	Training Loss: 0.0007965066470205784
Test Loss:  0.00082210055552423
Valid Loss:  0.0010514429304748774
Epoch:  387  	Training Loss: 0.0007955064647831023
Test Loss:  0.000821439316496253
Valid Loss:  0.001049849553965032
Epoch:  388  	Training Loss: 0.0007945209508761764
Test Loss:  0.0008207643404603004
Valid Loss:  0.0010483034420758486
Epoch:  389  	Training Loss: 0.0007935513276606798
Test Loss:  0.0008200538577511907
Valid Loss:  0.0010467928368598223
Epoch:  390  	Training Loss: 0.0007926119724288583
Test Loss:  0.0008193263784050941
Valid Loss:  0.001045316574163735
Epoch:  391  	Training Loss: 0.0007916995673440397
Test Loss:  0.0008186068153008819
Valid Loss:  0.001043872907757759
Epoch:  392  	Training Loss: 0.0007908018305897713
Test Loss:  0.0008183427853509784
Valid Loss:  0.0010439890902489424
Epoch:  393  	Training Loss: 0.0007899171323515475
Test Loss:  0.0008179070428013802
Valid Loss:  0.0010440672049298882
Epoch:  394  	Training Loss: 0.0007891670102253556
Test Loss:  0.000817303778603673
Valid Loss:  0.0010441213380545378
Epoch:  395  	Training Loss: 0.0007884897640906274
Test Loss:  0.0008165145409293473
Valid Loss:  0.001044170232489705
Epoch:  396  	Training Loss: 0.0007878539036028087
Test Loss:  0.0008156421827152371
Valid Loss:  0.0010441835038363934
Epoch:  397  	Training Loss: 0.0007872662972658873
Test Loss:  0.0008147807093337178
Valid Loss:  0.0010441499762237072
Epoch:  398  	Training Loss: 0.0007867268868722022
Test Loss:  0.0008139011333696544
Valid Loss:  0.001044097705744207
Epoch:  399  	Training Loss: 0.0007862209458835423
Test Loss:  0.0008130692876875401
Valid Loss:  0.0010439769830554724
Epoch:  400  	Training Loss: 0.0007857495220378041
Test Loss:  0.0008122530998662114
Valid Loss:  0.0010438237804919481
Epoch:  401  	Training Loss: 0.0007853017305023968
Test Loss:  0.0008115265518426895
Valid Loss:  0.0010436030570417643
Epoch:  402  	Training Loss: 0.0007848719251342118
Test Loss:  0.0008097856771200895
Valid Loss:  0.0010410775430500507
Epoch:  403  	Training Loss: 0.000783170573413372
Test Loss:  0.0008082296699285507
Valid Loss:  0.0010387222282588482
Epoch:  404  	Training Loss: 0.0007815680000931025
Test Loss:  0.0008068045135587454
Valid Loss:  0.0010365250054746866
Epoch:  405  	Training Loss: 0.0007800547173246741
Test Loss:  0.0008054526406340301
Valid Loss:  0.0010344117181375623
Epoch:  406  	Training Loss: 0.0007785886991769075
Test Loss:  0.0008041594410315156
Valid Loss:  0.0010323565220460296
Epoch:  407  	Training Loss: 0.0007771557429805398
Test Loss:  0.0008029014570638537
Valid Loss:  0.0010303243761882186
Epoch:  408  	Training Loss: 0.0007757430430501699
Test Loss:  0.0008016753708943725
Valid Loss:  0.0010284169111400843
Epoch:  409  	Training Loss: 0.0007743923924863338
Test Loss:  0.0008004663977771997
Valid Loss:  0.0010265740565955639
Epoch:  410  	Training Loss: 0.0007730653160251677
Test Loss:  0.0007993205799721181
Valid Loss:   82%|████████▏ | 410/500 [05:05<00:30,  2.99it/s] 82%|████████▏ | 412/500 [05:11<01:45,  1.20s/it] 83%|████████▎ | 414/500 [05:11<01:14,  1.16it/s] 83%|████████▎ | 416/500 [05:11<00:52,  1.59it/s] 84%|████████▎ | 418/500 [05:11<00:38,  2.14it/s] 84%|████████▍ | 420/500 [05:12<00:28,  2.84it/s] 84%|████████▍ | 422/500 [05:18<01:34,  1.22s/it] 85%|████████▍ | 424/500 [05:18<01:06,  1.15it/s] 85%|████████▌ | 426/500 [05:18<00:46,  1.59it/s] 86%|████████▌ | 428/500 [05:18<00:33,  2.17it/s] 86%|████████▌ | 430/500 [05:19<00:24,  2.91it/s] 86%|████████▋ | 432/500 [05:25<01:23,  1.23s/it] 87%|████████▋ | 434/500 [05:25<00:58,  1.14it/s] 87%|████████▋ | 436/500 [05:25<00:40,  1.57it/s] 88%|████████▊ | 438/500 [05:26<00:28,  2.15it/s] 88%|████████▊ | 440/500 [05:26<00:20,  2.89it/s] 88%|████████▊ | 442/500 [05:32<01:10,  1.21s/it] 89%|████████▉ | 444/500 [05:32<00:48,  1.15it/s] 89%|████████▉ | 446/500 [05:32<00:33,  1.59it/s] 90%|████████▉ | 448/500 [05:33<00:23,  2.18it/s] 90%|█████████ | 450/500 [05:33<00:17,  2.93it/s] 90%|█████████ | 452/500 [05:39<00:58,  1.22s/it] 91%|█████████ | 454/500 [05:39<00:40,  1.15it/s] 91%|█████████ | 456/500 [05:39<00:27,  1.59it/s] 92%|█████████▏| 458/500 [05:40<00:19,  2.15it/s] 92%|█████████▏| 460/500 [05:40<00:13,  2.87it/s] 92%|█████████▏| 462/500 [05:46<00:45,  1.21s/it] 93%|█████████▎| 464/500 [05:46<00:31,  1.15it/s] 93%|█████████▎| 466/500 [05:47<00:21,  1.60it/s] 94%|█████████▎| 468/500 [05:47<00:14,  2.18it/s] 94%|█████████▍| 470/500 [05:47<00:10,  2.91it/s] 94%|█████████▍| 472/500 [05:53<00:33,  1.20s/it] 95%|█████████▍| 474/500 [05:53<00:22,  1.16it/s] 95%|█████████▌| 476/500 [05:53<00:14,  1.61it/s] 96%|█████████▌| 478/500 [05:54<00:10,  2.18it/s]0.0010247519239783287
Epoch:  411  	Training Loss: 0.0007717431872151792
Test Loss:  0.0007982435054145753
Valid Loss:  0.0010229473700746894
Epoch:  412  	Training Loss: 0.0007704314775764942
Test Loss:  0.0007964916294440627
Valid Loss:  0.0010225289734080434
Epoch:  413  	Training Loss: 0.0007702815346419811
Test Loss:  0.0007951628649607301
Valid Loss:  0.0010220250114798546
Epoch:  414  	Training Loss: 0.000770153128542006
Test Loss:  0.0007941419607959688
Valid Loss:  0.0010214617941528559
Epoch:  415  	Training Loss: 0.0007700380519963801
Test Loss:  0.0007933418964967132
Valid Loss:  0.0010208562016487122
Epoch:  416  	Training Loss: 0.0007699306006543338
Test Loss:  0.0007927020196802914
Valid Loss:  0.0010202258126810193
Epoch:  417  	Training Loss: 0.0007698286790400743
Test Loss:  0.0007921803626231849
Valid Loss:  0.001019580289721489
Epoch:  418  	Training Loss: 0.0007697309483774006
Test Loss:  0.0007917463663034141
Valid Loss:  0.0010189281310886145
Epoch:  419  	Training Loss: 0.0007696364773437381
Test Loss:  0.0007913769222795963
Valid Loss:  0.0010182748083025217
Epoch:  420  	Training Loss: 0.0007695446256548166
Test Loss:  0.0007910543354228139
Valid Loss:  0.0010176249779760838
Epoch:  421  	Training Loss: 0.0007694556843489408
Test Loss:  0.000790767720900476
Valid Loss:  0.0010169822489842772
Epoch:  422  	Training Loss: 0.0007693692459724844
Test Loss:  0.0007902807556092739
Valid Loss:  0.0010164754930883646
Epoch:  423  	Training Loss: 0.0007693039951846004
Test Loss:  0.0007899086340330541
Valid Loss:  0.001015955931507051
Epoch:  424  	Training Loss: 0.0007692400831729174
Test Loss:  0.0007896102033555508
Valid Loss:  0.0010154289193451405
Epoch:  425  	Training Loss: 0.0007691782666370273
Test Loss:  0.0007893608999438584
Valid Loss:  0.0010149041190743446
Epoch:  426  	Training Loss: 0.0007691181963309646
Test Loss:  0.0007891438435763121
Valid Loss:  0.00101438257843256
Epoch:  427  	Training Loss: 0.0007690592901781201
Test Loss:  0.0007889500120654702
Valid Loss:  0.001013867324218154
Epoch:  428  	Training Loss: 0.0007690014899708331
Test Loss:  0.0007887713145464659
Valid Loss:  0.0010133585892617702
Epoch:  429  	Training Loss: 0.0007689454359933734
Test Loss:  0.0007886035600677133
Valid Loss:  0.0010128587018698454
Epoch:  430  	Training Loss: 0.0007688906043767929
Test Loss:  0.0007884446531534195
Valid Loss:  0.0010123667307198048
Epoch:  431  	Training Loss: 0.0007688365876674652
Test Loss:  0.0007882919744588435
Valid Loss:  0.0010118841892108321
Epoch:  432  	Training Loss: 0.0007687843171879649
Test Loss:  0.0007889250991865993
Valid Loss:  0.0010119311045855284
Epoch:  433  	Training Loss: 0.0007679552072659135
Test Loss:  0.0007889578700996935
Valid Loss:  0.0010120507795363665
Epoch:  434  	Training Loss: 0.0007672130595892668
Test Loss:  0.0007886033272370696
Valid Loss:  0.0010121951345354319
Epoch:  435  	Training Loss: 0.0007665343000553548
Test Loss:  0.0007879497134126723
Valid Loss:  0.0010123088723048568
Epoch:  436  	Training Loss: 0.0007659448310732841
Test Loss:  0.0007872729911468923
Valid Loss:  0.0010123513638973236
Epoch:  437  	Training Loss: 0.0007654302753508091
Test Loss:  0.0007865082006901503
Valid Loss:  0.0010123561369255185
Epoch:  438  	Training Loss: 0.0007649444742128253
Test Loss:  0.0007856629672460258
Valid Loss:  0.0010123339015990496
Epoch:  439  	Training Loss: 0.0007644826546311378
Test Loss:  0.000784808536991477
Valid Loss:  0.001012266962788999
Epoch:  440  	Training Loss: 0.0007640562835149467
Test Loss:  0.0007839335594326258
Valid Loss:  0.0010121234226971865
Epoch:  441  	Training Loss: 0.0007636727532371879
Test Loss:  0.000782991002779454
Valid Loss:  0.001011937391012907
Epoch:  442  	Training Loss: 0.0007633198401890695
Test Loss:  0.0007814276614226401
Valid Loss:  0.0010100010549649596
Epoch:  443  	Training Loss: 0.0007604134734719992
Test Loss:  0.0007797215366736054
Valid Loss:  0.001008088351227343
Epoch:  444  	Training Loss: 0.0007575895288027823
Test Loss:  0.0007779601728543639
Valid Loss:  0.00100618414580822
Epoch:  445  	Training Loss: 0.0007548037101514637
Test Loss:  0.0007760925218462944
Valid Loss:  0.0010042624780908227
Epoch:  446  	Training Loss: 0.0007520500803366303
Test Loss:  0.0007741887238807976
Valid Loss:  0.0010023405775427818
Epoch:  447  	Training Loss: 0.0007493578013963997
Test Loss:  0.0007724047172814608
Valid Loss:  0.0010004563955590129
Epoch:  448  	Training Loss: 0.0007467457326129079
Test Loss:  0.0007705463212914765
Valid Loss:  0.000998549279756844
Epoch:  449  	Training Loss: 0.0007441829657182097
Test Loss:  0.0007686405442655087
Valid Loss:  0.0009966159705072641
Epoch:  450  	Training Loss: 0.0007416695589199662
Test Loss:  0.0007667740574106574
Valid Loss:  0.0009946568170562387
Epoch:  451  	Training Loss: 0.0007391928811557591
Test Loss:  0.0007649391191080213
Valid Loss:  0.0009926798520609736
Epoch:  452  	Training Loss: 0.0007367455400526524
Test Loss:  0.0007634158828295767
Valid Loss:  0.0009916761191561818
Epoch:  453  	Training Loss: 0.0007356770802289248
Test Loss:  0.0007621006807312369
Valid Loss:  0.0009906458435580134
Epoch:  454  	Training Loss: 0.0007346154889091849
Test Loss:  0.0007609272142872214
Valid Loss:  0.0009895977564156055
Epoch:  455  	Training Loss: 0.0007335591944865882
Test Loss:  0.0007598514785058796
Valid Loss:  0.000988538609817624
Epoch:  456  	Training Loss: 0.0007325076148845255
Test Loss:  0.000758841575589031
Valid Loss:  0.0009874734096229076
Epoch:  457  	Training Loss: 0.0007314585382118821
Test Loss:  0.0007578786462545395
Valid Loss:  0.00098640494979918
Epoch:  458  	Training Loss: 0.0007304152240976691
Test Loss:  0.0007570115849375725
Valid Loss:  0.0009853534866124392
Epoch:  459  	Training Loss: 0.0007293775561265647
Test Loss:  0.0007561376551166177
Valid Loss:  0.0009843048173934221
Epoch:  460  	Training Loss: 0.0007283438462764025
Test Loss:  0.0007552604656666517
Valid Loss:  0.0009832588257268071
Epoch:  461  	Training Loss: 0.0007273135706782341
Test Loss:  0.0007543843821622431
Valid Loss:  0.0009822126012295485
Epoch:  462  	Training Loss: 0.0007262858562171459
Test Loss:  0.0007542885141447186
Valid Loss:  0.0009779317770153284
Epoch:  463  	Training Loss: 0.0007233265787363052
Test Loss:  0.000753703061491251
Valid Loss:  0.0009739820379763842
Epoch:  464  	Training Loss: 0.0007204810390248895
Test Loss:  0.0007528066635131836
Valid Loss:  0.0009703270625323057
Epoch:  465  	Training Loss: 0.0007177164079621434
Test Loss:  0.0007517246413044631
Valid Loss:  0.0009669022401794791
Epoch:  466  	Training Loss: 0.0007150149904191494
Test Loss:  0.0007505316752940416
Valid Loss:  0.0009636800969019532
Epoch:  467  	Training Loss: 0.0007124115945771337
Test Loss:  0.0007492301519960165
Valid Loss:  0.0009606642997823656
Epoch:  468  	Training Loss: 0.0007098775822669268
Test Loss:  0.0007478563347831368
Valid Loss:  0.0009578093886375427
Epoch:  469  	Training Loss: 0.0007073900778777897
Test Loss:  0.0007464588852599263
Valid Loss:  0.0009550623944960535
Epoch:  470  	Training Loss: 0.0007049342384561896
Test Loss:  0.0007449834374710917
Valid Loss:  0.0009523957851342857
Epoch:  471  	Training Loss: 0.0007025211816653609
Test Loss:  0.0007435098523274064
Valid Loss:  0.0009498137515038252
Epoch:  472  	Training Loss: 0.0007001406047493219
Test Loss:  0.0007432083366438746
Valid Loss:  0.0009501117165200412
Epoch:  473  	Training Loss: 0.0006996850715950131
Test Loss:  0.0007426856318488717
Valid Loss:  0.0009503785986453295
Epoch:  474  	Training Loss: 0.00069925602292642
Test Loss:  0.0007420184556394815
Valid Loss:  0.0009506149217486382
Epoch:  475  	Training Loss: 0.0006988525856286287
Test Loss:  0.0007412141421809793
Valid Loss:  0.0009508124203421175
Epoch:  476  	Training Loss: 0.0006984705105423927
Test Loss:  0.0007403683848679066
Valid Loss:  0.0009509839583188295
Epoch:  477  	Training Loss: 0.0006981006590649486
Test Loss:  0.0007394991698674858
Valid Loss:  0.0009511312237009406
Epoch:  478  	Training Loss: 0.0006977424491196871
Test Loss:  0.0007386235520243645
Valid Loss:  0.0009512557880952954
 96%|█████████▌| 480/500 [05:54<00:06,  2.93it/s] 96%|█████████▋| 482/500 [06:00<00:21,  1.21s/it] 97%|█████████▋| 484/500 [06:00<00:13,  1.15it/s] 97%|█████████▋| 486/500 [06:00<00:08,  1.59it/s] 98%|█████████▊| 488/500 [06:01<00:05,  2.17it/s] 98%|█████████▊| 490/500 [06:01<00:03,  2.92it/s] 98%|█████████▊| 492/500 [06:07<00:09,  1.19s/it] 99%|█████████▉| 494/500 [06:07<00:05,  1.18it/s] 99%|█████████▉| 496/500 [06:07<00:02,  1.62it/s]100%|█████████▉| 498/500 [06:07<00:00,  2.22it/s]100%|██████████| 500/500 [06:08<00:00,  2.97it/s]100%|██████████| 500/500 [06:08<00:00,  1.36it/s]
Epoch:  479  	Training Loss: 0.0006973937852308154
Test Loss:  0.0007377496222034097
Valid Loss:  0.0009513591066934168
Epoch:  480  	Training Loss: 0.0006970558315515518
Test Loss:  0.0007368369260802865
Valid Loss:  0.0009514280827715993
Epoch:  481  	Training Loss: 0.0006967397057451308
Test Loss:  0.000735873298253864
Valid Loss:  0.000951453810557723
Epoch:  482  	Training Loss: 0.0006964401109144092
Test Loss:  0.0007367075304500759
Valid Loss:  0.0009502919274382293
Epoch:  483  	Training Loss: 0.0006962041952647269
Test Loss:  0.0007372575928457081
Valid Loss:  0.0009492558892816305
Epoch:  484  	Training Loss: 0.0006959924940019846
Test Loss:  0.0007375909481197596
Valid Loss:  0.0009483159519731998
Epoch:  485  	Training Loss: 0.0006957956356927752
Test Loss:  0.0007377610309049487
Valid Loss:  0.0009474543621763587
Epoch:  486  	Training Loss: 0.0006956075085327029
Test Loss:  0.0007378059672191739
Valid Loss:  0.000946655054576695
Epoch:  487  	Training Loss: 0.0006954243872314692
Test Loss:  0.0007377573056146502
Valid Loss:  0.0009459097636863589
Epoch:  488  	Training Loss: 0.0006952454568818212
Test Loss:  0.0007376368157565594
Valid Loss:  0.000945206789765507
Epoch:  489  	Training Loss: 0.000695068680215627
Test Loss:  0.0007374621345661581
Valid Loss:  0.0009445420000702143
Epoch:  490  	Training Loss: 0.000694893766194582
Test Loss:  0.0007372481632046402
Valid Loss:  0.0009439088753424585
Epoch:  491  	Training Loss: 0.000694720190949738
Test Loss:  0.0007370036328211427
Valid Loss:  0.000943303108215332
Epoch:  492  	Training Loss: 0.0006945477216504514
Test Loss:  0.0007263906300067902
Valid Loss:  0.000943099963478744
Epoch:  493  	Training Loss: 0.0006929858354851604
Test Loss:  0.0007218067767098546
Valid Loss:  0.0009424634044989944
Epoch:  494  	Training Loss: 0.0006919787847436965
Test Loss:  0.0007195044308900833
Valid Loss:  0.0009415448876097798
Epoch:  495  	Training Loss: 0.0006910605588927865
Test Loss:  0.0007180891698226333
Valid Loss:  0.0009405020391568542
Epoch:  496  	Training Loss: 0.0006901657907292247
Test Loss:  0.0007169916061684489
Valid Loss:  0.0009394092485308647
Epoch:  497  	Training Loss: 0.0006893102545291185
Test Loss:  0.000716057256795466
Valid Loss:  0.0009382970165461302
Epoch:  498  	Training Loss: 0.0006884658941999078
Test Loss:  0.0007150947931222618
Valid Loss:  0.0009371617343276739
Epoch:  499  	Training Loss: 0.0006876429542899132
Test Loss:  0.0007142330869100988
Valid Loss:  0.0009360203403048217
Epoch:  500  	Training Loss: 0.0006868229247629642
Test Loss:  0.0007134138722904027
Valid Loss:  0.0009348819148726761
seed is  9
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.25it/s]  1%|          | 4/500 [00:00<00:31, 15.72it/s]  1%|          | 6/500 [00:00<00:30, 16.06it/s]  2%|▏         | 8/500 [00:00<00:30, 16.16it/s]  2%|▏         | 10/500 [00:00<00:30, 16.18it/s]  2%|▏         | 12/500 [00:00<00:30, 16.12it/s]  3%|▎         | 14/500 [00:00<00:30, 16.14it/s]  3%|▎         | 16/500 [00:00<00:29, 16.26it/s]  4%|▎         | 18/500 [00:01<00:29, 16.30it/s]  4%|▍         | 20/500 [00:01<00:29, 16.25it/s]  4%|▍         | 22/500 [00:01<00:29, 16.14it/s]  5%|▍         | 24/500 [00:01<00:29, 16.18it/s]  5%|▌         | 26/500 [00:01<00:29, 16.22it/s]  6%|▌         | 28/500 [00:01<00:29, 16.24it/s]  6%|▌         | 30/500 [00:01<00:28, 16.24it/s]  6%|▋         | 32/500 [00:01<00:28, 16.17it/s]  7%|▋         | 34/500 [00:02<00:28, 16.13it/s]  7%|▋         | 36/500 [00:02<00:28, 16.10it/s]  8%|▊         | 38/500 [00:02<00:28, 15.99it/s]  8%|▊         | 40/500 [00:02<00:28, 16.07it/s]  8%|▊         | 42/500 [00:02<00:28, 16.12it/s]  9%|▉         | 44/500 [00:02<00:28, 16.21it/s]  9%|▉         | 46/500 [00:02<00:27, 16.23it/s] 10%|▉         | 48/500 [00:02<00:27, 16.20it/s] 10%|█         | 50/500 [00:03<00:27, 16.22it/s] 10%|█         | 52/500 [00:03<00:28, 15.48it/s] 11%|█         | 54/500 [00:03<00:28, 15.71it/s] 11%|█         | 56/500 [00:03<00:28, 15.81it/s] 12%|█▏        | 58/500 [00:03<00:27, 15.82it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.98it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.84it/s] 13%|█▎        | 64/500 [00:03<00:27, 15.99it/s] 13%|█▎        | 66/500 [00:04<00:29, 14.82it/s] 14%|█▎        | 68/500 [00:04<00:29, 14.65it/s] 14%|█▍        | 70/500 [00:04<00:28, 14.95it/s] 14%|█▍        | 72/500 [00:04<00:28, 15.21it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.35it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.68it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.92it/s] 16%|█▌        | 80/500 [00:05<00:26, 16.01it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.56it/s] 17%|█▋        | 84/500 [00:05<00:28, 14.66it/s] 17%|█▋        | 86/500 [00:05<00:27, 15.19it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.56it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.65it/s] 18%|█▊        | 92/500 [00:05<00:26, 15.65it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.76it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.90it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.92it/s] 20%|██        | 100/500 [00:06<00:24, 16.06it/s] 20%|██        | 102/500 [00:06<00:24, 16.21it/s] 21%|██        | 104/500 [00:06<00:24, 15.98it/s] 21%|██        | 106/500 [00:06<00:25, 15.59it/s] 22%|██▏       | 108/500 [00:06<00:25, 15.66it/s] 22%|██▏       | 110/500 [00:06<00:24, 15.66it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.73it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.76it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.70it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.83it/s] 24%|██▍       | 120/500 [00:07<00:23, 15.92it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.03it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.13it/s]Epoch:  1  	Training Loss: 0.07082173973321915
Test Loss:  1347.865478515625
Valid Loss:  1339.5340576171875
Epoch:  2  	Training Loss: 1341.691162109375
Test Loss:  284192919257088.0
Valid Loss:  278679825416192.0
Epoch:  3  	Training Loss: 282765480165376.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.15it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.08it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.16it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.01it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.79it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.83it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.98it/s] 28%|██▊       | 140/500 [00:08<00:22, 15.69it/s] 28%|██▊       | 142/500 [00:08<00:23, 15.38it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.54it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.69it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.92it/s] 30%|███       | 150/500 [00:09<00:22, 15.87it/s] 30%|███       | 152/500 [00:09<00:21, 16.02it/s] 31%|███       | 154/500 [00:09<00:21, 16.06it/s] 31%|███       | 156/500 [00:09<00:21, 15.76it/s] 32%|███▏      | 158/500 [00:09<00:22, 15.38it/s] 32%|███▏      | 160/500 [00:10<00:22, 14.81it/s] 32%|███▏      | 162/500 [00:10<00:23, 14.37it/s] 33%|███▎      | 164/500 [00:10<00:24, 13.91it/s] 33%|███▎      | 166/500 [00:10<00:23, 14.50it/s] 34%|███▎      | 168/500 [00:10<00:23, 14.18it/s] 34%|███▍      | 170/500 [00:10<00:24, 13.74it/s] 34%|███▍      | 172/500 [00:10<00:22, 14.43it/s] 35%|███▍      | 174/500 [00:11<00:21, 14.95it/s] 35%|███▌      | 176/500 [00:11<00:21, 14.99it/s] 36%|███▌      | 178/500 [00:11<00:21, 14.83it/s] 36%|███▌      | 180/500 [00:11<00:21, 15.22it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.49it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.57it/s] 37%|███▋      | 186/500 [00:11<00:19, 15.83it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.99it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.10it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.17it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.20it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.09it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.19it/s] 40%|████      | 200/500 [00:12<00:19, 15.25it/s] 40%|████      | 202/500 [00:12<00:20, 14.21it/s] 41%|████      | 204/500 [00:13<00:20, 14.28it/s] 41%|████      | 206/500 [00:13<00:19, 14.85it/s] 42%|████▏     | 208/500 [00:13<00:19, 15.25it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.56it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.63it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.80it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.91it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.97it/s] 44%|████▍     | 220/500 [00:14<00:17, 15.80it/s] 44%|████▍     | 222/500 [00:14<00:19, 14.35it/s] 45%|████▍     | 224/500 [00:14<00:20, 13.79it/s] 45%|████▌     | 226/500 [00:14<00:19, 14.39it/s] 46%|████▌     | 228/500 [00:14<00:18, 14.79it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.20it/s] 46%|████▋     | 232/500 [00:14<00:17, 15.49it/s] 47%|████▋     | 234/500 [00:15<00:16, 15.74it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.95it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.96it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.00it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.98it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.91it/s] 49%|████▉     | 246/500 [00:15<00:15, 15.93it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.00it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.08it/s] 50%|█████     | 252/500 [00:16<00:15, 16.16it/s] 51%|█████     | 254/500 [00:16<00:15, 16.07it/s] 51%|█████     | 256/500 [00:16<00:15, 16.08it/s] 52%|█████▏    | 258/500 [00:16<00:15, 16.12it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.16it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.08it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.13it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.93it/s] 54%|█████▎    | 268/500 [00:17<00:15, 14.62it/s] 54%|█████▍    | 270/500 [00:17<00:15, 14.63it/s] 54%|█████▍    | 272/500 [00:17<00:15, 15.00it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.34it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.62it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.19it/s] 56%|█████▌    | 280/500 [00:17<00:15, 14.52it/s] 56%|█████▋    | 282/500 [00:18<00:15, 14.49it/s] 57%|█████▋    | 284/500 [00:18<00:14, 14.89it/s] 57%|█████▋    | 286/500 [00:18<00:14, 15.10it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.45it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.70it/s] 58%|█████▊    | 292/500 [00:18<00:13, 14.90it/s] 59%|█████▉    | 294/500 [00:18<00:14, 14.11it/s] 59%|█████▉    | 296/500 [00:19<00:14, 13.85it/s] 60%|█████▉    | 298/500 [00:19<00:13, 14.54it/s] 60%|██████    | 300/500 [00:19<00:13, 15.07it/s] 60%|██████    | 302/500 [00:19<00:12, 15.49it/s] 61%|██████    | 304/500 [00:19<00:12, 15.75it/s] 61%|██████    | 306/500 [00:19<00:12, 15.90it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.05it/s] 62%|██████▏   | 310/500 [00:19<00:13, 14.25it/s] 62%|██████▏   | 312/500 [00:20<00:13, 13.82it/s] 63%|██████▎   | 314/500 [00:20<00:13, 13.31it/s] 63%|██████▎   | 316/500 [00:20<00:14, 13.02it/s] 64%|██████▎   | 318/500 [00:20<00:14, 12.85it/s] 64%|██████▍   | 320/500 [00:20<00:14, 12.70it/s] 64%|██████▍   | 322/500 [00:20<00:13, 13.12it/s] 65%|██████▍   | 324/500 [00:21<00:13, 13.41it/s] 65%|██████▌   | 326/500 [00:21<00:12, 14.05it/s] 66%|██████▌   | 328/500 [00:21<00:11, 14.59it/s] 66%|██████▌   | 330/500 [00:21<00:11, 15.06it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.44it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.34it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.60it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.64it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.75it/s] 68%|██████▊   | 342/500 [00:22<00:09, 15.92it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.08it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.04it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.80it/s] 70%|███████   | 350/500 [00:22<00:09, 15.89it/s] 70%|███████   | 352/500 [00:22<00:09, 15.96it/s] 71%|███████   | 354/500 [00:22<00:09, 15.98it/s] 71%|███████   | 356/500 [00:23<00:09, 15.92it/s] 72%|███████▏  | 358/500 [00:23<00:08, 15.99it/s] 72%|███████▏  | 360/500 [00:23<00:08, 15.97it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.01it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.05it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.19it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.26it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.30it/s] 74%|███████▍  | 372/500 [00:24<00:07, 16.35it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 16.18it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.17it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.15it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.01it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.06it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.15it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.17it/s] 78%|███████▊  | 388/500 [00:25<00:06, 16.25it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.21it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.29it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.13it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.23it/s] 80%|███████▉  | 398/500 [00:25<00:07, 14.16it/s] 80%|████████  | 400/500 [00:25<00:07, 13.56it/s] 80%|████████  | 402/500 [00:26<00:07, 13.37it/s] 81%|████████  | 404/500 [00:26<00:06, 14.15it/s] 81%|████████  | 406/500 [00:26<00:06, 14.74it/s] 82%|████████▏ | 408/500 [00:26<00:06, 15.22it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.49it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.67it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.79it/s] 83%|████████▎ | 416/500 [00:26<00:05, 15.97it/s] 84%|████████▎ | 418/500 [00:27<00:05, 16.07it/s] 84%|████████▍ | 420/500 [00:27<00:04, 16.04it/s] 84%|████████▍ | 422/500 [00:27<00:04, 15.97it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.01it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.13it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.09it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.14it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.24it/s] 87%|████████▋ | 434/500 [00:28<00:04, 16.23it/s] 87%|████████▋ | 436/500 [00:28<00:03, 16.24it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.13it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.07it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.07it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.11it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.20it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.20it/s] 90%|█████████ | 450/500 [00:29<00:03, 15.69it/s] 90%|█████████ | 452/500 [00:29<00:03, 14.49it/s] 91%|█████████ | 454/500 [00:29<00:03, 14.42it/s] 91%|█████████ | 456/500 [00:29<00:02, 14.81it/s] 92%|█████████▏| 458/500 [00:29<00:02, 14.32it/s] 92%|█████████▏| 460/500 [00:29<00:02, 14.48it/s] 92%|█████████▏| 462/500 [00:29<00:02, 13.69it/s] 93%|█████████▎| 464/500 [00:30<00:02, 13.71it/s] 93%|█████████▎| 466/500 [00:30<00:02, 14.32it/s] 94%|█████████▎| 468/500 [00:30<00:02, 14.84it/s] 94%|█████████▍| 470/500 [00:30<00:02, 14.99it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.21it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.43it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.67it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.85it/s] 96%|█████████▌| 480/500 [00:31<00:01, 15.99it/s] 96%|█████████▋| 482/500 [00:31<00:01, 15.97it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.02it/s] 97%|█████████▋| 486/500 [00:31<00:00, 16.15it/s] 98%|█████████▊| 488/500 [00:31<00:00, 16.13it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.17it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.19it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.20it/s] 99%|█████████▉| 496/500 [00:32<00:00, 16.24it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 16.14it/s]100%|██████████| 500/500 [00:32<00:00, 16.01it/s]100%|██████████| 500/500 [00:32<00:00, 15.49it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  9
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:46,  6.47s/it]  1%|          | 3/500 [00:06<14:19,  1.73s/it]  1%|          | 5/500 [00:06<07:13,  1.14it/s]  1%|▏         | 7/500 [00:06<04:22,  1.88it/s]  2%|▏         | 9/500 [00:07<02:54,  2.81it/s]  2%|▏         | 11/500 [00:13<10:57,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:19<13:19,  1.65s/it]  3%|▎         | 17/500 [00:20<09:15,  1.15s/it]  4%|▍         | 19/500 [00:20<06:31,  1.23it/s]  4%|▍         | 21/500 [00:32<19:55,  2.50s/it]  5%|▍         | 23/500 [00:32<13:58,  1.76s/it]  5%|▌         | 25/500 [00:39<17:26,  2.20s/it]  5%|▌         | 27/500 [00:39<12:19,  1.56s/it]  6%|▌         | 29/500 [00:39<08:46,  1.12s/it]  6%|▌         | 30/500 [00:46<16:01,  2.04s/it]  6%|▌         | 31/500 [00:52<22:37,  2.89s/it]  7%|▋         | 33/500 [00:52<14:30,  1.86s/it]  7%|▋         | 35/500 [00:58<18:02,  2.33s/it]  7%|▋         | 37/500 [00:59<12:15,  1.59s/it]  8%|▊         | 39/500 [00:59<08:27,  1.10s/it]  8%|▊         | 40/500 [01:05<15:42,  2.05s/it]  8%|▊         | 41/500 [01:11<22:37,  2.96s/it]  9%|▊         | 43/500 [01:11<14:17,  1.88s/it]  9%|▉         | 45/500 [01:18<17:47,  2.35s/it]  9%|▉         | 47/500 [01:18<12:00,  1.59s/it] 10%|▉         | 49/500 [01:18<08:16,  1.10s/it] 10%|█         | 50/500 [01:24<15:30,  2.07s/it] 10%|█         | 51/500 [01:31<22:09,  2.96s/it] 11%|█         | 53/500 [01:31<13:59,  1.88s/it] 11%|█         | 55/500 [01:37<17:13,  2.32s/it] 11%|█▏        | 57/500 [01:37<11:36,  1.57s/it] 12%|█▏        | 59/500 [01:37<07:59,  1.09s/it] 12%|█▏        | 61/500 [01:50<19:56,  2.73s/it]Epoch:  1  	Training Loss: 0.07082174718379974
Test Loss:  28.16745376586914
Valid Loss:  27.446544647216797
Epoch:  2  	Training Loss: 26.826078414916992
Test Loss:  19.633331298828125
Valid Loss:  18.740182876586914
Epoch:  3  	Training Loss: 18.64175796508789
Test Loss:  0.8573104739189148
Valid Loss:  0.8146299123764038
Epoch:  4  	Training Loss: 0.7213367223739624
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  5  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145376205444336
Epoch:  6  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  7  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  8  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  9  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  10  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  11  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  12  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  13  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  14  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  15  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  17  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  18  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  19  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  20  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  22  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  23  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  24  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  25  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  27  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  28  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  29  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  30  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985661149025
Valid Loss:  0.12145376205444336
Epoch:  32  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  33  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  34  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  35  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.08949095755815506
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  37  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  38  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  39  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  40  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  42  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
Epoch:  43  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  44  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145376205444336
Epoch:  45  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  47  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  48  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  49  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  50  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  52  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  53  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  54  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  55  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  57  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  58  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  59  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  60  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  62  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  63  	Training Loss: 0.08949095755815506
 13%|█▎        | 63/500 [01:50<13:53,  1.91s/it] 13%|█▎        | 65/500 [01:57<16:45,  2.31s/it] 13%|█▎        | 67/500 [01:57<11:45,  1.63s/it] 14%|█▍        | 69/500 [01:57<08:20,  1.16s/it] 14%|█▍        | 70/500 [02:03<14:56,  2.08s/it] 14%|█▍        | 71/500 [02:10<21:07,  2.95s/it] 15%|█▍        | 73/500 [02:10<13:29,  1.90s/it] 15%|█▌        | 75/500 [02:16<16:38,  2.35s/it] 15%|█▌        | 77/500 [02:16<11:15,  1.60s/it] 16%|█▌        | 79/500 [02:16<07:46,  1.11s/it] 16%|█▌        | 81/500 [02:29<19:14,  2.76s/it] 17%|█▋        | 83/500 [02:29<13:24,  1.93s/it] 17%|█▋        | 85/500 [02:36<15:58,  2.31s/it] 17%|█▋        | 87/500 [02:36<11:12,  1.63s/it] 18%|█▊        | 89/500 [02:36<07:54,  1.15s/it] 18%|█▊        | 89/500 [02:46<07:54,  1.15s/it] 18%|█▊        | 91/500 [02:49<18:35,  2.73s/it] 19%|█▊        | 93/500 [02:49<13:04,  1.93s/it] 19%|█▉        | 95/500 [02:55<15:38,  2.32s/it] 19%|█▉        | 97/500 [02:55<11:03,  1.65s/it] 20%|█▉        | 99/500 [02:56<07:50,  1.17s/it] 20%|█▉        | 99/500 [03:06<07:50,  1.17s/it] 20%|██        | 101/500 [03:08<18:02,  2.71s/it] 21%|██        | 103/500 [03:08<12:42,  1.92s/it] 21%|██        | 105/500 [03:15<15:09,  2.30s/it] 21%|██▏       | 107/500 [03:15<10:41,  1.63s/it] 22%|██▏       | 109/500 [03:15<07:34,  1.16s/it] 22%|██▏       | 109/500 [03:26<07:34,  1.16s/it] 22%|██▏       | 111/500 [03:28<17:35,  2.71s/it] 23%|██▎       | 113/500 [03:28<12:25,  1.93s/it] 23%|██▎       | 115/500 [03:34<14:40,  2.29s/it] 23%|██▎       | 117/500 [03:34<10:21,  1.62s/it] 24%|██▍       | 119/500 [03:34<07:20,  1.16s/it] 24%|██▍       | 119/500 [03:46<07:20,  1.16s/it] 24%|██▍       | 121/500 [03:47<17:07,  2.71s/it]Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  64  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  65  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  67  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  68  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  69  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  70  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  72  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  73  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  74  	Training Loss: 0.08949095755815506
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  75  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  77  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  78  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  79  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  80  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  82  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  83  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  84  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  85  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  87  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  88  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  89  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  90  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  92  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  93  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  94  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  95  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  97  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  98  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  99  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  100  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
Epoch:  102  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  103  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  104  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  105  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  107  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  108  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  109  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  110  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  112  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  113  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  114  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  115  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  117  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  118  	Training Loss: 0.08949095755815506
Test Loss:  0.12259858101606369
Valid Loss:  0.12145376205444336
Epoch:  119  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
Epoch:  120  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  122  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  123  	Training Loss: 0.08949096500873566
 25%|██▍       | 123/500 [03:47<12:04,  1.92s/it] 25%|██▌       | 125/500 [03:54<14:29,  2.32s/it] 25%|██▌       | 127/500 [03:54<10:14,  1.65s/it] 26%|██▌       | 129/500 [03:54<07:17,  1.18s/it] 26%|██▌       | 129/500 [04:06<07:17,  1.18s/it] 26%|██▌       | 131/500 [04:07<16:54,  2.75s/it] 27%|██▋       | 133/500 [04:07<11:54,  1.95s/it] 27%|██▋       | 135/500 [04:13<14:10,  2.33s/it] 27%|██▋       | 137/500 [04:14<10:01,  1.66s/it] 28%|██▊       | 139/500 [04:14<07:08,  1.19s/it] 28%|██▊       | 140/500 [04:20<12:27,  2.08s/it] 28%|██▊       | 141/500 [04:26<17:26,  2.91s/it] 29%|██▊       | 143/500 [04:26<11:12,  1.88s/it] 29%|██▉       | 145/500 [04:33<13:45,  2.33s/it] 29%|██▉       | 147/500 [04:33<09:19,  1.58s/it] 30%|██▉       | 149/500 [04:33<06:26,  1.10s/it] 30%|███       | 150/500 [04:39<12:03,  2.07s/it] 30%|███       | 151/500 [04:46<17:16,  2.97s/it] 31%|███       | 153/500 [04:46<10:54,  1.89s/it] 31%|███       | 155/500 [04:52<13:28,  2.34s/it] 31%|███▏      | 157/500 [04:52<09:04,  1.59s/it] 32%|███▏      | 159/500 [04:53<06:15,  1.10s/it] 32%|███▏      | 160/500 [04:59<12:00,  2.12s/it] 32%|███▏      | 161/500 [05:06<17:02,  3.02s/it] 32%|███▏      | 162/500 [05:06<13:11,  2.34s/it] 33%|███▎      | 164/500 [05:06<08:05,  1.44s/it] 33%|███▎      | 165/500 [05:12<14:01,  2.51s/it] 33%|███▎      | 167/500 [05:12<08:41,  1.57s/it] 34%|███▍      | 169/500 [05:12<05:41,  1.03s/it] 34%|███▍      | 171/500 [05:25<15:26,  2.82s/it] 35%|███▍      | 173/500 [05:25<10:29,  1.92s/it] 35%|███▌      | 175/500 [05:32<12:34,  2.32s/it] 35%|███▌      | 177/500 [05:32<08:43,  1.62s/it] 36%|███▌      | 179/500 [05:32<06:07,  1.15s/it] 36%|███▌      | 181/500 [05:45<14:37,  2.75s/it]Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  124  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  125  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  127  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  128  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  129  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  130  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  132  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  133  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  134  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  135  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  137  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  138  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  139  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  140  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
Epoch:  142  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  143  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  144  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  145  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.08949095755815506
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  147  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  148  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  149  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  150  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  152  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  153  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  154  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  155  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985586643219
Valid Loss:  0.12145376205444336
Epoch:  157  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  158  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  159  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  160  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  162  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  163  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  164  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145376205444336
Epoch:  165  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  167  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  168  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  169  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  170  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  172  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  173  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  174  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  175  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  177  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  178  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  179  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  180  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  182  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
 37%|███▋      | 183/500 [05:45<10:13,  1.94s/it] 37%|███▋      | 185/500 [05:51<12:08,  2.31s/it] 37%|███▋      | 187/500 [05:51<08:32,  1.64s/it] 38%|███▊      | 189/500 [05:51<06:02,  1.17s/it] 38%|███▊      | 191/500 [06:04<14:01,  2.72s/it] 39%|███▊      | 193/500 [06:04<09:51,  1.93s/it] 39%|███▉      | 195/500 [06:11<11:41,  2.30s/it] 39%|███▉      | 197/500 [06:11<08:15,  1.64s/it] 40%|███▉      | 199/500 [06:11<05:52,  1.17s/it] 40%|████      | 201/500 [06:24<13:37,  2.73s/it] 41%|████      | 203/500 [06:24<09:34,  1.93s/it] 41%|████      | 205/500 [06:30<11:22,  2.31s/it] 41%|████▏     | 207/500 [06:30<08:00,  1.64s/it] 42%|████▏     | 209/500 [06:30<05:40,  1.17s/it] 42%|████▏     | 211/500 [06:43<13:10,  2.74s/it] 43%|████▎     | 213/500 [06:43<09:16,  1.94s/it] 43%|████▎     | 215/500 [06:50<11:06,  2.34s/it] 43%|████▎     | 217/500 [06:50<07:49,  1.66s/it] 44%|████▍     | 219/500 [06:50<05:31,  1.18s/it] 44%|████▍     | 221/500 [07:03<12:37,  2.72s/it] 45%|████▍     | 223/500 [07:03<08:52,  1.92s/it] 45%|████▌     | 225/500 [07:09<10:31,  2.30s/it] 45%|████▌     | 227/500 [07:10<07:26,  1.63s/it] 46%|████▌     | 229/500 [07:10<05:17,  1.17s/it] 46%|████▌     | 231/500 [07:22<12:12,  2.72s/it] 47%|████▋     | 233/500 [07:23<08:34,  1.93s/it] 47%|████▋     | 235/500 [07:29<10:11,  2.31s/it] 47%|████▋     | 237/500 [07:29<07:10,  1.64s/it] 48%|████▊     | 239/500 [07:29<05:04,  1.17s/it] 48%|████▊     | 241/500 [07:42<11:41,  2.71s/it]Epoch:  183  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  184  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  185  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  187  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  188  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  189  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  190  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  192  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  193  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  194  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  195  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  197  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  198  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  199  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  200  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  202  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  203  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  204  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  205  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  207  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  208  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  209  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  210  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  212  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  213  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  214  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  215  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  217  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  218  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  219  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  220  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  222  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  223  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  224  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  225  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  227  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  228  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  229  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  230  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  232  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  233  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
Epoch:  234  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  235  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  237  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
Epoch:  238  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  239  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  240  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  242  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
 49%|████▊     | 243/500 [07:42<08:12,  1.92s/it] 49%|████▉     | 245/500 [07:48<09:43,  2.29s/it] 49%|████▉     | 247/500 [07:48<06:50,  1.62s/it] 50%|████▉     | 249/500 [07:49<04:50,  1.16s/it] 50%|█████     | 251/500 [08:01<11:15,  2.71s/it] 51%|█████     | 253/500 [08:01<07:54,  1.92s/it] 51%|█████     | 255/500 [08:08<09:27,  2.32s/it] 51%|█████▏    | 257/500 [08:08<06:39,  1.64s/it] 52%|█████▏    | 259/500 [08:08<04:42,  1.17s/it] 52%|█████▏    | 261/500 [08:21<10:54,  2.74s/it] 53%|█████▎    | 263/500 [08:21<07:40,  1.94s/it] 53%|█████▎    | 265/500 [08:27<09:05,  2.32s/it] 53%|█████▎    | 267/500 [08:28<06:23,  1.65s/it] 54%|█████▍    | 269/500 [08:28<04:30,  1.17s/it] 54%|█████▍    | 271/500 [08:40<10:24,  2.73s/it] 55%|█████▍    | 273/500 [08:41<07:18,  1.93s/it] 55%|█████▌    | 275/500 [08:47<08:43,  2.33s/it] 55%|█████▌    | 277/500 [08:47<06:08,  1.65s/it] 56%|█████▌    | 279/500 [08:47<04:19,  1.18s/it] 56%|█████▌    | 281/500 [09:00<09:53,  2.71s/it] 57%|█████▋    | 283/500 [09:00<06:56,  1.92s/it] 57%|█████▋    | 285/500 [09:07<08:14,  2.30s/it] 57%|█████▋    | 287/500 [09:07<05:47,  1.63s/it] 58%|█████▊    | 289/500 [09:07<04:05,  1.16s/it] 58%|█████▊    | 291/500 [09:19<09:24,  2.70s/it] 59%|█████▊    | 293/500 [09:20<06:36,  1.92s/it] 59%|█████▉    | 295/500 [09:26<07:54,  2.31s/it] 59%|█████▉    | 297/500 [09:26<05:34,  1.65s/it] 60%|█████▉    | 299/500 [09:26<03:56,  1.18s/it] 60%|██████    | 300/500 [09:33<06:57,  2.09s/it] 60%|██████    | 301/500 [09:39<09:44,  2.93s/it]Valid Loss:  0.12145374715328217
Epoch:  243  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  244  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  245  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  247  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  248  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  249  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  250  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  252  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  253  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  254  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  255  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  257  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  258  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  259  	Training Loss: 0.08949095755815506
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  260  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  262  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  263  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  264  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  265  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  267  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  268  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  269  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  270  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  272  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  273  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  274  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  275  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145376205444336
Epoch:  277  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  278  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  279  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  280  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  282  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
Epoch:  283  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  284  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  285  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  287  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  288  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  289  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  290  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  292  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  293  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  294  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  295  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  297  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  298  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  299  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  300  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
 61%|██████    | 303/500 [09:39<06:13,  1.90s/it] 61%|██████    | 305/500 [09:46<07:39,  2.35s/it] 61%|██████▏   | 307/500 [09:46<05:09,  1.60s/it] 62%|██████▏   | 309/500 [09:46<03:33,  1.12s/it] 62%|██████▏   | 310/500 [09:52<06:35,  2.08s/it] 62%|██████▏   | 311/500 [09:59<09:21,  2.97s/it] 63%|██████▎   | 313/500 [09:59<05:53,  1.89s/it] 63%|██████▎   | 315/500 [10:05<07:12,  2.34s/it] 63%|██████▎   | 317/500 [10:05<04:50,  1.59s/it] 64%|██████▍   | 319/500 [10:05<03:18,  1.10s/it] 64%|██████▍   | 320/500 [10:12<06:10,  2.06s/it] 64%|██████▍   | 321/500 [10:18<08:53,  2.98s/it] 65%|██████▍   | 323/500 [10:18<05:33,  1.89s/it] 65%|██████▌   | 325/500 [10:25<06:52,  2.35s/it] 65%|██████▌   | 327/500 [10:25<04:35,  1.59s/it] 66%|██████▌   | 329/500 [10:25<03:08,  1.10s/it] 66%|██████▌   | 329/500 [10:36<03:08,  1.10s/it] 66%|██████▌   | 331/500 [10:38<07:44,  2.75s/it] 67%|██████▋   | 333/500 [10:38<05:20,  1.92s/it] 67%|██████▋   | 335/500 [10:44<06:20,  2.31s/it] 67%|██████▋   | 337/500 [10:44<04:24,  1.62s/it] 68%|██████▊   | 339/500 [10:44<03:05,  1.15s/it] 68%|██████▊   | 339/500 [10:56<03:05,  1.15s/it] 68%|██████▊   | 341/500 [10:57<07:08,  2.70s/it] 69%|██████▊   | 343/500 [10:57<04:59,  1.90s/it] 69%|██████▉   | 345/500 [11:04<05:58,  2.32s/it] 69%|██████▉   | 347/500 [11:04<04:11,  1.64s/it] 70%|██████▉   | 349/500 [11:04<02:57,  1.17s/it] 70%|██████▉   | 349/500 [11:16<02:57,  1.17s/it] 70%|███████   | 351/500 [11:16<06:43,  2.71s/it] 71%|███████   | 353/500 [11:17<04:42,  1.92s/it] 71%|███████   | 355/500 [11:23<05:33,  2.30s/it] 71%|███████▏  | 357/500 [11:23<03:53,  1.63s/it] 72%|███████▏  | 359/500 [11:23<02:43,  1.16s/it]Epoch:  302  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  303  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  304  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  305  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  307  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  308  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  309  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  310  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  312  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  313  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  314  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  315  	Training Loss: 0.08949095755815506
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  317  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  318  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  319  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  320  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  322  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  323  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  324  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  325  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  327  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  328  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  329  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  330  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  332  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  333  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  334  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  335  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  337  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  338  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145376205444336
Epoch:  339  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  340  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  342  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  343  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  344  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  345  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  347  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  348  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  349  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  350  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  352  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  353  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  354  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  355  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  357  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  358  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  359  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  360  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
 72%|███████▏  | 361/500 [11:36<06:17,  2.72s/it] 73%|███████▎  | 363/500 [11:36<04:23,  1.92s/it] 73%|███████▎  | 365/500 [11:43<05:11,  2.31s/it] 73%|███████▎  | 367/500 [11:43<03:37,  1.64s/it] 74%|███████▍  | 369/500 [11:43<02:32,  1.17s/it] 74%|███████▍  | 371/500 [11:56<05:52,  2.73s/it] 75%|███████▍  | 373/500 [11:56<04:05,  1.93s/it] 75%|███████▌  | 375/500 [12:02<04:49,  2.32s/it] 75%|███████▌  | 377/500 [12:02<03:23,  1.65s/it] 76%|███████▌  | 379/500 [12:03<02:23,  1.18s/it] 76%|███████▌  | 380/500 [12:09<04:11,  2.09s/it] 76%|███████▌  | 381/500 [12:15<05:48,  2.92s/it] 77%|███████▋  | 383/500 [12:15<03:40,  1.88s/it] 77%|███████▋  | 385/500 [12:22<04:28,  2.34s/it] 77%|███████▋  | 387/500 [12:22<02:59,  1.59s/it] 78%|███████▊  | 389/500 [12:22<02:02,  1.11s/it] 78%|███████▊  | 390/500 [12:28<03:48,  2.08s/it] 78%|███████▊  | 391/500 [12:35<05:25,  2.99s/it] 79%|███████▊  | 393/500 [12:35<03:22,  1.90s/it] 79%|███████▉  | 395/500 [12:41<04:08,  2.36s/it] 79%|███████▉  | 397/500 [12:41<02:45,  1.60s/it] 80%|███████▉  | 399/500 [12:42<01:51,  1.11s/it] 80%|████████  | 400/500 [12:48<03:29,  2.10s/it] 80%|████████  | 401/500 [12:54<04:56,  3.00s/it] 81%|████████  | 403/500 [12:55<03:04,  1.90s/it] 81%|████████  | 405/500 [13:01<03:43,  2.35s/it] 81%|████████▏ | 407/500 [13:01<02:28,  1.59s/it] 82%|████████▏ | 409/500 [13:01<01:40,  1.10s/it] 82%|████████▏ | 410/500 [13:08<03:07,  2.08s/it] 82%|████████▏ | 411/500 [13:14<04:22,  2.95s/it] 83%|████████▎ | 413/500 [13:14<02:42,  1.87s/it] 83%|████████▎ | 415/500 [13:20<03:19,  2.34s/it] 83%|████████▎ | 417/500 [13:20<02:11,  1.59s/it] 84%|████████▍ | 419/500 [13:21<01:29,  1.10s/it] 84%|████████▍ | 420/500 [13:27<02:46,  2.08s/it]Valid Loss:  0.12145375460386276
Epoch:  362  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  363  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  364  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  365  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  367  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  368  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  369  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  370  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  372  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  373  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145375460386276
Epoch:  374  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  375  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  377  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  378  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  379  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  380  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  382  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  383  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  384  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  385  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  387  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  388  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  389  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  390  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  392  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  393  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  394  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  395  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  397  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  398  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  399  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  400  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  402  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  403  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  404  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  405  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  407  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  408  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  409  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  410  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  412  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  413  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  414  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  415  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  417  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  418  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  419  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  420  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
 84%|████████▍ | 421/500 [13:33<03:53,  2.96s/it] 85%|████████▍ | 423/500 [13:33<02:24,  1.87s/it] 85%|████████▌ | 425/500 [13:40<02:53,  2.32s/it] 85%|████████▌ | 427/500 [13:40<01:54,  1.57s/it] 86%|████████▌ | 429/500 [13:40<01:17,  1.09s/it] 86%|████████▌ | 431/500 [13:53<03:09,  2.74s/it] 87%|████████▋ | 433/500 [13:53<02:08,  1.92s/it] 87%|████████▋ | 435/500 [13:59<02:31,  2.33s/it] 87%|████████▋ | 437/500 [13:59<01:43,  1.64s/it] 88%|████████▊ | 439/500 [14:00<01:11,  1.17s/it] 88%|████████▊ | 441/500 [14:12<02:42,  2.75s/it] 89%|████████▊ | 443/500 [14:13<01:50,  1.94s/it] 89%|████████▉ | 445/500 [14:19<02:08,  2.34s/it] 89%|████████▉ | 447/500 [14:19<01:27,  1.66s/it] 90%|████████▉ | 449/500 [14:19<01:00,  1.18s/it] 90%|█████████ | 451/500 [14:32<02:14,  2.75s/it] 90%|█████████ | 452/500 [14:32<01:49,  2.28s/it] 91%|█████████ | 454/500 [14:32<01:10,  1.54s/it] 91%|█████████ | 456/500 [14:39<01:31,  2.08s/it] 92%|█████████▏| 458/500 [14:39<01:00,  1.44s/it] 92%|█████████▏| 460/500 [14:45<01:19,  1.99s/it] 92%|█████████▏| 461/500 [14:52<01:48,  2.79s/it] 93%|█████████▎| 463/500 [14:52<01:08,  1.86s/it] 93%|█████████▎| 465/500 [14:58<01:20,  2.30s/it] 93%|█████████▎| 467/500 [14:58<00:52,  1.59s/it] 94%|█████████▍| 469/500 [14:59<00:34,  1.12s/it] 94%|█████████▍| 470/500 [15:05<01:02,  2.08s/it] 94%|█████████▍| 471/500 [15:11<01:25,  2.95s/it] 95%|█████████▍| 473/500 [15:11<00:50,  1.88s/it] 95%|█████████▌| 475/500 [15:18<00:58,  2.32s/it] 95%|█████████▌| 477/500 [15:18<00:36,  1.58s/it] 96%|█████████▌| 479/500 [15:18<00:22,  1.09s/it]Epoch:  421  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  422  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  423  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  424  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  425  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  427  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  428  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  429  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  430  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  432  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  433  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  434  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  435  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  437  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  438  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  439  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  440  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  442  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  443  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  444  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  445  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  447  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  448  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  449  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  450  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  452  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  453  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  454  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  455  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  457  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  458  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  459  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  460  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  462  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  463  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  464  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  465  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  467  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  468  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  469  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  470  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  472  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  473  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  474  	Training Loss: 0.08949095755815506
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  475  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  477  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  478  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  479  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145376205444336
Epoch:  480  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
 96%|█████████▌| 480/500 [15:24<00:41,  2.06s/it] 96%|█████████▌| 481/500 [15:31<00:56,  2.97s/it] 97%|█████████▋| 483/500 [15:31<00:32,  1.89s/it] 97%|█████████▋| 485/500 [15:37<00:35,  2.36s/it] 97%|█████████▋| 487/500 [15:37<00:20,  1.60s/it] 98%|█████████▊| 489/500 [15:38<00:12,  1.11s/it] 98%|█████████▊| 490/500 [15:44<00:20,  2.09s/it] 98%|█████████▊| 491/500 [15:50<00:26,  2.97s/it] 99%|█████████▊| 493/500 [15:50<00:13,  1.89s/it] 99%|█████████▉| 495/500 [15:57<00:11,  2.37s/it] 99%|█████████▉| 497/500 [15:57<00:04,  1.61s/it]100%|█████████▉| 499/500 [15:57<00:01,  1.11s/it]100%|██████████| 500/500 [16:04<00:00,  2.10s/it]100%|██████████| 500/500 [16:04<00:00,  1.93s/it]
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  482  	Training Loss: 0.08949095755815506
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  483  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  484  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  485  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985661149025
Valid Loss:  0.12145374715328217
Epoch:  487  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  488  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  489  	Training Loss: 0.08949095755815506
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  490  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  492  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145376205444336
Epoch:  493  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  494  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  495  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145375460386276
Epoch:  497  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145374715328217
Epoch:  498  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
Epoch:  499  	Training Loss: 0.08949096500873566
Test Loss:  0.12259858101606369
Valid Loss:  0.12145374715328217
Epoch:  500  	Training Loss: 0.08949096500873566
Test Loss:  0.1225985735654831
Valid Loss:  0.12145375460386276
**************************************************learning rate decay**************************************************
seed is  9
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:28,  6.31s/it]  1%|          | 3/500 [00:06<14:06,  1.70s/it]  1%|          | 5/500 [00:06<07:09,  1.15it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:54,  2.82it/s]  2%|▏         | 11/500 [00:13<11:06,  1.36s/it]  3%|▎         | 13/500 [00:13<07:34,  1.07it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:51,  1.23s/it]  5%|▍         | 23/500 [00:20<06:59,  1.14it/s]  5%|▌         | 25/500 [00:20<05:00,  1.58it/s]  5%|▌         | 27/500 [00:20<03:38,  2.17it/s]  6%|▌         | 29/500 [00:20<02:41,  2.92it/s]  6%|▌         | 31/500 [00:33<16:52,  2.16s/it]  7%|▋         | 33/500 [00:33<11:54,  1.53s/it]  7%|▋         | 35/500 [00:33<08:26,  1.09s/it]  7%|▋         | 37/500 [00:34<06:02,  1.28it/s]  8%|▊         | 39/500 [00:34<04:21,  1.76it/s]  8%|▊         | 41/500 [00:40<10:36,  1.39s/it]  9%|▊         | 43/500 [00:41<07:36,  1.00it/s]  9%|▉         | 45/500 [00:41<05:29,  1.38it/s]  9%|▉         | 47/500 [00:41<03:58,  1.90it/s] 10%|▉         | 49/500 [00:41<02:55,  2.57it/s] 10%|█         | 51/500 [00:47<09:18,  1.24s/it] 11%|█         | 53/500 [00:48<06:40,  1.12it/s] 11%|█         | 55/500 [00:48<04:50,  1.53it/s] 11%|█▏        | 57/500 [00:48<03:31,  2.09it/s] 12%|█▏        | 59/500 [00:48<02:38,  2.79it/s] 12%|█▏        | 61/500 [00:54<08:50,  1.21s/it] 13%|█▎        | 63/500 [00:55<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:55<04:35,  1.58it/s] 13%|█▎        | 67/500 [00:55<03:20,  2.15it/s] 14%|█▍        | 69/500 [00:55<02:28,  2.90it/s]Epoch:  1  	Training Loss: 0.07082174718379974
Test Loss:  1.766676425933838
Valid Loss:  1.736515998840332
Epoch:  2  	Training Loss: 1.8690999746322632
Test Loss:  129.71847534179688
Valid Loss:  122.91654968261719
Epoch:  3  	Training Loss: 127.85943603515625
Test Loss:  0.6714810132980347
Valid Loss:  0.6919822096824646
Epoch:  4  	Training Loss: 0.8337035179138184
Test Loss:  0.38928812742233276
Valid Loss:  0.43420904874801636
Epoch:  5  	Training Loss: 0.5950645804405212
Test Loss:  0.33434781432151794
Valid Loss:  0.38859522342681885
Epoch:  6  	Training Loss: 0.5387150049209595
Test Loss:  0.30949851870536804
Valid Loss:  0.36262309551239014
Epoch:  7  	Training Loss: 0.5113073587417603
Test Loss:  0.2899106740951538
Valid Loss:  0.3426477015018463
Epoch:  8  	Training Loss: 0.4908790588378906
Test Loss:  0.2740548253059387
Valid Loss:  0.3263982832431793
Epoch:  9  	Training Loss: 0.47431451082229614
Test Loss:  0.2615364193916321
Valid Loss:  0.3135569989681244
Epoch:  10  	Training Loss: 0.4607992470264435
Test Loss:  0.25386273860931396
Valid Loss:  0.30511608719825745
Epoch:  11  	Training Loss: 0.4511704444885254
Test Loss:  0.24799631536006927
Valid Loss:  0.298135906457901
Epoch:  12  	Training Loss: 0.4434933066368103
Test Loss:  0.09708460420370102
Valid Loss:  0.1232977956533432
Epoch:  13  	Training Loss: 0.19940167665481567
Test Loss:  0.02305428683757782
Valid Loss:  0.04023626446723938
Epoch:  14  	Training Loss: 0.07683348655700684
Test Loss:  0.013278612866997719
Valid Loss:  0.02447497472167015
Epoch:  15  	Training Loss: 0.04522816091775894
Test Loss:  0.01505809836089611
Valid Loss:  0.02280711568892002
Epoch:  16  	Training Loss: 0.036608293652534485
Test Loss:  0.017447467893362045
Valid Loss:  0.023287657648324966
Epoch:  17  	Training Loss: 0.03378945216536522
Test Loss:  0.018829533830285072
Valid Loss:  0.023551885038614273
Epoch:  18  	Training Loss: 0.03238361328840256
Test Loss:  0.019430439919233322
Valid Loss:  0.023418135941028595
Epoch:  19  	Training Loss: 0.0313604362308979
Test Loss:  0.019691523164510727
Valid Loss:  0.02321651205420494
Epoch:  20  	Training Loss: 0.03052598051726818
Test Loss:  0.01963740773499012
Valid Loss:  0.022845400497317314
Epoch:  21  	Training Loss: 0.029653634876012802
Test Loss:  0.01937919482588768
Valid Loss:  0.022415772080421448
Epoch:  22  	Training Loss: 0.028792545199394226
Test Loss:  0.003971125930547714
Valid Loss:  0.00434254901483655
Epoch:  23  	Training Loss: 0.006280209869146347
Test Loss:  0.004674188327044249
Valid Loss:  0.0033361250534653664
Epoch:  24  	Training Loss: 0.00359688070602715
Test Loss:  0.0020966543816030025
Valid Loss:  0.0036101159639656544
Epoch:  25  	Training Loss: 0.004150961525738239
Test Loss:  0.002899147104471922
Valid Loss:  0.002214137464761734
Epoch:  26  	Training Loss: 0.002662010956555605
Test Loss:  0.0016537077026441693
Valid Loss:  0.0028760586865246296
Epoch:  27  	Training Loss: 0.0031129885464906693
Test Loss:  0.0023987749591469765
Valid Loss:  0.001851398148573935
Epoch:  28  	Training Loss: 0.0021802440751343966
Test Loss:  0.0013596469070762396
Valid Loss:  0.002390814945101738
Epoch:  29  	Training Loss: 0.0024089559447020292
Test Loss:  0.0020332597196102142
Valid Loss:  0.001582871307618916
Epoch:  30  	Training Loss: 0.0018013457302004099
Test Loss:  0.001217842916958034
Valid Loss:  0.002164350589737296
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.002013969933614135
Test Loss:  0.000770521757658571
Valid Loss:  0.0009384609293192625
Epoch:  32  	Training Loss: 0.0006997665041126311
Test Loss:  0.0007682155119255185
Valid Loss:  0.0009289149893447757
Epoch:  33  	Training Loss: 0.0006803697906434536
Test Loss:  0.0007664085715077817
Valid Loss:  0.0009213467710651457
Epoch:  34  	Training Loss: 0.0006650194991379976
Test Loss:  0.0007650403422303498
Valid Loss:  0.000915347773116082
Epoch:  35  	Training Loss: 0.0006526202196255326
Test Loss:  0.0007639599498361349
Valid Loss:  0.0009100153110921383
Epoch:  36  	Training Loss: 0.0006421396974474192
Test Loss:  0.0007630707696080208
Valid Loss:  0.0009054910624399781
Epoch:  37  	Training Loss: 0.0006328573217615485
Test Loss:  0.0007616442162543535
Valid Loss:  0.0009014425450004637
Epoch:  38  	Training Loss: 0.0006252337479963899
Test Loss:  0.0007602248806506395
Valid Loss:  0.0008981033461168408
Epoch:  39  	Training Loss: 0.0006188624538481236
Test Loss:  0.000758980808313936
Valid Loss:  0.0008950255578383803
Epoch:  40  	Training Loss: 0.0006135845324024558
Test Loss:  0.0007578851073049009
Valid Loss:  0.000892464246135205
Epoch:  41  	Training Loss: 0.000609198585152626
Test Loss:  0.0007569156587123871
Valid Loss:  0.000890347408130765
Epoch:  42  	Training Loss: 0.0006055125268176198
Test Loss:  0.0006615009042434394
Valid Loss:  0.0009259630460292101
Epoch:  43  	Training Loss: 0.0005848860018886626
Test Loss:  0.0006894971011206508
Valid Loss:  0.0008685203501954675
Epoch:  44  	Training Loss: 0.0005748074036091566
Test Loss:  0.0006616623140871525
Valid Loss:  0.0008672848343849182
Epoch:  45  	Training Loss: 0.0005683285417035222
Test Loss:  0.0006668080459348857
Valid Loss:  0.0008446149295195937
Epoch:  46  	Training Loss: 0.0005635470151901245
Test Loss:  0.0006566848605871201
Valid Loss:  0.0008363481028936803
Epoch:  47  	Training Loss: 0.000559826148673892
Test Loss:  0.0006559023750014603
Valid Loss:  0.0008240130264312029
Epoch:  48  	Training Loss: 0.0005567935295403004
Test Loss:  0.0006512182299047709
Valid Loss:  0.0008161775185726583
Epoch:  49  	Training Loss: 0.0005542951403185725
Test Loss:  0.0006494208355434239
Valid Loss:  0.0008081234991550446
Epoch:  50  	Training Loss: 0.0005522140418179333
Test Loss:  0.0006467227940447628
Valid Loss:  0.0008019055239856243
Epoch:  51  	Training Loss: 0.0005504997679963708
Test Loss:  0.0006450514774769545
Valid Loss:  0.000796163163613528
Epoch:  52  	Training Loss: 0.0005490528419613838
Test Loss:  0.0006427708431147039
Valid Loss:  0.000793393817730248
Epoch:  53  	Training Loss: 0.0005456137587316334
Test Loss:  0.0006396268727257848
Valid Loss:  0.0007901265635155141
Epoch:  54  	Training Loss: 0.000541798654012382
Test Loss:  0.0006349650211632252
Valid Loss:  0.0007842311752028763
Epoch:  55  	Training Loss: 0.0005366767873056233
Test Loss:  0.0006294145714491606
Valid Loss:  0.0007768672076053917
Epoch:  56  	Training Loss: 0.0005308515392243862
Test Loss:  0.0006230124272406101
Valid Loss:  0.0007674343069083989
Epoch:  57  	Training Loss: 0.0005242381594143808
Test Loss:  0.0006165378727018833
Valid Loss:  0.0007581335958093405
Epoch:  58  	Training Loss: 0.0005175841506570578
Test Loss:  0.0006110466783866286
Valid Loss:  0.0007507968693971634
Epoch:  59  	Training Loss: 0.0005120966816321015
Test Loss:  0.0006075474666431546
Valid Loss:  0.0007468595867976546
Epoch:  60  	Training Loss: 0.0005083256401121616
Test Loss:  0.0006055684061720967
Valid Loss:  0.0007447118987329304
Epoch:  61  	Training Loss: 0.0005059265531599522
Test Loss:  0.0006040289881639183
Valid Loss:  0.0007433972787111998
Epoch:  62  	Training Loss: 0.0005038834642618895
Test Loss:  0.0006063641048967838
Valid Loss:  0.0007377755828201771
Epoch:  63  	Training Loss: 0.0005019818199798465
Test Loss:  0.000607714056968689
Valid Loss:  0.0007342207827605307
Epoch:  64  	Training Loss: 0.0005003127735108137
Test Loss:  0.0006084092310629785
Valid Loss:  0.0007318544667214155
Epoch:  65  	Training Loss: 0.0004987533902749419
Test Loss:  0.000608689384534955
Valid Loss:  0.0007301898440346122
Epoch:  66  	Training Loss: 0.0004972580354660749
Test Loss:  0.0006087125511839986
Valid Loss:  0.0007289472268894315
Epoch:  67  	Training Loss: 0.000495809072162956
Test Loss:  0.0006085821078158915
Valid Loss:  0.000727961421944201
Epoch:  68  	Training Loss: 0.0004943995736539364
Test Loss:  0.0006083601037971675
Valid Loss:  0.000727136735804379
Epoch:  69  	Training Loss: 0.0004930267459712923
Test Loss:  0.000608083326369524
Valid Loss:  0.0007264126325026155
 14%|█▍        | 71/500 [01:01<08:37,  1.21s/it] 15%|█▍        | 73/500 [01:02<06:10,  1.15it/s] 15%|█▌        | 75/500 [01:02<04:28,  1.58it/s] 15%|█▌        | 77/500 [01:02<03:17,  2.15it/s] 16%|█▌        | 79/500 [01:02<02:28,  2.84it/s] 16%|█▌        | 81/500 [01:09<08:36,  1.23s/it] 17%|█▋        | 83/500 [01:09<06:09,  1.13it/s] 17%|█▋        | 85/500 [01:09<04:25,  1.56it/s] 17%|█▋        | 87/500 [01:09<03:13,  2.14it/s] 18%|█▊        | 89/500 [01:09<02:23,  2.87it/s] 18%|█▊        | 91/500 [01:16<08:18,  1.22s/it] 19%|█▊        | 93/500 [01:16<05:56,  1.14it/s] 19%|█▉        | 95/500 [01:16<04:16,  1.58it/s] 19%|█▉        | 97/500 [01:16<03:07,  2.15it/s] 20%|█▉        | 99/500 [01:16<02:18,  2.89it/s] 20%|██        | 101/500 [01:23<08:06,  1.22s/it] 21%|██        | 103/500 [01:23<05:47,  1.14it/s] 21%|██        | 105/500 [01:23<04:09,  1.58it/s] 21%|██▏       | 107/500 [01:23<03:01,  2.16it/s] 22%|██▏       | 109/500 [01:23<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:30<07:46,  1.20s/it] 23%|██▎       | 113/500 [01:30<05:32,  1.16it/s] 23%|██▎       | 115/500 [01:30<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:30<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:30<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:37<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:37<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:37<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:37<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:37<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:44<07:23,  1.20s/it] 27%|██▋       | 133/500 [01:44<05:17,  1.16it/s] 27%|██▋       | 135/500 [01:44<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:44<02:49,  2.15it/s]Epoch:  70  	Training Loss: 0.0004916882026009262
Test Loss:  0.0006077780853956938
Valid Loss:  0.0007257566321641207
Epoch:  71  	Training Loss: 0.0004903835360892117
Test Loss:  0.0006074581760913134
Valid Loss:  0.0007251460338011384
Epoch:  72  	Training Loss: 0.0004891111748293042
Test Loss:  0.0005831005983054638
Valid Loss:  0.0007269294001162052
Epoch:  73  	Training Loss: 0.00048008450539782643
Test Loss:  0.0005786165711469948
Valid Loss:  0.0007221782580018044
Epoch:  74  	Training Loss: 0.00047269187052734196
Test Loss:  0.0005726697854697704
Valid Loss:  0.0007184797432273626
Epoch:  75  	Training Loss: 0.00046586274402216077
Test Loss:  0.0005672589177265763
Valid Loss:  0.0007148750592023134
Epoch:  76  	Training Loss: 0.00045952649088576436
Test Loss:  0.0005622630123980343
Valid Loss:  0.0007113493047654629
Epoch:  77  	Training Loss: 0.0004535918415058404
Test Loss:  0.0005575679242610931
Valid Loss:  0.0007079374045133591
Epoch:  78  	Training Loss: 0.00044806848745793104
Test Loss:  0.0005531705683097243
Valid Loss:  0.0007046436658129096
Epoch:  79  	Training Loss: 0.00044290826190263033
Test Loss:  0.0005490242619998753
Valid Loss:  0.000701468379702419
Epoch:  80  	Training Loss: 0.0004380812169983983
Test Loss:  0.0005451094475574791
Valid Loss:  0.0006983825005590916
Epoch:  81  	Training Loss: 0.00043356430251151323
Test Loss:  0.0005414073239080608
Valid Loss:  0.0006953811389394104
Epoch:  82  	Training Loss: 0.00042932596988976
Test Loss:  0.0005346913239918649
Valid Loss:  0.0006932571996003389
Epoch:  83  	Training Loss: 0.00042389711597934365
Test Loss:  0.0005311960121616721
Valid Loss:  0.0006895585684105754
Epoch:  84  	Training Loss: 0.00041899800999090075
Test Loss:  0.0005271235713735223
Valid Loss:  0.0006864879978820682
Epoch:  85  	Training Loss: 0.0004145244893152267
Test Loss:  0.0005236528813838959
Valid Loss:  0.0006832889630459249
Epoch:  86  	Training Loss: 0.0004104355175513774
Test Loss:  0.0005202081520110369
Valid Loss:  0.0006803346332162619
Epoch:  87  	Training Loss: 0.0004067029803991318
Test Loss:  0.0005172100500203669
Valid Loss:  0.0006773051572963595
Epoch:  88  	Training Loss: 0.000403250684030354
Test Loss:  0.0005141826695762575
Valid Loss:  0.0006744654383510351
Epoch:  89  	Training Loss: 0.0004000527551397681
Test Loss:  0.0005114084342494607
Valid Loss:  0.000671634916216135
Epoch:  90  	Training Loss: 0.0003970943216700107
Test Loss:  0.0005087823956273496
Valid Loss:  0.0006688436842523515
Epoch:  91  	Training Loss: 0.00039432544144801795
Test Loss:  0.0005062939017079771
Valid Loss:  0.0006661036750301719
Epoch:  92  	Training Loss: 0.0003917427675332874
Test Loss:  0.0005060175317339599
Valid Loss:  0.000662389793433249
Epoch:  93  	Training Loss: 0.00038954318733885884
Test Loss:  0.0005054693901911378
Valid Loss:  0.0006591641576960683
Epoch:  94  	Training Loss: 0.00038757588481530547
Test Loss:  0.0005047031445428729
Valid Loss:  0.000656300107948482
Epoch:  95  	Training Loss: 0.00038577266968786716
Test Loss:  0.0005037693772464991
Valid Loss:  0.0006537064909934998
Epoch:  96  	Training Loss: 0.00038409081753343344
Test Loss:  0.0005027087172493339
Valid Loss:  0.0006513205007649958
Epoch:  97  	Training Loss: 0.00038250931538641453
Test Loss:  0.0005015609785914421
Valid Loss:  0.000649106630589813
Epoch:  98  	Training Loss: 0.00038102277903817594
Test Loss:  0.0005003497935831547
Valid Loss:  0.0006470134248957038
Epoch:  99  	Training Loss: 0.00037960923509672284
Test Loss:  0.0004991033347323537
Valid Loss:  0.0006450263317674398
Epoch:  100  	Training Loss: 0.00037825791514478624
Test Loss:  0.0004978340584784746
Valid Loss:  0.0006431126384995878
Epoch:  101  	Training Loss: 0.00037695636274293065
Test Loss:  0.0004965566331520677
Valid Loss:  0.0006412689108401537
Epoch:  102  	Training Loss: 0.00037571165012195706
Test Loss:  0.0004921861691400409
Valid Loss:  0.0006229934515431523
Epoch:  103  	Training Loss: 0.00036816264037042856
Test Loss:  0.0004888607654720545
Valid Loss:  0.000610512332059443
Epoch:  104  	Training Loss: 0.00036337043275125325
Test Loss:  0.00048647000221535563
Valid Loss:  0.0006014620885252953
Epoch:  105  	Training Loss: 0.0003602927317842841
Test Loss:  0.00048484778380952775
Valid Loss:  0.000594369019381702
Epoch:  106  	Training Loss: 0.0003580870106816292
Test Loss:  0.00048373074969276786
Valid Loss:  0.0005885668797418475
Epoch:  107  	Training Loss: 0.000356390664819628
Test Loss:  0.00048279028851538897
Valid Loss:  0.0005839207442477345
Epoch:  108  	Training Loss: 0.00035507045686244965
Test Loss:  0.00048209435772150755
Valid Loss:  0.0005800396902486682
Epoch:  109  	Training Loss: 0.0003540024335961789
Test Loss:  0.0004814864369109273
Valid Loss:  0.0005768284318037331
Epoch:  110  	Training Loss: 0.00035311677493155
Test Loss:  0.0004809573001693934
Valid Loss:  0.0005741355707868934
Epoch:  111  	Training Loss: 0.0003523613268043846
Test Loss:  0.0004804901545867324
Valid Loss:  0.0005718393949791789
Epoch:  112  	Training Loss: 0.00035169697366654873
Test Loss:  0.00047801039181649685
Valid Loss:  0.0005693983403034508
Epoch:  113  	Training Loss: 0.0003498268488328904
Test Loss:  0.00047625467414036393
Valid Loss:  0.0005667090299539268
Epoch:  114  	Training Loss: 0.0003480318409856409
Test Loss:  0.0004742023884318769
Valid Loss:  0.0005642377072945237
Epoch:  115  	Training Loss: 0.0003463034809101373
Test Loss:  0.00047242926666513085
Valid Loss:  0.000561803113669157
Epoch:  116  	Training Loss: 0.000344644213328138
Test Loss:  0.0004706851323135197
Valid Loss:  0.0005595688708126545
Epoch:  117  	Training Loss: 0.0003430468204896897
Test Loss:  0.0004690221103373915
Valid Loss:  0.00055742880795151
Epoch:  118  	Training Loss: 0.00034150711144320667
Test Loss:  0.0004673682851716876
Valid Loss:  0.0005554406670853496
Epoch:  119  	Training Loss: 0.0003400203422643244
Test Loss:  0.0004657622775994241
Valid Loss:  0.000553492980543524
Epoch:  120  	Training Loss: 0.0003385843592695892
Test Loss:  0.0004641791747417301
Valid Loss:  0.0005515982629731297
Epoch:  121  	Training Loss: 0.0003371968923602253
Test Loss:  0.0004626317822840065
Valid Loss:  0.0005497473757714033
Epoch:  122  	Training Loss: 0.0003358724352438003
Test Loss:  0.000464083714177832
Valid Loss:  0.0005481201224029064
Epoch:  123  	Training Loss: 0.00033573643304407597
Test Loss:  0.00046515214489772916
Valid Loss:  0.0005469825700856745
Epoch:  124  	Training Loss: 0.00033565517514944077
Test Loss:  0.00046592953731305897
Valid Loss:  0.0005461793043650687
Epoch:  125  	Training Loss: 0.00033560278825461864
Test Loss:  0.0004664917942136526
Valid Loss:  0.0005456075305119157
Epoch:  126  	Training Loss: 0.0003355602384544909
Test Loss:  0.00046689409646205604
Valid Loss:  0.0005451958859339356
Epoch:  127  	Training Loss: 0.0003355226945132017
Test Loss:  0.0004671801289077848
Valid Loss:  0.0005448996089398861
Epoch:  128  	Training Loss: 0.0003354893997311592
Test Loss:  0.0004673828952945769
Valid Loss:  0.0005446841241791844
Epoch:  129  	Training Loss: 0.00033545758924447
Test Loss:  0.000467523408588022
Valid Loss:  0.0005445248680189252
Epoch:  130  	Training Loss: 0.0003354220825713128
Test Loss:  0.00046762023703195155
Valid Loss:  0.0005444061825983226
Epoch:  131  	Training Loss: 0.00033537292620167136
Test Loss:  0.00046768574975430965
Valid Loss:  0.000544316484592855
Epoch:  132  	Training Loss: 0.00033531931694597006
Test Loss:  0.00046763784484937787
Valid Loss:  0.0005441412795335054
Epoch:  133  	Training Loss: 0.00033511692890897393
Test Loss:  0.00046757329255342484
Valid Loss:  0.0005439833621494472
Epoch:  134  	Training Loss: 0.00033491977956146
Test Loss:  0.00046749721514061093
Valid Loss:  0.0005438376101665199
Epoch:  135  	Training Loss: 0.0003347268793731928
Test Loss:  0.00046741237747482955
Valid Loss:  0.0005437005893327296
Epoch:  136  	Training Loss: 0.0003345385775901377
Test Loss:  0.00046732270857319236
Valid Loss:  0.0005435716593638062
Epoch:  137  	Training Loss: 0.00033435437944717705
Test Loss:  0.0004672291688621044
Valid Loss:  0.0005434474442154169
 28%|██▊       | 139/500 [01:44<02:07,  2.84it/s] 28%|██▊       | 141/500 [01:51<07:14,  1.21s/it] 29%|██▊       | 143/500 [01:51<05:10,  1.15it/s] 29%|██▉       | 145/500 [01:51<03:43,  1.58it/s] 29%|██▉       | 147/500 [01:51<02:42,  2.17it/s] 30%|██▉       | 149/500 [01:51<02:00,  2.92it/s] 30%|███       | 151/500 [01:58<07:01,  1.21s/it] 31%|███       | 153/500 [01:58<05:00,  1.15it/s] 31%|███       | 155/500 [01:58<03:36,  1.59it/s] 31%|███▏      | 157/500 [01:58<02:38,  2.17it/s] 32%|███▏      | 159/500 [01:58<01:57,  2.91it/s] 32%|███▏      | 161/500 [02:05<06:50,  1.21s/it] 33%|███▎      | 163/500 [02:05<04:52,  1.15it/s] 33%|███▎      | 165/500 [02:05<03:30,  1.59it/s] 33%|███▎      | 167/500 [02:05<02:33,  2.17it/s] 34%|███▍      | 169/500 [02:05<01:53,  2.91it/s] 34%|███▍      | 171/500 [02:12<06:47,  1.24s/it] 35%|███▍      | 173/500 [02:12<04:50,  1.12it/s] 35%|███▌      | 175/500 [02:12<03:28,  1.56it/s] 35%|███▌      | 177/500 [02:12<02:31,  2.13it/s] 36%|███▌      | 179/500 [02:13<01:51,  2.87it/s] 36%|███▌      | 181/500 [02:19<06:23,  1.20s/it] 37%|███▋      | 183/500 [02:19<04:34,  1.16it/s] 37%|███▋      | 185/500 [02:19<03:17,  1.60it/s] 37%|███▋      | 187/500 [02:19<02:23,  2.18it/s] 38%|███▊      | 189/500 [02:20<01:46,  2.92it/s] 38%|███▊      | 191/500 [02:26<06:09,  1.20s/it] 39%|███▊      | 193/500 [02:26<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:26<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:26<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:26<01:42,  2.93it/s] 40%|████      | 201/500 [02:33<06:01,  1.21s/it] 41%|████      | 203/500 [02:33<04:17,  1.15it/s]Epoch:  138  	Training Loss: 0.00033417431404814124
Test Loss:  0.00046713283518329263
Valid Loss:  0.0005433280603028834
Epoch:  139  	Training Loss: 0.00033399806125089526
Test Loss:  0.00046703440602868795
Valid Loss:  0.0005432124016806483
Epoch:  140  	Training Loss: 0.00033382547553628683
Test Loss:  0.0004669346089940518
Valid Loss:  0.0005430995370261371
Epoch:  141  	Training Loss: 0.0003336568479426205
Test Loss:  0.0004668367328122258
Valid Loss:  0.0005429892335087061
Epoch:  142  	Training Loss: 0.0003334925277158618
Test Loss:  0.0004665051237680018
Valid Loss:  0.0005429381271824241
Epoch:  143  	Training Loss: 0.00033337355125695467
Test Loss:  0.0004661741550080478
Valid Loss:  0.0005429682205431163
Epoch:  144  	Training Loss: 0.0003333233471494168
Test Loss:  0.00046585165546275675
Valid Loss:  0.000543024274520576
Epoch:  145  	Training Loss: 0.0003332845226395875
Test Loss:  0.0004655438824556768
Valid Loss:  0.0005430769524537027
Epoch:  146  	Training Loss: 0.000333247531671077
Test Loss:  0.0004652439383789897
Valid Loss:  0.0005431347526609898
Epoch:  147  	Training Loss: 0.0003332134219817817
Test Loss:  0.0004649521433748305
Valid Loss:  0.0005431956378743052
Epoch:  148  	Training Loss: 0.0003331825719214976
Test Loss:  0.00046466803178191185
Valid Loss:  0.0005432601319625974
Epoch:  149  	Training Loss: 0.00033315294422209263
Test Loss:  0.00046439579455181956
Valid Loss:  0.0005433211335912347
Epoch:  150  	Training Loss: 0.00033312581945210695
Test Loss:  0.00046413103700615466
Valid Loss:  0.0005433863261714578
Epoch:  151  	Training Loss: 0.0003330996260046959
Test Loss:  0.0004638773971237242
Valid Loss:  0.0005434490740299225
Epoch:  152  	Training Loss: 0.0003330755571369082
Test Loss:  0.00045729856356047094
Valid Loss:  0.000533896847628057
Epoch:  153  	Training Loss: 0.00032734160777181387
Test Loss:  0.00045008561573922634
Valid Loss:  0.0005239196470938623
Epoch:  154  	Training Loss: 0.00032161641865968704
Test Loss:  0.00044819709728471935
Valid Loss:  0.0005237835575826466
Epoch:  155  	Training Loss: 0.00032083538826555014
Test Loss:  0.0004465879173949361
Valid Loss:  0.0005235786084085703
Epoch:  156  	Training Loss: 0.00032013311283662915
Test Loss:  0.00044519081711769104
Valid Loss:  0.0005234141135588288
Epoch:  157  	Training Loss: 0.0003194987657479942
Test Loss:  0.0004439587937667966
Valid Loss:  0.000523258582688868
Epoch:  158  	Training Loss: 0.0003189209965057671
Test Loss:  0.00044285861076787114
Valid Loss:  0.0005230816313996911
Epoch:  159  	Training Loss: 0.0003183939552400261
Test Loss:  0.00044186494778841734
Valid Loss:  0.0005228876834735274
Epoch:  160  	Training Loss: 0.0003179115301463753
Test Loss:  0.00044095859630033374
Valid Loss:  0.0005226817447692156
Epoch:  161  	Training Loss: 0.000317472469760105
Test Loss:  0.0004401365586090833
Valid Loss:  0.0005224800552241504
Epoch:  162  	Training Loss: 0.00031710328767076135
Test Loss:  0.0004375555436126888
Valid Loss:  0.0005222439067438245
Epoch:  163  	Training Loss: 0.00031672761542722583
Test Loss:  0.00043815778917632997
Valid Loss:  0.0005206457572057843
Epoch:  164  	Training Loss: 0.0003164091322105378
Test Loss:  0.0004378514422569424
Valid Loss:  0.0005195967387408018
Epoch:  165  	Training Loss: 0.00031612004386261106
Test Loss:  0.0004377912846393883
Valid Loss:  0.0005185411428101361
Epoch:  166  	Training Loss: 0.00031585246324539185
Test Loss:  0.00043767422903329134
Valid Loss:  0.0005175997503101826
Epoch:  167  	Training Loss: 0.0003156024031341076
Test Loss:  0.0004375582793727517
Valid Loss:  0.0005167318740859628
Epoch:  168  	Training Loss: 0.00031536666210740805
Test Loss:  0.0004374269919935614
Valid Loss:  0.000515935942530632
Epoch:  169  	Training Loss: 0.00031514227157458663
Test Loss:  0.0004372832481749356
Valid Loss:  0.0005152167286723852
Epoch:  170  	Training Loss: 0.0003149285330437124
Test Loss:  0.00043717792141251266
Valid Loss:  0.00051451864419505
Epoch:  171  	Training Loss: 0.00031472224509343505
Test Loss:  0.00043700227979570627
Valid Loss:  0.0005139062413945794
Epoch:  172  	Training Loss: 0.00031452366965822875
Test Loss:  0.0004368231166154146
Valid Loss:  0.000513634062372148
Epoch:  173  	Training Loss: 0.00031422520987689495
Test Loss:  0.0004365564091131091
Valid Loss:  0.0005134085076861084
Epoch:  174  	Training Loss: 0.00031395163387060165
Test Loss:  0.00043623324017971754
Valid Loss:  0.000513214326929301
Epoch:  175  	Training Loss: 0.00031369918724521995
Test Loss:  0.0004358775622677058
Valid Loss:  0.0005130410427227616
Epoch:  176  	Training Loss: 0.00031346530886366963
Test Loss:  0.0004355046839918941
Valid Loss:  0.0005128835327923298
Epoch:  177  	Training Loss: 0.0003132469137199223
Test Loss:  0.0004351240932010114
Valid Loss:  0.0005127371987327933
Epoch:  178  	Training Loss: 0.000313043303322047
Test Loss:  0.0004347440553829074
Valid Loss:  0.0005125962197780609
Epoch:  179  	Training Loss: 0.0003128527314402163
Test Loss:  0.00043436966370791197
Valid Loss:  0.0005124603630974889
Epoch:  180  	Training Loss: 0.00031267438316717744
Test Loss:  0.00043400569120422006
Valid Loss:  0.0005123262526467443
Epoch:  181  	Training Loss: 0.00031250674510374665
Test Loss:  0.0004336531856097281
Valid Loss:  0.0005121928988955915
Epoch:  182  	Training Loss: 0.000312349118757993
Test Loss:  0.0004347817157395184
Valid Loss:  0.0005110157653689384
Epoch:  183  	Training Loss: 0.0003122336638625711
Test Loss:  0.00043551751878112555
Valid Loss:  0.0005102130235172808
Epoch:  184  	Training Loss: 0.00031215068884193897
Test Loss:  0.0004359837912488729
Valid Loss:  0.0005096479435451329
Epoch:  185  	Training Loss: 0.0003120829933322966
Test Loss:  0.00043626694241538644
Valid Loss:  0.000509237521328032
Epoch:  186  	Training Loss: 0.00031202196259982884
Test Loss:  0.0004364263731986284
Valid Loss:  0.0005089251790195704
Epoch:  187  	Training Loss: 0.0003119641332887113
Test Loss:  0.0004365044296719134
Valid Loss:  0.0005086803575977683
Epoch:  188  	Training Loss: 0.0003119079628959298
Test Loss:  0.0004365273634903133
Valid Loss:  0.000508478085976094
Epoch:  189  	Training Loss: 0.00031185324769467115
Test Loss:  0.0004365143831819296
Valid Loss:  0.0005083052674308419
Epoch:  190  	Training Loss: 0.0003117993474006653
Test Loss:  0.00043647835263982415
Valid Loss:  0.0005081504350528121
Epoch:  191  	Training Loss: 0.0003117461455985904
Test Loss:  0.0004364250344224274
Valid Loss:  0.0005080098635517061
Epoch:  192  	Training Loss: 0.00031169340945780277
Test Loss:  0.0004317066341172904
Valid Loss:  0.0005094536463730037
Epoch:  193  	Training Loss: 0.00031153313466347754
Test Loss:  0.00043179161730222404
Valid Loss:  0.0005094184307381511
Epoch:  194  	Training Loss: 0.0003115313593298197
Test Loss:  0.00043178244959563017
Valid Loss:  0.00050941645167768
Epoch:  195  	Training Loss: 0.0003115292638540268
Test Loss:  0.00043177572661079466
Valid Loss:  0.0005094122607260942
Epoch:  196  	Training Loss: 0.0003115272556897253
Test Loss:  0.00043176577310077846
Valid Loss:  0.0005094107473269105
Epoch:  197  	Training Loss: 0.00031152524752542377
Test Loss:  0.0004317558486945927
Valid Loss:  0.0005094073130749166
Epoch:  198  	Training Loss: 0.0003115230065304786
Test Loss:  0.0004317458369769156
Valid Loss:  0.0005094057996757329
Epoch:  199  	Training Loss: 0.0003115205327048898
Test Loss:  0.00043173646554350853
Valid Loss:  0.0005094027146697044
Epoch:  200  	Training Loss: 0.0003115179424639791
Test Loss:  0.0004317228449508548
Valid Loss:  0.0005094002699479461
Epoch:  201  	Training Loss: 0.00031151482835412025
Test Loss:  0.0004317070124670863
Valid Loss:  0.0005093995714560151
Epoch:  202  	Training Loss: 0.00031151174334809184
Test Loss:  0.00042737816693261266
Valid Loss:  0.0005060739349573851
Epoch:  203  	Training Loss: 0.00030870537739247084
Test Loss:  0.0004261924768798053
Valid Loss:  0.000503340270370245
Epoch:  204  	Training Loss: 0.0003077410801779479
Test Loss:  0.0004266660544089973
Valid Loss:  0.0005016222130507231
Epoch:  205  	Training Loss: 0.0003074782434850931
Test Loss:  0.00042698998004198074
Valid Loss:   41%|████      | 205/500 [02:33<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:33<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:33<01:39,  2.93it/s] 42%|████▏     | 211/500 [02:40<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:40<04:09,  1.15it/s] 43%|████▎     | 215/500 [02:40<02:59,  1.59it/s] 43%|████▎     | 217/500 [02:40<02:11,  2.15it/s] 44%|████▍     | 219/500 [02:41<01:38,  2.85it/s] 44%|████▍     | 221/500 [02:47<05:33,  1.20s/it] 45%|████▍     | 223/500 [02:47<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:47<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:47<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:47<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:54<05:26,  1.21s/it] 47%|████▋     | 233/500 [02:54<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:54<02:46,  1.59it/s] 47%|████▋     | 237/500 [02:54<02:01,  2.17it/s] 48%|████▊     | 239/500 [02:55<01:29,  2.91it/s] 48%|████▊     | 241/500 [03:01<05:08,  1.19s/it] 49%|████▊     | 243/500 [03:01<03:40,  1.17it/s] 49%|████▉     | 245/500 [03:01<02:38,  1.61it/s] 49%|████▉     | 247/500 [03:01<01:55,  2.20it/s] 50%|████▉     | 249/500 [03:01<01:24,  2.96it/s] 50%|█████     | 251/500 [03:08<05:02,  1.21s/it] 51%|█████     | 253/500 [03:08<03:36,  1.14it/s] 51%|█████     | 255/500 [03:08<02:36,  1.56it/s] 51%|█████▏    | 257/500 [03:08<01:53,  2.14it/s] 52%|█████▏    | 259/500 [03:09<01:23,  2.88it/s] 52%|█████▏    | 261/500 [03:15<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:15<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:15<02:26,  1.60it/s] 53%|█████▎    | 267/500 [03:15<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:15<01:19,  2.92it/s] 54%|█████▍    | 271/500 [03:22<04:36,  1.21s/it]0.000500763300806284
Epoch:  206  	Training Loss: 0.00030730749131180346
Test Loss:  0.00042701809434220195
Valid Loss:  0.0005003281403332949
Epoch:  207  	Training Loss: 0.000307148729916662
Test Loss:  0.0004270475765224546
Valid Loss:  0.0004999807570129633
Epoch:  208  	Training Loss: 0.00030702631920576096
Test Loss:  0.00042710977140814066
Valid Loss:  0.0004996914649382234
Epoch:  209  	Training Loss: 0.0003069355443585664
Test Loss:  0.0004271113430149853
Valid Loss:  0.000499512767419219
Epoch:  210  	Training Loss: 0.0003068546939175576
Test Loss:  0.00042719862540252507
Valid Loss:  0.0004993313341401517
Epoch:  211  	Training Loss: 0.0003067907236982137
Test Loss:  0.00042723739170469344
Valid Loss:  0.0004991990863345563
Epoch:  212  	Training Loss: 0.00030672841239720583
Test Loss:  0.0004174914211034775
Valid Loss:  0.000501731934491545
Epoch:  213  	Training Loss: 0.00030595611315220594
Test Loss:  0.0004256213433109224
Valid Loss:  0.000497367000207305
Epoch:  214  	Training Loss: 0.00030522129964083433
Test Loss:  0.0004136479110457003
Valid Loss:  0.0005008855368942022
Epoch:  215  	Training Loss: 0.00030452810460701585
Test Loss:  0.00042461580596864223
Valid Loss:  0.0004953692550770938
Epoch:  216  	Training Loss: 0.00030387516017071903
Test Loss:  0.0004097186028957367
Valid Loss:  0.0005001819226890802
Epoch:  217  	Training Loss: 0.00030326424166560173
Test Loss:  0.0004243033763486892
Valid Loss:  0.000493217317853123
Epoch:  218  	Training Loss: 0.00030270073330029845
Test Loss:  0.0004056026809848845
Valid Loss:  0.0004997368669137359
Epoch:  219  	Training Loss: 0.0003021951124537736
Test Loss:  0.00042485870653763413
Valid Loss:  0.0004909505951218307
Epoch:  220  	Training Loss: 0.0003017537819687277
Test Loss:  0.0004012298886664212
Valid Loss:  0.0004996996140107512
Epoch:  221  	Training Loss: 0.0003013924870174378
Test Loss:  0.00042649032548069954
Valid Loss:  0.0004886010428890586
Epoch:  222  	Training Loss: 0.0003011269436683506
Test Loss:  0.00041615046211518347
Valid Loss:  0.0004926662659272552
Epoch:  223  	Training Loss: 0.00030007108580321074
Test Loss:  0.0004149322921875864
Valid Loss:  0.0004921437939628959
Epoch:  224  	Training Loss: 0.000299787730909884
Test Loss:  0.0004145661951042712
Valid Loss:  0.0004912285367026925
Epoch:  225  	Training Loss: 0.00029955102945677936
Test Loss:  0.00041416665771976113
Valid Loss:  0.0004904254456050694
Epoch:  226  	Training Loss: 0.00029933557379990816
Test Loss:  0.0004137830401305109
Valid Loss:  0.0004896901664324105
Epoch:  227  	Training Loss: 0.00029914366314187646
Test Loss:  0.00041354625136591494
Valid Loss:  0.0004889733390882611
Epoch:  228  	Training Loss: 0.00029897570493631065
Test Loss:  0.00041327046346850693
Valid Loss:  0.0004883494111709297
Epoch:  229  	Training Loss: 0.0002988253254443407
Test Loss:  0.0004130622837692499
Valid Loss:  0.00048776291077956557
Epoch:  230  	Training Loss: 0.000298692611977458
Test Loss:  0.000412868510466069
Valid Loss:  0.0004872362478636205
Epoch:  231  	Training Loss: 0.0002985711907967925
Test Loss:  0.00041268131462857127
Valid Loss:  0.0004867541720159352
Epoch:  232  	Training Loss: 0.0002984569000545889
Test Loss:  0.0004045842797495425
Valid Loss:  0.000471571838716045
Epoch:  233  	Training Loss: 0.0002865661808755249
Test Loss:  0.00038467947160825133
Valid Loss:  0.00047054991591721773
Epoch:  234  	Training Loss: 0.0002794280298985541
Test Loss:  0.00037465154309757054
Valid Loss:  0.00046527848462574184
Epoch:  235  	Training Loss: 0.0002738326438702643
Test Loss:  0.0003650218131951988
Valid Loss:  0.0004614527861122042
Epoch:  236  	Training Loss: 0.0002689919201657176
Test Loss:  0.0003579425101634115
Valid Loss:  0.0004569480661302805
Epoch:  237  	Training Loss: 0.00026460501248948276
Test Loss:  0.00035176367964595556
Valid Loss:  0.0004525647673290223
Epoch:  238  	Training Loss: 0.00026061979588121176
Test Loss:  0.0003462971653789282
Valid Loss:  0.00044822203926742077
Epoch:  239  	Training Loss: 0.0002569206990301609
Test Loss:  0.0003412443329580128
Valid Loss:  0.0004438062314875424
Epoch:  240  	Training Loss: 0.00025346368784084916
Test Loss:  0.00033637171145528555
Valid Loss:  0.00043967878445982933
Epoch:  241  	Training Loss: 0.00025022204499691725
Test Loss:  0.0003319550596643239
Valid Loss:  0.00043537491001188755
Epoch:  242  	Training Loss: 0.00024706253316253424
Test Loss:  0.00033299936330877244
Valid Loss:  0.00043201353400945663
Epoch:  243  	Training Loss: 0.00024630100233480334
Test Loss:  0.0003339520771987736
Valid Loss:  0.00043045193888247013
Epoch:  244  	Training Loss: 0.00024604357895441353
Test Loss:  0.00033473630901426077
Valid Loss:  0.0004294153186492622
Epoch:  245  	Training Loss: 0.0002458777744323015
Test Loss:  0.0003354094224050641
Valid Loss:  0.0004286124312784523
Epoch:  246  	Training Loss: 0.0002457526861689985
Test Loss:  0.0003360011032782495
Valid Loss:  0.0004279467975720763
Epoch:  247  	Training Loss: 0.00024565047351643443
Test Loss:  0.000336526136379689
Valid Loss:  0.000427386665251106
Epoch:  248  	Training Loss: 0.0002455658104736358
Test Loss:  0.000336986209731549
Valid Loss:  0.0004269064811524004
Epoch:  249  	Training Loss: 0.000245495728449896
Test Loss:  0.00033738723141141236
Valid Loss:  0.0004265005700290203
Epoch:  250  	Training Loss: 0.0002454354544170201
Test Loss:  0.00033772888127714396
Valid Loss:  0.00042616284918040037
Epoch:  251  	Training Loss: 0.00024538332945667207
Test Loss:  0.0003380260895937681
Valid Loss:  0.00042587274219840765
Epoch:  252  	Training Loss: 0.00024533673422411084
Test Loss:  0.00032877252670004964
Valid Loss:  0.0004270616336725652
Epoch:  253  	Training Loss: 0.0002425475395284593
Test Loss:  0.00032458052737638354
Valid Loss:  0.0004275995306670666
Epoch:  254  	Training Loss: 0.00024150119861587882
Test Loss:  0.00032255559926852584
Valid Loss:  0.00042746038525365293
Epoch:  255  	Training Loss: 0.00024092354578897357
Test Loss:  0.0003215362667106092
Valid Loss:  0.00042691364069469273
Epoch:  256  	Training Loss: 0.0002404875704087317
Test Loss:  0.0003210072172805667
Valid Loss:  0.0004261657304596156
Epoch:  257  	Training Loss: 0.00024010776542127132
Test Loss:  0.0003207271220162511
Valid Loss:  0.0004253352526575327
Epoch:  258  	Training Loss: 0.00023976119700819254
Test Loss:  0.0003205779939889908
Valid Loss:  0.0004244864685460925
Epoch:  259  	Training Loss: 0.00023944099666550756
Test Loss:  0.0003204988606739789
Valid Loss:  0.0004236504319123924
Epoch:  260  	Training Loss: 0.00023914308985695243
Test Loss:  0.00032045942498371005
Valid Loss:  0.00042284157825633883
Epoch:  261  	Training Loss: 0.00023886673443485051
Test Loss:  0.0003204447275493294
Valid Loss:  0.00042206532089039683
Epoch:  262  	Training Loss: 0.0002386093110544607
Test Loss:  0.00032043742248788476
Valid Loss:  0.00042166124330833554
Epoch:  263  	Training Loss: 0.00023848051205277443
Test Loss:  0.0003204315435141325
Valid Loss:  0.0004212681669741869
Epoch:  264  	Training Loss: 0.000238356355112046
Test Loss:  0.00032042741077020764
Valid Loss:  0.0004208842874504626
Epoch:  265  	Training Loss: 0.00023823622905183583
Test Loss:  0.0003204241511411965
Valid Loss:  0.00042051158379763365
Epoch:  266  	Training Loss: 0.00023811994469724596
Test Loss:  0.0003204215026926249
Valid Loss:  0.0004201461561024189
Epoch:  267  	Training Loss: 0.00023800812778063118
Test Loss:  0.00032042013481259346
Valid Loss:  0.00041979041998274624
Epoch:  268  	Training Loss: 0.00023789933766238391
Test Loss:  0.00032042007660493255
Valid Loss:  0.00041944364784285426
Epoch:  269  	Training Loss: 0.00023779491311870515
Test Loss:  0.0003204192908015102
Valid Loss:  0.0004191057523712516
Epoch:  270  	Training Loss: 0.0002376933698542416
Test Loss:  0.00032041952363215387
Valid Loss:  0.0004187756567262113
Epoch:  271  	Training Loss: 0.00023759463510941714
Test Loss:  0.0003204207168892026
Valid Loss:  0.00041845356463454664
Epoch:  272  	Training Loss: 0.00023750000400468707
Test Loss:  0.0003176629252266139
Valid Loss:  0.0004124593688175082
Epoch:  273  	Training Loss: 0.00023348911781795323
 55%|█████▍    | 273/500 [03:22<03:17,  1.15it/s] 55%|█████▌    | 275/500 [03:22<02:21,  1.59it/s] 55%|█████▌    | 277/500 [03:22<01:42,  2.18it/s] 56%|█████▌    | 279/500 [03:23<01:15,  2.93it/s] 56%|█████▌    | 281/500 [03:29<04:26,  1.22s/it] 57%|█████▋    | 283/500 [03:29<03:09,  1.15it/s] 57%|█████▋    | 285/500 [03:29<02:15,  1.59it/s] 57%|█████▋    | 287/500 [03:29<01:38,  2.17it/s] 58%|█████▊    | 289/500 [03:30<01:12,  2.92it/s] 58%|█████▊    | 291/500 [03:36<04:13,  1.21s/it] 59%|█████▊    | 293/500 [03:36<03:00,  1.15it/s] 59%|█████▉    | 295/500 [03:36<02:08,  1.59it/s] 59%|█████▉    | 297/500 [03:36<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:37<01:09,  2.89it/s] 60%|██████    | 301/500 [03:43<04:02,  1.22s/it] 61%|██████    | 303/500 [03:43<02:52,  1.14it/s] 61%|██████    | 305/500 [03:43<02:03,  1.58it/s] 61%|██████▏   | 307/500 [03:44<01:29,  2.15it/s] 62%|██████▏   | 309/500 [03:44<01:06,  2.89it/s] 62%|██████▏   | 311/500 [03:50<03:49,  1.21s/it] 63%|██████▎   | 313/500 [03:50<02:43,  1.15it/s] 63%|██████▎   | 315/500 [03:50<01:56,  1.58it/s] 63%|██████▎   | 317/500 [03:51<01:24,  2.17it/s] 64%|██████▍   | 319/500 [03:51<01:02,  2.92it/s] 64%|██████▍   | 321/500 [04:03<06:23,  2.14s/it] 65%|██████▍   | 323/500 [04:04<04:29,  1.53s/it] 65%|██████▌   | 325/500 [04:04<03:10,  1.09s/it] 65%|██████▌   | 327/500 [04:04<02:15,  1.28it/s] 66%|██████▌   | 329/500 [04:04<01:37,  1.76it/s] 66%|██████▌   | 331/500 [04:10<03:50,  1.36s/it] 67%|██████▋   | 333/500 [04:11<02:43,  1.02it/s] 67%|██████▋   | 335/500 [04:11<01:56,  1.41it/s] 67%|██████▋   | 337/500 [04:11<01:24,  1.94it/s] 68%|██████▊   | 339/500 [04:11<01:02,  2.59it/s]Test Loss:  0.00030747809796594083
Valid Loss:  0.00041325727943331003
Epoch:  274  	Training Loss: 0.00023076581419445574
Test Loss:  0.0003034832770936191
Valid Loss:  0.00041123933624476194
Epoch:  275  	Training Loss: 0.0002287237875862047
Test Loss:  0.00029839202761650085
Valid Loss:  0.0004109336878173053
Epoch:  276  	Training Loss: 0.0002270918048452586
Test Loss:  0.00029515859205275774
Valid Loss:  0.0004098190111108124
Epoch:  277  	Training Loss: 0.00022571886074729264
Test Loss:  0.00029201459256000817
Valid Loss:  0.00040906452341005206
Epoch:  278  	Training Loss: 0.00022449201787821949
Test Loss:  0.00028954155277460814
Valid Loss:  0.000408001767937094
Epoch:  279  	Training Loss: 0.00022335705580189824
Test Loss:  0.0002871918259188533
Valid Loss:  0.0004070591530762613
Epoch:  280  	Training Loss: 0.00022229526075534523
Test Loss:  0.00028518057661131024
Valid Loss:  0.0004059024795424193
Epoch:  281  	Training Loss: 0.0002212578838225454
Test Loss:  0.0002831969177350402
Valid Loss:  0.0004048482805956155
Epoch:  282  	Training Loss: 0.00022026685473974794
Test Loss:  0.0002839805092662573
Valid Loss:  0.0004008996766060591
Epoch:  283  	Training Loss: 0.0002189481456298381
Test Loss:  0.0002845722483471036
Valid Loss:  0.000397786614485085
Epoch:  284  	Training Loss: 0.00021789489255752414
Test Loss:  0.00028498348547145724
Valid Loss:  0.00039525728789158165
Epoch:  285  	Training Loss: 0.00021701351215597242
Test Loss:  0.00028524009394459426
Valid Loss:  0.0003931475803256035
Epoch:  286  	Training Loss: 0.0002162522287108004
Test Loss:  0.00028537563048303127
Valid Loss:  0.000391347159165889
Epoch:  287  	Training Loss: 0.0002155831753043458
Test Loss:  0.00028541887877509
Valid Loss:  0.00038978218799456954
Epoch:  288  	Training Loss: 0.00021498423302546144
Test Loss:  0.0002853925107046962
Valid Loss:  0.0003883989411406219
Epoch:  289  	Training Loss: 0.0002144429017789662
Test Loss:  0.0002853179757948965
Valid Loss:  0.00038716086419299245
Epoch:  290  	Training Loss: 0.0002139498683391139
Test Loss:  0.00028520950581878424
Valid Loss:  0.0003860394936054945
Epoch:  291  	Training Loss: 0.00021349887538235635
Test Loss:  0.00028507874230854213
Valid Loss:  0.0003850149514619261
Epoch:  292  	Training Loss: 0.00021308535360731184
Test Loss:  0.00027695068274624646
Valid Loss:  0.00038496730849146843
Epoch:  293  	Training Loss: 0.0002113552764058113
Test Loss:  0.0002792092855088413
Valid Loss:  0.00038005621172487736
Epoch:  294  	Training Loss: 0.00020992913050577044
Test Loss:  0.0002759777707979083
Valid Loss:  0.000378206605091691
Epoch:  295  	Training Loss: 0.00020863738609477878
Test Loss:  0.00027556874556466937
Valid Loss:  0.0003752291959244758
Epoch:  296  	Training Loss: 0.00020741290063597262
Test Loss:  0.0002735850866883993
Valid Loss:  0.00037313217762857676
Epoch:  297  	Training Loss: 0.00020625210891012102
Test Loss:  0.0002725117083173245
Valid Loss:  0.0003709074226208031
Epoch:  298  	Training Loss: 0.00020525255240499973
Test Loss:  0.0002711465931497514
Valid Loss:  0.0003691136953420937
Epoch:  299  	Training Loss: 0.00020444189431145787
Test Loss:  0.0002702420169953257
Valid Loss:  0.00036742701195180416
Epoch:  300  	Training Loss: 0.00020381782087497413
Test Loss:  0.0002694029244594276
Valid Loss:  0.0003659771173261106
Epoch:  301  	Training Loss: 0.00020330518600530922
Test Loss:  0.00026880254154093564
Valid Loss:  0.00036465784069150686
Epoch:  302  	Training Loss: 0.00020290908287279308
Test Loss:  0.0002694711438380182
Valid Loss:  0.0003637197660282254
Epoch:  303  	Training Loss: 0.0002027577575063333
Test Loss:  0.00026973430067300797
Valid Loss:  0.00036305977846495807
Epoch:  304  	Training Loss: 0.0002026406000368297
Test Loss:  0.0002698356402106583
Valid Loss:  0.0003625345416367054
Epoch:  305  	Training Loss: 0.00020254291302990168
Test Loss:  0.00026987638557329774
Valid Loss:  0.0003620864590629935
Epoch:  306  	Training Loss: 0.00020246040367055684
Test Loss:  0.0002698952448554337
Valid Loss:  0.0003616924805101007
Epoch:  307  	Training Loss: 0.0002023903070949018
Test Loss:  0.00026990647893399
Valid Loss:  0.00036133898538537323
Epoch:  308  	Training Loss: 0.0002023304987233132
Test Loss:  0.0002699165197554976
Valid Loss:  0.0003610214916989207
Epoch:  309  	Training Loss: 0.00020227977074682713
Test Loss:  0.00026992580387741327
Valid Loss:  0.0003607335384003818
Epoch:  310  	Training Loss: 0.00020223627507220954
Test Loss:  0.0002699356118682772
Valid Loss:  0.0003604732337407768
Epoch:  311  	Training Loss: 0.00020219909492880106
Test Loss:  0.0002699459146242589
Valid Loss:  0.0003602368524298072
Epoch:  312  	Training Loss: 0.00020216722623445094
Test Loss:  0.000266823306446895
Valid Loss:  0.00036041479324921966
Epoch:  313  	Training Loss: 0.00020197220146656036
Test Loss:  0.00027260283241048455
Valid Loss:  0.0003585387021303177
Epoch:  314  	Training Loss: 0.0002019376988755539
Test Loss:  0.0002591980737634003
Valid Loss:  0.00036272165016271174
Epoch:  315  	Training Loss: 0.00020276516443118453
Test Loss:  0.00029673121753148735
Valid Loss:  0.00035880180075764656
Epoch:  316  	Training Loss: 0.00020823633531108499
Test Loss:  0.0002496023662388325
Valid Loss:  0.0004056286416016519
Epoch:  317  	Training Loss: 0.00023876759223639965
Test Loss:  0.000577760161831975
Valid Loss:  0.000504661351442337
Epoch:  318  	Training Loss: 0.00040258484659716487
Test Loss:  0.0009570783004164696
Valid Loss:  0.0013010370312258601
Epoch:  319  	Training Loss: 0.0011444921838119626
Test Loss:  0.0035904264077544212
Valid Loss:  0.0029253847897052765
Epoch:  320  	Training Loss: 0.0031364834867417812
Test Loss:  0.007794653996825218
Valid Loss:  0.008714806288480759
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.008083939552307129
Test Loss:  0.003917854279279709
Valid Loss:  0.004610546864569187
Epoch:  322  	Training Loss: 0.0042048245668411255
Test Loss:  0.003299427917227149
Valid Loss:  0.0039319503121078014
Epoch:  323  	Training Loss: 0.003646057564765215
Test Loss:  0.0027693198062479496
Valid Loss:  0.0033439351245760918
Epoch:  324  	Training Loss: 0.003154964651912451
Test Loss:  0.002326779533177614
Valid Loss:  0.002849085722118616
Epoch:  325  	Training Loss: 0.0027327437419444323
Test Loss:  0.00196341285482049
Valid Loss:  0.002441063057631254
Epoch:  326  	Training Loss: 0.002376742195338011
Test Loss:  0.0016649025492370129
Valid Loss:  0.0021049396600574255
Epoch:  327  	Training Loss: 0.002075453754514456
Test Loss:  0.0014191847294569016
Valid Loss:  0.0018281438387930393
Epoch:  328  	Training Loss: 0.001821510260924697
Test Loss:  0.0012178895995020866
Valid Loss:  0.0015976324211806059
Epoch:  329  	Training Loss: 0.0016087191179394722
Test Loss:  0.0010527489939704537
Valid Loss:  0.001404857961460948
Epoch:  330  	Training Loss: 0.0014290360268205404
Test Loss:  0.0009166341042146087
Valid Loss:  0.0012435773387551308
Epoch:  331  	Training Loss: 0.0012748814187943935
Test Loss:  0.0008050308097153902
Valid Loss:  0.0011069257743656635
Epoch:  332  	Training Loss: 0.001140739070251584
Test Loss:  0.0005187847418710589
Valid Loss:  0.0007721463916823268
Epoch:  333  	Training Loss: 0.0008211652748286724
Test Loss:  0.0003792265197262168
Valid Loss:  0.0005960084963589907
Epoch:  334  	Training Loss: 0.0006481340387836099
Test Loss:  0.000310757226543501
Valid Loss:  0.0005096318200230598
Epoch:  335  	Training Loss: 0.0005497250240296125
Test Loss:  0.000282714085187763
Valid Loss:  0.0004703277663793415
Epoch:  336  	Training Loss: 0.0004997233627364039
Test Loss:  0.0002721800119616091
Valid Loss:  0.0004530987935140729
Epoch:  337  	Training Loss: 0.0004747983766719699
Test Loss:  0.00026921083917841315
Valid Loss:  0.0004460810450837016
Epoch:  338  	Training Loss: 0.0004612717020791024
Test Loss:  0.0002694091817829758
Valid Loss:  0.0004441498313099146
Epoch:  339  	Training Loss: 0.00045376570778898895
Test Loss:  0.00027068285271525383
Valid Loss:  0.0004447574319783598
 68%|██████▊   | 341/500 [04:18<03:18,  1.25s/it] 69%|██████▊   | 343/500 [04:18<02:20,  1.12it/s] 69%|██████▉   | 345/500 [04:18<01:40,  1.53it/s] 69%|██████▉   | 347/500 [04:18<01:13,  2.09it/s] 70%|██████▉   | 349/500 [04:18<00:53,  2.81it/s] 70%|███████   | 351/500 [04:24<02:57,  1.19s/it] 71%|███████   | 353/500 [04:25<02:05,  1.17it/s] 71%|███████   | 355/500 [04:25<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:25<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:25<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:31<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:32<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:32<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:32<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:32<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:38<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:38<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:38<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:39<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:39<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:45<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:45<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:45<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:45<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:46<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:52<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:52<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:52<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:52<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:52<00:33,  2.98it/s] 80%|████████  | 401/500 [04:59<01:57,  1.19s/it] 81%|████████  | 403/500 [04:59<01:22,  1.17it/s] 81%|████████  | 405/500 [04:59<00:59,  1.61it/s]Epoch:  340  	Training Loss: 0.0004498148337006569
Test Loss:  0.00027207989478483796
Valid Loss:  0.00044574850471690297
Epoch:  341  	Training Loss: 0.0004475275054574013
Test Loss:  0.0002732856082729995
Valid Loss:  0.0004467091930564493
Epoch:  342  	Training Loss: 0.0004460921336431056
Test Loss:  0.0002705628867261112
Valid Loss:  0.00043299124808982015
Epoch:  343  	Training Loss: 0.0004226260934956372
Test Loss:  0.00026803475338965654
Valid Loss:  0.00042094942182302475
Epoch:  344  	Training Loss: 0.0004023718647658825
Test Loss:  0.00026537064695730805
Valid Loss:  0.00040998414624482393
Epoch:  345  	Training Loss: 0.0003844618913717568
Test Loss:  0.0002624542103148997
Valid Loss:  0.0003997670719400048
Epoch:  346  	Training Loss: 0.0003683537361212075
Test Loss:  0.0002592860837467015
Valid Loss:  0.0003901342279277742
Epoch:  347  	Training Loss: 0.00035369000397622585
Test Loss:  0.00025590555742383003
Valid Loss:  0.0003809957706835121
Epoch:  348  	Training Loss: 0.00034021935425698757
Test Loss:  0.0002524010487832129
Valid Loss:  0.0003725803690031171
Epoch:  349  	Training Loss: 0.00032781940535642207
Test Loss:  0.0002491319610271603
Valid Loss:  0.00036559230647981167
Epoch:  350  	Training Loss: 0.00031709630275145173
Test Loss:  0.0002458931412547827
Valid Loss:  0.0003592774155549705
Epoch:  351  	Training Loss: 0.00030758598586544394
Test Loss:  0.00024272986047435552
Valid Loss:  0.0003528931993059814
Epoch:  352  	Training Loss: 0.0002984866441693157
Test Loss:  0.00025743324658833444
Valid Loss:  0.00034246803261339664
Epoch:  353  	Training Loss: 0.0002729895059019327
Test Loss:  0.00026530667673796415
Valid Loss:  0.00033528037602081895
Epoch:  354  	Training Loss: 0.00025892103440128267
Test Loss:  0.0002677075390238315
Valid Loss:  0.0003284970880486071
Epoch:  355  	Training Loss: 0.0002487172023393214
Test Loss:  0.00026684481417760253
Valid Loss:  0.00032156603992916644
Epoch:  356  	Training Loss: 0.00024020174168981612
Test Loss:  0.0002639638842083514
Valid Loss:  0.0003144613583572209
Epoch:  357  	Training Loss: 0.00023247940407600254
Test Loss:  0.00026009269640780985
Valid Loss:  0.00030765909468755126
Epoch:  358  	Training Loss: 0.0002250542602268979
Test Loss:  0.00025532106519676745
Valid Loss:  0.0003011068911291659
Epoch:  359  	Training Loss: 0.00021813035709783435
Test Loss:  0.00024941383162513375
Valid Loss:  0.00029479534714482725
Epoch:  360  	Training Loss: 0.00021174644643906504
Test Loss:  0.00024335012130904943
Valid Loss:  0.0002887339796870947
Epoch:  361  	Training Loss: 0.00020536317606456578
Test Loss:  0.0002374250761931762
Valid Loss:  0.00028285745065659285
Epoch:  362  	Training Loss: 0.00019908780814148486
Test Loss:  0.00022480906045529991
Valid Loss:  0.00026205304311588407
Epoch:  363  	Training Loss: 0.00017694817506708205
Test Loss:  0.0002110081841237843
Valid Loss:  0.0002478074748069048
Epoch:  364  	Training Loss: 0.0001627238525543362
Test Loss:  0.00019780878210440278
Valid Loss:  0.00023677051649428904
Epoch:  365  	Training Loss: 0.00015181631897576153
Test Loss:  0.00018628741963766515
Valid Loss:  0.00022802466992288828
Epoch:  366  	Training Loss: 0.00014310498954728246
Test Loss:  0.00017629211652092636
Valid Loss:  0.00022086198441684246
Epoch:  367  	Training Loss: 0.00013589089212473482
Test Loss:  0.00016782803868409246
Valid Loss:  0.00021516808192245662
Epoch:  368  	Training Loss: 0.00013014381693210453
Test Loss:  0.00016086646064650267
Valid Loss:  0.00021069019567221403
Epoch:  369  	Training Loss: 0.00012556847650557756
Test Loss:  0.0001551656168885529
Valid Loss:  0.0002070754999294877
Epoch:  370  	Training Loss: 0.00012192498979857191
Test Loss:  0.00015043173334561288
Valid Loss:  0.00020414788741618395
Epoch:  371  	Training Loss: 0.00011900331446668133
Test Loss:  0.00014643504982814193
Valid Loss:  0.0002018227824009955
Epoch:  372  	Training Loss: 0.00011668544175336137
Test Loss:  0.0001426933886250481
Valid Loss:  0.00020072291954420507
Epoch:  373  	Training Loss: 0.00011530729534570128
Test Loss:  0.00014012267638463527
Valid Loss:  0.00019981885270681232
Epoch:  374  	Training Loss: 0.00011435302440077066
Test Loss:  0.0001382379705319181
Valid Loss:  0.00019896756566595286
Epoch:  375  	Training Loss: 0.0001136187493102625
Test Loss:  0.00013691623462364078
Valid Loss:  0.00019816533313132823
Epoch:  376  	Training Loss: 0.00011305783118586987
Test Loss:  0.00013582258543465286
Valid Loss:  0.00019741838332265615
Epoch:  377  	Training Loss: 0.00011254736455157399
Test Loss:  0.0001348866062471643
Valid Loss:  0.00019667259766720235
Epoch:  378  	Training Loss: 0.00011207121860934421
Test Loss:  0.00013409869279712439
Valid Loss:  0.0001959825458470732
Epoch:  379  	Training Loss: 0.00011164227908011526
Test Loss:  0.0001334242697339505
Valid Loss:  0.00019536269246600568
Epoch:  380  	Training Loss: 0.00011122728028567508
Test Loss:  0.00013283995212987065
Valid Loss:  0.00019480772607494146
Epoch:  381  	Training Loss: 0.00011082635319326073
Test Loss:  0.00013232392666395754
Valid Loss:  0.000194281165022403
Epoch:  382  	Training Loss: 0.0001104461116483435
Test Loss:  0.0001312964886892587
Valid Loss:  0.00019161019008606672
Epoch:  383  	Training Loss: 0.0001089222205337137
Test Loss:  0.00013035637675784528
Valid Loss:  0.00018932420061901212
Epoch:  384  	Training Loss: 0.00010763735917862505
Test Loss:  0.00012949592201039195
Valid Loss:  0.00018747877038549632
Epoch:  385  	Training Loss: 0.00010657976963557303
Test Loss:  0.00012886400509160012
Valid Loss:  0.00018610525876283646
Epoch:  386  	Training Loss: 0.0001056924375006929
Test Loss:  0.00012828338367398828
Valid Loss:  0.0001850319531513378
Epoch:  387  	Training Loss: 0.00010494807793293148
Test Loss:  0.00012777959636878222
Valid Loss:  0.00018423092842567712
Epoch:  388  	Training Loss: 0.00010441992344567552
Test Loss:  0.00012730273010674864
Valid Loss:  0.00018367386655882
Epoch:  389  	Training Loss: 0.00010396090510766953
Test Loss:  0.00012683504610322416
Valid Loss:  0.00018317162175662816
Epoch:  390  	Training Loss: 0.0001035303866956383
Test Loss:  0.00012637776671908796
Valid Loss:  0.000182734991540201
Epoch:  391  	Training Loss: 0.00010314299288438633
Test Loss:  0.0001259404089068994
Valid Loss:  0.00018244743114337325
Epoch:  392  	Training Loss: 0.00010281090362695977
Test Loss:  0.0001256804825970903
Valid Loss:  0.0001809933310141787
Epoch:  393  	Training Loss: 0.00010182968981098384
Test Loss:  0.00012506029452197254
Valid Loss:  0.00018023521988652647
Epoch:  394  	Training Loss: 0.00010133633622899652
Test Loss:  0.00012428045738488436
Valid Loss:  0.00017973670037463307
Epoch:  395  	Training Loss: 0.00010098268103320152
Test Loss:  0.0001234501542057842
Valid Loss:  0.0001793940900824964
Epoch:  396  	Training Loss: 0.00010070390999317169
Test Loss:  0.00012264303222764283
Valid Loss:  0.0001791381509974599
Epoch:  397  	Training Loss: 0.00010047102114185691
Test Loss:  0.00012189075641799718
Valid Loss:  0.00017893679614644498
Epoch:  398  	Training Loss: 0.00010027077223639935
Test Loss:  0.00012121229519834742
Valid Loss:  0.00017874737386591733
Epoch:  399  	Training Loss: 0.00010009011020883918
Test Loss:  0.00012058054562658072
Valid Loss:  0.00017859457875601947
Epoch:  400  	Training Loss: 9.993340790970251e-05
Test Loss:  0.0001200006518047303
Valid Loss:  0.00017846535774879158
Epoch:  401  	Training Loss: 9.979231981560588e-05
Test Loss:  0.0001194822252728045
Valid Loss:  0.00017832903540693223
Epoch:  402  	Training Loss: 9.965803474187851e-05
Test Loss:  0.00011772513971664011
Valid Loss:  0.0001784526975825429
Epoch:  403  	Training Loss: 9.946108184522018e-05
Test Loss:  0.0001169883762486279
Valid Loss:  0.0001785412896424532
Epoch:  404  	Training Loss: 9.94176443782635e-05
Test Loss:  0.00011666677164612338
Valid Loss:  0.0001785824279068038
Epoch:  405  	Training Loss: 9.940401650965214e-05
Test Loss:  0.00011652013927232474
Valid Loss:  0.00017859670333564281
Epoch:  406  	Training Loss: 9.939602023223415e-05
Test Loss:  0.00011644996266113594
Valid Loss:  0.0001785971107892692
 81%|████████▏ | 407/500 [04:59<00:42,  2.19it/s] 82%|████████▏ | 409/500 [04:59<00:30,  2.95it/s] 82%|████████▏ | 411/500 [05:06<01:47,  1.21s/it] 83%|████████▎ | 413/500 [05:06<01:15,  1.15it/s] 83%|████████▎ | 415/500 [05:06<00:53,  1.59it/s] 83%|████████▎ | 417/500 [05:06<00:38,  2.18it/s] 84%|████████▍ | 419/500 [05:06<00:27,  2.93it/s] 84%|████████▍ | 421/500 [05:13<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:13<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:13<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:13<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:13<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:20<01:24,  1.22s/it] 87%|████████▋ | 433/500 [05:20<00:58,  1.14it/s] 87%|████████▋ | 435/500 [05:20<00:41,  1.58it/s] 87%|████████▋ | 437/500 [05:20<00:29,  2.16it/s] 88%|████████▊ | 439/500 [05:20<00:20,  2.91it/s] 88%|████████▊ | 441/500 [05:27<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:27<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:27<00:34,  1.59it/s] 89%|████████▉ | 447/500 [05:27<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:27<00:17,  2.91it/s] 90%|█████████ | 451/500 [05:34<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:34<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:34<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:34<00:19,  2.18it/s] 92%|█████████▏| 459/500 [05:34<00:13,  2.93it/s] 92%|█████████▏| 461/500 [05:41<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:41<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:41<00:22,  1.57it/s] 93%|█████████▎| 467/500 [05:41<00:15,  2.14it/s] 94%|█████████▍| 469/500 [05:42<00:10,  2.85it/s] 94%|█████████▍| 471/500 [05:48<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:48<00:23,  1.14it/s]Epoch:  407  	Training Loss: 9.938954462995753e-05
Test Loss:  0.00011641362652881071
Valid Loss:  0.00017859165382105857
Epoch:  408  	Training Loss: 9.938287257682532e-05
Test Loss:  0.00011639113654382527
Valid Loss:  0.00017858370847534388
Epoch:  409  	Training Loss: 9.937663708114997e-05
Test Loss:  0.0001163757624453865
Valid Loss:  0.00017857420607469976
Epoch:  410  	Training Loss: 9.93702924461104e-05
Test Loss:  0.00011636252020252869
Valid Loss:  0.00017856474732980132
Epoch:  411  	Training Loss: 9.936421702150255e-05
Test Loss:  0.00011635079135885462
Valid Loss:  0.00017855475016403943
Epoch:  412  	Training Loss: 9.93578287307173e-05
Test Loss:  0.00011606350017245859
Valid Loss:  0.00017815612955018878
Epoch:  413  	Training Loss: 9.91328852251172e-05
Test Loss:  0.00011577909754123539
Valid Loss:  0.00017778521578293294
Epoch:  414  	Training Loss: 9.892688103718683e-05
Test Loss:  0.00011549967166502029
Valid Loss:  0.0001774303673300892
Epoch:  415  	Training Loss: 9.873043018160388e-05
Test Loss:  0.00011522993736434728
Valid Loss:  0.00017711042892187834
Epoch:  416  	Training Loss: 9.855061944108456e-05
Test Loss:  0.00011498250387376174
Valid Loss:  0.0001768325746525079
Epoch:  417  	Training Loss: 9.839370613917708e-05
Test Loss:  0.0001147561488323845
Valid Loss:  0.00017657039279583842
Epoch:  418  	Training Loss: 9.824865264818072e-05
Test Loss:  0.00011454014747869223
Valid Loss:  0.00017631228547543287
Epoch:  419  	Training Loss: 9.810648043639958e-05
Test Loss:  0.00011434251064201817
Valid Loss:  0.00017606242909096181
Epoch:  420  	Training Loss: 9.796790254767984e-05
Test Loss:  0.00011416513007134199
Valid Loss:  0.00017581641441211104
Epoch:  421  	Training Loss: 9.783163841348141e-05
Test Loss:  0.00011399398499634117
Valid Loss:  0.00017558474792167544
Epoch:  422  	Training Loss: 9.770433825906366e-05
Test Loss:  0.00011402053496567532
Valid Loss:  0.00017548316100146621
Epoch:  423  	Training Loss: 9.764320566318929e-05
Test Loss:  0.00011403838288970292
Valid Loss:  0.00017538509564474225
Epoch:  424  	Training Loss: 9.75842704065144e-05
Test Loss:  0.00011404840915929526
Valid Loss:  0.00017529065371491015
Epoch:  425  	Training Loss: 9.752708137966692e-05
Test Loss:  0.00011405184341128916
Valid Loss:  0.00017519830726087093
Epoch:  426  	Training Loss: 9.747157309902832e-05
Test Loss:  0.00011404946417314932
Valid Loss:  0.00017510920588392764
Epoch:  427  	Training Loss: 9.741719259181991e-05
Test Loss:  0.00011404053657315671
Valid Loss:  0.00017501978436484933
Epoch:  428  	Training Loss: 9.736150968819857e-05
Test Loss:  0.00011402658128645271
Valid Loss:  0.0001749321527313441
Epoch:  429  	Training Loss: 9.730677993502468e-05
Test Loss:  0.0001140079548349604
Valid Loss:  0.00017484475392848253
Epoch:  430  	Training Loss: 9.725074778543785e-05
Test Loss:  0.00011398509377613664
Valid Loss:  0.00017475851927883923
Epoch:  431  	Training Loss: 9.719526133267209e-05
Test Loss:  0.00011395874753361568
Valid Loss:  0.00017467389989178628
Epoch:  432  	Training Loss: 9.714099724078551e-05
Test Loss:  0.00011364085366949439
Valid Loss:  0.00017469185695517808
Epoch:  433  	Training Loss: 9.712559403851628e-05
Test Loss:  0.00011360565258655697
Valid Loss:  0.00017465712153352797
Epoch:  434  	Training Loss: 9.711448365123942e-05
Test Loss:  0.00011360045027686283
Valid Loss:  0.00017461883544456214
Epoch:  435  	Training Loss: 9.710420272313058e-05
Test Loss:  0.0001135976126533933
Valid Loss:  0.00017458302318118513
Epoch:  436  	Training Loss: 9.709454025141895e-05
Test Loss:  0.00011359505879227072
Valid Loss:  0.0001745490008033812
Epoch:  437  	Training Loss: 9.708526340546086e-05
Test Loss:  0.00011359147902112454
Valid Loss:  0.00017451701569370925
Epoch:  438  	Training Loss: 9.707653953228146e-05
Test Loss:  0.00011358776828274131
Valid Loss:  0.00017448747530579567
Epoch:  439  	Training Loss: 9.706823038868606e-05
Test Loss:  0.00011358357733115554
Valid Loss:  0.00017445901175960898
Epoch:  440  	Training Loss: 9.706022683531046e-05
Test Loss:  0.00011357868788763881
Valid Loss:  0.00017443303659092635
Epoch:  441  	Training Loss: 9.705261618364602e-05
Test Loss:  0.0001135740167228505
Valid Loss:  0.0001744078181218356
Epoch:  442  	Training Loss: 9.70452674664557e-05
Test Loss:  0.00011317527241772041
Valid Loss:  0.00017441663658246398
Epoch:  443  	Training Loss: 9.70177206909284e-05
Test Loss:  0.00011312161950627342
Valid Loss:  0.0001743820757837966
Epoch:  444  	Training Loss: 9.699533984530717e-05
Test Loss:  0.00011307325621601194
Valid Loss:  0.00017434873734600842
Epoch:  445  	Training Loss: 9.697413042886183e-05
Test Loss:  0.00011302654456812888
Valid Loss:  0.00017431651940569282
Epoch:  446  	Training Loss: 9.695424523670226e-05
Test Loss:  0.00011298211757093668
Valid Loss:  0.00017428604769520462
Epoch:  447  	Training Loss: 9.693537140265107e-05
Test Loss:  0.00011293880379525945
Valid Loss:  0.00017425666737835854
Epoch:  448  	Training Loss: 9.691787272458896e-05
Test Loss:  0.00011289690155535936
Valid Loss:  0.0001742284803185612
Epoch:  449  	Training Loss: 9.690131264505908e-05
Test Loss:  0.00011285718937870115
Valid Loss:  0.000174201704794541
Epoch:  450  	Training Loss: 9.688636782811955e-05
Test Loss:  0.00011288892710581422
Valid Loss:  0.00017417516210116446
Epoch:  451  	Training Loss: 9.687822603154927e-05
Test Loss:  0.00011286444350844249
Valid Loss:  0.0001741576852509752
Epoch:  452  	Training Loss: 9.687062993180007e-05
Test Loss:  0.00011287175584584475
Valid Loss:  0.00017415103502571583
Epoch:  453  	Training Loss: 9.686473640613258e-05
Test Loss:  0.00011287762026768178
Valid Loss:  0.00017414410831406713
Epoch:  454  	Training Loss: 9.685891564004123e-05
Test Loss:  0.00011288237146800384
Valid Loss:  0.00017413761815987527
Epoch:  455  	Training Loss: 9.685342956800014e-05
Test Loss:  0.00011288601672276855
Valid Loss:  0.00017413182649761438
Epoch:  456  	Training Loss: 9.684796532383189e-05
Test Loss:  0.0001128883523051627
Valid Loss:  0.00017412533634342253
Epoch:  457  	Training Loss: 9.6842588391155e-05
Test Loss:  0.00011288956011412665
Valid Loss:  0.00017412035958841443
Epoch:  458  	Training Loss: 9.683730604592711e-05
Test Loss:  0.00011288980749668553
Valid Loss:  0.00017411497537977993
Epoch:  459  	Training Loss: 9.68322783592157e-05
Test Loss:  0.00011288940731901675
Valid Loss:  0.00017410909640602767
Epoch:  460  	Training Loss: 9.682711970526725e-05
Test Loss:  0.0001128883523051627
Valid Loss:  0.00017410435248166323
Epoch:  461  	Training Loss: 9.682208474259824e-05
Test Loss:  0.0001128861476900056
Valid Loss:  0.00017409957945346832
Epoch:  462  	Training Loss: 9.681730443844572e-05
Test Loss:  0.00011282911873422563
Valid Loss:  0.00017406434926670045
Epoch:  463  	Training Loss: 9.680536459200084e-05
Test Loss:  0.00011280614853603765
Valid Loss:  0.0001740253355819732
Epoch:  464  	Training Loss: 9.679373033577576e-05
Test Loss:  0.00011279243335593492
Valid Loss:  0.00017398566706106067
Epoch:  465  	Training Loss: 9.678262722445652e-05
Test Loss:  0.00011278192687314004
Valid Loss:  0.00017394640599377453
Epoch:  466  	Training Loss: 9.677186608314514e-05
Test Loss:  0.00011277215526206419
Valid Loss:  0.00017390790162608027
Epoch:  467  	Training Loss: 9.676137415226549e-05
Test Loss:  0.00011276274744886905
Valid Loss:  0.00017387101252097636
Epoch:  468  	Training Loss: 9.675126784713939e-05
Test Loss:  0.00011275341967120767
Valid Loss:  0.00017383461818099022
Epoch:  469  	Training Loss: 9.67416272033006e-05
Test Loss:  0.0001127448194893077
Valid Loss:  0.00017379948985762894
Epoch:  470  	Training Loss: 9.67322412179783e-05
Test Loss:  0.00011273566633462906
Valid Loss:  0.00017376533651258796
Epoch:  471  	Training Loss: 9.672292071627453e-05
Test Loss:  0.00011272693518549204
Valid Loss:  0.00017373202717863023
Epoch:  472  	Training Loss: 9.67141313594766e-05
Test Loss:  0.00011277562589384615
Valid Loss:  0.00017361907521262765
Epoch:  473  	Training Loss: 9.66578591032885e-05
Test Loss:  0.000112818532215897
Valid Loss:  0.0001735104451654479
Epoch:  474  	Training Loss: 9.660320210969076e-05
 95%|█████████▌| 475/500 [05:48<00:16,  1.56it/s] 95%|█████████▌| 477/500 [05:49<00:10,  2.13it/s] 96%|█████████▌| 479/500 [05:49<00:07,  2.86it/s] 96%|█████████▌| 481/500 [05:55<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:55<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:55<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:55<00:05,  2.17it/s] 98%|█████████▊| 489/500 [05:56<00:03,  2.92it/s] 98%|█████████▊| 491/500 [06:02<00:10,  1.21s/it] 99%|█████████▊| 493/500 [06:02<00:06,  1.15it/s] 99%|█████████▉| 495/500 [06:02<00:03,  1.59it/s] 99%|█████████▉| 497/500 [06:03<00:01,  2.18it/s]100%|█████████▉| 499/500 [06:03<00:00,  2.92it/s]100%|██████████| 500/500 [06:03<00:00,  1.38it/s]
Test Loss:  0.00011285593791399151
Valid Loss:  0.00017340571503154933
Epoch:  475  	Training Loss: 9.655010944698006e-05
Test Loss:  0.00011288831592537463
Valid Loss:  0.00017330434639006853
Epoch:  476  	Training Loss: 9.649823914514855e-05
Test Loss:  0.00011291664850432426
Valid Loss:  0.00017320731421932578
Epoch:  477  	Training Loss: 9.644775127526373e-05
Test Loss:  0.00011294080468360335
Valid Loss:  0.00017311159172095358
Epoch:  478  	Training Loss: 9.639846393838525e-05
Test Loss:  0.00011296098819002509
Valid Loss:  0.0001730195217533037
Epoch:  479  	Training Loss: 9.635025344323367e-05
Test Loss:  0.0001129739175667055
Valid Loss:  0.00017292978009209037
Epoch:  480  	Training Loss: 9.630329441279173e-05
Test Loss:  0.00011298268509563059
Valid Loss:  0.00017284222121816128
Epoch:  481  	Training Loss: 9.625706297811121e-05
Test Loss:  0.00011298909521428868
Valid Loss:  0.00017275699065066874
Epoch:  482  	Training Loss: 9.621201024856418e-05
Test Loss:  0.0001115463164751418
Valid Loss:  0.00017080482211895287
Epoch:  483  	Training Loss: 9.502658213023096e-05
Test Loss:  0.00011048476153519005
Valid Loss:  0.0001693003869149834
Epoch:  484  	Training Loss: 9.417818364454433e-05
Test Loss:  0.00010960939107462764
Valid Loss:  0.00016807175416033715
Epoch:  485  	Training Loss: 9.350042819278315e-05
Test Loss:  0.00010884853691095486
Valid Loss:  0.00016705933376215398
Epoch:  486  	Training Loss: 9.295152995036915e-05
Test Loss:  0.0001081764348782599
Valid Loss:  0.0001661657588556409
Epoch:  487  	Training Loss: 9.248688002116978e-05
Test Loss:  0.0001075797772500664
Valid Loss:  0.00016542308731004596
Epoch:  488  	Training Loss: 9.210676944348961e-05
Test Loss:  0.00010704615124268457
Valid Loss:  0.0001647540193516761
Epoch:  489  	Training Loss: 9.176482853945345e-05
Test Loss:  0.00010655879304977134
Valid Loss:  0.00016414726269431412
Epoch:  490  	Training Loss: 9.14538832148537e-05
Test Loss:  0.00010610747267492115
Valid Loss:  0.0001635924563743174
Epoch:  491  	Training Loss: 9.11733295652084e-05
Test Loss:  0.00010568985453573987
Valid Loss:  0.00016312426305375993
Epoch:  492  	Training Loss: 9.095184213947505e-05
Test Loss:  0.00010552591265877709
Valid Loss:  0.00016309402417391539
Epoch:  493  	Training Loss: 9.094372217077762e-05
Test Loss:  0.00010539100912865251
Valid Loss:  0.0001630701299291104
Epoch:  494  	Training Loss: 9.093782864511013e-05
Test Loss:  0.00010527919221203774
Valid Loss:  0.00016304990276694298
Epoch:  495  	Training Loss: 9.093347762245685e-05
Test Loss:  0.00010518660565139726
Valid Loss:  0.0001630332408240065
Epoch:  496  	Training Loss: 9.093015978578478e-05
Test Loss:  0.0001051102954079397
Valid Loss:  0.00016301865980494767
Epoch:  497  	Training Loss: 9.092753316508606e-05
Test Loss:  0.0001050468345056288
Valid Loss:  0.00016300698916893452
Epoch:  498  	Training Loss: 9.092542313737795e-05
Test Loss:  0.00010499395284568891
Valid Loss:  0.00016299606068059802
Epoch:  499  	Training Loss: 9.092358959605917e-05
Test Loss:  0.00010495038441149518
Valid Loss:  0.00016298715490847826
Epoch:  500  	Training Loss: 9.092219988815486e-05
Test Loss:  0.00010491365537745878
Valid Loss:  0.0001629793841857463
seed is  10
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.17it/s]  1%|          | 4/500 [00:00<00:31, 15.70it/s]  1%|          | 6/500 [00:00<00:31, 15.79it/s]  2%|▏         | 8/500 [00:00<00:31, 15.68it/s]  2%|▏         | 10/500 [00:00<00:30, 15.90it/s]  2%|▏         | 12/500 [00:00<00:30, 15.82it/s]  3%|▎         | 14/500 [00:00<00:30, 15.82it/s]  3%|▎         | 16/500 [00:01<00:30, 15.97it/s]  4%|▎         | 18/500 [00:01<00:29, 16.11it/s]  4%|▍         | 20/500 [00:01<00:30, 15.63it/s]  4%|▍         | 22/500 [00:01<00:30, 15.77it/s]  5%|▍         | 24/500 [00:01<00:29, 15.87it/s]  5%|▌         | 26/500 [00:01<00:30, 15.34it/s]  6%|▌         | 28/500 [00:01<00:31, 15.23it/s]  6%|▌         | 30/500 [00:01<00:33, 14.23it/s]  6%|▋         | 32/500 [00:02<00:34, 13.65it/s]  7%|▋         | 34/500 [00:02<00:34, 13.42it/s]  7%|▋         | 36/500 [00:02<00:32, 14.18it/s]  8%|▊         | 38/500 [00:02<00:31, 14.76it/s]  8%|▊         | 40/500 [00:02<00:30, 15.15it/s]  8%|▊         | 42/500 [00:02<00:29, 15.38it/s]  9%|▉         | 44/500 [00:02<00:29, 15.35it/s]  9%|▉         | 46/500 [00:03<00:31, 14.56it/s] 10%|▉         | 48/500 [00:03<00:30, 15.03it/s] 10%|█         | 50/500 [00:03<00:29, 15.35it/s] 10%|█         | 52/500 [00:03<00:28, 15.67it/s] 11%|█         | 54/500 [00:03<00:28, 15.86it/s] 11%|█         | 56/500 [00:03<00:29, 15.07it/s] 12%|█▏        | 58/500 [00:03<00:30, 14.73it/s] 12%|█▏        | 60/500 [00:03<00:29, 15.15it/s] 12%|█▏        | 62/500 [00:04<00:28, 15.47it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.68it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.68it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.81it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.88it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.01it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.01it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.07it/s] 16%|█▌        | 78/500 [00:05<00:26, 16.17it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.28it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.33it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.22it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.12it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.57it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.79it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.95it/s] 19%|█▉        | 94/500 [00:06<00:25, 16.06it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.16it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.20it/s] 20%|██        | 100/500 [00:06<00:24, 16.24it/s] 20%|██        | 102/500 [00:06<00:26, 15.14it/s] 21%|██        | 104/500 [00:06<00:27, 14.17it/s] 21%|██        | 106/500 [00:06<00:29, 13.57it/s] 22%|██▏       | 108/500 [00:07<00:28, 13.70it/s] 22%|██▏       | 110/500 [00:07<00:27, 14.38it/s] 22%|██▏       | 112/500 [00:07<00:26, 14.92it/s] 23%|██▎       | 114/500 [00:07<00:25, 15.30it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.51it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.76it/s] 24%|██▍       | 120/500 [00:07<00:23, 15.90it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.07it/s] 25%|██▍       | 124/500 [00:08<00:23, 16.13it/s]Epoch:  1  	Training Loss: 0.0547230988740921
Test Loss:  403.8055114746094
Valid Loss:  404.5005187988281
Epoch:  2  	Training Loss: 408.86181640625
Test Loss:  150408462336.0
Valid Loss:  147730251776.0
Epoch:  3  	Training Loss: 148783202304.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 16.17it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.20it/s] 26%|██▌       | 130/500 [00:08<00:24, 15.19it/s] 26%|██▋       | 132/500 [00:08<00:25, 14.16it/s] 27%|██▋       | 134/500 [00:08<00:27, 13.50it/s] 27%|██▋       | 136/500 [00:08<00:27, 13.11it/s] 28%|██▊       | 138/500 [00:09<00:28, 12.86it/s] 28%|██▊       | 140/500 [00:09<00:28, 12.74it/s] 28%|██▊       | 142/500 [00:09<00:27, 13.24it/s] 29%|██▉       | 144/500 [00:09<00:25, 14.03it/s] 29%|██▉       | 146/500 [00:09<00:24, 14.66it/s] 30%|██▉       | 148/500 [00:09<00:23, 15.09it/s] 30%|███       | 150/500 [00:09<00:22, 15.29it/s] 30%|███       | 152/500 [00:10<00:22, 15.61it/s] 31%|███       | 154/500 [00:10<00:21, 15.86it/s] 31%|███       | 156/500 [00:10<00:21, 15.89it/s] 32%|███▏      | 158/500 [00:10<00:21, 15.94it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.08it/s] 32%|███▏      | 162/500 [00:10<00:21, 16.09it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.15it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.14it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.03it/s] 34%|███▍      | 170/500 [00:11<00:20, 16.05it/s] 34%|███▍      | 172/500 [00:11<00:20, 16.16it/s] 35%|███▍      | 174/500 [00:11<00:20, 16.22it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.12it/s] 36%|███▌      | 178/500 [00:11<00:20, 16.07it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.03it/s] 36%|███▋      | 182/500 [00:11<00:19, 15.97it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.04it/s] 37%|███▋      | 186/500 [00:12<00:19, 15.97it/s] 38%|███▊      | 188/500 [00:12<00:19, 15.93it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.01it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.00it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.93it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.07it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.09it/s] 40%|████      | 200/500 [00:12<00:18, 16.17it/s] 40%|████      | 202/500 [00:13<00:18, 16.20it/s] 41%|████      | 204/500 [00:13<00:18, 16.15it/s] 41%|████      | 206/500 [00:13<00:18, 16.19it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.75it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.28it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.49it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.72it/s] 43%|████▎     | 216/500 [00:14<00:17, 15.86it/s] 44%|████▎     | 218/500 [00:14<00:17, 15.94it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.02it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.04it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.98it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.13it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.11it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.13it/s] 46%|████▋     | 232/500 [00:15<00:17, 15.07it/s] 47%|████▋     | 234/500 [00:15<00:18, 14.14it/s] 47%|████▋     | 236/500 [00:15<00:18, 14.33it/s] 48%|████▊     | 238/500 [00:15<00:17, 14.91it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.32it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.57it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.65it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.66it/s] 50%|████▉     | 248/500 [00:16<00:16, 15.53it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:17, 14.40it/s] 50%|█████     | 252/500 [00:16<00:17, 14.49it/s] 51%|█████     | 254/500 [00:16<00:16, 15.04it/s] 51%|█████     | 256/500 [00:16<00:15, 15.40it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.59it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.80it/s] 52%|█████▏    | 262/500 [00:16<00:15, 15.83it/s] 53%|█████▎    | 264/500 [00:17<00:14, 15.88it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.01it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.05it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.13it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.14it/s] 55%|█████▍    | 274/500 [00:17<00:14, 16.07it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.12it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.20it/s] 56%|█████▌    | 280/500 [00:18<00:13, 16.15it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.17it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.21it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.28it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.04it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.58it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.52it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.60it/s] 59%|█████▉    | 296/500 [00:19<00:12, 15.80it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.94it/s] 60%|██████    | 300/500 [00:19<00:12, 16.04it/s] 60%|██████    | 302/500 [00:19<00:12, 16.11it/s] 61%|██████    | 304/500 [00:19<00:12, 16.11it/s] 61%|██████    | 306/500 [00:19<00:12, 16.13it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.15it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.08it/s] 62%|██████▏   | 312/500 [00:20<00:11, 16.00it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.86it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.87it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.96it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.11it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.20it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.17it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.19it/s] 66%|██████▌   | 328/500 [00:21<00:11, 15.22it/s] 66%|██████▌   | 330/500 [00:21<00:11, 14.17it/s] 66%|██████▋   | 332/500 [00:21<00:12, 13.49it/s] 67%|██████▋   | 334/500 [00:21<00:12, 13.27it/s] 67%|██████▋   | 336/500 [00:21<00:12, 13.47it/s] 68%|██████▊   | 338/500 [00:21<00:11, 14.12it/s] 68%|██████▊   | 340/500 [00:21<00:10, 14.68it/s] 68%|██████▊   | 342/500 [00:22<00:10, 15.09it/s] 69%|██████▉   | 344/500 [00:22<00:10, 15.45it/s] 69%|██████▉   | 346/500 [00:22<00:09, 15.74it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.82it/s] 70%|███████   | 350/500 [00:22<00:10, 14.96it/s] 70%|███████   | 352/500 [00:22<00:10, 14.78it/s] 71%|███████   | 354/500 [00:22<00:09, 14.93it/s] 71%|███████   | 356/500 [00:23<00:09, 15.26it/s] 72%|███████▏  | 358/500 [00:23<00:09, 15.57it/s] 72%|███████▏  | 360/500 [00:23<00:08, 15.78it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.98it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.13it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.20it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.24it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.29it/s] 74%|███████▍  | 372/500 [00:24<00:07, 16.20it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 16.08it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.01it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.08it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.20it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.82it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.00it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.95it/s] 78%|███████▊  | 388/500 [00:25<00:07, 15.91it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.04it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.00it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.81it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.95it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.05it/s] 80%|████████  | 400/500 [00:25<00:06, 16.11it/s] 80%|████████  | 402/500 [00:25<00:06, 16.13it/s] 81%|████████  | 404/500 [00:26<00:05, 16.23it/s] 81%|████████  | 406/500 [00:26<00:05, 16.21it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.15it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.09it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.16it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.21it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.23it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.28it/s] 84%|████████▍ | 420/500 [00:27<00:04, 16.19it/s] 84%|████████▍ | 422/500 [00:27<00:04, 16.25it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.14it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.07it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.03it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.08it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.12it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.01it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.15it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.18it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.23it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.24it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.25it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.26it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.24it/s] 90%|█████████ | 450/500 [00:28<00:03, 15.93it/s] 90%|█████████ | 452/500 [00:29<00:03, 14.77it/s] 91%|█████████ | 454/500 [00:29<00:03, 15.07it/s] 91%|█████████ | 456/500 [00:29<00:02, 15.43it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.67it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.83it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.90it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.03it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.11it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.10it/s] 94%|█████████▍| 470/500 [00:30<00:01, 16.12it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.04it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.00it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.04it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.11it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.16it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.14it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.14it/s] 97%|█████████▋| 486/500 [00:31<00:00, 16.15it/s] 98%|█████████▊| 488/500 [00:31<00:00, 16.14it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.19it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.09it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.09it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.11it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.13it/s]100%|██████████| 500/500 [00:31<00:00, 16.17it/s]100%|██████████| 500/500 [00:31<00:00, 15.63it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  10
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:39,  6.33s/it]  1%|          | 3/500 [00:06<14:01,  1.69s/it]  1%|          | 5/500 [00:06<07:04,  1.17it/s]  1%|▏         | 7/500 [00:06<04:18,  1.90it/s]  2%|▏         | 9/500 [00:06<02:56,  2.78it/s]  2%|▏         | 11/500 [00:13<11:16,  1.38s/it]  3%|▎         | 13/500 [00:13<07:41,  1.06it/s]  3%|▎         | 15/500 [00:13<05:21,  1.51it/s]  3%|▎         | 17/500 [00:13<03:49,  2.11it/s]  4%|▍         | 19/500 [00:14<02:47,  2.88it/s]  4%|▍         | 21/500 [00:20<09:41,  1.21s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:27<09:21,  1.20s/it]  7%|▋         | 33/500 [00:27<06:41,  1.16it/s]  7%|▋         | 35/500 [00:27<04:49,  1.61it/s]  7%|▋         | 37/500 [00:27<03:30,  2.20it/s]  8%|▊         | 39/500 [00:27<02:35,  2.96it/s]  8%|▊         | 41/500 [00:34<09:09,  1.20s/it]  9%|▊         | 43/500 [00:34<06:32,  1.16it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.19it/s] 10%|▉         | 49/500 [00:34<02:33,  2.95it/s] 10%|█         | 51/500 [00:41<08:50,  1.18s/it] 11%|█         | 53/500 [00:41<06:18,  1.18it/s] 11%|█         | 55/500 [00:41<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:27,  3.00it/s] 12%|█▏        | 61/500 [00:48<08:51,  1.21s/it] 13%|█▎        | 63/500 [00:48<06:21,  1.14it/s] 13%|█▎        | 65/500 [00:48<04:34,  1.58it/s] 13%|█▎        | 67/500 [00:48<03:21,  2.14it/s] 14%|█▍        | 69/500 [00:48<02:32,  2.83it/s] 14%|█▍        | 71/500 [00:55<08:43,  1.22s/it]Epoch:  1  	Training Loss: 0.054723095148801804
Test Loss:  9.506434440612793
Valid Loss:  9.349347114562988
Epoch:  2  	Training Loss: 9.159849166870117
Test Loss:  0.08287134021520615
Valid Loss:  0.08108191192150116
Epoch:  3  	Training Loss: 0.06086285039782524
Test Loss:  0.08177503198385239
Valid Loss:  0.08003421872854233
Epoch:  4  	Training Loss: 0.06010064110159874
Test Loss:  0.08069771528244019
Valid Loss:  0.07900478690862656
Epoch:  5  	Training Loss: 0.05935278162360191
Test Loss:  0.0796390175819397
Valid Loss:  0.07799327373504639
Epoch:  6  	Training Loss: 0.05861897021532059
Test Loss:  0.07859857380390167
Valid Loss:  0.07699930667877197
Epoch:  7  	Training Loss: 0.05789890140295029
Test Loss:  0.07757602632045746
Valid Loss:  0.07602254301309586
Epoch:  8  	Training Loss: 0.057192299515008926
Test Loss:  0.0765710175037384
Valid Loss:  0.07506264001131058
Epoch:  9  	Training Loss: 0.05649887025356293
Test Loss:  0.07558320462703705
Valid Loss:  0.07411925494670868
Epoch:  10  	Training Loss: 0.055818334221839905
Test Loss:  0.07461223006248474
Valid Loss:  0.07319207489490509
Epoch:  11  	Training Loss: 0.05515042692422867
Test Loss:  0.0736577957868576
Valid Loss:  0.07228076457977295
Epoch:  12  	Training Loss: 0.054494891315698624
Test Loss:  0.0727359801530838
Valid Loss:  0.0714111402630806
Epoch:  13  	Training Loss: 0.05386703461408615
Test Loss:  0.07182876765727997
Valid Loss:  0.07055540382862091
Epoch:  14  	Training Loss: 0.053250234574079514
Test Loss:  0.07093589007854462
Valid Loss:  0.06971330940723419
Epoch:  15  	Training Loss: 0.052644286304712296
Test Loss:  0.07008575648069382
Valid Loss:  0.0689353197813034
Epoch:  16  	Training Loss: 0.05207568034529686
Test Loss:  0.06949642300605774
Valid Loss:  0.06847424805164337
Epoch:  17  	Training Loss: 0.051692962646484375
Test Loss:  0.06913669407367706
Valid Loss:  0.06816926598548889
Epoch:  18  	Training Loss: 0.05145609378814697
Test Loss:  0.0688181072473526
Valid Loss:  0.0678798258304596
Epoch:  19  	Training Loss: 0.05123874545097351
Test Loss:  0.06851270794868469
Valid Loss:  0.06759800016880035
Epoch:  20  	Training Loss: 0.05103367939591408
Test Loss:  0.068215511739254
Valid Loss:  0.06732089072465897
Epoch:  21  	Training Loss: 0.05083426833152771
Test Loss:  0.06799016892910004
Valid Loss:  0.06715552508831024
Epoch:  22  	Training Loss: 0.05069494619965553
Test Loss:  0.0679146870970726
Valid Loss:  0.06712368875741959
Epoch:  23  	Training Loss: 0.05065266042947769
Test Loss:  0.06788061559200287
Valid Loss:  0.06710955500602722
Epoch:  24  	Training Loss: 0.05063053220510483
Test Loss:  0.06786499917507172
Valid Loss:  0.06710149347782135
Epoch:  25  	Training Loss: 0.05061611533164978
Test Loss:  0.06785744428634644
Valid Loss:  0.0670982226729393
Epoch:  26  	Training Loss: 0.05061113461852074
Test Loss:  0.06785347312688828
Valid Loss:  0.06709582358598709
Epoch:  27  	Training Loss: 0.05060800909996033
Test Loss:  0.06785079836845398
Valid Loss:  0.06709379702806473
Epoch:  28  	Training Loss: 0.05060553550720215
Test Loss:  0.06784874200820923
Valid Loss:  0.06709207594394684
Epoch:  29  	Training Loss: 0.05060334876179695
Test Loss:  0.06784731149673462
Valid Loss:  0.06709085404872894
Epoch:  30  	Training Loss: 0.05060169845819473
Test Loss:  0.0678461417555809
Valid Loss:  0.06708991527557373
Epoch:  31  	Training Loss: 0.05060023069381714
Test Loss:  0.06784529238939285
Valid Loss:  0.06708913296461105
Epoch:  32  	Training Loss: 0.05059892684221268
Test Loss:  0.06784462183713913
Valid Loss:  0.06708843261003494
Epoch:  33  	Training Loss: 0.05059775710105896
Test Loss:  0.06784417480230331
Valid Loss:  0.06708782911300659
Epoch:  34  	Training Loss: 0.05059665068984032
Test Loss:  0.06784382462501526
Valid Loss:  0.06708727777004242
Epoch:  35  	Training Loss: 0.05059557408094406
Test Loss:  0.06784360110759735
Valid Loss:  0.06708678603172302
Epoch:  36  	Training Loss: 0.0505945160984993
Test Loss:  0.06784345954656601
Valid Loss:  0.06708633899688721
Epoch:  37  	Training Loss: 0.05059346556663513
Test Loss:  0.06784332543611526
Valid Loss:  0.0670858845114708
Epoch:  38  	Training Loss: 0.05059242248535156
Test Loss:  0.06784318387508392
Valid Loss:  0.06708543747663498
Epoch:  39  	Training Loss: 0.05059137940406799
Test Loss:  0.06784316152334213
Valid Loss:  0.06708502769470215
Epoch:  40  	Training Loss: 0.05059034749865532
Test Loss:  0.06784313917160034
Valid Loss:  0.06708462536334991
Epoch:  41  	Training Loss: 0.050589315593242645
Test Loss:  0.06784311681985855
Valid Loss:  0.06708422303199768
Epoch:  42  	Training Loss: 0.05058828368782997
Test Loss:  0.06784309446811676
Valid Loss:  0.06708382815122604
Epoch:  43  	Training Loss: 0.05058727040886879
Test Loss:  0.06784306466579437
Valid Loss:  0.0670834332704544
Epoch:  44  	Training Loss: 0.050586260855197906
Test Loss:  0.06784303486347198
Valid Loss:  0.06708303838968277
Epoch:  45  	Training Loss: 0.050585247576236725
Test Loss:  0.0678430050611496
Valid Loss:  0.06708263605833054
Epoch:  46  	Training Loss: 0.05058423429727554
Test Loss:  0.06784297525882721
Valid Loss:  0.0670822337269783
Epoch:  47  	Training Loss: 0.05058321729302406
Test Loss:  0.06784301996231079
Valid Loss:  0.06708185374736786
Epoch:  48  	Training Loss: 0.05058220401406288
Test Loss:  0.06784297525882721
Valid Loss:  0.06708145886659622
Epoch:  49  	Training Loss: 0.050581194460392
Test Loss:  0.06784294545650482
Valid Loss:  0.06708105653524399
Epoch:  50  	Training Loss: 0.05058018118143082
Test Loss:  0.06784290075302124
Valid Loss:  0.06708066165447235
Epoch:  51  	Training Loss: 0.050579171627759933
Test Loss:  0.06784285604953766
Valid Loss:  0.06708025932312012
Epoch:  52  	Training Loss: 0.05057816579937935
Test Loss:  0.06784289330244064
Valid Loss:  0.06707987189292908
Epoch:  53  	Training Loss: 0.05057714879512787
Test Loss:  0.06784282624721527
Valid Loss:  0.06707945466041565
Epoch:  54  	Training Loss: 0.05057613179087639
Test Loss:  0.0678427517414093
Valid Loss:  0.06707902997732162
Epoch:  55  	Training Loss: 0.05057511106133461
Test Loss:  0.06784269213676453
Valid Loss:  0.0670786201953888
Epoch:  56  	Training Loss: 0.05057409405708313
Test Loss:  0.06784261763095856
Valid Loss:  0.06707820296287537
Epoch:  57  	Training Loss: 0.05057308077812195
Test Loss:  0.06784263253211975
Valid Loss:  0.06707780063152313
Epoch:  58  	Training Loss: 0.05057206377387047
Test Loss:  0.06784255802631378
Valid Loss:  0.0670773833990097
Epoch:  59  	Training Loss: 0.05057104676961899
Test Loss:  0.06784248352050781
Valid Loss:  0.06707698106765747
Epoch:  60  	Training Loss: 0.050570033490657806
Test Loss:  0.06784248352050781
Valid Loss:  0.06707657128572464
Epoch:  61  	Training Loss: 0.050569020211696625
Test Loss:  0.06784245371818542
Valid Loss:  0.0670761689543724
Epoch:  62  	Training Loss: 0.05056801065802574
Test Loss:  0.06784243881702423
Valid Loss:  0.06707578152418137
Epoch:  63  	Training Loss: 0.05056702345609665
Test Loss:  0.06784241646528244
Valid Loss:  0.06707540154457092
Epoch:  64  	Training Loss: 0.050566039979457855
Test Loss:  0.06784248352050781
Valid Loss:  0.06707503646612167
Epoch:  65  	Training Loss: 0.050565049052238464
Test Loss:  0.06784246116876602
Valid Loss:  0.06707465648651123
Epoch:  66  	Training Loss: 0.05056406557559967
Test Loss:  0.06784243136644363
Valid Loss:  0.06707426905632019
Epoch:  67  	Training Loss: 0.050563082098960876
Test Loss:  0.06784249097108841
Valid Loss:  0.06707391142845154
Epoch:  68  	Training Loss: 0.050562094897031784
Test Loss:  0.06784246861934662
Valid Loss:  0.0670735239982605
Epoch:  69  	Training Loss: 0.05056111142039299
Test Loss:  0.06784243136644363
Valid Loss:  0.06707313656806946
Epoch:  70  	Training Loss: 0.050560127943754196
Test Loss:  0.06784248352050781
Valid Loss:  0.06707276403903961
Epoch:  71  	Training Loss: 0.050559140741825104
Test Loss:  0.06784245371818542
Valid Loss:  0.06707239151000977
Epoch:  72  	Training Loss: 0.05055816099047661
Test Loss:  0.06784240156412125
Valid Loss:  0.06707198172807693
Epoch:  73  	Training Loss: 0.05055716633796692
Test Loss:   15%|█▍        | 73/500 [00:55<06:13,  1.14it/s] 15%|█▌        | 75/500 [00:55<04:28,  1.58it/s] 15%|█▌        | 77/500 [00:55<03:17,  2.14it/s] 16%|█▌        | 79/500 [00:55<02:28,  2.84it/s] 16%|█▌        | 81/500 [01:02<08:25,  1.21s/it] 17%|█▋        | 83/500 [01:02<06:01,  1.15it/s] 17%|█▋        | 85/500 [01:02<04:20,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:09,  2.18it/s] 18%|█▊        | 89/500 [01:02<02:20,  2.93it/s] 18%|█▊        | 91/500 [01:09<08:05,  1.19s/it] 19%|█▊        | 93/500 [01:09<05:46,  1.17it/s] 19%|█▉        | 95/500 [01:09<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:09<03:02,  2.20it/s] 20%|█▉        | 99/500 [01:09<02:17,  2.91it/s] 20%|██        | 101/500 [01:16<08:01,  1.21s/it] 21%|██        | 103/500 [01:16<05:45,  1.15it/s] 21%|██        | 105/500 [01:16<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:16<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:16<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:23<07:44,  1.19s/it] 23%|██▎       | 113/500 [01:23<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:23<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:23<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:23<02:08,  2.95it/s] 24%|██▍       | 121/500 [01:30<07:35,  1.20s/it] 25%|██▍       | 123/500 [01:30<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:30<03:53,  1.60it/s] 25%|██▌       | 127/500 [01:30<02:51,  2.17it/s] 26%|██▌       | 129/500 [01:30<02:09,  2.87it/s] 26%|██▌       | 131/500 [01:37<07:27,  1.21s/it] 27%|██▋       | 133/500 [01:37<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:37<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:37<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:44<07:14,  1.21s/it] 29%|██▊       | 143/500 [01:44<05:12,  1.14it/s]0.06784242391586304
Valid Loss:  0.0670715868473053
Epoch:  74  	Training Loss: 0.05055616796016693
Test Loss:  0.06784235686063766
Valid Loss:  0.06707118451595306
Epoch:  75  	Training Loss: 0.05055517703294754
Test Loss:  0.06784237921237946
Valid Loss:  0.06707079708576202
Epoch:  76  	Training Loss: 0.05055418610572815
Test Loss:  0.06784231215715408
Valid Loss:  0.0670703798532486
Epoch:  77  	Training Loss: 0.05055319145321846
Test Loss:  0.06784231960773468
Valid Loss:  0.06706999987363815
Epoch:  78  	Training Loss: 0.05055220052599907
Test Loss:  0.06784224510192871
Valid Loss:  0.06706958264112473
Epoch:  79  	Training Loss: 0.05055120587348938
Test Loss:  0.06784218549728394
Valid Loss:  0.0670691728591919
Epoch:  80  	Training Loss: 0.050550222396850586
Test Loss:  0.06784220039844513
Valid Loss:  0.06706879287958145
Epoch:  81  	Training Loss: 0.0505492277443409
Test Loss:  0.06784212589263916
Valid Loss:  0.06706836819648743
Epoch:  82  	Training Loss: 0.050548240542411804
Test Loss:  0.06784214079380035
Valid Loss:  0.06706800311803818
Epoch:  83  	Training Loss: 0.05054726451635361
Test Loss:  0.06784208118915558
Valid Loss:  0.06706760078668594
Epoch:  84  	Training Loss: 0.05054629221558571
Test Loss:  0.06784208863973618
Valid Loss:  0.0670672208070755
Epoch:  85  	Training Loss: 0.05054531618952751
Test Loss:  0.0678420215845108
Valid Loss:  0.06706681847572327
Epoch:  86  	Training Loss: 0.05054434388875961
Test Loss:  0.067842036485672
Valid Loss:  0.06706644594669342
Epoch:  87  	Training Loss: 0.050543371587991714
Test Loss:  0.06784195452928543
Valid Loss:  0.06706603616476059
Epoch:  88  	Training Loss: 0.050542399287223816
Test Loss:  0.06784196197986603
Valid Loss:  0.06706566363573074
Epoch:  89  	Training Loss: 0.05054142326116562
Test Loss:  0.06784189492464066
Valid Loss:  0.06706526130437851
Epoch:  90  	Training Loss: 0.05054045841097832
Test Loss:  0.06784197688102722
Valid Loss:  0.06706489622592926
Epoch:  91  	Training Loss: 0.05053948611021042
Test Loss:  0.06784189492464066
Valid Loss:  0.06706450134515762
Epoch:  92  	Training Loss: 0.05053852126002312
Test Loss:  0.06784200668334961
Valid Loss:  0.06706417351961136
Epoch:  93  	Training Loss: 0.05053757503628731
Test Loss:  0.0678420215845108
Valid Loss:  0.0670638233423233
Epoch:  94  	Training Loss: 0.0505366250872612
Test Loss:  0.06784205138683319
Valid Loss:  0.06706346571445465
Epoch:  95  	Training Loss: 0.05053567886352539
Test Loss:  0.06784215569496155
Valid Loss:  0.06706314533948898
Epoch:  96  	Training Loss: 0.05053473636507988
Test Loss:  0.06784217059612274
Valid Loss:  0.06706278771162033
Epoch:  97  	Training Loss: 0.05053379014134407
Test Loss:  0.0678422749042511
Valid Loss:  0.06706245243549347
Epoch:  98  	Training Loss: 0.05053284391760826
Test Loss:  0.06784220784902573
Valid Loss:  0.06706208735704422
Epoch:  99  	Training Loss: 0.05053190141916275
Test Loss:  0.06784230470657349
Valid Loss:  0.06706175208091736
Epoch:  100  	Training Loss: 0.05053095892071724
Test Loss:  0.06784239411354065
Valid Loss:  0.0670614242553711
Epoch:  101  	Training Loss: 0.05053001269698143
Test Loss:  0.06784239411354065
Valid Loss:  0.06706106662750244
Epoch:  102  	Training Loss: 0.05052907019853592
Test Loss:  0.06784240901470184
Valid Loss:  0.06706070899963379
Epoch:  103  	Training Loss: 0.05052813142538071
Test Loss:  0.06784248352050781
Valid Loss:  0.06706037372350693
Epoch:  104  	Training Loss: 0.050527188926935196
Test Loss:  0.06784248352050781
Valid Loss:  0.06706000864505768
Epoch:  105  	Training Loss: 0.050526246428489685
Test Loss:  0.06784255802631378
Valid Loss:  0.06705966591835022
Epoch:  106  	Training Loss: 0.050525300204753876
Test Loss:  0.06784255802631378
Valid Loss:  0.06705930829048157
Epoch:  107  	Training Loss: 0.05052436888217926
Test Loss:  0.06784255057573318
Valid Loss:  0.06705895066261292
Epoch:  108  	Training Loss: 0.05052342265844345
Test Loss:  0.06784261763095856
Valid Loss:  0.06705860793590546
Epoch:  109  	Training Loss: 0.05052248388528824
Test Loss:  0.06784269213676453
Valid Loss:  0.067058265209198
Epoch:  110  	Training Loss: 0.050521545112133026
Test Loss:  0.06784266233444214
Valid Loss:  0.06705790758132935
Epoch:  111  	Training Loss: 0.050520606338977814
Test Loss:  0.06784266233444214
Valid Loss:  0.0670575425028801
Epoch:  112  	Training Loss: 0.0505196750164032
Test Loss:  0.0678427442908287
Valid Loss:  0.06705720722675323
Epoch:  113  	Training Loss: 0.050518739968538284
Test Loss:  0.06784273684024811
Valid Loss:  0.06705686450004578
Epoch:  114  	Training Loss: 0.050517819821834564
Test Loss:  0.06784281134605408
Valid Loss:  0.06705653667449951
Epoch:  115  	Training Loss: 0.05051688849925995
Test Loss:  0.06784288585186005
Valid Loss:  0.06705620139837265
Epoch:  116  	Training Loss: 0.05051596462726593
Test Loss:  0.06784295290708542
Valid Loss:  0.06705587357282639
Epoch:  117  	Training Loss: 0.050515033304691315
Test Loss:  0.06784293800592422
Valid Loss:  0.06705551594495773
Epoch:  118  	Training Loss: 0.050514105707407
Test Loss:  0.06784293055534363
Valid Loss:  0.06705515831708908
Epoch:  119  	Training Loss: 0.05051317811012268
Test Loss:  0.0678429901599884
Valid Loss:  0.06705482304096222
Epoch:  120  	Training Loss: 0.05051225423812866
Test Loss:  0.06784306466579437
Valid Loss:  0.06705449521541595
Epoch:  121  	Training Loss: 0.050511330366134644
Test Loss:  0.06784310936927795
Valid Loss:  0.06705415993928909
Epoch:  122  	Training Loss: 0.050510406494140625
Test Loss:  0.06784318387508392
Valid Loss:  0.06705384701490402
Epoch:  123  	Training Loss: 0.0505094900727272
Test Loss:  0.06784318387508392
Valid Loss:  0.06705349683761597
Epoch:  124  	Training Loss: 0.05050858110189438
Test Loss:  0.06784319132566452
Valid Loss:  0.06705315411090851
Epoch:  125  	Training Loss: 0.050507672131061554
Test Loss:  0.06784325838088989
Valid Loss:  0.06705284118652344
Epoch:  126  	Training Loss: 0.05050675943493843
Test Loss:  0.06784331798553467
Valid Loss:  0.06705251336097717
Epoch:  127  	Training Loss: 0.050505854189395905
Test Loss:  0.06784342229366302
Valid Loss:  0.0670522153377533
Epoch:  128  	Training Loss: 0.05050495266914368
Test Loss:  0.067843496799469
Valid Loss:  0.06705189496278763
Epoch:  129  	Training Loss: 0.050504036247730255
Test Loss:  0.06784350425004959
Valid Loss:  0.06705155968666077
Epoch:  130  	Training Loss: 0.05050313100218773
Test Loss:  0.06784360110759735
Valid Loss:  0.0670512467622757
Epoch:  131  	Training Loss: 0.0505022257566452
Test Loss:  0.06784367561340332
Valid Loss:  0.06705092638731003
Epoch:  132  	Training Loss: 0.050501320511102676
Test Loss:  0.06784377247095108
Valid Loss:  0.06705062836408615
Epoch:  133  	Training Loss: 0.050500426441431046
Test Loss:  0.06784383952617645
Valid Loss:  0.06705031543970108
Epoch:  134  	Training Loss: 0.050499532371759415
Test Loss:  0.06784393638372421
Valid Loss:  0.0670500099658966
Epoch:  135  	Training Loss: 0.050498634576797485
Test Loss:  0.06784400343894958
Valid Loss:  0.06704969704151154
Epoch:  136  	Training Loss: 0.050497740507125854
Test Loss:  0.06784410774707794
Valid Loss:  0.06704940646886826
Epoch:  137  	Training Loss: 0.05049685388803482
Test Loss:  0.0678441971540451
Valid Loss:  0.06704910099506378
Epoch:  138  	Training Loss: 0.05049595981836319
Test Loss:  0.06784425675868988
Valid Loss:  0.06704879552125931
Epoch:  139  	Training Loss: 0.05049506574869156
Test Loss:  0.06784436106681824
Valid Loss:  0.06704849749803543
Epoch:  140  	Training Loss: 0.050494179129600525
Test Loss:  0.0678444430232048
Valid Loss:  0.06704819202423096
Epoch:  141  	Training Loss: 0.05049329251050949
Test Loss:  0.06784450262784958
Valid Loss:  0.06704787909984589
Epoch:  142  	Training Loss: 0.05049239844083786
Test Loss:  0.06784453243017197
Valid Loss:  0.06704753637313843
Epoch:  143  	Training Loss: 0.05049147829413414
Test Loss:  0.06784453243017197
Valid Loss:  0.06704717129468918
Epoch:  144  	Training Loss: 0.05049055814743042
Test Loss:  0.06784456968307495
Valid Loss:  0.06704682111740112
Epoch:  145  	Training Loss: 0.0504896342754364
Test Loss:   29%|██▉       | 145/500 [01:44<03:47,  1.56it/s] 29%|██▉       | 147/500 [01:44<02:44,  2.14it/s] 30%|██▉       | 149/500 [01:44<02:01,  2.88it/s] 30%|███       | 151/500 [01:51<06:54,  1.19s/it] 31%|███       | 153/500 [01:51<04:56,  1.17it/s] 31%|███       | 155/500 [01:51<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:51<02:34,  2.21it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:58<06:45,  1.19s/it] 33%|███▎      | 163/500 [01:58<04:50,  1.16it/s] 33%|███▎      | 165/500 [01:58<03:29,  1.60it/s] 33%|███▎      | 167/500 [01:58<02:32,  2.18it/s] 34%|███▍      | 169/500 [01:58<01:53,  2.93it/s] 34%|███▍      | 171/500 [02:04<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:05<04:38,  1.18it/s] 35%|███▌      | 175/500 [02:05<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:05<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:05<01:47,  2.98it/s] 36%|███▌      | 181/500 [02:11<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:12<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:12<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:12<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:12<01:45,  2.95it/s] 38%|███▊      | 191/500 [02:18<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:19<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:19<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:19<01:41,  2.96it/s] 40%|████      | 201/500 [02:25<05:55,  1.19s/it] 41%|████      | 203/500 [02:25<04:13,  1.17it/s] 41%|████      | 205/500 [02:25<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:26<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:26<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:32<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:32<04:09,  1.15it/s] 43%|████▎     | 215/500 [02:32<02:58,  1.60it/s]0.06784459948539734
Valid Loss:  0.06704647839069366
Epoch:  146  	Training Loss: 0.05048871785402298
Test Loss:  0.06784458458423615
Valid Loss:  0.06704611331224442
Epoch:  147  	Training Loss: 0.05048779398202896
Test Loss:  0.06784462183713913
Valid Loss:  0.06704576313495636
Epoch:  148  	Training Loss: 0.05048687756061554
Test Loss:  0.06784465163946152
Valid Loss:  0.0670454129576683
Epoch:  149  	Training Loss: 0.05048596113920212
Test Loss:  0.06784463673830032
Valid Loss:  0.06704504787921906
Epoch:  150  	Training Loss: 0.0504850372672081
Test Loss:  0.06784465909004211
Valid Loss:  0.0670447051525116
Epoch:  151  	Training Loss: 0.050484124571084976
Test Loss:  0.0678446888923645
Valid Loss:  0.06704435497522354
Epoch:  152  	Training Loss: 0.050483204424381256
Test Loss:  0.0678447037935257
Valid Loss:  0.06704401969909668
Epoch:  153  	Training Loss: 0.050482310354709625
Test Loss:  0.06784474849700928
Valid Loss:  0.06704367697238922
Epoch:  154  	Training Loss: 0.050481412559747696
Test Loss:  0.06784478574991226
Valid Loss:  0.06704334914684296
Epoch:  155  	Training Loss: 0.05048051476478577
Test Loss:  0.06784480065107346
Valid Loss:  0.0670430138707161
Epoch:  156  	Training Loss: 0.050479620695114136
Test Loss:  0.06784485280513763
Valid Loss:  0.06704269349575043
Epoch:  157  	Training Loss: 0.050478726625442505
Test Loss:  0.06784488260746002
Valid Loss:  0.06704236567020416
Epoch:  158  	Training Loss: 0.050477832555770874
Test Loss:  0.06784488260746002
Valid Loss:  0.06704201549291611
Epoch:  159  	Training Loss: 0.05047693848609924
Test Loss:  0.0678449273109436
Valid Loss:  0.06704169511795044
Epoch:  160  	Training Loss: 0.050476040691137314
Test Loss:  0.06784495711326599
Valid Loss:  0.06704135239124298
Epoch:  161  	Training Loss: 0.05047514662146568
Test Loss:  0.06784498691558838
Valid Loss:  0.06704102456569672
Epoch:  162  	Training Loss: 0.05047425255179405
Test Loss:  0.06784498691558838
Valid Loss:  0.06704068183898926
Epoch:  163  	Training Loss: 0.05047336220741272
Test Loss:  0.06784502416849136
Valid Loss:  0.067040354013443
Epoch:  164  	Training Loss: 0.050472475588321686
Test Loss:  0.06784504652023315
Valid Loss:  0.06704002618789673
Epoch:  165  	Training Loss: 0.05047158896923065
Test Loss:  0.06784508377313614
Valid Loss:  0.06703969836235046
Epoch:  166  	Training Loss: 0.05047070235013962
Test Loss:  0.06784507632255554
Valid Loss:  0.067039355635643
Epoch:  167  	Training Loss: 0.050469815731048584
Test Loss:  0.06784510612487793
Valid Loss:  0.06703902781009674
Epoch:  168  	Training Loss: 0.05046892911195755
Test Loss:  0.06784513592720032
Valid Loss:  0.06703869998455048
Epoch:  169  	Training Loss: 0.050468042492866516
Test Loss:  0.06784515082836151
Valid Loss:  0.06703835725784302
Epoch:  170  	Training Loss: 0.05046715587377548
Test Loss:  0.06784514337778091
Valid Loss:  0.06703802943229675
Epoch:  171  	Training Loss: 0.05046626925468445
Test Loss:  0.0678451657295227
Valid Loss:  0.0670376867055893
Epoch:  172  	Training Loss: 0.050465382635593414
Test Loss:  0.06784521043300629
Valid Loss:  0.06703738868236542
Epoch:  173  	Training Loss: 0.05046452581882477
Test Loss:  0.06784526258707047
Valid Loss:  0.06703707575798035
Epoch:  174  	Training Loss: 0.05046366900205612
Test Loss:  0.06784525513648987
Valid Loss:  0.06703674793243408
Epoch:  175  	Training Loss: 0.05046280473470688
Test Loss:  0.06784529983997345
Valid Loss:  0.06703644245862961
Epoch:  176  	Training Loss: 0.05046194791793823
Test Loss:  0.06784534454345703
Valid Loss:  0.06703613698482513
Epoch:  177  	Training Loss: 0.05046108737587929
Test Loss:  0.06784538179636002
Valid Loss:  0.06703582406044006
Epoch:  178  	Training Loss: 0.05046023055911064
Test Loss:  0.0678454115986824
Valid Loss:  0.06703551858663559
Epoch:  179  	Training Loss: 0.050459373742341995
Test Loss:  0.0678454041481018
Valid Loss:  0.06703519076108932
Epoch:  180  	Training Loss: 0.05045850947499275
Test Loss:  0.06784544885158539
Valid Loss:  0.06703488528728485
Epoch:  181  	Training Loss: 0.050457656383514404
Test Loss:  0.06784547865390778
Valid Loss:  0.06703457981348038
Epoch:  182  	Training Loss: 0.05045679956674576
Test Loss:  0.06784550845623016
Valid Loss:  0.0670342668890953
Epoch:  183  	Training Loss: 0.05045594274997711
Test Loss:  0.06784553825855255
Valid Loss:  0.06703395396471024
Epoch:  184  	Training Loss: 0.05045507848262787
Test Loss:  0.06784556061029434
Valid Loss:  0.06703364849090576
Epoch:  185  	Training Loss: 0.05045422166585922
Test Loss:  0.06784556061029434
Valid Loss:  0.06703333556652069
Epoch:  186  	Training Loss: 0.050453364849090576
Test Loss:  0.0678456723690033
Valid Loss:  0.06703305244445801
Epoch:  187  	Training Loss: 0.05045250803232193
Test Loss:  0.06784568727016449
Valid Loss:  0.06703273206949234
Epoch:  188  	Training Loss: 0.050451651215553284
Test Loss:  0.06784570962190628
Valid Loss:  0.06703241914510727
Epoch:  189  	Training Loss: 0.05045079439878464
Test Loss:  0.06784580647945404
Valid Loss:  0.06703212857246399
Epoch:  190  	Training Loss: 0.05044993385672569
Test Loss:  0.06784583628177643
Valid Loss:  0.06703181564807892
Epoch:  191  	Training Loss: 0.050449080765247345
Test Loss:  0.06784585118293762
Valid Loss:  0.06703150272369385
Epoch:  192  	Training Loss: 0.0504482239484787
Test Loss:  0.0678458958864212
Valid Loss:  0.06703118979930878
Epoch:  193  	Training Loss: 0.050447359681129456
Test Loss:  0.0678458958864212
Valid Loss:  0.06703085452318192
Epoch:  194  	Training Loss: 0.05044649541378021
Test Loss:  0.06784595549106598
Valid Loss:  0.06703055649995804
Epoch:  195  	Training Loss: 0.05044562742114067
Test Loss:  0.06784595549106598
Valid Loss:  0.06703020632266998
Epoch:  196  	Training Loss: 0.05044475942850113
Test Loss:  0.06784594058990479
Valid Loss:  0.06702989339828491
Epoch:  197  	Training Loss: 0.050443898886442184
Test Loss:  0.06784601509571075
Valid Loss:  0.06702958047389984
Epoch:  198  	Training Loss: 0.05044303834438324
Test Loss:  0.06784600764513016
Valid Loss:  0.06702924519777298
Epoch:  199  	Training Loss: 0.050442174077034
Test Loss:  0.06784607470035553
Valid Loss:  0.0670289397239685
Epoch:  200  	Training Loss: 0.05044130980968475
Test Loss:  0.06784603744745255
Valid Loss:  0.06702858954668045
Epoch:  201  	Training Loss: 0.05044044554233551
Test Loss:  0.06784611195325851
Valid Loss:  0.06702827662229538
Epoch:  202  	Training Loss: 0.05043958127498627
Test Loss:  0.06784608960151672
Valid Loss:  0.06702795624732971
Epoch:  203  	Training Loss: 0.05043872445821762
Test Loss:  0.06784616410732269
Valid Loss:  0.06702764332294464
Epoch:  204  	Training Loss: 0.050437867641448975
Test Loss:  0.0678461343050003
Valid Loss:  0.06702730059623718
Epoch:  205  	Training Loss: 0.05043700337409973
Test Loss:  0.06784620881080627
Valid Loss:  0.06702699512243271
Epoch:  206  	Training Loss: 0.05043614283204079
Test Loss:  0.06784618645906448
Valid Loss:  0.06702665984630585
Epoch:  207  	Training Loss: 0.05043528974056244
Test Loss:  0.06784624606370926
Valid Loss:  0.06702635437250137
Epoch:  208  	Training Loss: 0.05043443292379379
Test Loss:  0.06784623116254807
Valid Loss:  0.06702601909637451
Epoch:  209  	Training Loss: 0.05043357238173485
Test Loss:  0.06784626841545105
Valid Loss:  0.06702570617198944
Epoch:  210  	Training Loss: 0.0504327230155468
Test Loss:  0.06784623861312866
Valid Loss:  0.06702537834644318
Epoch:  211  	Training Loss: 0.05043186992406845
Test Loss:  0.06784629821777344
Valid Loss:  0.0670250654220581
Epoch:  212  	Training Loss: 0.050431009382009506
Test Loss:  0.06784625351428986
Valid Loss:  0.06702470779418945
Epoch:  213  	Training Loss: 0.050430141389369965
Test Loss:  0.06784629821777344
Valid Loss:  0.06702437996864319
Epoch:  214  	Training Loss: 0.05042927712202072
Test Loss:  0.06784624606370926
Valid Loss:  0.06702402979135513
Epoch:  215  	Training Loss: 0.05042840912938118
Test Loss:  0.06784628331661224
Valid Loss:  0.06702370196580887
Epoch:  216  	Training Loss: 0.05042754113674164
Test Loss:  0.06784632056951523
Valid Loss:  0.067023366689682
Epoch:  217  	Training Loss: 0.050426676869392395
 43%|████▎     | 217/500 [02:33<02:10,  2.17it/s] 44%|████▍     | 219/500 [02:33<01:37,  2.88it/s] 44%|████▍     | 221/500 [02:39<05:33,  1.20s/it] 45%|████▍     | 223/500 [02:39<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:39<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:40<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:40<01:32,  2.92it/s] 46%|████▌     | 231/500 [02:46<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:49,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:46<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:47<01:28,  2.97it/s] 48%|████▊     | 241/500 [02:53<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:40,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:53<01:55,  2.20it/s] 50%|████▉     | 249/500 [02:54<01:24,  2.96it/s] 50%|█████     | 251/500 [03:00<04:57,  1.19s/it] 51%|█████     | 253/500 [03:00<03:31,  1.17it/s] 51%|█████     | 255/500 [03:00<02:32,  1.61it/s] 51%|█████▏    | 257/500 [03:00<01:50,  2.19it/s] 52%|█████▏    | 259/500 [03:01<01:21,  2.95it/s] 52%|█████▏    | 261/500 [03:07<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:07<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:07<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:07<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:07<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:14<04:40,  1.22s/it] 55%|█████▍    | 273/500 [03:14<03:19,  1.14it/s] 55%|█████▌    | 275/500 [03:14<02:23,  1.57it/s] 55%|█████▌    | 277/500 [03:14<01:43,  2.15it/s] 56%|█████▌    | 279/500 [03:15<01:16,  2.89it/s] 56%|█████▌    | 281/500 [03:21<04:19,  1.18s/it] 57%|█████▋    | 283/500 [03:21<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:21<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:21<01:38,  2.16it/s]Test Loss:  0.06784627586603165
Valid Loss:  0.06702300906181335
Epoch:  218  	Training Loss: 0.05042580887675285
Test Loss:  0.06784631311893463
Valid Loss:  0.06702268123626709
Epoch:  219  	Training Loss: 0.05042494088411331
Test Loss:  0.06784622371196747
Valid Loss:  0.06702232360839844
Epoch:  220  	Training Loss: 0.05042407661676407
Test Loss:  0.06784625351428986
Valid Loss:  0.06702198088169098
Epoch:  221  	Training Loss: 0.050423212349414825
Test Loss:  0.06784628331661224
Valid Loss:  0.06702165305614471
Epoch:  222  	Training Loss: 0.05042234808206558
Test Loss:  0.06784623861312866
Valid Loss:  0.06702131032943726
Epoch:  223  	Training Loss: 0.050421494990587234
Test Loss:  0.06784627586603165
Valid Loss:  0.06702098995447159
Epoch:  224  	Training Loss: 0.05042064189910889
Test Loss:  0.06784632056951523
Valid Loss:  0.06702067703008652
Epoch:  225  	Training Loss: 0.05041979253292084
Test Loss:  0.06784627586603165
Valid Loss:  0.06702032685279846
Epoch:  226  	Training Loss: 0.050418950617313385
Test Loss:  0.06784630566835403
Valid Loss:  0.0670200064778328
Epoch:  227  	Training Loss: 0.05041809752583504
Test Loss:  0.06784632802009583
Valid Loss:  0.06701968610286713
Epoch:  228  	Training Loss: 0.05041724443435669
Test Loss:  0.06784629076719284
Valid Loss:  0.06701934337615967
Epoch:  229  	Training Loss: 0.05041640251874924
Test Loss:  0.06784628331661224
Valid Loss:  0.0670190081000328
Epoch:  230  	Training Loss: 0.05041554942727089
Test Loss:  0.0678463727235794
Valid Loss:  0.06701870262622833
Epoch:  231  	Training Loss: 0.05041470378637314
Test Loss:  0.06784632056951523
Valid Loss:  0.06701835989952087
Epoch:  232  	Training Loss: 0.05041385814547539
Test Loss:  0.06784641742706299
Valid Loss:  0.06701807677745819
Epoch:  233  	Training Loss: 0.05041302740573883
Test Loss:  0.06784646213054657
Valid Loss:  0.06701777130365372
Epoch:  234  	Training Loss: 0.05041218549013138
Test Loss:  0.06784655898809433
Valid Loss:  0.06701748073101044
Epoch:  235  	Training Loss: 0.05041135475039482
Test Loss:  0.06784650683403015
Valid Loss:  0.06701713800430298
Epoch:  236  	Training Loss: 0.05041051656007767
Test Loss:  0.06784659624099731
Valid Loss:  0.0670168548822403
Epoch:  237  	Training Loss: 0.05040968582034111
Test Loss:  0.0678466260433197
Valid Loss:  0.06701653450727463
Epoch:  238  	Training Loss: 0.050408847630023956
Test Loss:  0.06784671545028687
Valid Loss:  0.06701625138521194
Epoch:  239  	Training Loss: 0.0504080206155777
Test Loss:  0.06784666329622269
Valid Loss:  0.06701590865850449
Epoch:  240  	Training Loss: 0.05040718615055084
Test Loss:  0.06784672290086746
Valid Loss:  0.06701561063528061
Epoch:  241  	Training Loss: 0.050406355410814285
Test Loss:  0.06784674525260925
Valid Loss:  0.06701529026031494
Epoch:  242  	Training Loss: 0.05040552094578743
Test Loss:  0.0678468719124794
Valid Loss:  0.06701504439115524
Epoch:  243  	Training Loss: 0.05040472000837326
Test Loss:  0.06784699857234955
Valid Loss:  0.06701478362083435
Epoch:  244  	Training Loss: 0.05040391534566879
Test Loss:  0.06784698367118835
Valid Loss:  0.06701448559761047
Epoch:  245  	Training Loss: 0.05040311440825462
Test Loss:  0.0678471028804779
Valid Loss:  0.06701423972845078
Epoch:  246  	Training Loss: 0.05040232092142105
Test Loss:  0.06784716248512268
Valid Loss:  0.0670139491558075
Epoch:  247  	Training Loss: 0.05040151625871658
Test Loss:  0.06784728169441223
Valid Loss:  0.0670137032866478
Epoch:  248  	Training Loss: 0.050400715321302414
Test Loss:  0.067847341299057
Valid Loss:  0.06701342761516571
Epoch:  249  	Training Loss: 0.050399914383888245
Test Loss:  0.06784746050834656
Valid Loss:  0.06701317429542542
Epoch:  250  	Training Loss: 0.050399117171764374
Test Loss:  0.06784749031066895
Valid Loss:  0.06701289862394333
Epoch:  251  	Training Loss: 0.050398316234350204
Test Loss:  0.06784754991531372
Valid Loss:  0.06701261550188065
Epoch:  252  	Training Loss: 0.050397515296936035
Test Loss:  0.0678476020693779
Valid Loss:  0.06701231747865677
Epoch:  253  	Training Loss: 0.05039668828248978
Test Loss:  0.06784766912460327
Valid Loss:  0.0670120120048523
Epoch:  254  	Training Loss: 0.05039585754275322
Test Loss:  0.06784766912460327
Valid Loss:  0.06701168417930603
Epoch:  255  	Training Loss: 0.05039503052830696
Test Loss:  0.06784772127866745
Valid Loss:  0.06701138615608215
Epoch:  256  	Training Loss: 0.050394207239151
Test Loss:  0.06784774363040924
Valid Loss:  0.06701107323169708
Epoch:  257  	Training Loss: 0.050393376499414444
Test Loss:  0.06784774363040924
Valid Loss:  0.06701074540615082
Epoch:  258  	Training Loss: 0.050392549484968185
Test Loss:  0.06784780323505402
Valid Loss:  0.06701044738292694
Epoch:  259  	Training Loss: 0.05039171874523163
Test Loss:  0.0678478479385376
Valid Loss:  0.06701014190912247
Epoch:  260  	Training Loss: 0.05039089918136597
Test Loss:  0.06784775853157043
Valid Loss:  0.06700979173183441
Epoch:  261  	Training Loss: 0.05039007216691971
Test Loss:  0.06784780323505402
Valid Loss:  0.06700949370861053
Epoch:  262  	Training Loss: 0.05038924887776375
Test Loss:  0.06784787029027939
Valid Loss:  0.06700919568538666
Epoch:  263  	Training Loss: 0.050388436764478683
Test Loss:  0.06784792244434357
Valid Loss:  0.06700890511274338
Epoch:  264  	Training Loss: 0.05038762092590332
Test Loss:  0.06784792989492416
Valid Loss:  0.0670085996389389
Epoch:  265  	Training Loss: 0.050386808812618256
Test Loss:  0.06784798949956894
Valid Loss:  0.06700830161571503
Epoch:  266  	Training Loss: 0.05038599669933319
Test Loss:  0.06784805655479431
Valid Loss:  0.06700801849365234
Epoch:  267  	Training Loss: 0.050385184586048126
Test Loss:  0.06784804165363312
Valid Loss:  0.06700770556926727
Epoch:  268  	Training Loss: 0.05038437992334366
Test Loss:  0.0678481012582779
Valid Loss:  0.0670074075460434
Epoch:  269  	Training Loss: 0.050383567810058594
Test Loss:  0.06784816086292267
Valid Loss:  0.06700711697340012
Epoch:  270  	Training Loss: 0.05038275569677353
Test Loss:  0.06784820556640625
Valid Loss:  0.06700682640075684
Epoch:  271  	Training Loss: 0.05038194730877876
Test Loss:  0.06784820556640625
Valid Loss:  0.06700650602579117
Epoch:  272  	Training Loss: 0.0503811351954937
Test Loss:  0.06784825772047043
Valid Loss:  0.06700622290372849
Epoch:  273  	Training Loss: 0.050380341708660126
Test Loss:  0.0678483173251152
Valid Loss:  0.0670059472322464
Epoch:  274  	Training Loss: 0.05037953704595566
Test Loss:  0.06784838438034058
Valid Loss:  0.06700566411018372
Epoch:  275  	Training Loss: 0.05037873983383179
Test Loss:  0.06784844398498535
Valid Loss:  0.06700538098812103
Epoch:  276  	Training Loss: 0.05037793517112732
Test Loss:  0.06784842908382416
Valid Loss:  0.06700507551431656
Epoch:  277  	Training Loss: 0.05037713795900345
Test Loss:  0.06784849613904953
Valid Loss:  0.06700480729341507
Epoch:  278  	Training Loss: 0.050376344472169876
Test Loss:  0.06784854829311371
Valid Loss:  0.06700452417135239
Epoch:  279  	Training Loss: 0.050375547260046005
Test Loss:  0.06784860789775848
Valid Loss:  0.0670042335987091
Epoch:  280  	Training Loss: 0.050374750047922134
Test Loss:  0.06784865260124207
Valid Loss:  0.06700395792722702
Epoch:  281  	Training Loss: 0.050373952835798264
Test Loss:  0.06784869730472565
Valid Loss:  0.06700367480516434
Epoch:  282  	Training Loss: 0.05037315562367439
Test Loss:  0.06784868985414505
Valid Loss:  0.06700336188077927
Epoch:  283  	Training Loss: 0.05037236213684082
Test Loss:  0.06784872710704803
Valid Loss:  0.06700307130813599
Epoch:  284  	Training Loss: 0.05037156492471695
Test Loss:  0.06784877926111221
Valid Loss:  0.0670027881860733
Epoch:  285  	Training Loss: 0.05037076771259308
Test Loss:  0.0678488165140152
Valid Loss:  0.06700250506401062
Epoch:  286  	Training Loss: 0.050369977951049805
Test Loss:  0.06784886121749878
Valid Loss:  0.06700222194194794
Epoch:  287  	Training Loss: 0.05036918446421623
Test Loss:  0.06784890592098236
Valid Loss:  0.06700193136930466
Epoch:  288  	Training Loss: 0.05036839097738266
Test Loss:  0.06784894317388535
Valid Loss:  0.06700164079666138
 58%|█████▊    | 289/500 [03:22<01:13,  2.86it/s] 58%|█████▊    | 291/500 [03:28<04:14,  1.22s/it] 59%|█████▊    | 293/500 [03:28<03:00,  1.14it/s] 59%|█████▉    | 295/500 [03:28<02:09,  1.58it/s] 59%|█████▉    | 297/500 [03:28<01:34,  2.16it/s] 60%|█████▉    | 299/500 [03:29<01:09,  2.89it/s] 60%|██████    | 301/500 [03:35<03:56,  1.19s/it] 61%|██████    | 303/500 [03:35<02:48,  1.17it/s] 61%|██████    | 305/500 [03:35<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:35<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:42<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:42<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:42<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:42<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:42<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:49<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:49<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:49<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:49<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:49<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:56<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:56<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:56<01:42,  1.62it/s] 67%|██████▋   | 337/500 [03:56<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:56<00:54,  2.96it/s] 68%|██████▊   | 341/500 [04:03<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:03<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:03<01:38,  1.58it/s] 69%|██████▉   | 347/500 [04:03<01:11,  2.15it/s] 70%|██████▉   | 349/500 [04:03<00:52,  2.90it/s] 70%|███████   | 351/500 [04:10<02:59,  1.21s/it] 71%|███████   | 353/500 [04:10<02:07,  1.16it/s] 71%|███████   | 355/500 [04:10<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:10<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:10<00:48,  2.93it/s]Epoch:  289  	Training Loss: 0.05036759376525879
Test Loss:  0.06784892082214355
Valid Loss:  0.0670013278722763
Epoch:  290  	Training Loss: 0.050366807729005814
Test Loss:  0.06784895062446594
Valid Loss:  0.06700104475021362
Epoch:  291  	Training Loss: 0.05036601424217224
Test Loss:  0.06784899532794952
Valid Loss:  0.06700076162815094
Epoch:  292  	Training Loss: 0.05036522448062897
Test Loss:  0.06784903258085251
Valid Loss:  0.06700047105550766
Epoch:  293  	Training Loss: 0.05036443471908569
Test Loss:  0.0678490698337555
Valid Loss:  0.06700018793344498
Epoch:  294  	Training Loss: 0.050363652408123016
Test Loss:  0.06784911453723907
Valid Loss:  0.0669999048113823
Epoch:  295  	Training Loss: 0.05036286637187004
Test Loss:  0.06784914433956146
Valid Loss:  0.06699961423873901
Epoch:  296  	Training Loss: 0.05036207661032677
Test Loss:  0.06784917414188385
Valid Loss:  0.06699933856725693
Epoch:  297  	Training Loss: 0.05036129057407379
Test Loss:  0.06784921139478683
Valid Loss:  0.06699904799461365
Epoch:  298  	Training Loss: 0.050360504537820816
Test Loss:  0.06784924119710922
Valid Loss:  0.06699876487255096
Epoch:  299  	Training Loss: 0.05035972222685814
Test Loss:  0.06784927845001221
Valid Loss:  0.06699848175048828
Epoch:  300  	Training Loss: 0.05035893991589546
Test Loss:  0.0678493082523346
Valid Loss:  0.0669981986284256
Epoch:  301  	Training Loss: 0.05035815387964249
Test Loss:  0.06784932315349579
Valid Loss:  0.06699790060520172
Epoch:  302  	Training Loss: 0.05035736411809921
Test Loss:  0.06784936785697937
Valid Loss:  0.06699761748313904
Epoch:  303  	Training Loss: 0.050356585532426834
Test Loss:  0.06784938275814056
Valid Loss:  0.06699733436107635
Epoch:  304  	Training Loss: 0.05035579949617386
Test Loss:  0.06784942746162415
Valid Loss:  0.06699705123901367
Epoch:  305  	Training Loss: 0.05035501345992088
Test Loss:  0.06784944981336594
Valid Loss:  0.06699676811695099
Epoch:  306  	Training Loss: 0.050354231148958206
Test Loss:  0.06784947216510773
Valid Loss:  0.06699647754430771
Epoch:  307  	Training Loss: 0.05035344511270523
Test Loss:  0.06784950196743011
Valid Loss:  0.06699619442224503
Epoch:  308  	Training Loss: 0.050352662801742554
Test Loss:  0.06784951686859131
Valid Loss:  0.06699591130018234
Epoch:  309  	Training Loss: 0.05035187304019928
Test Loss:  0.0678495466709137
Valid Loss:  0.06699562072753906
Epoch:  310  	Training Loss: 0.0503510944545269
Test Loss:  0.06784956157207489
Valid Loss:  0.06699533760547638
Epoch:  311  	Training Loss: 0.050350308418273926
Test Loss:  0.06784959137439728
Valid Loss:  0.0669950470328331
Epoch:  312  	Training Loss: 0.05034952983260155
Test Loss:  0.06784961372613907
Valid Loss:  0.06699477136135101
Epoch:  313  	Training Loss: 0.050348758697509766
Test Loss:  0.06784963607788086
Valid Loss:  0.06699449568986893
Epoch:  314  	Training Loss: 0.050347987562417984
Test Loss:  0.06784966588020325
Valid Loss:  0.06699422001838684
Epoch:  315  	Training Loss: 0.0503472164273262
Test Loss:  0.06784969568252563
Valid Loss:  0.06699394434690475
Epoch:  316  	Training Loss: 0.05034644901752472
Test Loss:  0.06784971058368683
Valid Loss:  0.06699365377426147
Epoch:  317  	Training Loss: 0.050345681607723236
Test Loss:  0.06784974038600922
Valid Loss:  0.06699338555335999
Epoch:  318  	Training Loss: 0.050344910472631454
Test Loss:  0.06784976273775101
Valid Loss:  0.0669931024312973
Epoch:  319  	Training Loss: 0.05034414306282997
Test Loss:  0.0678497850894928
Valid Loss:  0.06699283421039581
Epoch:  320  	Training Loss: 0.05034337565302849
Test Loss:  0.06784980744123459
Valid Loss:  0.06699255108833313
Epoch:  321  	Training Loss: 0.05034260451793671
Test Loss:  0.06784982234239578
Valid Loss:  0.06699226796627045
Epoch:  322  	Training Loss: 0.05034183710813522
Test Loss:  0.06784983724355698
Valid Loss:  0.06699199229478836
Epoch:  323  	Training Loss: 0.05034107342362404
Test Loss:  0.06784985959529877
Valid Loss:  0.06699171662330627
Epoch:  324  	Training Loss: 0.05034031346440315
Test Loss:  0.06784988194704056
Valid Loss:  0.06699143350124359
Epoch:  325  	Training Loss: 0.05033954977989197
Test Loss:  0.06784990429878235
Valid Loss:  0.0669911652803421
Epoch:  326  	Training Loss: 0.05033878982067108
Test Loss:  0.06784991919994354
Valid Loss:  0.06699088960886002
Epoch:  327  	Training Loss: 0.0503380261361599
Test Loss:  0.06784992665052414
Valid Loss:  0.06699061393737793
Epoch:  328  	Training Loss: 0.05033726245164871
Test Loss:  0.06784994900226593
Valid Loss:  0.06699033081531525
Epoch:  329  	Training Loss: 0.050336502492427826
Test Loss:  0.06784995645284653
Valid Loss:  0.06699006259441376
Epoch:  330  	Training Loss: 0.05033574253320694
Test Loss:  0.06784997880458832
Valid Loss:  0.06698977947235107
Epoch:  331  	Training Loss: 0.05033498257398605
Test Loss:  0.06784997880458832
Valid Loss:  0.06698949635028839
Epoch:  332  	Training Loss: 0.05033421888947487
Test Loss:  0.06784994900226593
Valid Loss:  0.06698918342590332
Epoch:  333  	Training Loss: 0.05033343285322189
Test Loss:  0.06784991919994354
Valid Loss:  0.06698885560035706
Epoch:  334  	Training Loss: 0.05033263936638832
Test Loss:  0.06784988194704056
Valid Loss:  0.06698853522539139
Epoch:  335  	Training Loss: 0.05033184960484505
Test Loss:  0.06784983724355698
Valid Loss:  0.06698820739984512
Epoch:  336  	Training Loss: 0.050331056118011475
Test Loss:  0.06784979999065399
Valid Loss:  0.06698788702487946
Epoch:  337  	Training Loss: 0.0503302663564682
Test Loss:  0.06784976273775101
Valid Loss:  0.06698755919933319
Epoch:  338  	Training Loss: 0.05032947659492493
Test Loss:  0.06784972548484802
Valid Loss:  0.06698724627494812
Epoch:  339  	Training Loss: 0.05032868683338165
Test Loss:  0.06784968078136444
Valid Loss:  0.06698691844940186
Epoch:  340  	Training Loss: 0.050327904522418976
Test Loss:  0.06784964352846146
Valid Loss:  0.06698659062385559
Epoch:  341  	Training Loss: 0.0503271147608757
Test Loss:  0.06784960627555847
Valid Loss:  0.06698627024888992
Epoch:  342  	Training Loss: 0.05032632499933243
Test Loss:  0.06784956902265549
Valid Loss:  0.06698595732450485
Epoch:  343  	Training Loss: 0.05032554268836975
Test Loss:  0.0678495317697525
Valid Loss:  0.06698563694953918
Epoch:  344  	Training Loss: 0.05032474920153618
Test Loss:  0.06784949451684952
Valid Loss:  0.06698532402515411
Epoch:  345  	Training Loss: 0.0503239631652832
Test Loss:  0.06784945726394653
Valid Loss:  0.06698501110076904
Epoch:  346  	Training Loss: 0.05032317340373993
Test Loss:  0.06784941256046295
Valid Loss:  0.06698469072580338
Epoch:  347  	Training Loss: 0.05032239109277725
Test Loss:  0.06784938275814056
Valid Loss:  0.06698437035083771
Epoch:  348  	Training Loss: 0.05032160133123398
Test Loss:  0.06784933805465698
Valid Loss:  0.06698405742645264
Epoch:  349  	Training Loss: 0.0503208190202713
Test Loss:  0.06784936785697937
Valid Loss:  0.06698375940322876
Epoch:  350  	Training Loss: 0.050320036709308624
Test Loss:  0.06784931570291519
Valid Loss:  0.06698344647884369
Epoch:  351  	Training Loss: 0.05031924694776535
Test Loss:  0.06784927099943161
Valid Loss:  0.06698312610387802
Epoch:  352  	Training Loss: 0.05031846463680267
Test Loss:  0.06784921884536743
Valid Loss:  0.06698280572891235
Epoch:  353  	Training Loss: 0.050317686051130295
Test Loss:  0.06784918159246445
Valid Loss:  0.06698248535394669
Epoch:  354  	Training Loss: 0.05031690374016762
Test Loss:  0.06784912198781967
Valid Loss:  0.06698216497898102
Epoch:  355  	Training Loss: 0.05031611770391464
Test Loss:  0.0678490698337555
Valid Loss:  0.06698183715343475
Epoch:  356  	Training Loss: 0.050315335392951965
Test Loss:  0.06784908473491669
Valid Loss:  0.06698153913021088
Epoch:  357  	Training Loss: 0.050314560532569885
Test Loss:  0.06784902513027191
Valid Loss:  0.0669812262058258
Epoch:  358  	Training Loss: 0.05031378194689751
Test Loss:  0.06784896552562714
Valid Loss:  0.06698089838027954
Epoch:  359  	Training Loss: 0.05031299591064453
Test Loss:  0.06784891337156296
Valid Loss:  0.06698057800531387
Epoch:  360  	Training Loss: 0.050312213599681854
Test Loss:  0.06784885376691818
Valid Loss:   72%|███████▏  | 361/500 [04:17<02:48,  1.21s/it] 73%|███████▎  | 363/500 [04:17<01:58,  1.15it/s] 73%|███████▎  | 365/500 [04:17<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:17<01:01,  2.18it/s] 74%|███████▍  | 369/500 [04:17<00:44,  2.93it/s] 74%|███████▍  | 371/500 [04:24<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:24<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:24<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:24<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:24<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:30<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:31<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:31<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:31<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:31<00:37,  2.95it/s] 78%|███████▊  | 391/500 [04:37<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:37<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:38<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:38<00:46,  2.19it/s] 80%|███████▉  | 399/500 [04:38<00:34,  2.95it/s] 80%|████████  | 401/500 [04:44<01:56,  1.17s/it] 81%|████████  | 403/500 [04:44<01:21,  1.19it/s] 81%|████████  | 405/500 [04:44<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:45<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:45<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:51<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:51<01:15,  1.16it/s] 83%|████████▎ | 415/500 [04:51<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:52<00:38,  2.18it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.94it/s] 84%|████████▍ | 421/500 [04:58<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:58<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:58<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:58<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:59<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:05<01:21,  1.18s/it]0.0669802576303482
Epoch:  361  	Training Loss: 0.050311438739299774
Test Loss:  0.06784879416227341
Valid Loss:  0.06697992980480194
Epoch:  362  	Training Loss: 0.0503106564283371
Test Loss:  0.06784874200820923
Valid Loss:  0.06697961688041687
Epoch:  363  	Training Loss: 0.05030988156795502
Test Loss:  0.06784876435995102
Valid Loss:  0.06697932630777359
Epoch:  364  	Training Loss: 0.05030910298228264
Test Loss:  0.06784871220588684
Valid Loss:  0.06697900593280792
Epoch:  365  	Training Loss: 0.05030832439661026
Test Loss:  0.06784866750240326
Valid Loss:  0.06697870045900345
Epoch:  366  	Training Loss: 0.05030754581093788
Test Loss:  0.06784860789775848
Valid Loss:  0.06697838008403778
Epoch:  367  	Training Loss: 0.0503067672252655
Test Loss:  0.0678485631942749
Valid Loss:  0.06697806715965271
Epoch:  368  	Training Loss: 0.05030599236488342
Test Loss:  0.06784850358963013
Valid Loss:  0.06697774678468704
Epoch:  369  	Training Loss: 0.05030521750450134
Test Loss:  0.06784851849079132
Valid Loss:  0.06697746366262436
Epoch:  370  	Training Loss: 0.05030444264411926
Test Loss:  0.06784845888614655
Valid Loss:  0.0669771358370781
Epoch:  371  	Training Loss: 0.050303664058446884
Test Loss:  0.06784840673208237
Valid Loss:  0.06697682291269302
Epoch:  372  	Training Loss: 0.050302889198064804
Test Loss:  0.06784836202859879
Valid Loss:  0.06697653234004974
Epoch:  373  	Training Loss: 0.050302132964134216
Test Loss:  0.0678483247756958
Valid Loss:  0.06697623431682587
Epoch:  374  	Training Loss: 0.05030137300491333
Test Loss:  0.06784834712743759
Valid Loss:  0.06697596609592438
Epoch:  375  	Training Loss: 0.05030062049627304
Test Loss:  0.06784830242395401
Valid Loss:  0.0669756680727005
Epoch:  376  	Training Loss: 0.050299860537052155
Test Loss:  0.06784826517105103
Valid Loss:  0.06697536259889603
Epoch:  377  	Training Loss: 0.050299108028411865
Test Loss:  0.06784822046756744
Valid Loss:  0.06697507202625275
Epoch:  378  	Training Loss: 0.05029835179448128
Test Loss:  0.06784817576408386
Valid Loss:  0.06697477400302887
Epoch:  379  	Training Loss: 0.05029759556055069
Test Loss:  0.06784813851118088
Valid Loss:  0.06697447597980499
Epoch:  380  	Training Loss: 0.0502968393266201
Test Loss:  0.06784815341234207
Valid Loss:  0.0669742003083229
Epoch:  381  	Training Loss: 0.05029608681797981
Test Loss:  0.0678481012582779
Valid Loss:  0.06697389483451843
Epoch:  382  	Training Loss: 0.050295330584049225
Test Loss:  0.06784803420305252
Valid Loss:  0.06697358191013336
Epoch:  383  	Training Loss: 0.05029455944895744
Test Loss:  0.06784797459840775
Valid Loss:  0.06697326898574829
Epoch:  384  	Training Loss: 0.05029379576444626
Test Loss:  0.06784790754318237
Valid Loss:  0.06697295606136322
Epoch:  385  	Training Loss: 0.050293032079935074
Test Loss:  0.06784789264202118
Valid Loss:  0.06697265803813934
Epoch:  386  	Training Loss: 0.05029226467013359
Test Loss:  0.0678478255867958
Valid Loss:  0.06697234511375427
Epoch:  387  	Training Loss: 0.050291500985622406
Test Loss:  0.06784775853157043
Valid Loss:  0.0669720321893692
Epoch:  388  	Training Loss: 0.05029073357582092
Test Loss:  0.06784768402576447
Valid Loss:  0.06697171181440353
Epoch:  389  	Training Loss: 0.05028996989130974
Test Loss:  0.0678476095199585
Valid Loss:  0.06697139889001846
Epoch:  390  	Training Loss: 0.05028920620679855
Test Loss:  0.0678476095199585
Valid Loss:  0.06697110086679459
Epoch:  391  	Training Loss: 0.05028843879699707
Test Loss:  0.06784753501415253
Valid Loss:  0.06697078794240952
Epoch:  392  	Training Loss: 0.050287678837776184
Test Loss:  0.06784744560718536
Valid Loss:  0.06697046756744385
Epoch:  393  	Training Loss: 0.0502869114279747
Test Loss:  0.0678473711013794
Valid Loss:  0.06697014719247818
Epoch:  394  	Training Loss: 0.05028614401817322
Test Loss:  0.06784729659557343
Valid Loss:  0.06696982681751251
Epoch:  395  	Training Loss: 0.05028538033366203
Test Loss:  0.0678473562002182
Valid Loss:  0.06696955859661102
Epoch:  396  	Training Loss: 0.05028461664915085
Test Loss:  0.0678473562002182
Valid Loss:  0.06696926057338715
Epoch:  397  	Training Loss: 0.050283849239349365
Test Loss:  0.0678473562002182
Valid Loss:  0.06696896255016327
Epoch:  398  	Training Loss: 0.05028308928012848
Test Loss:  0.06784740835428238
Valid Loss:  0.06696869432926178
Epoch:  399  	Training Loss: 0.050282321870326996
Test Loss:  0.06784747540950775
Valid Loss:  0.06696842610836029
Epoch:  400  	Training Loss: 0.05028156936168671
Test Loss:  0.06784752756357193
Valid Loss:  0.0669681578874588
Epoch:  401  	Training Loss: 0.05028080940246582
Test Loss:  0.06784752011299133
Valid Loss:  0.06696785986423492
Epoch:  402  	Training Loss: 0.05028004199266434
Test Loss:  0.06784749776124954
Valid Loss:  0.06696757674217224
Epoch:  403  	Training Loss: 0.050279293209314346
Test Loss:  0.06784749776124954
Valid Loss:  0.06696728616952896
Epoch:  404  	Training Loss: 0.05027853697538376
Test Loss:  0.06784762442111969
Valid Loss:  0.06696705520153046
Epoch:  405  	Training Loss: 0.05027778819203377
Test Loss:  0.06784768402576447
Valid Loss:  0.06696678698062897
Epoch:  406  	Training Loss: 0.05027703568339348
Test Loss:  0.06784766912460327
Valid Loss:  0.06696650385856628
Epoch:  407  	Training Loss: 0.05027627944946289
Test Loss:  0.06784772872924805
Valid Loss:  0.06696624308824539
Epoch:  408  	Training Loss: 0.0502755343914032
Test Loss:  0.06784771382808685
Valid Loss:  0.06696595251560211
Epoch:  409  	Training Loss: 0.05027477815747261
Test Loss:  0.0678478479385376
Valid Loss:  0.06696571409702301
Epoch:  410  	Training Loss: 0.05027402937412262
Test Loss:  0.0678478330373764
Valid Loss:  0.06696543097496033
Epoch:  411  	Training Loss: 0.05027328059077263
Test Loss:  0.06784787774085999
Valid Loss:  0.06696516275405884
Epoch:  412  	Training Loss: 0.05027253180742264
Test Loss:  0.06784787774085999
Valid Loss:  0.06696487963199615
Epoch:  413  	Training Loss: 0.05027179419994354
Test Loss:  0.06784800440073013
Valid Loss:  0.06696465611457825
Epoch:  414  	Training Loss: 0.050271064043045044
Test Loss:  0.0678480714559555
Valid Loss:  0.06696441769599915
Epoch:  415  	Training Loss: 0.05027034133672714
Test Loss:  0.0678480714559555
Valid Loss:  0.06696413457393646
Epoch:  416  	Training Loss: 0.05026960372924805
Test Loss:  0.06784813106060028
Valid Loss:  0.06696389615535736
Epoch:  417  	Training Loss: 0.050268881022930145
Test Loss:  0.06784825026988983
Valid Loss:  0.06696366518735886
Epoch:  418  	Training Loss: 0.05026815086603165
Test Loss:  0.06784824281930923
Valid Loss:  0.06696338951587677
Epoch:  419  	Training Loss: 0.05026742070913315
Test Loss:  0.0678483173251152
Valid Loss:  0.06696315109729767
Epoch:  420  	Training Loss: 0.05026669800281525
Test Loss:  0.06784830242395401
Valid Loss:  0.06696286797523499
Epoch:  421  	Training Loss: 0.05026596784591675
Test Loss:  0.06784841418266296
Valid Loss:  0.06696264445781708
Epoch:  422  	Training Loss: 0.05026523768901825
Test Loss:  0.06784845143556595
Valid Loss:  0.06696237623691559
Epoch:  423  	Training Loss: 0.050264500081539154
Test Loss:  0.06784842908382416
Valid Loss:  0.06696207821369171
Epoch:  424  	Training Loss: 0.05026376247406006
Test Loss:  0.06784845888614655
Valid Loss:  0.06696181744337082
Epoch:  425  	Training Loss: 0.05026302486658096
Test Loss:  0.0678485631942749
Valid Loss:  0.06696158647537231
Epoch:  426  	Training Loss: 0.050262290984392166
Test Loss:  0.06784854829311371
Valid Loss:  0.06696130335330963
Epoch:  427  	Training Loss: 0.05026155710220337
Test Loss:  0.0678485780954361
Valid Loss:  0.06696103513240814
Epoch:  428  	Training Loss: 0.050260819494724274
Test Loss:  0.06784861534833908
Valid Loss:  0.06696076691150665
Epoch:  429  	Training Loss: 0.05026008561253548
Test Loss:  0.06784871220588684
Valid Loss:  0.06696051359176636
Epoch:  430  	Training Loss: 0.05025935173034668
Test Loss:  0.06784867495298386
Valid Loss:  0.06696023046970367
Epoch:  431  	Training Loss: 0.050258614122867584
Test Loss:  0.06784870475530624
Valid Loss:  0.06695996224880219
Epoch:  432  	Training Loss: 0.050257883965969086
Test Loss:  0.06784876435995102
 87%|████████▋ | 433/500 [05:05<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:05<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:05<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:05<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:12<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:12<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:12<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:12<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:12<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:19<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:19<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:19<00:28,  1.59it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.17it/s] 92%|█████████▏| 459/500 [05:19<00:14,  2.90it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:26<00:15,  2.19it/s] 94%|█████████▍| 469/500 [05:26<00:10,  2.89it/s] 94%|█████████▍| 471/500 [05:33<00:35,  1.23s/it] 95%|█████████▍| 473/500 [05:33<00:23,  1.14it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.57it/s] 95%|█████████▌| 477/500 [05:33<00:10,  2.15it/s] 96%|█████████▌| 479/500 [05:33<00:07,  2.88it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.17it/s] 98%|█████████▊| 489/500 [05:40<00:03,  2.92it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:47<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:47<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:47<00:00,  2.94it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Valid Loss:  0.0669596865773201
Epoch:  433  	Training Loss: 0.0502571202814579
Test Loss:  0.06784868985414505
Valid Loss:  0.06695935130119324
Epoch:  434  	Training Loss: 0.050256356596946716
Test Loss:  0.06784868240356445
Valid Loss:  0.06695905327796936
Epoch:  435  	Training Loss: 0.05025558918714523
Test Loss:  0.06784866750240326
Valid Loss:  0.06695874035358429
Epoch:  436  	Training Loss: 0.05025482550263405
Test Loss:  0.06784871965646744
Valid Loss:  0.0669584646821022
Epoch:  437  	Training Loss: 0.050254061818122864
Test Loss:  0.06784863770008087
Valid Loss:  0.06695813685655594
Epoch:  438  	Training Loss: 0.05025329440832138
Test Loss:  0.06784863024950027
Valid Loss:  0.06695783138275146
Epoch:  439  	Training Loss: 0.050252534449100494
Test Loss:  0.06784860789775848
Valid Loss:  0.06695752590894699
Epoch:  440  	Training Loss: 0.05025177076458931
Test Loss:  0.06784866005182266
Valid Loss:  0.0669572502374649
Epoch:  441  	Training Loss: 0.050251007080078125
Test Loss:  0.06784863770008087
Valid Loss:  0.06695694476366043
Epoch:  442  	Training Loss: 0.05025024712085724
Test Loss:  0.06784860789775848
Valid Loss:  0.06695665419101715
Epoch:  443  	Training Loss: 0.05024952441453934
Test Loss:  0.06784871220588684
Valid Loss:  0.06695643067359924
Epoch:  444  	Training Loss: 0.050248801708221436
Test Loss:  0.06784874200820923
Valid Loss:  0.06695617735385895
Epoch:  445  	Training Loss: 0.05024808645248413
Test Loss:  0.06784877926111221
Valid Loss:  0.06695592403411865
Epoch:  446  	Training Loss: 0.05024736374616623
Test Loss:  0.06784886121749878
Valid Loss:  0.06695568561553955
Epoch:  447  	Training Loss: 0.050246644765138626
Test Loss:  0.06784883141517639
Valid Loss:  0.06695540994405746
Epoch:  448  	Training Loss: 0.050245918333530426
Test Loss:  0.06784885376691818
Valid Loss:  0.06695514917373657
Epoch:  449  	Training Loss: 0.05024520307779312
Test Loss:  0.06784888356924057
Valid Loss:  0.06695489585399628
Epoch:  450  	Training Loss: 0.05024448409676552
Test Loss:  0.06784896552562714
Valid Loss:  0.06695465743541718
Epoch:  451  	Training Loss: 0.050243765115737915
Test Loss:  0.06784899532794952
Valid Loss:  0.06695438921451569
Epoch:  452  	Training Loss: 0.05024304240942001
Test Loss:  0.06784900277853012
Valid Loss:  0.06695413589477539
Epoch:  453  	Training Loss: 0.05024232342839241
Test Loss:  0.06784908473491669
Valid Loss:  0.06695389747619629
Epoch:  454  	Training Loss: 0.05024160444736481
Test Loss:  0.06784903258085251
Valid Loss:  0.06695360690355301
Epoch:  455  	Training Loss: 0.050240881741046906
Test Loss:  0.06784909963607788
Valid Loss:  0.06695336848497391
Epoch:  456  	Training Loss: 0.0502401627600193
Test Loss:  0.06784911453723907
Valid Loss:  0.06695310771465302
Epoch:  457  	Training Loss: 0.0502394437789917
Test Loss:  0.06784911453723907
Valid Loss:  0.06695283949375153
Epoch:  458  	Training Loss: 0.0502387173473835
Test Loss:  0.06784912198781967
Valid Loss:  0.06695257127285004
Epoch:  459  	Training Loss: 0.0502379946410656
Test Loss:  0.06784919649362564
Valid Loss:  0.06695233285427094
Epoch:  460  	Training Loss: 0.050237275660037994
Test Loss:  0.06784918904304504
Valid Loss:  0.06695206463336945
Epoch:  461  	Training Loss: 0.05023656040430069
Test Loss:  0.06784918904304504
Valid Loss:  0.06695178896188736
Epoch:  462  	Training Loss: 0.05023583769798279
Test Loss:  0.06784926354885101
Valid Loss:  0.06695155799388885
Epoch:  463  	Training Loss: 0.05023512244224548
Test Loss:  0.06784927845001221
Valid Loss:  0.06695129722356796
Epoch:  464  	Training Loss: 0.05023440718650818
Test Loss:  0.0678492933511734
Valid Loss:  0.06695103645324707
Epoch:  465  	Training Loss: 0.050233691930770874
Test Loss:  0.06784935295581818
Valid Loss:  0.06695079803466797
Epoch:  466  	Training Loss: 0.05023298040032387
Test Loss:  0.067849300801754
Valid Loss:  0.06695051491260529
Epoch:  467  	Training Loss: 0.05023226886987686
Test Loss:  0.06784935295581818
Valid Loss:  0.06695027649402618
Epoch:  468  	Training Loss: 0.05023155361413956
Test Loss:  0.06784936785697937
Valid Loss:  0.0669500082731247
Epoch:  469  	Training Loss: 0.05023083835840225
Test Loss:  0.06784942746162415
Valid Loss:  0.06694977730512619
Epoch:  470  	Training Loss: 0.050230130553245544
Test Loss:  0.06784943491220474
Valid Loss:  0.0669495165348053
Epoch:  471  	Training Loss: 0.05022941529750824
Test Loss:  0.06784949451684952
Valid Loss:  0.0669492781162262
Epoch:  472  	Training Loss: 0.05022870749235153
Test Loss:  0.06784942001104355
Valid Loss:  0.06694898009300232
Epoch:  473  	Training Loss: 0.05022798478603363
Test Loss:  0.0678495466709137
Valid Loss:  0.0669487714767456
Epoch:  474  	Training Loss: 0.05022727698087692
Test Loss:  0.06784947216510773
Valid Loss:  0.06694846600294113
Epoch:  475  	Training Loss: 0.05022655799984932
Test Loss:  0.06784951686859131
Valid Loss:  0.06694821268320084
Epoch:  476  	Training Loss: 0.050225842744112015
Test Loss:  0.06784957647323608
Valid Loss:  0.06694796681404114
Epoch:  477  	Training Loss: 0.05022512748837471
Test Loss:  0.06784956902265549
Valid Loss:  0.06694769859313965
Epoch:  478  	Training Loss: 0.050224412232637405
Test Loss:  0.0678495541214943
Valid Loss:  0.06694743037223816
Epoch:  479  	Training Loss: 0.0502236932516098
Test Loss:  0.06784961372613907
Valid Loss:  0.06694717705249786
Epoch:  480  	Training Loss: 0.050222985446453094
Test Loss:  0.06784960627555847
Valid Loss:  0.06694690883159637
Epoch:  481  	Training Loss: 0.05022227019071579
Test Loss:  0.06784965097904205
Valid Loss:  0.06694666296243668
Epoch:  482  	Training Loss: 0.050221558660268784
Test Loss:  0.06784963607788086
Valid Loss:  0.06694638729095459
Epoch:  483  	Training Loss: 0.05022084712982178
Test Loss:  0.06784962862730026
Valid Loss:  0.0669461190700531
Epoch:  484  	Training Loss: 0.05022013559937477
Test Loss:  0.06784968078136444
Valid Loss:  0.066945880651474
Epoch:  485  	Training Loss: 0.050219424068927765
Test Loss:  0.06784965842962265
Valid Loss:  0.06694561243057251
Epoch:  486  	Training Loss: 0.05021871626377106
Test Loss:  0.06784970313310623
Valid Loss:  0.06694535911083221
Epoch:  487  	Training Loss: 0.05021800100803375
Test Loss:  0.06784974783658981
Valid Loss:  0.06694510579109192
Epoch:  488  	Training Loss: 0.050217293202877045
Test Loss:  0.06784966588020325
Valid Loss:  0.06694480776786804
Epoch:  489  	Training Loss: 0.05021658167243004
Test Loss:  0.0678497776389122
Valid Loss:  0.06694458425045013
Epoch:  490  	Training Loss: 0.05021587014198303
Test Loss:  0.06784975528717041
Valid Loss:  0.06694431602954865
Epoch:  491  	Training Loss: 0.050215162336826324
Test Loss:  0.0678497925400734
Valid Loss:  0.06694406270980835
Epoch:  492  	Training Loss: 0.050214458256959915
Test Loss:  0.0678497850894928
Valid Loss:  0.06694380193948746
Epoch:  493  	Training Loss: 0.050213754177093506
Test Loss:  0.06784984469413757
Valid Loss:  0.06694357097148895
Epoch:  494  	Training Loss: 0.050213057547807693
Test Loss:  0.06784982979297638
Valid Loss:  0.06694330275058746
Epoch:  495  	Training Loss: 0.050212353467941284
Test Loss:  0.06784988194704056
Valid Loss:  0.06694306433200836
Epoch:  496  	Training Loss: 0.05021165683865547
Test Loss:  0.06784993410110474
Valid Loss:  0.06694282591342926
Epoch:  497  	Training Loss: 0.05021096393465996
Test Loss:  0.06784992665052414
Valid Loss:  0.06694257259368896
Epoch:  498  	Training Loss: 0.050210267305374146
Test Loss:  0.06784997880458832
Valid Loss:  0.06694233417510986
Epoch:  499  	Training Loss: 0.050209566950798035
Test Loss:  0.06784995645284653
Valid Loss:  0.06694206595420837
Epoch:  500  	Training Loss: 0.050208866596221924
Test Loss:  0.06785006821155548
Valid Loss:  0.06694185733795166
seed is  10
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:48,  6.23s/it]  1%|          | 3/500 [00:06<13:50,  1.67s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<10:58,  1.35s/it]  3%|▎         | 13/500 [00:13<07:28,  1.09it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:56,  1.25s/it]  5%|▍         | 23/500 [00:20<07:03,  1.13it/s]  5%|▌         | 25/500 [00:20<05:02,  1.57it/s]  5%|▌         | 27/500 [00:20<03:39,  2.15it/s]  6%|▌         | 29/500 [00:20<02:42,  2.90it/s]  6%|▌         | 31/500 [00:27<09:31,  1.22s/it]  7%|▋         | 33/500 [00:27<06:48,  1.14it/s]  7%|▋         | 35/500 [00:27<04:53,  1.58it/s]  7%|▋         | 37/500 [00:27<03:33,  2.16it/s]  8%|▊         | 39/500 [00:27<02:38,  2.92it/s]  8%|▊         | 41/500 [00:34<09:24,  1.23s/it]  9%|▊         | 43/500 [00:34<06:43,  1.13it/s]  9%|▉         | 45/500 [00:34<04:53,  1.55it/s]  9%|▉         | 47/500 [00:34<03:34,  2.12it/s] 10%|▉         | 49/500 [00:35<02:38,  2.85it/s] 10%|█         | 51/500 [00:41<09:11,  1.23s/it] 11%|█         | 53/500 [00:41<06:34,  1.13it/s] 11%|█         | 55/500 [00:41<04:43,  1.57it/s] 11%|█▏        | 57/500 [00:42<03:26,  2.14it/s] 12%|█▏        | 59/500 [00:42<02:32,  2.89it/s] 12%|█▏        | 61/500 [00:48<08:44,  1.19s/it] 13%|█▎        | 63/500 [00:48<06:14,  1.17it/s] 13%|█▎        | 65/500 [00:55<11:15,  1.55s/it] 13%|█▎        | 67/500 [00:55<08:00,  1.11s/it] 14%|█▍        | 69/500 [00:55<05:43,  1.25it/s]Epoch:  1  	Training Loss: 0.054723095148801804
Test Loss:  0.5373129844665527
Valid Loss:  0.5517333149909973
Epoch:  2  	Training Loss: 0.5941325426101685
Test Loss:  3.0795416831970215
Valid Loss:  2.9141006469726562
Epoch:  3  	Training Loss: 2.7276642322540283
Test Loss:  0.3401166796684265
Valid Loss:  0.3561709523200989
Epoch:  4  	Training Loss: 0.43215513229370117
Test Loss:  0.3302658796310425
Valid Loss:  0.3487209677696228
Epoch:  5  	Training Loss: 0.4217633008956909
Test Loss:  0.32735297083854675
Valid Loss:  0.3458731174468994
Epoch:  6  	Training Loss: 0.4182412624359131
Test Loss:  0.325222373008728
Valid Loss:  0.34390074014663696
Epoch:  7  	Training Loss: 0.4156448245048523
Test Loss:  0.3235304355621338
Valid Loss:  0.342153936624527
Epoch:  8  	Training Loss: 0.41343966126441956
Test Loss:  0.32195132970809937
Valid Loss:  0.34048500657081604
Epoch:  9  	Training Loss: 0.411356121301651
Test Loss:  0.32040905952453613
Valid Loss:  0.33882009983062744
Epoch:  10  	Training Loss: 0.40932220220565796
Test Loss:  0.31867319345474243
Valid Loss:  0.33704543113708496
Epoch:  11  	Training Loss: 0.4071498513221741
Test Loss:  0.31508737802505493
Valid Loss:  0.33343157172203064
Epoch:  12  	Training Loss: 0.40361714363098145
Test Loss:  0.2246650606393814
Valid Loss:  0.20619705319404602
Epoch:  13  	Training Loss: 0.17015263438224792
Test Loss:  0.09070305526256561
Valid Loss:  0.08742204308509827
Epoch:  14  	Training Loss: 0.06704162806272507
Test Loss:  0.0820116251707077
Valid Loss:  0.07987344264984131
Epoch:  15  	Training Loss: 0.06106484308838844
Test Loss:  0.08174744248390198
Valid Loss:  0.07956143468618393
Epoch:  16  	Training Loss: 0.060588642954826355
Test Loss:  0.08147603273391724
Valid Loss:  0.07921363413333893
Epoch:  17  	Training Loss: 0.06008461117744446
Test Loss:  0.0812332034111023
Valid Loss:  0.07889403402805328
Epoch:  18  	Training Loss: 0.05960273742675781
Test Loss:  0.08100631833076477
Valid Loss:  0.07860705256462097
Epoch:  19  	Training Loss: 0.059196650981903076
Test Loss:  0.0807969719171524
Valid Loss:  0.0783364325761795
Epoch:  20  	Training Loss: 0.05888565629720688
Test Loss:  0.08062620460987091
Valid Loss:  0.07813612371683121
Epoch:  21  	Training Loss: 0.05865383893251419
Test Loss:  0.0804721862077713
Valid Loss:  0.0779629722237587
Epoch:  22  	Training Loss: 0.05848259478807449
Test Loss:  0.13440021872520447
Valid Loss:  0.1528850495815277
Epoch:  23  	Training Loss: 0.1272391378879547
Test Loss:  0.08865702152252197
Valid Loss:  0.08455882221460342
Epoch:  24  	Training Loss: 0.06386637687683105
Test Loss:  0.0841541737318039
Valid Loss:  0.08138734102249146
Epoch:  25  	Training Loss: 0.060460835695266724
Test Loss:  0.0831313356757164
Valid Loss:  0.08047938346862793
Epoch:  26  	Training Loss: 0.05946388840675354
Test Loss:  0.08210884034633636
Valid Loss:  0.0795951783657074
Epoch:  27  	Training Loss: 0.05855634808540344
Test Loss:  0.0811004787683487
Valid Loss:  0.07871320843696594
Epoch:  28  	Training Loss: 0.057748571038246155
Test Loss:  0.08010850101709366
Valid Loss:  0.07785030454397202
Epoch:  29  	Training Loss: 0.05698532238602638
Test Loss:  0.07913056015968323
Valid Loss:  0.07700099050998688
Epoch:  30  	Training Loss: 0.05624718219041824
Test Loss:  0.07816639542579651
Valid Loss:  0.076165571808815
Epoch:  31  	Training Loss: 0.05552692338824272
Test Loss:  0.07721744477748871
Valid Loss:  0.07534405589103699
Epoch:  32  	Training Loss: 0.05481947958469391
Test Loss:  0.03545248508453369
Valid Loss:  0.036873236298561096
Epoch:  33  	Training Loss: 0.025986727327108383
Test Loss:  0.022943580523133278
Valid Loss:  0.025306276977062225
Epoch:  34  	Training Loss: 0.0184104572981596
Test Loss:  0.017155710607767105
Valid Loss:  0.019803816452622414
Epoch:  35  	Training Loss: 0.015131283551454544
Test Loss:  0.013993808999657631
Valid Loss:  0.01650395616889
Epoch:  36  	Training Loss: 0.01310889795422554
Test Loss:  0.011853370815515518
Valid Loss:  0.014045046642422676
Epoch:  37  	Training Loss: 0.011344745755195618
Test Loss:  0.010143248364329338
Valid Loss:  0.012018448673188686
Epoch:  38  	Training Loss: 0.009723380208015442
Test Loss:  0.008731784299015999
Valid Loss:  0.01032368652522564
Epoch:  39  	Training Loss: 0.008349135518074036
Test Loss:  0.007588371634483337
Valid Loss:  0.008926410228013992
Epoch:  40  	Training Loss: 0.007282938342541456
Test Loss:  0.006688568275421858
Valid Loss:  0.007802573963999748
Epoch:  41  	Training Loss: 0.006472826469689608
Test Loss:  0.005968176294118166
Valid Loss:  0.006874348968267441
Epoch:  42  	Training Loss: 0.0057890089228749275
Test Loss:  0.0035630816128104925
Valid Loss:  0.004033438861370087
Epoch:  43  	Training Loss: 0.003307896899059415
Test Loss:  0.0035430961288511753
Valid Loss:  0.0034900768660008907
Epoch:  44  	Training Loss: 0.0027805885765701532
Test Loss:  0.003187154419720173
Valid Loss:  0.003214546013623476
Epoch:  45  	Training Loss: 0.0025908690877258778
Test Loss:  0.0030036503449082375
Valid Loss:  0.0030089414212852716
Epoch:  46  	Training Loss: 0.0024536121636629105
Test Loss:  0.002846154849976301
Valid Loss:  0.00286611239425838
Epoch:  47  	Training Loss: 0.0023552156053483486
Test Loss:  0.00275790155865252
Valid Loss:  0.0027630289550870657
Epoch:  48  	Training Loss: 0.00228445278480649
Test Loss:  0.0026642894372344017
Valid Loss:  0.0026830369606614113
Epoch:  49  	Training Loss: 0.0022245943546295166
Test Loss:  0.0026010992005467415
Valid Loss:  0.00260989461094141
Epoch:  50  	Training Loss: 0.002171963918954134
Test Loss:  0.002528308890759945
Valid Loss:  0.0025476254522800446
Epoch:  51  	Training Loss: 0.002124871825799346
Test Loss:  0.0024764062836766243
Valid Loss:  0.0024896119721233845
Epoch:  52  	Training Loss: 0.0020827115513384342
Test Loss:  0.0021186689846217632
Valid Loss:  0.0021488438360393047
Epoch:  53  	Training Loss: 0.0018071276135742664
Test Loss:  0.001860300311818719
Valid Loss:  0.00187528389506042
Epoch:  54  	Training Loss: 0.0015768855810165405
Test Loss:  0.001638224464841187
Valid Loss:  0.0016456536250188947
Epoch:  55  	Training Loss: 0.0013839711900800467
Test Loss:  0.0014502375852316618
Valid Loss:  0.0014525471488013864
Epoch:  56  	Training Loss: 0.0012233405141159892
Test Loss:  0.0012832155916839838
Valid Loss:  0.0012885021278634667
Epoch:  57  	Training Loss: 0.0010878697503358126
Test Loss:  0.0011359776835888624
Valid Loss:  0.0011506524169817567
Epoch:  58  	Training Loss: 0.0009751063771545887
Test Loss:  0.001012635650113225
Valid Loss:  0.0010362857719883323
Epoch:  59  	Training Loss: 0.0008825045661069453
Test Loss:  0.0009089615195989609
Valid Loss:  0.0009408202022314072
Epoch:  60  	Training Loss: 0.0008064074208959937
Test Loss:  0.0008188894134946167
Valid Loss:  0.0008639564621262252
Epoch:  61  	Training Loss: 0.0007440866902470589
Test Loss:  0.0007416829466819763
Valid Loss:  0.0008018273510970175
Epoch:  62  	Training Loss: 0.0006931651150807738
Test Loss:  0.0007963383104652166
Valid Loss:  0.0007086803670972586
Epoch:  63  	Training Loss: 0.000698549731168896
Test Loss:  0.0007279484998434782
Valid Loss:  0.0009384842705912888
Epoch:  64  	Training Loss: 0.0008090800838544965
Test Loss:  0.0011156609980389476
Valid Loss:  0.0008385821129195392
Epoch:  65  	Training Loss: 0.0009509857045486569
Test Loss:  0.0007876871968619525
Valid Loss:  0.0011485953582450747
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0010323720052838326
Test Loss:  0.0007677305256947875
Valid Loss:  0.0011016145581379533
Epoch:  67  	Training Loss: 0.0009827419416978955
Test Loss:  0.0007479620398953557
Valid Loss:  0.0010491821449249983
Epoch:  68  	Training Loss: 0.0009318739175796509
Test Loss:  0.0007266959291882813
Valid Loss:  0.0009937023278325796
Epoch:  69  	Training Loss: 0.0008778764167800546
Test Loss:  0.0007040072232484818
Valid Loss:  0.0009394998196512461
Epoch:  70  	Training Loss: 0.0008238499867729843
Test Loss:  0.0006793045904487371
Valid Loss:  0.0008881163084879518
 14%|█▍        | 71/500 [01:01<10:49,  1.51s/it] 15%|█▍        | 73/500 [01:01<07:43,  1.08s/it] 15%|█▌        | 75/500 [01:01<05:31,  1.28it/s] 15%|█▌        | 77/500 [01:02<03:58,  1.77it/s] 16%|█▌        | 79/500 [01:02<02:54,  2.41it/s] 16%|█▌        | 81/500 [01:08<08:41,  1.24s/it] 17%|█▋        | 83/500 [01:08<06:12,  1.12it/s] 17%|█▋        | 85/500 [01:08<04:27,  1.55it/s] 17%|█▋        | 87/500 [01:09<03:14,  2.12it/s] 18%|█▊        | 89/500 [01:09<02:23,  2.86it/s] 18%|█▊        | 91/500 [01:15<08:11,  1.20s/it] 19%|█▊        | 93/500 [01:15<05:51,  1.16it/s] 19%|█▉        | 95/500 [01:15<04:14,  1.59it/s] 19%|█▉        | 97/500 [01:15<03:05,  2.17it/s] 20%|█▉        | 99/500 [01:16<02:17,  2.92it/s] 20%|██        | 101/500 [01:22<07:59,  1.20s/it] 21%|██        | 103/500 [01:22<05:42,  1.16it/s] 21%|██        | 105/500 [01:22<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:22<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:23<02:13,  2.94it/s] 22%|██▏       | 111/500 [01:29<07:43,  1.19s/it] 23%|██▎       | 113/500 [01:29<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:29<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:29<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:29<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:36<07:36,  1.21s/it] 25%|██▍       | 123/500 [01:36<05:26,  1.16it/s] 25%|██▌       | 125/500 [01:36<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:36<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:36<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:43<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:43<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:43<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:43<02:44,  2.21it/s]Epoch:  71  	Training Loss: 0.0007730581564828753
Test Loss:  0.0006570301484316587
Valid Loss:  0.0008419329533353448
Epoch:  72  	Training Loss: 0.0007286869222298265
Test Loss:  0.0006473268149420619
Valid Loss:  0.0008150433422997594
Epoch:  73  	Training Loss: 0.000705961836501956
Test Loss:  0.0006437262054532766
Valid Loss:  0.0007966896519064903
Epoch:  74  	Training Loss: 0.0006906355265527964
Test Loss:  0.0006409251363947988
Valid Loss:  0.0007829979294911027
Epoch:  75  	Training Loss: 0.000679239456076175
Test Loss:  0.0006381291314028203
Valid Loss:  0.0007718905690126121
Epoch:  76  	Training Loss: 0.0006700761150568724
Test Loss:  0.0006352926138788462
Valid Loss:  0.0007622810080647469
Epoch:  77  	Training Loss: 0.0006622665096074343
Test Loss:  0.000632157432846725
Valid Loss:  0.0007538656936958432
Epoch:  78  	Training Loss: 0.0006553521961905062
Test Loss:  0.0006287951837293804
Valid Loss:  0.0007462070789188147
Epoch:  79  	Training Loss: 0.0006491472013294697
Test Loss:  0.0006252157036215067
Valid Loss:  0.0007391771068796515
Epoch:  80  	Training Loss: 0.0006435489049181342
Test Loss:  0.000621538027189672
Valid Loss:  0.0007326953345909715
Epoch:  81  	Training Loss: 0.0006384092848747969
Test Loss:  0.0006178704788908362
Valid Loss:  0.0007266500033438206
Epoch:  82  	Training Loss: 0.0006336149526759982
Test Loss:  0.0006021992303431034
Valid Loss:  0.0007197862723842263
Epoch:  83  	Training Loss: 0.0006276810308918357
Test Loss:  0.000588910945225507
Valid Loss:  0.0007143375114537776
Epoch:  84  	Training Loss: 0.0006228957790881395
Test Loss:  0.0005777372280135751
Valid Loss:  0.0007102082599885762
Epoch:  85  	Training Loss: 0.0006191250868141651
Test Loss:  0.0005683958297595382
Valid Loss:  0.0007070064311847091
Epoch:  86  	Training Loss: 0.0006161623168736696
Test Loss:  0.0005606979830190539
Valid Loss:  0.0007046477985568345
Epoch:  87  	Training Loss: 0.0006138804601505399
Test Loss:  0.0005542436265386641
Valid Loss:  0.0007029035477899015
Epoch:  88  	Training Loss: 0.0006120640318840742
Test Loss:  0.0005486761219799519
Valid Loss:  0.000701533688697964
Epoch:  89  	Training Loss: 0.0006105804350227118
Test Loss:  0.0005438962834887207
Valid Loss:  0.0007005363004282117
Epoch:  90  	Training Loss: 0.0006093797273933887
Test Loss:  0.0005398353096097708
Valid Loss:  0.00069982442073524
Epoch:  91  	Training Loss: 0.0006084531196393073
Test Loss:  0.0005363335949368775
Valid Loss:  0.000699302414432168
Epoch:  92  	Training Loss: 0.000607704627327621
Test Loss:  0.0005342119839042425
Valid Loss:  0.0006973422132432461
Epoch:  93  	Training Loss: 0.0006050186930224299
Test Loss:  0.0005321106873452663
Valid Loss:  0.000695413036737591
Epoch:  94  	Training Loss: 0.0006024159956723452
Test Loss:  0.0005300086922943592
Valid Loss:  0.0006934115663170815
Epoch:  95  	Training Loss: 0.0005998769775032997
Test Loss:  0.0005279466276988387
Valid Loss:  0.0006913713295944035
Epoch:  96  	Training Loss: 0.0005973927909508348
Test Loss:  0.0005258604651317
Valid Loss:  0.000689287087880075
Epoch:  97  	Training Loss: 0.000594942772295326
Test Loss:  0.0005238086450845003
Valid Loss:  0.0006872073863632977
Epoch:  98  	Training Loss: 0.0005925465375185013
Test Loss:  0.0005214534467086196
Valid Loss:  0.0006846535252407193
Epoch:  99  	Training Loss: 0.0005901695694774389
Test Loss:  0.0005195286357775331
Valid Loss:  0.0006826986791566014
Epoch:  100  	Training Loss: 0.0005878512165509164
Test Loss:  0.0005173176759853959
Valid Loss:  0.0006803157739341259
Epoch:  101  	Training Loss: 0.0005855293711647391
Test Loss:  0.0005151643417775631
Valid Loss:  0.0006780558614991605
Epoch:  102  	Training Loss: 0.0005832401220686734
Test Loss:  0.0005164629546925426
Valid Loss:  0.000672599533572793
Epoch:  103  	Training Loss: 0.0005787060363218188
Test Loss:  0.0005178964929655194
Valid Loss:  0.0006676737684756517
Epoch:  104  	Training Loss: 0.0005746919778175652
Test Loss:  0.000519365887157619
Valid Loss:  0.0006632908480241895
Epoch:  105  	Training Loss: 0.0005711786798201501
Test Loss:  0.000520861241966486
Valid Loss:  0.0006593844154849648
Epoch:  106  	Training Loss: 0.0005679214955307543
Test Loss:  0.0005223721382208169
Valid Loss:  0.0006558074383065104
Epoch:  107  	Training Loss: 0.0005647802026942372
Test Loss:  0.0005239320453256369
Valid Loss:  0.0006525237113237381
Epoch:  108  	Training Loss: 0.0005616287235170603
Test Loss:  0.0005253381677903235
Valid Loss:  0.0006494781118817627
Epoch:  109  	Training Loss: 0.0005586827755905688
Test Loss:  0.0005266480147838593
Valid Loss:  0.0006466482300311327
Epoch:  110  	Training Loss: 0.0005558867705985904
Test Loss:  0.0005279325414448977
Valid Loss:  0.0006440116558223963
Epoch:  111  	Training Loss: 0.0005532727809622884
Test Loss:  0.0005291767884045839
Valid Loss:  0.000641608377918601
Epoch:  112  	Training Loss: 0.000550710188690573
Test Loss:  0.0005362439551390707
Valid Loss:  0.0006199622293934226
Epoch:  113  	Training Loss: 0.000539685133844614
Test Loss:  0.0005407939315773547
Valid Loss:  0.0006095539429225028
Epoch:  114  	Training Loss: 0.0005350487190298736
Test Loss:  0.0005428550066426396
Valid Loss:  0.0006037301500327885
Epoch:  115  	Training Loss: 0.0005320453783497214
Test Loss:  0.0005433362675830722
Valid Loss:  0.0005998472915962338
Epoch:  116  	Training Loss: 0.0005294580478221178
Test Loss:  0.0005429998273029923
Valid Loss:  0.0005967955803498626
Epoch:  117  	Training Loss: 0.000526915886439383
Test Loss:  0.0005424102419055998
Valid Loss:  0.0005939975962974131
Epoch:  118  	Training Loss: 0.0005243520718067884
Test Loss:  0.0005414938204921782
Valid Loss:  0.000591423362493515
Epoch:  119  	Training Loss: 0.0005218407022766769
Test Loss:  0.000540209177415818
Valid Loss:  0.0005890844622626901
Epoch:  120  	Training Loss: 0.0005193554679863155
Test Loss:  0.0005386373377405107
Valid Loss:  0.000586898357141763
Epoch:  121  	Training Loss: 0.0005169096984900534
Test Loss:  0.000536814914084971
Valid Loss:  0.0005847298307344317
Epoch:  122  	Training Loss: 0.0005145122995600104
Test Loss:  0.0005171734374016523
Valid Loss:  0.000567631097510457
Epoch:  123  	Training Loss: 0.0004985742270946503
Test Loss:  0.0004985989071428776
Valid Loss:  0.0005522030987776816
Epoch:  124  	Training Loss: 0.0004840067704208195
Test Loss:  0.00048109263298101723
Valid Loss:  0.0005382865783758461
Epoch:  125  	Training Loss: 0.0004705931060016155
Test Loss:  0.00046463037142530084
Valid Loss:  0.0005256742006167769
Epoch:  126  	Training Loss: 0.00045824964763596654
Test Loss:  0.0004492766165640205
Valid Loss:  0.0005142008303664625
Epoch:  127  	Training Loss: 0.0004468928091228008
Test Loss:  0.00043496035505086184
Valid Loss:  0.0005037311348132789
Epoch:  128  	Training Loss: 0.0004364478518255055
Test Loss:  0.0004218131653033197
Valid Loss:  0.0004941305378451943
Epoch:  129  	Training Loss: 0.0004268412012606859
Test Loss:  0.00040954205906018615
Valid Loss:  0.0004853123682551086
Epoch:  130  	Training Loss: 0.00041795321158133447
Test Loss:  0.0003981884219683707
Valid Loss:  0.00047715066466480494
Epoch:  131  	Training Loss: 0.0004097511409781873
Test Loss:  0.00038754561683163047
Valid Loss:  0.0004697525582741946
Epoch:  132  	Training Loss: 0.0004020741325803101
Test Loss:  0.00038987607695162296
Valid Loss:  0.0004683894803747535
Epoch:  133  	Training Loss: 0.0004013440920971334
Test Loss:  0.00039197056321427226
Valid Loss:  0.0004672620561905205
Epoch:  134  	Training Loss: 0.0004007697571069002
Test Loss:  0.00039384246338158846
Valid Loss:  0.00046633119927719235
Epoch:  135  	Training Loss: 0.0004003217618446797
Test Loss:  0.00039547524647787213
Valid Loss:  0.00046556253801099956
Epoch:  136  	Training Loss: 0.000399970420403406
Test Loss:  0.00039683247450739145
Valid Loss:  0.0004649476904887706
Epoch:  137  	Training Loss: 0.00039970962097868323
Test Loss:  0.00039797407225705683
Valid Loss:  0.0004644505097530782
Epoch:  138  	Training Loss: 0.00039950833888724446
Test Loss:  0.00039885786827653646
Valid Loss:  0.00046406086767092347
Epoch:  139  	Training Loss: 0.0003993504506070167
Test Loss:   28%|██▊       | 139/500 [01:43<02:01,  2.96it/s] 28%|██▊       | 141/500 [01:50<07:05,  1.18s/it] 29%|██▊       | 143/500 [01:50<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:50<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:50<02:43,  2.16it/s] 30%|██▉       | 149/500 [01:50<02:01,  2.88it/s] 30%|███       | 151/500 [01:57<06:56,  1.19s/it] 31%|███       | 153/500 [01:57<04:57,  1.17it/s] 31%|███       | 155/500 [01:57<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:57<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:57<01:55,  2.95it/s] 32%|███▏      | 161/500 [02:04<06:45,  1.20s/it] 33%|███▎      | 163/500 [02:04<04:49,  1.16it/s] 33%|███▎      | 165/500 [02:04<03:28,  1.61it/s] 33%|███▎      | 167/500 [02:04<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:04<01:52,  2.96it/s] 34%|███▍      | 171/500 [02:11<06:39,  1.21s/it] 35%|███▍      | 173/500 [02:11<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:11<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:11<02:29,  2.17it/s] 36%|███▌      | 179/500 [02:11<01:50,  2.89it/s] 36%|███▌      | 181/500 [02:18<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:18<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:18<03:17,  1.59it/s] 37%|███▋      | 187/500 [02:18<02:23,  2.18it/s] 38%|███▊      | 189/500 [02:18<01:46,  2.93it/s] 38%|███▊      | 191/500 [02:25<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:25<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:25<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:25<02:20,  2.15it/s] 40%|███▉      | 199/500 [02:25<01:43,  2.90it/s] 40%|████      | 201/500 [02:32<06:00,  1.21s/it] 41%|████      | 203/500 [02:32<04:18,  1.15it/s] 41%|████      | 205/500 [02:32<03:07,  1.58it/s]0.00039962149458006024
Valid Loss:  0.00046372401993721724
Epoch:  140  	Training Loss: 0.00039921572897583246
Test Loss:  0.00040027842624112964
Valid Loss:  0.00046343629946932197
Epoch:  141  	Training Loss: 0.00039910111809149384
Test Loss:  0.0004008447576779872
Valid Loss:  0.00046318586100824177
Epoch:  142  	Training Loss: 0.0003990014083683491
Test Loss:  0.00039064898737706244
Valid Loss:  0.0004598907835315913
Epoch:  143  	Training Loss: 0.0003847964107990265
Test Loss:  0.0003815289819613099
Valid Loss:  0.0004524212854448706
Epoch:  144  	Training Loss: 0.00037583208177238703
Test Loss:  0.00037230379530228674
Valid Loss:  0.0004453402361832559
Epoch:  145  	Training Loss: 0.00036811985773965716
Test Loss:  0.00036283902591094375
Valid Loss:  0.0004380292375572026
Epoch:  146  	Training Loss: 0.0003612716682255268
Test Loss:  0.0003538807504810393
Valid Loss:  0.0004320777370594442
Epoch:  147  	Training Loss: 0.00035516716889105737
Test Loss:  0.00034535559825599194
Valid Loss:  0.00042731777648441494
Epoch:  148  	Training Loss: 0.00034964337828569114
Test Loss:  0.00033748039277270436
Valid Loss:  0.00042342397500760853
Epoch:  149  	Training Loss: 0.0003446636546868831
Test Loss:  0.000329869071720168
Valid Loss:  0.0004193682107143104
Epoch:  150  	Training Loss: 0.0003400369605515152
Test Loss:  0.00032304396154358983
Valid Loss:  0.00041673070518299937
Epoch:  151  	Training Loss: 0.00033565465128049254
Test Loss:  0.00031651664176024497
Valid Loss:  0.0004132455796934664
Epoch:  152  	Training Loss: 0.000331623392412439
Test Loss:  0.00031431630486622453
Valid Loss:  0.00041317264549434185
Epoch:  153  	Training Loss: 0.00032750400714576244
Test Loss:  0.00031233191839419305
Valid Loss:  0.0004131532914470881
Epoch:  154  	Training Loss: 0.0003241528174839914
Test Loss:  0.0003105163632426411
Valid Loss:  0.00041321743628941476
Epoch:  155  	Training Loss: 0.0003216154291294515
Test Loss:  0.0003088337543886155
Valid Loss:  0.00041319074807688594
Epoch:  156  	Training Loss: 0.0003197654150426388
Test Loss:  0.0003073306870646775
Valid Loss:  0.000413312460295856
Epoch:  157  	Training Loss: 0.00031817780109122396
Test Loss:  0.00030599726596847177
Valid Loss:  0.0004133764305151999
Epoch:  158  	Training Loss: 0.0003169203700963408
Test Loss:  0.0003048111102543771
Valid Loss:  0.00041335445712320507
Epoch:  159  	Training Loss: 0.00031594058964401484
Test Loss:  0.00030368100851774216
Valid Loss:  0.00041328970110043883
Epoch:  160  	Training Loss: 0.00031506665982306004
Test Loss:  0.0003026014310307801
Valid Loss:  0.00041319188312627375
Epoch:  161  	Training Loss: 0.00031425192719325423
Test Loss:  0.0003016053233295679
Valid Loss:  0.0004131543973926455
Epoch:  162  	Training Loss: 0.0003136484301649034
Test Loss:  0.00029948048177175224
Valid Loss:  0.0004084993852302432
Epoch:  163  	Training Loss: 0.00031170633155852556
Test Loss:  0.0002984548336826265
Valid Loss:  0.0004063668311573565
Epoch:  164  	Training Loss: 0.0003101847250945866
Test Loss:  0.00029758125310763717
Valid Loss:  0.00040455209091305733
Epoch:  165  	Training Loss: 0.00030881044222041965
Test Loss:  0.0002962846483569592
Valid Loss:  0.00040174086461775005
Epoch:  166  	Training Loss: 0.0003076464927289635
Test Loss:  0.00029587314929813147
Valid Loss:  0.0004008038667961955
Epoch:  167  	Training Loss: 0.00030654878355562687
Test Loss:  0.00029493309557437897
Valid Loss:  0.0003986508818343282
Epoch:  168  	Training Loss: 0.00030556105775758624
Test Loss:  0.0002942191786132753
Valid Loss:  0.0003969393437728286
Epoch:  169  	Training Loss: 0.0003046895726583898
Test Loss:  0.0002936632663477212
Valid Loss:  0.0003955356660299003
Epoch:  170  	Training Loss: 0.0003038948052562773
Test Loss:  0.00029320025350898504
Valid Loss:  0.00039435274084098637
Epoch:  171  	Training Loss: 0.0003031581290997565
Test Loss:  0.0002928149187937379
Valid Loss:  0.00039340107468888164
Epoch:  172  	Training Loss: 0.0003024939796887338
Test Loss:  0.00029049720615148544
Valid Loss:  0.0003929691156372428
Epoch:  173  	Training Loss: 0.0003010861692018807
Test Loss:  0.00028780728462152183
Valid Loss:  0.0003910117084160447
Epoch:  174  	Training Loss: 0.0002998359559569508
Test Loss:  0.00028574810130521655
Valid Loss:  0.00039086613105610013
Epoch:  175  	Training Loss: 0.0002985640021506697
Test Loss:  0.00028347078477963805
Valid Loss:  0.00038985631545074284
Epoch:  176  	Training Loss: 0.00029736547730863094
Test Loss:  0.0002815418120007962
Valid Loss:  0.00038968585431575775
Epoch:  177  	Training Loss: 0.0002962496364489198
Test Loss:  0.00027899257838726044
Valid Loss:  0.0003873117675539106
Epoch:  178  	Training Loss: 0.00029520041425712407
Test Loss:  0.0002773094456642866
Valid Loss:  0.00038747256621718407
Epoch:  179  	Training Loss: 0.00029407429974526167
Test Loss:  0.0002755256136879325
Valid Loss:  0.0003866868792101741
Epoch:  180  	Training Loss: 0.00029313418781384826
Test Loss:  0.0002736424212343991
Valid Loss:  0.00038525473792105913
Epoch:  181  	Training Loss: 0.0002922502753790468
Test Loss:  0.00027240824420005083
Valid Loss:  0.0003855143440887332
Epoch:  182  	Training Loss: 0.00029139372054487467
Test Loss:  0.00026961590629070997
Valid Loss:  0.0003863269812427461
Epoch:  183  	Training Loss: 0.0002906586742028594
Test Loss:  0.0002674325951375067
Valid Loss:  0.0003868930507451296
Epoch:  184  	Training Loss: 0.0002901331754401326
Test Loss:  0.00026567274471744895
Valid Loss:  0.0003872747183777392
Epoch:  185  	Training Loss: 0.00028973084408789873
Test Loss:  0.0002642098115757108
Valid Loss:  0.00038748953375034034
Epoch:  186  	Training Loss: 0.0002894042991101742
Test Loss:  0.0002629920491017401
Valid Loss:  0.00038766575744375587
Epoch:  187  	Training Loss: 0.00028914777794852853
Test Loss:  0.00026195551618002355
Valid Loss:  0.00038770929677411914
Epoch:  188  	Training Loss: 0.0002889168099500239
Test Loss:  0.0002610482624731958
Valid Loss:  0.00038769797538407147
Epoch:  189  	Training Loss: 0.0002887110458686948
Test Loss:  0.0002602528256829828
Valid Loss:  0.00038761310861445963
Epoch:  190  	Training Loss: 0.0002885142166633159
Test Loss:  0.00025952034047804773
Valid Loss:  0.00038748019142076373
Epoch:  191  	Training Loss: 0.00028833351098001003
Test Loss:  0.0002588461502455175
Valid Loss:  0.0003873936366289854
Epoch:  192  	Training Loss: 0.0002881796099245548
Test Loss:  0.0002568755007814616
Valid Loss:  0.0003880751901306212
Epoch:  193  	Training Loss: 0.000285276590147987
Test Loss:  0.0002559517160989344
Valid Loss:  0.0003886303456965834
Epoch:  194  	Training Loss: 0.00028217973886057734
Test Loss:  0.0002560639986768365
Valid Loss:  0.0003904164186678827
Epoch:  195  	Training Loss: 0.0002815350890159607
Test Loss:  0.0002546801115386188
Valid Loss:  0.00038752990076318383
Epoch:  196  	Training Loss: 0.0002812313032336533
Test Loss:  0.00025479585747234523
Valid Loss:  0.00038944013067521155
Epoch:  197  	Training Loss: 0.00028033729176968336
Test Loss:  0.00025347198243252933
Valid Loss:  0.000386695668566972
Epoch:  198  	Training Loss: 0.0002801927912514657
Test Loss:  0.00025375004042871296
Valid Loss:  0.0003890423977281898
Epoch:  199  	Training Loss: 0.00027944016619585454
Test Loss:  0.00025238707894459367
Valid Loss:  0.00038600509287789464
Epoch:  200  	Training Loss: 0.0002790545695461333
Test Loss:  0.0002526647876948118
Valid Loss:  0.0003882775199599564
Epoch:  201  	Training Loss: 0.00027845287695527077
Test Loss:  0.0002513574727345258
Valid Loss:  0.00038530645542778075
Epoch:  202  	Training Loss: 0.0002780752838589251
Test Loss:  0.000252196507062763
Valid Loss:  0.00038375696749426425
Epoch:  203  	Training Loss: 0.00027722481172531843
Test Loss:  0.0002528613549657166
Valid Loss:  0.00038244345341809094
Epoch:  204  	Training Loss: 0.0002764826931525022
Test Loss:  0.00025346793700009584
Valid Loss:  0.00038129196036607027
Epoch:  205  	Training Loss: 0.0002758346381597221
Test Loss:  0.00025389832444489
Valid Loss:  0.00038031506119295955
Epoch:  206  	Training Loss: 0.0002752586442511529
Test Loss:  0.00025427096989005804
Valid Loss:  0.0003794471558649093
 41%|████▏     | 207/500 [02:32<02:15,  2.16it/s] 42%|████▏     | 209/500 [02:32<01:40,  2.90it/s] 42%|████▏     | 211/500 [02:39<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:39<04:08,  1.15it/s] 43%|████▎     | 214/500 [02:39<03:29,  1.36it/s] 43%|████▎     | 216/500 [02:39<02:26,  1.94it/s] 44%|████▎     | 218/500 [02:39<01:44,  2.70it/s] 44%|████▍     | 220/500 [02:39<01:16,  3.65it/s] 44%|████▍     | 222/500 [02:46<05:31,  1.19s/it] 45%|████▍     | 224/500 [02:46<03:53,  1.18it/s] 45%|████▌     | 226/500 [02:46<02:46,  1.64it/s] 46%|████▌     | 228/500 [02:46<02:00,  2.25it/s] 46%|████▌     | 230/500 [02:46<01:29,  3.03it/s] 46%|████▋     | 232/500 [02:53<05:23,  1.21s/it] 47%|████▋     | 234/500 [02:53<03:49,  1.16it/s] 47%|████▋     | 236/500 [02:53<02:44,  1.61it/s] 48%|████▊     | 238/500 [02:53<01:59,  2.20it/s] 48%|████▊     | 240/500 [02:53<01:27,  2.96it/s] 48%|████▊     | 242/500 [03:00<05:16,  1.23s/it] 49%|████▉     | 244/500 [03:00<03:45,  1.14it/s] 49%|████▉     | 246/500 [03:00<02:41,  1.57it/s] 50%|████▉     | 248/500 [03:00<01:57,  2.15it/s] 50%|█████     | 250/500 [03:01<01:26,  2.88it/s] 50%|█████     | 252/500 [03:07<04:56,  1.19s/it] 51%|█████     | 254/500 [03:07<03:30,  1.17it/s] 51%|█████     | 256/500 [03:07<02:31,  1.62it/s] 52%|█████▏    | 258/500 [03:07<01:49,  2.20it/s] 52%|█████▏    | 260/500 [03:07<01:21,  2.96it/s] 52%|█████▏    | 262/500 [03:14<04:43,  1.19s/it] 53%|█████▎    | 264/500 [03:14<03:23,  1.16it/s] 53%|█████▎    | 266/500 [03:14<02:27,  1.59it/s] 54%|█████▎    | 268/500 [03:14<01:47,  2.16it/s] 54%|█████▍    | 270/500 [03:14<01:18,  2.91it/s] 54%|█████▍    | 272/500 [03:21<04:39,  1.22s/it]Epoch:  207  	Training Loss: 0.0002747474645730108
Test Loss:  0.00025455644936300814
Valid Loss:  0.0003786809102166444
Epoch:  208  	Training Loss: 0.0002742678625509143
Test Loss:  0.000254773156484589
Valid Loss:  0.00037809027708135545
Epoch:  209  	Training Loss: 0.00027381457039155066
Test Loss:  0.0002549193159211427
Valid Loss:  0.0003775448421947658
Epoch:  210  	Training Loss: 0.0002733764995355159
Test Loss:  0.00025503840879537165
Valid Loss:  0.0003770349139813334
Epoch:  211  	Training Loss: 0.0002729501575231552
Test Loss:  0.00025510150589980185
Valid Loss:  0.0003765719593502581
Epoch:  212  	Training Loss: 0.0002725348749663681
Test Loss:  0.00025451183319091797
Valid Loss:  0.00037642987444996834
Epoch:  213  	Training Loss: 0.00027213545399717987
Test Loss:  0.0002539657289162278
Valid Loss:  0.0003763678832910955
Epoch:  214  	Training Loss: 0.00027175561990588903
Test Loss:  0.0002534224186092615
Valid Loss:  0.00037629861617460847
Epoch:  215  	Training Loss: 0.00027138087898492813
Test Loss:  0.0002528841432649642
Valid Loss:  0.0003762226551771164
Epoch:  216  	Training Loss: 0.00027101009618490934
Test Loss:  0.00025234962231479585
Valid Loss:  0.00037614163011312485
Epoch:  217  	Training Loss: 0.0002706438535824418
Test Loss:  0.00025181876844726503
Valid Loss:  0.0003760536201298237
Epoch:  218  	Training Loss: 0.000270291231572628
Test Loss:  0.000251264515100047
Valid Loss:  0.0003758988459594548
Epoch:  219  	Training Loss: 0.0002699497854337096
Test Loss:  0.000250733777647838
Valid Loss:  0.00037574663292616606
Epoch:  220  	Training Loss: 0.0002696251613087952
Test Loss:  0.0002502085408195853
Valid Loss:  0.0003755934885703027
Epoch:  221  	Training Loss: 0.0002693031565286219
Test Loss:  0.00024968833895400167
Valid Loss:  0.00037543935468420386
Epoch:  222  	Training Loss: 0.0002689880202524364
Test Loss:  0.000248991564149037
Valid Loss:  0.0003753490746021271
Epoch:  223  	Training Loss: 0.00026870943838730454
Test Loss:  0.0002483490970917046
Valid Loss:  0.0003752679331228137
Epoch:  224  	Training Loss: 0.0002684603969100863
Test Loss:  0.000247727963142097
Valid Loss:  0.000375191040802747
Epoch:  225  	Training Loss: 0.0002682217163965106
Test Loss:  0.00024714841856621206
Valid Loss:  0.00037511796108447015
Epoch:  226  	Training Loss: 0.000267992407316342
Test Loss:  0.0002466132864356041
Valid Loss:  0.0003750469768419862
Epoch:  227  	Training Loss: 0.0002677722950465977
Test Loss:  0.00024609529646113515
Valid Loss:  0.0003749810275621712
Epoch:  228  	Training Loss: 0.00026756088482216
Test Loss:  0.00024559401208534837
Valid Loss:  0.0003749174647964537
Epoch:  229  	Training Loss: 0.000267357740085572
Test Loss:  0.000245109258685261
Valid Loss:  0.00037485675420612097
Epoch:  230  	Training Loss: 0.00026716283173300326
Test Loss:  0.00024464045418426394
Valid Loss:  0.0003748015151359141
Epoch:  231  	Training Loss: 0.00026697557768784463
Test Loss:  0.0002442211261950433
Valid Loss:  0.0003747859736904502
Epoch:  232  	Training Loss: 0.00026679562870413065
Test Loss:  0.0002423359837848693
Valid Loss:  0.0003715840866789222
Epoch:  233  	Training Loss: 0.0002648424415383488
Test Loss:  0.00024069749633781612
Valid Loss:  0.00036881110281683505
Epoch:  234  	Training Loss: 0.0002632116083987057
Test Loss:  0.00023922247055452317
Valid Loss:  0.0003663402749225497
Epoch:  235  	Training Loss: 0.00026180618442595005
Test Loss:  0.0002378567005507648
Valid Loss:  0.0003641282964963466
Epoch:  236  	Training Loss: 0.00026057445211336017
Test Loss:  0.00023657262499909848
Valid Loss:  0.00036214530700817704
Epoch:  237  	Training Loss: 0.00025948788970708847
Test Loss:  0.0002353626914555207
Valid Loss:  0.00036036327946931124
Epoch:  238  	Training Loss: 0.0002585211768746376
Test Loss:  0.00023422070080414414
Valid Loss:  0.00035874886089004576
Epoch:  239  	Training Loss: 0.0002576509432401508
Test Loss:  0.00023313461861107498
Valid Loss:  0.00035728191141970456
Epoch:  240  	Training Loss: 0.0002568655472714454
Test Loss:  0.00023208919446915388
Valid Loss:  0.00035594182554632425
Epoch:  241  	Training Loss: 0.0002561521832831204
Test Loss:  0.0002310883137397468
Valid Loss:  0.00035474373726174235
Epoch:  242  	Training Loss: 0.00025550657301209867
Test Loss:  0.0002301910426467657
Valid Loss:  0.00035936228232458234
Epoch:  243  	Training Loss: 0.0002542525762692094
Test Loss:  0.00022794405231252313
Valid Loss:  0.0003557527670636773
Epoch:  244  	Training Loss: 0.0002534619125071913
Test Loss:  0.0002279714390169829
Valid Loss:  0.00035956501960754395
Epoch:  245  	Training Loss: 0.00025285701849497855
Test Loss:  0.00022617483045905828
Valid Loss:  0.00035580346593633294
Epoch:  246  	Training Loss: 0.00025215305504389107
Test Loss:  0.00022644258569926023
Valid Loss:  0.00035920311347581446
Epoch:  247  	Training Loss: 0.0002516061067581177
Test Loss:  0.00022490799892693758
Valid Loss:  0.0003555145231075585
Epoch:  248  	Training Loss: 0.000251124263741076
Test Loss:  0.00022513899602927268
Valid Loss:  0.0003584202495403588
Epoch:  249  	Training Loss: 0.00025035906583070755
Test Loss:  0.00022384770272765309
Valid Loss:  0.00035563280107453465
Epoch:  250  	Training Loss: 0.0002497853711247444
Test Loss:  0.0002243207854917273
Valid Loss:  0.000358735240297392
Epoch:  251  	Training Loss: 0.00024956726701930165
Test Loss:  0.00022292087669484317
Valid Loss:  0.00035500223748385906
Epoch:  252  	Training Loss: 0.00024919924908317626
Test Loss:  0.00022246406297199428
Valid Loss:  0.0003545811050571501
Epoch:  253  	Training Loss: 0.0002483135904185474
Test Loss:  0.00022156265913508832
Valid Loss:  0.00035306031350046396
Epoch:  254  	Training Loss: 0.0002474887005519122
Test Loss:  0.00022073533909860998
Valid Loss:  0.00035198565456084907
Epoch:  255  	Training Loss: 0.00024672551080584526
Test Loss:  0.0002199457085225731
Valid Loss:  0.0003511718241497874
Epoch:  256  	Training Loss: 0.0002459987881593406
Test Loss:  0.0002192102838307619
Valid Loss:  0.0003504956257529557
Epoch:  257  	Training Loss: 0.0002453262568451464
Test Loss:  0.0002181211020797491
Valid Loss:  0.0003488276561256498
Epoch:  258  	Training Loss: 0.0002447080332785845
Test Loss:  0.00021753585315309465
Valid Loss:  0.00034870230592787266
Epoch:  259  	Training Loss: 0.00024405366275459528
Test Loss:  0.0002169210056308657
Valid Loss:  0.0003485080087557435
Epoch:  260  	Training Loss: 0.00024345688871107996
Test Loss:  0.00021592705161310732
Valid Loss:  0.0003470696392469108
Epoch:  261  	Training Loss: 0.0002428960578981787
Test Loss:  0.00021541460591834038
Valid Loss:  0.00034721000702120364
Epoch:  262  	Training Loss: 0.00024231949646491557
Test Loss:  0.00021733387256972492
Valid Loss:  0.00035246298648416996
Epoch:  263  	Training Loss: 0.00024167577794287354
Test Loss:  0.00021639495389536023
Valid Loss:  0.00034993147710338235
Epoch:  264  	Training Loss: 0.00024132670660037547
Test Loss:  0.00021778111113235354
Valid Loss:  0.0003536036529112607
Epoch:  265  	Training Loss: 0.00024130710517056286
Test Loss:  0.00021673491573892534
Valid Loss:  0.00035092528560198843
Epoch:  266  	Training Loss: 0.00024114566622301936
Test Loss:  0.0002179088769480586
Valid Loss:  0.0003539837198331952
Epoch:  267  	Training Loss: 0.00024101273447740823
Test Loss:  0.00021697244665119797
Valid Loss:  0.00035173402284272015
Epoch:  268  	Training Loss: 0.00024092363310046494
Test Loss:  0.00021803152048960328
Valid Loss:  0.00035445255343802273
Epoch:  269  	Training Loss: 0.0002409124281257391
Test Loss:  0.00021700223442167044
Valid Loss:  0.0003519526799209416
Epoch:  270  	Training Loss: 0.00024086411576718092
Test Loss:  0.0002179816656280309
Valid Loss:  0.00035442665102891624
Epoch:  271  	Training Loss: 0.00024074813700281084
Test Loss:  0.0002169942599721253
Valid Loss:  0.0003520071040838957
Epoch:  272  	Training Loss: 0.00024084518372546881
Test Loss:  0.00021560075401794165
Valid Loss:  0.00035123247653245926
Epoch:  273  	Training Loss: 0.00024003924045246094
Test Loss:  0.00021426973398774862
Valid Loss:  0.0003505009226500988
Epoch:  274  	Training Loss: 0.00023926605354063213
Test Loss:  55%|█████▍    | 274/500 [03:21<03:19,  1.13it/s] 55%|█████▌    | 276/500 [03:21<02:24,  1.55it/s] 56%|█████▌    | 278/500 [03:22<01:45,  2.10it/s] 56%|█████▌    | 280/500 [03:22<01:17,  2.83it/s] 56%|█████▋    | 282/500 [03:28<04:26,  1.22s/it] 57%|█████▋    | 284/500 [03:28<03:08,  1.14it/s] 57%|█████▋    | 286/500 [03:28<02:15,  1.58it/s] 58%|█████▊    | 288/500 [03:29<01:39,  2.14it/s] 58%|█████▊    | 290/500 [03:29<01:14,  2.84it/s] 58%|█████▊    | 292/500 [03:35<04:12,  1.22s/it] 59%|█████▉    | 294/500 [03:35<02:59,  1.15it/s] 59%|█████▉    | 296/500 [03:35<02:08,  1.59it/s] 60%|█████▉    | 298/500 [03:36<01:32,  2.17it/s] 60%|██████    | 300/500 [03:36<01:08,  2.92it/s] 60%|██████    | 302/500 [03:42<03:57,  1.20s/it] 61%|██████    | 304/500 [03:42<02:48,  1.16it/s] 61%|██████    | 306/500 [03:42<02:00,  1.61it/s] 62%|██████▏   | 308/500 [03:43<01:27,  2.19it/s] 62%|██████▏   | 310/500 [03:49<04:03,  1.28s/it] 62%|██████▏   | 311/500 [03:55<06:51,  2.18s/it] 63%|██████▎   | 313/500 [03:55<04:36,  1.48s/it] 63%|██████▎   | 315/500 [03:56<03:10,  1.03s/it] 63%|██████▎   | 317/500 [03:56<02:13,  1.37it/s] 64%|██████▍   | 319/500 [03:56<01:35,  1.89it/s] 64%|██████▍   | 321/500 [04:02<03:59,  1.34s/it] 65%|██████▍   | 323/500 [04:02<02:48,  1.05it/s] 65%|██████▌   | 325/500 [04:03<01:59,  1.47it/s] 65%|██████▌   | 327/500 [04:03<01:25,  2.02it/s] 66%|██████▌   | 329/500 [04:03<01:02,  2.73it/s] 66%|██████▌   | 331/500 [04:09<03:26,  1.22s/it] 67%|██████▋   | 333/500 [04:09<02:26,  1.14it/s] 67%|██████▋   | 335/500 [04:10<01:44,  1.58it/s] 67%|██████▋   | 337/500 [04:10<01:15,  2.15it/s] 68%|██████▊   | 339/500 [04:10<00:55,  2.90it/s] 0.00021296598424669355
Valid Loss:  0.00034973688889294863
Epoch:  275  	Training Loss: 0.00023853903985582292
Test Loss:  0.00021171857952140272
Valid Loss:  0.0003490711096674204
Epoch:  276  	Training Loss: 0.00023785819939803332
Test Loss:  0.0002105244348058477
Valid Loss:  0.00034843632602132857
Epoch:  277  	Training Loss: 0.00023720272292848676
Test Loss:  0.00020940348622389138
Valid Loss:  0.00034783052979037166
Epoch:  278  	Training Loss: 0.0002365702821407467
Test Loss:  0.0002083487925119698
Valid Loss:  0.0003472500538919121
Epoch:  279  	Training Loss: 0.00023596675600856543
Test Loss:  0.00020731965196318924
Valid Loss:  0.0003466563066467643
Epoch:  280  	Training Loss: 0.00023539837275166065
Test Loss:  0.00020633911481127143
Valid Loss:  0.00034609835711307824
Epoch:  281  	Training Loss: 0.0002348505222471431
Test Loss:  0.00020540985860861838
Valid Loss:  0.000345567794283852
Epoch:  282  	Training Loss: 0.0002343253727303818
Test Loss:  0.00020565700833685696
Valid Loss:  0.0003462563909124583
Epoch:  283  	Training Loss: 0.00023419896024279296
Test Loss:  0.00020587278413586318
Valid Loss:  0.0003468642244115472
Epoch:  284  	Training Loss: 0.0002341131039429456
Test Loss:  0.00020600995048880577
Valid Loss:  0.00034728884929791093
Epoch:  285  	Training Loss: 0.00023405018146149814
Test Loss:  0.00020609021885320544
Valid Loss:  0.00034758448600769043
Epoch:  286  	Training Loss: 0.00023399811470881104
Test Loss:  0.0002061324194073677
Valid Loss:  0.0003477886784821749
Epoch:  287  	Training Loss: 0.0002339531492907554
Test Loss:  0.00020614870300050825
Valid Loss:  0.0003479310544207692
Epoch:  288  	Training Loss: 0.0002339153434149921
Test Loss:  0.00020620680879801512
Valid Loss:  0.00034815847175195813
Epoch:  289  	Training Loss: 0.00023388111731037498
Test Loss:  0.00020620635768864304
Valid Loss:  0.00034824799513444304
Epoch:  290  	Training Loss: 0.00023384904488921165
Test Loss:  0.0002062243438558653
Valid Loss:  0.0003483788459561765
Epoch:  291  	Training Loss: 0.00023381876235362142
Test Loss:  0.00020619861606974155
Valid Loss:  0.0003484056214801967
Epoch:  292  	Training Loss: 0.00023379066260531545
Test Loss:  0.00020571533241309226
Valid Loss:  0.0003483336477074772
Epoch:  293  	Training Loss: 0.0002335821045562625
Test Loss:  0.00020528779714368284
Valid Loss:  0.0003482132451608777
Epoch:  294  	Training Loss: 0.00023337945458479226
Test Loss:  0.00020489879534579813
Valid Loss:  0.0003480569866951555
Epoch:  295  	Training Loss: 0.00023318117018789053
Test Loss:  0.00020454442710615695
Valid Loss:  0.00034787412732839584
Epoch:  296  	Training Loss: 0.00023298671294469386
Test Loss:  0.00020421369117684662
Valid Loss:  0.00034767267061397433
Epoch:  297  	Training Loss: 0.00023279470042325556
Test Loss:  0.0002039138344116509
Valid Loss:  0.00034745654556900263
Epoch:  298  	Training Loss: 0.00023260523448698223
Test Loss:  0.0002036292280536145
Valid Loss:  0.00034723104909062386
Epoch:  299  	Training Loss: 0.00023241809685714543
Test Loss:  0.00020335291628725827
Valid Loss:  0.00034700502874329686
Epoch:  300  	Training Loss: 0.00023223318567033857
Test Loss:  0.00020308440434746444
Valid Loss:  0.0003467786591500044
Epoch:  301  	Training Loss: 0.00023205022444017231
Test Loss:  0.00020282257173676044
Valid Loss:  0.00034657047945074737
Epoch:  302  	Training Loss: 0.0002318692277185619
Test Loss:  0.00020431028679013252
Valid Loss:  0.00034648372093215585
Epoch:  303  	Training Loss: 0.00023103615967556834
Test Loss:  0.00020397455955389887
Valid Loss:  0.00034289827453903854
Epoch:  304  	Training Loss: 0.00023079014499671757
Test Loss:  0.00020474012126214802
Valid Loss:  0.0003443791065365076
Epoch:  305  	Training Loss: 0.0002303841756656766
Test Loss:  0.0002038586389971897
Valid Loss:  0.00034171721199527383
Epoch:  306  	Training Loss: 0.00023016735212877393
Test Loss:  0.00020454396144486964
Valid Loss:  0.0003438238927628845
Epoch:  307  	Training Loss: 0.00023007973504718393
Test Loss:  0.00020343923824839294
Valid Loss:  0.00034093260182999074
Epoch:  308  	Training Loss: 0.0002297076425747946
Test Loss:  0.00020401642541401088
Valid Loss:  0.00034323817817494273
Epoch:  309  	Training Loss: 0.0002297579776495695
Test Loss:  0.00020311822299845517
Valid Loss:  0.0003401542198844254
Epoch:  310  	Training Loss: 0.0002293736906722188
Test Loss:  0.00020365265663713217
Valid Loss:  0.0003427205956541002
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.00022940579219721258
Test Loss:  0.00020366971148177981
Valid Loss:  0.00034269498428329825
Epoch:  312  	Training Loss: 0.0002291582350153476
Test Loss:  0.00020273419795557857
Valid Loss:  0.00034121127100661397
Epoch:  313  	Training Loss: 0.00022850984532851726
Test Loss:  0.00020220789883751422
Valid Loss:  0.0003410418576095253
Epoch:  314  	Training Loss: 0.00022820389131084085
Test Loss:  0.0002020130486926064
Valid Loss:  0.00034113461151719093
Epoch:  315  	Training Loss: 0.00022790953516960144
Test Loss:  0.00020166640751995146
Valid Loss:  0.00034118397161364555
Epoch:  316  	Training Loss: 0.00022762508888263255
Test Loss:  0.00020142333232797682
Valid Loss:  0.00034115725429728627
Epoch:  317  	Training Loss: 0.00022735018865205348
Test Loss:  0.00020112181664444506
Valid Loss:  0.00034110277192667127
Epoch:  318  	Training Loss: 0.00022707936295773834
Test Loss:  0.0002008317969739437
Valid Loss:  0.0003410112694837153
Epoch:  319  	Training Loss: 0.00022681296104565263
Test Loss:  0.00020055315690115094
Valid Loss:  0.00034089264227077365
Epoch:  320  	Training Loss: 0.00022655053180642426
Test Loss:  0.0002003599365707487
Valid Loss:  0.00034074063296429813
Epoch:  321  	Training Loss: 0.00022629086743108928
Test Loss:  0.00020009205036330968
Valid Loss:  0.00034060055622830987
Epoch:  322  	Training Loss: 0.00022603441902901977
Test Loss:  0.00019961828365921974
Valid Loss:  0.0003403601294849068
Epoch:  323  	Training Loss: 0.00022581953089684248
Test Loss:  0.00019920372869819403
Valid Loss:  0.0003401966532692313
Epoch:  324  	Training Loss: 0.00022561437799595296
Test Loss:  0.000198886584257707
Valid Loss:  0.00034018344013020396
Epoch:  325  	Training Loss: 0.0002254155551781878
Test Loss:  0.00019852555124089122
Valid Loss:  0.00033999874722212553
Epoch:  326  	Training Loss: 0.00022522735525853932
Test Loss:  0.00019818524015136063
Valid Loss:  0.0003398166154511273
Epoch:  327  	Training Loss: 0.00022504269145429134
Test Loss:  0.00019786310440395027
Valid Loss:  0.000339637219440192
Epoch:  328  	Training Loss: 0.0002248637902084738
Test Loss:  0.0001974870392587036
Valid Loss:  0.0003394894301891327
Epoch:  329  	Training Loss: 0.0002246910153189674
Test Loss:  0.00019713505753315985
Valid Loss:  0.0003393366059754044
Epoch:  330  	Training Loss: 0.00022452205303125083
Test Loss:  0.0001968037395272404
Valid Loss:  0.00033918925328180194
Epoch:  331  	Training Loss: 0.00022435898426920176
Test Loss:  0.00019649488967843354
Valid Loss:  0.00033904059091582894
Epoch:  332  	Training Loss: 0.00022420129971578717
Test Loss:  0.00019640226673800498
Valid Loss:  0.0003390483034309
Epoch:  333  	Training Loss: 0.00022415808052755892
Test Loss:  0.0001963157847058028
Valid Loss:  0.0003390550846233964
Epoch:  334  	Training Loss: 0.00022411547251977026
Test Loss:  0.00019623353728093207
Valid Loss:  0.000339060730766505
Epoch:  335  	Training Loss: 0.00022407335927709937
Test Loss:  0.00019615348719526082
Valid Loss:  0.0003390653000678867
Epoch:  336  	Training Loss: 0.00022403188631869853
Test Loss:  0.0001960751978913322
Valid Loss:  0.00033906911266967654
Epoch:  337  	Training Loss: 0.00022399082081392407
Test Loss:  0.00019599846564233303
Valid Loss:  0.00033907117904163897
Epoch:  338  	Training Loss: 0.0002239503082819283
Test Loss:  0.00019592567696236074
Valid Loss:  0.0003390724305063486
Epoch:  339  	Training Loss: 0.0002239100431324914
Test Loss:  0.00019585553673096
Valid Loss:  0.00033907394390553236
Epoch:  340  	Training Loss: 0.00022387056378647685
Test Loss:  0.00019578712817747146
 68%|██████▊   | 341/500 [04:16<03:10,  1.20s/it] 69%|██████▊   | 343/500 [04:16<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:16<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:17<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:17<00:51,  2.95it/s] 70%|███████   | 351/500 [04:23<02:55,  1.18s/it] 71%|███████   | 353/500 [04:23<02:04,  1.18it/s] 71%|███████   | 355/500 [04:23<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:23<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:24<00:46,  3.00it/s] 72%|███████▏  | 361/500 [04:30<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:30<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:30<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:30<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:30<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:37<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:37<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:37<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:37<00:57,  2.14it/s] 76%|███████▌  | 379/500 [04:38<00:42,  2.84it/s] 76%|███████▌  | 381/500 [04:44<02:27,  1.24s/it] 77%|███████▋  | 383/500 [04:44<01:44,  1.12it/s] 77%|███████▋  | 385/500 [04:44<01:14,  1.55it/s] 77%|███████▋  | 387/500 [04:45<00:53,  2.09it/s] 78%|███████▊  | 389/500 [04:45<00:39,  2.78it/s] 78%|███████▊  | 391/500 [04:51<02:13,  1.22s/it] 79%|███████▊  | 393/500 [04:51<01:34,  1.13it/s] 79%|███████▉  | 395/500 [04:52<01:07,  1.55it/s] 79%|███████▉  | 397/500 [04:52<00:48,  2.12it/s] 80%|███████▉  | 399/500 [04:52<00:35,  2.86it/s] 80%|████████  | 401/500 [04:58<01:59,  1.21s/it] 81%|████████  | 403/500 [04:58<01:24,  1.15it/s] 81%|████████  | 405/500 [04:59<00:59,  1.60it/s]Valid Loss:  0.00033907254692167044
Epoch:  341  	Training Loss: 0.00022383122995961457
Test Loss:  0.0001957327185664326
Valid Loss:  0.0003390998754184693
Epoch:  342  	Training Loss: 0.00022379265283234417
Test Loss:  0.0001953188912011683
Valid Loss:  0.00033780813100747764
Epoch:  343  	Training Loss: 0.00022359135618899018
Test Loss:  0.00019504266674630344
Valid Loss:  0.00033716851612553
Epoch:  344  	Training Loss: 0.00022346709738485515
Test Loss:  0.00019478410831652582
Valid Loss:  0.00033667884417809546
Epoch:  345  	Training Loss: 0.00022336089750751853
Test Loss:  0.00019464062643237412
Valid Loss:  0.0003365231677889824
Epoch:  346  	Training Loss: 0.00022327728220261633
Test Loss:  0.00019450022955425084
Valid Loss:  0.0003363856812939048
Epoch:  347  	Training Loss: 0.0002231950784334913
Test Loss:  0.00019426437211222947
Valid Loss:  0.0003360360278747976
Epoch:  348  	Training Loss: 0.00022312681539915502
Test Loss:  0.00019424594938755035
Valid Loss:  0.0003362039278727025
Epoch:  349  	Training Loss: 0.00022303755395114422
Test Loss:  0.00019401873578317463
Valid Loss:  0.0003358575631864369
Epoch:  350  	Training Loss: 0.0002229592064395547
Test Loss:  0.00019400508608669043
Valid Loss:  0.0003360279370099306
Epoch:  351  	Training Loss: 0.00022288177569862455
Test Loss:  0.00019378098659217358
Valid Loss:  0.00033568276558071375
Epoch:  352  	Training Loss: 0.00022279318363871425
Test Loss:  0.0001937240012921393
Valid Loss:  0.0003358107933308929
Epoch:  353  	Training Loss: 0.00022268490283749998
Test Loss:  0.00019353919196873903
Valid Loss:  0.00033564044861122966
Epoch:  354  	Training Loss: 0.00022259022807702422
Test Loss:  0.00019348863861523569
Valid Loss:  0.0003357602399773896
Epoch:  355  	Training Loss: 0.0002224946510978043
Test Loss:  0.00019330982468090951
Valid Loss:  0.0003355775261297822
Epoch:  356  	Training Loss: 0.00022239607642404735
Test Loss:  0.00019326488836668432
Valid Loss:  0.00033568707294762135
Epoch:  357  	Training Loss: 0.00022231083130463958
Test Loss:  0.00019309206982143223
Valid Loss:  0.0003354961227159947
Epoch:  358  	Training Loss: 0.00022221190738491714
Test Loss:  0.00019293397781439126
Valid Loss:  0.00033531541703268886
Epoch:  359  	Training Loss: 0.00022212926705833524
Test Loss:  0.0001929105637827888
Valid Loss:  0.0003354334912728518
Epoch:  360  	Training Loss: 0.00022203863773029298
Test Loss:  0.00019275787053629756
Valid Loss:  0.000335256801918149
Epoch:  361  	Training Loss: 0.0002219511370640248
Test Loss:  0.0001927386038005352
Valid Loss:  0.0003353766514919698
Epoch:  362  	Training Loss: 0.00022187168360687792
Test Loss:  0.000192698891623877
Valid Loss:  0.00033545203041285276
Epoch:  363  	Training Loss: 0.00022182866814546287
Test Loss:  0.0001926471304614097
Valid Loss:  0.0003354960063006729
Epoch:  364  	Training Loss: 0.00022178869403433055
Test Loss:  0.00019259637338109314
Valid Loss:  0.00033553846878930926
Epoch:  365  	Training Loss: 0.00022174946207087487
Test Loss:  0.00019254605285823345
Valid Loss:  0.00033557647839188576
Epoch:  366  	Training Loss: 0.00022171204909682274
Test Loss:  0.00019247036834713072
Valid Loss:  0.00033555575646460056
Epoch:  367  	Training Loss: 0.0002216770371887833
Test Loss:  0.00019242170674260706
Valid Loss:  0.00033559120493009686
Epoch:  368  	Training Loss: 0.00022163998801261187
Test Loss:  0.00019234814681112766
Valid Loss:  0.00033556827111169696
Epoch:  369  	Training Loss: 0.00022160637308843434
Test Loss:  0.00019230104226153344
Valid Loss:  0.0003356003435328603
Epoch:  370  	Training Loss: 0.0002215699350927025
Test Loss:  0.0001922412629937753
Valid Loss:  0.0003356023516971618
Epoch:  371  	Training Loss: 0.00022153569443617016
Test Loss:  0.00019219500245526433
Valid Loss:  0.00033563136821612716
Epoch:  372  	Training Loss: 0.00022150280710775405
Test Loss:  0.00019229191821068525
Valid Loss:  0.00033595762215554714
Epoch:  373  	Training Loss: 0.00022140576038509607
Test Loss:  0.000192370789591223
Valid Loss:  0.0003362329152878374
Epoch:  374  	Training Loss: 0.00022131834703031927
Test Loss:  0.0001924328098539263
Valid Loss:  0.00033646455267444253
Epoch:  375  	Training Loss: 0.0002212379185948521
Test Loss:  0.000192480772966519
Valid Loss:  0.00033665663795545697
Epoch:  376  	Training Loss: 0.000221162976231426
Test Loss:  0.0001925170363392681
Valid Loss:  0.00033681507920846343
Epoch:  377  	Training Loss: 0.00022109205019660294
Test Loss:  0.00019254213839303702
Valid Loss:  0.0003369446494616568
Epoch:  378  	Training Loss: 0.00022102484945207834
Test Loss:  0.00019256025552749634
Valid Loss:  0.00033704983070492744
Epoch:  379  	Training Loss: 0.0002209642989328131
Test Loss:  0.00019257135863881558
Valid Loss:  0.0003371346683707088
Epoch:  380  	Training Loss: 0.00022090660058893263
Test Loss:  0.00019257637904956937
Valid Loss:  0.0003372025676071644
Epoch:  381  	Training Loss: 0.00022085022646933794
Test Loss:  0.00019257565145380795
Valid Loss:  0.0003372531500644982
Epoch:  382  	Training Loss: 0.00022079511836636811
Test Loss:  0.0001925297692650929
Valid Loss:  0.0003372397623024881
Epoch:  383  	Training Loss: 0.00022076572349760681
Test Loss:  0.000192484469152987
Valid Loss:  0.00033722748048603535
Epoch:  384  	Training Loss: 0.00022073680884204805
Test Loss:  0.00019243897986598313
Valid Loss:  0.0003372147912159562
Epoch:  385  	Training Loss: 0.0002207086654379964
Test Loss:  0.00019239653192926198
Valid Loss:  0.00033720233477652073
Epoch:  386  	Training Loss: 0.00022068044927436858
Test Loss:  0.00019235590298194438
Valid Loss:  0.00033718982012942433
Epoch:  387  	Training Loss: 0.00022065361554268748
Test Loss:  0.00019231575424782932
Valid Loss:  0.000337176606990397
Epoch:  388  	Training Loss: 0.0002206265926361084
Test Loss:  0.0001922750088851899
Valid Loss:  0.00033716383040882647
Epoch:  389  	Training Loss: 0.00022060025366954505
Test Loss:  0.00019223538402002305
Valid Loss:  0.0003371511702425778
Epoch:  390  	Training Loss: 0.0002205740165663883
Test Loss:  0.0001921981165651232
Valid Loss:  0.00033713883021846414
Epoch:  391  	Training Loss: 0.00022054821602068841
Test Loss:  0.0001921618968481198
Valid Loss:  0.00033712631557136774
Epoch:  392  	Training Loss: 0.00022052248823456466
Test Loss:  0.00019209252786822617
Valid Loss:  0.00033711560536175966
Epoch:  393  	Training Loss: 0.00022049507242627442
Test Loss:  0.0001920242648338899
Valid Loss:  0.000337105942890048
Epoch:  394  	Training Loss: 0.00022046778758522123
Test Loss:  0.0001919564529089257
Valid Loss:  0.0003370954655110836
Epoch:  395  	Training Loss: 0.0002204408374382183
Test Loss:  0.00019188981968909502
Valid Loss:  0.0003370857157278806
Epoch:  396  	Training Loss: 0.00022041410556994379
Test Loss:  0.00019182395772077143
Valid Loss:  0.0003370744816493243
Epoch:  397  	Training Loss: 0.00022038762108422816
Test Loss:  0.00019175793568138033
Valid Loss:  0.0003370631893631071
Epoch:  398  	Training Loss: 0.00022036134032532573
Test Loss:  0.00019169511506333947
Valid Loss:  0.0003370520134922117
Epoch:  399  	Training Loss: 0.00022033533605281264
Test Loss:  0.0001916354231070727
Valid Loss:  0.0003370409249328077
Epoch:  400  	Training Loss: 0.00022030944819562137
Test Loss:  0.00019157672068104148
Valid Loss:  0.00033702890505082905
Epoch:  401  	Training Loss: 0.00022028385137673467
Test Loss:  0.00019151918240822852
Valid Loss:  0.0003370169142726809
Epoch:  402  	Training Loss: 0.0002202583709731698
Test Loss:  0.0001917621266329661
Valid Loss:  0.00033682226785458624
Epoch:  403  	Training Loss: 0.00022022161283530295
Test Loss:  0.00019198407244402915
Valid Loss:  0.0003366501769050956
Epoch:  404  	Training Loss: 0.00022019119933247566
Test Loss:  0.00019218675151932985
Valid Loss:  0.0003364992735441774
Epoch:  405  	Training Loss: 0.00022016820730641484
Test Loss:  0.0001923044619616121
Valid Loss:  0.0003363835858181119
Epoch:  406  	Training Loss: 0.00022015575086697936
Test Loss:  0.00019241140398662537
Valid Loss:  0.00033627887023612857
Epoch:  407  	Training Loss: 0.00022014472051523626
Test Loss:  0.00019250866898801178
Valid Loss:  0.00033618416637182236 81%|████████▏ | 407/500 [04:59<00:42,  2.18it/s] 82%|████████▏ | 409/500 [04:59<00:31,  2.93it/s] 82%|████████▏ | 411/500 [05:05<01:45,  1.18s/it] 83%|████████▎ | 413/500 [05:05<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:05<00:52,  1.62it/s] 83%|████████▎ | 417/500 [05:06<00:37,  2.22it/s] 84%|████████▍ | 419/500 [05:06<00:27,  2.98it/s] 84%|████████▍ | 421/500 [05:12<01:34,  1.20s/it] 85%|████████▍ | 423/500 [05:12<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:12<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:13<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:13<00:24,  2.96it/s] 86%|████████▌ | 431/500 [05:19<01:23,  1.20s/it] 87%|████████▋ | 433/500 [05:19<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:19<00:40,  1.59it/s] 87%|████████▋ | 437/500 [05:20<00:29,  2.16it/s] 88%|████████▊ | 439/500 [05:20<00:21,  2.89it/s] 88%|████████▊ | 441/500 [05:26<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:26<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:26<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:27<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:27<00:17,  2.94it/s] 90%|█████████ | 451/500 [05:33<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:33<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:33<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:33<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:34<00:13,  2.93it/s] 92%|█████████▏| 461/500 [05:40<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:40<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:40<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:40<00:14,  2.20it/s] 94%|█████████▍| 469/500 [05:40<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:47<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:47<00:23,  1.17it/s]
Epoch:  408  	Training Loss: 0.00022013549460098147
Test Loss:  0.00019259494729340076
Valid Loss:  0.00033609833917580545
Epoch:  409  	Training Loss: 0.00022012687986716628
Test Loss:  0.00019267220341134816
Valid Loss:  0.00033601938048377633
Epoch:  410  	Training Loss: 0.00022011906548868865
Test Loss:  0.00019274158694315702
Valid Loss:  0.00033594705746509135
Epoch:  411  	Training Loss: 0.00022011347755324095
Test Loss:  0.00019273473299108446
Valid Loss:  0.0003358982503414154
Epoch:  412  	Training Loss: 0.00022010742395650595
Test Loss:  0.00019261737179476768
Valid Loss:  0.00033574504777789116
Epoch:  413  	Training Loss: 0.00022005118080414832
Test Loss:  0.00019251031335443258
Valid Loss:  0.0003356303204782307
Epoch:  414  	Training Loss: 0.00021999538876116276
Test Loss:  0.00019239215180277824
Valid Loss:  0.0003354964719619602
Epoch:  415  	Training Loss: 0.00021993994596414268
Test Loss:  0.00019227410666644573
Valid Loss:  0.00033537301351316273
Epoch:  416  	Training Loss: 0.00021988469234202057
Test Loss:  0.0001921545626828447
Valid Loss:  0.00033525493927299976
Epoch:  417  	Training Loss: 0.00021982975886203349
Test Loss:  0.0001920356007758528
Valid Loss:  0.00033514242386445403
Epoch:  418  	Training Loss: 0.000219774927245453
Test Loss:  0.00019191985484212637
Valid Loss:  0.00033503363374620676
Epoch:  419  	Training Loss: 0.0002197213761974126
Test Loss:  0.00019180585513822734
Valid Loss:  0.0003349308972246945
Epoch:  420  	Training Loss: 0.00021966939675621688
Test Loss:  0.00019169144798070192
Valid Loss:  0.0003348301106598228
Epoch:  421  	Training Loss: 0.00021961783932056278
Test Loss:  0.00019157789938617498
Valid Loss:  0.0003347316524013877
Epoch:  422  	Training Loss: 0.0002195661945734173
Test Loss:  0.00019148908904753625
Valid Loss:  0.00033490086207166314
Epoch:  423  	Training Loss: 0.00021945431944914162
Test Loss:  0.0001912920270115137
Valid Loss:  0.0003348863683640957
Epoch:  424  	Training Loss: 0.00021934803226031363
Test Loss:  0.00019119109492748976
Valid Loss:  0.0003348284517414868
Epoch:  425  	Training Loss: 0.00021924554312136024
Test Loss:  0.0001910486025735736
Valid Loss:  0.000334777869284153
Epoch:  426  	Training Loss: 0.0002191455860156566
Test Loss:  0.00019100058125331998
Valid Loss:  0.0003348671307321638
Epoch:  427  	Training Loss: 0.00021904773893766105
Test Loss:  0.00019090090063400567
Valid Loss:  0.000334770476911217
Epoch:  428  	Training Loss: 0.00021895038662478328
Test Loss:  0.00019081402570009232
Valid Loss:  0.0003346711164340377
Epoch:  429  	Training Loss: 0.00021885393653064966
Test Loss:  0.0001907383557409048
Valid Loss:  0.0003345674485899508
Epoch:  430  	Training Loss: 0.0002187602804042399
Test Loss:  0.00019074184820055962
Valid Loss:  0.00033461779821664095
Epoch:  431  	Training Loss: 0.00021866700262762606
Test Loss:  0.00019068378605879843
Valid Loss:  0.00033448831527493894
Epoch:  432  	Training Loss: 0.00021857296815142035
Test Loss:  0.00019067998800892383
Valid Loss:  0.00033440726110711694
Epoch:  433  	Training Loss: 0.0002185375487897545
Test Loss:  0.00019066024105995893
Valid Loss:  0.0003343030984979123
Epoch:  434  	Training Loss: 0.00021850357006769627
Test Loss:  0.00019064886146225035
Valid Loss:  0.000334234326146543
Epoch:  435  	Training Loss: 0.00021846979507245123
Test Loss:  0.00019062147475779057
Valid Loss:  0.00033414072822779417
Epoch:  436  	Training Loss: 0.0002184355107601732
Test Loss:  0.00019059133774135262
Valid Loss:  0.0003340521943755448
Epoch:  437  	Training Loss: 0.00021840128465555608
Test Loss:  0.00019055858138017356
Valid Loss:  0.00033396860817447305
Epoch:  438  	Training Loss: 0.00021836787345819175
Test Loss:  0.00019053596770390868
Valid Loss:  0.0003339175891596824
Epoch:  439  	Training Loss: 0.00021833417122252285
Test Loss:  0.00019049932598136365
Valid Loss:  0.00033383845584467053
Epoch:  440  	Training Loss: 0.00021830014884471893
Test Loss:  0.00019046140369027853
Valid Loss:  0.00033376255305483937
Epoch:  441  	Training Loss: 0.00021826654847245663
Test Loss:  0.0001904215314425528
Valid Loss:  0.0003336900845170021
Epoch:  442  	Training Loss: 0.00021823288989253342
Test Loss:  0.00019039318431168795
Valid Loss:  0.0003335972432978451
Epoch:  443  	Training Loss: 0.0002181323361583054
Test Loss:  0.00019037892343476415
Valid Loss:  0.00033353391336277127
Epoch:  444  	Training Loss: 0.0002180329611292109
Test Loss:  0.0001903519150801003
Valid Loss:  0.0003334415960125625
Epoch:  445  	Training Loss: 0.00021793553605675697
Test Loss:  0.00019032633281312883
Valid Loss:  0.00033335323678329587
Epoch:  446  	Training Loss: 0.0002178405411541462
Test Loss:  0.00019030140538234264
Valid Loss:  0.00033326572156511247
Epoch:  447  	Training Loss: 0.00021774735068902373
Test Loss:  0.0001902769727166742
Valid Loss:  0.0003331791958771646
Epoch:  448  	Training Loss: 0.0002176547423005104
Test Loss:  0.00019025284564122558
Valid Loss:  0.0003330937761347741
Epoch:  449  	Training Loss: 0.00021756254136562347
Test Loss:  0.00019022815104108304
Valid Loss:  0.00033300856011919677
Epoch:  450  	Training Loss: 0.0002174701658077538
Test Loss:  0.00019021621847059578
Valid Loss:  0.0003329531173221767
Epoch:  451  	Training Loss: 0.000217378546949476
Test Loss:  0.00019019194587599486
Valid Loss:  0.00033286839607171714
Epoch:  452  	Training Loss: 0.00021728829597122967
Test Loss:  0.0001901937648653984
Valid Loss:  0.00033284188248217106
Epoch:  453  	Training Loss: 0.00021716573974117637
Test Loss:  0.0001901890937006101
Valid Loss:  0.0003328023012727499
Epoch:  454  	Training Loss: 0.00021704516257159412
Test Loss:  0.00019017956219613552
Valid Loss:  0.00033275297028012574
Epoch:  455  	Training Loss: 0.00021692612790502608
Test Loss:  0.00019016573787666857
Valid Loss:  0.00033269438426941633
Epoch:  456  	Training Loss: 0.00021680901409126818
Test Loss:  0.0001901488285511732
Valid Loss:  0.00033262796932831407
Epoch:  457  	Training Loss: 0.00021669379202648997
Test Loss:  0.00019014393910765648
Valid Loss:  0.0003325844882056117
Epoch:  458  	Training Loss: 0.00021657954494003206
Test Loss:  0.0001901222567539662
Valid Loss:  0.0003325029101688415
Epoch:  459  	Training Loss: 0.00021646663662977517
Test Loss:  0.00019009766401723027
Valid Loss:  0.00033241743221879005
Epoch:  460  	Training Loss: 0.0002163553872378543
Test Loss:  0.00019008482922799885
Valid Loss:  0.00033235829323530197
Epoch:  461  	Training Loss: 0.00021624600049108267
Test Loss:  0.000190055463463068
Valid Loss:  0.0003322638222016394
Epoch:  462  	Training Loss: 0.00021613806893583387
Test Loss:  0.00019003712804988027
Valid Loss:  0.0003321397234685719
Epoch:  463  	Training Loss: 0.00021611675038002431
Test Loss:  0.00019001870532520115
Valid Loss:  0.0003320226678624749
Epoch:  464  	Training Loss: 0.00021609711984638125
Test Loss:  0.00019000025349669158
Valid Loss:  0.0003319166717119515
Epoch:  465  	Training Loss: 0.00021607910457532853
Test Loss:  0.0001899816852528602
Valid Loss:  0.00033181687467731535
Epoch:  466  	Training Loss: 0.00021606167138088495
Test Loss:  0.00018996343715116382
Valid Loss:  0.00033172249095514417
Epoch:  467  	Training Loss: 0.00021604503854177892
Test Loss:  0.00018994486890733242
Valid Loss:  0.00033163270563818514
Epoch:  468  	Training Loss: 0.0002160287695005536
Test Loss:  0.00018992609693668783
Valid Loss:  0.00033154746051877737
Epoch:  469  	Training Loss: 0.00021601284970529377
Test Loss:  0.00018990776152350008
Valid Loss:  0.0003314666682854295
Epoch:  470  	Training Loss: 0.00021599781757686287
Test Loss:  0.0001898892951430753
Valid Loss:  0.0003313962952233851
Epoch:  471  	Training Loss: 0.0002159837749786675
Test Loss:  0.0001898706250358373
Valid Loss:  0.0003313285415060818
Epoch:  472  	Training Loss: 0.00021597013983409852
Test Loss:  0.00018989836098626256
Valid Loss:  0.0003315583453513682
Epoch:  473  	Training Loss: 0.00021591674885712564
Test Loss:  0.00018990134412888438
Valid Loss:  0.000331724964780733
Epoch:  474  	Training Loss: 0.00021586776711046696
Test Loss:  0.00018989323871210217
Valid Loss:  0.0003318643430247903
 95%|█████████▌| 475/500 [05:47<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:47<00:10,  2.20it/s] 96%|█████████▌| 479/500 [05:47<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:54<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:54<00:14,  1.14it/s] 97%|█████████▋| 485/500 [05:54<00:09,  1.56it/s] 97%|█████████▋| 487/500 [05:54<00:06,  2.11it/s] 98%|█████████▊| 489/500 [05:55<00:03,  2.80it/s] 98%|█████████▊| 491/500 [06:01<00:11,  1.23s/it] 99%|█████████▊| 493/500 [06:01<00:06,  1.13it/s] 99%|█████████▉| 495/500 [06:01<00:03,  1.55it/s] 99%|█████████▉| 497/500 [06:02<00:01,  2.09it/s]100%|█████████▉| 499/500 [06:02<00:00,  2.79it/s]100%|██████████| 500/500 [06:02<00:00,  1.38it/s]
Epoch:  475  	Training Loss: 0.00021582120098173618
Test Loss:  0.0001898771442938596
Valid Loss:  0.00033198081655427814
Epoch:  476  	Training Loss: 0.00021577726874966174
Test Loss:  0.0001898662158055231
Valid Loss:  0.0003321054100524634
Epoch:  477  	Training Loss: 0.00021573483536485583
Test Loss:  0.0001898357004392892
Valid Loss:  0.00033217977033928037
Epoch:  478  	Training Loss: 0.00021569401724264026
Test Loss:  0.00018981218454428017
Valid Loss:  0.00033226911909878254
Epoch:  479  	Training Loss: 0.00021565421775449067
Test Loss:  0.00018978328444063663
Valid Loss:  0.0003323405690025538
Epoch:  480  	Training Loss: 0.00021561566973105073
Test Loss:  0.0001897364272736013
Valid Loss:  0.0003323708660900593
Epoch:  481  	Training Loss: 0.0002155776892323047
Test Loss:  0.00018970001838169992
Valid Loss:  0.000332421506755054
Epoch:  482  	Training Loss: 0.00021554031991399825
Test Loss:  0.00018968489894177765
Valid Loss:  0.00033230159897357225
Epoch:  483  	Training Loss: 0.00021545820345636457
Test Loss:  0.00018966611241921782
Valid Loss:  0.00033219976467080414
Epoch:  484  	Training Loss: 0.00021537758584599942
Test Loss:  0.0001896440953714773
Valid Loss:  0.0003321119293104857
Epoch:  485  	Training Loss: 0.0002152987872250378
Test Loss:  0.00018955128325615078
Valid Loss:  0.0003318812814541161
Epoch:  486  	Training Loss: 0.00021522532915696502
Test Loss:  0.00018953165272250772
Valid Loss:  0.0003318539238534868
Epoch:  487  	Training Loss: 0.0002151510852854699
Test Loss:  0.000189507074537687
Valid Loss:  0.0003318207454867661
Epoch:  488  	Training Loss: 0.00021507771452888846
Test Loss:  0.0001894784509204328
Valid Loss:  0.0003317818627692759
Epoch:  489  	Training Loss: 0.0002150082727894187
Test Loss:  0.00018937792629003525
Valid Loss:  0.00033158966107293963
Epoch:  490  	Training Loss: 0.0002149368665413931
Test Loss:  0.00018935029220301658
Valid Loss:  0.0003315861104056239
Epoch:  491  	Training Loss: 0.00021486572222784162
Test Loss:  0.0001893178268801421
Valid Loss:  0.0003315708599984646
Epoch:  492  	Training Loss: 0.00021479872521013021
Test Loss:  0.000189312850125134
Valid Loss:  0.0003314697532914579
Epoch:  493  	Training Loss: 0.0002147754858015105
Test Loss:  0.00018930794612970203
Valid Loss:  0.0003313742927275598
Epoch:  494  	Training Loss: 0.00021475262474268675
Test Loss:  0.0001893016742542386
Valid Loss:  0.0003312845656182617
Epoch:  495  	Training Loss: 0.00021473078231792897
Test Loss:  0.00018929439829662442
Valid Loss:  0.00033120496664196253
Epoch:  496  	Training Loss: 0.00021471070067491382
Test Loss:  0.00018928726785816252
Valid Loss:  0.00033113069366663694
Epoch:  497  	Training Loss: 0.0002146912011085078
Test Loss:  0.0001892668369691819
Valid Loss:  0.00033103529131039977
Epoch:  498  	Training Loss: 0.00021467311307787895
Test Loss:  0.0001892590953502804
Valid Loss:  0.0003309712919872254
Epoch:  499  	Training Loss: 0.00021465483587235212
Test Loss:  0.00018923899915535003
Valid Loss:  0.0003308841260150075
Epoch:  500  	Training Loss: 0.00021463734447024763
Test Loss:  0.00018923074821941555
Valid Loss:  0.00033082818845286965
seed is  11
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:35, 13.84it/s]  1%|          | 4/500 [00:00<00:38, 12.88it/s]  1%|          | 6/500 [00:00<00:35, 14.11it/s]  2%|▏         | 8/500 [00:00<00:33, 14.71it/s]  2%|▏         | 10/500 [00:00<00:32, 15.18it/s]  2%|▏         | 12/500 [00:00<00:31, 15.54it/s]  3%|▎         | 14/500 [00:00<00:30, 15.79it/s]  3%|▎         | 16/500 [00:01<00:30, 15.79it/s]  4%|▎         | 18/500 [00:01<00:30, 15.99it/s]  4%|▍         | 20/500 [00:01<00:29, 16.09it/s]  4%|▍         | 22/500 [00:01<00:29, 16.20it/s]  5%|▍         | 24/500 [00:01<00:29, 16.33it/s]  5%|▌         | 26/500 [00:01<00:29, 16.34it/s]  6%|▌         | 28/500 [00:01<00:28, 16.38it/s]  6%|▌         | 30/500 [00:01<00:28, 16.25it/s]  6%|▋         | 32/500 [00:02<00:29, 15.98it/s]  7%|▋         | 34/500 [00:02<00:30, 15.39it/s]  7%|▋         | 36/500 [00:02<00:29, 15.72it/s]  8%|▊         | 38/500 [00:02<00:29, 15.89it/s]  8%|▊         | 40/500 [00:02<00:28, 16.06it/s]  8%|▊         | 42/500 [00:02<00:28, 16.04it/s]  9%|▉         | 44/500 [00:02<00:28, 16.14it/s]  9%|▉         | 46/500 [00:02<00:27, 16.23it/s] 10%|▉         | 48/500 [00:03<00:27, 16.37it/s] 10%|█         | 50/500 [00:03<00:27, 16.30it/s] 10%|█         | 52/500 [00:03<00:27, 16.35it/s] 11%|█         | 54/500 [00:03<00:27, 16.39it/s] 11%|█         | 56/500 [00:03<00:27, 16.25it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.14it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.21it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.22it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.27it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.31it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.30it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.41it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.57it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.71it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.79it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.94it/s] 16%|█▌        | 80/500 [00:05<00:26, 16.02it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.10it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.08it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.10it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.16it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.29it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.05it/s] 19%|█▉        | 94/500 [00:05<00:25, 16.02it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.01it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.11it/s] 20%|██        | 100/500 [00:06<00:24, 16.18it/s] 20%|██        | 102/500 [00:06<00:24, 16.17it/s] 21%|██        | 104/500 [00:06<00:24, 16.17it/s] 21%|██        | 106/500 [00:06<00:24, 16.17it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.05it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.13it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.26it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.28it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.31it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.26it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.04it/s] 24%|██▍       | 122/500 [00:07<00:24, 15.67it/s] 25%|██▍       | 124/500 [00:07<00:25, 14.91it/s]Epoch:  1  	Training Loss: 0.029232732951641083
Test Loss:  45.160404205322266
Valid Loss:  45.38990783691406
Epoch:  2  	Training Loss: 46.03192901611328
Test Loss:  72514288.0
Valid Loss:  71507408.0
Epoch:  3  	Training Loss: 71084544.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
 25%|██▌       | 126/500 [00:07<00:25, 14.76it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.20it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.48it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.80it/s] 27%|██▋       | 134/500 [00:08<00:22, 15.99it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.93it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.00it/s] 28%|██▊       | 140/500 [00:08<00:22, 15.91it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.05it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.18it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.53it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.69it/s] 30%|███       | 150/500 [00:09<00:22, 15.71it/s] 30%|███       | 152/500 [00:09<00:21, 15.93it/s] 31%|███       | 154/500 [00:09<00:21, 16.06it/s] 31%|███       | 156/500 [00:09<00:21, 16.11it/s] 32%|███▏      | 158/500 [00:09<00:21, 15.95it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.54it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.66it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.72it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.87it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.01it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.04it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.10it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.15it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.18it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.20it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.27it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.13it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.09it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.09it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.12it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.05it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.13it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.20it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.21it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.32it/s] 40%|████      | 200/500 [00:12<00:18, 16.22it/s] 40%|████      | 202/500 [00:12<00:18, 16.21it/s] 41%|████      | 204/500 [00:12<00:18, 16.21it/s] 41%|████      | 206/500 [00:12<00:18, 16.19it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.05it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.14it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.15it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.15it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.21it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.24it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.25it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.32it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.22it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.20it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.04it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.07it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.11it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.13it/s] 47%|████▋     | 236/500 [00:14<00:17, 15.43it/s] 48%|████▊     | 238/500 [00:14<00:16, 15.68it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.89it/s] 48%|████▊     | 242/500 [00:15<00:17, 14.64it/s] 49%|████▉     | 244/500 [00:15<00:17, 14.68it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.12it/s] 50%|████▉     | 248/500 [00:15<00:16, 15.50it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:15<00:15, 15.73it/s] 50%|█████     | 252/500 [00:15<00:15, 15.95it/s] 51%|█████     | 254/500 [00:15<00:15, 15.88it/s] 51%|█████     | 256/500 [00:16<00:15, 15.86it/s] 52%|█████▏    | 258/500 [00:16<00:15, 16.05it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.14it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.23it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.24it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.18it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.09it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.18it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.11it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.22it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.24it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.08it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.10it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.13it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.11it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.00it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.02it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.02it/s] 58%|█████▊    | 292/500 [00:18<00:14, 14.74it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.20it/s] 59%|█████▉    | 296/500 [00:18<00:13, 15.29it/s] 60%|█████▉    | 298/500 [00:18<00:14, 14.20it/s] 60%|██████    | 300/500 [00:18<00:14, 13.60it/s] 60%|██████    | 302/500 [00:19<00:15, 13.10it/s] 61%|██████    | 304/500 [00:19<00:15, 12.70it/s] 61%|██████    | 306/500 [00:19<00:15, 12.58it/s] 62%|██████▏   | 308/500 [00:19<00:15, 12.42it/s] 62%|██████▏   | 310/500 [00:19<00:15, 12.42it/s] 62%|██████▏   | 312/500 [00:19<00:15, 12.30it/s] 63%|██████▎   | 314/500 [00:20<00:14, 12.41it/s] 63%|██████▎   | 316/500 [00:20<00:13, 13.25it/s] 64%|██████▎   | 318/500 [00:20<00:13, 14.00it/s] 64%|██████▍   | 320/500 [00:20<00:12, 14.06it/s] 64%|██████▍   | 322/500 [00:20<00:12, 13.86it/s] 65%|██████▍   | 324/500 [00:20<00:13, 13.36it/s] 65%|██████▌   | 326/500 [00:20<00:12, 13.61it/s] 66%|██████▌   | 328/500 [00:21<00:12, 14.06it/s] 66%|██████▌   | 330/500 [00:21<00:11, 14.58it/s] 66%|██████▋   | 332/500 [00:21<00:11, 15.04it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.36it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.67it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.84it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.03it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.16it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.07it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.10it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.22it/s] 70%|███████   | 350/500 [00:22<00:09, 16.24it/s] 70%|███████   | 352/500 [00:22<00:09, 16.00it/s] 71%|███████   | 354/500 [00:22<00:09, 16.07it/s] 71%|███████   | 356/500 [00:22<00:08, 16.09it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.17it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.21it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.22it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.17it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.09it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.19it/s] 74%|███████▍  | 370/500 [00:23<00:08, 16.19it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.01it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:23<00:08, 15.40it/s] 75%|███████▌  | 376/500 [00:24<00:08, 14.32it/s] 76%|███████▌  | 378/500 [00:24<00:08, 14.45it/s] 76%|███████▌  | 380/500 [00:24<00:08, 14.96it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.25it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.25it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.47it/s] 78%|███████▊  | 388/500 [00:24<00:07, 15.62it/s] 78%|███████▊  | 390/500 [00:24<00:06, 15.85it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.96it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.11it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.20it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.29it/s] 80%|████████  | 400/500 [00:25<00:06, 16.19it/s] 80%|████████  | 402/500 [00:25<00:06, 16.05it/s] 81%|████████  | 404/500 [00:25<00:05, 16.07it/s] 81%|████████  | 406/500 [00:25<00:05, 16.12it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.24it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.17it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.10it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.08it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.10it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.19it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.27it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.38it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.34it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.30it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.28it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.21it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.18it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.26it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.28it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.28it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.33it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.21it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.28it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.37it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.18it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.14it/s] 90%|█████████ | 452/500 [00:28<00:03, 15.97it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.01it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.10it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.71it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.20it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.46it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.71it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.87it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.10it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.20it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.14it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.12it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.16it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.19it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.28it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.38it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.42it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.53it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.36it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.12it/s] 98%|█████████▊| 492/500 [00:31<00:00, 15.36it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.61it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.51it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:31<00:00, 14.37it/s]100%|██████████| 500/500 [00:31<00:00, 14.52it/s]100%|██████████| 500/500 [00:31<00:00, 15.69it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  11
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:40,  6.33s/it]  1%|          | 3/500 [00:06<14:02,  1.70s/it]  1%|          | 5/500 [00:06<07:04,  1.17it/s]  1%|▏         | 7/500 [00:06<04:17,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:14,  1.54it/s]  3%|▎         | 17/500 [00:13<03:46,  2.13it/s]  4%|▍         | 19/500 [00:13<02:45,  2.91it/s]  4%|▍         | 21/500 [00:20<09:49,  1.23s/it]  5%|▍         | 23/500 [00:20<06:58,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.59it/s]  5%|▌         | 27/500 [00:20<03:39,  2.15it/s]  6%|▌         | 29/500 [00:20<02:44,  2.86it/s]  6%|▌         | 31/500 [00:27<09:30,  1.22s/it]  7%|▋         | 33/500 [00:27<06:47,  1.15it/s]  7%|▋         | 35/500 [00:27<04:52,  1.59it/s]  7%|▋         | 37/500 [00:27<03:33,  2.17it/s]  8%|▊         | 39/500 [00:27<02:40,  2.88it/s]  8%|▊         | 41/500 [00:34<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:36,  1.15it/s]  9%|▉         | 45/500 [00:34<04:48,  1.58it/s]  9%|▉         | 47/500 [00:34<03:32,  2.13it/s] 10%|▉         | 49/500 [00:34<02:39,  2.82it/s] 10%|█         | 51/500 [00:41<09:03,  1.21s/it] 11%|█         | 53/500 [00:41<06:28,  1.15it/s] 11%|█         | 55/500 [00:41<04:39,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:23,  2.18it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.93it/s] 12%|█▏        | 61/500 [00:48<08:42,  1.19s/it] 13%|█▎        | 63/500 [00:48<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:26,  2.94it/s] 14%|█▍        | 71/500 [00:55<08:27,  1.18s/it]Epoch:  1  	Training Loss: 0.029232734814286232
Test Loss:  0.5043160915374756
Valid Loss:  0.5301977396011353
Epoch:  2  	Training Loss: 0.49799031019210815
Test Loss:  0.9261974692344666
Valid Loss:  0.8591983914375305
Epoch:  3  	Training Loss: 0.7949048280715942
Test Loss:  0.034478358924388885
Valid Loss:  0.03695239871740341
Epoch:  4  	Training Loss: 0.030555233359336853
Test Loss:  0.034476637840270996
Valid Loss:  0.036951079964637756
Epoch:  5  	Training Loss: 0.030553586781024933
Test Loss:  0.03447539731860161
Valid Loss:  0.03694982826709747
Epoch:  6  	Training Loss: 0.030551983043551445
Test Loss:  0.03447435051202774
Valid Loss:  0.03694861754775047
Epoch:  7  	Training Loss: 0.03055039420723915
Test Loss:  0.03447345644235611
Valid Loss:  0.03694741800427437
Epoch:  8  	Training Loss: 0.030548816546797752
Test Loss:  0.03447256237268448
Valid Loss:  0.036946214735507965
Epoch:  9  	Training Loss: 0.030547238886356354
Test Loss:  0.03447166830301285
Valid Loss:  0.03694501519203186
Epoch:  10  	Training Loss: 0.030545659363269806
Test Loss:  0.034470923244953156
Valid Loss:  0.036943815648555756
Epoch:  11  	Training Loss: 0.030544087290763855
Test Loss:  0.03447018563747406
Valid Loss:  0.03694262355566025
Epoch:  12  	Training Loss: 0.030542515218257904
Test Loss:  0.03446683660149574
Valid Loss:  0.03693949431180954
Epoch:  13  	Training Loss: 0.03053944557905197
Test Loss:  0.03446369618177414
Valid Loss:  0.036936428397893906
Epoch:  14  	Training Loss: 0.030536489561200142
Test Loss:  0.03446068614721298
Valid Loss:  0.03693360090255737
Epoch:  15  	Training Loss: 0.03053361363708973
Test Loss:  0.034457847476005554
Valid Loss:  0.03693090379238129
Epoch:  16  	Training Loss: 0.030530832707881927
Test Loss:  0.03445514664053917
Valid Loss:  0.036928340792655945
Epoch:  17  	Training Loss: 0.030528103932738304
Test Loss:  0.03445252776145935
Valid Loss:  0.03692585229873657
Epoch:  18  	Training Loss: 0.03052537515759468
Test Loss:  0.034449927508831024
Valid Loss:  0.0369233600795269
Epoch:  19  	Training Loss: 0.030522668734192848
Test Loss:  0.03444736450910568
Valid Loss:  0.03692089766263962
Epoch:  20  	Training Loss: 0.030519988387823105
Test Loss:  0.03444479778409004
Valid Loss:  0.03691846504807472
Epoch:  21  	Training Loss: 0.030517317354679108
Test Loss:  0.03444230556488037
Valid Loss:  0.03691619262099266
Epoch:  22  	Training Loss: 0.030514679849147797
Test Loss:  0.03444002568721771
Valid Loss:  0.03691412881016731
Epoch:  23  	Training Loss: 0.030512141063809395
Test Loss:  0.03443778306245804
Valid Loss:  0.03691210597753525
Epoch:  24  	Training Loss: 0.03050967864692211
Test Loss:  0.03443564474582672
Valid Loss:  0.03691020980477333
Epoch:  25  	Training Loss: 0.030507300049066544
Test Loss:  0.034433502703905106
Valid Loss:  0.036908335983753204
Epoch:  26  	Training Loss: 0.030504915863275528
Test Loss:  0.03443136066198349
Valid Loss:  0.036906495690345764
Epoch:  27  	Training Loss: 0.030502546578645706
Test Loss:  0.03442925959825516
Valid Loss:  0.0369047187268734
Epoch:  28  	Training Loss: 0.030500203371047974
Test Loss:  0.0344272255897522
Valid Loss:  0.03690294921398163
Epoch:  29  	Training Loss: 0.030497904866933823
Test Loss:  0.03442533314228058
Valid Loss:  0.03690120950341225
Epoch:  30  	Training Loss: 0.030495665967464447
Test Loss:  0.03442347049713135
Valid Loss:  0.03689947724342346
Epoch:  31  	Training Loss: 0.030493438243865967
Test Loss:  0.034421637654304504
Valid Loss:  0.03689775615930557
Epoch:  32  	Training Loss: 0.030491236597299576
Test Loss:  0.03441977500915527
Valid Loss:  0.036895982921123505
Epoch:  33  	Training Loss: 0.030489029362797737
Test Loss:  0.03441793844103813
Valid Loss:  0.03689423203468323
Epoch:  34  	Training Loss: 0.030486848205327988
Test Loss:  0.03441610187292099
Valid Loss:  0.03689247742295265
Epoch:  35  	Training Loss: 0.030484667047858238
Test Loss:  0.03441426903009415
Valid Loss:  0.036890722811222076
Epoch:  36  	Training Loss: 0.030482487753033638
Test Loss:  0.03441242501139641
Valid Loss:  0.0368889681994915
Epoch:  37  	Training Loss: 0.030480314046144485
Test Loss:  0.034410618245601654
Valid Loss:  0.036887235939502716
Epoch:  38  	Training Loss: 0.030478183180093765
Test Loss:  0.034408848732709885
Valid Loss:  0.03688556328415871
Epoch:  39  	Training Loss: 0.03047606348991394
Test Loss:  0.03440706804394722
Valid Loss:  0.03688390552997589
Epoch:  40  	Training Loss: 0.030473947525024414
Test Loss:  0.03440532460808754
Valid Loss:  0.03688226267695427
Epoch:  41  	Training Loss: 0.03047187440097332
Test Loss:  0.034403637051582336
Valid Loss:  0.03688065707683563
Epoch:  42  	Training Loss: 0.03046981617808342
Test Loss:  0.03440199792385101
Valid Loss:  0.03687912970781326
Epoch:  43  	Training Loss: 0.030467767268419266
Test Loss:  0.03440040722489357
Valid Loss:  0.03687769174575806
Epoch:  44  	Training Loss: 0.03046571835875511
Test Loss:  0.03439881280064583
Valid Loss:  0.036876268684864044
Epoch:  45  	Training Loss: 0.030463669449090958
Test Loss:  0.034397222101688385
Valid Loss:  0.03687487915158272
Epoch:  46  	Training Loss: 0.030461637303233147
Test Loss:  0.03439568355679512
Valid Loss:  0.03687352314591408
Epoch:  47  	Training Loss: 0.030459638684988022
Test Loss:  0.034394145011901855
Valid Loss:  0.03687216341495514
Epoch:  48  	Training Loss: 0.030457662418484688
Test Loss:  0.03439262509346008
Valid Loss:  0.036870814859867096
Epoch:  49  	Training Loss: 0.030455684289336205
Test Loss:  0.03439110517501831
Valid Loss:  0.03686946630477905
Epoch:  50  	Training Loss: 0.030453724786639214
Test Loss:  0.03438961133360863
Valid Loss:  0.036868125200271606
Epoch:  51  	Training Loss: 0.030451789498329163
Test Loss:  0.03438820317387581
Valid Loss:  0.03686679154634476
Epoch:  52  	Training Loss: 0.030449893325567245
Test Loss:  0.034386903047561646
Valid Loss:  0.03686552122235298
Epoch:  53  	Training Loss: 0.030448060482740402
Test Loss:  0.034385643899440765
Valid Loss:  0.0368642583489418
Epoch:  54  	Training Loss: 0.03044622391462326
Test Loss:  0.03438442572951317
Valid Loss:  0.036862991750240326
Epoch:  55  	Training Loss: 0.030444389209151268
Test Loss:  0.034383222460746765
Valid Loss:  0.036861732602119446
Epoch:  56  	Training Loss: 0.030442574992775917
Test Loss:  0.03438205271959305
Valid Loss:  0.036860473453998566
Epoch:  57  	Training Loss: 0.030440758913755417
Test Loss:  0.03438088670372963
Valid Loss:  0.036859214305877686
Epoch:  58  	Training Loss: 0.030438944697380066
Test Loss:  0.03437972068786621
Valid Loss:  0.03685794770717621
Epoch:  59  	Training Loss: 0.03043713979423046
Test Loss:  0.03437858074903488
Valid Loss:  0.036856699734926224
Epoch:  60  	Training Loss: 0.030435362830758095
Test Loss:  0.034377459436655045
Valid Loss:  0.03685545548796654
Epoch:  61  	Training Loss: 0.03043360263109207
Test Loss:  0.03437633067369461
Valid Loss:  0.03685420751571655
Epoch:  62  	Training Loss: 0.03043183498084545
Test Loss:  0.03437521308660507
Valid Loss:  0.036852944642305374
Epoch:  63  	Training Loss: 0.03043007291853428
Test Loss:  0.03437409922480583
Valid Loss:  0.0368516780436039
Epoch:  64  	Training Loss: 0.030428307130932808
Test Loss:  0.034372974187135696
Valid Loss:  0.03685041517019272
Epoch:  65  	Training Loss: 0.030426546931266785
Test Loss:  0.03437187150120735
Valid Loss:  0.03684915229678154
Epoch:  66  	Training Loss: 0.030424803495407104
Test Loss:  0.0343707837164402
Valid Loss:  0.03684789687395096
Epoch:  67  	Training Loss: 0.03042306937277317
Test Loss:  0.03436969593167305
Valid Loss:  0.036846645176410675
Epoch:  68  	Training Loss: 0.030421335250139236
Test Loss:  0.0343686081469059
Valid Loss:  0.03684538975358009
Epoch:  69  	Training Loss: 0.03041960671544075
Test Loss:  0.03436752036213875
Valid Loss:  0.03684414178133011
Epoch:  70  	Training Loss: 0.030417874455451965
Test Loss:  0.03436645120382309
Valid Loss:  0.036842890083789825
Epoch:  71  	Training Loss: 0.030416158959269524
Test Loss:  0.03436541557312012
Valid Loss:  0.03684164956212044
Epoch:  72  	Training Loss: 0.030414454638957977
Test Loss:  0.03436443209648132
Valid Loss:   15%|█▍        | 73/500 [00:55<06:02,  1.18it/s] 15%|█▌        | 75/500 [00:55<04:21,  1.63it/s] 15%|█▌        | 77/500 [00:55<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:55<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:02<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:02<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:02<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:02<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:08<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:09<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:09<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:09<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.94it/s] 20%|██        | 101/500 [01:15<08:00,  1.20s/it] 21%|██        | 103/500 [01:16<05:43,  1.16it/s] 21%|██        | 105/500 [01:16<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:16<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.94it/s] 22%|██▏       | 111/500 [01:22<07:48,  1.20s/it] 23%|██▎       | 113/500 [01:23<05:34,  1.16it/s] 23%|██▎       | 115/500 [01:23<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:23<02:55,  2.19it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.93it/s] 24%|██▍       | 121/500 [01:29<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:29<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:29<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:30<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:30<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:36<07:23,  1.20s/it] 27%|██▋       | 133/500 [01:36<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:47,  1.61it/s] 27%|██▋       | 137/500 [01:37<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:37<02:02,  2.95it/s] 28%|██▊       | 141/500 [01:43<07:12,  1.21s/it] 29%|██▊       | 143/500 [01:43<05:09,  1.15it/s]0.036840446293354034
Epoch:  73  	Training Loss: 0.030412793159484863
Test Loss:  0.034363456070423126
Valid Loss:  0.03683924674987793
Epoch:  74  	Training Loss: 0.030411137267947197
Test Loss:  0.03436249867081642
Valid Loss:  0.03683805093169212
Epoch:  75  	Training Loss: 0.030409473925828934
Test Loss:  0.03436154127120972
Valid Loss:  0.03683684766292572
Epoch:  76  	Training Loss: 0.03040781244635582
Test Loss:  0.03436058759689331
Valid Loss:  0.036835648119449615
Epoch:  77  	Training Loss: 0.030406150966882706
Test Loss:  0.03435962647199631
Valid Loss:  0.03683445602655411
Epoch:  78  	Training Loss: 0.03040449507534504
Test Loss:  0.034358665347099304
Valid Loss:  0.036833256483078
Epoch:  79  	Training Loss: 0.030402835458517075
Test Loss:  0.0343577079474926
Valid Loss:  0.0368320532143116
Epoch:  80  	Training Loss: 0.03040117397904396
Test Loss:  0.03435675427317619
Valid Loss:  0.03683085739612579
Epoch:  81  	Training Loss: 0.030399512499570847
Test Loss:  0.03435581177473068
Valid Loss:  0.03682966157793999
Epoch:  82  	Training Loss: 0.03039785660803318
Test Loss:  0.03435489907860756
Valid Loss:  0.03682845085859299
Epoch:  83  	Training Loss: 0.030396191403269768
Test Loss:  0.03435397893190384
Valid Loss:  0.03682725131511688
Epoch:  84  	Training Loss: 0.030394528061151505
Test Loss:  0.03435305878520012
Valid Loss:  0.03682604059576988
Epoch:  85  	Training Loss: 0.03039287030696869
Test Loss:  0.034352149814367294
Valid Loss:  0.03682485222816467
Epoch:  86  	Training Loss: 0.030391212552785873
Test Loss:  0.03435124084353447
Valid Loss:  0.03682367131114006
Epoch:  87  	Training Loss: 0.030389562249183655
Test Loss:  0.034350328147411346
Valid Loss:  0.036822497844696045
Epoch:  88  	Training Loss: 0.030387911945581436
Test Loss:  0.03434941917657852
Valid Loss:  0.03682132065296173
Epoch:  89  	Training Loss: 0.03038625791668892
Test Loss:  0.034348513931035995
Valid Loss:  0.03682013973593712
Epoch:  90  	Training Loss: 0.0303846076130867
Test Loss:  0.034347619861364365
Valid Loss:  0.03681895509362221
Epoch:  91  	Training Loss: 0.030382955446839333
Test Loss:  0.03434672951698303
Valid Loss:  0.03681778162717819
Epoch:  92  	Training Loss: 0.030381305143237114
Test Loss:  0.03434586152434349
Valid Loss:  0.036816615611314774
Epoch:  93  	Training Loss: 0.030379677191376686
Test Loss:  0.03434499353170395
Valid Loss:  0.036815449595451355
Epoch:  94  	Training Loss: 0.030378058552742004
Test Loss:  0.034344129264354706
Valid Loss:  0.03681429103016853
Epoch:  95  	Training Loss: 0.030376434326171875
Test Loss:  0.03434326499700546
Valid Loss:  0.03681312873959541
Epoch:  96  	Training Loss: 0.030374815687537193
Test Loss:  0.03434240072965622
Valid Loss:  0.03681197017431259
Epoch:  97  	Training Loss: 0.030373195186257362
Test Loss:  0.03434152156114578
Valid Loss:  0.03681079298257828
Epoch:  98  	Training Loss: 0.030371569097042084
Test Loss:  0.03434065729379654
Valid Loss:  0.03680963069200516
Epoch:  99  	Training Loss: 0.030369948595762253
Test Loss:  0.034339793026447296
Valid Loss:  0.036808472126722336
Epoch:  100  	Training Loss: 0.03036833181977272
Test Loss:  0.034338925033807755
Valid Loss:  0.03680730611085892
Epoch:  101  	Training Loss: 0.03036670945584774
Test Loss:  0.03433805704116821
Valid Loss:  0.0368061438202858
Epoch:  102  	Training Loss: 0.03036509081721306
Test Loss:  0.034337159246206284
Valid Loss:  0.03680495545268059
Epoch:  103  	Training Loss: 0.03036346100270748
Test Loss:  0.03433626890182495
Valid Loss:  0.03680376335978508
Epoch:  104  	Training Loss: 0.0303618386387825
Test Loss:  0.03433539345860481
Valid Loss:  0.03680258244276047
Epoch:  105  	Training Loss: 0.03036022186279297
Test Loss:  0.03433450311422348
Valid Loss:  0.03680139034986496
Epoch:  106  	Training Loss: 0.030358601361513138
Test Loss:  0.03433362394571304
Valid Loss:  0.03680019825696945
Epoch:  107  	Training Loss: 0.030356978997588158
Test Loss:  0.0343327559530735
Valid Loss:  0.03679901361465454
Epoch:  108  	Training Loss: 0.030355356633663177
Test Loss:  0.03433188050985336
Valid Loss:  0.03679782524704933
Epoch:  109  	Training Loss: 0.030353736132383347
Test Loss:  0.03433100879192352
Valid Loss:  0.03679663687944412
Epoch:  110  	Training Loss: 0.030352115631103516
Test Loss:  0.03433013707399368
Valid Loss:  0.036795444786548615
Epoch:  111  	Training Loss: 0.030350498855113983
Test Loss:  0.03432926535606384
Valid Loss:  0.036794260144233704
Epoch:  112  	Training Loss: 0.030348874628543854
Test Loss:  0.03432844206690788
Valid Loss:  0.03679311275482178
Epoch:  113  	Training Loss: 0.030347280204296112
Test Loss:  0.03432762995362282
Valid Loss:  0.03679197281599045
Epoch:  114  	Training Loss: 0.03034568578004837
Test Loss:  0.03432682156562805
Valid Loss:  0.036790844053030014
Epoch:  115  	Training Loss: 0.030344095081090927
Test Loss:  0.034326013177633286
Valid Loss:  0.03678971156477928
Epoch:  116  	Training Loss: 0.030342498794198036
Test Loss:  0.03432520478963852
Valid Loss:  0.03678857907652855
Epoch:  117  	Training Loss: 0.030340902507305145
Test Loss:  0.034324392676353455
Valid Loss:  0.036787450313568115
Epoch:  118  	Training Loss: 0.03033931367099285
Test Loss:  0.03432358801364899
Valid Loss:  0.03678632155060768
Epoch:  119  	Training Loss: 0.030337724834680557
Test Loss:  0.03432277590036392
Valid Loss:  0.03678518533706665
Epoch:  120  	Training Loss: 0.030336126685142517
Test Loss:  0.03432196378707886
Valid Loss:  0.036784056574106216
Epoch:  121  	Training Loss: 0.030334539711475372
Test Loss:  0.03432115539908409
Valid Loss:  0.03678292781114578
Epoch:  122  	Training Loss: 0.03033294901251793
Test Loss:  0.0343204140663147
Valid Loss:  0.036781854927539825
Epoch:  123  	Training Loss: 0.030331403017044067
Test Loss:  0.034319669008255005
Valid Loss:  0.036780793219804764
Epoch:  124  	Training Loss: 0.030329857021570206
Test Loss:  0.03431893140077591
Valid Loss:  0.0367797315120697
Epoch:  125  	Training Loss: 0.03032831847667694
Test Loss:  0.03431819751858711
Valid Loss:  0.03677867725491524
Epoch:  126  	Training Loss: 0.03032677248120308
Test Loss:  0.03431745991110802
Valid Loss:  0.036777619272470474
Epoch:  127  	Training Loss: 0.030325230211019516
Test Loss:  0.03431672602891922
Valid Loss:  0.03677656501531601
Epoch:  128  	Training Loss: 0.030323687940835953
Test Loss:  0.03431599587202072
Valid Loss:  0.036775507032871246
Epoch:  129  	Training Loss: 0.03032214380800724
Test Loss:  0.034315288066864014
Valid Loss:  0.03677445650100708
Epoch:  130  	Training Loss: 0.030320607125759125
Test Loss:  0.03431457653641701
Valid Loss:  0.036773405969142914
Epoch:  131  	Training Loss: 0.03031906485557556
Test Loss:  0.03431386500597
Valid Loss:  0.03677235171198845
Epoch:  132  	Training Loss: 0.030317526310682297
Test Loss:  0.03431306034326553
Valid Loss:  0.03677118569612503
Epoch:  133  	Training Loss: 0.03031589463353157
Test Loss:  0.03431227058172226
Valid Loss:  0.03677002340555191
Epoch:  134  	Training Loss: 0.030314264819025993
Test Loss:  0.03431147709488869
Valid Loss:  0.03676886856555939
Epoch:  135  	Training Loss: 0.030312638729810715
Test Loss:  0.03431069105863571
Valid Loss:  0.03676770627498627
Epoch:  136  	Training Loss: 0.030311010777950287
Test Loss:  0.034309908747673035
Valid Loss:  0.036766551434993744
Epoch:  137  	Training Loss: 0.03030938282608986
Test Loss:  0.034309130162000656
Valid Loss:  0.03676539659500122
Epoch:  138  	Training Loss: 0.03030775487422943
Test Loss:  0.03430835157632828
Valid Loss:  0.036764249205589294
Epoch:  139  	Training Loss: 0.030306123197078705
Test Loss:  0.0343075729906559
Valid Loss:  0.03676309809088707
Epoch:  140  	Training Loss: 0.030304493382573128
Test Loss:  0.03430682420730591
Valid Loss:  0.036761946976184845
Epoch:  141  	Training Loss: 0.0303028654307127
Test Loss:  0.034306079149246216
Valid Loss:  0.03676080331206322
Epoch:  142  	Training Loss: 0.030301231890916824
Test Loss:  0.0343053862452507
Valid Loss:  0.03675971180200577
Epoch:  143  	Training Loss: 0.030299663543701172
Test Loss:  0.03430469334125519
Valid Loss:  0.03675862401723862
 29%|██▉       | 145/500 [01:43<03:42,  1.60it/s] 29%|██▉       | 147/500 [01:44<02:41,  2.18it/s] 30%|██▉       | 149/500 [01:44<01:59,  2.94it/s] 30%|███       | 151/500 [01:50<06:58,  1.20s/it] 31%|███       | 153/500 [01:50<04:58,  1.16it/s] 31%|███       | 155/500 [01:50<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:51<02:38,  2.16it/s] 32%|███▏      | 159/500 [01:51<01:57,  2.90it/s] 32%|███▏      | 161/500 [01:57<06:47,  1.20s/it] 33%|███▎      | 163/500 [01:57<04:52,  1.15it/s] 33%|███▎      | 165/500 [01:57<03:30,  1.59it/s] 33%|███▎      | 167/500 [01:58<02:33,  2.17it/s] 34%|███▍      | 169/500 [01:58<01:53,  2.92it/s] 34%|███▍      | 171/500 [02:04<06:38,  1.21s/it] 35%|███▍      | 173/500 [02:04<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:05<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:05<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:05<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:11<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:11<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:12<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:12<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:18<06:11,  1.20s/it] 39%|███▊      | 193/500 [02:18<04:24,  1.16it/s] 39%|███▉      | 195/500 [02:18<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:19<02:18,  2.19it/s] 40%|███▉      | 199/500 [02:19<01:41,  2.95it/s] 40%|████      | 201/500 [02:25<05:58,  1.20s/it] 41%|████      | 203/500 [02:25<04:16,  1.16it/s] 41%|████      | 205/500 [02:25<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:25<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:26<01:40,  2.91it/s] 42%|████▏     | 211/500 [02:32<05:53,  1.22s/it] 43%|████▎     | 213/500 [02:32<04:12,  1.14it/s]Epoch:  144  	Training Loss: 0.030298098921775818
Test Loss:  0.034303996711969376
Valid Loss:  0.03675754368305206
Epoch:  145  	Training Loss: 0.030296530574560165
Test Loss:  0.03430330380797386
Valid Loss:  0.036756448447704315
Epoch:  146  	Training Loss: 0.03029496595263481
Test Loss:  0.03430260717868805
Valid Loss:  0.03675536811351776
Epoch:  147  	Training Loss: 0.030293412506580353
Test Loss:  0.03430192917585373
Valid Loss:  0.03675428032875061
Epoch:  148  	Training Loss: 0.030291862785816193
Test Loss:  0.03430124372243881
Valid Loss:  0.036753199994564056
Epoch:  149  	Training Loss: 0.030290313065052032
Test Loss:  0.034300610423088074
Valid Loss:  0.03675209730863571
Epoch:  150  	Training Loss: 0.03028876893222332
Test Loss:  0.03429992496967316
Valid Loss:  0.03675101697444916
Epoch:  151  	Training Loss: 0.03028722107410431
Test Loss:  0.03429929539561272
Valid Loss:  0.03674992173910141
Epoch:  152  	Training Loss: 0.030285676941275597
Test Loss:  0.0342986099421978
Valid Loss:  0.03674883022904396
Epoch:  153  	Training Loss: 0.030284129083156586
Test Loss:  0.03429798036813736
Valid Loss:  0.03674772009253502
Epoch:  154  	Training Loss: 0.030282579362392426
Test Loss:  0.03429729491472244
Valid Loss:  0.036746636033058167
Epoch:  155  	Training Loss: 0.030281029641628265
Test Loss:  0.034296661615371704
Valid Loss:  0.036745525896549225
Epoch:  156  	Training Loss: 0.030279479920864105
Test Loss:  0.034295979887247086
Valid Loss:  0.03674444556236267
Epoch:  157  	Training Loss: 0.030277933925390244
Test Loss:  0.03429534658789635
Valid Loss:  0.03674333542585373
Epoch:  158  	Training Loss: 0.030276387929916382
Test Loss:  0.03429465740919113
Valid Loss:  0.03674224019050598
Epoch:  159  	Training Loss: 0.03027484193444252
Test Loss:  0.034294020384550095
Valid Loss:  0.03674113750457764
Epoch:  160  	Training Loss: 0.030273299664258957
Test Loss:  0.034293390810489655
Valid Loss:  0.036740031093358994
Epoch:  161  	Training Loss: 0.030271757394075394
Test Loss:  0.03429270535707474
Valid Loss:  0.03673894703388214
Epoch:  162  	Training Loss: 0.03027021884918213
Test Loss:  0.034292109310626984
Valid Loss:  0.03673788160085678
Epoch:  163  	Training Loss: 0.030268708243966103
Test Loss:  0.034291453659534454
Valid Loss:  0.036736827343702316
Epoch:  164  	Training Loss: 0.030267197638750076
Test Loss:  0.0342908576130867
Valid Loss:  0.03673575818538666
Epoch:  165  	Training Loss: 0.0302656851708889
Test Loss:  0.03429019823670387
Valid Loss:  0.03673470765352249
Epoch:  166  	Training Loss: 0.030264178290963173
Test Loss:  0.03428959473967552
Valid Loss:  0.036733631044626236
Epoch:  167  	Training Loss: 0.030262663960456848
Test Loss:  0.03428899496793747
Valid Loss:  0.03673255443572998
Epoch:  168  	Training Loss: 0.030261151492595673
Test Loss:  0.03428834676742554
Valid Loss:  0.03673151135444641
Epoch:  169  	Training Loss: 0.030259642750024796
Test Loss:  0.03428775072097778
Valid Loss:  0.036730438470840454
Epoch:  170  	Training Loss: 0.030258135870099068
Test Loss:  0.03428715467453003
Valid Loss:  0.036729373037815094
Epoch:  171  	Training Loss: 0.03025662526488304
Test Loss:  0.0342865064740181
Valid Loss:  0.03672831878066063
Epoch:  172  	Training Loss: 0.030255116522312164
Test Loss:  0.034285902976989746
Valid Loss:  0.036727242171764374
Epoch:  173  	Training Loss: 0.03025360032916069
Test Loss:  0.03428523615002632
Valid Loss:  0.03672616928815842
Epoch:  174  	Training Loss: 0.03025207854807377
Test Loss:  0.034284621477127075
Valid Loss:  0.036725081503391266
Epoch:  175  	Training Loss: 0.030250560492277145
Test Loss:  0.03428401052951813
Valid Loss:  0.03672399744391441
Epoch:  176  	Training Loss: 0.030249042436480522
Test Loss:  0.034283347427845
Valid Loss:  0.03672293573617935
Epoch:  177  	Training Loss: 0.030247528105974197
Test Loss:  0.03428274393081665
Valid Loss:  0.0367218554019928
Epoch:  178  	Training Loss: 0.03024601936340332
Test Loss:  0.034282136708498
Valid Loss:  0.036720775067806244
Epoch:  179  	Training Loss: 0.030244505032896996
Test Loss:  0.03428152576088905
Valid Loss:  0.03671969100832939
Epoch:  180  	Training Loss: 0.03024299442768097
Test Loss:  0.03428085893392563
Valid Loss:  0.03671862930059433
Epoch:  181  	Training Loss: 0.030241481959819794
Test Loss:  0.03428025543689728
Valid Loss:  0.036717548966407776
Epoch:  182  	Training Loss: 0.030239973217248917
Test Loss:  0.03427966684103012
Valid Loss:  0.036716483533382416
Epoch:  183  	Training Loss: 0.030238473787903786
Test Loss:  0.034279026091098785
Valid Loss:  0.03671543672680855
Epoch:  184  	Training Loss: 0.030236974358558655
Test Loss:  0.03427843749523163
Valid Loss:  0.03671437129378319
Epoch:  185  	Training Loss: 0.030235474929213524
Test Loss:  0.03427783399820328
Valid Loss:  0.03671329841017723
Epoch:  186  	Training Loss: 0.030233971774578094
Test Loss:  0.03427725285291672
Valid Loss:  0.03671223297715187
Epoch:  187  	Training Loss: 0.030232470482587814
Test Loss:  0.034276608377695084
Valid Loss:  0.036711186170578
Epoch:  188  	Training Loss: 0.03023098036646843
Test Loss:  0.03427601605653763
Valid Loss:  0.03671012446284294
Epoch:  189  	Training Loss: 0.030229482799768448
Test Loss:  0.03427542746067047
Valid Loss:  0.03670905902981758
Epoch:  190  	Training Loss: 0.030227988958358765
Test Loss:  0.034274838864803314
Valid Loss:  0.03670798987150192
Epoch:  191  	Training Loss: 0.03022649511694908
Test Loss:  0.03427419066429138
Valid Loss:  0.03670694679021835
Epoch:  192  	Training Loss: 0.030225005000829697
Test Loss:  0.03427359089255333
Valid Loss:  0.03670588135719299
Epoch:  193  	Training Loss: 0.03022351674735546
Test Loss:  0.03427298739552498
Valid Loss:  0.03670480102300644
Epoch:  194  	Training Loss: 0.030222030356526375
Test Loss:  0.034272387623786926
Valid Loss:  0.03670373186469078
Epoch:  195  	Training Loss: 0.03022054210305214
Test Loss:  0.0342717282474041
Valid Loss:  0.03670267388224602
Epoch:  196  	Training Loss: 0.030219051986932755
Test Loss:  0.034271128475666046
Valid Loss:  0.03670160472393036
Epoch:  197  	Training Loss: 0.030217567458748817
Test Loss:  0.034270524978637695
Valid Loss:  0.0367005318403244
Epoch:  198  	Training Loss: 0.030216079205274582
Test Loss:  0.03426992893218994
Valid Loss:  0.036699458956718445
Epoch:  199  	Training Loss: 0.030214592814445496
Test Loss:  0.034269317984580994
Valid Loss:  0.036698393523693085
Epoch:  200  	Training Loss: 0.03021310456097126
Test Loss:  0.034268662333488464
Valid Loss:  0.03669734299182892
Epoch:  201  	Training Loss: 0.030211620032787323
Test Loss:  0.034268055111169815
Valid Loss:  0.03669627010822296
Epoch:  202  	Training Loss: 0.030210137367248535
Test Loss:  0.03426744416356087
Valid Loss:  0.03669518977403641
Epoch:  203  	Training Loss: 0.030208643525838852
Test Loss:  0.034266822040081024
Valid Loss:  0.03669410198926926
Epoch:  204  	Training Loss: 0.03020714409649372
Test Loss:  0.03426620364189148
Valid Loss:  0.036693014204502106
Epoch:  205  	Training Loss: 0.03020564466714859
Test Loss:  0.034265585243701935
Valid Loss:  0.036691926419734955
Epoch:  206  	Training Loss: 0.03020414710044861
Test Loss:  0.03426496684551239
Valid Loss:  0.036690838634967804
Epoch:  207  	Training Loss: 0.030202649533748627
Test Loss:  0.03426429629325867
Valid Loss:  0.036689773201942444
Epoch:  208  	Training Loss: 0.030201157554984093
Test Loss:  0.034263674169778824
Valid Loss:  0.036688681691884995
Epoch:  209  	Training Loss: 0.03019966185092926
Test Loss:  0.03426305949687958
Valid Loss:  0.03668760135769844
Epoch:  210  	Training Loss: 0.030198168009519577
Test Loss:  0.034262433648109436
Valid Loss:  0.03668650984764099
Epoch:  211  	Training Loss: 0.030196676030755043
Test Loss:  0.03426181524991989
Valid Loss:  0.03668542578816414
Epoch:  212  	Training Loss: 0.030195185914635658
Test Loss:  0.034261178225278854
Valid Loss:  0.03668433055281639
Epoch:  213  	Training Loss: 0.030193695798516273
Test Loss:  0.03426053375005722
Valid Loss:  0.03668323531746864
Epoch:  214  	Training Loss: 0.030192207545042038
Test Loss:  0.034259893000125885
Valid Loss:  0.0366821326315403
 43%|████▎     | 215/500 [02:32<03:00,  1.58it/s] 43%|████▎     | 217/500 [02:33<02:11,  2.15it/s] 44%|████▍     | 219/500 [02:33<01:37,  2.89it/s] 44%|████▍     | 221/500 [02:39<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:39<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:39<02:03,  2.20it/s] 46%|████▌     | 229/500 [02:40<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:46<05:26,  1.21s/it] 47%|████▋     | 233/500 [02:46<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:46<02:47,  1.58it/s] 47%|████▋     | 237/500 [02:47<02:03,  2.13it/s] 48%|████▊     | 239/500 [02:47<01:31,  2.85it/s] 48%|████▊     | 241/500 [02:53<05:13,  1.21s/it] 49%|████▊     | 243/500 [02:53<03:43,  1.15it/s] 49%|████▉     | 245/500 [02:53<02:40,  1.59it/s] 49%|████▉     | 247/500 [02:54<01:56,  2.18it/s] 50%|████▉     | 249/500 [02:54<01:25,  2.93it/s] 50%|█████     | 251/500 [03:00<04:54,  1.18s/it] 51%|█████     | 253/500 [03:00<03:30,  1.18it/s] 51%|█████     | 255/500 [03:00<02:30,  1.62it/s] 51%|█████▏    | 257/500 [03:00<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:01<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:07<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:07<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:07<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:07<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:07<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:14<04:33,  1.19s/it] 55%|█████▍    | 273/500 [03:14<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:14<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:14<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:21<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:21<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:21<02:12,  1.62it/s]Epoch:  215  	Training Loss: 0.0301907230168581
Test Loss:  0.034259259700775146
Valid Loss:  0.036681048572063446
Epoch:  216  	Training Loss: 0.030189236626029015
Test Loss:  0.03425862267613411
Valid Loss:  0.0366799458861351
Epoch:  217  	Training Loss: 0.030187752097845078
Test Loss:  0.034257933497428894
Valid Loss:  0.036678873002529144
Epoch:  218  	Training Loss: 0.03018626943230629
Test Loss:  0.034257300198078156
Valid Loss:  0.036677777767181396
Epoch:  219  	Training Loss: 0.0301847904920578
Test Loss:  0.03425666317343712
Valid Loss:  0.036676689982414246
Epoch:  220  	Training Loss: 0.030183307826519012
Test Loss:  0.03425602614879608
Valid Loss:  0.036675602197647095
Epoch:  221  	Training Loss: 0.03018183261156082
Test Loss:  0.034255389124155045
Valid Loss:  0.03667450696229935
Epoch:  222  	Training Loss: 0.030180351808667183
Test Loss:  0.03425480052828789
Valid Loss:  0.03667345643043518
Epoch:  223  	Training Loss: 0.03017888404428959
Test Loss:  0.03425420820713043
Valid Loss:  0.03667239844799042
Epoch:  224  	Training Loss: 0.030177418142557144
Test Loss:  0.03425361216068268
Valid Loss:  0.036671340465545654
Epoch:  225  	Training Loss: 0.03017595037817955
Test Loss:  0.03425302356481552
Valid Loss:  0.03667027875781059
Epoch:  226  	Training Loss: 0.030174482613801956
Test Loss:  0.034252431243658066
Valid Loss:  0.036669231951236725
Epoch:  227  	Training Loss: 0.03017301857471466
Test Loss:  0.03425184637308121
Valid Loss:  0.03666817396879196
Epoch:  228  	Training Loss: 0.030171558260917664
Test Loss:  0.034251246601343155
Valid Loss:  0.036667123436927795
Epoch:  229  	Training Loss: 0.030170094221830368
Test Loss:  0.0342506542801857
Valid Loss:  0.03666606545448303
Epoch:  230  	Training Loss: 0.030168626457452774
Test Loss:  0.03425005078315735
Valid Loss:  0.03666500747203827
Epoch:  231  	Training Loss: 0.03016715869307518
Test Loss:  0.03424946218729019
Valid Loss:  0.036663953214883804
Epoch:  232  	Training Loss: 0.030165698379278183
Test Loss:  0.034248895943164825
Valid Loss:  0.036662910133600235
Epoch:  233  	Training Loss: 0.03016422502696514
Test Loss:  0.034248314797878265
Valid Loss:  0.03666186332702637
Epoch:  234  	Training Loss: 0.0301627479493618
Test Loss:  0.0342477485537529
Valid Loss:  0.0366608202457428
Epoch:  235  	Training Loss: 0.03016127273440361
Test Loss:  0.03424715995788574
Valid Loss:  0.03665976598858833
Epoch:  236  	Training Loss: 0.03015979193150997
Test Loss:  0.03424658253788948
Valid Loss:  0.03665871173143387
Epoch:  237  	Training Loss: 0.03015831485390663
Test Loss:  0.03424600511789322
Valid Loss:  0.0366576686501503
Epoch:  238  	Training Loss: 0.03015683777630329
Test Loss:  0.03424542397260666
Valid Loss:  0.03665662184357643
Epoch:  239  	Training Loss: 0.030155356973409653
Test Loss:  0.0342448391020298
Valid Loss:  0.036655575037002563
Epoch:  240  	Training Loss: 0.030153881758451462
Test Loss:  0.03424426168203354
Valid Loss:  0.0366545207798481
Epoch:  241  	Training Loss: 0.030152400955557823
Test Loss:  0.03424368426203728
Valid Loss:  0.03665347397327423
Epoch:  242  	Training Loss: 0.030150923877954483
Test Loss:  0.034243062138557434
Valid Loss:  0.03665239363908768
Epoch:  243  	Training Loss: 0.030149441212415695
Test Loss:  0.034242428839206696
Valid Loss:  0.03665132075548172
Epoch:  244  	Training Loss: 0.030147960409522057
Test Loss:  0.03424180671572685
Valid Loss:  0.036650244146585464
Epoch:  245  	Training Loss: 0.03014647774398327
Test Loss:  0.03424118086695671
Valid Loss:  0.03664916753768921
Epoch:  246  	Training Loss: 0.03014499694108963
Test Loss:  0.03424055129289627
Valid Loss:  0.036648087203502655
Epoch:  247  	Training Loss: 0.030143512412905693
Test Loss:  0.034239914268255234
Valid Loss:  0.0366470031440258
Epoch:  248  	Training Loss: 0.030142027884721756
Test Loss:  0.034239284694194794
Valid Loss:  0.03664592653512955
Epoch:  249  	Training Loss: 0.030140547081828117
Test Loss:  0.03423865884542465
Valid Loss:  0.03664484992623329
Epoch:  250  	Training Loss: 0.03013906255364418
Test Loss:  0.03423808515071869
Valid Loss:  0.036643754690885544
Epoch:  251  	Training Loss: 0.03013758175075054
Test Loss:  0.03423745185136795
Valid Loss:  0.03664267808198929
Epoch:  252  	Training Loss: 0.030136100947856903
Test Loss:  0.034236833453178406
Valid Loss:  0.03664161264896393
Epoch:  253  	Training Loss: 0.03013463504612446
Test Loss:  0.03423621132969856
Valid Loss:  0.03664054721593857
Epoch:  254  	Training Loss: 0.030133165419101715
Test Loss:  0.03423558920621872
Valid Loss:  0.036639485508203506
Epoch:  255  	Training Loss: 0.03013170138001442
Test Loss:  0.034234970808029175
Valid Loss:  0.03663841634988785
Epoch:  256  	Training Loss: 0.030130235478281975
Test Loss:  0.03423440456390381
Valid Loss:  0.0366373285651207
Epoch:  257  	Training Loss: 0.030128762125968933
Test Loss:  0.034233786165714264
Valid Loss:  0.03663626313209534
Epoch:  258  	Training Loss: 0.030127298086881638
Test Loss:  0.03423316031694412
Valid Loss:  0.036635205149650574
Epoch:  259  	Training Loss: 0.030125834047794342
Test Loss:  0.034232545644044876
Valid Loss:  0.036634139716625214
Epoch:  260  	Training Loss: 0.030124368146061897
Test Loss:  0.034231919795274734
Valid Loss:  0.03663307800889015
Epoch:  261  	Training Loss: 0.03012290596961975
Test Loss:  0.03423135727643967
Valid Loss:  0.0366319976747036
Epoch:  262  	Training Loss: 0.030121441930532455
Test Loss:  0.034230757504701614
Valid Loss:  0.03663095459342003
Epoch:  263  	Training Loss: 0.030119992792606354
Test Loss:  0.034230150282382965
Valid Loss:  0.03662991151213646
Epoch:  264  	Training Loss: 0.030118538066744804
Test Loss:  0.03422953933477402
Valid Loss:  0.03662887215614319
Epoch:  265  	Training Loss: 0.030117085203528404
Test Loss:  0.03422894328832626
Valid Loss:  0.03662782907485962
Epoch:  266  	Training Loss: 0.030115636065602303
Test Loss:  0.03422839194536209
Valid Loss:  0.03662676736712456
Epoch:  267  	Training Loss: 0.0301141869276762
Test Loss:  0.03422779589891434
Valid Loss:  0.036625735461711884
Epoch:  268  	Training Loss: 0.03011273965239525
Test Loss:  0.03422718495130539
Valid Loss:  0.036624692380428314
Epoch:  269  	Training Loss: 0.030111292377114296
Test Loss:  0.034226641058921814
Valid Loss:  0.03662363439798355
Epoch:  270  	Training Loss: 0.030109845101833344
Test Loss:  0.03422603756189346
Valid Loss:  0.03662259131669998
Epoch:  271  	Training Loss: 0.03010839968919754
Test Loss:  0.03422543406486511
Valid Loss:  0.03662155568599701
Epoch:  272  	Training Loss: 0.03010695055127144
Test Loss:  0.034224800765514374
Valid Loss:  0.036620497703552246
Epoch:  273  	Training Loss: 0.030105499550700188
Test Loss:  0.03422423452138901
Valid Loss:  0.03661942109465599
Epoch:  274  	Training Loss: 0.030104052275419235
Test Loss:  0.034223608672618866
Valid Loss:  0.036618366837501526
Epoch:  275  	Training Loss: 0.030102603137493134
Test Loss:  0.03422297537326813
Valid Loss:  0.03661730885505676
Epoch:  276  	Training Loss: 0.030101152136921883
Test Loss:  0.03422240912914276
Valid Loss:  0.036616235971450806
Epoch:  277  	Training Loss: 0.03009970858693123
Test Loss:  0.03422178328037262
Valid Loss:  0.03661517798900604
Epoch:  278  	Training Loss: 0.030098259449005127
Test Loss:  0.03422115743160248
Valid Loss:  0.036614131182432175
Epoch:  279  	Training Loss: 0.030096814036369324
Test Loss:  0.034220583736896515
Valid Loss:  0.03661305457353592
Epoch:  280  	Training Loss: 0.03009537234902382
Test Loss:  0.034219954162836075
Valid Loss:  0.03661200404167175
Epoch:  281  	Training Loss: 0.030093926936388016
Test Loss:  0.034219324588775635
Valid Loss:  0.03661095350980759
Epoch:  282  	Training Loss: 0.030092477798461914
Test Loss:  0.034218739718198776
Valid Loss:  0.036609865725040436
Epoch:  283  	Training Loss: 0.030091024935245514
Test Loss:  0.03421809524297714
Valid Loss:  0.036608800292015076
Epoch:  284  	Training Loss: 0.030089570209383965
Test Loss:  0.03421745076775551
Valid Loss:  0.03660773113369942
Epoch:  285  	Training Loss: 0.030088115483522415
Test Loss:  0.03421685844659805
Valid Loss:  0.036606647074222565
 57%|█████▋    | 287/500 [03:21<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:21<01:11,  2.97it/s] 58%|█████▊    | 291/500 [03:28<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:28<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:28<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:28<01:34,  2.16it/s] 60%|█████▉    | 299/500 [03:28<01:10,  2.85it/s] 60%|██████    | 301/500 [03:35<04:03,  1.22s/it] 61%|██████    | 303/500 [03:35<02:53,  1.14it/s] 61%|██████    | 305/500 [03:35<02:03,  1.57it/s] 61%|██████▏   | 307/500 [03:35<01:29,  2.15it/s] 62%|██████▏   | 309/500 [03:35<01:06,  2.87it/s] 62%|██████▏   | 311/500 [03:42<03:49,  1.21s/it] 63%|██████▎   | 313/500 [03:42<02:42,  1.15it/s] 63%|██████▎   | 315/500 [03:42<01:56,  1.59it/s] 63%|██████▎   | 317/500 [03:42<01:24,  2.17it/s] 64%|██████▍   | 319/500 [03:42<01:01,  2.92it/s] 64%|██████▍   | 321/500 [03:49<03:36,  1.21s/it] 65%|██████▍   | 323/500 [03:49<02:33,  1.15it/s] 65%|██████▌   | 325/500 [03:49<01:49,  1.59it/s] 65%|██████▌   | 327/500 [03:49<01:20,  2.15it/s] 66%|██████▌   | 329/500 [03:49<00:59,  2.88it/s] 66%|██████▌   | 331/500 [03:56<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:56<02:24,  1.16it/s] 67%|██████▋   | 335/500 [03:56<01:43,  1.60it/s] 67%|██████▋   | 337/500 [03:56<01:14,  2.19it/s] 68%|██████▊   | 339/500 [03:56<00:54,  2.93it/s] 68%|██████▊   | 341/500 [04:03<03:11,  1.21s/it] 69%|██████▊   | 343/500 [04:03<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:03<01:37,  1.60it/s] 69%|██████▉   | 347/500 [04:03<01:10,  2.18it/s] 70%|██████▉   | 349/500 [04:03<00:51,  2.93it/s] 70%|███████   | 351/500 [04:10<02:59,  1.20s/it] 71%|███████   | 353/500 [04:10<02:07,  1.16it/s] 71%|███████   | 355/500 [04:10<01:31,  1.58it/s]Epoch:  286  	Training Loss: 0.030086658895015717
Test Loss:  0.03421621769666672
Valid Loss:  0.0366055965423584
Epoch:  287  	Training Loss: 0.030085211619734764
Test Loss:  0.03421557694673538
Valid Loss:  0.03660453110933304
Epoch:  288  	Training Loss: 0.030083760619163513
Test Loss:  0.03421498462557793
Valid Loss:  0.03660344332456589
Epoch:  289  	Training Loss: 0.030082305893301964
Test Loss:  0.03421434015035629
Valid Loss:  0.03660237789154053
Epoch:  290  	Training Loss: 0.03008085861802101
Test Loss:  0.03421374410390854
Valid Loss:  0.03660129755735397
Epoch:  291  	Training Loss: 0.03007940575480461
Test Loss:  0.0342131033539772
Valid Loss:  0.03660023212432861
Epoch:  292  	Training Loss: 0.03007795661687851
Test Loss:  0.034212421625852585
Valid Loss:  0.03659914433956146
Epoch:  293  	Training Loss: 0.03007650002837181
Test Loss:  0.03421180695295334
Valid Loss:  0.036598045378923416
Epoch:  294  	Training Loss: 0.030075039714574814
Test Loss:  0.03421112149953842
Valid Loss:  0.036596961319446564
Epoch:  295  	Training Loss: 0.030073583126068115
Test Loss:  0.03421050310134888
Valid Loss:  0.03659585863351822
Epoch:  296  	Training Loss: 0.030072126537561417
Test Loss:  0.03420981764793396
Valid Loss:  0.03659477084875107
Epoch:  297  	Training Loss: 0.03007066622376442
Test Loss:  0.03420919179916382
Valid Loss:  0.03659366816282272
Epoch:  298  	Training Loss: 0.03006920777261257
Test Loss:  0.0342085063457489
Valid Loss:  0.03659258037805557
Epoch:  299  	Training Loss: 0.030067749321460724
Test Loss:  0.03420787304639816
Valid Loss:  0.03659146651625633
Epoch:  300  	Training Loss: 0.030066289007663727
Test Loss:  0.03420718386769295
Valid Loss:  0.03659037873148918
Epoch:  301  	Training Loss: 0.03006482869386673
Test Loss:  0.03420654684305191
Valid Loss:  0.03658927232027054
Epoch:  302  	Training Loss: 0.030063368380069733
Test Loss:  0.034205976873636246
Valid Loss:  0.036588288843631744
Epoch:  303  	Training Loss: 0.030061982572078705
Test Loss:  0.03420546278357506
Valid Loss:  0.036587297916412354
Epoch:  304  	Training Loss: 0.030060596764087677
Test Loss:  0.03420490399003029
Valid Loss:  0.036586325615644455
Epoch:  305  	Training Loss: 0.030059218406677246
Test Loss:  0.0342043898999691
Valid Loss:  0.036585330963134766
Epoch:  306  	Training Loss: 0.030057836323976517
Test Loss:  0.03420381620526314
Valid Loss:  0.03658435493707657
Epoch:  307  	Training Loss: 0.030056454241275787
Test Loss:  0.03420329838991165
Valid Loss:  0.03658336028456688
Epoch:  308  	Training Loss: 0.030055072158575058
Test Loss:  0.03420272469520569
Valid Loss:  0.03658238798379898
Epoch:  309  	Training Loss: 0.03005369007587433
Test Loss:  0.0342022180557251
Valid Loss:  0.03658139705657959
Epoch:  310  	Training Loss: 0.030052313581109047
Test Loss:  0.03420165181159973
Valid Loss:  0.03658042848110199
Epoch:  311  	Training Loss: 0.030050933361053467
Test Loss:  0.034201133996248245
Valid Loss:  0.0365794338285923
Epoch:  312  	Training Loss: 0.030049551278352737
Test Loss:  0.034200519323349
Valid Loss:  0.036578405648469925
Epoch:  313  	Training Loss: 0.030048124492168427
Test Loss:  0.034199945628643036
Valid Loss:  0.03657735884189606
Epoch:  314  	Training Loss: 0.030046695843338966
Test Loss:  0.03419932350516319
Valid Loss:  0.03657632693648338
Epoch:  315  	Training Loss: 0.030045270919799805
Test Loss:  0.034198760986328125
Valid Loss:  0.036575280129909515
Epoch:  316  	Training Loss: 0.030043842270970345
Test Loss:  0.03419818729162216
Valid Loss:  0.036574237048625946
Epoch:  317  	Training Loss: 0.030042417347431183
Test Loss:  0.03419756144285202
Valid Loss:  0.036573201417922974
Epoch:  318  	Training Loss: 0.030040990561246872
Test Loss:  0.034196995198726654
Valid Loss:  0.036572154611349106
Epoch:  319  	Training Loss: 0.030039561912417412
Test Loss:  0.03419636934995651
Valid Loss:  0.03657113015651703
Epoch:  320  	Training Loss: 0.0300381388515234
Test Loss:  0.034195803105831146
Valid Loss:  0.036570075899362564
Epoch:  321  	Training Loss: 0.03003671206533909
Test Loss:  0.034195173531770706
Valid Loss:  0.036569055169820786
Epoch:  322  	Training Loss: 0.030035285279154778
Test Loss:  0.03419453650712967
Valid Loss:  0.03656793385744095
Epoch:  323  	Training Loss: 0.030033817514777184
Test Loss:  0.03419390320777893
Valid Loss:  0.03656682372093201
Epoch:  324  	Training Loss: 0.030032353475689888
Test Loss:  0.03419320285320282
Valid Loss:  0.03656572103500366
Epoch:  325  	Training Loss: 0.030030887573957443
Test Loss:  0.034192562103271484
Valid Loss:  0.03656461089849472
Epoch:  326  	Training Loss: 0.030029423534870148
Test Loss:  0.03419192135334015
Valid Loss:  0.03656349331140518
Epoch:  327  	Training Loss: 0.030027957633137703
Test Loss:  0.034191228449344635
Valid Loss:  0.036562398076057434
Epoch:  328  	Training Loss: 0.030026491731405258
Test Loss:  0.0341905802488327
Valid Loss:  0.036561280488967896
Epoch:  329  	Training Loss: 0.030025027692317963
Test Loss:  0.034189946949481964
Valid Loss:  0.036560166627168655
Epoch:  330  	Training Loss: 0.030023563653230667
Test Loss:  0.034189239144325256
Valid Loss:  0.036559075117111206
Epoch:  331  	Training Loss: 0.030022097751498222
Test Loss:  0.03418859839439392
Valid Loss:  0.03655795380473137
Epoch:  332  	Training Loss: 0.030020635575056076
Test Loss:  0.034187886863946915
Valid Loss:  0.03655677288770676
Epoch:  333  	Training Loss: 0.03001912496984005
Test Loss:  0.03418712317943573
Valid Loss:  0.036555610597133636
Epoch:  334  	Training Loss: 0.030017618089914322
Test Loss:  0.034186407923698425
Valid Loss:  0.03655443340539932
Epoch:  335  	Training Loss: 0.030016113072633743
Test Loss:  0.03418570011854172
Valid Loss:  0.03655324876308441
Epoch:  336  	Training Loss: 0.030014604330062866
Test Loss:  0.03418494015932083
Valid Loss:  0.036552101373672485
Epoch:  337  	Training Loss: 0.030013106763362885
Test Loss:  0.034184228628873825
Valid Loss:  0.036550916731357574
Epoch:  338  	Training Loss: 0.030011596158146858
Test Loss:  0.03418351337313652
Valid Loss:  0.03654973953962326
Epoch:  339  	Training Loss: 0.03001009114086628
Test Loss:  0.034182801842689514
Valid Loss:  0.03654855862259865
Epoch:  340  	Training Loss: 0.03000858798623085
Test Loss:  0.03418204188346863
Valid Loss:  0.036547403782606125
Epoch:  341  	Training Loss: 0.03000708669424057
Test Loss:  0.03418133407831192
Valid Loss:  0.03654623404145241
Epoch:  342  	Training Loss: 0.03000558540225029
Test Loss:  0.034180834889411926
Valid Loss:  0.0365452766418457
Epoch:  343  	Training Loss: 0.030004248023033142
Test Loss:  0.03418033570051193
Valid Loss:  0.0365443229675293
Epoch:  344  	Training Loss: 0.030002914369106293
Test Loss:  0.03417977690696716
Valid Loss:  0.03654337674379349
Epoch:  345  	Training Loss: 0.030001576989889145
Test Loss:  0.03417927771806717
Valid Loss:  0.03654242306947708
Epoch:  346  	Training Loss: 0.030000239610671997
Test Loss:  0.034178778529167175
Valid Loss:  0.03654147684574127
Epoch:  347  	Training Loss: 0.029998909682035446
Test Loss:  0.03417827934026718
Valid Loss:  0.03654053062200546
Epoch:  348  	Training Loss: 0.029997579753398895
Test Loss:  0.03417772427201271
Valid Loss:  0.03653959557414055
Epoch:  349  	Training Loss: 0.029996246099472046
Test Loss:  0.034177228808403015
Valid Loss:  0.03653864562511444
Epoch:  350  	Training Loss: 0.029994916170835495
Test Loss:  0.03417673334479332
Valid Loss:  0.03653770312666893
Epoch:  351  	Training Loss: 0.029993589967489243
Test Loss:  0.034176237881183624
Valid Loss:  0.03653675317764282
Epoch:  352  	Training Loss: 0.02999226003885269
Test Loss:  0.034175582230091095
Valid Loss:  0.03653562813997269
Epoch:  353  	Training Loss: 0.02999076060950756
Test Loss:  0.03417485952377319
Valid Loss:  0.03653449937701225
Epoch:  354  	Training Loss: 0.029989255592226982
Test Loss:  0.03417420759797096
Valid Loss:  0.03653337061405182
Epoch:  355  	Training Loss: 0.02998775616288185
Test Loss:  0.03417355194687843
Valid Loss:  0.036532238125801086
Epoch:  356  	Training Loss: 0.02998625487089157
Test Loss:  0.034172892570495605
Valid Loss:  0.03653110936284065
 71%|███████▏  | 357/500 [04:10<01:06,  2.14it/s] 72%|███████▏  | 359/500 [04:10<00:49,  2.88it/s] 72%|███████▏  | 361/500 [04:17<02:50,  1.23s/it] 73%|███████▎  | 363/500 [04:17<02:00,  1.13it/s] 73%|███████▎  | 365/500 [04:17<01:26,  1.57it/s] 73%|███████▎  | 367/500 [04:17<01:01,  2.15it/s] 74%|███████▍  | 369/500 [04:18<00:45,  2.89it/s] 74%|███████▍  | 371/500 [04:24<02:39,  1.24s/it] 75%|███████▍  | 373/500 [04:24<01:52,  1.12it/s] 75%|███████▌  | 375/500 [04:24<01:20,  1.56it/s] 75%|███████▌  | 377/500 [04:25<00:57,  2.13it/s] 76%|███████▌  | 379/500 [04:25<00:42,  2.86it/s] 76%|███████▌  | 381/500 [04:31<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:31<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:31<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:31<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:38<02:09,  1.18s/it] 79%|███████▊  | 393/500 [04:38<01:31,  1.18it/s] 79%|███████▉  | 395/500 [04:38<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:38<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:39<00:34,  2.92it/s] 80%|████████  | 401/500 [04:45<01:58,  1.20s/it] 81%|████████  | 403/500 [04:45<01:23,  1.16it/s] 81%|████████  | 405/500 [04:45<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:45<00:42,  2.19it/s] 82%|████████▏ | 409/500 [04:45<00:31,  2.90it/s] 82%|████████▏ | 411/500 [04:52<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:52<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:52<00:52,  1.60it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.95it/s] 84%|████████▍ | 421/500 [04:59<01:36,  1.22s/it] 85%|████████▍ | 423/500 [04:59<01:07,  1.14it/s] 85%|████████▌ | 425/500 [04:59<00:47,  1.58it/s] 85%|████████▌ | 427/500 [04:59<00:33,  2.16it/s]Epoch:  357  	Training Loss: 0.02998475357890129
Test Loss:  0.03417222946882248
Valid Loss:  0.03652997314929962
Epoch:  358  	Training Loss: 0.02998325228691101
Test Loss:  0.034171562641859055
Valid Loss:  0.036528825759887695
Epoch:  359  	Training Loss: 0.029981743544340134
Test Loss:  0.03417084738612175
Valid Loss:  0.036527715623378754
Epoch:  360  	Training Loss: 0.029980242252349854
Test Loss:  0.034170180559158325
Valid Loss:  0.036526575684547424
Epoch:  361  	Training Loss: 0.029978737235069275
Test Loss:  0.0341695211827755
Valid Loss:  0.03652544319629669
Epoch:  362  	Training Loss: 0.029977232217788696
Test Loss:  0.03416891396045685
Valid Loss:  0.03652437403798103
Epoch:  363  	Training Loss: 0.029975786805152893
Test Loss:  0.034168314188718796
Valid Loss:  0.03652330860495567
Epoch:  364  	Training Loss: 0.02997434139251709
Test Loss:  0.03416770324110985
Valid Loss:  0.036522239446640015
Epoch:  365  	Training Loss: 0.029972895979881287
Test Loss:  0.034167103469371796
Valid Loss:  0.036521170288324356
Epoch:  366  	Training Loss: 0.029971448704600334
Test Loss:  0.034166496247053146
Valid Loss:  0.036520108580589294
Epoch:  367  	Training Loss: 0.02997000142931938
Test Loss:  0.034165892750024796
Valid Loss:  0.036519039422273636
Epoch:  368  	Training Loss: 0.02996855229139328
Test Loss:  0.034165218472480774
Valid Loss:  0.036517977714538574
Epoch:  369  	Training Loss: 0.02996710315346718
Test Loss:  0.03416461497545242
Valid Loss:  0.036516912281513214
Epoch:  370  	Training Loss: 0.029965657740831375
Test Loss:  0.034164007753133774
Valid Loss:  0.036515846848487854
Epoch:  371  	Training Loss: 0.029964212328195572
Test Loss:  0.034163400530815125
Valid Loss:  0.036514777690172195
Epoch:  372  	Training Loss: 0.02996276319026947
Test Loss:  0.034162767231464386
Valid Loss:  0.036513689905405045
Epoch:  373  	Training Loss: 0.029961304739117622
Test Loss:  0.034162137657403946
Valid Loss:  0.03651260584592819
Epoch:  374  	Training Loss: 0.029959842562675476
Test Loss:  0.03416150435805321
Valid Loss:  0.036511510610580444
Epoch:  375  	Training Loss: 0.02995838224887848
Test Loss:  0.03416087478399277
Valid Loss:  0.03651043027639389
Epoch:  376  	Training Loss: 0.02995692938566208
Test Loss:  0.03416024520993233
Valid Loss:  0.03650934249162674
Epoch:  377  	Training Loss: 0.029955469071865082
Test Loss:  0.03415960818529129
Valid Loss:  0.03650825470685959
Epoch:  378  	Training Loss: 0.029954008758068085
Test Loss:  0.03415897861123085
Valid Loss:  0.03650716692209244
Epoch:  379  	Training Loss: 0.029952552169561386
Test Loss:  0.03415834158658981
Valid Loss:  0.03650607913732529
Epoch:  380  	Training Loss: 0.02995109185576439
Test Loss:  0.034157708287239075
Valid Loss:  0.03650498762726784
Epoch:  381  	Training Loss: 0.029949629679322243
Test Loss:  0.034157074987888336
Valid Loss:  0.03650389984250069
Epoch:  382  	Training Loss: 0.029948169365525246
Test Loss:  0.03415650129318237
Valid Loss:  0.03650288283824921
Epoch:  383  	Training Loss: 0.02994677983224392
Test Loss:  0.03415592759847641
Valid Loss:  0.036501865833997726
Epoch:  384  	Training Loss: 0.029945392161607742
Test Loss:  0.03415535017848015
Valid Loss:  0.03650084510445595
Epoch:  385  	Training Loss: 0.029944002628326416
Test Loss:  0.03415477275848389
Valid Loss:  0.03649982810020447
Epoch:  386  	Training Loss: 0.02994261309504509
Test Loss:  0.034154199063777924
Valid Loss:  0.03649880364537239
Epoch:  387  	Training Loss: 0.029941225424408913
Test Loss:  0.03415362164378166
Valid Loss:  0.03649779036641121
Epoch:  388  	Training Loss: 0.029939837753772736
Test Loss:  0.034153051674366
Valid Loss:  0.036496780812740326
Epoch:  389  	Training Loss: 0.029938453808426857
Test Loss:  0.03415248170495033
Valid Loss:  0.036495763808488846
Epoch:  390  	Training Loss: 0.02993706613779068
Test Loss:  0.03415190428495407
Valid Loss:  0.036494746804237366
Epoch:  391  	Training Loss: 0.029935680329799652
Test Loss:  0.03415133059024811
Valid Loss:  0.036493733525276184
Epoch:  392  	Training Loss: 0.029934294521808624
Test Loss:  0.03415072709321976
Valid Loss:  0.036492690443992615
Epoch:  393  	Training Loss: 0.029932886362075806
Test Loss:  0.03415011987090111
Valid Loss:  0.03649164363741875
Epoch:  394  	Training Loss: 0.029931478202342987
Test Loss:  0.03414951264858246
Valid Loss:  0.03649059683084488
Epoch:  395  	Training Loss: 0.02993006631731987
Test Loss:  0.03414890170097351
Valid Loss:  0.036489538848400116
Epoch:  396  	Training Loss: 0.029928652569651604
Test Loss:  0.03414829447865486
Valid Loss:  0.03648849576711655
Epoch:  397  	Training Loss: 0.029927244409918785
Test Loss:  0.034147683531045914
Valid Loss:  0.03648745268583298
Epoch:  398  	Training Loss: 0.029925836250185966
Test Loss:  0.03414708003401756
Valid Loss:  0.03648640960454941
Epoch:  399  	Training Loss: 0.029924426227808
Test Loss:  0.03414647653698921
Valid Loss:  0.03648536279797554
Epoch:  400  	Training Loss: 0.02992301993072033
Test Loss:  0.034145865589380264
Valid Loss:  0.03648431599140167
Epoch:  401  	Training Loss: 0.02992161363363266
Test Loss:  0.03414526209235191
Valid Loss:  0.0364832766354084
Epoch:  402  	Training Loss: 0.02992020547389984
Test Loss:  0.03414466232061386
Valid Loss:  0.036482248455286026
Epoch:  403  	Training Loss: 0.029918815940618515
Test Loss:  0.03414406627416611
Valid Loss:  0.03648121654987335
Epoch:  404  	Training Loss: 0.02991742640733719
Test Loss:  0.03414347022771835
Valid Loss:  0.036480192095041275
Epoch:  405  	Training Loss: 0.02991604059934616
Test Loss:  0.0341428741812706
Valid Loss:  0.0364791639149189
Epoch:  406  	Training Loss: 0.029914652928709984
Test Loss:  0.034142278134822845
Valid Loss:  0.03647814691066742
Epoch:  407  	Training Loss: 0.029913268983364105
Test Loss:  0.03414168208837509
Valid Loss:  0.036477118730545044
Epoch:  408  	Training Loss: 0.02991187945008278
Test Loss:  0.03414108604192734
Valid Loss:  0.03647609055042267
Epoch:  409  	Training Loss: 0.02991049736738205
Test Loss:  0.034140489995479584
Valid Loss:  0.03647507727146149
Epoch:  410  	Training Loss: 0.02990911155939102
Test Loss:  0.03413989022374153
Valid Loss:  0.03647404909133911
Epoch:  411  	Training Loss: 0.029907725751399994
Test Loss:  0.03413928672671318
Valid Loss:  0.03647302836179733
Epoch:  412  	Training Loss: 0.029906339943408966
Test Loss:  0.03413869068026543
Valid Loss:  0.03647199645638466
Epoch:  413  	Training Loss: 0.02990494854748249
Test Loss:  0.034138090908527374
Valid Loss:  0.036470964550971985
Epoch:  414  	Training Loss: 0.029903557151556015
Test Loss:  0.03413749113678932
Valid Loss:  0.03646993637084961
Epoch:  415  	Training Loss: 0.02990216203033924
Test Loss:  0.034136898815631866
Valid Loss:  0.03646891564130783
Epoch:  416  	Training Loss: 0.029900776222348213
Test Loss:  0.034136299043893814
Valid Loss:  0.036467887461185455
Epoch:  417  	Training Loss: 0.029899386689066887
Test Loss:  0.03413569927215576
Valid Loss:  0.03646685928106308
Epoch:  418  	Training Loss: 0.02989799715578556
Test Loss:  0.034135155379772186
Valid Loss:  0.03646581619977951
Epoch:  419  	Training Loss: 0.029896605759859085
Test Loss:  0.03413456678390503
Valid Loss:  0.03646480292081833
Epoch:  420  	Training Loss: 0.029895223677158356
Test Loss:  0.03413396701216698
Valid Loss:  0.036463771015405655
Epoch:  421  	Training Loss: 0.02989383600652218
Test Loss:  0.03413335978984833
Valid Loss:  0.03646274656057358
Epoch:  422  	Training Loss: 0.02989245019853115
Test Loss:  0.034132905304431915
Valid Loss:  0.03646177053451538
Epoch:  423  	Training Loss: 0.02989107370376587
Test Loss:  0.03413238376379013
Valid Loss:  0.03646080568432808
Epoch:  424  	Training Loss: 0.029889699071645737
Test Loss:  0.034131862223148346
Valid Loss:  0.03645984083414078
Epoch:  425  	Training Loss: 0.029888324439525604
Test Loss:  0.03413134440779686
Valid Loss:  0.03645887225866318
Epoch:  426  	Training Loss: 0.029886947944760323
Test Loss:  0.03413088619709015
Valid Loss:  0.03645789623260498
Epoch:  427  	Training Loss: 0.02988557517528534
Test Loss:  0.034130364656448364
Valid Loss:  0.03645693138241768
 86%|████████▌ | 429/500 [05:00<00:24,  2.90it/s] 86%|████████▌ | 431/500 [05:06<01:23,  1.20s/it] 87%|████████▋ | 433/500 [05:06<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:06<00:41,  1.57it/s] 87%|████████▋ | 437/500 [05:06<00:29,  2.13it/s] 88%|████████▊ | 439/500 [05:07<00:21,  2.87it/s] 88%|████████▊ | 441/500 [05:13<01:12,  1.23s/it] 89%|████████▊ | 443/500 [05:13<00:50,  1.13it/s] 89%|████████▉ | 445/500 [05:13<00:35,  1.57it/s] 89%|████████▉ | 447/500 [05:14<00:24,  2.14it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.89it/s] 90%|█████████ | 451/500 [05:20<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:20<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:21<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:27<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:27<00:15,  2.20it/s] 94%|█████████▍| 469/500 [05:28<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:34<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:34<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:34<00:07,  2.97it/s] 96%|█████████▌| 481/500 [05:41<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:41<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:48<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:48<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.17it/s]Epoch:  428  	Training Loss: 0.029884202405810356
Test Loss:  0.03412983566522598
Valid Loss:  0.036455973982810974
Epoch:  429  	Training Loss: 0.029882825911045074
Test Loss:  0.03412937372922897
Valid Loss:  0.03645499050617218
Epoch:  430  	Training Loss: 0.02988145314157009
Test Loss:  0.03412885218858719
Valid Loss:  0.03645402193069458
Epoch:  431  	Training Loss: 0.02988007478415966
Test Loss:  0.03412831574678421
Valid Loss:  0.03645305335521698
Epoch:  432  	Training Loss: 0.02987869642674923
Test Loss:  0.0341278538107872
Valid Loss:  0.03645206242799759
Epoch:  433  	Training Loss: 0.029877306893467903
Test Loss:  0.03412733972072601
Valid Loss:  0.036451101303100586
Epoch:  434  	Training Loss: 0.029875917360186577
Test Loss:  0.03412681072950363
Valid Loss:  0.03645012527704239
Epoch:  435  	Training Loss: 0.0298745259642601
Test Loss:  0.03412634879350662
Valid Loss:  0.036449141800403595
Epoch:  436  	Training Loss: 0.029873136430978775
Test Loss:  0.03412582725286484
Valid Loss:  0.036448173224925995
Epoch:  437  	Training Loss: 0.02987174689769745
Test Loss:  0.034125298261642456
Valid Loss:  0.036447200924158096
Epoch:  438  	Training Loss: 0.029870357364416122
Test Loss:  0.03412483632564545
Valid Loss:  0.0364462211728096
Epoch:  439  	Training Loss: 0.029868964105844498
Test Loss:  0.034124311059713364
Valid Loss:  0.0364452488720417
Epoch:  440  	Training Loss: 0.02986757457256317
Test Loss:  0.03412378579378128
Valid Loss:  0.0364442840218544
Epoch:  441  	Training Loss: 0.029866185039281845
Test Loss:  0.034123316407203674
Valid Loss:  0.03644328936934471
Epoch:  442  	Training Loss: 0.02986479178071022
Test Loss:  0.0341227687895298
Valid Loss:  0.03644232824444771
Epoch:  443  	Training Loss: 0.02986343577504158
Test Loss:  0.034122273325920105
Valid Loss:  0.036441341042518616
Epoch:  444  	Training Loss: 0.02986207976937294
Test Loss:  0.03412172198295593
Valid Loss:  0.03644037991762161
Epoch:  445  	Training Loss: 0.02986072190105915
Test Loss:  0.03412117063999176
Valid Loss:  0.036439403891563416
Epoch:  446  	Training Loss: 0.02985936775803566
Test Loss:  0.034120671451091766
Valid Loss:  0.03643842041492462
Epoch:  447  	Training Loss: 0.02985801175236702
Test Loss:  0.034120120108127594
Valid Loss:  0.03643745556473732
Epoch:  448  	Training Loss: 0.02985665388405323
Test Loss:  0.0341196171939373
Valid Loss:  0.036436472088098526
Epoch:  449  	Training Loss: 0.02985529415309429
Test Loss:  0.03411906585097313
Valid Loss:  0.03643549978733063
Epoch:  450  	Training Loss: 0.02985393814742565
Test Loss:  0.03411856293678284
Valid Loss:  0.036434516310691833
Epoch:  451  	Training Loss: 0.02985258214175701
Test Loss:  0.034118007868528366
Valid Loss:  0.03643354773521423
Epoch:  452  	Training Loss: 0.029851224273443222
Test Loss:  0.034117426723241806
Valid Loss:  0.03643248602747917
Epoch:  453  	Training Loss: 0.029849819839000702
Test Loss:  0.034116797149181366
Valid Loss:  0.036431439220905304
Epoch:  454  	Training Loss: 0.02984841726720333
Test Loss:  0.034116216003894806
Valid Loss:  0.03643038123846054
Epoch:  455  	Training Loss: 0.02984701283276081
Test Loss:  0.034115586429834366
Valid Loss:  0.03642933443188667
Epoch:  456  	Training Loss: 0.02984560839831829
Test Loss:  0.034115009009838104
Valid Loss:  0.03642827272415161
Epoch:  457  	Training Loss: 0.02984420582652092
Test Loss:  0.03411436825990677
Valid Loss:  0.03642723336815834
Epoch:  458  	Training Loss: 0.02984280325472355
Test Loss:  0.03411378711462021
Valid Loss:  0.03642617166042328
Epoch:  459  	Training Loss: 0.029841400682926178
Test Loss:  0.03411315008997917
Valid Loss:  0.03642512112855911
Epoch:  460  	Training Loss: 0.029839999973773956
Test Loss:  0.03411257266998291
Valid Loss:  0.036424070596694946
Epoch:  461  	Training Loss: 0.029838595539331436
Test Loss:  0.034111931920051575
Valid Loss:  0.03642302006483078
Epoch:  462  	Training Loss: 0.029837192967534065
Test Loss:  0.034111388027668
Valid Loss:  0.03642202168703079
Epoch:  463  	Training Loss: 0.029835864901542664
Test Loss:  0.03411078453063965
Valid Loss:  0.0364210344851017
Epoch:  464  	Training Loss: 0.029834531247615814
Test Loss:  0.03411024063825607
Valid Loss:  0.03642003610730171
Epoch:  465  	Training Loss: 0.02983320876955986
Test Loss:  0.03410964086651802
Valid Loss:  0.03641905263066292
Epoch:  466  	Training Loss: 0.02983187884092331
Test Loss:  0.03410908952355385
Valid Loss:  0.03641805425286293
Epoch:  467  	Training Loss: 0.029830552637577057
Test Loss:  0.034108489751815796
Valid Loss:  0.03641707822680473
Epoch:  468  	Training Loss: 0.029829226434230804
Test Loss:  0.03410794958472252
Valid Loss:  0.036416083574295044
Epoch:  469  	Training Loss: 0.02982790395617485
Test Loss:  0.034107401967048645
Valid Loss:  0.03641509264707565
Epoch:  470  	Training Loss: 0.029826579615473747
Test Loss:  0.03410680219531059
Valid Loss:  0.03641411289572716
Epoch:  471  	Training Loss: 0.029825257137417793
Test Loss:  0.034106262028217316
Valid Loss:  0.036413125693798065
Epoch:  472  	Training Loss: 0.02982393652200699
Test Loss:  0.03410566598176956
Valid Loss:  0.03641211614012718
Epoch:  473  	Training Loss: 0.029822558164596558
Test Loss:  0.034105122089385986
Valid Loss:  0.0364110991358757
Epoch:  474  	Training Loss: 0.029821183532476425
Test Loss:  0.03410458564758301
Valid Loss:  0.03641007840633392
Epoch:  475  	Training Loss: 0.029819808900356293
Test Loss:  0.03410398215055466
Valid Loss:  0.03640907257795334
Epoch:  476  	Training Loss: 0.029818430542945862
Test Loss:  0.03410343453288078
Valid Loss:  0.03640805929899216
Epoch:  477  	Training Loss: 0.029817059636116028
Test Loss:  0.03410283848643303
Valid Loss:  0.036407068371772766
Epoch:  478  	Training Loss: 0.029815688729286194
Test Loss:  0.034102290868759155
Valid Loss:  0.03640604019165039
Epoch:  479  	Training Loss: 0.02981431409716606
Test Loss:  0.03410175442695618
Valid Loss:  0.03640502691268921
Epoch:  480  	Training Loss: 0.02981293946504593
Test Loss:  0.034101150929927826
Valid Loss:  0.036404021084308624
Epoch:  481  	Training Loss: 0.029811564832925797
Test Loss:  0.034100595861673355
Valid Loss:  0.03640300780534744
Epoch:  482  	Training Loss: 0.029810190200805664
Test Loss:  0.0341000109910965
Valid Loss:  0.03640194982290268
Epoch:  483  	Training Loss: 0.02980879507958889
Test Loss:  0.03409937769174576
Valid Loss:  0.03640091419219971
Epoch:  484  	Training Loss: 0.029807401821017265
Test Loss:  0.0340987965464592
Valid Loss:  0.03639986738562584
Epoch:  485  	Training Loss: 0.02980600856244564
Test Loss:  0.03409820795059204
Valid Loss:  0.036398813128471375
Epoch:  486  	Training Loss: 0.029804617166519165
Test Loss:  0.034097567200660706
Valid Loss:  0.036397784948349
Epoch:  487  	Training Loss: 0.02980322577059269
Test Loss:  0.034096986055374146
Valid Loss:  0.036396726965904236
Epoch:  488  	Training Loss: 0.029801830649375916
Test Loss:  0.03409639745950699
Valid Loss:  0.03639567643404007
Epoch:  489  	Training Loss: 0.02980043552815914
Test Loss:  0.03409581258893013
Valid Loss:  0.0363946333527565
Epoch:  490  	Training Loss: 0.029799044132232666
Test Loss:  0.034095171838998795
Valid Loss:  0.03639359772205353
Epoch:  491  	Training Loss: 0.029797649011015892
Test Loss:  0.03409458324313164
Valid Loss:  0.03639254346489906
Epoch:  492  	Training Loss: 0.029796259477734566
Test Loss:  0.03409401699900627
Valid Loss:  0.036391522735357285
Epoch:  493  	Training Loss: 0.02979489043354988
Test Loss:  0.034093402326107025
Valid Loss:  0.0363905169069767
Epoch:  494  	Training Loss: 0.029793523252010345
Test Loss:  0.03409283608198166
Valid Loss:  0.03638949245214462
Epoch:  495  	Training Loss: 0.02979215607047081
Test Loss:  0.03409227356314659
Valid Loss:  0.03638847917318344
Epoch:  496  	Training Loss: 0.029790788888931274
Test Loss:  0.03409171104431152
Valid Loss:  0.03638745844364166
Epoch:  497  	Training Loss: 0.029789423570036888
Test Loss:  0.03409108147025108
Valid Loss:  0.036386460065841675
Epoch:  498  	Training Loss: 0.029788056388497353
Test Loss:  0.034090518951416016
Valid Loss:  0.0363854356110096
100%|█████████▉| 499/500 [05:48<00:00,  2.91it/s]100%|██████████| 500/500 [05:48<00:00,  1.43it/s]
Epoch:  499  	Training Loss: 0.02978668548166752
Test Loss:  0.03408995270729065
Valid Loss:  0.03638441115617752
Epoch:  500  	Training Loss: 0.029785318300127983
Test Loss:  0.03408938646316528
Valid Loss:  0.036383386701345444
seed is  11
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:16,  6.29s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:17,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<11:11,  1.37s/it]  3%|▎         | 13/500 [00:13<07:37,  1.06it/s]  3%|▎         | 15/500 [00:13<05:19,  1.52it/s]  3%|▎         | 17/500 [00:13<03:47,  2.12it/s]  4%|▍         | 19/500 [00:13<02:46,  2.89it/s]  4%|▍         | 21/500 [00:20<09:43,  1.22s/it]  5%|▍         | 23/500 [00:20<06:54,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:27<09:35,  1.23s/it]  7%|▋         | 33/500 [00:27<06:50,  1.14it/s]  7%|▋         | 35/500 [00:27<04:54,  1.58it/s]  7%|▋         | 37/500 [00:27<03:34,  2.16it/s]  8%|▊         | 39/500 [00:27<02:38,  2.90it/s]  8%|▊         | 41/500 [00:40<16:28,  2.15s/it]  9%|▊         | 43/500 [00:40<11:39,  1.53s/it]  9%|▉         | 45/500 [00:40<08:16,  1.09s/it]  9%|▉         | 47/500 [00:41<05:54,  1.28it/s] 10%|▉         | 49/500 [00:41<04:16,  1.76it/s] 10%|█         | 51/500 [00:47<10:27,  1.40s/it] 11%|█         | 53/500 [00:48<07:26,  1.00it/s] 11%|█         | 55/500 [00:48<05:20,  1.39it/s] 11%|█▏        | 57/500 [00:48<03:51,  1.91it/s] 12%|█▏        | 59/500 [00:48<02:50,  2.59it/s] 12%|█▏        | 61/500 [00:54<09:00,  1.23s/it] 13%|█▎        | 63/500 [00:55<06:26,  1.13it/s] 13%|█▎        | 65/500 [00:55<04:37,  1.57it/s] 13%|█▎        | 67/500 [00:55<03:21,  2.14it/s]Epoch:  1  	Training Loss: 0.029232734814286232
Test Loss:  0.024228084832429886
Valid Loss:  0.03312486410140991
Epoch:  2  	Training Loss: 0.04916759580373764
Test Loss:  0.13128352165222168
Valid Loss:  0.11860525608062744
Epoch:  3  	Training Loss: 0.0974411889910698
Test Loss:  0.010591709986329079
Valid Loss:  0.017464835196733475
Epoch:  4  	Training Loss: 0.026386234909296036
Test Loss:  0.01046136487275362
Valid Loss:  0.01725529134273529
Epoch:  5  	Training Loss: 0.02614223212003708
Test Loss:  0.010377169586718082
Valid Loss:  0.017070207744836807
Epoch:  6  	Training Loss: 0.025953486561775208
Test Loss:  0.010296854190528393
Valid Loss:  0.01689596101641655
Epoch:  7  	Training Loss: 0.02577773667871952
Test Loss:  0.010217109695076942
Valid Loss:  0.016712941229343414
Epoch:  8  	Training Loss: 0.0256008580327034
Test Loss:  0.010124865919351578
Valid Loss:  0.016518156975507736
Epoch:  9  	Training Loss: 0.025399571284651756
Test Loss:  0.009994059801101685
Valid Loss:  0.016300465911626816
Epoch:  10  	Training Loss: 0.02515358477830887
Test Loss:  0.009821108542382717
Valid Loss:  0.016051923856139183
Epoch:  11  	Training Loss: 0.024856174364686012
Test Loss:  0.009594823233783245
Valid Loss:  0.015741433948278427
Epoch:  12  	Training Loss: 0.024480102583765984
Test Loss:  0.012168379500508308
Valid Loss:  0.013034874573349953
Epoch:  13  	Training Loss: 0.013577794656157494
Test Loss:  0.006730425171554089
Valid Loss:  0.006990017369389534
Epoch:  14  	Training Loss: 0.007949205115437508
Test Loss:  0.0046849800273776054
Valid Loss:  0.004553909879177809
Epoch:  15  	Training Loss: 0.006031127646565437
Test Loss:  0.003705778159201145
Valid Loss:  0.003363749012351036
Epoch:  16  	Training Loss: 0.004929773509502411
Test Loss:  0.003114776685833931
Valid Loss:  0.002722509205341339
Epoch:  17  	Training Loss: 0.00424882210791111
Test Loss:  0.002771011320874095
Valid Loss:  0.002372283022850752
Epoch:  18  	Training Loss: 0.0037876470014452934
Test Loss:  0.0025305389426648617
Valid Loss:  0.0021665517706424
Epoch:  19  	Training Loss: 0.003460599109530449
Test Loss:  0.0023727465886622667
Valid Loss:  0.002049510134384036
Epoch:  20  	Training Loss: 0.003221722086891532
Test Loss:  0.002261853078380227
Valid Loss:  0.001983160153031349
Epoch:  21  	Training Loss: 0.003041041549295187
Test Loss:  0.0021746607962995768
Valid Loss:  0.001943867770023644
Epoch:  22  	Training Loss: 0.002900458872318268
Test Loss:  0.002063167281448841
Valid Loss:  0.0019391095265746117
Epoch:  23  	Training Loss: 0.0026687488425523043
Test Loss:  0.0021259314380586147
Valid Loss:  0.0019169634906575084
Epoch:  24  	Training Loss: 0.0025611757300794125
Test Loss:  0.001970358658581972
Valid Loss:  0.0019450450781732798
Epoch:  25  	Training Loss: 0.0024897088296711445
Test Loss:  0.0021512694656848907
Valid Loss:  0.00193387595936656
Epoch:  26  	Training Loss: 0.0024402099661529064
Test Loss:  0.0018540654564276338
Valid Loss:  0.002003797795623541
Epoch:  27  	Training Loss: 0.002400647848844528
Test Loss:  0.002151149557903409
Valid Loss:  0.0019326310139149427
Epoch:  28  	Training Loss: 0.0023442483507096767
Test Loss:  0.0017382411751896143
Valid Loss:  0.0019564907997846603
Epoch:  29  	Training Loss: 0.0022531915456056595
Test Loss:  0.0018202540231868625
Valid Loss:  0.001827058382332325
Epoch:  30  	Training Loss: 0.0021475234534591436
Test Loss:  0.0015742052346467972
Valid Loss:  0.001733693527057767
Epoch:  31  	Training Loss: 0.0020271718967705965
Test Loss:  0.0015402799472212791
Valid Loss:  0.0016085361130535603
Epoch:  32  	Training Loss: 0.0019209005404263735
Test Loss:  0.0018910001963376999
Valid Loss:  0.0016468418762087822
Epoch:  33  	Training Loss: 0.0018901159055531025
Test Loss:  0.001566477119922638
Valid Loss:  0.0028282655403017998
Epoch:  34  	Training Loss: 0.0028003714978694916
Test Loss:  0.01072756852954626
Valid Loss:  0.006904306821525097
Epoch:  35  	Training Loss: 0.008816548623144627
Test Loss:  0.0063360342755913734
Valid Loss:  0.009816126897931099
Epoch:  36  	Training Loss: 0.010538596659898758
Test Loss:  0.011510159820318222
Valid Loss:  0.007361655123531818
Epoch:  37  	Training Loss: 0.008926411159336567
Test Loss:  0.002621819032356143
Valid Loss:  0.004835124127566814
Epoch:  38  	Training Loss: 0.0052710846066474915
Test Loss:  0.004778576549142599
Valid Loss:  0.0028369463980197906
Epoch:  39  	Training Loss: 0.003796911798417568
Test Loss:  0.0015371349873021245
Valid Loss:  0.0026709444355219603
Epoch:  40  	Training Loss: 0.00296957278624177
Test Loss:  0.0028263949789106846
Valid Loss:  0.001905880868434906
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.002556923311203718
Test Loss:  0.0019916396122425795
Valid Loss:  0.0017234671395272017
Epoch:  42  	Training Loss: 0.0021181893534958363
Test Loss:  0.0015919430879876018
Valid Loss:  0.0016980220098048449
Epoch:  43  	Training Loss: 0.0019283464644104242
Test Loss:  0.001516203279606998
Valid Loss:  0.001682052854448557
Epoch:  44  	Training Loss: 0.001861433731392026
Test Loss:  0.0014865014236420393
Valid Loss:  0.0016097461339086294
Epoch:  45  	Training Loss: 0.0018036856781691313
Test Loss:  0.0014159909915179014
Valid Loss:  0.001587100327014923
Epoch:  46  	Training Loss: 0.0017524356953799725
Test Loss:  0.0013851472176611423
Valid Loss:  0.001520867575891316
Epoch:  47  	Training Loss: 0.0017007167916744947
Test Loss:  0.0013228394091129303
Valid Loss:  0.001493385760113597
Epoch:  48  	Training Loss: 0.0016533771995455027
Test Loss:  0.001293376088142395
Valid Loss:  0.001439436455257237
Epoch:  49  	Training Loss: 0.0016084853559732437
Test Loss:  0.0012383484281599522
Valid Loss:  0.0014119651168584824
Epoch:  50  	Training Loss: 0.001565641025081277
Test Loss:  0.0012082455214112997
Valid Loss:  0.0013742813607677817
Epoch:  51  	Training Loss: 0.001525320578366518
Test Loss:  0.0011668287916108966
Valid Loss:  0.0013458445901051164
Epoch:  52  	Training Loss: 0.0014878076035529375
Test Loss:  0.001097644679248333
Valid Loss:  0.0013014917494729161
Epoch:  53  	Training Loss: 0.001440578605979681
Test Loss:  0.0010528138373047113
Valid Loss:  0.0012693622848019004
Epoch:  54  	Training Loss: 0.0014069722965359688
Test Loss:  0.0010212829802185297
Valid Loss:  0.0012410373892635107
Epoch:  55  	Training Loss: 0.0013793249381706119
Test Loss:  0.0009941618191078305
Valid Loss:  0.0012157863238826394
Epoch:  56  	Training Loss: 0.0013556748162955046
Test Loss:  0.0009739393135532737
Valid Loss:  0.0011933958157896996
Epoch:  57  	Training Loss: 0.0013347447384148836
Test Loss:  0.0009556454606354237
Valid Loss:  0.0011743225622922182
Epoch:  58  	Training Loss: 0.0013148539001122117
Test Loss:  0.0009407284669578075
Valid Loss:  0.0011577234836295247
Epoch:  59  	Training Loss: 0.0012964592315256596
Test Loss:  0.0009284314000979066
Valid Loss:  0.0011436843778938055
Epoch:  60  	Training Loss: 0.0012790383771061897
Test Loss:  0.000918530160561204
Valid Loss:  0.001131716649979353
Epoch:  61  	Training Loss: 0.0012621521018445492
Test Loss:  0.0009127107332460582
Valid Loss:  0.0011223809560760856
Epoch:  62  	Training Loss: 0.00124600890558213
Test Loss:  0.0009155183215625584
Valid Loss:  0.0011168516939505935
Epoch:  63  	Training Loss: 0.0012428564950823784
Test Loss:  0.000917061697691679
Valid Loss:  0.0011141607537865639
Epoch:  64  	Training Loss: 0.001240459969267249
Test Loss:  0.0009179916232824326
Valid Loss:  0.001112713711336255
Epoch:  65  	Training Loss: 0.0012384506408125162
Test Loss:  0.0009192174184136093
Valid Loss:  0.0011119528207927942
Epoch:  66  	Training Loss: 0.0012366939336061478
Test Loss:  0.0009201691718772054
Valid Loss:  0.0011115354718640447
Epoch:  67  	Training Loss: 0.0012350474717095494
Test Loss:  0.0009208645205944777
Valid Loss:  0.001111785415560007
Epoch:  68  	Training Loss: 0.0012335992651060224
Test Loss:  0.0009220591746270657
Valid Loss:  0.001112240133807063
Epoch:  69  	Training Loss: 0.001232244074344635
Test Loss:  0.0009229792049154639
Valid Loss:   14%|█▍        | 69/500 [00:55<02:29,  2.89it/s] 14%|█▍        | 71/500 [01:01<08:31,  1.19s/it] 15%|█▍        | 73/500 [01:01<06:05,  1.17it/s] 15%|█▌        | 75/500 [01:02<04:23,  1.61it/s] 15%|█▌        | 77/500 [01:02<03:13,  2.19it/s] 16%|█▌        | 79/500 [01:02<02:23,  2.94it/s] 16%|█▌        | 81/500 [01:08<08:37,  1.24s/it] 17%|█▋        | 83/500 [01:09<06:09,  1.13it/s] 17%|█▋        | 85/500 [01:09<04:27,  1.55it/s] 17%|█▋        | 87/500 [01:09<03:16,  2.11it/s] 18%|█▊        | 89/500 [01:09<02:26,  2.80it/s] 18%|█▊        | 91/500 [01:16<08:16,  1.21s/it] 19%|█▊        | 93/500 [01:16<05:54,  1.15it/s] 19%|█▉        | 95/500 [01:16<04:15,  1.59it/s] 19%|█▉        | 97/500 [01:16<03:06,  2.16it/s] 20%|█▉        | 99/500 [01:16<02:17,  2.91it/s] 20%|██        | 101/500 [01:23<08:09,  1.23s/it] 21%|██        | 103/500 [01:23<05:49,  1.14it/s] 21%|██        | 105/500 [01:23<04:11,  1.57it/s] 21%|██▏       | 107/500 [01:23<03:03,  2.15it/s] 22%|██▏       | 109/500 [01:23<02:15,  2.89it/s] 22%|██▏       | 111/500 [01:30<07:53,  1.22s/it] 23%|██▎       | 113/500 [01:30<05:37,  1.15it/s] 23%|██▎       | 115/500 [01:30<04:02,  1.59it/s] 23%|██▎       | 117/500 [01:30<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:30<02:11,  2.90it/s] 24%|██▍       | 121/500 [01:37<07:53,  1.25s/it] 25%|██▍       | 123/500 [01:37<05:38,  1.12it/s] 25%|██▌       | 125/500 [01:37<04:03,  1.54it/s] 25%|██▌       | 127/500 [01:37<02:56,  2.11it/s] 26%|██▌       | 129/500 [01:37<02:10,  2.85it/s] 26%|██▌       | 131/500 [01:44<07:27,  1.21s/it] 27%|██▋       | 133/500 [01:44<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:44<03:50,  1.59it/s] 27%|██▋       | 137/500 [01:44<02:47,  2.17it/s]0.0011130233760923147
Epoch:  70  	Training Loss: 0.0012309839949011803
Test Loss:  0.0009237726335413754
Valid Loss:  0.0011139127891510725
Epoch:  71  	Training Loss: 0.0012298142537474632
Test Loss:  0.0009245879482477903
Valid Loss:  0.0011148920748382807
Epoch:  72  	Training Loss: 0.0012287180870771408
Test Loss:  0.0009220551582984626
Valid Loss:  0.0011154725216329098
Epoch:  73  	Training Loss: 0.0012227369006723166
Test Loss:  0.0009202192886732519
Valid Loss:  0.0011153563391417265
Epoch:  74  	Training Loss: 0.0012192695867270231
Test Loss:  0.0009193147998303175
Valid Loss:  0.0011151297949254513
Epoch:  75  	Training Loss: 0.0012167595559731126
Test Loss:  0.0009198047337122262
Valid Loss:  0.0011146323522552848
Epoch:  76  	Training Loss: 0.0012145971413701773
Test Loss:  0.0009203009540215135
Valid Loss:  0.0011141591239720583
Epoch:  77  	Training Loss: 0.001212764997035265
Test Loss:  0.0009210969437845051
Valid Loss:  0.0011133210500702262
Epoch:  78  	Training Loss: 0.001211107475683093
Test Loss:  0.0009218938648700714
Valid Loss:  0.0011124596931040287
Epoch:  79  	Training Loss: 0.0012095082784071565
Test Loss:  0.0009226859547197819
Valid Loss:  0.0011116939131170511
Epoch:  80  	Training Loss: 0.0012080237502232194
Test Loss:  0.0009239634964615107
Valid Loss:  0.0011111943749710917
Epoch:  81  	Training Loss: 0.0012067243224009871
Test Loss:  0.0009249499998986721
Valid Loss:  0.0011107719037681818
Epoch:  82  	Training Loss: 0.001205506268888712
Test Loss:  0.0009333392372354865
Valid Loss:  0.001097432803362608
Epoch:  83  	Training Loss: 0.0011928053572773933
Test Loss:  0.0009325359133072197
Valid Loss:  0.0010896995663642883
Epoch:  84  	Training Loss: 0.0011821044608950615
Test Loss:  0.0009301407262682915
Valid Loss:  0.0010832769330590963
Epoch:  85  	Training Loss: 0.0011725245276466012
Test Loss:  0.0009268827270716429
Valid Loss:  0.0010776531416922808
Epoch:  86  	Training Loss: 0.0011633855756372213
Test Loss:  0.0009243131498806179
Valid Loss:  0.0010729528730735183
Epoch:  87  	Training Loss: 0.0011557411635294557
Test Loss:  0.0009212680160999298
Valid Loss:  0.0010693201329559088
Epoch:  88  	Training Loss: 0.0011489398311823606
Test Loss:  0.0009183975635096431
Valid Loss:  0.001065501943230629
Epoch:  89  	Training Loss: 0.0011424871627241373
Test Loss:  0.0009152833372354507
Valid Loss:  0.0010624044807627797
Epoch:  90  	Training Loss: 0.0011368250707164407
Test Loss:  0.0009130912367254496
Valid Loss:  0.0010591269237920642
Epoch:  91  	Training Loss: 0.0011318393517285585
Test Loss:  0.0009104767232201993
Valid Loss:  0.0010564684635028243
Epoch:  92  	Training Loss: 0.0011269178939983249
Test Loss:  0.0009137758752331138
Valid Loss:  0.001058841240592301
Epoch:  93  	Training Loss: 0.0011220808373764157
Test Loss:  0.0009187847608700395
Valid Loss:  0.0010607708245515823
Epoch:  94  	Training Loss: 0.0011184404138475657
Test Loss:  0.000917138415388763
Valid Loss:  0.0010631578043103218
Epoch:  95  	Training Loss: 0.0011159731075167656
Test Loss:  0.0009147969540208578
Valid Loss:  0.0010646894806995988
Epoch:  96  	Training Loss: 0.0011138608679175377
Test Loss:  0.0009130339021794498
Valid Loss:  0.001066161203198135
Epoch:  97  	Training Loss: 0.0011118687689304352
Test Loss:  0.0009110768442042172
Valid Loss:  0.0010671376949176192
Epoch:  98  	Training Loss: 0.0011100475676357746
Test Loss:  0.0009096590802073479
Valid Loss:  0.0010677261743694544
Epoch:  99  	Training Loss: 0.0011082988930866122
Test Loss:  0.0009082728065550327
Valid Loss:  0.0010681722778826952
Epoch:  100  	Training Loss: 0.0011066222796216607
Test Loss:  0.0009059123112820089
Valid Loss:  0.0010682110441848636
Epoch:  101  	Training Loss: 0.0011050484608858824
Test Loss:  0.0009043129393830895
Valid Loss:  0.001067889155820012
Epoch:  102  	Training Loss: 0.0011034889612346888
Test Loss:  0.000858882034663111
Valid Loss:  0.0010443161008879542
Epoch:  103  	Training Loss: 0.0010574893094599247
Test Loss:  0.0008371412986889482
Valid Loss:  0.0010272945510223508
Epoch:  104  	Training Loss: 0.0010300474241375923
Test Loss:  0.0008161382284015417
Valid Loss:  0.0010147806024178863
Epoch:  105  	Training Loss: 0.0010159395169466734
Test Loss:  0.000804319279268384
Valid Loss:  0.001002890057861805
Epoch:  106  	Training Loss: 0.0010045258095487952
Test Loss:  0.000792494451161474
Valid Loss:  0.0009916621493175626
Epoch:  107  	Training Loss: 0.0009944172343239188
Test Loss:  0.000782677554525435
Valid Loss:  0.0009816845413297415
Epoch:  108  	Training Loss: 0.0009854116942733526
Test Loss:  0.0007733559468761086
Valid Loss:  0.0009725765557959676
Epoch:  109  	Training Loss: 0.0009769413154572248
Test Loss:  0.0007664941367693245
Valid Loss:  0.0009644896490499377
Epoch:  110  	Training Loss: 0.00096896942704916
Test Loss:  0.0007600809913128614
Valid Loss:  0.0009568302193656564
Epoch:  111  	Training Loss: 0.0009612053981982172
Test Loss:  0.0007524087559431791
Valid Loss:  0.0009500188753008842
Epoch:  112  	Training Loss: 0.0009536594152450562
Test Loss:  0.00075614417437464
Valid Loss:  0.0009339917451143265
Epoch:  113  	Training Loss: 0.0008993016090244055
Test Loss:  0.0007417803280986845
Valid Loss:  0.0009259821381419897
Epoch:  114  	Training Loss: 0.0008732170099392533
Test Loss:  0.0007327735656872392
Valid Loss:  0.000918613513931632
Epoch:  115  	Training Loss: 0.0008594397804699838
Test Loss:  0.0007257213583216071
Valid Loss:  0.0009120266186073422
Epoch:  116  	Training Loss: 0.0008491603075526655
Test Loss:  0.0007192675257101655
Valid Loss:  0.0009049325599335134
Epoch:  117  	Training Loss: 0.000840814202092588
Test Loss:  0.0007099165231920779
Valid Loss:  0.0008940594270825386
Epoch:  118  	Training Loss: 0.0008306376403197646
Test Loss:  0.0007004446815699339
Valid Loss:  0.0008878882508724928
Epoch:  119  	Training Loss: 0.000823009992018342
Test Loss:  0.0006954335840418935
Valid Loss:  0.0008863377734087408
Epoch:  120  	Training Loss: 0.0008182947640307248
Test Loss:  0.0006916383281350136
Valid Loss:  0.0008844609255902469
Epoch:  121  	Training Loss: 0.0008137348922900856
Test Loss:  0.0006882335874252021
Valid Loss:  0.0008823930402286351
Epoch:  122  	Training Loss: 0.0008093009237200022
Test Loss:  0.0006787411402910948
Valid Loss:  0.0008804178214631975
Epoch:  123  	Training Loss: 0.0008041439577937126
Test Loss:  0.0006794119253754616
Valid Loss:  0.0008759931661188602
Epoch:  124  	Training Loss: 0.00079927290789783
Test Loss:  0.0006741340621374547
Valid Loss:  0.0008731607813388109
Epoch:  125  	Training Loss: 0.0007945293327793479
Test Loss:  0.000672409194521606
Valid Loss:  0.0008694756543263793
Epoch:  126  	Training Loss: 0.0007898745825514197
Test Loss:  0.0006684783147647977
Valid Loss:  0.0008663866901770234
Epoch:  127  	Training Loss: 0.0007853206479921937
Test Loss:  0.0006660849321633577
Valid Loss:  0.0008629526128061116
Epoch:  128  	Training Loss: 0.0007808259688317776
Test Loss:  0.0006628151750192046
Valid Loss:  0.0008597817504778504
Epoch:  129  	Training Loss: 0.0007764205802232027
Test Loss:  0.0006601320346817374
Valid Loss:  0.0008564689196646214
Epoch:  130  	Training Loss: 0.0007720524445176125
Test Loss:  0.0006571262492798269
Valid Loss:  0.0008532522479072213
Epoch:  131  	Training Loss: 0.00076772749889642
Test Loss:  0.0006544066709466279
Valid Loss:  0.0008500402327626944
Epoch:  132  	Training Loss: 0.0007635002839379013
Test Loss:  0.000667272717691958
Valid Loss:  0.0008402682142332196
Epoch:  133  	Training Loss: 0.0007465406088158488
Test Loss:  0.0006564343348145485
Valid Loss:  0.000834898091852665
Epoch:  134  	Training Loss: 0.0007411031983792782
Test Loss:  0.0006511984393000603
Valid Loss:  0.000829732627607882
Epoch:  135  	Training Loss: 0.0007364593911916018
Test Loss:  0.0006460575968958437
Valid Loss:  0.0008245390490628779
Epoch:  136  	Training Loss: 0.0007321984157897532
Test Loss:  0.0006421919097192585
Valid Loss:  0.0008195855189114809
Epoch:  137  	Training Loss: 0.0007282198639586568
Test Loss:  0.0006385571323335171
Valid Loss:  0.0008152134250849485
Epoch:  138  	Training Loss: 0.0007244671578519046
Test Loss:   28%|██▊       | 139/500 [01:44<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:51<07:11,  1.20s/it] 29%|██▊       | 143/500 [01:51<05:07,  1.16it/s] 29%|██▉       | 145/500 [01:51<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:51<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:51<01:58,  2.95it/s] 30%|███       | 151/500 [01:58<07:01,  1.21s/it] 31%|███       | 153/500 [01:58<05:00,  1.15it/s] 31%|███       | 155/500 [01:58<03:37,  1.58it/s] 31%|███▏      | 157/500 [01:58<02:39,  2.15it/s] 32%|███▏      | 159/500 [01:58<01:57,  2.90it/s] 32%|███▏      | 161/500 [02:05<06:53,  1.22s/it] 33%|███▎      | 163/500 [02:05<04:55,  1.14it/s] 33%|███▎      | 165/500 [02:05<03:32,  1.58it/s] 33%|███▎      | 167/500 [02:05<02:34,  2.16it/s] 34%|███▍      | 169/500 [02:06<01:54,  2.90it/s] 34%|███▍      | 171/500 [02:12<06:38,  1.21s/it] 35%|███▍      | 173/500 [02:12<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:12<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:12<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:13<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:19<06:32,  1.23s/it] 37%|███▋      | 183/500 [02:19<04:41,  1.13it/s] 37%|███▋      | 185/500 [02:20<03:23,  1.55it/s] 37%|███▋      | 187/500 [02:20<02:27,  2.12it/s] 38%|███▊      | 189/500 [02:20<01:48,  2.86it/s] 38%|███▊      | 191/500 [02:26<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:26<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:26<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:27<02:19,  2.18it/s] 40%|███▉      | 199/500 [02:27<01:42,  2.93it/s] 40%|████      | 201/500 [02:33<06:03,  1.22s/it] 41%|████      | 203/500 [02:33<04:19,  1.15it/s] 41%|████      | 205/500 [02:34<03:06,  1.58it/s]0.0006352599011734128
Valid Loss:  0.0008110645576380193
Epoch:  139  	Training Loss: 0.0007209358736872673
Test Loss:  0.0006303027039393783
Valid Loss:  0.0008068374590948224
Epoch:  140  	Training Loss: 0.0007175654172897339
Test Loss:  0.0006277612992562354
Valid Loss:  0.0008029026794247329
Epoch:  141  	Training Loss: 0.0007143685943447053
Test Loss:  0.0006243322277441621
Valid Loss:  0.0007990821031853557
Epoch:  142  	Training Loss: 0.0007113065803423524
Test Loss:  0.000620479229837656
Valid Loss:  0.0007911602733656764
Epoch:  143  	Training Loss: 0.0006878608837723732
Test Loss:  0.0006148778484202921
Valid Loss:  0.0007874933071434498
Epoch:  144  	Training Loss: 0.0006701339734718204
Test Loss:  0.000609889451880008
Valid Loss:  0.0007870454574003816
Epoch:  145  	Training Loss: 0.0006645565154030919
Test Loss:  0.000606064626481384
Valid Loss:  0.000786640914157033
Epoch:  146  	Training Loss: 0.000662336649838835
Test Loss:  0.0006032201927155256
Valid Loss:  0.0007860834011808038
Epoch:  147  	Training Loss: 0.0006601980421692133
Test Loss:  0.000601144798565656
Valid Loss:  0.0007854878203943372
Epoch:  148  	Training Loss: 0.0006581038469448686
Test Loss:  0.0005992850637994707
Valid Loss:  0.0007848000386729836
Epoch:  149  	Training Loss: 0.0006560311303474009
Test Loss:  0.0005975606618449092
Valid Loss:  0.0007840377511456609
Epoch:  150  	Training Loss: 0.0006539794849231839
Test Loss:  0.0005959210102446377
Valid Loss:  0.0007832122500985861
Epoch:  151  	Training Loss: 0.0006519455928355455
Test Loss:  0.0005943381111137569
Valid Loss:  0.0007823281921446323
Epoch:  152  	Training Loss: 0.0006499284063465893
Test Loss:  0.0005824238178320229
Valid Loss:  0.0007770801894366741
Epoch:  153  	Training Loss: 0.0006437299307435751
Test Loss:  0.0005824117688462138
Valid Loss:  0.0007686855387873948
Epoch:  154  	Training Loss: 0.0006382749415934086
Test Loss:  0.0005764393135905266
Valid Loss:  0.0007632169290445745
Epoch:  155  	Training Loss: 0.0006335119251161814
Test Loss:  0.000574045698158443
Valid Loss:  0.00075717200525105
Epoch:  156  	Training Loss: 0.0006291742902249098
Test Loss:  0.0005700357723981142
Valid Loss:  0.0007520950748585165
Epoch:  157  	Training Loss: 0.0006249549915082753
Test Loss:  0.0005671513499692082
Valid Loss:  0.0007471051067113876
Epoch:  158  	Training Loss: 0.0006209242856130004
Test Loss:  0.0005638849688693881
Valid Loss:  0.000742623582482338
Epoch:  159  	Training Loss: 0.0006170880515128374
Test Loss:  0.0005609141662716866
Valid Loss:  0.000738355505745858
Epoch:  160  	Training Loss: 0.000613349606283009
Test Loss:  0.0005578211857937276
Valid Loss:  0.0007342132739722729
Epoch:  161  	Training Loss: 0.0006097346777096391
Test Loss:  0.0005551439826376736
Valid Loss:  0.0007302032317966223
Epoch:  162  	Training Loss: 0.0006062010070309043
Test Loss:  0.0005510282935574651
Valid Loss:  0.0007274546660482883
Epoch:  163  	Training Loss: 0.0006039205472916365
Test Loss:  0.000548830721527338
Valid Loss:  0.0007243917789310217
Epoch:  164  	Training Loss: 0.0006018227431923151
Test Loss:  0.0005473835626617074
Valid Loss:  0.0007214262732304633
Epoch:  165  	Training Loss: 0.0005998050328344107
Test Loss:  0.0005460098618641496
Valid Loss:  0.0007185275317169726
Epoch:  166  	Training Loss: 0.0005978423287160695
Test Loss:  0.0005444205016829073
Valid Loss:  0.000715658301487565
Epoch:  167  	Training Loss: 0.0005959635600447655
Test Loss:  0.0005433238693512976
Valid Loss:  0.0007128981524147093
Epoch:  168  	Training Loss: 0.000594123441260308
Test Loss:  0.0005418715300038457
Valid Loss:  0.0007101889932528138
Epoch:  169  	Training Loss: 0.0005923198186792433
Test Loss:  0.0005408234428614378
Valid Loss:  0.0007075078901834786
Epoch:  170  	Training Loss: 0.0005905601428821683
Test Loss:  0.0005394982290454209
Valid Loss:  0.0007049341220408678
Epoch:  171  	Training Loss: 0.0005888249725103378
Test Loss:  0.0005382692907005548
Valid Loss:  0.0007024563383311033
Epoch:  172  	Training Loss: 0.0005871132016181946
Test Loss:  0.0005282359779812396
Valid Loss:  0.0006950476090423763
Epoch:  173  	Training Loss: 0.0005753972800448537
Test Loss:  0.0005190270021557808
Valid Loss:  0.0006883086753077805
Epoch:  174  	Training Loss: 0.0005648002261295915
Test Loss:  0.000510421406943351
Valid Loss:  0.0006817302200943232
Epoch:  175  	Training Loss: 0.0005547107430174947
Test Loss:  0.000502491369843483
Valid Loss:  0.0006752796471118927
Epoch:  176  	Training Loss: 0.0005452881450764835
Test Loss:  0.0004948814166709781
Valid Loss:  0.0006688976427540183
Epoch:  177  	Training Loss: 0.0005362550728023052
Test Loss:  0.0004874907317571342
Valid Loss:  0.0006625558598898351
Epoch:  178  	Training Loss: 0.000527680036611855
Test Loss:  0.00048090546624735
Valid Loss:  0.0006563490023836493
Epoch:  179  	Training Loss: 0.0005195430712774396
Test Loss:  0.0004748147330246866
Valid Loss:  0.0006503586191684008
Epoch:  180  	Training Loss: 0.0005117453401908278
Test Loss:  0.00046918130828998983
Valid Loss:  0.0006446953630074859
Epoch:  181  	Training Loss: 0.0005042586708441377
Test Loss:  0.00046369514893740416
Valid Loss:  0.0006391349015757442
Epoch:  182  	Training Loss: 0.0004970657755620778
Test Loss:  0.00045777298510074615
Valid Loss:  0.0006332134362310171
Epoch:  183  	Training Loss: 0.0004911973373964429
Test Loss:  0.00045326072722673416
Valid Loss:  0.0006274468032643199
Epoch:  184  	Training Loss: 0.00048566769692115486
Test Loss:  0.00044974370393902063
Valid Loss:  0.0006218889029696584
Epoch:  185  	Training Loss: 0.0004804320342373103
Test Loss:  0.0004471641732379794
Valid Loss:  0.000616804463788867
Epoch:  186  	Training Loss: 0.00047544579138047993
Test Loss:  0.00044516497291624546
Valid Loss:  0.0006120626931078732
Epoch:  187  	Training Loss: 0.00047071874723769724
Test Loss:  0.0004436419694684446
Valid Loss:  0.0006076073041185737
Epoch:  188  	Training Loss: 0.0004664866719394922
Test Loss:  0.0004424185026437044
Valid Loss:  0.0006034389371052384
Epoch:  189  	Training Loss: 0.0004625571600627154
Test Loss:  0.00044114896445535123
Valid Loss:  0.0005996030522510409
Epoch:  190  	Training Loss: 0.000458913273178041
Test Loss:  0.0004396001168061048
Valid Loss:  0.0005961296847090125
Epoch:  191  	Training Loss: 0.0004555320192594081
Test Loss:  0.0004384272324386984
Valid Loss:  0.0005928341415710747
Epoch:  192  	Training Loss: 0.0004523673269432038
Test Loss:  0.0004427618987392634
Valid Loss:  0.0005902312695980072
Epoch:  193  	Training Loss: 0.0004496528417803347
Test Loss:  0.00044349560630507767
Valid Loss:  0.0005891618202440441
Epoch:  194  	Training Loss: 0.000447790720500052
Test Loss:  0.00044272944796830416
Valid Loss:  0.0005884341662749648
Epoch:  195  	Training Loss: 0.00044623931171372533
Test Loss:  0.0004412610433064401
Valid Loss:  0.0005877147195860744
Epoch:  196  	Training Loss: 0.0004448331310413778
Test Loss:  0.00043974569416604936
Valid Loss:  0.0005869012675248086
Epoch:  197  	Training Loss: 0.00044353623525239527
Test Loss:  0.0004377951263450086
Valid Loss:  0.0005859146476723254
Epoch:  198  	Training Loss: 0.0004423860227689147
Test Loss:  0.000436104804975912
Valid Loss:  0.0005847843131050467
Epoch:  199  	Training Loss: 0.00044127588625997305
Test Loss:  0.0004343705659266561
Valid Loss:  0.0005835419287905097
Epoch:  200  	Training Loss: 0.0004402369086164981
Test Loss:  0.00043277625809423625
Valid Loss:  0.0005822329549118876
Epoch:  201  	Training Loss: 0.00043922345503233373
Test Loss:  0.0004312095115892589
Valid Loss:  0.0005808316636830568
Epoch:  202  	Training Loss: 0.0004382437909953296
Test Loss:  0.00043216091580688953
Valid Loss:  0.0005804100655950606
Epoch:  203  	Training Loss: 0.0004361821338534355
Test Loss:  0.00043152127182111144
Valid Loss:  0.0005800796207040548
Epoch:  204  	Training Loss: 0.00043442368041723967
Test Loss:  0.00043026430648751557
Valid Loss:  0.0005796808982267976
Epoch:  205  	Training Loss: 0.0004327944479882717
Test Loss:  0.0004288305644877255
Valid Loss:  0.0005791628500446677
Epoch:  206  	Training Loss: 0.0004312341916374862
Test Loss:  0.0004273855884093791
Valid Loss:  41%|████▏     | 207/500 [02:34<02:15,  2.17it/s] 42%|████▏     | 209/500 [02:34<01:40,  2.90it/s] 42%|████▏     | 211/500 [02:40<05:48,  1.21s/it] 43%|████▎     | 213/500 [02:40<04:08,  1.15it/s] 43%|████▎     | 215/500 [02:41<02:58,  1.60it/s] 43%|████▎     | 217/500 [02:41<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:41<01:36,  2.92it/s] 44%|████▍     | 221/500 [02:47<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:47<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:47<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:48<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:48<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:54<05:29,  1.22s/it] 47%|████▋     | 233/500 [02:54<03:54,  1.14it/s] 47%|████▋     | 235/500 [02:55<02:48,  1.58it/s] 47%|████▋     | 237/500 [02:55<02:03,  2.14it/s] 48%|████▊     | 239/500 [02:55<01:31,  2.85it/s] 48%|████▊     | 241/500 [03:01<05:15,  1.22s/it] 49%|████▊     | 243/500 [03:01<03:44,  1.14it/s] 49%|████▉     | 245/500 [03:02<02:41,  1.58it/s] 49%|████▉     | 247/500 [03:02<01:57,  2.16it/s] 50%|████▉     | 249/500 [03:02<01:26,  2.90it/s] 50%|█████     | 251/500 [03:08<04:56,  1.19s/it] 51%|█████     | 253/500 [03:08<03:31,  1.17it/s] 51%|█████     | 255/500 [03:08<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:09<01:50,  2.21it/s] 52%|█████▏    | 259/500 [03:09<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:15<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:15<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:15<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:16<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:16<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:22<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:22<03:15,  1.16it/s] 0.0005785221001133323
Epoch:  207  	Training Loss: 0.00042973196832463145
Test Loss:  0.0004259260604158044
Valid Loss:  0.0005777734913863242
Epoch:  208  	Training Loss: 0.00042828271398320794
Test Loss:  0.0004245184827595949
Valid Loss:  0.0005769162671640515
Epoch:  209  	Training Loss: 0.0004268639604561031
Test Loss:  0.0004231886996421963
Valid Loss:  0.0005759743507951498
Epoch:  210  	Training Loss: 0.00042545964242890477
Test Loss:  0.0004219077236484736
Valid Loss:  0.0005749635747633874
Epoch:  211  	Training Loss: 0.00042407168075442314
Test Loss:  0.00042066368041560054
Valid Loss:  0.0005739134503528476
Epoch:  212  	Training Loss: 0.0004227070021443069
Test Loss:  0.00041354846325702965
Valid Loss:  0.0005680143949575722
Epoch:  213  	Training Loss: 0.00041852996218949556
Test Loss:  0.0004105528932996094
Valid Loss:  0.0005625680205412209
Epoch:  214  	Training Loss: 0.0004148874431848526
Test Loss:  0.0004086904227733612
Valid Loss:  0.0005576340481638908
Epoch:  215  	Training Loss: 0.0004115511546842754
Test Loss:  0.00040674523916095495
Valid Loss:  0.0005533080548048019
Epoch:  216  	Training Loss: 0.00040854403050616384
Test Loss:  0.00040497357258573174
Valid Loss:  0.0005493918433785439
Epoch:  217  	Training Loss: 0.0004057442129123956
Test Loss:  0.00040306017035618424
Valid Loss:  0.0005458677187561989
Epoch:  218  	Training Loss: 0.0004031934658996761
Test Loss:  0.0004011940327472985
Valid Loss:  0.0005426373681984842
Epoch:  219  	Training Loss: 0.00040076355799101293
Test Loss:  0.000399447453673929
Valid Loss:  0.0005397074855864048
Epoch:  220  	Training Loss: 0.0003985221264883876
Test Loss:  0.00039774266770109534
Valid Loss:  0.000536968233063817
Epoch:  221  	Training Loss: 0.0003963970229960978
Test Loss:  0.00039613590342924
Valid Loss:  0.0005343836965039372
Epoch:  222  	Training Loss: 0.0003943897318094969
Test Loss:  0.00039543138700537384
Valid Loss:  0.0005333787412382662
Epoch:  223  	Training Loss: 0.0003929383819922805
Test Loss:  0.0003942078328691423
Valid Loss:  0.0005323536461219192
Epoch:  224  	Training Loss: 0.00039153575198724866
Test Loss:  0.00039292272413149476
Valid Loss:  0.0005312152206897736
Epoch:  225  	Training Loss: 0.000390176079235971
Test Loss:  0.00039164244662970304
Valid Loss:  0.0005300240009091794
Epoch:  226  	Training Loss: 0.00038883849629200995
Test Loss:  0.00039034575456753373
Valid Loss:  0.0005287930252961814
Epoch:  227  	Training Loss: 0.0003875244001392275
Test Loss:  0.000389102817280218
Valid Loss:  0.0005275015719234943
Epoch:  228  	Training Loss: 0.0003862300654873252
Test Loss:  0.00038790280814282596
Valid Loss:  0.0005261768237687647
Epoch:  229  	Training Loss: 0.0003849492350127548
Test Loss:  0.00038672087248414755
Valid Loss:  0.0005248416564427316
Epoch:  230  	Training Loss: 0.0003836755931843072
Test Loss:  0.0003855576505884528
Valid Loss:  0.0005235003773123026
Epoch:  231  	Training Loss: 0.000382409431040287
Test Loss:  0.00038440688513219357
Valid Loss:  0.0005221524625085294
Epoch:  232  	Training Loss: 0.0003811510978266597
Test Loss:  0.0003817557299043983
Valid Loss:  0.0005213334807194769
Epoch:  233  	Training Loss: 0.00038024806417524815
Test Loss:  0.000380412966478616
Valid Loss:  0.0005202848115004599
Epoch:  234  	Training Loss: 0.00037944456562399864
Test Loss:  0.00037885759957134724
Valid Loss:  0.000519147957675159
Epoch:  235  	Training Loss: 0.0003787046589422971
Test Loss:  0.00037752999924123287
Valid Loss:  0.0005179265281185508
Epoch:  236  	Training Loss: 0.0003779917606152594
Test Loss:  0.0003762508276849985
Valid Loss:  0.0005166929913684726
Epoch:  237  	Training Loss: 0.0003773051721509546
Test Loss:  0.000374981842469424
Valid Loss:  0.0005154280224815011
Epoch:  238  	Training Loss: 0.0003766380832530558
Test Loss:  0.0003738054365385324
Valid Loss:  0.0005141490255482495
Epoch:  239  	Training Loss: 0.0003759929386433214
Test Loss:  0.00037261866964399815
Valid Loss:  0.0005128779448568821
Epoch:  240  	Training Loss: 0.00037537459866143763
Test Loss:  0.0003715045750141144
Valid Loss:  0.0005116008687764406
Epoch:  241  	Training Loss: 0.00037477174191735685
Test Loss:  0.00037042214535176754
Valid Loss:  0.0005103435833007097
Epoch:  242  	Training Loss: 0.0003741814289242029
Test Loss:  0.00037045098724775016
Valid Loss:  0.0005075514782220125
Epoch:  243  	Training Loss: 0.00037313473876565695
Test Loss:  0.00036978020216338336
Valid Loss:  0.0005050783511251211
Epoch:  244  	Training Loss: 0.00037217632052488625
Test Loss:  0.0003692598547786474
Valid Loss:  0.0005029268213547766
Epoch:  245  	Training Loss: 0.00037128181429579854
Test Loss:  0.00036856584483757615
Valid Loss:  0.0005010026507079601
Epoch:  246  	Training Loss: 0.0003704306436702609
Test Loss:  0.0003678149078041315
Valid Loss:  0.0004992474569007754
Epoch:  247  	Training Loss: 0.0003696098574437201
Test Loss:  0.0003670401347335428
Valid Loss:  0.0004976388299837708
Epoch:  248  	Training Loss: 0.00036882131826132536
Test Loss:  0.0003663836687337607
Valid Loss:  0.0004962128587067127
Epoch:  249  	Training Loss: 0.00036807902506552637
Test Loss:  0.0003654080501291901
Valid Loss:  0.0004948272253386676
Epoch:  250  	Training Loss: 0.00036736304173246026
Test Loss:  0.0003645883407443762
Valid Loss:  0.0004935242468491197
Epoch:  251  	Training Loss: 0.000366654567187652
Test Loss:  0.00036374112823978066
Valid Loss:  0.0004922865191474557
Epoch:  252  	Training Loss: 0.0003659570647869259
Test Loss:  0.0003567019011825323
Valid Loss:  0.0004913238808512688
Epoch:  253  	Training Loss: 0.000364942301530391
Test Loss:  0.0003595873713493347
Valid Loss:  0.0004903094377368689
Epoch:  254  	Training Loss: 0.000363980361726135
Test Loss:  0.0003563355130609125
Valid Loss:  0.0004893768345937133
Epoch:  255  	Training Loss: 0.0003630572755355388
Test Loss:  0.0003568212559912354
Valid Loss:  0.0004883744986727834
Epoch:  256  	Training Loss: 0.00036217973683960736
Test Loss:  0.00035523687256500125
Valid Loss:  0.0004874211153946817
Epoch:  257  	Training Loss: 0.0003613370063249022
Test Loss:  0.00035500145168043673
Valid Loss:  0.0004864789079874754
Epoch:  258  	Training Loss: 0.0003605116216931492
Test Loss:  0.00035398287582211196
Valid Loss:  0.0004855974984820932
Epoch:  259  	Training Loss: 0.0003597017494030297
Test Loss:  0.00035337067674845457
Valid Loss:  0.00048472851631231606
Epoch:  260  	Training Loss: 0.00035891373408958316
Test Loss:  0.0003525599604472518
Valid Loss:  0.0004838694294448942
Epoch:  261  	Training Loss: 0.0003581455093808472
Test Loss:  0.00035196225508116186
Valid Loss:  0.00048303703079000115
Epoch:  262  	Training Loss: 0.00035739573650062084
Test Loss:  0.00035294186091050506
Valid Loss:  0.000481972296256572
Epoch:  263  	Training Loss: 0.00035597907844930887
Test Loss:  0.00035266182385385036
Valid Loss:  0.00048104539746418595
Epoch:  264  	Training Loss: 0.0003546741500031203
Test Loss:  0.00035192014183849096
Valid Loss:  0.00048017094377428293
Epoch:  265  	Training Loss: 0.00035342323826625943
Test Loss:  0.0003509980742819607
Valid Loss:  0.0004792691906914115
Epoch:  266  	Training Loss: 0.0003522047190926969
Test Loss:  0.0003500405000522733
Valid Loss:  0.0004784052725881338
Epoch:  267  	Training Loss: 0.00035103142727166414
Test Loss:  0.00034908432280644774
Valid Loss:  0.0004775330889970064
Epoch:  268  	Training Loss: 0.0003498864243738353
Test Loss:  0.00034813457750715315
Valid Loss:  0.0004766764759551734
Epoch:  269  	Training Loss: 0.00034877454163506627
Test Loss:  0.0003472214739304036
Valid Loss:  0.0004757909046020359
Epoch:  270  	Training Loss: 0.0003476717392913997
Test Loss:  0.00034632848110049963
Valid Loss:  0.0004748801584355533
Epoch:  271  	Training Loss: 0.00034657734795473516
Test Loss:  0.00034544419031590223
Valid Loss:  0.0004739544237963855
Epoch:  272  	Training Loss: 0.0003454957331996411
Test Loss:  0.00034458504524081945
Valid Loss:  0.0004723509482573718
Epoch:  273  	Training Loss: 0.0003446732007432729
Test Loss:  0.0003437268896959722
Valid Loss:  0.00047086720587685704
Epoch:  274  	Training Loss: 0.000343883759342134
Test Loss:   55%|█████▌    | 275/500 [03:22<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:23<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:23<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:29<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:29<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:29<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:29<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:30<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:36<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:36<02:56,  1.18it/s] 59%|█████▉    | 295/500 [03:36<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:36<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:36<01:08,  2.95it/s] 60%|██████    | 301/500 [03:43<03:55,  1.18s/it] 61%|██████    | 303/500 [03:43<02:48,  1.17it/s] 61%|██████    | 305/500 [03:43<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:43<01:29,  2.16it/s] 62%|██████▏   | 309/500 [03:43<01:06,  2.87it/s] 62%|██████▏   | 311/500 [03:50<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:50<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:50<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:50<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:50<01:02,  2.90it/s] 64%|██████▍   | 321/500 [03:57<03:36,  1.21s/it] 65%|██████▍   | 323/500 [03:57<02:33,  1.15it/s] 65%|██████▌   | 325/500 [03:57<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:57<01:19,  2.19it/s] 66%|██████▌   | 329/500 [03:57<00:58,  2.94it/s] 66%|██████▌   | 331/500 [04:04<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:04<02:21,  1.18it/s] 67%|██████▋   | 335/500 [04:04<01:40,  1.63it/s] 67%|██████▋   | 337/500 [04:04<01:13,  2.23it/s] 68%|██████▊   | 339/500 [04:04<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:11<03:14,  1.22s/it]0.00034290191251784563
Valid Loss:  0.0004694662638939917
Epoch:  275  	Training Loss: 0.00034313072683289647
Test Loss:  0.00034211023012176156
Valid Loss:  0.0004681279242504388
Epoch:  276  	Training Loss: 0.0003424057213123888
Test Loss:  0.00034133082954213023
Valid Loss:  0.00046685757115483284
Epoch:  277  	Training Loss: 0.00034169957507401705
Test Loss:  0.00034058879828080535
Valid Loss:  0.00046563445357605815
Epoch:  278  	Training Loss: 0.0003410182544030249
Test Loss:  0.00033984676701948047
Valid Loss:  0.0004644945729523897
Epoch:  279  	Training Loss: 0.00034035835415124893
Test Loss:  0.00033913517836481333
Valid Loss:  0.0004633973876480013
Epoch:  280  	Training Loss: 0.0003397214168217033
Test Loss:  0.00033843747223727405
Valid Loss:  0.0004623373970389366
Epoch:  281  	Training Loss: 0.00033909420017153025
Test Loss:  0.0003377451794221997
Valid Loss:  0.00046133057912811637
Epoch:  282  	Training Loss: 0.0003384789451956749
Test Loss:  0.0003349671605974436
Valid Loss:  0.00046076500439085066
Epoch:  283  	Training Loss: 0.000337561359629035
Test Loss:  0.00033474306110292673
Valid Loss:  0.0004599401436280459
Epoch:  284  	Training Loss: 0.0003367314930073917
Test Loss:  0.0003343919524922967
Valid Loss:  0.00045915768714621663
Epoch:  285  	Training Loss: 0.0003359465626999736
Test Loss:  0.00033403298584744334
Valid Loss:  0.0004584063426591456
Epoch:  286  	Training Loss: 0.0003351998166181147
Test Loss:  0.00033365609124302864
Valid Loss:  0.00045767342089675367
Epoch:  287  	Training Loss: 0.0003344676806591451
Test Loss:  0.0003332940977998078
Valid Loss:  0.00045696183224208653
Epoch:  288  	Training Loss: 0.0003337597008794546
Test Loss:  0.00033293006708845496
Valid Loss:  0.00045629951637238264
Epoch:  289  	Training Loss: 0.00033309421269223094
Test Loss:  0.0003325419966131449
Valid Loss:  0.0004556595813483
Epoch:  290  	Training Loss: 0.00033245631493628025
Test Loss:  0.00033213570713996887
Valid Loss:  0.00045503454748541117
Epoch:  291  	Training Loss: 0.00033183093182742596
Test Loss:  0.00033172970870509744
Valid Loss:  0.00045441812835633755
Epoch:  292  	Training Loss: 0.00033121960586868227
Test Loss:  0.0003339867980685085
Valid Loss:  0.00045521603897213936
Epoch:  293  	Training Loss: 0.0003303521662019193
Test Loss:  0.0003331789339426905
Valid Loss:  0.00045560699072666466
Epoch:  294  	Training Loss: 0.00032983088749460876
Test Loss:  0.00033205177169293165
Valid Loss:  0.00045587768545374274
Epoch:  295  	Training Loss: 0.0003293902555014938
Test Loss:  0.0003309451858513057
Valid Loss:  0.0004560684028547257
Epoch:  296  	Training Loss: 0.000329008063999936
Test Loss:  0.000330000591930002
Valid Loss:  0.0004562026006169617
Epoch:  297  	Training Loss: 0.0003286743303760886
Test Loss:  0.0003291431348770857
Valid Loss:  0.0004562794347293675
Epoch:  298  	Training Loss: 0.00032837415346875787
Test Loss:  0.0003283887344878167
Valid Loss:  0.00045630946988239884
Epoch:  299  	Training Loss: 0.0003280980745330453
Test Loss:  0.00032770924735814333
Valid Loss:  0.00045629445230588317
Epoch:  300  	Training Loss: 0.00032784140785224736
Test Loss:  0.0003270907327532768
Valid Loss:  0.00045623857295140624
Epoch:  301  	Training Loss: 0.00032760101021267474
Test Loss:  0.0003265214036218822
Valid Loss:  0.0004561419482342899
Epoch:  302  	Training Loss: 0.00032737432047724724
Test Loss:  0.00032481548259966075
Valid Loss:  0.0004538357607088983
Epoch:  303  	Training Loss: 0.0003251630114391446
Test Loss:  0.00032416253816336393
Valid Loss:  0.0004517171473708004
Epoch:  304  	Training Loss: 0.00032307967194356024
Test Loss:  0.0003234977484680712
Valid Loss:  0.00044975720811635256
Epoch:  305  	Training Loss: 0.0003210875438526273
Test Loss:  0.0003228189598303288
Valid Loss:  0.0004479140625335276
Epoch:  306  	Training Loss: 0.000319150451105088
Test Loss:  0.000322147534461692
Valid Loss:  0.00044616468949243426
Epoch:  307  	Training Loss: 0.0003172711585648358
Test Loss:  0.0003214979951735586
Valid Loss:  0.0004445037920959294
Epoch:  308  	Training Loss: 0.0003154515870846808
Test Loss:  0.0003208431589882821
Valid Loss:  0.00044291012454777956
Epoch:  309  	Training Loss: 0.0003136846353299916
Test Loss:  0.00032020441722124815
Valid Loss:  0.0004413843562360853
Epoch:  310  	Training Loss: 0.00031198334181681275
Test Loss:  0.0003195616591256112
Valid Loss:  0.0004399121389724314
Epoch:  311  	Training Loss: 0.00031032986589707434
Test Loss:  0.00031893380219116807
Valid Loss:  0.0004384949279483408
Epoch:  312  	Training Loss: 0.00030873052310198545
Test Loss:  0.0003182835644111037
Valid Loss:  0.00043723679846152663
Epoch:  313  	Training Loss: 0.0003077314468100667
Test Loss:  0.00031762057915329933
Valid Loss:  0.00043603137601166964
Epoch:  314  	Training Loss: 0.0003067424986511469
Test Loss:  0.0003169528499711305
Valid Loss:  0.00043487217044457793
Epoch:  315  	Training Loss: 0.00030576405697502196
Test Loss:  0.0003162812499795109
Valid Loss:  0.0004337504506111145
Epoch:  316  	Training Loss: 0.00030479449196718633
Test Loss:  0.00031560863135382533
Valid Loss:  0.0004326631024014205
Epoch:  317  	Training Loss: 0.00030383342527784407
Test Loss:  0.0003149363910779357
Valid Loss:  0.00043160340283066034
Epoch:  318  	Training Loss: 0.00030288059497252107
Test Loss:  0.000314259494189173
Valid Loss:  0.0004305701586417854
Epoch:  319  	Training Loss: 0.00030193678685463965
Test Loss:  0.0003135823644697666
Valid Loss:  0.0004295562976039946
Epoch:  320  	Training Loss: 0.0003010015352629125
Test Loss:  0.0003128971438854933
Valid Loss:  0.00042856988147832453
Epoch:  321  	Training Loss: 0.00030007591703906655
Test Loss:  0.0003122130292467773
Valid Loss:  0.00042759854113683105
Epoch:  322  	Training Loss: 0.000299157080007717
Test Loss:  0.00031282100826501846
Valid Loss:  0.0004269859055057168
Epoch:  323  	Training Loss: 0.00029839869239367545
Test Loss:  0.000312449352350086
Valid Loss:  0.00042631739052012563
Epoch:  324  	Training Loss: 0.0002976804389618337
Test Loss:  0.00031178531935438514
Valid Loss:  0.000425605452619493
Epoch:  325  	Training Loss: 0.00029697464196942747
Test Loss:  0.0003110089455731213
Valid Loss:  0.00042486132588237524
Epoch:  326  	Training Loss: 0.00029628147603943944
Test Loss:  0.0003101841430179775
Valid Loss:  0.0004240920243319124
Epoch:  327  	Training Loss: 0.00029560516122728586
Test Loss:  0.00030931984656490386
Valid Loss:  0.00042329163989052176
Epoch:  328  	Training Loss: 0.0002949443587567657
Test Loss:  0.0003085539792664349
Valid Loss:  0.0004225095617584884
Epoch:  329  	Training Loss: 0.000294295372441411
Test Loss:  0.000307727896142751
Valid Loss:  0.0004217095847707242
Epoch:  330  	Training Loss: 0.0002936715027317405
Test Loss:  0.00030688231345266104
Valid Loss:  0.0004208965692669153
Epoch:  331  	Training Loss: 0.00029306934447959065
Test Loss:  0.00030608472297899425
Valid Loss:  0.00042008000309579074
Epoch:  332  	Training Loss: 0.00029248674400150776
Test Loss:  0.00030447973404079676
Valid Loss:  0.0004187254817225039
Epoch:  333  	Training Loss: 0.00029069045558571815
Test Loss:  0.0003036570851691067
Valid Loss:  0.0004174700006842613
Epoch:  334  	Training Loss: 0.00028905985527671874
Test Loss:  0.0003029858344234526
Valid Loss:  0.00041626064921729267
Epoch:  335  	Training Loss: 0.00028750646742992103
Test Loss:  0.00030233326833695173
Valid Loss:  0.0004150820313952863
Epoch:  336  	Training Loss: 0.00028601716621778905
Test Loss:  0.00030165910720825195
Valid Loss:  0.0004139172378927469
Epoch:  337  	Training Loss: 0.0002845569106284529
Test Loss:  0.00030092219822108746
Valid Loss:  0.0004127648426219821
Epoch:  338  	Training Loss: 0.0002831204910762608
Test Loss:  0.00030015938682481647
Valid Loss:  0.00041162752313539386
Epoch:  339  	Training Loss: 0.00028169917641207576
Test Loss:  0.0002993668313138187
Valid Loss:  0.000410498003475368
Epoch:  340  	Training Loss: 0.0002802925300784409
Test Loss:  0.00029855198226869106
Valid Loss:  0.0004093781462870538
Epoch:  341  	Training Loss: 0.0002789045393001288
Test Loss:  0.0002977272088173777
Valid Loss:  0.0004082682426087558
 69%|██████▊   | 343/500 [04:11<02:17,  1.14it/s] 69%|██████▉   | 345/500 [04:11<01:38,  1.58it/s] 69%|██████▉   | 347/500 [04:11<01:10,  2.16it/s] 70%|██████▉   | 349/500 [04:11<00:52,  2.90it/s] 70%|███████   | 351/500 [04:18<02:58,  1.20s/it] 71%|███████   | 353/500 [04:18<02:06,  1.16it/s] 71%|███████   | 355/500 [04:18<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:18<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:18<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:25<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:25<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:25<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:25<01:01,  2.16it/s] 74%|███████▍  | 369/500 [04:25<00:45,  2.86it/s] 74%|███████▍  | 371/500 [04:32<02:35,  1.21s/it] 75%|███████▍  | 373/500 [04:32<01:49,  1.15it/s] 75%|███████▌  | 375/500 [04:32<01:18,  1.60it/s] 75%|███████▌  | 377/500 [04:32<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:32<00:41,  2.93it/s] 76%|███████▌  | 381/500 [04:39<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:39<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:39<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:39<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:39<00:37,  2.94it/s] 78%|███████▊  | 391/500 [04:45<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:46<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:46<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:46<00:46,  2.19it/s] 80%|███████▉  | 399/500 [04:46<00:34,  2.95it/s] 80%|████████  | 401/500 [04:52<01:59,  1.21s/it] 81%|████████  | 403/500 [04:53<01:24,  1.15it/s] 81%|████████  | 405/500 [04:53<00:59,  1.59it/s] 81%|████████▏ | 407/500 [04:53<00:42,  2.18it/s]Epoch:  342  	Training Loss: 0.00027753744507208467
Test Loss:  0.00029771585832349956
Valid Loss:  0.00040798558620736003
Epoch:  343  	Training Loss: 0.0002770944847725332
Test Loss:  0.00029690979863516986
Valid Loss:  0.0004076063050888479
Epoch:  344  	Training Loss: 0.0002766870893537998
Test Loss:  0.0002960004494525492
Valid Loss:  0.000407147454097867
Epoch:  345  	Training Loss: 0.0002762927324511111
Test Loss:  0.0002950866473838687
Valid Loss:  0.0004066170076839626
Epoch:  346  	Training Loss: 0.0002759094350039959
Test Loss:  0.00029420736245810986
Valid Loss:  0.000406032835599035
Epoch:  347  	Training Loss: 0.00027553545078262687
Test Loss:  0.0002933819778263569
Valid Loss:  0.0004054130404256284
Epoch:  348  	Training Loss: 0.0002751668798737228
Test Loss:  0.0002925808366853744
Valid Loss:  0.0004047681577503681
Epoch:  349  	Training Loss: 0.0002748032275121659
Test Loss:  0.0002917965757660568
Valid Loss:  0.0004041020874865353
Epoch:  350  	Training Loss: 0.00027444527950137854
Test Loss:  0.0002910156617872417
Valid Loss:  0.00040341680869460106
Epoch:  351  	Training Loss: 0.00027409353060647845
Test Loss:  0.00029024516697973013
Valid Loss:  0.0004027185495942831
Epoch:  352  	Training Loss: 0.00027374725323170424
Test Loss:  0.0002881260879803449
Valid Loss:  0.0004024197696708143
Epoch:  353  	Training Loss: 0.0002735602902248502
Test Loss:  0.0002874275087378919
Valid Loss:  0.0004023062065243721
Epoch:  354  	Training Loss: 0.00027340700034983456
Test Loss:  0.0002868473529815674
Valid Loss:  0.0004021910426672548
Epoch:  355  	Training Loss: 0.0002732608118094504
Test Loss:  0.0002862993278540671
Valid Loss:  0.00040206502308137715
Epoch:  356  	Training Loss: 0.0002731192798819393
Test Loss:  0.0002857755753211677
Valid Loss:  0.00040192774031311274
Epoch:  357  	Training Loss: 0.0002729827829170972
Test Loss:  0.0002852568286471069
Valid Loss:  0.00040177273331210017
Epoch:  358  	Training Loss: 0.0002728537074290216
Test Loss:  0.0002847830764949322
Valid Loss:  0.0004016112652607262
Epoch:  359  	Training Loss: 0.00027272780425846577
Test Loss:  0.0002843282127287239
Valid Loss:  0.00040144071681424975
Epoch:  360  	Training Loss: 0.0002726047532632947
Test Loss:  0.0002838888904079795
Valid Loss:  0.00040126233943738043
Epoch:  361  	Training Loss: 0.0002724839432630688
Test Loss:  0.00028346438193693757
Valid Loss:  0.00040107520180754364
Epoch:  362  	Training Loss: 0.0002723656943999231
Test Loss:  0.00028233954799361527
Valid Loss:  0.00040033675031736493
Epoch:  363  	Training Loss: 0.0002718043979257345
Test Loss:  0.0002816825872287154
Valid Loss:  0.0003996129962615669
Epoch:  364  	Training Loss: 0.00027126396889798343
Test Loss:  0.0002812468446791172
Valid Loss:  0.00039890603511594236
Epoch:  365  	Training Loss: 0.0002707376843318343
Test Loss:  0.00028092280263081193
Valid Loss:  0.0003982156631536782
Epoch:  366  	Training Loss: 0.0002702232450246811
Test Loss:  0.0002806392149068415
Valid Loss:  0.0003975450526922941
Epoch:  367  	Training Loss: 0.0002697171876206994
Test Loss:  0.00028038216987624764
Valid Loss:  0.00039688977994956076
Epoch:  368  	Training Loss: 0.0002692191628739238
Test Loss:  0.0002801339724101126
Valid Loss:  0.0003962544724345207
Epoch:  369  	Training Loss: 0.0002687283558771014
Test Loss:  0.00027989113004878163
Valid Loss:  0.0003956349100917578
Epoch:  370  	Training Loss: 0.0002682442427612841
Test Loss:  0.00027965105255134404
Valid Loss:  0.00039503167499788105
Epoch:  371  	Training Loss: 0.0002677662414498627
Test Loss:  0.00027940754080191255
Valid Loss:  0.0003944430500268936
Epoch:  372  	Training Loss: 0.0002672929549589753
Test Loss:  0.00028038345044478774
Valid Loss:  0.00039233334246091545
Epoch:  373  	Training Loss: 0.00026646803598850965
Test Loss:  0.00028017061413265765
Valid Loss:  0.00039070291677489877
Epoch:  374  	Training Loss: 0.0002657288277987391
Test Loss:  0.0002796761109493673
Valid Loss:  0.00038928340654820204
Epoch:  375  	Training Loss: 0.00026502448599785566
Test Loss:  0.00027913160738535225
Valid Loss:  0.00038800269248895347
Epoch:  376  	Training Loss: 0.00026434333994984627
Test Loss:  0.00027859173133037984
Valid Loss:  0.00038682937156409025
Epoch:  377  	Training Loss: 0.0002636801218613982
Test Loss:  0.0002780704526230693
Valid Loss:  0.0003857467381749302
Epoch:  378  	Training Loss: 0.0002630312810651958
Test Loss:  0.0002775638713501394
Valid Loss:  0.00038474047323688865
Epoch:  379  	Training Loss: 0.000262395478785038
Test Loss:  0.0002770703285932541
Valid Loss:  0.00038379611214622855
Epoch:  380  	Training Loss: 0.000261767883785069
Test Loss:  0.00027658152976073325
Valid Loss:  0.00038290678639896214
Epoch:  381  	Training Loss: 0.0002611451200209558
Test Loss:  0.00027609907556325197
Valid Loss:  0.0003820640849880874
Epoch:  382  	Training Loss: 0.0002605296322144568
Test Loss:  0.0002762317890301347
Valid Loss:  0.0003818090190179646
Epoch:  383  	Training Loss: 0.0002604499168228358
Test Loss:  0.0002763211086858064
Valid Loss:  0.00038159574614837766
Epoch:  384  	Training Loss: 0.00026037293719127774
Test Loss:  0.00027637777384370565
Valid Loss:  0.00038141533150337636
Epoch:  385  	Training Loss: 0.0002602974127512425
Test Loss:  0.0002764085656963289
Valid Loss:  0.00038125936407595873
Epoch:  386  	Training Loss: 0.00026022345991805196
Test Loss:  0.0002764198579825461
Valid Loss:  0.0003811225469689816
Epoch:  387  	Training Loss: 0.0002601501764729619
Test Loss:  0.0002764166274573654
Valid Loss:  0.00038099935045465827
Epoch:  388  	Training Loss: 0.00026007869746536016
Test Loss:  0.0002764016971923411
Valid Loss:  0.0003808887558989227
Epoch:  389  	Training Loss: 0.00026000794605351985
Test Loss:  0.0002763781521935016
Valid Loss:  0.0003807860775850713
Epoch:  390  	Training Loss: 0.00025993792223744094
Test Loss:  0.0002763476804830134
Valid Loss:  0.0003806904423981905
Epoch:  391  	Training Loss: 0.0002598682476673275
Test Loss:  0.0002763126394711435
Valid Loss:  0.0003806000459007919
Epoch:  392  	Training Loss: 0.0002597999991849065
Test Loss:  0.00027758110081776977
Valid Loss:  0.00038075423799455166
Epoch:  393  	Training Loss: 0.00025838083820417523
Test Loss:  0.00027696765027940273
Valid Loss:  0.00038057507481426
Epoch:  394  	Training Loss: 0.000257198786130175
Test Loss:  0.0002761822543106973
Valid Loss:  0.0003801757120527327
Epoch:  395  	Training Loss: 0.00025609496515244246
Test Loss:  0.0002755282330326736
Valid Loss:  0.00037965545197948813
Epoch:  396  	Training Loss: 0.0002550341887399554
Test Loss:  0.0002748783736024052
Valid Loss:  0.00037902325857430696
Epoch:  397  	Training Loss: 0.0002540092100389302
Test Loss:  0.00027425860753282905
Valid Loss:  0.00037830896326340735
Epoch:  398  	Training Loss: 0.000253015459747985
Test Loss:  0.000273682177066803
Valid Loss:  0.0003775390796363354
Epoch:  399  	Training Loss: 0.0002520432462915778
Test Loss:  0.0002731636632233858
Valid Loss:  0.00037675609928555787
Epoch:  400  	Training Loss: 0.00025107862893491983
Test Loss:  0.0002725892700254917
Valid Loss:  0.0003759373794309795
Epoch:  401  	Training Loss: 0.000250127020990476
Test Loss:  0.0002720250631682575
Valid Loss:  0.0003751062322407961
Epoch:  402  	Training Loss: 0.00024918990675359964
Test Loss:  0.0002694824943318963
Valid Loss:  0.0003740258398465812
Epoch:  403  	Training Loss: 0.0002485133591108024
Test Loss:  0.00026892294408753514
Valid Loss:  0.00037299367249943316
Epoch:  404  	Training Loss: 0.0002478585811331868
Test Loss:  0.00026763873756863177
Valid Loss:  0.000371880189049989
Epoch:  405  	Training Loss: 0.00024722187663428485
Test Loss:  0.000266671268036589
Valid Loss:  0.000370760535588488
Epoch:  406  	Training Loss: 0.00024660583585500717
Test Loss:  0.00026558423996903
Valid Loss:  0.00036961014848202467
Epoch:  407  	Training Loss: 0.0002460104878991842
Test Loss:  0.0002646723296493292
Valid Loss:  0.0003684735274873674
Epoch:  408  	Training Loss: 0.0002454287023283541
Test Loss:  0.00026372226420789957
Valid Loss:  0.00036733897286467254
Epoch:  409  	Training Loss: 0.00024486787151545286
Test Loss:  0.00026279129087924957
 82%|████████▏ | 409/500 [04:53<00:31,  2.93it/s] 82%|████████▏ | 411/500 [05:00<01:47,  1.21s/it] 83%|████████▎ | 413/500 [05:00<01:15,  1.15it/s] 83%|████████▎ | 415/500 [05:00<00:53,  1.60it/s] 83%|████████▎ | 417/500 [05:00<00:38,  2.18it/s] 84%|████████▍ | 419/500 [05:00<00:27,  2.94it/s] 84%|████████▍ | 421/500 [05:06<01:33,  1.18s/it] 85%|████████▍ | 423/500 [05:06<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:07<00:46,  1.63it/s] 85%|████████▌ | 427/500 [05:07<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:07<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:13<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:13<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:13<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:14<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:14<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:20<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:20<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:20<00:34,  1.62it/s] 89%|████████▉ | 447/500 [05:21<00:24,  2.21it/s] 90%|████████▉ | 449/500 [05:21<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:27<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:27<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:27<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:27<00:19,  2.18it/s] 92%|█████████▏| 459/500 [05:28<00:14,  2.90it/s] 92%|█████████▏| 461/500 [05:34<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:34<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:34<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:34<00:15,  2.20it/s] 94%|█████████▍| 469/500 [05:35<00:10,  2.92it/s] 94%|█████████▍| 471/500 [05:41<00:35,  1.21s/it] 95%|█████████▍| 473/500 [05:41<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:41<00:15,  1.60it/s]Valid Loss:  0.0003662067174445838
Epoch:  410  	Training Loss: 0.00024433303042314947
Test Loss:  0.0002618438156787306
Valid Loss:  0.0003650513244792819
Epoch:  411  	Training Loss: 0.00024382512492593378
Test Loss:  0.00026126974262297153
Valid Loss:  0.00036398449447005987
Epoch:  412  	Training Loss: 0.00024332464090548456
Test Loss:  0.00026134593645110726
Valid Loss:  0.0003633819578681141
Epoch:  413  	Training Loss: 0.00024289707653224468
Test Loss:  0.00026112914201803505
Valid Loss:  0.00036279275082051754
Epoch:  414  	Training Loss: 0.00024247697729151696
Test Loss:  0.0002608051581773907
Valid Loss:  0.00036221506888978183
Epoch:  415  	Training Loss: 0.00024205882800742984
Test Loss:  0.00026044866535812616
Valid Loss:  0.00036165150231681764
Epoch:  416  	Training Loss: 0.00024163980560842901
Test Loss:  0.0002600755251478404
Valid Loss:  0.00036110077053308487
Epoch:  417  	Training Loss: 0.0002412188914604485
Test Loss:  0.000259698077570647
Valid Loss:  0.00036056365934200585
Epoch:  418  	Training Loss: 0.0002407945430604741
Test Loss:  0.0002593108220025897
Valid Loss:  0.00036003769491799176
Epoch:  419  	Training Loss: 0.00024036719696596265
Test Loss:  0.000258871354162693
Valid Loss:  0.00035949976881965995
Epoch:  420  	Training Loss: 0.00023994017101358622
Test Loss:  0.00025844568153843284
Valid Loss:  0.0003589665284380317
Epoch:  421  	Training Loss: 0.00023951302864588797
Test Loss:  0.0002580300788395107
Valid Loss:  0.0003584421065170318
Epoch:  422  	Training Loss: 0.00023908648290671408
Test Loss:  0.0002572808298282325
Valid Loss:  0.00035797679447568953
Epoch:  423  	Training Loss: 0.00023880803200881928
Test Loss:  0.00025673891650512815
Valid Loss:  0.000357519747922197
Epoch:  424  	Training Loss: 0.00023853578022681177
Test Loss:  0.0002563082380220294
Valid Loss:  0.00035706450580619276
Epoch:  425  	Training Loss: 0.0002382630918873474
Test Loss:  0.00025596923660486937
Valid Loss:  0.00035662332084029913
Epoch:  426  	Training Loss: 0.0002379892102908343
Test Loss:  0.0002556738327257335
Valid Loss:  0.00035619031405076385
Epoch:  427  	Training Loss: 0.00023771289852447808
Test Loss:  0.0002553927479311824
Valid Loss:  0.00035576027585193515
Epoch:  428  	Training Loss: 0.00023743159545119852
Test Loss:  0.0002551138459239155
Valid Loss:  0.0003553321002982557
Epoch:  429  	Training Loss: 0.00023714310373179615
Test Loss:  0.00025483689387328923
Valid Loss:  0.000354907097062096
Epoch:  430  	Training Loss: 0.00023684950429014862
Test Loss:  0.0002545846509747207
Valid Loss:  0.0003544979845173657
Epoch:  431  	Training Loss: 0.0002365436521358788
Test Loss:  0.00025432143593207
Valid Loss:  0.00035409879637882113
Epoch:  432  	Training Loss: 0.00023623435117769986
Test Loss:  0.00025429867673665285
Valid Loss:  0.00035391689743846655
Epoch:  433  	Training Loss: 0.000235814179177396
Test Loss:  0.00025413933326490223
Valid Loss:  0.0003536941949278116
Epoch:  434  	Training Loss: 0.00023541160044260323
Test Loss:  0.00025389110669493675
Valid Loss:  0.00035343709168955684
Epoch:  435  	Training Loss: 0.000235018422245048
Test Loss:  0.00025357361300848424
Valid Loss:  0.00035314791603013873
Epoch:  436  	Training Loss: 0.00023463380057364702
Test Loss:  0.000253212230745703
Valid Loss:  0.0003528336528688669
Epoch:  437  	Training Loss: 0.00023425338440574706
Test Loss:  0.0002528299519326538
Valid Loss:  0.0003524980857037008
Epoch:  438  	Training Loss: 0.00023387689725495875
Test Loss:  0.0002524269511923194
Valid Loss:  0.0003521455801092088
Epoch:  439  	Training Loss: 0.00023350189439952374
Test Loss:  0.00025202089454978704
Valid Loss:  0.0003517789300531149
Epoch:  440  	Training Loss: 0.0002331302675884217
Test Loss:  0.00025160182849504054
Valid Loss:  0.00035139740793965757
Epoch:  441  	Training Loss: 0.00023276073625311255
Test Loss:  0.0002511769416742027
Valid Loss:  0.00035100625245831907
Epoch:  442  	Training Loss: 0.00023239203437697142
Test Loss:  0.00024982320610433817
Valid Loss:  0.0003494535922072828
Epoch:  443  	Training Loss: 0.00023163824516814202
Test Loss:  0.0002493421779945493
Valid Loss:  0.00034807281917892396
Epoch:  444  	Training Loss: 0.0002309750852873549
Test Loss:  0.00024904392194002867
Valid Loss:  0.0003468574723228812
Epoch:  445  	Training Loss: 0.00023039054940454662
Test Loss:  0.00024875305825844407
Valid Loss:  0.00034576765028759837
Epoch:  446  	Training Loss: 0.00022984339739196002
Test Loss:  0.000248452095547691
Valid Loss:  0.00034477096050977707
Epoch:  447  	Training Loss: 0.00022932051797397435
Test Loss:  0.0002481450792402029
Valid Loss:  0.00034384839818812907
Epoch:  448  	Training Loss: 0.00022881932090967894
Test Loss:  0.000247825839323923
Valid Loss:  0.00034298477112315595
Epoch:  449  	Training Loss: 0.00022833392722532153
Test Loss:  0.000247494550421834
Valid Loss:  0.0003421693982090801
Epoch:  450  	Training Loss: 0.00022785915643908083
Test Loss:  0.00024714769097045064
Valid Loss:  0.00034139156923629344
Epoch:  451  	Training Loss: 0.00022739020641893148
Test Loss:  0.0002467969316057861
Valid Loss:  0.0003406464820727706
Epoch:  452  	Training Loss: 0.00022693007485941052
Test Loss:  0.00024625135120004416
Valid Loss:  0.0003401543654035777
Epoch:  453  	Training Loss: 0.0002262394700665027
Test Loss:  0.00024472910445183516
Valid Loss:  0.00033939891727641225
Epoch:  454  	Training Loss: 0.00022557066404260695
Test Loss:  0.0002437574148643762
Valid Loss:  0.0003386833122931421
Epoch:  455  	Training Loss: 0.00022491661366075277
Test Loss:  0.00024262542137876153
Valid Loss:  0.000337884557666257
Epoch:  456  	Training Loss: 0.00022427075600717217
Test Loss:  0.00024162817862816155
Valid Loss:  0.00033707189140841365
Epoch:  457  	Training Loss: 0.00022363231983035803
Test Loss:  0.00024062796728685498
Valid Loss:  0.0003362322458997369
Epoch:  458  	Training Loss: 0.00022299672127701342
Test Loss:  0.0002396468771621585
Valid Loss:  0.0003353734209667891
Epoch:  459  	Training Loss: 0.00022236784570850432
Test Loss:  0.00023869439610280097
Valid Loss:  0.00033450350747443736
Epoch:  460  	Training Loss: 0.00022174257901497185
Test Loss:  0.00023776346642989665
Valid Loss:  0.00033363013062626123
Epoch:  461  	Training Loss: 0.000221116904867813
Test Loss:  0.00023680222511757165
Valid Loss:  0.00033274246379733086
Epoch:  462  	Training Loss: 0.00022049604740459472
Test Loss:  0.00023554750077892095
Valid Loss:  0.0003315307549200952
Epoch:  463  	Training Loss: 0.0002199709415435791
Test Loss:  0.0002351830480620265
Valid Loss:  0.00033054701634682715
Epoch:  464  	Training Loss: 0.00021947342611383647
Test Loss:  0.00023481801326852292
Valid Loss:  0.00032961444230750203
Epoch:  465  	Training Loss: 0.00021898889099247754
Test Loss:  0.00023445271654054523
Valid Loss:  0.0003287290164735168
Epoch:  466  	Training Loss: 0.0002185154880862683
Test Loss:  0.0002340441569685936
Valid Loss:  0.00032787388772703707
Epoch:  467  	Training Loss: 0.00021804832795169204
Test Loss:  0.0002336195611860603
Valid Loss:  0.0003270478919148445
Epoch:  468  	Training Loss: 0.00021758730872534215
Test Loss:  0.00023318894091062248
Valid Loss:  0.0003262446844018996
Epoch:  469  	Training Loss: 0.0002171302039641887
Test Loss:  0.0002327773254364729
Valid Loss:  0.0003254698240198195
Epoch:  470  	Training Loss: 0.0002166706253774464
Test Loss:  0.00023230200167745352
Valid Loss:  0.0003246996784582734
Epoch:  471  	Training Loss: 0.00021621043561026454
Test Loss:  0.00023176282411441207
Valid Loss:  0.00032393480069004
Epoch:  472  	Training Loss: 0.00021574088896159083
Test Loss:  0.0002314215962542221
Valid Loss:  0.00032361032208427787
Epoch:  473  	Training Loss: 0.00021548126824200153
Test Loss:  0.00023116209194995463
Valid Loss:  0.0003232964954804629
Epoch:  474  	Training Loss: 0.0002152246597688645
Test Loss:  0.0002309513947693631
Valid Loss:  0.0003229915746487677
Epoch:  475  	Training Loss: 0.0002149695937987417
Test Loss:  0.00023076690558809787
Valid Loss:  0.00032269294024445117
Epoch:  476  	Training Loss: 0.00021471467334777117
Test Loss:  0.00023059427621774375
Valid Loss:  0.0003223964013159275
 95%|█████████▌| 477/500 [05:41<00:10,  2.18it/s] 96%|█████████▌| 479/500 [05:42<00:07,  2.92it/s] 96%|█████████▌| 481/500 [05:48<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:48<00:14,  1.14it/s] 97%|█████████▋| 485/500 [05:48<00:09,  1.58it/s] 97%|█████████▋| 487/500 [05:49<00:06,  2.16it/s] 98%|█████████▊| 489/500 [05:49<00:03,  2.90it/s] 98%|█████████▊| 491/500 [05:55<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:55<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:55<00:03,  1.58it/s] 99%|█████████▉| 497/500 [05:56<00:01,  2.16it/s]100%|█████████▉| 499/500 [05:56<00:00,  2.91it/s]100%|██████████| 500/500 [05:56<00:00,  1.40it/s]
Epoch:  477  	Training Loss: 0.00021445384481921792
Test Loss:  0.00023042256361804903
Valid Loss:  0.000322104140650481
Epoch:  478  	Training Loss: 0.00021419284166768193
Test Loss:  0.0002302541834069416
Valid Loss:  0.00032181438291445374
Epoch:  479  	Training Loss: 0.00021393329370766878
Test Loss:  0.00023009430151432753
Valid Loss:  0.0003215298056602478
Epoch:  480  	Training Loss: 0.00021367421140894294
Test Loss:  0.00022993324091657996
Valid Loss:  0.00032124706194736063
Epoch:  481  	Training Loss: 0.00021341624960768968
Test Loss:  0.00022977431945037097
Valid Loss:  0.00032096708309836686
Epoch:  482  	Training Loss: 0.0002131588407792151
Test Loss:  0.000229341778322123
Valid Loss:  0.00032036806805990636
Epoch:  483  	Training Loss: 0.00021259092318359762
Test Loss:  0.0002288406976731494
Valid Loss:  0.0003197430050931871
Epoch:  484  	Training Loss: 0.000212015031138435
Test Loss:  0.00022830074885860085
Valid Loss:  0.00031909713288769126
Epoch:  485  	Training Loss: 0.00021142684272490442
Test Loss:  0.0002277809107908979
Valid Loss:  0.00031844794284552336
Epoch:  486  	Training Loss: 0.0002108443295583129
Test Loss:  0.00022724045265931636
Valid Loss:  0.00031779054552316666
Epoch:  487  	Training Loss: 0.00021025820751674473
Test Loss:  0.00022668688325211406
Valid Loss:  0.00031712735653854907
Epoch:  488  	Training Loss: 0.00020967326418031007
Test Loss:  0.0002261365734739229
Valid Loss:  0.00031645939452573657
Epoch:  489  	Training Loss: 0.00020909187151119113
Test Loss:  0.00022559036733582616
Valid Loss:  0.0003157891915179789
Epoch:  490  	Training Loss: 0.00020851704175584018
Test Loss:  0.00022505743254441768
Valid Loss:  0.00031512300483882427
Epoch:  491  	Training Loss: 0.00020795555610675365
Test Loss:  0.0002245483046863228
Valid Loss:  0.0003144599322695285
Epoch:  492  	Training Loss: 0.000207412987947464
Test Loss:  0.00022446399088948965
Valid Loss:  0.0003143473877571523
Epoch:  493  	Training Loss: 0.00020708631200250238
Test Loss:  0.00022338787675835192
Valid Loss:  0.00031394982943311334
Epoch:  494  	Training Loss: 0.0002068014000542462
Test Loss:  0.00022257350792642683
Valid Loss:  0.0003135735751129687
Epoch:  495  	Training Loss: 0.00020654776017181575
Test Loss:  0.0002218259178334847
Valid Loss:  0.00031316978856921196
Epoch:  496  	Training Loss: 0.00020631548250094056
Test Loss:  0.00022121606161817908
Valid Loss:  0.0003127714735455811
Epoch:  497  	Training Loss: 0.00020609181956388056
Test Loss:  0.00022065956727601588
Valid Loss:  0.00031235854839906096
Epoch:  498  	Training Loss: 0.00020587621838785708
Test Loss:  0.00022013673151377589
Valid Loss:  0.0003119360189884901
Epoch:  499  	Training Loss: 0.0002056694938801229
Test Loss:  0.0002196668938267976
Valid Loss:  0.0003115255676675588
Epoch:  500  	Training Loss: 0.00020546400628518313
Test Loss:  0.0002191707317251712
Valid Loss:  0.00031109555857256055
seed is  12
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.18it/s]  1%|          | 4/500 [00:00<00:31, 15.69it/s]  1%|          | 6/500 [00:00<00:31, 15.77it/s]  2%|▏         | 8/500 [00:00<00:31, 15.52it/s]  2%|▏         | 10/500 [00:00<00:31, 15.44it/s]  2%|▏         | 12/500 [00:00<00:31, 15.63it/s]  3%|▎         | 14/500 [00:00<00:30, 15.75it/s]  3%|▎         | 16/500 [00:01<00:30, 15.88it/s]  4%|▎         | 18/500 [00:01<00:30, 15.99it/s]  4%|▍         | 20/500 [00:01<00:30, 15.81it/s]  4%|▍         | 22/500 [00:01<00:30, 15.72it/s]  5%|▍         | 24/500 [00:01<00:30, 15.56it/s]  5%|▌         | 26/500 [00:01<00:30, 15.72it/s]  6%|▌         | 28/500 [00:01<00:29, 15.84it/s]  6%|▌         | 30/500 [00:01<00:29, 15.94it/s]  6%|▋         | 32/500 [00:02<00:29, 16.02it/s]  7%|▋         | 34/500 [00:02<00:29, 15.95it/s]  7%|▋         | 36/500 [00:02<00:29, 15.89it/s]  8%|▊         | 38/500 [00:02<00:28, 15.98it/s]  8%|▊         | 40/500 [00:02<00:28, 16.13it/s]  8%|▊         | 42/500 [00:02<00:28, 16.09it/s]  9%|▉         | 44/500 [00:02<00:28, 15.96it/s]  9%|▉         | 46/500 [00:02<00:28, 15.78it/s] 10%|▉         | 48/500 [00:03<00:28, 15.95it/s] 10%|█         | 50/500 [00:03<00:28, 15.99it/s] 10%|█         | 52/500 [00:03<00:27, 16.11it/s] 11%|█         | 54/500 [00:03<00:27, 16.19it/s] 11%|█         | 56/500 [00:03<00:27, 16.25it/s] 12%|█▏        | 58/500 [00:03<00:27, 15.88it/s] 12%|█▏        | 60/500 [00:03<00:29, 14.87it/s] 12%|█▏        | 62/500 [00:03<00:30, 14.41it/s] 13%|█▎        | 64/500 [00:04<00:30, 14.51it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.02it/s] 14%|█▎        | 68/500 [00:04<00:29, 14.45it/s] 14%|█▍        | 70/500 [00:04<00:29, 14.39it/s] 14%|█▍        | 72/500 [00:04<00:28, 14.90it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.30it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.55it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.84it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.75it/s] 16%|█▋        | 82/500 [00:05<00:28, 14.51it/s] 17%|█▋        | 84/500 [00:05<00:30, 13.78it/s] 17%|█▋        | 86/500 [00:05<00:31, 13.20it/s] 18%|█▊        | 88/500 [00:05<00:32, 12.87it/s] 18%|█▊        | 90/500 [00:05<00:30, 13.26it/s] 18%|█▊        | 92/500 [00:06<00:29, 14.00it/s] 19%|█▉        | 94/500 [00:06<00:27, 14.53it/s] 19%|█▉        | 96/500 [00:06<00:27, 14.88it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.27it/s] 20%|██        | 100/500 [00:06<00:25, 15.58it/s] 20%|██        | 102/500 [00:06<00:25, 15.79it/s] 21%|██        | 104/500 [00:06<00:25, 15.78it/s] 21%|██        | 106/500 [00:06<00:25, 15.65it/s] 22%|██▏       | 108/500 [00:07<00:24, 15.81it/s] 22%|██▏       | 110/500 [00:07<00:25, 15.49it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.69it/s] 23%|██▎       | 114/500 [00:07<00:25, 15.38it/s] 23%|██▎       | 116/500 [00:07<00:25, 14.90it/s] 24%|██▎       | 118/500 [00:07<00:25, 14.93it/s] 24%|██▍       | 120/500 [00:07<00:25, 15.06it/s] 24%|██▍       | 122/500 [00:07<00:24, 15.42it/s] 25%|██▍       | 124/500 [00:08<00:23, 15.68it/s]Epoch:  1  	Training Loss: 0.1598755270242691
Test Loss:  4141.6552734375
Valid Loss:  4108.4296875
Epoch:  2  	Training Loss: 4248.173828125
Test Loss:  3.248976114692915e+16
Valid Loss:  3.182024446495949e+16
Epoch:  3  	Training Loss: 3.227909300106035e+16
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 15.87it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.93it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.88it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.84it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.75it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.99it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.93it/s] 28%|██▊       | 140/500 [00:09<00:22, 16.00it/s] 28%|██▊       | 142/500 [00:09<00:22, 16.06it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.97it/s] 29%|██▉       | 146/500 [00:09<00:22, 16.09it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.09it/s] 30%|███       | 150/500 [00:09<00:21, 15.94it/s] 30%|███       | 152/500 [00:09<00:23, 14.66it/s] 31%|███       | 154/500 [00:10<00:25, 13.84it/s] 31%|███       | 156/500 [00:10<00:24, 13.96it/s] 32%|███▏      | 158/500 [00:10<00:23, 14.60it/s] 32%|███▏      | 160/500 [00:10<00:22, 15.08it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.44it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.68it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.90it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.03it/s] 34%|███▍      | 170/500 [00:11<00:20, 16.11it/s] 34%|███▍      | 172/500 [00:11<00:20, 16.15it/s] 35%|███▍      | 174/500 [00:11<00:20, 16.25it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.97it/s] 36%|███▌      | 178/500 [00:11<00:20, 16.04it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.14it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.24it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.25it/s] 37%|███▋      | 186/500 [00:12<00:19, 16.18it/s] 38%|███▊      | 188/500 [00:12<00:20, 15.06it/s] 38%|███▊      | 190/500 [00:12<00:22, 13.90it/s] 38%|███▊      | 192/500 [00:12<00:21, 14.53it/s] 39%|███▉      | 194/500 [00:12<00:20, 14.79it/s] 39%|███▉      | 196/500 [00:12<00:20, 15.19it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.53it/s] 40%|████      | 200/500 [00:12<00:19, 15.71it/s] 40%|████      | 202/500 [00:13<00:19, 15.41it/s] 41%|████      | 204/500 [00:13<00:19, 15.46it/s] 41%|████      | 206/500 [00:13<00:18, 15.53it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.58it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.82it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.93it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.01it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.16it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.21it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.25it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.16it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.05it/s] 45%|████▌     | 226/500 [00:14<00:17, 16.03it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.93it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.70it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.90it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.00it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.69it/s] 48%|████▊     | 238/500 [00:15<00:18, 14.46it/s] 48%|████▊     | 240/500 [00:15<00:18, 13.75it/s] 48%|████▊     | 242/500 [00:15<00:19, 13.15it/s] 49%|████▉     | 244/500 [00:15<00:19, 12.89it/s] 49%|████▉     | 246/500 [00:16<00:20, 12.63it/s] 50%|████▉     | 248/500 [00:16<00:19, 13.22it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:18, 13.82it/s] 50%|█████     | 252/500 [00:16<00:17, 14.46it/s] 51%|█████     | 254/500 [00:16<00:16, 14.84it/s] 51%|█████     | 256/500 [00:16<00:15, 15.29it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.60it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.68it/s] 52%|█████▏    | 262/500 [00:17<00:15, 15.55it/s] 53%|█████▎    | 264/500 [00:17<00:16, 14.40it/s] 53%|█████▎    | 266/500 [00:17<00:16, 14.36it/s] 54%|█████▎    | 268/500 [00:17<00:15, 14.74it/s] 54%|█████▍    | 270/500 [00:17<00:15, 14.41it/s] 54%|█████▍    | 272/500 [00:17<00:15, 14.85it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.27it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.57it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.80it/s] 56%|█████▌    | 280/500 [00:18<00:13, 15.96it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.94it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.73it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.85it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.49it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.26it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.25it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.47it/s] 59%|█████▉    | 296/500 [00:19<00:13, 15.60it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.75it/s] 60%|██████    | 300/500 [00:19<00:12, 15.95it/s] 60%|██████    | 302/500 [00:19<00:12, 15.98it/s] 61%|██████    | 304/500 [00:19<00:12, 15.65it/s] 61%|██████    | 306/500 [00:19<00:12, 15.32it/s] 62%|██████▏   | 308/500 [00:20<00:12, 15.43it/s] 62%|██████▏   | 310/500 [00:20<00:12, 15.49it/s] 62%|██████▏   | 312/500 [00:20<00:12, 15.47it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.58it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.75it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.88it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.02it/s] 64%|██████▍   | 322/500 [00:20<00:11, 16.13it/s] 65%|██████▍   | 324/500 [00:21<00:10, 16.12it/s] 65%|██████▌   | 326/500 [00:21<00:10, 16.15it/s] 66%|██████▌   | 328/500 [00:21<00:10, 16.04it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.06it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.67it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.13it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.38it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.65it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.43it/s] 68%|██████▊   | 342/500 [00:22<00:10, 15.62it/s] 69%|██████▉   | 344/500 [00:22<00:09, 15.79it/s] 69%|██████▉   | 346/500 [00:22<00:09, 15.88it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.05it/s] 70%|███████   | 350/500 [00:22<00:09, 15.71it/s] 70%|███████   | 352/500 [00:22<00:09, 15.85it/s] 71%|███████   | 354/500 [00:22<00:09, 15.96it/s] 71%|███████   | 356/500 [00:23<00:08, 16.09it/s] 72%|███████▏  | 358/500 [00:23<00:08, 16.17it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.25it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.92it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.91it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.02it/s] 74%|███████▎  | 368/500 [00:23<00:09, 14.54it/s] 74%|███████▍  | 370/500 [00:24<00:08, 15.00it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.41it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:08, 15.62it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.80it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.93it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.91it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.88it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.00it/s] 77%|███████▋  | 386/500 [00:25<00:07, 16.01it/s] 78%|███████▊  | 388/500 [00:25<00:07, 15.96it/s] 78%|███████▊  | 390/500 [00:25<00:06, 15.95it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.06it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.03it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.08it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.09it/s] 80%|████████  | 400/500 [00:25<00:06, 15.99it/s] 80%|████████  | 402/500 [00:26<00:06, 16.03it/s] 81%|████████  | 404/500 [00:26<00:06, 15.84it/s] 81%|████████  | 406/500 [00:26<00:05, 15.83it/s] 82%|████████▏ | 408/500 [00:26<00:05, 15.95it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.87it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.70it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.03it/s] 83%|████████▎ | 416/500 [00:26<00:05, 15.14it/s] 84%|████████▎ | 418/500 [00:27<00:05, 15.46it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.69it/s] 84%|████████▍ | 422/500 [00:27<00:04, 15.72it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.58it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.68it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.75it/s] 86%|████████▌ | 430/500 [00:27<00:04, 15.73it/s] 86%|████████▋ | 432/500 [00:27<00:04, 14.95it/s] 87%|████████▋ | 434/500 [00:28<00:04, 14.06it/s] 87%|████████▋ | 436/500 [00:28<00:04, 13.42it/s] 88%|████████▊ | 438/500 [00:28<00:04, 12.98it/s] 88%|████████▊ | 440/500 [00:28<00:04, 12.64it/s] 88%|████████▊ | 442/500 [00:28<00:04, 12.45it/s] 89%|████████▉ | 444/500 [00:28<00:04, 13.04it/s] 89%|████████▉ | 446/500 [00:29<00:03, 13.84it/s] 90%|████████▉ | 448/500 [00:29<00:03, 13.52it/s] 90%|█████████ | 450/500 [00:29<00:03, 13.11it/s] 90%|█████████ | 452/500 [00:29<00:03, 12.88it/s] 91%|█████████ | 454/500 [00:29<00:03, 12.79it/s] 91%|█████████ | 456/500 [00:29<00:03, 13.57it/s] 92%|█████████▏| 458/500 [00:29<00:02, 14.31it/s] 92%|█████████▏| 460/500 [00:30<00:02, 14.91it/s] 92%|█████████▏| 462/500 [00:30<00:02, 15.34it/s] 93%|█████████▎| 464/500 [00:30<00:02, 15.64it/s] 93%|█████████▎| 466/500 [00:30<00:02, 15.83it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.83it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.93it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.74it/s] 95%|█████████▍| 474/500 [00:30<00:01, 14.54it/s] 95%|█████████▌| 476/500 [00:31<00:01, 13.93it/s] 96%|█████████▌| 478/500 [00:31<00:01, 14.44it/s] 96%|█████████▌| 480/500 [00:31<00:01, 14.98it/s] 96%|█████████▋| 482/500 [00:31<00:01, 15.35it/s] 97%|█████████▋| 484/500 [00:31<00:01, 15.11it/s] 97%|█████████▋| 486/500 [00:31<00:00, 15.15it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.41it/s] 98%|█████████▊| 490/500 [00:32<00:00, 15.38it/s] 98%|█████████▊| 492/500 [00:32<00:00, 14.96it/s] 99%|█████████▉| 494/500 [00:32<00:00, 15.04it/s] 99%|█████████▉| 496/500 [00:32<00:00, 14.10it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 13.48it/s]100%|██████████| 500/500 [00:32<00:00, 13.80it/s]100%|██████████| 500/500 [00:32<00:00, 15.26it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  12
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:22,  6.30s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<11:02,  1.36s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:45,  2.91it/s]  4%|▍         | 21/500 [00:20<09:36,  1.20s/it]  5%|▍         | 23/500 [00:20<06:49,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:13,  1.18s/it]  7%|▋         | 33/500 [00:27<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<09:05,  1.19s/it]  9%|▊         | 43/500 [00:33<06:29,  1.17it/s]  9%|▉         | 45/500 [00:34<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.22it/s] 10%|▉         | 49/500 [00:34<02:31,  2.99it/s] 10%|█         | 51/500 [00:40<08:51,  1.18s/it] 11%|█         | 53/500 [00:40<06:20,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:46,  1.20s/it] 13%|█▎        | 63/500 [00:47<06:15,  1.16it/s] 13%|█▎        | 65/500 [00:47<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:48<03:16,  2.20it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.96it/s] 14%|█▍        | 71/500 [00:54<08:33,  1.20s/it] 15%|█▍        | 73/500 [00:54<06:07,  1.16it/s]Epoch:  1  	Training Loss: 0.1598755419254303
Test Loss:  7.107072830200195
Valid Loss:  6.911368370056152
Epoch:  2  	Training Loss: 7.2079081535339355
Test Loss:  0.21388235688209534
Valid Loss:  0.20748797059059143
Epoch:  3  	Training Loss: 0.1600748598575592
Test Loss:  0.21383222937583923
Valid Loss:  0.20743818581104279
Epoch:  4  	Training Loss: 0.16003620624542236
Test Loss:  0.2137821614742279
Valid Loss:  0.20738843083381653
Epoch:  5  	Training Loss: 0.1599975824356079
Test Loss:  0.21373623609542847
Valid Loss:  0.20734569430351257
Epoch:  6  	Training Loss: 0.15996259450912476
Test Loss:  0.21370264887809753
Valid Loss:  0.20731550455093384
Epoch:  7  	Training Loss: 0.15993665158748627
Test Loss:  0.21367570757865906
Valid Loss:  0.20728790760040283
Epoch:  8  	Training Loss: 0.15991461277008057
Test Loss:  0.213650181889534
Valid Loss:  0.20726126432418823
Epoch:  9  	Training Loss: 0.15989482402801514
Test Loss:  0.2136249542236328
Valid Loss:  0.20723503828048706
Epoch:  10  	Training Loss: 0.15987561643123627
Test Loss:  0.21359992027282715
Valid Loss:  0.2072088122367859
Epoch:  11  	Training Loss: 0.1598566472530365
Test Loss:  0.21357497572898865
Valid Loss:  0.20718258619308472
Epoch:  12  	Training Loss: 0.15983779728412628
Test Loss:  0.21357041597366333
Valid Loss:  0.20717789232730865
Epoch:  13  	Training Loss: 0.15983407199382782
Test Loss:  0.213565856218338
Valid Loss:  0.20717322826385498
Epoch:  14  	Training Loss: 0.15983043611049652
Test Loss:  0.21356138586997986
Valid Loss:  0.20716862380504608
Epoch:  15  	Training Loss: 0.15982685983181
Test Loss:  0.2135569304227829
Valid Loss:  0.20716409385204315
Epoch:  16  	Training Loss: 0.15982335805892944
Test Loss:  0.21355247497558594
Valid Loss:  0.2071596086025238
Epoch:  17  	Training Loss: 0.15981990098953247
Test Loss:  0.21354803442955017
Valid Loss:  0.20715513825416565
Epoch:  18  	Training Loss: 0.1598164439201355
Test Loss:  0.2135435938835144
Valid Loss:  0.20715069770812988
Epoch:  19  	Training Loss: 0.15981300175189972
Test Loss:  0.21353916823863983
Valid Loss:  0.20714624226093292
Epoch:  20  	Training Loss: 0.15980957448482513
Test Loss:  0.21353472769260406
Valid Loss:  0.20714180171489716
Epoch:  21  	Training Loss: 0.15980613231658936
Test Loss:  0.2135302871465683
Valid Loss:  0.20713737607002258
Epoch:  22  	Training Loss: 0.15980270504951477
Test Loss:  0.2135252058506012
Valid Loss:  0.20713216066360474
Epoch:  23  	Training Loss: 0.15979884564876556
Test Loss:  0.2135201245546341
Valid Loss:  0.20712696015834808
Epoch:  24  	Training Loss: 0.15979497134685516
Test Loss:  0.213515043258667
Valid Loss:  0.20712175965309143
Epoch:  25  	Training Loss: 0.15979109704494476
Test Loss:  0.21350997686386108
Valid Loss:  0.20711655914783478
Epoch:  26  	Training Loss: 0.15978723764419556
Test Loss:  0.21350489556789398
Valid Loss:  0.20711135864257812
Epoch:  27  	Training Loss: 0.15978339314460754
Test Loss:  0.21349981427192688
Valid Loss:  0.20710617303848267
Epoch:  28  	Training Loss: 0.15977953374385834
Test Loss:  0.21349473297595978
Valid Loss:  0.2071009874343872
Epoch:  29  	Training Loss: 0.15977567434310913
Test Loss:  0.21348966658115387
Valid Loss:  0.20709578692913055
Epoch:  30  	Training Loss: 0.15977182984352112
Test Loss:  0.21348460018634796
Valid Loss:  0.2070905864238739
Epoch:  31  	Training Loss: 0.1597679853439331
Test Loss:  0.21347951889038086
Valid Loss:  0.20708541572093964
Epoch:  32  	Training Loss: 0.1597641408443451
Test Loss:  0.21347442269325256
Valid Loss:  0.2070801556110382
Epoch:  33  	Training Loss: 0.1597602665424347
Test Loss:  0.21346929669380188
Valid Loss:  0.20707491040229797
Epoch:  34  	Training Loss: 0.15975640714168549
Test Loss:  0.21346420049667358
Valid Loss:  0.20706966519355774
Epoch:  35  	Training Loss: 0.15975254774093628
Test Loss:  0.2134590744972229
Valid Loss:  0.2070644199848175
Epoch:  36  	Training Loss: 0.15974867343902588
Test Loss:  0.21345394849777222
Valid Loss:  0.20705917477607727
Epoch:  37  	Training Loss: 0.15974479913711548
Test Loss:  0.21344883739948273
Valid Loss:  0.20705391466617584
Epoch:  38  	Training Loss: 0.15974093973636627
Test Loss:  0.21344372630119324
Valid Loss:  0.2070486694574356
Epoch:  39  	Training Loss: 0.15973708033561707
Test Loss:  0.21343860030174255
Valid Loss:  0.20704342424869537
Epoch:  40  	Training Loss: 0.15973320603370667
Test Loss:  0.21343347430229187
Valid Loss:  0.20703816413879395
Epoch:  41  	Training Loss: 0.15972933173179626
Test Loss:  0.21342837810516357
Valid Loss:  0.2070329338312149
Epoch:  42  	Training Loss: 0.15972548723220825
Test Loss:  0.21342326700687408
Valid Loss:  0.20702770352363586
Epoch:  43  	Training Loss: 0.15972164273262024
Test Loss:  0.21341818571090698
Valid Loss:  0.20702247321605682
Epoch:  44  	Training Loss: 0.15971779823303223
Test Loss:  0.2134130895137787
Valid Loss:  0.20701724290847778
Epoch:  45  	Training Loss: 0.1597139537334442
Test Loss:  0.2134079933166504
Valid Loss:  0.20701199769973755
Epoch:  46  	Training Loss: 0.1597101092338562
Test Loss:  0.2134029120206833
Valid Loss:  0.2070067822933197
Epoch:  47  	Training Loss: 0.159706249833107
Test Loss:  0.213397815823555
Valid Loss:  0.20700156688690186
Epoch:  48  	Training Loss: 0.15970240533351898
Test Loss:  0.2133927345275879
Valid Loss:  0.20699632167816162
Epoch:  49  	Training Loss: 0.15969854593276978
Test Loss:  0.2133876234292984
Valid Loss:  0.20699110627174377
Epoch:  50  	Training Loss: 0.15969471633434296
Test Loss:  0.2133825421333313
Valid Loss:  0.20698586106300354
Epoch:  51  	Training Loss: 0.15969087183475494
Test Loss:  0.2133774310350418
Valid Loss:  0.2069806456565857
Epoch:  52  	Training Loss: 0.15968701243400574
Test Loss:  0.2133723795413971
Valid Loss:  0.20697543025016785
Epoch:  53  	Training Loss: 0.1596831977367401
Test Loss:  0.2133673131465912
Valid Loss:  0.2069702297449112
Epoch:  54  	Training Loss: 0.1596793532371521
Test Loss:  0.2133622169494629
Valid Loss:  0.20696502923965454
Epoch:  55  	Training Loss: 0.15967553853988647
Test Loss:  0.21335718035697937
Valid Loss:  0.2069598287343979
Epoch:  56  	Training Loss: 0.15967170894145966
Test Loss:  0.21335208415985107
Valid Loss:  0.20695462822914124
Epoch:  57  	Training Loss: 0.15966787934303284
Test Loss:  0.21334704756736755
Valid Loss:  0.2069494128227234
Epoch:  58  	Training Loss: 0.1596640646457672
Test Loss:  0.21334195137023926
Valid Loss:  0.20694419741630554
Epoch:  59  	Training Loss: 0.1596602201461792
Test Loss:  0.21333688497543335
Valid Loss:  0.20693902671337128
Epoch:  60  	Training Loss: 0.15965640544891357
Test Loss:  0.21333181858062744
Valid Loss:  0.20693382620811462
Epoch:  61  	Training Loss: 0.15965256094932556
Test Loss:  0.21332675218582153
Valid Loss:  0.20692862570285797
Epoch:  62  	Training Loss: 0.15964873135089874
Test Loss:  0.21332170069217682
Valid Loss:  0.20692342519760132
Epoch:  63  	Training Loss: 0.1596449315547943
Test Loss:  0.2133166342973709
Valid Loss:  0.20691823959350586
Epoch:  64  	Training Loss: 0.1596411168575287
Test Loss:  0.2133115977048874
Valid Loss:  0.2069130688905716
Epoch:  65  	Training Loss: 0.15963730216026306
Test Loss:  0.21330654621124268
Valid Loss:  0.20690786838531494
Epoch:  66  	Training Loss: 0.15963348746299744
Test Loss:  0.21330150961875916
Valid Loss:  0.20690268278121948
Epoch:  67  	Training Loss: 0.1596296727657318
Test Loss:  0.21329642832279205
Valid Loss:  0.20689749717712402
Epoch:  68  	Training Loss: 0.159625843167305
Test Loss:  0.21329137682914734
Valid Loss:  0.20689231157302856
Epoch:  69  	Training Loss: 0.15962202847003937
Test Loss:  0.21328632533550262
Valid Loss:  0.2068871259689331
Epoch:  70  	Training Loss: 0.15961821377277374
Test Loss:  0.2132812738418579
Valid Loss:  0.20688194036483765
Epoch:  71  	Training Loss: 0.15961438417434692
Test Loss:  0.213276207447052
Valid Loss:  0.2068767547607422
Epoch:  72  	Training Loss: 0.1596105843782425
Test Loss:  0.21327117085456848
Valid Loss:  0.20687156915664673
Epoch:  73  	Training Loss: 0.15960675477981567
Test Loss:  0.21326611936092377
Valid Loss:  0.20686639845371246
 15%|█▌        | 75/500 [00:54<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:12,  2.20it/s] 16%|█▌        | 79/500 [00:55<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:01<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:02<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:08<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:15<08:07,  1.22s/it] 21%|██        | 103/500 [01:15<05:48,  1.14it/s] 21%|██        | 105/500 [01:15<04:10,  1.58it/s] 21%|██▏       | 107/500 [01:15<03:03,  2.14it/s] 22%|██▏       | 109/500 [01:16<02:16,  2.87it/s] 22%|██▏       | 111/500 [01:22<07:57,  1.23s/it] 23%|██▎       | 113/500 [01:22<05:41,  1.13it/s] 23%|██▎       | 115/500 [01:22<04:05,  1.57it/s] 23%|██▎       | 117/500 [01:23<02:58,  2.15it/s] 24%|██▍       | 119/500 [01:23<02:11,  2.89it/s] 24%|██▍       | 121/500 [01:29<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:52,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:30<02:06,  2.93it/s] 26%|██▌       | 131/500 [01:36<07:22,  1.20s/it] 27%|██▋       | 133/500 [01:36<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:47,  1.60it/s] 27%|██▋       | 137/500 [01:36<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:37<02:02,  2.95it/s] 28%|██▊       | 141/500 [01:43<07:10,  1.20s/it] 29%|██▊       | 143/500 [01:43<05:07,  1.16it/s] 29%|██▉       | 145/500 [01:43<03:40,  1.61it/s]Epoch:  74  	Training Loss: 0.15960295498371124
Test Loss:  0.21326108276844025
Valid Loss:  0.2068612277507782
Epoch:  75  	Training Loss: 0.15959914028644562
Test Loss:  0.21325603127479553
Valid Loss:  0.20685605704784393
Epoch:  76  	Training Loss: 0.1595953404903412
Test Loss:  0.21325097978115082
Valid Loss:  0.20685088634490967
Epoch:  77  	Training Loss: 0.15959152579307556
Test Loss:  0.2132459431886673
Valid Loss:  0.2068457007408142
Epoch:  78  	Training Loss: 0.15958771109580994
Test Loss:  0.21324092149734497
Valid Loss:  0.20684053003787994
Epoch:  79  	Training Loss: 0.1595838963985443
Test Loss:  0.21323587000370026
Valid Loss:  0.20683535933494568
Epoch:  80  	Training Loss: 0.15958011150360107
Test Loss:  0.21323083341121674
Valid Loss:  0.2068302035331726
Epoch:  81  	Training Loss: 0.15957629680633545
Test Loss:  0.21322578191757202
Valid Loss:  0.20682501792907715
Epoch:  82  	Training Loss: 0.15957248210906982
Test Loss:  0.21322080492973328
Valid Loss:  0.20681989192962646
Epoch:  83  	Training Loss: 0.15956871211528778
Test Loss:  0.21321579813957214
Valid Loss:  0.20681478083133698
Epoch:  84  	Training Loss: 0.15956494212150574
Test Loss:  0.2132108062505722
Valid Loss:  0.2068096399307251
Epoch:  85  	Training Loss: 0.1595611721277237
Test Loss:  0.21320581436157227
Valid Loss:  0.20680451393127441
Epoch:  86  	Training Loss: 0.15955740213394165
Test Loss:  0.21320082247257233
Valid Loss:  0.20679940283298492
Epoch:  87  	Training Loss: 0.1595536321401596
Test Loss:  0.2131958305835724
Valid Loss:  0.20679427683353424
Epoch:  88  	Training Loss: 0.15954986214637756
Test Loss:  0.21319085359573364
Valid Loss:  0.20678916573524475
Epoch:  89  	Training Loss: 0.15954609215259552
Test Loss:  0.2131858617067337
Valid Loss:  0.20678405463695526
Epoch:  90  	Training Loss: 0.15954232215881348
Test Loss:  0.21318086981773376
Valid Loss:  0.20677891373634338
Epoch:  91  	Training Loss: 0.15953855216503143
Test Loss:  0.21317587792873383
Valid Loss:  0.2067738026380539
Epoch:  92  	Training Loss: 0.1595347821712494
Test Loss:  0.2131708860397339
Valid Loss:  0.2067686915397644
Epoch:  93  	Training Loss: 0.15953102707862854
Test Loss:  0.21316590905189514
Valid Loss:  0.2067635953426361
Epoch:  94  	Training Loss: 0.1595272719860077
Test Loss:  0.2131609469652176
Valid Loss:  0.20675846934318542
Epoch:  95  	Training Loss: 0.15952351689338684
Test Loss:  0.21315595507621765
Valid Loss:  0.20675335824489594
Epoch:  96  	Training Loss: 0.159519761800766
Test Loss:  0.2131509929895401
Valid Loss:  0.20674824714660645
Epoch:  97  	Training Loss: 0.15951599180698395
Test Loss:  0.21314600110054016
Valid Loss:  0.20674315094947815
Epoch:  98  	Training Loss: 0.1595122218132019
Test Loss:  0.21314102411270142
Valid Loss:  0.20673802495002747
Epoch:  99  	Training Loss: 0.15950846672058105
Test Loss:  0.21313606202602386
Valid Loss:  0.20673292875289917
Epoch:  100  	Training Loss: 0.1595047265291214
Test Loss:  0.21313107013702393
Valid Loss:  0.20672781765460968
Epoch:  101  	Training Loss: 0.15950095653533936
Test Loss:  0.21312609314918518
Valid Loss:  0.2067227065563202
Epoch:  102  	Training Loss: 0.1594972014427185
Test Loss:  0.21312114596366882
Valid Loss:  0.20671764016151428
Epoch:  103  	Training Loss: 0.15949346125125885
Test Loss:  0.21311616897583008
Valid Loss:  0.206712543964386
Epoch:  104  	Training Loss: 0.159489706158638
Test Loss:  0.21311122179031372
Valid Loss:  0.2067074477672577
Epoch:  105  	Training Loss: 0.15948596596717834
Test Loss:  0.21310624480247498
Valid Loss:  0.20670238137245178
Epoch:  106  	Training Loss: 0.1594822257757187
Test Loss:  0.2131013125181198
Valid Loss:  0.2066972851753235
Epoch:  107  	Training Loss: 0.15947847068309784
Test Loss:  0.21309635043144226
Valid Loss:  0.2066921889781952
Epoch:  108  	Training Loss: 0.15947473049163818
Test Loss:  0.2130913883447647
Valid Loss:  0.20668712258338928
Epoch:  109  	Training Loss: 0.15947097539901733
Test Loss:  0.21308642625808716
Valid Loss:  0.206682026386261
Epoch:  110  	Training Loss: 0.15946725010871887
Test Loss:  0.2130814790725708
Valid Loss:  0.2066769301891327
Epoch:  111  	Training Loss: 0.15946348011493683
Test Loss:  0.21307653188705444
Valid Loss:  0.20667186379432678
Epoch:  112  	Training Loss: 0.15945973992347717
Test Loss:  0.21307159960269928
Valid Loss:  0.20666679739952087
Epoch:  113  	Training Loss: 0.1594560444355011
Test Loss:  0.21306666731834412
Valid Loss:  0.20666176080703735
Epoch:  114  	Training Loss: 0.15945231914520264
Test Loss:  0.21306174993515015
Valid Loss:  0.20665669441223145
Epoch:  115  	Training Loss: 0.15944859385490417
Test Loss:  0.21305683255195618
Valid Loss:  0.20665161311626434
Epoch:  116  	Training Loss: 0.1594448685646057
Test Loss:  0.21305188536643982
Valid Loss:  0.20664657652378082
Epoch:  117  	Training Loss: 0.15944115817546844
Test Loss:  0.21304696798324585
Valid Loss:  0.20664151012897491
Epoch:  118  	Training Loss: 0.15943743288516998
Test Loss:  0.21304203569889069
Valid Loss:  0.2066364586353302
Epoch:  119  	Training Loss: 0.15943370759487152
Test Loss:  0.21303710341453552
Valid Loss:  0.20663142204284668
Epoch:  120  	Training Loss: 0.15942999720573425
Test Loss:  0.21303218603134155
Valid Loss:  0.20662635564804077
Epoch:  121  	Training Loss: 0.1594262719154358
Test Loss:  0.2130272537469864
Valid Loss:  0.20662128925323486
Epoch:  122  	Training Loss: 0.15942254662513733
Test Loss:  0.2130223512649536
Valid Loss:  0.20661625266075134
Epoch:  123  	Training Loss: 0.15941883623600006
Test Loss:  0.21301743388175964
Valid Loss:  0.2066112458705902
Epoch:  124  	Training Loss: 0.1594151258468628
Test Loss:  0.21301254630088806
Valid Loss:  0.20660622417926788
Epoch:  125  	Training Loss: 0.1594114452600479
Test Loss:  0.21300765872001648
Valid Loss:  0.20660118758678436
Epoch:  126  	Training Loss: 0.15940773487091064
Test Loss:  0.2130027711391449
Valid Loss:  0.20659616589546204
Epoch:  127  	Training Loss: 0.15940403938293457
Test Loss:  0.21299785375595093
Valid Loss:  0.2065911442041397
Epoch:  128  	Training Loss: 0.1594003438949585
Test Loss:  0.21299296617507935
Valid Loss:  0.20658613741397858
Epoch:  129  	Training Loss: 0.15939664840698242
Test Loss:  0.21298806369304657
Valid Loss:  0.20658111572265625
Epoch:  130  	Training Loss: 0.15939293801784515
Test Loss:  0.2129831612110138
Valid Loss:  0.20657607913017273
Epoch:  131  	Training Loss: 0.15938924252986908
Test Loss:  0.2129782736301422
Valid Loss:  0.2065710425376892
Epoch:  132  	Training Loss: 0.1593855321407318
Test Loss:  0.21297341585159302
Valid Loss:  0.20656606554985046
Epoch:  133  	Training Loss: 0.15938186645507812
Test Loss:  0.21296852827072144
Valid Loss:  0.20656105875968933
Epoch:  134  	Training Loss: 0.15937817096710205
Test Loss:  0.21296364068984985
Valid Loss:  0.20655608177185059
Epoch:  135  	Training Loss: 0.15937450528144836
Test Loss:  0.21295878291130066
Valid Loss:  0.20655107498168945
Epoch:  136  	Training Loss: 0.15937082469463348
Test Loss:  0.21295392513275146
Valid Loss:  0.20654608309268951
Epoch:  137  	Training Loss: 0.1593671292066574
Test Loss:  0.21294903755187988
Valid Loss:  0.20654107630252838
Epoch:  138  	Training Loss: 0.15936344861984253
Test Loss:  0.2129441648721695
Valid Loss:  0.20653608441352844
Epoch:  139  	Training Loss: 0.15935978293418884
Test Loss:  0.2129392921924591
Valid Loss:  0.2065311074256897
Epoch:  140  	Training Loss: 0.15935610234737396
Test Loss:  0.2129344344139099
Valid Loss:  0.20652607083320618
Epoch:  141  	Training Loss: 0.15935242176055908
Test Loss:  0.21292957663536072
Valid Loss:  0.20652110874652863
Epoch:  142  	Training Loss: 0.1593487560749054
Test Loss:  0.21292471885681152
Valid Loss:  0.20651614665985107
Epoch:  143  	Training Loss: 0.1593450903892517
Test Loss:  0.21291989088058472
Valid Loss:  0.20651116967201233
Epoch:  144  	Training Loss: 0.15934142470359802
Test Loss:  0.21291503310203552
Valid Loss:  0.20650619268417358
Epoch:  145  	Training Loss: 0.15933777391910553
Test Loss:  0.21291020512580872
Valid Loss:  0.20650123059749603
Epoch:  146  	Training Loss: 0.15933410823345184
Test Loss:   29%|██▉       | 147/500 [01:43<02:40,  2.19it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.95it/s] 30%|███       | 151/500 [01:50<06:59,  1.20s/it] 31%|███       | 153/500 [01:50<05:01,  1.15it/s] 31%|███       | 155/500 [01:50<03:38,  1.58it/s] 31%|███▏      | 157/500 [01:50<02:39,  2.14it/s] 32%|███▏      | 159/500 [01:51<01:57,  2.89it/s] 32%|███▏      | 161/500 [01:57<06:47,  1.20s/it] 33%|███▎      | 163/500 [01:57<04:52,  1.15it/s] 33%|███▎      | 165/500 [01:57<03:31,  1.58it/s] 33%|███▎      | 167/500 [01:57<02:36,  2.13it/s] 34%|███▍      | 169/500 [01:58<01:57,  2.82it/s] 34%|███▍      | 171/500 [02:04<06:37,  1.21s/it] 35%|███▍      | 173/500 [02:04<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:04<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:04<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:05<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:11<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:11<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:11<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:11<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:18<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:18<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:18<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:18<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:18<01:42,  2.95it/s] 40%|████      | 201/500 [02:25<06:03,  1.22s/it] 41%|████      | 203/500 [02:25<04:19,  1.15it/s] 41%|████      | 205/500 [02:25<03:06,  1.58it/s] 41%|████▏     | 207/500 [02:25<02:15,  2.16it/s] 42%|████▏     | 209/500 [02:25<01:39,  2.91it/s] 42%|████▏     | 211/500 [02:32<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:32<04:06,  1.16it/s] 43%|████▎     | 215/500 [02:32<02:57,  1.61it/s] 43%|████▎     | 217/500 [02:32<02:08,  2.20it/s]0.21290536224842072
Valid Loss:  0.20649626851081848
Epoch:  147  	Training Loss: 0.15933045744895935
Test Loss:  0.21290051937103271
Valid Loss:  0.20649130642414093
Epoch:  148  	Training Loss: 0.15932679176330566
Test Loss:  0.21289566159248352
Valid Loss:  0.206486314535141
Epoch:  149  	Training Loss: 0.15932312607765198
Test Loss:  0.21289081871509552
Valid Loss:  0.20648136734962463
Epoch:  150  	Training Loss: 0.15931947529315948
Test Loss:  0.21288597583770752
Valid Loss:  0.20647640526294708
Epoch:  151  	Training Loss: 0.1593158096075058
Test Loss:  0.21288111805915833
Valid Loss:  0.20647142827510834
Epoch:  152  	Training Loss: 0.1593121588230133
Test Loss:  0.2128763198852539
Valid Loss:  0.20646649599075317
Epoch:  153  	Training Loss: 0.159308522939682
Test Loss:  0.2128715217113495
Valid Loss:  0.206461563706398
Epoch:  154  	Training Loss: 0.1593048870563507
Test Loss:  0.21286670863628387
Valid Loss:  0.20645663142204285
Epoch:  155  	Training Loss: 0.1593012511730194
Test Loss:  0.21286189556121826
Valid Loss:  0.20645169913768768
Epoch:  156  	Training Loss: 0.1592976152896881
Test Loss:  0.21285709738731384
Valid Loss:  0.2064467817544937
Epoch:  157  	Training Loss: 0.159293994307518
Test Loss:  0.21285226941108704
Valid Loss:  0.20644184947013855
Epoch:  158  	Training Loss: 0.1592903435230255
Test Loss:  0.21284747123718262
Valid Loss:  0.2064369022846222
Epoch:  159  	Training Loss: 0.1592867076396942
Test Loss:  0.212842658162117
Valid Loss:  0.20643197000026703
Epoch:  160  	Training Loss: 0.1592830866575241
Test Loss:  0.2128378450870514
Valid Loss:  0.20642703771591187
Epoch:  161  	Training Loss: 0.159279465675354
Test Loss:  0.21283304691314697
Valid Loss:  0.2064221203327179
Epoch:  162  	Training Loss: 0.1592758148908615
Test Loss:  0.21282824873924255
Valid Loss:  0.20641718804836273
Epoch:  163  	Training Loss: 0.1592721939086914
Test Loss:  0.21282345056533813
Valid Loss:  0.20641228556632996
Epoch:  164  	Training Loss: 0.1592685878276825
Test Loss:  0.2128186821937561
Valid Loss:  0.206407368183136
Epoch:  165  	Training Loss: 0.1592649519443512
Test Loss:  0.21281388401985168
Valid Loss:  0.2064024806022644
Epoch:  166  	Training Loss: 0.15926134586334229
Test Loss:  0.21280910074710846
Valid Loss:  0.20639756321907043
Epoch:  167  	Training Loss: 0.15925773978233337
Test Loss:  0.21280428767204285
Valid Loss:  0.20639264583587646
Epoch:  168  	Training Loss: 0.15925410389900208
Test Loss:  0.21279951930046082
Valid Loss:  0.2063877284526825
Epoch:  169  	Training Loss: 0.15925048291683197
Test Loss:  0.2127947211265564
Valid Loss:  0.2063828408718109
Epoch:  170  	Training Loss: 0.15924686193466187
Test Loss:  0.21278995275497437
Valid Loss:  0.20637792348861694
Epoch:  171  	Training Loss: 0.15924325585365295
Test Loss:  0.21278515458106995
Valid Loss:  0.20637302100658417
Epoch:  172  	Training Loss: 0.15923961997032166
Test Loss:  0.21278038620948792
Valid Loss:  0.2063681185245514
Epoch:  173  	Training Loss: 0.15923602879047394
Test Loss:  0.21277561783790588
Valid Loss:  0.2063632309436798
Epoch:  174  	Training Loss: 0.15923243761062622
Test Loss:  0.21277084946632385
Valid Loss:  0.20635834336280823
Epoch:  175  	Training Loss: 0.1592288315296173
Test Loss:  0.21276606619358063
Valid Loss:  0.20635345578193665
Epoch:  176  	Training Loss: 0.1592252254486084
Test Loss:  0.2127613127231598
Valid Loss:  0.20634856820106506
Epoch:  177  	Training Loss: 0.1592216193675995
Test Loss:  0.21275652945041656
Valid Loss:  0.20634368062019348
Epoch:  178  	Training Loss: 0.15921801328659058
Test Loss:  0.21275179088115692
Valid Loss:  0.2063387930393219
Epoch:  179  	Training Loss: 0.15921440720558167
Test Loss:  0.2127470076084137
Valid Loss:  0.20633390545845032
Epoch:  180  	Training Loss: 0.15921080112457275
Test Loss:  0.21274223923683167
Valid Loss:  0.20632901787757874
Epoch:  181  	Training Loss: 0.15920720994472504
Test Loss:  0.21273747086524963
Valid Loss:  0.20632413029670715
Epoch:  182  	Training Loss: 0.15920358896255493
Test Loss:  0.21273274719715118
Valid Loss:  0.20631928741931915
Epoch:  183  	Training Loss: 0.1592000275850296
Test Loss:  0.21272802352905273
Valid Loss:  0.20631444454193115
Epoch:  184  	Training Loss: 0.15919645130634308
Test Loss:  0.21272329986095428
Valid Loss:  0.20630960166454315
Epoch:  185  	Training Loss: 0.15919287502765656
Test Loss:  0.21271856129169464
Valid Loss:  0.20630475878715515
Epoch:  186  	Training Loss: 0.15918929874897003
Test Loss:  0.2127138376235962
Valid Loss:  0.20629990100860596
Epoch:  187  	Training Loss: 0.1591857373714447
Test Loss:  0.21270909905433655
Valid Loss:  0.20629507303237915
Epoch:  188  	Training Loss: 0.15918216109275818
Test Loss:  0.2127043902873993
Valid Loss:  0.20629021525382996
Epoch:  189  	Training Loss: 0.15917858481407166
Test Loss:  0.21269965171813965
Valid Loss:  0.20628535747528076
Epoch:  190  	Training Loss: 0.15917500853538513
Test Loss:  0.2126949429512024
Valid Loss:  0.20628051459789276
Epoch:  191  	Training Loss: 0.1591714322566986
Test Loss:  0.21269020438194275
Valid Loss:  0.20627567172050476
Epoch:  192  	Training Loss: 0.15916787087917328
Test Loss:  0.2126854956150055
Valid Loss:  0.20627085864543915
Epoch:  193  	Training Loss: 0.15916430950164795
Test Loss:  0.21268078684806824
Valid Loss:  0.20626603066921234
Epoch:  194  	Training Loss: 0.15916074812412262
Test Loss:  0.21267607808113098
Valid Loss:  0.20626121759414673
Epoch:  195  	Training Loss: 0.1591571867465973
Test Loss:  0.21267136931419373
Valid Loss:  0.20625638961791992
Epoch:  196  	Training Loss: 0.15915364027023315
Test Loss:  0.21266664564609528
Valid Loss:  0.20625154674053192
Epoch:  197  	Training Loss: 0.15915006399154663
Test Loss:  0.2126619517803192
Valid Loss:  0.2062467336654663
Epoch:  198  	Training Loss: 0.1591465026140213
Test Loss:  0.21265722811222076
Valid Loss:  0.2062418907880783
Epoch:  199  	Training Loss: 0.15914294123649597
Test Loss:  0.2126525193452835
Valid Loss:  0.2062370628118515
Epoch:  200  	Training Loss: 0.15913939476013184
Test Loss:  0.21264782547950745
Valid Loss:  0.2062322497367859
Epoch:  201  	Training Loss: 0.1591358333826065
Test Loss:  0.212643101811409
Valid Loss:  0.20622742176055908
Epoch:  202  	Training Loss: 0.15913227200508118
Test Loss:  0.21263840794563293
Valid Loss:  0.20622262358665466
Epoch:  203  	Training Loss: 0.15912872552871704
Test Loss:  0.21263372898101807
Valid Loss:  0.20621782541275024
Epoch:  204  	Training Loss: 0.1591251790523529
Test Loss:  0.2126290500164032
Valid Loss:  0.20621302723884583
Epoch:  205  	Training Loss: 0.15912163257598877
Test Loss:  0.21262437105178833
Valid Loss:  0.2062082290649414
Epoch:  206  	Training Loss: 0.15911810100078583
Test Loss:  0.21261966228485107
Valid Loss:  0.206203430891037
Epoch:  207  	Training Loss: 0.1591145545244217
Test Loss:  0.2126150131225586
Valid Loss:  0.20619863271713257
Epoch:  208  	Training Loss: 0.15911102294921875
Test Loss:  0.21261033415794373
Valid Loss:  0.20619383454322815
Epoch:  209  	Training Loss: 0.15910747647285461
Test Loss:  0.21260562539100647
Valid Loss:  0.20618903636932373
Epoch:  210  	Training Loss: 0.15910392999649048
Test Loss:  0.2126009464263916
Valid Loss:  0.2061842381954193
Epoch:  211  	Training Loss: 0.15910039842128754
Test Loss:  0.21259626746177673
Valid Loss:  0.2061794549226761
Epoch:  212  	Training Loss: 0.1590968519449234
Test Loss:  0.21259164810180664
Valid Loss:  0.20617471635341644
Epoch:  213  	Training Loss: 0.15909335017204285
Test Loss:  0.21258702874183655
Valid Loss:  0.2061699628829956
Epoch:  214  	Training Loss: 0.1590898633003235
Test Loss:  0.21258239448070526
Valid Loss:  0.20616522431373596
Epoch:  215  	Training Loss: 0.15908637642860413
Test Loss:  0.21257777512073517
Valid Loss:  0.20616048574447632
Epoch:  216  	Training Loss: 0.15908287465572357
Test Loss:  0.21257315576076508
Valid Loss:  0.20615574717521667
Epoch:  217  	Training Loss: 0.15907937288284302
Test Loss:  0.21256853640079498
Valid Loss:  0.20615100860595703
Epoch:  218  	Training Loss: 0.15907588601112366
Test Loss:  0.2125639021396637
Valid Loss:  0.2061462700366974
 44%|████▍     | 219/500 [02:32<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:39<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:39<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:39<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:39<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:46<05:20,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:46<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:46<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:52<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:53<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:53<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:53<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:53<01:24,  2.96it/s] 50%|█████     | 251/500 [02:59<04:57,  1.20s/it] 51%|█████     | 253/500 [02:59<03:32,  1.16it/s] 51%|█████     | 255/500 [03:00<02:32,  1.61it/s] 51%|█████▏    | 257/500 [03:00<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:00<01:21,  2.95it/s] 52%|█████▏    | 261/500 [03:06<04:45,  1.19s/it] 53%|█████▎    | 263/500 [03:06<03:23,  1.17it/s] 53%|█████▎    | 265/500 [03:07<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:07<01:46,  2.20it/s] 54%|█████▍    | 269/500 [03:07<01:18,  2.93it/s] 54%|█████▍    | 271/500 [03:13<04:43,  1.24s/it] 55%|█████▍    | 273/500 [03:14<03:21,  1.13it/s] 55%|█████▌    | 275/500 [03:14<02:24,  1.56it/s] 55%|█████▌    | 277/500 [03:14<01:44,  2.14it/s] 56%|█████▌    | 279/500 [03:14<01:16,  2.87it/s] 56%|█████▌    | 281/500 [03:20<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:20<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:21<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:21<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:21<01:11,  2.97it/s]Epoch:  219  	Training Loss: 0.1590723842382431
Test Loss:  0.2125592827796936
Valid Loss:  0.20614153146743774
Epoch:  220  	Training Loss: 0.15906891226768494
Test Loss:  0.2125546634197235
Valid Loss:  0.2061367928981781
Epoch:  221  	Training Loss: 0.15906541049480438
Test Loss:  0.21255002915859222
Valid Loss:  0.20613205432891846
Epoch:  222  	Training Loss: 0.15906190872192383
Test Loss:  0.21254542469978333
Valid Loss:  0.20612733066082
Epoch:  223  	Training Loss: 0.15905842185020447
Test Loss:  0.21254080533981323
Valid Loss:  0.20612257719039917
Epoch:  224  	Training Loss: 0.1590549349784851
Test Loss:  0.21253618597984314
Valid Loss:  0.20611786842346191
Epoch:  225  	Training Loss: 0.15905144810676575
Test Loss:  0.21253156661987305
Valid Loss:  0.20611314475536346
Epoch:  226  	Training Loss: 0.1590479612350464
Test Loss:  0.21252696216106415
Valid Loss:  0.20610842108726501
Epoch:  227  	Training Loss: 0.15904447436332703
Test Loss:  0.21252234280109406
Valid Loss:  0.20610368251800537
Epoch:  228  	Training Loss: 0.15904095768928528
Test Loss:  0.21251773834228516
Valid Loss:  0.20609895884990692
Epoch:  229  	Training Loss: 0.1590374857187271
Test Loss:  0.21251311898231506
Valid Loss:  0.20609423518180847
Epoch:  230  	Training Loss: 0.15903398394584656
Test Loss:  0.21250852942466736
Valid Loss:  0.20608951151371002
Epoch:  231  	Training Loss: 0.1590304970741272
Test Loss:  0.21250389516353607
Valid Loss:  0.20608478784561157
Epoch:  232  	Training Loss: 0.15902701020240784
Test Loss:  0.21249932050704956
Valid Loss:  0.2060801088809967
Epoch:  233  	Training Loss: 0.15902355313301086
Test Loss:  0.21249476075172424
Valid Loss:  0.20607542991638184
Epoch:  234  	Training Loss: 0.1590200960636139
Test Loss:  0.21249017119407654
Valid Loss:  0.20607075095176697
Epoch:  235  	Training Loss: 0.15901663899421692
Test Loss:  0.21248561143875122
Valid Loss:  0.2060660570859909
Epoch:  236  	Training Loss: 0.15901318192481995
Test Loss:  0.21248102188110352
Valid Loss:  0.20606136322021484
Epoch:  237  	Training Loss: 0.15900972485542297
Test Loss:  0.2124764621257782
Valid Loss:  0.20605668425559998
Epoch:  238  	Training Loss: 0.1590062826871872
Test Loss:  0.2124718874692917
Valid Loss:  0.2060520052909851
Epoch:  239  	Training Loss: 0.15900281071662903
Test Loss:  0.21246731281280518
Valid Loss:  0.20604731142520905
Epoch:  240  	Training Loss: 0.15899935364723206
Test Loss:  0.21246275305747986
Valid Loss:  0.20604264736175537
Epoch:  241  	Training Loss: 0.15899591147899628
Test Loss:  0.21245816349983215
Valid Loss:  0.2060379534959793
Epoch:  242  	Training Loss: 0.1589924544095993
Test Loss:  0.21245363354682922
Valid Loss:  0.20603328943252563
Epoch:  243  	Training Loss: 0.15898899734020233
Test Loss:  0.2124490737915039
Valid Loss:  0.20602864027023315
Epoch:  244  	Training Loss: 0.15898557007312775
Test Loss:  0.21244452893733978
Valid Loss:  0.2060239613056183
Epoch:  245  	Training Loss: 0.15898212790489197
Test Loss:  0.21243996918201447
Valid Loss:  0.2060193121433258
Epoch:  246  	Training Loss: 0.15897870063781738
Test Loss:  0.21243542432785034
Valid Loss:  0.20601464807987213
Epoch:  247  	Training Loss: 0.1589752435684204
Test Loss:  0.2124308943748474
Valid Loss:  0.20600999891757965
Epoch:  248  	Training Loss: 0.15897180140018463
Test Loss:  0.2124263346195221
Valid Loss:  0.20600533485412598
Epoch:  249  	Training Loss: 0.15896835923194885
Test Loss:  0.21242177486419678
Valid Loss:  0.2060006856918335
Epoch:  250  	Training Loss: 0.15896493196487427
Test Loss:  0.21241723001003265
Valid Loss:  0.20599602162837982
Epoch:  251  	Training Loss: 0.1589614897966385
Test Loss:  0.21241268515586853
Valid Loss:  0.20599135756492615
Epoch:  252  	Training Loss: 0.1589580476284027
Test Loss:  0.2124081552028656
Valid Loss:  0.20598673820495605
Epoch:  253  	Training Loss: 0.15895462036132812
Test Loss:  0.21240364015102386
Valid Loss:  0.20598210394382477
Epoch:  254  	Training Loss: 0.15895122289657593
Test Loss:  0.21239912509918213
Valid Loss:  0.20597746968269348
Epoch:  255  	Training Loss: 0.15894779562950134
Test Loss:  0.2123946100473404
Valid Loss:  0.2059728503227234
Epoch:  256  	Training Loss: 0.15894438326358795
Test Loss:  0.21239009499549866
Valid Loss:  0.2059682309627533
Epoch:  257  	Training Loss: 0.15894095599651337
Test Loss:  0.21238556504249573
Valid Loss:  0.2059636116027832
Epoch:  258  	Training Loss: 0.15893754363059998
Test Loss:  0.212381049990654
Valid Loss:  0.20595896244049072
Epoch:  259  	Training Loss: 0.1589341163635254
Test Loss:  0.21237653493881226
Valid Loss:  0.20595435798168182
Epoch:  260  	Training Loss: 0.1589306890964508
Test Loss:  0.21237200498580933
Valid Loss:  0.20594972372055054
Epoch:  261  	Training Loss: 0.1589272916316986
Test Loss:  0.2123674750328064
Valid Loss:  0.20594508945941925
Epoch:  262  	Training Loss: 0.15892387926578522
Test Loss:  0.21236301958560944
Valid Loss:  0.20594051480293274
Epoch:  263  	Training Loss: 0.15892048180103302
Test Loss:  0.2123585343360901
Valid Loss:  0.20593592524528503
Epoch:  264  	Training Loss: 0.15891708433628082
Test Loss:  0.21235404908657074
Valid Loss:  0.20593133568763733
Epoch:  265  	Training Loss: 0.15891370177268982
Test Loss:  0.2123495638370514
Valid Loss:  0.20592674612998962
Epoch:  266  	Training Loss: 0.15891030430793762
Test Loss:  0.21234509348869324
Valid Loss:  0.2059221714735031
Epoch:  267  	Training Loss: 0.15890692174434662
Test Loss:  0.21234062314033508
Valid Loss:  0.2059175670146942
Epoch:  268  	Training Loss: 0.15890353918075562
Test Loss:  0.21233612298965454
Valid Loss:  0.2059129774570465
Epoch:  269  	Training Loss: 0.15890014171600342
Test Loss:  0.21233166754245758
Valid Loss:  0.2059084177017212
Epoch:  270  	Training Loss: 0.15889675915241241
Test Loss:  0.21232718229293823
Valid Loss:  0.2059038281440735
Epoch:  271  	Training Loss: 0.15889336168766022
Test Loss:  0.2123226821422577
Valid Loss:  0.20589923858642578
Epoch:  272  	Training Loss: 0.1588899791240692
Test Loss:  0.21231825649738312
Valid Loss:  0.20589470863342285
Epoch:  273  	Training Loss: 0.1588866114616394
Test Loss:  0.21231380105018616
Valid Loss:  0.20589014887809753
Epoch:  274  	Training Loss: 0.15888327360153198
Test Loss:  0.2123093605041504
Valid Loss:  0.20588558912277222
Epoch:  275  	Training Loss: 0.15887990593910217
Test Loss:  0.212304949760437
Valid Loss:  0.2058810591697693
Epoch:  276  	Training Loss: 0.15887653827667236
Test Loss:  0.21230049431324005
Valid Loss:  0.20587649941444397
Epoch:  277  	Training Loss: 0.15887320041656494
Test Loss:  0.2122960388660431
Valid Loss:  0.20587193965911865
Epoch:  278  	Training Loss: 0.15886983275413513
Test Loss:  0.21229161322116852
Valid Loss:  0.20586740970611572
Epoch:  279  	Training Loss: 0.15886646509170532
Test Loss:  0.21228717267513275
Valid Loss:  0.2058628797531128
Epoch:  280  	Training Loss: 0.1588631123304367
Test Loss:  0.21228273212909698
Valid Loss:  0.20585831999778748
Epoch:  281  	Training Loss: 0.1588597297668457
Test Loss:  0.21227829158306122
Valid Loss:  0.20585376024246216
Epoch:  282  	Training Loss: 0.15885639190673828
Test Loss:  0.21227389574050903
Valid Loss:  0.20584924519062042
Epoch:  283  	Training Loss: 0.15885305404663086
Test Loss:  0.21226947009563446
Valid Loss:  0.20584474503993988
Epoch:  284  	Training Loss: 0.15884971618652344
Test Loss:  0.2122650444507599
Valid Loss:  0.20584024488925934
Epoch:  285  	Training Loss: 0.15884637832641602
Test Loss:  0.2122606486082077
Valid Loss:  0.2058357298374176
Epoch:  286  	Training Loss: 0.1588430404663086
Test Loss:  0.21225625276565552
Valid Loss:  0.20583121478557587
Epoch:  287  	Training Loss: 0.15883970260620117
Test Loss:  0.21225184202194214
Valid Loss:  0.20582669973373413
Epoch:  288  	Training Loss: 0.15883637964725494
Test Loss:  0.21224743127822876
Valid Loss:  0.2058221846818924
Epoch:  289  	Training Loss: 0.15883304178714752
Test Loss:  0.21224302053451538
Valid Loss:  0.20581766963005066
Epoch:  290  	Training Loss: 0.1588297039270401
Test Loss:  0.212238609790802
Valid Loss:  0.20581313967704773
Epoch:  291  	Training Loss: 0.15882638096809387
 58%|█████▊    | 291/500 [03:27<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:27<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:28<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:28<01:34,  2.16it/s] 60%|█████▉    | 299/500 [03:28<01:10,  2.86it/s] 60%|██████    | 301/500 [03:34<03:57,  1.19s/it] 61%|██████    | 303/500 [03:34<02:48,  1.17it/s] 61%|██████    | 305/500 [03:35<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:35<01:05,  2.91it/s] 62%|██████▏   | 311/500 [03:41<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:41<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:41<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:42<01:23,  2.18it/s] 64%|██████▍   | 319/500 [03:42<01:01,  2.92it/s] 64%|██████▍   | 321/500 [03:48<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:48<02:33,  1.16it/s] 65%|██████▌   | 325/500 [03:48<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:49<01:19,  2.19it/s] 66%|██████▌   | 329/500 [03:49<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:55<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:55<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:55<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:55<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:56<00:53,  2.98it/s] 68%|██████▊   | 341/500 [04:02<03:13,  1.22s/it] 69%|██████▊   | 343/500 [04:02<02:18,  1.14it/s] 69%|██████▉   | 345/500 [04:02<01:38,  1.57it/s] 69%|██████▉   | 347/500 [04:03<01:11,  2.15it/s] 70%|██████▉   | 349/500 [04:03<00:52,  2.87it/s] 70%|███████   | 351/500 [04:09<02:59,  1.20s/it] 71%|███████   | 353/500 [04:09<02:06,  1.16it/s] 71%|███████   | 355/500 [04:09<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:09<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:10<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:16<02:43,  1.18s/it]Test Loss:  0.21223421394824982
Valid Loss:  0.20580865442752838
Epoch:  292  	Training Loss: 0.15882304310798645
Test Loss:  0.21222981810569763
Valid Loss:  0.20580415427684784
Epoch:  293  	Training Loss: 0.15881972014904022
Test Loss:  0.21222545206546783
Valid Loss:  0.2057996690273285
Epoch:  294  	Training Loss: 0.1588164120912552
Test Loss:  0.21222107112407684
Valid Loss:  0.20579519867897034
Epoch:  295  	Training Loss: 0.15881310403347015
Test Loss:  0.21221667528152466
Valid Loss:  0.205790713429451
Epoch:  296  	Training Loss: 0.15880978107452393
Test Loss:  0.21221232414245605
Valid Loss:  0.20578625798225403
Epoch:  297  	Training Loss: 0.1588064730167389
Test Loss:  0.21220794320106506
Valid Loss:  0.2057817578315735
Epoch:  298  	Training Loss: 0.15880316495895386
Test Loss:  0.21220353245735168
Valid Loss:  0.20577728748321533
Epoch:  299  	Training Loss: 0.15879984200000763
Test Loss:  0.2121991664171219
Valid Loss:  0.20577280223369598
Epoch:  300  	Training Loss: 0.1587965190410614
Test Loss:  0.2121948003768921
Valid Loss:  0.20576831698417664
Epoch:  301  	Training Loss: 0.15879321098327637
Test Loss:  0.2121904194355011
Valid Loss:  0.2057638317346573
Epoch:  302  	Training Loss: 0.15878990292549133
Test Loss:  0.2121860682964325
Valid Loss:  0.20575939118862152
Epoch:  303  	Training Loss: 0.1587866246700287
Test Loss:  0.2121817171573639
Valid Loss:  0.20575496554374695
Epoch:  304  	Training Loss: 0.15878334641456604
Test Loss:  0.21217738091945648
Valid Loss:  0.20575051009655
Epoch:  305  	Training Loss: 0.1587800532579422
Test Loss:  0.21217304468154907
Valid Loss:  0.20574606955051422
Epoch:  306  	Training Loss: 0.15877676010131836
Test Loss:  0.21216870844364166
Valid Loss:  0.20574161410331726
Epoch:  307  	Training Loss: 0.1587734818458557
Test Loss:  0.21216437220573425
Valid Loss:  0.2057371735572815
Epoch:  308  	Training Loss: 0.15877020359039307
Test Loss:  0.21216002106666565
Valid Loss:  0.20573274791240692
Epoch:  309  	Training Loss: 0.15876691043376923
Test Loss:  0.21215569972991943
Valid Loss:  0.20572830736637115
Epoch:  310  	Training Loss: 0.15876363217830658
Test Loss:  0.21215134859085083
Valid Loss:  0.2057238668203354
Epoch:  311  	Training Loss: 0.15876033902168274
Test Loss:  0.21214701235294342
Valid Loss:  0.20571942627429962
Epoch:  312  	Training Loss: 0.1587570607662201
Test Loss:  0.212142676115036
Valid Loss:  0.20571501553058624
Epoch:  313  	Training Loss: 0.15875379741191864
Test Loss:  0.21213838458061218
Valid Loss:  0.20571058988571167
Epoch:  314  	Training Loss: 0.1587505340576172
Test Loss:  0.21213407814502716
Valid Loss:  0.2057061791419983
Epoch:  315  	Training Loss: 0.15874725580215454
Test Loss:  0.21212974190711975
Valid Loss:  0.2057017683982849
Epoch:  316  	Training Loss: 0.15874400734901428
Test Loss:  0.21212545037269592
Valid Loss:  0.20569735765457153
Epoch:  317  	Training Loss: 0.15874072909355164
Test Loss:  0.2121211290359497
Valid Loss:  0.20569294691085815
Epoch:  318  	Training Loss: 0.15873746573925018
Test Loss:  0.2121168076992035
Valid Loss:  0.20568853616714478
Epoch:  319  	Training Loss: 0.15873420238494873
Test Loss:  0.21211250126361847
Valid Loss:  0.2056841254234314
Epoch:  320  	Training Loss: 0.15873095393180847
Test Loss:  0.21210817992687225
Valid Loss:  0.20567971467971802
Epoch:  321  	Training Loss: 0.15872767567634583
Test Loss:  0.21210388839244843
Valid Loss:  0.20567530393600464
Epoch:  322  	Training Loss: 0.15872442722320557
Test Loss:  0.2120995819568634
Valid Loss:  0.20567092299461365
Epoch:  323  	Training Loss: 0.1587211638689041
Test Loss:  0.21209529042243958
Valid Loss:  0.20566652715206146
Epoch:  324  	Training Loss: 0.15871793031692505
Test Loss:  0.21209099888801575
Valid Loss:  0.20566214621067047
Epoch:  325  	Training Loss: 0.1587146669626236
Test Loss:  0.21208670735359192
Valid Loss:  0.2056577503681183
Epoch:  326  	Training Loss: 0.15871143341064453
Test Loss:  0.21208243072032928
Valid Loss:  0.2056533545255661
Epoch:  327  	Training Loss: 0.15870818495750427
Test Loss:  0.21207812428474426
Valid Loss:  0.2056489735841751
Epoch:  328  	Training Loss: 0.15870492160320282
Test Loss:  0.21207383275032043
Valid Loss:  0.20564459264278412
Epoch:  329  	Training Loss: 0.15870168805122375
Test Loss:  0.2120695561170578
Valid Loss:  0.20564022660255432
Epoch:  330  	Training Loss: 0.1586984395980835
Test Loss:  0.21206526458263397
Valid Loss:  0.20563581585884094
Epoch:  331  	Training Loss: 0.15869519114494324
Test Loss:  0.21206098794937134
Valid Loss:  0.20563143491744995
Epoch:  332  	Training Loss: 0.15869194269180298
Test Loss:  0.2120567411184311
Valid Loss:  0.20562708377838135
Epoch:  333  	Training Loss: 0.1586887240409851
Test Loss:  0.21205247938632965
Valid Loss:  0.20562274754047394
Epoch:  334  	Training Loss: 0.15868550539016724
Test Loss:  0.2120482474565506
Valid Loss:  0.20561839640140533
Epoch:  335  	Training Loss: 0.15868230164051056
Test Loss:  0.21204400062561035
Valid Loss:  0.20561406016349792
Epoch:  336  	Training Loss: 0.1586790829896927
Test Loss:  0.2120397388935089
Valid Loss:  0.20560972392559052
Epoch:  337  	Training Loss: 0.15867586433887482
Test Loss:  0.21203550696372986
Valid Loss:  0.2056053876876831
Epoch:  338  	Training Loss: 0.15867266058921814
Test Loss:  0.2120312601327896
Valid Loss:  0.2056010514497757
Epoch:  339  	Training Loss: 0.15866944193840027
Test Loss:  0.21202701330184937
Valid Loss:  0.2055966854095459
Epoch:  340  	Training Loss: 0.1586662381887436
Test Loss:  0.21202276647090912
Valid Loss:  0.20559236407279968
Epoch:  341  	Training Loss: 0.15866301953792572
Test Loss:  0.21201851963996887
Valid Loss:  0.20558801293373108
Epoch:  342  	Training Loss: 0.15865980088710785
Test Loss:  0.2120143175125122
Valid Loss:  0.20558370649814606
Epoch:  343  	Training Loss: 0.15865662693977356
Test Loss:  0.21201010048389435
Valid Loss:  0.20557940006256104
Epoch:  344  	Training Loss: 0.15865342319011688
Test Loss:  0.2120058834552765
Valid Loss:  0.205575093626976
Epoch:  345  	Training Loss: 0.1586502343416214
Test Loss:  0.21200166642665863
Valid Loss:  0.2055707722902298
Epoch:  346  	Training Loss: 0.15864704549312592
Test Loss:  0.21199744939804077
Valid Loss:  0.20556646585464478
Epoch:  347  	Training Loss: 0.15864385664463043
Test Loss:  0.2119932323694229
Valid Loss:  0.20556217432022095
Epoch:  348  	Training Loss: 0.15864065289497375
Test Loss:  0.21198901534080505
Valid Loss:  0.20555785298347473
Epoch:  349  	Training Loss: 0.15863746404647827
Test Loss:  0.2119848132133484
Valid Loss:  0.20555353164672852
Epoch:  350  	Training Loss: 0.1586342751979828
Test Loss:  0.21198059618473053
Valid Loss:  0.20554925501346588
Epoch:  351  	Training Loss: 0.1586310863494873
Test Loss:  0.21197637915611267
Valid Loss:  0.20554491877555847
Epoch:  352  	Training Loss: 0.15862789750099182
Test Loss:  0.2119722217321396
Valid Loss:  0.20554067194461823
Epoch:  353  	Training Loss: 0.15862473845481873
Test Loss:  0.2119680494070053
Valid Loss:  0.2055363953113556
Epoch:  354  	Training Loss: 0.15862159430980682
Test Loss:  0.21196386218070984
Valid Loss:  0.20553214848041534
Epoch:  355  	Training Loss: 0.15861842036247253
Test Loss:  0.21195970475673676
Valid Loss:  0.2055278718471527
Epoch:  356  	Training Loss: 0.15861526131629944
Test Loss:  0.21195551753044128
Valid Loss:  0.20552361011505127
Epoch:  357  	Training Loss: 0.15861211717128754
Test Loss:  0.2119513750076294
Valid Loss:  0.20551934838294983
Epoch:  358  	Training Loss: 0.15860897302627563
Test Loss:  0.21194718778133392
Valid Loss:  0.2055150866508484
Epoch:  359  	Training Loss: 0.15860581398010254
Test Loss:  0.21194303035736084
Valid Loss:  0.20551082491874695
Epoch:  360  	Training Loss: 0.15860265493392944
Test Loss:  0.21193885803222656
Valid Loss:  0.2055065631866455
Epoch:  361  	Training Loss: 0.15859949588775635
Test Loss:  0.21193470060825348
Valid Loss:  0.20550228655338287
Epoch:  362  	Training Loss: 0.15859633684158325
Test Loss:  0.2119305431842804
Valid Loss:  0.20549805462360382
Epoch:  363  	Training Loss: 0.15859319269657135
Test Loss:  0.2119264006614685
Valid Loss:   73%|███████▎  | 363/500 [04:16<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:16<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:16<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:16<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:23<02:34,  1.19s/it] 75%|███████▍  | 373/500 [04:23<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:23<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:23<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:23<00:41,  2.91it/s] 76%|███████▌  | 381/500 [04:30<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:30<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:30<01:12,  1.58it/s] 77%|███████▋  | 387/500 [04:30<00:53,  2.13it/s] 78%|███████▊  | 389/500 [04:31<00:39,  2.82it/s] 78%|███████▊  | 391/500 [04:37<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:37<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:37<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:37<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:37<00:34,  2.95it/s] 80%|████████  | 401/500 [04:44<01:58,  1.19s/it] 81%|████████  | 403/500 [04:44<01:23,  1.17it/s] 81%|████████  | 405/500 [04:44<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:44<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:44<00:30,  2.97it/s] 82%|████████▏ | 411/500 [04:51<01:47,  1.21s/it] 82%|████████▏ | 412/500 [04:51<01:29,  1.01s/it] 83%|████████▎ | 414/500 [04:51<01:00,  1.42it/s] 83%|████████▎ | 416/500 [04:51<00:42,  1.99it/s] 84%|████████▎ | 418/500 [04:51<00:30,  2.69it/s] 84%|████████▍ | 420/500 [04:52<00:22,  3.54it/s] 84%|████████▍ | 422/500 [04:58<01:32,  1.19s/it] 85%|████████▍ | 424/500 [04:58<01:04,  1.18it/s] 85%|████████▌ | 426/500 [04:58<00:45,  1.64it/s] 86%|████████▌ | 428/500 [04:58<00:32,  2.24it/s] 86%|████████▌ | 430/500 [04:59<00:23,  3.02it/s] 86%|████████▋ | 432/500 [05:05<01:21,  1.20s/it] 87%|████████▋ | 434/500 [05:05<00:56,  1.16it/s]0.20549383759498596
Epoch:  364  	Training Loss: 0.15859004855155945
Test Loss:  0.21192224323749542
Valid Loss:  0.20548956096172333
Epoch:  365  	Training Loss: 0.15858691930770874
Test Loss:  0.21191811561584473
Valid Loss:  0.20548532903194427
Epoch:  366  	Training Loss: 0.15858376026153564
Test Loss:  0.21191394329071045
Valid Loss:  0.20548111200332642
Epoch:  367  	Training Loss: 0.15858063101768494
Test Loss:  0.21190978586673737
Valid Loss:  0.20547685027122498
Epoch:  368  	Training Loss: 0.15857750177383423
Test Loss:  0.21190565824508667
Valid Loss:  0.20547261834144592
Epoch:  369  	Training Loss: 0.15857434272766113
Test Loss:  0.21190151572227478
Valid Loss:  0.20546837151050568
Epoch:  370  	Training Loss: 0.15857121348381042
Test Loss:  0.2118973582983017
Valid Loss:  0.20546412467956543
Epoch:  371  	Training Loss: 0.15856806933879852
Test Loss:  0.211893230676651
Valid Loss:  0.20545989274978638
Epoch:  372  	Training Loss: 0.15856492519378662
Test Loss:  0.2118890881538391
Valid Loss:  0.20545567572116852
Epoch:  373  	Training Loss: 0.1585618108510971
Test Loss:  0.211885005235672
Valid Loss:  0.20545148849487305
Epoch:  374  	Training Loss: 0.1585586965084076
Test Loss:  0.2118808627128601
Valid Loss:  0.2054472714662552
Epoch:  375  	Training Loss: 0.15855558216571808
Test Loss:  0.2118767499923706
Valid Loss:  0.20544306933879852
Epoch:  376  	Training Loss: 0.15855246782302856
Test Loss:  0.2118726372718811
Valid Loss:  0.20543885231018066
Epoch:  377  	Training Loss: 0.15854933857917786
Test Loss:  0.2118685245513916
Valid Loss:  0.205434650182724
Epoch:  378  	Training Loss: 0.15854622423648834
Test Loss:  0.2118644118309021
Valid Loss:  0.20543044805526733
Epoch:  379  	Training Loss: 0.15854312479496002
Test Loss:  0.2118602991104126
Valid Loss:  0.20542624592781067
Epoch:  380  	Training Loss: 0.15853999555110931
Test Loss:  0.2118561714887619
Valid Loss:  0.2054220288991928
Epoch:  381  	Training Loss: 0.1585368812084198
Test Loss:  0.2118520438671112
Valid Loss:  0.20541784167289734
Epoch:  382  	Training Loss: 0.15853378176689148
Test Loss:  0.21184797585010529
Valid Loss:  0.20541366934776306
Epoch:  383  	Training Loss: 0.15853068232536316
Test Loss:  0.21184390783309937
Valid Loss:  0.20540949702262878
Epoch:  384  	Training Loss: 0.15852758288383484
Test Loss:  0.21183982491493225
Valid Loss:  0.2054053395986557
Epoch:  385  	Training Loss: 0.1585244983434677
Test Loss:  0.21183574199676514
Valid Loss:  0.20540116727352142
Epoch:  386  	Training Loss: 0.15852141380310059
Test Loss:  0.21183167397975922
Valid Loss:  0.20539699494838715
Epoch:  387  	Training Loss: 0.15851831436157227
Test Loss:  0.2118276059627533
Valid Loss:  0.20539282262325287
Epoch:  388  	Training Loss: 0.15851524472236633
Test Loss:  0.21182352304458618
Valid Loss:  0.20538866519927979
Epoch:  389  	Training Loss: 0.158512145280838
Test Loss:  0.21181944012641907
Valid Loss:  0.2053844928741455
Epoch:  390  	Training Loss: 0.15850907564163208
Test Loss:  0.21181537210941315
Valid Loss:  0.20538035035133362
Epoch:  391  	Training Loss: 0.15850597620010376
Test Loss:  0.21181128919124603
Valid Loss:  0.20537617802619934
Epoch:  392  	Training Loss: 0.15850289165973663
Test Loss:  0.2118072509765625
Valid Loss:  0.20537203550338745
Epoch:  393  	Training Loss: 0.1584998220205307
Test Loss:  0.21180316805839539
Valid Loss:  0.20536789298057556
Epoch:  394  	Training Loss: 0.15849673748016357
Test Loss:  0.21179911494255066
Valid Loss:  0.20536372065544128
Epoch:  395  	Training Loss: 0.15849366784095764
Test Loss:  0.21179506182670593
Valid Loss:  0.2053595930337906
Epoch:  396  	Training Loss: 0.1584905982017517
Test Loss:  0.2117910087108612
Valid Loss:  0.2053554356098175
Epoch:  397  	Training Loss: 0.15848752856254578
Test Loss:  0.21178695559501648
Valid Loss:  0.20535129308700562
Epoch:  398  	Training Loss: 0.15848445892333984
Test Loss:  0.21178287267684937
Valid Loss:  0.20534715056419373
Epoch:  399  	Training Loss: 0.1584813892841339
Test Loss:  0.21177884936332703
Valid Loss:  0.20534299314022064
Epoch:  400  	Training Loss: 0.15847831964492798
Test Loss:  0.2117747664451599
Valid Loss:  0.20533885061740875
Epoch:  401  	Training Loss: 0.15847525000572205
Test Loss:  0.21177072823047638
Valid Loss:  0.20533470809459686
Epoch:  402  	Training Loss: 0.15847216546535492
Test Loss:  0.21176670491695404
Valid Loss:  0.20533061027526855
Epoch:  403  	Training Loss: 0.15846911072731018
Test Loss:  0.2117626965045929
Valid Loss:  0.20532652735710144
Epoch:  404  	Training Loss: 0.15846608579158783
Test Loss:  0.21175868809223175
Valid Loss:  0.20532242953777313
Epoch:  405  	Training Loss: 0.1584630310535431
Test Loss:  0.2117546796798706
Valid Loss:  0.20531831681728363
Epoch:  406  	Training Loss: 0.15845999121665955
Test Loss:  0.21175065636634827
Valid Loss:  0.20531423389911652
Epoch:  407  	Training Loss: 0.1584569662809372
Test Loss:  0.21174664795398712
Valid Loss:  0.2053101360797882
Epoch:  408  	Training Loss: 0.15845391154289246
Test Loss:  0.21174262464046478
Valid Loss:  0.2053060382604599
Epoch:  409  	Training Loss: 0.1584508717060089
Test Loss:  0.21173861622810364
Valid Loss:  0.2053019404411316
Epoch:  410  	Training Loss: 0.15844783186912537
Test Loss:  0.2117346078157425
Valid Loss:  0.2052978277206421
Epoch:  411  	Training Loss: 0.15844479203224182
Test Loss:  0.21173059940338135
Valid Loss:  0.20529374480247498
Epoch:  412  	Training Loss: 0.15844175219535828
Test Loss:  0.2117266058921814
Valid Loss:  0.20528967678546906
Epoch:  413  	Training Loss: 0.15843874216079712
Test Loss:  0.21172262728214264
Valid Loss:  0.20528560876846313
Epoch:  414  	Training Loss: 0.15843571722507477
Test Loss:  0.21171864867210388
Valid Loss:  0.20528154075145721
Epoch:  415  	Training Loss: 0.1584327071905136
Test Loss:  0.21171468496322632
Valid Loss:  0.2052774727344513
Epoch:  416  	Training Loss: 0.15842968225479126
Test Loss:  0.21171067655086517
Valid Loss:  0.20527341961860657
Epoch:  417  	Training Loss: 0.1584266722202301
Test Loss:  0.21170669794082642
Valid Loss:  0.20526933670043945
Epoch:  418  	Training Loss: 0.15842366218566895
Test Loss:  0.21170273423194885
Valid Loss:  0.20526528358459473
Epoch:  419  	Training Loss: 0.1584206372499466
Test Loss:  0.2116987407207489
Valid Loss:  0.2052612155675888
Epoch:  420  	Training Loss: 0.15841761231422424
Test Loss:  0.21169476211071014
Valid Loss:  0.20525714755058289
Epoch:  421  	Training Loss: 0.15841460227966309
Test Loss:  0.2116907835006714
Valid Loss:  0.20525307953357697
Epoch:  422  	Training Loss: 0.15841159224510193
Test Loss:  0.21168681979179382
Valid Loss:  0.20524905622005463
Epoch:  423  	Training Loss: 0.15840859711170197
Test Loss:  0.21168288588523865
Valid Loss:  0.2052450180053711
Epoch:  424  	Training Loss: 0.158405601978302
Test Loss:  0.21167895197868347
Valid Loss:  0.20524099469184875
Epoch:  425  	Training Loss: 0.15840262174606323
Test Loss:  0.2116750031709671
Valid Loss:  0.20523697137832642
Epoch:  426  	Training Loss: 0.15839962661266327
Test Loss:  0.21167105436325073
Valid Loss:  0.20523294806480408
Epoch:  427  	Training Loss: 0.1583966314792633
Test Loss:  0.21166712045669556
Valid Loss:  0.20522889494895935
Epoch:  428  	Training Loss: 0.15839365124702454
Test Loss:  0.211663156747818
Valid Loss:  0.2052248865365982
Epoch:  429  	Training Loss: 0.15839065611362457
Test Loss:  0.21165922284126282
Valid Loss:  0.20522084832191467
Epoch:  430  	Training Loss: 0.1583876758813858
Test Loss:  0.21165527403354645
Valid Loss:  0.20521681010723114
Epoch:  431  	Training Loss: 0.15838468074798584
Test Loss:  0.21165132522583008
Valid Loss:  0.20521280169487
Epoch:  432  	Training Loss: 0.15838170051574707
Test Loss:  0.2116474211215973
Valid Loss:  0.20520880818367004
Epoch:  433  	Training Loss: 0.1583787202835083
Test Loss:  0.2116435170173645
Valid Loss:  0.2052047997713089
Epoch:  434  	Training Loss: 0.15837576985359192
Test Loss:  0.21163958311080933
Valid Loss:  0.20520082116127014
Epoch:  435  	Training Loss: 0.15837280452251434
Test Loss:  0.21163569390773773
Valid Loss:  0.2051968276500702
 87%|████████▋ | 436/500 [05:05<00:39,  1.61it/s] 88%|████████▊ | 438/500 [05:05<00:28,  2.21it/s] 88%|████████▊ | 440/500 [05:06<00:20,  2.93it/s] 88%|████████▊ | 442/500 [05:12<01:10,  1.22s/it] 89%|████████▉ | 444/500 [05:12<00:48,  1.15it/s] 89%|████████▉ | 446/500 [05:12<00:33,  1.59it/s] 90%|████████▉ | 448/500 [05:12<00:23,  2.18it/s] 90%|█████████ | 450/500 [05:13<00:17,  2.93it/s] 90%|█████████ | 452/500 [05:19<00:58,  1.21s/it] 91%|█████████ | 454/500 [05:19<00:39,  1.15it/s] 91%|█████████ | 456/500 [05:19<00:27,  1.58it/s] 92%|█████████▏| 458/500 [05:20<00:19,  2.14it/s] 92%|█████████▏| 460/500 [05:20<00:13,  2.86it/s] 92%|█████████▏| 462/500 [05:26<00:45,  1.19s/it] 93%|█████████▎| 464/500 [05:26<00:30,  1.17it/s] 93%|█████████▎| 466/500 [05:26<00:21,  1.62it/s] 94%|█████████▎| 468/500 [05:26<00:14,  2.21it/s] 94%|█████████▍| 470/500 [05:27<00:10,  2.97it/s] 94%|█████████▍| 472/500 [05:33<00:33,  1.21s/it] 95%|█████████▍| 474/500 [05:33<00:22,  1.16it/s] 95%|█████████▌| 476/500 [05:33<00:15,  1.60it/s] 96%|█████████▌| 478/500 [05:33<00:10,  2.19it/s] 96%|█████████▌| 480/500 [05:34<00:06,  2.94it/s] 96%|█████████▋| 482/500 [05:40<00:21,  1.20s/it] 97%|█████████▋| 484/500 [05:40<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:40<00:08,  1.61it/s] 98%|█████████▊| 488/500 [05:40<00:05,  2.20it/s] 98%|█████████▊| 490/500 [05:40<00:03,  2.95it/s] 98%|█████████▊| 492/500 [05:47<00:09,  1.19s/it] 99%|█████████▉| 494/500 [05:47<00:05,  1.17it/s] 99%|█████████▉| 496/500 [05:47<00:02,  1.62it/s]100%|█████████▉| 498/500 [05:47<00:00,  2.21it/s]100%|██████████| 500/500 [05:47<00:00,  2.95it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Epoch:  436  	Training Loss: 0.15836983919143677
Test Loss:  0.21163178980350494
Valid Loss:  0.20519281923770905
Epoch:  437  	Training Loss: 0.15836688876152039
Test Loss:  0.21162787079811096
Valid Loss:  0.2051888406276703
Epoch:  438  	Training Loss: 0.1583639234304428
Test Loss:  0.21162395179271698
Valid Loss:  0.20518484711647034
Epoch:  439  	Training Loss: 0.15836095809936523
Test Loss:  0.2116200476884842
Valid Loss:  0.2051808387041092
Epoch:  440  	Training Loss: 0.15835799276828766
Test Loss:  0.2116161435842514
Valid Loss:  0.20517686009407043
Epoch:  441  	Training Loss: 0.15835502743721008
Test Loss:  0.21161223948001862
Valid Loss:  0.20517286658287048
Epoch:  442  	Training Loss: 0.1583520770072937
Test Loss:  0.21160835027694702
Valid Loss:  0.20516890287399292
Epoch:  443  	Training Loss: 0.15834912657737732
Test Loss:  0.21160447597503662
Valid Loss:  0.20516492426395416
Epoch:  444  	Training Loss: 0.15834617614746094
Test Loss:  0.21160057187080383
Valid Loss:  0.2051609754562378
Epoch:  445  	Training Loss: 0.15834322571754456
Test Loss:  0.21159666776657104
Valid Loss:  0.20515698194503784
Epoch:  446  	Training Loss: 0.15834029018878937
Test Loss:  0.21159279346466064
Valid Loss:  0.20515301823616028
Epoch:  447  	Training Loss: 0.1583373248577118
Test Loss:  0.21158890426158905
Valid Loss:  0.20514905452728271
Epoch:  448  	Training Loss: 0.1583343744277954
Test Loss:  0.21158501505851746
Valid Loss:  0.20514506101608276
Epoch:  449  	Training Loss: 0.15833145380020142
Test Loss:  0.21158112585544586
Valid Loss:  0.2051410973072052
Epoch:  450  	Training Loss: 0.15832847356796265
Test Loss:  0.21157723665237427
Valid Loss:  0.20513713359832764
Epoch:  451  	Training Loss: 0.15832555294036865
Test Loss:  0.21157333254814148
Valid Loss:  0.20513316988945007
Epoch:  452  	Training Loss: 0.15832258760929108
Test Loss:  0.21156948804855347
Valid Loss:  0.2051292359828949
Epoch:  453  	Training Loss: 0.15831966698169708
Test Loss:  0.21156562864780426
Valid Loss:  0.20512530207633972
Epoch:  454  	Training Loss: 0.1583167463541031
Test Loss:  0.21156176924705505
Valid Loss:  0.20512133836746216
Epoch:  455  	Training Loss: 0.1583138257265091
Test Loss:  0.21155792474746704
Valid Loss:  0.20511741936206818
Epoch:  456  	Training Loss: 0.1583108901977539
Test Loss:  0.21155405044555664
Valid Loss:  0.205113485455513
Epoch:  457  	Training Loss: 0.1583079695701599
Test Loss:  0.21155019104480743
Valid Loss:  0.20510955154895782
Epoch:  458  	Training Loss: 0.15830504894256592
Test Loss:  0.21154634654521942
Valid Loss:  0.20510561764240265
Epoch:  459  	Training Loss: 0.15830212831497192
Test Loss:  0.21154248714447021
Valid Loss:  0.20510166883468628
Epoch:  460  	Training Loss: 0.15829920768737793
Test Loss:  0.211538627743721
Valid Loss:  0.2050977349281311
Epoch:  461  	Training Loss: 0.15829627215862274
Test Loss:  0.2115347683429718
Valid Loss:  0.20509380102157593
Epoch:  462  	Training Loss: 0.15829335153102875
Test Loss:  0.21153095364570618
Valid Loss:  0.20508989691734314
Epoch:  463  	Training Loss: 0.15829044580459595
Test Loss:  0.21152710914611816
Valid Loss:  0.20508597791194916
Epoch:  464  	Training Loss: 0.15828752517700195
Test Loss:  0.21152326464653015
Valid Loss:  0.20508205890655518
Epoch:  465  	Training Loss: 0.15828463435173035
Test Loss:  0.21151942014694214
Valid Loss:  0.2050781548023224
Epoch:  466  	Training Loss: 0.15828171372413635
Test Loss:  0.2115156054496765
Valid Loss:  0.2050742506980896
Epoch:  467  	Training Loss: 0.15827880799770355
Test Loss:  0.2115117609500885
Valid Loss:  0.20507033169269562
Epoch:  468  	Training Loss: 0.15827590227127075
Test Loss:  0.21150793135166168
Valid Loss:  0.20506641268730164
Epoch:  469  	Training Loss: 0.15827301144599915
Test Loss:  0.21150410175323486
Valid Loss:  0.20506250858306885
Epoch:  470  	Training Loss: 0.15827009081840515
Test Loss:  0.21150025725364685
Valid Loss:  0.20505858957767487
Epoch:  471  	Training Loss: 0.15826718509197235
Test Loss:  0.21149642765522003
Valid Loss:  0.20505467057228088
Epoch:  472  	Training Loss: 0.15826427936553955
Test Loss:  0.2114926278591156
Valid Loss:  0.20505079627037048
Epoch:  473  	Training Loss: 0.15826138854026794
Test Loss:  0.21148881316184998
Valid Loss:  0.20504692196846008
Epoch:  474  	Training Loss: 0.15825851261615753
Test Loss:  0.21148502826690674
Valid Loss:  0.20504304766654968
Epoch:  475  	Training Loss: 0.15825562179088593
Test Loss:  0.2114812135696411
Valid Loss:  0.20503917336463928
Epoch:  476  	Training Loss: 0.1582527458667755
Test Loss:  0.21147742867469788
Valid Loss:  0.20503529906272888
Epoch:  477  	Training Loss: 0.1582498550415039
Test Loss:  0.21147362887859344
Valid Loss:  0.2050314098596573
Epoch:  478  	Training Loss: 0.1582469791173935
Test Loss:  0.21146981418132782
Valid Loss:  0.20502755045890808
Epoch:  479  	Training Loss: 0.1582440882921219
Test Loss:  0.2114659994840622
Valid Loss:  0.2050236612558365
Epoch:  480  	Training Loss: 0.15824121236801147
Test Loss:  0.21146221458911896
Valid Loss:  0.2050197720527649
Epoch:  481  	Training Loss: 0.15823832154273987
Test Loss:  0.21145841479301453
Valid Loss:  0.2050158977508545
Epoch:  482  	Training Loss: 0.15823544561862946
Test Loss:  0.2114546298980713
Valid Loss:  0.20501205325126648
Epoch:  483  	Training Loss: 0.15823258459568024
Test Loss:  0.21145087480545044
Valid Loss:  0.20500820875167847
Epoch:  484  	Training Loss: 0.1582297384738922
Test Loss:  0.2114470899105072
Valid Loss:  0.20500436425209045
Epoch:  485  	Training Loss: 0.158226877450943
Test Loss:  0.21144331991672516
Valid Loss:  0.20500050485134125
Epoch:  486  	Training Loss: 0.15822400152683258
Test Loss:  0.21143954992294312
Valid Loss:  0.20499664545059204
Epoch:  487  	Training Loss: 0.15822114050388336
Test Loss:  0.21143576502799988
Valid Loss:  0.20499280095100403
Epoch:  488  	Training Loss: 0.15821827948093414
Test Loss:  0.21143200993537903
Valid Loss:  0.20498895645141602
Epoch:  489  	Training Loss: 0.15821543335914612
Test Loss:  0.2114282250404358
Valid Loss:  0.204985111951828
Epoch:  490  	Training Loss: 0.1582125723361969
Test Loss:  0.21142446994781494
Valid Loss:  0.20498126745224
Epoch:  491  	Training Loss: 0.15820971131324768
Test Loss:  0.2114206850528717
Valid Loss:  0.20497742295265198
Epoch:  492  	Training Loss: 0.15820685029029846
Test Loss:  0.21141692996025085
Valid Loss:  0.20497360825538635
Epoch:  493  	Training Loss: 0.15820398926734924
Test Loss:  0.2114131897687912
Valid Loss:  0.20496977865695953
Epoch:  494  	Training Loss: 0.1582011580467224
Test Loss:  0.21140943467617035
Valid Loss:  0.2049659788608551
Epoch:  495  	Training Loss: 0.1581983119249344
Test Loss:  0.2114056944847107
Valid Loss:  0.2049621343612671
Epoch:  496  	Training Loss: 0.15819546580314636
Test Loss:  0.21140193939208984
Valid Loss:  0.20495831966400146
Epoch:  497  	Training Loss: 0.15819261968135834
Test Loss:  0.21139821410179138
Valid Loss:  0.20495450496673584
Epoch:  498  	Training Loss: 0.1581897735595703
Test Loss:  0.21139445900917053
Valid Loss:  0.20495066046714783
Epoch:  499  	Training Loss: 0.15818694233894348
Test Loss:  0.21139070391654968
Valid Loss:  0.2049468606710434
Epoch:  500  	Training Loss: 0.15818408131599426
Test Loss:  0.21138694882392883
Valid Loss:  0.20494303107261658
seed is  12
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:13,  6.28s/it]  1%|          | 3/500 [00:06<13:53,  1.68s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:49,  1.33s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:26<17:22,  2.18s/it]  5%|▍         | 23/500 [00:26<12:11,  1.53s/it]  5%|▌         | 25/500 [00:26<08:37,  1.09s/it]  5%|▌         | 27/500 [00:26<06:08,  1.28it/s]  6%|▌         | 29/500 [00:26<04:25,  1.77it/s]  6%|▌         | 31/500 [00:33<10:54,  1.40s/it]  7%|▋         | 33/500 [00:33<07:46,  1.00it/s]  7%|▋         | 35/500 [00:33<05:33,  1.39it/s]  7%|▋         | 37/500 [00:33<04:03,  1.90it/s]  8%|▊         | 39/500 [00:34<02:58,  2.58it/s]  8%|▊         | 41/500 [00:40<09:29,  1.24s/it]  9%|▊         | 43/500 [00:40<06:48,  1.12it/s]  9%|▉         | 45/500 [00:40<04:55,  1.54it/s]  9%|▉         | 47/500 [00:40<03:34,  2.11it/s] 10%|▉         | 49/500 [00:41<02:38,  2.84it/s] 10%|█         | 51/500 [00:47<09:05,  1.22s/it] 11%|█         | 53/500 [00:47<06:30,  1.15it/s] 11%|█         | 55/500 [00:47<04:41,  1.58it/s] 11%|█▏        | 57/500 [00:47<03:24,  2.17it/s] 12%|█▏        | 59/500 [00:48<02:31,  2.92it/s] 12%|█▏        | 61/500 [00:54<08:57,  1.22s/it] 13%|█▎        | 63/500 [00:54<06:23,  1.14it/s] 13%|█▎        | 65/500 [00:54<04:36,  1.57it/s] 13%|█▎        | 67/500 [00:55<03:22,  2.14it/s]Epoch:  1  	Training Loss: 0.1598755419254303
Test Loss:  0.11204439401626587
Valid Loss:  0.12273881584405899
Epoch:  2  	Training Loss: 0.161708801984787
Test Loss:  0.138979971408844
Valid Loss:  0.11856622248888016
Epoch:  3  	Training Loss: 0.11533033847808838
Test Loss:  0.012226928025484085
Valid Loss:  0.017736313864588737
Epoch:  4  	Training Loss: 0.027252916246652603
Test Loss:  0.016559429466724396
Valid Loss:  0.012869657948613167
Epoch:  5  	Training Loss: 0.011772723868489265
Test Loss:  0.0036826133728027344
Valid Loss:  0.005235631950199604
Epoch:  6  	Training Loss: 0.007797513157129288
Test Loss:  0.007370495703071356
Valid Loss:  0.006395673844963312
Epoch:  7  	Training Loss: 0.006672019604593515
Test Loss:  0.004651078954339027
Valid Loss:  0.004993160255253315
Epoch:  8  	Training Loss: 0.006323465146124363
Test Loss:  0.005808084271848202
Valid Loss:  0.005435530096292496
Epoch:  9  	Training Loss: 0.00618158420547843
Test Loss:  0.005058508366346359
Valid Loss:  0.005045692436397076
Epoch:  10  	Training Loss: 0.006094580516219139
Test Loss:  0.005348126403987408
Valid Loss:  0.005127925891429186
Epoch:  11  	Training Loss: 0.006023280322551727
Test Loss:  0.005105135031044483
Valid Loss:  0.004975919146090746
Epoch:  12  	Training Loss: 0.005956969223916531
Test Loss:  0.0017609568312764168
Valid Loss:  0.0023702664766460657
Epoch:  13  	Training Loss: 0.0035361521877348423
Test Loss:  0.008882870897650719
Valid Loss:  0.005842552520334721
Epoch:  14  	Training Loss: 0.006396935321390629
Test Loss:  0.021700087934732437
Valid Loss:  0.027291005477309227
Epoch:  15  	Training Loss: 0.02898092195391655
Test Loss:  0.10057233273983002
Valid Loss:  0.08528020232915878
Epoch:  16  	Training Loss: 0.08220835030078888
Test Loss:  0.07413912564516068
Valid Loss:  0.08071450889110565
Epoch:  17  	Training Loss: 0.09367430210113525
Test Loss:  0.0225981492549181
Valid Loss:  0.016492072492837906
Epoch:  18  	Training Loss: 0.017252186313271523
Test Loss:  0.008230465464293957
Valid Loss:  0.01048947498202324
Epoch:  19  	Training Loss: 0.014199841767549515
Test Loss:  0.007362122181802988
Valid Loss:  0.004570642486214638
Epoch:  20  	Training Loss: 0.005444864742457867
Test Loss:  0.0017180269351229072
Valid Loss:  0.0028120765928179026
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.003844615537673235
Test Loss:  0.0014207825297489762
Valid Loss:  0.000973645132035017
Epoch:  22  	Training Loss: 0.0012578676687553525
Test Loss:  0.0008532110368832946
Valid Loss:  0.0007119837682694197
Epoch:  23  	Training Loss: 0.0008849131991155446
Test Loss:  0.0006032661767676473
Valid Loss:  0.000636440934613347
Epoch:  24  	Training Loss: 0.0007284062448889017
Test Loss:  0.0005312831490300596
Valid Loss:  0.0006392191862687469
Epoch:  25  	Training Loss: 0.0006884167669340968
Test Loss:  0.0005121544236317277
Valid Loss:  0.0006399692501872778
Epoch:  26  	Training Loss: 0.000675275397952646
Test Loss:  0.0005086654564365745
Valid Loss:  0.0006336134392768145
Epoch:  27  	Training Loss: 0.0006627980619668961
Test Loss:  0.000503347662743181
Valid Loss:  0.0006279160734266043
Epoch:  28  	Training Loss: 0.0006499370210804045
Test Loss:  0.0004973679315298796
Valid Loss:  0.0006215793546289206
Epoch:  29  	Training Loss: 0.0006375037482939661
Test Loss:  0.0004908374976366758
Valid Loss:  0.000614206597674638
Epoch:  30  	Training Loss: 0.00062501837965101
Test Loss:  0.0004839781322516501
Valid Loss:  0.0006063695182092488
Epoch:  31  	Training Loss: 0.0006118600722402334
Test Loss:  0.00047697313129901886
Valid Loss:  0.0005979575216770172
Epoch:  32  	Training Loss: 0.0005981684662401676
Test Loss:  0.00047246337635442615
Valid Loss:  0.0005657426663674414
Epoch:  33  	Training Loss: 0.0005451556062325835
Test Loss:  0.00045464816503226757
Valid Loss:  0.0005501598352566361
Epoch:  34  	Training Loss: 0.0005112848011776805
Test Loss:  0.0004285972681827843
Valid Loss:  0.0005389939760789275
Epoch:  35  	Training Loss: 0.00048662687186151743
Test Loss:  0.00041628521285019815
Valid Loss:  0.0005267875385470688
Epoch:  36  	Training Loss: 0.0004656236560549587
Test Loss:  0.0004076845070812851
Valid Loss:  0.0005132942460477352
Epoch:  37  	Training Loss: 0.00044681187137030065
Test Loss:  0.00039657525485381484
Valid Loss:  0.0005012283800169826
Epoch:  38  	Training Loss: 0.00042830387246795
Test Loss:  0.0003884175093844533
Valid Loss:  0.0004893543664366007
Epoch:  39  	Training Loss: 0.0004100467776879668
Test Loss:  0.0003789626935031265
Valid Loss:  0.0004775904235430062
Epoch:  40  	Training Loss: 0.0003926088393200189
Test Loss:  0.0003706652205437422
Valid Loss:  0.0004651229246519506
Epoch:  41  	Training Loss: 0.0003752955235540867
Test Loss:  0.0003605102247092873
Valid Loss:  0.0004532640741672367
Epoch:  42  	Training Loss: 0.0003591278800740838
Test Loss:  0.00033642753260210156
Valid Loss:  0.0004297398845665157
Epoch:  43  	Training Loss: 0.00032282734173350036
Test Loss:  0.00031283521093428135
Valid Loss:  0.00041659126873128116
Epoch:  44  	Training Loss: 0.00029901257948949933
Test Loss:  0.0002934537478722632
Valid Loss:  0.0004059152561239898
Epoch:  45  	Training Loss: 0.0002816370106302202
Test Loss:  0.0002786527620628476
Valid Loss:  0.0003955968131776899
Epoch:  46  	Training Loss: 0.00026750986580736935
Test Loss:  0.00026654425892047584
Valid Loss:  0.0003854387323372066
Epoch:  47  	Training Loss: 0.0002551260113250464
Test Loss:  0.0002560471184551716
Valid Loss:  0.00037585687823593616
Epoch:  48  	Training Loss: 0.00024418585235252976
Test Loss:  0.0002469176542945206
Valid Loss:  0.00036678125616163015
Epoch:  49  	Training Loss: 0.00023430309374816716
Test Loss:  0.00023873282771091908
Valid Loss:  0.0003582577046472579
Epoch:  50  	Training Loss: 0.00022545052343048155
Test Loss:  0.00023150807828642428
Valid Loss:  0.0003501863684505224
Epoch:  51  	Training Loss: 0.00021753729379270226
Test Loss:  0.0002249597746413201
Valid Loss:  0.00034259125823155046
Epoch:  52  	Training Loss: 0.00021032500080764294
Test Loss:  0.00021734685287810862
Valid Loss:  0.00033936859108507633
Epoch:  53  	Training Loss: 0.00020561032579280436
Test Loss:  0.0002135118847945705
Valid Loss:  0.00033455679658800364
Epoch:  54  	Training Loss: 0.00020140421111136675
Test Loss:  0.00020959177345503122
Valid Loss:  0.00033044314477592707
Epoch:  55  	Training Loss: 0.00019759268616326153
Test Loss:  0.0002064883301500231
Valid Loss:  0.000326824898365885
Epoch:  56  	Training Loss: 0.00019427214283496141
Test Loss:  0.0002038359671132639
Valid Loss:  0.00032378564355894923
Epoch:  57  	Training Loss: 0.00019138341303914785
Test Loss:  0.00020179091370664537
Valid Loss:  0.0003209661808796227
Epoch:  58  	Training Loss: 0.00018889257626142353
Test Loss:  0.0001998600346269086
Valid Loss:  0.00031849724473431706
Epoch:  59  	Training Loss: 0.00018655437452252954
Test Loss:  0.0001981267414521426
Valid Loss:  0.0003161158529110253
Epoch:  60  	Training Loss: 0.00018438877305015922
Test Loss:  0.0001965180563274771
Valid Loss:  0.00031401473097503185
Epoch:  61  	Training Loss: 0.00018238049233332276
Test Loss:  0.00019505237287376076
Valid Loss:  0.00031199678778648376
Epoch:  62  	Training Loss: 0.00018049051868729293
Test Loss:  0.00019303479348309338
Valid Loss:  0.0003055293927900493
Epoch:  63  	Training Loss: 0.00017764620133675635
Test Loss:  0.00019164348486810923
Valid Loss:  0.000300062820315361
Epoch:  64  	Training Loss: 0.00017525054863654077
Test Loss:  0.0001904474338516593
Valid Loss:  0.0002954630763269961
Epoch:  65  	Training Loss: 0.0001731818774715066
Test Loss:  0.00018948651268146932
Valid Loss:  0.0002915117656812072
Epoch:  66  	Training Loss: 0.00017135011148639023
Test Loss:  0.0001886042155092582
Valid Loss:  0.0002880961983464658
Epoch:  67  	Training Loss: 0.00016970123397186399
Test Loss:  0.00018775135686155409
Valid Loss:  0.00028510167612694204
Epoch:  68  	Training Loss: 0.00016816906281746924
Test Loss:  0.0001870330306701362
Valid Loss:  0.00028243439737707376
 14%|█▍        | 69/500 [00:55<02:31,  2.84it/s] 14%|█▍        | 71/500 [01:01<08:40,  1.21s/it] 15%|█▍        | 73/500 [01:01<06:11,  1.15it/s] 15%|█▌        | 75/500 [01:01<04:27,  1.59it/s] 15%|█▌        | 77/500 [01:02<03:14,  2.17it/s] 16%|█▌        | 79/500 [01:02<02:23,  2.93it/s] 16%|█▌        | 81/500 [01:08<08:25,  1.21s/it] 17%|█▋        | 83/500 [01:08<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:08<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:09<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:09<02:19,  2.94it/s] 18%|█▊        | 91/500 [01:15<08:08,  1.19s/it] 19%|█▊        | 93/500 [01:15<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:15<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:15<03:02,  2.20it/s] 20%|█▉        | 99/500 [01:16<02:15,  2.96it/s] 20%|██        | 101/500 [01:22<08:04,  1.21s/it] 21%|██        | 103/500 [01:22<05:47,  1.14it/s] 21%|██        | 105/500 [01:22<04:12,  1.57it/s] 21%|██▏       | 107/500 [01:23<03:05,  2.11it/s] 22%|██▏       | 109/500 [01:23<02:19,  2.80it/s] 22%|██▏       | 111/500 [01:29<07:51,  1.21s/it] 23%|██▎       | 113/500 [01:29<05:37,  1.15it/s] 23%|██▎       | 115/500 [01:30<04:02,  1.59it/s] 23%|██▎       | 117/500 [01:30<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:30<02:10,  2.93it/s] 24%|██▍       | 121/500 [01:36<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:36<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:36<03:53,  1.60it/s] 25%|██▌       | 127/500 [01:37<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:37<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:43<07:23,  1.20s/it] 27%|██▋       | 133/500 [01:43<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:43<03:47,  1.61it/s]Epoch:  69  	Training Loss: 0.0001667479082243517
Test Loss:  0.00018629446276463568
Valid Loss:  0.0002800730289891362
Epoch:  70  	Training Loss: 0.00016541770310141146
Test Loss:  0.00018565222853794694
Valid Loss:  0.00027793459594249725
Epoch:  71  	Training Loss: 0.00016414934361819178
Test Loss:  0.00018502603052183986
Valid Loss:  0.000276004197075963
Epoch:  72  	Training Loss: 0.00016296400281134993
Test Loss:  0.0001827616652008146
Valid Loss:  0.00027302998933009803
Epoch:  73  	Training Loss: 0.00015965921920724213
Test Loss:  0.0001803436316549778
Valid Loss:  0.0002704290091060102
Epoch:  74  	Training Loss: 0.0001567094004712999
Test Loss:  0.00017817340267356485
Valid Loss:  0.00026793035794980824
Epoch:  75  	Training Loss: 0.00015402643475681543
Test Loss:  0.00017620943253859878
Valid Loss:  0.0002654998388607055
Epoch:  76  	Training Loss: 0.00015147912199608982
Test Loss:  0.00017435173504054546
Valid Loss:  0.0002631657989695668
Epoch:  77  	Training Loss: 0.000149085812154226
Test Loss:  0.00017249936354346573
Valid Loss:  0.0002609598741400987
Epoch:  78  	Training Loss: 0.0001468840055167675
Test Loss:  0.00017077018856070936
Valid Loss:  0.0002588266506791115
Epoch:  79  	Training Loss: 0.00014483174891211092
Test Loss:  0.00016917411994654685
Valid Loss:  0.0002567719202488661
Epoch:  80  	Training Loss: 0.00014293927233666182
Test Loss:  0.00016771780792623758
Valid Loss:  0.00025479422765783966
Epoch:  81  	Training Loss: 0.0001411966950399801
Test Loss:  0.00016635263455100358
Valid Loss:  0.00025285276933573186
Epoch:  82  	Training Loss: 0.00013956734619569033
Test Loss:  0.0001654533261898905
Valid Loss:  0.00025081803323701024
Epoch:  83  	Training Loss: 0.00013865188520867378
Test Loss:  0.00016490792040713131
Valid Loss:  0.00024886149913072586
Epoch:  84  	Training Loss: 0.00013781350571662188
Test Loss:  0.00016427178343292326
Valid Loss:  0.0002471362822689116
Epoch:  85  	Training Loss: 0.00013703030708711594
Test Loss:  0.00016364280600100756
Valid Loss:  0.0002455541689414531
Epoch:  86  	Training Loss: 0.00013628986198455095
Test Loss:  0.00016298831906169653
Valid Loss:  0.0002441021497361362
Epoch:  87  	Training Loss: 0.00013558517093770206
Test Loss:  0.00016235401562880725
Valid Loss:  0.00024273742747027427
Epoch:  88  	Training Loss: 0.0001349130179733038
Test Loss:  0.0001617414236534387
Valid Loss:  0.00024145205679815263
Epoch:  89  	Training Loss: 0.00013426494842860848
Test Loss:  0.00016112017328850925
Valid Loss:  0.00024024565936997533
Epoch:  90  	Training Loss: 0.00013363406469579786
Test Loss:  0.00016053956642281264
Valid Loss:  0.0002390699228271842
Epoch:  91  	Training Loss: 0.00013301827129907906
Test Loss:  0.00015984932542778552
Valid Loss:  0.00023799964401405305
Epoch:  92  	Training Loss: 0.00013241908163763583
Test Loss:  0.00015852428623475134
Valid Loss:  0.00023787913960404694
Epoch:  93  	Training Loss: 0.00013210062752477825
Test Loss:  0.00015802314737811685
Valid Loss:  0.00023767298262100667
Epoch:  94  	Training Loss: 0.0001318313297815621
Test Loss:  0.00015734830230940133
Valid Loss:  0.00023749712272547185
Epoch:  95  	Training Loss: 0.00013159435184206814
Test Loss:  0.00015684202662669122
Valid Loss:  0.00023729994427412748
Epoch:  96  	Training Loss: 0.0001313810353167355
Test Loss:  0.0001563677506055683
Valid Loss:  0.0002371008595218882
Epoch:  97  	Training Loss: 0.0001311770611209795
Test Loss:  0.00015591905685141683
Valid Loss:  0.0002368989516980946
Epoch:  98  	Training Loss: 0.00013098213821649551
Test Loss:  0.00015551154501736164
Valid Loss:  0.00023668771609663963
Epoch:  99  	Training Loss: 0.00013079086784273386
Test Loss:  0.00015511910896748304
Valid Loss:  0.00023647313355468214
Epoch:  100  	Training Loss: 0.0001306070771533996
Test Loss:  0.00015474448446184397
Valid Loss:  0.0002362542727496475
Epoch:  101  	Training Loss: 0.0001304314937442541
Test Loss:  0.00015443858865182847
Valid Loss:  0.00023602123837918043
Epoch:  102  	Training Loss: 0.0001302614255109802
Test Loss:  0.0001535719638923183
Valid Loss:  0.00023332897399086505
Epoch:  103  	Training Loss: 0.00012812584463972598
Test Loss:  0.00015197438187897205
Valid Loss:  0.00023104343563318253
Epoch:  104  	Training Loss: 0.00012618597247637808
Test Loss:  0.00014984712470322847
Valid Loss:  0.00022810394875705242
Epoch:  105  	Training Loss: 0.00012390423216857016
Test Loss:  0.00014680266031064093
Valid Loss:  0.00022358039859682322
Epoch:  106  	Training Loss: 0.00012084859918104485
Test Loss:  0.00014233333058655262
Valid Loss:  0.00021697358170058578
Epoch:  107  	Training Loss: 0.00011685906065395102
Test Loss:  0.0001405601215083152
Valid Loss:  0.00021453907538671046
Epoch:  108  	Training Loss: 0.00011523721332196146
Test Loss:  0.00013957751798443496
Valid Loss:  0.00021380030375439674
Epoch:  109  	Training Loss: 0.00011440680827945471
Test Loss:  0.00013869049143977463
Valid Loss:  0.0002130750654032454
Epoch:  110  	Training Loss: 0.00011366391845513135
Test Loss:  0.00013789627701044083
Valid Loss:  0.00021235753956716508
Epoch:  111  	Training Loss: 0.00011299051402602345
Test Loss:  0.00013717470574192703
Valid Loss:  0.00021164517966099083
Epoch:  112  	Training Loss: 0.00011237070430070162
Test Loss:  0.00013658657553605735
Valid Loss:  0.00021029234630987048
Epoch:  113  	Training Loss: 0.00011157279368489981
Test Loss:  0.000135915499413386
Valid Loss:  0.00020902979304082692
Epoch:  114  	Training Loss: 0.00011081460979767144
Test Loss:  0.00013527015107683837
Valid Loss:  0.00020781627972610295
Epoch:  115  	Training Loss: 0.00011008851288352162
Test Loss:  0.00013461598427966237
Valid Loss:  0.00020665318879764527
Epoch:  116  	Training Loss: 0.00010939285857602954
Test Loss:  0.00013396823487710208
Valid Loss:  0.00020553116337396204
Epoch:  117  	Training Loss: 0.00010872518760152161
Test Loss:  0.00013328599743545055
Valid Loss:  0.00020444685651455075
Epoch:  118  	Training Loss: 0.00010808202205225825
Test Loss:  0.0001326083583990112
Valid Loss:  0.00020339498587418348
Epoch:  119  	Training Loss: 0.00010745938925538212
Test Loss:  0.0001319285947829485
Valid Loss:  0.000202372859348543
Epoch:  120  	Training Loss: 0.00010685132292564958
Test Loss:  0.00013124963152222335
Valid Loss:  0.00020137614046689123
Epoch:  121  	Training Loss: 0.00010625965660437942
Test Loss:  0.0001305699988733977
Valid Loss:  0.00020040199160575867
Epoch:  122  	Training Loss: 0.00010567716526566073
Test Loss:  0.00013017737364862114
Valid Loss:  0.0001995351631194353
Epoch:  123  	Training Loss: 0.00010520122305024415
Test Loss:  0.0001296436821576208
Valid Loss:  0.0001987185241887346
Epoch:  124  	Training Loss: 0.00010474247392266989
Test Loss:  0.00012911688827443868
Valid Loss:  0.00019792135572060943
Epoch:  125  	Training Loss: 0.00010429037502035499
Test Loss:  0.00012857685214839876
Valid Loss:  0.0001971427263924852
Epoch:  126  	Training Loss: 0.00010383112385170534
Test Loss:  0.0001280200231121853
Valid Loss:  0.00019637850346043706
Epoch:  127  	Training Loss: 0.00010336666309740394
Test Loss:  0.00012745299318339676
Valid Loss:  0.00019562640227377415
Epoch:  128  	Training Loss: 0.00010290276986779645
Test Loss:  0.0001268896012334153
Valid Loss:  0.0001948838180396706
Epoch:  129  	Training Loss: 0.00010244807344861329
Test Loss:  0.000126325263408944
Valid Loss:  0.00019414897542446852
Epoch:  130  	Training Loss: 0.0001020019844872877
Test Loss:  0.0001257542462553829
Valid Loss:  0.00019342433370184153
Epoch:  131  	Training Loss: 0.00010156328789889812
Test Loss:  0.0001251880166819319
Valid Loss:  0.00019270789925940335
Epoch:  132  	Training Loss: 0.00010113204916706309
Test Loss:  0.0001250073837582022
Valid Loss:  0.0001923664240166545
Epoch:  133  	Training Loss: 0.0001009641564451158
Test Loss:  0.00012482271995395422
Valid Loss:  0.00019203353440389037
Epoch:  134  	Training Loss: 0.00010079838830279186
Test Loss:  0.0001246331084985286
Valid Loss:  0.00019170594168826938
Epoch:  135  	Training Loss: 0.00010063473018817604
Test Loss:  0.0001244395098183304
Valid Loss:  0.0001913853920996189
 27%|██▋       | 137/500 [01:44<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:44<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:50<07:16,  1.22s/it] 29%|██▊       | 143/500 [01:50<05:11,  1.15it/s] 29%|██▉       | 145/500 [01:50<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:51<02:43,  2.16it/s] 30%|██▉       | 149/500 [01:51<02:02,  2.85it/s] 30%|███       | 151/500 [01:57<07:03,  1.21s/it] 31%|███       | 153/500 [01:57<05:02,  1.15it/s] 31%|███       | 155/500 [01:58<03:37,  1.58it/s] 31%|███▏      | 157/500 [01:58<02:38,  2.16it/s] 32%|███▏      | 159/500 [01:58<01:57,  2.91it/s] 32%|███▏      | 161/500 [02:04<06:41,  1.18s/it] 33%|███▎      | 163/500 [02:04<04:46,  1.18it/s] 33%|███▎      | 165/500 [02:04<03:27,  1.62it/s] 33%|███▎      | 167/500 [02:05<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:05<01:52,  2.93it/s] 34%|███▍      | 171/500 [02:11<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:11<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:11<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:12<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:12<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:18<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:18<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:18<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:18<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:19<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:25<06:14,  1.21s/it] 39%|███▊      | 193/500 [02:25<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:25<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:25<02:19,  2.18it/s] 40%|███▉      | 199/500 [02:26<01:42,  2.93it/s] 40%|████      | 201/500 [02:32<05:54,  1.19s/it]Epoch:  136  	Training Loss: 0.00010047266550827771
Test Loss:  0.0001242415455635637
Valid Loss:  0.0001910704595502466
Epoch:  137  	Training Loss: 0.0001003122451948002
Test Loss:  0.00012404088920447975
Valid Loss:  0.0001907608238980174
Epoch:  138  	Training Loss: 0.00010015323641709983
Test Loss:  0.00012383671128191054
Valid Loss:  0.00019045680528506637
Epoch:  139  	Training Loss: 9.999572648666799e-05
Test Loss:  0.00012363004498183727
Valid Loss:  0.00019015619182027876
Epoch:  140  	Training Loss: 9.983926429413259e-05
Test Loss:  0.00012342043919488788
Valid Loss:  0.0001898602640721947
Epoch:  141  	Training Loss: 9.968436643248424e-05
Test Loss:  0.00012320905807428062
Valid Loss:  0.00018956768326461315
Epoch:  142  	Training Loss: 9.95304508251138e-05
Test Loss:  0.00012248448911122978
Valid Loss:  0.00018932789680548012
Epoch:  143  	Training Loss: 9.931476961355656e-05
Test Loss:  0.0001219108744408004
Valid Loss:  0.00018913755775429308
Epoch:  144  	Training Loss: 9.912410314427689e-05
Test Loss:  0.00012137957673985511
Valid Loss:  0.00018896034453064203
Epoch:  145  	Training Loss: 9.894945105770603e-05
Test Loss:  0.00012089145457139239
Valid Loss:  0.00018879433628171682
Epoch:  146  	Training Loss: 9.878726268652827e-05
Test Loss:  0.00012043986498611048
Valid Loss:  0.0001886372920125723
Epoch:  147  	Training Loss: 9.863630111794919e-05
Test Loss:  0.00012002130097243935
Valid Loss:  0.00018848752370104194
Epoch:  148  	Training Loss: 9.849401249084622e-05
Test Loss:  0.00011963141150772572
Valid Loss:  0.00018834380898624659
Epoch:  149  	Training Loss: 9.835961100179702e-05
Test Loss:  0.00011926540173590183
Valid Loss:  0.00018820434343069792
Epoch:  150  	Training Loss: 9.82322744675912e-05
Test Loss:  0.00011892276961589232
Valid Loss:  0.00018806848675012589
Epoch:  151  	Training Loss: 9.8110489489045e-05
Test Loss:  0.00011860006634378806
Valid Loss:  0.00018793600611388683
Epoch:  152  	Training Loss: 9.799380495678633e-05
Test Loss:  0.00011817496124422178
Valid Loss:  0.0001873404544312507
Epoch:  153  	Training Loss: 9.768526797415689e-05
Test Loss:  0.00011776233441196382
Valid Loss:  0.00018675530736800283
Epoch:  154  	Training Loss: 9.738023800309747e-05
Test Loss:  0.00011734214785974473
Valid Loss:  0.00018617950263433158
Epoch:  155  	Training Loss: 9.707964636618271e-05
Test Loss:  0.00011692775296978652
Valid Loss:  0.00018561356409918517
Epoch:  156  	Training Loss: 9.678499918663874e-05
Test Loss:  0.0001165170397143811
Valid Loss:  0.00018505507614463568
Epoch:  157  	Training Loss: 9.649455023463815e-05
Test Loss:  0.00011611045920290053
Valid Loss:  0.00018450446077622473
Epoch:  158  	Training Loss: 9.620898345019668e-05
Test Loss:  0.00011570797505555674
Valid Loss:  0.00018396193627268076
Epoch:  159  	Training Loss: 9.592666174285114e-05
Test Loss:  0.00011530860501807183
Valid Loss:  0.00018342655675951391
Epoch:  160  	Training Loss: 9.564786887494847e-05
Test Loss:  0.00011491165787447244
Valid Loss:  0.00018289728905074298
Epoch:  161  	Training Loss: 9.53712296904996e-05
Test Loss:  0.00011451631144154817
Valid Loss:  0.00018237688345834613
Epoch:  162  	Training Loss: 9.509768278803676e-05
Test Loss:  0.00011418679787311703
Valid Loss:  0.00018221919890493155
Epoch:  163  	Training Loss: 9.485935152042657e-05
Test Loss:  0.0001138631341746077
Valid Loss:  0.00018206467211712152
Epoch:  164  	Training Loss: 9.464462345931679e-05
Test Loss:  0.00011354486923664808
Valid Loss:  0.0001819117460399866
Epoch:  165  	Training Loss: 9.443524322705343e-05
Test Loss:  0.00011324266233714297
Valid Loss:  0.00018175924196839333
Epoch:  166  	Training Loss: 9.42362385103479e-05
Test Loss:  0.00011295120202703401
Valid Loss:  0.00018160826584789902
Epoch:  167  	Training Loss: 9.404405136592686e-05
Test Loss:  0.00011267497029621154
Valid Loss:  0.00018145539797842503
Epoch:  168  	Training Loss: 9.386433521285653e-05
Test Loss:  0.00011241542233619839
Valid Loss:  0.0001813015842344612
Epoch:  169  	Training Loss: 9.36930809984915e-05
Test Loss:  0.00011216467100894079
Valid Loss:  0.00018114788690581918
Epoch:  170  	Training Loss: 9.352124470751733e-05
Test Loss:  0.00011190641816938296
Valid Loss:  0.00018099480075761676
Epoch:  171  	Training Loss: 9.33487099246122e-05
Test Loss:  0.0001116536877816543
Valid Loss:  0.0001808383094612509
Epoch:  172  	Training Loss: 9.318054799223319e-05
Test Loss:  0.00011172299855388701
Valid Loss:  0.0001795418793335557
Epoch:  173  	Training Loss: 9.272016905015334e-05
Test Loss:  0.00011174532119184732
Valid Loss:  0.00017855738406069577
Epoch:  174  	Training Loss: 9.236850019078702e-05
Test Loss:  0.00011172958329552785
Valid Loss:  0.00017775007290765643
Epoch:  175  	Training Loss: 9.207647235598415e-05
Test Loss:  0.00011168781929882243
Valid Loss:  0.00017706086509861052
Epoch:  176  	Training Loss: 9.182457142742351e-05
Test Loss:  0.00011162838927702978
Valid Loss:  0.00017645544721744955
Epoch:  177  	Training Loss: 9.1601672465913e-05
Test Loss:  0.00011155402171425521
Valid Loss:  0.00017591522191651165
Epoch:  178  	Training Loss: 9.140063775703311e-05
Test Loss:  0.00011146660835947841
Valid Loss:  0.00017542587011121213
Epoch:  179  	Training Loss: 9.121546463575214e-05
Test Loss:  0.00011136712419101968
Valid Loss:  0.00017497691442258656
Epoch:  180  	Training Loss: 9.104234050028026e-05
Test Loss:  0.00011125698802061379
Valid Loss:  0.00017456072964705527
Epoch:  181  	Training Loss: 9.087832586374134e-05
Test Loss:  0.00011113678920082748
Valid Loss:  0.0001741713349474594
Epoch:  182  	Training Loss: 9.072129614651203e-05
Test Loss:  0.0001100774243241176
Valid Loss:  0.00017371735884808004
Epoch:  183  	Training Loss: 9.02256288100034e-05
Test Loss:  0.00010939426283584908
Valid Loss:  0.00017330153787042946
Epoch:  184  	Training Loss: 8.978180994745344e-05
Test Loss:  0.00010873503924813122
Valid Loss:  0.0001728394563542679
Epoch:  185  	Training Loss: 8.93667311174795e-05
Test Loss:  0.00010812879918375984
Valid Loss:  0.00017237194697372615
Epoch:  186  	Training Loss: 8.897370571503416e-05
Test Loss:  0.00010756163101177663
Valid Loss:  0.0001718994608381763
Epoch:  187  	Training Loss: 8.859761874191463e-05
Test Loss:  0.00010701944847824052
Valid Loss:  0.00017142153228633106
Epoch:  188  	Training Loss: 8.822075324133039e-05
Test Loss:  0.00010649653268046677
Valid Loss:  0.00017093789938371629
Epoch:  189  	Training Loss: 8.785696263657883e-05
Test Loss:  0.00010599970846669748
Valid Loss:  0.00017044940614141524
Epoch:  190  	Training Loss: 8.750364213483408e-05
Test Loss:  0.00010552298772381619
Valid Loss:  0.000169958861079067
Epoch:  191  	Training Loss: 8.715960575500503e-05
Test Loss:  0.0001050646387739107
Valid Loss:  0.0001694652164587751
Epoch:  192  	Training Loss: 8.682273619342595e-05
Test Loss:  0.00010491523426026106
Valid Loss:  0.0001688951742835343
Epoch:  193  	Training Loss: 8.654632256366313e-05
Test Loss:  0.00010464656224939972
Valid Loss:  0.00016838041483424604
Epoch:  194  	Training Loss: 8.629384683445096e-05
Test Loss:  0.00010436532465973869
Valid Loss:  0.00016788255015853792
Epoch:  195  	Training Loss: 8.604611502960324e-05
Test Loss:  0.00010407834633952007
Valid Loss:  0.0001674008963163942
Epoch:  196  	Training Loss: 8.580350549891591e-05
Test Loss:  0.00010378628940088674
Valid Loss:  0.00016693100042175502
Epoch:  197  	Training Loss: 8.556534885428846e-05
Test Loss:  0.00010348948126193136
Valid Loss:  0.0001664727897150442
Epoch:  198  	Training Loss: 8.53314995765686e-05
Test Loss:  0.00010318930435460061
Valid Loss:  0.00016602514369878918
Epoch:  199  	Training Loss: 8.510187035426497e-05
Test Loss:  0.0001028882252285257
Valid Loss:  0.00016558667994104326
Epoch:  200  	Training Loss: 8.4875246102456e-05
Test Loss:  0.00010258594556944445
Valid Loss:  0.0001651568163651973
Epoch:  201  	Training Loss: 8.465209975838661e-05
Test Loss:  0.00010228349856333807
Valid Loss:  0.00016473379218950868
Epoch:  202  	Training Loss: 8.443182741757482e-05
Test Loss:  0.00010169846063945442
Valid Loss:  0.00016433434211649
Epoch:  203  	Training Loss: 8.407320274272934e-05
 41%|████      | 203/500 [02:32<04:12,  1.17it/s] 41%|████      | 205/500 [02:32<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:32<02:12,  2.22it/s] 42%|████▏     | 209/500 [02:32<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:39<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:39<04:09,  1.15it/s] 43%|████▎     | 215/500 [02:39<02:58,  1.59it/s] 43%|████▎     | 217/500 [02:39<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:39<01:35,  2.93it/s] 44%|████▍     | 221/500 [02:46<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:46<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:46<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:46<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:46<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:53<05:27,  1.22s/it] 47%|████▋     | 233/500 [02:53<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:53<02:47,  1.59it/s] 47%|████▋     | 237/500 [02:53<02:01,  2.17it/s] 48%|████▊     | 239/500 [02:54<01:29,  2.92it/s] 48%|████▊     | 241/500 [03:00<05:13,  1.21s/it] 49%|████▊     | 243/500 [03:00<03:43,  1.15it/s] 49%|████▉     | 245/500 [03:00<02:40,  1.59it/s] 49%|████▉     | 247/500 [03:00<01:56,  2.18it/s] 50%|████▉     | 249/500 [03:01<01:25,  2.93it/s] 50%|█████     | 251/500 [03:07<04:57,  1.19s/it] 51%|█████     | 253/500 [03:07<03:31,  1.17it/s] 51%|█████     | 255/500 [03:07<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:07<01:49,  2.21it/s] 52%|█████▏    | 259/500 [03:07<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:14<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:14<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:14<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:14<01:46,  2.20it/s] 54%|█████▍    | 269/500 [03:14<01:19,  2.89it/s]Test Loss:  0.00010115465556737036
Valid Loss:  0.00016392223187722266
Epoch:  204  	Training Loss: 8.37329716887325e-05
Test Loss:  0.00010065175592899323
Valid Loss:  0.0001634838990867138
Epoch:  205  	Training Loss: 8.340117346961051e-05
Test Loss:  0.00010017227759817615
Valid Loss:  0.00016303040320053697
Epoch:  206  	Training Loss: 8.307304233312607e-05
Test Loss:  9.971408871933818e-05
Valid Loss:  0.00016256952949333936
Epoch:  207  	Training Loss: 8.275260915979743e-05
Test Loss:  9.927003702614456e-05
Valid Loss:  0.0001621019036974758
Epoch:  208  	Training Loss: 8.24367452878505e-05
Test Loss:  9.882202721200883e-05
Valid Loss:  0.0001616282679606229
Epoch:  209  	Training Loss: 8.212606189772487e-05
Test Loss:  9.838701953412965e-05
Valid Loss:  0.00016115009202621877
Epoch:  210  	Training Loss: 8.18196203908883e-05
Test Loss:  9.79616743279621e-05
Valid Loss:  0.00016066947137005627
Epoch:  211  	Training Loss: 8.151415386237204e-05
Test Loss:  9.753798804013059e-05
Valid Loss:  0.0001601879921508953
Epoch:  212  	Training Loss: 8.120713755488396e-05
Test Loss:  9.70869732555002e-05
Valid Loss:  0.0001599924871698022
Epoch:  213  	Training Loss: 8.106842869892716e-05
Test Loss:  9.695551125332713e-05
Valid Loss:  0.00015984001220203936
Epoch:  214  	Training Loss: 8.099504339043051e-05
Test Loss:  9.687929559731856e-05
Valid Loss:  0.00015968923980835825
Epoch:  215  	Training Loss: 8.092467760434374e-05
Test Loss:  9.681013762019575e-05
Valid Loss:  0.0001595377834746614
Epoch:  216  	Training Loss: 8.085249282885343e-05
Test Loss:  9.673988097347319e-05
Valid Loss:  0.00015938669093884528
Epoch:  217  	Training Loss: 8.077982056420296e-05
Test Loss:  9.666854748502374e-05
Valid Loss:  0.0001592349144630134
Epoch:  218  	Training Loss: 8.07070973678492e-05
Test Loss:  9.659545321483165e-05
Valid Loss:  0.0001590810134075582
Epoch:  219  	Training Loss: 8.063011046033353e-05
Test Loss:  9.651845903135836e-05
Valid Loss:  0.0001589283492648974
Epoch:  220  	Training Loss: 8.055223588598892e-05
Test Loss:  9.643971134210005e-05
Valid Loss:  0.00015877699479460716
Epoch:  221  	Training Loss: 8.047366281971335e-05
Test Loss:  9.636036702431738e-05
Valid Loss:  0.00015862408326938748
Epoch:  222  	Training Loss: 8.039439853746444e-05
Test Loss:  9.61741607170552e-05
Valid Loss:  0.00015800984692759812
Epoch:  223  	Training Loss: 7.998307410161942e-05
Test Loss:  9.585822408553213e-05
Valid Loss:  0.00015753982006572187
Epoch:  224  	Training Loss: 7.971574814291671e-05
Test Loss:  9.56042786128819e-05
Valid Loss:  0.0001570731692481786
Epoch:  225  	Training Loss: 7.945921242935583e-05
Test Loss:  9.533514094073325e-05
Valid Loss:  0.00015662219084333628
Epoch:  226  	Training Loss: 7.92069622548297e-05
Test Loss:  9.506251808488742e-05
Valid Loss:  0.00015618391626048833
Epoch:  227  	Training Loss: 7.895820453995839e-05
Test Loss:  9.478653373662382e-05
Valid Loss:  0.00015574719873256981
Epoch:  228  	Training Loss: 7.871260459069163e-05
Test Loss:  9.450723882764578e-05
Valid Loss:  0.00015531503595411777
Epoch:  229  	Training Loss: 7.847027154639363e-05
Test Loss:  9.422642324352637e-05
Valid Loss:  0.00015488963981624693
Epoch:  230  	Training Loss: 7.823020860087126e-05
Test Loss:  9.39446035772562e-05
Valid Loss:  0.00015447007899638265
Epoch:  231  	Training Loss: 7.79930705903098e-05
Test Loss:  9.366206359118223e-05
Valid Loss:  0.00015405626618303359
Epoch:  232  	Training Loss: 7.775803533149883e-05
Test Loss:  9.287464490626007e-05
Valid Loss:  0.00015355885261669755
Epoch:  233  	Training Loss: 7.74442232795991e-05
Test Loss:  9.256473276764154e-05
Valid Loss:  0.00015308907313738018
Epoch:  234  	Training Loss: 7.716749678365886e-05
Test Loss:  9.210073039866984e-05
Valid Loss:  0.00015262802480719984
Epoch:  235  	Training Loss: 7.690141501370817e-05
Test Loss:  9.172040154226124e-05
Valid Loss:  0.00015216825704555959
Epoch:  236  	Training Loss: 7.664043369004503e-05
Test Loss:  9.132181003224105e-05
Valid Loss:  0.00015171189443208277
Epoch:  237  	Training Loss: 7.638442912138999e-05
Test Loss:  9.09487425815314e-05
Valid Loss:  0.00015125761274248362
Epoch:  238  	Training Loss: 7.613474735990167e-05
Test Loss:  9.0586363512557e-05
Valid Loss:  0.00015080688172020018
Epoch:  239  	Training Loss: 7.588830339955166e-05
Test Loss:  9.022800077218562e-05
Valid Loss:  0.00015036702097859234
Epoch:  240  	Training Loss: 7.564479165012017e-05
Test Loss:  8.988019544631243e-05
Valid Loss:  0.00014993446529842913
Epoch:  241  	Training Loss: 7.540860679000616e-05
Test Loss:  8.95508419489488e-05
Valid Loss:  0.00014950391778256744
Epoch:  242  	Training Loss: 7.517472840845585e-05
Test Loss:  8.9296605437994e-05
Valid Loss:  0.00014918319357093424
Epoch:  243  	Training Loss: 7.4950628913939e-05
Test Loss:  8.898502710508183e-05
Valid Loss:  0.0001488803536631167
Epoch:  244  	Training Loss: 7.474664016626775e-05
Test Loss:  8.868016448104754e-05
Valid Loss:  0.00014857428323011845
Epoch:  245  	Training Loss: 7.454020669683814e-05
Test Loss:  8.838318171910942e-05
Valid Loss:  0.000148266670294106
Epoch:  246  	Training Loss: 7.43380660424009e-05
Test Loss:  8.809537393972278e-05
Valid Loss:  0.00014795635070186108
Epoch:  247  	Training Loss: 7.413866114802659e-05
Test Loss:  8.781524957157671e-05
Valid Loss:  0.00014764469233341515
Epoch:  248  	Training Loss: 7.394223212031648e-05
Test Loss:  8.754193549975753e-05
Valid Loss:  0.00014732874114997685
Epoch:  249  	Training Loss: 7.374832784989849e-05
Test Loss:  8.727448584977537e-05
Valid Loss:  0.00014700359315611422
Epoch:  250  	Training Loss: 7.355646812357008e-05
Test Loss:  8.70124640641734e-05
Valid Loss:  0.0001466782996430993
Epoch:  251  	Training Loss: 7.336193812079728e-05
Test Loss:  8.674823038745672e-05
Valid Loss:  0.00014635114348493516
Epoch:  252  	Training Loss: 7.316296978387982e-05
Test Loss:  8.669283124618232e-05
Valid Loss:  0.00014607423509005457
Epoch:  253  	Training Loss: 7.302925951080397e-05
Test Loss:  8.662649634061381e-05
Valid Loss:  0.00014582302537746727
Epoch:  254  	Training Loss: 7.290542998816818e-05
Test Loss:  8.655342389829457e-05
Valid Loss:  0.0001455876335967332
Epoch:  255  	Training Loss: 7.27878650650382e-05
Test Loss:  8.64749526954256e-05
Valid Loss:  0.000145361089380458
Epoch:  256  	Training Loss: 7.267362525453791e-05
Test Loss:  8.63926688907668e-05
Valid Loss:  0.00014514235954266042
Epoch:  257  	Training Loss: 7.256184471771121e-05
Test Loss:  8.630829688627273e-05
Valid Loss:  0.00014492942136712372
Epoch:  258  	Training Loss: 7.2452261520084e-05
Test Loss:  8.622182940598577e-05
Valid Loss:  0.00014472269685938954
Epoch:  259  	Training Loss: 7.234470103867352e-05
Test Loss:  8.613354293629527e-05
Valid Loss:  0.0001445200468879193
Epoch:  260  	Training Loss: 7.223889406304806e-05
Test Loss:  8.604472532169893e-05
Valid Loss:  0.00014432119496632367
Epoch:  261  	Training Loss: 7.213473145384341e-05
Test Loss:  8.595450344728306e-05
Valid Loss:  0.00014412650489248335
Epoch:  262  	Training Loss: 7.203200948424637e-05
Test Loss:  8.50934156915173e-05
Valid Loss:  0.00014373949670698494
Epoch:  263  	Training Loss: 7.175824430305511e-05
Test Loss:  8.486052684020251e-05
Valid Loss:  0.0001434427686035633
Epoch:  264  	Training Loss: 7.151950558181852e-05
Test Loss:  8.431999594904482e-05
Valid Loss:  0.00014312731218524277
Epoch:  265  	Training Loss: 7.130060839699581e-05
Test Loss:  8.402734238188714e-05
Valid Loss:  0.00014283027849160135
Epoch:  266  	Training Loss: 7.109445868991315e-05
Test Loss:  8.362688822671771e-05
Valid Loss:  0.000142534205224365
Epoch:  267  	Training Loss: 7.089679274940863e-05
Test Loss:  8.33309895824641e-05
Valid Loss:  0.0001422401110175997
Epoch:  268  	Training Loss: 7.070657738950104e-05
Test Loss:  8.300103945657611e-05
Valid Loss:  0.00014194824325386435
Epoch:  269  	Training Loss: 7.052163709886372e-05
Test Loss:  8.271947444882244e-05
Valid Loss:  0.00014165615721140057
Epoch:  270  	Training Loss: 7.03416662872769e-05
Test Loss:  8.24311573524028e-05
Valid Loss:  0.00014136667596176267
Epoch:  271  	Training Loss: 7.01660756021738e-05
Test Loss:   54%|█████▍    | 271/500 [03:21<04:37,  1.21s/it] 55%|█████▍    | 273/500 [03:21<03:18,  1.15it/s] 55%|█████▌    | 275/500 [03:21<02:23,  1.57it/s] 55%|█████▌    | 277/500 [03:21<01:45,  2.12it/s] 56%|█████▌    | 279/500 [03:21<01:18,  2.81it/s] 56%|█████▌    | 281/500 [03:28<04:26,  1.22s/it] 57%|█████▋    | 283/500 [03:28<03:09,  1.14it/s] 57%|█████▋    | 285/500 [03:28<02:16,  1.58it/s] 57%|█████▋    | 287/500 [03:28<01:39,  2.15it/s] 58%|█████▊    | 289/500 [03:29<01:15,  2.79it/s] 58%|█████▊    | 291/500 [03:35<04:14,  1.22s/it] 59%|█████▊    | 293/500 [03:35<03:01,  1.14it/s] 59%|█████▉    | 295/500 [03:35<02:10,  1.57it/s] 59%|█████▉    | 297/500 [03:36<01:36,  2.11it/s] 60%|█████▉    | 299/500 [03:36<01:10,  2.85it/s] 60%|██████    | 301/500 [03:42<03:57,  1.19s/it] 61%|██████    | 303/500 [03:42<02:48,  1.17it/s] 61%|██████    | 305/500 [03:42<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:42<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:43<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:49<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:49<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:49<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:49<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:49<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:56<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:56<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:56<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:56<01:17,  2.22it/s] 66%|██████▌   | 329/500 [03:56<00:58,  2.93it/s] 66%|██████▌   | 331/500 [04:03<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:03<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:03<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:03<01:14,  2.19it/s]8.216848073061556e-05
Valid Loss:  0.00014107642346061766
Epoch:  272  	Training Loss: 6.999393372097984e-05
Test Loss:  8.19932174636051e-05
Valid Loss:  0.0001401594781782478
Epoch:  273  	Training Loss: 6.962397310417145e-05
Test Loss:  8.163278107531369e-05
Valid Loss:  0.00013941811630502343
Epoch:  274  	Training Loss: 6.92910689394921e-05
Test Loss:  8.138822158798575e-05
Valid Loss:  0.0001387101219734177
Epoch:  275  	Training Loss: 6.898114224895835e-05
Test Loss:  8.102397987386212e-05
Valid Loss:  0.00013807901996187866
Epoch:  276  	Training Loss: 6.86862476868555e-05
Test Loss:  8.072535274550319e-05
Valid Loss:  0.00013746967306360602
Epoch:  277  	Training Loss: 6.840158312115818e-05
Test Loss:  8.035834616748616e-05
Valid Loss:  0.0001368992670904845
Epoch:  278  	Training Loss: 6.812479841755703e-05
Test Loss:  8.003029506653547e-05
Valid Loss:  0.00013634352944791317
Epoch:  279  	Training Loss: 6.785491132177413e-05
Test Loss:  7.967172132339329e-05
Valid Loss:  0.00013584278349298984
Epoch:  280  	Training Loss: 6.759747338946909e-05
Test Loss:  7.930565334390849e-05
Valid Loss:  0.00013540376676246524
Epoch:  281  	Training Loss: 6.735725764883682e-05
Test Loss:  7.898146577645093e-05
Valid Loss:  0.0001349866797681898
Epoch:  282  	Training Loss: 6.712089088978246e-05
Test Loss:  7.863201608415693e-05
Valid Loss:  0.0001346804783679545
Epoch:  283  	Training Loss: 6.69521396048367e-05
Test Loss:  7.839701720513403e-05
Valid Loss:  0.00013437372399494052
Epoch:  284  	Training Loss: 6.679155922029167e-05
Test Loss:  7.81397829996422e-05
Valid Loss:  0.00013406950165517628
Epoch:  285  	Training Loss: 6.663328531431034e-05
Test Loss:  7.789932715240866e-05
Valid Loss:  0.00013376650167629123
Epoch:  286  	Training Loss: 6.647715053986758e-05
Test Loss:  7.76608067099005e-05
Valid Loss:  0.00013346501509658992
Epoch:  287  	Training Loss: 6.632345321122557e-05
Test Loss:  7.74286309024319e-05
Valid Loss:  0.00013316482363734394
Epoch:  288  	Training Loss: 6.617199687752873e-05
Test Loss:  7.719809946138412e-05
Valid Loss:  0.00013286774628795683
Epoch:  289  	Training Loss: 6.60251680528745e-05
Test Loss:  7.69828911870718e-05
Valid Loss:  0.00013257208047434688
Epoch:  290  	Training Loss: 6.58802455291152e-05
Test Loss:  7.676293898839504e-05
Valid Loss:  0.00013227970339357853
Epoch:  291  	Training Loss: 6.573909195140004e-05
Test Loss:  7.65589575166814e-05
Valid Loss:  0.00013198911619838327
Epoch:  292  	Training Loss: 6.55990734230727e-05
Test Loss:  7.643798744538799e-05
Valid Loss:  0.00013177764776628464
Epoch:  293  	Training Loss: 6.549892714247108e-05
Test Loss:  7.632500637555495e-05
Valid Loss:  0.0001315693516517058
Epoch:  294  	Training Loss: 6.539977039210498e-05
Test Loss:  7.621404074598104e-05
Valid Loss:  0.00013136371853761375
Epoch:  295  	Training Loss: 6.530158134410158e-05
Test Loss:  7.610354805365205e-05
Valid Loss:  0.00013116186892148107
Epoch:  296  	Training Loss: 6.520442548207939e-05
Test Loss:  7.599226955790073e-05
Valid Loss:  0.00013096285692881793
Epoch:  297  	Training Loss: 6.510765524581075e-05
Test Loss:  7.588077278342098e-05
Valid Loss:  0.00013076700270175934
Epoch:  298  	Training Loss: 6.501180905615911e-05
Test Loss:  7.576748612336814e-05
Valid Loss:  0.0001305740443058312
Epoch:  299  	Training Loss: 6.491652311524376e-05
Test Loss:  7.56524023017846e-05
Valid Loss:  0.0001303810568060726
Epoch:  300  	Training Loss: 6.482189928647131e-05
Test Loss:  7.553755131084472e-05
Valid Loss:  0.0001301902811974287
Epoch:  301  	Training Loss: 6.472742825280875e-05
Test Loss:  7.542181992903352e-05
Valid Loss:  0.00013000141188967973
Epoch:  302  	Training Loss: 6.463390309363604e-05
Test Loss:  7.518267375417054e-05
Valid Loss:  0.0001296392292715609
Epoch:  303  	Training Loss: 6.446871702792123e-05
Test Loss:  7.49420141801238e-05
Valid Loss:  0.00012928052456118166
Epoch:  304  	Training Loss: 6.430551002267748e-05
Test Loss:  7.470814307453111e-05
Valid Loss:  0.0001289301726501435
Epoch:  305  	Training Loss: 6.414433300960809e-05
Test Loss:  7.447512325597927e-05
Valid Loss:  0.00012859172420576215
Epoch:  306  	Training Loss: 6.398471305146813e-05
Test Loss:  7.426236697938293e-05
Valid Loss:  0.00012827024329453707
Epoch:  307  	Training Loss: 6.382816354744136e-05
Test Loss:  7.401335460599512e-05
Valid Loss:  0.0001279246062040329
Epoch:  308  	Training Loss: 6.367191963363439e-05
Test Loss:  7.379699673037976e-05
Valid Loss:  0.00012759219680447131
Epoch:  309  	Training Loss: 6.35207979939878e-05
Test Loss:  7.357659342233092e-05
Valid Loss:  0.00012727471766993403
Epoch:  310  	Training Loss: 6.337339436868206e-05
Test Loss:  7.339206786127761e-05
Valid Loss:  0.00012696103658527136
Epoch:  311  	Training Loss: 6.32273149676621e-05
Test Loss:  7.315785478567705e-05
Valid Loss:  0.00012663821689784527
Epoch:  312  	Training Loss: 6.308242154773325e-05
Test Loss:  7.305679173441604e-05
Valid Loss:  0.00012629418051801622
Epoch:  313  	Training Loss: 6.29411224508658e-05
Test Loss:  7.286621257662773e-05
Valid Loss:  0.00012597674503922462
Epoch:  314  	Training Loss: 6.280429806793109e-05
Test Loss:  7.268742774613202e-05
Valid Loss:  0.0001256676041521132
Epoch:  315  	Training Loss: 6.266986019909382e-05
Test Loss:  7.250555790960789e-05
Valid Loss:  0.00012536614667624235
Epoch:  316  	Training Loss: 6.253739411477e-05
Test Loss:  7.232346979435533e-05
Valid Loss:  0.00012507264909800142
Epoch:  317  	Training Loss: 6.240672519197688e-05
Test Loss:  7.214094512164593e-05
Valid Loss:  0.00012478584540076554
Epoch:  318  	Training Loss: 6.227745325304568e-05
Test Loss:  7.195868238341063e-05
Valid Loss:  0.00012450452777557075
Epoch:  319  	Training Loss: 6.214986933628097e-05
Test Loss:  7.177647785283625e-05
Valid Loss:  0.0001242278958670795
Epoch:  320  	Training Loss: 6.202336226124316e-05
Test Loss:  7.159586675697938e-05
Valid Loss:  0.0001239561097463593
Epoch:  321  	Training Loss: 6.189832492964342e-05
Test Loss:  7.141581590985879e-05
Valid Loss:  0.00012368809257168323
Epoch:  322  	Training Loss: 6.177427712827921e-05
Test Loss:  7.126270065782592e-05
Valid Loss:  0.0001234631345141679
Epoch:  323  	Training Loss: 6.157960160635412e-05
Test Loss:  7.105352415237576e-05
Valid Loss:  0.00012324089766480029
Epoch:  324  	Training Loss: 6.1404614825733e-05
Test Loss:  7.085681863827631e-05
Valid Loss:  0.00012301522656343877
Epoch:  325  	Training Loss: 6.123556522652507e-05
Test Loss:  7.065518730087206e-05
Valid Loss:  0.00012278597569093108
Epoch:  326  	Training Loss: 6.107039371272549e-05
Test Loss:  7.046993414405733e-05
Valid Loss:  0.00012255240289960057
Epoch:  327  	Training Loss: 6.090763781685382e-05
Test Loss:  7.028658728813753e-05
Valid Loss:  0.00012231663276907057
Epoch:  328  	Training Loss: 6.0749269323423505e-05
Test Loss:  7.010808621998876e-05
Valid Loss:  0.00012207822874188423
Epoch:  329  	Training Loss: 6.059453517082147e-05
Test Loss:  6.993516581133008e-05
Valid Loss:  0.00012183829676359892
Epoch:  330  	Training Loss: 6.044233305146918e-05
Test Loss:  6.977190787438303e-05
Valid Loss:  0.00012159682955825701
Epoch:  331  	Training Loss: 6.0293416026979685e-05
Test Loss:  6.96026545483619e-05
Valid Loss:  0.00012135461292928085
Epoch:  332  	Training Loss: 6.0147598560433835e-05
Test Loss:  6.92667526891455e-05
Valid Loss:  0.00012103298649890348
Epoch:  333  	Training Loss: 5.987875192658976e-05
Test Loss:  6.895534170325845e-05
Valid Loss:  0.00012070579396095127
Epoch:  334  	Training Loss: 5.962245995760895e-05
Test Loss:  6.866233889013529e-05
Valid Loss:  0.00012037229316774756
Epoch:  335  	Training Loss: 5.9371301176724955e-05
Test Loss:  6.837985711172223e-05
Valid Loss:  0.00012003385927528143
Epoch:  336  	Training Loss: 5.9130739828106016e-05
Test Loss:  6.8111956352368e-05
Valid Loss:  0.0001196921948576346
Epoch:  337  	Training Loss: 5.889881867915392e-05
Test Loss:  6.785547884646803e-05
Valid Loss:  0.00011934872600249946
Epoch:  338  	Training Loss: 5.867440631845966e-05
Test Loss:  6.760818359907717e-05
Valid Loss:  0.0001190034017781727
Epoch:  339  	Training Loss: 5.845633859280497e-05
Test Loss:   68%|██████▊   | 339/500 [04:03<00:55,  2.90it/s] 68%|██████▊   | 341/500 [04:10<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:10<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:10<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:10<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:10<00:50,  2.97it/s] 70%|███████   | 351/500 [04:16<02:56,  1.18s/it] 71%|███████   | 353/500 [04:17<02:05,  1.18it/s] 71%|███████   | 355/500 [04:17<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:17<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:17<00:48,  2.89it/s] 72%|███████▏  | 361/500 [04:23<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:24<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:24<01:25,  1.59it/s] 73%|███████▎  | 367/500 [04:24<01:02,  2.14it/s] 74%|███████▍  | 369/500 [04:24<00:45,  2.87it/s] 74%|███████▍  | 371/500 [04:30<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:31<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:31<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:31<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:31<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:37<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:38<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:38<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:38<00:52,  2.16it/s] 78%|███████▊  | 389/500 [04:38<00:38,  2.89it/s] 78%|███████▊  | 391/500 [04:44<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:45<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:45<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:45<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:45<00:34,  2.94it/s] 80%|████████  | 401/500 [04:51<01:56,  1.18s/it] 81%|████████  | 403/500 [04:51<01:22,  1.18it/s] 81%|████████  | 405/500 [04:52<00:58,  1.63it/s]6.736921204719692e-05
Valid Loss:  0.0001186589288408868
Epoch:  340  	Training Loss: 5.824432446388528e-05
Test Loss:  6.713684706483036e-05
Valid Loss:  0.00011831459414679557
Epoch:  341  	Training Loss: 5.803732346976176e-05
Test Loss:  6.69098662910983e-05
Valid Loss:  0.00011797144543379545
Epoch:  342  	Training Loss: 5.783541564596817e-05
Test Loss:  6.693650357192382e-05
Valid Loss:  0.00011768814147217199
Epoch:  343  	Training Loss: 5.775019963039085e-05
Test Loss:  6.693864270346239e-05
Valid Loss:  0.00011746599921025336
Epoch:  344  	Training Loss: 5.768375558545813e-05
Test Loss:  6.692755414405838e-05
Valid Loss:  0.00011727485980372876
Epoch:  345  	Training Loss: 5.762651562690735e-05
Test Loss:  6.690717418678105e-05
Valid Loss:  0.00011710508988471702
Epoch:  346  	Training Loss: 5.7575081882532686e-05
Test Loss:  6.688141729682684e-05
Valid Loss:  0.00011695059947669506
Epoch:  347  	Training Loss: 5.7528097386239097e-05
Test Loss:  6.684500840492547e-05
Valid Loss:  0.00011681136675179005
Epoch:  348  	Training Loss: 5.7484616263536736e-05
Test Loss:  6.68155771563761e-05
Valid Loss:  0.00011667687067529187
Epoch:  349  	Training Loss: 5.7444212870905176e-05
Test Loss:  6.678475619992241e-05
Valid Loss:  0.00011655154958134517
Epoch:  350  	Training Loss: 5.7406610721955076e-05
Test Loss:  6.675391341559589e-05
Valid Loss:  0.00011643389734672382
Epoch:  351  	Training Loss: 5.737145693274215e-05
Test Loss:  6.672255403827876e-05
Valid Loss:  0.00011632295354502276
Epoch:  352  	Training Loss: 5.73385477764532e-05
Test Loss:  6.636699981754646e-05
Valid Loss:  0.00011612291564233601
Epoch:  353  	Training Loss: 5.7126548199448735e-05
Test Loss:  6.607628165511414e-05
Valid Loss:  0.00011594709940254688
Epoch:  354  	Training Loss: 5.694056744687259e-05
Test Loss:  6.581869092769921e-05
Valid Loss:  0.00011576811084523797
Epoch:  355  	Training Loss: 5.6767799833323807e-05
Test Loss:  6.558247696375474e-05
Valid Loss:  0.00011559491395018995
Epoch:  356  	Training Loss: 5.6612952903378755e-05
Test Loss:  6.536899309139699e-05
Valid Loss:  0.00011542801803443581
Epoch:  357  	Training Loss: 5.647191937896423e-05
Test Loss:  6.517377187265083e-05
Valid Loss:  0.00011526603339007124
Epoch:  358  	Training Loss: 5.6342447351198643e-05
Test Loss:  6.499334995169193e-05
Valid Loss:  0.00011510659533087164
Epoch:  359  	Training Loss: 5.622172830044292e-05
Test Loss:  6.482618482550606e-05
Valid Loss:  0.00011494931095512584
Epoch:  360  	Training Loss: 5.610753578366712e-05
Test Loss:  6.467008643085137e-05
Valid Loss:  0.00011479301610961556
Epoch:  361  	Training Loss: 5.5994783906498924e-05
Test Loss:  6.451879016822204e-05
Valid Loss:  0.00011463664850452915
Epoch:  362  	Training Loss: 5.58875581191387e-05
Test Loss:  6.449775537475944e-05
Valid Loss:  0.00011441559036029503
Epoch:  363  	Training Loss: 5.576996773015708e-05
Test Loss:  6.443762686103582e-05
Valid Loss:  0.00011420840019127354
Epoch:  364  	Training Loss: 5.566356048802845e-05
Test Loss:  6.435639807023108e-05
Valid Loss:  0.00011400522635085508
Epoch:  365  	Training Loss: 5.556144242291339e-05
Test Loss:  6.426766776712611e-05
Valid Loss:  0.00011380585783626884
Epoch:  366  	Training Loss: 5.546122702071443e-05
Test Loss:  6.417639087885618e-05
Valid Loss:  0.0001136098726419732
Epoch:  367  	Training Loss: 5.536271055461839e-05
Test Loss:  6.408426270354539e-05
Valid Loss:  0.00011341677600285038
Epoch:  368  	Training Loss: 5.526552195078693e-05
Test Loss:  6.399096309905872e-05
Valid Loss:  0.00011322778300382197
Epoch:  369  	Training Loss: 5.516959572560154e-05
Test Loss:  6.389781628968194e-05
Valid Loss:  0.00011304095824016258
Epoch:  370  	Training Loss: 5.507486639544368e-05
Test Loss:  6.380421109497547e-05
Valid Loss:  0.00011285723303444684
Epoch:  371  	Training Loss: 5.498122482094914e-05
Test Loss:  6.371056952048093e-05
Valid Loss:  0.00011267527588643134
Epoch:  372  	Training Loss: 5.488891474669799e-05
Test Loss:  6.335186481010169e-05
Valid Loss:  0.00011231227108510211
Epoch:  373  	Training Loss: 5.474273712025024e-05
Test Loss:  6.324953574221581e-05
Valid Loss:  0.00011203030589967966
Epoch:  374  	Training Loss: 5.46498667972628e-05
Test Loss:  6.318803207250312e-05
Valid Loss:  0.00011177773558301851
Epoch:  375  	Training Loss: 5.456944927573204e-05
Test Loss:  6.313794438028708e-05
Valid Loss:  0.0001115495542762801
Epoch:  376  	Training Loss: 5.44987888133619e-05
Test Loss:  6.309507443802431e-05
Valid Loss:  0.00011134165833937004
Epoch:  377  	Training Loss: 5.443698319140822e-05
Test Loss:  6.305822898866609e-05
Valid Loss:  0.00011115282541140914
Epoch:  378  	Training Loss: 5.4382358939619735e-05
Test Loss:  6.30253562121652e-05
Valid Loss:  0.00011098050890723243
Epoch:  379  	Training Loss: 5.433446494862437e-05
Test Loss:  6.299722736002877e-05
Valid Loss:  0.00011082302080467343
Epoch:  380  	Training Loss: 5.429204611573368e-05
Test Loss:  6.297214713413268e-05
Valid Loss:  0.00011067852756241336
Epoch:  381  	Training Loss: 5.425428753369488e-05
Test Loss:  6.294997729128227e-05
Valid Loss:  0.00011054612696170807
Epoch:  382  	Training Loss: 5.4220981837715954e-05
Test Loss:  6.278601358644664e-05
Valid Loss:  0.00011033861665055156
Epoch:  383  	Training Loss: 5.4038311645854264e-05
Test Loss:  6.247313285712153e-05
Valid Loss:  0.0001100911176763475
Epoch:  384  	Training Loss: 5.388660792959854e-05
Test Loss:  6.22557636233978e-05
Valid Loss:  0.00010988893336616457
Epoch:  385  	Training Loss: 5.3746240155305713e-05
Test Loss:  6.20074279140681e-05
Valid Loss:  0.00010967085836455226
Epoch:  386  	Training Loss: 5.361032526707277e-05
Test Loss:  6.178460898809135e-05
Valid Loss:  0.00010946105612674728
Epoch:  387  	Training Loss: 5.347949991119094e-05
Test Loss:  6.156845483928919e-05
Valid Loss:  0.00010925087553914636
Epoch:  388  	Training Loss: 5.335313471732661e-05
Test Loss:  6.135948933660984e-05
Valid Loss:  0.00010904543159995228
Epoch:  389  	Training Loss: 5.323081131791696e-05
Test Loss:  6.116872827988118e-05
Valid Loss:  0.00010884082439588383
Epoch:  390  	Training Loss: 5.311165296006948e-05
Test Loss:  6.097428558859974e-05
Valid Loss:  0.00010863484931178391
Epoch:  391  	Training Loss: 5.2995335863670334e-05
Test Loss:  6.0795427998527884e-05
Valid Loss:  0.0001084341129171662
Epoch:  392  	Training Loss: 5.2881590818287805e-05
Test Loss:  6.0628321080002934e-05
Valid Loss:  0.0001081751543097198
Epoch:  393  	Training Loss: 5.2772360504604876e-05
Test Loss:  6.0533075156854466e-05
Valid Loss:  0.00010794192348839715
Epoch:  394  	Training Loss: 5.2666611736640334e-05
Test Loss:  6.0420334193622693e-05
Valid Loss:  0.00010771272354759276
Epoch:  395  	Training Loss: 5.256295480648987e-05
Test Loss:  6.031259545125067e-05
Valid Loss:  0.00010749122884590179
Epoch:  396  	Training Loss: 5.2461087761912495e-05
Test Loss:  6.0203514294698834e-05
Valid Loss:  0.0001072752638719976
Epoch:  397  	Training Loss: 5.236086144577712e-05
Test Loss:  6.00951025262475e-05
Valid Loss:  0.0001070653524948284
Epoch:  398  	Training Loss: 5.226192297413945e-05
Test Loss:  5.998607957735658e-05
Valid Loss:  0.00010685973393265158
Epoch:  399  	Training Loss: 5.216400313656777e-05
Test Loss:  5.987794793327339e-05
Valid Loss:  0.00010665855370461941
Epoch:  400  	Training Loss: 5.206714922678657e-05
Test Loss:  5.976855391054414e-05
Valid Loss:  0.0001064612515619956
Epoch:  401  	Training Loss: 5.197119025979191e-05
Test Loss:  5.966020034975372e-05
Valid Loss:  0.00010626763105392456
Epoch:  402  	Training Loss: 5.187578062759712e-05
Test Loss:  5.947075624135323e-05
Valid Loss:  0.00010602551628835499
Epoch:  403  	Training Loss: 5.1757895562332124e-05
Test Loss:  5.935302033321932e-05
Valid Loss:  0.00010580752859823406
Epoch:  404  	Training Loss: 5.164100366528146e-05
Test Loss:  5.9181104006711394e-05
Valid Loss:  0.00010557325731497258
Epoch:  405  	Training Loss: 5.152529774932191e-05
Test Loss:  5.9065605455543846e-05
Valid Loss:  0.0001053641753969714
Epoch:  406  	Training Loss: 5.1412444008747116e-05
Test Loss:  5.8899735449813306e-05
Valid Loss:  0.00010514270979911089
 81%|████████▏ | 407/500 [04:52<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:52<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:58<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:58<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:58<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:58<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:59<00:27,  2.99it/s] 84%|████████▍ | 421/500 [05:05<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:05<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:05<00:46,  1.63it/s] 85%|████████▌ | 427/500 [05:05<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:05<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:12<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:12<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:12<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:12<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:12<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:19<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:19<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:19<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:19<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:19<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:26<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:26<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:26<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:26<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:26<00:13,  2.93it/s] 92%|█████████▏| 461/500 [05:33<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:33<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:33<00:22,  1.58it/s] 93%|█████████▎| 467/500 [05:33<00:15,  2.14it/s] 94%|█████████▍| 469/500 [05:33<00:10,  2.83it/s] 94%|█████████▍| 471/500 [05:40<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:40<00:23,  1.13it/s]Epoch:  407  	Training Loss: 5.130052159074694e-05
Test Loss:  5.8777237427420914e-05
Valid Loss:  0.00010493414447410032
Epoch:  408  	Training Loss: 5.1189184887334704e-05
Test Loss:  5.8623063523555174e-05
Valid Loss:  0.00010471839050296694
Epoch:  409  	Training Loss: 5.1078528485959396e-05
Test Loss:  5.849746958119795e-05
Valid Loss:  0.00010451176058268175
Epoch:  410  	Training Loss: 5.096860695630312e-05
Test Loss:  5.835133561049588e-05
Valid Loss:  0.00010430063412059098
Epoch:  411  	Training Loss: 5.085969314677641e-05
Test Loss:  5.8224439271725714e-05
Valid Loss:  0.00010409552487544715
Epoch:  412  	Training Loss: 5.075167428003624e-05
Test Loss:  5.824060644954443e-05
Valid Loss:  0.00010395309800514951
Epoch:  413  	Training Loss: 5.0649021432036534e-05
Test Loss:  5.8135348808718845e-05
Valid Loss:  0.00010380319145042449
Epoch:  414  	Training Loss: 5.056622831034474e-05
Test Loss:  5.801973748020828e-05
Valid Loss:  0.00010365180787630379
Epoch:  415  	Training Loss: 5.048464663559571e-05
Test Loss:  5.790505019831471e-05
Valid Loss:  0.00010350040975026786
Epoch:  416  	Training Loss: 5.040417090640403e-05
Test Loss:  5.779405910288915e-05
Valid Loss:  0.00010334843682358041
Epoch:  417  	Training Loss: 5.0324160838499665e-05
Test Loss:  5.7684501371113583e-05
Valid Loss:  0.00010319630382582545
Epoch:  418  	Training Loss: 5.024459824198857e-05
Test Loss:  5.757716280641034e-05
Valid Loss:  0.00010304447641829029
Epoch:  419  	Training Loss: 5.016560317017138e-05
Test Loss:  5.7470933825243264e-05
Valid Loss:  0.00010289238707628101
Epoch:  420  	Training Loss: 5.008688458474353e-05
Test Loss:  5.736622551921755e-05
Valid Loss:  0.00010274040687363595
Epoch:  421  	Training Loss: 5.000865348847583e-05
Test Loss:  5.726290328311734e-05
Valid Loss:  0.00010258886322844774
Epoch:  422  	Training Loss: 4.993061884306371e-05
Test Loss:  5.695463914889842e-05
Valid Loss:  0.00010239813127554953
Epoch:  423  	Training Loss: 4.985127452528104e-05
Test Loss:  5.690268881153315e-05
Valid Loss:  0.00010228385508526117
Epoch:  424  	Training Loss: 4.9785485316533595e-05
Test Loss:  5.680690810550004e-05
Valid Loss:  0.00010215753718512133
Epoch:  425  	Training Loss: 4.971991802449338e-05
Test Loss:  5.672149563906714e-05
Valid Loss:  0.0001020331765175797
Epoch:  426  	Training Loss: 4.965328116668388e-05
Test Loss:  5.663096089847386e-05
Valid Loss:  0.00010190693137701601
Epoch:  427  	Training Loss: 4.958738645655103e-05
Test Loss:  5.654313645209186e-05
Valid Loss:  0.00010178194497711957
Epoch:  428  	Training Loss: 4.9521207984071225e-05
Test Loss:  5.645651981467381e-05
Valid Loss:  0.00010165672574657947
Epoch:  429  	Training Loss: 4.9455698899691924e-05
Test Loss:  5.637069989461452e-05
Valid Loss:  0.0001015312664094381
Epoch:  430  	Training Loss: 4.9390313506592065e-05
Test Loss:  5.628619692288339e-05
Valid Loss:  0.0001014067092910409
Epoch:  431  	Training Loss: 4.9325240979669616e-05
Test Loss:  5.620250158244744e-05
Valid Loss:  0.00010128180292667821
Epoch:  432  	Training Loss: 4.926051042275503e-05
Test Loss:  5.6194490753114223e-05
Valid Loss:  0.00010112968448083848
Epoch:  433  	Training Loss: 4.921025538351387e-05
Test Loss:  5.616905036731623e-05
Valid Loss:  0.00010098859638674185
Epoch:  434  	Training Loss: 4.9164500524057075e-05
Test Loss:  5.6137934734579176e-05
Valid Loss:  0.00010085603571496904
Epoch:  435  	Training Loss: 4.9122783821076155e-05
Test Loss:  5.6105112889781594e-05
Valid Loss:  0.0001007324899546802
Epoch:  436  	Training Loss: 4.9083566409535706e-05
Test Loss:  5.6072036386467516e-05
Valid Loss:  0.00010061561624752358
Epoch:  437  	Training Loss: 4.9046691856347024e-05
Test Loss:  5.604040779871866e-05
Valid Loss:  0.00010050553100882098
Epoch:  438  	Training Loss: 4.9012029194273055e-05
Test Loss:  5.600912118097767e-05
Valid Loss:  0.0001004014047794044
Epoch:  439  	Training Loss: 4.897935286862776e-05
Test Loss:  5.597900599241257e-05
Valid Loss:  0.00010030210978584364
Epoch:  440  	Training Loss: 4.894814264844172e-05
Test Loss:  5.5949763918761164e-05
Valid Loss:  0.00010020834452006966
Epoch:  441  	Training Loss: 4.8918460379354656e-05
Test Loss:  5.5921052990015596e-05
Valid Loss:  0.00010011834092438221
Epoch:  442  	Training Loss: 4.888994590146467e-05
Test Loss:  5.581346704275347e-05
Valid Loss:  0.00010001154441852123
Epoch:  443  	Training Loss: 4.881927452515811e-05
Test Loss:  5.5701697419863194e-05
Valid Loss:  9.990258695324883e-05
Epoch:  444  	Training Loss: 4.875057493336499e-05
Test Loss:  5.559526107390411e-05
Valid Loss:  9.979411697713658e-05
Epoch:  445  	Training Loss: 4.8683290515327826e-05
Test Loss:  5.549151683226228e-05
Valid Loss:  9.968678205041215e-05
Epoch:  446  	Training Loss: 4.861722845816985e-05
Test Loss:  5.539143239730038e-05
Valid Loss:  9.957849397324026e-05
Epoch:  447  	Training Loss: 4.855229053646326e-05
Test Loss:  5.529439658857882e-05
Valid Loss:  9.947206126525998e-05
Epoch:  448  	Training Loss: 4.848834942094982e-05
Test Loss:  5.519953992916271e-05
Valid Loss:  9.936440619640052e-05
Epoch:  449  	Training Loss: 4.842533962801099e-05
Test Loss:  5.51077609998174e-05
Valid Loss:  9.925742779159918e-05
Epoch:  450  	Training Loss: 4.836314110434614e-05
Test Loss:  5.501806299434975e-05
Valid Loss:  9.915031841956079e-05
Epoch:  451  	Training Loss: 4.830189936910756e-05
Test Loss:  5.49293945368845e-05
Valid Loss:  9.904299076879397e-05
Epoch:  452  	Training Loss: 4.824135612579994e-05
Test Loss:  5.497324309544638e-05
Valid Loss:  9.883943130262196e-05
Epoch:  453  	Training Loss: 4.7941408411134034e-05
Test Loss:  5.459016392705962e-05
Valid Loss:  9.853659139480442e-05
Epoch:  454  	Training Loss: 4.769123188452795e-05
Test Loss:  5.441675602924079e-05
Valid Loss:  9.826302994042635e-05
Epoch:  455  	Training Loss: 4.7462999646086246e-05
Test Loss:  5.419096851255745e-05
Valid Loss:  9.796725498745218e-05
Epoch:  456  	Training Loss: 4.724699101643637e-05
Test Loss:  5.400567169999704e-05
Valid Loss:  9.767050505615771e-05
Epoch:  457  	Training Loss: 4.70402737846598e-05
Test Loss:  5.381352093536407e-05
Valid Loss:  9.736763604450971e-05
Epoch:  458  	Training Loss: 4.6840777940815315e-05
Test Loss:  5.3628791647497565e-05
Valid Loss:  9.706339915283024e-05
Epoch:  459  	Training Loss: 4.6647539420519024e-05
Test Loss:  5.344872624846175e-05
Valid Loss:  9.675843466538936e-05
Epoch:  460  	Training Loss: 4.645943408831954e-05
Test Loss:  5.327440885594115e-05
Valid Loss:  9.645418322179466e-05
Epoch:  461  	Training Loss: 4.6275308704935014e-05
Test Loss:  5.310412961989641e-05
Valid Loss:  9.61513287620619e-05
Epoch:  462  	Training Loss: 4.609523239196278e-05
Test Loss:  5.303626676322892e-05
Valid Loss:  9.60409888648428e-05
Epoch:  463  	Training Loss: 4.6023815230000764e-05
Test Loss:  5.296340532368049e-05
Valid Loss:  9.59292083280161e-05
Epoch:  464  	Training Loss: 4.595462087308988e-05
Test Loss:  5.2890707593178377e-05
Valid Loss:  9.581633639754727e-05
Epoch:  465  	Training Loss: 4.588694719132036e-05
Test Loss:  5.281875201035291e-05
Valid Loss:  9.570333349984139e-05
Epoch:  466  	Training Loss: 4.581972461892292e-05
Test Loss:  5.274867726257071e-05
Valid Loss:  9.55908399191685e-05
Epoch:  467  	Training Loss: 4.5751530706183985e-05
Test Loss:  5.267872620606795e-05
Valid Loss:  9.547696390654892e-05
Epoch:  468  	Training Loss: 4.5684493670705706e-05
Test Loss:  5.260935358819552e-05
Valid Loss:  9.536304423818365e-05
Epoch:  469  	Training Loss: 4.561866808217019e-05
Test Loss:  5.2541396144079044e-05
Valid Loss:  9.524957567919046e-05
Epoch:  470  	Training Loss: 4.555400300887413e-05
Test Loss:  5.247472654446028e-05
Valid Loss:  9.513526310911402e-05
Epoch:  471  	Training Loss: 4.549017467070371e-05
Test Loss:  5.2409312047529966e-05
Valid Loss:  9.50216272030957e-05
Epoch:  472  	Training Loss: 4.542736860457808e-05
Test Loss:  5.22539448866155e-05
Valid Loss:  9.489939839113504e-05
Epoch:  473  	Training Loss: 4.535446714726277e-05
Test Loss:  5.2159019105602056e-05
Valid Loss:  9.480402513872832e-05
Epoch:  474  	Training Loss: 4.529026409727521e-05
Test Loss:  5.20705507369712e-05
 95%|█████████▌| 475/500 [05:40<00:15,  1.57it/s] 95%|█████████▌| 477/500 [05:40<00:10,  2.14it/s] 96%|█████████▌| 479/500 [05:40<00:07,  2.86it/s] 96%|█████████▌| 481/500 [05:47<00:23,  1.23s/it] 97%|█████████▋| 483/500 [05:47<00:15,  1.13it/s] 97%|█████████▋| 485/500 [05:47<00:09,  1.56it/s] 97%|█████████▋| 487/500 [05:47<00:06,  2.13it/s] 98%|█████████▊| 489/500 [05:48<00:03,  2.88it/s] 98%|█████████▊| 491/500 [05:54<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:54<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:54<00:03,  1.60it/s] 99%|█████████▉| 497/500 [05:54<00:01,  2.18it/s]100%|█████████▉| 499/500 [05:55<00:00,  2.93it/s]100%|██████████| 500/500 [05:55<00:00,  1.41it/s]
Valid Loss:  9.47102380450815e-05
Epoch:  475  	Training Loss: 4.522906965576112e-05
Test Loss:  5.1986295147798955e-05
Valid Loss:  9.461815352551639e-05
Epoch:  476  	Training Loss: 4.517030174611136e-05
Test Loss:  5.1905637519666925e-05
Valid Loss:  9.45259744185023e-05
Epoch:  477  	Training Loss: 4.5113534724805504e-05
Test Loss:  5.182836321182549e-05
Valid Loss:  9.443424642086029e-05
Epoch:  478  	Training Loss: 4.505860124481842e-05
Test Loss:  5.1753391744568944e-05
Valid Loss:  9.43433478823863e-05
Epoch:  479  	Training Loss: 4.500506474869326e-05
Test Loss:  5.168061761651188e-05
Valid Loss:  9.425201278645545e-05
Epoch:  480  	Training Loss: 4.495269604376517e-05
Test Loss:  5.1609600632218644e-05
Valid Loss:  9.416125249117613e-05
Epoch:  481  	Training Loss: 4.490111314225942e-05
Test Loss:  5.154056998435408e-05
Valid Loss:  9.406993922311813e-05
Epoch:  482  	Training Loss: 4.4850596168544143e-05
Test Loss:  5.146304829395376e-05
Valid Loss:  9.37672593863681e-05
Epoch:  483  	Training Loss: 4.471441206987947e-05
Test Loss:  5.135435640113428e-05
Valid Loss:  9.3484552053269e-05
Epoch:  484  	Training Loss: 4.4588967284653336e-05
Test Loss:  5.1250339311081916e-05
Valid Loss:  9.322209371021017e-05
Epoch:  485  	Training Loss: 4.4470143620856106e-05
Test Loss:  5.114651867188513e-05
Valid Loss:  9.29731540963985e-05
Epoch:  486  	Training Loss: 4.4356311263982207e-05
Test Loss:  5.1042741688434035e-05
Valid Loss:  9.27353321458213e-05
Epoch:  487  	Training Loss: 4.424611324793659e-05
Test Loss:  5.093721119919792e-05
Valid Loss:  9.250664879800752e-05
Epoch:  488  	Training Loss: 4.4138869270682335e-05
Test Loss:  5.083088035462424e-05
Valid Loss:  9.228517592418939e-05
Epoch:  489  	Training Loss: 4.4033782614860684e-05
Test Loss:  5.072394196758978e-05
Valid Loss:  9.206958202412352e-05
Epoch:  490  	Training Loss: 4.3930744141107425e-05
Test Loss:  5.061690171714872e-05
Valid Loss:  9.18588339118287e-05
Epoch:  491  	Training Loss: 4.382959014037624e-05
Test Loss:  5.05095740663819e-05
Valid Loss:  9.165279334411025e-05
Epoch:  492  	Training Loss: 4.3729713070206344e-05
Test Loss:  5.033780325902626e-05
Valid Loss:  9.139713074546307e-05
Epoch:  493  	Training Loss: 4.362133768154308e-05
Test Loss:  5.0231443310622126e-05
Valid Loss:  9.117304580286145e-05
Epoch:  494  	Training Loss: 4.351575262262486e-05
Test Loss:  5.0095644837711006e-05
Valid Loss:  9.094102279050276e-05
Epoch:  495  	Training Loss: 4.3412484956206754e-05
Test Loss:  4.997551513952203e-05
Valid Loss:  9.071861859411001e-05
Epoch:  496  	Training Loss: 4.331082891440019e-05
Test Loss:  4.984938641428016e-05
Valid Loss:  9.049710934050381e-05
Epoch:  497  	Training Loss: 4.321126834838651e-05
Test Loss:  4.972811439074576e-05
Valid Loss:  9.02806714293547e-05
Epoch:  498  	Training Loss: 4.3113366700708866e-05
Test Loss:  4.960674050380476e-05
Valid Loss:  9.006740583572537e-05
Epoch:  499  	Training Loss: 4.301724402466789e-05
Test Loss:  4.948775313096121e-05
Valid Loss:  8.985696331365034e-05
Epoch:  500  	Training Loss: 4.2922754801111296e-05
Test Loss:  4.937018093187362e-05
Valid Loss:  8.964956941781566e-05
seed is  13
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:36, 13.76it/s]  1%|          | 4/500 [00:00<00:37, 13.12it/s]  1%|          | 6/500 [00:00<00:34, 14.33it/s]  2%|▏         | 8/500 [00:00<00:33, 14.60it/s]  2%|▏         | 10/500 [00:00<00:32, 14.85it/s]  2%|▏         | 12/500 [00:00<00:32, 14.99it/s]  3%|▎         | 14/500 [00:00<00:31, 15.25it/s]  3%|▎         | 16/500 [00:01<00:31, 15.33it/s]  4%|▎         | 18/500 [00:01<00:31, 15.50it/s]  4%|▍         | 20/500 [00:01<00:30, 15.77it/s]  4%|▍         | 22/500 [00:01<00:30, 15.46it/s]  5%|▍         | 24/500 [00:01<00:30, 15.61it/s]  5%|▌         | 26/500 [00:01<00:30, 15.58it/s]  6%|▌         | 28/500 [00:01<00:29, 15.85it/s]  6%|▌         | 30/500 [00:01<00:30, 15.62it/s]  6%|▋         | 32/500 [00:02<00:29, 15.74it/s]  7%|▋         | 34/500 [00:02<00:29, 15.83it/s]  7%|▋         | 36/500 [00:02<00:29, 15.70it/s]  8%|▊         | 38/500 [00:02<00:29, 15.90it/s]  8%|▊         | 40/500 [00:02<00:28, 16.03it/s]  8%|▊         | 42/500 [00:02<00:28, 15.98it/s]  9%|▉         | 44/500 [00:02<00:29, 15.54it/s]  9%|▉         | 46/500 [00:03<00:31, 14.32it/s] 10%|▉         | 48/500 [00:03<00:31, 14.36it/s] 10%|█         | 50/500 [00:03<00:30, 14.56it/s] 10%|█         | 52/500 [00:03<00:30, 14.79it/s] 11%|█         | 54/500 [00:03<00:29, 15.18it/s] 11%|█         | 56/500 [00:03<00:28, 15.54it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.72it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.92it/s] 12%|█▏        | 62/500 [00:04<00:27, 16.05it/s] 13%|█▎        | 64/500 [00:04<00:27, 16.11it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.20it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.21it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.01it/s] 14%|█▍        | 72/500 [00:04<00:28, 14.94it/s] 15%|█▍        | 74/500 [00:04<00:28, 14.87it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.16it/s] 16%|█▌        | 78/500 [00:05<00:27, 15.43it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.72it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.76it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.92it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.01it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.65it/s] 18%|█▊        | 90/500 [00:05<00:28, 14.34it/s] 18%|█▊        | 92/500 [00:06<00:29, 13.79it/s] 19%|█▉        | 94/500 [00:06<00:28, 14.46it/s] 19%|█▉        | 96/500 [00:06<00:26, 14.98it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.30it/s] 20%|██        | 100/500 [00:06<00:25, 15.46it/s] 20%|██        | 102/500 [00:06<00:25, 15.57it/s] 21%|██        | 104/500 [00:06<00:25, 15.55it/s] 21%|██        | 106/500 [00:06<00:25, 15.31it/s] 22%|██▏       | 108/500 [00:07<00:25, 15.54it/s] 22%|██▏       | 110/500 [00:07<00:24, 15.64it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.69it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.72it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.46it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.49it/s] 24%|██▍       | 120/500 [00:07<00:25, 14.64it/s] 24%|██▍       | 122/500 [00:07<00:26, 14.46it/s] 25%|██▍       | 124/500 [00:08<00:25, 14.94it/s]Epoch:  1  	Training Loss: 0.04473322629928589
Test Loss:  119.71635437011719
Valid Loss:  120.24702453613281
Epoch:  2  	Training Loss: 121.40263366699219
Test Loss:  316926464.0
Valid Loss:  311585632.0
Epoch:  3  	Training Loss: 310975424.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:26, 14.05it/s] 26%|██▌       | 128/500 [00:08<00:25, 14.53it/s] 26%|██▌       | 130/500 [00:08<00:24, 15.01it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.38it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.61it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.64it/s] 28%|██▊       | 138/500 [00:09<00:23, 15.69it/s] 28%|██▊       | 140/500 [00:09<00:22, 15.82it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.71it/s] 29%|██▉       | 144/500 [00:09<00:24, 14.43it/s] 29%|██▉       | 146/500 [00:09<00:25, 13.70it/s] 30%|██▉       | 148/500 [00:09<00:26, 13.25it/s] 30%|███       | 150/500 [00:09<00:27, 12.96it/s] 30%|███       | 152/500 [00:10<00:27, 12.65it/s] 31%|███       | 154/500 [00:10<00:27, 12.48it/s] 31%|███       | 156/500 [00:10<00:28, 12.27it/s] 32%|███▏      | 158/500 [00:10<00:27, 12.26it/s] 32%|███▏      | 160/500 [00:10<00:27, 12.22it/s] 32%|███▏      | 162/500 [00:10<00:27, 12.27it/s] 33%|███▎      | 164/500 [00:11<00:27, 12.26it/s] 33%|███▎      | 166/500 [00:11<00:27, 12.19it/s] 34%|███▎      | 168/500 [00:11<00:27, 12.19it/s] 34%|███▍      | 170/500 [00:11<00:26, 12.24it/s] 34%|███▍      | 172/500 [00:11<00:26, 12.56it/s] 35%|███▍      | 174/500 [00:11<00:24, 13.48it/s] 35%|███▌      | 176/500 [00:11<00:22, 14.22it/s] 36%|███▌      | 178/500 [00:12<00:21, 14.84it/s] 36%|███▌      | 180/500 [00:12<00:21, 15.23it/s] 36%|███▋      | 182/500 [00:12<00:21, 14.85it/s] 37%|███▋      | 184/500 [00:12<00:21, 14.98it/s] 37%|███▋      | 186/500 [00:12<00:20, 15.33it/s] 38%|███▊      | 188/500 [00:12<00:20, 15.56it/s] 38%|███▊      | 190/500 [00:12<00:19, 15.65it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.71it/s] 39%|███▉      | 194/500 [00:13<00:19, 15.74it/s] 39%|███▉      | 196/500 [00:13<00:19, 15.80it/s] 40%|███▉      | 198/500 [00:13<00:19, 15.68it/s] 40%|████      | 200/500 [00:13<00:20, 14.93it/s] 40%|████      | 202/500 [00:13<00:21, 14.04it/s] 41%|████      | 204/500 [00:13<00:20, 14.22it/s] 41%|████      | 206/500 [00:13<00:19, 14.77it/s] 42%|████▏     | 208/500 [00:14<00:19, 15.06it/s] 42%|████▏     | 210/500 [00:14<00:19, 15.24it/s] 42%|████▏     | 212/500 [00:14<00:18, 15.47it/s] 43%|████▎     | 214/500 [00:14<00:19, 14.68it/s] 43%|████▎     | 216/500 [00:14<00:20, 13.84it/s] 44%|████▎     | 218/500 [00:14<00:21, 13.33it/s] 44%|████▍     | 220/500 [00:14<00:20, 13.73it/s] 44%|████▍     | 222/500 [00:15<00:19, 14.31it/s] 45%|████▍     | 224/500 [00:15<00:18, 14.81it/s] 45%|████▌     | 226/500 [00:15<00:18, 15.21it/s] 46%|████▌     | 228/500 [00:15<00:17, 15.36it/s] 46%|████▌     | 230/500 [00:15<00:17, 15.39it/s] 46%|████▋     | 232/500 [00:15<00:17, 15.34it/s] 47%|████▋     | 234/500 [00:15<00:17, 15.53it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.83it/s] 48%|████▊     | 238/500 [00:16<00:16, 15.89it/s] 48%|████▊     | 240/500 [00:16<00:16, 15.86it/s] 48%|████▊     | 242/500 [00:16<00:16, 15.90it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.83it/s] 49%|████▉     | 246/500 [00:16<00:15, 15.97it/s] 50%|████▉     | 248/500 [00:16<00:15, 15.97it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 15.81it/s] 50%|█████     | 252/500 [00:16<00:15, 15.83it/s] 51%|█████     | 254/500 [00:17<00:15, 15.64it/s] 51%|█████     | 256/500 [00:17<00:15, 15.79it/s] 52%|█████▏    | 258/500 [00:17<00:15, 15.43it/s] 52%|█████▏    | 260/500 [00:17<00:16, 14.69it/s] 52%|█████▏    | 262/500 [00:17<00:16, 14.66it/s] 53%|█████▎    | 264/500 [00:17<00:15, 15.05it/s] 53%|█████▎    | 266/500 [00:17<00:16, 14.58it/s] 54%|█████▎    | 268/500 [00:18<00:15, 14.82it/s] 54%|█████▍    | 270/500 [00:18<00:16, 13.76it/s] 54%|█████▍    | 272/500 [00:18<00:16, 13.90it/s] 55%|█████▍    | 274/500 [00:18<00:15, 14.50it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.03it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.44it/s] 56%|█████▌    | 280/500 [00:18<00:14, 15.69it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.76it/s] 57%|█████▋    | 284/500 [00:19<00:13, 15.94it/s] 57%|█████▋    | 286/500 [00:19<00:20, 10.20it/s] 58%|█████▊    | 288/500 [00:19<00:21,  9.83it/s] 58%|█████▊    | 290/500 [00:19<00:23,  8.75it/s] 58%|█████▊    | 292/500 [00:20<00:20,  9.99it/s] 59%|█████▉    | 294/500 [00:20<00:18, 11.19it/s] 59%|█████▉    | 296/500 [00:20<00:16, 12.26it/s] 60%|█████▉    | 298/500 [00:20<00:15, 13.17it/s] 60%|██████    | 300/500 [00:20<00:14, 13.62it/s] 60%|██████    | 302/500 [00:20<00:14, 13.88it/s] 61%|██████    | 304/500 [00:20<00:14, 13.54it/s] 61%|██████    | 306/500 [00:21<00:13, 14.17it/s] 62%|██████▏   | 308/500 [00:21<00:13, 14.58it/s] 62%|██████▏   | 310/500 [00:21<00:12, 14.70it/s] 62%|██████▏   | 312/500 [00:21<00:12, 14.96it/s] 63%|██████▎   | 314/500 [00:21<00:12, 15.35it/s] 63%|██████▎   | 316/500 [00:21<00:11, 15.44it/s] 64%|██████▎   | 318/500 [00:21<00:11, 15.56it/s] 64%|██████▍   | 320/500 [00:21<00:11, 15.80it/s] 64%|██████▍   | 322/500 [00:22<00:11, 15.77it/s] 65%|██████▍   | 324/500 [00:22<00:11, 15.81it/s] 65%|██████▌   | 326/500 [00:22<00:11, 15.78it/s] 66%|██████▌   | 328/500 [00:22<00:10, 15.77it/s] 66%|██████▌   | 330/500 [00:22<00:10, 15.70it/s] 66%|██████▋   | 332/500 [00:22<00:11, 14.80it/s] 67%|██████▋   | 334/500 [00:22<00:11, 13.86it/s] 67%|██████▋   | 336/500 [00:23<00:12, 13.38it/s] 68%|██████▊   | 338/500 [00:23<00:11, 13.67it/s] 68%|██████▊   | 340/500 [00:23<00:11, 14.20it/s] 68%|██████▊   | 342/500 [00:23<00:10, 14.54it/s] 69%|██████▉   | 344/500 [00:23<00:10, 14.88it/s] 69%|██████▉   | 346/500 [00:23<00:10, 15.06it/s] 70%|██████▉   | 348/500 [00:23<00:09, 15.42it/s] 70%|███████   | 350/500 [00:23<00:09, 15.66it/s] 70%|███████   | 352/500 [00:24<00:09, 15.53it/s] 71%|███████   | 354/500 [00:24<00:09, 15.73it/s] 71%|███████   | 356/500 [00:24<00:09, 15.74it/s] 72%|███████▏  | 358/500 [00:24<00:09, 14.77it/s] 72%|███████▏  | 360/500 [00:24<00:10, 13.93it/s] 72%|███████▏  | 362/500 [00:24<00:10, 13.50it/s] 73%|███████▎  | 364/500 [00:24<00:09, 14.02it/s] 73%|███████▎  | 366/500 [00:25<00:09, 14.41it/s] 74%|███████▎  | 368/500 [00:25<00:09, 13.70it/s] 74%|███████▍  | 370/500 [00:25<00:09, 13.25it/s] 74%|███████▍  | 372/500 [00:25<00:09, 12.94it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:25<00:09, 12.92it/s] 75%|███████▌  | 376/500 [00:25<00:09, 13.77it/s] 76%|███████▌  | 378/500 [00:25<00:08, 14.46it/s] 76%|███████▌  | 380/500 [00:26<00:08, 14.97it/s] 76%|███████▋  | 382/500 [00:26<00:07, 15.19it/s] 77%|███████▋  | 384/500 [00:26<00:07, 15.42it/s] 77%|███████▋  | 386/500 [00:26<00:07, 15.33it/s] 78%|███████▊  | 388/500 [00:26<00:07, 15.49it/s] 78%|███████▊  | 390/500 [00:26<00:07, 15.62it/s] 78%|███████▊  | 392/500 [00:26<00:07, 15.35it/s] 79%|███████▉  | 394/500 [00:26<00:07, 14.48it/s] 79%|███████▉  | 396/500 [00:27<00:06, 14.88it/s] 80%|███████▉  | 398/500 [00:27<00:06, 15.21it/s] 80%|████████  | 400/500 [00:27<00:06, 15.18it/s] 80%|████████  | 402/500 [00:27<00:06, 14.55it/s] 81%|████████  | 404/500 [00:27<00:06, 13.72it/s] 81%|████████  | 406/500 [00:27<00:07, 13.16it/s] 82%|████████▏ | 408/500 [00:27<00:07, 12.91it/s] 82%|████████▏ | 410/500 [00:28<00:07, 12.71it/s] 82%|████████▏ | 412/500 [00:28<00:06, 13.41it/s] 83%|████████▎ | 414/500 [00:28<00:06, 14.00it/s] 83%|████████▎ | 416/500 [00:28<00:05, 14.43it/s] 84%|████████▎ | 418/500 [00:28<00:05, 14.86it/s] 84%|████████▍ | 420/500 [00:28<00:05, 14.93it/s] 84%|████████▍ | 422/500 [00:28<00:05, 15.23it/s] 85%|████████▍ | 424/500 [00:29<00:05, 14.84it/s] 85%|████████▌ | 426/500 [00:29<00:05, 13.96it/s] 86%|████████▌ | 428/500 [00:29<00:05, 13.34it/s] 86%|████████▌ | 430/500 [00:29<00:05, 12.66it/s] 86%|████████▋ | 432/500 [00:29<00:05, 13.33it/s] 87%|████████▋ | 434/500 [00:29<00:05, 12.91it/s] 87%|████████▋ | 436/500 [00:30<00:04, 13.32it/s] 88%|████████▊ | 438/500 [00:30<00:04, 13.92it/s] 88%|████████▊ | 440/500 [00:30<00:04, 14.45it/s] 88%|████████▊ | 442/500 [00:30<00:03, 14.94it/s] 89%|████████▉ | 444/500 [00:30<00:03, 15.29it/s] 89%|████████▉ | 446/500 [00:30<00:03, 15.54it/s] 90%|████████▉ | 448/500 [00:30<00:03, 15.78it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.79it/s] 90%|█████████ | 452/500 [00:31<00:03, 15.86it/s] 91%|█████████ | 454/500 [00:31<00:02, 15.80it/s] 91%|█████████ | 456/500 [00:31<00:02, 15.92it/s] 92%|█████████▏| 458/500 [00:31<00:02, 16.05it/s] 92%|█████████▏| 460/500 [00:31<00:02, 16.03it/s] 92%|█████████▏| 462/500 [00:31<00:02, 15.79it/s] 93%|█████████▎| 464/500 [00:31<00:02, 15.87it/s] 93%|█████████▎| 466/500 [00:31<00:02, 15.96it/s] 94%|█████████▎| 468/500 [00:32<00:01, 16.14it/s] 94%|█████████▍| 470/500 [00:32<00:01, 16.11it/s] 94%|█████████▍| 472/500 [00:32<00:01, 15.92it/s] 95%|█████████▍| 474/500 [00:32<00:01, 15.34it/s] 95%|█████████▌| 476/500 [00:32<00:01, 15.25it/s] 96%|█████████▌| 478/500 [00:32<00:01, 14.92it/s] 96%|█████████▌| 480/500 [00:32<00:01, 15.31it/s] 96%|█████████▋| 482/500 [00:32<00:01, 15.56it/s] 97%|█████████▋| 484/500 [00:33<00:01, 15.79it/s] 97%|█████████▋| 486/500 [00:33<00:00, 14.85it/s] 98%|█████████▊| 488/500 [00:33<00:00, 15.24it/s] 98%|█████████▊| 490/500 [00:33<00:00, 15.38it/s] 98%|█████████▊| 492/500 [00:33<00:00, 15.50it/s] 99%|█████████▉| 494/500 [00:33<00:00, 15.54it/s] 99%|█████████▉| 496/500 [00:33<00:00, 15.72it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 15.33it/s]100%|██████████| 500/500 [00:34<00:00, 15.51it/s]100%|██████████| 500/500 [00:34<00:00, 14.67it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  13
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:43,  6.34s/it]  1%|          | 3/500 [00:06<14:02,  1.69s/it]  1%|          | 5/500 [00:06<07:06,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.91it/s]  2%|▏         | 9/500 [00:06<02:55,  2.80it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:30,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.54it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:33,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:16,  1.19s/it]  7%|▋         | 33/500 [00:27<06:37,  1.17it/s]  7%|▋         | 35/500 [00:27<04:48,  1.61it/s]  7%|▋         | 37/500 [00:27<03:30,  2.20it/s]  8%|▊         | 39/500 [00:27<02:36,  2.95it/s]  8%|▊         | 41/500 [00:33<09:06,  1.19s/it]  9%|▊         | 43/500 [00:34<06:31,  1.17it/s]  9%|▉         | 45/500 [00:34<04:41,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.21it/s] 10%|▉         | 49/500 [00:34<02:32,  2.97it/s] 10%|█         | 51/500 [00:40<08:54,  1.19s/it] 11%|█         | 53/500 [00:40<06:21,  1.17it/s] 11%|█         | 55/500 [00:41<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.96it/s] 12%|█▏        | 61/500 [00:47<08:44,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:14,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:29,  1.61it/s] 13%|█▎        | 67/500 [00:48<03:16,  2.20it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.97it/s] 14%|█▍        | 71/500 [00:54<08:33,  1.20s/it] 15%|█▍        | 73/500 [00:54<06:09,  1.16it/s]Epoch:  1  	Training Loss: 0.04473323002457619
Test Loss:  91.90025329589844
Valid Loss:  92.05577850341797
Epoch:  2  	Training Loss: 79.79684448242188
Test Loss:  5485.3310546875
Valid Loss:  5264.0517578125
Epoch:  3  	Training Loss: 5324.369140625
Test Loss:  2.877962589263916
Valid Loss:  2.838183879852295
Epoch:  4  	Training Loss: 2.9873290061950684
Test Loss:  2.661228656768799
Valid Loss:  2.6271777153015137
Epoch:  5  	Training Loss: 2.771200180053711
Test Loss:  2.4592151641845703
Valid Loss:  2.430417776107788
Epoch:  6  	Training Loss: 2.5694196224212646
Test Loss:  2.271090507507324
Valid Loss:  2.247100830078125
Epoch:  7  	Training Loss: 2.3811874389648438
Test Loss:  2.0960474014282227
Valid Loss:  2.076449155807495
Epoch:  8  	Training Loss: 2.205730676651001
Test Loss:  1.9333133697509766
Valid Loss:  1.9177165031433105
Epoch:  9  	Training Loss: 2.0423049926757812
Test Loss:  1.7821450233459473
Valid Loss:  1.770186424255371
Epoch:  10  	Training Loss: 1.8901971578598022
Test Loss:  1.6418312788009644
Valid Loss:  1.6331716775894165
Epoch:  11  	Training Loss: 1.7487220764160156
Test Loss:  1.511692762374878
Valid Loss:  1.5060174465179443
Epoch:  12  	Training Loss: 1.6172257661819458
Test Loss:  1.3517627716064453
Valid Loss:  1.3498876094818115
Epoch:  13  	Training Loss: 1.45273756980896
Test Loss:  1.2087864875793457
Valid Loss:  1.210151195526123
Epoch:  14  	Training Loss: 1.3053464889526367
Test Loss:  1.0809377431869507
Valid Loss:  1.0850497484207153
Epoch:  15  	Training Loss: 1.1732287406921387
Test Loss:  0.9665926694869995
Valid Loss:  0.9730201959609985
Epoch:  16  	Training Loss: 1.0547629594802856
Test Loss:  0.8643077611923218
Valid Loss:  0.8726723790168762
Epoch:  17  	Training Loss: 0.9485061168670654
Test Loss:  0.7727991938591003
Valid Loss:  0.7827690839767456
Epoch:  18  	Training Loss: 0.8531737923622131
Test Loss:  0.6909219026565552
Valid Loss:  0.7022069692611694
Epoch:  19  	Training Loss: 0.767619788646698
Test Loss:  0.617655873298645
Valid Loss:  0.6300029754638672
Epoch:  20  	Training Loss: 0.6908224821090698
Test Loss:  0.5520923137664795
Valid Loss:  0.565280556678772
Epoch:  21  	Training Loss: 0.6218703985214233
Test Loss:  0.4934193789958954
Valid Loss:  0.5072565078735352
Epoch:  22  	Training Loss: 0.5599489212036133
Test Loss:  0.4414164423942566
Valid Loss:  0.45572859048843384
Epoch:  23  	Training Loss: 0.5048218369483948
Test Loss:  0.39472508430480957
Valid Loss:  0.4093712270259857
Epoch:  24  	Training Loss: 0.45513662695884705
Test Loss:  0.35282039642333984
Valid Loss:  0.3676779866218567
Epoch:  25  	Training Loss: 0.41036534309387207
Test Loss:  0.3152276873588562
Valid Loss:  0.3301902413368225
Epoch:  26  	Training Loss: 0.3700296878814697
Test Loss:  0.2815172076225281
Valid Loss:  0.29649314284324646
Epoch:  27  	Training Loss: 0.3336966335773468
Test Loss:  0.2513011395931244
Valid Loss:  0.2662118375301361
Epoch:  28  	Training Loss: 0.30097466707229614
Test Loss:  0.22422850131988525
Valid Loss:  0.23900696635246277
Epoch:  29  	Training Loss: 0.2715091109275818
Test Loss:  0.1999831348657608
Valid Loss:  0.21457260847091675
Epoch:  30  	Training Loss: 0.24498000741004944
Test Loss:  0.1782793551683426
Valid Loss:  0.19263216853141785
Epoch:  31  	Training Loss: 0.22109785676002502
Test Loss:  0.15885938704013824
Valid Loss:  0.17293596267700195
Epoch:  32  	Training Loss: 0.19960111379623413
Test Loss:  0.1408902406692505
Valid Loss:  0.15464265644550323
Epoch:  33  	Training Loss: 0.17963415384292603
Test Loss:  0.12497977912425995
Valid Loss:  0.13838325440883636
Epoch:  34  	Training Loss: 0.16183021664619446
Test Loss:  0.11088605225086212
Valid Loss:  0.12392187118530273
Epoch:  35  	Training Loss: 0.1459418684244156
Test Loss:  0.09839706867933273
Valid Loss:  0.11105170100927353
Epoch:  36  	Training Loss: 0.1317518800497055
Test Loss:  0.08732685446739197
Valid Loss:  0.09959110617637634
Epoch:  37  	Training Loss: 0.1190694123506546
Test Loss:  0.07751189917325974
Valid Loss:  0.08938026428222656
Epoch:  38  	Training Loss: 0.10772626101970673
Test Loss:  0.06880845129489899
Valid Loss:  0.08027847111225128
Epoch:  39  	Training Loss: 0.09757420420646667
Test Loss:  0.06108975410461426
Valid Loss:  0.07216158509254456
Epoch:  40  	Training Loss: 0.08848228305578232
Test Loss:  0.05424416810274124
Valid Loss:  0.06492011249065399
Epoch:  41  	Training Loss: 0.08033484220504761
Test Loss:  0.04817306622862816
Valid Loss:  0.05845720320940018
Epoch:  42  	Training Loss: 0.07302951067686081
Test Loss:  0.04288823902606964
Valid Loss:  0.05279354751110077
Epoch:  43  	Training Loss: 0.06657972186803818
Test Loss:  0.0381794348359108
Valid Loss:  0.04771117866039276
Epoch:  44  	Training Loss: 0.060763612389564514
Test Loss:  0.03398655354976654
Valid Loss:  0.04315106198191643
Epoch:  45  	Training Loss: 0.05551837012171745
Test Loss:  0.030255675315856934
Valid Loss:  0.03906014561653137
Epoch:  46  	Training Loss: 0.05078747868537903
Test Loss:  0.026938367635011673
Valid Loss:  0.035390716046094894
Epoch:  47  	Training Loss: 0.04652003198862076
Test Loss:  0.0239911787211895
Valid Loss:  0.032099902629852295
Epoch:  48  	Training Loss: 0.04267017915844917
Test Loss:  0.02137507125735283
Valid Loss:  0.029149096459150314
Epoch:  49  	Training Loss: 0.03919661045074463
Test Loss:  0.019055064767599106
Valid Loss:  0.026503674685955048
Epoch:  50  	Training Loss: 0.036062151193618774
Test Loss:  0.016999725252389908
Valid Loss:  0.02413245290517807
Epoch:  51  	Training Loss: 0.03331784904003143
Test Loss:  0.015328897163271904
Valid Loss:  0.022250119596719742
Epoch:  52  	Training Loss: 0.031362488865852356
Test Loss:  0.014095116406679153
Valid Loss:  0.020871542394161224
Epoch:  53  	Training Loss: 0.03006461262702942
Test Loss:  0.013114518485963345
Valid Loss:  0.019721930846571922
Epoch:  54  	Training Loss: 0.029048977419734
Test Loss:  0.012263795360922813
Valid Loss:  0.018778733909130096
Epoch:  55  	Training Loss: 0.028151143342256546
Test Loss:  0.01153814047574997
Valid Loss:  0.018017403781414032
Epoch:  56  	Training Loss: 0.02738495171070099
Test Loss:  0.010934649966657162
Valid Loss:  0.017411429435014725
Epoch:  57  	Training Loss: 0.026791254058480263
Test Loss:  0.010414015501737595
Valid Loss:  0.016941938549280167
Epoch:  58  	Training Loss: 0.026310591027140617
Test Loss:  0.009998000226914883
Valid Loss:  0.016580738127231598
Epoch:  59  	Training Loss: 0.025925859808921814
Test Loss:  0.00966646522283554
Valid Loss:  0.01629580557346344
Epoch:  60  	Training Loss: 0.025625087320804596
Test Loss:  0.00939708761870861
Valid Loss:  0.01604568399488926
Epoch:  61  	Training Loss: 0.025371629744768143
Test Loss:  0.009153672493994236
Valid Loss:  0.015817511826753616
Epoch:  62  	Training Loss: 0.02514554373919964
Test Loss:  0.008935767225921154
Valid Loss:  0.015612280927598476
Epoch:  63  	Training Loss: 0.024947091937065125
Test Loss:  0.008742861449718475
Valid Loss:  0.015438860282301903
Epoch:  64  	Training Loss: 0.024778276681900024
Test Loss:  0.00857087504118681
Valid Loss:  0.01528271846473217
Epoch:  65  	Training Loss: 0.0246270764619112
Test Loss:  0.008423175662755966
Valid Loss:  0.015139808878302574
Epoch:  66  	Training Loss: 0.02449369616806507
Test Loss:  0.008299075998365879
Valid Loss:  0.015014215372502804
Epoch:  67  	Training Loss: 0.024382011964917183
Test Loss:  0.008185958489775658
Valid Loss:  0.01489898283034563
Epoch:  68  	Training Loss: 0.024283112958073616
Test Loss:  0.008091285824775696
Valid Loss:  0.014797716401517391
Epoch:  69  	Training Loss: 0.024199508130550385
Test Loss:  0.008006233721971512
Valid Loss:  0.01470454316586256
Epoch:  70  	Training Loss: 0.02412322349846363
Test Loss:  0.007927341386675835
Valid Loss:  0.014620466157793999
Epoch:  71  	Training Loss: 0.024052590131759644
Test Loss:  0.007855337113142014
Valid Loss:  0.01454450935125351
Epoch:  72  	Training Loss: 0.023989159613847733
Test Loss:  0.007793682627379894
Valid Loss:  0.014475944451987743
Epoch:  73  	Training Loss: 0.023934468626976013
Test Loss:  0.007740573026239872
Valid Loss:  0.014413784258067608
 15%|█▌        | 75/500 [00:55<04:27,  1.59it/s] 15%|█▌        | 77/500 [00:55<03:17,  2.14it/s] 16%|█▌        | 79/500 [00:55<02:28,  2.83it/s] 16%|█▌        | 81/500 [01:01<08:28,  1.21s/it] 17%|█▋        | 83/500 [01:02<06:05,  1.14it/s] 17%|█▋        | 85/500 [01:02<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:02<03:11,  2.15it/s] 18%|█▊        | 89/500 [01:02<02:22,  2.88it/s] 18%|█▊        | 91/500 [01:08<08:12,  1.20s/it] 19%|█▊        | 93/500 [01:08<05:51,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:12,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.95it/s] 20%|██        | 101/500 [01:15<07:57,  1.20s/it] 21%|██        | 103/500 [01:15<05:40,  1.17it/s] 21%|██        | 105/500 [01:16<04:04,  1.61it/s] 21%|██▏       | 107/500 [01:16<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:16<02:12,  2.96it/s] 22%|██▏       | 111/500 [01:22<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:22<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:23<02:57,  2.16it/s] 24%|██▍       | 119/500 [01:23<02:10,  2.91it/s] 24%|██▍       | 121/500 [01:29<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:30<02:52,  2.16it/s] 26%|██▌       | 129/500 [01:30<02:10,  2.85it/s] 26%|██▌       | 131/500 [01:36<07:23,  1.20s/it] 27%|██▋       | 133/500 [01:36<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:47,  2.16it/s] 28%|██▊       | 139/500 [01:37<02:05,  2.87it/s] 28%|██▊       | 141/500 [01:43<07:15,  1.21s/it] 29%|██▊       | 143/500 [01:43<05:10,  1.15it/s]Epoch:  74  	Training Loss: 0.0238860622048378
Test Loss:  0.007693850435316563
Valid Loss:  0.014356449246406555
Epoch:  75  	Training Loss: 0.023841749876737595
Test Loss:  0.0076505038887262344
Valid Loss:  0.014302666299045086
Epoch:  76  	Training Loss: 0.02380027249455452
Test Loss:  0.007612455636262894
Valid Loss:  0.01425221562385559
Epoch:  77  	Training Loss: 0.023761440068483353
Test Loss:  0.0075777554884552956
Valid Loss:  0.014204885810613632
Epoch:  78  	Training Loss: 0.023725226521492004
Test Loss:  0.007547126151621342
Valid Loss:  0.014161896891891956
Epoch:  79  	Training Loss: 0.023693960160017014
Test Loss:  0.007520983926951885
Valid Loss:  0.014122184365987778
Epoch:  80  	Training Loss: 0.023665256798267365
Test Loss:  0.007496836129575968
Valid Loss:  0.01408483274281025
Epoch:  81  	Training Loss: 0.023638948798179626
Test Loss:  0.007475951686501503
Valid Loss:  0.014050900936126709
Epoch:  82  	Training Loss: 0.023616092279553413
Test Loss:  0.007458613719791174
Valid Loss:  0.014020821079611778
Epoch:  83  	Training Loss: 0.02359633520245552
Test Loss:  0.0074425917118787766
Valid Loss:  0.01399359479546547
Epoch:  84  	Training Loss: 0.023577801883220673
Test Loss:  0.007428068667650223
Valid Loss:  0.013968370854854584
Epoch:  85  	Training Loss: 0.023561030626296997
Test Loss:  0.007414655759930611
Valid Loss:  0.013944554142653942
Epoch:  86  	Training Loss: 0.023545388132333755
Test Loss:  0.007403657305985689
Valid Loss:  0.013922919519245625
Epoch:  87  	Training Loss: 0.023531267419457436
Test Loss:  0.007394189015030861
Valid Loss:  0.013903522863984108
Epoch:  88  	Training Loss: 0.023518424481153488
Test Loss:  0.007386081852018833
Valid Loss:  0.013885186985135078
Epoch:  89  	Training Loss: 0.023506544530391693
Test Loss:  0.007378810551017523
Valid Loss:  0.013868284411728382
Epoch:  90  	Training Loss: 0.023495646193623543
Test Loss:  0.0073721702210605145
Valid Loss:  0.013853069394826889
Epoch:  91  	Training Loss: 0.023485394194722176
Test Loss:  0.007366114761680365
Valid Loss:  0.013838673010468483
Epoch:  92  	Training Loss: 0.02347588911652565
Test Loss:  0.007360619492828846
Valid Loss:  0.013825725764036179
Epoch:  93  	Training Loss: 0.023466985672712326
Test Loss:  0.0073557752184569836
Valid Loss:  0.013814231380820274
Epoch:  94  	Training Loss: 0.023459266871213913
Test Loss:  0.0073514156974852085
Valid Loss:  0.013803532347083092
Epoch:  95  	Training Loss: 0.02345217391848564
Test Loss:  0.007347416132688522
Valid Loss:  0.013793360441923141
Epoch:  96  	Training Loss: 0.023445457220077515
Test Loss:  0.00734375324100256
Valid Loss:  0.013783685863018036
Epoch:  97  	Training Loss: 0.02343909442424774
Test Loss:  0.007340406067669392
Valid Loss:  0.013774478808045387
Epoch:  98  	Training Loss: 0.02343318983912468
Test Loss:  0.007337406277656555
Valid Loss:  0.013765901327133179
Epoch:  99  	Training Loss: 0.023427721112966537
Test Loss:  0.00733466912060976
Valid Loss:  0.013757734559476376
Epoch:  100  	Training Loss: 0.023422544822096825
Test Loss:  0.007332175504416227
Valid Loss:  0.013749947771430016
Epoch:  101  	Training Loss: 0.023417629301548004
Test Loss:  0.007329909130930901
Valid Loss:  0.01374252699315548
Epoch:  102  	Training Loss: 0.02341296523809433
Test Loss:  0.007327997125685215
Valid Loss:  0.013735577464103699
Epoch:  103  	Training Loss: 0.023408889770507812
Test Loss:  0.007326317019760609
Valid Loss:  0.013729463331401348
Epoch:  104  	Training Loss: 0.02340521663427353
Test Loss:  0.0073248157277703285
Valid Loss:  0.013723677024245262
Epoch:  105  	Training Loss: 0.02340174838900566
Test Loss:  0.007323477417230606
Valid Loss:  0.013718163594603539
Epoch:  106  	Training Loss: 0.023398466408252716
Test Loss:  0.007322316989302635
Valid Loss:  0.013713043183088303
Epoch:  107  	Training Loss: 0.02339552901685238
Test Loss:  0.007321291137486696
Valid Loss:  0.013708159327507019
Epoch:  108  	Training Loss: 0.023392830044031143
Test Loss:  0.007320411968976259
Valid Loss:  0.013703735545277596
Epoch:  109  	Training Loss: 0.023390470072627068
Test Loss:  0.007319638971239328
Valid Loss:  0.01369950920343399
Epoch:  110  	Training Loss: 0.02338823489844799
Test Loss:  0.007318960502743721
Valid Loss:  0.013695461675524712
Epoch:  111  	Training Loss: 0.023386109620332718
Test Loss:  0.007318370975553989
Valid Loss:  0.013691598549485207
Epoch:  112  	Training Loss: 0.02338411472737789
Test Loss:  0.0073178596794605255
Valid Loss:  0.013687980361282825
Epoch:  113  	Training Loss: 0.02338229864835739
Test Loss:  0.007317420560866594
Valid Loss:  0.01368451677262783
Epoch:  114  	Training Loss: 0.023380577564239502
Test Loss:  0.007317046169191599
Valid Loss:  0.013681197538971901
Epoch:  115  	Training Loss: 0.023378940299153328
Test Loss:  0.007316813804209232
Valid Loss:  0.013678018935024738
Epoch:  116  	Training Loss: 0.02337738685309887
Test Loss:  0.0073167323134839535
Valid Loss:  0.013674966059625149
Epoch:  117  	Training Loss: 0.02337590605020523
Test Loss:  0.007316696457564831
Valid Loss:  0.013672039844095707
Epoch:  118  	Training Loss: 0.023374497890472412
Test Loss:  0.007316702976822853
Valid Loss:  0.013669230043888092
Epoch:  119  	Training Loss: 0.023373162373900414
Test Loss:  0.007316745817661285
Valid Loss:  0.013666538521647453
Epoch:  120  	Training Loss: 0.023371893912553787
Test Loss:  0.007316819857805967
Valid Loss:  0.013663951307535172
Epoch:  121  	Training Loss: 0.023370714858174324
Test Loss:  0.007316905073821545
Valid Loss:  0.013661541044712067
Epoch:  122  	Training Loss: 0.023369628936052322
Test Loss:  0.00731701822951436
Valid Loss:  0.013659225776791573
Epoch:  123  	Training Loss: 0.023368600755929947
Test Loss:  0.00731715327128768
Valid Loss:  0.013656999915838242
Epoch:  124  	Training Loss: 0.0233676228672266
Test Loss:  0.007317309267818928
Valid Loss:  0.013654854148626328
Epoch:  125  	Training Loss: 0.023366689682006836
Test Loss:  0.007317482493817806
Valid Loss:  0.013652791269123554
Epoch:  126  	Training Loss: 0.023365799337625504
Test Loss:  0.007317671552300453
Valid Loss:  0.01365080289542675
Epoch:  127  	Training Loss: 0.023364948108792305
Test Loss:  0.007317873649299145
Valid Loss:  0.013648884370923042
Epoch:  128  	Training Loss: 0.023364130407571793
Test Loss:  0.007318087853491306
Valid Loss:  0.013647036626935005
Epoch:  129  	Training Loss: 0.023363355547189713
Test Loss:  0.007318314164876938
Valid Loss:  0.013645254075527191
Epoch:  130  	Training Loss: 0.02336260676383972
Test Loss:  0.007318549323827028
Valid Loss:  0.013643533922731876
Epoch:  131  	Training Loss: 0.023361897096037865
Test Loss:  0.007318790536373854
Valid Loss:  0.013641871511936188
Epoch:  132  	Training Loss: 0.023361215367913246
Test Loss:  0.007319033145904541
Valid Loss:  0.013640258461236954
Epoch:  133  	Training Loss: 0.023360542953014374
Test Loss:  0.007319278549402952
Valid Loss:  0.013638697564601898
Epoch:  134  	Training Loss: 0.02335989475250244
Test Loss:  0.0073195286095142365
Valid Loss:  0.01363719254732132
Epoch:  135  	Training Loss: 0.023359276354312897
Test Loss:  0.007319784257560968
Valid Loss:  0.013635734096169472
Epoch:  136  	Training Loss: 0.02335868403315544
Test Loss:  0.00732004176825285
Valid Loss:  0.013634325936436653
Epoch:  137  	Training Loss: 0.023358114063739777
Test Loss:  0.00732029601931572
Valid Loss:  0.01363296341150999
Epoch:  138  	Training Loss: 0.023357566446065903
Test Loss:  0.007320554461330175
Valid Loss:  0.01363164372742176
Epoch:  139  	Training Loss: 0.02335703745484352
Test Loss:  0.007320811040699482
Valid Loss:  0.013630364090204239
Epoch:  140  	Training Loss: 0.02335653081536293
Test Loss:  0.007321068085730076
Valid Loss:  0.01362912543118
Epoch:  141  	Training Loss: 0.023356039077043533
Test Loss:  0.007321320939809084
Valid Loss:  0.013627924025058746
Epoch:  142  	Training Loss: 0.023355569690465927
Test Loss:  0.007321581710129976
Valid Loss:  0.013626785948872566
Epoch:  143  	Training Loss: 0.023355135694146156
Test Loss:  0.007321839686483145
Valid Loss:  0.013625679537653923
Epoch:  144  	Training Loss: 0.02335471846163273
Test Loss:   29%|██▉       | 145/500 [01:44<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:44<02:44,  2.15it/s] 30%|██▉       | 149/500 [01:44<02:04,  2.83it/s] 30%|███       | 151/500 [01:50<06:57,  1.20s/it] 31%|███       | 153/500 [01:50<04:57,  1.17it/s] 31%|███       | 155/500 [01:50<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:51<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:57<06:44,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:27,  1.61it/s] 33%|███▎      | 167/500 [01:58<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:58<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:04<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:04<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:04<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:04<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:04<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:11<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:11<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:11<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:11<02:20,  2.24it/s] 38%|███▊      | 189/500 [02:11<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:18<06:06,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:18<02:16,  2.21it/s] 40%|███▉      | 199/500 [02:18<01:41,  2.97it/s] 40%|████      | 201/500 [02:25<06:03,  1.22s/it] 41%|████      | 203/500 [02:25<04:21,  1.14it/s] 41%|████      | 205/500 [02:25<03:09,  1.55it/s] 41%|████▏     | 207/500 [02:25<02:17,  2.13it/s] 42%|████▏     | 209/500 [02:25<01:41,  2.87it/s] 42%|████▏     | 211/500 [02:32<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:32<04:05,  1.17it/s]0.0073220934718847275
Valid Loss:  0.013624602928757668
Epoch:  145  	Training Loss: 0.023354316130280495
Test Loss:  0.007322345394641161
Valid Loss:  0.013623560778796673
Epoch:  146  	Training Loss: 0.023353928700089455
Test Loss:  0.007322591729462147
Valid Loss:  0.013622548431158066
Epoch:  147  	Training Loss: 0.02335355244576931
Test Loss:  0.007322834338992834
Valid Loss:  0.013621567748486996
Epoch:  148  	Training Loss: 0.023353196680545807
Test Loss:  0.007323071360588074
Valid Loss:  0.013620611280202866
Epoch:  149  	Training Loss: 0.023352844640612602
Test Loss:  0.007323301397264004
Valid Loss:  0.013619677163660526
Epoch:  150  	Training Loss: 0.023352503776550293
Test Loss:  0.007323527242988348
Valid Loss:  0.013618771918118
Epoch:  151  	Training Loss: 0.02335217036306858
Test Loss:  0.007323745638132095
Valid Loss:  0.01361788995563984
Epoch:  152  	Training Loss: 0.023351848125457764
Test Loss:  0.007323957979679108
Valid Loss:  0.013617020100355148
Epoch:  153  	Training Loss: 0.023351533338427544
Test Loss:  0.007324163801968098
Valid Loss:  0.013616170734167099
Epoch:  154  	Training Loss: 0.02335122600197792
Test Loss:  0.00732436403632164
Valid Loss:  0.013615347445011139
Epoch:  155  	Training Loss: 0.023350931704044342
Test Loss:  0.007324556354433298
Valid Loss:  0.013614538125693798
Epoch:  156  	Training Loss: 0.023350637406110764
Test Loss:  0.007324740756303072
Valid Loss:  0.013613748364150524
Epoch:  157  	Training Loss: 0.023350350558757782
Test Loss:  0.0073249186389148235
Valid Loss:  0.013612977229058743
Epoch:  158  	Training Loss: 0.023350071161985397
Test Loss:  0.007325091399252415
Valid Loss:  0.013612224720418453
Epoch:  159  	Training Loss: 0.02334979549050331
Test Loss:  0.007325252518057823
Valid Loss:  0.013611488044261932
Epoch:  160  	Training Loss: 0.023349525406956673
Test Loss:  0.007325409911572933
Valid Loss:  0.013610766269266605
Epoch:  161  	Training Loss: 0.023349260911345482
Test Loss:  0.007325558457523584
Valid Loss:  0.013610059395432472
Epoch:  162  	Training Loss: 0.02334900200366974
Test Loss:  0.007325699552893639
Valid Loss:  0.013609361834824085
Epoch:  163  	Training Loss: 0.023348737508058548
Test Loss:  0.0073258355259895325
Valid Loss:  0.01360868476331234
Epoch:  164  	Training Loss: 0.023348484188318253
Test Loss:  0.00732596218585968
Valid Loss:  0.013608017936348915
Epoch:  165  	Training Loss: 0.023348229005932808
Test Loss:  0.007326081395149231
Valid Loss:  0.013607364147901535
Epoch:  166  	Training Loss: 0.02334798127412796
Test Loss:  0.007326195947825909
Valid Loss:  0.013606720604002476
Epoch:  167  	Training Loss: 0.02334773540496826
Test Loss:  0.007326303981244564
Valid Loss:  0.013606099411845207
Epoch:  168  	Training Loss: 0.02334750071167946
Test Loss:  0.007326402701437473
Valid Loss:  0.013605481013655663
Epoch:  169  	Training Loss: 0.023347262293100357
Test Loss:  0.0073264967650175095
Valid Loss:  0.013604875653982162
Epoch:  170  	Training Loss: 0.023347029462456703
Test Loss:  0.007326584309339523
Valid Loss:  0.013604283332824707
Epoch:  171  	Training Loss: 0.023346802219748497
Test Loss:  0.007326665334403515
Valid Loss:  0.013603702187538147
Epoch:  172  	Training Loss: 0.02334657497704029
Test Loss:  0.007326736114919186
Valid Loss:  0.013603128492832184
Epoch:  173  	Training Loss: 0.023346344009041786
Test Loss:  0.007326803635805845
Valid Loss:  0.013602560386061668
Epoch:  174  	Training Loss: 0.02334611676633358
Test Loss:  0.0073268599808216095
Valid Loss:  0.013602008111774921
Epoch:  175  	Training Loss: 0.023345891386270523
Test Loss:  0.007326912600547075
Valid Loss:  0.013601459562778473
Epoch:  176  	Training Loss: 0.023345667868852615
Test Loss:  0.007326963357627392
Valid Loss:  0.013600924983620644
Epoch:  177  	Training Loss: 0.023345449939370155
Test Loss:  0.007326956372708082
Valid Loss:  0.013600419275462627
Epoch:  178  	Training Loss: 0.023345233872532845
Test Loss:  0.007326946593821049
Valid Loss:  0.013599921017885208
Epoch:  179  	Training Loss: 0.023345019668340683
Test Loss:  0.007326931692659855
Valid Loss:  0.013599432073533535
Epoch:  180  	Training Loss: 0.02334480732679367
Test Loss:  0.007326912600547075
Valid Loss:  0.01359894871711731
Epoch:  181  	Training Loss: 0.023344600573182106
Test Loss:  0.007326886057853699
Valid Loss:  0.013598469085991383
Epoch:  182  	Training Loss: 0.023344390094280243
Test Loss:  0.00732686510309577
Valid Loss:  0.013598009012639523
Epoch:  183  	Training Loss: 0.02334420196712017
Test Loss:  0.007326836697757244
Valid Loss:  0.013597553595900536
Epoch:  184  	Training Loss: 0.02334401197731495
Test Loss:  0.007326803635805845
Valid Loss:  0.013597102835774422
Epoch:  185  	Training Loss: 0.023343823850154877
Test Loss:  0.0073267677798867226
Valid Loss:  0.013596659526228905
Epoch:  186  	Training Loss: 0.023343639448285103
Test Loss:  0.0073267268016934395
Valid Loss:  0.013596219010651112
Epoch:  187  	Training Loss: 0.02334345318377018
Test Loss:  0.0073266830295324326
Valid Loss:  0.013595787808299065
Epoch:  188  	Training Loss: 0.023343272507190704
Test Loss:  0.007326635532081127
Valid Loss:  0.013595359399914742
Epoch:  189  	Training Loss: 0.02334308996796608
Test Loss:  0.0073265815153717995
Valid Loss:  0.013594934716820717
Epoch:  190  	Training Loss: 0.023342909291386604
Test Loss:  0.007326527498662472
Valid Loss:  0.013594520278275013
Epoch:  191  	Training Loss: 0.023342739790678024
Test Loss:  0.007326468825340271
Valid Loss:  0.013594105839729309
Epoch:  192  	Training Loss: 0.023342560976743698
Test Loss:  0.007326408289372921
Valid Loss:  0.013593696989119053
Epoch:  193  	Training Loss: 0.023342391476035118
Test Loss:  0.0073263440281152725
Valid Loss:  0.013593289069831371
Epoch:  194  	Training Loss: 0.023342221975326538
Test Loss:  0.007326275110244751
Valid Loss:  0.013592887669801712
Epoch:  195  	Training Loss: 0.023342054337263107
Test Loss:  0.007326205261051655
Valid Loss:  0.013592490926384926
Epoch:  196  	Training Loss: 0.023341886699199677
Test Loss:  0.007326129358261824
Valid Loss:  0.013592099770903587
Epoch:  197  	Training Loss: 0.023341717198491096
Test Loss:  0.007326052524149418
Valid Loss:  0.013591710478067398
Epoch:  198  	Training Loss: 0.023341555148363113
Test Loss:  0.007325969636440277
Valid Loss:  0.013591324910521507
Epoch:  199  	Training Loss: 0.023341387510299683
Test Loss:  0.0073258839547634125
Valid Loss:  0.013590941205620766
Epoch:  200  	Training Loss: 0.02334122359752655
Test Loss:  0.007325798273086548
Valid Loss:  0.013590559363365173
Epoch:  201  	Training Loss: 0.02334105782210827
Test Loss:  0.007325706072151661
Valid Loss:  0.013590183109045029
Epoch:  202  	Training Loss: 0.023340893909335136
Test Loss:  0.007325613871216774
Valid Loss:  0.013589812442660332
Epoch:  203  	Training Loss: 0.023340735584497452
Test Loss:  0.007325518410652876
Valid Loss:  0.013589439913630486
Epoch:  204  	Training Loss: 0.02334057167172432
Test Loss:  0.007325466256588697
Valid Loss:  0.013589052483439445
Epoch:  205  	Training Loss: 0.023340411484241486
Test Loss:  0.0073254164308309555
Valid Loss:  0.013588668778538704
Epoch:  206  	Training Loss: 0.02334025874733925
Test Loss:  0.007325358223170042
Valid Loss:  0.013588286936283112
Epoch:  207  	Training Loss: 0.023340098559856415
Test Loss:  0.0073252953588962555
Valid Loss:  0.013587907887995243
Epoch:  208  	Training Loss: 0.023339934647083282
Test Loss:  0.007325233891606331
Valid Loss:  0.013587535358965397
Epoch:  209  	Training Loss: 0.023339783772826195
Test Loss:  0.007325164042413235
Valid Loss:  0.013587163761258125
Epoch:  210  	Training Loss: 0.02333962544798851
Test Loss:  0.007325092796236277
Valid Loss:  0.013586794957518578
Epoch:  211  	Training Loss: 0.023339467123150826
Test Loss:  0.007325020618736744
Valid Loss:  0.013586432673037052
Epoch:  212  	Training Loss: 0.023339316248893738
Test Loss:  0.007324925623834133
Valid Loss:  0.013586046174168587
Epoch:  213  	Training Loss: 0.02333911880850792
Test Loss:  0.007324833422899246
Valid Loss:  0.013585668057203293
Epoch:  214  	Training Loss: 0.02333892695605755
Test Loss:   43%|████▎     | 215/500 [02:32<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:32<02:07,  2.21it/s] 44%|████▍     | 219/500 [02:32<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:39<05:30,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:39<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:39<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:39<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:45<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:46<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:46<01:29,  2.93it/s] 48%|████▊     | 241/500 [02:52<05:11,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:53<01:55,  2.19it/s] 50%|████▉     | 249/500 [02:53<01:25,  2.93it/s] 50%|█████     | 251/500 [02:59<04:55,  1.19s/it] 51%|█████     | 253/500 [02:59<03:30,  1.17it/s] 51%|█████     | 255/500 [03:00<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:00<01:49,  2.21it/s] 52%|█████▏    | 259/500 [03:00<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:06<04:49,  1.21s/it] 53%|█████▎    | 263/500 [03:06<03:26,  1.15it/s] 53%|█████▎    | 265/500 [03:07<02:27,  1.59it/s] 53%|█████▎    | 267/500 [03:07<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:07<01:18,  2.93it/s] 54%|█████▍    | 271/500 [03:13<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:13<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:13<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:14<01:15,  2.92it/s] 56%|█████▌    | 281/500 [03:20<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:20<03:06,  1.16it/s]0.0073247370310127735
Valid Loss:  0.013585289940237999
Epoch:  215  	Training Loss: 0.023338736966252327
Test Loss:  0.007324635982513428
Valid Loss:  0.013584911823272705
Epoch:  216  	Training Loss: 0.023338548839092255
Test Loss:  0.007324532605707645
Valid Loss:  0.013584541156888008
Epoch:  217  	Training Loss: 0.023338358849287033
Test Loss:  0.007324426434934139
Valid Loss:  0.013584173284471035
Epoch:  218  	Training Loss: 0.023338166996836662
Test Loss:  0.007324317004531622
Valid Loss:  0.013583803549408913
Epoch:  219  	Training Loss: 0.02333797514438629
Test Loss:  0.007324204780161381
Valid Loss:  0.013583440333604813
Epoch:  220  	Training Loss: 0.02333778515458107
Test Loss:  0.007324093021452427
Valid Loss:  0.013583079911768436
Epoch:  221  	Training Loss: 0.023337598890066147
Test Loss:  0.007323975674808025
Valid Loss:  0.013582720421254635
Epoch:  222  	Training Loss: 0.023337410762906075
Test Loss:  0.007323869038373232
Valid Loss:  0.013582384213805199
Epoch:  223  	Training Loss: 0.02333725616335869
Test Loss:  0.007323759142309427
Valid Loss:  0.013582048006355762
Epoch:  224  	Training Loss: 0.023337097838521004
Test Loss:  0.007323647849261761
Valid Loss:  0.013581719249486923
Epoch:  225  	Training Loss: 0.023336943238973618
Test Loss:  0.007323531433939934
Valid Loss:  0.013581388629972935
Epoch:  226  	Training Loss: 0.02333679050207138
Test Loss:  0.007323416881263256
Valid Loss:  0.013581059873104095
Epoch:  227  	Training Loss: 0.023336635902523994
Test Loss:  0.00732329860329628
Valid Loss:  0.013580736704170704
Epoch:  228  	Training Loss: 0.02333648130297661
Test Loss:  0.007323176600039005
Valid Loss:  0.013580409809947014
Epoch:  229  	Training Loss: 0.023336324840784073
Test Loss:  0.00732305645942688
Valid Loss:  0.013580087572336197
Epoch:  230  	Training Loss: 0.023336172103881836
Test Loss:  0.007322932127863169
Valid Loss:  0.013579769060015678
Epoch:  231  	Training Loss: 0.023336021229624748
Test Loss:  0.007322806864976883
Valid Loss:  0.013579453341662884
Epoch:  232  	Training Loss: 0.02333587035536766
Test Loss:  0.0073226760141551495
Valid Loss:  0.013579128310084343
Epoch:  233  	Training Loss: 0.023335708305239677
Test Loss:  0.007322544232010841
Valid Loss:  0.013578805141150951
Epoch:  234  	Training Loss: 0.023335549980401993
Test Loss:  0.007322408724576235
Valid Loss:  0.013578485697507858
Epoch:  235  	Training Loss: 0.02333538979291916
Test Loss:  0.007322274148464203
Valid Loss:  0.013578166253864765
Epoch:  236  	Training Loss: 0.023335229605436325
Test Loss:  0.00732213631272316
Valid Loss:  0.013577846810221672
Epoch:  237  	Training Loss: 0.023335067555308342
Test Loss:  0.0073219966143369675
Valid Loss:  0.013577532954514027
Epoch:  238  	Training Loss: 0.023334909230470657
Test Loss:  0.007321859709918499
Valid Loss:  0.013577218167483807
Epoch:  239  	Training Loss: 0.023334749042987823
Test Loss:  0.007321716286242008
Valid Loss:  0.013576907105743885
Epoch:  240  	Training Loss: 0.023334596306085587
Test Loss:  0.007321573793888092
Valid Loss:  0.013576596975326538
Epoch:  241  	Training Loss: 0.02333443984389305
Test Loss:  0.007321431301534176
Valid Loss:  0.013576291501522064
Epoch:  242  	Training Loss: 0.023334285244345665
Test Loss:  0.0073213037103414536
Valid Loss:  0.013576017692685127
Epoch:  243  	Training Loss: 0.02333417721092701
Test Loss:  0.007321175653487444
Valid Loss:  0.013575748540461063
Epoch:  244  	Training Loss: 0.023334072902798653
Test Loss:  0.007321047596633434
Valid Loss:  0.013575481250882149
Epoch:  245  	Training Loss: 0.023333970457315445
Test Loss:  0.0073209176771342754
Valid Loss:  0.013575214892625809
Epoch:  246  	Training Loss: 0.023333869874477386
Test Loss:  0.00732078542932868
Valid Loss:  0.01357494667172432
Epoch:  247  	Training Loss: 0.02333376184105873
Test Loss:  0.007320651784539223
Valid Loss:  0.013574682176113129
Epoch:  248  	Training Loss: 0.023333657532930374
Test Loss:  0.007320520468056202
Valid Loss:  0.013574420474469662
Epoch:  249  	Training Loss: 0.023333558812737465
Test Loss:  0.007320386357605457
Valid Loss:  0.01357415784150362
Epoch:  250  	Training Loss: 0.023333456367254257
Test Loss:  0.007320251315832138
Valid Loss:  0.013573895208537579
Epoch:  251  	Training Loss: 0.02333335392177105
Test Loss:  0.007320112083107233
Valid Loss:  0.013573633506894112
Epoch:  252  	Training Loss: 0.023333247750997543
Test Loss:  0.007319959811866283
Valid Loss:  0.01357334665954113
Epoch:  253  	Training Loss: 0.023333100602030754
Test Loss:  0.007319806143641472
Valid Loss:  0.013573057949543
Epoch:  254  	Training Loss: 0.023332955315709114
Test Loss:  0.007319651544094086
Valid Loss:  0.013572773896157742
Epoch:  255  	Training Loss: 0.023332808166742325
Test Loss:  0.00731949508190155
Valid Loss:  0.013572487980127335
Epoch:  256  	Training Loss: 0.023332662880420685
Test Loss:  0.007319340482354164
Valid Loss:  0.01357220858335495
Epoch:  257  	Training Loss: 0.023332523182034492
Test Loss:  0.007319183088839054
Valid Loss:  0.013571924529969692
Epoch:  258  	Training Loss: 0.023332376033067703
Test Loss:  0.007319025229662657
Valid Loss:  0.013571644201874733
Epoch:  259  	Training Loss: 0.023332230746746063
Test Loss:  0.007318866439163685
Valid Loss:  0.013571362942457199
Epoch:  260  	Training Loss: 0.02333208918571472
Test Loss:  0.007318707183003426
Valid Loss:  0.013571083545684814
Epoch:  261  	Training Loss: 0.02333194389939308
Test Loss:  0.007318546995520592
Valid Loss:  0.01357080414891243
Epoch:  262  	Training Loss: 0.02333179861307144
Test Loss:  0.007318384945392609
Valid Loss:  0.013570519164204597
Epoch:  263  	Training Loss: 0.023331649601459503
Test Loss:  0.00731821870431304
Valid Loss:  0.01357023324817419
Epoch:  264  	Training Loss: 0.023331496864557266
Test Loss:  0.007318058051168919
Valid Loss:  0.013569949194788933
Epoch:  265  	Training Loss: 0.023331347852945328
Test Loss:  0.007317893672734499
Valid Loss:  0.013569667935371399
Epoch:  266  	Training Loss: 0.02333119884133339
Test Loss:  0.0073177265003323555
Valid Loss:  0.013569386675953865
Epoch:  267  	Training Loss: 0.02333104982972145
Test Loss:  0.007317562587559223
Valid Loss:  0.013569105416536331
Epoch:  268  	Training Loss: 0.023330900818109512
Test Loss:  0.007317395880818367
Valid Loss:  0.013568826019763947
Epoch:  269  	Training Loss: 0.023330753669142723
Test Loss:  0.007317228242754936
Valid Loss:  0.013568542897701263
Epoch:  270  	Training Loss: 0.023330599069595337
Test Loss:  0.007317060604691505
Valid Loss:  0.013568263500928879
Epoch:  271  	Training Loss: 0.0233304500579834
Test Loss:  0.0073168920353055
Valid Loss:  0.013567985966801643
Epoch:  272  	Training Loss: 0.02333030104637146
Test Loss:  0.007316723000258207
Valid Loss:  0.013567709363996983
Epoch:  273  	Training Loss: 0.02333015203475952
Test Loss:  0.0073165553621947765
Valid Loss:  0.01356743648648262
Epoch:  274  	Training Loss: 0.023330003023147583
Test Loss:  0.007316385395824909
Valid Loss:  0.013567161746323109
Epoch:  275  	Training Loss: 0.023329854011535645
Test Loss:  0.007316215429455042
Valid Loss:  0.013566887006163597
Epoch:  276  	Training Loss: 0.023329701274633408
Test Loss:  0.0073160445317626
Valid Loss:  0.013566612266004086
Epoch:  277  	Training Loss: 0.02332955226302147
Test Loss:  0.007315873168408871
Valid Loss:  0.013566343113780022
Epoch:  278  	Training Loss: 0.02332940325140953
Test Loss:  0.007315703202039003
Valid Loss:  0.01356606837362051
Epoch:  279  	Training Loss: 0.023329254239797592
Test Loss:  0.007315532770007849
Valid Loss:  0.013565801084041595
Epoch:  280  	Training Loss: 0.0233291108161211
Test Loss:  0.007315363734960556
Valid Loss:  0.013565530069172382
Epoch:  281  	Training Loss: 0.023328963667154312
Test Loss:  0.007315192371606827
Valid Loss:  0.013565261848270893
Epoch:  282  	Training Loss: 0.023328816518187523
Test Loss:  0.007315023802220821
Valid Loss:  0.013564997352659702
Epoch:  283  	Training Loss: 0.02332867681980133
Test Loss:  0.007314855698496103
Valid Loss:  0.013564735651016235
Epoch:  284  	Training Loss: 0.023328542709350586
Test Loss:  0.007314685732126236
Valid Loss:   57%|█████▋    | 285/500 [03:20<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:21<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:21<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:27<04:07,  1.19s/it] 59%|█████▊    | 293/500 [03:27<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:27<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:27<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:28<01:07,  2.98it/s] 60%|██████    | 301/500 [03:34<03:55,  1.18s/it] 61%|██████    | 303/500 [03:34<02:47,  1.18it/s] 61%|██████    | 305/500 [03:34<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:34<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:34<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:41<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:41<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:41<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:41<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:41<01:01,  2.94it/s] 64%|██████▍   | 321/500 [03:48<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:48<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:48<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:48<01:18,  2.22it/s] 66%|██████▌   | 329/500 [03:48<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:55<03:20,  1.18s/it] 67%|██████▋   | 333/500 [03:55<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:55<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:55<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:55<00:53,  2.99it/s] 68%|██████▊   | 341/500 [04:01<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:01<02:12,  1.18it/s] 69%|██████▉   | 345/500 [04:02<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:02<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:02<00:50,  3.00it/s] 70%|███████   | 351/500 [04:08<02:55,  1.18s/it] 71%|███████   | 353/500 [04:08<02:04,  1.18it/s]0.013564474880695343
Epoch:  285  	Training Loss: 0.023328404873609543
Test Loss:  0.007314517628401518
Valid Loss:  0.0135642159730196
Epoch:  286  	Training Loss: 0.023328272625803947
Test Loss:  0.0073143495246768
Valid Loss:  0.013563950546085835
Epoch:  287  	Training Loss: 0.023328132927417755
Test Loss:  0.0073141795583069324
Valid Loss:  0.013563691638410091
Epoch:  288  	Training Loss: 0.02332799881696701
Test Loss:  0.00731401052325964
Valid Loss:  0.013563434593379498
Epoch:  289  	Training Loss: 0.023327864706516266
Test Loss:  0.007313840091228485
Valid Loss:  0.01356317289173603
Epoch:  290  	Training Loss: 0.02332773059606552
Test Loss:  0.00731367152184248
Valid Loss:  0.01356291864067316
Epoch:  291  	Training Loss: 0.023327592760324478
Test Loss:  0.007313501089811325
Valid Loss:  0.013562660664319992
Epoch:  292  	Training Loss: 0.023327458649873734
Test Loss:  0.007313331589102745
Valid Loss:  0.013562406413257122
Epoch:  293  	Training Loss: 0.02332732453942299
Test Loss:  0.007313161622732878
Valid Loss:  0.013562152162194252
Epoch:  294  	Training Loss: 0.023327192291617393
Test Loss:  0.007312992587685585
Valid Loss:  0.013561898842453957
Epoch:  295  	Training Loss: 0.0233270563185215
Test Loss:  0.007312821224331856
Valid Loss:  0.013561645522713661
Epoch:  296  	Training Loss: 0.023326922208070755
Test Loss:  0.007312651723623276
Valid Loss:  0.013561395928263664
Epoch:  297  	Training Loss: 0.02332679182291031
Test Loss:  0.007312482222914696
Valid Loss:  0.013561148196458817
Epoch:  298  	Training Loss: 0.023326661437749863
Test Loss:  0.007312311325222254
Valid Loss:  0.013560894876718521
Epoch:  299  	Training Loss: 0.023326527327299118
Test Loss:  0.0073121413588523865
Valid Loss:  0.013560641556978226
Epoch:  300  	Training Loss: 0.023326393216848373
Test Loss:  0.007311970926821232
Valid Loss:  0.013560392893850803
Epoch:  301  	Training Loss: 0.023326262831687927
Test Loss:  0.007311799097806215
Valid Loss:  0.013560142368078232
Epoch:  302  	Training Loss: 0.023326128721237183
Test Loss:  0.007311629131436348
Valid Loss:  0.013559889048337936
Epoch:  303  	Training Loss: 0.023325996473431587
Test Loss:  0.007311456836760044
Valid Loss:  0.013559640385210514
Epoch:  304  	Training Loss: 0.023325862362980843
Test Loss:  0.007311288733035326
Valid Loss:  0.013559389859437943
Epoch:  305  	Training Loss: 0.023325730115175247
Test Loss:  0.007311117369681597
Valid Loss:  0.013559142127633095
Epoch:  306  	Training Loss: 0.023325597867369652
Test Loss:  0.007310946471989155
Valid Loss:  0.013558892533183098
Epoch:  307  	Training Loss: 0.023325465619564056
Test Loss:  0.007310776039958
Valid Loss:  0.013558645732700825
Epoch:  308  	Training Loss: 0.023325331509113312
Test Loss:  0.007310603279620409
Valid Loss:  0.013558397069573402
Epoch:  309  	Training Loss: 0.023325201123952866
Test Loss:  0.007310433313250542
Valid Loss:  0.013558149337768555
Epoch:  310  	Training Loss: 0.02332506701350212
Test Loss:  0.007310263812541962
Valid Loss:  0.013557901605963707
Epoch:  311  	Training Loss: 0.023324932903051376
Test Loss:  0.007310094777494669
Valid Loss:  0.013557660393416882
Epoch:  312  	Training Loss: 0.02332480624318123
Test Loss:  0.007309908978641033
Valid Loss:  0.01355738379061222
Epoch:  313  	Training Loss: 0.0233246348798275
Test Loss:  0.007309724576771259
Valid Loss:  0.013557110913097858
Epoch:  314  	Training Loss: 0.02332445979118347
Test Loss:  0.0073095387779176235
Valid Loss:  0.01355684082955122
Epoch:  315  	Training Loss: 0.02332429215312004
Test Loss:  0.007309353910386562
Valid Loss:  0.013556568883359432
Epoch:  316  	Training Loss: 0.02332412265241146
Test Loss:  0.007309170439839363
Valid Loss:  0.013556299731135368
Epoch:  317  	Training Loss: 0.023323949426412582
Test Loss:  0.007308985106647015
Valid Loss:  0.01355602778494358
Epoch:  318  	Training Loss: 0.023323778063058853
Test Loss:  0.007308801636099815
Valid Loss:  0.01355576142668724
Epoch:  319  	Training Loss: 0.02332361415028572
Test Loss:  0.0073086172342300415
Valid Loss:  0.013555488549172878
Epoch:  320  	Training Loss: 0.02332344278693199
Test Loss:  0.00730843236669898
Valid Loss:  0.013555221259593964
Epoch:  321  	Training Loss: 0.023323271423578262
Test Loss:  0.007308248896151781
Valid Loss:  0.013554956763982773
Epoch:  322  	Training Loss: 0.02332310751080513
Test Loss:  0.007308055646717548
Valid Loss:  0.01355467177927494
Epoch:  323  	Training Loss: 0.02332291193306446
Test Loss:  0.0073078591376543045
Valid Loss:  0.013554386794567108
Epoch:  324  	Training Loss: 0.023322712630033493
Test Loss:  0.0073076654225587845
Valid Loss:  0.013554104603827
Epoch:  325  	Training Loss: 0.023322518914937973
Test Loss:  0.007307471241801977
Valid Loss:  0.013553822413086891
Epoch:  326  	Training Loss: 0.023322325199842453
Test Loss:  0.007307276129722595
Valid Loss:  0.013553541153669357
Epoch:  327  	Training Loss: 0.023322127759456635
Test Loss:  0.007307083811610937
Valid Loss:  0.013553259894251823
Epoch:  328  	Training Loss: 0.023321934044361115
Test Loss:  0.007306886836886406
Valid Loss:  0.01355297677218914
Epoch:  329  	Training Loss: 0.023321734741330147
Test Loss:  0.0073066940531134605
Valid Loss:  0.013552695512771606
Epoch:  330  	Training Loss: 0.023321542888879776
Test Loss:  0.007306499406695366
Valid Loss:  0.013552416115999222
Epoch:  331  	Training Loss: 0.023321347311139107
Test Loss:  0.007306305691599846
Valid Loss:  0.013552134856581688
Epoch:  332  	Training Loss: 0.023321153596043587
Test Loss:  0.007306145504117012
Valid Loss:  0.01355191133916378
Epoch:  333  	Training Loss: 0.02332104742527008
Test Loss:  0.007305982988327742
Valid Loss:  0.013551688753068447
Epoch:  334  	Training Loss: 0.023320941254496574
Test Loss:  0.007305819541215897
Valid Loss:  0.013551462441682816
Epoch:  335  	Training Loss: 0.023320835083723068
Test Loss:  0.007305661216378212
Valid Loss:  0.013551244512200356
Epoch:  336  	Training Loss: 0.02332073450088501
Test Loss:  0.007305499631911516
Valid Loss:  0.013551020063459873
Epoch:  337  	Training Loss: 0.023320624604821205
Test Loss:  0.00730533804744482
Valid Loss:  0.013550795614719391
Epoch:  338  	Training Loss: 0.023320522159337997
Test Loss:  0.0073051778599619865
Valid Loss:  0.013550573959946632
Epoch:  339  	Training Loss: 0.023320414125919342
Test Loss:  0.007305016741156578
Valid Loss:  0.013550352305173874
Epoch:  340  	Training Loss: 0.023320309817790985
Test Loss:  0.007304857950657606
Valid Loss:  0.013550134375691414
Epoch:  341  	Training Loss: 0.023320209234952927
Test Loss:  0.007304697297513485
Valid Loss:  0.01354991178959608
Epoch:  342  	Training Loss: 0.02332010492682457
Test Loss:  0.007304532919079065
Valid Loss:  0.0135496836155653
Epoch:  343  	Training Loss: 0.02331998571753502
Test Loss:  0.0073043666779994965
Valid Loss:  0.013549450784921646
Epoch:  344  	Training Loss: 0.02331986092031002
Test Loss:  0.007304200902581215
Valid Loss:  0.01354922354221344
Epoch:  345  	Training Loss: 0.02331974171102047
Test Loss:  0.007304036989808083
Valid Loss:  0.013548994436860085
Epoch:  346  	Training Loss: 0.023319624364376068
Test Loss:  0.007303871680051088
Valid Loss:  0.013548767194151878
Epoch:  347  	Training Loss: 0.023319507017731667
Test Loss:  0.007303708698600531
Valid Loss:  0.013548541814088821
Epoch:  348  	Training Loss: 0.023319385945796967
Test Loss:  0.007303543388843536
Valid Loss:  0.013548314571380615
Epoch:  349  	Training Loss: 0.023319266736507416
Test Loss:  0.00730337668210268
Valid Loss:  0.01354808360338211
Epoch:  350  	Training Loss: 0.023319145664572716
Test Loss:  0.007303212303668261
Valid Loss:  0.013547858223319054
Epoch:  351  	Training Loss: 0.023319028317928314
Test Loss:  0.007303050719201565
Valid Loss:  0.013547632843255997
Epoch:  352  	Training Loss: 0.023318910971283913
Test Loss:  0.007302883081138134
Valid Loss:  0.013547400012612343
Epoch:  353  	Training Loss: 0.023318784311413765
Test Loss:  0.0073027173057198524
Valid Loss:  0.013547170907258987
Epoch:  354  	Training Loss: 0.023318659514188766
Test Loss:  0.007302550598978996
Valid Loss:  0.013546937145292759
 71%|███████   | 355/500 [04:08<01:29,  1.63it/s] 71%|███████▏  | 357/500 [04:09<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:09<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:15<02:47,  1.21s/it] 73%|███████▎  | 363/500 [04:15<01:59,  1.15it/s] 73%|███████▎  | 365/500 [04:16<01:25,  1.58it/s] 73%|███████▎  | 367/500 [04:16<01:01,  2.16it/s] 74%|███████▍  | 369/500 [04:16<00:45,  2.91it/s] 74%|███████▍  | 371/500 [04:22<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:22<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:23<01:18,  1.60it/s] 75%|███████▌  | 377/500 [04:23<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:23<00:41,  2.90it/s] 76%|███████▌  | 381/500 [04:29<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:29<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:29<01:12,  1.60it/s] 77%|███████▋  | 387/500 [04:30<00:52,  2.15it/s] 78%|███████▊  | 389/500 [04:30<00:39,  2.84it/s] 78%|███████▊  | 391/500 [04:36<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:36<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:36<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:37<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:37<00:34,  2.95it/s] 80%|████████  | 401/500 [04:43<01:57,  1.19s/it] 81%|████████  | 403/500 [04:43<01:22,  1.17it/s] 81%|████████  | 405/500 [04:43<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:43<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:44<00:31,  2.91it/s] 82%|████████▏ | 411/500 [04:50<01:45,  1.19s/it] 83%|████████▎ | 413/500 [04:50<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:50<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:50<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:51<00:27,  2.92it/s] 84%|████████▍ | 421/500 [04:57<01:35,  1.21s/it] 85%|████████▍ | 423/500 [04:57<01:06,  1.15it/s]Epoch:  355  	Training Loss: 0.02331852726638317
Test Loss:  0.007302383426576853
Valid Loss:  0.013546706177294254
Epoch:  356  	Training Loss: 0.023318402469158173
Test Loss:  0.007302220445126295
Valid Loss:  0.013546474277973175
Epoch:  357  	Training Loss: 0.023318279534578323
Test Loss:  0.007302054204046726
Valid Loss:  0.01354624517261982
Epoch:  358  	Training Loss: 0.023318152874708176
Test Loss:  0.007301887031644583
Valid Loss:  0.01354601513594389
Epoch:  359  	Training Loss: 0.023318026214838028
Test Loss:  0.007301722187548876
Valid Loss:  0.013545784167945385
Epoch:  360  	Training Loss: 0.023317895829677582
Test Loss:  0.007301556412130594
Valid Loss:  0.013545555993914604
Epoch:  361  	Training Loss: 0.023317772895097733
Test Loss:  0.007301392499357462
Valid Loss:  0.013545326888561249
Epoch:  362  	Training Loss: 0.023317651823163033
Test Loss:  0.007301231846213341
Valid Loss:  0.013545108959078789
Epoch:  363  	Training Loss: 0.02331753633916378
Test Loss:  0.007301069796085358
Valid Loss:  0.013544885441660881
Epoch:  364  	Training Loss: 0.02331741526722908
Test Loss:  0.0073009068146348
Valid Loss:  0.013544665649533272
Epoch:  365  	Training Loss: 0.023317303508520126
Test Loss:  0.007300748489797115
Valid Loss:  0.013544447720050812
Epoch:  366  	Training Loss: 0.023317188024520874
Test Loss:  0.007300587836652994
Valid Loss:  0.013544226065278053
Epoch:  367  	Training Loss: 0.02331707254052162
Test Loss:  0.007300426717847586
Valid Loss:  0.013544004410505295
Epoch:  368  	Training Loss: 0.02331695705652237
Test Loss:  0.0073002660647034645
Valid Loss:  0.013543786481022835
Epoch:  369  	Training Loss: 0.023316843435168266
Test Loss:  0.007300104480236769
Valid Loss:  0.013543566688895226
Epoch:  370  	Training Loss: 0.023316724225878716
Test Loss:  0.007299946155399084
Valid Loss:  0.013543348759412766
Epoch:  371  	Training Loss: 0.023316610604524612
Test Loss:  0.007299785502254963
Valid Loss:  0.013543128967285156
Epoch:  372  	Training Loss: 0.02331649884581566
Test Loss:  0.007299627177417278
Valid Loss:  0.013542911037802696
Epoch:  373  	Training Loss: 0.023316379636526108
Test Loss:  0.0072994655929505825
Valid Loss:  0.013542691245675087
Epoch:  374  	Training Loss: 0.023316262289881706
Test Loss:  0.0072993068024516106
Valid Loss:  0.013542471453547478
Epoch:  375  	Training Loss: 0.023316144943237305
Test Loss:  0.007299146614968777
Valid Loss:  0.013542255386710167
Epoch:  376  	Training Loss: 0.023316029459238052
Test Loss:  0.0072989873588085175
Valid Loss:  0.013542034663259983
Epoch:  377  	Training Loss: 0.0233159139752388
Test Loss:  0.007298830430954695
Valid Loss:  0.013541820459067822
Epoch:  378  	Training Loss: 0.023315800353884697
Test Loss:  0.007298671640455723
Valid Loss:  0.013541599735617638
Epoch:  379  	Training Loss: 0.023315683007240295
Test Loss:  0.007298511918634176
Valid Loss:  0.013541385531425476
Epoch:  380  	Training Loss: 0.023315567523241043
Test Loss:  0.007298353593796492
Valid Loss:  0.013541167601943016
Epoch:  381  	Training Loss: 0.02331545203924179
Test Loss:  0.007298195734620094
Valid Loss:  0.01354095246642828
Epoch:  382  	Training Loss: 0.02331533655524254
Test Loss:  0.007298056967556477
Valid Loss:  0.013540768064558506
Epoch:  383  	Training Loss: 0.023315273225307465
Test Loss:  0.00729791447520256
Valid Loss:  0.013540578074753284
Epoch:  384  	Training Loss: 0.023315202444791794
Test Loss:  0.007297775242477655
Valid Loss:  0.013540392741560936
Epoch:  385  	Training Loss: 0.02331513538956642
Test Loss:  0.007297634147107601
Valid Loss:  0.013540204614400864
Epoch:  386  	Training Loss: 0.0233150664716959
Test Loss:  0.007297494448721409
Valid Loss:  0.01354001834988594
Epoch:  387  	Training Loss: 0.02331499755382538
Test Loss:  0.00729735754430294
Valid Loss:  0.013539833948016167
Epoch:  388  	Training Loss: 0.023314932361245155
Test Loss:  0.007297217845916748
Valid Loss:  0.013539649546146393
Epoch:  389  	Training Loss: 0.023314863443374634
Test Loss:  0.007297078147530556
Valid Loss:  0.013539462350308895
Epoch:  390  	Training Loss: 0.023314792662858963
Test Loss:  0.007296940311789513
Valid Loss:  0.01353927981108427
Epoch:  391  	Training Loss: 0.02331473119556904
Test Loss:  0.00729680061340332
Valid Loss:  0.013539096340537071
Epoch:  392  	Training Loss: 0.023314660415053368
Test Loss:  0.007296649739146233
Valid Loss:  0.013538888655602932
Epoch:  393  	Training Loss: 0.02331455796957016
Test Loss:  0.0072965011931955814
Valid Loss:  0.013538684695959091
Epoch:  394  	Training Loss: 0.0233144573867321
Test Loss:  0.007296348921954632
Valid Loss:  0.013538477942347527
Epoch:  395  	Training Loss: 0.023314353078603745
Test Loss:  0.007296198047697544
Valid Loss:  0.013538271188735962
Epoch:  396  	Training Loss: 0.023314250633120537
Test Loss:  0.007296048104763031
Valid Loss:  0.013538066297769547
Epoch:  397  	Training Loss: 0.02331415005028248
Test Loss:  0.007295896764844656
Valid Loss:  0.013537859544157982
Epoch:  398  	Training Loss: 0.023314043879508972
Test Loss:  0.007295746356248856
Valid Loss:  0.013537655584514141
Epoch:  399  	Training Loss: 0.023313941434025764
Test Loss:  0.00729559687897563
Valid Loss:  0.013537449762225151
Epoch:  400  	Training Loss: 0.023313838988542557
Test Loss:  0.007295449264347553
Valid Loss:  0.01353724766522646
Epoch:  401  	Training Loss: 0.023313742130994797
Test Loss:  0.0072952983900904655
Valid Loss:  0.01353704184293747
Epoch:  402  	Training Loss: 0.02331363782286644
Test Loss:  0.007295145187526941
Valid Loss:  0.01353683415800333
Epoch:  403  	Training Loss: 0.023313529789447784
Test Loss:  0.007294995244592428
Valid Loss:  0.013536626473069191
Epoch:  404  	Training Loss: 0.02331342175602913
Test Loss:  0.0072948443703353405
Valid Loss:  0.013536417856812477
Epoch:  405  	Training Loss: 0.023313313722610474
Test Loss:  0.007294692099094391
Valid Loss:  0.013536209240555763
Epoch:  406  	Training Loss: 0.023313205689191818
Test Loss:  0.007294543087482452
Valid Loss:  0.013536003418266773
Epoch:  407  	Training Loss: 0.023313097655773163
Test Loss:  0.0072943903505802155
Valid Loss:  0.013535792008042336
Epoch:  408  	Training Loss: 0.023312989622354507
Test Loss:  0.007294242735952139
Valid Loss:  0.01353558711707592
Epoch:  409  	Training Loss: 0.023312881588935852
Test Loss:  0.007294091396033764
Valid Loss:  0.013535378500819206
Epoch:  410  	Training Loss: 0.023312775418162346
Test Loss:  0.007293942384421825
Valid Loss:  0.013535174541175365
Epoch:  411  	Training Loss: 0.02331266924738884
Test Loss:  0.007293793372809887
Valid Loss:  0.01353496965020895
Epoch:  412  	Training Loss: 0.023312564939260483
Test Loss:  0.007293642032891512
Valid Loss:  0.013534761033952236
Epoch:  413  	Training Loss: 0.02331245318055153
Test Loss:  0.00729349022731185
Valid Loss:  0.013534555211663246
Epoch:  414  	Training Loss: 0.023312341421842575
Test Loss:  0.007293342612683773
Valid Loss:  0.013534343801438808
Epoch:  415  	Training Loss: 0.02331223152577877
Test Loss:  0.007293190807104111
Valid Loss:  0.013534140773117542
Epoch:  416  	Training Loss: 0.023312121629714966
Test Loss:  0.00729304039850831
Valid Loss:  0.013533933088183403
Epoch:  417  	Training Loss: 0.02331201173365116
Test Loss:  0.007292891386896372
Valid Loss:  0.013533726334571838
Epoch:  418  	Training Loss: 0.023311905562877655
Test Loss:  0.007292742375284433
Valid Loss:  0.013533519580960274
Epoch:  419  	Training Loss: 0.0233117938041687
Test Loss:  0.007292593829333782
Valid Loss:  0.013533315621316433
Epoch:  420  	Training Loss: 0.023311685770750046
Test Loss:  0.007292445749044418
Valid Loss:  0.013533111661672592
Epoch:  421  	Training Loss: 0.02331157773733139
Test Loss:  0.00729229673743248
Valid Loss:  0.013532906770706177
Epoch:  422  	Training Loss: 0.023311467841267586
Test Loss:  0.007292145863175392
Valid Loss:  0.01353269349783659
Epoch:  423  	Training Loss: 0.023311352357268333
Test Loss:  0.0072919949889183044
Valid Loss:  0.013532483018934727
Epoch:  424  	Training Loss: 0.02331123873591423
Test Loss:  0.007291844114661217
Valid Loss:  0.01353226974606514
 85%|████████▌ | 425/500 [04:57<00:46,  1.60it/s] 85%|████████▌ | 427/500 [04:57<00:33,  2.18it/s] 86%|████████▌ | 429/500 [04:58<00:24,  2.92it/s] 86%|████████▌ | 431/500 [05:04<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:04<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:04<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:04<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:05<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:11<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:11<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:11<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:11<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:11<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:18<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:18<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:18<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:18<00:19,  2.18it/s] 92%|█████████▏| 459/500 [05:18<00:14,  2.91it/s] 92%|█████████▏| 461/500 [05:25<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:25<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:25<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:25<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:25<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:32<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:32<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:32<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:32<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:32<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:38<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:39<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:39<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:39<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:39<00:03,  2.96it/s] 98%|█████████▊| 491/500 [05:45<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:45<00:05,  1.17it/s]Epoch:  425  	Training Loss: 0.023311123251914978
Test Loss:  0.007291694171726704
Valid Loss:  0.013532057404518127
Epoch:  426  	Training Loss: 0.023311005905270576
Test Loss:  0.007291546557098627
Valid Loss:  0.013531847856938839
Epoch:  427  	Training Loss: 0.023310892283916473
Test Loss:  0.007291396148502827
Valid Loss:  0.0135316401720047
Epoch:  428  	Training Loss: 0.02331078052520752
Test Loss:  0.007291245274245739
Valid Loss:  0.013531428761780262
Epoch:  429  	Training Loss: 0.023310665041208267
Test Loss:  0.007291171234101057
Valid Loss:  0.01353120245039463
Epoch:  430  	Training Loss: 0.023310557007789612
Test Loss:  0.007291095331311226
Valid Loss:  0.013530980795621872
Epoch:  431  	Training Loss: 0.023310450837016106
Test Loss:  0.007291016168892384
Valid Loss:  0.013530760072171688
Epoch:  432  	Training Loss: 0.0233103446662426
Test Loss:  0.007290939800441265
Valid Loss:  0.013530552387237549
Epoch:  433  	Training Loss: 0.023310251533985138
Test Loss:  0.007290863431990147
Valid Loss:  0.013530345633625984
Epoch:  434  	Training Loss: 0.023310158401727676
Test Loss:  0.007290782872587442
Valid Loss:  0.013530140742659569
Epoch:  435  	Training Loss: 0.023310065269470215
Test Loss:  0.0072907037101686
Valid Loss:  0.013529937714338303
Epoch:  436  	Training Loss: 0.023309975862503052
Test Loss:  0.007290621288120747
Valid Loss:  0.013529729098081589
Epoch:  437  	Training Loss: 0.023309879004955292
Test Loss:  0.007290538400411606
Valid Loss:  0.013529526069760323
Epoch:  438  	Training Loss: 0.02330978773534298
Test Loss:  0.007290455978363752
Valid Loss:  0.013529321178793907
Epoch:  439  	Training Loss: 0.023309696465730667
Test Loss:  0.0072903698310256
Valid Loss:  0.01352912187576294
Epoch:  440  	Training Loss: 0.023309607058763504
Test Loss:  0.007290282286703587
Valid Loss:  0.013528916984796524
Epoch:  441  	Training Loss: 0.023309508338570595
Test Loss:  0.007290194742381573
Valid Loss:  0.013528717681765556
Epoch:  442  	Training Loss: 0.023309417068958282
Test Loss:  0.007290111389011145
Valid Loss:  0.013528523966670036
Epoch:  443  	Training Loss: 0.023309338837862015
Test Loss:  0.00729002570733428
Valid Loss:  0.013528333976864815
Epoch:  444  	Training Loss: 0.023309260606765747
Test Loss:  0.007289938163012266
Valid Loss:  0.01352813933044672
Epoch:  445  	Training Loss: 0.02330917678773403
Test Loss:  0.007289852015674114
Valid Loss:  0.013527949340641499
Epoch:  446  	Training Loss: 0.023309100419282913
Test Loss:  0.0072897630743682384
Valid Loss:  0.013527759350836277
Epoch:  447  	Training Loss: 0.023309020325541496
Test Loss:  0.007289674133062363
Valid Loss:  0.01352757029235363
Epoch:  448  	Training Loss: 0.023308943957090378
Test Loss:  0.007289583329111338
Valid Loss:  0.013527377508580685
Epoch:  449  	Training Loss: 0.023308858275413513
Test Loss:  0.007289491593837738
Valid Loss:  0.013527190312743187
Epoch:  450  	Training Loss: 0.023308781906962395
Test Loss:  0.007289400324225426
Valid Loss:  0.013527004979550838
Epoch:  451  	Training Loss: 0.023308703675866127
Test Loss:  0.007289307191967964
Valid Loss:  0.013526814989745617
Epoch:  452  	Training Loss: 0.02330862730741501
Test Loss:  0.007289204280823469
Valid Loss:  0.013526609167456627
Epoch:  453  	Training Loss: 0.023308519273996353
Test Loss:  0.007289102766662836
Valid Loss:  0.013526404276490211
Epoch:  454  	Training Loss: 0.023308413103222847
Test Loss:  0.007288997061550617
Valid Loss:  0.013526195660233498
Epoch:  455  	Training Loss: 0.02330831065773964
Test Loss:  0.007288890890777111
Valid Loss:  0.013525990769267082
Epoch:  456  	Training Loss: 0.023308202624320984
Test Loss:  0.007288786116987467
Valid Loss:  0.013525785878300667
Epoch:  457  	Training Loss: 0.023308096453547478
Test Loss:  0.007288680411875248
Valid Loss:  0.013525580987334251
Epoch:  458  	Training Loss: 0.02330799028277397
Test Loss:  0.007288573309779167
Valid Loss:  0.01352537889033556
Epoch:  459  	Training Loss: 0.023307885974645615
Test Loss:  0.007288464345037937
Valid Loss:  0.013525178655982018
Epoch:  460  	Training Loss: 0.023307785391807556
Test Loss:  0.007288356311619282
Valid Loss:  0.0135249774903059
Epoch:  461  	Training Loss: 0.0233076810836792
Test Loss:  0.007288247346878052
Valid Loss:  0.013524774461984634
Epoch:  462  	Training Loss: 0.023307576775550842
Test Loss:  0.00728814210742712
Valid Loss:  0.013524588197469711
Epoch:  463  	Training Loss: 0.023307491093873978
Test Loss:  0.007288035005331039
Valid Loss:  0.013524400070309639
Epoch:  464  	Training Loss: 0.023307399824261665
Test Loss:  0.007287929765880108
Valid Loss:  0.013524211943149567
Epoch:  465  	Training Loss: 0.023307308554649353
Test Loss:  0.00728782219812274
Valid Loss:  0.013524024747312069
Epoch:  466  	Training Loss: 0.02330721914768219
Test Loss:  0.007287714164704084
Valid Loss:  0.01352383941411972
Epoch:  467  	Training Loss: 0.023307127878069878
Test Loss:  0.007287607062608004
Valid Loss:  0.013523654080927372
Epoch:  468  	Training Loss: 0.023307044059038162
Test Loss:  0.007287497632205486
Valid Loss:  0.013523468747735023
Epoch:  469  	Training Loss: 0.0233069509267807
Test Loss:  0.007287387736141682
Valid Loss:  0.0135232824832201
Epoch:  470  	Training Loss: 0.023306861519813538
Test Loss:  0.007287278771400452
Valid Loss:  0.013523096218705177
Epoch:  471  	Training Loss: 0.023306772112846375
Test Loss:  0.007287168875336647
Valid Loss:  0.013522910885512829
Epoch:  472  	Training Loss: 0.02330668270587921
Test Loss:  0.00728705944493413
Valid Loss:  0.01352272741496563
Epoch:  473  	Training Loss: 0.023306595161557198
Test Loss:  0.007286949548870325
Valid Loss:  0.013522543013095856
Epoch:  474  	Training Loss: 0.023306503891944885
Test Loss:  0.007286837324500084
Valid Loss:  0.013522360473871231
Epoch:  475  	Training Loss: 0.023306414484977722
Test Loss:  0.007286727428436279
Valid Loss:  0.013522177003324032
Epoch:  476  	Training Loss: 0.023306328803300858
Test Loss:  0.007286616135388613
Valid Loss:  0.013521993532776833
Epoch:  477  	Training Loss: 0.023306239396333694
Test Loss:  0.007286504376679659
Valid Loss:  0.013521810993552208
Epoch:  478  	Training Loss: 0.02330614998936653
Test Loss:  0.007286392152309418
Valid Loss:  0.013521628454327583
Epoch:  479  	Training Loss: 0.023306062445044518
Test Loss:  0.00728627759963274
Valid Loss:  0.013521443121135235
Epoch:  480  	Training Loss: 0.023305965587496758
Test Loss:  0.007286163978278637
Valid Loss:  0.013521263375878334
Epoch:  481  	Training Loss: 0.023305878043174744
Test Loss:  0.00728605268523097
Valid Loss:  0.013521082699298859
Epoch:  482  	Training Loss: 0.02330579236149788
Test Loss:  0.0072859423235058784
Valid Loss:  0.01352089736610651
Epoch:  483  	Training Loss: 0.023305702954530716
Test Loss:  0.007285831030458212
Valid Loss:  0.01352071575820446
Epoch:  484  	Training Loss: 0.023305619135499
Test Loss:  0.007285719737410545
Valid Loss:  0.013520529493689537
Epoch:  485  	Training Loss: 0.023305535316467285
Test Loss:  0.007285616360604763
Valid Loss:  0.013520345091819763
Epoch:  486  	Training Loss: 0.02330544963479042
Test Loss:  0.007285518571734428
Valid Loss:  0.013520164415240288
Epoch:  487  	Training Loss: 0.023305363953113556
Test Loss:  0.0072854203172028065
Valid Loss:  0.013519978150725365
Epoch:  488  	Training Loss: 0.02330527827143669
Test Loss:  0.007285322528332472
Valid Loss:  0.013519799336791039
Epoch:  489  	Training Loss: 0.023305192589759827
Test Loss:  0.007285221014171839
Valid Loss:  0.013519616797566414
Epoch:  490  	Training Loss: 0.023305106908082962
Test Loss:  0.0072851236909627914
Valid Loss:  0.01351943425834179
Epoch:  491  	Training Loss: 0.023305023089051247
Test Loss:  0.007285023108124733
Valid Loss:  0.01351925265043974
Epoch:  492  	Training Loss: 0.023304931819438934
Test Loss:  0.007284924853593111
Valid Loss:  0.013519084081053734
Epoch:  493  	Training Loss: 0.023304857313632965
Test Loss:  0.007284824270755053
Valid Loss:  0.013518910855054855
Epoch:  494  	Training Loss: 0.0233047753572464
Test Loss:  0.007284724153578281
Valid Loss:  0.0135187404230237
Epoch:  495  	Training Loss: 0.023304695263504982
 99%|█████████▉| 495/500 [05:46<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:46<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:46<00:00,  2.95it/s]100%|██████████| 500/500 [05:46<00:00,  1.44it/s]
Test Loss:  0.007284626364707947
Valid Loss:  0.013518569990992546
Epoch:  496  	Training Loss: 0.023304617032408714
Test Loss:  0.007284524850547314
Valid Loss:  0.013518398627638817
Epoch:  497  	Training Loss: 0.023304536938667297
Test Loss:  0.0072844261303544044
Valid Loss:  0.013518229126930237
Epoch:  498  	Training Loss: 0.02330445684492588
Test Loss:  0.007284327410161495
Valid Loss:  0.013518059626221657
Epoch:  499  	Training Loss: 0.023304376751184464
Test Loss:  0.007284225896000862
Valid Loss:  0.013517891988158226
Epoch:  500  	Training Loss: 0.023304298520088196
Test Loss:  0.007284127175807953
Valid Loss:  0.013517718762159348
seed is  13
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:19,  6.29s/it]  1%|          | 3/500 [00:06<13:57,  1.68s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<11:04,  1.36s/it]  3%|▎         | 13/500 [00:13<07:32,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:45,  2.15it/s]  4%|▍         | 19/500 [00:13<02:44,  2.93it/s]  4%|▍         | 21/500 [00:20<09:44,  1.22s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:26<12:27,  1.57s/it]  5%|▌         | 27/500 [00:26<08:51,  1.12s/it]  6%|▌         | 29/500 [00:27<06:19,  1.24it/s]  6%|▌         | 31/500 [00:33<11:53,  1.52s/it]  7%|▋         | 33/500 [00:33<08:26,  1.08s/it]  7%|▋         | 35/500 [00:33<06:02,  1.28it/s]  7%|▋         | 37/500 [00:33<04:22,  1.76it/s]  8%|▊         | 39/500 [00:34<03:12,  2.40it/s]  8%|▊         | 41/500 [00:40<09:40,  1.26s/it]  9%|▊         | 43/500 [00:40<06:54,  1.10it/s]  9%|▉         | 45/500 [00:40<04:57,  1.53it/s]  9%|▉         | 47/500 [00:40<03:36,  2.09it/s] 10%|▉         | 49/500 [00:41<02:40,  2.82it/s] 10%|█         | 51/500 [00:47<09:08,  1.22s/it] 11%|█         | 53/500 [00:47<06:31,  1.14it/s] 11%|█         | 55/500 [00:47<04:41,  1.58it/s] 11%|█▏        | 57/500 [00:47<03:25,  2.16it/s] 12%|█▏        | 59/500 [00:48<02:34,  2.86it/s] 12%|█▏        | 61/500 [00:54<08:51,  1.21s/it] 13%|█▎        | 63/500 [00:54<06:18,  1.15it/s] 13%|█▎        | 65/500 [00:54<04:32,  1.60it/s] 13%|█▎        | 67/500 [00:54<03:18,  2.18it/s] 14%|█▍        | 69/500 [00:55<02:28,  2.91it/s]Epoch:  1  	Training Loss: 0.04473323002457619
Test Loss:  2.956246852874756
Valid Loss:  2.978161096572876
Epoch:  2  	Training Loss: 2.7780492305755615
Test Loss:  2964.88525390625
Valid Loss:  2826.20166015625
Epoch:  3  	Training Loss: 3002.544921875
Test Loss:  0.5442416071891785
Valid Loss:  0.5764549374580383
Epoch:  4  	Training Loss: 0.5515416860580444
Test Loss:  0.544169545173645
Valid Loss:  0.5763060450553894
Epoch:  5  	Training Loss: 0.5513402223587036
Test Loss:  0.5440841913223267
Valid Loss:  0.576156735420227
Epoch:  6  	Training Loss: 0.5511393547058105
Test Loss:  0.5439613461494446
Valid Loss:  0.5760033130645752
Epoch:  7  	Training Loss: 0.5509164333343506
Test Loss:  0.5434463024139404
Valid Loss:  0.5755754113197327
Epoch:  8  	Training Loss: 0.5504412055015564
Test Loss:  0.5416290760040283
Valid Loss:  0.5736205577850342
Epoch:  9  	Training Loss: 0.548935055732727
Test Loss:  0.5396842956542969
Valid Loss:  0.5715316534042358
Epoch:  10  	Training Loss: 0.5473415851593018
Test Loss:  0.5377559065818787
Valid Loss:  0.5694629549980164
Epoch:  11  	Training Loss: 0.5457618236541748
Test Loss:  0.5358384251594543
Valid Loss:  0.5674144625663757
Epoch:  12  	Training Loss: 0.5441924929618835
Test Loss:  73.21248626708984
Valid Loss:  70.20909881591797
Epoch:  13  	Training Loss: 67.42399597167969
Test Loss:  0.14095905423164368
Valid Loss:  0.15711338818073273
Epoch:  14  	Training Loss: 0.19808894395828247
Test Loss:  0.04849480837583542
Valid Loss:  0.06936682760715485
Epoch:  15  	Training Loss: 0.1181320771574974
Test Loss:  0.039932671934366226
Valid Loss:  0.06323288381099701
Epoch:  16  	Training Loss: 0.10803452879190445
Test Loss:  0.0354376956820488
Valid Loss:  0.0586954690515995
Epoch:  17  	Training Loss: 0.10168924927711487
Test Loss:  0.031971268355846405
Valid Loss:  0.05506082624197006
Epoch:  18  	Training Loss: 0.09691568464040756
Test Loss:  0.029372883960604668
Valid Loss:  0.0521942675113678
Epoch:  19  	Training Loss: 0.09323504567146301
Test Loss:  0.02732338383793831
Valid Loss:  0.0499008484184742
Epoch:  20  	Training Loss: 0.09030781686306
Test Loss:  0.025686156004667282
Valid Loss:  0.0480475015938282
Epoch:  21  	Training Loss: 0.08792753517627716
Test Loss:  0.024357423186302185
Valid Loss:  0.046502191573381424
Epoch:  22  	Training Loss: 0.08595380187034607
Test Loss:  1.701432704925537
Valid Loss:  1.5194332599639893
Epoch:  23  	Training Loss: 1.6019002199172974
Test Loss:  2.7344541549682617
Valid Loss:  2.975419044494629
Epoch:  24  	Training Loss: 2.261599540710449
Test Loss:  0.01726432703435421
Valid Loss:  0.03109874203801155
Epoch:  25  	Training Loss: 0.05340314656496048
Test Loss:  0.017259061336517334
Valid Loss:  0.031091248616576195
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.05338575690984726
Test Loss:  0.00805271789431572
Valid Loss:  0.013428466394543648
Epoch:  27  	Training Loss: 0.023880377411842346
Test Loss:  0.006948315538465977
Valid Loss:  0.010795303620398045
Epoch:  28  	Training Loss: 0.017144866287708282
Test Loss:  0.005373042076826096
Valid Loss:  0.009402459487318993
Epoch:  29  	Training Loss: 0.016676872968673706
Test Loss:  0.005561837460845709
Valid Loss:  0.009527625516057014
Epoch:  30  	Training Loss: 0.016651522368192673
Test Loss:  0.005508669652044773
Valid Loss:  0.009487991221249104
Epoch:  31  	Training Loss: 0.01665012538433075
Test Loss:  0.005520416423678398
Valid Loss:  0.009496556594967842
Epoch:  32  	Training Loss: 0.016650056466460228
Test Loss:  0.01704404503107071
Valid Loss:  0.01413477398455143
Epoch:  33  	Training Loss: 0.013815252110362053
Test Loss:  0.00436233589425683
Valid Loss:  0.006574700586497784
Epoch:  34  	Training Loss: 0.011288573034107685
Test Loss:  0.010329587385058403
Valid Loss:  0.00847914069890976
Epoch:  35  	Training Loss: 0.009522277861833572
Test Loss:  0.004102935083210468
Valid Loss:  0.0050128852017223835
Epoch:  36  	Training Loss: 0.008311666548252106
Test Loss:  0.0069857072085142136
Valid Loss:  0.005734538193792105
Epoch:  37  	Training Loss: 0.007431895472109318
Test Loss:  0.003942010458558798
Valid Loss:  0.004137921147048473
Epoch:  38  	Training Loss: 0.006759990938007832
Test Loss:  0.0052725994028151035
Valid Loss:  0.004327930044382811
Epoch:  39  	Training Loss: 0.006226008757948875
Test Loss:  0.003726385300979018
Valid Loss:  0.0035505257546901703
Epoch:  40  	Training Loss: 0.0057851821184158325
Test Loss:  0.004308206960558891
Valid Loss:  0.0035394332371652126
Epoch:  41  	Training Loss: 0.0054168300703167915
Test Loss:  0.0034945134539157152
Valid Loss:  0.0031433291733264923
Epoch:  42  	Training Loss: 0.005099431145936251
Test Loss:  0.002383874263614416
Valid Loss:  0.004347027745097876
Epoch:  43  	Training Loss: 0.004915579687803984
Test Loss:  0.0023718986194580793
Valid Loss:  0.002798747271299362
Epoch:  44  	Training Loss: 0.004387921653687954
Test Loss:  0.002124977298080921
Valid Loss:  0.002952096750959754
Epoch:  45  	Training Loss: 0.004344668239355087
Test Loss:  0.0021726961713284254
Valid Loss:  0.0028881686739623547
Epoch:  46  	Training Loss: 0.004339844919741154
Test Loss:  0.002156535629183054
Valid Loss:  0.002904490800574422
Epoch:  47  	Training Loss: 0.0043374598026275635
Test Loss:  0.0021592197008430958
Valid Loss:  0.0028997748158872128
Epoch:  48  	Training Loss: 0.004334898665547371
Test Loss:  0.002156323753297329
Valid Loss:  0.0029007059056311846
Epoch:  49  	Training Loss: 0.004331754520535469
Test Loss:  0.0021554389968514442
Valid Loss:  0.002898885402828455
Epoch:  50  	Training Loss: 0.004328276962041855
Test Loss:  0.0021536159329116344
Valid Loss:  0.0028975876048207283
Epoch:  51  	Training Loss: 0.0043244678527116776
Test Loss:  0.00215200730599463
Valid Loss:  0.0028954483568668365
Epoch:  52  	Training Loss: 0.004320243373513222
Test Loss:  0.014725180342793465
Valid Loss:  0.00949938502162695
Epoch:  53  	Training Loss: 0.011191547848284245
Test Loss:  0.012061461806297302
Valid Loss:  0.01790706440806389
Epoch:  54  	Training Loss: 0.02277063950896263
Test Loss:  0.016044676303863525
Valid Loss:  0.010445190593600273
Epoch:  55  	Training Loss: 0.012120687402784824
Test Loss:  0.0028167380951344967
Valid Loss:  0.005349034443497658
Epoch:  56  	Training Loss: 0.007394922897219658
Test Loss:  0.006750186439603567
Valid Loss:  0.004214055836200714
Epoch:  57  	Training Loss: 0.005324767902493477
Test Loss:  0.002145006787031889
Valid Loss:  0.00310501828789711
Epoch:  58  	Training Loss: 0.004363222047686577
Test Loss:  0.004208534490317106
Valid Loss:  0.00294394139200449
Epoch:  59  	Training Loss: 0.0038840232882648706
Test Loss:  0.002417085226625204
Valid Loss:  0.002700868993997574
Epoch:  60  	Training Loss: 0.0036129006184637547
Test Loss:  0.0033499295823276043
Valid Loss:  0.002665701787918806
Epoch:  61  	Training Loss: 0.0034201722592115402
Test Loss:  0.002594149671494961
Valid Loss:  0.002592099364846945
Epoch:  62  	Training Loss: 0.003202706342563033
Test Loss:  0.0025956432800740004
Valid Loss:  0.002523529576137662
Epoch:  63  	Training Loss: 0.002990901470184326
Test Loss:  0.0025966940447688103
Valid Loss:  0.002459164708852768
Epoch:  64  	Training Loss: 0.0027503473684191704
Test Loss:  0.002575450576841831
Valid Loss:  0.0024056716356426477
Epoch:  65  	Training Loss: 0.0025351117365062237
Test Loss:  0.0025485889054834843
Valid Loss:  0.002365047112107277
Epoch:  66  	Training Loss: 0.002343487925827503
Test Loss:  0.002527222502976656
Valid Loss:  0.0023355633020401
Epoch:  67  	Training Loss: 0.002192836720496416
Test Loss:  0.0024980693124234676
Valid Loss:  0.002316587371751666
Epoch:  68  	Training Loss: 0.002090765628963709
Test Loss:  0.0024716686457395554
Valid Loss:  0.002303567947819829
Epoch:  69  	Training Loss: 0.0020235837437212467
Test Loss:  0.0024524927139282227
Valid Loss:  0.002274972852319479
Epoch:  70  	Training Loss: 0.001982412301003933
Test Loss:  0.0024380513932555914
Valid Loss:  0.002254152437672019
Epoch:  71  	Training Loss: 0.0019568628631532192
Test Loss:   14%|█▍        | 71/500 [01:01<08:30,  1.19s/it] 15%|█▍        | 73/500 [01:01<06:05,  1.17it/s] 15%|█▌        | 75/500 [01:01<04:22,  1.62it/s] 15%|█▌        | 77/500 [01:01<03:11,  2.21it/s] 16%|█▌        | 79/500 [01:01<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:08<08:13,  1.18s/it] 17%|█▋        | 83/500 [01:08<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:08<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:08<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:08<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:15<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:15<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:15<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:15<03:03,  2.20it/s] 20%|█▉        | 99/500 [01:15<02:15,  2.95it/s] 20%|██        | 101/500 [01:22<07:57,  1.20s/it] 21%|██        | 103/500 [01:22<05:43,  1.16it/s] 21%|██        | 105/500 [01:22<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:22<03:01,  2.16it/s] 22%|██▏       | 109/500 [01:22<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:29<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:29<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:35<10:02,  1.57s/it] 23%|██▎       | 117/500 [01:35<07:09,  1.12s/it] 24%|██▍       | 119/500 [01:35<05:07,  1.24it/s] 24%|██▍       | 120/500 [01:42<11:14,  1.78s/it] 24%|██▍       | 121/500 [01:48<17:01,  2.70s/it] 25%|██▍       | 123/500 [01:48<10:55,  1.74s/it] 25%|██▌       | 125/500 [01:48<07:17,  1.17s/it] 25%|██▌       | 127/500 [01:49<04:59,  1.24it/s] 26%|██▌       | 129/500 [01:49<03:31,  1.76it/s] 26%|██▌       | 131/500 [01:55<08:37,  1.40s/it] 27%|██▋       | 133/500 [01:55<06:05,  1.00it/s] 27%|██▋       | 135/500 [01:55<04:20,  1.40it/s] 27%|██▋       | 137/500 [01:56<03:07,  1.94it/s]0.0024267658591270447
Valid Loss:  0.0022395371925085783
Epoch:  72  	Training Loss: 0.0019407006911933422
Test Loss:  0.0023961178958415985
Valid Loss:  0.0022451430559158325
Epoch:  73  	Training Loss: 0.0019272946519777179
Test Loss:  0.002368818037211895
Valid Loss:  0.0022515838500112295
Epoch:  74  	Training Loss: 0.0019157563801854849
Test Loss:  0.0023443703539669514
Valid Loss:  0.0022587236016988754
Epoch:  75  	Training Loss: 0.0019057425670325756
Test Loss:  0.0023224453907459974
Valid Loss:  0.0022665238939225674
Epoch:  76  	Training Loss: 0.0018970516975969076
Test Loss:  0.002302748616784811
Valid Loss:  0.0022745796013623476
Epoch:  77  	Training Loss: 0.00188951357267797
Test Loss:  0.002285037888213992
Valid Loss:  0.0022827512584626675
Epoch:  78  	Training Loss: 0.001882967771962285
Test Loss:  0.0022691250778734684
Valid Loss:  0.002290938748046756
Epoch:  79  	Training Loss: 0.0018772828625515103
Test Loss:  0.002254901919513941
Valid Loss:  0.002299061743542552
Epoch:  80  	Training Loss: 0.0018723977264016867
Test Loss:  0.0022420603781938553
Valid Loss:  0.0023070531897246838
Epoch:  81  	Training Loss: 0.0018681527581065893
Test Loss:  0.002230440266430378
Valid Loss:  0.0023148762993514538
Epoch:  82  	Training Loss: 0.0018644805531948805
Test Loss:  0.002121875062584877
Valid Loss:  0.0023501727264374495
Epoch:  83  	Training Loss: 0.0018249636050313711
Test Loss:  0.0020680008456110954
Valid Loss:  0.0023642913438379765
Epoch:  84  	Training Loss: 0.0018017931142821908
Test Loss:  0.002032051794230938
Valid Loss:  0.002372284419834614
Epoch:  85  	Training Loss: 0.0017884746193885803
Test Loss:  0.0020073004998266697
Valid Loss:  0.002377892844378948
Epoch:  86  	Training Loss: 0.0017793821170926094
Test Loss:  0.0019885331857949495
Valid Loss:  0.002379142679274082
Epoch:  87  	Training Loss: 0.0017716337461024523
Test Loss:  0.001972867175936699
Valid Loss:  0.002381382044404745
Epoch:  88  	Training Loss: 0.0017664930783212185
Test Loss:  0.0019604964181780815
Valid Loss:  0.002381415106356144
Epoch:  89  	Training Loss: 0.0017628793139010668
Test Loss:  0.0019511457066982985
Valid Loss:  0.0023806586395949125
Epoch:  90  	Training Loss: 0.0017599891871213913
Test Loss:  0.0019434001296758652
Valid Loss:  0.0023763596545904875
Epoch:  91  	Training Loss: 0.001757495105266571
Test Loss:  0.0019367360509932041
Valid Loss:  0.0023705773055553436
Epoch:  92  	Training Loss: 0.0017552135977894068
Test Loss:  0.0019518815679475665
Valid Loss:  0.002331856172531843
Epoch:  93  	Training Loss: 0.0017513514030724764
Test Loss:  0.0019606868736445904
Valid Loss:  0.0023133682552725077
Epoch:  94  	Training Loss: 0.0017500212416052818
Test Loss:  0.0019654599018394947
Valid Loss:  0.0023042229004204273
Epoch:  95  	Training Loss: 0.0017493653576821089
Test Loss:  0.001967988908290863
Valid Loss:  0.0022995811887085438
Epoch:  96  	Training Loss: 0.0017489693127572536
Test Loss:  0.0019692741334438324
Valid Loss:  0.0022971713915467262
Epoch:  97  	Training Loss: 0.001748779439367354
Test Loss:  0.0019699344411492348
Valid Loss:  0.0022958852350711823
Epoch:  98  	Training Loss: 0.0017486487049609423
Test Loss:  0.0019702399149537086
Valid Loss:  0.0022951732389628887
Epoch:  99  	Training Loss: 0.001748562091961503
Test Loss:  0.0019703772850334644
Valid Loss:  0.002294756704941392
Epoch:  100  	Training Loss: 0.0017484873533248901
Test Loss:  0.0019703912548720837
Valid Loss:  0.0022944991942495108
Epoch:  101  	Training Loss: 0.0017484418349340558
Test Loss:  0.0019703535363078117
Valid Loss:  0.0022943296935409307
Epoch:  102  	Training Loss: 0.001748396665789187
Test Loss:  0.001970079494640231
Valid Loss:  0.0022943769581615925
Epoch:  103  	Training Loss: 0.0017482165712863207
Test Loss:  0.001969916746020317
Valid Loss:  0.002294412814080715
Epoch:  104  	Training Loss: 0.001748118083924055
Test Loss:  0.0019698170945048332
Valid Loss:  0.00229443795979023
Epoch:  105  	Training Loss: 0.0017480493988841772
Test Loss:  0.0019697542302310467
Valid Loss:  0.002294453326612711
Epoch:  106  	Training Loss: 0.0017479929374530911
Test Loss:  0.0019697139505296946
Valid Loss:  0.0022944645024836063
Epoch:  107  	Training Loss: 0.0017479420639574528
Test Loss:  0.0019696857780218124
Valid Loss:  0.0022944705560803413
Epoch:  108  	Training Loss: 0.0017478701192885637
Test Loss:  0.001968881580978632
Valid Loss:  0.0022945513483136892
Epoch:  109  	Training Loss: 0.0017476326320320368
Test Loss:  0.0019683854188770056
Valid Loss:  0.0022946081589907408
Epoch:  110  	Training Loss: 0.0017474011983722448
Test Loss:  0.0019680580589920282
Valid Loss:  0.0022946512326598167
Epoch:  111  	Training Loss: 0.00174720271024853
Test Loss:  0.001967828255146742
Valid Loss:  0.0022946810349822044
Epoch:  112  	Training Loss: 0.0017470195889472961
Test Loss:  0.0018835579976439476
Valid Loss:  0.002392466878518462
Epoch:  113  	Training Loss: 0.001748482696712017
Test Loss:  0.001986320596188307
Valid Loss:  0.0022802676539868116
Epoch:  114  	Training Loss: 0.0017505170544609427
Test Loss:  0.0018699023639783263
Valid Loss:  0.0024168500676751137
Epoch:  115  	Training Loss: 0.001753352116793394
Test Loss:  0.0020137426909059286
Valid Loss:  0.002261925023049116
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0017572925426065922
Test Loss:  0.0018608311656862497
Valid Loss:  0.0024332317989319563
Epoch:  117  	Training Loss: 0.001756665762513876
Test Loss:  0.002016431884840131
Valid Loss:  0.002247352385893464
Epoch:  118  	Training Loss: 0.0017574942903593183
Test Loss:  0.0018513323739171028
Valid Loss:  0.002432103268802166
Epoch:  119  	Training Loss: 0.0017558475956320763
Test Loss:  0.002010838594287634
Valid Loss:  0.002240254543721676
Epoch:  120  	Training Loss: 0.0017571225762367249
Test Loss:  0.0018436296377331018
Valid Loss:  0.0024314597249031067
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.001755466335453093
Test Loss:  0.0018435062374919653
Valid Loss:  0.002431251807138324
Epoch:  122  	Training Loss: 0.00175525713711977
Test Loss:  0.0019107784610241652
Valid Loss:  0.002322100568562746
Epoch:  123  	Training Loss: 0.001738567603752017
Test Loss:  0.001909384736791253
Valid Loss:  0.0023236465640366077
Epoch:  124  	Training Loss: 0.0017385556129738688
Test Loss:  0.001909387530758977
Valid Loss:  0.002323591150343418
Epoch:  125  	Training Loss: 0.00173854804597795
Test Loss:  0.0019093682058155537
Valid Loss:  0.0023235641419887543
Epoch:  126  	Training Loss: 0.0017385403625667095
Test Loss:  0.0019093486480414867
Valid Loss:  0.0023235350381582975
Epoch:  127  	Training Loss: 0.0017385331448167562
Test Loss:  0.0019093294395133853
Valid Loss:  0.002323505934327841
Epoch:  128  	Training Loss: 0.0017385254614055157
Test Loss:  0.0019093098817393184
Valid Loss:  0.0023234770633280277
Epoch:  129  	Training Loss: 0.001738517777994275
Test Loss:  0.0019092896254733205
Valid Loss:  0.0023234488908201456
Epoch:  130  	Training Loss: 0.001738510443829
Test Loss:  0.0019092708826065063
Valid Loss:  0.002323420951142907
Epoch:  131  	Training Loss: 0.0017385026440024376
Test Loss:  0.001909250975586474
Valid Loss:  0.002323391381651163
Epoch:  132  	Training Loss: 0.0017384947277605534
Test Loss:  0.001909393584355712
Valid Loss:  0.002318903338164091
Epoch:  133  	Training Loss: 0.0017377472249791026
Test Loss:  0.0019079194171354175
Valid Loss:  0.002316452795639634
Epoch:  134  	Training Loss: 0.0017370295245200396
Test Loss:  0.0019065646920353174
Valid Loss:  0.00231392914429307
Epoch:  135  	Training Loss: 0.0017363340593874454
Test Loss:  0.001905225683003664
Valid Loss:  0.0023114520590752363
Epoch:  136  	Training Loss: 0.0017356602475047112
Test Loss:  0.0019039115868508816
Valid Loss:  0.0023090119939297438
Epoch:  137  	Training Loss: 0.0017350070411339402
Test Loss:  0.001902619143947959
Valid Loss:  0.002306609880179167
Epoch:  138  	Training Loss: 0.001734375488013029
Test Loss:   28%|██▊       | 139/500 [01:56<02:18,  2.61it/s] 28%|██▊       | 141/500 [02:02<07:28,  1.25s/it] 29%|██▊       | 143/500 [02:02<05:21,  1.11it/s] 29%|██▉       | 145/500 [02:03<03:52,  1.53it/s] 29%|██▉       | 147/500 [02:03<02:48,  2.09it/s] 30%|██▉       | 149/500 [02:03<02:04,  2.82it/s] 30%|███       | 151/500 [02:09<07:03,  1.21s/it] 31%|███       | 153/500 [02:09<05:04,  1.14it/s] 31%|███       | 155/500 [02:10<03:40,  1.56it/s] 31%|███▏      | 157/500 [02:10<02:40,  2.13it/s] 32%|███▏      | 159/500 [02:10<01:59,  2.85it/s] 32%|███▏      | 161/500 [02:16<06:48,  1.20s/it] 33%|███▎      | 163/500 [02:16<04:51,  1.16it/s] 33%|███▎      | 165/500 [02:17<03:29,  1.60it/s] 33%|███▎      | 167/500 [02:17<02:32,  2.19it/s] 34%|███▍      | 169/500 [02:17<01:52,  2.93it/s] 34%|███▍      | 171/500 [02:23<06:42,  1.22s/it] 35%|███▍      | 173/500 [02:24<04:46,  1.14it/s] 35%|███▌      | 175/500 [02:24<03:25,  1.58it/s] 35%|███▌      | 177/500 [02:24<02:29,  2.16it/s] 36%|███▌      | 179/500 [02:24<01:51,  2.89it/s] 36%|███▌      | 181/500 [02:30<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:31<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:31<03:16,  1.60it/s] 37%|███▋      | 187/500 [02:31<02:22,  2.19it/s] 38%|███▊      | 189/500 [02:31<01:46,  2.92it/s] 38%|███▊      | 191/500 [02:38<06:20,  1.23s/it] 39%|███▊      | 193/500 [02:38<04:30,  1.13it/s] 39%|███▉      | 195/500 [02:44<07:59,  1.57s/it] 39%|███▉      | 197/500 [02:44<05:41,  1.13s/it] 40%|███▉      | 199/500 [02:44<04:03,  1.23it/s] 40%|████      | 201/500 [02:51<07:36,  1.53s/it] 41%|████      | 203/500 [02:51<05:22,  1.09s/it] 41%|████      | 205/500 [02:51<03:50,  1.28it/s]0.0019013496348634362
Valid Loss:  0.0023042468819767237
Epoch:  139  	Training Loss: 0.0017337624449282885
Test Loss:  0.0019001017790287733
Valid Loss:  0.0023019169457256794
Epoch:  140  	Training Loss: 0.0017331680282950401
Test Loss:  0.0018988747615367174
Valid Loss:  0.002299625426530838
Epoch:  141  	Training Loss: 0.0017325133085250854
Test Loss:  0.0018969631055369973
Valid Loss:  0.002295759040862322
Epoch:  142  	Training Loss: 0.0017313251737505198
Test Loss:  0.0018936017295345664
Valid Loss:  0.002286872360855341
Epoch:  143  	Training Loss: 0.0017248715739697218
Test Loss:  0.00189149659126997
Valid Loss:  0.0022815107367932796
Epoch:  144  	Training Loss: 0.0017214458202943206
Test Loss:  0.0018906521145254374
Valid Loss:  0.002278028056025505
Epoch:  145  	Training Loss: 0.0017193888779729605
Test Loss:  0.0018903720192611217
Valid Loss:  0.002275520469993353
Epoch:  146  	Training Loss: 0.0017179310088977218
Test Loss:  0.0018899680580943823
Valid Loss:  0.0022739083506166935
Epoch:  147  	Training Loss: 0.0017169684870168567
Test Loss:  0.001889319159090519
Valid Loss:  0.002272928599268198
Epoch:  148  	Training Loss: 0.0017161418218165636
Test Loss:  0.0018884451128542423
Valid Loss:  0.0022725227754563093
Epoch:  149  	Training Loss: 0.001715349848382175
Test Loss:  0.0018877193797379732
Valid Loss:  0.0022719567641615868
Epoch:  150  	Training Loss: 0.0017145737074315548
Test Loss:  0.001886988990008831
Valid Loss:  0.00227138539776206
Epoch:  151  	Training Loss: 0.0017138024559244514
Test Loss:  0.001886255107820034
Valid Loss:  0.002270811004564166
Epoch:  152  	Training Loss: 0.0017130364431068301
Test Loss:  0.0018851628992706537
Valid Loss:  0.0022683246061205864
Epoch:  153  	Training Loss: 0.0017124549485743046
Test Loss:  0.001884137513116002
Valid Loss:  0.0022659918759018183
Epoch:  154  	Training Loss: 0.0017119247931987047
Test Loss:  0.0018831726629287004
Valid Loss:  0.002263801172375679
Epoch:  155  	Training Loss: 0.0017114056972786784
Test Loss:  0.0018819444812834263
Valid Loss:  0.0022610053420066833
Epoch:  156  	Training Loss: 0.0017106521409004927
Test Loss:  0.001880795112811029
Valid Loss:  0.002258390188217163
Epoch:  157  	Training Loss: 0.0017099687829613686
Test Loss:  0.0018797186203300953
Valid Loss:  0.002255943138152361
Epoch:  158  	Training Loss: 0.0017093478236347437
Test Loss:  0.0018787094159051776
Valid Loss:  0.0022536504548043013
Epoch:  159  	Training Loss: 0.0017087822780013084
Test Loss:  0.0018777642399072647
Valid Loss:  0.0022515002638101578
Epoch:  160  	Training Loss: 0.0017082656268030405
Test Loss:  0.0018768756417557597
Valid Loss:  0.0022494804579764605
Epoch:  161  	Training Loss: 0.0017077932134270668
Test Loss:  0.001876041293144226
Valid Loss:  0.0022475840523838997
Epoch:  162  	Training Loss: 0.0017073589842766523
Test Loss:  0.0018854166846722364
Valid Loss:  0.002228058874607086
Epoch:  163  	Training Loss: 0.0017057961085811257
Test Loss:  0.001890862826257944
Valid Loss:  0.0022175353951752186
Epoch:  164  	Training Loss: 0.001704996102489531
Test Loss:  0.0018940407317131758
Valid Loss:  0.0022116871550679207
Epoch:  165  	Training Loss: 0.001704384689219296
Test Loss:  0.001895903260447085
Valid Loss:  0.0022083709482103586
Epoch:  166  	Training Loss: 0.0017039342783391476
Test Loss:  0.0018970067612826824
Valid Loss:  0.0022064424119889736
Epoch:  167  	Training Loss: 0.0017035724595189095
Test Loss:  0.001897674286738038
Valid Loss:  0.0022052847780287266
Epoch:  168  	Training Loss: 0.001703245914541185
Test Loss:  0.0018980941968038678
Valid Loss:  0.0022045657970011234
Epoch:  169  	Training Loss: 0.0017029722221195698
Test Loss:  0.0018983681220561266
Valid Loss:  0.002204093150794506
Epoch:  170  	Training Loss: 0.0017027348512783647
Test Loss:  0.0018985843053087592
Valid Loss:  0.0022037408780306578
Epoch:  171  	Training Loss: 0.0017024530097842216
Test Loss:  0.001898753340356052
Valid Loss:  0.0022034705616533756
Epoch:  172  	Training Loss: 0.0017022154061123729
Test Loss:  0.00189258623868227
Valid Loss:  0.0022078787442296743
Epoch:  173  	Training Loss: 0.0017009321600198746
Test Loss:  0.0018879227573052049
Valid Loss:  0.0022108452394604683
Epoch:  174  	Training Loss: 0.00169998942874372
Test Loss:  0.0018843101570382714
Valid Loss:  0.0022127293050289154
Epoch:  175  	Training Loss: 0.0016992446035146713
Test Loss:  0.001881600939668715
Valid Loss:  0.0022137926425784826
Epoch:  176  	Training Loss: 0.0016987239941954613
Test Loss:  0.0018794782226905227
Valid Loss:  0.0022142722737044096
Epoch:  177  	Training Loss: 0.0016982785891741514
Test Loss:  0.0018777886871248484
Valid Loss:  0.002214322332292795
Epoch:  178  	Training Loss: 0.0016978743951767683
Test Loss:  0.0018764311680570245
Valid Loss:  0.0022140606306493282
Epoch:  179  	Training Loss: 0.0016975010512396693
Test Loss:  0.0018753319745883346
Valid Loss:  0.0022135707549750805
Epoch:  180  	Training Loss: 0.0016971537843346596
Test Loss:  0.0018744176486507058
Valid Loss:  0.0022129216231405735
Epoch:  181  	Training Loss: 0.001696830615401268
Test Loss:  0.0018736571073532104
Valid Loss:  0.002212161896750331
Epoch:  182  	Training Loss: 0.0016965343384072185
Test Loss:  0.0018736571073532104
Valid Loss:  0.0022121616639196873
Epoch:  183  	Training Loss: 0.001696533989161253
Test Loss:  0.0018736571073532104
Valid Loss:  0.002212161896750331
Epoch:  184  	Training Loss: 0.001696533989161253
Test Loss:  0.0018736571073532104
Valid Loss:  0.002212161896750331
Epoch:  185  	Training Loss: 0.0016965337563306093
Test Loss:  0.001873657340183854
Valid Loss:  0.0022121616639196873
Epoch:  186  	Training Loss: 0.0016965337563306093
Test Loss:  0.001873657340183854
Valid Loss:  0.0022121616639196873
Epoch:  187  	Training Loss: 0.0016965335234999657
Test Loss:  0.001873657340183854
Valid Loss:  0.0022121616639196873
Epoch:  188  	Training Loss: 0.001696533290669322
Test Loss:  0.0018736575730144978
Valid Loss:  0.0022121616639196873
Epoch:  189  	Training Loss: 0.0016965330578386784
Test Loss:  0.001873657340183854
Valid Loss:  0.0022121616639196873
Epoch:  190  	Training Loss: 0.0016965329414233565
Test Loss:  0.001873657340183854
Valid Loss:  0.0022121616639196873
Epoch:  191  	Training Loss: 0.0016965328250080347
Test Loss:  0.001873657340183854
Valid Loss:  0.0022121616639196873
Epoch:  192  	Training Loss: 0.0016965328250080347
Test Loss:  0.001873614965006709
Valid Loss:  0.002212122781202197
Epoch:  193  	Training Loss: 0.0016965048853307962
Test Loss:  0.0018735716585069895
Valid Loss:  0.002212083898484707
Epoch:  194  	Training Loss: 0.0016964764799922705
Test Loss:  0.0018735285848379135
Valid Loss:  0.002212046179920435
Epoch:  195  	Training Loss: 0.0016964483074843884
Test Loss:  0.0018734862096607685
Valid Loss:  0.0022120079956948757
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0016964203678071499
Test Loss:  0.0018706906121224165
Valid Loss:  0.0022138182539492846
Epoch:  197  	Training Loss: 0.001696151914075017
Test Loss:  0.0018688137643039227
Valid Loss:  0.002214697189629078
Epoch:  198  	Training Loss: 0.0016959416680037975
Test Loss:  0.0018675404135137796
Valid Loss:  0.002214958891272545
Epoch:  199  	Training Loss: 0.0016957614570856094
Test Loss:  0.0018666642718017101
Valid Loss:  0.0022148191928863525
Epoch:  200  	Training Loss: 0.0016955987084656954
Test Loss:  0.001866050879471004
Valid Loss:  0.002214424079284072
Epoch:  201  	Training Loss: 0.0016954485327005386
Test Loss:  0.0018656110623851418
Valid Loss:  0.0022138715721666813
Epoch:  202  	Training Loss: 0.0016953065060079098
Test Loss:  0.0018633297877386212
Valid Loss:  0.0022137132473289967
Epoch:  203  	Training Loss: 0.001694133854471147
Test Loss:  0.001861513126641512
Valid Loss:  0.0022135009057819843
Epoch:  204  	Training Loss: 0.0016930786659941077
Test Loss:  0.0018597966991364956
Valid Loss:  0.0022136359475553036
Epoch:  205  	Training Loss: 0.0016924430383369327
Test Loss:  0.0018583170603960752
Valid Loss:  0.0022137120831757784
 41%|████▏     | 207/500 [02:51<02:45,  1.77it/s] 42%|████▏     | 209/500 [02:51<02:00,  2.41it/s] 42%|████▏     | 211/500 [02:58<05:58,  1.24s/it] 43%|████▎     | 213/500 [02:58<04:15,  1.12it/s] 43%|████▎     | 215/500 [02:58<03:02,  1.56it/s] 43%|████▎     | 217/500 [02:58<02:12,  2.13it/s] 44%|████▍     | 219/500 [02:58<01:37,  2.87it/s] 44%|████▍     | 221/500 [03:04<05:32,  1.19s/it] 45%|████▍     | 223/500 [03:05<03:56,  1.17it/s] 45%|████▌     | 225/500 [03:05<02:49,  1.62it/s] 45%|████▌     | 227/500 [03:05<02:03,  2.21it/s] 46%|████▌     | 229/500 [03:05<01:30,  2.98it/s] 46%|████▌     | 231/500 [03:11<05:18,  1.18s/it] 47%|████▋     | 233/500 [03:11<03:47,  1.18it/s] 47%|████▋     | 235/500 [03:12<02:42,  1.63it/s] 47%|████▋     | 237/500 [03:12<01:58,  2.22it/s] 48%|████▊     | 239/500 [03:12<01:27,  2.98it/s] 48%|████▊     | 241/500 [03:18<05:05,  1.18s/it] 49%|████▊     | 243/500 [03:18<03:37,  1.18it/s] 49%|████▉     | 245/500 [03:18<02:37,  1.62it/s] 49%|████▉     | 247/500 [03:19<01:55,  2.18it/s] 50%|████▉     | 249/500 [03:19<01:25,  2.92it/s] 50%|█████     | 251/500 [03:25<04:56,  1.19s/it] 51%|█████     | 253/500 [03:25<03:31,  1.17it/s] 51%|█████     | 255/500 [03:25<02:31,  1.61it/s] 51%|█████▏    | 257/500 [03:26<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:26<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:32<04:43,  1.18s/it] 53%|█████▎    | 263/500 [03:32<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:32<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:32<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:33<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:39<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:39<03:15,  1.16it/s]Epoch:  206  	Training Loss: 0.0016919627087190747
Test Loss:  0.0018570031970739365
Valid Loss:  0.002213969361037016
Epoch:  207  	Training Loss: 0.0016916784225031734
Test Loss:  0.0018558489391580224
Valid Loss:  0.002214438747614622
Epoch:  208  	Training Loss: 0.0016915189335122705
Test Loss:  0.001855033216997981
Valid Loss:  0.002214557956904173
Epoch:  209  	Training Loss: 0.0016913623549044132
Test Loss:  0.0018543736077845097
Valid Loss:  0.002214517444372177
Epoch:  210  	Training Loss: 0.0016912062419578433
Test Loss:  0.0018537822179496288
Valid Loss:  0.0022144033573567867
Epoch:  211  	Training Loss: 0.0016910635167732835
Test Loss:  0.001853212364949286
Valid Loss:  0.002214331179857254
Epoch:  212  	Training Loss: 0.0016909523401409388
Test Loss:  0.001853218418546021
Valid Loss:  0.0022143186070024967
Epoch:  213  	Training Loss: 0.0016909514088183641
Test Loss:  0.0018532255198806524
Valid Loss:  0.0022143046371638775
Epoch:  214  	Training Loss: 0.0016909511759877205
Test Loss:  0.0018532320391386747
Valid Loss:  0.0022142911329865456
Epoch:  215  	Training Loss: 0.0016909503610804677
Test Loss:  0.001853237859904766
Valid Loss:  0.002214278094470501
Epoch:  216  	Training Loss: 0.0016909493133425713
Test Loss:  0.0018532455433160067
Valid Loss:  0.0022142641246318817
Epoch:  217  	Training Loss: 0.0016909487312659621
Test Loss:  0.001853251364082098
Valid Loss:  0.002214251086115837
Epoch:  218  	Training Loss: 0.0016909482656046748
Test Loss:  0.0018532571848481894
Valid Loss:  0.002214237814769149
Epoch:  219  	Training Loss: 0.0016909469850361347
Test Loss:  0.0018532637041062117
Valid Loss:  0.002214223612099886
Epoch:  220  	Training Loss: 0.0016909465193748474
Test Loss:  0.0018532711546868086
Valid Loss:  0.002214210107922554
Epoch:  221  	Training Loss: 0.0016909458208829165
Test Loss:  0.0018532774411141872
Valid Loss:  0.0022141963709145784
Epoch:  222  	Training Loss: 0.0016909451223909855
Test Loss:  0.001852308982051909
Valid Loss:  0.0022119858767837286
Epoch:  223  	Training Loss: 0.001690099947154522
Test Loss:  0.001851376611739397
Valid Loss:  0.0022098561748862267
Epoch:  224  	Training Loss: 0.0016891940031200647
Test Loss:  0.0018503135070204735
Valid Loss:  0.002207433804869652
Epoch:  225  	Training Loss: 0.0016881513874977827
Test Loss:  0.0018492925446480513
Valid Loss:  0.002205103635787964
Epoch:  226  	Training Loss: 0.0016871674451977015
Test Loss:  0.0018483094172552228
Valid Loss:  0.0022028617095202208
Epoch:  227  	Training Loss: 0.0016862389165908098
Test Loss:  0.0018473619129508734
Valid Loss:  0.0022007038351148367
Epoch:  228  	Training Loss: 0.001685361610725522
Test Loss:  0.001846451312303543
Valid Loss:  0.002198626287281513
Epoch:  229  	Training Loss: 0.0016845206264406443
Test Loss:  0.0018454170785844326
Valid Loss:  0.0021962730679661036
Epoch:  230  	Training Loss: 0.0016834454145282507
Test Loss:  0.0018444233573973179
Valid Loss:  0.0021940094884485006
Epoch:  231  	Training Loss: 0.0016824299236759543
Test Loss:  0.001843467354774475
Valid Loss:  0.002191832521930337
Epoch:  232  	Training Loss: 0.0016814693808555603
Test Loss:  0.0018436018144711852
Valid Loss:  0.002191392006352544
Epoch:  233  	Training Loss: 0.0016814346890896559
Test Loss:  0.0018437276594340801
Valid Loss:  0.002190963365137577
Epoch:  234  	Training Loss: 0.0016814006958156824
Test Loss:  0.0018438464030623436
Valid Loss:  0.0021905475296080112
Epoch:  235  	Training Loss: 0.0016813669353723526
Test Loss:  0.001843957812525332
Valid Loss:  0.0021901431027799845
Epoch:  236  	Training Loss: 0.0016813334077596664
Test Loss:  0.0018440616549924016
Valid Loss:  0.0021897517144680023
Epoch:  237  	Training Loss: 0.0016813015099614859
Test Loss:  0.0018441586289554834
Valid Loss:  0.002189371269196272
Epoch:  238  	Training Loss: 0.0016812693793326616
Test Loss:  0.0018442493164911866
Valid Loss:  0.002189000602811575
Epoch:  239  	Training Loss: 0.0016812379471957684
Test Loss:  0.0018443340668454766
Valid Loss:  0.0021886418107897043
Epoch:  240  	Training Loss: 0.0016812069807201624
Test Loss:  0.0018444131128489971
Valid Loss:  0.0021882914006710052
Epoch:  241  	Training Loss: 0.0016811760142445564
Test Loss:  0.0018444861052557826
Valid Loss:  0.002187950536608696
Epoch:  242  	Training Loss: 0.0016811462119221687
Test Loss:  0.00184474210254848
Valid Loss:  0.0021874364465475082
Epoch:  243  	Training Loss: 0.001681121764704585
Test Loss:  0.0018449921626597643
Valid Loss:  0.0021869351621717215
Epoch:  244  	Training Loss: 0.0016810973174870014
Test Loss:  0.0018452376825734973
Valid Loss:  0.0021864441223442554
Epoch:  245  	Training Loss: 0.0016810750821605325
Test Loss:  0.0018454792443662882
Valid Loss:  0.00218596332706511
Epoch:  246  	Training Loss: 0.0016810523811727762
Test Loss:  0.0018457146361470222
Valid Loss:  0.0021854937076568604
Epoch:  247  	Training Loss: 0.0016810311935842037
Test Loss:  0.0018459457205608487
Valid Loss:  0.0021850354969501495
Epoch:  248  	Training Loss: 0.0016810105880722404
Test Loss:  0.0018461733125150204
Valid Loss:  0.002184587996453047
Epoch:  249  	Training Loss: 0.0016809909138828516
Test Loss:  0.0018463950837031007
Valid Loss:  0.0021841484121978283
Epoch:  250  	Training Loss: 0.0016809719381853938
Test Loss:  0.0018466131296008825
Valid Loss:  0.002183720702305436
Epoch:  251  	Training Loss: 0.0016809531953185797
Test Loss:  0.0018468250054866076
Valid Loss:  0.002183302538469434
Epoch:  252  	Training Loss: 0.001680935500189662
Test Loss:  0.0018475718097761273
Valid Loss:  0.0021781008690595627
Epoch:  253  	Training Loss: 0.0016798865981400013
Test Loss:  0.001848106738179922
Valid Loss:  0.0021734721958637238
Epoch:  254  	Training Loss: 0.001678896602243185
Test Loss:  0.001848459942266345
Valid Loss:  0.0021693245507776737
Epoch:  255  	Training Loss: 0.0016779524739831686
Test Loss:  0.0018486555200070143
Valid Loss:  0.002165581565350294
Epoch:  256  	Training Loss: 0.0016770451329648495
Test Loss:  0.0018487198976799846
Valid Loss:  0.002162179909646511
Epoch:  257  	Training Loss: 0.001676167012192309
Test Loss:  0.00184867181815207
Valid Loss:  0.0021590704564005136
Epoch:  258  	Training Loss: 0.0016753131058067083
Test Loss:  0.0018485310720279813
Valid Loss:  0.0021562082692980766
Epoch:  259  	Training Loss: 0.0016744794556871057
Test Loss:  0.0018483122112229466
Valid Loss:  0.0021535567939281464
Epoch:  260  	Training Loss: 0.0016736413817852736
Test Loss:  0.0018480371218174696
Valid Loss:  0.002151071559637785
Epoch:  261  	Training Loss: 0.0016727698966860771
Test Loss:  0.0018477167468518019
Valid Loss:  0.0021487241610884666
Epoch:  262  	Training Loss: 0.0016718636034056544
Test Loss:  0.001831078203395009
Valid Loss:  0.002162616467103362
Epoch:  263  	Training Loss: 0.0016697964165359735
Test Loss:  0.001823296071961522
Valid Loss:  0.002169583924114704
Epoch:  264  	Training Loss: 0.0016690581105649471
Test Loss:  0.0018195529701188207
Valid Loss:  0.0021728998981416225
Epoch:  265  	Training Loss: 0.001668642507866025
Test Loss:  0.0018177153542637825
Valid Loss:  0.002174368128180504
Epoch:  266  	Training Loss: 0.0016682997811585665
Test Loss:  0.0018167940434068441
Valid Loss:  0.002174935070797801
Epoch:  267  	Training Loss: 0.0016679872060194612
Test Loss:  0.0018163591157644987
Valid Loss:  0.0021750892046839
Epoch:  268  	Training Loss: 0.0016677597304806113
Test Loss:  0.001816148404031992
Valid Loss:  0.0021750745363533497
Epoch:  269  	Training Loss: 0.0016675746301189065
Test Loss:  0.0018160343170166016
Valid Loss:  0.0021749879233539104
Epoch:  270  	Training Loss: 0.0016674112994223833
Test Loss:  0.0018159670289605856
Valid Loss:  0.0021748642902821302
Epoch:  271  	Training Loss: 0.0016672757919877768
Test Loss:  0.0018159246537834406
Valid Loss:  0.0021747294813394547
Epoch:  272  	Training Loss: 0.0016671514604240656
Test Loss:  0.0018159248866140842
Valid Loss:  0.0021747294813394547
Epoch:  273  	Training Loss: 0.0016671174671500921
Test Loss:  0.0018159239552915096
Valid Loss:  0.002174729248508811
Epoch:  274  	Training Loss: 0.001667084638029337
Test Loss:  0.0018159243045374751
 55%|█████▌    | 275/500 [03:39<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:39<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:39<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:46<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:46<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:46<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:46<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:46<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:53<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:53<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:53<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:53<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:53<01:07,  2.97it/s] 60%|██████    | 301/500 [03:59<03:53,  1.17s/it] 61%|██████    | 303/500 [04:00<02:47,  1.18it/s] 61%|██████    | 305/500 [04:06<05:05,  1.57s/it] 61%|██████▏   | 307/500 [04:06<03:35,  1.12s/it] 62%|██████▏   | 309/500 [04:06<02:33,  1.25it/s] 62%|██████▏   | 311/500 [04:13<04:47,  1.52s/it] 63%|██████▎   | 313/500 [04:13<03:23,  1.09s/it] 63%|██████▎   | 315/500 [04:13<02:26,  1.27it/s] 63%|██████▎   | 317/500 [04:13<01:44,  1.75it/s] 64%|██████▍   | 319/500 [04:13<01:16,  2.38it/s] 64%|██████▍   | 321/500 [04:20<03:45,  1.26s/it] 65%|██████▍   | 323/500 [04:20<02:40,  1.10it/s] 65%|██████▌   | 325/500 [04:20<01:55,  1.51it/s] 65%|██████▌   | 327/500 [04:20<01:24,  2.04it/s] 66%|██████▌   | 329/500 [04:21<01:03,  2.71it/s] 66%|██████▌   | 331/500 [04:27<03:25,  1.22s/it] 67%|██████▋   | 333/500 [04:27<02:26,  1.14it/s] 67%|██████▋   | 335/500 [04:27<01:44,  1.58it/s] 67%|██████▋   | 337/500 [04:27<01:15,  2.16it/s] 68%|██████▊   | 339/500 [04:27<00:55,  2.91it/s] 68%|██████▊   | 341/500 [04:34<03:09,  1.19s/it]Valid Loss:  0.0021747294813394547
Epoch:  275  	Training Loss: 0.0016670518089085817
Test Loss:  0.0018159248866140842
Valid Loss:  0.002174729248508811
Epoch:  276  	Training Loss: 0.0016670189797878265
Test Loss:  0.0018159241881221533
Valid Loss:  0.0021747294813394547
Epoch:  277  	Training Loss: 0.0016669868491590023
Test Loss:  0.0018159246537834406
Valid Loss:  0.002174729947000742
Epoch:  278  	Training Loss: 0.0016669546021148562
Test Loss:  0.0018159241881221533
Valid Loss:  0.0021747301798313856
Epoch:  279  	Training Loss: 0.0016669232863932848
Test Loss:  0.001815923722460866
Valid Loss:  0.0021747301798313856
Epoch:  280  	Training Loss: 0.0016668923199176788
Test Loss:  0.0018159239552915096
Valid Loss:  0.0021747297141700983
Epoch:  281  	Training Loss: 0.0016668620519340038
Test Loss:  0.0018159241881221533
Valid Loss:  0.0021747301798313856
Epoch:  282  	Training Loss: 0.0016668320167809725
Test Loss:  0.001817396841943264
Valid Loss:  0.0021719709038734436
Epoch:  283  	Training Loss: 0.0016666617011651397
Test Loss:  0.001818489981815219
Valid Loss:  0.00216972129419446
Epoch:  284  	Training Loss: 0.001666514202952385
Test Loss:  0.001819297089241445
Valid Loss:  0.0021678502671420574
Epoch:  285  	Training Loss: 0.0016663821879774332
Test Loss:  0.0018198901088908315
Valid Loss:  0.00216626632027328
Epoch:  286  	Training Loss: 0.0016662604175508022
Test Loss:  0.0018203279469162226
Valid Loss:  0.002164894947782159
Epoch:  287  	Training Loss: 0.0016661467961966991
Test Loss:  0.0018206456443294883
Valid Loss:  0.0021636872552335262
Epoch:  288  	Training Loss: 0.0016660401597619057
Test Loss:  0.001820879289880395
Valid Loss:  0.002162606455385685
Epoch:  289  	Training Loss: 0.0016659387620165944
Test Loss:  0.0018210464622825384
Valid Loss:  0.002161623677238822
Epoch:  290  	Training Loss: 0.0016658434178680182
Test Loss:  0.0018211669521406293
Valid Loss:  0.0021607177332043648
Epoch:  291  	Training Loss: 0.0016657521482557058
Test Loss:  0.001821253914386034
Valid Loss:  0.002159874187782407
Epoch:  292  	Training Loss: 0.0016656654188409448
Test Loss:  0.0018186287488788366
Valid Loss:  0.0021624481305480003
Epoch:  293  	Training Loss: 0.0016656359657645226
Test Loss:  0.0018178751925006509
Valid Loss:  0.0021631962154060602
Epoch:  294  	Training Loss: 0.0016656338702887297
Test Loss:  0.0018176580779254436
Valid Loss:  0.002163413679227233
Epoch:  295  	Training Loss: 0.0016656334046274424
Test Loss:  0.0018175950972363353
Valid Loss:  0.002163475379347801
Epoch:  296  	Training Loss: 0.001665632938966155
Test Loss:  0.0018175761215388775
Valid Loss:  0.002163495635613799
Epoch:  297  	Training Loss: 0.0016656330553814769
Test Loss:  0.0018175694858655334
Valid Loss:  0.002163501223549247
Epoch:  298  	Training Loss: 0.001665632938966155
Test Loss:  0.0018175680888816714
Valid Loss:  0.0021635042503476143
Epoch:  299  	Training Loss: 0.001665632938966155
Test Loss:  0.001817566342651844
Valid Loss:  0.002163504483178258
Epoch:  300  	Training Loss: 0.0016656324733048677
Test Loss:  0.0018175645964220166
Valid Loss:  0.002163505647331476
Epoch:  301  	Training Loss: 0.0016656325897201896
Test Loss:  0.0018175637815147638
Valid Loss:  0.002163507044315338
Epoch:  302  	Training Loss: 0.0016656324733048677
Test Loss:  0.0018179853213950992
Valid Loss:  0.0021626846864819527
Epoch:  303  	Training Loss: 0.001665588584728539
Test Loss:  0.0018183947540819645
Valid Loss:  0.002161887474358082
Epoch:  304  	Training Loss: 0.0016655471408739686
Test Loss:  0.0018187942914664745
Valid Loss:  0.0021611140109598637
Epoch:  305  	Training Loss: 0.0016655081417411566
Test Loss:  0.0018191838171333075
Valid Loss:  0.002160364529117942
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0016654704231768847
Test Loss:  0.0018192458664998412
Valid Loss:  0.00216005090624094
Epoch:  307  	Training Loss: 0.0016653952188789845
Test Loss:  0.0018193053547292948
Valid Loss:  0.0021597412414848804
Epoch:  308  	Training Loss: 0.0016653197817504406
Test Loss:  0.0018193612340837717
Valid Loss:  0.0021594371646642685
Epoch:  309  	Training Loss: 0.0016652450431138277
Test Loss:  0.0018194152507930994
Valid Loss:  0.0021591365803033113
Epoch:  310  	Training Loss: 0.0016651706537231803
Test Loss:  0.0018194669391959906
Valid Loss:  0.0021588413510471582
Epoch:  311  	Training Loss: 0.0016650962643325329
Test Loss:  0.001819516415707767
Valid Loss:  0.002158551011234522
Epoch:  312  	Training Loss: 0.00166502280626446
Test Loss:  0.0018189558759331703
Valid Loss:  0.002157469978556037
Epoch:  313  	Training Loss: 0.0016645018476992846
Test Loss:  0.0018183839274570346
Valid Loss:  0.002156431321054697
Epoch:  314  	Training Loss: 0.0016639961395412683
Test Loss:  0.0018178018508479
Valid Loss:  0.002155433176085353
Epoch:  315  	Training Loss: 0.0016635059146210551
Test Loss:  0.001817209180444479
Valid Loss:  0.0021544748451560736
Epoch:  316  	Training Loss: 0.0016630305908620358
Test Loss:  0.0018166095251217484
Valid Loss:  0.002153554931282997
Epoch:  317  	Training Loss: 0.0016625678399577737
Test Loss:  0.0018159998580813408
Valid Loss:  0.002152669010683894
Epoch:  318  	Training Loss: 0.00166211964096874
Test Loss:  0.0018153840210288763
Valid Loss:  0.0021518212743103504
Epoch:  319  	Training Loss: 0.0016616838984191418
Test Loss:  0.0018147630617022514
Valid Loss:  0.0021510054357349873
Epoch:  320  	Training Loss: 0.001661259913817048
Test Loss:  0.0018141341861337423
Valid Loss:  0.0021502207964658737
Epoch:  321  	Training Loss: 0.0016608480364084244
Test Loss:  0.0018134994897991419
Valid Loss:  0.00214946735650301
Epoch:  322  	Training Loss: 0.001660447334870696
Test Loss:  0.001814423012547195
Valid Loss:  0.0021475667599588633
Epoch:  323  	Training Loss: 0.0016602887772023678
Test Loss:  0.0018152858829125762
Valid Loss:  0.002145814709365368
Epoch:  324  	Training Loss: 0.0016601511742919683
Test Loss:  0.0018160915933549404
Valid Loss:  0.0021442011930048466
Epoch:  325  	Training Loss: 0.0016600291710346937
Test Loss:  0.00181683711707592
Valid Loss:  0.0021427145693451166
Epoch:  326  	Training Loss: 0.001659921370446682
Test Loss:  0.001817540847696364
Valid Loss:  0.00214134412817657
Epoch:  327  	Training Loss: 0.0016598307993263006
Test Loss:  0.0018181983614340425
Valid Loss:  0.0021400803234428167
Epoch:  328  	Training Loss: 0.001659751171246171
Test Loss:  0.0018188061658293009
Valid Loss:  0.002138916403055191
Epoch:  329  	Training Loss: 0.0016596773639321327
Test Loss:  0.0018193669384345412
Valid Loss:  0.0021378418896347284
Epoch:  330  	Training Loss: 0.0016596084460616112
Test Loss:  0.001819884986616671
Valid Loss:  0.0021368502639234066
Epoch:  331  	Training Loss: 0.0016595441848039627
Test Loss:  0.001820369972847402
Valid Loss:  0.002135936636477709
Epoch:  332  	Training Loss: 0.0016594884218648076
Test Loss:  0.0018204947700724006
Valid Loss:  0.0021353624761104584
Epoch:  333  	Training Loss: 0.0016594415064901114
Test Loss:  0.0018205938395112753
Valid Loss:  0.002134833950549364
Epoch:  334  	Training Loss: 0.0016593962209299207
Test Loss:  0.0018206691602244973
Valid Loss:  0.002134347101673484
Epoch:  335  	Training Loss: 0.0016593525651842356
Test Loss:  0.001820723875425756
Valid Loss:  0.002133898437023163
Epoch:  336  	Training Loss: 0.001659309957176447
Test Loss:  0.001820759498514235
Valid Loss:  0.002133481204509735
Epoch:  337  	Training Loss: 0.0016592692118138075
Test Loss:  0.0018207815010100603
Valid Loss:  0.0021330942399799824
Epoch:  338  	Training Loss: 0.0016592293977737427
Test Loss:  0.0018207875546067953
Valid Loss:  0.0021327328868210316
Epoch:  339  	Training Loss: 0.0016591913299635053
Test Loss:  0.001820781733840704
Valid Loss:  0.0021323959808796644
Epoch:  340  	Training Loss: 0.0016591533785685897
Test Loss:  0.00182076555211097
Valid Loss:  0.0021320804953575134
Epoch:  341  	Training Loss: 0.0016591176390647888
Test Loss:  0.0018207392422482371
Valid Loss:  0.0021317831706255674
Epoch:  342  	Training Loss: 0.001659081899560988
Test Loss:   69%|██████▊   | 343/500 [04:34<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:34<01:37,  1.60it/s] 69%|██████▉   | 347/500 [04:34<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:34<00:52,  2.88it/s] 70%|███████   | 351/500 [04:41<03:03,  1.23s/it] 71%|███████   | 353/500 [04:41<02:09,  1.13it/s] 71%|███████   | 355/500 [04:41<01:32,  1.56it/s] 71%|███████▏  | 357/500 [04:42<01:07,  2.11it/s] 72%|███████▏  | 359/500 [04:42<00:50,  2.81it/s] 72%|███████▏  | 361/500 [04:48<02:48,  1.21s/it] 73%|███████▎  | 363/500 [04:48<01:59,  1.15it/s] 73%|███████▎  | 365/500 [04:48<01:25,  1.59it/s] 73%|███████▎  | 367/500 [04:49<01:01,  2.17it/s] 74%|███████▍  | 369/500 [04:49<00:44,  2.92it/s] 74%|███████▍  | 371/500 [04:55<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:55<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:55<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:55<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:55<00:40,  2.97it/s] 76%|███████▌  | 381/500 [05:02<02:23,  1.20s/it] 77%|███████▋  | 383/500 [05:02<01:41,  1.16it/s] 77%|███████▋  | 385/500 [05:02<01:11,  1.60it/s] 77%|███████▋  | 387/500 [05:02<00:51,  2.19it/s] 78%|███████▊  | 389/500 [05:02<00:37,  2.94it/s] 78%|███████▊  | 391/500 [05:09<02:11,  1.20s/it] 79%|███████▊  | 393/500 [05:09<01:32,  1.16it/s] 79%|███████▉  | 395/500 [05:09<01:05,  1.60it/s] 79%|███████▉  | 397/500 [05:09<00:47,  2.19it/s] 80%|███████▉  | 399/500 [05:09<00:34,  2.94it/s] 80%|████████  | 401/500 [05:16<01:57,  1.19s/it] 81%|████████  | 403/500 [05:16<01:23,  1.16it/s] 81%|████████  | 405/500 [05:16<00:59,  1.60it/s] 81%|████████▏ | 407/500 [05:16<00:42,  2.19it/s] 82%|████████▏ | 409/500 [05:16<00:30,  2.95it/s]0.0018206877866759896
Valid Loss:  0.0021317903883755207
Epoch:  343  	Training Loss: 0.0016590652521699667
Test Loss:  0.001820637029595673
Valid Loss:  0.002131796907633543
Epoch:  344  	Training Loss: 0.001659048954024911
Test Loss:  0.0018205867381766438
Valid Loss:  0.0021318024955689907
Epoch:  345  	Training Loss: 0.0016590321902185678
Test Loss:  0.0018205370288342237
Valid Loss:  0.0021318085491657257
Epoch:  346  	Training Loss: 0.0016590150771662593
Test Loss:  0.0018204861553385854
Valid Loss:  0.0021318146027624607
Epoch:  347  	Training Loss: 0.0016589986626058817
Test Loss:  0.0018204424995929003
Valid Loss:  0.002131821122020483
Epoch:  348  	Training Loss: 0.0016589820152148604
Test Loss:  0.0018204012885689735
Valid Loss:  0.002131827874109149
Epoch:  349  	Training Loss: 0.0016589656006544828
Test Loss:  0.0018203601939603686
Valid Loss:  0.002131833229213953
Epoch:  350  	Training Loss: 0.0016589489532634616
Test Loss:  0.0018203193321824074
Valid Loss:  0.0021318388171494007
Epoch:  351  	Training Loss: 0.0016589324222877622
Test Loss:  0.0018202783539891243
Valid Loss:  0.0021318458020687103
Epoch:  352  	Training Loss: 0.001658915774896741
Test Loss:  0.0018202719511464238
Valid Loss:  0.002131829969584942
Epoch:  353  	Training Loss: 0.001658906927332282
Test Loss:  0.0018202655483037233
Valid Loss:  0.0021318139042705297
Epoch:  354  	Training Loss: 0.001658898196183145
Test Loss:  0.0018202592618763447
Valid Loss:  0.0021317978389561176
Epoch:  355  	Training Loss: 0.001658889465034008
Test Loss:  0.0018202532082796097
Valid Loss:  0.002131782006472349
Epoch:  356  	Training Loss: 0.001658880733884871
Test Loss:  0.0018202468054369092
Valid Loss:  0.0021317671053111553
Epoch:  357  	Training Loss: 0.0016588722355663776
Test Loss:  0.0018202406354248524
Valid Loss:  0.0021317508071660995
Epoch:  358  	Training Loss: 0.0016588633880019188
Test Loss:  0.0018202338833361864
Valid Loss:  0.002131734974682331
Epoch:  359  	Training Loss: 0.00165885454043746
Test Loss:  0.0018202275969088078
Valid Loss:  0.00213171960785985
Epoch:  360  	Training Loss: 0.0016588459257036448
Test Loss:  0.0018202211940661073
Valid Loss:  0.002131703542545438
Epoch:  361  	Training Loss: 0.0016588371945545077
Test Loss:  0.0018202150240540504
Valid Loss:  0.002131687942892313
Epoch:  362  	Training Loss: 0.0016588284634053707
Test Loss:  0.0018202114151790738
Valid Loss:  0.002131689339876175
Epoch:  363  	Training Loss: 0.0016588277649134398
Test Loss:  0.0018202087376266718
Valid Loss:  0.002131691901013255
Epoch:  364  	Training Loss: 0.0016588268335908651
Test Loss:  0.0018202050123363733
Valid Loss:  0.002131693996489048
Epoch:  365  	Training Loss: 0.0016588263679295778
Test Loss:  0.0018202026840299368
Valid Loss:  0.0021316958591341972
Epoch:  366  	Training Loss: 0.0016588254366070032
Test Loss:  0.0018201987259089947
Valid Loss:  0.002131697256118059
Epoch:  367  	Training Loss: 0.001658824854530394
Test Loss:  0.0018201952334493399
Valid Loss:  0.0021316998172551394
Epoch:  368  	Training Loss: 0.0016588240396231413
Test Loss:  0.0018201926723122597
Valid Loss:  0.002131702145561576
Epoch:  369  	Training Loss: 0.0016588233411312103
Test Loss:  0.0018201899947598577
Valid Loss:  0.002131704008206725
Epoch:  370  	Training Loss: 0.0016588233411312103
Test Loss:  0.0018201859202235937
Valid Loss:  0.0021317051723599434
Epoch:  371  	Training Loss: 0.0016588222933933139
Test Loss:  0.0018201833590865135
Valid Loss:  0.0021317079663276672
Epoch:  372  	Training Loss: 0.0016588217113167048
Test Loss:  0.0018205081578344107
Valid Loss:  0.0021311070304363966
Epoch:  373  	Training Loss: 0.0016587954014539719
Test Loss:  0.0018208071123808622
Valid Loss:  0.002130550565198064
Epoch:  374  	Training Loss: 0.0016587708378210664
Test Loss:  0.0018210832495242357
Valid Loss:  0.002130037173628807
Epoch:  375  	Training Loss: 0.0016587469726800919
Test Loss:  0.0018213357543572783
Valid Loss:  0.002129561733454466
Epoch:  376  	Training Loss: 0.001658724620938301
Test Loss:  0.0018215689342468977
Valid Loss:  0.0021291207522153854
Epoch:  377  	Training Loss: 0.0016587028512731194
Test Loss:  0.0018217810429632664
Valid Loss:  0.002128713298588991
Epoch:  378  	Training Loss: 0.0016586820129305124
Test Loss:  0.0018219827907159925
Valid Loss:  0.0021283356472849846
Epoch:  379  	Training Loss: 0.0016586616402491927
Test Loss:  0.0018221728969365358
Valid Loss:  0.002127985004335642
Epoch:  380  	Training Loss: 0.0016586413839831948
Test Loss:  0.0018223447259515524
Valid Loss:  0.0021276604384183884
Epoch:  381  	Training Loss: 0.001658622408285737
Test Loss:  0.0018225045641884208
Valid Loss:  0.0021273589227348566
Epoch:  382  	Training Loss: 0.0016586033161729574
Test Loss:  0.0018226932734251022
Valid Loss:  0.0021270248107612133
Epoch:  383  	Training Loss: 0.001658591558225453
Test Loss:  0.0018228658009320498
Valid Loss:  0.0021267179399728775
Epoch:  384  	Training Loss: 0.0016585809644311666
Test Loss:  0.0018230221467092633
Valid Loss:  0.0021264369133859873
Epoch:  385  	Training Loss: 0.0016585701378062367
Test Loss:  0.001823164988309145
Valid Loss:  0.0021261805668473244
Epoch:  386  	Training Loss: 0.0016585593111813068
Test Loss:  0.0018232936272397637
Valid Loss:  0.0021259444765746593
Epoch:  387  	Training Loss: 0.0016585492994636297
Test Loss:  0.0018234103918075562
Valid Loss:  0.0021257279440760612
Epoch:  388  	Training Loss: 0.0016585391713306308
Test Loss:  0.0018235164461657405
Valid Loss:  0.002125529106706381
Epoch:  389  	Training Loss: 0.0016585295088589191
Test Loss:  0.0018236124888062477
Valid Loss:  0.0021253456361591816
Epoch:  390  	Training Loss: 0.0016585199628025293
Test Loss:  0.0018237004987895489
Valid Loss:  0.002125178463757038
Epoch:  391  	Training Loss: 0.0016585099510848522
Test Loss:  0.0018237787298858166
Valid Loss:  0.0021250236313790083
Epoch:  392  	Training Loss: 0.0016585008706897497
Test Loss:  0.00181983329821378
Valid Loss:  0.0021284478716552258
Epoch:  393  	Training Loss: 0.0016582745593041182
Test Loss:  0.0018169403774663806
Valid Loss:  0.002131022047251463
Epoch:  394  	Training Loss: 0.0016581483650952578
Test Loss:  0.0018148109083995223
Valid Loss:  0.002132943831384182
Epoch:  395  	Training Loss: 0.001658078283071518
Test Loss:  0.0018132443074136972
Valid Loss:  0.0021343762055039406
Epoch:  396  	Training Loss: 0.0016580377705395222
Test Loss:  0.0018120845779776573
Valid Loss:  0.0021354362834244967
Epoch:  397  	Training Loss: 0.0016580147203058004
Test Loss:  0.0018112288089469075
Valid Loss:  0.0021362192928791046
Epoch:  398  	Training Loss: 0.001658000168390572
Test Loss:  0.0018105963245034218
Valid Loss:  0.002136793453246355
Epoch:  399  	Training Loss: 0.0016579912044107914
Test Loss:  0.0018101274035871029
Valid Loss:  0.0021372120827436447
Epoch:  400  	Training Loss: 0.0016579858493059874
Test Loss:  0.0018097818829119205
Valid Loss:  0.002137515228241682
Epoch:  401  	Training Loss: 0.0016579816583544016
Test Loss:  0.0018095261184498668
Valid Loss:  0.0021377308294177055
Epoch:  402  	Training Loss: 0.0016579777002334595
Test Loss:  0.0018096249550580978
Valid Loss:  0.002135452814400196
Epoch:  403  	Training Loss: 0.0016574247274547815
Test Loss:  0.0018093946855515242
Valid Loss:  0.0021335661876946688
Epoch:  404  	Training Loss: 0.0016568873543292284
Test Loss:  0.0018089443910866976
Valid Loss:  0.002131943590939045
Epoch:  405  	Training Loss: 0.001656359643675387
Test Loss:  0.0018083438044413924
Valid Loss:  0.0021305042318999767
Epoch:  406  	Training Loss: 0.0016558411298319697
Test Loss:  0.00180764717515558
Valid Loss:  0.002129186177626252
Epoch:  407  	Training Loss: 0.0016553299501538277
Test Loss:  0.0018068887293338776
Valid Loss:  0.002127955900505185
Epoch:  408  	Training Loss: 0.0016548261046409607
Test Loss:  0.0018060901202261448
Valid Loss:  0.002126782201230526
Epoch:  409  	Training Loss: 0.001654330175369978
Test Loss:  0.001805266598239541
Valid Loss:  0.002125650644302368
Epoch:  410  	Training Loss: 0.001653842395171523
Test Loss:  0.0018044286407530308
Valid Loss:  0.002124551683664322
 82%|████████▏ | 411/500 [05:23<01:45,  1.19s/it] 83%|████████▎ | 413/500 [05:23<01:14,  1.17it/s] 83%|████████▎ | 415/500 [05:23<00:52,  1.62it/s] 83%|████████▎ | 417/500 [05:23<00:37,  2.21it/s] 84%|████████▍ | 419/500 [05:23<00:27,  2.97it/s] 84%|████████▍ | 421/500 [05:30<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:30<01:06,  1.17it/s] 85%|████████▌ | 425/500 [05:30<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:30<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:30<00:24,  2.96it/s] 86%|████████▌ | 431/500 [05:37<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:37<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:37<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:37<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:37<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:43<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:44<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:44<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:44<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:44<00:17,  2.86it/s] 90%|█████████ | 451/500 [05:51<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:51<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:51<00:28,  1.59it/s] 91%|█████████▏| 457/500 [05:51<00:19,  2.17it/s] 92%|█████████▏| 459/500 [05:51<00:14,  2.93it/s] 92%|█████████▏| 461/500 [05:57<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:58<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:58<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:58<00:15,  2.17it/s] 94%|█████████▍| 469/500 [05:58<00:10,  2.87it/s] 94%|█████████▍| 471/500 [06:05<00:35,  1.21s/it] 95%|█████████▍| 473/500 [06:05<00:23,  1.14it/s] 95%|█████████▌| 475/500 [06:05<00:15,  1.58it/s] 95%|█████████▌| 477/500 [06:05<00:10,  2.16it/s]Epoch:  411  	Training Loss: 0.0016533610178157687
Test Loss:  0.0018035853281617165
Valid Loss:  0.0021234743762761354
Epoch:  412  	Training Loss: 0.0016528860433027148
Test Loss:  0.001803204882889986
Valid Loss:  0.0021238308399915695
Epoch:  413  	Training Loss: 0.0016528775449842215
Test Loss:  0.0018028697231784463
Valid Loss:  0.0021241456270217896
Epoch:  414  	Training Loss: 0.0016528693959116936
Test Loss:  0.0018025729805231094
Valid Loss:  0.0021244240924715996
Epoch:  415  	Training Loss: 0.001652863109484315
Test Loss:  0.0018023111624643207
Valid Loss:  0.0021246694959700108
Epoch:  416  	Training Loss: 0.0016528572887182236
Test Loss:  0.0018020800780504942
Valid Loss:  0.002124886028468609
Epoch:  417  	Training Loss: 0.0016528519336134195
Test Loss:  0.0018018780974671245
Valid Loss:  0.002125076949596405
Epoch:  418  	Training Loss: 0.0016528475098311901
Test Loss:  0.0018016991671174765
Valid Loss:  0.002125245751813054
Epoch:  419  	Training Loss: 0.0016528429696336389
Test Loss:  0.0018015422392636538
Valid Loss:  0.0021253940649330616
Epoch:  420  	Training Loss: 0.0016528391279280186
Test Loss:  0.0018014038214460015
Valid Loss:  0.002125523518770933
Epoch:  421  	Training Loss: 0.0016528356354683638
Test Loss:  0.0018012851942330599
Valid Loss:  0.002125636674463749
Epoch:  422  	Training Loss: 0.0016528312116861343
Test Loss:  0.0018009294290095568
Valid Loss:  0.0021259007044136524
Epoch:  423  	Training Loss: 0.001652807928621769
Test Loss:  0.001800676342099905
Valid Loss:  0.0021260660141706467
Epoch:  424  	Training Loss: 0.0016527853440493345
Test Loss:  0.0018004985759034753
Valid Loss:  0.0021261596120893955
Epoch:  425  	Training Loss: 0.0016527635743841529
Test Loss:  0.001800376339815557
Valid Loss:  0.002126197563484311
Epoch:  426  	Training Loss: 0.0016527415718883276
Test Loss:  0.0018002946162596345
Valid Loss:  0.002126196399331093
Epoch:  427  	Training Loss: 0.0016527208499610424
Test Loss:  0.0018002432771027088
Valid Loss:  0.002126166131347418
Epoch:  428  	Training Loss: 0.0016526994295418262
Test Loss:  0.001800216268748045
Valid Loss:  0.002126114908605814
Epoch:  429  	Training Loss: 0.0016526795225217938
Test Loss:  0.0018002026481553912
Valid Loss:  0.002126046922057867
Epoch:  430  	Training Loss: 0.0016526584513485432
Test Loss:  0.0018002024153247476
Valid Loss:  0.002125968225300312
Epoch:  431  	Training Loss: 0.0016526385443285108
Test Loss:  0.0018002113793045282
Valid Loss:  0.002125881379470229
Epoch:  432  	Training Loss: 0.0016526184044778347
Test Loss:  0.0018009799532592297
Valid Loss:  0.0021245472598820925
Epoch:  433  	Training Loss: 0.0016525743994861841
Test Loss:  0.0018016903195530176
Valid Loss:  0.0021233265288174152
Epoch:  434  	Training Loss: 0.0016525363316759467
Test Loss:  0.001802345272153616
Valid Loss:  0.0021222084760665894
Epoch:  435  	Training Loss: 0.0016525047831237316
Test Loss:  0.0018029515631496906
Valid Loss:  0.002121184952557087
Epoch:  436  	Training Loss: 0.0016524780075997114
Test Loss:  0.001803510938771069
Valid Loss:  0.002120246645063162
Epoch:  437  	Training Loss: 0.001652455423027277
Test Loss:  0.001804026891477406
Valid Loss:  0.0021193884313106537
Epoch:  438  	Training Loss: 0.0016524360980838537
Test Loss:  0.0018045015167444944
Valid Loss:  0.0021186009980738163
Epoch:  439  	Training Loss: 0.001652419799938798
Test Loss:  0.0018049408681690693
Valid Loss:  0.0021178785245865583
Epoch:  440  	Training Loss: 0.001652406295761466
Test Loss:  0.0018053450621664524
Valid Loss:  0.0021172179840505123
Epoch:  441  	Training Loss: 0.0016523946542292833
Test Loss:  0.0018057177076116204
Valid Loss:  0.0021166112273931503
Epoch:  442  	Training Loss: 0.0016523846425116062
Test Loss:  0.0018055705586448312
Valid Loss:  0.002116741379722953
Epoch:  443  	Training Loss: 0.001652316888794303
Test Loss:  0.0018054433166980743
Valid Loss:  0.0021168538369238377
Epoch:  444  	Training Loss: 0.001652232022024691
Test Loss:  0.0018053308594971895
Valid Loss:  0.002116954419761896
Epoch:  445  	Training Loss: 0.0016521515790373087
Test Loss:  0.0018052324885502458
Valid Loss:  0.0021170438267290592
Epoch:  446  	Training Loss: 0.0016520750941708684
Test Loss:  0.0018051466904580593
Valid Loss:  0.002117120660841465
Epoch:  447  	Training Loss: 0.0016520032659173012
Test Loss:  0.001805072883144021
Valid Loss:  0.0021171884145587683
Epoch:  448  	Training Loss: 0.0016519248019903898
Test Loss:  0.001805017003789544
Valid Loss:  0.002117239637300372
Epoch:  449  	Training Loss: 0.0016518314369022846
Test Loss:  0.001804976724088192
Valid Loss:  0.0021172778215259314
Epoch:  450  	Training Loss: 0.0016517231706529856
Test Loss:  0.001804948435164988
Valid Loss:  0.002117305528372526
Epoch:  451  	Training Loss: 0.001651620608754456
Test Loss:  0.0018049328355118632
Valid Loss:  0.002117322525009513
Epoch:  452  	Training Loss: 0.0016515229362994432
Test Loss:  0.0018049499485641718
Valid Loss:  0.0021172938868403435
Epoch:  453  	Training Loss: 0.001651522470638156
Test Loss:  0.0018049678765237331
Valid Loss:  0.0021172650158405304
Epoch:  454  	Training Loss: 0.001651521772146225
Test Loss:  0.0018049856880679727
Valid Loss:  0.00211723567917943
Epoch:  455  	Training Loss: 0.0016515214229002595
Test Loss:  0.0018050034996122122
Valid Loss:  0.002117206808179617
Epoch:  456  	Training Loss: 0.0016515206079930067
Test Loss:  0.001805020496249199
Valid Loss:  0.0021171788685023785
Epoch:  457  	Training Loss: 0.0016515200259163976
Test Loss:  0.0018050377257168293
Valid Loss:  0.0021171499975025654
Epoch:  458  	Training Loss: 0.0016515195602551103
Test Loss:  0.001805054722353816
Valid Loss:  0.0021171201951801777
Epoch:  459  	Training Loss: 0.0016515187453478575
Test Loss:  0.0018050719518214464
Valid Loss:  0.0021170922555029392
Epoch:  460  	Training Loss: 0.0016515178140252829
Test Loss:  0.0018050899961963296
Valid Loss:  0.0021170643158257008
Epoch:  461  	Training Loss: 0.001651517697609961
Test Loss:  0.0018051064107567072
Valid Loss:  0.002117036608979106
Epoch:  462  	Training Loss: 0.0016515168827027082
Test Loss:  0.0018047725316137075
Valid Loss:  0.0021156955044716597
Epoch:  463  	Training Loss: 0.001651009195484221
Test Loss:  0.00180444261059165
Valid Loss:  0.0021143893245607615
Epoch:  464  	Training Loss: 0.0016505189705640078
Test Loss:  0.001804115017876029
Valid Loss:  0.002113115508109331
Epoch:  465  	Training Loss: 0.0016500446945428848
Test Loss:  0.001803792081773281
Valid Loss:  0.002111871726810932
Epoch:  466  	Training Loss: 0.001649585785344243
Test Loss:  0.0018034731037914753
Valid Loss:  0.002110658213496208
Epoch:  467  	Training Loss: 0.0016491410788148642
Test Loss:  0.0018031565705314279
Valid Loss:  0.00210947566665709
Epoch:  468  	Training Loss: 0.0016487112734466791
Test Loss:  0.0018028432969003916
Valid Loss:  0.0021083217579871416
Epoch:  469  	Training Loss: 0.0016482950886711478
Test Loss:  0.0018025340978056192
Valid Loss:  0.0021071939263492823
Epoch:  470  	Training Loss: 0.0016478922916576266
Test Loss:  0.0018022283911705017
Valid Loss:  0.0021060947328805923
Epoch:  471  	Training Loss: 0.0016475026495754719
Test Loss:  0.0018019252456724644
Valid Loss:  0.002105023479089141
Epoch:  472  	Training Loss: 0.0016471261624246836
Test Loss:  0.0017995686503127217
Valid Loss:  0.002105715684592724
Epoch:  473  	Training Loss: 0.0016466835513710976
Test Loss:  0.001797679578885436
Valid Loss:  0.0021059405989944935
Epoch:  474  	Training Loss: 0.001646260847337544
Test Loss:  0.0017961133271455765
Valid Loss:  0.0021058409474790096
Epoch:  475  	Training Loss: 0.0016458507161587477
Test Loss:  0.001794770359992981
Valid Loss:  0.002105516381561756
Epoch:  476  	Training Loss: 0.0016454446595162153
Test Loss:  0.0017935150535777211
Valid Loss:  0.0021048737689852715
Epoch:  477  	Training Loss: 0.001644909381866455
Test Loss:  0.001792341936379671
Valid Loss:  0.0021041545551270247
Epoch:  478  	Training Loss: 0.0016443836502730846
Test Loss:  0.0017912292387336493
Valid Loss:  0.002103382721543312
Epoch:  479  	Training Loss: 0.001643866067752242
Test Loss:  0.0017901621758937836
Valid Loss:   96%|█████████▌| 479/500 [06:05<00:07,  2.91it/s] 96%|█████████▌| 481/500 [06:11<00:22,  1.19s/it] 97%|█████████▋| 483/500 [06:12<00:14,  1.17it/s] 97%|█████████▋| 485/500 [06:12<00:09,  1.62it/s] 97%|█████████▋| 487/500 [06:12<00:05,  2.22it/s] 98%|█████████▊| 489/500 [06:12<00:03,  2.99it/s] 98%|█████████▊| 491/500 [06:18<00:10,  1.19s/it] 99%|█████████▊| 493/500 [06:19<00:05,  1.17it/s] 99%|█████████▉| 495/500 [06:19<00:03,  1.61it/s] 99%|█████████▉| 497/500 [06:19<00:01,  2.21it/s]100%|█████████▉| 499/500 [06:19<00:00,  2.97it/s]100%|██████████| 500/500 [06:19<00:00,  1.32it/s]
0.0021025766618549824
Epoch:  480  	Training Loss: 0.0016433580312877893
Test Loss:  0.0017891314346343279
Valid Loss:  0.002101743593811989
Epoch:  481  	Training Loss: 0.001642857096157968
Test Loss:  0.001788127003237605
Valid Loss:  0.002100895857438445
Epoch:  482  	Training Loss: 0.0016423644265159965
Test Loss:  0.001788444584235549
Valid Loss:  0.0021000299602746964
Epoch:  483  	Training Loss: 0.001642303541302681
Test Loss:  0.001788693480193615
Valid Loss:  0.002099270699545741
Epoch:  484  	Training Loss: 0.0016422461485490203
Test Loss:  0.001788887893781066
Valid Loss:  0.0020985971204936504
Epoch:  485  	Training Loss: 0.0016421917825937271
Test Loss:  0.001789037836715579
Valid Loss:  0.002097998047247529
Epoch:  486  	Training Loss: 0.001642140676267445
Test Loss:  0.0017891514580696821
Valid Loss:  0.0020974581129848957
Epoch:  487  	Training Loss: 0.001642091665416956
Test Loss:  0.0017892357427626848
Valid Loss:  0.0020969691686332226
Epoch:  488  	Training Loss: 0.0016420453321188688
Test Loss:  0.0017892955802381039
Valid Loss:  0.002096522133797407
Epoch:  489  	Training Loss: 0.0016420009778812528
Test Loss:  0.001789337140507996
Valid Loss:  0.0020961137488484383
Epoch:  490  	Training Loss: 0.0016419581370428205
Test Loss:  0.001789364032447338
Valid Loss:  0.0020957349333912134
Epoch:  491  	Training Loss: 0.0016419172752648592
Test Loss:  0.0017893780022859573
Valid Loss:  0.0020953835919499397
Epoch:  492  	Training Loss: 0.0016418781597167253
Test Loss:  0.0017895291093736887
Valid Loss:  0.0020951428450644016
Epoch:  493  	Training Loss: 0.001641873735934496
Test Loss:  0.0017896726494655013
Valid Loss:  0.0020949116442352533
Epoch:  494  	Training Loss: 0.0016418695449829102
Test Loss:  0.0017898131627589464
Valid Loss:  0.002094687893986702
Epoch:  495  	Training Loss: 0.0016418652376160026
Test Loss:  0.0017899482045322657
Valid Loss:  0.002094470662996173
Epoch:  496  	Training Loss: 0.0016418613959103823
Test Loss:  0.0017900790553539991
Valid Loss:  0.002094263443723321
Epoch:  497  	Training Loss: 0.0016418584855273366
Test Loss:  0.0017902044346556067
Valid Loss:  0.0020940632093697786
Epoch:  498  	Training Loss: 0.0016418551094830036
Test Loss:  0.001790326088666916
Valid Loss:  0.002093867864459753
Epoch:  499  	Training Loss: 0.0016418520826846361
Test Loss:  0.0017904441338032484
Valid Loss:  0.0020936818327754736
Epoch:  500  	Training Loss: 0.0016418492887169123
Test Loss:  0.0017905569402500987
Valid Loss:  0.00209350255317986
seed is  14
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:36, 13.61it/s]  1%|          | 4/500 [00:00<00:33, 14.91it/s]  1%|          | 6/500 [00:00<00:31, 15.52it/s]  2%|▏         | 8/500 [00:00<00:30, 15.87it/s]  2%|▏         | 10/500 [00:00<00:30, 15.96it/s]  2%|▏         | 12/500 [00:00<00:30, 16.01it/s]  3%|▎         | 14/500 [00:00<00:30, 15.99it/s]  3%|▎         | 16/500 [00:01<00:30, 15.98it/s]  4%|▎         | 18/500 [00:01<00:29, 16.10it/s]  4%|▍         | 20/500 [00:01<00:29, 16.18it/s]  4%|▍         | 22/500 [00:01<00:29, 16.26it/s]  5%|▍         | 24/500 [00:01<00:29, 16.01it/s]  5%|▌         | 26/500 [00:01<00:30, 15.47it/s]  6%|▌         | 28/500 [00:01<00:30, 15.59it/s]  6%|▌         | 30/500 [00:01<00:31, 14.99it/s]  6%|▋         | 32/500 [00:02<00:32, 14.26it/s]  7%|▋         | 34/500 [00:02<00:31, 14.76it/s]  7%|▋         | 36/500 [00:02<00:30, 15.20it/s]  8%|▊         | 38/500 [00:02<00:29, 15.49it/s]  8%|▊         | 40/500 [00:02<00:30, 15.07it/s]  8%|▊         | 42/500 [00:02<00:30, 15.13it/s]  9%|▉         | 44/500 [00:02<00:29, 15.49it/s]  9%|▉         | 46/500 [00:02<00:28, 15.73it/s] 10%|▉         | 48/500 [00:03<00:28, 15.95it/s] 10%|█         | 50/500 [00:03<00:27, 16.12it/s] 10%|█         | 52/500 [00:03<00:28, 16.00it/s] 11%|█         | 54/500 [00:03<00:27, 16.01it/s] 11%|█         | 56/500 [00:03<00:27, 16.09it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.16it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.22it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.25it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.28it/s] 13%|█▎        | 66/500 [00:04<00:27, 16.01it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.08it/s] 14%|█▍        | 70/500 [00:04<00:26, 15.98it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.97it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.80it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.34it/s] 16%|█▌        | 78/500 [00:04<00:27, 15.28it/s] 16%|█▌        | 80/500 [00:05<00:27, 15.29it/s] 16%|█▋        | 82/500 [00:05<00:27, 15.28it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.60it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.86it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.65it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.31it/s] 18%|█▊        | 92/500 [00:05<00:26, 15.37it/s] 19%|█▉        | 94/500 [00:06<00:26, 15.38it/s] 19%|█▉        | 96/500 [00:06<00:26, 15.01it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.05it/s] 20%|██        | 100/500 [00:06<00:26, 15.07it/s] 20%|██        | 102/500 [00:06<00:26, 15.19it/s] 21%|██        | 104/500 [00:06<00:25, 15.38it/s] 21%|██        | 106/500 [00:06<00:25, 15.29it/s] 22%|██▏       | 108/500 [00:06<00:27, 14.36it/s] 22%|██▏       | 110/500 [00:07<00:26, 14.91it/s] 22%|██▏       | 112/500 [00:07<00:25, 15.25it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.51it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.59it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.80it/s] 24%|██▍       | 120/500 [00:07<00:25, 14.97it/s] 24%|██▍       | 122/500 [00:07<00:26, 14.05it/s] 25%|██▍       | 124/500 [00:08<00:28, 13.43it/s]Epoch:  1  	Training Loss: 0.240797758102417
Test Loss:  3864.9150390625
Valid Loss:  3875.1875
Epoch:  2  	Training Loss: 3881.982421875
Test Loss:  23536240427008.0
Valid Loss:  23056527392768.0
Epoch:  3  	Training Loss: 23375342731264.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
 25%|██▌       | 126/500 [00:08<00:29, 12.85it/s] 26%|██▌       | 128/500 [00:08<00:27, 13.34it/s] 26%|██▌       | 130/500 [00:08<00:26, 13.73it/s] 26%|██▋       | 132/500 [00:08<00:25, 14.46it/s] 27%|██▋       | 134/500 [00:08<00:24, 14.77it/s] 27%|██▋       | 136/500 [00:08<00:25, 14.54it/s] 28%|██▊       | 138/500 [00:09<00:24, 14.99it/s] 28%|██▊       | 140/500 [00:09<00:23, 15.32it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.64it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.85it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.92it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.03it/s] 30%|███       | 150/500 [00:09<00:21, 16.10it/s] 30%|███       | 152/500 [00:09<00:21, 16.01it/s] 31%|███       | 154/500 [00:10<00:21, 16.06it/s] 31%|███       | 156/500 [00:10<00:21, 16.03it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.01it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.92it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.95it/s] 33%|███▎      | 164/500 [00:10<00:22, 14.87it/s] 33%|███▎      | 166/500 [00:10<00:23, 13.98it/s] 34%|███▎      | 168/500 [00:10<00:24, 13.44it/s] 34%|███▍      | 170/500 [00:11<00:25, 13.15it/s] 34%|███▍      | 172/500 [00:11<00:24, 13.21it/s] 35%|███▍      | 174/500 [00:11<00:25, 12.84it/s] 35%|███▌      | 176/500 [00:11<00:25, 12.70it/s] 36%|███▌      | 178/500 [00:11<00:23, 13.61it/s] 36%|███▌      | 180/500 [00:11<00:22, 14.35it/s] 36%|███▋      | 182/500 [00:11<00:21, 14.80it/s] 37%|███▋      | 184/500 [00:12<00:22, 14.19it/s] 37%|███▋      | 186/500 [00:12<00:21, 14.73it/s] 38%|███▊      | 188/500 [00:12<00:20, 14.99it/s] 38%|███▊      | 190/500 [00:12<00:20, 15.38it/s] 38%|███▊      | 192/500 [00:12<00:20, 15.04it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.42it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.51it/s] 40%|███▉      | 198/500 [00:13<00:20, 14.77it/s] 40%|████      | 200/500 [00:13<00:21, 13.77it/s] 40%|████      | 202/500 [00:13<00:22, 13.22it/s] 41%|████      | 204/500 [00:13<00:22, 13.26it/s] 41%|████      | 206/500 [00:13<00:20, 14.06it/s] 42%|████▏     | 208/500 [00:13<00:20, 14.57it/s] 42%|████▏     | 210/500 [00:13<00:19, 14.95it/s] 42%|████▏     | 212/500 [00:14<00:18, 15.32it/s] 43%|████▎     | 214/500 [00:14<00:19, 14.53it/s] 43%|████▎     | 216/500 [00:14<00:20, 13.72it/s] 44%|████▎     | 218/500 [00:14<00:21, 13.15it/s] 44%|████▍     | 220/500 [00:14<00:21, 12.90it/s] 44%|████▍     | 222/500 [00:14<00:21, 12.73it/s] 45%|████▍     | 224/500 [00:14<00:20, 13.16it/s] 45%|████▌     | 226/500 [00:15<00:19, 13.97it/s] 46%|████▌     | 228/500 [00:15<00:18, 14.36it/s] 46%|████▌     | 230/500 [00:15<00:18, 14.80it/s] 46%|████▋     | 232/500 [00:15<00:18, 14.74it/s] 47%|████▋     | 234/500 [00:15<00:17, 14.84it/s] 47%|████▋     | 236/500 [00:15<00:17, 15.23it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.52it/s] 48%|████▊     | 240/500 [00:16<00:16, 15.46it/s] 48%|████▊     | 242/500 [00:16<00:17, 14.54it/s] 49%|████▉     | 244/500 [00:16<00:18, 14.16it/s] 49%|████▉     | 246/500 [00:16<00:17, 14.30it/s] 50%|████▉     | 248/500 [00:16<00:16, 14.85it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:16<00:17, 14.55it/s] 50%|█████     | 252/500 [00:16<00:16, 14.82it/s] 51%|█████     | 254/500 [00:16<00:16, 14.90it/s] 51%|█████     | 256/500 [00:17<00:17, 14.19it/s] 52%|█████▏    | 258/500 [00:17<00:16, 14.52it/s] 52%|█████▏    | 260/500 [00:17<00:16, 14.96it/s] 52%|█████▏    | 262/500 [00:17<00:15, 15.28it/s] 53%|█████▎    | 264/500 [00:17<00:15, 15.56it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.73it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.77it/s] 54%|█████▍    | 270/500 [00:18<00:14, 15.40it/s] 54%|█████▍    | 272/500 [00:18<00:14, 15.48it/s] 55%|█████▍    | 274/500 [00:18<00:14, 15.52it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.73it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.72it/s] 56%|█████▌    | 280/500 [00:18<00:14, 15.49it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.74it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.90it/s] 57%|█████▋    | 286/500 [00:19<00:13, 15.64it/s] 58%|█████▊    | 288/500 [00:19<00:13, 15.57it/s] 58%|█████▊    | 290/500 [00:19<00:13, 15.57it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.65it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.72it/s] 59%|█████▉    | 296/500 [00:19<00:13, 15.51it/s] 60%|█████▉    | 298/500 [00:19<00:13, 15.42it/s] 60%|██████    | 300/500 [00:19<00:12, 15.69it/s] 60%|██████    | 302/500 [00:20<00:13, 15.15it/s] 61%|██████    | 304/500 [00:20<00:13, 14.15it/s] 61%|██████    | 306/500 [00:20<00:14, 13.41it/s] 62%|██████▏   | 308/500 [00:20<00:14, 13.61it/s] 62%|██████▏   | 310/500 [00:20<00:14, 13.39it/s] 62%|██████▏   | 312/500 [00:20<00:14, 13.22it/s] 63%|██████▎   | 314/500 [00:21<00:13, 13.41it/s] 63%|██████▎   | 316/500 [00:21<00:13, 13.68it/s] 64%|██████▎   | 318/500 [00:21<00:12, 14.37it/s] 64%|██████▍   | 320/500 [00:21<00:12, 14.81it/s] 64%|██████▍   | 322/500 [00:21<00:11, 15.21it/s] 65%|██████▍   | 324/500 [00:21<00:11, 15.42it/s] 65%|██████▌   | 326/500 [00:21<00:11, 15.60it/s] 66%|██████▌   | 328/500 [00:21<00:10, 15.80it/s] 66%|██████▌   | 330/500 [00:22<00:10, 15.95it/s] 66%|██████▋   | 332/500 [00:22<00:10, 15.80it/s] 67%|██████▋   | 334/500 [00:22<00:10, 15.98it/s] 67%|██████▋   | 336/500 [00:22<00:10, 16.00it/s] 68%|██████▊   | 338/500 [00:22<00:10, 16.03it/s] 68%|██████▊   | 340/500 [00:22<00:09, 16.07it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.08it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.20it/s] 69%|██████▉   | 346/500 [00:23<00:09, 16.18it/s] 70%|██████▉   | 348/500 [00:23<00:09, 15.83it/s] 70%|███████   | 350/500 [00:23<00:09, 15.88it/s] 70%|███████   | 352/500 [00:23<00:09, 15.71it/s] 71%|███████   | 354/500 [00:23<00:09, 15.74it/s] 71%|███████   | 356/500 [00:23<00:09, 15.94it/s] 72%|███████▏  | 358/500 [00:23<00:08, 15.97it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.03it/s] 72%|███████▏  | 362/500 [00:24<00:08, 15.94it/s] 73%|███████▎  | 364/500 [00:24<00:08, 15.95it/s] 73%|███████▎  | 366/500 [00:24<00:08, 16.01it/s] 74%|███████▎  | 368/500 [00:24<00:08, 16.02it/s] 74%|███████▍  | 370/500 [00:24<00:08, 16.08it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.77it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:24<00:08, 15.67it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.81it/s] 76%|███████▌  | 378/500 [00:25<00:07, 15.98it/s] 76%|███████▌  | 380/500 [00:25<00:07, 16.04it/s] 76%|███████▋  | 382/500 [00:25<00:07, 16.09it/s] 77%|███████▋  | 384/500 [00:25<00:07, 15.94it/s] 77%|███████▋  | 386/500 [00:25<00:07, 15.98it/s] 78%|███████▊  | 388/500 [00:25<00:07, 15.84it/s] 78%|███████▊  | 390/500 [00:25<00:06, 15.81it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.75it/s] 79%|███████▉  | 394/500 [00:26<00:06, 15.91it/s] 79%|███████▉  | 396/500 [00:26<00:06, 16.05it/s] 80%|███████▉  | 398/500 [00:26<00:06, 15.90it/s] 80%|████████  | 400/500 [00:26<00:06, 15.73it/s] 80%|████████  | 402/500 [00:26<00:06, 15.45it/s] 81%|████████  | 404/500 [00:26<00:06, 15.64it/s] 81%|████████  | 406/500 [00:26<00:05, 15.81it/s] 82%|████████▏ | 408/500 [00:26<00:05, 15.87it/s] 82%|████████▏ | 410/500 [00:27<00:05, 15.95it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.92it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.97it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.88it/s] 84%|████████▎ | 418/500 [00:27<00:05, 15.66it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.79it/s] 84%|████████▍ | 422/500 [00:27<00:04, 15.87it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.95it/s] 85%|████████▌ | 426/500 [00:28<00:04, 15.88it/s] 86%|████████▌ | 428/500 [00:28<00:04, 15.90it/s] 86%|████████▌ | 430/500 [00:28<00:04, 14.96it/s] 86%|████████▋ | 432/500 [00:28<00:04, 14.09it/s] 87%|████████▋ | 434/500 [00:28<00:04, 13.70it/s] 87%|████████▋ | 436/500 [00:28<00:04, 13.36it/s] 88%|████████▊ | 438/500 [00:28<00:04, 14.05it/s] 88%|████████▊ | 440/500 [00:29<00:04, 14.49it/s] 88%|████████▊ | 442/500 [00:29<00:03, 14.63it/s] 89%|████████▉ | 444/500 [00:29<00:03, 15.10it/s] 89%|████████▉ | 446/500 [00:29<00:03, 15.42it/s] 90%|████████▉ | 448/500 [00:29<00:03, 15.61it/s] 90%|█████████ | 450/500 [00:29<00:03, 15.79it/s] 90%|█████████ | 452/500 [00:29<00:03, 15.59it/s] 91%|█████████ | 454/500 [00:29<00:03, 14.65it/s] 91%|█████████ | 456/500 [00:30<00:02, 15.01it/s] 92%|█████████▏| 458/500 [00:30<00:02, 15.27it/s] 92%|█████████▏| 460/500 [00:30<00:02, 15.45it/s] 92%|█████████▏| 462/500 [00:30<00:02, 15.68it/s] 93%|█████████▎| 464/500 [00:30<00:02, 15.79it/s] 93%|█████████▎| 466/500 [00:30<00:02, 15.78it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.88it/s] 94%|█████████▍| 470/500 [00:31<00:01, 15.01it/s] 94%|█████████▍| 472/500 [00:31<00:01, 14.28it/s] 95%|█████████▍| 474/500 [00:31<00:01, 13.89it/s] 95%|█████████▌| 476/500 [00:31<00:01, 13.19it/s] 96%|█████████▌| 478/500 [00:31<00:01, 12.88it/s] 96%|█████████▌| 480/500 [00:31<00:01, 12.63it/s] 96%|█████████▋| 482/500 [00:31<00:01, 12.44it/s] 97%|█████████▋| 484/500 [00:32<00:01, 12.62it/s] 97%|█████████▋| 486/500 [00:32<00:01, 13.55it/s] 98%|█████████▊| 488/500 [00:32<00:00, 14.03it/s] 98%|█████████▊| 490/500 [00:32<00:00, 14.50it/s] 98%|█████████▊| 492/500 [00:32<00:00, 14.99it/s] 99%|█████████▉| 494/500 [00:32<00:00, 14.92it/s] 99%|█████████▉| 496/500 [00:32<00:00, 14.00it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:33<00:00, 13.29it/s]100%|██████████| 500/500 [00:33<00:00, 12.71it/s]100%|██████████| 500/500 [00:33<00:00, 15.02it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  14
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:18,  6.29s/it]  1%|          | 3/500 [00:06<13:56,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:37,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:37,  2.17it/s]  6%|▌         | 29/500 [00:20<02:40,  2.93it/s]  6%|▌         | 31/500 [00:27<09:26,  1.21s/it]  7%|▋         | 33/500 [00:27<06:44,  1.16it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:33,  2.16it/s]  8%|▊         | 39/500 [00:27<02:40,  2.87it/s]  8%|▊         | 41/500 [00:34<09:04,  1.19s/it]  9%|▊         | 43/500 [00:34<06:31,  1.17it/s]  9%|▉         | 45/500 [00:34<04:44,  1.60it/s]  9%|▉         | 47/500 [00:34<03:29,  2.16it/s] 10%|▉         | 49/500 [00:34<02:37,  2.86it/s] 10%|█         | 51/500 [00:41<08:57,  1.20s/it] 11%|█         | 53/500 [00:41<06:23,  1.16it/s] 11%|█         | 55/500 [00:41<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:41,  1.19s/it] 13%|█▎        | 63/500 [00:48<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.95it/s]Epoch:  1  	Training Loss: 0.240797758102417
Test Loss:  0.034899868071079254
Valid Loss:  0.0395398885011673
Epoch:  2  	Training Loss: 0.030215809121727943
Test Loss:  0.01672239601612091
Valid Loss:  0.021950222551822662
Epoch:  3  	Training Loss: 0.021243460476398468
Test Loss:  0.013556653633713722
Valid Loss:  0.017672792077064514
Epoch:  4  	Training Loss: 0.017823828384280205
Test Loss:  0.011321519501507282
Valid Loss:  0.014474641531705856
Epoch:  5  	Training Loss: 0.01501324400305748
Test Loss:  0.00950583815574646
Valid Loss:  0.01188796665519476
Epoch:  6  	Training Loss: 0.012696814723312855
Test Loss:  0.008022489957511425
Valid Loss:  0.009792354889214039
Epoch:  7  	Training Loss: 0.01078757643699646
Test Loss:  0.0068107107654213905
Valid Loss:  0.008096816018223763
Epoch:  8  	Training Loss: 0.009213507175445557
Test Loss:  0.0058196596801280975
Valid Loss:  0.006727105006575584
Epoch:  9  	Training Loss: 0.00791766494512558
Test Loss:  0.005000622011721134
Valid Loss:  0.005619987845420837
Epoch:  10  	Training Loss: 0.006854620762169361
Test Loss:  0.004314987920224667
Valid Loss:  0.004727850202471018
Epoch:  11  	Training Loss: 0.00598814245313406
Test Loss:  0.003780701197683811
Valid Loss:  0.00402823556214571
Epoch:  12  	Training Loss: 0.005271864123642445
Test Loss:  0.003356196219101548
Valid Loss:  0.0034750604536384344
Epoch:  13  	Training Loss: 0.004679192788898945
Test Loss:  0.0030193477869033813
Valid Loss:  0.0030375642236322165
Epoch:  14  	Training Loss: 0.0041880118660628796
Test Loss:  0.002741196658462286
Valid Loss:  0.002689361572265625
Epoch:  15  	Training Loss: 0.003780981292948127
Test Loss:  0.0025190631859004498
Valid Loss:  0.0024163122288882732
Epoch:  16  	Training Loss: 0.0034436360001564026
Test Loss:  0.00233992887660861
Valid Loss:  0.002203085459768772
Epoch:  17  	Training Loss: 0.0031640813685953617
Test Loss:  0.0021934257820248604
Valid Loss:  0.002037939615547657
Epoch:  18  	Training Loss: 0.0029336807783693075
Test Loss:  0.0020711752586066723
Valid Loss:  0.0019118241034448147
Epoch:  19  	Training Loss: 0.0027434593066573143
Test Loss:  0.001977368723601103
Valid Loss:  0.001818265300244093
Epoch:  20  	Training Loss: 0.002585556823760271
Test Loss:  0.0019044624641537666
Valid Loss:  0.001749872462823987
Epoch:  21  	Training Loss: 0.0024543460458517075
Test Loss:  0.0018498145509511232
Valid Loss:  0.0017012156313285232
Epoch:  22  	Training Loss: 0.00234535476192832
Test Loss:  0.001805006992071867
Valid Loss:  0.0016679571708664298
Epoch:  23  	Training Loss: 0.002254731487482786
Test Loss:  0.0017700151074677706
Valid Loss:  0.0016470170812681317
Epoch:  24  	Training Loss: 0.0021793635096400976
Test Loss:  0.0017435562331229448
Valid Loss:  0.0016356658888980746
Epoch:  25  	Training Loss: 0.0021166668739169836
Test Loss:  0.0017242314061149955
Valid Loss:  0.0016316550318151712
Epoch:  26  	Training Loss: 0.002064536325633526
Test Loss:  0.0017107907915487885
Valid Loss:  0.001633184147067368
Epoch:  27  	Training Loss: 0.0020213075913488865
Test Loss:  0.0016981568187475204
Valid Loss:  0.0016393888508901
Epoch:  28  	Training Loss: 0.0019857108127325773
Test Loss:  0.0016888114623725414
Valid Loss:  0.0016487562097609043
Epoch:  29  	Training Loss: 0.001956094056367874
Test Loss:  0.0016847422812134027
Valid Loss:  0.0016598324291408062
Epoch:  30  	Training Loss: 0.001931387698277831
Test Loss:  0.0016825632192194462
Valid Loss:  0.0016723815351724625
Epoch:  31  	Training Loss: 0.0019107370171695948
Test Loss:  0.0016812693793326616
Valid Loss:  0.0016859957249835134
Epoch:  32  	Training Loss: 0.001893453299999237
Test Loss:  0.0016811622772365808
Valid Loss:  0.0017000744119286537
Epoch:  33  	Training Loss: 0.0018789577297866344
Test Loss:  0.0016819452866911888
Valid Loss:  0.0017142855795100331
Epoch:  34  	Training Loss: 0.0018667730037122965
Test Loss:  0.001683878479525447
Valid Loss:  0.0017282434273511171
Epoch:  35  	Training Loss: 0.0018565881764516234
Test Loss:  0.001687483279965818
Valid Loss:  0.0017415967304259539
Epoch:  36  	Training Loss: 0.0018480599392205477
Test Loss:  0.0016913317376747727
Valid Loss:  0.0017546614399179816
Epoch:  37  	Training Loss: 0.0018409729236736894
Test Loss:  0.0016959269996732473
Valid Loss:  0.0017671682871878147
Epoch:  38  	Training Loss: 0.0018350518075749278
Test Loss:  0.001698045525699854
Valid Loss:  0.0017799930647015572
Epoch:  39  	Training Loss: 0.0018301106756553054
Test Loss:  0.0017030402086675167
Valid Loss:  0.001791274407878518
Epoch:  40  	Training Loss: 0.001825989573262632
Test Loss:  0.0017048395238816738
Valid Loss:  0.0018030537758022547
Epoch:  41  	Training Loss: 0.0018225273815914989
Test Loss:  0.001708619180135429
Valid Loss:  0.001813401933759451
Epoch:  42  	Training Loss: 0.0018196312012150884
Test Loss:  0.0017120417905971408
Valid Loss:  0.0018232911825180054
Epoch:  43  	Training Loss: 0.0018172208219766617
Test Loss:  0.0017137541435658932
Valid Loss:  0.0018330917228013277
Epoch:  44  	Training Loss: 0.001815189840272069
Test Loss:  0.0017175325192511082
Valid Loss:  0.001841383520513773
Epoch:  45  	Training Loss: 0.001813490060158074
Test Loss:  0.0017199879512190819
Valid Loss:  0.0018496167613193393
Epoch:  46  	Training Loss: 0.0018120595486834645
Test Loss:  0.0017222517635673285
Valid Loss:  0.0018572520930320024
Epoch:  47  	Training Loss: 0.0018108556978404522
Test Loss:  0.0017243764596059918
Valid Loss:  0.0018642967334017158
Epoch:  48  	Training Loss: 0.0018098349682986736
Test Loss:  0.0017270196694880724
Valid Loss:  0.001870573963969946
Epoch:  49  	Training Loss: 0.0018089775694534183
Test Loss:  0.0017282847547903657
Valid Loss:  0.0018768454901874065
Epoch:  50  	Training Loss: 0.0018082462484017015
Test Loss:  0.001731029013171792
Valid Loss:  0.0018819763790816069
Epoch:  51  	Training Loss: 0.0018076259875670075
Test Loss:  0.0017332031857222319
Valid Loss:  0.0018869811901822686
Epoch:  52  	Training Loss: 0.0018071068916469812
Test Loss:  0.0017338114557787776
Valid Loss:  0.0018921495648100972
Epoch:  53  	Training Loss: 0.0018066630000248551
Test Loss:  0.0017361111240461469
Valid Loss:  0.0018961087334901094
Epoch:  54  	Training Loss: 0.0018062820890918374
Test Loss:  0.0017374689923599362
Valid Loss:  0.001900158473290503
Epoch:  55  	Training Loss: 0.0018059553112834692
Test Loss:  0.0017386926338076591
Valid Loss:  0.0019038785248994827
Epoch:  56  	Training Loss: 0.0018056753324344754
Test Loss:  0.0017398148775100708
Valid Loss:  0.001907276688143611
Epoch:  57  	Training Loss: 0.0018054269021376967
Test Loss:  0.0017408531857654452
Valid Loss:  0.0019103861413896084
Epoch:  58  	Training Loss: 0.0018052093219012022
Test Loss:  0.0017418095376342535
Valid Loss:  0.0019132239976897836
Epoch:  59  	Training Loss: 0.0018050218932330608
Test Loss:  0.0017426902195438743
Valid Loss:  0.001915801432915032
Epoch:  60  	Training Loss: 0.0018048554193228483
Test Loss:  0.0017434852197766304
Valid Loss:  0.001918163849040866
Epoch:  61  	Training Loss: 0.0018047071062028408
Test Loss:  0.0017442161915823817
Valid Loss:  0.00192031089682132
Epoch:  62  	Training Loss: 0.0018045753240585327
Test Loss:  0.0017448901198804379
Valid Loss:  0.0019222639966756105
Epoch:  63  	Training Loss: 0.001804458093829453
Test Loss:  0.0017454995540902019
Valid Loss:  0.0019240400288254023
Epoch:  64  	Training Loss: 0.0018043499439954758
Test Loss:  0.001746053108945489
Valid Loss:  0.0019256636733189225
Epoch:  65  	Training Loss: 0.00180425017606467
Test Loss:  0.0017465583514422178
Valid Loss:  0.0019271379569545388
Epoch:  66  	Training Loss: 0.0018041597213596106
Test Loss:  0.001747641246765852
Valid Loss:  0.001928245066665113
Epoch:  67  	Training Loss: 0.0018040826544165611
Test Loss:  0.0017478911904618144
Valid Loss:  0.0019296465907245874
Epoch:  68  	Training Loss: 0.0018040095455944538
Test Loss:  0.0017492019105702639
Valid Loss:  0.0019304744200780988
Epoch:  69  	Training Loss: 0.0018039440037682652
Test Loss:  0.0017490441678091884
Valid Loss:  0.0019318985287100077
Epoch:  70  	Training Loss: 0.0018038887064903975
Test Loss:  0.0017494389321655035
 14%|█▍        | 71/500 [00:55<08:40,  1.21s/it] 15%|█▍        | 73/500 [00:55<06:14,  1.14it/s] 15%|█▌        | 75/500 [00:55<04:31,  1.57it/s] 15%|█▌        | 77/500 [00:55<03:20,  2.11it/s] 16%|█▌        | 79/500 [00:55<02:30,  2.80it/s] 16%|█▌        | 81/500 [01:02<08:23,  1.20s/it] 17%|█▋        | 83/500 [01:02<06:01,  1.15it/s] 17%|█▋        | 85/500 [01:02<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:02<03:13,  2.13it/s] 18%|█▊        | 89/500 [01:02<02:25,  2.83it/s] 18%|█▊        | 91/500 [01:09<08:13,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:54,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:17,  1.57it/s] 19%|█▉        | 97/500 [01:09<03:09,  2.12it/s] 20%|█▉        | 99/500 [01:09<02:22,  2.81it/s] 20%|██        | 101/500 [01:16<08:10,  1.23s/it] 21%|██        | 103/500 [01:16<05:49,  1.13it/s] 21%|██        | 105/500 [01:16<04:11,  1.57it/s] 21%|██▏       | 107/500 [01:16<03:03,  2.14it/s] 22%|██▏       | 109/500 [01:16<02:15,  2.88it/s] 22%|██▏       | 111/500 [01:23<07:44,  1.19s/it] 23%|██▎       | 113/500 [01:23<05:32,  1.16it/s] 23%|██▎       | 115/500 [01:23<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:23<02:55,  2.18it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:30<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:30<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:30<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:30<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:30<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:37<07:17,  1.19s/it] 27%|██▋       | 133/500 [01:37<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:37<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:37<02:44,  2.20it/s]Valid Loss:  0.0019328861963003874
Epoch:  71  	Training Loss: 0.0018038364360108972
Test Loss:  0.0017504158895462751
Valid Loss:  0.0019335625693202019
Epoch:  72  	Training Loss: 0.0018037885893136263
Test Loss:  0.0017508366145193577
Valid Loss:  0.0019344771280884743
Epoch:  73  	Training Loss: 0.0018037479603663087
Test Loss:  0.0017507248558104038
Valid Loss:  0.0019355097319930792
Epoch:  74  	Training Loss: 0.0018037079134956002
Test Loss:  0.0017510242760181427
Valid Loss:  0.001936224172823131
Epoch:  75  	Training Loss: 0.0018036719411611557
Test Loss:  0.0017510093748569489
Valid Loss:  0.0019369807559996843
Epoch:  76  	Training Loss: 0.0018036391120404005
Test Loss:  0.0017518096137791872
Valid Loss:  0.0019373162649571896
Epoch:  77  	Training Loss: 0.0018036067485809326
Test Loss:  0.0017519762041047215
Valid Loss:  0.0019379450241103768
Epoch:  78  	Training Loss: 0.0018035754328593612
Test Loss:  0.0017522363923490047
Valid Loss:  0.0019384634215384722
Epoch:  79  	Training Loss: 0.0018035480752587318
Test Loss:  0.001752415206283331
Valid Loss:  0.001938975416123867
Epoch:  80  	Training Loss: 0.0018035187385976315
Test Loss:  0.0017525739967823029
Valid Loss:  0.0019394310656934977
Epoch:  81  	Training Loss: 0.0018034884706139565
Test Loss:  0.0017522959969937801
Valid Loss:  0.0019400172168388963
Epoch:  82  	Training Loss: 0.0018034627428278327
Test Loss:  0.001752813346683979
Valid Loss:  0.0019401672761887312
Epoch:  83  	Training Loss: 0.0018034400418400764
Test Loss:  0.0017525898292660713
Valid Loss:  0.001940650981850922
Epoch:  84  	Training Loss: 0.0018034200184047222
Test Loss:  0.0017530254554003477
Valid Loss:  0.0019407797371968627
Epoch:  85  	Training Loss: 0.0018033997621387243
Test Loss:  0.001752533484250307
Valid Loss:  0.001941298134624958
Epoch:  86  	Training Loss: 0.0018033822998404503
Test Loss:  0.0017531723715364933
Valid Loss:  0.0019412415567785501
Epoch:  87  	Training Loss: 0.0018033606465905905
Test Loss:  0.0017532785423099995
Valid Loss:  0.0019414837006479502
Epoch:  88  	Training Loss: 0.0018033442320302129
Test Loss:  0.00175335758831352
Valid Loss:  0.001941717229783535
Epoch:  89  	Training Loss: 0.001803327351808548
Test Loss:  0.0017534246435388923
Valid Loss:  0.0019419286400079727
Epoch:  90  	Training Loss: 0.0018033108208328485
Test Loss:  0.0017534218495711684
Valid Loss:  0.0019421449396759272
Epoch:  91  	Training Loss: 0.0018032955704256892
Test Loss:  0.001753539778292179
Valid Loss:  0.0019422838231548667
Epoch:  92  	Training Loss: 0.001803276943974197
Test Loss:  0.0017535953084006906
Valid Loss:  0.0019424348138272762
Epoch:  93  	Training Loss: 0.0018032616935670376
Test Loss:  0.001753637450747192
Valid Loss:  0.0019425801001489162
Epoch:  94  	Training Loss: 0.0018032471416518092
Test Loss:  0.0017536779632791877
Valid Loss:  0.0019427051302045584
Epoch:  95  	Training Loss: 0.0018032328225672245
Test Loss:  0.0017537213861942291
Valid Loss:  0.0019428185187280178
Epoch:  96  	Training Loss: 0.0018032208317890763
Test Loss:  0.0017537572421133518
Valid Loss:  0.0019429269013926387
Epoch:  97  	Training Loss: 0.0018032104708254337
Test Loss:  0.0017537851817905903
Valid Loss:  0.001943023526109755
Epoch:  98  	Training Loss: 0.0018032013904303312
Test Loss:  0.001753809629008174
Valid Loss:  0.0019431090913712978
Epoch:  99  	Training Loss: 0.001803190098144114
Test Loss:  0.0017538327956572175
Valid Loss:  0.0019431887194514275
Epoch:  100  	Training Loss: 0.001803177990950644
Test Loss:  0.001753856660798192
Valid Loss:  0.0019432594999670982
Epoch:  101  	Training Loss: 0.001803169958293438
Test Loss:  0.0017538749380037189
Valid Loss:  0.0019433286506682634
Epoch:  102  	Training Loss: 0.0018031590152531862
Test Loss:  0.0017538944957777858
Valid Loss:  0.0019433855777606368
Epoch:  103  	Training Loss: 0.0018031499348580837
Test Loss:  0.0017539081163704395
Valid Loss:  0.001943437848240137
Epoch:  104  	Training Loss: 0.0018031378276646137
Test Loss:  0.0017539201071485877
Valid Loss:  0.00194348709192127
Epoch:  105  	Training Loss: 0.001803130260668695
Test Loss:  0.0017539337277412415
Valid Loss:  0.0019435221329331398
Epoch:  106  	Training Loss: 0.0018031179206445813
Test Loss:  0.0017539439722895622
Valid Loss:  0.001943565788678825
Epoch:  107  	Training Loss: 0.0018031070940196514
Test Loss:  0.0017539651598781347
Valid Loss:  0.0019435985013842583
Epoch:  108  	Training Loss: 0.001803097315132618
Test Loss:  0.0017539621330797672
Valid Loss:  0.0019436273723840714
Epoch:  109  	Training Loss: 0.0018030873034149408
Test Loss:  0.0017539793625473976
Valid Loss:  0.001943659968674183
Epoch:  110  	Training Loss: 0.001803076360374689
Test Loss:  0.001753986463882029
Valid Loss:  0.0019436739385128021
Epoch:  111  	Training Loss: 0.001803067047148943
Test Loss:  0.0017539896070957184
Valid Loss:  0.0019436952425166965
Epoch:  112  	Training Loss: 0.0018030572682619095
Test Loss:  0.0017540024127811193
Valid Loss:  0.0019437242299318314
Epoch:  113  	Training Loss: 0.0018030456267297268
Test Loss:  0.001754004624672234
Valid Loss:  0.001943735871464014
Epoch:  114  	Training Loss: 0.0018030377104878426
Test Loss:  0.0017540114931762218
Valid Loss:  0.0019437451846897602
Epoch:  115  	Training Loss: 0.0018030273495242
Test Loss:  0.0017540183616802096
Valid Loss:  0.0019437640439718962
Epoch:  116  	Training Loss: 0.0018030183855444193
Test Loss:  0.0017540191765874624
Valid Loss:  0.0019437777809798717
Epoch:  117  	Training Loss: 0.0018030076753348112
Test Loss:  0.001754025579430163
Valid Loss:  0.0019437817391008139
Epoch:  118  	Training Loss: 0.0018029996426776052
Test Loss:  0.0017540256958454847
Valid Loss:  0.001943791750818491
Epoch:  119  	Training Loss: 0.0018029913771897554
Test Loss:  0.0017540291883051395
Valid Loss:  0.0019437945447862148
Epoch:  120  	Training Loss: 0.0018029838101938367
Test Loss:  0.0017540310509502888
Valid Loss:  0.001943802461028099
Epoch:  121  	Training Loss: 0.0018029746133834124
Test Loss:  0.0017540310509502888
Valid Loss:  0.0019438071176409721
Epoch:  122  	Training Loss: 0.0018029669299721718
Test Loss:  0.0017540326807647943
Valid Loss:  0.0019438149174675345
Epoch:  123  	Training Loss: 0.0018029583152383566
Test Loss:  0.0017540357075631618
Valid Loss:  0.001943819923326373
Epoch:  124  	Training Loss: 0.001802952727302909
Test Loss:  0.0017537216190248728
Valid Loss:  0.001943937735632062
Epoch:  125  	Training Loss: 0.0018029441125690937
Test Loss:  0.0017540031112730503
Valid Loss:  0.0019437704468145967
Epoch:  126  	Training Loss: 0.001802934450097382
Test Loss:  0.0017539099790155888
Valid Loss:  0.001943816663697362
Epoch:  127  	Training Loss: 0.001802929094992578
Test Loss:  0.0017540068365633488
Valid Loss:  0.0019437602022662759
Epoch:  128  	Training Loss: 0.0018029209459200501
Test Loss:  0.0017540202243253589
Valid Loss:  0.0019437624141573906
Epoch:  129  	Training Loss: 0.0018029124476015568
Test Loss:  0.0017540212720632553
Valid Loss:  0.0019437761511653662
Epoch:  130  	Training Loss: 0.0018029059283435345
Test Loss:  0.0017540259286761284
Valid Loss:  0.0019437724258750677
Epoch:  131  	Training Loss: 0.0018028984777629375
Test Loss:  0.0017540236003696918
Valid Loss:  0.0019437787123024464
Epoch:  132  	Training Loss: 0.0018028917256742716
Test Loss:  0.0017540303524583578
Valid Loss:  0.0019437881419435143
Epoch:  133  	Training Loss: 0.001802882645279169
Test Loss:  0.001754028839059174
Valid Loss:  0.0019437853479757905
Epoch:  134  	Training Loss: 0.0018028749618679285
Test Loss:  0.0017540305852890015
Valid Loss:  0.0019437882583588362
Epoch:  135  	Training Loss: 0.0018028673948720098
Test Loss:  0.0017540300032123923
Valid Loss:  0.0019437916344031692
Epoch:  136  	Training Loss: 0.001802859827876091
Test Loss:  0.001754034194163978
Valid Loss:  0.0019437867449596524
Epoch:  137  	Training Loss: 0.0018028520280495286
Test Loss:  0.0017540385015308857
Valid Loss:  0.0019437952432781458
Epoch:  138  	Training Loss: 0.0018028466729447246
Test Loss:  0.0017540398985147476
Valid Loss:  0.0019437901210039854
Epoch:  139  	Training Loss: 0.001802840968593955
Test Loss:   28%|██▊       | 139/500 [01:37<02:02,  2.95it/s] 28%|██▊       | 141/500 [01:43<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:44<05:06,  1.17it/s] 29%|██▉       | 145/500 [01:44<03:40,  1.61it/s] 29%|██▉       | 147/500 [01:44<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:44<01:58,  2.96it/s] 30%|███       | 151/500 [01:50<06:51,  1.18s/it] 31%|███       | 153/500 [01:50<04:54,  1.18it/s] 31%|███       | 155/500 [01:51<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:51<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.99it/s] 32%|███▏      | 161/500 [01:57<06:42,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:47,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:26,  1.62it/s] 33%|███▎      | 167/500 [01:58<02:30,  2.22it/s] 34%|███▍      | 169/500 [01:58<01:50,  2.98it/s] 34%|███▍      | 171/500 [02:04<06:37,  1.21s/it] 35%|███▍      | 173/500 [02:04<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:05<03:23,  1.59it/s] 35%|███▌      | 177/500 [02:05<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:05<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:11<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:11<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:11<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:11<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:12<01:44,  2.99it/s] 38%|███▊      | 191/500 [02:18<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:18<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:18<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:18<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:18<01:40,  3.00it/s] 40%|████      | 201/500 [02:25<06:00,  1.21s/it] 41%|████      | 203/500 [02:25<04:17,  1.15it/s] 41%|████      | 205/500 [02:25<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:25<02:14,  2.18it/s]0.0017540401313453913
Valid Loss:  0.001943797105923295
Epoch:  140  	Training Loss: 0.001802832935936749
Test Loss:  0.0017540454864501953
Valid Loss:  0.0019437912851572037
Epoch:  141  	Training Loss: 0.0018028258346021175
Test Loss:  0.0017540431581437588
Valid Loss:  0.0019437879091128707
Epoch:  142  	Training Loss: 0.0018028176855295897
Test Loss:  0.0017540412954986095
Valid Loss:  0.0019437862792983651
Epoch:  143  	Training Loss: 0.0018028132617473602
Test Loss:  0.001754045020788908
Valid Loss:  0.0019437815062701702
Epoch:  144  	Training Loss: 0.0018028044141829014
Test Loss:  0.0017540487460792065
Valid Loss:  0.0019437845330685377
Epoch:  145  	Training Loss: 0.001802797894924879
Test Loss:  0.001754044322296977
Valid Loss:  0.0019437820883467793
Epoch:  146  	Training Loss: 0.0018027909100055695
Test Loss:  0.0017540489789098501
Valid Loss:  0.0019437804585322738
Epoch:  147  	Training Loss: 0.0018027852056548
Test Loss:  0.0017540554981678724
Valid Loss:  0.001943779643625021
Epoch:  148  	Training Loss: 0.0018027795013040304
Test Loss:  0.0017540572443976998
Valid Loss:  0.00194377894513309
Epoch:  149  	Training Loss: 0.001802772399969399
Test Loss:  0.001754051772877574
Valid Loss:  0.0019437752198427916
Epoch:  150  	Training Loss: 0.0018027673941105604
Test Loss:  0.001754057127982378
Valid Loss:  0.0019437723094597459
Epoch:  151  	Training Loss: 0.0018027611076831818
Test Loss:  0.0017540622502565384
Valid Loss:  0.0019437606679275632
Epoch:  152  	Training Loss: 0.0018027529586106539
Test Loss:  0.0017540566623210907
Valid Loss:  0.0019437633454799652
Epoch:  153  	Training Loss: 0.0018027473706752062
Test Loss:  0.0017540582921355963
Valid Loss:  0.001943760784342885
Epoch:  154  	Training Loss: 0.0018027416663244367
Test Loss:  0.0017540593398734927
Valid Loss:  0.0019437549635767937
Epoch:  155  	Training Loss: 0.0018027342157438397
Test Loss:  0.0017540580593049526
Valid Loss:  0.0019437551964074373
Epoch:  156  	Training Loss: 0.0018027267651632428
Test Loss:  0.0017540580593049526
Valid Loss:  0.001943752053193748
Epoch:  157  	Training Loss: 0.0018027217593044043
Test Loss:  0.0017540594562888145
Valid Loss:  0.0019437432056292892
Epoch:  158  	Training Loss: 0.0018027162877842784
Test Loss:  0.0017540643457323313
Valid Loss:  0.0019437418086454272
Epoch:  159  	Training Loss: 0.0018027073238044977
Test Loss:  0.0017540606204420328
Valid Loss:  0.0019437405280768871
Epoch:  160  	Training Loss: 0.0018027027836069465
Test Loss:  0.0017540614353492856
Valid Loss:  0.001943731214851141
Epoch:  161  	Training Loss: 0.0018026973120868206
Test Loss:  0.0017540652770549059
Valid Loss:  0.0019437327282503247
Epoch:  162  	Training Loss: 0.0018026904435828328
Test Loss:  0.001754063880071044
Valid Loss:  0.00194372923579067
Epoch:  163  	Training Loss: 0.0018026827601715922
Test Loss:  0.0017540701664984226
Valid Loss:  0.0019437219016253948
Epoch:  164  	Training Loss: 0.0018026779871433973
Test Loss:  0.0017540703993290663
Valid Loss:  0.0019437193404883146
Epoch:  165  	Training Loss: 0.0018026719335466623
Test Loss:  0.0017540730768814683
Valid Loss:  0.0019437181763350964
Epoch:  166  	Training Loss: 0.0018026656471192837
Test Loss:  0.001754074590280652
Valid Loss:  0.0019437179435044527
Epoch:  167  	Training Loss: 0.0018026591278612614
Test Loss:  0.0017540708649903536
Valid Loss:  0.0019437095616012812
Epoch:  168  	Training Loss: 0.0018026537727564573
Test Loss:  0.0017540761036798358
Valid Loss:  0.001943705603480339
Epoch:  169  	Training Loss: 0.0018026476027444005
Test Loss:  0.0017540721455588937
Valid Loss:  0.0019437046721577644
Epoch:  170  	Training Loss: 0.0018026417819783092
Test Loss:  0.001754075288772583
Valid Loss:  0.0019437051378190517
Epoch:  171  	Training Loss: 0.0018026353791356087
Test Loss:  0.0017540771514177322
Valid Loss:  0.0019437007140368223
Epoch:  172  	Training Loss: 0.001802631188184023
Test Loss:  0.0017540791304782033
Valid Loss:  0.001943701645359397
Epoch:  173  	Training Loss: 0.0018026258330792189
Test Loss:  0.001754077384248376
Valid Loss:  0.0019436965230852365
Epoch:  174  	Training Loss: 0.0018026211764663458
Test Loss:  0.001754076685756445
Valid Loss:  0.001943695591762662
Epoch:  175  	Training Loss: 0.0018026158213615417
Test Loss:  0.001754086697474122
Valid Loss:  0.0019436918664723635
Epoch:  176  	Training Loss: 0.0018026115139946342
Test Loss:  0.0017540822736918926
Valid Loss:  0.0019436896545812488
Epoch:  177  	Training Loss: 0.001802606275305152
Test Loss:  0.001754083437845111
Valid Loss:  0.001943684183061123
Epoch:  178  	Training Loss: 0.0018026020843535662
Test Loss:  0.0017540837870910764
Valid Loss:  0.00194368208758533
Epoch:  179  	Training Loss: 0.0018025976605713367
Test Loss:  0.0017540850676596165
Valid Loss:  0.0019436830189079046
Epoch:  180  	Training Loss: 0.0018025937024503946
Test Loss:  0.001754085998982191
Valid Loss:  0.0019436758011579514
Epoch:  181  	Training Loss: 0.0018025884637609124
Test Loss:  0.0017540879780426621
Valid Loss:  0.001943678129464388
Epoch:  182  	Training Loss: 0.001802586717531085
Test Loss:  0.0017540884437039495
Valid Loss:  0.0019436721922829747
Epoch:  183  	Training Loss: 0.0018025824101641774
Test Loss:  0.0017540872795507312
Valid Loss:  0.0019436709117144346
Epoch:  184  	Training Loss: 0.0018025783356279135
Test Loss:  0.0017540897242724895
Valid Loss:  0.0019436690490692854
Epoch:  185  	Training Loss: 0.001802574610337615
Test Loss:  0.0017540906555950642
Valid Loss:  0.0019436678849160671
Epoch:  186  	Training Loss: 0.0018025680910795927
Test Loss:  0.001754093449562788
Valid Loss:  0.0019436681177467108
Epoch:  187  	Training Loss: 0.0018025656463578343
Test Loss:  0.0017540928674861789
Valid Loss:  0.0019436657894402742
Epoch:  188  	Training Loss: 0.0018025607569143176
Test Loss:  0.0017540962435305119
Valid Loss:  0.001943661249242723
Epoch:  189  	Training Loss: 0.0018025554018095136
Test Loss:  0.0017540950793772936
Valid Loss:  0.0019436588045209646
Epoch:  190  	Training Loss: 0.0018025529570877552
Test Loss:  0.001754090073518455
Valid Loss:  0.0019436550792306662
Epoch:  191  	Training Loss: 0.0018025479512289166
Test Loss:  0.0017540946137160063
Valid Loss:  0.0019436501897871494
Epoch:  192  	Training Loss: 0.0018025427125394344
Test Loss:  0.001754094148054719
Valid Loss:  0.001943649840541184
Epoch:  193  	Training Loss: 0.0018025394529104233
Test Loss:  0.0017540940316393971
Valid Loss:  0.001943654497154057
Epoch:  194  	Training Loss: 0.0018025372410193086
Test Loss:  0.0017540942644700408
Valid Loss:  0.0019436465809121728
Epoch:  195  	Training Loss: 0.0018025318859145045
Test Loss:  0.0017540935659781098
Valid Loss:  0.0019436478614807129
Epoch:  196  	Training Loss: 0.001802527578547597
Test Loss:  0.00175409484654665
Valid Loss:  0.0019436436705291271
Epoch:  197  	Training Loss: 0.0018025244353339076
Test Loss:  0.0017537394305691123
Valid Loss:  0.0019437787123024464
Epoch:  198  	Training Loss: 0.0018025182653218508
Test Loss:  0.0017540662083774805
Valid Loss:  0.0019435841822996736
Epoch:  199  	Training Loss: 0.0018025183817371726
Test Loss:  0.0017540797125548124
Valid Loss:  0.0019435792928561568
Epoch:  200  	Training Loss: 0.0018025119788944721
Test Loss:  0.0017540848348289728
Valid Loss:  0.001943582552485168
Epoch:  201  	Training Loss: 0.0018025110475718975
Test Loss:  0.0017540896078571677
Valid Loss:  0.0019435824360698462
Epoch:  202  	Training Loss: 0.001802506623789668
Test Loss:  0.0017540858825668693
Valid Loss:  0.0019435877911746502
Epoch:  203  	Training Loss: 0.0018025056924670935
Test Loss:  0.0017540901899337769
Valid Loss:  0.0019435894209891558
Epoch:  204  	Training Loss: 0.0018025049939751625
Test Loss:  0.0017540935659781098
Valid Loss:  0.0019435904687270522
Epoch:  205  	Training Loss: 0.0018024980090558529
Test Loss:  0.001754092751070857
Valid Loss:  0.0019435955910012126
Epoch:  206  	Training Loss: 0.001802494516596198
Test Loss:  0.0017540933331474662
Valid Loss:  0.001943598035722971
Epoch:  207  	Training Loss: 0.0018024921882897615
Test Loss:  0.0017540960106998682
Valid Loss:  0.0019436003640294075
 42%|████▏     | 209/500 [02:25<01:39,  2.93it/s] 42%|████▏     | 211/500 [02:32<05:48,  1.21s/it] 43%|████▎     | 213/500 [02:32<04:08,  1.16it/s] 43%|████▎     | 215/500 [02:32<02:59,  1.59it/s] 43%|████▎     | 217/500 [02:32<02:12,  2.14it/s] 44%|████▍     | 219/500 [02:33<01:39,  2.83it/s] 44%|████▍     | 221/500 [02:39<05:39,  1.22s/it] 45%|████▍     | 223/500 [02:39<04:02,  1.14it/s] 45%|████▌     | 225/500 [02:39<02:53,  1.58it/s] 45%|████▌     | 227/500 [02:39<02:06,  2.16it/s] 46%|████▌     | 229/500 [02:40<01:33,  2.91it/s] 46%|████▌     | 231/500 [02:46<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:46<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:47<01:29,  2.90it/s] 48%|████▊     | 241/500 [02:53<05:14,  1.22s/it] 49%|████▊     | 243/500 [02:53<03:45,  1.14it/s] 49%|████▉     | 245/500 [03:00<06:41,  1.57s/it] 49%|████▉     | 247/500 [03:00<04:44,  1.12s/it] 50%|████▉     | 249/500 [03:00<03:22,  1.24it/s] 50%|█████     | 251/500 [03:06<06:15,  1.51s/it] 51%|█████     | 253/500 [03:06<04:25,  1.08s/it] 51%|█████     | 255/500 [03:06<03:09,  1.29it/s] 51%|█████▏    | 257/500 [03:07<02:16,  1.78it/s] 52%|█████▏    | 259/500 [03:07<01:39,  2.42it/s] 52%|█████▏    | 259/500 [03:19<01:39,  2.42it/s] 52%|█████▏    | 261/500 [03:19<08:40,  2.18s/it] 53%|█████▎    | 263/500 [03:19<06:06,  1.55s/it] 53%|█████▎    | 265/500 [03:20<04:19,  1.10s/it] 53%|█████▎    | 267/500 [03:20<03:04,  1.26it/s] 54%|█████▍    | 269/500 [03:20<02:12,  1.74it/s] 54%|█████▍    | 271/500 [03:26<05:11,  1.36s/it] 55%|█████▍    | 273/500 [03:26<03:41,  1.02it/s]Epoch:  208  	Training Loss: 0.0018024869496002793
Test Loss:  0.0017540946137160063
Valid Loss:  0.0019436024595052004
Epoch:  209  	Training Loss: 0.0018024854362010956
Test Loss:  0.0017540974076837301
Valid Loss:  0.0019436044385656714
Epoch:  210  	Training Loss: 0.0018024805467575788
Test Loss:  0.0017540919361636043
Valid Loss:  0.001943604787811637
Epoch:  211  	Training Loss: 0.0018024805467575788
Test Loss:  0.0017540967091917992
Valid Loss:  0.0019436071161180735
Epoch:  212  	Training Loss: 0.001802479149773717
Test Loss:  0.0017541006673127413
Valid Loss:  0.001943602692335844
Epoch:  213  	Training Loss: 0.0018024714663624763
Test Loss:  0.001754104276187718
Valid Loss:  0.0019436051370576024
Epoch:  214  	Training Loss: 0.0018024705350399017
Test Loss:  0.0017541047418490052
Valid Loss:  0.0019436061847954988
Epoch:  215  	Training Loss: 0.0018024662276729941
Test Loss:  0.001754101598635316
Valid Loss:  0.0019436039729043841
Epoch:  216  	Training Loss: 0.0018024637829512358
Test Loss:  0.0017541081178933382
Valid Loss:  0.0019436029251664877
Epoch:  217  	Training Loss: 0.0018024600576609373
Test Loss:  0.001754106255248189
Valid Loss:  0.0019436028087511659
Epoch:  218  	Training Loss: 0.0018024584278464317
Test Loss:  0.0017541097477078438
Valid Loss:  0.0019436024595052004
Epoch:  219  	Training Loss: 0.001802455517463386
Test Loss:  0.00175410695374012
Valid Loss:  0.0019436012953519821
Epoch:  220  	Training Loss: 0.0018024495802819729
Test Loss:  0.0017541019478812814
Valid Loss:  0.0019436032744124532
Epoch:  221  	Training Loss: 0.0018024491146206856
Test Loss:  0.0017541097477078438
Valid Loss:  0.001943604089319706
Epoch:  222  	Training Loss: 0.0018024457385763526
Test Loss:  0.0017541078850626945
Valid Loss:  0.0019436064176261425
Epoch:  223  	Training Loss: 0.0018024446908384562
Test Loss:  0.0017541100969538093
Valid Loss:  0.0019436032744124532
Epoch:  224  	Training Loss: 0.0018024409655481577
Test Loss:  0.0017541110282763839
Valid Loss:  0.0019435985013842583
Epoch:  225  	Training Loss: 0.0018024381715804338
Test Loss:  0.0017541081178933382
Valid Loss:  0.0019435985013842583
Epoch:  226  	Training Loss: 0.0018024349119514227
Test Loss:  0.0017541090492159128
Valid Loss:  0.0019436002476140857
Epoch:  227  	Training Loss: 0.0018024331657215953
Test Loss:  0.0017541121924296021
Valid Loss:  0.001943600713275373
Epoch:  228  	Training Loss: 0.0018024309538304806
Test Loss:  0.0017541057895869017
Valid Loss:  0.0019435975700616837
Epoch:  229  	Training Loss: 0.001802427927032113
Test Loss:  0.001754104276187718
Valid Loss:  0.0019435978028923273
Epoch:  230  	Training Loss: 0.0018024244345724583
Test Loss:  0.0017541100969538093
Valid Loss:  0.0019435988506302238
Epoch:  231  	Training Loss: 0.0018024226883426309
Test Loss:  0.0017541092820465565
Valid Loss:  0.0019436024595052004
Epoch:  232  	Training Loss: 0.0018024207092821598
Test Loss:  0.0017541074194014072
Valid Loss:  0.0019436008296906948
Epoch:  233  	Training Loss: 0.0018024169839918613
Test Loss:  0.0017541121924296021
Valid Loss:  0.001943593262694776
Epoch:  234  	Training Loss: 0.001802416518330574
Test Loss:  0.001754110911861062
Valid Loss:  0.001943600713275373
Epoch:  235  	Training Loss: 0.0018024139571934938
Test Loss:  0.0017541147535666823
Valid Loss:  0.001943598734214902
Epoch:  236  	Training Loss: 0.0018024113960564137
Test Loss:  0.0017541139386594296
Valid Loss:  0.0019435960566625
Epoch:  237  	Training Loss: 0.0018024079035967588
Test Loss:  0.0017541125416755676
Valid Loss:  0.0019435957074165344
Epoch:  238  	Training Loss: 0.0018024072051048279
Test Loss:  0.0017541141714900732
Valid Loss:  0.0019435901194810867
Epoch:  239  	Training Loss: 0.0018024041783064604
Test Loss:  0.0017541140550747514
Valid Loss:  0.0019435882568359375
Epoch:  240  	Training Loss: 0.0018024023156613111
Test Loss:  0.0017541141714900732
Valid Loss:  0.0019435875583440065
Epoch:  241  	Training Loss: 0.001802401035092771
Test Loss:  0.0017541100969538093
Valid Loss:  0.0019435887224972248
Epoch:  242  	Training Loss: 0.0018023988232016563
Test Loss:  0.0017541099805384874
Valid Loss:  0.0019435840658843517
Epoch:  243  	Training Loss: 0.0018023955635726452
Test Loss:  0.0017541080014780164
Valid Loss:  0.0019435858121141791
Epoch:  244  	Training Loss: 0.0018023957964032888
Test Loss:  0.0017541110282763839
Valid Loss:  0.001943584531545639
Epoch:  245  	Training Loss: 0.0018023918382823467
Test Loss:  0.0017541151028126478
Valid Loss:  0.0019435868598520756
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0018023885786533356
Test Loss:  0.0017541160341352224
Valid Loss:  0.0019435851136222482
Epoch:  247  	Training Loss: 0.0018023892771452665
Test Loss:  0.0017541160341352224
Valid Loss:  0.001943588606081903
Epoch:  248  	Training Loss: 0.0018023870652541518
Test Loss:  0.0017541144043207169
Valid Loss:  0.001943586627021432
Epoch:  249  	Training Loss: 0.0018023839220404625
Test Loss:  0.0017541083507239819
Valid Loss:  0.0019435873255133629
Epoch:  250  	Training Loss: 0.0018023832235485315
Test Loss:  0.0017541095148772001
Valid Loss:  0.0019435820868238807
Epoch:  251  	Training Loss: 0.001802380895242095
Test Loss:  0.0017541106790304184
Valid Loss:  0.0019435797585174441
Epoch:  252  	Training Loss: 0.0018023813609033823
Test Loss:  0.0017541144043207169
Valid Loss:  0.0019435803405940533
Epoch:  253  	Training Loss: 0.001802378916181624
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435863941907883
Epoch:  254  	Training Loss: 0.0018023786833509803
Test Loss:  0.0017541145207360387
Valid Loss:  0.0019435808062553406
Epoch:  255  	Training Loss: 0.0018023769371211529
Test Loss:  0.001754113007336855
Valid Loss:  0.0019435785943642259
Epoch:  256  	Training Loss: 0.0018023760057985783
Test Loss:  0.0017541168490424752
Valid Loss:  0.001943579874932766
Epoch:  257  	Training Loss: 0.0018023774027824402
Test Loss:  0.00175411906093359
Valid Loss:  0.0019435812719166279
Epoch:  258  	Training Loss: 0.001802377519197762
Test Loss:  0.0017541146371513605
Valid Loss:  0.001943577779456973
Epoch:  259  	Training Loss: 0.0018023744923993945
Test Loss:  0.0017541170818731189
Valid Loss:  0.0019435766153037548
Epoch:  260  	Training Loss: 0.0018023746088147163
Test Loss:  0.001754117663949728
Valid Loss:  0.0019435762660577893
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.00180237356107682
Test Loss:  0.0017541145207360387
Valid Loss:  0.001943575101904571
Epoch:  262  	Training Loss: 0.001802372746169567
Test Loss:  0.001754116383381188
Valid Loss:  0.0019435752183198929
Epoch:  263  	Training Loss: 0.0018023725133389235
Test Loss:  0.0017541180131956935
Valid Loss:  0.001943578477948904
Epoch:  264  	Training Loss: 0.0018023716984316707
Test Loss:  0.0017541182460263371
Valid Loss:  0.0019435780122876167
Epoch:  265  	Training Loss: 0.0018023713491857052
Test Loss:  0.0017541171982884407
Valid Loss:  0.0019435766153037548
Epoch:  266  	Training Loss: 0.0018023697193711996
Test Loss:  0.0017541140550747514
Valid Loss:  0.0019435761496424675
Epoch:  267  	Training Loss: 0.001802369486540556
Test Loss:  0.0017541134729981422
Valid Loss:  0.0019435721915215254
Epoch:  268  	Training Loss: 0.0018023699522018433
Test Loss:  0.0017541131237521768
Valid Loss:  0.0019435739377513528
Epoch:  269  	Training Loss: 0.001802369486540556
Test Loss:  0.0017541144043207169
Valid Loss:  0.001943574519827962
Epoch:  270  	Training Loss: 0.0018023692537099123
Test Loss:  0.001754116383381188
Valid Loss:  0.00194357440341264
Epoch:  271  	Training Loss: 0.0018023690208792686
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435752183198929
Epoch:  272  	Training Loss: 0.0018023706506937742
Test Loss:  0.0017541161505505443
Valid Loss:  0.0019435782451182604
Epoch:  273  	Training Loss: 0.0018023692537099123
Test Loss:  0.001754113705828786
Valid Loss:  0.0019435699796304107
Epoch:  274  	Training Loss: 0.0018023683223873377
Test Loss:   55%|█████▌    | 275/500 [03:27<02:38,  1.42it/s] 55%|█████▌    | 277/500 [03:27<01:54,  1.95it/s] 56%|█████▌    | 279/500 [03:27<01:23,  2.64it/s] 56%|█████▌    | 279/500 [03:39<01:23,  2.64it/s] 56%|█████▌    | 281/500 [03:39<07:52,  2.16s/it] 57%|█████▋    | 283/500 [03:40<05:33,  1.53s/it] 57%|█████▋    | 285/500 [03:40<03:55,  1.09s/it] 57%|█████▋    | 287/500 [03:40<02:47,  1.27it/s] 58%|█████▊    | 289/500 [03:40<02:00,  1.75it/s] 58%|█████▊    | 291/500 [03:53<07:58,  2.29s/it] 59%|█████▊    | 293/500 [03:53<05:37,  1.63s/it] 59%|█████▉    | 295/500 [03:59<07:08,  2.09s/it] 59%|█████▉    | 297/500 [03:59<05:01,  1.48s/it] 60%|█████▉    | 299/500 [03:59<03:32,  1.06s/it] 60%|██████    | 301/500 [04:12<08:45,  2.64s/it] 61%|██████    | 303/500 [04:12<06:08,  1.87s/it] 61%|██████    | 305/500 [04:12<04:18,  1.33s/it] 61%|██████▏   | 307/500 [04:12<03:03,  1.05it/s] 62%|██████▏   | 309/500 [04:13<02:10,  1.46it/s] 62%|██████▏   | 311/500 [04:25<07:36,  2.41s/it] 63%|██████▎   | 313/500 [04:26<05:19,  1.71s/it] 63%|██████▎   | 315/500 [04:32<06:41,  2.17s/it] 63%|██████▎   | 317/500 [04:32<04:42,  1.54s/it] 64%|██████▍   | 319/500 [04:32<03:18,  1.10s/it] 64%|██████▍   | 321/500 [04:45<08:02,  2.69s/it] 65%|██████▍   | 323/500 [04:45<05:37,  1.91s/it] 65%|██████▌   | 325/500 [04:52<06:41,  2.29s/it] 65%|██████▌   | 327/500 [04:52<04:42,  1.63s/it] 66%|██████▌   | 329/500 [04:52<03:19,  1.17s/it] 66%|██████▌   | 331/500 [05:05<07:37,  2.71s/it] 67%|██████▋   | 333/500 [05:05<05:19,  1.92s/it]0.001754113589413464
Valid Loss:  0.0019435727735981345
Epoch:  275  	Training Loss: 0.0018023662269115448
Test Loss:  0.0017541106790304184
Valid Loss:  0.001943574519827962
Epoch:  276  	Training Loss: 0.0018023665761575103
Test Loss:  0.0017541146371513605
Valid Loss:  0.0019435759168118238
Epoch:  277  	Training Loss: 0.0018023655284196138
Test Loss:  0.0017541110282763839
Valid Loss:  0.001943571143783629
Epoch:  278  	Training Loss: 0.0018023652955889702
Test Loss:  0.0017541106790304184
Valid Loss:  0.0019435712601989508
Epoch:  279  	Training Loss: 0.001802364131435752
Test Loss:  0.0017541106790304184
Valid Loss:  0.0019435714930295944
Epoch:  280  	Training Loss: 0.0018023659940809011
Test Loss:  0.0017541107954457402
Valid Loss:  0.0019435675349086523
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0018023655284196138
Test Loss:  0.0017541127745062113
Valid Loss:  0.0019435698632150888
Epoch:  282  	Training Loss: 0.0018023652955889702
Test Loss:  0.0017541131237521768
Valid Loss:  0.0019435721915215254
Epoch:  283  	Training Loss: 0.0018023649463430047
Test Loss:  0.001754111610352993
Valid Loss:  0.0019435733556747437
Epoch:  284  	Training Loss: 0.0018023656448349357
Test Loss:  0.0017541121924296021
Valid Loss:  0.001943574519827962
Epoch:  285  	Training Loss: 0.001802365412004292
Test Loss:  0.0017541125416755676
Valid Loss:  0.0019435740541666746
Epoch:  286  	Training Loss: 0.001802364131435752
Test Loss:  0.0017541139386594296
Valid Loss:  0.0019435726571828127
Epoch:  287  	Training Loss: 0.0018023637821897864
Test Loss:  0.0017541178967803717
Valid Loss:  0.0019435730064287782
Epoch:  288  	Training Loss: 0.0018023645970970392
Test Loss:  0.0017541185952723026
Valid Loss:  0.0019435709109529853
Epoch:  289  	Training Loss: 0.001802364713512361
Test Loss:  0.0017541174311190844
Valid Loss:  0.00194357440341264
Epoch:  290  	Training Loss: 0.001802364131435752
Test Loss:  0.0017541159177199006
Valid Loss:  0.0019435689318925142
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0018023642478510737
Test Loss:  0.0017541154520586133
Valid Loss:  0.0019435686990618706
Epoch:  292  	Training Loss: 0.0018023643642663956
Test Loss:  0.001754114986397326
Valid Loss:  0.001943568349815905
Epoch:  293  	Training Loss: 0.0018023636657744646
Test Loss:  0.0017541131237521768
Valid Loss:  0.0019435698632150888
Epoch:  294  	Training Loss: 0.0018023637821897864
Test Loss:  0.0017541127745062113
Valid Loss:  0.001943569746799767
Epoch:  295  	Training Loss: 0.0018023626180365682
Test Loss:  0.001754112890921533
Valid Loss:  0.0019435725407674909
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0018023629672825336
Test Loss:  0.0017541126580908895
Valid Loss:  0.001943572424352169
Epoch:  297  	Training Loss: 0.0018023629672825336
Test Loss:  0.0017541131237521768
Valid Loss:  0.001943572424352169
Epoch:  298  	Training Loss: 0.001802362035959959
Test Loss:  0.0017541134729981422
Valid Loss:  0.0019435721915215254
Epoch:  299  	Training Loss: 0.0018023621523752809
Test Loss:  0.0017541132401674986
Valid Loss:  0.0019435716094449162
Epoch:  300  	Training Loss: 0.0018023616867139935
Test Loss:  0.0017541125416755676
Valid Loss:  0.0019435721915215254
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.00180236145388335
Test Loss:  0.001754112890921533
Valid Loss:  0.001943571725860238
Epoch:  302  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541125416755676
Valid Loss:  0.0019435721915215254
Epoch:  303  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.001943571725860238
Epoch:  304  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.00194357184227556
Epoch:  305  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541098641231656
Valid Loss:  0.0019435714930295944
Epoch:  306  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541100969538093
Valid Loss:  0.00194357184227556
Epoch:  307  	Training Loss: 0.0018023611046373844
Test Loss:  0.0017541095148772001
Valid Loss:  0.0019435719586908817
Epoch:  308  	Training Loss: 0.0018023611046373844
Test Loss:  0.0017541098641231656
Valid Loss:  0.0019435720751062036
Epoch:  309  	Training Loss: 0.0018023611046373844
Test Loss:  0.001754110213369131
Valid Loss:  0.0019435719586908817
Epoch:  310  	Training Loss: 0.0018023611046373844
Test Loss:  0.0017541097477078438
Valid Loss:  0.00194357184227556
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.001802361337468028
Test Loss:  0.001754109631292522
Valid Loss:  0.0019435714930295944
Epoch:  312  	Training Loss: 0.0018023611046373844
Test Loss:  0.0017541097477078438
Valid Loss:  0.0019435714930295944
Epoch:  313  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541100969538093
Valid Loss:  0.0019435714930295944
Epoch:  314  	Training Loss: 0.00180236145388335
Test Loss:  0.001754110213369131
Valid Loss:  0.0019435710273683071
Epoch:  315  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541114939376712
Valid Loss:  0.0019435707945376635
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541114939376712
Valid Loss:  0.0019435707945376635
Epoch:  317  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541111446917057
Valid Loss:  0.0019435707945376635
Epoch:  318  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541111446917057
Valid Loss:  0.0019435712601989508
Epoch:  319  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541111446917057
Valid Loss:  0.0019435712601989508
Epoch:  320  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541112611070275
Valid Loss:  0.0019435712601989508
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541113775223494
Valid Loss:  0.0019435712601989508
Epoch:  322  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435712601989508
Epoch:  323  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435712601989508
Epoch:  324  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435712601989508
Epoch:  325  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435710273683071
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541118431836367
Valid Loss:  0.001943571143783629
Epoch:  327  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435709109529853
Epoch:  328  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435709109529853
Epoch:  329  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435713766142726
Epoch:  330  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435716094449162
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435716094449162
Epoch:  332  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.001943571725860238
Epoch:  333  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435716094449162
 67%|██████▋   | 335/500 [05:11<06:18,  2.30s/it] 67%|██████▋   | 337/500 [05:11<04:25,  1.63s/it] 68%|██████▊   | 339/500 [05:11<03:06,  1.16s/it] 68%|██████▊   | 341/500 [05:24<07:05,  2.68s/it] 69%|██████▊   | 343/500 [05:24<04:58,  1.90s/it] 69%|██████▉   | 345/500 [05:30<05:55,  2.30s/it] 69%|██████▉   | 347/500 [05:31<04:09,  1.63s/it] 70%|██████▉   | 349/500 [05:31<02:55,  1.16s/it] 70%|███████   | 351/500 [05:43<06:39,  2.68s/it] 71%|███████   | 353/500 [05:43<04:39,  1.90s/it] 71%|███████   | 355/500 [05:50<05:31,  2.29s/it] 71%|███████▏  | 357/500 [05:50<03:52,  1.62s/it] 72%|███████▏  | 359/500 [05:50<02:42,  1.16s/it] 72%|███████▏  | 361/500 [06:03<06:16,  2.71s/it] 73%|███████▎  | 363/500 [06:03<04:22,  1.92s/it] 73%|███████▎  | 365/500 [06:09<05:09,  2.29s/it] 73%|███████▎  | 367/500 [06:09<03:36,  1.62s/it] 74%|███████▍  | 369/500 [06:09<02:31,  1.16s/it] 74%|███████▍  | 371/500 [06:22<05:47,  2.69s/it] 75%|███████▍  | 373/500 [06:22<04:01,  1.90s/it] 75%|███████▌  | 375/500 [06:28<04:45,  2.28s/it] 75%|███████▌  | 377/500 [06:29<03:19,  1.63s/it] 76%|███████▌  | 379/500 [06:29<02:20,  1.16s/it] 76%|███████▌  | 379/500 [06:39<02:20,  1.16s/it] 76%|███████▌  | 381/500 [06:41<05:23,  2.72s/it] 77%|███████▋  | 383/500 [06:42<03:45,  1.93s/it] 77%|███████▋  | 385/500 [06:48<04:28,  2.33s/it] 77%|███████▋  | 387/500 [06:48<03:07,  1.66s/it] 78%|███████▊  | 389/500 [06:49<02:11,  1.18s/it]Epoch:  334  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435716094449162
Epoch:  335  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.001943571725860238
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.001943571725860238
Epoch:  337  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435716094449162
Epoch:  338  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.001943571725860238
Epoch:  339  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.001943571725860238
Epoch:  340  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.001943571725860238
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435716094449162
Epoch:  342  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435714930295944
Epoch:  343  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435714930295944
Epoch:  344  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435716094449162
Epoch:  345  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  347  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  348  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435719586908817
Epoch:  349  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  350  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435720751062036
Epoch:  352  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  353  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  354  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  355  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  357  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  358  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435719586908817
Epoch:  359  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  360  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  362  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  363  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.00194357184227556
Epoch:  364  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  365  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  367  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  368  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  369  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435719586908817
Epoch:  370  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  372  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.00194357184227556
Epoch:  373  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  374  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  375  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  377  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  378  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  379  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  380  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  382  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.00194357184227556
Epoch:  383  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  384  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  385  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  387  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  388  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.00194357184227556
Epoch:  389  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435720751062036
Epoch:  390  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
 78%|███████▊  | 389/500 [06:59<02:11,  1.18s/it] 78%|███████▊  | 391/500 [07:01<04:55,  2.71s/it] 79%|███████▊  | 393/500 [07:01<03:25,  1.92s/it] 79%|███████▉  | 395/500 [07:08<04:03,  2.32s/it] 79%|███████▉  | 397/500 [07:08<02:49,  1.65s/it] 80%|███████▉  | 399/500 [07:08<01:58,  1.17s/it] 80%|███████▉  | 399/500 [07:19<01:58,  1.17s/it] 80%|████████  | 401/500 [07:21<04:31,  2.74s/it] 81%|████████  | 403/500 [07:21<03:08,  1.94s/it] 81%|████████  | 405/500 [07:27<03:40,  2.32s/it] 81%|████████▏ | 407/500 [07:28<02:33,  1.65s/it] 82%|████████▏ | 409/500 [07:28<01:47,  1.18s/it] 82%|████████▏ | 409/500 [07:39<01:47,  1.18s/it] 82%|████████▏ | 411/500 [07:41<04:04,  2.75s/it] 83%|████████▎ | 413/500 [07:41<02:49,  1.94s/it] 83%|████████▎ | 415/500 [07:47<03:15,  2.30s/it] 83%|████████▎ | 417/500 [07:47<02:15,  1.64s/it] 84%|████████▍ | 419/500 [07:47<01:34,  1.17s/it] 84%|████████▍ | 419/500 [07:59<01:34,  1.17s/it] 84%|████████▍ | 421/500 [08:00<03:32,  2.69s/it] 85%|████████▍ | 423/500 [08:00<02:26,  1.91s/it] 85%|████████▌ | 425/500 [08:06<02:51,  2.29s/it] 85%|████████▌ | 427/500 [08:06<01:58,  1.62s/it] 86%|████████▌ | 429/500 [08:07<01:22,  1.16s/it] 86%|████████▌ | 431/500 [08:19<03:05,  2.68s/it] 87%|████████▋ | 433/500 [08:19<02:07,  1.90s/it] 87%|████████▋ | 435/500 [08:26<02:28,  2.28s/it] 87%|████████▋ | 437/500 [08:26<01:41,  1.62s/it] 88%|████████▊ | 439/500 [08:26<01:10,  1.15s/it] 88%|████████▊ | 441/500 [08:38<02:39,  2.71s/it] 89%|████████▊ | 443/500 [08:39<01:49,  1.92s/it] 89%|████████▉ | 445/500 [08:45<02:06,  2.30s/it]**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  392  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  393  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  394  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  395  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435720751062036
Epoch:  397  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  398  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  399  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  400  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  402  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  403  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  404  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  405  	Training Loss: 0.0018023615702986717
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.00194357184227556
Epoch:  407  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  408  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  409  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  410  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435719586908817
Epoch:  412  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  413  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  414  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  415  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.00194357184227556
Epoch:  417  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  418  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  419  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  420  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435719586908817
Epoch:  422  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  423  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  424  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  425  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  427  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541120760142803
Valid Loss:  0.00194357184227556
Epoch:  428  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  429  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  430  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  432  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.00194357184227556
Epoch:  433  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.00194357184227556
Epoch:  434  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435719586908817
Epoch:  435  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  437  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  438  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  439  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  440  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  442  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  443  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  444  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  445  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435719586908817
Epoch:  447  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:   89%|████████▉ | 447/500 [08:45<01:26,  1.63s/it] 90%|████████▉ | 449/500 [08:45<00:59,  1.16s/it] 90%|█████████ | 451/500 [08:58<02:13,  2.73s/it] 91%|█████████ | 453/500 [08:58<01:30,  1.93s/it] 91%|█████████ | 455/500 [09:05<01:45,  2.33s/it] 91%|█████████▏| 457/500 [09:05<01:11,  1.66s/it] 92%|█████████▏| 459/500 [09:05<00:48,  1.18s/it] 92%|█████████▏| 461/500 [09:18<01:46,  2.73s/it] 93%|█████████▎| 463/500 [09:18<01:11,  1.93s/it] 93%|█████████▎| 465/500 [09:24<01:20,  2.30s/it] 93%|█████████▎| 467/500 [09:24<00:53,  1.63s/it] 94%|█████████▍| 469/500 [09:24<00:35,  1.16s/it] 94%|█████████▍| 471/500 [09:37<01:18,  2.72s/it] 95%|█████████▍| 473/500 [09:37<00:51,  1.93s/it] 95%|█████████▌| 475/500 [09:44<00:57,  2.30s/it] 95%|█████████▌| 477/500 [09:44<00:37,  1.63s/it] 96%|█████████▌| 479/500 [09:44<00:24,  1.16s/it] 96%|█████████▌| 481/500 [09:56<00:51,  2.70s/it] 97%|█████████▋| 483/500 [09:57<00:32,  1.91s/it] 97%|█████████▋| 485/500 [10:03<00:34,  2.28s/it] 97%|█████████▋| 487/500 [10:03<00:21,  1.62s/it] 98%|█████████▊| 489/500 [10:03<00:12,  1.15s/it] 98%|█████████▊| 491/500 [10:16<00:24,  2.70s/it] 99%|█████████▊| 493/500 [10:16<00:13,  1.91s/it] 99%|█████████▉| 495/500 [10:23<00:11,  2.33s/it] 99%|█████████▉| 497/500 [10:23<00:04,  1.65s/it]100%|█████████▉| 499/500 [10:23<00:01,  1.18s/it]100%|██████████| 500/500 [10:29<00:00,  1.26s/it]
0.0019435719586908817
Epoch:  448  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  449  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  450  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  452  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  453  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  454  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  455  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  457  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435720751062036
Epoch:  458  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  459  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  460  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435720751062036
Epoch:  462  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  463  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  464  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  465  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  467  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  468  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  469  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  470  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435720751062036
Epoch:  472  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  473  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  474  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  475  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.00194357184227556
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  477  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  478  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  479  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  480  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.00194357184227556
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  482  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541120760142803
Valid Loss:  0.0019435720751062036
Epoch:  483  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.00194357184227556
Epoch:  484  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  485  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  487  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  488  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  489  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  490  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  492  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  493  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.00194357184227556
Epoch:  494  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  495  	Training Loss: 0.00180236145388335
Test Loss:  0.0017541120760142803
Valid Loss:  0.00194357184227556
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  497  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
Epoch:  498  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435720751062036
Epoch:  499  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541118431836367
Valid Loss:  0.0019435719586908817
Epoch:  500  	Training Loss: 0.001802361337468028
Test Loss:  0.0017541119595989585
Valid Loss:  0.0019435719586908817
**************************************************learning rate decay**************************************************
seed is  14
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:14,  6.28s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:50,  2.87it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:41,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:41,  2.92it/s]  6%|▌         | 31/500 [00:27<09:23,  1.20s/it]  7%|▋         | 33/500 [00:27<06:42,  1.16it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:34,  2.16it/s]  8%|▊         | 39/500 [00:27<02:40,  2.87it/s]  8%|▊         | 41/500 [00:34<09:14,  1.21s/it]  9%|▊         | 43/500 [00:34<06:35,  1.16it/s]  9%|▉         | 45/500 [00:34<04:44,  1.60it/s]  9%|▉         | 47/500 [00:34<03:29,  2.17it/s] 10%|▉         | 49/500 [00:34<02:37,  2.87it/s] 10%|█         | 51/500 [00:41<08:58,  1.20s/it] 11%|█         | 53/500 [00:41<06:25,  1.16it/s] 11%|█         | 55/500 [00:41<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:41<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:47<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:48<06:08,  1.19it/s] 13%|█▎        | 65/500 [00:48<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:48<03:13,  2.23it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.97it/s]Epoch:  1  	Training Loss: 0.240797758102417
Test Loss:  0.1817457377910614
Valid Loss:  0.17564941942691803
Epoch:  2  	Training Loss: 0.13607069849967957
Test Loss:  0.11520268023014069
Valid Loss:  0.11294655501842499
Epoch:  3  	Training Loss: 0.084019735455513
Test Loss:  0.07524214684963226
Valid Loss:  0.07590578496456146
Epoch:  4  	Training Loss: 0.054867856204509735
Test Loss:  0.05029077082872391
Valid Loss:  0.05285629630088806
Epoch:  5  	Training Loss: 0.038213860243558884
Test Loss:  0.036559488624334335
Valid Loss:  0.04011887311935425
Epoch:  6  	Training Loss: 0.029899541288614273
Test Loss:  0.028548136353492737
Valid Loss:  0.03256303071975708
Epoch:  7  	Training Loss: 0.025360409170389175
Test Loss:  0.0235549695789814
Valid Loss:  0.027721989899873734
Epoch:  8  	Training Loss: 0.022576795890927315
Test Loss:  0.020252855494618416
Valid Loss:  0.024376677349209785
Epoch:  9  	Training Loss: 0.020691297948360443
Test Loss:  0.017958354204893112
Valid Loss:  0.021924173459410667
Epoch:  10  	Training Loss: 0.019287826493382454
Test Loss:  0.016280123963952065
Valid Loss:  0.020018938928842545
Epoch:  11  	Training Loss: 0.018141116946935654
Test Loss:  0.014967798255383968
Valid Loss:  0.018473904579877853
Epoch:  12  	Training Loss: 0.017153915017843246
Test Loss:  0.013571853749454021
Valid Loss:  0.01683792658150196
Epoch:  13  	Training Loss: 0.016076523810625076
Test Loss:  0.012480821460485458
Valid Loss:  0.015505041927099228
Epoch:  14  	Training Loss: 0.015138834714889526
Test Loss:  0.01163506880402565
Valid Loss:  0.014428209513425827
Epoch:  15  	Training Loss: 0.014338331297039986
Test Loss:  0.010887100361287594
Valid Loss:  0.013473810628056526
Epoch:  16  	Training Loss: 0.013605048879981041
Test Loss:  0.010224615223705769
Valid Loss:  0.012614374980330467
Epoch:  17  	Training Loss: 0.012922491878271103
Test Loss:  0.009637909010052681
Valid Loss:  0.011842198669910431
Epoch:  18  	Training Loss: 0.01228768564760685
Test Loss:  0.009128202684223652
Valid Loss:  0.011170378886163235
Epoch:  19  	Training Loss: 0.011729983612895012
Test Loss:  0.00844599399715662
Valid Loss:  0.010426059365272522
Epoch:  20  	Training Loss: 0.011233228258788586
Test Loss:  0.008100119419395924
Valid Loss:  0.009900351986289024
Epoch:  21  	Training Loss: 0.010723182931542397
Test Loss:  0.007748518604785204
Valid Loss:  0.009393474087119102
Epoch:  22  	Training Loss: 0.010246125981211662
Test Loss:  0.007651527412235737
Valid Loss:  0.008958980441093445
Epoch:  23  	Training Loss: 0.009618522599339485
Test Loss:  0.007344398181885481
Valid Loss:  0.0085386261343956
Epoch:  24  	Training Loss: 0.009229414165019989
Test Loss:  0.007206985726952553
Valid Loss:  0.008231415413320065
Epoch:  25  	Training Loss: 0.00888407789170742
Test Loss:  0.007004283368587494
Valid Loss:  0.007910310290753841
Epoch:  26  	Training Loss: 0.008568385615944862
Test Loss:  0.006779337301850319
Valid Loss:  0.007588483393192291
Epoch:  27  	Training Loss: 0.00826958753168583
Test Loss:  0.0065491776913404465
Valid Loss:  0.007275005802512169
Epoch:  28  	Training Loss: 0.007985131815075874
Test Loss:  0.006322278641164303
Valid Loss:  0.006973166484385729
Epoch:  29  	Training Loss: 0.007714030798524618
Test Loss:  0.0060917679220438
Valid Loss:  0.006679548416286707
Epoch:  30  	Training Loss: 0.0074562993831932545
Test Loss:  0.005854562856256962
Valid Loss:  0.006392121315002441
Epoch:  31  	Training Loss: 0.007210947573184967
Test Loss:  0.005666906014084816
Valid Loss:  0.006138334050774574
Epoch:  32  	Training Loss: 0.0069740223698318005
Test Loss:  0.005556200165301561
Valid Loss:  0.005963869858533144
Epoch:  33  	Training Loss: 0.006789264734834433
Test Loss:  0.005437236279249191
Valid Loss:  0.0057958876714110374
Epoch:  34  	Training Loss: 0.006619200576096773
Test Loss:  0.005324844270944595
Valid Loss:  0.0056399330496788025
Epoch:  35  	Training Loss: 0.006466503720730543
Test Loss:  0.005139456130564213
Valid Loss:  0.005451574921607971
Epoch:  36  	Training Loss: 0.006320221349596977
Test Loss:  0.005063137970864773
Valid Loss:  0.005319658666849136
Epoch:  37  	Training Loss: 0.0061753494665026665
Test Loss:  0.004966342821717262
Valid Loss:  0.005180436186492443
Epoch:  38  	Training Loss: 0.006036066450178623
Test Loss:  0.004863651003688574
Valid Loss:  0.005041428375989199
Epoch:  39  	Training Loss: 0.005901718512177467
Test Loss:  0.004758347757160664
Valid Loss:  0.004904474131762981
Epoch:  40  	Training Loss: 0.005771819967776537
Test Loss:  0.004655338358134031
Valid Loss:  0.004771705716848373
Epoch:  41  	Training Loss: 0.00564608396962285
Test Loss:  0.004552870988845825
Valid Loss:  0.004642339423298836
Epoch:  42  	Training Loss: 0.005524392705410719
Test Loss:  0.004385089501738548
Valid Loss:  0.004455546848475933
Epoch:  43  	Training Loss: 0.005345901474356651
Test Loss:  0.004235598724335432
Valid Loss:  0.0042797415517270565
Epoch:  44  	Training Loss: 0.005171679425984621
Test Loss:  0.004055493511259556
Valid Loss:  0.004091096110641956
Epoch:  45  	Training Loss: 0.004987013526260853
Test Loss:  0.003941414412111044
Valid Loss:  0.0039394209161400795
Epoch:  46  	Training Loss: 0.004807440564036369
Test Loss:  0.0038312289398163557
Valid Loss:  0.0038025111425668
Epoch:  47  	Training Loss: 0.004656898323446512
Test Loss:  0.0037255531642585993
Valid Loss:  0.003680149093270302
Epoch:  48  	Training Loss: 0.004535961896181107
Test Loss:  0.00363009050488472
Valid Loss:  0.003569468390196562
Epoch:  49  	Training Loss: 0.004427406005561352
Test Loss:  0.0035447082482278347
Valid Loss:  0.0034661428071558475
Epoch:  50  	Training Loss: 0.004324780311435461
Test Loss:  0.003460625186562538
Valid Loss:  0.0033669271506369114
Epoch:  51  	Training Loss: 0.004227807745337486
Test Loss:  0.0033757942728698254
Valid Loss:  0.0032716146670281887
Epoch:  52  	Training Loss: 0.004135860595852137
Test Loss:  0.0032511865720152855
Valid Loss:  0.003136077430099249
Epoch:  53  	Training Loss: 0.0040182084776461124
Test Loss:  0.003146862844005227
Valid Loss:  0.0030181678012013435
Epoch:  54  	Training Loss: 0.0039086551405489445
Test Loss:  0.0030534365214407444
Valid Loss:  0.00291035370901227
Epoch:  55  	Training Loss: 0.0038055162876844406
Test Loss:  0.0029667052440345287
Valid Loss:  0.0028099622577428818
Epoch:  56  	Training Loss: 0.0037083032075315714
Test Loss:  0.00288754771463573
Valid Loss:  0.0027173589915037155
Epoch:  57  	Training Loss: 0.0036162687465548515
Test Loss:  0.0028124426025897264
Valid Loss:  0.0026308761443942785
Epoch:  58  	Training Loss: 0.0035289276856929064
Test Loss:  0.002742903772741556
Valid Loss:  0.002550436183810234
Epoch:  59  	Training Loss: 0.0034457643050700426
Test Loss:  0.0026779896579682827
Valid Loss:  0.0024753068573772907
Epoch:  60  	Training Loss: 0.0033665751107037067
Test Loss:  0.0026168418116867542
Valid Loss:  0.002404657658189535
Epoch:  61  	Training Loss: 0.0032907924614846706
Test Loss:  0.002558128908276558
Valid Loss:  0.0023378184996545315
Epoch:  62  	Training Loss: 0.003218274097889662
Test Loss:  0.0025109117850661278
Valid Loss:  0.0022468892857432365
Epoch:  63  	Training Loss: 0.0031064392533153296
Test Loss:  0.002391848945990205
Valid Loss:  0.0021528713405132294
Epoch:  64  	Training Loss: 0.00301871495321393
Test Loss:  0.0022944193333387375
Valid Loss:  0.0020722486078739166
Epoch:  65  	Training Loss: 0.002938750898465514
Test Loss:  0.0022121225483715534
Valid Loss:  0.001999929081648588
Epoch:  66  	Training Loss: 0.0028639843221753836
Test Loss:  0.0021403643768280745
Valid Loss:  0.0019352200906723738
Epoch:  67  	Training Loss: 0.0027930396609008312
Test Loss:  0.002080578124150634
Valid Loss:  0.0018793377093970776
Epoch:  68  	Training Loss: 0.002728143474087119
Test Loss:  0.002029172610491514
Valid Loss:  0.0018309829756617546
Epoch:  69  	Training Loss: 0.002667949767783284
Test Loss:  0.0019843638874590397
Valid Loss:  0.0017875537741929293
Epoch:  70  	Training Loss: 0.002611957024782896
Test Loss:  0.0019429277162998915
Valid Loss:  0.00174821843393147
Epoch:  71  	Training Loss: 0.0025589419528841972
Test Loss:   14%|█▍        | 71/500 [00:54<08:35,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:08,  1.16it/s] 15%|█▌        | 75/500 [00:55<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:12,  2.19it/s] 16%|█▌        | 79/500 [00:55<02:24,  2.92it/s] 16%|█▌        | 81/500 [01:01<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:02<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:02<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:02<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:08<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.18it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.93it/s] 20%|██        | 101/500 [01:15<07:59,  1.20s/it] 21%|██        | 103/500 [01:15<05:42,  1.16it/s] 21%|██        | 105/500 [01:15<04:07,  1.59it/s] 21%|██▏       | 107/500 [01:16<03:02,  2.15it/s] 22%|██▏       | 109/500 [01:16<02:16,  2.87it/s] 22%|██▏       | 111/500 [01:22<07:42,  1.19s/it] 23%|██▎       | 113/500 [01:22<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:22<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:23<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:23<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:29<07:44,  1.22s/it] 25%|██▍       | 123/500 [01:29<05:32,  1.13it/s] 25%|██▌       | 125/500 [01:30<03:59,  1.57it/s] 25%|██▌       | 127/500 [01:30<02:54,  2.14it/s] 26%|██▌       | 129/500 [01:30<02:08,  2.88it/s] 26%|██▌       | 131/500 [01:36<07:21,  1.20s/it] 27%|██▋       | 133/500 [01:36<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:47,  1.61it/s] 27%|██▋       | 137/500 [01:37<02:46,  2.19it/s] 28%|██▊       | 139/500 [01:37<02:02,  2.94it/s]0.001905883545987308
Valid Loss:  0.0017118352698162198
Epoch:  72  	Training Loss: 0.002509355079382658
Test Loss:  0.001857914961874485
Valid Loss:  0.0016605635173618793
Epoch:  73  	Training Loss: 0.002445764373987913
Test Loss:  0.0018145448993891478
Valid Loss:  0.0016176796052604914
Epoch:  74  	Training Loss: 0.0023918109945952892
Test Loss:  0.0017754191067069769
Valid Loss:  0.0015803591813892126
Epoch:  75  	Training Loss: 0.002342791296541691
Test Loss:  0.0017397627234458923
Valid Loss:  0.001547519350424409
Epoch:  76  	Training Loss: 0.0022974584717303514
Test Loss:  0.001707587973214686
Valid Loss:  0.0015182397328317165
Epoch:  77  	Training Loss: 0.0022552008740603924
Test Loss:  0.0016782849561423063
Valid Loss:  0.001492106937803328
Epoch:  78  	Training Loss: 0.002215662505477667
Test Loss:  0.0016515303868800402
Valid Loss:  0.0014686586800962687
Epoch:  79  	Training Loss: 0.0021785860881209373
Test Loss:  0.0016257674433290958
Valid Loss:  0.0014456219505518675
Epoch:  80  	Training Loss: 0.0021424894221127033
Test Loss:  0.001602549571543932
Valid Loss:  0.001425290829502046
Epoch:  81  	Training Loss: 0.0021085403859615326
Test Loss:  0.001582201337441802
Valid Loss:  0.0014074677601456642
Epoch:  82  	Training Loss: 0.0020771175622940063
Test Loss:  0.0015712848398834467
Valid Loss:  0.0013966220431029797
Epoch:  83  	Training Loss: 0.002059157704934478
Test Loss:  0.0015599974431097507
Valid Loss:  0.001386782038025558
Epoch:  84  	Training Loss: 0.002042123582214117
Test Loss:  0.0015495665138587356
Valid Loss:  0.0013777666026726365
Epoch:  85  	Training Loss: 0.002025898080319166
Test Loss:  0.0015393183566629887
Valid Loss:  0.0013697223039343953
Epoch:  86  	Training Loss: 0.0020104502327740192
Test Loss:  0.0015302055981010199
Valid Loss:  0.0013623264385387301
Epoch:  87  	Training Loss: 0.001995789585635066
Test Loss:  0.001521711004897952
Valid Loss:  0.001355272252112627
Epoch:  88  	Training Loss: 0.0019817762076854706
Test Loss:  0.0015135619323700666
Valid Loss:  0.0013486091047525406
Epoch:  89  	Training Loss: 0.0019682087004184723
Test Loss:  0.0015057867858558893
Valid Loss:  0.0013423312921077013
Epoch:  90  	Training Loss: 0.0019550640136003494
Test Loss:  0.0014983420260250568
Valid Loss:  0.0013356722192838788
Epoch:  91  	Training Loss: 0.0019419395830482244
Test Loss:  0.0014886172721162438
Valid Loss:  0.001327301375567913
Epoch:  92  	Training Loss: 0.0019274455262348056
Test Loss:  0.0014739094767719507
Valid Loss:  0.0013170409947633743
Epoch:  93  	Training Loss: 0.0019068318651989102
Test Loss:  0.0014603519812226295
Valid Loss:  0.00130763603374362
Epoch:  94  	Training Loss: 0.0018870518542826176
Test Loss:  0.0014481678372249007
Valid Loss:  0.0012987940572202206
Epoch:  95  	Training Loss: 0.001867141341790557
Test Loss:  0.0014434768818318844
Valid Loss:  0.0012907828204333782
Epoch:  96  	Training Loss: 0.0018476846162229776
Test Loss:  0.0014326414093375206
Valid Loss:  0.0012832696083933115
Epoch:  97  	Training Loss: 0.0018299754010513425
Test Loss:  0.0014223845209926367
Valid Loss:  0.0012762879487127066
Epoch:  98  	Training Loss: 0.0018129319651052356
Test Loss:  0.0014126647729426622
Valid Loss:  0.0012697905767709017
Epoch:  99  	Training Loss: 0.0017965128645300865
Test Loss:  0.0014034293126314878
Valid Loss:  0.0012638161424547434
Epoch:  100  	Training Loss: 0.0017807413823902607
Test Loss:  0.0013946536928415298
Valid Loss:  0.0012583595234900713
Epoch:  101  	Training Loss: 0.0017655778210610151
Test Loss:  0.0013865204527974129
Valid Loss:  0.001253659138455987
Epoch:  102  	Training Loss: 0.001751013332977891
Test Loss:  0.001406466355547309
Valid Loss:  0.0012505995109677315
Epoch:  103  	Training Loss: 0.001742812804877758
Test Loss:  0.0014189458452165127
Valid Loss:  0.0012482083402574062
Epoch:  104  	Training Loss: 0.0017363359220325947
Test Loss:  0.001426133792847395
Valid Loss:  0.0012462555896490812
Epoch:  105  	Training Loss: 0.0017308276146650314
Test Loss:  0.0014300830662250519
Valid Loss:  0.0012445675674825907
Epoch:  106  	Training Loss: 0.0017259358428418636
Test Loss:  0.001431850716471672
Valid Loss:  0.0012433036463335156
Epoch:  107  	Training Loss: 0.0017214443068951368
Test Loss:  0.0014321336057037115
Valid Loss:  0.0012421149294823408
Epoch:  108  	Training Loss: 0.0017173778032884002
Test Loss:  0.0014318054309114814
Valid Loss:  0.0012409716146066785
Epoch:  109  	Training Loss: 0.0017135732341557741
Test Loss:  0.0014311254490166903
Valid Loss:  0.0012399128172546625
Epoch:  110  	Training Loss: 0.001709883799776435
Test Loss:  0.0014300672337412834
Valid Loss:  0.0012388993054628372
Epoch:  111  	Training Loss: 0.001706286333501339
Test Loss:  0.001429099589586258
Valid Loss:  0.0012380029074847698
Epoch:  112  	Training Loss: 0.0017027684953063726
Test Loss:  0.0013917813776060939
Valid Loss:  0.0012313488405197859
Epoch:  113  	Training Loss: 0.001680121524259448
Test Loss:  0.0013658769894391298
Valid Loss:  0.001228294800966978
Epoch:  114  	Training Loss: 0.0016634613275527954
Test Loss:  0.0013469523983076215
Valid Loss:  0.0012267159763723612
Epoch:  115  	Training Loss: 0.0016485198866575956
Test Loss:  0.0013322874438017607
Valid Loss:  0.0012261559022590518
Epoch:  116  	Training Loss: 0.0016348535427823663
Test Loss:  0.0013213728088885546
Valid Loss:  0.0012263082899153233
Epoch:  117  	Training Loss: 0.0016222137492150068
Test Loss:  0.001312687760218978
Valid Loss:  0.0012270259903743863
Epoch:  118  	Training Loss: 0.0016104580136016011
Test Loss:  0.001305885030888021
Valid Loss:  0.0012281474191695452
Epoch:  119  	Training Loss: 0.0015994582790881395
Test Loss:  0.0013002862688153982
Valid Loss:  0.0012295788619667292
Epoch:  120  	Training Loss: 0.0015891389921307564
Test Loss:  0.0012955197598785162
Valid Loss:  0.0012312354519963264
Epoch:  121  	Training Loss: 0.001579445437528193
Test Loss:  0.0012913441751152277
Valid Loss:  0.0012330804020166397
Epoch:  122  	Training Loss: 0.00157031265553087
Test Loss:  0.0012816382804885507
Valid Loss:  0.0012316692154854536
Epoch:  123  	Training Loss: 0.0015570165123790503
Test Loss:  0.0012742571998387575
Valid Loss:  0.0012307425495237112
Epoch:  124  	Training Loss: 0.0015457015251740813
Test Loss:  0.0012684871908277273
Valid Loss:  0.0012303973780944943
Epoch:  125  	Training Loss: 0.0015360404504463077
Test Loss:  0.0012628892436623573
Valid Loss:  0.0012302870163694024
Epoch:  126  	Training Loss: 0.0015271453885361552
Test Loss:  0.0012578205205500126
Valid Loss:  0.001230623689480126
Epoch:  127  	Training Loss: 0.0015187874669209123
Test Loss:  0.0012533291010186076
Valid Loss:  0.001231142901815474
Epoch:  128  	Training Loss: 0.001510924776084721
Test Loss:  0.0012492915848270059
Valid Loss:  0.0012317358050495386
Epoch:  129  	Training Loss: 0.0015035413671284914
Test Loss:  0.0012457207776606083
Valid Loss:  0.001232342328876257
Epoch:  130  	Training Loss: 0.0014965115115046501
Test Loss:  0.001242303755134344
Valid Loss:  0.0012329908786341548
Epoch:  131  	Training Loss: 0.0014897161163389683
Test Loss:  0.0012388998875394464
Valid Loss:  0.0012336771469563246
Epoch:  132  	Training Loss: 0.0014831742737442255
Test Loss:  0.001238938421010971
Valid Loss:  0.0012344258138909936
Epoch:  133  	Training Loss: 0.0014795325696468353
Test Loss:  0.001238625613041222
Valid Loss:  0.0012352252379059792
Epoch:  134  	Training Loss: 0.0014759816695004702
Test Loss:  0.0012380621628835797
Valid Loss:  0.0012360613327473402
Epoch:  135  	Training Loss: 0.0014725124929100275
Test Loss:  0.0012373012723401189
Valid Loss:  0.001236911746673286
Epoch:  136  	Training Loss: 0.0014691262040287256
Test Loss:  0.001236417330801487
Valid Loss:  0.001237776130437851
Epoch:  137  	Training Loss: 0.0014658123254776
Test Loss:  0.0012354268692433834
Valid Loss:  0.0012386341113597155
Epoch:  138  	Training Loss: 0.0014625710900872946
Test Loss:  0.001234372379258275
Valid Loss:  0.001239491393789649
Epoch:  139  	Training Loss: 0.001459396444261074
Test Loss:  0.0012335984501987696
Valid Loss:  0.0012402413412928581
Epoch:  140  	Training Loss: 0.0014562875730916858
 28%|██▊       | 141/500 [01:43<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:43<05:06,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:40,  1.61it/s] 29%|██▉       | 147/500 [01:44<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:44<01:59,  2.93it/s] 30%|███       | 151/500 [01:50<06:52,  1.18s/it] 31%|███       | 153/500 [01:50<04:54,  1.18it/s] 31%|███       | 155/500 [01:50<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:50<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:57<06:43,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:27,  1.62it/s] 33%|███▎      | 167/500 [01:57<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:57<01:52,  2.96it/s] 34%|███▍      | 171/500 [02:04<06:30,  1.19s/it] 35%|███▍      | 173/500 [02:04<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:04<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:04<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:04<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:11<06:24,  1.20s/it] 37%|███▋      | 183/500 [02:11<04:34,  1.15it/s] 37%|███▋      | 185/500 [02:11<03:17,  1.59it/s] 37%|███▋      | 187/500 [02:11<02:24,  2.16it/s] 38%|███▊      | 189/500 [02:11<01:46,  2.91it/s] 38%|███▊      | 191/500 [02:18<06:16,  1.22s/it] 39%|███▊      | 193/500 [02:18<04:29,  1.14it/s] 39%|███▉      | 195/500 [02:18<03:13,  1.58it/s] 39%|███▉      | 197/500 [02:18<02:20,  2.16it/s] 40%|███▉      | 199/500 [02:18<01:44,  2.89it/s] 40%|████      | 201/500 [02:25<06:01,  1.21s/it] 41%|████      | 203/500 [02:25<04:17,  1.15it/s] 41%|████      | 205/500 [02:25<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:25<02:14,  2.18it/s]Test Loss:  0.0012323701521381736
Valid Loss:  0.0012410974595695734
Epoch:  141  	Training Loss: 0.0014532416826114058
Test Loss:  0.0012311867903918028
Valid Loss:  0.0012419569538906217
Epoch:  142  	Training Loss: 0.0014502642443403602
Test Loss:  0.0012173284776508808
Valid Loss:  0.0012352841440588236
Epoch:  143  	Training Loss: 0.001438633189536631
Test Loss:  0.001205726875923574
Valid Loss:  0.0012294026091694832
Epoch:  144  	Training Loss: 0.0014277350855991244
Test Loss:  0.001196097582578659
Valid Loss:  0.0012240931391716003
Epoch:  145  	Training Loss: 0.0014177421107888222
Test Loss:  0.001187576330266893
Valid Loss:  0.0012190488632768393
Epoch:  146  	Training Loss: 0.0014082530979067087
Test Loss:  0.0011799698695540428
Valid Loss:  0.001214332995004952
Epoch:  147  	Training Loss: 0.0013990679290145636
Test Loss:  0.0011734005529433489
Valid Loss:  0.0012098842998966575
Epoch:  148  	Training Loss: 0.0013901583151891828
Test Loss:  0.0011676620924845338
Valid Loss:  0.0012055973056703806
Epoch:  149  	Training Loss: 0.0013818418374285102
Test Loss:  0.001162452856078744
Valid Loss:  0.0012014873791486025
Epoch:  150  	Training Loss: 0.0013739952119067311
Test Loss:  0.001157125923782587
Valid Loss:  0.001197607023641467
Epoch:  151  	Training Loss: 0.0013664935249835253
Test Loss:  0.0011517410166561604
Valid Loss:  0.001193827367387712
Epoch:  152  	Training Loss: 0.001359248417429626
Test Loss:  0.001143275061622262
Valid Loss:  0.001190660521388054
Epoch:  153  	Training Loss: 0.0013507597614079714
Test Loss:  0.001135439146310091
Valid Loss:  0.00118758506141603
Epoch:  154  	Training Loss: 0.0013426255900412798
Test Loss:  0.0011281955521553755
Valid Loss:  0.0011846297420561314
Epoch:  155  	Training Loss: 0.0013347640633583069
Test Loss:  0.00112189631909132
Valid Loss:  0.00118192657828331
Epoch:  156  	Training Loss: 0.0013272607466205955
Test Loss:  0.0011160779977217317
Valid Loss:  0.0011797636980190873
Epoch:  157  	Training Loss: 0.0013198892120271921
Test Loss:  0.0011103965807706118
Valid Loss:  0.0011778443586081266
Epoch:  158  	Training Loss: 0.0013127103447914124
Test Loss:  0.001105251838453114
Valid Loss:  0.0011760822962969542
Epoch:  159  	Training Loss: 0.0013058921322226524
Test Loss:  0.001100262627005577
Valid Loss:  0.001174352364614606
Epoch:  160  	Training Loss: 0.0012993146665394306
Test Loss:  0.001096111023798585
Valid Loss:  0.0011727536329999566
Epoch:  161  	Training Loss: 0.0012931545497849584
Test Loss:  0.0010923495283350348
Valid Loss:  0.001171225681900978
Epoch:  162  	Training Loss: 0.0012872223742306232
Test Loss:  0.0010958013590425253
Valid Loss:  0.0011685314821079373
Epoch:  163  	Training Loss: 0.0012824870645999908
Test Loss:  0.0010981452651321888
Valid Loss:  0.0011666947975754738
Epoch:  164  	Training Loss: 0.0012782415142282844
Test Loss:  0.0010995430639013648
Valid Loss:  0.0011654805857688189
Epoch:  165  	Training Loss: 0.0012747874716296792
Test Loss:  0.0011003011604771018
Valid Loss:  0.0011646965285763144
Epoch:  166  	Training Loss: 0.0012718176003545523
Test Loss:  0.0011000731028616428
Valid Loss:  0.0011642873287200928
Epoch:  167  	Training Loss: 0.0012690527364611626
Test Loss:  0.0010995699558407068
Valid Loss:  0.001164049026556313
Epoch:  168  	Training Loss: 0.0012664612149819732
Test Loss:  0.0010989406146109104
Valid Loss:  0.0011639175936579704
Epoch:  169  	Training Loss: 0.001263979123905301
Test Loss:  0.0010982634266838431
Valid Loss:  0.0011638387804850936
Epoch:  170  	Training Loss: 0.0012616233434528112
Test Loss:  0.0010967458365485072
Valid Loss:  0.0011640663724392653
Epoch:  171  	Training Loss: 0.0012593974824994802
Test Loss:  0.001095612533390522
Valid Loss:  0.0011643082834780216
Epoch:  172  	Training Loss: 0.001257323194295168
Test Loss:  0.0010896837338805199
Valid Loss:  0.0011642944300547242
Epoch:  173  	Training Loss: 0.00125215295702219
Test Loss:  0.0010850178077816963
Valid Loss:  0.001164200366474688
Epoch:  174  	Training Loss: 0.001247492735274136
Test Loss:  0.0010815415298566222
Valid Loss:  0.0011641023447737098
Epoch:  175  	Training Loss: 0.0012430748902261257
Test Loss:  0.0010786005295813084
Valid Loss:  0.0011639950098469853
Epoch:  176  	Training Loss: 0.0012388299219310284
Test Loss:  0.0010762671008706093
Valid Loss:  0.0011639893054962158
Epoch:  177  	Training Loss: 0.0012347729643806815
Test Loss:  0.0010745932813733816
Valid Loss:  0.001164157409220934
Epoch:  178  	Training Loss: 0.001230768975801766
Test Loss:  0.0010736590484157205
Valid Loss:  0.0011643861653283238
Epoch:  179  	Training Loss: 0.0012270052684471011
Test Loss:  0.0010731338988989592
Valid Loss:  0.0011646805796772242
Epoch:  180  	Training Loss: 0.0012235838221386075
Test Loss:  0.001072811195626855
Valid Loss:  0.0011650570668280125
Epoch:  181  	Training Loss: 0.0012204492231830955
Test Loss:  0.0010730675421655178
Valid Loss:  0.00116535066626966
Epoch:  182  	Training Loss: 0.0012176453601568937
Test Loss:  0.0010748346103355289
Valid Loss:  0.0011645257472991943
Epoch:  183  	Training Loss: 0.0012153461575508118
Test Loss:  0.0010751707013696432
Valid Loss:  0.0011641195742413402
Epoch:  184  	Training Loss: 0.001213247887790203
Test Loss:  0.001074752421118319
Valid Loss:  0.0011638994328677654
Epoch:  185  	Training Loss: 0.0012112287804484367
Test Loss:  0.0010737010743469
Valid Loss:  0.0011639727745205164
Epoch:  186  	Training Loss: 0.0012093388941138983
Test Loss:  0.0010724461171776056
Valid Loss:  0.0011640733573585749
Epoch:  187  	Training Loss: 0.0012074958067387342
Test Loss:  0.001071843900717795
Valid Loss:  0.0011642016470432281
Epoch:  188  	Training Loss: 0.0012057179119437933
Test Loss:  0.0010707154870033264
Valid Loss:  0.0011646184138953686
Epoch:  189  	Training Loss: 0.001203966443426907
Test Loss:  0.0010702265426516533
Valid Loss:  0.0011649513617157936
Epoch:  190  	Training Loss: 0.001202290179207921
Test Loss:  0.0010694824159145355
Valid Loss:  0.0011654332047328353
Epoch:  191  	Training Loss: 0.0012007011100649834
Test Loss:  0.0010683148866519332
Valid Loss:  0.0011660612653940916
Epoch:  192  	Training Loss: 0.0011991963256150484
Test Loss:  0.0010647561866790056
Valid Loss:  0.0011685190256685019
Epoch:  193  	Training Loss: 0.0011980279814451933
Test Loss:  0.001064004492945969
Valid Loss:  0.0011700296308845282
Epoch:  194  	Training Loss: 0.001196881290525198
Test Loss:  0.001061945571564138
Valid Loss:  0.0011721205664798617
Epoch:  195  	Training Loss: 0.001195835880935192
Test Loss:  0.0010622008703649044
Valid Loss:  0.001173422671854496
Epoch:  196  	Training Loss: 0.0011948136379942298
Test Loss:  0.0010604787385091186
Valid Loss:  0.0011754430597648025
Epoch:  197  	Training Loss: 0.0011938910465687513
Test Loss:  0.00106163346208632
Valid Loss:  0.001176497433334589
Epoch:  198  	Training Loss: 0.0011929944157600403
Test Loss:  0.0010609666351228952
Valid Loss:  0.0011782038491219282
Epoch:  199  	Training Loss: 0.001192163210362196
Test Loss:  0.0010622694389894605
Valid Loss:  0.001179198152385652
Epoch:  200  	Training Loss: 0.0011914108181372285
Test Loss:  0.0010612336918711662
Valid Loss:  0.0011811064323410392
Epoch:  201  	Training Loss: 0.0011906952131539583
Test Loss:  0.001062894589267671
Valid Loss:  0.0011819927021861076
Epoch:  202  	Training Loss: 0.0011899742530658841
Test Loss:  0.001065064687281847
Valid Loss:  0.0011819384526461363
Epoch:  203  	Training Loss: 0.0011874062474817038
Test Loss:  0.0010663706343621016
Valid Loss:  0.001182221807539463
Epoch:  204  	Training Loss: 0.0011849779402837157
Test Loss:  0.0010674579534679651
Valid Loss:  0.001182733802124858
Epoch:  205  	Training Loss: 0.001182683976367116
Test Loss:  0.0010682385182008147
Valid Loss:  0.0011833831667900085
Epoch:  206  	Training Loss: 0.0011804611422121525
Test Loss:  0.0010687290923669934
Valid Loss:  0.00118413963355124
Epoch:  207  	Training Loss: 0.0011783363297581673
Test Loss:  0.001069388585165143
Valid Loss:  0.0011848080903291702
Epoch:  208  	Training Loss: 0.0011762783396989107
Test Loss:  0.0010698949918150902
Valid Loss:  0.0011855637421831489
 42%|████▏     | 209/500 [02:25<01:39,  2.93it/s] 42%|████▏     | 211/500 [02:32<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:32<04:06,  1.17it/s] 43%|████▎     | 215/500 [02:32<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:32<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:32<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:39<05:35,  1.20s/it] 45%|████▍     | 223/500 [02:39<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:39<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:39<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:39<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:46<05:20,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:46<02:01,  2.16it/s] 48%|████▊     | 239/500 [02:46<01:31,  2.85it/s] 48%|████▊     | 241/500 [02:53<05:11,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:43,  1.15it/s] 49%|████▉     | 245/500 [02:53<02:41,  1.58it/s] 49%|████▉     | 247/500 [02:53<01:59,  2.13it/s] 50%|████▉     | 249/500 [02:53<01:29,  2.82it/s] 50%|█████     | 251/500 [03:00<04:59,  1.20s/it] 51%|█████     | 253/500 [03:00<03:33,  1.16it/s] 51%|█████     | 255/500 [03:00<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:00<01:52,  2.16it/s] 52%|█████▏    | 259/500 [03:00<01:23,  2.88it/s] 52%|█████▏    | 261/500 [03:07<04:49,  1.21s/it] 53%|█████▎    | 263/500 [03:07<03:26,  1.15it/s] 53%|█████▎    | 265/500 [03:07<02:28,  1.58it/s] 53%|█████▎    | 267/500 [03:07<01:47,  2.16it/s] 54%|█████▍    | 269/500 [03:07<01:19,  2.91it/s] 54%|█████▍    | 271/500 [03:14<04:33,  1.20s/it] 55%|█████▍    | 273/500 [03:14<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:14<02:20,  1.61it/s]Epoch:  209  	Training Loss: 0.0011743323411792517
Test Loss:  0.0010702464496716857
Valid Loss:  0.0011863672407343984
Epoch:  210  	Training Loss: 0.0011724341893568635
Test Loss:  0.0010704242158681154
Valid Loss:  0.001187203684821725
Epoch:  211  	Training Loss: 0.001170602859929204
Test Loss:  0.0010705350432544947
Valid Loss:  0.0011880743550136685
Epoch:  212  	Training Loss: 0.0011688473168760538
Test Loss:  0.0010661387350410223
Valid Loss:  0.0011894822819158435
Epoch:  213  	Training Loss: 0.0011679602321237326
Test Loss:  0.0010627059964463115
Valid Loss:  0.0011906158179044724
Epoch:  214  	Training Loss: 0.0011672211112454534
Test Loss:  0.0010599493980407715
Valid Loss:  0.0011915408540517092
Epoch:  215  	Training Loss: 0.0011666163336485624
Test Loss:  0.0010578050278127193
Valid Loss:  0.0011922870762646198
Epoch:  216  	Training Loss: 0.0011661085300147533
Test Loss:  0.0010553576285019517
Valid Loss:  0.0011931706685572863
Epoch:  217  	Training Loss: 0.00116567627992481
Test Loss:  0.0010534020839259028
Valid Loss:  0.0011938823154196143
Epoch:  218  	Training Loss: 0.0011652985122054815
Test Loss:  0.0010522454977035522
Valid Loss:  0.001194328535348177
Epoch:  219  	Training Loss: 0.0011649779044091702
Test Loss:  0.0010510504944249988
Valid Loss:  0.0011948414612561464
Epoch:  220  	Training Loss: 0.0011646791826933622
Test Loss:  0.0010500421049073339
Valid Loss:  0.001195256132632494
Epoch:  221  	Training Loss: 0.0011643926845863461
Test Loss:  0.0010491746943444014
Valid Loss:  0.001195583026856184
Epoch:  222  	Training Loss: 0.0011641087476164103
Test Loss:  0.0010474973823875189
Valid Loss:  0.0011947776656597853
Epoch:  223  	Training Loss: 0.001162517350167036
Test Loss:  0.0010456452146172523
Valid Loss:  0.0011940904660150409
Epoch:  224  	Training Loss: 0.001161013962700963
Test Loss:  0.0010440363548696041
Valid Loss:  0.0011933622881770134
Epoch:  225  	Training Loss: 0.0011595853138715029
Test Loss:  0.00104254309553653
Valid Loss:  0.0011925897561013699
Epoch:  226  	Training Loss: 0.001158190076239407
Test Loss:  0.0010413913987576962
Valid Loss:  0.001191850402392447
Epoch:  227  	Training Loss: 0.00115688587538898
Test Loss:  0.0010402537882328033
Valid Loss:  0.0011912428308278322
Epoch:  228  	Training Loss: 0.001155675621703267
Test Loss:  0.0010389948729425669
Valid Loss:  0.0011907013831660151
Epoch:  229  	Training Loss: 0.0011544990120455623
Test Loss:  0.0010381911415606737
Valid Loss:  0.0011899862438440323
Epoch:  230  	Training Loss: 0.0011533413780853152
Test Loss:  0.0010370011441409588
Valid Loss:  0.0011894346680492163
Epoch:  231  	Training Loss: 0.0011521928245201707
Test Loss:  0.0010360819287598133
Valid Loss:  0.0011887915898114443
Epoch:  232  	Training Loss: 0.0011510926997289062
Test Loss:  0.0010342641035094857
Valid Loss:  0.0011877184733748436
Epoch:  233  	Training Loss: 0.0011497309897094965
Test Loss:  0.0010326853953301907
Valid Loss:  0.0011868062429130077
Epoch:  234  	Training Loss: 0.0011484076967462897
Test Loss:  0.0010317569831386209
Valid Loss:  0.0011858942452818155
Epoch:  235  	Training Loss: 0.0011471710167825222
Test Loss:  0.0010307496413588524
Valid Loss:  0.0011851085582748055
Epoch:  236  	Training Loss: 0.0011460368987172842
Test Loss:  0.0010301790898665786
Valid Loss:  0.0011842045933008194
Epoch:  237  	Training Loss: 0.00114496611058712
Test Loss:  0.0010293249506503344
Valid Loss:  0.0011835163459181786
Epoch:  238  	Training Loss: 0.0011440040543675423
Test Loss:  0.0010284571908414364
Valid Loss:  0.001182873616926372
Epoch:  239  	Training Loss: 0.0011431211605668068
Test Loss:  0.001027943566441536
Valid Loss:  0.0011821334483101964
Epoch:  240  	Training Loss: 0.0011422999668866396
Test Loss:  0.0010273096850141883
Valid Loss:  0.0011816623155027628
Epoch:  241  	Training Loss: 0.0011415901826694608
Test Loss:  0.00102683634031564
Valid Loss:  0.0011812375159934163
Epoch:  242  	Training Loss: 0.0011409309227019548
Test Loss:  0.0010283607989549637
Valid Loss:  0.0011780913919210434
Epoch:  243  	Training Loss: 0.00113776046782732
Test Loss:  0.0010287961922585964
Valid Loss:  0.001175618264824152
Epoch:  244  	Training Loss: 0.0011347482213750482
Test Loss:  0.001028000027872622
Valid Loss:  0.0011737326858565211
Epoch:  245  	Training Loss: 0.0011318324832245708
Test Loss:  0.0010269073536619544
Valid Loss:  0.0011720445472747087
Epoch:  246  	Training Loss: 0.0011289616813883185
Test Loss:  0.0010256238747388124
Valid Loss:  0.0011705018114298582
Epoch:  247  	Training Loss: 0.0011261426843702793
Test Loss:  0.0010241923155263066
Valid Loss:  0.0011691718827933073
Epoch:  248  	Training Loss: 0.0011233994737267494
Test Loss:  0.0010226215235888958
Valid Loss:  0.0011679423041641712
Epoch:  249  	Training Loss: 0.0011206711642444134
Test Loss:  0.0010210918262600899
Valid Loss:  0.0011667459039017558
Epoch:  250  	Training Loss: 0.0011179600842297077
Test Loss:  0.0010197940282523632
Valid Loss:  0.0011655441485345364
Epoch:  251  	Training Loss: 0.0011153575032949448
Test Loss:  0.0010182360420003533
Valid Loss:  0.0011644801124930382
Epoch:  252  	Training Loss: 0.0011128161568194628
Test Loss:  0.0010182529222220182
Valid Loss:  0.0011647316860035062
Epoch:  253  	Training Loss: 0.0011118734255433083
Test Loss:  0.0010177933145314455
Valid Loss:  0.001165161607787013
Epoch:  254  	Training Loss: 0.0011109858751296997
Test Loss:  0.0010179153177887201
Valid Loss:  0.0011654830304905772
Epoch:  255  	Training Loss: 0.0011102557182312012
Test Loss:  0.0010175352217629552
Valid Loss:  0.0011660747695714235
Epoch:  256  	Training Loss: 0.0011096859816461802
Test Loss:  0.0010175645584240556
Valid Loss:  0.0011665954953059554
Epoch:  257  	Training Loss: 0.0011092557106167078
Test Loss:  0.0010175856295973063
Valid Loss:  0.0011671078391373158
Epoch:  258  	Training Loss: 0.0011088696774095297
Test Loss:  0.0010175744537264109
Valid Loss:  0.0011676190188154578
Epoch:  259  	Training Loss: 0.0011085278820246458
Test Loss:  0.0010175623465329409
Valid Loss:  0.0011681059841066599
Epoch:  260  	Training Loss: 0.001108201569877565
Test Loss:  0.0010175424395129085
Valid Loss:  0.001168561284430325
Epoch:  261  	Training Loss: 0.0011078810784965754
Test Loss:  0.0010175302159041166
Valid Loss:  0.0011689921375364065
Epoch:  262  	Training Loss: 0.0011075622169300914
Test Loss:  0.0010156154166907072
Valid Loss:  0.0011691843392327428
Epoch:  263  	Training Loss: 0.0011067234445363283
Test Loss:  0.0010155881755053997
Valid Loss:  0.0011687681544572115
Epoch:  264  	Training Loss: 0.0011058959644287825
Test Loss:  0.0010143067920580506
Valid Loss:  0.0011688536033034325
Epoch:  265  	Training Loss: 0.0011051460169255733
Test Loss:  0.00101475662086159
Valid Loss:  0.0011683074990287423
Epoch:  266  	Training Loss: 0.001104347174987197
Test Loss:  0.0010137695353478193
Valid Loss:  0.0011682810727506876
Epoch:  267  	Training Loss: 0.0011036114301532507
Test Loss:  0.0010142277460545301
Valid Loss:  0.0011677639558911324
Epoch:  268  	Training Loss: 0.0011028479784727097
Test Loss:  0.001012908760458231
Valid Loss:  0.0011679070303216577
Epoch:  269  	Training Loss: 0.0011021295795217156
Test Loss:  0.0010134109761565924
Valid Loss:  0.0011673889821395278
Epoch:  270  	Training Loss: 0.0011013689218088984
Test Loss:  0.0010123588144779205
Valid Loss:  0.0011674367124214768
Epoch:  271  	Training Loss: 0.0011006610002368689
Test Loss:  0.0010127642890438437
Valid Loss:  0.001167020876891911
Epoch:  272  	Training Loss: 0.001099897432141006
Test Loss:  0.0010133979376405478
Valid Loss:  0.001166516449302435
Epoch:  273  	Training Loss: 0.0010993951000273228
Test Loss:  0.0010138320503756404
Valid Loss:  0.0011660938616842031
Epoch:  274  	Training Loss: 0.001098918728530407
Test Loss:  0.0010141427628695965
Valid Loss:  0.0011657524155452847
Epoch:  275  	Training Loss: 0.0010984714608639479
Test Loss:  0.0010143757099285722
Valid Loss:  0.0011654493864625692
Epoch:  276  	Training Loss: 0.0010980648221448064
Test Loss:  0.0010132711613550782
Valid Loss:  0.001165619120001793
Epoch:  277  	Training Loss: 0.0010976775083690882
Test Loss:   55%|█████▌    | 277/500 [03:14<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:14<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:21<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:21<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:21<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:21<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:21<01:11,  2.97it/s] 58%|█████▊    | 291/500 [03:28<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:28<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:28<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:28<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:28<01:09,  2.87it/s] 60%|██████    | 301/500 [03:35<04:01,  1.21s/it] 61%|██████    | 303/500 [03:35<02:52,  1.14it/s] 61%|██████    | 305/500 [03:35<02:04,  1.57it/s] 61%|██████▏   | 307/500 [03:35<01:31,  2.12it/s] 62%|██████▏   | 309/500 [03:35<01:07,  2.82it/s] 62%|██████▏   | 311/500 [03:42<03:49,  1.21s/it] 63%|██████▎   | 313/500 [03:42<02:43,  1.14it/s] 63%|██████▎   | 315/500 [03:42<01:58,  1.57it/s] 63%|██████▎   | 317/500 [03:42<01:26,  2.12it/s] 64%|██████▍   | 319/500 [03:42<01:04,  2.81it/s] 64%|██████▍   | 321/500 [03:49<03:36,  1.21s/it] 65%|██████▍   | 323/500 [03:49<02:33,  1.15it/s] 65%|██████▌   | 325/500 [03:49<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:49<01:19,  2.18it/s] 66%|██████▌   | 329/500 [03:49<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:56<03:24,  1.21s/it] 67%|██████▋   | 333/500 [03:56<02:25,  1.15it/s] 67%|██████▋   | 335/500 [03:56<01:43,  1.59it/s] 67%|██████▋   | 337/500 [03:56<01:14,  2.18it/s] 68%|██████▊   | 339/500 [03:56<00:54,  2.93it/s] 68%|██████▊   | 341/500 [04:03<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:03<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:03<01:35,  1.63it/s]0.0010140747763216496
Valid Loss:  0.0011651499662548304
Epoch:  278  	Training Loss: 0.0010972574818879366
Test Loss:  0.001013998407870531
Valid Loss:  0.0011650088708847761
Epoch:  279  	Training Loss: 0.001096875173971057
Test Loss:  0.0010136133059859276
Valid Loss:  0.001165012363344431
Epoch:  280  	Training Loss: 0.001096514519304037
Test Loss:  0.001014437060803175
Valid Loss:  0.0011646572966128588
Epoch:  281  	Training Loss: 0.0010961306979879737
Test Loss:  0.0010141744278371334
Valid Loss:  0.0011647387873381376
Epoch:  282  	Training Loss: 0.001095776678994298
Test Loss:  0.0010110558941960335
Valid Loss:  0.0011637010611593723
Epoch:  283  	Training Loss: 0.0010924618691205978
Test Loss:  0.0010085116373375058
Valid Loss:  0.0011626578634604812
Epoch:  284  	Training Loss: 0.001089268596842885
Test Loss:  0.0010060511995106936
Valid Loss:  0.001161794876679778
Epoch:  285  	Training Loss: 0.0010861768387258053
Test Loss:  0.0010042233625426888
Valid Loss:  0.0011609075590968132
Epoch:  286  	Training Loss: 0.0010831545805558562
Test Loss:  0.0010027122916653752
Valid Loss:  0.001160117331892252
Epoch:  287  	Training Loss: 0.0010802475735545158
Test Loss:  0.001001467346213758
Valid Loss:  0.0011593527160584927
Epoch:  288  	Training Loss: 0.0010775565169751644
Test Loss:  0.0010004127398133278
Valid Loss:  0.0011586527107283473
Epoch:  289  	Training Loss: 0.0010749988723546267
Test Loss:  0.0009996311273425817
Valid Loss:  0.0011579932179301977
Epoch:  290  	Training Loss: 0.001072552753612399
Test Loss:  0.0009991038823500276
Valid Loss:  0.001157292746938765
Epoch:  291  	Training Loss: 0.0010703231673687696
Test Loss:  0.0009985733777284622
Valid Loss:  0.0011566730681806803
Epoch:  292  	Training Loss: 0.0010682668071240187
Test Loss:  0.0010004602372646332
Valid Loss:  0.0011559631675481796
Epoch:  293  	Training Loss: 0.0010676089441403747
Test Loss:  0.0010015980806201696
Valid Loss:  0.0011555805103853345
Epoch:  294  	Training Loss: 0.0010670458432286978
Test Loss:  0.0010028561810031533
Valid Loss:  0.0011551942443475127
Epoch:  295  	Training Loss: 0.0010665301233530045
Test Loss:  0.0010036483872681856
Valid Loss:  0.0011549792252480984
Epoch:  296  	Training Loss: 0.0010660598054528236
Test Loss:  0.0010041698114946485
Valid Loss:  0.0011548735201358795
Epoch:  297  	Training Loss: 0.0010655969381332397
Test Loss:  0.0010045154485851526
Valid Loss:  0.0011548280017450452
Epoch:  298  	Training Loss: 0.0010651389602571726
Test Loss:  0.0010047374526038766
Valid Loss:  0.001154823461547494
Epoch:  299  	Training Loss: 0.0010646836599335074
Test Loss:  0.0010049272095784545
Valid Loss:  0.0011548497714102268
Epoch:  300  	Training Loss: 0.0010642381384968758
Test Loss:  0.0010050478158518672
Valid Loss:  0.001154936384409666
Epoch:  301  	Training Loss: 0.0010638301027938724
Test Loss:  0.0010050893761217594
Valid Loss:  0.0011550592025741935
Epoch:  302  	Training Loss: 0.0010634537320584059
Test Loss:  0.0010045324452221394
Valid Loss:  0.0011548080947250128
Epoch:  303  	Training Loss: 0.0010620256653055549
Test Loss:  0.0010042620124295354
Valid Loss:  0.0011545770103111863
Epoch:  304  	Training Loss: 0.0010608932934701443
Test Loss:  0.0010042417561635375
Valid Loss:  0.0011543682776391506
Epoch:  305  	Training Loss: 0.0010599368251860142
Test Loss:  0.0010042432695627213
Valid Loss:  0.001154233468696475
Epoch:  306  	Training Loss: 0.0010590462479740381
Test Loss:  0.0010042788926512003
Valid Loss:  0.001154115074314177
Epoch:  307  	Training Loss: 0.001058212830685079
Test Loss:  0.0010044758673757315
Valid Loss:  0.0011540601262822747
Epoch:  308  	Training Loss: 0.0010574671905487776
Test Loss:  0.0010045963572338223
Valid Loss:  0.001154060009866953
Epoch:  309  	Training Loss: 0.0010567549616098404
Test Loss:  0.0010046401293948293
Valid Loss:  0.0011540711857378483
Epoch:  310  	Training Loss: 0.0010560550726950169
Test Loss:  0.0010045845992863178
Valid Loss:  0.0011540884152054787
Epoch:  311  	Training Loss: 0.0010553905740380287
Test Loss:  0.001004528603516519
Valid Loss:  0.001154096331447363
Epoch:  312  	Training Loss: 0.0010547349229454994
Test Loss:  0.0010036297608166933
Valid Loss:  0.0011534856166690588
Epoch:  313  	Training Loss: 0.0010529088322073221
Test Loss:  0.0010028518736362457
Valid Loss:  0.0011528604663908482
Epoch:  314  	Training Loss: 0.001051120227202773
Test Loss:  0.0010021982016041875
Valid Loss:  0.0011522254208102822
Epoch:  315  	Training Loss: 0.0010493384907022119
Test Loss:  0.0010015753796324134
Valid Loss:  0.0011515677906572819
Epoch:  316  	Training Loss: 0.0010475838789716363
Test Loss:  0.0010010902769863605
Valid Loss:  0.0011509123723953962
Epoch:  317  	Training Loss: 0.0010458772303536534
Test Loss:  0.0010005789808928967
Valid Loss:  0.0011502476409077644
Epoch:  318  	Training Loss: 0.001044190488755703
Test Loss:  0.0010002946946769953
Valid Loss:  0.001149523537606001
Epoch:  319  	Training Loss: 0.0010425837244838476
Test Loss:  0.0010000476613640785
Valid Loss:  0.0011488390155136585
Epoch:  320  	Training Loss: 0.0010410510003566742
Test Loss:  0.0009996455628424883
Valid Loss:  0.0011482196860015392
Epoch:  321  	Training Loss: 0.0010395431891083717
Test Loss:  0.0009993682615458965
Valid Loss:  0.001147545874118805
Epoch:  322  	Training Loss: 0.001038076588883996
Test Loss:  0.0009996626758947968
Valid Loss:  0.0011481328401714563
Epoch:  323  	Training Loss: 0.0010378947481513023
Test Loss:  0.0009998150635510683
Valid Loss:  0.0011487051378935575
Epoch:  324  	Training Loss: 0.00103776587639004
Test Loss:  0.0010002430062741041
Valid Loss:  0.0011492102639749646
Epoch:  325  	Training Loss: 0.0010376803111284971
Test Loss:  0.0010003576753661036
Valid Loss:  0.0011497471714392304
Epoch:  326  	Training Loss: 0.0010376106947660446
Test Loss:  0.0010004593059420586
Valid Loss:  0.0011502807028591633
Epoch:  327  	Training Loss: 0.0010375562123954296
Test Loss:  0.0010004907380789518
Valid Loss:  0.0011508052702993155
Epoch:  328  	Training Loss: 0.0010375035926699638
Test Loss:  0.00100047851447016
Valid Loss:  0.0011512953788042068
Epoch:  329  	Training Loss: 0.0010374662233516574
Test Loss:  0.0010006788652390242
Valid Loss:  0.0011517025995999575
Epoch:  330  	Training Loss: 0.0010374360717833042
Test Loss:  0.0010007559321820736
Valid Loss:  0.001152112614363432
Epoch:  331  	Training Loss: 0.001037411275319755
Test Loss:  0.001000823569484055
Valid Loss:  0.0011525070294737816
Epoch:  332  	Training Loss: 0.0010373854311183095
Test Loss:  0.0010004508076235652
Valid Loss:  0.001153174671344459
Epoch:  333  	Training Loss: 0.001037293579429388
Test Loss:  0.0010012676939368248
Valid Loss:  0.001153391320258379
Epoch:  334  	Training Loss: 0.0010372190736234188
Test Loss:  0.001001759897917509
Valid Loss:  0.0011537233367562294
Epoch:  335  	Training Loss: 0.0010371761163696647
Test Loss:  0.0010020448826253414
Valid Loss:  0.0011541037820279598
Epoch:  336  	Training Loss: 0.0010371520183980465
Test Loss:  0.0010022036731243134
Valid Loss:  0.0011544970329850912
Epoch:  337  	Training Loss: 0.0010371343232691288
Test Loss:  0.0010023419745266438
Valid Loss:  0.0011548784095793962
Epoch:  338  	Training Loss: 0.001037119422107935
Test Loss:  0.0010025138035416603
Valid Loss:  0.0011552312644198537
Epoch:  339  	Training Loss: 0.0010371061507612467
Test Loss:  0.001002445467747748
Valid Loss:  0.0011556600220501423
Epoch:  340  	Training Loss: 0.0010370936943218112
Test Loss:  0.0010026622330769897
Valid Loss:  0.001155972946435213
Epoch:  341  	Training Loss: 0.0010370821692049503
Test Loss:  0.0010025952942669392
Valid Loss:  0.001156363869085908
Epoch:  342  	Training Loss: 0.0010370741365477443
Test Loss:  0.0010017468594014645
Valid Loss:  0.0011562344152480364
Epoch:  343  	Training Loss: 0.0010362305911257863
Test Loss:  0.0010012402199208736
Valid Loss:  0.001155997160822153
Epoch:  344  	Training Loss: 0.0010354234836995602
Test Loss:  0.0010008721146732569
Valid Loss:  0.001155712641775608
Epoch:  345  	Training Loss: 0.0010346316266804934
Test Loss:  0.0010007116943597794
Valid Loss:  0.0011554495431482792
 69%|██████▉   | 347/500 [04:03<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:03<00:50,  3.00it/s] 70%|███████   | 351/500 [04:10<02:57,  1.19s/it] 71%|███████   | 353/500 [04:10<02:05,  1.17it/s] 71%|███████   | 355/500 [04:10<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:10<01:06,  2.16it/s] 72%|███████▏  | 359/500 [04:10<00:49,  2.85it/s] 72%|███████▏  | 361/500 [04:17<02:48,  1.21s/it] 73%|███████▎  | 363/500 [04:17<01:59,  1.15it/s] 73%|███████▎  | 365/500 [04:17<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:17<01:01,  2.18it/s] 74%|███████▍  | 369/500 [04:17<00:45,  2.91it/s] 74%|███████▍  | 371/500 [04:24<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:24<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:24<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:24<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:24<00:41,  2.93it/s] 76%|███████▌  | 381/500 [04:31<02:23,  1.20s/it] 77%|███████▋  | 383/500 [04:31<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:31<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:31<00:52,  2.17it/s] 78%|███████▊  | 389/500 [04:31<00:38,  2.86it/s] 78%|███████▊  | 391/500 [04:38<02:12,  1.22s/it] 79%|███████▊  | 393/500 [04:38<01:33,  1.15it/s] 79%|███████▉  | 395/500 [04:38<01:06,  1.59it/s] 79%|███████▉  | 397/500 [04:38<00:47,  2.17it/s] 80%|███████▉  | 399/500 [04:38<00:34,  2.93it/s] 80%|████████  | 401/500 [04:45<02:00,  1.22s/it] 81%|████████  | 403/500 [04:45<01:25,  1.14it/s] 81%|████████  | 405/500 [04:45<01:00,  1.58it/s] 81%|████████▏ | 407/500 [04:45<00:43,  2.16it/s] 82%|████████▏ | 409/500 [04:45<00:31,  2.91it/s] 82%|████████▏ | 411/500 [04:52<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:52<01:15,  1.15it/s]Epoch:  346  	Training Loss: 0.001033899374306202
Test Loss:  0.0010006388183683157
Valid Loss:  0.0011552609503269196
Epoch:  347  	Training Loss: 0.0010332337114959955
Test Loss:  0.0010005463846027851
Valid Loss:  0.0011551049537956715
Epoch:  348  	Training Loss: 0.0010325959883630276
Test Loss:  0.0010004416108131409
Valid Loss:  0.0011549820192158222
Epoch:  349  	Training Loss: 0.0010319853900000453
Test Loss:  0.0010003199568018317
Valid Loss:  0.0011548734037205577
Epoch:  350  	Training Loss: 0.0010313901584595442
Test Loss:  0.0010001366026699543
Valid Loss:  0.0011547798058018088
Epoch:  351  	Training Loss: 0.0010307987686246634
Test Loss:  0.0009999843314290047
Valid Loss:  0.0011546749155968428
Epoch:  352  	Training Loss: 0.0010302378796041012
Test Loss:  0.0009981038747355342
Valid Loss:  0.001153956283815205
Epoch:  353  	Training Loss: 0.0010284213349223137
Test Loss:  0.000996974529698491
Valid Loss:  0.0011531288037076592
Epoch:  354  	Training Loss: 0.001026754267513752
Test Loss:  0.0009960923343896866
Valid Loss:  0.0011522340355440974
Epoch:  355  	Training Loss: 0.00102513050660491
Test Loss:  0.0009952912805601954
Valid Loss:  0.001151308766566217
Epoch:  356  	Training Loss: 0.0010235208319500089
Test Loss:  0.0009947605431079865
Valid Loss:  0.0011504197027534246
Epoch:  357  	Training Loss: 0.0010219844989478588
Test Loss:  0.0009943449404090643
Valid Loss:  0.0011495575308799744
Epoch:  358  	Training Loss: 0.0010204769205302
Test Loss:  0.000993845285847783
Valid Loss:  0.0011487416923046112
Epoch:  359  	Training Loss: 0.0010189784225076437
Test Loss:  0.0009933777619153261
Valid Loss:  0.001147937262430787
Epoch:  360  	Training Loss: 0.0010174959897994995
Test Loss:  0.0009928629733622074
Valid Loss:  0.001147145638242364
Epoch:  361  	Training Loss: 0.0010160221718251705
Test Loss:  0.0009925136109814048
Valid Loss:  0.0011464412091299891
Epoch:  362  	Training Loss: 0.0010146040003746748
Test Loss:  0.000994391506537795
Valid Loss:  0.001146124443039298
Epoch:  363  	Training Loss: 0.0010142630198970437
Test Loss:  0.0009953128173947334
Valid Loss:  0.0011461322428658605
Epoch:  364  	Training Loss: 0.0010140696540474892
Test Loss:  0.000995907001197338
Valid Loss:  0.0011462843976914883
Epoch:  365  	Training Loss: 0.001013921108096838
Test Loss:  0.0009960135212168097
Valid Loss:  0.0011465304996818304
Epoch:  366  	Training Loss: 0.00101384031586349
Test Loss:  0.000995950773358345
Valid Loss:  0.0011467901058495045
Epoch:  367  	Training Loss: 0.0010137846693396568
Test Loss:  0.0009957889560610056
Valid Loss:  0.0011470579775050282
Epoch:  368  	Training Loss: 0.0010137531207874417
Test Loss:  0.0009954844135791063
Valid Loss:  0.001147288247011602
Epoch:  369  	Training Loss: 0.0010137362405657768
Test Loss:  0.0009952178224921227
Valid Loss:  0.001147484639659524
Epoch:  370  	Training Loss: 0.0010137201752513647
Test Loss:  0.0009949944214895368
Valid Loss:  0.0011476504150778055
Epoch:  371  	Training Loss: 0.0010137103963643312
Test Loss:  0.00099480664357543
Valid Loss:  0.0011477755615487695
Epoch:  372  	Training Loss: 0.001013703877106309
Test Loss:  0.0009946627542376518
Valid Loss:  0.0011474612401798368
Epoch:  373  	Training Loss: 0.001012184889987111
Test Loss:  0.0009939169976860285
Valid Loss:  0.0011475160717964172
Epoch:  374  	Training Loss: 0.0010112917516380548
Test Loss:  0.0009931433014571667
Valid Loss:  0.001147587550804019
Epoch:  375  	Training Loss: 0.0010105731198564172
Test Loss:  0.0009924429468810558
Valid Loss:  0.001147569972090423
Epoch:  376  	Training Loss: 0.0010099196806550026
Test Loss:  0.0009917211718857288
Valid Loss:  0.0011474767234176397
Epoch:  377  	Training Loss: 0.0010093040764331818
Test Loss:  0.000991074019111693
Valid Loss:  0.0011473260819911957
Epoch:  378  	Training Loss: 0.001008710591122508
Test Loss:  0.0009902585297822952
Valid Loss:  0.0011471027974039316
Epoch:  379  	Training Loss: 0.001008129445835948
Test Loss:  0.0009896161500364542
Valid Loss:  0.0011467926669865847
Epoch:  380  	Training Loss: 0.001007559010758996
Test Loss:  0.0009892439702525735
Valid Loss:  0.0011463818373158574
Epoch:  381  	Training Loss: 0.0010069913696497679
Test Loss:  0.0009888154454529285
Valid Loss:  0.0011459649540483952
Epoch:  382  	Training Loss: 0.0010064337402582169
Test Loss:  0.0009869348723441362
Valid Loss:  0.001145138288848102
Epoch:  383  	Training Loss: 0.0010048155672848225
Test Loss:  0.0009856743272393942
Valid Loss:  0.0011442715767771006
Epoch:  384  	Training Loss: 0.001003296347334981
Test Loss:  0.0009846965549513698
Valid Loss:  0.0011433756444603205
Epoch:  385  	Training Loss: 0.0010018408065661788
Test Loss:  0.0009838782716542482
Valid Loss:  0.0011425248812884092
Epoch:  386  	Training Loss: 0.0010004643118008971
Test Loss:  0.0009831564966589212
Valid Loss:  0.0011416631750762463
Epoch:  387  	Training Loss: 0.000999151379801333
Test Loss:  0.0009825109736993909
Valid Loss:  0.0011408063583076
Epoch:  388  	Training Loss: 0.0009978734888136387
Test Loss:  0.000981936464086175
Valid Loss:  0.0011399530339986086
Epoch:  389  	Training Loss: 0.0009966485667973757
Test Loss:  0.0009814059594646096
Valid Loss:  0.0011391122825443745
Epoch:  390  	Training Loss: 0.0009954447159543633
Test Loss:  0.0009808966424316168
Valid Loss:  0.001138288644142449
Epoch:  391  	Training Loss: 0.000994293950498104
Test Loss:  0.000980402692221105
Valid Loss:  0.0011374829337000847
Epoch:  392  	Training Loss: 0.0009931761305779219
Test Loss:  0.0009811101481318474
Valid Loss:  0.0011368861887603998
Epoch:  393  	Training Loss: 0.000992440851405263
Test Loss:  0.000981300137937069
Valid Loss:  0.0011365331010892987
Epoch:  394  	Training Loss: 0.0009917740244418383
Test Loss:  0.000981329008936882
Valid Loss:  0.0011362044606357813
Epoch:  395  	Training Loss: 0.000991146545857191
Test Loss:  0.0009811674244701862
Valid Loss:  0.0011359310010448098
Epoch:  396  	Training Loss: 0.0009905400220304728
Test Loss:  0.000981021672487259
Valid Loss:  0.0011356730246916413
Epoch:  397  	Training Loss: 0.0009899483993649483
Test Loss:  0.0009807961760088801
Valid Loss:  0.0011354428716003895
Epoch:  398  	Training Loss: 0.0009893623646348715
Test Loss:  0.0009804022265598178
Valid Loss:  0.0011352284345775843
Epoch:  399  	Training Loss: 0.0009888004278764129
Test Loss:  0.0009799576364457607
Valid Loss:  0.0011350201675668359
Epoch:  400  	Training Loss: 0.0009882524609565735
Test Loss:  0.0009794807992875576
Valid Loss:  0.0011347918771207333
Epoch:  401  	Training Loss: 0.000987705891020596
Test Loss:  0.0009790124604478478
Valid Loss:  0.0011345567181706429
Epoch:  402  	Training Loss: 0.000987162464298308
Test Loss:  0.0009779464453458786
Valid Loss:  0.0011340411147102714
Epoch:  403  	Training Loss: 0.0009863651357591152
Test Loss:  0.0009770863689482212
Valid Loss:  0.0011335471644997597
Epoch:  404  	Training Loss: 0.0009857064578682184
Test Loss:  0.0009763314155861735
Valid Loss:  0.0011330293491482735
Epoch:  405  	Training Loss: 0.0009851042414084077
Test Loss:  0.0009756555664353073
Valid Loss:  0.001132490113377571
Epoch:  406  	Training Loss: 0.000984561862424016
Test Loss:  0.0009750525350682437
Valid Loss:  0.001131935277953744
Epoch:  407  	Training Loss: 0.0009840402053669095
Test Loss:  0.0009744871640577912
Valid Loss:  0.0011313662398606539
Epoch:  408  	Training Loss: 0.000983544159680605
Test Loss:  0.0009740100358612835
Valid Loss:  0.0011308158282190561
Epoch:  409  	Training Loss: 0.0009831408970057964
Test Loss:  0.0009738102089613676
Valid Loss:  0.0011301760096102953
Epoch:  410  	Training Loss: 0.000982779311016202
Test Loss:  0.000973633024841547
Valid Loss:  0.0011295774020254612
Epoch:  411  	Training Loss: 0.0009824285516515374
Test Loss:  0.0009734302293509245
Valid Loss:  0.001129021868109703
Epoch:  412  	Training Loss: 0.0009820798877626657
Test Loss:  0.0009738653898239136
Valid Loss:  0.0011290241964161396
Epoch:  413  	Training Loss: 0.000981791759841144
Test Loss:  0.000974174530711025
Valid Loss:  0.0011290868278592825
Epoch:  414  	Training Loss: 0.000981516670435667
Test Loss:  0.0009742919937707484
 83%|████████▎ | 415/500 [04:52<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:52<00:38,  2.18it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.94it/s] 84%|████████▍ | 421/500 [04:59<01:34,  1.19s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:59<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:59<00:33,  2.21it/s] 86%|████████▌ | 429/500 [04:59<00:24,  2.93it/s] 86%|████████▌ | 431/500 [05:06<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:06<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:06<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:06<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:06<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:13<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:13<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:13<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:13<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:13<00:17,  2.94it/s] 90%|█████████ | 451/500 [05:20<00:58,  1.18s/it] 91%|█████████ | 453/500 [05:20<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:20<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.99it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:33<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:34<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.18s/it]Valid Loss:  0.0011291957926005125
Epoch:  415  	Training Loss: 0.0009813004871830344
Test Loss:  0.0009741055546328425
Valid Loss:  0.0011293381685391068
Epoch:  416  	Training Loss: 0.000981176970526576
Test Loss:  0.0009738657390698791
Valid Loss:  0.0011294784490019083
Epoch:  417  	Training Loss: 0.0009810691699385643
Test Loss:  0.0009736460051499307
Valid Loss:  0.0011296067386865616
Epoch:  418  	Training Loss: 0.0009809688199311495
Test Loss:  0.000973380752839148
Valid Loss:  0.0011297407327219844
Epoch:  419  	Training Loss: 0.0009808847680687904
Test Loss:  0.0009731532773002982
Valid Loss:  0.0011298579629510641
Epoch:  420  	Training Loss: 0.000980813056230545
Test Loss:  0.0009728390141390264
Valid Loss:  0.0011299734469503164
Epoch:  421  	Training Loss: 0.000980766024440527
Test Loss:  0.0009725206764414907
Valid Loss:  0.0011300770565867424
Epoch:  422  	Training Loss: 0.000980728305876255
Test Loss:  0.0009712699102237821
Valid Loss:  0.0011292463168501854
Epoch:  423  	Training Loss: 0.0009798335377126932
Test Loss:  0.000970519264228642
Valid Loss:  0.0011282763443887234
Epoch:  424  	Training Loss: 0.0009789764881134033
Test Loss:  0.0009698927169665694
Valid Loss:  0.001127331517636776
Epoch:  425  	Training Loss: 0.0009781783446669579
Test Loss:  0.0009693136671558022
Valid Loss:  0.001126396469771862
Epoch:  426  	Training Loss: 0.000977386487647891
Test Loss:  0.0009687464917078614
Valid Loss:  0.0011254912242293358
Epoch:  427  	Training Loss: 0.0009766025468707085
Test Loss:  0.00096817163284868
Valid Loss:  0.0011246229987591505
Epoch:  428  	Training Loss: 0.0009758484666235745
Test Loss:  0.0009676206391304731
Valid Loss:  0.0011237665312364697
Epoch:  429  	Training Loss: 0.0009750986937433481
Test Loss:  0.0009670722065493464
Valid Loss:  0.0011229363735765219
Epoch:  430  	Training Loss: 0.0009743520640768111
Test Loss:  0.0009665299439802766
Valid Loss:  0.0011221244931221008
Epoch:  431  	Training Loss: 0.0009736104402691126
Test Loss:  0.000966001651249826
Valid Loss:  0.001121332636103034
Epoch:  432  	Training Loss: 0.0009728864533826709
Test Loss:  0.0009662722586654127
Valid Loss:  0.0011209446238353848
Epoch:  433  	Training Loss: 0.0009728320292197168
Test Loss:  0.0009664473473094404
Valid Loss:  0.0011206285562366247
Epoch:  434  	Training Loss: 0.0009727880242280662
Test Loss:  0.000966549851000309
Valid Loss:  0.0011203581234440207
Epoch:  435  	Training Loss: 0.0009727452415972948
Test Loss:  0.0009665702236816287
Valid Loss:  0.0011201237794011831
Epoch:  436  	Training Loss: 0.0009727084543555975
Test Loss:  0.00096656329696998
Valid Loss:  0.0011199158616364002
Epoch:  437  	Training Loss: 0.0009726764401420951
Test Loss:  0.0009664783719927073
Valid Loss:  0.0011197372805327177
Epoch:  438  	Training Loss: 0.0009726554271765053
Test Loss:  0.0009663892560638487
Valid Loss:  0.0011195585830137134
Epoch:  439  	Training Loss: 0.0009726355201564729
Test Loss:  0.0009662482189014554
Valid Loss:  0.001119396649301052
Epoch:  440  	Training Loss: 0.0009726214921101928
Test Loss:  0.0009661405347287655
Valid Loss:  0.0011192334350198507
Epoch:  441  	Training Loss: 0.0009726056014187634
Test Loss:  0.0009659857023507357
Valid Loss:  0.0011190730147063732
Epoch:  442  	Training Loss: 0.0009725946583785117
Test Loss:  0.0009650596184656024
Valid Loss:  0.001118542393669486
Epoch:  443  	Training Loss: 0.0009713990148156881
Test Loss:  0.0009643073426559567
Valid Loss:  0.0011180457659065723
Epoch:  444  	Training Loss: 0.0009704003459773958
Test Loss:  0.0009636898757889867
Valid Loss:  0.0011175369145348668
Epoch:  445  	Training Loss: 0.0009694809559732676
Test Loss:  0.0009631469147279859
Valid Loss:  0.0011170522775501013
Epoch:  446  	Training Loss: 0.0009686101693660021
Test Loss:  0.0009626135579310358
Valid Loss:  0.001116602448746562
Epoch:  447  	Training Loss: 0.000967810396105051
Test Loss:  0.0009620948694646358
Valid Loss:  0.0011161667061969638
Epoch:  448  	Training Loss: 0.0009670470608398318
Test Loss:  0.0009616309544071555
Valid Loss:  0.0011157332919538021
Epoch:  449  	Training Loss: 0.0009663165546953678
Test Loss:  0.0009611262939870358
Valid Loss:  0.0011153049999848008
Epoch:  450  	Training Loss: 0.0009656180627644062
Test Loss:  0.0009606109815649688
Valid Loss:  0.0011148694902658463
Epoch:  451  	Training Loss: 0.0009649357525631785
Test Loss:  0.0009601617348380387
Valid Loss:  0.001114426413550973
Epoch:  452  	Training Loss: 0.0009642754448577762
Test Loss:  0.0009611659916117787
Valid Loss:  0.0011138359550386667
Epoch:  453  	Training Loss: 0.000963362748734653
Test Loss:  0.0009613014408387244
Valid Loss:  0.0011135642416775227
Epoch:  454  	Training Loss: 0.0009626842220313847
Test Loss:  0.0009611603454686701
Valid Loss:  0.001113399164751172
Epoch:  455  	Training Loss: 0.0009621036006137729
Test Loss:  0.0009608472464606166
Valid Loss:  0.0011132786748930812
Epoch:  456  	Training Loss: 0.0009616166935302317
Test Loss:  0.0009604602819308639
Valid Loss:  0.0011131556238979101
Epoch:  457  	Training Loss: 0.0009611956775188446
Test Loss:  0.0009597894968464971
Valid Loss:  0.0011130118509754539
Epoch:  458  	Training Loss: 0.0009608555701561272
Test Loss:  0.0009590697009116411
Valid Loss:  0.00111280323471874
Epoch:  459  	Training Loss: 0.0009605381637811661
Test Loss:  0.0009583018254488707
Valid Loss:  0.0011125484015792608
Epoch:  460  	Training Loss: 0.0009602517820894718
Test Loss:  0.0009576291777193546
Valid Loss:  0.0011122443247586489
Epoch:  461  	Training Loss: 0.0009599934564903378
Test Loss:  0.0009569491958245635
Valid Loss:  0.0011119114933535457
Epoch:  462  	Training Loss: 0.0009597618482075632
Test Loss:  0.0009563963394612074
Valid Loss:  0.0011116156820207834
Epoch:  463  	Training Loss: 0.0009592316928319633
Test Loss:  0.0009558855672366917
Valid Loss:  0.0011113255750387907
Epoch:  464  	Training Loss: 0.0009587347158230841
Test Loss:  0.0009553699055686593
Valid Loss:  0.0011110355844721198
Epoch:  465  	Training Loss: 0.0009582550846971571
Test Loss:  0.0009548928355798125
Valid Loss:  0.001110730692744255
Epoch:  466  	Training Loss: 0.0009577942546457052
Test Loss:  0.00095443578902632
Valid Loss:  0.0011104191653430462
Epoch:  467  	Training Loss: 0.000957338372245431
Test Loss:  0.0009539680904708803
Valid Loss:  0.0011101008858531713
Epoch:  468  	Training Loss: 0.0009568899404257536
Test Loss:  0.0009535187855362892
Valid Loss:  0.0011097713140770793
Epoch:  469  	Training Loss: 0.0009564494830556214
Test Loss:  0.0009530995739623904
Valid Loss:  0.0011094356887042522
Epoch:  470  	Training Loss: 0.0009560350445099175
Test Loss:  0.0009527092333883047
Valid Loss:  0.0011091091437265277
Epoch:  471  	Training Loss: 0.0009556380682624876
Test Loss:  0.000952294678427279
Valid Loss:  0.0011087750317528844
Epoch:  472  	Training Loss: 0.0009552463889122009
Test Loss:  0.0009510843083262444
Valid Loss:  0.0011080910917371511
Epoch:  473  	Training Loss: 0.0009547576773911715
Test Loss:  0.000950391695369035
Valid Loss:  0.0011072736233472824
Epoch:  474  	Training Loss: 0.0009543274063616991
Test Loss:  0.0009498229483142495
Valid Loss:  0.0011064285645261407
Epoch:  475  	Training Loss: 0.0009539156453683972
Test Loss:  0.0009493249235674739
Valid Loss:  0.0011056140065193176
Epoch:  476  	Training Loss: 0.0009535157005302608
Test Loss:  0.0009488037903793156
Valid Loss:  0.0011048330925405025
Epoch:  477  	Training Loss: 0.0009531376999802887
Test Loss:  0.0009482073946855962
Valid Loss:  0.0011040556710213423
Epoch:  478  	Training Loss: 0.0009527669753879309
Test Loss:  0.0009477731073275208
Valid Loss:  0.00110328895971179
Epoch:  479  	Training Loss: 0.0009524024790152907
Test Loss:  0.0009473812533542514
Valid Loss:  0.0011025595013052225
Epoch:  480  	Training Loss: 0.000952046480961144
Test Loss:  0.0009469507494941354
Valid Loss:  0.001101851579733193
Epoch:  481  	Training Loss: 0.0009516925783827901
Test Loss:  0.0009465741459280252
Valid Loss:  0.0011011736933141947
Epoch:  482  	Training Loss: 0.000951344205532223
Test Loss:  0.0009459667489863932
Valid Loss:  0.0011009314330294728
 97%|█████████▋| 483/500 [05:40<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:41<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:41<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.95it/s]100%|██████████| 500/500 [05:48<00:00,  1.44it/s]
Epoch:  483  	Training Loss: 0.0009511871612630785
Test Loss:  0.0009455665713176131
Valid Loss:  0.0011006381828337908
Epoch:  484  	Training Loss: 0.0009510284289717674
Test Loss:  0.000945226987823844
Valid Loss:  0.001100302441045642
Epoch:  485  	Training Loss: 0.0009508715593256056
Test Loss:  0.0009449593489989638
Valid Loss:  0.0010999522637575865
Epoch:  486  	Training Loss: 0.0009507159702479839
Test Loss:  0.0009447462507523596
Valid Loss:  0.0010995820630341768
Epoch:  487  	Training Loss: 0.0009505589259788394
Test Loss:  0.0009445605101063848
Valid Loss:  0.0010992181487381458
Epoch:  488  	Training Loss: 0.0009504072368144989
Test Loss:  0.0009443946182727814
Valid Loss:  0.0010988451540470123
Epoch:  489  	Training Loss: 0.0009502524044364691
Test Loss:  0.0009442470036447048
Valid Loss:  0.0010984857799485326
Epoch:  490  	Training Loss: 0.0009500973392277956
Test Loss:  0.0009441053844057024
Valid Loss:  0.0010981264058500528
Epoch:  491  	Training Loss: 0.0009499440202489495
Test Loss:  0.000943968421779573
Valid Loss:  0.001097776461392641
Epoch:  492  	Training Loss: 0.0009497974533587694
Test Loss:  0.0009439201676286757
Valid Loss:  0.0010973841417580843
Epoch:  493  	Training Loss: 0.0009496529237367213
Test Loss:  0.0009438665583729744
Valid Loss:  0.0010970158036798239
Epoch:  494  	Training Loss: 0.0009495100239291787
Test Loss:  0.0009437952539883554
Valid Loss:  0.0010966658592224121
Epoch:  495  	Training Loss: 0.0009493667166680098
Test Loss:  0.000943716848269105
Valid Loss:  0.001096322201192379
Epoch:  496  	Training Loss: 0.0009492262615822256
Test Loss:  0.0009436299442313612
Valid Loss:  0.001096006017178297
Epoch:  497  	Training Loss: 0.0009490845841355622
Test Loss:  0.0009435453685000539
Valid Loss:  0.0010956893675029278
Epoch:  498  	Training Loss: 0.0009489490184932947
Test Loss:  0.0009434618405066431
Valid Loss:  0.0010953900637105107
Epoch:  499  	Training Loss: 0.0009488234645687044
Test Loss:  0.0009433748200535774
Valid Loss:  0.001095103332772851
Epoch:  500  	Training Loss: 0.0009487034985795617
Test Loss:  0.0009432871593162417
Valid Loss:  0.0010948262643069029
seed is  15
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 14.91it/s]  1%|          | 4/500 [00:00<00:32, 15.12it/s]  1%|          | 6/500 [00:00<00:31, 15.57it/s]  2%|▏         | 8/500 [00:00<00:31, 15.70it/s]  2%|▏         | 10/500 [00:00<00:33, 14.81it/s]  2%|▏         | 12/500 [00:00<00:35, 13.83it/s]  3%|▎         | 14/500 [00:00<00:36, 13.44it/s]  3%|▎         | 16/500 [00:01<00:34, 14.11it/s]  4%|▎         | 18/500 [00:01<00:32, 14.73it/s]  4%|▍         | 20/500 [00:01<00:31, 15.16it/s]  4%|▍         | 22/500 [00:01<00:30, 15.54it/s]  5%|▍         | 24/500 [00:01<00:30, 15.61it/s]  5%|▌         | 26/500 [00:01<00:29, 15.86it/s]  6%|▌         | 28/500 [00:01<00:29, 15.94it/s]  6%|▌         | 30/500 [00:01<00:29, 15.80it/s]  6%|▋         | 32/500 [00:02<00:30, 15.26it/s]  7%|▋         | 34/500 [00:02<00:29, 15.58it/s]  7%|▋         | 36/500 [00:02<00:29, 15.72it/s]  8%|▊         | 38/500 [00:02<00:29, 15.80it/s]  8%|▊         | 40/500 [00:02<00:29, 15.66it/s]  8%|▊         | 42/500 [00:02<00:31, 14.50it/s]  9%|▉         | 44/500 [00:02<00:32, 13.97it/s]  9%|▉         | 46/500 [00:03<00:31, 14.55it/s] 10%|▉         | 48/500 [00:03<00:30, 14.97it/s] 10%|█         | 50/500 [00:03<00:29, 15.33it/s] 10%|█         | 52/500 [00:03<00:28, 15.62it/s] 11%|█         | 54/500 [00:03<00:28, 15.73it/s] 11%|█         | 56/500 [00:03<00:28, 15.77it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.00it/s] 12%|█▏        | 60/500 [00:03<00:29, 15.07it/s] 12%|█▏        | 62/500 [00:04<00:31, 13.89it/s] 13%|█▎        | 64/500 [00:04<00:31, 13.71it/s] 13%|█▎        | 66/500 [00:04<00:30, 14.29it/s] 14%|█▎        | 68/500 [00:04<00:29, 14.83it/s] 14%|█▍        | 70/500 [00:04<00:28, 15.26it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.42it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.60it/s] 15%|█▌        | 76/500 [00:05<00:26, 15.85it/s] 16%|█▌        | 78/500 [00:05<00:26, 15.90it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.90it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.76it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.78it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.76it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.44it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.71it/s] 18%|█▊        | 92/500 [00:06<00:26, 15.46it/s] 19%|█▉        | 94/500 [00:06<00:28, 14.30it/s] 19%|█▉        | 96/500 [00:06<00:29, 13.76it/s] 20%|█▉        | 98/500 [00:06<00:28, 14.34it/s] 20%|██        | 100/500 [00:06<00:27, 14.38it/s] 20%|██        | 102/500 [00:06<00:26, 14.85it/s] 21%|██        | 104/500 [00:06<00:26, 15.01it/s] 21%|██        | 106/500 [00:07<00:27, 14.10it/s] 22%|██▏       | 108/500 [00:07<00:28, 13.53it/s] 22%|██▏       | 110/500 [00:07<00:29, 13.03it/s] 22%|██▏       | 112/500 [00:07<00:29, 12.96it/s] 23%|██▎       | 114/500 [00:07<00:27, 13.80it/s] 23%|██▎       | 116/500 [00:07<00:26, 14.41it/s] 24%|██▎       | 118/500 [00:07<00:25, 14.93it/s] 24%|██▍       | 120/500 [00:08<00:24, 15.31it/s] 24%|██▍       | 122/500 [00:08<00:24, 15.58it/s] 25%|██▍       | 124/500 [00:08<00:24, 15.09it/s]Epoch:  1  	Training Loss: 0.09472019970417023
Test Loss:  1531.7509765625
Valid Loss:  1536.413818359375
Epoch:  2  	Training Loss: 1531.9501953125
Test Loss:  24357489344512.0
Valid Loss:  23879242219520.0
Epoch:  3  	Training Loss: 24219349942272.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:24, 15.39it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.48it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.73it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.61it/s] 27%|██▋       | 134/500 [00:08<00:25, 14.37it/s] 27%|██▋       | 136/500 [00:09<00:26, 13.53it/s] 28%|██▊       | 138/500 [00:09<00:26, 13.85it/s] 28%|██▊       | 140/500 [00:09<00:24, 14.43it/s] 28%|██▊       | 142/500 [00:09<00:23, 14.97it/s] 29%|██▉       | 144/500 [00:09<00:23, 15.34it/s] 29%|██▉       | 146/500 [00:09<00:23, 14.87it/s] 30%|██▉       | 148/500 [00:09<00:23, 15.19it/s] 30%|███       | 150/500 [00:10<00:23, 14.63it/s] 30%|███       | 152/500 [00:10<00:25, 13.67it/s] 31%|███       | 154/500 [00:10<00:26, 13.03it/s] 31%|███       | 156/500 [00:10<00:26, 12.80it/s] 32%|███▏      | 158/500 [00:10<00:27, 12.64it/s] 32%|███▏      | 160/500 [00:10<00:27, 12.56it/s] 32%|███▏      | 162/500 [00:11<00:25, 13.02it/s] 33%|███▎      | 164/500 [00:11<00:26, 12.76it/s] 33%|███▎      | 166/500 [00:11<00:25, 13.14it/s] 34%|███▎      | 168/500 [00:11<00:23, 13.93it/s] 34%|███▍      | 170/500 [00:11<00:22, 14.48it/s] 34%|███▍      | 172/500 [00:11<00:22, 14.79it/s] 35%|███▍      | 174/500 [00:11<00:21, 15.04it/s] 35%|███▌      | 176/500 [00:11<00:21, 15.10it/s] 36%|███▌      | 178/500 [00:12<00:20, 15.40it/s] 36%|███▌      | 180/500 [00:12<00:20, 15.31it/s] 36%|███▋      | 182/500 [00:12<00:20, 15.46it/s] 37%|███▋      | 184/500 [00:12<00:20, 15.65it/s] 37%|███▋      | 186/500 [00:12<00:19, 15.80it/s] 38%|███▊      | 188/500 [00:12<00:20, 15.13it/s] 38%|███▊      | 190/500 [00:12<00:20, 15.24it/s] 38%|███▊      | 192/500 [00:12<00:20, 15.27it/s] 39%|███▉      | 194/500 [00:13<00:20, 15.26it/s] 39%|███▉      | 196/500 [00:13<00:21, 14.20it/s] 40%|███▉      | 198/500 [00:13<00:22, 13.38it/s] 40%|████      | 200/500 [00:13<00:23, 12.96it/s] 40%|████      | 202/500 [00:13<00:22, 13.26it/s] 41%|████      | 204/500 [00:13<00:21, 14.06it/s] 41%|████      | 206/500 [00:14<00:20, 14.37it/s] 42%|████▏     | 208/500 [00:14<00:21, 13.68it/s] 42%|████▏     | 210/500 [00:14<00:20, 14.04it/s] 42%|████▏     | 212/500 [00:14<00:19, 14.68it/s] 43%|████▎     | 214/500 [00:14<00:18, 15.17it/s] 43%|████▎     | 216/500 [00:14<00:18, 15.39it/s] 44%|████▎     | 218/500 [00:14<00:18, 15.59it/s] 44%|████▍     | 220/500 [00:14<00:17, 15.88it/s] 44%|████▍     | 222/500 [00:15<00:17, 15.96it/s] 45%|████▍     | 224/500 [00:15<00:17, 15.83it/s] 45%|████▌     | 226/500 [00:15<00:17, 16.06it/s] 46%|████▌     | 228/500 [00:15<00:16, 16.03it/s] 46%|████▌     | 230/500 [00:15<00:16, 16.05it/s] 46%|████▋     | 232/500 [00:15<00:17, 14.93it/s] 47%|████▋     | 234/500 [00:15<00:18, 14.17it/s] 47%|████▋     | 236/500 [00:15<00:18, 14.57it/s] 48%|████▊     | 238/500 [00:16<00:17, 15.03it/s] 48%|████▊     | 240/500 [00:16<00:17, 15.29it/s] 48%|████▊     | 242/500 [00:16<00:16, 15.58it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.66it/s] 49%|████▉     | 246/500 [00:16<00:16, 15.64it/s] 50%|████▉     | 248/500 [00:16<00:16, 15.56it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 15.70it/s] 50%|█████     | 252/500 [00:17<00:15, 15.85it/s] 51%|█████     | 254/500 [00:17<00:15, 15.97it/s] 51%|█████     | 256/500 [00:17<00:15, 16.09it/s] 52%|█████▏    | 258/500 [00:17<00:15, 15.98it/s] 52%|█████▏    | 260/500 [00:17<00:15, 15.92it/s] 52%|█████▏    | 262/500 [00:17<00:14, 16.05it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.01it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.06it/s] 54%|█████▎    | 268/500 [00:18<00:14, 15.95it/s] 54%|█████▍    | 270/500 [00:18<00:14, 15.98it/s] 54%|█████▍    | 272/500 [00:18<00:14, 16.08it/s] 55%|█████▍    | 274/500 [00:18<00:14, 15.63it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.75it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.70it/s] 56%|█████▌    | 280/500 [00:18<00:13, 15.88it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.95it/s] 57%|█████▋    | 284/500 [00:19<00:13, 16.02it/s] 57%|█████▋    | 286/500 [00:19<00:13, 16.11it/s] 58%|█████▊    | 288/500 [00:19<00:13, 15.27it/s] 58%|█████▊    | 290/500 [00:19<00:13, 15.59it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.62it/s] 59%|█████▉    | 294/500 [00:19<00:14, 14.49it/s] 59%|█████▉    | 296/500 [00:19<00:14, 13.72it/s] 60%|█████▉    | 298/500 [00:20<00:15, 13.27it/s] 60%|██████    | 300/500 [00:20<00:15, 12.95it/s] 60%|██████    | 302/500 [00:20<00:15, 12.78it/s] 61%|██████    | 304/500 [00:20<00:15, 12.62it/s] 61%|██████    | 306/500 [00:20<00:15, 12.52it/s] 62%|██████▏   | 308/500 [00:20<00:14, 13.00it/s] 62%|██████▏   | 310/500 [00:20<00:13, 13.85it/s] 62%|██████▏   | 312/500 [00:21<00:12, 14.52it/s] 63%|██████▎   | 314/500 [00:21<00:12, 15.07it/s] 63%|██████▎   | 316/500 [00:21<00:11, 15.37it/s] 64%|██████▎   | 318/500 [00:21<00:11, 15.63it/s] 64%|██████▍   | 320/500 [00:21<00:11, 15.72it/s] 64%|██████▍   | 322/500 [00:21<00:11, 15.79it/s] 65%|██████▍   | 324/500 [00:21<00:11, 15.91it/s] 65%|██████▌   | 326/500 [00:21<00:11, 14.93it/s] 66%|██████▌   | 328/500 [00:22<00:11, 15.08it/s] 66%|██████▌   | 330/500 [00:22<00:11, 15.26it/s] 66%|██████▋   | 332/500 [00:22<00:10, 15.49it/s] 67%|██████▋   | 334/500 [00:22<00:10, 15.75it/s] 67%|██████▋   | 336/500 [00:22<00:10, 15.71it/s] 68%|██████▊   | 338/500 [00:22<00:10, 15.55it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.76it/s] 68%|██████▊   | 342/500 [00:22<00:09, 15.90it/s] 69%|██████▉   | 344/500 [00:23<00:09, 15.88it/s] 69%|██████▉   | 346/500 [00:23<00:09, 15.78it/s] 70%|██████▉   | 348/500 [00:23<00:09, 15.80it/s] 70%|███████   | 350/500 [00:23<00:09, 15.68it/s] 70%|███████   | 352/500 [00:23<00:09, 15.63it/s] 71%|███████   | 354/500 [00:23<00:09, 15.84it/s] 71%|███████   | 356/500 [00:23<00:09, 15.74it/s] 72%|███████▏  | 358/500 [00:23<00:09, 15.69it/s] 72%|███████▏  | 360/500 [00:24<00:08, 15.68it/s] 72%|███████▏  | 362/500 [00:24<00:08, 15.76it/s] 73%|███████▎  | 364/500 [00:24<00:08, 15.91it/s] 73%|███████▎  | 366/500 [00:24<00:08, 15.94it/s] 74%|███████▎  | 368/500 [00:24<00:08, 15.82it/s] 74%|███████▍  | 370/500 [00:24<00:08, 15.95it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.48it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 15.80it/s] 75%|███████▌  | 376/500 [00:25<00:07, 15.79it/s] 76%|███████▌  | 378/500 [00:25<00:07, 15.48it/s] 76%|███████▌  | 380/500 [00:25<00:08, 14.22it/s] 76%|███████▋  | 382/500 [00:25<00:08, 14.20it/s] 77%|███████▋  | 384/500 [00:25<00:08, 14.48it/s] 77%|███████▋  | 386/500 [00:25<00:08, 13.76it/s] 78%|███████▊  | 388/500 [00:26<00:08, 13.28it/s] 78%|███████▊  | 390/500 [00:26<00:08, 12.98it/s] 78%|███████▊  | 392/500 [00:26<00:08, 12.74it/s] 79%|███████▉  | 394/500 [00:26<00:08, 12.52it/s] 79%|███████▉  | 396/500 [00:26<00:08, 12.35it/s] 80%|███████▉  | 398/500 [00:26<00:08, 12.46it/s] 80%|████████  | 400/500 [00:26<00:07, 13.34it/s] 80%|████████  | 402/500 [00:27<00:06, 14.03it/s] 81%|████████  | 404/500 [00:27<00:06, 14.39it/s] 81%|████████  | 406/500 [00:27<00:06, 14.89it/s] 82%|████████▏ | 408/500 [00:27<00:06, 15.28it/s] 82%|████████▏ | 410/500 [00:27<00:05, 15.51it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.54it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.68it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.81it/s] 84%|████████▎ | 418/500 [00:28<00:05, 15.89it/s] 84%|████████▍ | 420/500 [00:28<00:04, 16.05it/s] 84%|████████▍ | 422/500 [00:28<00:04, 16.12it/s] 85%|████████▍ | 424/500 [00:28<00:04, 16.08it/s] 85%|████████▌ | 426/500 [00:28<00:04, 15.87it/s] 86%|████████▌ | 428/500 [00:28<00:04, 15.97it/s] 86%|████████▌ | 430/500 [00:28<00:04, 15.86it/s] 86%|████████▋ | 432/500 [00:28<00:04, 15.74it/s] 87%|████████▋ | 434/500 [00:29<00:04, 15.72it/s] 87%|████████▋ | 436/500 [00:29<00:04, 15.78it/s] 88%|████████▊ | 438/500 [00:29<00:03, 16.02it/s] 88%|████████▊ | 440/500 [00:29<00:03, 16.00it/s] 88%|████████▊ | 442/500 [00:29<00:03, 16.02it/s] 89%|████████▉ | 444/500 [00:29<00:03, 16.03it/s] 89%|████████▉ | 446/500 [00:29<00:03, 16.10it/s] 90%|████████▉ | 448/500 [00:29<00:03, 16.19it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.28it/s] 90%|█████████ | 452/500 [00:30<00:03, 15.41it/s] 91%|█████████ | 454/500 [00:30<00:02, 15.39it/s] 91%|█████████ | 456/500 [00:30<00:02, 15.00it/s] 92%|█████████▏| 458/500 [00:30<00:02, 15.30it/s] 92%|█████████▏| 460/500 [00:30<00:02, 15.52it/s] 92%|█████████▏| 462/500 [00:30<00:02, 15.70it/s] 93%|█████████▎| 464/500 [00:30<00:02, 15.89it/s] 93%|█████████▎| 466/500 [00:31<00:02, 15.45it/s] 94%|█████████▎| 468/500 [00:31<00:02, 15.70it/s] 94%|█████████▍| 470/500 [00:31<00:01, 15.39it/s] 94%|█████████▍| 472/500 [00:31<00:01, 15.63it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.51it/s] 95%|█████████▌| 476/500 [00:31<00:01, 15.55it/s] 96%|█████████▌| 478/500 [00:31<00:01, 15.29it/s] 96%|█████████▌| 480/500 [00:32<00:01, 15.36it/s] 96%|█████████▋| 482/500 [00:32<00:01, 15.44it/s] 97%|█████████▋| 484/500 [00:32<00:01, 15.18it/s] 97%|█████████▋| 486/500 [00:32<00:00, 15.45it/s] 98%|█████████▊| 488/500 [00:32<00:00, 15.76it/s] 98%|█████████▊| 490/500 [00:32<00:00, 14.96it/s] 98%|█████████▊| 492/500 [00:32<00:00, 14.24it/s] 99%|█████████▉| 494/500 [00:32<00:00, 14.59it/s] 99%|█████████▉| 496/500 [00:33<00:00, 14.26it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 14.75it/s]100%|██████████| 500/500 [00:33<00:00, 15.13it/s]100%|██████████| 500/500 [00:33<00:00, 14.98it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  15
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:41,  6.22s/it]  1%|          | 3/500 [00:06<13:53,  1.68s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:53,  2.82it/s]  2%|▏         | 11/500 [00:13<11:01,  1.35s/it]  3%|▎         | 13/500 [00:13<07:30,  1.08it/s]  3%|▎         | 15/500 [00:13<05:14,  1.54it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:27<09:29,  1.21s/it]  7%|▋         | 33/500 [00:27<06:46,  1.15it/s]  7%|▋         | 35/500 [00:27<04:51,  1.59it/s]  7%|▋         | 37/500 [00:27<03:32,  2.18it/s]  8%|▊         | 39/500 [00:27<02:39,  2.90it/s]  8%|▊         | 41/500 [00:34<09:10,  1.20s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:41<08:56,  1.19s/it] 11%|█         | 53/500 [00:41<06:23,  1.17it/s] 11%|█         | 55/500 [00:41<04:38,  1.60it/s] 11%|█▏        | 57/500 [00:41<03:24,  2.17it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.91it/s] 12%|█▏        | 61/500 [00:48<08:55,  1.22s/it] 13%|█▎        | 63/500 [00:48<06:24,  1.14it/s] 13%|█▎        | 65/500 [00:48<04:37,  1.57it/s] 13%|█▎        | 67/500 [00:48<03:21,  2.15it/s] 14%|█▍        | 69/500 [00:48<02:29,  2.89it/s] 14%|█▍        | 71/500 [00:55<08:34,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:10,  1.15it/s]Epoch:  1  	Training Loss: 0.09472019225358963
Test Loss:  285.9560546875
Valid Loss:  276.7340087890625
Epoch:  2  	Training Loss: 273.13232421875
Test Loss:  2.331660747528076
Valid Loss:  2.219311237335205
Epoch:  3  	Training Loss: 2.0377743244171143
Test Loss:  2.0625758171081543
Valid Loss:  1.961410403251648
Epoch:  4  	Training Loss: 1.7947452068328857
Test Loss:  1.8251025676727295
Valid Loss:  1.7339322566986084
Epoch:  5  	Training Loss: 1.5808603763580322
Test Loss:  1.6155049800872803
Valid Loss:  1.533273696899414
Epoch:  6  	Training Loss: 1.3926336765289307
Test Loss:  1.4304877519607544
Valid Loss:  1.3562572002410889
Epoch:  7  	Training Loss: 1.226994276046753
Test Loss:  1.267146110534668
Valid Loss:  1.200082540512085
Epoch:  8  	Training Loss: 1.0812370777130127
Test Loss:  1.1230251789093018
Valid Loss:  1.0624668598175049
Epoch:  9  	Training Loss: 0.95307457447052
Test Loss:  0.996179461479187
Valid Loss:  0.941598117351532
Epoch:  10  	Training Loss: 0.840668797492981
Test Loss:  0.8843865394592285
Valid Loss:  0.8351590633392334
Epoch:  11  	Training Loss: 0.7419198751449585
Test Loss:  0.7856252789497375
Valid Loss:  0.7412037253379822
Epoch:  12  	Training Loss: 0.6550350785255432
Test Loss:  0.7034817934036255
Valid Loss:  0.6633386611938477
Epoch:  13  	Training Loss: 0.5828525424003601
Test Loss:  0.6304326057434082
Valid Loss:  0.59406977891922
Epoch:  14  	Training Loss: 0.5189288854598999
Test Loss:  0.5653841495513916
Valid Loss:  0.5324068069458008
Epoch:  15  	Training Loss: 0.4622608423233032
Test Loss:  0.5074535012245178
Valid Loss:  0.4774985611438751
Epoch:  16  	Training Loss: 0.4120105803012848
Test Loss:  0.45581546425819397
Valid Loss:  0.42857784032821655
Epoch:  17  	Training Loss: 0.36745941638946533
Test Loss:  0.40975475311279297
Valid Loss:  0.3849813938140869
Epoch:  18  	Training Loss: 0.327957421541214
Test Loss:  0.36864960193634033
Valid Loss:  0.3461149334907532
Epoch:  19  	Training Loss: 0.29292213916778564
Test Loss:  0.33195406198501587
Valid Loss:  0.3114478290081024
Epoch:  20  	Training Loss: 0.26183947920799255
Test Loss:  0.29917776584625244
Valid Loss:  0.28051233291625977
Epoch:  21  	Training Loss: 0.23425355553627014
Test Loss:  0.26989543437957764
Valid Loss:  0.2529076933860779
Epoch:  22  	Training Loss: 0.2097754031419754
Test Loss:  0.24229252338409424
Valid Loss:  0.22698858380317688
Epoch:  23  	Training Loss: 0.1868097484111786
Test Loss:  0.21781586110591888
Valid Loss:  0.20402565598487854
Epoch:  24  	Training Loss: 0.16660766303539276
Test Loss:  0.1960827112197876
Valid Loss:  0.18365177512168884
Epoch:  25  	Training Loss: 0.14882054924964905
Test Loss:  0.17676356434822083
Valid Loss:  0.16557839512825012
Epoch:  26  	Training Loss: 0.13315773010253906
Test Loss:  0.165054589509964
Valid Loss:  0.15701508522033691
Epoch:  27  	Training Loss: 0.1234666034579277
Test Loss:  0.16357192397117615
Valid Loss:  0.15567541122436523
Epoch:  28  	Training Loss: 0.12164553999900818
Test Loss:  0.16324353218078613
Valid Loss:  0.15533775091171265
Epoch:  29  	Training Loss: 0.12119646370410919
Test Loss:  0.16309627890586853
Valid Loss:  0.15512609481811523
Epoch:  30  	Training Loss: 0.12097793817520142
Test Loss:  0.1630048155784607
Valid Loss:  0.15498127043247223
Epoch:  31  	Training Loss: 0.12084925174713135
Test Loss:  0.16293595731258392
Valid Loss:  0.15488961338996887
Epoch:  32  	Training Loss: 0.12076684087514877
Test Loss:  0.16288191080093384
Valid Loss:  0.1548301875591278
Epoch:  33  	Training Loss: 0.1207149475812912
Test Loss:  0.1628294587135315
Valid Loss:  0.1547737568616867
Epoch:  34  	Training Loss: 0.12066803872585297
Test Loss:  0.16277888417243958
Valid Loss:  0.1547219604253769
Epoch:  35  	Training Loss: 0.1206236332654953
Test Loss:  0.16272860765457153
Valid Loss:  0.1546715348958969
Epoch:  36  	Training Loss: 0.12058024853467941
Test Loss:  0.16267848014831543
Valid Loss:  0.15462234616279602
Epoch:  37  	Training Loss: 0.12053734064102173
Test Loss:  0.16262850165367126
Valid Loss:  0.1545744389295578
Epoch:  38  	Training Loss: 0.12049469351768494
Test Loss:  0.16257944703102112
Valid Loss:  0.15452659130096436
Epoch:  39  	Training Loss: 0.1204524040222168
Test Loss:  0.16253048181533813
Valid Loss:  0.15447881817817688
Epoch:  40  	Training Loss: 0.12041059881448746
Test Loss:  0.16248159110546112
Valid Loss:  0.15443113446235657
Epoch:  41  	Training Loss: 0.12036952376365662
Test Loss:  0.16243287920951843
Valid Loss:  0.15438364446163177
Epoch:  42  	Training Loss: 0.12032961845397949
Test Loss:  0.16237816214561462
Valid Loss:  0.15433001518249512
Epoch:  43  	Training Loss: 0.12028518319129944
Test Loss:  0.16232356429100037
Valid Loss:  0.1542765200138092
Epoch:  44  	Training Loss: 0.1202409490942955
Test Loss:  0.1622689962387085
Valid Loss:  0.15422308444976807
Epoch:  45  	Training Loss: 0.12019683420658112
Test Loss:  0.1622144728899002
Valid Loss:  0.1541697382926941
Epoch:  46  	Training Loss: 0.120153047144413
Test Loss:  0.1621599793434143
Valid Loss:  0.1541164666414261
Epoch:  47  	Training Loss: 0.12010952830314636
Test Loss:  0.1621055006980896
Valid Loss:  0.15406329929828644
Epoch:  48  	Training Loss: 0.12006618827581406
Test Loss:  0.16205105185508728
Valid Loss:  0.15401017665863037
Epoch:  49  	Training Loss: 0.12002294510602951
Test Loss:  0.16199667751789093
Valid Loss:  0.15395715832710266
Epoch:  50  	Training Loss: 0.11997991055250168
Test Loss:  0.1619424819946289
Valid Loss:  0.15390422940254211
Epoch:  51  	Training Loss: 0.11993701756000519
Test Loss:  0.16188842058181763
Valid Loss:  0.15385133028030396
Epoch:  52  	Training Loss: 0.11989419162273407
Test Loss:  0.1618354320526123
Valid Loss:  0.15379971265792847
Epoch:  53  	Training Loss: 0.11985206604003906
Test Loss:  0.16178253293037415
Valid Loss:  0.1537482589483261
Epoch:  54  	Training Loss: 0.11981019377708435
Test Loss:  0.16172967851161957
Valid Loss:  0.15369683504104614
Epoch:  55  	Training Loss: 0.1197684183716774
Test Loss:  0.161676824092865
Valid Loss:  0.15364542603492737
Epoch:  56  	Training Loss: 0.11972689628601074
Test Loss:  0.16162408888339996
Valid Loss:  0.15359416604042053
Epoch:  57  	Training Loss: 0.11968560516834259
Test Loss:  0.1615714430809021
Valid Loss:  0.15354295074939728
Epoch:  58  	Training Loss: 0.1196444034576416
Test Loss:  0.16151879727840424
Valid Loss:  0.15349185466766357
Epoch:  59  	Training Loss: 0.11960325390100479
Test Loss:  0.16146625578403473
Valid Loss:  0.1534409523010254
Epoch:  60  	Training Loss: 0.11956223845481873
Test Loss:  0.16141371428966522
Valid Loss:  0.1533900946378708
Epoch:  61  	Training Loss: 0.11952123045921326
Test Loss:  0.1613611876964569
Valid Loss:  0.1533392369747162
Epoch:  62  	Training Loss: 0.11948026716709137
Test Loss:  0.1613091230392456
Valid Loss:  0.15328893065452576
Epoch:  63  	Training Loss: 0.11943961679935455
Test Loss:  0.1612570881843567
Valid Loss:  0.15323863923549652
Epoch:  64  	Training Loss: 0.11939897388219833
Test Loss:  0.16120503842830658
Valid Loss:  0.15318836271762848
Epoch:  65  	Training Loss: 0.11935834586620331
Test Loss:  0.16115307807922363
Valid Loss:  0.15313813090324402
Epoch:  66  	Training Loss: 0.11931784451007843
Test Loss:  0.16110113263130188
Valid Loss:  0.15308791399002075
Epoch:  67  	Training Loss: 0.11927735805511475
Test Loss:  0.16104918718338013
Valid Loss:  0.15303775668144226
Epoch:  68  	Training Loss: 0.11923687160015106
Test Loss:  0.16099727153778076
Valid Loss:  0.15298756957054138
Epoch:  69  	Training Loss: 0.11919642239809036
Test Loss:  0.1609453558921814
Valid Loss:  0.1529374122619629
Epoch:  70  	Training Loss: 0.11915598064661026
Test Loss:  0.1608934998512268
Valid Loss:  0.15288731455802917
Epoch:  71  	Training Loss: 0.1191156655550003
Test Loss:  0.16084177792072296
Valid Loss:  0.15283739566802979
Epoch:  72  	Training Loss: 0.11907552927732468
Test Loss:  0.16078755259513855
Valid Loss:  0.15278521180152893
Epoch:  73  	Training Loss: 0.11903344094753265
Test Loss:  0.16073334217071533
Valid Loss:  0.15273307263851166
Epoch:  74  	Training Loss: 0.11899137496948242
Test Loss:   15%|█▌        | 75/500 [00:55<04:27,  1.59it/s] 15%|█▌        | 77/500 [00:55<03:15,  2.17it/s] 16%|█▌        | 79/500 [00:55<02:24,  2.92it/s] 16%|█▌        | 81/500 [01:02<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:20,  1.59it/s] 17%|█▋        | 87/500 [01:02<03:11,  2.15it/s] 18%|█▊        | 89/500 [01:02<02:24,  2.85it/s] 18%|█▊        | 91/500 [01:09<08:14,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:53,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:05,  2.18it/s] 20%|█▉        | 99/500 [01:09<02:18,  2.90it/s] 20%|██        | 101/500 [01:16<07:55,  1.19s/it] 21%|██        | 103/500 [01:16<05:40,  1.17it/s] 21%|██        | 105/500 [01:16<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:16<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:23<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:23<05:29,  1.18it/s] 23%|██▎       | 115/500 [01:23<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:23<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:23<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:30<07:41,  1.22s/it] 25%|██▍       | 123/500 [01:30<05:29,  1.14it/s] 25%|██▌       | 125/500 [01:30<03:59,  1.57it/s] 25%|██▌       | 127/500 [01:30<02:54,  2.14it/s] 26%|██▌       | 129/500 [01:30<02:08,  2.88it/s] 26%|██▌       | 131/500 [01:37<07:21,  1.20s/it] 27%|██▋       | 133/500 [01:37<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:37<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:37<02:45,  2.20it/s] 28%|██▊       | 139/500 [01:37<02:02,  2.96it/s] 28%|██▊       | 141/500 [01:43<07:05,  1.19s/it] 29%|██▊       | 143/500 [01:44<05:03,  1.17it/s] 29%|██▉       | 145/500 [01:44<03:38,  1.62it/s]0.1606791764497757
Valid Loss:  0.15268096327781677
Epoch:  75  	Training Loss: 0.11894939839839935
Test Loss:  0.16062504053115845
Valid Loss:  0.15262886881828308
Epoch:  76  	Training Loss: 0.11890743672847748
Test Loss:  0.1605709344148636
Valid Loss:  0.15257683396339417
Epoch:  77  	Training Loss: 0.1188654899597168
Test Loss:  0.16051681339740753
Valid Loss:  0.152524933218956
Epoch:  78  	Training Loss: 0.11882355809211731
Test Loss:  0.16046275198459625
Valid Loss:  0.15247303247451782
Epoch:  79  	Training Loss: 0.11878164112567902
Test Loss:  0.16040867567062378
Valid Loss:  0.15242117643356323
Epoch:  80  	Training Loss: 0.11873974651098251
Test Loss:  0.1603546142578125
Valid Loss:  0.15236932039260864
Epoch:  81  	Training Loss: 0.1186978742480278
Test Loss:  0.1603006273508072
Valid Loss:  0.15231749415397644
Epoch:  82  	Training Loss: 0.11865607649087906
Test Loss:  0.1602475643157959
Valid Loss:  0.1522664576768875
Epoch:  83  	Training Loss: 0.11861491203308105
Test Loss:  0.1601945459842682
Valid Loss:  0.15221545100212097
Epoch:  84  	Training Loss: 0.11857375502586365
Test Loss:  0.16014154255390167
Valid Loss:  0.152164489030838
Epoch:  85  	Training Loss: 0.11853264272212982
Test Loss:  0.16008861362934113
Valid Loss:  0.15211369097232819
Epoch:  86  	Training Loss: 0.11849160492420197
Test Loss:  0.16003575921058655
Valid Loss:  0.15206292271614075
Epoch:  87  	Training Loss: 0.1184505894780159
Test Loss:  0.15998303890228271
Valid Loss:  0.1520121693611145
Epoch:  88  	Training Loss: 0.11840961873531342
Test Loss:  0.15993034839630127
Valid Loss:  0.15196146070957184
Epoch:  89  	Training Loss: 0.1183687150478363
Test Loss:  0.1598776876926422
Valid Loss:  0.15191076695919037
Epoch:  90  	Training Loss: 0.11832784116268158
Test Loss:  0.15982505679130554
Valid Loss:  0.15186011791229248
Epoch:  91  	Training Loss: 0.11828698962926865
Test Loss:  0.15977245569229126
Valid Loss:  0.1518094837665558
Epoch:  92  	Training Loss: 0.1182461529970169
Test Loss:  0.15971827507019043
Valid Loss:  0.15175741910934448
Epoch:  93  	Training Loss: 0.11820408701896667
Test Loss:  0.159664124250412
Valid Loss:  0.15170535445213318
Epoch:  94  	Training Loss: 0.11816205084323883
Test Loss:  0.15961001813411713
Valid Loss:  0.15165331959724426
Epoch:  95  	Training Loss: 0.11812007427215576
Test Loss:  0.15955591201782227
Valid Loss:  0.15160129964351654
Epoch:  96  	Training Loss: 0.11807809770107269
Test Loss:  0.1595018059015274
Valid Loss:  0.15154927968978882
Epoch:  97  	Training Loss: 0.11803612858057022
Test Loss:  0.15944771468639374
Valid Loss:  0.15149730443954468
Epoch:  98  	Training Loss: 0.11799417436122894
Test Loss:  0.15939363837242126
Valid Loss:  0.1514454334974289
Epoch:  99  	Training Loss: 0.11795223504304886
Test Loss:  0.15933957695960999
Valid Loss:  0.1513935923576355
Epoch:  100  	Training Loss: 0.11791029572486877
Test Loss:  0.1592855155467987
Valid Loss:  0.15134172141551971
Epoch:  101  	Training Loss: 0.11786835640668869
Test Loss:  0.15923148393630981
Valid Loss:  0.15128988027572632
Epoch:  102  	Training Loss: 0.11782645434141159
Test Loss:  0.15917721390724182
Valid Loss:  0.15123778581619263
Epoch:  103  	Training Loss: 0.11778434365987778
Test Loss:  0.159123033285141
Valid Loss:  0.15118569135665894
Epoch:  104  	Training Loss: 0.11774229258298874
Test Loss:  0.15906888246536255
Valid Loss:  0.15113364160060883
Epoch:  105  	Training Loss: 0.11770029366016388
Test Loss:  0.15901479125022888
Valid Loss:  0.1510816216468811
Epoch:  106  	Training Loss: 0.117658331990242
Test Loss:  0.15896070003509521
Valid Loss:  0.15102961659431458
Epoch:  107  	Training Loss: 0.11761640012264252
Test Loss:  0.15890662372112274
Valid Loss:  0.15097762644290924
Epoch:  108  	Training Loss: 0.11757447570562363
Test Loss:  0.15885257720947266
Valid Loss:  0.1509256660938263
Epoch:  109  	Training Loss: 0.11753259599208832
Test Loss:  0.15879859030246735
Valid Loss:  0.15087372064590454
Epoch:  110  	Training Loss: 0.11749076843261719
Test Loss:  0.15874463319778442
Valid Loss:  0.15082181990146637
Epoch:  111  	Training Loss: 0.11744900047779083
Test Loss:  0.1586906909942627
Valid Loss:  0.1507699340581894
Epoch:  112  	Training Loss: 0.11740724742412567
Test Loss:  0.15863604843616486
Valid Loss:  0.15071740746498108
Epoch:  113  	Training Loss: 0.11736493557691574
Test Loss:  0.1585814207792282
Valid Loss:  0.15066486597061157
Epoch:  114  	Training Loss: 0.117322638630867
Test Loss:  0.15852680802345276
Valid Loss:  0.15061235427856445
Epoch:  115  	Training Loss: 0.11728036403656006
Test Loss:  0.1584722101688385
Valid Loss:  0.15055984258651733
Epoch:  116  	Training Loss: 0.11723809689283371
Test Loss:  0.15841761231422424
Valid Loss:  0.1505073606967926
Epoch:  117  	Training Loss: 0.11719584465026855
Test Loss:  0.15836307406425476
Valid Loss:  0.15045487880706787
Epoch:  118  	Training Loss: 0.1171535924077034
Test Loss:  0.15830853581428528
Valid Loss:  0.15040242671966553
Epoch:  119  	Training Loss: 0.11711136996746063
Test Loss:  0.15825410187244415
Valid Loss:  0.15034997463226318
Epoch:  120  	Training Loss: 0.11706914007663727
Test Loss:  0.15819963812828064
Valid Loss:  0.15029753744602203
Epoch:  121  	Training Loss: 0.11702693998813629
Test Loss:  0.1581452190876007
Valid Loss:  0.15024513006210327
Epoch:  122  	Training Loss: 0.11698475480079651
Test Loss:  0.15809263288974762
Valid Loss:  0.150194451212883
Epoch:  123  	Training Loss: 0.11694397032260895
Test Loss:  0.15804006159305573
Valid Loss:  0.1501438021659851
Epoch:  124  	Training Loss: 0.11690323054790497
Test Loss:  0.1579875349998474
Valid Loss:  0.150093212723732
Epoch:  125  	Training Loss: 0.11686256527900696
Test Loss:  0.15793508291244507
Valid Loss:  0.15004266798496246
Epoch:  126  	Training Loss: 0.11682196706533432
Test Loss:  0.1578826755285263
Valid Loss:  0.1499921679496765
Epoch:  127  	Training Loss: 0.11678142845630646
Test Loss:  0.15783029794692993
Valid Loss:  0.14994169771671295
Epoch:  128  	Training Loss: 0.11674090474843979
Test Loss:  0.15777796506881714
Valid Loss:  0.14989125728607178
Epoch:  129  	Training Loss: 0.1167004182934761
Test Loss:  0.15772566199302673
Valid Loss:  0.149840846657753
Epoch:  130  	Training Loss: 0.11665995419025421
Test Loss:  0.15767335891723633
Valid Loss:  0.1497904658317566
Epoch:  131  	Training Loss: 0.11661950498819351
Test Loss:  0.1576211154460907
Valid Loss:  0.14974012970924377
Epoch:  132  	Training Loss: 0.1165791004896164
Test Loss:  0.15756697952747345
Valid Loss:  0.1496880054473877
Epoch:  133  	Training Loss: 0.1165371835231781
Test Loss:  0.1575128734111786
Valid Loss:  0.1496359407901764
Epoch:  134  	Training Loss: 0.1164952963590622
Test Loss:  0.15745876729488373
Valid Loss:  0.1495838761329651
Epoch:  135  	Training Loss: 0.11645341664552689
Test Loss:  0.15740469098091125
Valid Loss:  0.14953184127807617
Epoch:  136  	Training Loss: 0.11641156673431396
Test Loss:  0.15735065937042236
Valid Loss:  0.14947983622550964
Epoch:  137  	Training Loss: 0.11636974662542343
Test Loss:  0.15729664266109467
Valid Loss:  0.1494278460741043
Epoch:  138  	Training Loss: 0.1163279265165329
Test Loss:  0.15724265575408936
Valid Loss:  0.14937587082386017
Epoch:  139  	Training Loss: 0.11628613620996475
Test Loss:  0.15718874335289001
Valid Loss:  0.1493239402770996
Epoch:  140  	Training Loss: 0.1162443682551384
Test Loss:  0.15713486075401306
Valid Loss:  0.14927202463150024
Epoch:  141  	Training Loss: 0.11620262265205383
Test Loss:  0.1570810228586197
Valid Loss:  0.14922012388706207
Epoch:  142  	Training Loss: 0.11616088449954987
Test Loss:  0.15702742338180542
Valid Loss:  0.1491684764623642
Epoch:  143  	Training Loss: 0.11611934751272202
Test Loss:  0.15697383880615234
Valid Loss:  0.1491168588399887
Epoch:  144  	Training Loss: 0.11607782542705536
Test Loss:  0.15692028403282166
Valid Loss:  0.14906524121761322
Epoch:  145  	Training Loss: 0.1160363107919693
Test Loss:  0.15686672925949097
Valid Loss:  0.14901363849639893
Epoch:  146  	Training Loss: 0.11599482595920563
Test Loss:  0.15681320428848267
Valid Loss:  0.14896206557750702
 29%|██▉       | 147/500 [01:44<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:44<02:00,  2.92it/s] 30%|███       | 151/500 [01:50<06:52,  1.18s/it] 31%|███       | 153/500 [01:50<04:54,  1.18it/s] 31%|███       | 155/500 [01:51<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:51<02:34,  2.23it/s] 32%|███▏      | 159/500 [01:51<01:53,  2.99it/s] 32%|███▏      | 161/500 [01:57<06:43,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:49,  1.16it/s] 33%|███▎      | 165/500 [01:58<03:27,  1.61it/s] 33%|███▎      | 167/500 [01:58<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:58<01:52,  2.95it/s] 34%|███▍      | 171/500 [02:04<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:04<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:05<03:25,  1.58it/s] 35%|███▌      | 177/500 [02:05<02:31,  2.14it/s] 36%|███▌      | 179/500 [02:05<01:52,  2.86it/s] 36%|███▌      | 181/500 [02:11<06:23,  1.20s/it] 37%|███▋      | 183/500 [02:11<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:11<03:16,  1.60it/s] 37%|███▋      | 187/500 [02:12<02:22,  2.19it/s] 38%|███▊      | 189/500 [02:12<01:45,  2.94it/s] 38%|███▊      | 191/500 [02:18<06:12,  1.20s/it] 39%|███▊      | 193/500 [02:18<04:27,  1.15it/s] 39%|███▉      | 195/500 [02:19<03:12,  1.59it/s] 39%|███▉      | 197/500 [02:19<02:19,  2.17it/s] 40%|███▉      | 199/500 [02:19<01:43,  2.92it/s] 40%|████      | 201/500 [02:25<05:57,  1.20s/it] 41%|████      | 203/500 [02:25<04:15,  1.16it/s] 41%|████      | 205/500 [02:25<03:03,  1.61it/s] 41%|████▏     | 207/500 [02:26<02:13,  2.20it/s] 42%|████▏     | 209/500 [02:26<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:32<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:32<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:32<02:57,  1.61it/s] 43%|████▎     | 217/500 [02:33<02:09,  2.19it/s]Epoch:  147  	Training Loss: 0.11595334112644196
Test Loss:  0.15675969421863556
Valid Loss:  0.1489105224609375
Epoch:  148  	Training Loss: 0.11591187864542007
Test Loss:  0.15670621395111084
Valid Loss:  0.1488589644432068
Epoch:  149  	Training Loss: 0.11587043106555939
Test Loss:  0.15665274858474731
Valid Loss:  0.14880746603012085
Epoch:  150  	Training Loss: 0.1158289983868599
Test Loss:  0.15659929811954498
Valid Loss:  0.14875595271587372
Epoch:  151  	Training Loss: 0.1157875806093216
Test Loss:  0.15654587745666504
Valid Loss:  0.14870446920394897
Epoch:  152  	Training Loss: 0.11574618518352509
Test Loss:  0.1564924418926239
Valid Loss:  0.14865300059318542
Epoch:  153  	Training Loss: 0.11570477485656738
Test Loss:  0.15643905103206635
Valid Loss:  0.14860156178474426
Epoch:  154  	Training Loss: 0.11566339433193207
Test Loss:  0.1563856601715088
Valid Loss:  0.1485501378774643
Epoch:  155  	Training Loss: 0.11562202870845795
Test Loss:  0.15633229911327362
Valid Loss:  0.1484987437725067
Epoch:  156  	Training Loss: 0.11558067798614502
Test Loss:  0.15627896785736084
Valid Loss:  0.14844733476638794
Epoch:  157  	Training Loss: 0.11553935706615448
Test Loss:  0.15622565150260925
Valid Loss:  0.14839598536491394
Epoch:  158  	Training Loss: 0.11549805104732513
Test Loss:  0.15617235004901886
Valid Loss:  0.14834466576576233
Epoch:  159  	Training Loss: 0.11545675247907639
Test Loss:  0.15611907839775085
Valid Loss:  0.14829334616661072
Epoch:  160  	Training Loss: 0.11541546881198883
Test Loss:  0.15606583654880524
Valid Loss:  0.1482420265674591
Epoch:  161  	Training Loss: 0.11537420749664307
Test Loss:  0.15601259469985962
Valid Loss:  0.14819076657295227
Epoch:  162  	Training Loss: 0.11533297598361969
Test Loss:  0.15595923364162445
Valid Loss:  0.14813938736915588
Epoch:  163  	Training Loss: 0.11529159545898438
Test Loss:  0.1559058576822281
Valid Loss:  0.14808803796768188
Epoch:  164  	Training Loss: 0.11525023728609085
Test Loss:  0.1558525413274765
Valid Loss:  0.14803670346736908
Epoch:  165  	Training Loss: 0.11520890891551971
Test Loss:  0.15579929947853088
Valid Loss:  0.14798538386821747
Epoch:  166  	Training Loss: 0.11516758799552917
Test Loss:  0.15574607253074646
Valid Loss:  0.14793410897254944
Epoch:  167  	Training Loss: 0.11512628197669983
Test Loss:  0.15569286048412323
Valid Loss:  0.1478828340768814
Epoch:  168  	Training Loss: 0.11508500576019287
Test Loss:  0.1556396782398224
Valid Loss:  0.14783160388469696
Epoch:  169  	Training Loss: 0.1150437593460083
Test Loss:  0.15558654069900513
Valid Loss:  0.1477803885936737
Epoch:  170  	Training Loss: 0.11500254273414612
Test Loss:  0.15553343296051025
Valid Loss:  0.14772920310497284
Epoch:  171  	Training Loss: 0.11496135592460632
Test Loss:  0.15548035502433777
Valid Loss:  0.14767804741859436
Epoch:  172  	Training Loss: 0.11492019891738892
Test Loss:  0.15542644262313843
Valid Loss:  0.1476261466741562
Epoch:  173  	Training Loss: 0.11487840116024017
Test Loss:  0.15537256002426147
Valid Loss:  0.1475742608308792
Epoch:  174  	Training Loss: 0.11483661830425262
Test Loss:  0.1553187370300293
Valid Loss:  0.14752238988876343
Epoch:  175  	Training Loss: 0.11479484289884567
Test Loss:  0.15526491403579712
Valid Loss:  0.14747054874897003
Epoch:  176  	Training Loss: 0.1147531121969223
Test Loss:  0.15521109104156494
Valid Loss:  0.14741873741149902
Epoch:  177  	Training Loss: 0.11471138894557953
Test Loss:  0.15515731275081635
Valid Loss:  0.1473669409751892
Epoch:  178  	Training Loss: 0.11466968804597855
Test Loss:  0.15510356426239014
Valid Loss:  0.14731517434120178
Epoch:  179  	Training Loss: 0.11462803184986115
Test Loss:  0.15504983067512512
Valid Loss:  0.14726343750953674
Epoch:  180  	Training Loss: 0.11458639055490494
Test Loss:  0.1549961417913437
Valid Loss:  0.1472117006778717
Epoch:  181  	Training Loss: 0.11454477161169052
Test Loss:  0.15494251251220703
Valid Loss:  0.14716002345085144
Epoch:  182  	Training Loss: 0.1145031675696373
Test Loss:  0.1548902988433838
Valid Loss:  0.14710962772369385
Epoch:  183  	Training Loss: 0.11446265876293182
Test Loss:  0.15483808517456055
Valid Loss:  0.14705927670001984
Epoch:  184  	Training Loss: 0.11442215740680695
Test Loss:  0.15478593111038208
Valid Loss:  0.1470089554786682
Epoch:  185  	Training Loss: 0.11438171565532684
Test Loss:  0.1547337770462036
Valid Loss:  0.14695866405963898
Epoch:  186  	Training Loss: 0.11434128880500793
Test Loss:  0.15468166768550873
Valid Loss:  0.14690840244293213
Epoch:  187  	Training Loss: 0.11430089175701141
Test Loss:  0.15462958812713623
Valid Loss:  0.14685818552970886
Epoch:  188  	Training Loss: 0.11426050961017609
Test Loss:  0.15457750856876373
Valid Loss:  0.1468079537153244
Epoch:  189  	Training Loss: 0.11422015726566315
Test Loss:  0.154525488615036
Valid Loss:  0.14675776660442352
Epoch:  190  	Training Loss: 0.1141798198223114
Test Loss:  0.1544734537601471
Valid Loss:  0.14670762419700623
Epoch:  191  	Training Loss: 0.11413951963186264
Test Loss:  0.15442149341106415
Valid Loss:  0.14665746688842773
Epoch:  192  	Training Loss: 0.11409925669431686
Test Loss:  0.1543692648410797
Valid Loss:  0.14660713076591492
Epoch:  193  	Training Loss: 0.11405879259109497
Test Loss:  0.15431708097457886
Valid Loss:  0.1465568244457245
Epoch:  194  	Training Loss: 0.11401837319135666
Test Loss:  0.1542649120092392
Valid Loss:  0.14650651812553406
Epoch:  195  	Training Loss: 0.11397796869277954
Test Loss:  0.15421277284622192
Valid Loss:  0.1464562714099884
Epoch:  196  	Training Loss: 0.11393760144710541
Test Loss:  0.15416067838668823
Valid Loss:  0.14640602469444275
Epoch:  197  	Training Loss: 0.11389724910259247
Test Loss:  0.15410861372947693
Valid Loss:  0.14635582268238068
Epoch:  198  	Training Loss: 0.11385691165924072
Test Loss:  0.15405654907226562
Valid Loss:  0.1463056355714798
Epoch:  199  	Training Loss: 0.11381661891937256
Test Loss:  0.1540045440196991
Valid Loss:  0.1462554782629013
Epoch:  200  	Training Loss: 0.1137763261795044
Test Loss:  0.15395253896713257
Valid Loss:  0.1462053656578064
Epoch:  201  	Training Loss: 0.11373606324195862
Test Loss:  0.15390056371688843
Valid Loss:  0.1461552530527115
Epoch:  202  	Training Loss: 0.11369581520557404
Test Loss:  0.1538466215133667
Valid Loss:  0.14610332250595093
Epoch:  203  	Training Loss: 0.11365401744842529
Test Loss:  0.15379267930984497
Valid Loss:  0.14605143666267395
Epoch:  204  	Training Loss: 0.11361224204301834
Test Loss:  0.15373876690864563
Valid Loss:  0.14599955081939697
Epoch:  205  	Training Loss: 0.11357046663761139
Test Loss:  0.1536848545074463
Valid Loss:  0.1459476500749588
Epoch:  206  	Training Loss: 0.11352870613336563
Test Loss:  0.15363095700740814
Valid Loss:  0.14589577913284302
Epoch:  207  	Training Loss: 0.11348695307970047
Test Loss:  0.15357705950737
Valid Loss:  0.14584390819072723
Epoch:  208  	Training Loss: 0.1134452149271965
Test Loss:  0.15352317690849304
Valid Loss:  0.14579206705093384
Epoch:  209  	Training Loss: 0.11340347677469254
Test Loss:  0.1534692943096161
Valid Loss:  0.14574021100997925
Epoch:  210  	Training Loss: 0.11336176842451096
Test Loss:  0.1534154713153839
Valid Loss:  0.14568838477134705
Epoch:  211  	Training Loss: 0.11332006752490997
Test Loss:  0.15336163341999054
Valid Loss:  0.1456366330385208
Epoch:  212  	Training Loss: 0.11327838152647018
Test Loss:  0.15331000089645386
Valid Loss:  0.14558693766593933
Epoch:  213  	Training Loss: 0.11323842406272888
Test Loss:  0.15325841307640076
Valid Loss:  0.14553727209568024
Epoch:  214  	Training Loss: 0.11319849640130997
Test Loss:  0.15320684015750885
Valid Loss:  0.14548763632774353
Epoch:  215  	Training Loss: 0.11315858364105225
Test Loss:  0.15315529704093933
Valid Loss:  0.1454380303621292
Epoch:  216  	Training Loss: 0.11311869323253632
Test Loss:  0.1531037986278534
Valid Loss:  0.14538845419883728
Epoch:  217  	Training Loss: 0.11307884007692337
Test Loss:  0.15305233001708984
Valid Loss:  0.14533889293670654
Epoch:  218  	Training Loss: 0.11303899437189102
Test Loss:  0.1530008614063263
Valid Loss:  0.1452893614768982
 44%|████▍     | 219/500 [02:33<01:35,  2.95it/s] 44%|████▍     | 221/500 [02:39<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:39<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:39<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:40<01:33,  2.90it/s] 46%|████▌     | 231/500 [02:46<05:21,  1.20s/it] 47%|████▋     | 233/500 [02:46<03:49,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:46<01:59,  2.19it/s] 48%|████▊     | 239/500 [02:47<01:28,  2.94it/s] 48%|████▊     | 241/500 [02:53<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:53<01:55,  2.19it/s] 50%|████▉     | 249/500 [02:53<01:25,  2.95it/s] 50%|█████     | 251/500 [03:00<04:58,  1.20s/it] 51%|█████     | 253/500 [03:00<03:32,  1.16it/s] 51%|█████     | 255/500 [03:00<02:32,  1.61it/s] 51%|█████▏    | 257/500 [03:00<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:00<01:22,  2.94it/s] 52%|█████▏    | 261/500 [03:07<04:45,  1.19s/it] 53%|█████▎    | 263/500 [03:07<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:07<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:07<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:07<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:14<04:33,  1.20s/it] 55%|█████▍    | 273/500 [03:14<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:14<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.21it/s] 56%|█████▌    | 279/500 [03:14<01:14,  2.97it/s] 56%|█████▌    | 281/500 [03:21<04:23,  1.20s/it] 57%|█████▋    | 283/500 [03:21<03:07,  1.16it/s] 57%|█████▋    | 285/500 [03:21<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:21<01:37,  2.18it/s] 58%|█████▊    | 289/500 [03:21<01:11,  2.94it/s]Epoch:  219  	Training Loss: 0.11299917846918106
Test Loss:  0.15294945240020752
Valid Loss:  0.14523988962173462
Epoch:  220  	Training Loss: 0.11295938491821289
Test Loss:  0.15289804339408875
Valid Loss:  0.14519041776657104
Epoch:  221  	Training Loss: 0.11291961371898651
Test Loss:  0.15284669399261475
Valid Loss:  0.14514097571372986
Epoch:  222  	Training Loss: 0.11287986487150192
Test Loss:  0.15279263257980347
Valid Loss:  0.1450890302658081
Epoch:  223  	Training Loss: 0.1128380224108696
Test Loss:  0.15273863077163696
Valid Loss:  0.14503711462020874
Epoch:  224  	Training Loss: 0.11279620230197906
Test Loss:  0.15268461406230927
Valid Loss:  0.14498519897460938
Epoch:  225  	Training Loss: 0.11275438964366913
Test Loss:  0.15263061225414276
Valid Loss:  0.1449333280324936
Epoch:  226  	Training Loss: 0.11271259188652039
Test Loss:  0.15257665514945984
Valid Loss:  0.1448814421892166
Epoch:  227  	Training Loss: 0.11267080157995224
Test Loss:  0.15252268314361572
Valid Loss:  0.14482958614826202
Epoch:  228  	Training Loss: 0.11262902617454529
Test Loss:  0.152468740940094
Valid Loss:  0.14477774500846863
Epoch:  229  	Training Loss: 0.11258726567029953
Test Loss:  0.15241481363773346
Valid Loss:  0.14472590386867523
Epoch:  230  	Training Loss: 0.11254552006721497
Test Loss:  0.15236090123653412
Valid Loss:  0.14467409253120422
Epoch:  231  	Training Loss: 0.1125037744641304
Test Loss:  0.15230700373649597
Valid Loss:  0.1446222960948944
Epoch:  232  	Training Loss: 0.11246205866336823
Test Loss:  0.1522546410560608
Valid Loss:  0.144571915268898
Epoch:  233  	Training Loss: 0.11242152750492096
Test Loss:  0.152202308177948
Valid Loss:  0.1445215791463852
Epoch:  234  	Training Loss: 0.11238102614879608
Test Loss:  0.1521500200033188
Valid Loss:  0.14447128772735596
Epoch:  235  	Training Loss: 0.11234056204557419
Test Loss:  0.15209776163101196
Valid Loss:  0.1444210261106491
Epoch:  236  	Training Loss: 0.11230011284351349
Test Loss:  0.15204554796218872
Valid Loss:  0.14437079429626465
Epoch:  237  	Training Loss: 0.11225969344377518
Test Loss:  0.15199336409568787
Valid Loss:  0.14432060718536377
Epoch:  238  	Training Loss: 0.11221931129693985
Test Loss:  0.1519412100315094
Valid Loss:  0.1442704200744629
Epoch:  239  	Training Loss: 0.11217895895242691
Test Loss:  0.15188907086849213
Valid Loss:  0.1442202925682068
Epoch:  240  	Training Loss: 0.11213862895965576
Test Loss:  0.15183700621128082
Valid Loss:  0.14417019486427307
Epoch:  241  	Training Loss: 0.1120983213186264
Test Loss:  0.1517849564552307
Valid Loss:  0.14412011206150055
Epoch:  242  	Training Loss: 0.11205804347991943
Test Loss:  0.15173129737377167
Valid Loss:  0.14406858384609222
Epoch:  243  	Training Loss: 0.11201651394367218
Test Loss:  0.15167765319347382
Valid Loss:  0.1440170407295227
Epoch:  244  	Training Loss: 0.11197499930858612
Test Loss:  0.15162402391433716
Valid Loss:  0.14396552741527557
Epoch:  245  	Training Loss: 0.11193348467350006
Test Loss:  0.1515704095363617
Valid Loss:  0.14391404390335083
Epoch:  246  	Training Loss: 0.11189199984073639
Test Loss:  0.15151682496070862
Valid Loss:  0.1438625454902649
Epoch:  247  	Training Loss: 0.11185051500797272
Test Loss:  0.15146324038505554
Valid Loss:  0.14381107687950134
Epoch:  248  	Training Loss: 0.11180904507637024
Test Loss:  0.15140967071056366
Valid Loss:  0.143759623169899
Epoch:  249  	Training Loss: 0.11176759004592896
Test Loss:  0.15135616064071655
Valid Loss:  0.14370818436145782
Epoch:  250  	Training Loss: 0.11172616481781006
Test Loss:  0.15130262076854706
Valid Loss:  0.14365677535533905
Epoch:  251  	Training Loss: 0.11168475449085236
Test Loss:  0.15124911069869995
Valid Loss:  0.14360538125038147
Epoch:  252  	Training Loss: 0.11164335906505585
Test Loss:  0.15119701623916626
Valid Loss:  0.14355531334877014
Epoch:  253  	Training Loss: 0.11160305142402649
Test Loss:  0.15114496648311615
Valid Loss:  0.1435053050518036
Epoch:  254  	Training Loss: 0.11156277358531952
Test Loss:  0.15109297633171082
Valid Loss:  0.14345531165599823
Epoch:  255  	Training Loss: 0.11152249574661255
Test Loss:  0.1510409712791443
Valid Loss:  0.14340534806251526
Epoch:  256  	Training Loss: 0.11148226261138916
Test Loss:  0.15098901093006134
Valid Loss:  0.14335539937019348
Epoch:  257  	Training Loss: 0.11144202947616577
Test Loss:  0.15093708038330078
Valid Loss:  0.1433054804801941
Epoch:  258  	Training Loss: 0.11140183359384537
Test Loss:  0.15088516473770142
Valid Loss:  0.1432555764913559
Epoch:  259  	Training Loss: 0.11136165261268616
Test Loss:  0.15083327889442444
Valid Loss:  0.14320571720600128
Epoch:  260  	Training Loss: 0.11132149398326874
Test Loss:  0.15078142285346985
Valid Loss:  0.14315587282180786
Epoch:  261  	Training Loss: 0.11128135025501251
Test Loss:  0.15072959661483765
Valid Loss:  0.14310605823993683
Epoch:  262  	Training Loss: 0.11124123632907867
Test Loss:  0.15067757666110992
Valid Loss:  0.14305606484413147
Epoch:  263  	Training Loss: 0.1112009808421135
Test Loss:  0.15062560141086578
Valid Loss:  0.1430061012506485
Epoch:  264  	Training Loss: 0.11116074025630951
Test Loss:  0.15057362616062164
Valid Loss:  0.14295616745948792
Epoch:  265  	Training Loss: 0.11112052202224731
Test Loss:  0.1505216807126999
Valid Loss:  0.14290623366832733
Epoch:  266  	Training Loss: 0.11108031868934631
Test Loss:  0.15046975016593933
Valid Loss:  0.14285635948181152
Epoch:  267  	Training Loss: 0.1110401302576065
Test Loss:  0.15041786432266235
Valid Loss:  0.14280647039413452
Epoch:  268  	Training Loss: 0.11099998652935028
Test Loss:  0.15036599338054657
Valid Loss:  0.1427566111087799
Epoch:  269  	Training Loss: 0.11095985770225525
Test Loss:  0.15031413733959198
Valid Loss:  0.14270678162574768
Epoch:  270  	Training Loss: 0.1109197586774826
Test Loss:  0.15026231110095978
Valid Loss:  0.14265699684619904
Epoch:  271  	Training Loss: 0.11087968200445175
Test Loss:  0.15021051466464996
Valid Loss:  0.1426072120666504
Epoch:  272  	Training Loss: 0.11083962023258209
Test Loss:  0.1501593440771103
Valid Loss:  0.14255806803703308
Epoch:  273  	Training Loss: 0.11080006510019302
Test Loss:  0.1501082181930542
Valid Loss:  0.14250893890857697
Epoch:  274  	Training Loss: 0.11076052486896515
Test Loss:  0.15005707740783691
Valid Loss:  0.14245980978012085
Epoch:  275  	Training Loss: 0.11072100698947906
Test Loss:  0.1500059962272644
Valid Loss:  0.1424107551574707
Epoch:  276  	Training Loss: 0.11068150401115417
Test Loss:  0.1499549150466919
Valid Loss:  0.14236170053482056
Epoch:  277  	Training Loss: 0.11064202338457108
Test Loss:  0.14990386366844177
Valid Loss:  0.1423126608133316
Epoch:  278  	Training Loss: 0.11060255765914917
Test Loss:  0.14985284209251404
Valid Loss:  0.14226365089416504
Epoch:  279  	Training Loss: 0.11056310683488846
Test Loss:  0.1498018503189087
Valid Loss:  0.14221467077732086
Epoch:  280  	Training Loss: 0.11052369326353073
Test Loss:  0.14975085854530334
Valid Loss:  0.14216569066047668
Epoch:  281  	Training Loss: 0.1104843020439148
Test Loss:  0.14969991147518158
Valid Loss:  0.1421167403459549
Epoch:  282  	Training Loss: 0.11044492572546005
Test Loss:  0.14964662492275238
Valid Loss:  0.14206558465957642
Epoch:  283  	Training Loss: 0.11040372401475906
Test Loss:  0.149593323469162
Valid Loss:  0.14201442897319794
Epoch:  284  	Training Loss: 0.11036252975463867
Test Loss:  0.14954009652137756
Valid Loss:  0.14196328818798065
Epoch:  285  	Training Loss: 0.11032136529684067
Test Loss:  0.14948686957359314
Valid Loss:  0.14191217720508575
Epoch:  286  	Training Loss: 0.11028020828962326
Test Loss:  0.14943364262580872
Valid Loss:  0.14186108112335205
Epoch:  287  	Training Loss: 0.11023908853530884
Test Loss:  0.14938044548034668
Valid Loss:  0.14181001484394073
Epoch:  288  	Training Loss: 0.11019797623157501
Test Loss:  0.14932727813720703
Valid Loss:  0.14175894856452942
Epoch:  289  	Training Loss: 0.11015688627958298
Test Loss:  0.14927414059638977
Valid Loss:  0.14170792698860168
Epoch:  290  	Training Loss: 0.11011581122875214
Test Loss:  0.14922098815441132
Valid Loss:  0.14165693521499634
 58%|█████▊    | 291/500 [03:28<04:13,  1.22s/it] 59%|█████▊    | 293/500 [03:28<03:01,  1.14it/s] 59%|█████▉    | 295/500 [03:28<02:10,  1.57it/s] 59%|█████▉    | 297/500 [03:28<01:35,  2.13it/s] 60%|█████▉    | 299/500 [03:28<01:09,  2.88it/s] 60%|██████    | 301/500 [03:35<03:55,  1.19s/it] 61%|██████    | 303/500 [03:35<02:47,  1.18it/s] 61%|██████    | 305/500 [03:35<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:35<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:35<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:42<03:47,  1.20s/it] 63%|██████▎   | 313/500 [03:42<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:42<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:42<01:24,  2.18it/s] 64%|██████▍   | 319/500 [03:42<01:01,  2.93it/s] 64%|██████▍   | 321/500 [03:49<03:37,  1.22s/it] 65%|██████▍   | 323/500 [03:49<02:34,  1.15it/s] 65%|██████▌   | 325/500 [03:49<01:50,  1.58it/s] 65%|██████▌   | 327/500 [03:49<01:20,  2.15it/s] 66%|██████▌   | 329/500 [03:49<00:59,  2.90it/s] 66%|██████▌   | 331/500 [03:56<03:24,  1.21s/it] 67%|██████▋   | 333/500 [03:56<02:24,  1.15it/s] 67%|██████▋   | 335/500 [03:56<01:43,  1.59it/s] 67%|██████▋   | 337/500 [03:56<01:14,  2.18it/s] 68%|██████▊   | 339/500 [03:56<00:54,  2.93it/s] 68%|██████▊   | 341/500 [04:03<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:03<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:03<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:03<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:03<00:51,  2.96it/s] 70%|███████   | 351/500 [04:10<02:56,  1.19s/it] 71%|███████   | 353/500 [04:10<02:06,  1.17it/s] 71%|███████   | 355/500 [04:10<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:10<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:10<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:16<02:44,  1.18s/it]Epoch:  291  	Training Loss: 0.11007475852966309
Test Loss:  0.14916789531707764
Valid Loss:  0.1416059136390686
Epoch:  292  	Training Loss: 0.11003372073173523
Test Loss:  0.14911526441574097
Valid Loss:  0.14155539870262146
Epoch:  293  	Training Loss: 0.10999304056167603
Test Loss:  0.1490626484155655
Valid Loss:  0.1415048986673355
Epoch:  294  	Training Loss: 0.10995239019393921
Test Loss:  0.14901003241539001
Valid Loss:  0.14145439863204956
Epoch:  295  	Training Loss: 0.10991175472736359
Test Loss:  0.14895746111869812
Valid Loss:  0.1414039433002472
Epoch:  296  	Training Loss: 0.10987113416194916
Test Loss:  0.14890490472316742
Valid Loss:  0.14135350286960602
Epoch:  297  	Training Loss: 0.10983052104711533
Test Loss:  0.1488523781299591
Valid Loss:  0.14130307734012604
Epoch:  298  	Training Loss: 0.10978993773460388
Test Loss:  0.148799866437912
Valid Loss:  0.14125269651412964
Epoch:  299  	Training Loss: 0.10974937677383423
Test Loss:  0.14874738454818726
Valid Loss:  0.14120230078697205
Epoch:  300  	Training Loss: 0.10970880836248398
Test Loss:  0.14869490265846252
Valid Loss:  0.14115193486213684
Epoch:  301  	Training Loss: 0.10966826975345612
Test Loss:  0.148642435669899
Valid Loss:  0.14110159873962402
Epoch:  302  	Training Loss: 0.10962775349617004
Test Loss:  0.14859038591384888
Valid Loss:  0.14105162024497986
Epoch:  303  	Training Loss: 0.10958754271268845
Test Loss:  0.14853835105895996
Valid Loss:  0.1410016417503357
Epoch:  304  	Training Loss: 0.10954734683036804
Test Loss:  0.14848633110523224
Valid Loss:  0.14095169305801392
Epoch:  305  	Training Loss: 0.10950716584920883
Test Loss:  0.1484343260526657
Valid Loss:  0.14090177416801453
Epoch:  306  	Training Loss: 0.10946701467037201
Test Loss:  0.14838235080242157
Valid Loss:  0.14085187017917633
Epoch:  307  	Training Loss: 0.10942687094211578
Test Loss:  0.14833040535449982
Valid Loss:  0.14080199599266052
Epoch:  308  	Training Loss: 0.10938674211502075
Test Loss:  0.14827847480773926
Valid Loss:  0.1407521367073059
Epoch:  309  	Training Loss: 0.10934664309024811
Test Loss:  0.1482265293598175
Valid Loss:  0.1407022923231125
Epoch:  310  	Training Loss: 0.10930655151605606
Test Loss:  0.14817465841770172
Valid Loss:  0.14065247774124146
Epoch:  311  	Training Loss: 0.1092664822936058
Test Loss:  0.14812278747558594
Valid Loss:  0.140602707862854
Epoch:  312  	Training Loss: 0.10922643542289734
Test Loss:  0.14806917309761047
Valid Loss:  0.14055128395557404
Epoch:  313  	Training Loss: 0.10918502509593964
Test Loss:  0.1480155885219574
Valid Loss:  0.14049986004829407
Epoch:  314  	Training Loss: 0.10914362221956253
Test Loss:  0.14796201884746552
Valid Loss:  0.14044848084449768
Epoch:  315  	Training Loss: 0.10910223424434662
Test Loss:  0.14790844917297363
Valid Loss:  0.1403971016407013
Epoch:  316  	Training Loss: 0.1090608686208725
Test Loss:  0.14785492420196533
Valid Loss:  0.1403457522392273
Epoch:  317  	Training Loss: 0.10901950299739838
Test Loss:  0.14780139923095703
Valid Loss:  0.1402944028377533
Epoch:  318  	Training Loss: 0.10897816717624664
Test Loss:  0.14774790406227112
Valid Loss:  0.14024308323860168
Epoch:  319  	Training Loss: 0.1089368462562561
Test Loss:  0.1476944088935852
Valid Loss:  0.14019176363945007
Epoch:  320  	Training Loss: 0.10889551788568497
Test Loss:  0.14764092862606049
Valid Loss:  0.14014050364494324
Epoch:  321  	Training Loss: 0.10885421931743622
Test Loss:  0.14758747816085815
Valid Loss:  0.140089213848114
Epoch:  322  	Training Loss: 0.10881293565034866
Test Loss:  0.14753594994544983
Valid Loss:  0.14003974199295044
Epoch:  323  	Training Loss: 0.10877316445112228
Test Loss:  0.1474844515323639
Valid Loss:  0.13999029994010925
Epoch:  324  	Training Loss: 0.10873343050479889
Test Loss:  0.14743301272392273
Valid Loss:  0.13994085788726807
Epoch:  325  	Training Loss: 0.10869370400905609
Test Loss:  0.14738154411315918
Valid Loss:  0.13989147543907166
Epoch:  326  	Training Loss: 0.10865400731563568
Test Loss:  0.1473301649093628
Valid Loss:  0.13984212279319763
Epoch:  327  	Training Loss: 0.10861434042453766
Test Loss:  0.1472787857055664
Valid Loss:  0.139792799949646
Epoch:  328  	Training Loss: 0.10857469588518143
Test Loss:  0.1472274363040924
Valid Loss:  0.13974350690841675
Epoch:  329  	Training Loss: 0.10853506624698639
Test Loss:  0.14717614650726318
Valid Loss:  0.1396942436695099
Epoch:  330  	Training Loss: 0.10849548876285553
Test Loss:  0.14712485671043396
Valid Loss:  0.13964498043060303
Epoch:  331  	Training Loss: 0.10845591127872467
Test Loss:  0.14707361161708832
Valid Loss:  0.13959577679634094
Epoch:  332  	Training Loss: 0.1084163710474968
Test Loss:  0.14702239632606506
Valid Loss:  0.13954663276672363
Epoch:  333  	Training Loss: 0.10837684571743011
Test Loss:  0.146971195936203
Valid Loss:  0.13949748873710632
Epoch:  334  	Training Loss: 0.10833734273910522
Test Loss:  0.14692002534866333
Valid Loss:  0.139448344707489
Epoch:  335  	Training Loss: 0.10829787701368332
Test Loss:  0.14686889946460724
Valid Loss:  0.13939929008483887
Epoch:  336  	Training Loss: 0.1082584410905838
Test Loss:  0.14681783318519592
Valid Loss:  0.13935023546218872
Epoch:  337  	Training Loss: 0.10821903496980667
Test Loss:  0.1467667669057846
Valid Loss:  0.13930121064186096
Epoch:  338  	Training Loss: 0.10817962884902954
Test Loss:  0.1467157006263733
Valid Loss:  0.1392521858215332
Epoch:  339  	Training Loss: 0.1081402525305748
Test Loss:  0.14666470885276794
Valid Loss:  0.13920319080352783
Epoch:  340  	Training Loss: 0.10810089111328125
Test Loss:  0.1466137170791626
Valid Loss:  0.13915422558784485
Epoch:  341  	Training Loss: 0.10806156694889069
Test Loss:  0.14656275510787964
Valid Loss:  0.13910529017448425
Epoch:  342  	Training Loss: 0.10802224278450012
Test Loss:  0.14651057124137878
Valid Loss:  0.13905522227287292
Epoch:  343  	Training Loss: 0.10798195749521255
Test Loss:  0.14645838737487793
Valid Loss:  0.1390051543712616
Epoch:  344  	Training Loss: 0.10794169455766678
Test Loss:  0.14640623331069946
Valid Loss:  0.13895514607429504
Epoch:  345  	Training Loss: 0.1079014390707016
Test Loss:  0.14635410904884338
Valid Loss:  0.1389051377773285
Epoch:  346  	Training Loss: 0.10786120593547821
Test Loss:  0.1463019996881485
Valid Loss:  0.13885512948036194
Epoch:  347  	Training Loss: 0.10782100260257721
Test Loss:  0.146249920129776
Valid Loss:  0.13880519568920135
Epoch:  348  	Training Loss: 0.107780821621418
Test Loss:  0.1461978703737259
Valid Loss:  0.13875526189804077
Epoch:  349  	Training Loss: 0.10774065554141998
Test Loss:  0.14614583551883698
Valid Loss:  0.1387053281068802
Epoch:  350  	Training Loss: 0.10770049691200256
Test Loss:  0.14609381556510925
Valid Loss:  0.13865545392036438
Epoch:  351  	Training Loss: 0.10766039788722992
Test Loss:  0.1460418403148651
Valid Loss:  0.13860559463500977
Epoch:  352  	Training Loss: 0.10762028396129608
Test Loss:  0.14598959684371948
Valid Loss:  0.13855548202991486
Epoch:  353  	Training Loss: 0.10757997632026672
Test Loss:  0.14593736827373505
Valid Loss:  0.13850539922714233
Epoch:  354  	Training Loss: 0.10753968358039856
Test Loss:  0.145885169506073
Valid Loss:  0.1384553462266922
Epoch:  355  	Training Loss: 0.10749941319227219
Test Loss:  0.14583300054073334
Valid Loss:  0.13840532302856445
Epoch:  356  	Training Loss: 0.1074591651558876
Test Loss:  0.14578086137771606
Valid Loss:  0.1383553147315979
Epoch:  357  	Training Loss: 0.10741893947124481
Test Loss:  0.14572873711585999
Valid Loss:  0.13830533623695374
Epoch:  358  	Training Loss: 0.10737873613834381
Test Loss:  0.1456766426563263
Valid Loss:  0.13825537264347076
Epoch:  359  	Training Loss: 0.107338547706604
Test Loss:  0.1456245481967926
Valid Loss:  0.13820543885231018
Epoch:  360  	Training Loss: 0.10729837417602539
Test Loss:  0.1455724984407425
Valid Loss:  0.1381555199623108
Epoch:  361  	Training Loss: 0.10725823044776917
Test Loss:  0.14552044868469238
Valid Loss:  0.1381056010723114
Epoch:  362  	Training Loss: 0.10721809417009354
Test Loss:  0.14546839892864227
Valid Loss:  0.1380557119846344
Epoch:  363  	Training Loss: 0.10717795789241791
 73%|███████▎  | 363/500 [04:17<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:17<01:23,  1.63it/s] 73%|███████▎  | 367/500 [04:17<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:17<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:23<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:23<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:24<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:24<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:24<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:30<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:30<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:30<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:31<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:31<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:37<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:37<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:37<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:37<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:38<00:33,  2.97it/s] 80%|████████  | 401/500 [04:44<02:01,  1.23s/it] 81%|████████  | 403/500 [04:44<01:25,  1.13it/s] 81%|████████  | 405/500 [04:45<01:00,  1.56it/s] 81%|████████▏ | 407/500 [04:45<00:43,  2.14it/s] 82%|████████▏ | 409/500 [04:45<00:31,  2.88it/s] 82%|████████▏ | 411/500 [04:51<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:51<01:15,  1.16it/s] 83%|████████▎ | 415/500 [04:52<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.18it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.94it/s] 84%|████████▍ | 421/500 [04:58<01:34,  1.20s/it] 85%|████████▍ | 423/500 [04:58<01:06,  1.16it/s] 85%|████████▌ | 425/500 [04:58<00:46,  1.61it/s] 85%|████████▌ | 427/500 [04:59<00:33,  2.20it/s] 86%|████████▌ | 429/500 [04:59<00:23,  2.96it/s] 86%|████████▌ | 431/500 [05:05<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:05<00:56,  1.18it/s]Test Loss:  0.14541634917259216
Valid Loss:  0.1380058228969574
Epoch:  364  	Training Loss: 0.10713781416416168
Test Loss:  0.14536434412002563
Valid Loss:  0.1379559338092804
Epoch:  365  	Training Loss: 0.10709771513938904
Test Loss:  0.1453123390674591
Valid Loss:  0.13790607452392578
Epoch:  366  	Training Loss: 0.1070576161146164
Test Loss:  0.14526036381721497
Valid Loss:  0.13785624504089355
Epoch:  367  	Training Loss: 0.10701753199100494
Test Loss:  0.1452084183692932
Valid Loss:  0.13780643045902252
Epoch:  368  	Training Loss: 0.10697746276855469
Test Loss:  0.14515647292137146
Valid Loss:  0.13775664567947388
Epoch:  369  	Training Loss: 0.10693743824958801
Test Loss:  0.14510458707809448
Valid Loss:  0.13770687580108643
Epoch:  370  	Training Loss: 0.10689741373062134
Test Loss:  0.1450527012348175
Valid Loss:  0.13765713572502136
Epoch:  371  	Training Loss: 0.10685741156339645
Test Loss:  0.14500084519386292
Valid Loss:  0.1376074254512787
Epoch:  372  	Training Loss: 0.10681742429733276
Test Loss:  0.1449500322341919
Valid Loss:  0.13755866885185242
Epoch:  373  	Training Loss: 0.10677824169397354
Test Loss:  0.14489921927452087
Valid Loss:  0.13750997185707092
Epoch:  374  	Training Loss: 0.1067390888929367
Test Loss:  0.14484846591949463
Valid Loss:  0.13746127486228943
Epoch:  375  	Training Loss: 0.10669995844364166
Test Loss:  0.14479771256446838
Valid Loss:  0.13741260766983032
Epoch:  376  	Training Loss: 0.10666084289550781
Test Loss:  0.14474701881408691
Valid Loss:  0.13736394047737122
Epoch:  377  	Training Loss: 0.10662176460027695
Test Loss:  0.14469632506370544
Valid Loss:  0.13731536269187927
Epoch:  378  	Training Loss: 0.10658270120620728
Test Loss:  0.14464569091796875
Valid Loss:  0.13726675510406494
Epoch:  379  	Training Loss: 0.1065436601638794
Test Loss:  0.14459508657455444
Valid Loss:  0.137218177318573
Epoch:  380  	Training Loss: 0.1065046489238739
Test Loss:  0.14454451203346252
Valid Loss:  0.13716967403888702
Epoch:  381  	Training Loss: 0.1064656600356102
Test Loss:  0.1444939374923706
Valid Loss:  0.13712114095687866
Epoch:  382  	Training Loss: 0.10642668604850769
Test Loss:  0.14444297552108765
Valid Loss:  0.13707229495048523
Epoch:  383  	Training Loss: 0.10638739913702011
Test Loss:  0.14439205825328827
Valid Loss:  0.1370234489440918
Epoch:  384  	Training Loss: 0.10634812712669373
Test Loss:  0.1443411409854889
Valid Loss:  0.13697464764118195
Epoch:  385  	Training Loss: 0.10630887746810913
Test Loss:  0.1442902535200119
Valid Loss:  0.1369258612394333
Epoch:  386  	Training Loss: 0.10626965761184692
Test Loss:  0.1442394107580185
Valid Loss:  0.13687710464000702
Epoch:  387  	Training Loss: 0.10623045265674591
Test Loss:  0.1441885530948639
Valid Loss:  0.13682836294174194
Epoch:  388  	Training Loss: 0.10619127005338669
Test Loss:  0.14413774013519287
Valid Loss:  0.13677962124347687
Epoch:  389  	Training Loss: 0.10615209490060806
Test Loss:  0.14408695697784424
Valid Loss:  0.13673093914985657
Epoch:  390  	Training Loss: 0.10611295700073242
Test Loss:  0.144036203622818
Valid Loss:  0.13668227195739746
Epoch:  391  	Training Loss: 0.10607382655143738
Test Loss:  0.14398546516895294
Valid Loss:  0.13663360476493835
Epoch:  392  	Training Loss: 0.10603472590446472
Test Loss:  0.14393390715122223
Valid Loss:  0.13658419251441956
Epoch:  393  	Training Loss: 0.10599496960639954
Test Loss:  0.14388233423233032
Valid Loss:  0.13653478026390076
Epoch:  394  	Training Loss: 0.10595524311065674
Test Loss:  0.14383083581924438
Valid Loss:  0.13648539781570435
Epoch:  395  	Training Loss: 0.10591552406549454
Test Loss:  0.14377932250499725
Valid Loss:  0.13643604516983032
Epoch:  396  	Training Loss: 0.10587583482265472
Test Loss:  0.1437278389930725
Valid Loss:  0.1363866925239563
Epoch:  397  	Training Loss: 0.10583615303039551
Test Loss:  0.14367637038230896
Valid Loss:  0.13633738458156586
Epoch:  398  	Training Loss: 0.10579647868871689
Test Loss:  0.1436249315738678
Valid Loss:  0.13628806173801422
Epoch:  399  	Training Loss: 0.10575683414936066
Test Loss:  0.14357352256774902
Valid Loss:  0.13623878359794617
Epoch:  400  	Training Loss: 0.10571719706058502
Test Loss:  0.14352211356163025
Valid Loss:  0.1361895203590393
Epoch:  401  	Training Loss: 0.10567758977413177
Test Loss:  0.14347070455551147
Valid Loss:  0.13614027202129364
Epoch:  402  	Training Loss: 0.10563799738883972
Test Loss:  0.14341744780540466
Valid Loss:  0.1360892355442047
Epoch:  403  	Training Loss: 0.10559691488742828
Test Loss:  0.14336417615413666
Valid Loss:  0.13603821396827698
Epoch:  404  	Training Loss: 0.10555586963891983
Test Loss:  0.14331094920635223
Valid Loss:  0.13598722219467163
Epoch:  405  	Training Loss: 0.10551483184099197
Test Loss:  0.1432577222585678
Valid Loss:  0.13593624532222748
Epoch:  406  	Training Loss: 0.10547380149364471
Test Loss:  0.14320451021194458
Valid Loss:  0.13588526844978333
Epoch:  407  	Training Loss: 0.10543277859687805
Test Loss:  0.14315129816532135
Valid Loss:  0.13583429157733917
Epoch:  408  	Training Loss: 0.10539177805185318
Test Loss:  0.1430981457233429
Valid Loss:  0.1357833594083786
Epoch:  409  	Training Loss: 0.1053507924079895
Test Loss:  0.14304496347904205
Valid Loss:  0.13573242723941803
Epoch:  410  	Training Loss: 0.10530982166528702
Test Loss:  0.1429918259382248
Valid Loss:  0.13568152487277985
Epoch:  411  	Training Loss: 0.10526886582374573
Test Loss:  0.14293870329856873
Valid Loss:  0.13563062250614166
Epoch:  412  	Training Loss: 0.10522790253162384
Test Loss:  0.14288747310638428
Valid Loss:  0.13558152318000793
Epoch:  413  	Training Loss: 0.10518844425678253
Test Loss:  0.14283625781536102
Valid Loss:  0.13553248345851898
Epoch:  414  	Training Loss: 0.10514900088310242
Test Loss:  0.14278508722782135
Valid Loss:  0.13548342883586884
Epoch:  415  	Training Loss: 0.1051095724105835
Test Loss:  0.14273390173912048
Valid Loss:  0.13543441891670227
Epoch:  416  	Training Loss: 0.10507014393806458
Test Loss:  0.1426827609539032
Valid Loss:  0.1353853940963745
Epoch:  417  	Training Loss: 0.10503076016902924
Test Loss:  0.1426316499710083
Valid Loss:  0.13533642888069153
Epoch:  418  	Training Loss: 0.1049913763999939
Test Loss:  0.1425805389881134
Valid Loss:  0.13528744876384735
Epoch:  419  	Training Loss: 0.10495200753211975
Test Loss:  0.1425294578075409
Valid Loss:  0.13523849844932556
Epoch:  420  	Training Loss: 0.1049126610159874
Test Loss:  0.14247839152812958
Valid Loss:  0.13518956303596497
Epoch:  421  	Training Loss: 0.10487332195043564
Test Loss:  0.14242735505104065
Valid Loss:  0.13514067232608795
Epoch:  422  	Training Loss: 0.10483400523662567
Test Loss:  0.14237569272518158
Valid Loss:  0.13509118556976318
Epoch:  423  	Training Loss: 0.1047942191362381
Test Loss:  0.1423240453004837
Valid Loss:  0.13504168391227722
Epoch:  424  	Training Loss: 0.10475444793701172
Test Loss:  0.1422724425792694
Valid Loss:  0.13499224185943604
Epoch:  425  	Training Loss: 0.10471469163894653
Test Loss:  0.14222083985805511
Valid Loss:  0.13494277000427246
Epoch:  426  	Training Loss: 0.10467495024204254
Test Loss:  0.1421692669391632
Valid Loss:  0.13489337265491486
Epoch:  427  	Training Loss: 0.10463523119688034
Test Loss:  0.1421177238225937
Valid Loss:  0.13484399020671844
Epoch:  428  	Training Loss: 0.10459552705287933
Test Loss:  0.14206619560718536
Valid Loss:  0.13479462265968323
Epoch:  429  	Training Loss: 0.10455584526062012
Test Loss:  0.14201469719409943
Valid Loss:  0.13474524021148682
Epoch:  430  	Training Loss: 0.1045161783695221
Test Loss:  0.14196321368217468
Valid Loss:  0.13469593226909637
Epoch:  431  	Training Loss: 0.10447654128074646
Test Loss:  0.14191177487373352
Valid Loss:  0.13464662432670593
Epoch:  432  	Training Loss: 0.10443691164255142
Test Loss:  0.14185845851898193
Valid Loss:  0.13459555804729462
Epoch:  433  	Training Loss: 0.10439584404230118
Test Loss:  0.14180517196655273
Valid Loss:  0.13454453647136688
Epoch:  434  	Training Loss: 0.10435479879379272
Test Loss:  0.14175188541412354
Valid Loss:  0.13449352979660034
Epoch:  435  	Training Loss: 0.10431375354528427
Test Loss:  0.14169862866401672 87%|████████▋ | 435/500 [05:05<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:05<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:06<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:12<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:12<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:12<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:12<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:12<00:17,  2.90it/s] 90%|█████████ | 451/500 [05:19<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:19<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:19<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:19<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:26<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:26<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:33<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:33<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:33<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:39<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:40<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:46<00:10,  1.19s/it] 98%|█████████▊| 492/500 [05:46<00:07,  1.00it/s] 99%|█████████▉| 494/500 [05:47<00:04,  1.44it/s] 99%|█████████▉| 496/500 [05:47<00:01,  2.01it/s]100%|█████████▉| 498/500 [05:47<00:00,  2.77it/s]100%|██████████| 500/500 [05:47<00:00,  3.71it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]

Valid Loss:  0.1344425231218338
Epoch:  436  	Training Loss: 0.10427272319793701
Test Loss:  0.1416454017162323
Valid Loss:  0.13439154624938965
Epoch:  437  	Training Loss: 0.10423172265291214
Test Loss:  0.14159217476844788
Valid Loss:  0.1343405544757843
Epoch:  438  	Training Loss: 0.10419072955846786
Test Loss:  0.14153897762298584
Valid Loss:  0.13428962230682373
Epoch:  439  	Training Loss: 0.10414975136518478
Test Loss:  0.141485795378685
Valid Loss:  0.13423867523670197
Epoch:  440  	Training Loss: 0.1041087955236435
Test Loss:  0.14143262803554535
Valid Loss:  0.13418777287006378
Epoch:  441  	Training Loss: 0.1040678471326828
Test Loss:  0.14137950539588928
Valid Loss:  0.1341368705034256
Epoch:  442  	Training Loss: 0.1040269136428833
Test Loss:  0.14132550358772278
Valid Loss:  0.13408517837524414
Epoch:  443  	Training Loss: 0.10398534685373306
Test Loss:  0.14127153158187866
Valid Loss:  0.13403350114822388
Epoch:  444  	Training Loss: 0.10394378006458282
Test Loss:  0.14121757447719574
Valid Loss:  0.133981853723526
Epoch:  445  	Training Loss: 0.10390223562717438
Test Loss:  0.141163632273674
Valid Loss:  0.13393017649650574
Epoch:  446  	Training Loss: 0.10386070609092712
Test Loss:  0.14110969007015228
Valid Loss:  0.13387855887413025
Epoch:  447  	Training Loss: 0.10381917655467987
Test Loss:  0.14105579257011414
Valid Loss:  0.13382692635059357
Epoch:  448  	Training Loss: 0.10377766191959381
Test Loss:  0.1410018801689148
Valid Loss:  0.13377529382705688
Epoch:  449  	Training Loss: 0.10373616218566895
Test Loss:  0.14094798266887665
Valid Loss:  0.13372372090816498
Epoch:  450  	Training Loss: 0.10369467735290527
Test Loss:  0.1408941149711609
Valid Loss:  0.13367213308811188
Epoch:  451  	Training Loss: 0.1036532074213028
Test Loss:  0.14084023237228394
Valid Loss:  0.13362054526805878
Epoch:  452  	Training Loss: 0.10361173748970032
Test Loss:  0.14079047739505768
Valid Loss:  0.13357284665107727
Epoch:  453  	Training Loss: 0.10357345640659332
Test Loss:  0.1407407820224762
Valid Loss:  0.13352520763874054
Epoch:  454  	Training Loss: 0.10353520512580872
Test Loss:  0.1406911015510559
Valid Loss:  0.1334775686264038
Epoch:  455  	Training Loss: 0.1034969836473465
Test Loss:  0.14064143598079681
Valid Loss:  0.13342998921871185
Epoch:  456  	Training Loss: 0.10345879197120667
Test Loss:  0.1405918300151825
Valid Loss:  0.1333824098110199
Epoch:  457  	Training Loss: 0.10342061519622803
Test Loss:  0.14054225385189056
Valid Loss:  0.13333489000797272
Epoch:  458  	Training Loss: 0.10338246077299118
Test Loss:  0.14049270749092102
Valid Loss:  0.13328737020492554
Epoch:  459  	Training Loss: 0.10334433615207672
Test Loss:  0.14044316112995148
Valid Loss:  0.13323992490768433
Epoch:  460  	Training Loss: 0.10330624133348465
Test Loss:  0.1403936892747879
Valid Loss:  0.13319247961044312
Epoch:  461  	Training Loss: 0.10326817631721497
Test Loss:  0.14034423232078552
Valid Loss:  0.1331450641155243
Epoch:  462  	Training Loss: 0.10323013365268707
Test Loss:  0.14029139280319214
Valid Loss:  0.13309447467327118
Epoch:  463  	Training Loss: 0.10318946838378906
Test Loss:  0.14023858308792114
Valid Loss:  0.13304392993450165
Epoch:  464  	Training Loss: 0.10314883291721344
Test Loss:  0.14018580317497253
Valid Loss:  0.13299337029457092
Epoch:  465  	Training Loss: 0.10310821235179901
Test Loss:  0.14013302326202393
Valid Loss:  0.13294288516044617
Epoch:  466  	Training Loss: 0.10306760668754578
Test Loss:  0.1400802731513977
Valid Loss:  0.13289235532283783
Epoch:  467  	Training Loss: 0.10302701592445374
Test Loss:  0.14002756774425507
Valid Loss:  0.13284189999103546
Epoch:  468  	Training Loss: 0.10298644006252289
Test Loss:  0.13997486233711243
Valid Loss:  0.1327914446592331
Epoch:  469  	Training Loss: 0.10294588655233383
Test Loss:  0.13992217183113098
Valid Loss:  0.13274100422859192
Epoch:  470  	Training Loss: 0.10290534794330597
Test Loss:  0.13986951112747192
Valid Loss:  0.13269057869911194
Epoch:  471  	Training Loss: 0.1028648242354393
Test Loss:  0.13981685042381287
Valid Loss:  0.13264018297195435
Epoch:  472  	Training Loss: 0.10282431542873383
Test Loss:  0.13976597785949707
Valid Loss:  0.13259145617485046
Epoch:  473  	Training Loss: 0.10278517752885818
Test Loss:  0.13971510529518127
Valid Loss:  0.13254274427890778
Epoch:  474  	Training Loss: 0.10274606198072433
Test Loss:  0.13966429233551025
Valid Loss:  0.13249406218528748
Epoch:  475  	Training Loss: 0.10270695388317108
Test Loss:  0.13961350917816162
Valid Loss:  0.13244542479515076
Epoch:  476  	Training Loss: 0.10266788303852081
Test Loss:  0.139562726020813
Valid Loss:  0.13239680230617523
Epoch:  477  	Training Loss: 0.10262884199619293
Test Loss:  0.13951195776462555
Valid Loss:  0.1323481798171997
Epoch:  478  	Training Loss: 0.10258980095386505
Test Loss:  0.1394612193107605
Valid Loss:  0.13229960203170776
Epoch:  479  	Training Loss: 0.10255078226327896
Test Loss:  0.13941051065921783
Valid Loss:  0.13225102424621582
Epoch:  480  	Training Loss: 0.10251177847385406
Test Loss:  0.13935983180999756
Valid Loss:  0.13220250606536865
Epoch:  481  	Training Loss: 0.10247281193733215
Test Loss:  0.13930916786193848
Valid Loss:  0.13215398788452148
Epoch:  482  	Training Loss: 0.10243386030197144
Test Loss:  0.1392585039138794
Valid Loss:  0.13210543990135193
Epoch:  483  	Training Loss: 0.10239489376544952
Test Loss:  0.13920781016349792
Valid Loss:  0.13205695152282715
Epoch:  484  	Training Loss: 0.1023559421300888
Test Loss:  0.13915720582008362
Valid Loss:  0.13200844824314117
Epoch:  485  	Training Loss: 0.10231700539588928
Test Loss:  0.13910657167434692
Valid Loss:  0.1319599747657776
Epoch:  486  	Training Loss: 0.10227809846401215
Test Loss:  0.1390559822320938
Valid Loss:  0.1319115310907364
Epoch:  487  	Training Loss: 0.1022391989827156
Test Loss:  0.1390054076910019
Valid Loss:  0.13186310231685638
Epoch:  488  	Training Loss: 0.10220032930374146
Test Loss:  0.13895487785339355
Valid Loss:  0.13181470334529877
Epoch:  489  	Training Loss: 0.1021614819765091
Test Loss:  0.13890434801578522
Valid Loss:  0.13176631927490234
Epoch:  490  	Training Loss: 0.10212264209985733
Test Loss:  0.13885387778282166
Valid Loss:  0.1317179799079895
Epoch:  491  	Training Loss: 0.10208383202552795
Test Loss:  0.1388033926486969
Valid Loss:  0.13166964054107666
Epoch:  492  	Training Loss: 0.10204504430294037
Test Loss:  0.1387520283460617
Valid Loss:  0.13162046670913696
Epoch:  493  	Training Loss: 0.10200555622577667
Test Loss:  0.1387006938457489
Valid Loss:  0.13157133758068085
Epoch:  494  	Training Loss: 0.10196608304977417
Test Loss:  0.13864940404891968
Valid Loss:  0.13152220845222473
Epoch:  495  	Training Loss: 0.10192663967609406
Test Loss:  0.13859809935092926
Valid Loss:  0.1314730942249298
Epoch:  496  	Training Loss: 0.10188721865415573
Test Loss:  0.13854685425758362
Valid Loss:  0.13142403960227966
Epoch:  497  	Training Loss: 0.1018478125333786
Test Loss:  0.13849562406539917
Valid Loss:  0.13137498497962952
Epoch:  498  	Training Loss: 0.10180842876434326
Test Loss:  0.13844440877437592
Valid Loss:  0.13132598996162415
Epoch:  499  	Training Loss: 0.10176907479763031
Test Loss:  0.13839323818683624
Valid Loss:  0.13127699494361877
Epoch:  500  	Training Loss: 0.10172975063323975
Test Loss:  0.13834209740161896
Valid Loss:  0.1312280148267746
seed is  15
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:56,  6.36s/it]  1%|          | 3/500 [00:06<14:06,  1.70s/it]  1%|          | 5/500 [00:06<07:06,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.85it/s]  2%|▏         | 11/500 [00:13<11:06,  1.36s/it]  3%|▎         | 13/500 [00:13<07:34,  1.07it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:44,  1.22s/it]  5%|▍         | 23/500 [00:20<06:54,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:27<09:30,  1.22s/it]  7%|▋         | 33/500 [00:27<06:46,  1.15it/s]  7%|▋         | 35/500 [00:27<04:52,  1.59it/s]  7%|▋         | 37/500 [00:27<03:33,  2.17it/s]  8%|▊         | 39/500 [00:27<02:37,  2.92it/s]  8%|▊         | 41/500 [00:34<09:06,  1.19s/it]  9%|▊         | 43/500 [00:34<06:31,  1.17it/s]  9%|▉         | 45/500 [00:40<11:49,  1.56s/it]  9%|▉         | 47/500 [00:40<08:24,  1.11s/it] 10%|▉         | 49/500 [00:41<06:00,  1.25it/s] 10%|█         | 51/500 [00:47<11:25,  1.53s/it] 11%|█         | 53/500 [00:47<08:08,  1.09s/it] 11%|█         | 55/500 [00:47<05:51,  1.27it/s] 11%|█▏        | 57/500 [00:48<04:16,  1.73it/s] 12%|█▏        | 59/500 [00:48<03:08,  2.34it/s] 12%|█▏        | 61/500 [00:54<09:11,  1.26s/it] 13%|█▎        | 63/500 [00:54<06:33,  1.11it/s] 13%|█▎        | 65/500 [00:54<04:42,  1.54it/s] 13%|█▎        | 67/500 [00:54<03:25,  2.10it/s] 14%|█▍        | 69/500 [00:55<02:31,  2.84it/s] 14%|█▍        | 71/500 [01:01<08:34,  1.20s/it]Epoch:  1  	Training Loss: 0.09472019225358963
Test Loss:  18.699527740478516
Valid Loss:  18.144197463989258
Epoch:  2  	Training Loss: 18.562936782836914
Test Loss:  4302.6005859375
Valid Loss:  4075.226318359375
Epoch:  3  	Training Loss: 4655.05859375
Test Loss:  0.59763503074646
Valid Loss:  0.5559396743774414
Epoch:  4  	Training Loss: 0.783194899559021
Test Loss:  0.5540404319763184
Valid Loss:  0.5180451273918152
Epoch:  5  	Training Loss: 0.7363480925559998
Test Loss:  0.5176633596420288
Valid Loss:  0.4868447184562683
Epoch:  6  	Training Loss: 0.6952120065689087
Test Loss:  0.5117249488830566
Valid Loss:  0.4781992435455322
Epoch:  7  	Training Loss: 0.6821572780609131
Test Loss:  0.5117251873016357
Valid Loss:  0.4780769348144531
Epoch:  8  	Training Loss: 0.6814203858375549
Test Loss:  0.5117478370666504
Valid Loss:  0.47807613015174866
Epoch:  9  	Training Loss: 0.6813841462135315
Test Loss:  0.5117794871330261
Valid Loss:  0.47804903984069824
Epoch:  10  	Training Loss: 0.681288480758667
Test Loss:  0.511641800403595
Valid Loss:  0.47763675451278687
Epoch:  11  	Training Loss: 0.6807161569595337
Test Loss:  0.397797554731369
Valid Loss:  0.3959397077560425
Epoch:  12  	Training Loss: 0.5867688655853271
Test Loss:  346.6543884277344
Valid Loss:  334.67327880859375
Epoch:  13  	Training Loss: 334.4894104003906
Test Loss:  0.028250427916646004
Valid Loss:  0.03602074831724167
Epoch:  14  	Training Loss: 0.044869374483823776
Test Loss:  0.0282660573720932
Valid Loss:  0.036037854850292206
Epoch:  15  	Training Loss: 0.044071100652217865
Test Loss:  0.028285034000873566
Valid Loss:  0.03605867177248001
Epoch:  16  	Training Loss: 0.042654745280742645
Test Loss:  0.028311610221862793
Valid Loss:  0.03487476706504822
Epoch:  17  	Training Loss: 0.04012730345129967
Test Loss:  0.028338421136140823
Valid Loss:  0.03370783105492592
Epoch:  18  	Training Loss: 0.037792738527059555
Test Loss:  0.0283633042126894
Valid Loss:  0.03291568160057068
Epoch:  19  	Training Loss: 0.035908814519643784
Test Loss:  0.028031840920448303
Valid Loss:  0.03256341814994812
Epoch:  20  	Training Loss: 0.03519799932837486
Test Loss:  0.02781023271381855
Valid Loss:  0.0324125662446022
Epoch:  21  	Training Loss: 0.03493916988372803
Test Loss:  0.027631759643554688
Valid Loss:  0.03231196478009224
Epoch:  22  	Training Loss: 0.034735120832920074
Test Loss:  4.6732177734375
Valid Loss:  4.574950218200684
Epoch:  23  	Training Loss: 4.099810600280762
Test Loss:  1.8930145502090454
Valid Loss:  2.0990524291992188
Epoch:  24  	Training Loss: 1.4667012691497803
Test Loss:  0.2921397089958191
Valid Loss:  0.32193583250045776
Epoch:  25  	Training Loss: 0.24250391125679016
Test Loss:  0.05046013742685318
Valid Loss:  0.05668479949235916
Epoch:  26  	Training Loss: 0.052709680050611496
Test Loss:  0.015515006147325039
Valid Loss:  0.01955810934305191
Epoch:  27  	Training Loss: 0.023252245038747787
Test Loss:  0.011097757145762444
Valid Loss:  0.015383257530629635
Epoch:  28  	Training Loss: 0.018676485866308212
Test Loss:  0.010808052495121956
Valid Loss:  0.015359664335846901
Epoch:  29  	Training Loss: 0.01796378754079342
Test Loss:  0.010918148793280125
Valid Loss:  0.01560064684599638
Epoch:  30  	Training Loss: 0.017850976437330246
Test Loss:  0.0109953498467803
Valid Loss:  0.01573302410542965
Epoch:  31  	Training Loss: 0.017831385135650635
Test Loss:  0.011030001565814018
Valid Loss:  0.015789542347192764
Epoch:  32  	Training Loss: 0.017826272174715996
Test Loss:  0.011042147874832153
Valid Loss:  0.015810994431376457
Epoch:  33  	Training Loss: 0.01724228821694851
Test Loss:  0.011046531610190868
Valid Loss:  0.01581975445151329
Epoch:  34  	Training Loss: 0.017238780856132507
Test Loss:  0.011047356761991978
Valid Loss:  0.01582285761833191
Epoch:  35  	Training Loss: 0.01723531261086464
Test Loss:  0.011046767234802246
Valid Loss:  0.01582374982535839
Epoch:  36  	Training Loss: 0.017231866717338562
Test Loss:  0.011045627295970917
Valid Loss:  0.01582374796271324
Epoch:  37  	Training Loss: 0.017228426411747932
Test Loss:  0.01104426383972168
Valid Loss:  0.015823397785425186
Epoch:  38  	Training Loss: 0.0172249935567379
Test Loss:  0.011042815633118153
Valid Loss:  0.015822917222976685
Epoch:  39  	Training Loss: 0.017221571877598763
Test Loss:  0.011041339486837387
Valid Loss:  0.015822388231754303
Epoch:  40  	Training Loss: 0.01721815951168537
Test Loss:  0.011039845645427704
Valid Loss:  0.015821831300854683
Epoch:  41  	Training Loss: 0.01721474900841713
Test Loss:  0.01103835366666317
Valid Loss:  0.01582125760614872
Epoch:  42  	Training Loss: 0.017211347818374634
Test Loss:  0.01824164018034935
Valid Loss:  0.022823940962553024
Epoch:  43  	Training Loss: 0.019614877179265022
Test Loss:  0.011641568504273891
Valid Loss:  0.016648367047309875
Epoch:  44  	Training Loss: 0.016791822388768196
Test Loss:  0.01778005063533783
Valid Loss:  0.022402547299861908
Epoch:  45  	Training Loss: 0.019302092492580414
Test Loss:  0.011712532490491867
Valid Loss:  0.016783833503723145
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.017048154026269913
Test Loss:  0.011701268143951893
Valid Loss:  0.016781724989414215
Epoch:  47  	Training Loss: 0.017040032893419266
Test Loss:  0.01169511303305626
Valid Loss:  0.016780655831098557
Epoch:  48  	Training Loss: 0.017032941803336143
Test Loss:  0.011691614054143429
Valid Loss:  0.01678009331226349
Epoch:  49  	Training Loss: 0.017026199027895927
Test Loss:  0.01168946735560894
Valid Loss:  0.016779780387878418
Epoch:  50  	Training Loss: 0.017019614577293396
Test Loss:  0.011688049882650375
Valid Loss:  0.016779590398073196
Epoch:  51  	Training Loss: 0.017013143748044968
Test Loss:  0.011686988174915314
Valid Loss:  0.016779456287622452
Epoch:  52  	Training Loss: 0.017006773501634598
Test Loss:  0.011255169287323952
Valid Loss:  0.016203582286834717
Epoch:  53  	Training Loss: 0.016550909727811813
Test Loss:  0.010988743975758553
Valid Loss:  0.01585359126329422
Epoch:  54  	Training Loss: 0.016463525593280792
Test Loss:  0.010827411897480488
Valid Loss:  0.015635229647159576
Epoch:  55  	Training Loss: 0.016420502215623856
Test Loss:  0.010726732201874256
Valid Loss:  0.015495257452130318
Epoch:  56  	Training Loss: 0.01639893278479576
Test Loss:  0.01066216267645359
Valid Loss:  0.015403419733047485
Epoch:  57  	Training Loss: 0.01638779789209366
Test Loss:  0.010619748383760452
Valid Loss:  0.01534193754196167
Epoch:  58  	Training Loss: 0.01638171263039112
Test Loss:  0.010591287165880203
Valid Loss:  0.015300092287361622
Epoch:  59  	Training Loss: 0.016378100961446762
Test Loss:  0.01057184487581253
Valid Loss:  0.015271179378032684
Epoch:  60  	Training Loss: 0.016375701874494553
Test Loss:  0.01055833138525486
Valid Loss:  0.015250912867486477
Epoch:  61  	Training Loss: 0.0163738951086998
Test Loss:  0.01054878905415535
Valid Loss:  0.015236514620482922
Epoch:  62  	Training Loss: 0.01637238636612892
Test Loss:  0.010542590171098709
Valid Loss:  0.015227042138576508
Epoch:  63  	Training Loss: 0.01636672206223011
Test Loss:  0.010538047179579735
Valid Loss:  0.015220442786812782
Epoch:  64  	Training Loss: 0.01636127382516861
Test Loss:  0.010534662753343582
Valid Loss:  0.015215793624520302
Epoch:  65  	Training Loss: 0.016356004402041435
Test Loss:  0.01053213607519865
Valid Loss:  0.01521250233054161
Epoch:  66  	Training Loss: 0.0163508839905262
Test Loss:  0.010530208237469196
Valid Loss:  0.01521017774939537
Epoch:  67  	Training Loss: 0.016345905140042305
Test Loss:  0.010528694838285446
Valid Loss:  0.015208510681986809
Epoch:  68  	Training Loss: 0.016341058537364006
Test Loss:  0.010527477599680424
Valid Loss:  0.015207295306026936
Epoch:  69  	Training Loss: 0.016336340457201004
Test Loss:  0.010526479221880436
Valid Loss:  0.015206403099000454
Epoch:  70  	Training Loss: 0.016331426799297333
Test Loss:  0.010525605641305447
Valid Loss:  0.01520572043955326
Epoch:  71  	Training Loss: 0.016325347125530243
Test Loss:  0.010524760000407696
Valid Loss:  0.015205174684524536
 15%|█▍        | 73/500 [01:01<06:06,  1.16it/s] 15%|█▌        | 75/500 [01:01<04:23,  1.61it/s] 15%|█▌        | 77/500 [01:01<03:12,  2.20it/s] 16%|█▌        | 79/500 [01:01<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:08<08:14,  1.18s/it] 17%|█▋        | 83/500 [01:08<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:08<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:08<03:06,  2.22it/s] 18%|█▊        | 89/500 [01:08<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:15<08:08,  1.19s/it] 19%|█▊        | 93/500 [01:15<05:49,  1.17it/s] 19%|█▉        | 95/500 [01:15<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:15<03:02,  2.20it/s] 20%|█▉        | 99/500 [01:15<02:15,  2.96it/s] 20%|██        | 101/500 [01:22<07:55,  1.19s/it] 21%|██        | 103/500 [01:22<05:39,  1.17it/s] 21%|██        | 105/500 [01:22<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:22<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:22<02:11,  2.96it/s] 22%|██▏       | 111/500 [01:29<07:42,  1.19s/it] 23%|██▎       | 113/500 [01:29<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:29<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:29<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:29<02:10,  2.91it/s] 24%|██▍       | 121/500 [01:35<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:36<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:36<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:36<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:36<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:42<07:25,  1.21s/it] 27%|██▋       | 133/500 [01:43<05:18,  1.15it/s] 27%|██▋       | 135/500 [01:43<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:43<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:43<02:04,  2.91it/s] 28%|██▊       | 141/500 [01:49<07:08,  1.19s/it]Epoch:  72  	Training Loss: 0.016319412738084793
Test Loss:  0.010523409582674503
Valid Loss:  0.015204368159174919
Epoch:  73  	Training Loss: 0.01631239615380764
Test Loss:  0.010521713644266129
Valid Loss:  0.015203002840280533
Epoch:  74  	Training Loss: 0.01630544662475586
Test Loss:  0.010519743897020817
Valid Loss:  0.015201197937130928
Epoch:  75  	Training Loss: 0.016298530623316765
Test Loss:  0.01051756925880909
Valid Loss:  0.015199068933725357
Epoch:  76  	Training Loss: 0.016291681677103043
Test Loss:  0.010515228845179081
Valid Loss:  0.01519668661057949
Epoch:  77  	Training Loss: 0.01628487929701805
Test Loss:  0.010512761771678925
Valid Loss:  0.015194115228950977
Epoch:  78  	Training Loss: 0.016278130933642387
Test Loss:  0.010510217398405075
Valid Loss:  0.01519138552248478
Epoch:  79  	Training Loss: 0.01627144031226635
Test Loss:  0.010507583618164062
Valid Loss:  0.015188544988632202
Epoch:  80  	Training Loss: 0.016264792531728745
Test Loss:  0.010504908859729767
Valid Loss:  0.01518561877310276
Epoch:  81  	Training Loss: 0.01625819504261017
Test Loss:  0.010502185672521591
Valid Loss:  0.01518261805176735
Epoch:  82  	Training Loss: 0.016251644119620323
Test Loss:  0.009673689492046833
Valid Loss:  0.013041665777564049
Epoch:  83  	Training Loss: 0.01339198462665081
Test Loss:  0.009665777906775475
Valid Loss:  0.013039411045610905
Epoch:  84  	Training Loss: 0.013391394168138504
Test Loss:  0.00966506078839302
Valid Loss:  0.013038424775004387
Epoch:  85  	Training Loss: 0.013390861451625824
Test Loss:  0.009664308279752731
Valid Loss:  0.01303743477910757
Epoch:  86  	Training Loss: 0.013390325009822845
Test Loss:  0.009663552977144718
Valid Loss:  0.01303644198924303
Epoch:  87  	Training Loss: 0.013389790430665016
Test Loss:  0.00966279860585928
Valid Loss:  0.01303545106202364
Epoch:  88  	Training Loss: 0.01338926050812006
Test Loss:  0.009662051685154438
Valid Loss:  0.013034455478191376
Epoch:  89  	Training Loss: 0.013388721272349358
Test Loss:  0.009661296382546425
Valid Loss:  0.013033466413617134
Epoch:  90  	Training Loss: 0.013388190418481827
Test Loss:  0.009660543873906136
Valid Loss:  0.013032474555075169
Epoch:  91  	Training Loss: 0.013387655839323997
Test Loss:  0.009659791365265846
Valid Loss:  0.0130314901471138
Epoch:  92  	Training Loss: 0.013387122191488743
Test Loss:  0.009807812049984932
Valid Loss:  0.012965855188667774
Epoch:  93  	Training Loss: 0.012931566685438156
Test Loss:  0.010115589015185833
Valid Loss:  0.012987814843654633
Epoch:  94  	Training Loss: 0.01263374648988247
Test Loss:  0.010368617251515388
Valid Loss:  0.013036951422691345
Epoch:  95  	Training Loss: 0.012419883161783218
Test Loss:  0.010606197640299797
Valid Loss:  0.013100562617182732
Epoch:  96  	Training Loss: 0.012256572023034096
Test Loss:  0.010816446505486965
Valid Loss:  0.013173258863389492
Epoch:  97  	Training Loss: 0.012182488106191158
Test Loss:  0.010960789397358894
Valid Loss:  0.013228155672550201
Epoch:  98  	Training Loss: 0.01214610692113638
Test Loss:  0.011027548462152481
Valid Loss:  0.013276472687721252
Epoch:  99  	Training Loss: 0.01211098674684763
Test Loss:  0.011097023263573647
Valid Loss:  0.013321777805685997
Epoch:  100  	Training Loss: 0.012094386853277683
Test Loss:  0.011142576113343239
Valid Loss:  0.013352730311453342
Epoch:  101  	Training Loss: 0.012086223810911179
Test Loss:  0.011174047365784645
Valid Loss:  0.013374187052249908
Epoch:  102  	Training Loss: 0.0120819341391325
Test Loss:  0.009256204590201378
Valid Loss:  0.011311942711472511
Epoch:  103  	Training Loss: 0.010928274132311344
Test Loss:  0.008049619384109974
Valid Loss:  0.010026074945926666
Epoch:  104  	Training Loss: 0.010242762044072151
Test Loss:  0.007280820980668068
Valid Loss:  0.009215187281370163
Epoch:  105  	Training Loss: 0.009835290722548962
Test Loss:  0.006784203462302685
Valid Loss:  0.008697408251464367
Epoch:  106  	Training Loss: 0.009593091905117035
Test Loss:  0.0064583816565573215
Valid Loss:  0.008361958898603916
Epoch:  107  	Training Loss: 0.009448875673115253
Test Loss:  0.006240869406610727
Valid Loss:  0.00814098585397005
Epoch:  108  	Training Loss: 0.009362837299704552
Test Loss:  0.006093328818678856
Valid Loss:  0.007993118837475777
Epoch:  109  	Training Loss: 0.009311411529779434
Test Loss:  0.0059915510937571526
Valid Loss:  0.007892463356256485
Epoch:  110  	Training Loss: 0.009280530735850334
Test Loss:  0.00592019222676754
Valid Loss:  0.00782278086990118
Epoch:  111  	Training Loss: 0.009261853992938995
Test Loss:  0.005869402550160885
Valid Loss:  0.00777374766767025
Epoch:  112  	Training Loss: 0.009250414557754993
Test Loss:  0.005984747316688299
Valid Loss:  0.006938677281141281
Epoch:  113  	Training Loss: 0.007788102142512798
Test Loss:  0.0052586267702281475
Valid Loss:  0.006284158676862717
Epoch:  114  	Training Loss: 0.007425904273986816
Test Loss:  0.004970552399754524
Valid Loss:  0.0059835766442120075
Epoch:  115  	Training Loss: 0.00720681669190526
Test Loss:  0.004705887753516436
Valid Loss:  0.005756058264523745
Epoch:  116  	Training Loss: 0.0070595587603747845
Test Loss:  0.0045210518874228
Valid Loss:  0.005616937763988972
Epoch:  117  	Training Loss: 0.006965371780097485
Test Loss:  0.0043945275247097015
Valid Loss:  0.005530758760869503
Epoch:  118  	Training Loss: 0.006899969652295113
Test Loss:  0.0043034334667027
Valid Loss:  0.005476871505379677
Epoch:  119  	Training Loss: 0.00685122050344944
Test Loss:  0.004227508790791035
Valid Loss:  0.005434608552604914
Epoch:  120  	Training Loss: 0.006820138543844223
Test Loss:  0.004171618260443211
Valid Loss:  0.005408621393144131
Epoch:  121  	Training Loss: 0.006799632683396339
Test Loss:  0.004127160646021366
Valid Loss:  0.005388776306062937
Epoch:  122  	Training Loss: 0.006785122212022543
Test Loss:  0.004409675486385822
Valid Loss:  0.004661623388528824
Epoch:  123  	Training Loss: 0.00607972452417016
Test Loss:  0.00440613366663456
Valid Loss:  0.004687700420618057
Epoch:  124  	Training Loss: 0.006000763736665249
Test Loss:  0.004474332556128502
Valid Loss:  0.004698318429291248
Epoch:  125  	Training Loss: 0.005966812372207642
Test Loss:  0.004515929147601128
Valid Loss:  0.004710452631115913
Epoch:  126  	Training Loss: 0.005950850434601307
Test Loss:  0.0045462846755981445
Valid Loss:  0.00472018588334322
Epoch:  127  	Training Loss: 0.005943172611296177
Test Loss:  0.004567361436784267
Valid Loss:  0.004727509804069996
Epoch:  128  	Training Loss: 0.005936053581535816
Test Loss:  0.004581499379128218
Valid Loss:  0.004741107113659382
Epoch:  129  	Training Loss: 0.0059271203354001045
Test Loss:  0.004606322385370731
Valid Loss:  0.004750465042889118
Epoch:  130  	Training Loss: 0.005922751501202583
Test Loss:  0.004622090607881546
Valid Loss:  0.004757266025990248
Epoch:  131  	Training Loss: 0.005920437164604664
Test Loss:  0.004633139353245497
Valid Loss:  0.004762042313814163
Epoch:  132  	Training Loss: 0.005919085815548897
Test Loss:  0.003906077705323696
Valid Loss:  0.0042262389324605465
Epoch:  133  	Training Loss: 0.005531431175768375
Test Loss:  0.003508065128698945
Valid Loss:  0.003973029553890228
Epoch:  134  	Training Loss: 0.005342627409845591
Test Loss:  0.003283381462097168
Valid Loss:  0.003854654962196946
Epoch:  135  	Training Loss: 0.005250145215541124
Test Loss:  0.003152335062623024
Valid Loss:  0.0038002096116542816
Epoch:  136  	Training Loss: 0.005204366985708475
Test Loss:  0.003073394764214754
Valid Loss:  0.0037757863756269217
Epoch:  137  	Training Loss: 0.005181263200938702
Test Loss:  0.003024375531822443
Valid Loss:  0.003765240777283907
Epoch:  138  	Training Loss: 0.005169158801436424
Test Loss:  0.0029931014869362116
Valid Loss:  0.003760975319892168
Epoch:  139  	Training Loss: 0.00516241230070591
Test Loss:  0.0029726927168667316
Valid Loss:  0.0037594344466924667
Epoch:  140  	Training Loss: 0.00515827676281333
Test Loss:  0.0029591303318738937
Valid Loss:  0.0037589999847114086
Epoch:  141  	Training Loss: 0.005155420396476984
Test Loss:  0.0029499714728444815
Valid Loss:  0.0037589622661471367
Epoch:  142  	Training Loss: 0.005153205711394548
 29%|██▊       | 143/500 [01:49<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:50<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:50<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:50<01:59,  2.94it/s] 30%|███       | 151/500 [01:56<06:56,  1.19s/it] 31%|███       | 153/500 [01:56<04:56,  1.17it/s] 31%|███       | 155/500 [01:57<03:33,  1.62it/s] 31%|███▏      | 157/500 [01:57<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:57<01:54,  2.97it/s] 32%|███▏      | 161/500 [02:03<06:50,  1.21s/it] 33%|███▎      | 163/500 [02:03<04:52,  1.15it/s] 33%|███▎      | 165/500 [02:04<03:30,  1.59it/s] 33%|███▎      | 167/500 [02:04<02:33,  2.17it/s] 34%|███▍      | 169/500 [02:04<01:55,  2.87it/s] 34%|███▍      | 171/500 [02:10<06:33,  1.20s/it] 35%|███▍      | 173/500 [02:10<04:40,  1.16it/s] 35%|███▌      | 175/500 [02:11<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:11<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:11<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:17<06:24,  1.21s/it] 37%|███▋      | 183/500 [02:17<04:34,  1.16it/s] 37%|███▋      | 185/500 [02:18<03:18,  1.59it/s] 37%|███▋      | 187/500 [02:18<02:25,  2.15it/s] 38%|███▊      | 189/500 [02:18<01:48,  2.87it/s] 38%|███▊      | 191/500 [02:24<06:12,  1.21s/it] 39%|███▊      | 193/500 [02:24<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:25<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:25<02:19,  2.18it/s] 40%|███▉      | 199/500 [02:25<01:42,  2.93it/s] 40%|████      | 201/500 [02:31<06:02,  1.21s/it] 41%|████      | 203/500 [02:31<04:17,  1.15it/s] 41%|████      | 205/500 [02:32<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:32<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:32<01:39,  2.93it/s]Test Loss:  0.0029437271878123283
Valid Loss:  0.003759214887395501
Epoch:  143  	Training Loss: 0.005152455531060696
Test Loss:  0.002939426340162754
Valid Loss:  0.0037594044115394354
Epoch:  144  	Training Loss: 0.005151849240064621
Test Loss:  0.0029364372603595257
Valid Loss:  0.0037595017347484827
Epoch:  145  	Training Loss: 0.005151312332600355
Test Loss:  0.0029343427158892155
Valid Loss:  0.0037595191970467567
Epoch:  146  	Training Loss: 0.0051508136093616486
Test Loss:  0.0029328654054552317
Valid Loss:  0.0037594649475067854
Epoch:  147  	Training Loss: 0.0051503367722034454
Test Loss:  0.002931807655841112
Valid Loss:  0.0037593499291688204
Epoch:  148  	Training Loss: 0.005149860866367817
Test Loss:  0.0029310474637895823
Valid Loss:  0.003759198822081089
Epoch:  149  	Training Loss: 0.00514939334243536
Test Loss:  0.002930490765720606
Valid Loss:  0.003759016515687108
Epoch:  150  	Training Loss: 0.005148924887180328
Test Loss:  0.00293007236905396
Valid Loss:  0.0037588151171803474
Epoch:  151  	Training Loss: 0.00514846108853817
Test Loss:  0.0029297582805156708
Valid Loss:  0.0037585929967463017
Epoch:  152  	Training Loss: 0.005147992633283138
Test Loss:  0.003177266800776124
Valid Loss:  0.00315973162651062
Epoch:  153  	Training Loss: 0.00472092442214489
Test Loss:  0.0031756041571497917
Valid Loss:  0.003186431247740984
Epoch:  154  	Training Loss: 0.004674234893172979
Test Loss:  0.003219809615984559
Valid Loss:  0.0031886575743556023
Epoch:  155  	Training Loss: 0.004645213950425386
Test Loss:  0.003246183041483164
Valid Loss:  0.0032100481912493706
Epoch:  156  	Training Loss: 0.004607670474797487
Test Loss:  0.0032858126796782017
Valid Loss:  0.0032213523518294096
Epoch:  157  	Training Loss: 0.004589274525642395
Test Loss:  0.003312910906970501
Valid Loss:  0.0032315035350620747
Epoch:  158  	Training Loss: 0.004578125197440386
Test Loss:  0.003332288470119238
Valid Loss:  0.003248758614063263
Epoch:  159  	Training Loss: 0.004565010312944651
Test Loss:  0.0033567682839930058
Valid Loss:  0.003259509103372693
Epoch:  160  	Training Loss: 0.004557423293590546
Test Loss:  0.0033734163735061884
Valid Loss:  0.0032779905013740063
Epoch:  161  	Training Loss: 0.00454644113779068
Test Loss:  0.003396069398149848
Valid Loss:  0.0032899195794016123
Epoch:  162  	Training Loss: 0.004538232460618019
Test Loss:  0.0033961294684559107
Valid Loss:  0.0032899288926273584
Epoch:  163  	Training Loss: 0.004534084815531969
Test Loss:  0.003396187908947468
Valid Loss:  0.0032899430952966213
Epoch:  164  	Training Loss: 0.004530085250735283
Test Loss:  0.0033962433226406574
Valid Loss:  0.003289949381724
Epoch:  165  	Training Loss: 0.004526226781308651
Test Loss:  0.0033962917514145374
Valid Loss:  0.0032899626530706882
Epoch:  166  	Training Loss: 0.004522507544606924
Test Loss:  0.003396347165107727
Valid Loss:  0.003289968241006136
Epoch:  167  	Training Loss: 0.00451892102137208
Test Loss:  0.0033964035101234913
Valid Loss:  0.003289977088570595
Epoch:  168  	Training Loss: 0.004515461623668671
Test Loss:  0.003396454732865095
Valid Loss:  0.0032899873331189156
Epoch:  169  	Training Loss: 0.004512127488851547
Test Loss:  0.0033965078182518482
Valid Loss:  0.003289997112005949
Epoch:  170  	Training Loss: 0.004508910235017538
Test Loss:  0.003396563930436969
Valid Loss:  0.003290006425231695
Epoch:  171  	Training Loss: 0.004505808465182781
Test Loss:  0.0033966153860092163
Valid Loss:  0.003290010616183281
Epoch:  172  	Training Loss: 0.004502816125750542
Test Loss:  0.003396551590412855
Valid Loss:  0.0033090710639953613
Epoch:  173  	Training Loss: 0.00449520954862237
Test Loss:  0.003396521555259824
Valid Loss:  0.003321919124573469
Epoch:  174  	Training Loss: 0.004491541534662247
Test Loss:  0.0033965040929615498
Valid Loss:  0.003330433275550604
Epoch:  175  	Training Loss: 0.004488540813326836
Test Loss:  0.0033965040929615498
Valid Loss:  0.0033359313383698463
Epoch:  176  	Training Loss: 0.004485529847443104
Test Loss:  0.0033965057227760553
Valid Loss:  0.003339354880154133
Epoch:  177  	Training Loss: 0.004482893273234367
Test Loss:  0.0033965138718485832
Valid Loss:  0.0033414065837860107
Epoch:  178  	Training Loss: 0.004480428993701935
Test Loss:  0.0033965257462114096
Valid Loss:  0.0033425558358430862
Epoch:  179  	Training Loss: 0.004478052258491516
Test Loss:  0.003396542277187109
Valid Loss:  0.0033431185875087976
Epoch:  180  	Training Loss: 0.0044757225550711155
Test Loss:  0.003396559739485383
Valid Loss:  0.0033432936761528254
Epoch:  181  	Training Loss: 0.00447249598801136
Test Loss:  0.0033965797629207373
Valid Loss:  0.0033431584015488625
Epoch:  182  	Training Loss: 0.004466822370886803
Test Loss:  0.0033964733593165874
Valid Loss:  0.0033430035691708326
Epoch:  183  	Training Loss: 0.004464598838239908
Test Loss:  0.003396368585526943
Valid Loss:  0.0033428515307605267
Epoch:  184  	Training Loss: 0.004462447948753834
Test Loss:  0.0033962619490921497
Valid Loss:  0.0033426941372454166
Epoch:  185  	Training Loss: 0.004460365977138281
Test Loss:  0.0033961557783186436
Valid Loss:  0.0033425416331738234
Epoch:  186  	Training Loss: 0.004458354786038399
Test Loss:  0.0033960500732064247
Valid Loss:  0.0033423847053200006
Epoch:  187  	Training Loss: 0.0044564069248735905
Test Loss:  0.00339594017714262
Valid Loss:  0.0033422312699258327
Epoch:  188  	Training Loss: 0.0044545261189341545
Test Loss:  0.003395829815417528
Valid Loss:  0.0033420734107494354
Epoch:  189  	Training Loss: 0.004452701658010483
Test Loss:  0.0033957227133214474
Valid Loss:  0.003341919742524624
Epoch:  190  	Training Loss: 0.004450939130038023
Test Loss:  0.0033956135157495737
Valid Loss:  0.0033417607191950083
Epoch:  191  	Training Loss: 0.0044492315500974655
Test Loss:  0.003395495004951954
Valid Loss:  0.003341604955494404
Epoch:  192  	Training Loss: 0.004447578452527523
Test Loss:  0.002989610191434622
Valid Loss:  0.0031342310830950737
Epoch:  193  	Training Loss: 0.0042441776022315025
Test Loss:  0.0027623004280030727
Valid Loss:  0.0030509920325130224
Epoch:  194  	Training Loss: 0.004142645746469498
Test Loss:  0.0026308749802410603
Valid Loss:  0.003022484015673399
Epoch:  195  	Training Loss: 0.004090648610144854
Test Loss:  0.0025523812510073185
Valid Loss:  0.003016703762114048
Epoch:  196  	Training Loss: 0.004062758758664131
Test Loss:  0.0025040414184331894
Valid Loss:  0.0030192984268069267
Epoch:  197  	Training Loss: 0.004046618938446045
Test Loss:  0.0024734358303248882
Valid Loss:  0.0030241222120821476
Epoch:  198  	Training Loss: 0.004036229103803635
Test Loss:  0.0024535979609936476
Valid Loss:  0.0030287564732134342
Epoch:  199  	Training Loss: 0.004028662573546171
Test Loss:  0.002440493321046233
Valid Loss:  0.003032410517334938
Epoch:  200  	Training Loss: 0.0040220520459115505
Test Loss:  0.002431706991046667
Valid Loss:  0.0030349597800523043
Epoch:  201  	Training Loss: 0.004014694597572088
Test Loss:  0.0024257441982626915
Valid Loss:  0.0030364308040589094
Epoch:  202  	Training Loss: 0.004007748793810606
Test Loss:  0.002421656623482704
Valid Loss:  0.0030368920415639877
Epoch:  203  	Training Loss: 0.00400102324783802
Test Loss:  0.002418837044388056
Valid Loss:  0.003036800306290388
Epoch:  204  	Training Loss: 0.003994462545961142
Test Loss:  0.0024168784730136395
Valid Loss:  0.0030362973921000957
Epoch:  205  	Training Loss: 0.003988019190728664
Test Loss:  0.0024155108258128166
Valid Loss:  0.0030355060007423162
Epoch:  206  	Training Loss: 0.003981677815318108
Test Loss:  0.002414541784673929
Valid Loss:  0.003034513909369707
Epoch:  207  	Training Loss: 0.003975432366132736
Test Loss:  0.002413856564089656
Valid Loss:  0.0030333898030221462
Epoch:  208  	Training Loss: 0.003969274461269379
Test Loss:  0.002413367386907339
Valid Loss:  0.0030321741942316294
Epoch:  209  	Training Loss: 0.00396320503205061
Test Loss:  0.0024130125530064106
Valid Loss:  0.00303090107627213
Epoch:  210  	Training Loss: 0.003957224078476429
Test Loss:  0.0024127506185323
Valid Loss:  0.003029590705409646
Epoch:  211  	Training Loss: 0.003951323218643665
Test Loss:  0.0024125557392835617
Valid Loss:   42%|████▏     | 211/500 [02:38<05:45,  1.20s/it] 43%|████▎     | 213/500 [02:38<04:06,  1.17it/s] 43%|████▎     | 215/500 [02:39<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:39<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:39<01:34,  2.96it/s] 44%|████▍     | 221/500 [02:45<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:45<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:45<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:46<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:46<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:52<05:26,  1.21s/it] 47%|████▋     | 233/500 [02:52<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:53<02:47,  1.58it/s] 47%|████▋     | 237/500 [02:53<02:01,  2.16it/s] 48%|████▊     | 239/500 [02:53<01:29,  2.91it/s] 48%|████▊     | 241/500 [02:59<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:59<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:59<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:00<01:54,  2.20it/s] 50%|████▉     | 249/500 [03:00<01:26,  2.91it/s] 50%|█████     | 251/500 [03:06<04:58,  1.20s/it] 51%|█████     | 253/500 [03:06<03:34,  1.15it/s] 51%|█████     | 255/500 [03:06<02:34,  1.59it/s] 51%|█████▏    | 257/500 [03:07<01:51,  2.17it/s] 52%|█████▏    | 259/500 [03:07<01:22,  2.91it/s] 52%|█████▏    | 261/500 [03:13<04:45,  1.19s/it] 53%|█████▎    | 263/500 [03:13<03:23,  1.17it/s] 53%|█████▎    | 265/500 [03:13<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:13<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:14<01:17,  2.96it/s] 54%|█████▍    | 271/500 [03:20<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:20<03:14,  1.16it/s] 55%|█████▌    | 275/500 [03:20<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:20<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:21<01:14,  2.95it/s]0.0030282565858215094
Epoch:  212  	Training Loss: 0.003945500589907169
Test Loss:  0.0024125692434608936
Valid Loss:  0.003028095467016101
Epoch:  213  	Training Loss: 0.0039441147819161415
Test Loss:  0.0024125815834850073
Valid Loss:  0.003027933882549405
Epoch:  214  	Training Loss: 0.0039387838914990425
Test Loss:  0.0024125988129526377
Valid Loss:  0.003027759725227952
Epoch:  215  	Training Loss: 0.0039297230541706085
Test Loss:  0.0024126172065734863
Valid Loss:  0.0030275932513177395
Epoch:  216  	Training Loss: 0.0039212931878864765
Test Loss:  0.0024126365315169096
Valid Loss:  0.0030274258460849524
Epoch:  217  	Training Loss: 0.003913444466888905
Test Loss:  0.0024126549251377583
Valid Loss:  0.003027253784239292
Epoch:  218  	Training Loss: 0.003906139638274908
Test Loss:  0.0024126707576215267
Valid Loss:  0.003027083817869425
Epoch:  219  	Training Loss: 0.0038993358612060547
Test Loss:  0.002412692178040743
Valid Loss:  0.003026914782822132
Epoch:  220  	Training Loss: 0.003893002402037382
Test Loss:  0.0024127052165567875
Valid Loss:  0.003026748076081276
Epoch:  221  	Training Loss: 0.0038864414673298597
Test Loss:  0.002412722446024418
Valid Loss:  0.0030265753157436848
Epoch:  222  	Training Loss: 0.003873005975037813
Test Loss:  0.0027507003396749496
Valid Loss:  0.0025933333672583103
Epoch:  223  	Training Loss: 0.0035916585475206375
Test Loss:  0.002548778895288706
Valid Loss:  0.002584471832960844
Epoch:  224  	Training Loss: 0.0034946310333907604
Test Loss:  0.0025315454695373774
Valid Loss:  0.0025300162378698587
Epoch:  225  	Training Loss: 0.003420587396249175
Test Loss:  0.0024850727058947086
Valid Loss:  0.0025041145272552967
Epoch:  226  	Training Loss: 0.0033584001939743757
Test Loss:  0.0024549709632992744
Valid Loss:  0.0024823187850415707
Epoch:  227  	Training Loss: 0.0033058193512260914
Test Loss:  0.002428824780508876
Valid Loss:  0.002468569902703166
Epoch:  228  	Training Loss: 0.003261337988078594
Test Loss:  0.0024082022719085217
Valid Loss:  0.0024600715842097998
Epoch:  229  	Training Loss: 0.0032237092964351177
Test Loss:  0.0023916231002658606
Valid Loss:  0.002456048969179392
Epoch:  230  	Training Loss: 0.0031918762251734734
Test Loss:  0.0023785103112459183
Valid Loss:  0.0024554776027798653
Epoch:  231  	Training Loss: 0.003164945635944605
Test Loss:  0.0023682196624577045
Valid Loss:  0.00245762150734663
Epoch:  232  	Training Loss: 0.003142164321616292
Test Loss:  0.002409030683338642
Valid Loss:  0.002430718159303069
Epoch:  233  	Training Loss: 0.0031349232885986567
Test Loss:  0.0024097547866404057
Valid Loss:  0.002430243417620659
Epoch:  234  	Training Loss: 0.0031297130044549704
Test Loss:  0.002410599496215582
Valid Loss:  0.0024296934716403484
Epoch:  235  	Training Loss: 0.0031245958525687456
Test Loss:  0.002411442343145609
Valid Loss:  0.0024291505105793476
Epoch:  236  	Training Loss: 0.003119567409157753
Test Loss:  0.002412279136478901
Valid Loss:  0.002428610809147358
Epoch:  237  	Training Loss: 0.003114627441391349
Test Loss:  0.0024131108075380325
Valid Loss:  0.0024280776269733906
Epoch:  238  	Training Loss: 0.003109778044745326
Test Loss:  0.0024139326997101307
Valid Loss:  0.0024275537580251694
Epoch:  239  	Training Loss: 0.0031050120014697313
Test Loss:  0.0024147476069629192
Valid Loss:  0.002427030587568879
Epoch:  240  	Training Loss: 0.003100329078733921
Test Loss:  0.0024155564606189728
Valid Loss:  0.002426519524306059
Epoch:  241  	Training Loss: 0.0030957285780459642
Test Loss:  0.002416357398033142
Valid Loss:  0.0024260079953819513
Epoch:  242  	Training Loss: 0.00309121236205101
Test Loss:  0.002076726872473955
Valid Loss:  0.0023824693635106087
Epoch:  243  	Training Loss: 0.002895141253247857
Test Loss:  0.002017709892243147
Valid Loss:  0.0024095778353512287
Epoch:  244  	Training Loss: 0.0028648548759520054
Test Loss:  0.002008839976042509
Valid Loss:  0.0024158854503184557
Epoch:  245  	Training Loss: 0.0028490559197962284
Test Loss:  0.0020050802268087864
Valid Loss:  0.0024189401883631945
Epoch:  246  	Training Loss: 0.0028352132067084312
Test Loss:  0.002003462053835392
Valid Loss:  0.0024202794302254915
Epoch:  247  	Training Loss: 0.0028228771407157183
Test Loss:  0.002002757042646408
Valid Loss:  0.00242086173966527
Epoch:  248  	Training Loss: 0.002811846788972616
Test Loss:  0.00200244621373713
Valid Loss:  0.0024211020208895206
Epoch:  249  	Training Loss: 0.0028019724413752556
Test Loss:  0.002002308377996087
Valid Loss:  0.002421200042590499
Epoch:  250  	Training Loss: 0.002793133957311511
Test Loss:  0.0020058690570294857
Valid Loss:  0.00241819117218256
Epoch:  251  	Training Loss: 0.0027852514758706093
Test Loss:  0.002003784291446209
Valid Loss:  0.002419903874397278
Epoch:  252  	Training Loss: 0.002778142923489213
Test Loss:  0.0020180512219667435
Valid Loss:  0.0023757219314575195
Epoch:  253  	Training Loss: 0.0027682799845933914
Test Loss:  0.0020300140604376793
Valid Loss:  0.002347511239349842
Epoch:  254  	Training Loss: 0.0027625032234936953
Test Loss:  0.0020393203012645245
Valid Loss:  0.002329052658751607
Epoch:  255  	Training Loss: 0.0027586871292442083
Test Loss:  0.002046266570687294
Valid Loss:  0.002316707046702504
Epoch:  256  	Training Loss: 0.0027558228466659784
Test Loss:  0.0020513255149126053
Valid Loss:  0.0023082850966602564
Epoch:  257  	Training Loss: 0.0027531010564416647
Test Loss:  0.0020549516193568707
Valid Loss:  0.00230238726362586
Epoch:  258  	Training Loss: 0.002749950159341097
Test Loss:  0.002057523000985384
Valid Loss:  0.00229809433221817
Epoch:  259  	Training Loss: 0.0027469447813928127
Test Loss:  0.0020593355875462294
Valid Loss:  0.0022948826663196087
Epoch:  260  	Training Loss: 0.002744034631177783
Test Loss:  0.0020606042817234993
Valid Loss:  0.0022924067452549934
Epoch:  261  	Training Loss: 0.0027411894407123327
Test Loss:  0.0020614860113710165
Valid Loss:  0.0022904358338564634
Epoch:  262  	Training Loss: 0.0027383998967707157
Test Loss:  0.0020614999812096357
Valid Loss:  0.002289530821144581
Epoch:  263  	Training Loss: 0.0027383225969970226
Test Loss:  0.0020615148823708296
Valid Loss:  0.002288943389430642
Epoch:  264  	Training Loss: 0.002738257171586156
Test Loss:  0.0020615295507013798
Valid Loss:  0.0022885561920702457
Epoch:  265  	Training Loss: 0.002738193841651082
Test Loss:  0.002061540726572275
Valid Loss:  0.0022883019410073757
Epoch:  266  	Training Loss: 0.002738136565312743
Test Loss:  0.0020615537650883198
Valid Loss:  0.002288125455379486
Epoch:  267  	Training Loss: 0.0027380785904824734
Test Loss:  0.0020615668036043644
Valid Loss:  0.002288002520799637
Epoch:  268  	Training Loss: 0.0027380231767892838
Test Loss:  0.002061578445136547
Valid Loss:  0.0022879159078001976
Epoch:  269  	Training Loss: 0.0027379654347896576
Test Loss:  0.002061590552330017
Valid Loss:  0.0022878467570990324
Epoch:  270  	Training Loss: 0.0027379083912819624
Test Loss:  0.0020616031251847744
Valid Loss:  0.0022877883166074753
Epoch:  271  	Training Loss: 0.0027378518134355545
Test Loss:  0.0020616156980395317
Valid Loss:  0.0022877389565110207
Epoch:  272  	Training Loss: 0.002737795701250434
Test Loss:  0.002148831496015191
Valid Loss:  0.002124412450939417
Epoch:  273  	Training Loss: 0.00264933705329895
Test Loss:  0.002043703570961952
Valid Loss:  0.0021159742027521133
Epoch:  274  	Training Loss: 0.002602567430585623
Test Loss:  0.002076513599604368
Valid Loss:  0.0020595965906977654
Epoch:  275  	Training Loss: 0.0025725532323122025
Test Loss:  0.0020306911319494247
Valid Loss:  0.0020640746224671602
Epoch:  276  	Training Loss: 0.0025496252346783876
Test Loss:  0.0020251255482435226
Valid Loss:  0.0020521413534879684
Epoch:  277  	Training Loss: 0.0025295489467680454
Test Loss:  0.002006526105105877
Valid Loss:  0.0020555437076836824
Epoch:  278  	Training Loss: 0.002512900624424219
Test Loss:  0.0020062224939465523
Valid Loss:  0.002046775771304965
Epoch:  279  	Training Loss: 0.002499528229236603
Test Loss:  0.0020001688972115517
Valid Loss:  0.002044610446318984
Epoch:  280  	Training Loss: 0.0024880673736333847
Test Loss:  0.002007866743952036
Valid Loss:   56%|█████▌    | 281/500 [03:27<04:22,  1.20s/it] 57%|█████▋    | 283/500 [03:27<03:06,  1.16it/s] 57%|█████▋    | 285/500 [03:27<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:27<01:37,  2.20it/s] 58%|█████▊    | 289/500 [03:27<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:34<04:10,  1.20s/it] 58%|█████▊    | 292/500 [03:34<03:28,  1.00s/it] 59%|█████▉    | 294/500 [03:34<02:22,  1.45it/s] 59%|█████▉    | 296/500 [03:34<01:39,  2.04it/s] 60%|█████▉    | 298/500 [03:34<01:11,  2.81it/s] 60%|██████    | 300/500 [03:35<00:53,  3.76it/s] 60%|██████    | 302/500 [03:41<03:51,  1.17s/it] 61%|██████    | 304/500 [03:41<02:42,  1.20it/s] 61%|██████    | 306/500 [03:41<01:56,  1.66it/s] 62%|██████▏   | 308/500 [03:41<01:25,  2.24it/s] 62%|██████▏   | 310/500 [03:41<01:03,  3.01it/s] 62%|██████▏   | 312/500 [03:48<03:46,  1.21s/it] 63%|██████▎   | 314/500 [03:48<02:40,  1.16it/s] 63%|██████▎   | 316/500 [03:48<01:54,  1.61it/s] 64%|██████▎   | 318/500 [03:48<01:22,  2.20it/s] 64%|██████▍   | 320/500 [03:48<01:00,  2.96it/s] 64%|██████▍   | 322/500 [03:55<03:32,  1.20s/it] 65%|██████▍   | 324/500 [03:55<02:31,  1.16it/s] 65%|██████▌   | 326/500 [03:55<01:49,  1.59it/s] 66%|██████▌   | 328/500 [03:55<01:20,  2.15it/s] 66%|██████▌   | 330/500 [03:56<00:59,  2.85it/s] 66%|██████▋   | 332/500 [04:02<03:23,  1.21s/it] 67%|██████▋   | 334/500 [04:02<02:23,  1.15it/s] 67%|██████▋   | 336/500 [04:02<01:42,  1.60it/s] 68%|██████▊   | 338/500 [04:02<01:14,  2.18it/s] 68%|██████▊   | 340/500 [04:02<00:54,  2.94it/s] 68%|██████▊   | 342/500 [04:09<03:06,  1.18s/it] 69%|██████▉   | 344/500 [04:09<02:12,  1.17it/s] 69%|██████▉   | 346/500 [04:09<01:35,  1.61it/s] 70%|██████▉   | 348/500 [04:09<01:09,  2.19it/s]0.0020341852214187384
Epoch:  281  	Training Loss: 0.002479834482073784
Test Loss:  0.002012630458921194
Valid Loss:  0.002028658054769039
Epoch:  282  	Training Loss: 0.002473411848768592
Test Loss:  0.0019697328098118305
Valid Loss:  0.002062530256807804
Epoch:  283  	Training Loss: 0.002459968440234661
Test Loss:  0.00195217109285295
Valid Loss:  0.0020811818540096283
Epoch:  284  	Training Loss: 0.00245259003713727
Test Loss:  0.0019444986246526241
Valid Loss:  0.0020905069541186094
Epoch:  285  	Training Loss: 0.002446644939482212
Test Loss:  0.0019410222303122282
Valid Loss:  0.002094993367791176
Epoch:  286  	Training Loss: 0.002440791577100754
Test Loss:  0.0019394125556573272
Valid Loss:  0.002097109565511346
Epoch:  287  	Training Loss: 0.0024338937364518642
Test Loss:  0.0019386630738154054
Valid Loss:  0.0020980890840291977
Epoch:  288  	Training Loss: 0.0024271905422210693
Test Loss:  0.001938310218974948
Valid Loss:  0.002098530065268278
Epoch:  289  	Training Loss: 0.002420667093247175
Test Loss:  0.0019381390884518623
Valid Loss:  0.0020987221505492926
Epoch:  290  	Training Loss: 0.0024143133778125048
Test Loss:  0.001938055269420147
Valid Loss:  0.0020987973548471928
Epoch:  291  	Training Loss: 0.002408126834779978
Test Loss:  0.0019380125449970365
Valid Loss:  0.002098818775266409
Epoch:  292  	Training Loss: 0.0024021028075367212
Test Loss:  0.0019965956453233957
Valid Loss:  0.0020513110794126987
Epoch:  293  	Training Loss: 0.002360577927902341
Test Loss:  0.0020161205902695656
Valid Loss:  0.002050751354545355
Epoch:  294  	Training Loss: 0.0023363579530268908
Test Loss:  0.0020324839279055595
Valid Loss:  0.002054555807262659
Epoch:  295  	Training Loss: 0.002319182502105832
Test Loss:  0.002048441208899021
Valid Loss:  0.0020553446374833584
Epoch:  296  	Training Loss: 0.002305822679772973
Test Loss:  0.002061063889414072
Valid Loss:  0.002055372577160597
Epoch:  297  	Training Loss: 0.002297482918947935
Test Loss:  0.002070141024887562
Valid Loss:  0.0020552389323711395
Epoch:  298  	Training Loss: 0.0022918127942830324
Test Loss:  0.0020766379311680794
Valid Loss:  0.00205477187409997
Epoch:  299  	Training Loss: 0.002287613693624735
Test Loss:  0.0020812475122511387
Valid Loss:  0.002054015640169382
Epoch:  300  	Training Loss: 0.002284271875396371
Test Loss:  0.0020844792015850544
Valid Loss:  0.0020530330948531628
Epoch:  301  	Training Loss: 0.0022814669646322727
Test Loss:  0.0020867222920060158
Valid Loss:  0.0020519003737717867
Epoch:  302  	Training Loss: 0.002279028296470642
Test Loss:  0.002052729483693838
Valid Loss:  0.0020703314803540707
Epoch:  303  	Training Loss: 0.0022686850279569626
Test Loss:  0.002048925030976534
Valid Loss:  0.002073500771075487
Epoch:  304  	Training Loss: 0.002260681940242648
Test Loss:  0.002042696811258793
Valid Loss:  0.002080596750602126
Epoch:  305  	Training Loss: 0.0022540204226970673
Test Loss:  0.002038989681750536
Valid Loss:  0.0020874140318483114
Epoch:  306  	Training Loss: 0.0022483610082417727
Test Loss:  0.002036305610090494
Valid Loss:  0.002094488125294447
Epoch:  307  	Training Loss: 0.002243499271571636
Test Loss:  0.002034504897892475
Valid Loss:  0.002101542893797159
Epoch:  308  	Training Loss: 0.002239299938082695
Test Loss:  0.00203333399258554
Valid Loss:  0.002108521293848753
Epoch:  309  	Training Loss: 0.0022355057299137115
Test Loss:  0.002032605465501547
Valid Loss:  0.0021199278999119997
Epoch:  310  	Training Loss: 0.0022306565660983324
Test Loss:  0.002035671379417181
Valid Loss:  0.0021272371523082256
Epoch:  311  	Training Loss: 0.002226665150374174
Test Loss:  0.002037311438471079
Valid Loss:  0.002134960610419512
Epoch:  312  	Training Loss: 0.0022225845605134964
Test Loss:  0.002027404960244894
Valid Loss:  0.002152560744434595
Epoch:  313  	Training Loss: 0.002216936554759741
Test Loss:  0.0020319651812314987
Valid Loss:  0.002156647853553295
Epoch:  314  	Training Loss: 0.0022124736569821835
Test Loss:  0.0020318087190389633
Valid Loss:  0.0021645643282681704
Epoch:  315  	Training Loss: 0.0022088433615863323
Test Loss:  0.002033524913713336
Valid Loss:  0.002169976243749261
Epoch:  316  	Training Loss: 0.0022058384492993355
Test Loss:  0.0020346546079963446
Valid Loss:  0.002175268018618226
Epoch:  317  	Training Loss: 0.0022033124696463346
Test Loss:  0.0020359985064715147
Valid Loss:  0.0021796724759042263
Epoch:  318  	Training Loss: 0.002201161812990904
Test Loss:  0.00203721784055233
Valid Loss:  0.002183574251830578
Epoch:  319  	Training Loss: 0.0021993108093738556
Test Loss:  0.002038420643657446
Valid Loss:  0.0021869344636797905
Epoch:  320  	Training Loss: 0.0021977080032229424
Test Loss:  0.0020395424216985703
Valid Loss:  0.0021898611448705196
Epoch:  321  	Training Loss: 0.0021963054314255714
Test Loss:  0.0020406050607562065
Valid Loss:  0.002192407613620162
Epoch:  322  	Training Loss: 0.0021950718946754932
Test Loss:  0.001994682475924492
Valid Loss:  0.002236157190054655
Epoch:  323  	Training Loss: 0.0021859463304281235
Test Loss:  0.0019899324979633093
Valid Loss:  0.0022468585520982742
Epoch:  324  	Training Loss: 0.002184392884373665
Test Loss:  0.0019882293418049812
Valid Loss:  0.0022529251873493195
Epoch:  325  	Training Loss: 0.002183680422604084
Test Loss:  0.0019876104779541492
Valid Loss:  0.0022566330153495073
Epoch:  326  	Training Loss: 0.002183344215154648
Test Loss:  0.0019873855635523796
Valid Loss:  0.0022590269800275564
Epoch:  327  	Training Loss: 0.0021831835620105267
Test Loss:  0.001987307332456112
Valid Loss:  0.002260617446154356
Epoch:  328  	Training Loss: 0.002183103933930397
Test Loss:  0.001987276365980506
Valid Loss:  0.0022616980131715536
Epoch:  329  	Training Loss: 0.0021830652840435505
Test Loss:  0.0019872637931257486
Valid Loss:  0.0022624386474490166
Epoch:  330  	Training Loss: 0.002183047356083989
Test Loss:  0.001987260766327381
Valid Loss:  0.0022629480808973312
Epoch:  331  	Training Loss: 0.0021830357145518064
Test Loss:  0.0019872619304805994
Valid Loss:  0.0022632977925240993
Epoch:  332  	Training Loss: 0.002183029195293784
Test Loss:  0.0019949376583099365
Valid Loss:  0.0022452259436249733
Epoch:  333  	Training Loss: 0.0021805225405842066
Test Loss:  0.0020006736740469933
Valid Loss:  0.002232923172414303
Epoch:  334  	Training Loss: 0.002178761875256896
Test Loss:  0.0020048602018505335
Valid Loss:  0.0022244032006710768
Epoch:  335  	Training Loss: 0.0021773669868707657
Test Loss:  0.0020078648813068867
Valid Loss:  0.0022184127010405064
Epoch:  336  	Training Loss: 0.0021761590614914894
Test Loss:  0.002009997144341469
Valid Loss:  0.002214125357568264
Epoch:  337  	Training Loss: 0.002175047527998686
Test Loss:  0.002011503092944622
Valid Loss:  0.0022110012359917164
Epoch:  338  	Training Loss: 0.002173988614231348
Test Loss:  0.002012562705203891
Valid Loss:  0.0022086664102971554
Epoch:  339  	Training Loss: 0.002172959502786398
Test Loss:  0.002013302408158779
Valid Loss:  0.0022068843245506287
Epoch:  340  	Training Loss: 0.002171954605728388
Test Loss:  0.002013819059357047
Valid Loss:  0.002205486409366131
Epoch:  341  	Training Loss: 0.0021709641441702843
Test Loss:  0.0020141792483627796
Valid Loss:  0.002204353455454111
Epoch:  342  	Training Loss: 0.0021699864882975817
Test Loss:  0.0020130109041929245
Valid Loss:  0.002206353936344385
Epoch:  343  	Training Loss: 0.002169949933886528
Test Loss:  0.0020121182315051556
Valid Loss:  0.002207901095971465
Epoch:  344  	Training Loss: 0.002169926417991519
Test Loss:  0.002011434407904744
Valid Loss:  0.0022090934216976166
Epoch:  345  	Training Loss: 0.0021699112839996815
Test Loss:  0.0020109103061258793
Valid Loss:  0.002210015896707773
Epoch:  346  	Training Loss: 0.002169898012652993
Test Loss:  0.0020105105359107256
Valid Loss:  0.0022107241675257683
Epoch:  347  	Training Loss: 0.0021698884665966034
Test Loss:  0.0020102038979530334
Valid Loss:  0.002211265964433551
Epoch:  348  	Training Loss: 0.0021698803175240755
Test Loss:  0.002009965945035219
Valid Loss:  0.002211682964116335
Epoch:  349  	Training Loss: 0.0021698707714676857
Test Loss:  0.0020097889937460423
Valid Loss:   70%|███████   | 350/500 [04:09<00:51,  2.94it/s] 70%|███████   | 352/500 [04:16<02:58,  1.21s/it] 71%|███████   | 354/500 [04:16<02:07,  1.15it/s] 71%|███████   | 356/500 [04:16<01:31,  1.57it/s] 72%|███████▏  | 358/500 [04:16<01:07,  2.12it/s] 72%|███████▏  | 360/500 [04:17<00:49,  2.85it/s] 72%|███████▏  | 362/500 [04:23<02:45,  1.20s/it] 73%|███████▎  | 364/500 [04:23<01:56,  1.17it/s] 73%|███████▎  | 366/500 [04:23<01:23,  1.61it/s] 74%|███████▎  | 368/500 [04:23<00:59,  2.20it/s] 74%|███████▍  | 370/500 [04:23<00:44,  2.95it/s] 74%|███████▍  | 372/500 [04:30<02:32,  1.19s/it] 75%|███████▍  | 374/500 [04:30<01:47,  1.17it/s] 75%|███████▌  | 376/500 [04:30<01:16,  1.62it/s] 76%|███████▌  | 378/500 [04:30<00:55,  2.21it/s] 76%|███████▌  | 380/500 [04:30<00:40,  2.97it/s] 76%|███████▋  | 382/500 [04:37<02:21,  1.20s/it] 77%|███████▋  | 384/500 [04:37<01:39,  1.16it/s] 77%|███████▋  | 386/500 [04:37<01:10,  1.61it/s] 78%|███████▊  | 388/500 [04:37<00:50,  2.20it/s] 78%|███████▊  | 390/500 [04:37<00:37,  2.95it/s] 78%|███████▊  | 392/500 [04:44<02:08,  1.19s/it] 79%|███████▉  | 394/500 [04:44<01:30,  1.17it/s] 79%|███████▉  | 396/500 [04:44<01:04,  1.62it/s] 80%|███████▉  | 398/500 [04:44<00:46,  2.21it/s] 80%|████████  | 400/500 [04:44<00:33,  2.98it/s] 80%|████████  | 402/500 [04:51<01:57,  1.20s/it] 81%|████████  | 404/500 [04:51<01:22,  1.16it/s] 81%|████████  | 406/500 [04:51<00:59,  1.59it/s] 82%|████████▏ | 408/500 [04:51<00:42,  2.14it/s] 82%|████████▏ | 410/500 [04:51<00:31,  2.84it/s] 82%|████████▏ | 412/500 [04:58<01:46,  1.21s/it] 83%|████████▎ | 414/500 [04:58<01:14,  1.16it/s] 83%|████████▎ | 416/500 [04:58<00:52,  1.60it/s]0.002212000545114279
Epoch:  350  	Training Loss: 0.0021698656491935253
Test Loss:  0.00200964929535985
Valid Loss:  0.002212241990491748
Epoch:  351  	Training Loss: 0.0021698586642742157
Test Loss:  0.002009544987231493
Valid Loss:  0.0022124273236840963
Epoch:  352  	Training Loss: 0.002169852377846837
Test Loss:  0.0020620226860046387
Valid Loss:  0.00216881325468421
Epoch:  353  	Training Loss: 0.0021655913442373276
Test Loss:  0.0020515061914920807
Valid Loss:  0.002182210795581341
Epoch:  354  	Training Loss: 0.002164472360163927
Test Loss:  0.0020539488177746534
Valid Loss:  0.0021846038289368153
Epoch:  355  	Training Loss: 0.002163632307201624
Test Loss:  0.002053954405710101
Valid Loss:  0.002188737504184246
Epoch:  356  	Training Loss: 0.002162928692996502
Test Loss:  0.0020544682629406452
Valid Loss:  0.0021921200677752495
Epoch:  357  	Training Loss: 0.002162337303161621
Test Loss:  0.002054900862276554
Valid Loss:  0.00219526793807745
Epoch:  358  	Training Loss: 0.0021618353202939034
Test Loss:  0.0020553527865558863
Valid Loss:  0.0021981089375913143
Epoch:  359  	Training Loss: 0.0021614073775708675
Test Loss:  0.002055799588561058
Valid Loss:  0.0022006866056472063
Epoch:  360  	Training Loss: 0.0021610409021377563
Test Loss:  0.0020562356803566217
Valid Loss:  0.0022030267864465714
Epoch:  361  	Training Loss: 0.0021607258822768927
Test Loss:  0.002056658733636141
Valid Loss:  0.0022051529958844185
Epoch:  362  	Training Loss: 0.0021604544017463923
Test Loss:  0.002014187164604664
Valid Loss:  0.0022338293492794037
Epoch:  363  	Training Loss: 0.002157216891646385
Test Loss:  0.0020672304090112448
Valid Loss:  0.002191902371123433
Epoch:  364  	Training Loss: 0.0021554147824645042
Test Loss:  0.002026982605457306
Valid Loss:  0.0022192802280187607
Epoch:  365  	Training Loss: 0.0021543956827372313
Test Loss:  0.0020555956289172173
Valid Loss:  0.002196495421230793
Epoch:  366  	Training Loss: 0.0021534934639930725
Test Loss:  0.002037096070125699
Valid Loss:  0.002208883175626397
Epoch:  367  	Training Loss: 0.0021530305966734886
Test Loss:  0.0020540356636047363
Valid Loss:  0.002196128945797682
Epoch:  368  	Training Loss: 0.002152686472982168
Test Loss:  0.002043310087174177
Valid Loss:  0.002203457523137331
Epoch:  369  	Training Loss: 0.0021524187177419662
Test Loss:  0.0020494915079325438
Valid Loss:  0.0021986477077007294
Epoch:  370  	Training Loss: 0.0021521798335015774
Test Loss:  0.00204542838037014
Valid Loss:  0.0022012759000062943
Epoch:  371  	Training Loss: 0.002151956781744957
Test Loss:  0.002047623274847865
Valid Loss:  0.0021994018461555243
Epoch:  372  	Training Loss: 0.002151740249246359
Test Loss:  0.002045406959950924
Valid Loss:  0.0022007792722433805
Epoch:  373  	Training Loss: 0.0021504582837224007
Test Loss:  0.002044654916971922
Valid Loss:  0.0022012442350387573
Epoch:  374  	Training Loss: 0.0021492985542863607
Test Loss:  0.0020443983376026154
Valid Loss:  0.0022013948764652014
Epoch:  375  	Training Loss: 0.002148234751075506
Test Loss:  0.0020443145185709
Valid Loss:  0.002201440278440714
Epoch:  376  	Training Loss: 0.002147249411791563
Test Loss:  0.0020442784298211336
Valid Loss:  0.00220144703052938
Epoch:  377  	Training Loss: 0.002146335318684578
Test Loss:  0.0020442772656679153
Valid Loss:  0.0022014400456100702
Epoch:  378  	Training Loss: 0.0021454801317304373
Test Loss:  0.0020442684181034565
Valid Loss:  0.0022014270070940256
Epoch:  379  	Training Loss: 0.002144653582945466
Test Loss:  0.0020442658569663763
Valid Loss:  0.002201416529715061
Epoch:  380  	Training Loss: 0.002143516670912504
Test Loss:  0.002044268185272813
Valid Loss:  0.0022013999987393618
Epoch:  381  	Training Loss: 0.0021424381993710995
Test Loss:  0.002044264692813158
Valid Loss:  0.0022013916168361902
Epoch:  382  	Training Loss: 0.0021414081566035748
Test Loss:  0.00205499236471951
Valid Loss:  0.002196230459958315
Epoch:  383  	Training Loss: 0.0021407266613096
Test Loss:  0.002057393081486225
Valid Loss:  0.00219717831350863
Epoch:  384  	Training Loss: 0.00214040232822299
Test Loss:  0.0020594755187630653
Valid Loss:  0.002197647700086236
Epoch:  385  	Training Loss: 0.0021402265410870314
Test Loss:  0.0020609968341886997
Valid Loss:  0.002198020229116082
Epoch:  386  	Training Loss: 0.002140129217877984
Test Loss:  0.002062112558633089
Valid Loss:  0.002198300091549754
Epoch:  387  	Training Loss: 0.0021400772966444492
Test Loss:  0.0020629344508051872
Valid Loss:  0.002198506612330675
Epoch:  388  	Training Loss: 0.0021400460973381996
Test Loss:  0.0020635370165109634
Valid Loss:  0.0021986612118780613
Epoch:  389  	Training Loss: 0.002140029799193144
Test Loss:  0.0020639789290726185
Valid Loss:  0.0021987739019095898
Epoch:  390  	Training Loss: 0.0021400186233222485
Test Loss:  0.002064303494989872
Valid Loss:  0.002198854461312294
Epoch:  391  	Training Loss: 0.0021400107070803642
Test Loss:  0.002064540283754468
Valid Loss:  0.002198913600295782
Epoch:  392  	Training Loss: 0.002140006050467491
Test Loss:  0.0020647100172936916
Valid Loss:  0.0021989610977470875
Epoch:  393  	Training Loss: 0.0021399985998868942
Test Loss:  0.0020647961646318436
Valid Loss:  0.002199041424319148
Epoch:  394  	Training Loss: 0.0021399911493062973
Test Loss:  0.00206485902890563
Valid Loss:  0.0021991170942783356
Epoch:  395  	Training Loss: 0.0021399857942014933
Test Loss:  0.002064904198050499
Valid Loss:  0.002199181355535984
Epoch:  396  	Training Loss: 0.0021399788092821836
Test Loss:  0.0020649407524615526
Valid Loss:  0.0021992442198097706
Epoch:  397  	Training Loss: 0.002139973919838667
Test Loss:  0.0020649684593081474
Valid Loss:  0.002199301030486822
Epoch:  398  	Training Loss: 0.0021399669349193573
Test Loss:  0.002064988249912858
Valid Loss:  0.0021993580739945173
Epoch:  399  	Training Loss: 0.0021399627439677715
Test Loss:  0.0020650068763643503
Valid Loss:  0.002199409296736121
Epoch:  400  	Training Loss: 0.0021399562247097492
Test Loss:  0.0020650187507271767
Valid Loss:  0.002199461217969656
Epoch:  401  	Training Loss: 0.0021399524994194508
Test Loss:  0.002065032720565796
Valid Loss:  0.0021995066199451685
Epoch:  402  	Training Loss: 0.0021399478428065777
Test Loss:  0.00206101406365633
Valid Loss:  0.0022059848997741938
Epoch:  403  	Training Loss: 0.0021397187374532223
Test Loss:  0.002058273646980524
Valid Loss:  0.0022105704993009567
Epoch:  404  	Training Loss: 0.002139604650437832
Test Loss:  0.0020563912112265825
Valid Loss:  0.0022137979976832867
Epoch:  405  	Training Loss: 0.0021395478397607803
Test Loss:  0.0020550996996462345
Valid Loss:  0.0022160618100315332
Epoch:  406  	Training Loss: 0.00213951850309968
Test Loss:  0.002054202603176236
Valid Loss:  0.002217648085206747
Epoch:  407  	Training Loss: 0.0021395019721239805
Test Loss:  0.002053582575172186
Valid Loss:  0.0022187535651028156
Epoch:  408  	Training Loss: 0.0021394912619143724
Test Loss:  0.002053148578852415
Valid Loss:  0.0022195223718881607
Epoch:  409  	Training Loss: 0.002139484975486994
Test Loss:  0.002052848692983389
Valid Loss:  0.0022200585808604956
Epoch:  410  	Training Loss: 0.0021394803188741207
Test Loss:  0.002052640076726675
Valid Loss:  0.002220432972535491
Epoch:  411  	Training Loss: 0.0021394751965999603
Test Loss:  0.0020524931605905294
Valid Loss:  0.0022206855937838554
Epoch:  412  	Training Loss: 0.002139472169801593
Test Loss:  0.0020524945575743914
Valid Loss:  0.002220684429630637
Epoch:  413  	Training Loss: 0.002139471471309662
Test Loss:  0.002052498981356621
Valid Loss:  0.0022206827998161316
Epoch:  414  	Training Loss: 0.002139470772817731
Test Loss:  0.0020524978172034025
Valid Loss:  0.002220683265477419
Epoch:  415  	Training Loss: 0.0021394705399870872
Test Loss:  0.0020524996798485518
Valid Loss:  0.0022206802386790514
Epoch:  416  	Training Loss: 0.0021394698414951563
Test Loss:  0.0020525020081549883
Valid Loss:  0.0022206800058484077
Epoch:  417  	Training Loss: 0.002139468677341938
Test Loss:  0.0020525027066469193
Valid Loss:  0.0022206795401871204
Epoch:  418  	Training Loss: 0.0021394684445112944
Test Loss:  0.00205250340513885
Valid Loss:  0.002220678608864546
 84%|████████▎ | 418/500 [04:58<00:37,  2.18it/s] 84%|████████▍ | 420/500 [04:58<00:27,  2.94it/s] 84%|████████▍ | 422/500 [05:05<01:33,  1.19s/it] 85%|████████▍ | 424/500 [05:05<01:05,  1.17it/s] 85%|████████▌ | 426/500 [05:05<00:45,  1.61it/s] 86%|████████▌ | 428/500 [05:05<00:32,  2.21it/s] 86%|████████▌ | 430/500 [05:05<00:23,  2.97it/s] 86%|████████▋ | 432/500 [05:11<01:20,  1.18s/it] 87%|████████▋ | 434/500 [05:12<00:56,  1.18it/s] 87%|████████▋ | 436/500 [05:12<00:39,  1.63it/s] 88%|████████▊ | 438/500 [05:12<00:27,  2.22it/s] 88%|████████▊ | 440/500 [05:12<00:20,  2.98it/s] 88%|████████▊ | 442/500 [05:18<01:09,  1.20s/it] 89%|████████▉ | 444/500 [05:19<00:48,  1.16it/s] 89%|████████▉ | 446/500 [05:19<00:34,  1.58it/s] 90%|████████▉ | 448/500 [05:19<00:24,  2.15it/s] 90%|█████████ | 450/500 [05:19<00:17,  2.87it/s] 90%|█████████ | 452/500 [05:25<00:58,  1.21s/it] 91%|█████████ | 454/500 [05:26<00:39,  1.15it/s] 91%|█████████ | 456/500 [05:26<00:27,  1.60it/s] 92%|█████████▏| 458/500 [05:26<00:19,  2.18it/s] 92%|█████████▏| 460/500 [05:26<00:13,  2.88it/s] 92%|█████████▏| 462/500 [05:32<00:45,  1.20s/it] 93%|█████████▎| 464/500 [05:33<00:31,  1.16it/s] 93%|█████████▎| 466/500 [05:33<00:21,  1.60it/s] 94%|█████████▎| 468/500 [05:33<00:14,  2.19it/s] 94%|█████████▍| 470/500 [05:33<00:10,  2.95it/s] 94%|█████████▍| 472/500 [05:39<00:33,  1.20s/it] 95%|█████████▍| 474/500 [05:40<00:22,  1.16it/s] 95%|█████████▌| 476/500 [05:40<00:14,  1.61it/s] 96%|█████████▌| 478/500 [05:40<00:09,  2.20it/s] 96%|█████████▌| 480/500 [05:40<00:06,  2.96it/s] 96%|█████████▋| 482/500 [05:46<00:21,  1.20s/it] 97%|█████████▋| 484/500 [05:46<00:13,  1.16it/s] 97%|█████████▋| 486/500 [05:47<00:08,  1.59it/s]Epoch:  419  	Training Loss: 0.002139468677341938
Test Loss:  0.0020525059662759304
Valid Loss:  0.002220677910372615
Epoch:  420  	Training Loss: 0.002139467280358076
Test Loss:  0.0020525066647678614
Valid Loss:  0.0022206753492355347
Epoch:  421  	Training Loss: 0.0021394677460193634
Test Loss:  0.0020525080617517233
Valid Loss:  0.0022206755820661783
Epoch:  422  	Training Loss: 0.0021394675131887197
Test Loss:  0.002052405383437872
Valid Loss:  0.002220852766185999
Epoch:  423  	Training Loss: 0.002139465417712927
Test Loss:  0.0020523318089544773
Valid Loss:  0.002220975235104561
Epoch:  424  	Training Loss: 0.002139461226761341
Test Loss:  0.002052281517535448
Valid Loss:  0.0022210562601685524
Epoch:  425  	Training Loss: 0.0021394577343016863
Test Loss:  0.0020522484555840492
Valid Loss:  0.0022211114410310984
Epoch:  426  	Training Loss: 0.0021394549403339624
Test Loss:  0.002052223077043891
Valid Loss:  0.002221147296950221
Epoch:  427  	Training Loss: 0.0021394514478743076
Test Loss:  0.0020522046834230423
Valid Loss:  0.002221168950200081
Epoch:  428  	Training Loss: 0.002139448653906584
Test Loss:  0.0020521939732134342
Valid Loss:  0.0022211819887161255
Epoch:  429  	Training Loss: 0.00213944585993886
Test Loss:  0.00205218605697155
Valid Loss:  0.0022211873438209295
Epoch:  430  	Training Loss: 0.002139443065971136
Test Loss:  0.002052180701866746
Valid Loss:  0.002221187110990286
Epoch:  431  	Training Loss: 0.0021394379436969757
Test Loss:  0.0020521758124232292
Valid Loss:  0.002221186412498355
Epoch:  432  	Training Loss: 0.002139435149729252
Test Loss:  0.0020594557281583548
Valid Loss:  0.00221477122977376
Epoch:  433  	Training Loss: 0.0021379964891821146
Test Loss:  0.0020600054413080215
Valid Loss:  0.0022152159363031387
Epoch:  434  	Training Loss: 0.0021368558518588543
Test Loss:  0.002066825982183218
Valid Loss:  0.0022120438516139984
Epoch:  435  	Training Loss: 0.0021357941441237926
Test Loss:  0.002055428922176361
Valid Loss:  0.00222172774374485
Epoch:  436  	Training Loss: 0.0021347571164369583
Test Loss:  0.002071884460747242
Valid Loss:  0.0022106277756392956
Epoch:  437  	Training Loss: 0.002133721951395273
Test Loss:  0.0020526049192994833
Valid Loss:  0.002226357813924551
Epoch:  438  	Training Loss: 0.00213275826536119
Test Loss:  0.002075357362627983
Valid Loss:  0.0022099530324339867
Epoch:  439  	Training Loss: 0.0021317044738680124
Test Loss:  0.002050878247246146
Valid Loss:  0.0022296409588307142
Epoch:  440  	Training Loss: 0.0021306818816810846
Test Loss:  0.0020777869503945112
Valid Loss:  0.0022096491884440184
Epoch:  441  	Training Loss: 0.002129263710230589
Test Loss:  0.0020499760285019875
Valid Loss:  0.0022318451665341854
Epoch:  442  	Training Loss: 0.0021281540393829346
Test Loss:  0.0020530838519334793
Valid Loss:  0.0022256425581872463
Epoch:  443  	Training Loss: 0.0021268227137625217
Test Loss:  0.002054564654827118
Valid Loss:  0.002222552429884672
Epoch:  444  	Training Loss: 0.002125571481883526
Test Loss:  0.0020552650094032288
Valid Loss:  0.002220882335677743
Epoch:  445  	Training Loss: 0.00212434446439147
Test Loss:  0.002055595861747861
Valid Loss:  0.0022198492661118507
Epoch:  446  	Training Loss: 0.0021231339778751135
Test Loss:  0.002055745106190443
Valid Loss:  0.0022191135212779045
Epoch:  447  	Training Loss: 0.002121932804584503
Test Loss:  0.002055817749351263
Valid Loss:  0.0022185146808624268
Epoch:  448  	Training Loss: 0.002120743505656719
Test Loss:  0.0020558475516736507
Valid Loss:  0.002217974979430437
Epoch:  449  	Training Loss: 0.0021195653825998306
Test Loss:  0.002055862918496132
Valid Loss:  0.0022174681071192026
Epoch:  450  	Training Loss: 0.002118396572768688
Test Loss:  0.0020558673422783613
Valid Loss:  0.0022169742733240128
Epoch:  451  	Training Loss: 0.002117238473147154
Test Loss:  0.002055869670584798
Valid Loss:  0.0022164974361658096
Epoch:  452  	Training Loss: 0.00211608805693686
Test Loss:  0.002066438551992178
Valid Loss:  0.002208544872701168
Epoch:  453  	Training Loss: 0.0021159062162041664
Test Loss:  0.002065021311864257
Valid Loss:  0.0022109979763627052
Epoch:  454  	Training Loss: 0.0021158617455512285
Test Loss:  0.00206530699506402
Valid Loss:  0.0022118818014860153
Epoch:  455  	Training Loss: 0.0021158261224627495
Test Loss:  0.002065348904579878
Valid Loss:  0.002212880179286003
Epoch:  456  	Training Loss: 0.0021157979499548674
Test Loss:  0.0020654217805713415
Valid Loss:  0.0022137623745948076
Epoch:  457  	Training Loss: 0.002115773968398571
Test Loss:  0.0020654783584177494
Valid Loss:  0.002214571461081505
Epoch:  458  	Training Loss: 0.0021157539449632168
Test Loss:  0.0020655361004173756
Valid Loss:  0.0022153067402541637
Epoch:  459  	Training Loss: 0.0021157367154955864
Test Loss:  0.0020655877888202667
Valid Loss:  0.002215975895524025
Epoch:  460  	Training Loss: 0.002115722745656967
Test Loss:  0.002065641339868307
Valid Loss:  0.002216584514826536
Epoch:  461  	Training Loss: 0.002115709939971566
Test Loss:  0.0020656820852309465
Valid Loss:  0.0022171386517584324
Epoch:  462  	Training Loss: 0.002115699928253889
Test Loss:  0.002065681852400303
Valid Loss:  0.002217593602836132
Epoch:  463  	Training Loss: 0.0021156740840524435
Test Loss:  0.0020656809210777283
Valid Loss:  0.0022179437801241875
Epoch:  464  	Training Loss: 0.0021156538277864456
Test Loss:  0.002065683249384165
Valid Loss:  0.0022182194516062737
Epoch:  465  	Training Loss: 0.0021156342700123787
Test Loss:  0.002065683249384165
Valid Loss:  0.002218448556959629
Epoch:  466  	Training Loss: 0.0021156161092221737
Test Loss:  0.002065683249384165
Valid Loss:  0.002218642272055149
Epoch:  467  	Training Loss: 0.002115600975230336
Test Loss:  0.002065681852400303
Valid Loss:  0.00221880991011858
Epoch:  468  	Training Loss: 0.0021155858412384987
Test Loss:  0.00206568231806159
Valid Loss:  0.002218961715698242
Epoch:  469  	Training Loss: 0.002115572802722454
Test Loss:  0.0020656806882470846
Valid Loss:  0.0022190993186086416
Epoch:  470  	Training Loss: 0.0021155602298676968
Test Loss:  0.0020656813867390156
Valid Loss:  0.002219228772446513
Epoch:  471  	Training Loss: 0.0021155476570129395
Test Loss:  0.0020656809210777283
Valid Loss:  0.002219350077211857
Epoch:  472  	Training Loss: 0.002115536481142044
Test Loss:  0.0020664434414356947
Valid Loss:  0.002219423186033964
Epoch:  473  	Training Loss: 0.002115517156198621
Test Loss:  0.00206631887704134
Valid Loss:  0.0022202199324965477
Epoch:  474  	Training Loss: 0.0021155024878680706
Test Loss:  0.0020663593895733356
Valid Loss:  0.0022207810543477535
Epoch:  475  	Training Loss: 0.002115491311997175
Test Loss:  0.002066359156742692
Valid Loss:  0.002221296075731516
Epoch:  476  	Training Loss: 0.0021154824644327164
Test Loss:  0.002066365210339427
Valid Loss:  0.0022217407822608948
Epoch:  477  	Training Loss: 0.002115474781021476
Test Loss:  0.002066368702799082
Valid Loss:  0.0022221319377422333
Epoch:  478  	Training Loss: 0.00211546802893281
Test Loss:  0.002066367771476507
Valid Loss:  0.0022224741987884045
Epoch:  479  	Training Loss: 0.002115463837981224
Test Loss:  0.0020663668401539326
Valid Loss:  0.002222771290689707
Epoch:  480  	Training Loss: 0.0021154601126909256
Test Loss:  0.0020663610193878412
Valid Loss:  0.0022230283357203007
Epoch:  481  	Training Loss: 0.00211545592173934
Test Loss:  0.002066357061266899
Valid Loss:  0.0022232551127672195
Epoch:  482  	Training Loss: 0.0021154535934329033
Test Loss:  0.0020661780145019293
Valid Loss:  0.002224150812253356
Epoch:  483  	Training Loss: 0.0021152282133698463
Test Loss:  0.002066034823656082
Valid Loss:  0.0022247976157814264
Epoch:  484  	Training Loss: 0.002115008421242237
Test Loss:  0.0020659342408180237
Valid Loss:  0.0022252718918025494
Epoch:  485  	Training Loss: 0.002114793285727501
Test Loss:  0.0020658548455685377
Valid Loss:  0.002225620439276099
Epoch:  486  	Training Loss: 0.0021145830396562815
Test Loss:  0.0020657917484641075
Valid Loss:  0.0022258800454437733
Epoch:  487  	Training Loss: 0.002114373492076993
Test Loss:  0.002065743552520871
Valid Loss:  0.002226081909611821
 98%|█████████▊| 488/500 [05:47<00:05,  2.15it/s] 98%|█████████▊| 490/500 [05:47<00:03,  2.88it/s] 98%|█████████▊| 492/500 [05:54<00:09,  1.23s/it] 99%|█████████▉| 494/500 [05:54<00:05,  1.14it/s] 99%|█████████▉| 496/500 [05:54<00:02,  1.58it/s]100%|█████████▉| 498/500 [05:54<00:00,  2.15it/s]100%|██████████| 500/500 [05:54<00:00,  2.89it/s]100%|██████████| 500/500 [05:54<00:00,  1.41it/s]
Epoch:  488  	Training Loss: 0.002114163711667061
Test Loss:  0.002065706066787243
Valid Loss:  0.0022262379061430693
Epoch:  489  	Training Loss: 0.00211395719088614
Test Loss:  0.002065677661448717
Valid Loss:  0.002226361073553562
Epoch:  490  	Training Loss: 0.002113750670105219
Test Loss:  0.002065656241029501
Valid Loss:  0.0022264625877141953
Epoch:  491  	Training Loss: 0.0021135464776307344
Test Loss:  0.002065638778731227
Valid Loss:  0.002226544776931405
Epoch:  492  	Training Loss: 0.0021133434493094683
Test Loss:  0.0020656425040215254
Valid Loss:  0.0022265329025685787
Epoch:  493  	Training Loss: 0.002113138325512409
Test Loss:  0.0020656436681747437
Valid Loss:  0.0022265214938670397
Epoch:  494  	Training Loss: 0.0021129348315298557
Test Loss:  0.0020656478591263294
Valid Loss:  0.0022265075240284204
Epoch:  495  	Training Loss: 0.0021127345971763134
Test Loss:  0.0020656511187553406
Valid Loss:  0.002226495649665594
Epoch:  496  	Training Loss: 0.0021126032806932926
Test Loss:  0.002065652282908559
Valid Loss:  0.0022264872677624226
Epoch:  497  	Training Loss: 0.0021126000210642815
Test Loss:  0.002065651584416628
Valid Loss:  0.0022264784201979637
Epoch:  498  	Training Loss: 0.002112596994265914
Test Loss:  0.002065651584416628
Valid Loss:  0.0022264698054641485
Epoch:  499  	Training Loss: 0.002112593501806259
Test Loss:  0.002065652050077915
Valid Loss:  0.0022264616563916206
Epoch:  500  	Training Loss: 0.002112590242177248
Test Loss:  0.002065652282908559
Valid Loss:  0.0022264537401497364
seed is  16
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.16it/s]  1%|          | 4/500 [00:00<00:31, 15.68it/s]  1%|          | 6/500 [00:00<00:31, 15.80it/s]  2%|▏         | 8/500 [00:00<00:30, 16.02it/s]  2%|▏         | 10/500 [00:00<00:30, 15.95it/s]  2%|▏         | 12/500 [00:00<00:30, 15.88it/s]  3%|▎         | 14/500 [00:00<00:30, 15.83it/s]  3%|▎         | 16/500 [00:01<00:30, 15.93it/s]  4%|▎         | 18/500 [00:01<00:30, 15.56it/s]  4%|▍         | 20/500 [00:01<00:33, 14.48it/s]  4%|▍         | 22/500 [00:01<00:32, 14.91it/s]  5%|▍         | 24/500 [00:01<00:31, 15.24it/s]  5%|▌         | 26/500 [00:01<00:30, 15.54it/s]  6%|▌         | 28/500 [00:01<00:30, 15.53it/s]  6%|▌         | 30/500 [00:01<00:30, 15.36it/s]  6%|▋         | 32/500 [00:02<00:31, 15.07it/s]  7%|▋         | 34/500 [00:02<00:30, 15.14it/s]  7%|▋         | 36/500 [00:02<00:30, 15.42it/s]  8%|▊         | 38/500 [00:02<00:29, 15.63it/s]  8%|▊         | 40/500 [00:02<00:29, 15.41it/s]  8%|▊         | 42/500 [00:02<00:29, 15.51it/s]  9%|▉         | 44/500 [00:02<00:29, 15.57it/s]  9%|▉         | 46/500 [00:02<00:28, 15.75it/s] 10%|▉         | 48/500 [00:03<00:28, 15.91it/s] 10%|█         | 50/500 [00:03<00:28, 16.02it/s] 10%|█         | 52/500 [00:03<00:27, 16.08it/s] 11%|█         | 54/500 [00:03<00:27, 16.11it/s] 11%|█         | 56/500 [00:03<00:27, 16.03it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.11it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.08it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.07it/s] 13%|█▎        | 64/500 [00:04<00:27, 16.09it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.96it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.98it/s] 14%|█▍        | 70/500 [00:04<00:26, 15.98it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.89it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.99it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.05it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.07it/s] 16%|█▌        | 80/500 [00:05<00:26, 16.05it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.09it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.13it/s] 17%|█▋        | 86/500 [00:05<00:25, 15.98it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.03it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.95it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.69it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.71it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.79it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.98it/s] 20%|██        | 100/500 [00:06<00:26, 15.01it/s] 20%|██        | 102/500 [00:06<00:28, 14.07it/s] 21%|██        | 104/500 [00:06<00:29, 13.42it/s] 21%|██        | 106/500 [00:06<00:30, 13.10it/s] 22%|██▏       | 108/500 [00:06<00:28, 13.83it/s] 22%|██▏       | 110/500 [00:07<00:27, 14.33it/s] 22%|██▏       | 112/500 [00:07<00:26, 14.55it/s] 23%|██▎       | 114/500 [00:07<00:25, 15.05it/s] 23%|██▎       | 116/500 [00:07<00:25, 15.25it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.56it/s] 24%|██▍       | 120/500 [00:07<00:24, 15.79it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.94it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.05it/s]Epoch:  1  	Training Loss: 0.5022580623626709
Test Loss:  5143.76171875
Valid Loss:  5161.22802734375
Epoch:  2  	Training Loss: 5121.369140625
Test Loss:  2.95845621173479e+18
Valid Loss:  2.8980245787710587e+18
Epoch:  3  	Training Loss: 2.937709251952378e+18
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 15.94it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.02it/s] 26%|██▌       | 130/500 [00:08<00:23, 16.06it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.08it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.05it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.02it/s] 28%|██▊       | 138/500 [00:08<00:23, 15.21it/s] 28%|██▊       | 140/500 [00:09<00:23, 15.47it/s] 28%|██▊       | 142/500 [00:09<00:23, 15.45it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.62it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.46it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.59it/s] 30%|███       | 150/500 [00:09<00:22, 15.59it/s] 30%|███       | 152/500 [00:09<00:22, 15.67it/s] 31%|███       | 154/500 [00:09<00:21, 15.83it/s] 31%|███       | 156/500 [00:10<00:21, 15.99it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.06it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.13it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.16it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.20it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.17it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.14it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.05it/s] 34%|███▍      | 172/500 [00:11<00:20, 15.82it/s] 35%|███▍      | 174/500 [00:11<00:22, 14.41it/s] 35%|███▌      | 176/500 [00:11<00:23, 13.67it/s] 36%|███▌      | 178/500 [00:11<00:24, 13.23it/s] 36%|███▌      | 180/500 [00:11<00:23, 13.69it/s] 36%|███▋      | 182/500 [00:11<00:22, 14.16it/s] 37%|███▋      | 184/500 [00:11<00:23, 13.40it/s] 37%|███▋      | 186/500 [00:12<00:24, 13.01it/s] 38%|███▊      | 188/500 [00:12<00:24, 12.65it/s] 38%|███▊      | 190/500 [00:12<00:24, 12.50it/s] 38%|███▊      | 192/500 [00:12<00:25, 12.21it/s] 39%|███▉      | 194/500 [00:12<00:23, 12.99it/s] 39%|███▉      | 196/500 [00:12<00:22, 13.45it/s] 40%|███▉      | 198/500 [00:12<00:21, 14.18it/s] 40%|████      | 200/500 [00:13<00:20, 14.67it/s] 40%|████      | 202/500 [00:13<00:19, 15.16it/s] 41%|████      | 204/500 [00:13<00:19, 15.39it/s] 41%|████      | 206/500 [00:13<00:18, 15.59it/s] 42%|████▏     | 208/500 [00:13<00:19, 14.61it/s] 42%|████▏     | 210/500 [00:13<00:21, 13.70it/s] 42%|████▏     | 212/500 [00:13<00:21, 13.18it/s] 43%|████▎     | 214/500 [00:14<00:21, 13.45it/s] 43%|████▎     | 216/500 [00:14<00:20, 14.13it/s] 44%|████▎     | 218/500 [00:14<00:19, 14.51it/s] 44%|████▍     | 220/500 [00:14<00:18, 14.87it/s] 44%|████▍     | 222/500 [00:14<00:18, 15.25it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.55it/s] 45%|████▌     | 226/500 [00:14<00:18, 14.76it/s] 46%|████▌     | 228/500 [00:15<00:18, 14.73it/s] 46%|████▌     | 230/500 [00:15<00:17, 15.05it/s] 46%|████▋     | 232/500 [00:15<00:17, 15.31it/s] 47%|████▋     | 234/500 [00:15<00:17, 15.39it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.57it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.61it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.59it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.56it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.78it/s] 49%|████▉     | 246/500 [00:16<00:16, 15.87it/s] 50%|████▉     | 248/500 [00:16<00:15, 15.88it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 15.70it/s] 50%|█████     | 252/500 [00:16<00:15, 15.79it/s] 51%|█████     | 254/500 [00:16<00:15, 15.82it/s] 51%|█████     | 256/500 [00:16<00:15, 15.65it/s] 52%|█████▏    | 258/500 [00:16<00:16, 14.84it/s] 52%|█████▏    | 260/500 [00:17<00:17, 13.85it/s] 52%|█████▏    | 262/500 [00:17<00:17, 13.37it/s] 53%|█████▎    | 264/500 [00:17<00:17, 13.49it/s] 53%|█████▎    | 266/500 [00:17<00:16, 14.11it/s] 54%|█████▎    | 268/500 [00:17<00:16, 14.49it/s] 54%|█████▍    | 270/500 [00:17<00:15, 14.83it/s] 54%|█████▍    | 272/500 [00:17<00:15, 14.77it/s] 55%|█████▍    | 274/500 [00:18<00:15, 15.06it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.14it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.50it/s] 56%|█████▌    | 280/500 [00:18<00:14, 15.61it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.83it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.87it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.01it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.92it/s] 58%|█████▊    | 290/500 [00:19<00:13, 15.76it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.75it/s] 59%|█████▉    | 294/500 [00:19<00:12, 15.87it/s] 59%|█████▉    | 296/500 [00:19<00:12, 16.03it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.94it/s] 60%|██████    | 300/500 [00:19<00:12, 16.01it/s] 60%|██████    | 302/500 [00:19<00:12, 16.00it/s] 61%|██████    | 304/500 [00:19<00:12, 15.19it/s] 61%|██████    | 306/500 [00:20<00:12, 15.52it/s] 62%|██████▏   | 308/500 [00:20<00:12, 15.72it/s] 62%|██████▏   | 310/500 [00:20<00:11, 15.92it/s] 62%|██████▏   | 312/500 [00:20<00:11, 15.84it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.75it/s] 63%|██████▎   | 316/500 [00:20<00:12, 14.55it/s] 64%|██████▎   | 318/500 [00:20<00:12, 14.81it/s] 64%|██████▍   | 320/500 [00:21<00:12, 14.79it/s] 64%|██████▍   | 322/500 [00:21<00:12, 14.77it/s] 65%|██████▍   | 324/500 [00:21<00:11, 15.20it/s] 65%|██████▌   | 326/500 [00:21<00:11, 15.40it/s] 66%|██████▌   | 328/500 [00:21<00:10, 15.66it/s] 66%|██████▌   | 330/500 [00:21<00:10, 15.91it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.96it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.08it/s] 67%|██████▋   | 336/500 [00:22<00:10, 16.07it/s] 68%|██████▊   | 338/500 [00:22<00:10, 16.05it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.81it/s] 68%|██████▊   | 342/500 [00:22<00:09, 15.92it/s] 69%|██████▉   | 344/500 [00:22<00:09, 15.98it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.00it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.04it/s] 70%|███████   | 350/500 [00:22<00:09, 16.04it/s] 70%|███████   | 352/500 [00:23<00:09, 16.13it/s] 71%|███████   | 354/500 [00:23<00:09, 15.82it/s] 71%|███████   | 356/500 [00:23<00:09, 15.46it/s] 72%|███████▏  | 358/500 [00:23<00:09, 15.65it/s] 72%|███████▏  | 360/500 [00:23<00:08, 15.71it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.55it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.73it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.79it/s] 74%|███████▎  | 368/500 [00:24<00:08, 15.98it/s] 74%|███████▍  | 370/500 [00:24<00:08, 16.00it/s] 74%|███████▍  | 372/500 [00:24<00:08, 14.77it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:08, 14.10it/s] 75%|███████▌  | 376/500 [00:24<00:08, 14.67it/s] 76%|███████▌  | 378/500 [00:24<00:08, 15.05it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.29it/s] 76%|███████▋  | 382/500 [00:25<00:07, 14.98it/s] 77%|███████▋  | 384/500 [00:25<00:07, 15.08it/s] 77%|███████▋  | 386/500 [00:25<00:07, 14.45it/s] 78%|███████▊  | 388/500 [00:25<00:08, 13.65it/s] 78%|███████▊  | 390/500 [00:25<00:08, 13.20it/s] 78%|███████▊  | 392/500 [00:25<00:08, 12.68it/s] 79%|███████▉  | 394/500 [00:25<00:07, 13.25it/s] 79%|███████▉  | 396/500 [00:26<00:07, 13.79it/s] 80%|███████▉  | 398/500 [00:26<00:07, 14.44it/s] 80%|████████  | 400/500 [00:26<00:06, 14.86it/s] 80%|████████  | 402/500 [00:26<00:06, 15.18it/s] 81%|████████  | 404/500 [00:26<00:06, 15.27it/s] 81%|████████  | 406/500 [00:26<00:06, 15.06it/s] 82%|████████▏ | 408/500 [00:26<00:06, 15.21it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.39it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.67it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.83it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.80it/s] 84%|████████▎ | 418/500 [00:27<00:05, 15.35it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.49it/s] 84%|████████▍ | 422/500 [00:27<00:05, 15.53it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.69it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.67it/s] 86%|████████▌ | 428/500 [00:28<00:04, 15.89it/s] 86%|████████▌ | 430/500 [00:28<00:04, 16.00it/s] 86%|████████▋ | 432/500 [00:28<00:04, 15.46it/s] 87%|████████▋ | 434/500 [00:28<00:04, 15.55it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.72it/s] 88%|████████▊ | 438/500 [00:28<00:03, 15.53it/s] 88%|████████▊ | 440/500 [00:28<00:03, 15.74it/s] 88%|████████▊ | 442/500 [00:28<00:03, 15.93it/s] 89%|████████▉ | 444/500 [00:29<00:03, 14.83it/s] 89%|████████▉ | 446/500 [00:29<00:03, 13.94it/s] 90%|████████▉ | 448/500 [00:29<00:03, 14.05it/s] 90%|█████████ | 450/500 [00:29<00:03, 14.60it/s] 90%|█████████ | 452/500 [00:29<00:03, 14.98it/s] 91%|█████████ | 454/500 [00:29<00:03, 14.76it/s] 91%|█████████ | 456/500 [00:30<00:03, 13.92it/s] 92%|█████████▏| 458/500 [00:30<00:02, 14.09it/s] 92%|█████████▏| 460/500 [00:30<00:02, 14.61it/s] 92%|█████████▏| 462/500 [00:30<00:02, 15.04it/s] 93%|█████████▎| 464/500 [00:30<00:02, 15.33it/s] 93%|█████████▎| 466/500 [00:30<00:02, 15.51it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.54it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.68it/s] 94%|█████████▍| 472/500 [00:31<00:01, 15.85it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.96it/s] 95%|█████████▌| 476/500 [00:31<00:01, 16.04it/s] 96%|█████████▌| 478/500 [00:31<00:01, 16.09it/s] 96%|█████████▌| 480/500 [00:31<00:01, 16.14it/s] 96%|█████████▋| 482/500 [00:31<00:01, 16.08it/s] 97%|█████████▋| 484/500 [00:31<00:01, 15.04it/s] 97%|█████████▋| 486/500 [00:31<00:01, 13.96it/s] 98%|█████████▊| 488/500 [00:32<00:00, 13.37it/s] 98%|█████████▊| 490/500 [00:32<00:00, 13.01it/s] 98%|█████████▊| 492/500 [00:32<00:00, 12.73it/s] 99%|█████████▉| 494/500 [00:32<00:00, 12.59it/s] 99%|█████████▉| 496/500 [00:32<00:00, 12.49it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 12.37it/s]100%|██████████| 500/500 [00:33<00:00, 12.92it/s]100%|██████████| 500/500 [00:33<00:00, 15.12it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  16
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:56,  6.37s/it]  1%|          | 3/500 [00:06<14:05,  1.70s/it]  1%|          | 5/500 [00:06<07:06,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.84it/s]  2%|▏         | 11/500 [00:13<10:56,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:14,  1.54it/s]  3%|▎         | 17/500 [00:13<03:47,  2.13it/s]  4%|▍         | 19/500 [00:13<02:46,  2.88it/s]  4%|▍         | 21/500 [00:20<09:52,  1.24s/it]  5%|▍         | 23/500 [00:20<07:00,  1.13it/s]  5%|▌         | 25/500 [00:20<05:01,  1.58it/s]  5%|▌         | 27/500 [00:20<03:38,  2.16it/s]  6%|▌         | 29/500 [00:20<02:42,  2.91it/s]  6%|▌         | 31/500 [00:27<09:20,  1.20s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:27<04:47,  1.61it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:35,  2.96it/s]  8%|▊         | 41/500 [00:34<09:07,  1.19s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:43,  1.60it/s]  9%|▉         | 47/500 [00:34<03:26,  2.19it/s] 10%|▉         | 49/500 [00:34<02:32,  2.95it/s] 10%|█         | 51/500 [00:41<08:55,  1.19s/it] 11%|█         | 53/500 [00:41<06:24,  1.16it/s] 11%|█         | 55/500 [00:41<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:41<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:48<08:45,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:15,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:48<03:17,  2.20it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.96it/s] 14%|█▍        | 71/500 [00:55<08:31,  1.19s/it] 15%|█▍        | 73/500 [00:55<06:05,  1.17it/s]Epoch:  1  	Training Loss: 0.5022580623626709
Test Loss:  147.33670043945312
Valid Loss:  141.83370971679688
Epoch:  2  	Training Loss: 143.7503662109375
Test Loss:  0.46453312039375305
Valid Loss:  0.44547101855278015
Epoch:  3  	Training Loss: 0.3779836595058441
Test Loss:  0.46080055832862854
Valid Loss:  0.4418410658836365
Epoch:  4  	Training Loss: 0.3748438358306885
Test Loss:  0.4607967138290405
Valid Loss:  0.44183769822120667
Epoch:  5  	Training Loss: 0.37483882904052734
Test Loss:  0.4607928395271301
Valid Loss:  0.44183433055877686
Epoch:  6  	Training Loss: 0.3748337924480438
Test Loss:  0.4607889652252197
Valid Loss:  0.44183093309402466
Epoch:  7  	Training Loss: 0.3748287558555603
Test Loss:  0.4607851505279541
Valid Loss:  0.44182753562927246
Epoch:  8  	Training Loss: 0.37482374906539917
Test Loss:  0.4607812762260437
Valid Loss:  0.44182419776916504
Epoch:  9  	Training Loss: 0.37481874227523804
Test Loss:  0.4607774019241333
Valid Loss:  0.44182077050209045
Epoch:  10  	Training Loss: 0.3748137056827545
Test Loss:  0.4607735574245453
Valid Loss:  0.44181740283966064
Epoch:  11  	Training Loss: 0.37480872869491577
Test Loss:  0.4607696533203125
Valid Loss:  0.44181403517723083
Epoch:  12  	Training Loss: 0.37480366230010986
Test Loss:  0.46075737476348877
Valid Loss:  0.44180214405059814
Epoch:  13  	Training Loss: 0.3747866451740265
Test Loss:  0.4607449769973755
Valid Loss:  0.44179022312164307
Epoch:  14  	Training Loss: 0.37476956844329834
Test Loss:  0.4607326090335846
Valid Loss:  0.4417783319950104
Epoch:  15  	Training Loss: 0.37475186586380005
Test Loss:  0.46071863174438477
Valid Loss:  0.4417658746242523
Epoch:  16  	Training Loss: 0.37473297119140625
Test Loss:  0.4607042670249939
Valid Loss:  0.4417533874511719
Epoch:  17  	Training Loss: 0.3747138977050781
Test Loss:  0.46068933606147766
Valid Loss:  0.441740483045578
Epoch:  18  	Training Loss: 0.37469345331192017
Test Loss:  0.46067243814468384
Valid Loss:  0.4417269825935364
Epoch:  19  	Training Loss: 0.37467139959335327
Test Loss:  0.4606552720069885
Valid Loss:  0.4417119324207306
Epoch:  20  	Training Loss: 0.3746488094329834
Test Loss:  0.46063780784606934
Valid Loss:  0.4416966438293457
Epoch:  21  	Training Loss: 0.3746255040168762
Test Loss:  0.4606182277202606
Valid Loss:  0.4416801333427429
Epoch:  22  	Training Loss: 0.37460121512413025
Test Loss:  0.46059679985046387
Valid Loss:  0.44166260957717896
Epoch:  23  	Training Loss: 0.37457597255706787
Test Loss:  0.4605749249458313
Valid Loss:  0.44164320826530457
Epoch:  24  	Training Loss: 0.37455010414123535
Test Loss:  0.46055275201797485
Valid Loss:  0.4416219890117645
Epoch:  25  	Training Loss: 0.37452268600463867
Test Loss:  0.4605293869972229
Valid Loss:  0.4415992796421051
Epoch:  26  	Training Loss: 0.37449321150779724
Test Loss:  0.4605056643486023
Valid Loss:  0.4415762424468994
Epoch:  27  	Training Loss: 0.37446290254592896
Test Loss:  0.4604819118976593
Valid Loss:  0.4415517747402191
Epoch:  28  	Training Loss: 0.37443217635154724
Test Loss:  0.46045738458633423
Valid Loss:  0.4415258765220642
Epoch:  29  	Training Loss: 0.3743988871574402
Test Loss:  0.46043017506599426
Valid Loss:  0.4414987564086914
Epoch:  30  	Training Loss: 0.3743632137775421
Test Loss:  0.46040165424346924
Valid Loss:  0.4414711594581604
Epoch:  31  	Training Loss: 0.3743264377117157
Test Loss:  0.4603731334209442
Valid Loss:  0.44144362211227417
Epoch:  32  	Training Loss: 0.37428969144821167
Test Loss:  0.46034717559814453
Valid Loss:  0.44141823053359985
Epoch:  33  	Training Loss: 0.3742554187774658
Test Loss:  0.460318386554718
Valid Loss:  0.4413900077342987
Epoch:  34  	Training Loss: 0.37421879172325134
Test Loss:  0.4602887034416199
Valid Loss:  0.4413609504699707
Epoch:  35  	Training Loss: 0.3741796016693115
Test Loss:  0.4602575898170471
Valid Loss:  0.4413303732872009
Epoch:  36  	Training Loss: 0.3741374611854553
Test Loss:  0.46022549271583557
Valid Loss:  0.4412964880466461
Epoch:  37  	Training Loss: 0.37409234046936035
Test Loss:  0.4601925015449524
Valid Loss:  0.441261351108551
Epoch:  38  	Training Loss: 0.37404465675354004
Test Loss:  0.4601570963859558
Valid Loss:  0.4412219822406769
Epoch:  39  	Training Loss: 0.3739924430847168
Test Loss:  0.46011850237846375
Valid Loss:  0.4411815106868744
Epoch:  40  	Training Loss: 0.3739382028579712
Test Loss:  0.46007877588272095
Valid Loss:  0.4411410093307495
Epoch:  41  	Training Loss: 0.37388303875923157
Test Loss:  0.4600331783294678
Valid Loss:  0.4410993456840515
Epoch:  42  	Training Loss: 0.37382543087005615
Test Loss:  0.4599977731704712
Valid Loss:  0.4410666823387146
Epoch:  43  	Training Loss: 0.3737788200378418
Test Loss:  0.4599587321281433
Valid Loss:  0.4410327970981598
Epoch:  44  	Training Loss: 0.3737296164035797
Test Loss:  0.4599164128303528
Valid Loss:  0.440998911857605
Epoch:  45  	Training Loss: 0.3736804127693176
Test Loss:  0.45987212657928467
Valid Loss:  0.44096463918685913
Epoch:  46  	Training Loss: 0.3736282289028168
Test Loss:  0.4598248302936554
Valid Loss:  0.44092822074890137
Epoch:  47  	Training Loss: 0.3735705018043518
Test Loss:  0.4597758650779724
Valid Loss:  0.4408876597881317
Epoch:  48  	Training Loss: 0.37350723147392273
Test Loss:  0.4597232937812805
Valid Loss:  0.4408411383628845
Epoch:  49  	Training Loss: 0.37343692779541016
Test Loss:  0.4596700966358185
Valid Loss:  0.44079408049583435
Epoch:  50  	Training Loss: 0.37336286902427673
Test Loss:  0.45961278676986694
Valid Loss:  0.44074445962905884
Epoch:  51  	Training Loss: 0.373280793428421
Test Loss:  0.45954787731170654
Valid Loss:  0.4406926929950714
Epoch:  52  	Training Loss: 0.37319302558898926
Test Loss:  0.45948970317840576
Valid Loss:  0.44064533710479736
Epoch:  53  	Training Loss: 0.3731116056442261
Test Loss:  0.45941871404647827
Valid Loss:  0.44059422612190247
Epoch:  54  	Training Loss: 0.3730252683162689
Test Loss:  0.45933669805526733
Valid Loss:  0.4405404329299927
Epoch:  55  	Training Loss: 0.37293893098831177
Test Loss:  0.45925235748291016
Valid Loss:  0.4404834508895874
Epoch:  56  	Training Loss: 0.3728526830673218
Test Loss:  0.4591636657714844
Valid Loss:  0.4404247999191284
Epoch:  57  	Training Loss: 0.3727661073207855
Test Loss:  0.45907366275787354
Valid Loss:  0.44036564230918884
Epoch:  58  	Training Loss: 0.37267807126045227
Test Loss:  0.45897936820983887
Valid Loss:  0.4403046667575836
Epoch:  59  	Training Loss: 0.37258848547935486
Test Loss:  0.45888158679008484
Valid Loss:  0.4402409791946411
Epoch:  60  	Training Loss: 0.3724973499774933
Test Loss:  0.458778977394104
Valid Loss:  0.440177321434021
Epoch:  61  	Training Loss: 0.37240585684776306
Test Loss:  0.4586713910102844
Valid Loss:  0.44011250138282776
Epoch:  62  	Training Loss: 0.3723107576370239
Test Loss:  0.45855873823165894
Valid Loss:  0.44004154205322266
Epoch:  63  	Training Loss: 0.3722049295902252
Test Loss:  0.45844200253486633
Valid Loss:  0.4399694800376892
Epoch:  64  	Training Loss: 0.37209489941596985
Test Loss:  0.4583139419555664
Valid Loss:  0.4398963153362274
Epoch:  65  	Training Loss: 0.3719817101955414
Test Loss:  0.4581797122955322
Valid Loss:  0.43982142210006714
Epoch:  66  	Training Loss: 0.3718627095222473
Test Loss:  0.45804277062416077
Valid Loss:  0.4397408366203308
Epoch:  67  	Training Loss: 0.3717394471168518
Test Loss:  0.4578978419303894
Valid Loss:  0.43964600563049316
Epoch:  68  	Training Loss: 0.37161362171173096
Test Loss:  0.4577491879463196
Valid Loss:  0.4395456910133362
Epoch:  69  	Training Loss: 0.3714841604232788
Test Loss:  0.4575982391834259
Valid Loss:  0.43944215774536133
Epoch:  70  	Training Loss: 0.3713510036468506
Test Loss:  0.4574473798274994
Valid Loss:  0.43933871388435364
Epoch:  71  	Training Loss: 0.3712172210216522
Test Loss:  0.4572933614253998
Valid Loss:  0.43923455476760864
Epoch:  72  	Training Loss: 0.3710809350013733
Test Loss:  0.45711320638656616
Valid Loss:  0.43911421298980713
Epoch:  73  	Training Loss: 0.3709207773208618
Test Loss:  0.45693057775497437
Valid Loss:  0.4389877915382385
Epoch:  74  	Training Loss: 0.3707573711872101
Test Loss:  0.4567463994026184
 15%|█▌        | 75/500 [00:55<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:11,  2.21it/s] 16%|█▌        | 79/500 [00:55<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:01<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:02<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:20,  1.59it/s] 17%|█▋        | 87/500 [01:02<03:09,  2.18it/s] 18%|█▊        | 89/500 [01:02<02:20,  2.93it/s] 18%|█▊        | 91/500 [01:08<08:12,  1.20s/it] 19%|█▊        | 93/500 [01:09<05:51,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:06,  2.16it/s] 20%|█▉        | 99/500 [01:09<02:18,  2.91it/s] 20%|██        | 101/500 [01:15<07:56,  1.19s/it] 21%|██        | 103/500 [01:16<05:40,  1.17it/s] 21%|██        | 105/500 [01:16<04:04,  1.61it/s] 21%|██▏       | 107/500 [01:16<02:58,  2.21it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:22<07:44,  1.19s/it] 23%|██▎       | 113/500 [01:22<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:23<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:23<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:23<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:29<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:29<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:30<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:30<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:36<07:21,  1.20s/it] 27%|██▋       | 133/500 [01:36<05:17,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:47,  1.60it/s] 27%|██▋       | 137/500 [01:37<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:37<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:43<07:14,  1.21s/it] 29%|██▊       | 143/500 [01:43<05:10,  1.15it/s] 29%|██▉       | 145/500 [01:43<03:42,  1.59it/s]Valid Loss:  0.43885546922683716
Epoch:  75  	Training Loss: 0.37058964371681213
Test Loss:  0.4565544128417969
Valid Loss:  0.43871134519577026
Epoch:  76  	Training Loss: 0.37041693925857544
Test Loss:  0.45636123418807983
Valid Loss:  0.43856412172317505
Epoch:  77  	Training Loss: 0.3702424466609955
Test Loss:  0.4561624228954315
Valid Loss:  0.43841293454170227
Epoch:  78  	Training Loss: 0.37006595730781555
Test Loss:  0.4559553861618042
Valid Loss:  0.4382527470588684
Epoch:  79  	Training Loss: 0.3698861598968506
Test Loss:  0.4557415246963501
Valid Loss:  0.4380834698677063
Epoch:  80  	Training Loss: 0.3697013258934021
Test Loss:  0.45551222562789917
Valid Loss:  0.43790706992149353
Epoch:  81  	Training Loss: 0.3695083558559418
Test Loss:  0.45527762174606323
Valid Loss:  0.43772774934768677
Epoch:  82  	Training Loss: 0.36931169033050537
Test Loss:  0.4550544023513794
Valid Loss:  0.4375585913658142
Epoch:  83  	Training Loss: 0.36913472414016724
Test Loss:  0.45482420921325684
Valid Loss:  0.43736928701400757
Epoch:  84  	Training Loss: 0.36894822120666504
Test Loss:  0.45458680391311646
Valid Loss:  0.43715900182724
Epoch:  85  	Training Loss: 0.3687516450881958
Test Loss:  0.4543367624282837
Valid Loss:  0.4369366466999054
Epoch:  86  	Training Loss: 0.36854445934295654
Test Loss:  0.454081654548645
Valid Loss:  0.43670570850372314
Epoch:  87  	Training Loss: 0.36833229660987854
Test Loss:  0.4538196325302124
Valid Loss:  0.43646737933158875
Epoch:  88  	Training Loss: 0.36811763048171997
Test Loss:  0.4535489082336426
Valid Loss:  0.4362117648124695
Epoch:  89  	Training Loss: 0.3678915500640869
Test Loss:  0.45324599742889404
Valid Loss:  0.435932993888855
Epoch:  90  	Training Loss: 0.36764320731163025
Test Loss:  0.4529346525669098
Valid Loss:  0.4356446862220764
Epoch:  91  	Training Loss: 0.36739102005958557
Test Loss:  0.45260363817214966
Valid Loss:  0.4353337585926056
Epoch:  92  	Training Loss: 0.3671199679374695
Test Loss:  0.45217031240463257
Valid Loss:  0.43489933013916016
Epoch:  93  	Training Loss: 0.36677372455596924
Test Loss:  0.4517374038696289
Valid Loss:  0.4344653785228729
Epoch:  94  	Training Loss: 0.36642777919769287
Test Loss:  0.45130491256713867
Valid Loss:  0.43403181433677673
Epoch:  95  	Training Loss: 0.3660821318626404
Test Loss:  0.45087283849716187
Valid Loss:  0.43359869718551636
Epoch:  96  	Training Loss: 0.3657369017601013
Test Loss:  0.4504412114620209
Valid Loss:  0.4331660270690918
Epoch:  97  	Training Loss: 0.36539196968078613
Test Loss:  0.4500100016593933
Valid Loss:  0.43273377418518066
Epoch:  98  	Training Loss: 0.3650473952293396
Test Loss:  0.4495791494846344
Valid Loss:  0.43230193853378296
Epoch:  99  	Training Loss: 0.36470305919647217
Test Loss:  0.4491487741470337
Valid Loss:  0.43187057971954346
Epoch:  100  	Training Loss: 0.36435914039611816
Test Loss:  0.4487188458442688
Valid Loss:  0.4314396381378174
Epoch:  101  	Training Loss: 0.3640155494213104
Test Loss:  0.44828933477401733
Valid Loss:  0.43100911378860474
Epoch:  102  	Training Loss: 0.36367228627204895
Test Loss:  0.4479055106639862
Valid Loss:  0.43062683939933777
Epoch:  103  	Training Loss: 0.3633621335029602
Test Loss:  0.44752204418182373
Valid Loss:  0.43024489283561707
Epoch:  104  	Training Loss: 0.36305224895477295
Test Loss:  0.4471389353275299
Valid Loss:  0.429863303899765
Epoch:  105  	Training Loss: 0.3627426028251648
Test Loss:  0.44675612449645996
Valid Loss:  0.4294820725917816
Epoch:  106  	Training Loss: 0.3624332547187805
Test Loss:  0.44637367129325867
Valid Loss:  0.4291011691093445
Epoch:  107  	Training Loss: 0.3621242046356201
Test Loss:  0.445991575717926
Valid Loss:  0.4287205934524536
Epoch:  108  	Training Loss: 0.3618153929710388
Test Loss:  0.4456097483634949
Valid Loss:  0.4283403754234314
Epoch:  109  	Training Loss: 0.3615068197250366
Test Loss:  0.4452282786369324
Valid Loss:  0.4279603958129883
Epoch:  110  	Training Loss: 0.3611985445022583
Test Loss:  0.4448471665382385
Valid Loss:  0.427580863237381
Epoch:  111  	Training Loss: 0.36089053750038147
Test Loss:  0.44446632266044617
Valid Loss:  0.42720162868499756
Epoch:  112  	Training Loss: 0.36058276891708374
Test Loss:  0.4441125988960266
Valid Loss:  0.42685115337371826
Epoch:  113  	Training Loss: 0.3602942228317261
Test Loss:  0.44375908374786377
Valid Loss:  0.42650097608566284
Epoch:  114  	Training Loss: 0.3600059151649475
Test Loss:  0.4434059262275696
Valid Loss:  0.4261510670185089
Epoch:  115  	Training Loss: 0.35971787571907043
Test Loss:  0.4430530369281769
Valid Loss:  0.42580145597457886
Epoch:  116  	Training Loss: 0.3594300448894501
Test Loss:  0.44270044565200806
Valid Loss:  0.42545217275619507
Epoch:  117  	Training Loss: 0.3591424524784088
Test Loss:  0.4423481225967407
Valid Loss:  0.4251031279563904
Epoch:  118  	Training Loss: 0.35885506868362427
Test Loss:  0.44199612736701965
Valid Loss:  0.42475444078445435
Epoch:  119  	Training Loss: 0.3585679829120636
Test Loss:  0.4416444003582001
Valid Loss:  0.4244059920310974
Epoch:  120  	Training Loss: 0.35828113555908203
Test Loss:  0.441292941570282
Valid Loss:  0.42405784130096436
Epoch:  121  	Training Loss: 0.3579944372177124
Test Loss:  0.44094181060791016
Valid Loss:  0.4237099587917328
Epoch:  122  	Training Loss: 0.35770803689956665
Test Loss:  0.4406075179576874
Valid Loss:  0.42338013648986816
Epoch:  123  	Training Loss: 0.3574334383010864
Test Loss:  0.4402735233306885
Valid Loss:  0.4230506718158722
Epoch:  124  	Training Loss: 0.3571591079235077
Test Loss:  0.43993979692459106
Valid Loss:  0.4227214455604553
Epoch:  125  	Training Loss: 0.3568849563598633
Test Loss:  0.43960630893707275
Valid Loss:  0.42239245772361755
Epoch:  126  	Training Loss: 0.356611043214798
Test Loss:  0.43927308917045593
Valid Loss:  0.4220637381076813
Epoch:  127  	Training Loss: 0.3563373386859894
Test Loss:  0.4389401376247406
Valid Loss:  0.4217352867126465
Epoch:  128  	Training Loss: 0.3560638427734375
Test Loss:  0.438607394695282
Valid Loss:  0.4214070439338684
Epoch:  129  	Training Loss: 0.35579055547714233
Test Loss:  0.43827494978904724
Valid Loss:  0.4210790991783142
Epoch:  130  	Training Loss: 0.3555174469947815
Test Loss:  0.4379427433013916
Valid Loss:  0.4207513630390167
Epoch:  131  	Training Loss: 0.35524457693099976
Test Loss:  0.43761080503463745
Valid Loss:  0.4204239249229431
Epoch:  132  	Training Loss: 0.3549719750881195
Test Loss:  0.43728959560394287
Valid Loss:  0.42010805010795593
Epoch:  133  	Training Loss: 0.35470664501190186
Test Loss:  0.436968594789505
Valid Loss:  0.41979244351387024
Epoch:  134  	Training Loss: 0.35444149374961853
Test Loss:  0.43664783239364624
Valid Loss:  0.41947704553604126
Epoch:  135  	Training Loss: 0.3541765511035919
Test Loss:  0.43632733821868896
Valid Loss:  0.41916191577911377
Epoch:  136  	Training Loss: 0.3539118468761444
Test Loss:  0.436007022857666
Valid Loss:  0.4188469648361206
Epoch:  137  	Training Loss: 0.35364729166030884
Test Loss:  0.43568700551986694
Valid Loss:  0.4185323119163513
Epoch:  138  	Training Loss: 0.35338294506073
Test Loss:  0.4353671967983246
Valid Loss:  0.41821789741516113
Epoch:  139  	Training Loss: 0.3531188368797302
Test Loss:  0.43504762649536133
Valid Loss:  0.4179036617279053
Epoch:  140  	Training Loss: 0.3528549075126648
Test Loss:  0.4347282946109772
Valid Loss:  0.4175897240638733
Epoch:  141  	Training Loss: 0.3525910973548889
Test Loss:  0.4344092011451721
Valid Loss:  0.417275995016098
Epoch:  142  	Training Loss: 0.3523275852203369
Test Loss:  0.4340977668762207
Valid Loss:  0.41697055101394653
Epoch:  143  	Training Loss: 0.35206925868988037
Test Loss:  0.4337866008281708
Valid Loss:  0.41666534543037415
Epoch:  144  	Training Loss: 0.35181111097335815
Test Loss:  0.4334756135940552
Valid Loss:  0.41636037826538086
Epoch:  145  	Training Loss: 0.35155320167541504
Test Loss:  0.43316489458084106
Valid Loss:  0.4160556197166443
Epoch:  146  	Training Loss: 0.3512954115867615
Test Loss:  0.4328543543815613
Valid Loss:  0.41575106978416443
Epoch:  147  	Training Loss: 0.351037859916687
Test Loss:  0.432544082403183
Valid Loss:  0.41544675827026367
 29%|██▉       | 147/500 [01:44<02:42,  2.18it/s] 30%|██▉       | 149/500 [01:44<01:59,  2.93it/s] 30%|███       | 151/500 [01:50<06:59,  1.20s/it] 31%|███       | 153/500 [01:50<04:59,  1.16it/s] 31%|███       | 155/500 [01:50<03:36,  1.59it/s] 31%|███▏      | 157/500 [01:51<02:39,  2.15it/s] 32%|███▏      | 159/500 [01:51<01:58,  2.87it/s] 32%|███▏      | 161/500 [01:57<06:58,  1.23s/it] 33%|███▎      | 163/500 [01:58<04:59,  1.13it/s] 33%|███▎      | 165/500 [01:58<03:35,  1.55it/s] 33%|███▎      | 167/500 [01:58<02:37,  2.12it/s] 34%|███▍      | 169/500 [01:58<01:55,  2.86it/s] 34%|███▍      | 171/500 [02:04<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:04<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:05<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:05<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:05<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:11<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:11<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:12<02:21,  2.20it/s] 38%|███▊      | 189/500 [02:12<01:44,  2.96it/s] 38%|███▊      | 191/500 [02:18<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:18<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:18<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:19<02:21,  2.14it/s] 40%|███▉      | 199/500 [02:19<01:46,  2.84it/s] 40%|████      | 201/500 [02:25<06:01,  1.21s/it] 41%|████      | 203/500 [02:25<04:17,  1.15it/s] 41%|████      | 205/500 [02:26<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:26<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:26<01:39,  2.93it/s] 42%|████▏     | 211/500 [02:32<05:52,  1.22s/it] 43%|████▎     | 213/500 [02:32<04:11,  1.14it/s] 43%|████▎     | 215/500 [02:33<03:00,  1.58it/s] 43%|████▎     | 217/500 [02:33<02:11,  2.15it/s] 44%|████▍     | 219/500 [02:33<01:37,  2.90it/s]Epoch:  148  	Training Loss: 0.3507804870605469
Test Loss:  0.4322340190410614
Valid Loss:  0.4151427149772644
Epoch:  149  	Training Loss: 0.35052329301834106
Test Loss:  0.43192416429519653
Valid Loss:  0.4148388206958771
Epoch:  150  	Training Loss: 0.3502662777900696
Test Loss:  0.4316145181655884
Valid Loss:  0.41453519463539124
Epoch:  151  	Training Loss: 0.3500095009803772
Test Loss:  0.4313051700592041
Valid Loss:  0.4142317473888397
Epoch:  152  	Training Loss: 0.34975287318229675
Test Loss:  0.4310012459754944
Valid Loss:  0.41393429040908813
Epoch:  153  	Training Loss: 0.34950000047683716
Test Loss:  0.43069756031036377
Valid Loss:  0.41363707184791565
Epoch:  154  	Training Loss: 0.3492473065853119
Test Loss:  0.43039411306381226
Valid Loss:  0.4133400321006775
Epoch:  155  	Training Loss: 0.34899482131004333
Test Loss:  0.43009084463119507
Valid Loss:  0.41304323077201843
Epoch:  156  	Training Loss: 0.3487425148487091
Test Loss:  0.429787814617157
Valid Loss:  0.4127466380596161
Epoch:  157  	Training Loss: 0.3484903872013092
Test Loss:  0.4294849932193756
Valid Loss:  0.41245025396347046
Epoch:  158  	Training Loss: 0.348238468170166
Test Loss:  0.42918241024017334
Valid Loss:  0.41215407848358154
Epoch:  159  	Training Loss: 0.3479866683483124
Test Loss:  0.4288800358772278
Valid Loss:  0.41185814142227173
Epoch:  160  	Training Loss: 0.34773507714271545
Test Loss:  0.42857789993286133
Valid Loss:  0.41156238317489624
Epoch:  161  	Training Loss: 0.34748369455337524
Test Loss:  0.4282759428024292
Valid Loss:  0.41126686334609985
Epoch:  162  	Training Loss: 0.34723249077796936
Test Loss:  0.4279782474040985
Valid Loss:  0.41097596287727356
Epoch:  163  	Training Loss: 0.34698420763015747
Test Loss:  0.4276807904243469
Valid Loss:  0.4106852412223816
Epoch:  164  	Training Loss: 0.34673604369163513
Test Loss:  0.4273834824562073
Valid Loss:  0.41039472818374634
Epoch:  165  	Training Loss: 0.3464881181716919
Test Loss:  0.42708641290664673
Valid Loss:  0.4101044535636902
Epoch:  166  	Training Loss: 0.3462403416633606
Test Loss:  0.4267895817756653
Valid Loss:  0.40981432795524597
Epoch:  167  	Training Loss: 0.3459927439689636
Test Loss:  0.42649292945861816
Valid Loss:  0.40952444076538086
Epoch:  168  	Training Loss: 0.345745325088501
Test Loss:  0.42619651556015015
Valid Loss:  0.40923476219177246
Epoch:  169  	Training Loss: 0.34549811482429504
Test Loss:  0.42590031027793884
Valid Loss:  0.40894532203674316
Epoch:  170  	Training Loss: 0.34525108337402344
Test Loss:  0.42560428380966187
Valid Loss:  0.4086560606956482
Epoch:  171  	Training Loss: 0.34500420093536377
Test Loss:  0.4253084659576416
Valid Loss:  0.40836697816848755
Epoch:  172  	Training Loss: 0.3447574973106384
Test Loss:  0.42501646280288696
Valid Loss:  0.40808191895484924
Epoch:  173  	Training Loss: 0.3445134162902832
Test Loss:  0.4247245490550995
Valid Loss:  0.4077970087528229
Epoch:  174  	Training Loss: 0.3442695438861847
Test Loss:  0.4244329333305359
Valid Loss:  0.407512366771698
Epoch:  175  	Training Loss: 0.3440258204936981
Test Loss:  0.42414143681526184
Valid Loss:  0.40722787380218506
Epoch:  176  	Training Loss: 0.34378230571746826
Test Loss:  0.4238502085208893
Valid Loss:  0.4069436192512512
Epoch:  177  	Training Loss: 0.34353893995285034
Test Loss:  0.42355918884277344
Valid Loss:  0.4066595435142517
Epoch:  178  	Training Loss: 0.34329575300216675
Test Loss:  0.4232683777809143
Valid Loss:  0.4063757061958313
Epoch:  179  	Training Loss: 0.34305277466773987
Test Loss:  0.4229777455329895
Valid Loss:  0.4060920476913452
Epoch:  180  	Training Loss: 0.34280991554260254
Test Loss:  0.422687292098999
Valid Loss:  0.40580859780311584
Epoch:  181  	Training Loss: 0.3425672650337219
Test Loss:  0.4223971366882324
Valid Loss:  0.4055253565311432
Epoch:  182  	Training Loss: 0.34232479333877563
Test Loss:  0.4221097528934479
Valid Loss:  0.4052451252937317
Epoch:  183  	Training Loss: 0.34208428859710693
Test Loss:  0.42182254791259766
Valid Loss:  0.40496504306793213
Epoch:  184  	Training Loss: 0.34184396266937256
Test Loss:  0.42153552174568176
Valid Loss:  0.40468519926071167
Epoch:  185  	Training Loss: 0.3416038155555725
Test Loss:  0.42124873399734497
Valid Loss:  0.40440553426742554
Epoch:  186  	Training Loss: 0.3413638472557068
Test Loss:  0.4209621548652649
Valid Loss:  0.4041260778903961
Epoch:  187  	Training Loss: 0.341124027967453
Test Loss:  0.42067569494247437
Valid Loss:  0.403846800327301
Epoch:  188  	Training Loss: 0.34088438749313354
Test Loss:  0.4203895330429077
Valid Loss:  0.40356773138046265
Epoch:  189  	Training Loss: 0.340644896030426
Test Loss:  0.420103520154953
Valid Loss:  0.403288871049881
Epoch:  190  	Training Loss: 0.34040558338165283
Test Loss:  0.419817715883255
Valid Loss:  0.40301015973091125
Epoch:  191  	Training Loss: 0.34016644954681396
Test Loss:  0.4195321202278137
Valid Loss:  0.40273168683052063
Epoch:  192  	Training Loss: 0.3399274945259094
Test Loss:  0.41924870014190674
Valid Loss:  0.40245556831359863
Epoch:  193  	Training Loss: 0.33969008922576904
Test Loss:  0.41896554827690125
Valid Loss:  0.40217965841293335
Epoch:  194  	Training Loss: 0.339452862739563
Test Loss:  0.4186825454235077
Valid Loss:  0.4019039273262024
Epoch:  195  	Training Loss: 0.33921581506729126
Test Loss:  0.41839975118637085
Valid Loss:  0.40162837505340576
Epoch:  196  	Training Loss: 0.3389788866043091
Test Loss:  0.41811713576316833
Valid Loss:  0.40135300159454346
Epoch:  197  	Training Loss: 0.338742196559906
Test Loss:  0.4178347587585449
Valid Loss:  0.40107786655426025
Epoch:  198  	Training Loss: 0.33850565552711487
Test Loss:  0.41755253076553345
Valid Loss:  0.4008029103279114
Epoch:  199  	Training Loss: 0.33826929330825806
Test Loss:  0.4172705411911011
Valid Loss:  0.4005281627178192
Epoch:  200  	Training Loss: 0.3380330801010132
Test Loss:  0.4169887602329254
Valid Loss:  0.4002535939216614
Epoch:  201  	Training Loss: 0.33779704570770264
Test Loss:  0.4167070984840393
Valid Loss:  0.39997923374176025
Epoch:  202  	Training Loss: 0.33756113052368164
Test Loss:  0.4164271056652069
Valid Loss:  0.3997066020965576
Epoch:  203  	Training Loss: 0.33732640743255615
Test Loss:  0.41614729166030884
Valid Loss:  0.39943408966064453
Epoch:  204  	Training Loss: 0.3370917737483978
Test Loss:  0.4158676862716675
Valid Loss:  0.39916184544563293
Epoch:  205  	Training Loss: 0.3368573784828186
Test Loss:  0.41558825969696045
Valid Loss:  0.39888978004455566
Epoch:  206  	Training Loss: 0.33662307262420654
Test Loss:  0.41530901193618774
Valid Loss:  0.39861786365509033
Epoch:  207  	Training Loss: 0.3363890051841736
Test Loss:  0.41503000259399414
Valid Loss:  0.3983461856842041
Epoch:  208  	Training Loss: 0.3361550569534302
Test Loss:  0.4147511422634125
Valid Loss:  0.3980746567249298
Epoch:  209  	Training Loss: 0.3359213173389435
Test Loss:  0.41447246074676514
Valid Loss:  0.3978033661842346
Epoch:  210  	Training Loss: 0.33568769693374634
Test Loss:  0.4141940176486969
Valid Loss:  0.39753222465515137
Epoch:  211  	Training Loss: 0.3354542553424835
Test Loss:  0.413915753364563
Valid Loss:  0.39726129174232483
Epoch:  212  	Training Loss: 0.33522099256515503
Test Loss:  0.4136389493942261
Valid Loss:  0.39699190855026245
Epoch:  213  	Training Loss: 0.3349888026714325
Test Loss:  0.41336241364479065
Valid Loss:  0.3967227339744568
Epoch:  214  	Training Loss: 0.3347567617893219
Test Loss:  0.4130859673023224
Valid Loss:  0.39645373821258545
Epoch:  215  	Training Loss: 0.33452486991882324
Test Loss:  0.4128097593784332
Valid Loss:  0.39618492126464844
Epoch:  216  	Training Loss: 0.3342931866645813
Test Loss:  0.4125337600708008
Valid Loss:  0.3959163427352905
Epoch:  217  	Training Loss: 0.3340616226196289
Test Loss:  0.41225796937942505
Valid Loss:  0.39564794301986694
Epoch:  218  	Training Loss: 0.3338302671909332
Test Loss:  0.41198229789733887
Valid Loss:  0.3953797221183777
Epoch:  219  	Training Loss: 0.3335990309715271
Test Loss:  0.41170692443847656
Valid Loss:  0.39511168003082275
Epoch:  220  	Training Loss: 0.3333680033683777
Test Loss:  0.4114316701889038
Valid Loss:   44%|████▍     | 221/500 [02:39<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:39<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:40<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:40<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:46<05:31,  1.23s/it] 47%|████▋     | 233/500 [02:47<03:56,  1.13it/s] 47%|████▋     | 235/500 [02:47<02:49,  1.56it/s] 47%|████▋     | 237/500 [02:47<02:03,  2.14it/s] 48%|████▊     | 239/500 [02:47<01:30,  2.88it/s] 48%|████▊     | 241/500 [02:53<05:11,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:54<02:40,  1.59it/s] 49%|████▉     | 247/500 [02:54<01:56,  2.18it/s] 50%|████▉     | 249/500 [02:54<01:25,  2.93it/s] 50%|█████     | 251/500 [03:00<04:55,  1.19s/it] 51%|█████     | 253/500 [03:00<03:30,  1.17it/s] 51%|█████     | 255/500 [03:01<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:01<01:50,  2.21it/s] 52%|█████▏    | 259/500 [03:01<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:07<04:43,  1.18s/it] 53%|█████▎    | 263/500 [03:07<03:21,  1.17it/s] 53%|█████▎    | 265/500 [03:07<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:08<01:46,  2.18it/s] 54%|█████▍    | 269/500 [03:08<01:18,  2.93it/s] 54%|█████▍    | 271/500 [03:14<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:14<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:14<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:15<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:21<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:21<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:21<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:21<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:21<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:28<04:07,  1.18s/it]0.39484381675720215
Epoch:  221  	Training Loss: 0.3331371545791626
Test Loss:  0.41115662455558777
Valid Loss:  0.39457619190216064
Epoch:  222  	Training Loss: 0.33290645480155945
Test Loss:  0.410882830619812
Valid Loss:  0.3943098485469818
Epoch:  223  	Training Loss: 0.33267664909362793
Test Loss:  0.41060927510261536
Valid Loss:  0.3940437436103821
Epoch:  224  	Training Loss: 0.33244702219963074
Test Loss:  0.410335898399353
Valid Loss:  0.3937777876853943
Epoch:  225  	Training Loss: 0.3322175443172455
Test Loss:  0.41006267070770264
Valid Loss:  0.3935120403766632
Epoch:  226  	Training Loss: 0.33198824524879456
Test Loss:  0.4097896218299866
Valid Loss:  0.39324644207954407
Epoch:  227  	Training Loss: 0.33175909519195557
Test Loss:  0.4095168113708496
Valid Loss:  0.39298105239868164
Epoch:  228  	Training Loss: 0.3315301239490509
Test Loss:  0.409244179725647
Valid Loss:  0.39271581172943115
Epoch:  229  	Training Loss: 0.3313013017177582
Test Loss:  0.40897172689437866
Valid Loss:  0.39245080947875977
Epoch:  230  	Training Loss: 0.3310726284980774
Test Loss:  0.4086994528770447
Valid Loss:  0.3921859860420227
Epoch:  231  	Training Loss: 0.33084413409233093
Test Loss:  0.408427357673645
Valid Loss:  0.3919212818145752
Epoch:  232  	Training Loss: 0.3306157886981964
Test Loss:  0.4081561863422394
Valid Loss:  0.39165762066841125
Epoch:  233  	Training Loss: 0.33038806915283203
Test Loss:  0.40788522362709045
Valid Loss:  0.39139413833618164
Epoch:  234  	Training Loss: 0.33016058802604675
Test Loss:  0.40761440992355347
Valid Loss:  0.39113083481788635
Epoch:  235  	Training Loss: 0.329933226108551
Test Loss:  0.4073438346385956
Valid Loss:  0.3908677101135254
Epoch:  236  	Training Loss: 0.32970601320266724
Test Loss:  0.40707337856292725
Valid Loss:  0.39060476422309875
Epoch:  237  	Training Loss: 0.3294789791107178
Test Loss:  0.406803160905838
Valid Loss:  0.39034199714660645
Epoch:  238  	Training Loss: 0.32925209403038025
Test Loss:  0.4065331220626831
Valid Loss:  0.3900793790817261
Epoch:  239  	Training Loss: 0.32902538776397705
Test Loss:  0.4062632620334625
Valid Loss:  0.3898169994354248
Epoch:  240  	Training Loss: 0.3287988305091858
Test Loss:  0.40599358081817627
Valid Loss:  0.38955479860305786
Epoch:  241  	Training Loss: 0.32857242226600647
Test Loss:  0.40572410821914673
Valid Loss:  0.38929277658462524
Epoch:  242  	Training Loss: 0.3283461928367615
Test Loss:  0.4054555296897888
Valid Loss:  0.38903164863586426
Epoch:  243  	Training Loss: 0.3281205892562866
Test Loss:  0.4051871597766876
Valid Loss:  0.38877081871032715
Epoch:  244  	Training Loss: 0.3278951644897461
Test Loss:  0.40491896867752075
Valid Loss:  0.3885101079940796
Epoch:  245  	Training Loss: 0.3276699185371399
Test Loss:  0.4046509861946106
Valid Loss:  0.38824957609176636
Epoch:  246  	Training Loss: 0.32744479179382324
Test Loss:  0.4043831527233124
Valid Loss:  0.38798925280570984
Epoch:  247  	Training Loss: 0.3272198736667633
Test Loss:  0.4041155278682709
Valid Loss:  0.38772910833358765
Epoch:  248  	Training Loss: 0.3269950747489929
Test Loss:  0.4038480818271637
Valid Loss:  0.38746917247772217
Epoch:  249  	Training Loss: 0.32677045464515686
Test Loss:  0.4035808742046356
Valid Loss:  0.38720938563346863
Epoch:  250  	Training Loss: 0.3265460133552551
Test Loss:  0.4033137857913971
Valid Loss:  0.3869497776031494
Epoch:  251  	Training Loss: 0.32632172107696533
Test Loss:  0.4030469059944153
Valid Loss:  0.3866903781890869
Epoch:  252  	Training Loss: 0.32609760761260986
Test Loss:  0.40278056263923645
Valid Loss:  0.3864315450191498
Epoch:  253  	Training Loss: 0.32587385177612305
Test Loss:  0.40251439809799194
Valid Loss:  0.3861728608608246
Epoch:  254  	Training Loss: 0.3256502151489258
Test Loss:  0.4022483825683594
Valid Loss:  0.3859143853187561
Epoch:  255  	Training Loss: 0.32542675733566284
Test Loss:  0.40198254585266113
Valid Loss:  0.3856560289859772
Epoch:  256  	Training Loss: 0.32520344853401184
Test Loss:  0.401716947555542
Valid Loss:  0.38539788126945496
Epoch:  257  	Training Loss: 0.32498031854629517
Test Loss:  0.4014514684677124
Valid Loss:  0.38513994216918945
Epoch:  258  	Training Loss: 0.32475730776786804
Test Loss:  0.40118616819381714
Valid Loss:  0.3848821520805359
Epoch:  259  	Training Loss: 0.32453447580337524
Test Loss:  0.4009210765361786
Valid Loss:  0.38462454080581665
Epoch:  260  	Training Loss: 0.3243117928504944
Test Loss:  0.40065616369247437
Valid Loss:  0.38436710834503174
Epoch:  261  	Training Loss: 0.32408925890922546
Test Loss:  0.4003913998603821
Valid Loss:  0.38410982489585876
Epoch:  262  	Training Loss: 0.32386690378189087
Test Loss:  0.40012702345848083
Valid Loss:  0.3838529586791992
Epoch:  263  	Training Loss: 0.3236446976661682
Test Loss:  0.3998628258705139
Valid Loss:  0.383596271276474
Epoch:  264  	Training Loss: 0.32342272996902466
Test Loss:  0.39959877729415894
Valid Loss:  0.3833397328853607
Epoch:  265  	Training Loss: 0.32320088148117065
Test Loss:  0.3993349075317383
Valid Loss:  0.38308340311050415
Epoch:  266  	Training Loss: 0.3229791522026062
Test Loss:  0.39907121658325195
Valid Loss:  0.3828272223472595
Epoch:  267  	Training Loss: 0.32275766134262085
Test Loss:  0.39880773425102234
Valid Loss:  0.3825712203979492
Epoch:  268  	Training Loss: 0.32253625988960266
Test Loss:  0.39854443073272705
Valid Loss:  0.38231542706489563
Epoch:  269  	Training Loss: 0.3223150372505188
Test Loss:  0.3982813060283661
Valid Loss:  0.382059782743454
Epoch:  270  	Training Loss: 0.3220939636230469
Test Loss:  0.39801836013793945
Valid Loss:  0.38180431723594666
Epoch:  271  	Training Loss: 0.3218730688095093
Test Loss:  0.39775562286376953
Valid Loss:  0.38154906034469604
Epoch:  272  	Training Loss: 0.3216523230075836
Test Loss:  0.39749330282211304
Valid Loss:  0.38129428029060364
Epoch:  273  	Training Loss: 0.3214319050312042
Test Loss:  0.39723119139671326
Valid Loss:  0.38103970885276794
Epoch:  274  	Training Loss: 0.32121163606643677
Test Loss:  0.3969692587852478
Valid Loss:  0.3807852864265442
Epoch:  275  	Training Loss: 0.32099148631095886
Test Loss:  0.3967074751853943
Valid Loss:  0.38053104281425476
Epoch:  276  	Training Loss: 0.3207715153694153
Test Loss:  0.3964459002017975
Valid Loss:  0.38027697801589966
Epoch:  277  	Training Loss: 0.32055169343948364
Test Loss:  0.396184504032135
Valid Loss:  0.3800230622291565
Epoch:  278  	Training Loss: 0.3203320801258087
Test Loss:  0.39592331647872925
Valid Loss:  0.37976932525634766
Epoch:  279  	Training Loss: 0.32011258602142334
Test Loss:  0.39566224813461304
Valid Loss:  0.37951579689979553
Epoch:  280  	Training Loss: 0.3198932409286499
Test Loss:  0.39540138840675354
Valid Loss:  0.37926241755485535
Epoch:  281  	Training Loss: 0.319674015045166
Test Loss:  0.39514070749282837
Valid Loss:  0.3790092468261719
Epoch:  282  	Training Loss: 0.31945499777793884
Test Loss:  0.39488014578819275
Valid Loss:  0.37875619530677795
Epoch:  283  	Training Loss: 0.31923598051071167
Test Loss:  0.39461976289749146
Valid Loss:  0.37850329279899597
Epoch:  284  	Training Loss: 0.31901711225509644
Test Loss:  0.3943595290184021
Valid Loss:  0.3782505989074707
Epoch:  285  	Training Loss: 0.3187984228134155
Test Loss:  0.39409950375556946
Valid Loss:  0.37799808382987976
Epoch:  286  	Training Loss: 0.31857991218566895
Test Loss:  0.39383962750434875
Valid Loss:  0.37774568796157837
Epoch:  287  	Training Loss: 0.3183615207672119
Test Loss:  0.39357995986938477
Valid Loss:  0.37749356031417847
Epoch:  288  	Training Loss: 0.3181432783603668
Test Loss:  0.3933204412460327
Valid Loss:  0.3772415220737457
Epoch:  289  	Training Loss: 0.31792518496513367
Test Loss:  0.393061101436615
Valid Loss:  0.3769896626472473
Epoch:  290  	Training Loss: 0.31770724058151245
Test Loss:  0.3928019106388092
Valid Loss:  0.3767380118370056
Epoch:  291  	Training Loss: 0.3174894452095032
Test Loss:  0.39254292845726013
Valid Loss:  0.37648648023605347
Epoch:  292  	Training Loss: 0.31727176904678345
Test Loss:  0.3922840356826782
Valid Loss:  0.37623515725135803
Epoch:  293  	Training Loss: 0.31705421209335327
Test Loss:   59%|█████▊    | 293/500 [03:28<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:28<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:28<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:28<01:07,  2.99it/s] 60%|██████    | 301/500 [03:35<03:55,  1.19s/it] 61%|██████    | 303/500 [03:35<02:48,  1.17it/s] 61%|██████    | 305/500 [03:35<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:35<01:04,  2.94it/s] 62%|██████▏   | 311/500 [03:42<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:42<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:42<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:42<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:42<01:01,  2.95it/s] 64%|██████▍   | 321/500 [03:49<03:36,  1.21s/it] 65%|██████▍   | 323/500 [03:49<02:33,  1.15it/s] 65%|██████▌   | 325/500 [03:49<01:49,  1.59it/s] 65%|██████▌   | 327/500 [03:49<01:19,  2.18it/s] 66%|██████▌   | 329/500 [03:49<00:58,  2.93it/s] 66%|██████▌   | 331/500 [03:56<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:56<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:56<01:42,  1.62it/s] 67%|██████▋   | 337/500 [03:56<01:14,  2.20it/s] 68%|██████▊   | 339/500 [03:56<00:55,  2.92it/s] 68%|██████▊   | 341/500 [04:02<03:08,  1.18s/it] 69%|██████▊   | 343/500 [04:03<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:03<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:03<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:03<00:50,  2.99it/s] 70%|███████   | 351/500 [04:09<03:00,  1.21s/it] 71%|███████   | 353/500 [04:10<02:08,  1.14it/s] 71%|███████   | 355/500 [04:10<01:32,  1.57it/s] 71%|███████▏  | 357/500 [04:10<01:07,  2.13it/s] 72%|███████▏  | 359/500 [04:10<00:49,  2.86it/s] 72%|███████▏  | 361/500 [04:17<02:50,  1.22s/it] 73%|███████▎  | 363/500 [04:17<02:00,  1.14it/s] 73%|███████▎  | 365/500 [04:17<01:25,  1.58it/s]0.3920253813266754
Valid Loss:  0.37598398327827454
Epoch:  294  	Training Loss: 0.3168368637561798
Test Loss:  0.39176687598228455
Valid Loss:  0.37573301792144775
Epoch:  295  	Training Loss: 0.3166196346282959
Test Loss:  0.391508549451828
Valid Loss:  0.3754821717739105
Epoch:  296  	Training Loss: 0.31640252470970154
Test Loss:  0.3912504017353058
Valid Loss:  0.3752315640449524
Epoch:  297  	Training Loss: 0.3161855936050415
Test Loss:  0.3909924030303955
Valid Loss:  0.3749810755252838
Epoch:  298  	Training Loss: 0.3159688115119934
Test Loss:  0.39073461294174194
Valid Loss:  0.37473076581954956
Epoch:  299  	Training Loss: 0.31575217843055725
Test Loss:  0.3904769718647003
Valid Loss:  0.37448060512542725
Epoch:  300  	Training Loss: 0.3155357241630554
Test Loss:  0.390219509601593
Valid Loss:  0.37423068284988403
Epoch:  301  	Training Loss: 0.31531938910484314
Test Loss:  0.38996225595474243
Valid Loss:  0.37398087978363037
Epoch:  302  	Training Loss: 0.3151032030582428
Test Loss:  0.3897048234939575
Valid Loss:  0.37373101711273193
Epoch:  303  	Training Loss: 0.3148868680000305
Test Loss:  0.3894475996494293
Valid Loss:  0.37348127365112305
Epoch:  304  	Training Loss: 0.3146706223487854
Test Loss:  0.38919052481651306
Valid Loss:  0.3732317090034485
Epoch:  305  	Training Loss: 0.3144545555114746
Test Loss:  0.38893359899520874
Valid Loss:  0.37298229336738586
Epoch:  306  	Training Loss: 0.31423860788345337
Test Loss:  0.38867685198783875
Valid Loss:  0.37273308634757996
Epoch:  307  	Training Loss: 0.31402283906936646
Test Loss:  0.3884202837944031
Valid Loss:  0.372484028339386
Epoch:  308  	Training Loss: 0.3138071894645691
Test Loss:  0.38816389441490173
Valid Loss:  0.37223514914512634
Epoch:  309  	Training Loss: 0.31359174847602844
Test Loss:  0.3879077136516571
Valid Loss:  0.37198641896247864
Epoch:  310  	Training Loss: 0.31337642669677734
Test Loss:  0.38765162229537964
Valid Loss:  0.37173783779144287
Epoch:  311  	Training Loss: 0.3131612539291382
Test Loss:  0.3873957395553589
Valid Loss:  0.3714894652366638
Epoch:  312  	Training Loss: 0.3129462003707886
Test Loss:  0.3871397376060486
Valid Loss:  0.3712409436702728
Epoch:  313  	Training Loss: 0.3127310276031494
Test Loss:  0.3868838846683502
Valid Loss:  0.37099260091781616
Epoch:  314  	Training Loss: 0.3125159740447998
Test Loss:  0.3866282105445862
Valid Loss:  0.3707444369792938
Epoch:  315  	Training Loss: 0.3123010993003845
Test Loss:  0.3863726854324341
Valid Loss:  0.3704964220523834
Epoch:  316  	Training Loss: 0.3120863437652588
Test Loss:  0.3861173093318939
Valid Loss:  0.37024858593940735
Epoch:  317  	Training Loss: 0.3118717074394226
Test Loss:  0.38586217164993286
Valid Loss:  0.3700008988380432
Epoch:  318  	Training Loss: 0.31165724992752075
Test Loss:  0.38560712337493896
Valid Loss:  0.3697534203529358
Epoch:  319  	Training Loss: 0.3114429712295532
Test Loss:  0.38535231351852417
Valid Loss:  0.3695060610771179
Epoch:  320  	Training Loss: 0.31122881174087524
Test Loss:  0.3850976228713989
Valid Loss:  0.369258850812912
Epoch:  321  	Training Loss: 0.3110147714614868
Test Loss:  0.3848431706428528
Valid Loss:  0.36901184916496277
Epoch:  322  	Training Loss: 0.3108009099960327
Test Loss:  0.38458865880966187
Valid Loss:  0.36876487731933594
Epoch:  323  	Training Loss: 0.3105870485305786
Test Loss:  0.38433435559272766
Valid Loss:  0.3685181140899658
Epoch:  324  	Training Loss: 0.31037333607673645
Test Loss:  0.3840802311897278
Valid Loss:  0.36827147006988525
Epoch:  325  	Training Loss: 0.3101598024368286
Test Loss:  0.3838263154029846
Valid Loss:  0.3680250644683838
Epoch:  326  	Training Loss: 0.3099464178085327
Test Loss:  0.3835725784301758
Valid Loss:  0.36777883768081665
Epoch:  327  	Training Loss: 0.30973315238952637
Test Loss:  0.38331902027130127
Valid Loss:  0.36753273010253906
Epoch:  328  	Training Loss: 0.30952009558677673
Test Loss:  0.3830656409263611
Valid Loss:  0.3672868609428406
Epoch:  329  	Training Loss: 0.30930715799331665
Test Loss:  0.3828124403953552
Valid Loss:  0.36704114079475403
Epoch:  330  	Training Loss: 0.3090944290161133
Test Loss:  0.3825594186782837
Valid Loss:  0.3667955994606018
Epoch:  331  	Training Loss: 0.30888181924819946
Test Loss:  0.38230663537979126
Valid Loss:  0.3665502667427063
Epoch:  332  	Training Loss: 0.3086693584918976
Test Loss:  0.3820534646511078
Valid Loss:  0.3663046061992645
Epoch:  333  	Training Loss: 0.3084566295146942
Test Loss:  0.3818005323410034
Valid Loss:  0.3660591244697571
Epoch:  334  	Training Loss: 0.30824407935142517
Test Loss:  0.381547749042511
Valid Loss:  0.36581388115882874
Epoch:  335  	Training Loss: 0.30803167819976807
Test Loss:  0.3812951445579529
Valid Loss:  0.36556875705718994
Epoch:  336  	Training Loss: 0.3078194260597229
Test Loss:  0.3810426890850067
Valid Loss:  0.3653238117694855
Epoch:  337  	Training Loss: 0.3076072931289673
Test Loss:  0.3807904124259949
Valid Loss:  0.36507904529571533
Epoch:  338  	Training Loss: 0.3073953092098236
Test Loss:  0.38053834438323975
Valid Loss:  0.36483442783355713
Epoch:  339  	Training Loss: 0.30718350410461426
Test Loss:  0.38028645515441895
Valid Loss:  0.36459001898765564
Epoch:  340  	Training Loss: 0.30697184801101685
Test Loss:  0.3800346851348877
Valid Loss:  0.3643457293510437
Epoch:  341  	Training Loss: 0.30676034092903137
Test Loss:  0.37978312373161316
Valid Loss:  0.3641016483306885
Epoch:  342  	Training Loss: 0.30654898285865784
Test Loss:  0.37953120470046997
Valid Loss:  0.3638572096824646
Epoch:  343  	Training Loss: 0.30633726716041565
Test Loss:  0.3792794942855835
Valid Loss:  0.36361297965049744
Epoch:  344  	Training Loss: 0.3061257302761078
Test Loss:  0.3790279030799866
Valid Loss:  0.3633688986301422
Epoch:  345  	Training Loss: 0.3059142827987671
Test Loss:  0.378776490688324
Valid Loss:  0.3631249666213989
Epoch:  346  	Training Loss: 0.3057030439376831
Test Loss:  0.3785252869129181
Valid Loss:  0.36288124322891235
Epoch:  347  	Training Loss: 0.30549192428588867
Test Loss:  0.37827426195144653
Valid Loss:  0.3626376986503601
Epoch:  348  	Training Loss: 0.30528098344802856
Test Loss:  0.37802332639694214
Valid Loss:  0.3623942732810974
Epoch:  349  	Training Loss: 0.3050701320171356
Test Loss:  0.37777262926101685
Valid Loss:  0.36215105652809143
Epoch:  350  	Training Loss: 0.304859459400177
Test Loss:  0.3775221109390259
Valid Loss:  0.361907958984375
Epoch:  351  	Training Loss: 0.3046489357948303
Test Loss:  0.37727171182632446
Valid Loss:  0.3616650700569153
Epoch:  352  	Training Loss: 0.3044385313987732
Test Loss:  0.37702107429504395
Valid Loss:  0.3614218831062317
Epoch:  353  	Training Loss: 0.30422791838645935
Test Loss:  0.37677061557769775
Valid Loss:  0.3611789643764496
Epoch:  354  	Training Loss: 0.30401748418807983
Test Loss:  0.3765203058719635
Valid Loss:  0.36093613505363464
Epoch:  355  	Training Loss: 0.3038071095943451
Test Loss:  0.3762701749801636
Valid Loss:  0.36069345474243164
Epoch:  356  	Training Loss: 0.3035969138145447
Test Loss:  0.37602025270462036
Valid Loss:  0.36045101284980774
Epoch:  357  	Training Loss: 0.3033868968486786
Test Loss:  0.3757704496383667
Valid Loss:  0.3602086901664734
Epoch:  358  	Training Loss: 0.30317699909210205
Test Loss:  0.37552085518836975
Valid Loss:  0.35996657609939575
Epoch:  359  	Training Loss: 0.30296725034713745
Test Loss:  0.37527143955230713
Valid Loss:  0.35972461104393005
Epoch:  360  	Training Loss: 0.3027576804161072
Test Loss:  0.37502217292785645
Valid Loss:  0.3594828248023987
Epoch:  361  	Training Loss: 0.30254822969436646
Test Loss:  0.3747730851173401
Valid Loss:  0.35924118757247925
Epoch:  362  	Training Loss: 0.3023388981819153
Test Loss:  0.3745235800743103
Valid Loss:  0.3589991629123688
Epoch:  363  	Training Loss: 0.30212926864624023
Test Loss:  0.37427425384521484
Valid Loss:  0.3587573170661926
Epoch:  364  	Training Loss: 0.30191975831985474
Test Loss:  0.3740250766277313
Valid Loss:  0.3585156202316284
Epoch:  365  	Training Loss: 0.30171042680740356
Test Loss:  0.37377607822418213
Valid Loss:  0.35827410221099854
Epoch:  366  	Training Loss: 0.30150121450424194
 73%|███████▎  | 367/500 [04:17<01:01,  2.15it/s] 74%|███████▍  | 369/500 [04:17<00:45,  2.88it/s] 74%|███████▍  | 371/500 [04:24<02:42,  1.26s/it] 75%|███████▍  | 373/500 [04:24<01:54,  1.11it/s] 75%|███████▌  | 375/500 [04:24<01:22,  1.52it/s] 75%|███████▌  | 377/500 [04:24<00:59,  2.08it/s] 76%|███████▌  | 379/500 [04:25<00:43,  2.79it/s] 76%|███████▌  | 381/500 [04:31<02:23,  1.21s/it] 76%|███████▋  | 382/500 [04:31<01:59,  1.01s/it] 77%|███████▋  | 384/500 [04:31<01:21,  1.42it/s] 77%|███████▋  | 386/500 [04:31<00:57,  1.99it/s] 78%|███████▊  | 388/500 [04:32<00:41,  2.69it/s] 78%|███████▊  | 390/500 [04:32<00:31,  3.54it/s] 78%|███████▊  | 392/500 [04:38<02:08,  1.19s/it] 79%|███████▉  | 394/500 [04:38<01:29,  1.18it/s] 79%|███████▉  | 396/500 [04:38<01:03,  1.64it/s] 80%|███████▉  | 398/500 [04:39<00:45,  2.24it/s] 80%|████████  | 400/500 [04:39<00:33,  3.01it/s] 80%|████████  | 402/500 [04:45<01:57,  1.20s/it] 81%|████████  | 404/500 [04:45<01:22,  1.17it/s] 81%|████████  | 406/500 [04:45<00:58,  1.62it/s] 82%|████████▏ | 408/500 [04:46<00:41,  2.21it/s] 82%|████████▏ | 410/500 [04:46<00:30,  2.97it/s] 82%|████████▏ | 412/500 [04:52<01:44,  1.19s/it] 83%|████████▎ | 414/500 [04:52<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:52<00:51,  1.62it/s] 84%|████████▎ | 418/500 [04:52<00:37,  2.21it/s] 84%|████████▍ | 420/500 [04:53<00:26,  2.97it/s] 84%|████████▍ | 422/500 [04:59<01:32,  1.19s/it] 85%|████████▍ | 424/500 [04:59<01:04,  1.17it/s] 85%|████████▌ | 426/500 [04:59<00:45,  1.62it/s] 86%|████████▌ | 428/500 [04:59<00:32,  2.22it/s] 86%|████████▌ | 430/500 [04:59<00:23,  2.99it/s] 86%|████████▋ | 432/500 [05:06<01:20,  1.18s/it] 87%|████████▋ | 434/500 [05:06<00:56,  1.18it/s] 87%|████████▋ | 436/500 [05:06<00:39,  1.63it/s] 88%|████████▊ | 438/500 [05:06<00:27,  2.22it/s]Test Loss:  0.37352728843688965
Valid Loss:  0.358032763004303
Epoch:  367  	Training Loss: 0.30129218101501465
Test Loss:  0.3732786178588867
Valid Loss:  0.35779157280921936
Epoch:  368  	Training Loss: 0.3010832667350769
Test Loss:  0.3730301558971405
Valid Loss:  0.35755056142807007
Epoch:  369  	Training Loss: 0.3008745014667511
Test Loss:  0.3727818727493286
Valid Loss:  0.3573097288608551
Epoch:  370  	Training Loss: 0.3006659150123596
Test Loss:  0.37253373861312866
Valid Loss:  0.35706907510757446
Epoch:  371  	Training Loss: 0.3004574775695801
Test Loss:  0.37228578329086304
Valid Loss:  0.356828510761261
Epoch:  372  	Training Loss: 0.3002491593360901
Test Loss:  0.37203744053840637
Valid Loss:  0.3565877079963684
Epoch:  373  	Training Loss: 0.30004051327705383
Test Loss:  0.3717893362045288
Valid Loss:  0.35634708404541016
Epoch:  374  	Training Loss: 0.2998320460319519
Test Loss:  0.37154141068458557
Valid Loss:  0.35610663890838623
Epoch:  375  	Training Loss: 0.2996237576007843
Test Loss:  0.37129366397857666
Valid Loss:  0.35586631298065186
Epoch:  376  	Training Loss: 0.29941558837890625
Test Loss:  0.3710460662841797
Valid Loss:  0.3556261658668518
Epoch:  377  	Training Loss: 0.29920756816864014
Test Loss:  0.37079858779907227
Valid Loss:  0.3553861677646637
Epoch:  378  	Training Loss: 0.29899969696998596
Test Loss:  0.37055134773254395
Valid Loss:  0.3551463484764099
Epoch:  379  	Training Loss: 0.29879194498062134
Test Loss:  0.37030428647994995
Valid Loss:  0.35490673780441284
Epoch:  380  	Training Loss: 0.2985844016075134
Test Loss:  0.3700573742389679
Valid Loss:  0.3546672463417053
Epoch:  381  	Training Loss: 0.29837697744369507
Test Loss:  0.3698106110095978
Valid Loss:  0.35442793369293213
Epoch:  382  	Training Loss: 0.29816970229148865
Test Loss:  0.36956334114074707
Valid Loss:  0.35418814420700073
Epoch:  383  	Training Loss: 0.297961950302124
Test Loss:  0.3693162798881531
Valid Loss:  0.35394856333732605
Epoch:  384  	Training Loss: 0.2977544069290161
Test Loss:  0.36906933784484863
Valid Loss:  0.3537091016769409
Epoch:  385  	Training Loss: 0.29754698276519775
Test Loss:  0.3688226342201233
Valid Loss:  0.3534698188304901
Epoch:  386  	Training Loss: 0.29733967781066895
Test Loss:  0.3685760498046875
Valid Loss:  0.35323065519332886
Epoch:  387  	Training Loss: 0.29713255167007446
Test Loss:  0.36832964420318604
Valid Loss:  0.3529917299747467
Epoch:  388  	Training Loss: 0.29692554473876953
Test Loss:  0.3680833578109741
Valid Loss:  0.3527529239654541
Epoch:  389  	Training Loss: 0.2967187166213989
Test Loss:  0.3678373098373413
Valid Loss:  0.35251426696777344
Epoch:  390  	Training Loss: 0.29651200771331787
Test Loss:  0.3675914406776428
Valid Loss:  0.3522758483886719
Epoch:  391  	Training Loss: 0.29630547761917114
Test Loss:  0.3673456907272339
Valid Loss:  0.35203754901885986
Epoch:  392  	Training Loss: 0.2960990369319916
Test Loss:  0.36709946393966675
Valid Loss:  0.35179877281188965
Epoch:  393  	Training Loss: 0.29589220881462097
Test Loss:  0.36685335636138916
Valid Loss:  0.35156017541885376
Epoch:  394  	Training Loss: 0.2956855297088623
Test Loss:  0.3666074872016907
Valid Loss:  0.3513216972351074
Epoch:  395  	Training Loss: 0.2954789400100708
Test Loss:  0.36636173725128174
Valid Loss:  0.3510834276676178
Epoch:  396  	Training Loss: 0.2952725887298584
Test Loss:  0.36611616611480713
Valid Loss:  0.3508453071117401
Epoch:  397  	Training Loss: 0.29506635665893555
Test Loss:  0.36587077379226685
Valid Loss:  0.35060739517211914
Epoch:  398  	Training Loss: 0.29486024379730225
Test Loss:  0.3656255602836609
Valid Loss:  0.3503696322441101
Epoch:  399  	Training Loss: 0.2946542799472809
Test Loss:  0.36538052558898926
Valid Loss:  0.3501319885253906
Epoch:  400  	Training Loss: 0.29444846510887146
Test Loss:  0.36513566970825195
Valid Loss:  0.34989455342292786
Epoch:  401  	Training Loss: 0.29424282908439636
Test Loss:  0.3648909330368042
Valid Loss:  0.349657267332077
Epoch:  402  	Training Loss: 0.2940372824668884
Test Loss:  0.3646458387374878
Valid Loss:  0.34941965341567993
Epoch:  403  	Training Loss: 0.29383140802383423
Test Loss:  0.3644008934497833
Valid Loss:  0.34918212890625
Epoch:  404  	Training Loss: 0.29362571239471436
Test Loss:  0.3641561269760132
Valid Loss:  0.3489447832107544
Epoch:  405  	Training Loss: 0.29342013597488403
Test Loss:  0.363911509513855
Valid Loss:  0.3487076759338379
Epoch:  406  	Training Loss: 0.29321473836898804
Test Loss:  0.3636671304702759
Valid Loss:  0.34847068786621094
Epoch:  407  	Training Loss: 0.2930094599723816
Test Loss:  0.36342287063598633
Valid Loss:  0.3482338786125183
Epoch:  408  	Training Loss: 0.2928043007850647
Test Loss:  0.3631787896156311
Valid Loss:  0.34799724817276
Epoch:  409  	Training Loss: 0.29259932041168213
Test Loss:  0.3629348874092102
Valid Loss:  0.34776073694229126
Epoch:  410  	Training Loss: 0.2923945188522339
Test Loss:  0.36269116401672363
Valid Loss:  0.34752440452575684
Epoch:  411  	Training Loss: 0.2921898365020752
Test Loss:  0.3624476194381714
Valid Loss:  0.3472883105278015
Epoch:  412  	Training Loss: 0.29198527336120605
Test Loss:  0.36220335960388184
Valid Loss:  0.3470514416694641
Epoch:  413  	Training Loss: 0.29178014397621155
Test Loss:  0.36195921897888184
Valid Loss:  0.3468148112297058
Epoch:  414  	Training Loss: 0.2915751338005066
Test Loss:  0.36171528697013855
Valid Loss:  0.3465782701969147
Epoch:  415  	Training Loss: 0.2913702726364136
Test Loss:  0.3614715337753296
Valid Loss:  0.34634196758270264
Epoch:  416  	Training Loss: 0.2911655604839325
Test Loss:  0.36122792959213257
Valid Loss:  0.34610581398010254
Epoch:  417  	Training Loss: 0.29096099734306335
Test Loss:  0.3609845042228699
Valid Loss:  0.345869779586792
Epoch:  418  	Training Loss: 0.29075658321380615
Test Loss:  0.3607412278652191
Valid Loss:  0.34563395380973816
Epoch:  419  	Training Loss: 0.2905523180961609
Test Loss:  0.3604981601238251
Valid Loss:  0.34539830684661865
Epoch:  420  	Training Loss: 0.29034820199012756
Test Loss:  0.36025524139404297
Valid Loss:  0.3451628088951111
Epoch:  421  	Training Loss: 0.2901442050933838
Test Loss:  0.3600125014781952
Valid Loss:  0.34492748975753784
Epoch:  422  	Training Loss: 0.28994041681289673
Test Loss:  0.359769344329834
Valid Loss:  0.34469175338745117
Epoch:  423  	Training Loss: 0.28973621129989624
Test Loss:  0.3595263361930847
Valid Loss:  0.34445619583129883
Epoch:  424  	Training Loss: 0.2895321846008301
Test Loss:  0.3592834770679474
Valid Loss:  0.3442208170890808
Epoch:  425  	Training Loss: 0.28932830691337585
Test Loss:  0.3590408265590668
Valid Loss:  0.34398555755615234
Epoch:  426  	Training Loss: 0.28912457823753357
Test Loss:  0.3587983250617981
Valid Loss:  0.3437505066394806
Epoch:  427  	Training Loss: 0.2889209985733032
Test Loss:  0.35855603218078613
Valid Loss:  0.34351563453674316
Epoch:  428  	Training Loss: 0.2887175679206848
Test Loss:  0.3583139181137085
Valid Loss:  0.3432809114456177
Epoch:  429  	Training Loss: 0.28851428627967834
Test Loss:  0.3580719232559204
Valid Loss:  0.3430463671684265
Epoch:  430  	Training Loss: 0.2883111238479614
Test Loss:  0.3578301668167114
Valid Loss:  0.3428120017051697
Epoch:  431  	Training Loss: 0.28810814023017883
Test Loss:  0.357588529586792
Valid Loss:  0.3425777554512024
Epoch:  432  	Training Loss: 0.2879053056240082
Test Loss:  0.35734638571739197
Valid Loss:  0.3423430323600769
Epoch:  433  	Training Loss: 0.2877019941806793
Test Loss:  0.3571043610572815
Valid Loss:  0.34210842847824097
Epoch:  434  	Training Loss: 0.2874988317489624
Test Loss:  0.35686254501342773
Valid Loss:  0.34187406301498413
Epoch:  435  	Training Loss: 0.2872958183288574
Test Loss:  0.3566208779811859
Valid Loss:  0.34163975715637207
Epoch:  436  	Training Loss: 0.287092924118042
Test Loss:  0.35637935996055603
Valid Loss:  0.3414056897163391
Epoch:  437  	Training Loss: 0.2868902087211609
Test Loss:  0.35613805055618286
Valid Loss:  0.3411717712879181
Epoch:  438  	Training Loss: 0.28668761253356934
Test Loss:  0.35589689016342163
Valid Loss:  0.340938001871109
Epoch:  439  	Training Loss: 0.2864851951599121
 88%|████████▊ | 440/500 [05:06<00:20,  2.99it/s] 88%|████████▊ | 442/500 [05:13<01:10,  1.22s/it] 89%|████████▉ | 444/500 [05:13<00:48,  1.15it/s] 89%|████████▉ | 446/500 [05:13<00:33,  1.59it/s] 90%|████████▉ | 448/500 [05:13<00:23,  2.17it/s] 90%|█████████ | 450/500 [05:13<00:17,  2.91it/s] 90%|█████████ | 452/500 [05:20<00:57,  1.19s/it] 91%|█████████ | 454/500 [05:20<00:39,  1.17it/s] 91%|█████████ | 456/500 [05:20<00:27,  1.62it/s] 92%|█████████▏| 458/500 [05:20<00:18,  2.21it/s] 92%|█████████▏| 460/500 [05:20<00:13,  2.97it/s] 92%|█████████▏| 462/500 [05:27<00:45,  1.19s/it] 93%|█████████▎| 464/500 [05:27<00:30,  1.18it/s] 93%|█████████▎| 466/500 [05:27<00:20,  1.63it/s] 94%|█████████▎| 468/500 [05:27<00:14,  2.22it/s] 94%|█████████▍| 470/500 [05:27<00:10,  2.97it/s] 94%|█████████▍| 472/500 [05:33<00:33,  1.18s/it] 95%|█████████▍| 474/500 [05:34<00:22,  1.18it/s] 95%|█████████▌| 476/500 [05:34<00:14,  1.63it/s] 96%|█████████▌| 478/500 [05:34<00:09,  2.23it/s] 96%|█████████▌| 480/500 [05:34<00:06,  2.98it/s] 96%|█████████▋| 482/500 [05:40<00:21,  1.19s/it] 97%|█████████▋| 484/500 [05:40<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:41<00:08,  1.61it/s] 98%|█████████▊| 488/500 [05:41<00:05,  2.19it/s] 98%|█████████▊| 490/500 [05:41<00:03,  2.94it/s] 98%|█████████▊| 492/500 [05:47<00:09,  1.20s/it] 99%|█████████▉| 494/500 [05:47<00:05,  1.16it/s] 99%|█████████▉| 496/500 [05:48<00:02,  1.60it/s]100%|█████████▉| 498/500 [05:48<00:00,  2.19it/s]100%|██████████| 500/500 [05:48<00:00,  2.94it/s]100%|██████████| 500/500 [05:48<00:00,  1.44it/s]
Test Loss:  0.3556559085845947
Valid Loss:  0.34070444107055664
Epoch:  440  	Training Loss: 0.28628289699554443
Test Loss:  0.35541510581970215
Valid Loss:  0.3404710292816162
Epoch:  441  	Training Loss: 0.2860807180404663
Test Loss:  0.3551744222640991
Valid Loss:  0.34023773670196533
Epoch:  442  	Training Loss: 0.2858787477016449
Test Loss:  0.35493332147598267
Valid Loss:  0.340004026889801
Epoch:  443  	Training Loss: 0.28567636013031006
Test Loss:  0.35469233989715576
Valid Loss:  0.33977043628692627
Epoch:  444  	Training Loss: 0.2854740619659424
Test Loss:  0.3544515371322632
Valid Loss:  0.33953702449798584
Epoch:  445  	Training Loss: 0.28527194261550903
Test Loss:  0.35421091318130493
Valid Loss:  0.33930379152297974
Epoch:  446  	Training Loss: 0.28506994247436523
Test Loss:  0.3539704382419586
Valid Loss:  0.33907073736190796
Epoch:  447  	Training Loss: 0.2848680913448334
Test Loss:  0.35373011231422424
Valid Loss:  0.3388378620147705
Epoch:  448  	Training Loss: 0.28466638922691345
Test Loss:  0.3534899950027466
Valid Loss:  0.3386051058769226
Epoch:  449  	Training Loss: 0.28446486592292786
Test Loss:  0.35325002670288086
Valid Loss:  0.33837249875068665
Epoch:  450  	Training Loss: 0.2842634618282318
Test Loss:  0.35301023721694946
Valid Loss:  0.3381401300430298
Epoch:  451  	Training Loss: 0.2840622067451477
Test Loss:  0.35277059674263
Valid Loss:  0.3379078507423401
Epoch:  452  	Training Loss: 0.28386107087135315
Test Loss:  0.3525305688381195
Valid Loss:  0.33767518401145935
Epoch:  453  	Training Loss: 0.28365960717201233
Test Loss:  0.35229063034057617
Valid Loss:  0.33744269609451294
Epoch:  454  	Training Loss: 0.28345823287963867
Test Loss:  0.3520509600639343
Valid Loss:  0.33721035718917847
Epoch:  455  	Training Loss: 0.28325706720352173
Test Loss:  0.35181137919425964
Valid Loss:  0.3369781970977783
Epoch:  456  	Training Loss: 0.28305599093437195
Test Loss:  0.3515720069408417
Valid Loss:  0.3367461860179901
Epoch:  457  	Training Loss: 0.2828550934791565
Test Loss:  0.35133281350135803
Valid Loss:  0.33651435375213623
Epoch:  458  	Training Loss: 0.282654345035553
Test Loss:  0.35109376907348633
Valid Loss:  0.3362826704978943
Epoch:  459  	Training Loss: 0.282453715801239
Test Loss:  0.35085490345954895
Valid Loss:  0.33605116605758667
Epoch:  460  	Training Loss: 0.2822532653808594
Test Loss:  0.3506162166595459
Valid Loss:  0.3358198404312134
Epoch:  461  	Training Loss: 0.2820529341697693
Test Loss:  0.35037761926651
Valid Loss:  0.335588663816452
Epoch:  462  	Training Loss: 0.28185275197029114
Test Loss:  0.35013848543167114
Valid Loss:  0.33535686135292053
Epoch:  463  	Training Loss: 0.28165203332901
Test Loss:  0.34989944100379944
Valid Loss:  0.33512526750564575
Epoch:  464  	Training Loss: 0.2814514636993408
Test Loss:  0.34966060519218445
Valid Loss:  0.33489376306533813
Epoch:  465  	Training Loss: 0.2812510132789612
Test Loss:  0.3494219481945038
Valid Loss:  0.33466246724128723
Epoch:  466  	Training Loss: 0.28105074167251587
Test Loss:  0.34918344020843506
Valid Loss:  0.33443135023117065
Epoch:  467  	Training Loss: 0.2808506190776825
Test Loss:  0.34894511103630066
Valid Loss:  0.334200382232666
Epoch:  468  	Training Loss: 0.28065064549446106
Test Loss:  0.3487069308757782
Valid Loss:  0.3339695930480957
Epoch:  469  	Training Loss: 0.2804507613182068
Test Loss:  0.34846892952919006
Valid Loss:  0.3337389826774597
Epoch:  470  	Training Loss: 0.28025108575820923
Test Loss:  0.34823107719421387
Valid Loss:  0.3335084617137909
Epoch:  471  	Training Loss: 0.2800515294075012
Test Loss:  0.3479934334754944
Valid Loss:  0.3332781493663788
Epoch:  472  	Training Loss: 0.27985212206840515
Test Loss:  0.34775522351264954
Valid Loss:  0.3330473303794861
Epoch:  473  	Training Loss: 0.27965229749679565
Test Loss:  0.347517192363739
Valid Loss:  0.3328166604042053
Epoch:  474  	Training Loss: 0.2794525623321533
Test Loss:  0.3472793400287628
Valid Loss:  0.3325861692428589
Epoch:  475  	Training Loss: 0.2792530059814453
Test Loss:  0.34704163670539856
Valid Loss:  0.3323558568954468
Epoch:  476  	Training Loss: 0.27905356884002686
Test Loss:  0.34680408239364624
Valid Loss:  0.3321256637573242
Epoch:  477  	Training Loss: 0.2788543105125427
Test Loss:  0.34656670689582825
Valid Loss:  0.331895649433136
Epoch:  478  	Training Loss: 0.27865514159202576
Test Loss:  0.3463295102119446
Valid Loss:  0.3316657841205597
Epoch:  479  	Training Loss: 0.2784561514854431
Test Loss:  0.34609246253967285
Valid Loss:  0.3314360976219177
Epoch:  480  	Training Loss: 0.2782573103904724
Test Loss:  0.34585559368133545
Valid Loss:  0.3312065601348877
Epoch:  481  	Training Loss: 0.27805858850479126
Test Loss:  0.3456189036369324
Valid Loss:  0.330977201461792
Epoch:  482  	Training Loss: 0.2778600752353668
Test Loss:  0.345381498336792
Valid Loss:  0.33074715733528137
Epoch:  483  	Training Loss: 0.27766087651252747
Test Loss:  0.34514424204826355
Valid Loss:  0.3305172920227051
Epoch:  484  	Training Loss: 0.27746185660362244
Test Loss:  0.34490716457366943
Valid Loss:  0.33028754591941833
Epoch:  485  	Training Loss: 0.27726298570632935
Test Loss:  0.34467023611068726
Valid Loss:  0.3300579786300659
Epoch:  486  	Training Loss: 0.2770642340183258
Test Loss:  0.3444334864616394
Valid Loss:  0.3298285901546478
Epoch:  487  	Training Loss: 0.2768656313419342
Test Loss:  0.3441969156265259
Valid Loss:  0.32959938049316406
Epoch:  488  	Training Loss: 0.27666717767715454
Test Loss:  0.3439605236053467
Valid Loss:  0.32937031984329224
Epoch:  489  	Training Loss: 0.2764688730239868
Test Loss:  0.3437242805957794
Valid Loss:  0.32914140820503235
Epoch:  490  	Training Loss: 0.2762707471847534
Test Loss:  0.3434882164001465
Valid Loss:  0.3289126753807068
Epoch:  491  	Training Loss: 0.27607274055480957
Test Loss:  0.3432523012161255
Valid Loss:  0.32868409156799316
Epoch:  492  	Training Loss: 0.2758748531341553
Test Loss:  0.3430160582065582
Valid Loss:  0.3284551799297333
Epoch:  493  	Training Loss: 0.2756767272949219
Test Loss:  0.3427799642086029
Valid Loss:  0.3282264471054077
Epoch:  494  	Training Loss: 0.275478720664978
Test Loss:  0.3425440788269043
Valid Loss:  0.3279978930950165
Epoch:  495  	Training Loss: 0.2752808928489685
Test Loss:  0.34230831265449524
Valid Loss:  0.3277694880962372
Epoch:  496  	Training Loss: 0.2750832140445709
Test Loss:  0.3420727252960205
Valid Loss:  0.3275412321090698
Epoch:  497  	Training Loss: 0.2748856544494629
Test Loss:  0.3418373167514801
Valid Loss:  0.3273131549358368
Epoch:  498  	Training Loss: 0.2746882438659668
Test Loss:  0.341602087020874
Valid Loss:  0.3270852565765381
Epoch:  499  	Training Loss: 0.27449098229408264
Test Loss:  0.3413670063018799
Valid Loss:  0.3268575072288513
Epoch:  500  	Training Loss: 0.2742938697338104
Test Loss:  0.34113210439682007
Valid Loss:  0.3266299068927765
seed is  16
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:36,  6.45s/it]  1%|          | 3/500 [00:06<14:16,  1.72s/it]  1%|          | 5/500 [00:06<07:11,  1.15it/s]  1%|▏         | 7/500 [00:06<04:21,  1.89it/s]  2%|▏         | 9/500 [00:06<02:54,  2.82it/s]  2%|▏         | 11/500 [00:13<11:05,  1.36s/it]  3%|▎         | 13/500 [00:13<07:33,  1.07it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:37,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:38,  2.16it/s]  6%|▌         | 29/500 [00:20<02:41,  2.91it/s]  6%|▌         | 31/500 [00:27<09:36,  1.23s/it]  7%|▋         | 33/500 [00:27<06:51,  1.14it/s]  7%|▋         | 35/500 [00:27<04:55,  1.57it/s]  7%|▋         | 37/500 [00:27<03:34,  2.15it/s]  8%|▊         | 39/500 [00:28<02:38,  2.90it/s]  8%|▊         | 41/500 [00:34<09:18,  1.22s/it]  9%|▊         | 43/500 [00:34<06:38,  1.15it/s]  9%|▉         | 45/500 [00:34<04:46,  1.59it/s]  9%|▉         | 47/500 [00:34<03:29,  2.17it/s] 10%|▉         | 49/500 [00:35<02:34,  2.92it/s] 10%|█         | 51/500 [00:41<08:49,  1.18s/it] 11%|█         | 53/500 [00:41<06:18,  1.18it/s] 11%|█         | 55/500 [00:41<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.94it/s] 12%|█▏        | 61/500 [00:48<08:47,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:16,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:48<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.95it/s]Epoch:  1  	Training Loss: 0.5022580623626709
Test Loss:  2.747314691543579
Valid Loss:  2.658485174179077
Epoch:  2  	Training Loss: 3.285898447036743
Test Loss:  100.07341003417969
Valid Loss:  94.04310607910156
Epoch:  3  	Training Loss: 102.02055358886719
Test Loss:  0.955143928527832
Valid Loss:  0.9414174556732178
Epoch:  4  	Training Loss: 0.9980764985084534
Test Loss:  0.3830956518650055
Valid Loss:  0.3972450792789459
Epoch:  5  	Training Loss: 0.5361968278884888
Test Loss:  0.2308424711227417
Valid Loss:  0.26634109020233154
Epoch:  6  	Training Loss: 0.40606027841567993
Test Loss:  0.17614132165908813
Valid Loss:  0.22655202448368073
Epoch:  7  	Training Loss: 0.3551943600177765
Test Loss:  0.14844761788845062
Valid Loss:  0.2062838226556778
Epoch:  8  	Training Loss: 0.32620421051979065
Test Loss:  0.1328352987766266
Valid Loss:  0.1925199031829834
Epoch:  9  	Training Loss: 0.3063637316226959
Test Loss:  0.12248778343200684
Valid Loss:  0.18263794481754303
Epoch:  10  	Training Loss: 0.29312700033187866
Test Loss:  0.114925816655159
Valid Loss:  0.17451803386211395
Epoch:  11  	Training Loss: 0.282686710357666
Test Loss:  0.10866843163967133
Valid Loss:  0.1680614948272705
Epoch:  12  	Training Loss: 0.2743776738643646
Test Loss:  1.152324914932251
Valid Loss:  1.0779502391815186
Epoch:  13  	Training Loss: 1.0549161434173584
Test Loss:  0.1285337209701538
Valid Loss:  0.1396210640668869
Epoch:  14  	Training Loss: 0.1816994994878769
Test Loss:  0.09580659866333008
Valid Loss:  0.1082824170589447
Epoch:  15  	Training Loss: 0.1530161201953888
Test Loss:  0.0755060464143753
Valid Loss:  0.08969302475452423
Epoch:  16  	Training Loss: 0.13474436104297638
Test Loss:  0.06271514296531677
Valid Loss:  0.07868175208568573
Epoch:  17  	Training Loss: 0.12267778813838959
Test Loss:  0.054911479353904724
Valid Loss:  0.07254594564437866
Epoch:  18  	Training Loss: 0.11497019231319427
Test Loss:  0.05062832683324814
Valid Loss:  0.06975529342889786
Epoch:  19  	Training Loss: 0.1107369139790535
Test Loss:  0.04798239469528198
Valid Loss:  0.06841833889484406
Epoch:  20  	Training Loss: 0.10792810469865799
Test Loss:  0.04638834297657013
Valid Loss:  0.06794731318950653
Epoch:  21  	Training Loss: 0.10605229437351227
Test Loss:  0.045454248785972595
Valid Loss:  0.06796389073133469
Epoch:  22  	Training Loss: 0.10478972643613815
Test Loss:  0.03968428820371628
Valid Loss:  0.05982175096869469
Epoch:  23  	Training Loss: 0.0887603685259819
Test Loss:  0.023687070235610008
Valid Loss:  0.03504485636949539
Epoch:  24  	Training Loss: 0.04902749881148338
Test Loss:  0.007235045079141855
Valid Loss:  0.012158248573541641
Epoch:  25  	Training Loss: 0.012766962870955467
Test Loss:  0.005991418845951557
Valid Loss:  0.00834609568119049
Epoch:  26  	Training Loss: 0.006678069941699505
Test Loss:  0.0045001935213804245
Valid Loss:  0.006315743550658226
Epoch:  27  	Training Loss: 0.005294389557093382
Test Loss:  0.0034347320906817913
Valid Loss:  0.0048254309222102165
Epoch:  28  	Training Loss: 0.004247617442160845
Test Loss:  0.0026348037645220757
Valid Loss:  0.0037082829512655735
Epoch:  29  	Training Loss: 0.003445688635110855
Test Loss:  0.002042869571596384
Valid Loss:  0.002863943576812744
Epoch:  30  	Training Loss: 0.0028214147314429283
Test Loss:  0.00159078324213624
Valid Loss:  0.002220813650637865
Epoch:  31  	Training Loss: 0.002333732321858406
Test Loss:  0.00124869414139539
Valid Loss:  0.001732297008857131
Epoch:  32  	Training Loss: 0.0019519259221851826
Test Loss:  0.0011005266569554806
Valid Loss:  0.0014905133284628391
Epoch:  33  	Training Loss: 0.0017320637125521898
Test Loss:  0.0009533315896987915
Valid Loss:  0.0012832826469093561
Epoch:  34  	Training Loss: 0.0015483670867979527
Test Loss:  0.0008250465616583824
Valid Loss:  0.0011076704831793904
Epoch:  35  	Training Loss: 0.001391253317706287
Test Loss:  0.000716911512427032
Valid Loss:  0.0009595256997272372
Epoch:  36  	Training Loss: 0.0012568780221045017
Test Loss:  0.00062680768314749
Valid Loss:  0.0008347958792001009
Epoch:  37  	Training Loss: 0.0011431032326072454
Test Loss:  0.0005523085710592568
Valid Loss:  0.0007299190619960427
Epoch:  38  	Training Loss: 0.0010451660491526127
Test Loss:  0.0004903598455712199
Valid Loss:  0.0006417231052182615
Epoch:  39  	Training Loss: 0.0009607877000235021
Test Loss:  0.00043947066296823323
Valid Loss:  0.000567724637221545
Epoch:  40  	Training Loss: 0.0008879545493982732
Test Loss:  0.0003977864980697632
Valid Loss:  0.0005056943045929074
Epoch:  41  	Training Loss: 0.0008250175160355866
Test Loss:  0.0003633471205830574
Valid Loss:  0.0004536562191788107
Epoch:  42  	Training Loss: 0.0007705050520598888
Test Loss:  0.00029183237347751856
Valid Loss:  0.0003417077532503754
Epoch:  43  	Training Loss: 0.0006575192674063146
Test Loss:  0.00023167321342043579
Valid Loss:  0.0002508791221771389
Epoch:  44  	Training Loss: 0.0005520957638509572
Test Loss:  0.00022891808475833386
Valid Loss:  0.00022493561846204102
Epoch:  45  	Training Loss: 0.0005014846101403236
Test Loss:  0.00023711462563369423
Valid Loss:  0.00021782133262604475
Epoch:  46  	Training Loss: 0.00047369988169521093
Test Loss:  0.0002472957130521536
Valid Loss:  0.00021663530787918717
Epoch:  47  	Training Loss: 0.0004567518481053412
Test Loss:  0.0002566172042861581
Valid Loss:  0.00021721201483160257
Epoch:  48  	Training Loss: 0.00044597452506422997
Test Loss:  0.00026453216560184956
Valid Loss:  0.00021797357476316392
Epoch:  49  	Training Loss: 0.0004383205669000745
Test Loss:  0.000270903023192659
Valid Loss:  0.00021840629051439464
Epoch:  50  	Training Loss: 0.00043236766941845417
Test Loss:  0.00027559726731851697
Valid Loss:  0.0002182293392252177
Epoch:  51  	Training Loss: 0.00042754848254844546
Test Loss:  0.00027898093685507774
Valid Loss:  0.00021753160399384797
Epoch:  52  	Training Loss: 0.00042330019641667604
Test Loss:  0.0002807999844662845
Valid Loss:  0.0002148725325241685
Epoch:  53  	Training Loss: 0.00041653169319033623
Test Loss:  0.00028312852373346686
Valid Loss:  0.0002141019213013351
Epoch:  54  	Training Loss: 0.00041128936572931707
Test Loss:  0.0002851054014172405
Valid Loss:  0.00021401057892944664
Epoch:  55  	Training Loss: 0.0004067389527335763
Test Loss:  0.000286779657471925
Valid Loss:  0.0002144221361959353
Epoch:  56  	Training Loss: 0.0004030527197755873
Test Loss:  0.00028832361567765474
Valid Loss:  0.00021492379892151803
Epoch:  57  	Training Loss: 0.0004002560453955084
Test Loss:  0.00028948893304914236
Valid Loss:  0.00021550129167735577
Epoch:  58  	Training Loss: 0.00039804840344004333
Test Loss:  0.00029062520479783416
Valid Loss:  0.00021600304171442986
Epoch:  59  	Training Loss: 0.0003964208299294114
Test Loss:  0.0002917344099842012
Valid Loss:  0.00021647756511811167
Epoch:  60  	Training Loss: 0.0003953998093493283
Test Loss:  0.0002926760644186288
Valid Loss:  0.00021690673020202667
Epoch:  61  	Training Loss: 0.00039467160240747035
Test Loss:  0.0002933899231720716
Valid Loss:  0.00021730408479925245
Epoch:  62  	Training Loss: 0.0003940631286241114
Test Loss:  0.0002940025879070163
Valid Loss:  0.00021690188441425562
Epoch:  63  	Training Loss: 0.00039397215005010366
Test Loss:  0.0002935064840130508
Valid Loss:  0.0002171474479837343
Epoch:  64  	Training Loss: 0.00039390058373101056
Test Loss:  0.00029381091007962823
Valid Loss:  0.00021703579113818705
Epoch:  65  	Training Loss: 0.00039384112460538745
Test Loss:  0.0002936365781351924
Valid Loss:  0.00021718628704547882
Epoch:  66  	Training Loss: 0.0003937835863325745
Test Loss:  0.00029375465237535536
Valid Loss:  0.00021716032642871141
Epoch:  67  	Training Loss: 0.00039372779428958893
Test Loss:  0.0002936736564151943
Valid Loss:  0.00021724002726841718
Epoch:  68  	Training Loss: 0.00039367363206110895
Test Loss:  0.00029370750417001545
Valid Loss:  0.0002172439417336136
Epoch:  69  	Training Loss: 0.0003936200519092381
Test Loss:  0.00029365732916630805
Valid Loss:  0.00021729085710830986
Epoch:  70  	Training Loss: 0.00039356740307994187
Test Loss:  0.000293650955427438
Valid Loss:  0.00021730229491367936
 14%|█▍        | 71/500 [00:55<08:33,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:06,  1.16it/s] 15%|█▌        | 75/500 [00:55<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:12,  2.19it/s] 16%|█▌        | 79/500 [00:55<02:24,  2.91it/s] 16%|█▌        | 81/500 [01:02<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:02<05:59,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:09<08:18,  1.22s/it] 19%|█▊        | 93/500 [01:09<05:57,  1.14it/s] 19%|█▉        | 95/500 [01:15<10:40,  1.58s/it] 19%|█▉        | 97/500 [01:16<07:37,  1.14s/it] 20%|█▉        | 99/500 [01:16<05:29,  1.22it/s] 20%|██        | 101/500 [01:22<10:17,  1.55s/it] 21%|██        | 103/500 [01:22<07:18,  1.10s/it] 21%|██        | 105/500 [01:23<05:13,  1.26it/s] 21%|██▏       | 107/500 [01:23<03:46,  1.74it/s] 22%|██▏       | 109/500 [01:23<02:45,  2.37it/s] 22%|██▏       | 111/500 [01:29<08:04,  1.25s/it] 23%|██▎       | 113/500 [01:29<05:46,  1.12it/s] 23%|██▎       | 115/500 [01:29<04:09,  1.54it/s] 23%|██▎       | 117/500 [01:30<03:01,  2.11it/s] 24%|██▍       | 119/500 [01:30<02:13,  2.85it/s] 24%|██▍       | 121/500 [01:36<07:33,  1.20s/it] 25%|██▍       | 123/500 [01:36<05:24,  1.16it/s] 25%|██▌       | 125/500 [01:36<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:37<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:37<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:43<07:25,  1.21s/it] 27%|██▋       | 133/500 [01:43<05:17,  1.15it/s] 27%|██▋       | 135/500 [01:43<03:48,  1.60it/s]Epoch:  71  	Training Loss: 0.00039351731538772583
Test Loss:  0.0002937041863333434
Valid Loss:  0.00021737173665314913
Epoch:  72  	Training Loss: 0.00039347950951196253
Test Loss:  0.00028117926558479667
Valid Loss:  0.000208830286283046
Epoch:  73  	Training Loss: 0.00038857723120599985
Test Loss:  0.000278810563031584
Valid Loss:  0.00020760527695529163
Epoch:  74  	Training Loss: 0.00038663740269839764
Test Loss:  0.0002755166497081518
Valid Loss:  0.00020508115994744003
Epoch:  75  	Training Loss: 0.0003852022346109152
Test Loss:  0.00027301805675961077
Valid Loss:  0.00020316126756370068
Epoch:  76  	Training Loss: 0.0003834881936199963
Test Loss:  0.00027102057356387377
Valid Loss:  0.00020165162277407944
Epoch:  77  	Training Loss: 0.00038119489909149706
Test Loss:  0.00026935021742247045
Valid Loss:  0.00020041695097461343
Epoch:  78  	Training Loss: 0.00037826516199856997
Test Loss:  0.00026789266848936677
Valid Loss:  0.00019937109027523547
Epoch:  79  	Training Loss: 0.00037342755240388215
Test Loss:  0.00026648081257008016
Valid Loss:  0.00019589264411479235
Epoch:  80  	Training Loss: 0.0003641315852291882
Test Loss:  0.0002648014051374048
Valid Loss:  0.00019173583132214844
Epoch:  81  	Training Loss: 0.0003522563783917576
Test Loss:  0.00026197044644504786
Valid Loss:  0.00018713143072091043
Epoch:  82  	Training Loss: 0.00033772882306948304
Test Loss:  0.00025701886625029147
Valid Loss:  0.00017523273709230125
Epoch:  83  	Training Loss: 0.0002963518491014838
Test Loss:  0.0002583107561804354
Valid Loss:  0.00017024607222992927
Epoch:  84  	Training Loss: 0.0002701554330997169
Test Loss:  0.00025476349401287735
Valid Loss:  0.00016438303282484412
Epoch:  85  	Training Loss: 0.00025609356816858053
Test Loss:  0.0002520669368095696
Valid Loss:  0.00015968261868692935
Epoch:  86  	Training Loss: 0.00024445977760478854
Test Loss:  0.0002491004124749452
Valid Loss:  0.00015479240391869098
Epoch:  87  	Training Loss: 0.00023220136063173413
Test Loss:  0.00024568152730353177
Valid Loss:  0.0001505361869931221
Epoch:  88  	Training Loss: 0.00022069417173042893
Test Loss:  0.00024186872178688645
Valid Loss:  0.00014653970720246434
Epoch:  89  	Training Loss: 0.00020990570192225277
Test Loss:  0.00023833308659959584
Valid Loss:  0.00014297784946393222
Epoch:  90  	Training Loss: 0.0001989952870644629
Test Loss:  0.00023527146549895406
Valid Loss:  0.00014000514056533575
Epoch:  91  	Training Loss: 0.0001891775755211711
Test Loss:  0.00023180604330264032
Valid Loss:  0.00013751766528002918
Epoch:  92  	Training Loss: 0.00018070783698931336
Test Loss:  0.00024351902538910508
Valid Loss:  0.00014846168051008135
Epoch:  93  	Training Loss: 0.00018306654237676412
Test Loss:  0.0002268874377477914
Valid Loss:  0.00013427087105810642
Epoch:  94  	Training Loss: 0.0001913990854518488
Test Loss:  0.00027852895436808467
Valid Loss:  0.0001793974224710837
Epoch:  95  	Training Loss: 0.00021345556888263673
Test Loss:  0.00026097625959664583
Valid Loss:  0.00016428821254521608
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.00024947652127593756
Test Loss:  0.00023238120775204152
Valid Loss:  0.0001371535618091002
Epoch:  97  	Training Loss: 0.00019762685406021774
Test Loss:  0.000233605649555102
Valid Loss:  0.00013844268687535077
Epoch:  98  	Training Loss: 0.00019141205120831728
Test Loss:  0.00023348568356595933
Valid Loss:  0.00013863251660950482
Epoch:  99  	Training Loss: 0.00018824722792487592
Test Loss:  0.00023261172464117408
Valid Loss:  0.00013849121751263738
Epoch:  100  	Training Loss: 0.0001859524054452777
Test Loss:  0.00023152369249146432
Valid Loss:  0.0001381688634864986
Epoch:  101  	Training Loss: 0.00018403201829642057
Test Loss:  0.00023033868637867272
Valid Loss:  0.00013777398271486163
Epoch:  102  	Training Loss: 0.00018221874779555947
Test Loss:  0.00023063027765601873
Valid Loss:  0.00013761942682322115
Epoch:  103  	Training Loss: 0.00018155816360376775
Test Loss:  0.00023086847795639187
Valid Loss:  0.00013739094720222056
Epoch:  104  	Training Loss: 0.0001809445529943332
Test Loss:  0.00023106069420464337
Valid Loss:  0.00013710407074540854
Epoch:  105  	Training Loss: 0.0001803635386750102
Test Loss:  0.00023121350386645645
Valid Loss:  0.0001367748191114515
Epoch:  106  	Training Loss: 0.0001798059092834592
Test Loss:  0.00023133486683946103
Valid Loss:  0.0001364160270895809
Epoch:  107  	Training Loss: 0.00017926725558936596
Test Loss:  0.0002314387820661068
Valid Loss:  0.00013602951366920024
Epoch:  108  	Training Loss: 0.00017874348850455135
Test Loss:  0.00023152603534981608
Valid Loss:  0.0001356304856017232
Epoch:  109  	Training Loss: 0.0001782329345587641
Test Loss:  0.0002315986348548904
Valid Loss:  0.0001352247636532411
Epoch:  110  	Training Loss: 0.00017773517174646258
Test Loss:  0.0002316605532541871
Valid Loss:  0.0001348165824310854
Epoch:  111  	Training Loss: 0.00017719976312946528
Test Loss:  0.0002317786420462653
Valid Loss:  0.00013439942267723382
Epoch:  112  	Training Loss: 0.0001766229688655585
Test Loss:  0.00022929628903511912
Valid Loss:  0.00013341568410396576
Epoch:  113  	Training Loss: 0.00017386148101650178
Test Loss:  0.0002260578767163679
Valid Loss:  0.0001318244612775743
Epoch:  114  	Training Loss: 0.00017179128190036863
Test Loss:  0.0002230000973213464
Valid Loss:  0.00013030393165536225
Epoch:  115  	Training Loss: 0.00016996095655485988
Test Loss:  0.00022027082741260529
Valid Loss:  0.00012895246618427336
Epoch:  116  	Training Loss: 0.00016835246060509235
Test Loss:  0.0002179770963266492
Valid Loss:  0.00012780065299011767
Epoch:  117  	Training Loss: 0.00016694080841261894
Test Loss:  0.00021609393297694623
Valid Loss:  0.00012684025568887591
Epoch:  118  	Training Loss: 0.0001656599633861333
Test Loss:  0.00021451122302096337
Valid Loss:  0.0001259995624423027
Epoch:  119  	Training Loss: 0.00016448112728539854
Test Loss:  0.0002131365763489157
Valid Loss:  0.00012522446922957897
Epoch:  120  	Training Loss: 0.00016340096772182733
Test Loss:  0.0002119149430654943
Valid Loss:  0.0001244879385922104
Epoch:  121  	Training Loss: 0.00016242204583249986
Test Loss:  0.0002108631597366184
Valid Loss:  0.0001238024269696325
Epoch:  122  	Training Loss: 0.00016151441377587616
Test Loss:  0.0002075604279525578
Valid Loss:  0.00012119907478336245
Epoch:  123  	Training Loss: 0.00015795425861142576
Test Loss:  0.00020828188280574977
Valid Loss:  0.00012169575347797945
Epoch:  124  	Training Loss: 0.0001550863089505583
Test Loss:  0.00020765344379469752
Valid Loss:  0.00012054974649799988
Epoch:  125  	Training Loss: 0.00015255063772201538
Test Loss:  0.0002076508098980412
Valid Loss:  0.00011985722812823951
Epoch:  126  	Training Loss: 0.00015027432527858764
Test Loss:  0.00020744855282828212
Valid Loss:  0.00011909830936929211
Epoch:  127  	Training Loss: 0.00014822313096374273
Test Loss:  0.0002073556970572099
Valid Loss:  0.00011848910799017176
Epoch:  128  	Training Loss: 0.00014637282583862543
Test Loss:  0.00020726982620544732
Valid Loss:  0.00011792796431109309
Epoch:  129  	Training Loss: 0.00014468640438281
Test Loss:  0.00020720914471894503
Valid Loss:  0.0001174138014903292
Epoch:  130  	Training Loss: 0.0001430484262527898
Test Loss:  0.0002071950293611735
Valid Loss:  0.00011674534471239895
Epoch:  131  	Training Loss: 0.00014157156692817807
Test Loss:  0.00020718270388897508
Valid Loss:  0.00011614529648795724
Epoch:  132  	Training Loss: 0.0001402252964908257
Test Loss:  0.00020691429381258786
Valid Loss:  0.00011606131738517433
Epoch:  133  	Training Loss: 0.0001396885490976274
Test Loss:  0.0002066529996227473
Valid Loss:  0.00011600301513681188
Epoch:  134  	Training Loss: 0.00013916697935201228
Test Loss:  0.00020633498206734657
Valid Loss:  0.00011596177500905469
Epoch:  135  	Training Loss: 0.00013862992636859417
Test Loss:  0.00020603841403499246
Valid Loss:  0.00011594001989578828
Epoch:  136  	Training Loss: 0.00013811461394652724
Test Loss:  0.00020575695089064538
Valid Loss:  0.00011593435192480683
 27%|██▋       | 137/500 [01:44<02:46,  2.18it/s] 28%|██▊       | 139/500 [01:44<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:50<07:05,  1.19s/it] 29%|██▊       | 143/500 [01:50<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:50<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:50<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:51<01:58,  2.95it/s] 30%|███       | 151/500 [01:57<06:56,  1.19s/it] 31%|███       | 153/500 [01:57<04:57,  1.17it/s] 31%|███       | 155/500 [01:57<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:57<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:57<01:55,  2.96it/s] 32%|███▏      | 161/500 [02:04<06:47,  1.20s/it] 33%|███▎      | 163/500 [02:04<04:51,  1.16it/s] 33%|███▎      | 165/500 [02:04<03:29,  1.60it/s] 33%|███▎      | 167/500 [02:04<02:32,  2.18it/s] 34%|███▍      | 169/500 [02:04<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:11<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:11<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:11<03:21,  1.62it/s] 35%|███▌      | 177/500 [02:11<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:11<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:18<06:21,  1.19s/it] 37%|███▋      | 183/500 [02:18<04:32,  1.16it/s] 37%|███▋      | 185/500 [02:18<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:18<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:18<01:45,  2.96it/s] 38%|███▊      | 191/500 [02:25<06:06,  1.18s/it] 39%|███▊      | 193/500 [02:25<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:25<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:25<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:25<01:40,  2.98it/s] 40%|████      | 201/500 [02:32<05:58,  1.20s/it] 41%|████      | 203/500 [02:32<04:15,  1.16it/s]Epoch:  137  	Training Loss: 0.00013761890295427293
Test Loss:  0.0002054884098470211
Valid Loss:  0.0001159415696747601
Epoch:  138  	Training Loss: 0.0001371410326100886
Test Loss:  0.00020522931299638003
Valid Loss:  0.00011596033436944708
Epoch:  139  	Training Loss: 0.00013668039173353463
Test Loss:  0.0002049775794148445
Valid Loss:  0.00011598282435443252
Epoch:  140  	Training Loss: 0.00013623558334074914
Test Loss:  0.0002047307207249105
Valid Loss:  0.00011589846690185368
Epoch:  141  	Training Loss: 0.00013580570521298796
Test Loss:  0.0002044881839537993
Valid Loss:  0.00011577652185223997
Epoch:  142  	Training Loss: 0.00013539017527364194
Test Loss:  0.00020460865925997496
Valid Loss:  0.00011547376197995618
Epoch:  143  	Training Loss: 0.00013503359514288604
Test Loss:  0.00020475860219448805
Valid Loss:  0.00011520295811351389
Epoch:  144  	Training Loss: 0.00013469794066622853
Test Loss:  0.00020493475312832743
Valid Loss:  0.000114961811050307
Epoch:  145  	Training Loss: 0.0001343812618870288
Test Loss:  0.00020513113122433424
Valid Loss:  0.00011474556959001347
Epoch:  146  	Training Loss: 0.00013408128870651126
Test Loss:  0.00020534491341095418
Valid Loss:  0.0001145528513006866
Epoch:  147  	Training Loss: 0.00013379749725572765
Test Loss:  0.00020557096286211163
Valid Loss:  0.00011437944340286776
Epoch:  148  	Training Loss: 0.00013352777750696987
Test Loss:  0.0002058079990092665
Valid Loss:  0.00011422393436077982
Epoch:  149  	Training Loss: 0.0001332713436568156
Test Loss:  0.0002060544939013198
Valid Loss:  0.0001140853128163144
Epoch:  150  	Training Loss: 0.00013302740990184247
Test Loss:  0.00020630736253224313
Valid Loss:  0.00011396085028536618
Epoch:  151  	Training Loss: 0.00013278114784043282
Test Loss:  0.00020656577544286847
Valid Loss:  0.00011378290946595371
Epoch:  152  	Training Loss: 0.00013250748452264816
Test Loss:  0.0002066421293420717
Valid Loss:  0.00011400335642974824
Epoch:  153  	Training Loss: 0.00013229945034254342
Test Loss:  0.00020667482749558985
Valid Loss:  0.00011420877854106948
Epoch:  154  	Training Loss: 0.00013211462646722794
Test Loss:  0.00020666656200774014
Valid Loss:  0.00011439822264946997
Epoch:  155  	Training Loss: 0.00013195016072131693
Test Loss:  0.00020661242888309062
Valid Loss:  0.00011456617357907817
Epoch:  156  	Training Loss: 0.00013180443784222007
Test Loss:  0.00020652984676416963
Valid Loss:  0.00011472195910755545
Epoch:  157  	Training Loss: 0.00013167345605324954
Test Loss:  0.00020640084403567016
Valid Loss:  0.00011485307186376303
Epoch:  158  	Training Loss: 0.00013155877240933478
Test Loss:  0.0002062560961348936
Valid Loss:  0.00011497506056912243
Epoch:  159  	Training Loss: 0.0001314529508817941
Test Loss:  0.00020608815248124301
Valid Loss:  0.00011508223542477936
Epoch:  160  	Training Loss: 0.00013135516201145947
Test Loss:  0.00020591143402270973
Valid Loss:  0.00011518545943545178
Epoch:  161  	Training Loss: 0.00013126317935530096
Test Loss:  0.00020573010260704905
Valid Loss:  0.00011528717004694045
Epoch:  162  	Training Loss: 0.00013117605703882873
Test Loss:  0.00020537956152111292
Valid Loss:  0.00011523801367729902
Epoch:  163  	Training Loss: 0.0001311369996983558
Test Loss:  0.00020507739100139588
Valid Loss:  0.00011520869884407148
Epoch:  164  	Training Loss: 0.00013110224972479045
Test Loss:  0.000204817159101367
Valid Loss:  0.00011519269901327789
Epoch:  165  	Training Loss: 0.0001310703664785251
Test Loss:  0.00020458651124499738
Valid Loss:  0.00011518767132656649
Epoch:  166  	Training Loss: 0.00013104118988849223
Test Loss:  0.00020438199862837791
Valid Loss:  0.0001151909091277048
Epoch:  167  	Training Loss: 0.00013101348304189742
Test Loss:  0.0002041986444965005
Valid Loss:  0.00011520097905304283
Epoch:  168  	Training Loss: 0.00013098752242513
Test Loss:  0.00020403350936248899
Valid Loss:  0.00011521556007210165
Epoch:  169  	Training Loss: 0.00013096259499434382
Test Loss:  0.00020388263510540128
Valid Loss:  0.0001152343611465767
Epoch:  170  	Training Loss: 0.00013093890447635204
Test Loss:  0.000203743577003479
Valid Loss:  0.00011525525769684464
Epoch:  171  	Training Loss: 0.00013091620348859578
Test Loss:  0.00020361511269584298
Valid Loss:  0.00011527921014931053
Epoch:  172  	Training Loss: 0.00013089404092170298
Test Loss:  0.00020347483223304152
Valid Loss:  0.00011534802615642548
Epoch:  173  	Training Loss: 0.00013085048703942448
Test Loss:  0.00020332960411906242
Valid Loss:  0.00011541041021700948
Epoch:  174  	Training Loss: 0.00013080939243081957
Test Loss:  0.00020318197493907064
Valid Loss:  0.00011546796304173768
Epoch:  175  	Training Loss: 0.0001307705679209903
Test Loss:  0.0002030331816058606
Valid Loss:  0.00011552193609531969
Epoch:  176  	Training Loss: 0.0001307333295699209
Test Loss:  0.0002028847229667008
Valid Loss:  0.00011557049583643675
Epoch:  177  	Training Loss: 0.00013069729902781546
Test Loss:  0.00020273640984669328
Valid Loss:  0.0001156173602794297
Epoch:  178  	Training Loss: 0.00013066308747511357
Test Loss:  0.0002025910944212228
Valid Loss:  0.00011566113971639425
Epoch:  179  	Training Loss: 0.0001306300109717995
Test Loss:  0.00020245072664692998
Valid Loss:  0.00011570323840714991
Epoch:  180  	Training Loss: 0.00013059782213531435
Test Loss:  0.00020232031238265336
Valid Loss:  0.00011574233940336853
Epoch:  181  	Training Loss: 0.0001305671758018434
Test Loss:  0.00020219263387843966
Valid Loss:  0.00011578071280382574
Epoch:  182  	Training Loss: 0.00013053719885647297
Test Loss:  0.00020219097496010363
Valid Loss:  0.0001158829327323474
Epoch:  183  	Training Loss: 0.00012888535275124013
Test Loss:  0.0002001546963583678
Valid Loss:  0.00011494544742163271
Epoch:  184  	Training Loss: 0.00012735906057059765
Test Loss:  0.00020018310169689357
Valid Loss:  0.00011476913641672581
Epoch:  185  	Training Loss: 0.00012586015509441495
Test Loss:  0.00019884496578015387
Valid Loss:  0.0001139000742114149
Epoch:  186  	Training Loss: 0.00012434757081791759
Test Loss:  0.00019833861733786762
Valid Loss:  0.0001133525074692443
Epoch:  187  	Training Loss: 0.00012296615750528872
Test Loss:  0.00019718753173947334
Valid Loss:  0.00011258987069595605
Epoch:  188  	Training Loss: 0.00012169813271611929
Test Loss:  0.00019661585974972695
Valid Loss:  0.0001120422821259126
Epoch:  189  	Training Loss: 0.00012049243377987295
Test Loss:  0.0001957970962394029
Valid Loss:  0.00011130972416140139
Epoch:  190  	Training Loss: 0.0001192264971905388
Test Loss:  0.00019537114712875336
Valid Loss:  0.00011070926848333329
Epoch:  191  	Training Loss: 0.00011799166532000527
Test Loss:  0.0001947847631527111
Valid Loss:  0.00011005180567735806
Epoch:  192  	Training Loss: 0.00011676657595671713
Test Loss:  0.00019566569244489074
Valid Loss:  0.00011025097774108872
Epoch:  193  	Training Loss: 0.00011597418051678687
Test Loss:  0.00019607097783591598
Valid Loss:  0.0001102384994737804
Epoch:  194  	Training Loss: 0.00011528949107741937
Test Loss:  0.00019609194714576006
Valid Loss:  0.0001101397501770407
Epoch:  195  	Training Loss: 0.0001146628346759826
Test Loss:  0.00019603778491728008
Valid Loss:  0.0001100162262446247
Epoch:  196  	Training Loss: 0.00011407571582822129
Test Loss:  0.00019594328477978706
Valid Loss:  0.00010985475091729313
Epoch:  197  	Training Loss: 0.00011349367559887469
Test Loss:  0.00019584473920986056
Valid Loss:  0.00010971521987812594
Epoch:  198  	Training Loss: 0.00011295046715531498
Test Loss:  0.0001957412896445021
Valid Loss:  0.00010959293285850435
Epoch:  199  	Training Loss: 0.00011244255438214168
Test Loss:  0.00019563359091989696
Valid Loss:  0.00010948773706331849
Epoch:  200  	Training Loss: 0.0001119587614084594
Test Loss:  0.0001955188054125756
Valid Loss:  0.00010936109174508601
Epoch:  201  	Training Loss: 0.00011147395707666874
Test Loss:  0.00019541254732757807
Valid Loss:  0.00010925790411420166
Epoch:  202  	Training Loss: 0.00011101577547378838
Test Loss:  0.00019643928681034595
Valid Loss:  0.00010894789738813415
Epoch:  203  	Training Loss: 0.00011047931911889464
Test Loss:  0.0001971767342183739
Valid Loss:  0.0001085278854588978
 41%|████      | 205/500 [02:32<03:03,  1.61it/s] 41%|████▏     | 207/500 [02:32<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:32<01:38,  2.95it/s] 42%|████▏     | 211/500 [02:39<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:39<04:09,  1.15it/s] 43%|████▎     | 215/500 [02:39<02:58,  1.59it/s] 43%|████▎     | 217/500 [02:39<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:39<01:36,  2.93it/s] 44%|████▍     | 221/500 [02:45<05:33,  1.20s/it] 45%|████▍     | 223/500 [02:46<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:46<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:46<02:03,  2.20it/s] 46%|████▌     | 229/500 [02:46<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:52<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:52<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:53<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:53<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:53<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:59<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:59<03:40,  1.16it/s] 49%|████▉     | 245/500 [03:00<02:38,  1.60it/s] 49%|████▉     | 247/500 [03:00<01:55,  2.19it/s] 50%|████▉     | 249/500 [03:00<01:25,  2.95it/s] 50%|█████     | 251/500 [03:06<04:52,  1.18s/it] 51%|█████     | 253/500 [03:06<03:30,  1.18it/s] 51%|█████     | 255/500 [03:06<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:07<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:07<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:13<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:13<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:13<02:23,  1.63it/s] 53%|█████▎    | 267/500 [03:13<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:14<01:18,  2.95it/s]Epoch:  204  	Training Loss: 0.00010969923459924757
Test Loss:  0.00019743305165320635
Valid Loss:  0.00010811726679094136
Epoch:  205  	Training Loss: 0.00010877889872062951
Test Loss:  0.00019734367378987372
Valid Loss:  0.00010771072265924886
Epoch:  206  	Training Loss: 0.00010782251774799079
Test Loss:  0.00019645487191155553
Valid Loss:  0.00010750997898867354
Epoch:  207  	Training Loss: 0.00010710657079471275
Test Loss:  0.00019513326697051525
Valid Loss:  0.00010744995961431414
Epoch:  208  	Training Loss: 0.00010669337643776089
Test Loss:  0.0001942059607245028
Valid Loss:  0.00010742224549176171
Epoch:  209  	Training Loss: 0.00010648142779245973
Test Loss:  0.00019290762429591268
Valid Loss:  0.00010740139987319708
Epoch:  210  	Training Loss: 0.00010637044033501297
Test Loss:  0.00019280392734799534
Valid Loss:  0.00010743330494733527
Epoch:  211  	Training Loss: 0.00010628901509335265
Test Loss:  0.00019242112466599792
Valid Loss:  0.00010744905011961237
Epoch:  212  	Training Loss: 0.00010622832633089274
Test Loss:  0.0001926171244122088
Valid Loss:  0.00010781368473544717
Epoch:  213  	Training Loss: 0.0001060864597093314
Test Loss:  0.0001925038523040712
Valid Loss:  0.00010804606426972896
Epoch:  214  	Training Loss: 0.00010597342770779505
Test Loss:  0.0001922775845741853
Valid Loss:  0.00010820366151165217
Epoch:  215  	Training Loss: 0.00010587117867544293
Test Loss:  0.00019201988470740616
Valid Loss:  0.00010831259714905173
Epoch:  216  	Training Loss: 0.00010577481589280069
Test Loss:  0.00019176429486833513
Valid Loss:  0.00010838926391443238
Epoch:  217  	Training Loss: 0.00010568254219833761
Test Loss:  0.00019152185996063054
Valid Loss:  0.00010843975906027481
Epoch:  218  	Training Loss: 0.0001055929678841494
Test Loss:  0.00019129487918689847
Valid Loss:  0.00010847002704394981
Epoch:  219  	Training Loss: 0.00010550541628617793
Test Loss:  0.00019108399283140898
Valid Loss:  0.00010848242527572438
Epoch:  220  	Training Loss: 0.00010541958909016103
Test Loss:  0.00019089074339717627
Valid Loss:  0.00010848151578102261
Epoch:  221  	Training Loss: 0.00010533462045714259
Test Loss:  0.00019070866983383894
Valid Loss:  0.00010846686200238764
Epoch:  222  	Training Loss: 0.00010525088873691857
Test Loss:  0.00018992985133081675
Valid Loss:  0.00010780378215713426
Epoch:  223  	Training Loss: 0.00010487549297977239
Test Loss:  0.0001894346351036802
Valid Loss:  0.00010726175969466567
Epoch:  224  	Training Loss: 0.00010458922770339996
Test Loss:  0.00018913057283498347
Valid Loss:  0.00010680562991183251
Epoch:  225  	Training Loss: 0.00010435993317514658
Test Loss:  0.00018895629909820855
Valid Loss:  0.00010641317203408107
Epoch:  226  	Training Loss: 0.00010417002340545878
Test Loss:  0.00018886780890170485
Valid Loss:  0.00010607115109451115
Epoch:  227  	Training Loss: 0.00010400875908089802
Test Loss:  0.0001888387487269938
Valid Loss:  0.00010576872591627762
Epoch:  228  	Training Loss: 0.00010386959183961153
Test Loss:  0.00018884807650465518
Valid Loss:  0.0001055013999575749
Epoch:  229  	Training Loss: 0.00010374872363172472
Test Loss:  0.0001888830738607794
Valid Loss:  0.00010526239202590659
Epoch:  230  	Training Loss: 0.00010363453475292772
Test Loss:  0.00018892320804297924
Valid Loss:  0.0001050229329848662
Epoch:  231  	Training Loss: 0.00010351724631618708
Test Loss:  0.0001889804843813181
Valid Loss:  0.00010480984929017723
Epoch:  232  	Training Loss: 0.00010341384768253192
Test Loss:  0.00019022000196855515
Valid Loss:  0.00010557799396337941
Epoch:  233  	Training Loss: 0.00010312606173101813
Test Loss:  0.0001905417157104239
Valid Loss:  0.00010600486712064594
Epoch:  234  	Training Loss: 0.00010300139547325671
Test Loss:  0.00019052100833505392
Valid Loss:  0.00010627653682604432
Epoch:  235  	Training Loss: 0.00010290632781106979
Test Loss:  0.00019037265155930072
Valid Loss:  0.0001064699245034717
Epoch:  236  	Training Loss: 0.00010282350558554754
Test Loss:  0.00019018474267795682
Valid Loss:  0.00010662381100701168
Epoch:  237  	Training Loss: 0.00010274721716996282
Test Loss:  0.0001900080096675083
Valid Loss:  0.00010676048987079412
Epoch:  238  	Training Loss: 0.00010267601464875042
Test Loss:  0.0001898460031952709
Valid Loss:  0.00010688293696148321
Epoch:  239  	Training Loss: 0.00010260897397529334
Test Loss:  0.00018969850498251617
Valid Loss:  0.00010699310223571956
Epoch:  240  	Training Loss: 0.0001025454475893639
Test Loss:  0.00018956811982207
Valid Loss:  0.00010709228808991611
Epoch:  241  	Training Loss: 0.00010248521721223369
Test Loss:  0.00018944971088785678
Valid Loss:  0.00010718049452407286
Epoch:  242  	Training Loss: 0.00010242745338473469
Test Loss:  0.00018636589811649173
Valid Loss:  0.00010633126657921821
Epoch:  243  	Training Loss: 0.0001021646021399647
Test Loss:  0.00018718450155574828
Valid Loss:  0.00010634317004587501
Epoch:  244  	Training Loss: 0.00010194368951488286
Test Loss:  0.00018589703540783376
Valid Loss:  0.00010590559395495802
Epoch:  245  	Training Loss: 0.00010175360512221232
Test Loss:  0.00018584926147013903
Valid Loss:  0.00010575715714367107
Epoch:  246  	Training Loss: 0.00010158553050132468
Test Loss:  0.00018519266450311989
Valid Loss:  0.00010554559412412345
Epoch:  247  	Training Loss: 0.00010144106636289507
Test Loss:  0.00018494985124561936
Valid Loss:  0.0001054484600899741
Epoch:  248  	Training Loss: 0.00010132635361514986
Test Loss:  0.0001846162776928395
Valid Loss:  0.0001053221058100462
Epoch:  249  	Training Loss: 0.00010124873369932175
Test Loss:  0.0001844221114879474
Valid Loss:  0.00010521567310206592
Epoch:  250  	Training Loss: 0.00010118555655935779
Test Loss:  0.00018423519213683903
Valid Loss:  0.0001051146027748473
Epoch:  251  	Training Loss: 0.00010114199540112168
Test Loss:  0.00018405796436127275
Valid Loss:  0.00010501075303182006
Epoch:  252  	Training Loss: 0.00010110325820278376
Test Loss:  0.00018409165204502642
Valid Loss:  0.0001048759586410597
Epoch:  253  	Training Loss: 0.00010108221613336354
Test Loss:  0.0001841060584411025
Valid Loss:  0.00010474647569935769
Epoch:  254  	Training Loss: 0.00010106326953973621
Test Loss:  0.000184107237146236
Valid Loss:  0.00010462015779921785
Epoch:  255  	Training Loss: 0.00010104491957463324
Test Loss:  0.00018409951007924974
Valid Loss:  0.00010449945693835616
Epoch:  256  	Training Loss: 0.00010102793748956174
Test Loss:  0.00018408268806524575
Valid Loss:  0.00010438161552883685
Epoch:  257  	Training Loss: 0.00010101179941557348
Test Loss:  0.0001840599870774895
Valid Loss:  0.00010426787775941193
Epoch:  258  	Training Loss: 0.00010099648352479562
Test Loss:  0.00018403393914923072
Valid Loss:  0.0001041576178977266
Epoch:  259  	Training Loss: 0.00010098209895659238
Test Loss:  0.00018400364206172526
Valid Loss:  0.00010405138891655952
Epoch:  260  	Training Loss: 0.00010096827463712543
Test Loss:  0.0001839728356571868
Valid Loss:  0.00010394818673375994
Epoch:  261  	Training Loss: 0.00010095526522491127
Test Loss:  0.00018393871141597629
Valid Loss:  0.00010384825873188674
Epoch:  262  	Training Loss: 0.0001009429688565433
Test Loss:  0.00018313911277800798
Valid Loss:  0.00010315347753930837
Epoch:  263  	Training Loss: 0.00010072244185721502
Test Loss:  0.00018324816483072937
Valid Loss:  0.00010272291547153145
Epoch:  264  	Training Loss: 0.00010052543075289577
Test Loss:  0.00018321952666155994
Valid Loss:  0.00010230022598989308
Epoch:  265  	Training Loss: 0.00010033673606812954
Test Loss:  0.0001831845729611814
Valid Loss:  0.00010191218461841345
Epoch:  266  	Training Loss: 0.00010015496809501201
Test Loss:  0.00018312987231183797
Valid Loss:  0.00010154944902751595
Epoch:  267  	Training Loss: 9.997878078138456e-05
Test Loss:  0.00018305875710211694
Valid Loss:  0.00010120997467311099
Epoch:  268  	Training Loss: 9.980743925552815e-05
Test Loss:  0.00018297333735972643
Valid Loss:  0.0001008920808089897
Epoch:  269  	Training Loss: 9.964015043806285e-05
Test Loss:  0.00018287454440724105
Valid Loss:  0.00010059153282782063
Epoch:  270  	Training Loss: 9.947577927960083e-05
Test Loss:  0.00018276262562721968
Valid Loss:   54%|█████▍    | 271/500 [03:20<04:36,  1.21s/it] 55%|█████▍    | 273/500 [03:20<03:16,  1.15it/s] 55%|█████▌    | 275/500 [03:20<02:21,  1.59it/s] 55%|█████▌    | 277/500 [03:20<01:42,  2.18it/s] 56%|█████▌    | 279/500 [03:21<01:15,  2.94it/s] 56%|█████▌    | 281/500 [03:27<04:22,  1.20s/it] 57%|█████▋    | 283/500 [03:27<03:06,  1.16it/s] 57%|█████▋    | 285/500 [03:27<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:27<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:27<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:34<04:13,  1.21s/it] 59%|█████▊    | 293/500 [03:34<03:00,  1.15it/s] 59%|█████▉    | 295/500 [03:34<02:08,  1.59it/s] 59%|█████▉    | 297/500 [03:34<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:34<01:08,  2.93it/s] 60%|██████    | 301/500 [03:41<03:56,  1.19s/it] 61%|██████    | 303/500 [03:41<02:48,  1.17it/s] 61%|██████    | 305/500 [03:41<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:41<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:41<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:48<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:48<02:40,  1.16it/s] 63%|██████▎   | 315/500 [03:48<01:56,  1.59it/s] 63%|██████▎   | 317/500 [03:48<01:24,  2.18it/s] 64%|██████▍   | 319/500 [03:48<01:01,  2.92it/s] 64%|██████▍   | 321/500 [03:55<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:55<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:55<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:55<01:18,  2.19it/s] 66%|██████▌   | 329/500 [03:55<00:58,  2.95it/s] 66%|██████▌   | 331/500 [04:02<03:25,  1.21s/it] 67%|██████▋   | 333/500 [04:02<02:25,  1.15it/s] 67%|██████▋   | 335/500 [04:02<01:43,  1.59it/s] 67%|██████▋   | 337/500 [04:02<01:15,  2.16it/s]0.00010030761768575758
Epoch:  271  	Training Loss: 9.93149442365393e-05
Test Loss:  0.00018264120444655418
Valid Loss:  0.0001000373886199668
Epoch:  272  	Training Loss: 9.915123519022018e-05
Test Loss:  0.0001836150768212974
Valid Loss:  0.0001007665996439755
Epoch:  273  	Training Loss: 9.888886415865272e-05
Test Loss:  0.00018349249148741364
Valid Loss:  0.00010106145782629028
Epoch:  274  	Training Loss: 9.873713133856654e-05
Test Loss:  0.0001831257832236588
Valid Loss:  0.00010123816173290834
Epoch:  275  	Training Loss: 9.860136196948588e-05
Test Loss:  0.00018272189481649548
Valid Loss:  0.00010137706703972071
Epoch:  276  	Training Loss: 9.847493492998183e-05
Test Loss:  0.00018232902220916003
Valid Loss:  0.0001015003799693659
Epoch:  277  	Training Loss: 9.83565259957686e-05
Test Loss:  0.00018195644952356815
Valid Loss:  0.00010161010141018778
Epoch:  278  	Training Loss: 9.824473818298429e-05
Test Loss:  0.0001816043513827026
Valid Loss:  0.0001017093745758757
Epoch:  279  	Training Loss: 9.81392731773667e-05
Test Loss:  0.00018127210205420852
Valid Loss:  0.0001017988397506997
Epoch:  280  	Training Loss: 9.803837019717321e-05
Test Loss:  0.0001809568639146164
Valid Loss:  0.00010187743464484811
Epoch:  281  	Training Loss: 9.794188372325152e-05
Test Loss:  0.00018065795302391052
Valid Loss:  0.0001019466872094199
Epoch:  282  	Training Loss: 9.784894064068794e-05
Test Loss:  0.00017877497884910554
Valid Loss:  0.00010158892837353051
Epoch:  283  	Training Loss: 9.74915164988488e-05
Test Loss:  0.000178703194251284
Valid Loss:  0.00010165598359890282
Epoch:  284  	Training Loss: 9.715191117720678e-05
Test Loss:  0.00017740571638569236
Valid Loss:  0.00010138325160369277
Epoch:  285  	Training Loss: 9.683037205832079e-05
Test Loss:  0.00017710596148390323
Valid Loss:  0.00010132927127415314
Epoch:  286  	Training Loss: 9.652089647715911e-05
Test Loss:  0.00017613827367313206
Valid Loss:  0.0001010867563309148
Epoch:  287  	Training Loss: 9.622049401514232e-05
Test Loss:  0.00017571894568391144
Valid Loss:  0.00010098709026351571
Epoch:  288  	Training Loss: 9.592791320756078e-05
Test Loss:  0.0001749312796164304
Valid Loss:  0.00010077170009026304
Epoch:  289  	Training Loss: 9.564196807332337e-05
Test Loss:  0.00017447341815568507
Valid Loss:  0.00010063473746413365
Epoch:  290  	Training Loss: 9.53612761804834e-05
Test Loss:  0.00017380159988533705
Valid Loss:  0.00010042340727522969
Epoch:  291  	Training Loss: 9.50860558077693e-05
Test Loss:  0.0001733500394038856
Valid Loss:  0.0001002518692985177
Epoch:  292  	Training Loss: 9.481846063863486e-05
Test Loss:  0.00017306639347225428
Valid Loss:  0.00010013718565460294
Epoch:  293  	Training Loss: 9.47950393310748e-05
Test Loss:  0.00017282168846577406
Valid Loss:  0.00010003249917645007
Epoch:  294  	Training Loss: 9.477481944486499e-05
Test Loss:  0.00017261994071304798
Valid Loss:  9.99418698484078e-05
Epoch:  295  	Training Loss: 9.475757542531937e-05
Test Loss:  0.00017244213086087257
Valid Loss:  9.985750511987135e-05
Epoch:  296  	Training Loss: 9.47420485317707e-05
Test Loss:  0.00017228520300704986
Valid Loss:  9.977949957828969e-05
Epoch:  297  	Training Loss: 9.472758392803371e-05
Test Loss:  0.00017214397666975856
Valid Loss:  9.970690007321537e-05
Epoch:  298  	Training Loss: 9.471391240367666e-05
Test Loss:  0.00017201658920384943
Valid Loss:  9.963737102225423e-05
Epoch:  299  	Training Loss: 9.470048826187849e-05
Test Loss:  0.0001719006395433098
Valid Loss:  9.95712325675413e-05
Epoch:  300  	Training Loss: 9.468804637435824e-05
Test Loss:  0.00017179391579702497
Valid Loss:  9.950767707778141e-05
Epoch:  301  	Training Loss: 9.467582276556641e-05
Test Loss:  0.00017169542843475938
Valid Loss:  9.944669727701694e-05
Epoch:  302  	Training Loss: 9.466390474699438e-05
Test Loss:  0.00017146821483038366
Valid Loss:  9.899225551635027e-05
Epoch:  303  	Training Loss: 9.444043826078996e-05
Test Loss:  0.00017118487448897213
Valid Loss:  9.85520746326074e-05
Epoch:  304  	Training Loss: 9.422231232747436e-05
Test Loss:  0.00017088164167944342
Valid Loss:  9.812720236368477e-05
Epoch:  305  	Training Loss: 9.400957787875086e-05
Test Loss:  0.00017056975048035383
Valid Loss:  9.77187737589702e-05
Epoch:  306  	Training Loss: 9.380125266034156e-05
Test Loss:  0.00017025561828631908
Valid Loss:  9.732400940265507e-05
Epoch:  307  	Training Loss: 9.359721298096702e-05
Test Loss:  0.00016994027828332037
Valid Loss:  9.694360778667033e-05
Epoch:  308  	Training Loss: 9.339747339254245e-05
Test Loss:  0.00016962442896328866
Valid Loss:  9.657523332862183e-05
Epoch:  309  	Training Loss: 9.320082608610392e-05
Test Loss:  0.00016930833226069808
Valid Loss:  9.622015932109207e-05
Epoch:  310  	Training Loss: 9.300866076955572e-05
Test Loss:  0.00016899267211556435
Valid Loss:  9.587517706677318e-05
Epoch:  311  	Training Loss: 9.28197696339339e-05
Test Loss:  0.00016867785598151386
Valid Loss:  9.553480776958168e-05
Epoch:  312  	Training Loss: 9.26340653677471e-05
Test Loss:  0.00016883673379197717
Valid Loss:  9.546068031340837e-05
Epoch:  313  	Training Loss: 9.26199572859332e-05
Test Loss:  0.00016898484318517148
Valid Loss:  9.539305028738454e-05
Epoch:  314  	Training Loss: 9.26077482290566e-05
Test Loss:  0.00016912404680624604
Valid Loss:  9.533113916404545e-05
Epoch:  315  	Training Loss: 9.259711805498227e-05
Test Loss:  0.000169253908097744
Valid Loss:  9.527419751975685e-05
Epoch:  316  	Training Loss: 9.25877975532785e-05
Test Loss:  0.0001693753438303247
Valid Loss:  9.522234904579818e-05
Epoch:  317  	Training Loss: 9.257975034415722e-05
Test Loss:  0.00016948823758866638
Valid Loss:  9.517461148789153e-05
Epoch:  318  	Training Loss: 9.257275087293237e-05
Test Loss:  0.00016959369531832635
Valid Loss:  9.513154509477317e-05
Epoch:  319  	Training Loss: 9.256695193471387e-05
Test Loss:  0.00016969209536910057
Valid Loss:  9.509145456831902e-05
Epoch:  320  	Training Loss: 9.256145131075755e-05
Test Loss:  0.00016978361236397177
Valid Loss:  9.505443449597806e-05
Epoch:  321  	Training Loss: 9.25568092497997e-05
Test Loss:  0.0001698696578387171
Valid Loss:  9.50207031564787e-05
Epoch:  322  	Training Loss: 9.2552654678002e-05
Test Loss:  0.00016936566680669785
Valid Loss:  9.490329102845863e-05
Epoch:  323  	Training Loss: 9.251348092220724e-05
Test Loss:  0.00016914334264583886
Valid Loss:  9.488798241363838e-05
Epoch:  324  	Training Loss: 9.248430433217436e-05
Test Loss:  0.0001689835189608857
Valid Loss:  9.487578790867701e-05
Epoch:  325  	Training Loss: 9.246086119674146e-05
Test Loss:  0.0001688791817286983
Valid Loss:  9.487483475822955e-05
Epoch:  326  	Training Loss: 9.243800741387531e-05
Test Loss:  0.00016877407324500382
Valid Loss:  9.48615197557956e-05
Epoch:  327  	Training Loss: 9.242421947419643e-05
Test Loss:  0.00016866550140548497
Valid Loss:  9.483772737439722e-05
Epoch:  328  	Training Loss: 9.241262887371704e-05
Test Loss:  0.00016858380695339292
Valid Loss:  9.482244058744982e-05
Epoch:  329  	Training Loss: 9.240233339369297e-05
Test Loss:  0.00016848604718688875
Valid Loss:  9.479474101681262e-05
Epoch:  330  	Training Loss: 9.239416976924986e-05
Test Loss:  0.00016838643932715058
Valid Loss:  9.475863771513104e-05
Epoch:  331  	Training Loss: 9.238655911758542e-05
Test Loss:  0.00016831158427521586
Valid Loss:  9.473011596128345e-05
Epoch:  332  	Training Loss: 9.23791594686918e-05
Test Loss:  0.00016876735026016831
Valid Loss:  9.505967318546027e-05
Epoch:  333  	Training Loss: 9.225180838257074e-05
Test Loss:  0.00016880102339200675
Valid Loss:  9.520366438664496e-05
Epoch:  334  	Training Loss: 9.216563921654597e-05
Test Loss:  0.0001686615141807124
Valid Loss:  9.526482608634979e-05
Epoch:  335  	Training Loss: 9.208572009811178e-05
Test Loss:  0.0001684650924289599
Valid Loss:  9.529024828225374e-05
Epoch:  336  	Training Loss: 9.201122156810015e-05
Test Loss:  0.0001682885631453246
Valid Loss:  9.53098206082359e-05
Epoch:  337  	Training Loss: 9.19411177164875e-05
Test Loss:  0.00016810237138997763
Valid Loss:  9.531609248369932e-05
Epoch:  338  	Training Loss: 9.187147952616215e-05
Test Loss:  0.00016791974485386163
 68%|██████▊   | 339/500 [04:02<00:55,  2.91it/s] 68%|██████▊   | 341/500 [04:09<03:13,  1.21s/it] 69%|██████▊   | 343/500 [04:09<02:17,  1.15it/s] 69%|██████▉   | 345/500 [04:09<01:37,  1.58it/s] 69%|██████▉   | 347/500 [04:09<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:09<00:51,  2.92it/s] 70%|███████   | 351/500 [04:16<02:59,  1.20s/it] 71%|███████   | 353/500 [04:16<02:06,  1.16it/s] 71%|███████   | 355/500 [04:16<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:16<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:16<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:23<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:23<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:23<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:23<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:23<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:30<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:30<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:30<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:30<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:30<00:40,  2.95it/s] 76%|███████▌  | 381/500 [04:36<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:37<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:37<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:37<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:37<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:43<02:11,  1.21s/it] 79%|███████▊  | 393/500 [04:44<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:44<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:44<00:47,  2.18it/s] 80%|███████▉  | 399/500 [04:44<00:34,  2.94it/s] 80%|████████  | 401/500 [04:50<01:58,  1.19s/it] 81%|████████  | 403/500 [04:51<01:23,  1.17it/s] 81%|████████  | 405/500 [04:51<00:58,  1.61it/s]Valid Loss:  9.531475370749831e-05
Epoch:  339  	Training Loss: 9.180251799989492e-05
Test Loss:  0.0001677404943620786
Valid Loss:  9.530781244393438e-05
Epoch:  340  	Training Loss: 9.173439320875332e-05
Test Loss:  0.00016756539116613567
Valid Loss:  9.529510862194002e-05
Epoch:  341  	Training Loss: 9.166711970465258e-05
Test Loss:  0.00016739449347369373
Valid Loss:  9.527824295219034e-05
Epoch:  342  	Training Loss: 9.160023182630539e-05
Test Loss:  0.0001676046522334218
Valid Loss:  9.4967195764184e-05
Epoch:  343  	Training Loss: 9.154198050964624e-05
Test Loss:  0.00016773419338278472
Valid Loss:  9.469912038184702e-05
Epoch:  344  	Training Loss: 9.149269317276776e-05
Test Loss:  0.0001678112312220037
Valid Loss:  9.446449985262007e-05
Epoch:  345  	Training Loss: 9.145099465968087e-05
Test Loss:  0.00016784938634373248
Valid Loss:  9.425637108506635e-05
Epoch:  346  	Training Loss: 9.141440386883914e-05
Test Loss:  0.00016785392654128373
Valid Loss:  9.406758908880875e-05
Epoch:  347  	Training Loss: 9.138086170423776e-05
Test Loss:  0.0001678332919254899
Valid Loss:  9.38947923714295e-05
Epoch:  348  	Training Loss: 9.135006985161453e-05
Test Loss:  0.0001677933760220185
Valid Loss:  9.373416833113879e-05
Epoch:  349  	Training Loss: 9.132154809776694e-05
Test Loss:  0.00016774015966802835
Valid Loss:  9.358472016174346e-05
Epoch:  350  	Training Loss: 9.129508543992415e-05
Test Loss:  0.00016767658235039562
Valid Loss:  9.344433783553541e-05
Epoch:  351  	Training Loss: 9.127041994361207e-05
Test Loss:  0.00016760775179136544
Valid Loss:  9.331217734143138e-05
Epoch:  352  	Training Loss: 9.12470422917977e-05
Test Loss:  0.00016650751058477908
Valid Loss:  9.295693598687649e-05
Epoch:  353  	Training Loss: 9.086060163099319e-05
Test Loss:  0.00016622632392682135
Valid Loss:  9.287526336265728e-05
Epoch:  354  	Training Loss: 9.049808431882411e-05
Test Loss:  0.0001657193643040955
Valid Loss:  9.270893497159705e-05
Epoch:  355  	Training Loss: 9.015396062750369e-05
Test Loss:  0.00016546326514799148
Valid Loss:  9.26077991607599e-05
Epoch:  356  	Training Loss: 8.982131112134084e-05
Test Loss:  0.00016499534831382334
Valid Loss:  9.243563545169309e-05
Epoch:  357  	Training Loss: 8.949915354605764e-05
Test Loss:  0.0001647766912356019
Valid Loss:  9.23282714211382e-05
Epoch:  358  	Training Loss: 8.918782987166196e-05
Test Loss:  0.00016434353892691433
Valid Loss:  9.215428872266784e-05
Epoch:  359  	Training Loss: 8.888563024811447e-05
Test Loss:  0.0001640436821617186
Valid Loss:  9.201513603329659e-05
Epoch:  360  	Training Loss: 8.859529043547809e-05
Test Loss:  0.0001637685054447502
Valid Loss:  9.187529212795198e-05
Epoch:  361  	Training Loss: 8.831842569634318e-05
Test Loss:  0.00016360983136110008
Valid Loss:  9.177291940432042e-05
Epoch:  362  	Training Loss: 8.804992830846459e-05
Test Loss:  0.00016432795382570475
Valid Loss:  9.183724614558741e-05
Epoch:  363  	Training Loss: 8.798840281087905e-05
Test Loss:  0.00016458577010780573
Valid Loss:  9.181951463688165e-05
Epoch:  364  	Training Loss: 8.794889436103404e-05
Test Loss:  0.0001646912714932114
Valid Loss:  9.177738684229553e-05
Epoch:  365  	Training Loss: 8.791162690613419e-05
Test Loss:  0.0001647446770220995
Valid Loss:  9.173066064249724e-05
Epoch:  366  	Training Loss: 8.787539263721555e-05
Test Loss:  0.00016477916506119072
Valid Loss:  9.16860590223223e-05
Epoch:  367  	Training Loss: 8.783931116340682e-05
Test Loss:  0.0001648077741265297
Valid Loss:  9.164527000393718e-05
Epoch:  368  	Training Loss: 8.780381904216483e-05
Test Loss:  0.00016483283252455294
Valid Loss:  9.160835179500282e-05
Epoch:  369  	Training Loss: 8.776919275987893e-05
Test Loss:  0.00016479822807013988
Valid Loss:  9.153952851193026e-05
Epoch:  370  	Training Loss: 8.773547597229481e-05
Test Loss:  0.00016485265223309398
Valid Loss:  9.15207783691585e-05
Epoch:  371  	Training Loss: 8.770127169555053e-05
Test Loss:  0.0001648525649216026
Valid Loss:  9.14807606022805e-05
Epoch:  372  	Training Loss: 8.766744576860219e-05
Test Loss:  0.0001644369913265109
Valid Loss:  9.127151861321181e-05
Epoch:  373  	Training Loss: 8.761566277826205e-05
Test Loss:  0.00016411495744250715
Valid Loss:  9.106926154345274e-05
Epoch:  374  	Training Loss: 8.757050818530843e-05
Test Loss:  0.0001638582325540483
Valid Loss:  9.087387297768146e-05
Epoch:  375  	Training Loss: 8.753019938012585e-05
Test Loss:  0.0001636507222428918
Valid Loss:  9.06846034922637e-05
Epoch:  376  	Training Loss: 8.749346307013184e-05
Test Loss:  0.0001634762593312189
Valid Loss:  9.050236258190125e-05
Epoch:  377  	Training Loss: 8.745906234253198e-05
Test Loss:  0.000163327029440552
Valid Loss:  9.03272521100007e-05
Epoch:  378  	Training Loss: 8.742690260987729e-05
Test Loss:  0.00016319629503414035
Valid Loss:  9.015838440973312e-05
Epoch:  379  	Training Loss: 8.739706390770152e-05
Test Loss:  0.0001630787446629256
Valid Loss:  8.999623241834342e-05
Epoch:  380  	Training Loss: 8.736854942981154e-05
Test Loss:  0.00016297216643579304
Valid Loss:  8.984117448562756e-05
Epoch:  381  	Training Loss: 8.734178845770657e-05
Test Loss:  0.00016287295147776604
Valid Loss:  8.969251939561218e-05
Epoch:  382  	Training Loss: 8.731649722903967e-05
Test Loss:  0.00016360232257284224
Valid Loss:  8.996362157631665e-05
Epoch:  383  	Training Loss: 8.724967483431101e-05
Test Loss:  0.000164005410624668
Valid Loss:  9.015889372676611e-05
Epoch:  384  	Training Loss: 8.72257660375908e-05
Test Loss:  0.00016422073531430215
Valid Loss:  9.030196815729141e-05
Epoch:  385  	Training Loss: 8.721600170247257e-05
Test Loss:  0.00016432837583124638
Valid Loss:  9.041093289852142e-05
Epoch:  386  	Training Loss: 8.721198537386954e-05
Test Loss:  0.0001643749128561467
Valid Loss:  9.049281652551144e-05
Epoch:  387  	Training Loss: 8.720927144167945e-05
Test Loss:  0.00016439167666248977
Valid Loss:  9.055693226400763e-05
Epoch:  388  	Training Loss: 8.720786718185991e-05
Test Loss:  0.00016439057071693242
Valid Loss:  9.060680167749524e-05
Epoch:  389  	Training Loss: 8.720647019799799e-05
Test Loss:  0.00016437102749478072
Valid Loss:  9.064024197869003e-05
Epoch:  390  	Training Loss: 8.720578625798225e-05
Test Loss:  0.00016436474106740206
Valid Loss:  9.067451901501045e-05
Epoch:  391  	Training Loss: 8.720466576050967e-05
Test Loss:  0.0001643560390220955
Valid Loss:  9.07019930309616e-05
Epoch:  392  	Training Loss: 8.720421465113759e-05
Test Loss:  0.00016310323553625494
Valid Loss:  8.987266483018175e-05
Epoch:  393  	Training Loss: 8.685509237693623e-05
Test Loss:  0.00016303907614201307
Valid Loss:  8.966067980509251e-05
Epoch:  394  	Training Loss: 8.661959873279557e-05
Test Loss:  0.00016312606749124825
Valid Loss:  8.954895019996911e-05
Epoch:  395  	Training Loss: 8.640001760795712e-05
Test Loss:  0.00016320394934155047
Valid Loss:  8.942221757024527e-05
Epoch:  396  	Training Loss: 8.616145350970328e-05
Test Loss:  0.00016331629012711346
Valid Loss:  8.934311335906386e-05
Epoch:  397  	Training Loss: 8.594747487222776e-05
Test Loss:  0.0001634199288673699
Valid Loss:  8.928935130825266e-05
Epoch:  398  	Training Loss: 8.575398533139378e-05
Test Loss:  0.00016351182421203703
Valid Loss:  8.925340080168098e-05
Epoch:  399  	Training Loss: 8.557878754800186e-05
Test Loss:  0.00016359105939045548
Valid Loss:  8.920865366235375e-05
Epoch:  400  	Training Loss: 8.541927672922611e-05
Test Loss:  0.00016365863848477602
Valid Loss:  8.916567458072677e-05
Epoch:  401  	Training Loss: 8.527379395673051e-05
Test Loss:  0.00016371702076867223
Valid Loss:  8.913748024497181e-05
Epoch:  402  	Training Loss: 8.514046930940822e-05
Test Loss:  0.00016298986156471074
Valid Loss:  8.890598110156134e-05
Epoch:  403  	Training Loss: 8.507849997840822e-05
Test Loss:  0.0001627227757126093
Valid Loss:  8.874351624399424e-05
Epoch:  404  	Training Loss: 8.502526179654524e-05
Test Loss:  0.00016251437773462385
Valid Loss:  8.859302761266008e-05
Epoch:  405  	Training Loss: 8.497424278175458e-05
Test Loss:  0.00016231529298238456
Valid Loss:  8.844883268466219e-05
Epoch:  406  	Training Loss: 8.492412598570809e-05
Test Loss:  0.00016211954061873257
 81%|████████▏ | 407/500 [04:51<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:51<00:30,  2.96it/s] 82%|████████▏ | 411/500 [04:57<01:48,  1.21s/it] 83%|████████▎ | 413/500 [04:58<01:16,  1.14it/s] 83%|████████▎ | 415/500 [04:58<00:54,  1.57it/s] 83%|████████▎ | 417/500 [04:58<00:38,  2.14it/s] 84%|████████▍ | 419/500 [04:58<00:28,  2.87it/s] 84%|████████▍ | 421/500 [05:04<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:05<01:06,  1.17it/s] 85%|████████▌ | 425/500 [05:05<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:05<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:05<00:23,  2.96it/s] 86%|████████▌ | 431/500 [05:11<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:11<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:12<00:40,  1.59it/s] 87%|████████▋ | 437/500 [05:12<00:29,  2.15it/s] 88%|████████▊ | 439/500 [05:12<00:21,  2.89it/s] 88%|████████▊ | 441/500 [05:18<01:11,  1.22s/it] 89%|████████▊ | 443/500 [05:19<00:49,  1.14it/s] 89%|████████▉ | 445/500 [05:19<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:19<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:19<00:17,  2.89it/s] 90%|█████████ | 451/500 [05:26<00:59,  1.22s/it] 91%|█████████ | 453/500 [05:26<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:26<00:28,  1.58it/s] 91%|█████████▏| 457/500 [05:26<00:19,  2.16it/s] 92%|█████████▏| 459/500 [05:26<00:14,  2.91it/s] 92%|█████████▏| 461/500 [05:32<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:33<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:33<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:33<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:33<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:39<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:39<00:23,  1.17it/s]Valid Loss:  8.830927254166454e-05
Epoch:  407  	Training Loss: 8.4876170149073e-05
Test Loss:  0.00016192827024497092
Valid Loss:  8.8174594566226e-05
Epoch:  408  	Training Loss: 8.482996054226533e-05
Test Loss:  0.00016173991025425494
Valid Loss:  8.804425306152552e-05
Epoch:  409  	Training Loss: 8.478464587824419e-05
Test Loss:  0.00016155460616573691
Valid Loss:  8.791805885266513e-05
Epoch:  410  	Training Loss: 8.474125934299082e-05
Test Loss:  0.00016137282364070415
Valid Loss:  8.779582276474684e-05
Epoch:  411  	Training Loss: 8.469926251564175e-05
Test Loss:  0.00016119382053148001
Valid Loss:  8.767806139076129e-05
Epoch:  412  	Training Loss: 8.465853170491755e-05
Test Loss:  0.0001611915504327044
Valid Loss:  8.769342093728483e-05
Epoch:  413  	Training Loss: 8.464702841592953e-05
Test Loss:  0.00016118941130116582
Valid Loss:  8.770892600296065e-05
Epoch:  414  	Training Loss: 8.463574340566993e-05
Test Loss:  0.00016118516214191914
Valid Loss:  8.772570436121896e-05
Epoch:  415  	Training Loss: 8.462497498840094e-05
Test Loss:  0.0001611793413758278
Valid Loss:  8.7742242612876e-05
Epoch:  416  	Training Loss: 8.461483230348676e-05
Test Loss:  0.0001611720654182136
Valid Loss:  8.775909373071045e-05
Epoch:  417  	Training Loss: 8.460483513772488e-05
Test Loss:  0.00016116624465212226
Valid Loss:  8.777575567364693e-05
Epoch:  418  	Training Loss: 8.459504169877619e-05
Test Loss:  0.00016115824109874666
Valid Loss:  8.779306517681107e-05
Epoch:  419  	Training Loss: 8.458652155240998e-05
Test Loss:  0.00016115348262246698
Valid Loss:  8.78145219758153e-05
Epoch:  420  	Training Loss: 8.457845979137346e-05
Test Loss:  0.00016114766185637563
Valid Loss:  8.783533121459186e-05
Epoch:  421  	Training Loss: 8.45709873829037e-05
Test Loss:  0.0001611403131391853
Valid Loss:  8.785625686869025e-05
Epoch:  422  	Training Loss: 8.456349314656109e-05
Test Loss:  0.00016058649634942412
Valid Loss:  8.778319897828624e-05
Epoch:  423  	Training Loss: 8.436932694166899e-05
Test Loss:  0.00016007984231691808
Valid Loss:  8.771288412390277e-05
Epoch:  424  	Training Loss: 8.418144716415554e-05
Test Loss:  0.00015960715245455503
Valid Loss:  8.764351514400914e-05
Epoch:  425  	Training Loss: 8.399784564971924e-05
Test Loss:  0.0001591574982739985
Valid Loss:  8.757199248066172e-05
Epoch:  426  	Training Loss: 8.381867519346997e-05
Test Loss:  0.00015872715448495
Valid Loss:  8.749694097787142e-05
Epoch:  427  	Training Loss: 8.364318637177348e-05
Test Loss:  0.00015831179916858673
Valid Loss:  8.742453064769506e-05
Epoch:  428  	Training Loss: 8.347097900696099e-05
Test Loss:  0.00015791004989296198
Valid Loss:  8.734731818549335e-05
Epoch:  429  	Training Loss: 8.330191485583782e-05
Test Loss:  0.00015752174658700824
Valid Loss:  8.726533269509673e-05
Epoch:  430  	Training Loss: 8.313594298670068e-05
Test Loss:  0.00015715209883637726
Valid Loss:  8.717876335140318e-05
Epoch:  431  	Training Loss: 8.297217573272064e-05
Test Loss:  0.00015679259377066046
Valid Loss:  8.708721725270152e-05
Epoch:  432  	Training Loss: 8.281126793008298e-05
Test Loss:  0.00015657296171411872
Valid Loss:  8.71226002345793e-05
Epoch:  433  	Training Loss: 8.259379683295265e-05
Test Loss:  0.00015625153901055455
Valid Loss:  8.711499685887247e-05
Epoch:  434  	Training Loss: 8.238441660068929e-05
Test Loss:  0.00015604388318024576
Valid Loss:  8.71228112373501e-05
Epoch:  435  	Training Loss: 8.218182483687997e-05
Test Loss:  0.0001557793002575636
Valid Loss:  8.710406109457836e-05
Epoch:  436  	Training Loss: 8.198554860427976e-05
Test Loss:  0.00015558250015601516
Valid Loss:  8.709084067959338e-05
Epoch:  437  	Training Loss: 8.179475844372064e-05
Test Loss:  0.00015535554848611355
Valid Loss:  8.705931395525113e-05
Epoch:  438  	Training Loss: 8.16091924207285e-05
Test Loss:  0.00015517296560574323
Valid Loss:  8.702921331860125e-05
Epoch:  439  	Training Loss: 8.143086597556248e-05
Test Loss:  0.00015499367145821452
Valid Loss:  8.69871219038032e-05
Epoch:  440  	Training Loss: 8.126134343910962e-05
Test Loss:  0.00015483096649404615
Valid Loss:  8.6941770859994e-05
Epoch:  441  	Training Loss: 8.109572809189558e-05
Test Loss:  0.0001546705316286534
Valid Loss:  8.68892457219772e-05
Epoch:  442  	Training Loss: 8.093434735201299e-05
Test Loss:  0.0001553659822093323
Valid Loss:  8.64188841660507e-05
Epoch:  443  	Training Loss: 8.079652616288513e-05
Test Loss:  0.00015555012214463204
Valid Loss:  8.601105946581811e-05
Epoch:  444  	Training Loss: 8.068172610364854e-05
Test Loss:  0.00015565217472612858
Valid Loss:  8.566737233195454e-05
Epoch:  445  	Training Loss: 8.057483501033857e-05
Test Loss:  0.00015573670680169016
Valid Loss:  8.540900307707489e-05
Epoch:  446  	Training Loss: 8.047442679526284e-05
Test Loss:  0.00015580520266667008
Valid Loss:  8.519802941009402e-05
Epoch:  447  	Training Loss: 8.037925726966932e-05
Test Loss:  0.00015585942310281098
Valid Loss:  8.501530101057142e-05
Epoch:  448  	Training Loss: 8.028979209484532e-05
Test Loss:  0.00015603362408000976
Valid Loss:  8.486962178722024e-05
Epoch:  449  	Training Loss: 8.021271059988067e-05
Test Loss:  0.0001560570381116122
Valid Loss:  8.475272625219077e-05
Epoch:  450  	Training Loss: 8.013930346351117e-05
Test Loss:  0.0001562521210871637
Valid Loss:  8.467205771012232e-05
Epoch:  451  	Training Loss: 8.007568249013275e-05
Test Loss:  0.00015624304069206119
Valid Loss:  8.459106902591884e-05
Epoch:  452  	Training Loss: 8.001425885595381e-05
Test Loss:  0.00015573197742924094
Valid Loss:  8.416287164436653e-05
Epoch:  453  	Training Loss: 7.989218283910304e-05
Test Loss:  0.00015567010268568993
Valid Loss:  8.373676973860711e-05
Epoch:  454  	Training Loss: 7.978537178132683e-05
Test Loss:  0.00015551348042208701
Valid Loss:  8.33763915579766e-05
Epoch:  455  	Training Loss: 7.968924182932824e-05
Test Loss:  0.00015537315630353987
Valid Loss:  8.305603842018172e-05
Epoch:  456  	Training Loss: 7.960018410813063e-05
Test Loss:  0.00015522848116233945
Valid Loss:  8.277306915260851e-05
Epoch:  457  	Training Loss: 7.951601583044976e-05
Test Loss:  0.0001550804590806365
Valid Loss:  8.252145926235244e-05
Epoch:  458  	Training Loss: 7.94357038103044e-05
Test Loss:  0.00015487647033296525
Valid Loss:  8.229552622651681e-05
Epoch:  459  	Training Loss: 7.936016481835395e-05
Test Loss:  0.00015468394849449396
Valid Loss:  8.21002759039402e-05
Epoch:  460  	Training Loss: 7.92884238762781e-05
Test Loss:  0.0001544809783808887
Valid Loss:  8.192340465029702e-05
Epoch:  461  	Training Loss: 7.921874930616468e-05
Test Loss:  0.00015427934704348445
Valid Loss:  8.176032861229032e-05
Epoch:  462  	Training Loss: 7.915111200418323e-05
Test Loss:  0.00015474714746233076
Valid Loss:  8.208100916817784e-05
Epoch:  463  	Training Loss: 7.903832010924816e-05
Test Loss:  0.0001540118537377566
Valid Loss:  8.207892824430019e-05
Epoch:  464  	Training Loss: 7.893748261267319e-05
Test Loss:  0.00015382372657768428
Valid Loss:  8.21963039925322e-05
Epoch:  465  	Training Loss: 7.88431498222053e-05
Test Loss:  0.00015342803089879453
Valid Loss:  8.224108751164749e-05
Epoch:  466  	Training Loss: 7.875316077843308e-05
Test Loss:  0.00015314904158003628
Valid Loss:  8.229838567785919e-05
Epoch:  467  	Training Loss: 7.866624218877405e-05
Test Loss:  0.00015283937682397664
Valid Loss:  8.233383414335549e-05
Epoch:  468  	Training Loss: 7.858235767344013e-05
Test Loss:  0.0001525602419860661
Valid Loss:  8.23631344246678e-05
Epoch:  469  	Training Loss: 7.850035035517067e-05
Test Loss:  0.0001522837847005576
Valid Loss:  8.237954170908779e-05
Epoch:  470  	Training Loss: 7.842057675588876e-05
Test Loss:  0.00015202102076727897
Valid Loss:  8.238913142122328e-05
Epoch:  471  	Training Loss: 7.834276766516268e-05
Test Loss:  0.000151766391354613
Valid Loss:  8.238963346229866e-05
Epoch:  472  	Training Loss: 7.826581713743508e-05
Test Loss:  0.00015181304479483515
Valid Loss:  8.235522545874119e-05
Epoch:  473  	Training Loss: 7.82622882979922e-05
Test Loss:  0.00015185418305918574
Valid Loss:  8.232252730522305e-05
Epoch:  474  	Training Loss: 7.825870125088841e-05
Test Loss:  0.0001518906792625785
 95%|█████████▌| 475/500 [05:40<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:40<00:10,  2.20it/s] 96%|█████████▌| 479/500 [05:40<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:46<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:46<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:47<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:47<00:05,  2.17it/s] 98%|█████████▊| 489/500 [05:47<00:03,  2.92it/s] 98%|█████████▊| 491/500 [05:53<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:53<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:54<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:54<00:01,  2.15it/s]100%|█████████▉| 499/500 [05:54<00:00,  2.87it/s]100%|██████████| 500/500 [05:54<00:00,  1.41it/s]
Valid Loss:  8.229140075854957e-05
Epoch:  475  	Training Loss: 7.825539069017395e-05
Test Loss:  0.00015192307182587683
Valid Loss:  8.226118370657787e-05
Epoch:  476  	Training Loss: 7.825219654478133e-05
Test Loss:  0.00015195149171631783
Valid Loss:  8.22321162559092e-05
Epoch:  477  	Training Loss: 7.824903150321916e-05
Test Loss:  0.00015197704487945884
Valid Loss:  8.220456220442429e-05
Epoch:  478  	Training Loss: 7.824586646165699e-05
Test Loss:  0.00015199983317870647
Valid Loss:  8.217766298912466e-05
Epoch:  479  	Training Loss: 7.824326166883111e-05
Test Loss:  0.00015202004578895867
Valid Loss:  8.215192065108567e-05
Epoch:  480  	Training Loss: 7.824011845514178e-05
Test Loss:  0.00015203826478682458
Valid Loss:  8.212675311369821e-05
Epoch:  481  	Training Loss: 7.823741907486692e-05
Test Loss:  0.00015205497038550675
Valid Loss:  8.21020221337676e-05
Epoch:  482  	Training Loss: 7.823462510714307e-05
Test Loss:  0.000152344728121534
Valid Loss:  8.237591828219593e-05
Epoch:  483  	Training Loss: 7.819804886821657e-05
Test Loss:  0.00015238850028254092
Valid Loss:  8.253699343185872e-05
Epoch:  484  	Training Loss: 7.817470759619027e-05
Test Loss:  0.00015233548765536398
Valid Loss:  8.263241761596873e-05
Epoch:  485  	Training Loss: 7.815752178430557e-05
Test Loss:  0.000152260297909379
Valid Loss:  8.27110416139476e-05
Epoch:  486  	Training Loss: 7.814147102180868e-05
Test Loss:  0.00015217707550618798
Valid Loss:  8.278217865154147e-05
Epoch:  487  	Training Loss: 7.812600233592093e-05
Test Loss:  0.00015209174307528883
Valid Loss:  8.284900832222775e-05
Epoch:  488  	Training Loss: 7.811127579770982e-05
Test Loss:  0.0001520093937870115
Valid Loss:  8.291377889690921e-05
Epoch:  489  	Training Loss: 7.809730595909059e-05
Test Loss:  0.0001519296201877296
Valid Loss:  8.297114982269704e-05
Epoch:  490  	Training Loss: 7.808466034475714e-05
Test Loss:  0.00015185440133791417
Valid Loss:  8.302945934701711e-05
Epoch:  491  	Training Loss: 7.807256770320237e-05
Test Loss:  0.00015178268949966878
Valid Loss:  8.30870121717453e-05
Epoch:  492  	Training Loss: 7.80612463131547e-05
Test Loss:  0.00015179271576926112
Valid Loss:  8.285928197437897e-05
Epoch:  493  	Training Loss: 7.798925071256235e-05
Test Loss:  0.00015173440624494106
Valid Loss:  8.265084034064785e-05
Epoch:  494  	Training Loss: 7.792082760715857e-05
Test Loss:  0.0001516348565928638
Valid Loss:  8.246064680861309e-05
Epoch:  495  	Training Loss: 7.785495836287737e-05
Test Loss:  0.00015151262050494552
Valid Loss:  8.228627848438919e-05
Epoch:  496  	Training Loss: 7.779092993587255e-05
Test Loss:  0.00015135180728975683
Valid Loss:  8.212603279389441e-05
Epoch:  497  	Training Loss: 7.772880780976266e-05
Test Loss:  0.0001511633745394647
Valid Loss:  8.19779306766577e-05
Epoch:  498  	Training Loss: 7.76678352849558e-05
Test Loss:  0.00015096871356945485
Valid Loss:  8.184085163520649e-05
Epoch:  499  	Training Loss: 7.760884909657761e-05
Test Loss:  0.00015078381693456322
Valid Loss:  8.172167872544378e-05
Epoch:  500  	Training Loss: 7.755131809972227e-05
Test Loss:  0.00015059068391565233
Valid Loss:  8.161016012309119e-05
seed is  17
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:41, 12.11it/s]  1%|          | 4/500 [00:00<00:39, 12.51it/s]  1%|          | 6/500 [00:00<00:36, 13.60it/s]  2%|▏         | 8/500 [00:00<00:33, 14.56it/s]  2%|▏         | 10/500 [00:00<00:32, 15.07it/s]  2%|▏         | 12/500 [00:00<00:31, 15.52it/s]  3%|▎         | 14/500 [00:00<00:30, 15.77it/s]  3%|▎         | 16/500 [00:01<00:30, 15.91it/s]  4%|▎         | 18/500 [00:01<00:30, 15.98it/s]  4%|▍         | 20/500 [00:01<00:30, 15.86it/s]  4%|▍         | 22/500 [00:01<00:30, 15.92it/s]  5%|▍         | 24/500 [00:01<00:29, 16.01it/s]  5%|▌         | 26/500 [00:01<00:29, 16.17it/s]  6%|▌         | 28/500 [00:01<00:29, 16.10it/s]  6%|▌         | 30/500 [00:01<00:29, 16.13it/s]  6%|▋         | 32/500 [00:02<00:28, 16.17it/s]  7%|▋         | 34/500 [00:02<00:28, 16.13it/s]  7%|▋         | 36/500 [00:02<00:28, 16.11it/s]  8%|▊         | 38/500 [00:02<00:28, 16.22it/s]  8%|▊         | 40/500 [00:02<00:28, 16.23it/s]  8%|▊         | 42/500 [00:02<00:29, 15.30it/s]  9%|▉         | 44/500 [00:02<00:32, 14.23it/s]  9%|▉         | 46/500 [00:03<00:33, 13.60it/s] 10%|▉         | 48/500 [00:03<00:33, 13.63it/s] 10%|█         | 50/500 [00:03<00:32, 13.94it/s] 10%|█         | 52/500 [00:03<00:30, 14.46it/s] 11%|█         | 54/500 [00:03<00:29, 14.90it/s] 11%|█         | 56/500 [00:03<00:29, 15.03it/s] 12%|█▏        | 58/500 [00:03<00:31, 14.04it/s] 12%|█▏        | 60/500 [00:04<00:32, 13.44it/s] 12%|█▏        | 62/500 [00:04<00:33, 13.08it/s] 13%|█▎        | 64/500 [00:04<00:34, 12.82it/s] 13%|█▎        | 66/500 [00:04<00:34, 12.59it/s] 14%|█▎        | 68/500 [00:04<00:34, 12.48it/s] 14%|█▍        | 70/500 [00:04<00:34, 12.42it/s] 14%|█▍        | 72/500 [00:04<00:34, 12.41it/s] 15%|█▍        | 74/500 [00:05<00:34, 12.39it/s] 15%|█▌        | 76/500 [00:05<00:34, 12.37it/s] 16%|█▌        | 78/500 [00:05<00:31, 13.33it/s] 16%|█▌        | 80/500 [00:05<00:29, 14.02it/s] 16%|█▋        | 82/500 [00:05<00:28, 14.50it/s] 17%|█▋        | 84/500 [00:05<00:27, 14.96it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.35it/s] 18%|█▊        | 88/500 [00:06<00:26, 15.59it/s] 18%|█▊        | 90/500 [00:06<00:26, 15.53it/s] 18%|█▊        | 92/500 [00:06<00:25, 15.72it/s] 19%|█▉        | 94/500 [00:06<00:25, 15.80it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.92it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.05it/s] 20%|██        | 100/500 [00:06<00:28, 14.13it/s] 20%|██        | 102/500 [00:07<00:29, 13.56it/s] 21%|██        | 104/500 [00:07<00:30, 13.05it/s] 21%|██        | 106/500 [00:07<00:30, 12.77it/s] 22%|██▏       | 108/500 [00:07<00:31, 12.64it/s] 22%|██▏       | 110/500 [00:07<00:31, 12.57it/s] 22%|██▏       | 112/500 [00:07<00:30, 12.52it/s] 23%|██▎       | 114/500 [00:08<00:30, 12.47it/s] 23%|██▎       | 116/500 [00:08<00:31, 12.35it/s] 24%|██▎       | 118/500 [00:08<00:31, 12.24it/s] 24%|██▍       | 120/500 [00:08<00:31, 12.22it/s] 24%|██▍       | 122/500 [00:08<00:29, 12.73it/s] 25%|██▍       | 124/500 [00:08<00:27, 13.64it/s]Epoch:  1  	Training Loss: 0.10601764172315598
Test Loss:  1715.5535888671875
Valid Loss:  1723.4935302734375
Epoch:  2  	Training Loss: 1687.690673828125
Test Loss:  89552215605248.0
Valid Loss:  87705203507200.0
Epoch:  3  	Training Loss: 88886629892096.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:26, 14.19it/s] 26%|██▌       | 128/500 [00:09<00:25, 14.83it/s] 26%|██▌       | 130/500 [00:09<00:24, 15.17it/s] 26%|██▋       | 132/500 [00:09<00:24, 15.31it/s] 27%|██▋       | 134/500 [00:09<00:25, 14.51it/s] 27%|██▋       | 136/500 [00:09<00:24, 14.98it/s] 28%|██▊       | 138/500 [00:09<00:23, 15.26it/s] 28%|██▊       | 140/500 [00:09<00:24, 14.69it/s] 28%|██▊       | 142/500 [00:09<00:24, 14.77it/s] 29%|██▉       | 144/500 [00:10<00:23, 15.17it/s] 29%|██▉       | 146/500 [00:10<00:23, 15.24it/s] 30%|██▉       | 148/500 [00:10<00:22, 15.53it/s] 30%|███       | 150/500 [00:10<00:22, 15.70it/s] 30%|███       | 152/500 [00:10<00:22, 15.68it/s] 31%|███       | 154/500 [00:10<00:22, 15.45it/s] 31%|███       | 156/500 [00:10<00:23, 14.35it/s] 32%|███▏      | 158/500 [00:11<00:24, 13.81it/s] 32%|███▏      | 160/500 [00:11<00:23, 14.48it/s] 32%|███▏      | 162/500 [00:11<00:22, 15.00it/s] 33%|███▎      | 164/500 [00:11<00:22, 15.00it/s] 33%|███▎      | 166/500 [00:11<00:21, 15.25it/s] 34%|███▎      | 168/500 [00:11<00:21, 15.55it/s] 34%|███▍      | 170/500 [00:11<00:22, 14.52it/s] 34%|███▍      | 172/500 [00:12<00:24, 13.65it/s] 35%|███▍      | 174/500 [00:12<00:23, 14.08it/s] 35%|███▌      | 176/500 [00:12<00:22, 14.62it/s] 36%|███▌      | 178/500 [00:12<00:21, 15.09it/s] 36%|███▌      | 180/500 [00:12<00:20, 15.37it/s] 36%|███▋      | 182/500 [00:12<00:20, 15.66it/s] 37%|███▋      | 184/500 [00:12<00:19, 15.82it/s] 37%|███▋      | 186/500 [00:12<00:19, 15.97it/s] 38%|███▊      | 188/500 [00:13<00:19, 15.87it/s] 38%|███▊      | 190/500 [00:13<00:19, 16.00it/s] 38%|███▊      | 192/500 [00:13<00:19, 15.97it/s] 39%|███▉      | 194/500 [00:13<00:19, 15.99it/s] 39%|███▉      | 196/500 [00:13<00:19, 15.88it/s] 40%|███▉      | 198/500 [00:13<00:18, 16.00it/s] 40%|████      | 200/500 [00:13<00:19, 15.62it/s] 40%|████      | 202/500 [00:13<00:19, 15.14it/s] 41%|████      | 204/500 [00:14<00:21, 14.09it/s] 41%|████      | 206/500 [00:14<00:20, 14.19it/s] 42%|████▏     | 208/500 [00:14<00:20, 14.55it/s] 42%|████▏     | 210/500 [00:14<00:19, 14.98it/s] 42%|████▏     | 212/500 [00:14<00:18, 15.45it/s] 43%|████▎     | 214/500 [00:14<00:18, 15.55it/s] 43%|████▎     | 216/500 [00:14<00:17, 15.80it/s] 44%|████▎     | 218/500 [00:14<00:17, 15.91it/s] 44%|████▍     | 220/500 [00:15<00:17, 16.02it/s] 44%|████▍     | 222/500 [00:15<00:17, 16.12it/s] 45%|████▍     | 224/500 [00:15<00:17, 16.03it/s] 45%|████▌     | 226/500 [00:15<00:17, 15.95it/s] 46%|████▌     | 228/500 [00:15<00:16, 16.03it/s] 46%|████▌     | 230/500 [00:15<00:16, 16.10it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.17it/s] 47%|████▋     | 234/500 [00:15<00:17, 15.28it/s] 47%|████▋     | 236/500 [00:16<00:18, 14.21it/s] 48%|████▊     | 238/500 [00:16<00:19, 13.68it/s] 48%|████▊     | 240/500 [00:16<00:18, 14.30it/s] 48%|████▊     | 242/500 [00:16<00:17, 14.59it/s] 49%|████▉     | 244/500 [00:16<00:18, 13.79it/s] 49%|████▉     | 246/500 [00:16<00:18, 13.64it/s] 50%|████▉     | 248/500 [00:16<00:17, 14.10it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:17<00:17, 14.06it/s] 50%|█████     | 252/500 [00:17<00:17, 14.13it/s] 51%|█████     | 254/500 [00:17<00:16, 14.57it/s] 51%|█████     | 256/500 [00:17<00:16, 14.90it/s] 52%|█████▏    | 258/500 [00:17<00:15, 15.16it/s] 52%|█████▏    | 260/500 [00:17<00:16, 14.85it/s] 52%|█████▏    | 262/500 [00:17<00:15, 15.30it/s] 53%|█████▎    | 264/500 [00:18<00:15, 15.55it/s] 53%|█████▎    | 266/500 [00:18<00:14, 15.75it/s] 54%|█████▎    | 268/500 [00:18<00:14, 15.87it/s] 54%|█████▍    | 270/500 [00:18<00:14, 16.01it/s] 54%|█████▍    | 272/500 [00:18<00:14, 16.08it/s] 55%|█████▍    | 274/500 [00:18<00:14, 15.99it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.25it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.47it/s] 56%|█████▌    | 280/500 [00:19<00:14, 15.61it/s] 56%|█████▋    | 282/500 [00:19<00:14, 15.30it/s] 57%|█████▋    | 284/500 [00:19<00:14, 15.27it/s] 57%|█████▋    | 286/500 [00:19<00:13, 15.31it/s] 58%|█████▊    | 288/500 [00:19<00:13, 15.49it/s] 58%|█████▊    | 290/500 [00:19<00:13, 15.28it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.62it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.78it/s] 59%|█████▉    | 296/500 [00:20<00:12, 15.93it/s] 60%|█████▉    | 298/500 [00:20<00:13, 15.41it/s] 60%|██████    | 300/500 [00:20<00:12, 15.66it/s] 60%|██████    | 302/500 [00:20<00:12, 15.69it/s] 61%|██████    | 304/500 [00:20<00:12, 15.72it/s] 61%|██████    | 306/500 [00:20<00:12, 15.88it/s] 62%|██████▏   | 308/500 [00:20<00:12, 15.92it/s] 62%|██████▏   | 310/500 [00:20<00:11, 15.98it/s] 62%|██████▏   | 312/500 [00:21<00:11, 15.86it/s] 63%|██████▎   | 314/500 [00:21<00:11, 16.02it/s] 63%|██████▎   | 316/500 [00:21<00:11, 16.11it/s] 64%|██████▎   | 318/500 [00:21<00:11, 16.20it/s] 64%|██████▍   | 320/500 [00:21<00:11, 16.16it/s] 64%|██████▍   | 322/500 [00:21<00:10, 16.21it/s] 65%|██████▍   | 324/500 [00:21<00:10, 16.16it/s] 65%|██████▌   | 326/500 [00:21<00:10, 16.06it/s] 66%|██████▌   | 328/500 [00:22<00:10, 16.14it/s] 66%|██████▌   | 330/500 [00:22<00:10, 16.17it/s] 66%|██████▋   | 332/500 [00:22<00:10, 16.17it/s] 67%|██████▋   | 334/500 [00:22<00:10, 15.91it/s] 67%|██████▋   | 336/500 [00:22<00:10, 15.90it/s] 68%|██████▊   | 338/500 [00:22<00:10, 16.01it/s] 68%|██████▊   | 340/500 [00:22<00:09, 16.13it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.19it/s] 69%|██████▉   | 344/500 [00:23<00:09, 16.24it/s] 69%|██████▉   | 346/500 [00:23<00:09, 16.30it/s] 70%|██████▉   | 348/500 [00:23<00:09, 15.69it/s] 70%|███████   | 350/500 [00:23<00:09, 15.69it/s] 70%|███████   | 352/500 [00:23<00:09, 15.73it/s] 71%|███████   | 354/500 [00:23<00:09, 14.88it/s] 71%|███████   | 356/500 [00:23<00:10, 13.99it/s] 72%|███████▏  | 358/500 [00:24<00:10, 13.40it/s] 72%|███████▏  | 360/500 [00:24<00:10, 13.78it/s] 72%|███████▏  | 362/500 [00:24<00:09, 14.39it/s] 73%|███████▎  | 364/500 [00:24<00:09, 14.72it/s] 73%|███████▎  | 366/500 [00:24<00:08, 15.00it/s] 74%|███████▎  | 368/500 [00:24<00:08, 15.05it/s] 74%|███████▍  | 370/500 [00:24<00:08, 15.14it/s] 74%|███████▍  | 372/500 [00:24<00:08, 14.56it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:25<00:09, 13.68it/s] 75%|███████▌  | 376/500 [00:25<00:09, 13.75it/s] 76%|███████▌  | 378/500 [00:25<00:08, 14.39it/s] 76%|███████▌  | 380/500 [00:25<00:08, 14.89it/s] 76%|███████▋  | 382/500 [00:25<00:07, 15.21it/s] 77%|███████▋  | 384/500 [00:25<00:07, 15.27it/s] 77%|███████▋  | 386/500 [00:25<00:07, 15.58it/s] 78%|███████▊  | 388/500 [00:26<00:07, 15.73it/s] 78%|███████▊  | 390/500 [00:26<00:06, 15.84it/s] 78%|███████▊  | 392/500 [00:26<00:07, 14.72it/s] 79%|███████▉  | 394/500 [00:26<00:07, 13.83it/s] 79%|███████▉  | 396/500 [00:26<00:07, 13.26it/s] 80%|███████▉  | 398/500 [00:26<00:07, 13.00it/s] 80%|████████  | 400/500 [00:26<00:07, 12.71it/s] 80%|████████  | 402/500 [00:27<00:07, 12.77it/s] 81%|████████  | 404/500 [00:27<00:07, 13.70it/s] 81%|████████  | 406/500 [00:27<00:06, 14.06it/s] 82%|████████▏ | 408/500 [00:27<00:06, 14.53it/s] 82%|████████▏ | 410/500 [00:27<00:06, 14.67it/s] 82%|████████▏ | 412/500 [00:27<00:05, 14.69it/s] 83%|████████▎ | 414/500 [00:27<00:05, 14.94it/s] 83%|████████▎ | 416/500 [00:28<00:05, 15.16it/s] 84%|████████▎ | 418/500 [00:28<00:05, 15.39it/s] 84%|████████▍ | 420/500 [00:28<00:05, 15.71it/s] 84%|████████▍ | 422/500 [00:28<00:04, 15.64it/s] 85%|████████▍ | 424/500 [00:28<00:04, 15.67it/s] 85%|████████▌ | 426/500 [00:28<00:04, 15.82it/s] 86%|████████▌ | 428/500 [00:28<00:04, 15.96it/s] 86%|████████▌ | 430/500 [00:28<00:04, 16.00it/s] 86%|████████▋ | 432/500 [00:29<00:04, 16.11it/s] 87%|████████▋ | 434/500 [00:29<00:04, 16.07it/s] 87%|████████▋ | 436/500 [00:29<00:03, 16.11it/s] 88%|████████▊ | 438/500 [00:29<00:03, 16.20it/s] 88%|████████▊ | 440/500 [00:29<00:03, 16.13it/s] 88%|████████▊ | 442/500 [00:29<00:03, 16.25it/s] 89%|████████▉ | 444/500 [00:29<00:03, 16.20it/s] 89%|████████▉ | 446/500 [00:29<00:03, 16.08it/s] 90%|████████▉ | 448/500 [00:30<00:03, 16.13it/s] 90%|█████████ | 450/500 [00:30<00:03, 16.24it/s] 90%|█████████ | 452/500 [00:30<00:02, 16.11it/s] 91%|█████████ | 454/500 [00:30<00:02, 16.01it/s] 91%|█████████ | 456/500 [00:30<00:02, 14.97it/s] 92%|█████████▏| 458/500 [00:30<00:02, 14.01it/s] 92%|█████████▏| 460/500 [00:30<00:02, 13.39it/s] 92%|█████████▏| 462/500 [00:31<00:02, 13.13it/s] 93%|█████████▎| 464/500 [00:31<00:02, 13.99it/s] 93%|█████████▎| 466/500 [00:31<00:02, 14.55it/s] 94%|█████████▎| 468/500 [00:31<00:02, 14.74it/s] 94%|█████████▍| 470/500 [00:31<00:01, 15.00it/s] 94%|█████████▍| 472/500 [00:31<00:01, 15.24it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.36it/s] 95%|█████████▌| 476/500 [00:31<00:01, 15.41it/s] 96%|█████████▌| 478/500 [00:32<00:01, 15.74it/s] 96%|█████████▌| 480/500 [00:32<00:01, 15.92it/s] 96%|█████████▋| 482/500 [00:32<00:01, 15.86it/s] 97%|█████████▋| 484/500 [00:32<00:01, 15.93it/s] 97%|█████████▋| 486/500 [00:32<00:00, 15.97it/s] 98%|█████████▊| 488/500 [00:32<00:00, 15.77it/s] 98%|█████████▊| 490/500 [00:32<00:00, 15.77it/s] 98%|█████████▊| 492/500 [00:32<00:00, 15.74it/s] 99%|█████████▉| 494/500 [00:33<00:00, 15.85it/s] 99%|█████████▉| 496/500 [00:33<00:00, 15.76it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 15.87it/s]100%|██████████| 500/500 [00:33<00:00, 15.73it/s]100%|██████████| 500/500 [00:33<00:00, 14.94it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  17
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:21,  6.30s/it]  1%|          | 3/500 [00:06<13:56,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:26<17:19,  2.17s/it]  5%|▍         | 23/500 [00:26<12:10,  1.53s/it]  5%|▌         | 25/500 [00:32<16:06,  2.03s/it]  5%|▌         | 27/500 [00:32<11:22,  1.44s/it]  6%|▌         | 29/500 [00:33<08:03,  1.03s/it]  6%|▌         | 31/500 [00:45<20:24,  2.61s/it]  7%|▋         | 33/500 [00:45<14:23,  1.85s/it]  7%|▋         | 35/500 [00:52<17:30,  2.26s/it]  7%|▋         | 37/500 [00:52<12:21,  1.60s/it]  8%|▊         | 39/500 [00:52<08:45,  1.14s/it]  8%|▊         | 41/500 [01:05<20:29,  2.68s/it]  9%|▊         | 43/500 [01:05<14:26,  1.90s/it]  9%|▉         | 45/500 [01:11<17:18,  2.28s/it]  9%|▉         | 47/500 [01:11<12:13,  1.62s/it] 10%|▉         | 49/500 [01:11<08:39,  1.15s/it] 10%|█         | 51/500 [01:24<20:14,  2.71s/it] 11%|█         | 53/500 [01:24<14:16,  1.92s/it] 11%|█         | 55/500 [01:31<17:07,  2.31s/it] 11%|█▏        | 57/500 [01:31<12:05,  1.64s/it] 12%|█▏        | 59/500 [01:31<08:34,  1.17s/it] 12%|█▏        | 61/500 [01:43<19:43,  2.70s/it] 13%|█▎        | 63/500 [01:44<13:56,  1.91s/it]Epoch:  1  	Training Loss: 0.10601764172315598
Test Loss:  0.5314172506332397
Valid Loss:  0.5395491123199463
Epoch:  2  	Training Loss: 0.6191599369049072
Test Loss:  0.13451358675956726
Valid Loss:  0.1292579621076584
Epoch:  3  	Training Loss: 0.09821474552154541
Test Loss:  0.13170252740383148
Valid Loss:  0.12684549391269684
Epoch:  4  	Training Loss: 0.09605393558740616
Test Loss:  0.13151010870933533
Valid Loss:  0.12666866183280945
Epoch:  5  	Training Loss: 0.09590902179479599
Test Loss:  0.13146395981311798
Valid Loss:  0.12663869559764862
Epoch:  6  	Training Loss: 0.09587101638317108
Test Loss:  0.13146398961544037
Valid Loss:  0.1266387403011322
Epoch:  7  	Training Loss: 0.09587101638317108
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387403011322
Epoch:  8  	Training Loss: 0.09587100148200989
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  9  	Training Loss: 0.09587100148200989
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  10  	Training Loss: 0.09587100148200989
Test Loss:  0.13146400451660156
Valid Loss:  0.12663878500461578
Epoch:  11  	Training Loss: 0.09587099403142929
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  12  	Training Loss: 0.09587100148200989
Test Loss:  0.13146400451660156
Valid Loss:  0.12663878500461578
Epoch:  13  	Training Loss: 0.09587099403142929
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  14  	Training Loss: 0.09587099403142929
Test Loss:  0.13146401941776276
Valid Loss:  0.12663878500461578
Epoch:  15  	Training Loss: 0.0958709865808487
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  16  	Training Loss: 0.0958709865808487
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  17  	Training Loss: 0.0958709865808487
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  18  	Training Loss: 0.0958709865808487
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  19  	Training Loss: 0.0958709865808487
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  20  	Training Loss: 0.0958709865808487
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  22  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  23  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  24  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  25  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  27  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  28  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  29  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  30  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  32  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  33  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  34  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  35  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  37  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  38  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  39  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  40  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  42  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  43  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  44  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  45  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  47  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  48  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  49  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  50  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  52  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  53  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  54  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  55  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  57  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  58  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  59  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  60  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  62  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  63  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  64  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934 13%|█▎        | 65/500 [01:50<16:37,  2.29s/it] 13%|█▎        | 67/500 [01:50<11:44,  1.63s/it] 14%|█▍        | 69/500 [01:50<08:21,  1.16s/it] 14%|█▍        | 71/500 [02:03<19:26,  2.72s/it] 15%|█▍        | 73/500 [02:03<13:42,  1.93s/it] 15%|█▌        | 75/500 [02:09<16:11,  2.29s/it] 15%|█▌        | 77/500 [02:09<11:26,  1.62s/it] 16%|█▌        | 79/500 [02:10<08:06,  1.16s/it] 16%|█▌        | 79/500 [02:20<08:06,  1.16s/it] 16%|█▌        | 81/500 [02:22<18:51,  2.70s/it] 17%|█▋        | 83/500 [02:22<13:17,  1.91s/it] 17%|█▋        | 85/500 [02:29<15:48,  2.29s/it] 17%|█▋        | 87/500 [02:29<11:11,  1.63s/it] 18%|█▊        | 89/500 [02:29<07:56,  1.16s/it] 18%|█▊        | 89/500 [02:40<07:56,  1.16s/it] 18%|█▊        | 91/500 [02:42<18:30,  2.72s/it] 19%|█▊        | 93/500 [02:42<13:04,  1.93s/it] 19%|█▉        | 95/500 [02:48<15:34,  2.31s/it] 19%|█▉        | 97/500 [02:48<10:59,  1.64s/it] 20%|█▉        | 99/500 [02:49<07:47,  1.17s/it] 20%|█▉        | 99/500 [03:00<07:47,  1.17s/it] 20%|██        | 101/500 [03:01<18:11,  2.74s/it] 21%|██        | 103/500 [03:01<12:48,  1.94s/it] 21%|██        | 105/500 [03:08<15:09,  2.30s/it] 21%|██▏       | 107/500 [03:08<10:43,  1.64s/it] 22%|██▏       | 109/500 [03:08<07:38,  1.17s/it] 22%|██▏       | 109/500 [03:20<07:38,  1.17s/it] 22%|██▏       | 111/500 [03:21<17:52,  2.76s/it] 23%|██▎       | 113/500 [03:21<12:35,  1.95s/it] 23%|██▎       | 115/500 [03:27<14:46,  2.30s/it] 23%|██▎       | 117/500 [03:28<10:27,  1.64s/it] 24%|██▍       | 119/500 [03:28<07:25,  1.17s/it] 24%|██▍       | 119/500 [03:40<07:25,  1.17s/it] 24%|██▍       | 121/500 [03:40<17:06,  2.71s/it] 25%|██▍       | 123/500 [03:40<12:02,  1.92s/it]
Epoch:  65  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  67  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  68  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  69  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  70  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  72  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  73  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  74  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  75  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  77  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  78  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  79  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  80  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  82  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  83  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  84  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  85  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  87  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  88  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  89  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  90  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  92  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  93  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  94  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  95  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  97  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  98  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  99  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  100  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  102  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  103  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  104  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  105  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  107  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  108  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  109  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  110  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  112  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  113  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  114  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  115  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  117  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  118  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  119  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  120  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  122  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  123  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  124  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  125  	Training Loss: 0.0958709716796875
Test Loss:   25%|██▌       | 125/500 [03:47<14:24,  2.31s/it] 25%|██▌       | 127/500 [03:47<10:10,  1.64s/it] 26%|██▌       | 129/500 [03:47<07:12,  1.16s/it] 26%|██▌       | 131/500 [04:00<16:36,  2.70s/it] 27%|██▋       | 133/500 [04:00<11:42,  1.91s/it] 27%|██▋       | 135/500 [04:06<14:03,  2.31s/it] 27%|██▋       | 137/500 [04:07<09:55,  1.64s/it] 28%|██▊       | 139/500 [04:07<07:01,  1.17s/it] 28%|██▊       | 141/500 [04:19<16:12,  2.71s/it] 29%|██▊       | 143/500 [04:19<11:24,  1.92s/it] 29%|██▉       | 145/500 [04:26<13:33,  2.29s/it] 29%|██▉       | 147/500 [04:26<09:33,  1.63s/it] 30%|██▉       | 149/500 [04:26<06:46,  1.16s/it] 30%|███       | 151/500 [04:39<15:53,  2.73s/it] 31%|███       | 153/500 [04:39<11:11,  1.94s/it] 31%|███       | 155/500 [04:45<13:12,  2.30s/it] 31%|███▏      | 157/500 [04:45<09:19,  1.63s/it] 32%|███▏      | 159/500 [04:46<06:36,  1.16s/it] 32%|███▏      | 161/500 [04:58<15:09,  2.68s/it] 33%|███▎      | 163/500 [04:58<10:40,  1.90s/it] 33%|███▎      | 165/500 [05:05<12:49,  2.30s/it] 33%|███▎      | 167/500 [05:05<09:02,  1.63s/it] 34%|███▍      | 169/500 [05:05<06:23,  1.16s/it] 34%|███▍      | 171/500 [05:18<15:00,  2.74s/it] 35%|███▍      | 173/500 [05:18<10:33,  1.94s/it] 35%|███▌      | 175/500 [05:24<12:35,  2.32s/it] 35%|███▌      | 177/500 [05:24<08:52,  1.65s/it] 36%|███▌      | 179/500 [05:25<06:16,  1.17s/it] 36%|███▌      | 181/500 [05:37<14:25,  2.71s/it] 37%|███▋      | 183/500 [05:37<10:08,  1.92s/it]0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  127  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  128  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  129  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  130  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  132  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  133  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  134  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  135  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  137  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  138  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  139  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  140  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  142  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  143  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  144  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  145  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  147  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  148  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  149  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  150  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  152  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  153  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  154  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  155  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  157  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  158  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  159  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  160  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  162  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  163  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  164  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  165  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  167  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  168  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  169  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  170  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  172  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  173  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  174  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  175  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  177  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  178  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  179  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  180  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  182  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  183  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  184  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  185  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  37%|███▋      | 185/500 [05:44<12:00,  2.29s/it] 37%|███▋      | 187/500 [05:44<08:28,  1.62s/it] 38%|███▊      | 189/500 [05:44<05:59,  1.16s/it] 38%|███▊      | 191/500 [05:57<13:55,  2.70s/it] 39%|███▊      | 193/500 [05:57<09:47,  1.91s/it] 39%|███▉      | 195/500 [06:03<11:43,  2.31s/it] 39%|███▉      | 197/500 [06:03<08:17,  1.64s/it] 40%|███▉      | 199/500 [06:03<05:53,  1.17s/it] 40%|████      | 201/500 [06:16<13:46,  2.76s/it] 41%|████      | 203/500 [06:17<09:40,  1.96s/it] 41%|████      | 205/500 [06:23<11:27,  2.33s/it] 41%|████▏     | 207/500 [06:23<08:05,  1.66s/it] 42%|████▏     | 209/500 [06:23<05:43,  1.18s/it] 42%|████▏     | 211/500 [06:36<13:06,  2.72s/it] 43%|████▎     | 213/500 [06:36<09:13,  1.93s/it] 43%|████▎     | 215/500 [06:43<11:01,  2.32s/it] 43%|████▎     | 217/500 [06:43<07:46,  1.65s/it] 44%|████▍     | 219/500 [06:43<05:29,  1.17s/it] 44%|████▍     | 221/500 [06:55<12:37,  2.71s/it] 45%|████▍     | 223/500 [06:56<08:52,  1.92s/it] 45%|████▌     | 225/500 [07:02<10:33,  2.31s/it] 45%|████▌     | 227/500 [07:02<07:26,  1.64s/it] 46%|████▌     | 229/500 [07:02<05:15,  1.17s/it] 46%|████▌     | 231/500 [07:15<12:08,  2.71s/it] 47%|████▋     | 233/500 [07:15<08:31,  1.92s/it] 47%|████▋     | 235/500 [07:21<10:04,  2.28s/it] 47%|████▋     | 237/500 [07:21<07:05,  1.62s/it] 48%|████▊     | 239/500 [07:22<05:00,  1.15s/it] 48%|████▊     | 241/500 [07:34<11:33,  2.68s/it] 49%|████▊     | 243/500 [07:34<08:07,  1.90s/it] 0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  187  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  188  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  189  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  190  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  192  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  193  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  194  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  195  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  197  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  198  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  199  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  200  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  202  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  203  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  204  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  205  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  207  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  208  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  209  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  210  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  212  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  213  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  214  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  215  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  217  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  218  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  219  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  220  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  222  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  223  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  224  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  225  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  227  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  228  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  229  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  230  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  232  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  233  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  234  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  235  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  237  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  238  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  239  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  240  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  242  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  243  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  244  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  245  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
 49%|████▉     | 245/500 [07:41<09:47,  2.30s/it] 49%|████▉     | 247/500 [07:41<06:53,  1.64s/it] 50%|████▉     | 249/500 [07:41<04:53,  1.17s/it] 50%|█████     | 251/500 [07:54<11:13,  2.70s/it] 51%|█████     | 253/500 [07:54<07:52,  1.91s/it] 51%|█████     | 255/500 [08:00<09:22,  2.30s/it] 51%|█████▏    | 257/500 [08:00<06:35,  1.63s/it] 52%|█████▏    | 259/500 [08:00<04:39,  1.16s/it] 52%|█████▏    | 261/500 [08:13<10:50,  2.72s/it] 53%|█████▎    | 263/500 [08:13<07:36,  1.93s/it] 53%|█████▎    | 265/500 [08:20<09:02,  2.31s/it] 53%|█████▎    | 267/500 [08:20<06:21,  1.64s/it] 54%|█████▍    | 269/500 [08:20<04:29,  1.17s/it] 54%|█████▍    | 269/500 [08:30<04:29,  1.17s/it] 54%|█████▍    | 271/500 [08:33<10:20,  2.71s/it] 55%|█████▍    | 273/500 [08:33<07:15,  1.92s/it] 55%|█████▌    | 275/500 [08:39<08:36,  2.30s/it] 55%|█████▌    | 277/500 [08:39<06:03,  1.63s/it] 56%|█████▌    | 279/500 [08:39<04:17,  1.16s/it] 56%|█████▌    | 279/500 [08:50<04:17,  1.16s/it] 56%|█████▌    | 281/500 [08:52<09:51,  2.70s/it] 57%|█████▋    | 283/500 [08:52<06:55,  1.91s/it] 57%|█████▋    | 285/500 [08:58<08:09,  2.28s/it] 57%|█████▋    | 287/500 [08:58<05:44,  1.62s/it] 58%|█████▊    | 289/500 [08:59<04:03,  1.15s/it] 58%|█████▊    | 289/500 [09:10<04:03,  1.15s/it] 58%|█████▊    | 291/500 [09:11<09:27,  2.72s/it] 59%|█████▊    | 293/500 [09:12<06:39,  1.93s/it] 59%|█████▉    | 295/500 [09:18<07:56,  2.33s/it] 59%|█████▉    | 297/500 [09:18<05:34,  1.65s/it] 60%|█████▉    | 299/500 [09:18<03:56,  1.17s/it] 60%|█████▉    | 299/500 [09:30<03:56,  1.17s/it] 60%|██████    | 301/500 [09:31<08:58,  2.71s/it] 61%|██████    | 303/500 [09:31<06:17,  1.92s/it]**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  247  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  248  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  249  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  250  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  252  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  253  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  254  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  255  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  257  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  258  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  259  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  260  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  262  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  263  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  264  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  265  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  267  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  268  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  269  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  270  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  272  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  273  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  274  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  275  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  277  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  278  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  279  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  280  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  282  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  283  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  284  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  285  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  287  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  288  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  289  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  290  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  292  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  293  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  294  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  295  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  297  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  298  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  299  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  300  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  302  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  303  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  304  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  305  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
 61%|██████    | 305/500 [09:37<07:25,  2.28s/it] 61%|██████▏   | 307/500 [09:37<05:12,  1.62s/it] 62%|██████▏   | 309/500 [09:38<03:40,  1.15s/it] 62%|██████▏   | 309/500 [09:50<03:40,  1.15s/it] 62%|██████▏   | 311/500 [09:50<08:34,  2.72s/it] 63%|██████▎   | 313/500 [09:51<06:00,  1.93s/it] 63%|██████▎   | 315/500 [09:57<07:07,  2.31s/it] 63%|██████▎   | 317/500 [09:57<04:59,  1.64s/it] 64%|██████▍   | 319/500 [09:57<03:31,  1.17s/it] 64%|██████▍   | 321/500 [10:10<08:01,  2.69s/it] 65%|██████▍   | 323/500 [10:10<05:37,  1.91s/it] 65%|██████▌   | 325/500 [10:16<06:38,  2.28s/it] 65%|██████▌   | 327/500 [10:16<04:39,  1.62s/it] 66%|██████▌   | 329/500 [10:16<03:16,  1.15s/it] 66%|██████▌   | 331/500 [10:29<07:36,  2.70s/it] 67%|██████▋   | 333/500 [10:29<05:19,  1.91s/it] 67%|██████▋   | 335/500 [10:36<06:22,  2.32s/it] 67%|██████▋   | 337/500 [10:36<04:28,  1.65s/it] 68%|██████▊   | 339/500 [10:36<03:08,  1.17s/it] 68%|██████▊   | 341/500 [10:49<07:10,  2.71s/it] 69%|██████▊   | 343/500 [10:49<05:00,  1.92s/it] 69%|██████▉   | 345/500 [10:55<05:55,  2.29s/it] 69%|██████▉   | 347/500 [10:55<04:08,  1.63s/it] 70%|██████▉   | 349/500 [10:55<02:54,  1.16s/it] 70%|███████   | 351/500 [11:08<06:39,  2.68s/it] 71%|███████   | 353/500 [11:08<04:40,  1.90s/it] 71%|███████   | 355/500 [11:14<05:34,  2.31s/it] 71%|███████▏  | 357/500 [11:15<03:54,  1.64s/it] 72%|███████▏  | 359/500 [11:15<02:44,  1.17s/it] 72%|███████▏  | 361/500 [11:28<06:19,  2.73s/it] 73%|███████▎  | 363/500 [11:28<04:25,  1.93s/it]**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  307  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  308  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  309  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  310  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  312  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  313  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  314  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  315  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  317  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  318  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  319  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  320  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  322  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  323  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  324  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  325  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  327  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  328  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  329  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  330  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  332  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  333  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  334  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  335  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  337  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  338  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  339  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  340  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  342  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  343  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  344  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  345  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  347  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  348  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  349  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  350  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  352  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  353  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  354  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  355  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  357  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  358  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  359  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  360  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  362  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  363  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  364  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  365  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
 73%|███████▎  | 365/500 [11:34<05:12,  2.31s/it] 73%|███████▎  | 367/500 [11:34<03:38,  1.65s/it] 74%|███████▍  | 369/500 [11:34<02:33,  1.17s/it] 74%|███████▍  | 371/500 [11:47<05:51,  2.73s/it] 75%|███████▍  | 373/500 [11:47<04:05,  1.93s/it] 75%|███████▌  | 375/500 [11:54<04:47,  2.30s/it] 75%|███████▌  | 377/500 [11:54<03:20,  1.63s/it] 76%|███████▌  | 379/500 [11:54<02:20,  1.16s/it] 76%|███████▌  | 381/500 [12:06<05:21,  2.70s/it] 77%|███████▋  | 383/500 [12:07<03:43,  1.91s/it] 77%|███████▋  | 385/500 [12:13<04:22,  2.29s/it] 77%|███████▋  | 387/500 [12:13<03:03,  1.62s/it] 78%|███████▊  | 389/500 [12:13<02:08,  1.16s/it] 78%|███████▊  | 391/500 [12:26<04:53,  2.69s/it] 79%|███████▊  | 393/500 [12:26<03:23,  1.90s/it] 79%|███████▉  | 395/500 [12:32<04:00,  2.29s/it] 79%|███████▉  | 397/500 [12:32<02:47,  1.63s/it] 80%|███████▉  | 399/500 [12:33<01:57,  1.16s/it] 80%|████████  | 401/500 [12:45<04:27,  2.70s/it] 81%|████████  | 403/500 [12:45<03:05,  1.92s/it] 81%|████████  | 405/500 [12:52<03:39,  2.31s/it] 81%|████████▏ | 407/500 [12:52<02:32,  1.64s/it] 82%|████████▏ | 409/500 [12:52<01:46,  1.17s/it] 82%|████████▏ | 411/500 [13:04<03:58,  2.68s/it] 83%|████████▎ | 413/500 [13:05<02:45,  1.90s/it] 83%|████████▎ | 415/500 [13:11<03:14,  2.28s/it] 83%|████████▎ | 417/500 [13:11<02:14,  1.63s/it] 84%|████████▍ | 419/500 [13:11<01:34,  1.16s/it] 84%|████████▍ | 421/500 [13:24<03:32,  2.69s/it] 85%|████████▍ | 423/500 [13:24<02:26,  1.91s/it]**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  367  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  368  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  369  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  370  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  372  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  373  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  374  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  375  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  377  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  378  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  379  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  380  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  382  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  383  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  384  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  385  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  387  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  388  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  389  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  390  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  392  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  393  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  394  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  395  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  397  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  398  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  399  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  400  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  402  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  403  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  404  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  405  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  407  	Training Loss: 0.0958709791302681
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  408  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  409  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  410  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  412  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  413  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  414  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  415  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  417  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  418  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  419  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  420  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  422  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  423  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  424  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  425  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
 85%|████████▌ | 425/500 [13:30<02:51,  2.29s/it] 85%|████████▌ | 427/500 [13:30<01:58,  1.62s/it] 86%|████████▌ | 429/500 [13:31<01:22,  1.16s/it] 86%|████████▌ | 431/500 [13:43<03:07,  2.72s/it] 86%|████████▋ | 432/500 [13:43<02:33,  2.26s/it] 87%|████████▋ | 434/500 [13:44<01:41,  1.53s/it] 87%|████████▋ | 436/500 [13:50<02:12,  2.08s/it] 88%|████████▊ | 438/500 [13:50<01:29,  1.44s/it] 88%|████████▊ | 440/500 [13:57<01:58,  1.98s/it] 88%|████████▊ | 441/500 [14:03<02:43,  2.78s/it] 89%|████████▊ | 443/500 [14:03<01:45,  1.85s/it] 89%|████████▉ | 445/500 [14:09<02:05,  2.28s/it] 89%|████████▉ | 447/500 [14:10<01:23,  1.58s/it] 90%|████████▉ | 449/500 [14:10<00:56,  1.11s/it] 90%|█████████ | 450/500 [14:16<01:43,  2.06s/it] 90%|█████████ | 451/500 [14:22<02:23,  2.93s/it] 91%|█████████ | 453/500 [14:22<01:27,  1.87s/it] 91%|█████████ | 455/500 [14:29<01:43,  2.31s/it] 91%|█████████▏| 457/500 [14:29<01:07,  1.57s/it] 92%|█████████▏| 459/500 [14:29<00:44,  1.09s/it] 92%|█████████▏| 460/500 [14:35<01:21,  2.05s/it] 92%|█████████▏| 461/500 [14:42<01:54,  2.94s/it] 93%|█████████▎| 463/500 [14:42<01:08,  1.86s/it] 93%|█████████▎| 465/500 [14:48<01:20,  2.30s/it] 93%|█████████▎| 467/500 [14:48<00:51,  1.56s/it] 94%|█████████▍| 469/500 [14:48<00:33,  1.08s/it] 94%|█████████▍| 470/500 [14:55<01:01,  2.06s/it] 94%|█████████▍| 471/500 [15:01<01:24,  2.93s/it] 95%|█████████▍| 473/500 [15:01<00:50,  1.86s/it] 95%|█████████▌| 475/500 [15:07<00:57,  2.31s/it] 95%|█████████▌| 477/500 [15:07<00:35,  1.56s/it] 96%|█████████▌| 479/500 [15:07<00:22,  1.08s/it] 96%|█████████▌| 480/500 [15:14<00:41,  2.05s/it] 96%|█████████▌| 481/500 [15:20<00:56,  2.95s/it] 97%|█████████▋| 483/500 [15:20<00:31,  1.88s/it]**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  427  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  428  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  429  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  430  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  432  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  433  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  434  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  435  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  437  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  438  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  439  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  440  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  442  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  443  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  444  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  445  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  447  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  448  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  449  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  450  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  452  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  453  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  454  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  455  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  457  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  458  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  459  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  460  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  462  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  463  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  464  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  465  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  467  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  468  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  469  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  470  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  472  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  473  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  474  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  475  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  477  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  478  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  479  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  480  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  482  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  483  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  484  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  485  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
 97%|█████████▋| 485/500 [15:27<00:35,  2.37s/it] 97%|█████████▋| 487/500 [15:27<00:20,  1.60s/it] 98%|█████████▊| 489/500 [15:27<00:12,  1.11s/it] 98%|█████████▊| 490/500 [15:33<00:20,  2.09s/it] 98%|█████████▊| 491/500 [15:40<00:26,  2.99s/it] 99%|█████████▊| 493/500 [15:40<00:13,  1.89s/it] 99%|█████████▉| 495/500 [15:46<00:11,  2.34s/it] 99%|█████████▉| 497/500 [15:46<00:04,  1.59s/it]100%|█████████▉| 499/500 [15:47<00:01,  1.10s/it]100%|██████████| 500/500 [15:53<00:00,  1.91s/it]
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  487  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  488  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  489  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  490  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  492  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  493  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  494  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  495  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387552022934
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
Epoch:  497  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  498  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387552022934
Epoch:  499  	Training Loss: 0.0958709716796875
Test Loss:  0.13146401941776276
Valid Loss:  0.1266387701034546
Epoch:  500  	Training Loss: 0.0958709716796875
Test Loss:  0.13146400451660156
Valid Loss:  0.1266387701034546
**************************************************learning rate decay**************************************************
seed is  17
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:35,  6.20s/it]  1%|          | 3/500 [00:06<13:44,  1.66s/it]  1%|          | 5/500 [00:06<06:57,  1.19it/s]  1%|▏         | 7/500 [00:06<04:17,  1.92it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<11:05,  1.36s/it]  3%|▎         | 13/500 [00:13<07:33,  1.07it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.59it/s]  5%|▌         | 27/500 [00:20<03:36,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:27<09:13,  1.18s/it]  7%|▋         | 33/500 [00:27<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:40<16:12,  2.12s/it]  9%|▊         | 43/500 [00:40<11:27,  1.50s/it]  9%|▉         | 45/500 [00:40<08:07,  1.07s/it]  9%|▉         | 47/500 [00:40<05:48,  1.30it/s] 10%|▉         | 49/500 [00:40<04:11,  1.79it/s] 10%|█         | 51/500 [00:47<10:04,  1.35s/it] 11%|█         | 53/500 [00:47<07:11,  1.04it/s] 11%|█         | 55/500 [00:47<05:09,  1.44it/s] 11%|█▏        | 57/500 [00:47<03:44,  1.98it/s] 12%|█▏        | 59/500 [00:47<02:44,  2.68it/s] 12%|█▏        | 61/500 [00:53<08:49,  1.21s/it] 13%|█▎        | 63/500 [00:54<06:18,  1.16it/s] 13%|█▎        | 65/500 [00:54<04:32,  1.60it/s] 13%|█▎        | 67/500 [00:54<03:18,  2.18it/s]Epoch:  1  	Training Loss: 0.10601764172315598
Test Loss:  0.019590716809034348
Valid Loss:  0.02527613751590252
Epoch:  2  	Training Loss: 0.024777568876743317
Test Loss:  0.010508095845580101
Valid Loss:  0.014412632212042809
Epoch:  3  	Training Loss: 0.01754073239862919
Test Loss:  0.00699348421767354
Valid Loss:  0.009674584493041039
Epoch:  4  	Training Loss: 0.012971548363566399
Test Loss:  0.007011708803474903
Valid Loss:  0.007886975072324276
Epoch:  5  	Training Loss: 0.00990863423794508
Test Loss:  0.003410519566386938
Valid Loss:  0.00535511365160346
Epoch:  6  	Training Loss: 0.008685726672410965
Test Loss:  0.0076881819404661655
Valid Loss:  0.006728077307343483
Epoch:  7  	Training Loss: 0.00825346540659666
Test Loss:  0.00247508124448359
Valid Loss:  0.004414294846355915
Epoch:  8  	Training Loss: 0.00696058152243495
Test Loss:  0.007219127379357815
Valid Loss:  0.005484613124281168
Epoch:  9  	Training Loss: 0.006947530433535576
Test Loss:  0.002078140154480934
Valid Loss:  0.0037397537380456924
Epoch:  10  	Training Loss: 0.005210664588958025
Test Loss:  0.005344657227396965
Valid Loss:  0.0037854425609111786
Epoch:  11  	Training Loss: 0.005236881319433451
Test Loss:  0.0018774701748043299
Valid Loss:  0.0032921493984758854
Epoch:  12  	Training Loss: 0.0040710559114813805
Test Loss:  0.0028393727261573076
Valid Loss:  0.0022052039857953787
Epoch:  13  	Training Loss: 0.0028612161986529827
Test Loss:  0.0020522524137049913
Valid Loss:  0.002185358665883541
Epoch:  14  	Training Loss: 0.002644226886332035
Test Loss:  0.002258626278489828
Valid Loss:  0.0021480112336575985
Epoch:  15  	Training Loss: 0.00255624670535326
Test Loss:  0.002178316004574299
Valid Loss:  0.002194568980485201
Epoch:  16  	Training Loss: 0.0025056793820112944
Test Loss:  0.0021913102827966213
Valid Loss:  0.002200225368142128
Epoch:  17  	Training Loss: 0.00245482474565506
Test Loss:  0.002125886734575033
Valid Loss:  0.002208512742072344
Epoch:  18  	Training Loss: 0.002404233440756798
Test Loss:  0.0020432379096746445
Valid Loss:  0.002162408782169223
Epoch:  19  	Training Loss: 0.002328472211956978
Test Loss:  0.001971388701349497
Valid Loss:  0.002118040807545185
Epoch:  20  	Training Loss: 0.00225743162445724
Test Loss:  0.001981179229915142
Valid Loss:  0.0020957901142537594
Epoch:  21  	Training Loss: 0.0022140638902783394
Test Loss:  0.0019751768559217453
Valid Loss:  0.002095920266583562
Epoch:  22  	Training Loss: 0.0021793022751808167
Test Loss:  0.001969783566892147
Valid Loss:  0.002116181654855609
Epoch:  23  	Training Loss: 0.002174519468098879
Test Loss:  0.0019649912137538195
Valid Loss:  0.0021330981981009245
Epoch:  24  	Training Loss: 0.002171576488763094
Test Loss:  0.001958743203431368
Valid Loss:  0.002146949991583824
Epoch:  25  	Training Loss: 0.0021694093011319637
Test Loss:  0.001960520399734378
Valid Loss:  0.0021564660128206015
Epoch:  26  	Training Loss: 0.0021675527095794678
Test Loss:  0.0019585350528359413
Valid Loss:  0.002165169920772314
Epoch:  27  	Training Loss: 0.0021659850608557463
Test Loss:  0.001962133217602968
Valid Loss:  0.0021712747402489185
Epoch:  28  	Training Loss: 0.0021644849330186844
Test Loss:  0.0019646859727799892
Valid Loss:  0.00217715697363019
Epoch:  29  	Training Loss: 0.0021631745621562004
Test Loss:  0.0019636519718915224
Valid Loss:  0.0021825507283210754
Epoch:  30  	Training Loss: 0.002161963377147913
Test Loss:  0.0019686694722622633
Valid Loss:  0.0021861090790480375
Epoch:  31  	Training Loss: 0.0021607517264783382
Test Loss:  0.0019707418978214264
Valid Loss:  0.002190264640375972
Epoch:  32  	Training Loss: 0.002159668132662773
Test Loss:  0.002006296534091234
Valid Loss:  0.002199944108724594
Epoch:  33  	Training Loss: 0.002151095774024725
Test Loss:  0.0019489460391923785
Valid Loss:  0.0022159519139677286
Epoch:  34  	Training Loss: 0.002143015619367361
Test Loss:  0.002023103414103389
Valid Loss:  0.0021845828741788864
Epoch:  35  	Training Loss: 0.0021387457381933928
Test Loss:  0.001949915080331266
Valid Loss:  0.002226572949439287
Epoch:  36  	Training Loss: 0.002138714073225856
Test Loss:  0.002116201678290963
Valid Loss:  0.002182388212531805
Epoch:  37  	Training Loss: 0.002147735096514225
Test Loss:  0.001896014204248786
Valid Loss:  0.002292051212862134
Epoch:  38  	Training Loss: 0.0021591682452708483
Test Loss:  0.00226626661606133
Valid Loss:  0.0021864997688680887
Epoch:  39  	Training Loss: 0.0021885130554437637
Test Loss:  0.001823548460379243
Valid Loss:  0.002431432716548443
Epoch:  40  	Training Loss: 0.0022395248524844646
Test Loss:  0.0025497162714600563
Valid Loss:  0.002225868869572878
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.0023104227147996426
Test Loss:  0.0021195965819060802
Valid Loss:  0.002200578572228551
Epoch:  42  	Training Loss: 0.002128609223291278
Test Loss:  0.0019833622500300407
Valid Loss:  0.0022544178646057844
Epoch:  43  	Training Loss: 0.002103750593960285
Test Loss:  0.0020027379505336285
Valid Loss:  0.0022395369596779346
Epoch:  44  	Training Loss: 0.0020946343429386616
Test Loss:  0.0019911574199795723
Valid Loss:  0.0022399784065783024
Epoch:  45  	Training Loss: 0.0020865872502326965
Test Loss:  0.0019899820908904076
Valid Loss:  0.0022352070081979036
Epoch:  46  	Training Loss: 0.0020789571572095156
Test Loss:  0.0019889932591468096
Valid Loss:  0.002229927806183696
Epoch:  47  	Training Loss: 0.002072058618068695
Test Loss:  0.001989135518670082
Valid Loss:  0.002225535688921809
Epoch:  48  	Training Loss: 0.00206542806699872
Test Loss:  0.001992118777707219
Valid Loss:  0.0022206632420420647
Epoch:  49  	Training Loss: 0.0020594752859324217
Test Loss:  0.001990599324926734
Valid Loss:  0.0022185910493135452
Epoch:  50  	Training Loss: 0.002053704811260104
Test Loss:  0.0019873729906976223
Valid Loss:  0.0022171353921294212
Epoch:  51  	Training Loss: 0.002048046560958028
Test Loss:  0.0019858968444168568
Valid Loss:  0.0022148157004266977
Epoch:  52  	Training Loss: 0.0020425249822437763
Test Loss:  0.001979695400223136
Valid Loss:  0.00221365038305521
Epoch:  53  	Training Loss: 0.0020344634540379047
Test Loss:  0.0019796965643763542
Valid Loss:  0.002210809849202633
Epoch:  54  	Training Loss: 0.0020291137043386698
Test Loss:  0.0019783354364335537
Valid Loss:  0.0022085583768785
Epoch:  55  	Training Loss: 0.002023880835622549
Test Loss:  0.001975441351532936
Valid Loss:  0.002206830307841301
Epoch:  56  	Training Loss: 0.002018711529672146
Test Loss:  0.0019720413256436586
Valid Loss:  0.0022051373962312937
Epoch:  57  	Training Loss: 0.00201359111815691
Test Loss:  0.0019686524756252766
Valid Loss:  0.002203269163146615
Epoch:  58  	Training Loss: 0.0020085216965526342
Test Loss:  0.0019657593220472336
Valid Loss:  0.0022013476118445396
Epoch:  59  	Training Loss: 0.0020035388879477978
Test Loss:  0.0019649192690849304
Valid Loss:  0.0021988435182720423
Epoch:  60  	Training Loss: 0.0019986473489552736
Test Loss:  0.001962164416909218
Valid Loss:  0.002197036286816001
Epoch:  61  	Training Loss: 0.001993815880268812
Test Loss:  0.001958768116310239
Valid Loss:  0.0021953145042061806
Epoch:  62  	Training Loss: 0.0019890223629772663
Test Loss:  0.0019556833431124687
Valid Loss:  0.0021911272779107094
Epoch:  63  	Training Loss: 0.001981899840757251
Test Loss:  0.0019542211666703224
Valid Loss:  0.0021883496083319187
Epoch:  64  	Training Loss: 0.0019770069047808647
Test Loss:  0.0019528837874531746
Valid Loss:  0.002186624798923731
Epoch:  65  	Training Loss: 0.001973118633031845
Test Loss:  0.0019514192827045918
Valid Loss:  0.0021855072118341923
Epoch:  66  	Training Loss: 0.0019701814744621515
Test Loss:  0.0019498779438436031
Valid Loss:  0.0021846399176865816
Epoch:  67  	Training Loss: 0.001967731863260269
Test Loss:  0.001948418328538537
Valid Loss:  0.002184099517762661
Epoch:  68  	Training Loss: 0.001965827541425824
Test Loss:  0.0019467532401904464
Valid Loss:  0.0021837761159986258
Epoch:  69  	Training Loss: 0.0019644172862172127
Test Loss:  0.0019449793035164475
Valid Loss:   14%|█▍        | 69/500 [00:54<02:26,  2.94it/s] 14%|█▍        | 71/500 [01:00<08:42,  1.22s/it] 15%|█▍        | 73/500 [01:01<06:13,  1.14it/s] 15%|█▌        | 75/500 [01:01<04:28,  1.59it/s] 15%|█▌        | 77/500 [01:01<03:14,  2.17it/s] 16%|█▌        | 79/500 [01:01<02:24,  2.92it/s] 16%|█▌        | 81/500 [01:07<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:08<05:59,  1.16it/s] 17%|█▋        | 85/500 [01:08<04:18,  1.60it/s] 17%|█▋        | 87/500 [01:08<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:08<02:19,  2.94it/s] 18%|█▊        | 91/500 [01:14<08:05,  1.19s/it] 19%|█▊        | 93/500 [01:14<05:46,  1.17it/s] 19%|█▉        | 95/500 [01:15<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:15<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:15<02:15,  2.97it/s] 20%|██        | 101/500 [01:21<08:00,  1.20s/it] 21%|██        | 103/500 [01:21<05:43,  1.16it/s] 21%|██        | 105/500 [01:22<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:22<03:00,  2.18it/s] 22%|██▏       | 109/500 [01:22<02:13,  2.93it/s] 22%|██▏       | 111/500 [01:28<07:41,  1.19s/it] 23%|██▎       | 113/500 [01:28<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:28<03:58,  1.62it/s] 23%|██▎       | 117/500 [01:29<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:29<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:35<07:39,  1.21s/it] 25%|██▍       | 123/500 [01:35<05:28,  1.15it/s] 25%|██▌       | 125/500 [01:42<09:41,  1.55s/it] 25%|██▌       | 127/500 [01:42<06:52,  1.11s/it] 26%|██▌       | 129/500 [01:42<04:54,  1.26it/s] 26%|██▌       | 131/500 [01:48<09:17,  1.51s/it] 27%|██▋       | 133/500 [01:48<06:38,  1.09s/it] 27%|██▋       | 135/500 [01:49<04:45,  1.28it/s]0.0021835335064679384
Epoch:  70  	Training Loss: 0.0019632838666439056
Test Loss:  0.0019432675326243043
Valid Loss:  0.0021833465434610844
Epoch:  71  	Training Loss: 0.0019624116830527782
Test Loss:  0.0019416224677115679
Valid Loss:  0.002183086471632123
Epoch:  72  	Training Loss: 0.001961639616638422
Test Loss:  0.0019285152666270733
Valid Loss:  0.002171779051423073
Epoch:  73  	Training Loss: 0.0019553559832274914
Test Loss:  0.0019179024966433644
Valid Loss:  0.0021593724377453327
Epoch:  74  	Training Loss: 0.0019491410348564386
Test Loss:  0.001909398939460516
Valid Loss:  0.0021483036689460278
Epoch:  75  	Training Loss: 0.0019438659073784947
Test Loss:  0.001903272233903408
Valid Loss:  0.002140600001439452
Epoch:  76  	Training Loss: 0.0019402795005589724
Test Loss:  0.0018999064341187477
Valid Loss:  0.002135764341801405
Epoch:  77  	Training Loss: 0.0019384953193366528
Test Loss:  0.0018983932677656412
Valid Loss:  0.002132972702383995
Epoch:  78  	Training Loss: 0.0019379784353077412
Test Loss:  0.001897320500575006
Valid Loss:  0.0021310984157025814
Epoch:  79  	Training Loss: 0.0019377004355192184
Test Loss:  0.0018964039627462626
Valid Loss:  0.0021292823366820812
Epoch:  80  	Training Loss: 0.0019374268595129251
Test Loss:  0.0018955552950501442
Valid Loss:  0.0021275263279676437
Epoch:  81  	Training Loss: 0.0019371483940631151
Test Loss:  0.0018947607604786754
Valid Loss:  0.002125851344317198
Epoch:  82  	Training Loss: 0.0019368670182302594
Test Loss:  0.001912995707243681
Valid Loss:  0.0020948091987520456
Epoch:  83  	Training Loss: 0.0019401562167331576
Test Loss:  0.0018939347937703133
Valid Loss:  0.0021076221019029617
Epoch:  84  	Training Loss: 0.0019385956693440676
Test Loss:  0.0018686105031520128
Valid Loss:  0.002120831748470664
Epoch:  85  	Training Loss: 0.0019286989700049162
Test Loss:  0.0018888136837631464
Valid Loss:  0.002080688253045082
Epoch:  86  	Training Loss: 0.0019254032522439957
Test Loss:  0.0018626271048560739
Valid Loss:  0.0021062816958874464
Epoch:  87  	Training Loss: 0.0019222836708649993
Test Loss:  0.0018744954140856862
Valid Loss:  0.0020626492332667112
Epoch:  88  	Training Loss: 0.0019124692771583796
Test Loss:  0.0018518485594540834
Valid Loss:  0.0020756754092872143
Epoch:  89  	Training Loss: 0.0019079005578532815
Test Loss:  0.0018649469129741192
Valid Loss:  0.002049566013738513
Epoch:  90  	Training Loss: 0.0019044314976781607
Test Loss:  0.0018424887675791979
Valid Loss:  0.0020617377012968063
Epoch:  91  	Training Loss: 0.0018985853530466557
Test Loss:  0.001849511987529695
Valid Loss:  0.0020428139250725508
Epoch:  92  	Training Loss: 0.001894836314022541
Test Loss:  0.001846302766352892
Valid Loss:  0.002045394852757454
Epoch:  93  	Training Loss: 0.001894638640806079
Test Loss:  0.0018450713250786066
Valid Loss:  0.0020468919537961483
Epoch:  94  	Training Loss: 0.0018944668117910624
Test Loss:  0.0018446273170411587
Valid Loss:  0.0020479182712733746
Epoch:  95  	Training Loss: 0.00189430161844939
Test Loss:  0.001844495884142816
Valid Loss:  0.0020487154833972454
Epoch:  96  	Training Loss: 0.0018941366579383612
Test Loss:  0.0018444962333887815
Valid Loss:  0.0020493867341428995
Epoch:  97  	Training Loss: 0.0018939751898869872
Test Loss:  0.0018445372115820646
Valid Loss:  0.0020499916281551123
Epoch:  98  	Training Loss: 0.001893812557682395
Test Loss:  0.0018445808673277497
Valid Loss:  0.0020505378488451242
Epoch:  99  	Training Loss: 0.0018936535343527794
Test Loss:  0.001844625687226653
Valid Loss:  0.0020510400645434856
Epoch:  100  	Training Loss: 0.0018934934632852674
Test Loss:  0.0018446673639118671
Valid Loss:  0.002051504561677575
Epoch:  101  	Training Loss: 0.0018933359533548355
Test Loss:  0.0018446993781253695
Valid Loss:  0.0020519366953521967
Epoch:  102  	Training Loss: 0.0018931799568235874
Test Loss:  0.0018471053335815668
Valid Loss:  0.0020530940964818
Epoch:  103  	Training Loss: 0.0018910749349743128
Test Loss:  0.0018471179064363241
Valid Loss:  0.0020546033047139645
Epoch:  104  	Training Loss: 0.0018899311544373631
Test Loss:  0.0018457635305821896
Valid Loss:  0.0020561697892844677
Epoch:  105  	Training Loss: 0.0018893445376306772
Test Loss:  0.001843538018874824
Valid Loss:  0.0020574508234858513
Epoch:  106  	Training Loss: 0.0018889604834839702
Test Loss:  0.001841534161940217
Valid Loss:  0.002057839184999466
Epoch:  107  	Training Loss: 0.001888795057311654
Test Loss:  0.0018414044752717018
Valid Loss:  0.0020579490810632706
Epoch:  108  	Training Loss: 0.0018886441830545664
Test Loss:  0.0018401603447273374
Valid Loss:  0.002057937905192375
Epoch:  109  	Training Loss: 0.0018884913297370076
Test Loss:  0.0018392993370071054
Valid Loss:  0.0020577649120241404
Epoch:  110  	Training Loss: 0.0018883442971855402
Test Loss:  0.001838676747865975
Valid Loss:  0.0020574857480823994
Epoch:  111  	Training Loss: 0.0018882022704929113
Test Loss:  0.0018387121381238103
Valid Loss:  0.002057235222309828
Epoch:  112  	Training Loss: 0.0018880699062719941
Test Loss:  0.0018388538155704737
Valid Loss:  0.0020570894703269005
Epoch:  113  	Training Loss: 0.0018880610587075353
Test Loss:  0.0018388552125543356
Valid Loss:  0.0020570051856338978
Epoch:  114  	Training Loss: 0.0018880540737882257
Test Loss:  0.0018388282041996717
Valid Loss:  0.002056934405118227
Epoch:  115  	Training Loss: 0.0018880473216995597
Test Loss:  0.0018388048047199845
Valid Loss:  0.00205686641857028
Epoch:  116  	Training Loss: 0.00188804033678025
Test Loss:  0.0018387763993814588
Valid Loss:  0.002056802622973919
Epoch:  117  	Training Loss: 0.0018880339339375496
Test Loss:  0.0018387531163170934
Valid Loss:  0.0020567355677485466
Epoch:  118  	Training Loss: 0.0018880290444940329
Test Loss:  0.0018387341406196356
Valid Loss:  0.0020566764287650585
Epoch:  119  	Training Loss: 0.0018880224088206887
Test Loss:  0.0018387141171842813
Valid Loss:  0.0020566117018461227
Epoch:  120  	Training Loss: 0.0018880171701312065
Test Loss:  0.001839013653807342
Valid Loss:  0.0020564452279359102
Epoch:  121  	Training Loss: 0.0018880171701312065
Test Loss:  0.001839055330492556
Valid Loss:  0.002056385390460491
Epoch:  122  	Training Loss: 0.0018880169373005629
Test Loss:  0.0018374922219663858
Valid Loss:  0.0020520968828350306
Epoch:  123  	Training Loss: 0.0018755951896309853
Test Loss:  0.0018309125443920493
Valid Loss:  0.0020532775670289993
Epoch:  124  	Training Loss: 0.001868452993221581
Test Loss:  0.0018244661623612046
Valid Loss:  0.0020534261129796505
Epoch:  125  	Training Loss: 0.0018627854296937585
Test Loss:  0.00181742908898741
Valid Loss:  0.0020521352998912334
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.001857919036410749
Test Loss:  0.001814557472243905
Valid Loss:  0.0020498866215348244
Epoch:  127  	Training Loss: 0.0018539277371019125
Test Loss:  0.0018125541973859072
Valid Loss:  0.002047760644927621
Epoch:  128  	Training Loss: 0.001850344706326723
Test Loss:  0.0018109010998159647
Valid Loss:  0.002045745961368084
Epoch:  129  	Training Loss: 0.0018470385111868382
Test Loss:  0.0018093689577654004
Valid Loss:  0.002043875865638256
Epoch:  130  	Training Loss: 0.0018438880797475576
Test Loss:  0.001807690947316587
Valid Loss:  0.0020420649088919163
Epoch:  131  	Training Loss: 0.0018407513853162527
Test Loss:  0.0018060116562992334
Valid Loss:  0.002040300751104951
Epoch:  132  	Training Loss: 0.0018376830266788602
Test Loss:  0.0018066936172544956
Valid Loss:  0.002039712853729725
Epoch:  133  	Training Loss: 0.001837142976000905
Test Loss:  0.0018063817406073213
Valid Loss:  0.002039352199062705
Epoch:  134  	Training Loss: 0.0018367457669228315
Test Loss:  0.0018059317953884602
Valid Loss:  0.0020390383433550596
Epoch:  135  	Training Loss: 0.0018363581039011478
Test Loss:  0.0018053929088637233
Valid Loss:  0.0020387512631714344
Epoch:  136  	Training Loss: 0.001836015610024333
Test Loss:  0.0018045604228973389
Valid Loss:  0.0020384672097861767
Epoch:  137  	Training Loss: 0.001835718285292387
Test Loss:  0.001803792081773281
Valid Loss:   27%|██▋       | 137/500 [01:49<03:25,  1.76it/s] 28%|██▊       | 139/500 [01:49<02:30,  2.40it/s] 28%|██▊       | 141/500 [01:55<07:26,  1.24s/it] 29%|██▊       | 143/500 [01:55<05:18,  1.12it/s] 29%|██▉       | 145/500 [01:55<03:48,  1.55it/s] 29%|██▉       | 147/500 [01:56<02:46,  2.12it/s] 30%|██▉       | 149/500 [01:56<02:03,  2.85it/s] 30%|███       | 151/500 [02:02<07:11,  1.24s/it] 31%|███       | 153/500 [02:03<05:09,  1.12it/s] 31%|███       | 155/500 [02:03<03:42,  1.55it/s] 31%|███▏      | 157/500 [02:03<02:41,  2.12it/s] 32%|███▏      | 159/500 [02:03<01:59,  2.86it/s] 32%|███▏      | 161/500 [02:09<06:52,  1.22s/it] 33%|███▎      | 163/500 [02:10<04:54,  1.15it/s] 33%|███▎      | 165/500 [02:10<03:31,  1.59it/s] 33%|███▎      | 167/500 [02:10<02:33,  2.17it/s] 34%|███▍      | 169/500 [02:10<01:53,  2.92it/s] 34%|███▍      | 171/500 [02:16<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:17<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:17<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:17<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:17<01:49,  2.92it/s] 36%|███▌      | 181/500 [02:23<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:23<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:24<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:24<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:24<01:45,  2.95it/s] 38%|███▊      | 191/500 [02:30<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:30<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:30<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:31<02:16,  2.21it/s] 40%|███▉      | 199/500 [02:31<01:41,  2.97it/s] 40%|████      | 201/500 [02:37<05:56,  1.19s/it] 41%|████      | 203/500 [02:37<04:14,  1.17it/s] 41%|████      | 205/500 [02:37<03:02,  1.61it/s]0.0020381351932883263
Epoch:  138  	Training Loss: 0.0018354547210037708
Test Loss:  0.0018025791505351663
Valid Loss:  0.0020377659238874912
Epoch:  139  	Training Loss: 0.0018352647311985493
Test Loss:  0.0018015989335253835
Valid Loss:  0.002037281636148691
Epoch:  140  	Training Loss: 0.0018350775353610516
Test Loss:  0.0018005343154072762
Valid Loss:  0.002036724239587784
Epoch:  141  	Training Loss: 0.0018349235178902745
Test Loss:  0.001799674821086228
Valid Loss:  0.002036115387454629
Epoch:  142  	Training Loss: 0.0018347811419516802
Test Loss:  0.0017993203364312649
Valid Loss:  0.0020304396748542786
Epoch:  143  	Training Loss: 0.00183286692481488
Test Loss:  0.0017987790051847696
Valid Loss:  0.0020253737457096577
Epoch:  144  	Training Loss: 0.00183112733066082
Test Loss:  0.0017981136916205287
Valid Loss:  0.0020210398361086845
Epoch:  145  	Training Loss: 0.0018295880872756243
Test Loss:  0.0017973097274079919
Valid Loss:  0.0020175157114863396
Epoch:  146  	Training Loss: 0.0018282453529536724
Test Loss:  0.0017963848076760769
Valid Loss:  0.002014503814280033
Epoch:  147  	Training Loss: 0.0018270706059411168
Test Loss:  0.0017953681526705623
Valid Loss:  0.00201186491176486
Epoch:  148  	Training Loss: 0.0018259758362546563
Test Loss:  0.0017943179700523615
Valid Loss:  0.0020095566287636757
Epoch:  149  	Training Loss: 0.00182494823820889
Test Loss:  0.001793382572941482
Valid Loss:  0.0020074648782610893
Epoch:  150  	Training Loss: 0.0018239682540297508
Test Loss:  0.0017924709245562553
Valid Loss:  0.002005679067224264
Epoch:  151  	Training Loss: 0.001823102356866002
Test Loss:  0.001791501883417368
Valid Loss:  0.0020040874369442463
Epoch:  152  	Training Loss: 0.0018222886137664318
Test Loss:  0.0017872950993478298
Valid Loss:  0.0020036092028021812
Epoch:  153  	Training Loss: 0.0018199239857494831
Test Loss:  0.0017840834334492683
Valid Loss:  0.0020027142018079758
Epoch:  154  	Training Loss: 0.001817805226892233
Test Loss:  0.0017816302133724093
Valid Loss:  0.002001561690121889
Epoch:  155  	Training Loss: 0.0018158892635256052
Test Loss:  0.0017796584870666265
Valid Loss:  0.002000239444896579
Epoch:  156  	Training Loss: 0.0018140585161745548
Test Loss:  0.0017779727932065725
Valid Loss:  0.0019987975247204304
Epoch:  157  	Training Loss: 0.0018123677000403404
Test Loss:  0.001776728080585599
Valid Loss:  0.0019973863381892443
Epoch:  158  	Training Loss: 0.001811024034395814
Test Loss:  0.0017756933812052011
Valid Loss:  0.0019960119388997555
Epoch:  159  	Training Loss: 0.0018098148284479976
Test Loss:  0.001774863339960575
Valid Loss:  0.0019946503452956676
Epoch:  160  	Training Loss: 0.0018086133059114218
Test Loss:  0.0017740755574777722
Valid Loss:  0.001993297366425395
Epoch:  161  	Training Loss: 0.0018074165564030409
Test Loss:  0.0017734633293002844
Valid Loss:  0.001991972327232361
Epoch:  162  	Training Loss: 0.0018062256276607513
Test Loss:  0.0017719244351610541
Valid Loss:  0.0019917478784918785
Epoch:  163  	Training Loss: 0.0018056546105071902
Test Loss:  0.001770682167261839
Valid Loss:  0.0019913404248654842
Epoch:  164  	Training Loss: 0.0018051151419058442
Test Loss:  0.0017698416486382484
Valid Loss:  0.0019907369278371334
Epoch:  165  	Training Loss: 0.0018046402838081121
Test Loss:  0.0017693056724965572
Valid Loss:  0.0019900104962289333
Epoch:  166  	Training Loss: 0.0018042066367343068
Test Loss:  0.001769011258147657
Valid Loss:  0.0019892172422260046
Epoch:  167  	Training Loss: 0.0018038263078778982
Test Loss:  0.0017687042709439993
Valid Loss:  0.0019884593784809113
Epoch:  168  	Training Loss: 0.00180344982072711
Test Loss:  0.001768392277881503
Valid Loss:  0.001987734343856573
Epoch:  169  	Training Loss: 0.0018030740320682526
Test Loss:  0.0017680823802947998
Valid Loss:  0.001987032126635313
Epoch:  170  	Training Loss: 0.0018027019686996937
Test Loss:  0.0017677729483693838
Valid Loss:  0.0019863592460751534
Epoch:  171  	Training Loss: 0.001802331069484353
Test Loss:  0.0017674679402261972
Valid Loss:  0.0019857087172567844
Epoch:  172  	Training Loss: 0.001801984617486596
Test Loss:  0.0017678142758086324
Valid Loss:  0.0019837517756968737
Epoch:  173  	Training Loss: 0.0018006612081080675
Test Loss:  0.0017678366275504231
Valid Loss:  0.0019820667803287506
Epoch:  174  	Training Loss: 0.0017993696965277195
Test Loss:  0.0017677238211035728
Valid Loss:  0.001980561064556241
Epoch:  175  	Training Loss: 0.001798123586922884
Test Loss:  0.0017676260322332382
Valid Loss:  0.001979205757379532
Epoch:  176  	Training Loss: 0.0017969342879951
Test Loss:  0.0017674413975328207
Valid Loss:  0.00197793822735548
Epoch:  177  	Training Loss: 0.0017957852687686682
Test Loss:  0.0017672860994935036
Valid Loss:  0.0019767936319112778
Epoch:  178  	Training Loss: 0.0017947754822671413
Test Loss:  0.0017670791130512953
Valid Loss:  0.0019757142290472984
Epoch:  179  	Training Loss: 0.0017937800148501992
Test Loss:  0.0017668784130364656
Valid Loss:  0.0019747093319892883
Epoch:  180  	Training Loss: 0.0017928497400134802
Test Loss:  0.0017666537314653397
Valid Loss:  0.001973752398043871
Epoch:  181  	Training Loss: 0.001791932387277484
Test Loss:  0.0017664702609181404
Valid Loss:  0.001972832949832082
Epoch:  182  	Training Loss: 0.0017910234164446592
Test Loss:  0.0017664432525634766
Valid Loss:  0.0019720145501196384
Epoch:  183  	Training Loss: 0.0017899458762258291
Test Loss:  0.0017663425533100963
Valid Loss:  0.001971256220713258
Epoch:  184  	Training Loss: 0.0017889119917526841
Test Loss:  0.0017661959864199162
Valid Loss:  0.001970532815903425
Epoch:  185  	Training Loss: 0.0017879278166219592
Test Loss:  0.0017661706078797579
Valid Loss:  0.0019698303658515215
Epoch:  186  	Training Loss: 0.0017869970761239529
Test Loss:  0.0017660495359450579
Valid Loss:  0.0019691719207912683
Epoch:  187  	Training Loss: 0.001786171575076878
Test Loss:  0.001765927765518427
Valid Loss:  0.001968519762158394
Epoch:  188  	Training Loss: 0.0017853883327916265
Test Loss:  0.001765754073858261
Valid Loss:  0.001967896707355976
Epoch:  189  	Training Loss: 0.0017846664413809776
Test Loss:  0.0017655676929280162
Valid Loss:  0.0019672587513923645
Epoch:  190  	Training Loss: 0.001783955143764615
Test Loss:  0.0017654309049248695
Valid Loss:  0.0019666070584207773
Epoch:  191  	Training Loss: 0.001783246174454689
Test Loss:  0.001765331020578742
Valid Loss:  0.0019659504760056734
Epoch:  192  	Training Loss: 0.0017825393006205559
Test Loss:  0.0017666947096586227
Valid Loss:  0.001964267110452056
Epoch:  193  	Training Loss: 0.0017788304248824716
Test Loss:  0.0017672269605100155
Valid Loss:  0.0019630412571132183
Epoch:  194  	Training Loss: 0.0017754173604771495
Test Loss:  0.0017675410490483046
Valid Loss:  0.0019619902595877647
Epoch:  195  	Training Loss: 0.0017723863711580634
Test Loss:  0.001767100766301155
Valid Loss:  0.0019612209871411324
Epoch:  196  	Training Loss: 0.0017695464193820953
Test Loss:  0.0017663444159552455
Valid Loss:  0.0019607103895395994
Epoch:  197  	Training Loss: 0.0017667878419160843
Test Loss:  0.001765447435900569
Valid Loss:  0.0019602314569056034
Epoch:  198  	Training Loss: 0.0017641112208366394
Test Loss:  0.001763983629643917
Valid Loss:  0.0019598896615207195
Epoch:  199  	Training Loss: 0.0017615808174014091
Test Loss:  0.0017623205203562975
Valid Loss:  0.0019595425110310316
Epoch:  200  	Training Loss: 0.0017591260839253664
Test Loss:  0.0017600273713469505
Valid Loss:  0.0019593776669353247
Epoch:  201  	Training Loss: 0.0017568317707628012
Test Loss:  0.0017577764810994267
Valid Loss:  0.0019591106101870537
Epoch:  202  	Training Loss: 0.0017545634182170033
Test Loss:  0.0017559622647240758
Valid Loss:  0.0019596286583691835
Epoch:  203  	Training Loss: 0.00175211310852319
Test Loss:  0.0017541184788569808
Valid Loss:  0.0019600426312536
Epoch:  204  	Training Loss: 0.0017497213557362556
Test Loss:  0.0017520339461043477
Valid Loss:  0.001960324589163065
Epoch:  205  	Training Loss: 0.0017473885091021657
Test Loss:  0.0017499581445008516
Valid Loss:  0.001960471272468567
Epoch:  206  	Training Loss: 0.0017450894229114056
Test Loss:   41%|████▏     | 207/500 [02:37<02:12,  2.20it/s] 42%|████▏     | 209/500 [02:38<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:44<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:44<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:44<02:58,  1.60it/s] 43%|████▎     | 217/500 [02:44<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:45<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:51<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:51<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:51<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:51<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:52<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:58<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:58<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:58<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:58<02:01,  2.16it/s] 48%|████▊     | 239/500 [02:59<01:31,  2.86it/s] 48%|████▊     | 241/500 [03:05<05:11,  1.20s/it] 49%|████▊     | 243/500 [03:05<03:41,  1.16it/s] 49%|████▉     | 245/500 [03:05<02:38,  1.61it/s] 49%|████▉     | 247/500 [03:05<01:55,  2.20it/s] 50%|████▉     | 249/500 [03:05<01:24,  2.96it/s] 50%|█████     | 251/500 [03:12<05:01,  1.21s/it] 51%|█████     | 253/500 [03:12<03:35,  1.15it/s] 51%|█████     | 255/500 [03:12<02:35,  1.58it/s] 51%|█████▏    | 257/500 [03:12<01:53,  2.15it/s] 52%|█████▏    | 259/500 [03:12<01:23,  2.89it/s] 52%|█████▏    | 261/500 [03:19<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:19<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:19<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:19<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:19<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:26<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:26<03:16,  1.16it/s]0.0017479120288044214
Valid Loss:  0.001960484776645899
Epoch:  207  	Training Loss: 0.0017428412102162838
Test Loss:  0.00174587348010391
Valid Loss:  0.001960376277565956
Epoch:  208  	Training Loss: 0.0017406285041943192
Test Loss:  0.0017438973300158978
Valid Loss:  0.001960147637873888
Epoch:  209  	Training Loss: 0.0017384325619786978
Test Loss:  0.001741940388455987
Valid Loss:  0.0019598063081502914
Epoch:  210  	Training Loss: 0.0017362540820613503
Test Loss:  0.0017399340867996216
Valid Loss:  0.0019593562465161085
Epoch:  211  	Training Loss: 0.001734109129756689
Test Loss:  0.0017379641067236662
Valid Loss:  0.0019588032737374306
Epoch:  212  	Training Loss: 0.0017319917678833008
Test Loss:  0.0017197129782289267
Valid Loss:  0.001962892012670636
Epoch:  213  	Training Loss: 0.0017246538773179054
Test Loss:  0.001710059936158359
Valid Loss:  0.0019649406895041466
Epoch:  214  	Training Loss: 0.0017211430240422487
Test Loss:  0.0017045378917828202
Valid Loss:  0.0019653469789773226
Epoch:  215  	Training Loss: 0.0017187027260661125
Test Loss:  0.0017014829209074378
Valid Loss:  0.0019645995926111937
Epoch:  216  	Training Loss: 0.001716818893328309
Test Loss:  0.00169938406907022
Valid Loss:  0.001963494811207056
Epoch:  217  	Training Loss: 0.0017153286607936025
Test Loss:  0.0016987251583486795
Valid Loss:  0.0019612349569797516
Epoch:  218  	Training Loss: 0.0017140968702733517
Test Loss:  0.0016984427347779274
Valid Loss:  0.001958634005859494
Epoch:  219  	Training Loss: 0.0017129576299339533
Test Loss:  0.0016980880172923207
Valid Loss:  0.0019562176894396544
Epoch:  220  	Training Loss: 0.0017119119875133038
Test Loss:  0.0016976161859929562
Valid Loss:  0.0019539189524948597
Epoch:  221  	Training Loss: 0.0017108876490965486
Test Loss:  0.0016972546000033617
Valid Loss:  0.0019515880849212408
Epoch:  222  	Training Loss: 0.0017099280375987291
Test Loss:  0.0017009631264954805
Valid Loss:  0.0019475006265565753
Epoch:  223  	Training Loss: 0.0017082401318475604
Test Loss:  0.0017035783967003226
Valid Loss:  0.0019444127101451159
Epoch:  224  	Training Loss: 0.0017069308087229729
Test Loss:  0.0017051231116056442
Valid Loss:  0.001942034112289548
Epoch:  225  	Training Loss: 0.0017059718957170844
Test Loss:  0.0017063288250938058
Valid Loss:  0.0019401665776968002
Epoch:  226  	Training Loss: 0.0017051277682185173
Test Loss:  0.0017069580499082804
Valid Loss:  0.0019386637723073363
Epoch:  227  	Training Loss: 0.0017044059932231903
Test Loss:  0.0017072604969143867
Valid Loss:  0.0019374225521460176
Epoch:  228  	Training Loss: 0.0017037121579051018
Test Loss:  0.0017073729541152716
Valid Loss:  0.001936376909725368
Epoch:  229  	Training Loss: 0.0017030384624376893
Test Loss:  0.001707390882074833
Valid Loss:  0.0019354824908077717
Epoch:  230  	Training Loss: 0.0017023923574015498
Test Loss:  0.0017072295304387808
Valid Loss:  0.0019346941262483597
Epoch:  231  	Training Loss: 0.0017017610371112823
Test Loss:  0.0017070863395929337
Valid Loss:  0.0019339851569384336
Epoch:  232  	Training Loss: 0.0017011389136314392
Test Loss:  0.0017002220265567303
Valid Loss:  0.0019348011119291186
Epoch:  233  	Training Loss: 0.001700642635114491
Test Loss:  0.0016953661106526852
Valid Loss:  0.0019344980828464031
Epoch:  234  	Training Loss: 0.0017002944368869066
Test Loss:  0.001691826619207859
Valid Loss:  0.0019334678072482347
Epoch:  235  	Training Loss: 0.0017000192310661077
Test Loss:  0.0016891604755073786
Valid Loss:  0.0019319808343425393
Epoch:  236  	Training Loss: 0.0016997839557006955
Test Loss:  0.0016870839754119515
Valid Loss:  0.0019302190048620105
Epoch:  237  	Training Loss: 0.0016995761543512344
Test Loss:  0.0016854112036526203
Valid Loss:  0.0019283145666122437
Epoch:  238  	Training Loss: 0.001699388725683093
Test Loss:  0.0016840128228068352
Valid Loss:  0.0019263417925685644
Epoch:  239  	Training Loss: 0.0016992132877930999
Test Loss:  0.0016828111838549376
Valid Loss:  0.001924352254718542
Epoch:  240  	Training Loss: 0.0016990510048344731
Test Loss:  0.0016817499417811632
Valid Loss:  0.0019223797135055065
Epoch:  241  	Training Loss: 0.0016989019932225347
Test Loss:  0.0016807965002954006
Valid Loss:  0.0019204483833163977
Epoch:  242  	Training Loss: 0.0016987610142678022
Test Loss:  0.0016811778768897057
Valid Loss:  0.001911934232339263
Epoch:  243  	Training Loss: 0.0016944436356425285
Test Loss:  0.0016792897367849946
Valid Loss:  0.0019061777275055647
Epoch:  244  	Training Loss: 0.0016904370859265327
Test Loss:  0.0016757785342633724
Valid Loss:  0.00190190807916224
Epoch:  245  	Training Loss: 0.0016864907229319215
Test Loss:  0.001672574901022017
Valid Loss:  0.0018969362135976553
Epoch:  246  	Training Loss: 0.0016825556522235274
Test Loss:  0.001668820041231811
Valid Loss:  0.0018926775082945824
Epoch:  247  	Training Loss: 0.0016786339692771435
Test Loss:  0.0016651579644531012
Valid Loss:  0.0018882073927670717
Epoch:  248  	Training Loss: 0.0016747243935242295
Test Loss:  0.001661422080360353
Valid Loss:  0.0018838143441826105
Epoch:  249  	Training Loss: 0.0016708254115656018
Test Loss:  0.001657642307691276
Valid Loss:  0.0018794778734445572
Epoch:  250  	Training Loss: 0.0016669378383085132
Test Loss:  0.001653787912800908
Valid Loss:  0.001875184359960258
Epoch:  251  	Training Loss: 0.0016630777390673757
Test Loss:  0.0016496195457875729
Valid Loss:  0.0018708852585405111
Epoch:  252  	Training Loss: 0.001659251982346177
Test Loss:  0.0016446521040052176
Valid Loss:  0.001872096210718155
Epoch:  253  	Training Loss: 0.0016577185597270727
Test Loss:  0.0016409086529165506
Valid Loss:  0.0018726646667346358
Epoch:  254  	Training Loss: 0.0016565141268074512
Test Loss:  0.001638170680962503
Valid Loss:  0.0018727390561252832
Epoch:  255  	Training Loss: 0.0016554095782339573
Test Loss:  0.00163590582087636
Valid Loss:  0.0018725345144048333
Epoch:  256  	Training Loss: 0.0016544610261917114
Test Loss:  0.0016338099958375096
Valid Loss:  0.0018720943480730057
Epoch:  257  	Training Loss: 0.0016537407645955682
Test Loss:  0.0016321302391588688
Valid Loss:  0.0018714345060288906
Epoch:  258  	Training Loss: 0.0016530831344425678
Test Loss:  0.0016308536287397146
Valid Loss:  0.0018706335686147213
Epoch:  259  	Training Loss: 0.0016524391248822212
Test Loss:  0.0016296367393806577
Valid Loss:  0.0018697513733059168
Epoch:  260  	Training Loss: 0.001651947619393468
Test Loss:  0.001627931371331215
Valid Loss:  0.0018687918782234192
Epoch:  261  	Training Loss: 0.0016515831230208278
Test Loss:  0.0016265453305095434
Valid Loss:  0.0018676421605050564
Epoch:  262  	Training Loss: 0.0016512495931237936
Test Loss:  0.0016266369493678212
Valid Loss:  0.0018653597217053175
Epoch:  263  	Training Loss: 0.001646182732656598
Test Loss:  0.0016252673231065273
Valid Loss:  0.001864327583462
Epoch:  264  	Training Loss: 0.0016425863141193986
Test Loss:  0.0016229564789682627
Valid Loss:  0.001863890211097896
Epoch:  265  	Training Loss: 0.0016398808220401406
Test Loss:  0.0016206437721848488
Valid Loss:  0.0018635240849107504
Epoch:  266  	Training Loss: 0.001637481153011322
Test Loss:  0.0016183562111109495
Valid Loss:  0.001863106619566679
Epoch:  267  	Training Loss: 0.0016352289821952581
Test Loss:  0.001615996239706874
Valid Loss:  0.0018625999800860882
Epoch:  268  	Training Loss: 0.0016330917133018374
Test Loss:  0.0016137599013745785
Valid Loss:  0.001861978555098176
Epoch:  269  	Training Loss: 0.001631053863093257
Test Loss:  0.0016111976001411676
Valid Loss:  0.001861237338744104
Epoch:  270  	Training Loss: 0.00162907550111413
Test Loss:  0.0016087808180600405
Valid Loss:  0.0018603471107780933
Epoch:  271  	Training Loss: 0.0016271178610622883
Test Loss:  0.001606617821380496
Valid Loss:  0.0018593303393572569
Epoch:  272  	Training Loss: 0.0016251656925305724
Test Loss:  0.0016056897584348917
Valid Loss:  0.00185626361053437
Epoch:  273  	Training Loss: 0.0016226114239543676
Test Loss:  0.0016045932425186038
Valid Loss:  0.0018534142291173339
Epoch:  274  	Training Loss: 0.0016202745027840137
Test Loss:  0.001603437471203506
Valid Loss:  0.0018507455242797732
 55%|█████▌    | 275/500 [03:26<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:26<01:42,  2.17it/s] 56%|█████▌    | 279/500 [03:26<01:16,  2.88it/s] 56%|█████▌    | 281/500 [03:33<04:24,  1.21s/it] 57%|█████▋    | 283/500 [03:33<03:08,  1.15it/s] 57%|█████▋    | 285/500 [03:33<02:15,  1.59it/s] 57%|█████▋    | 287/500 [03:33<01:38,  2.16it/s] 58%|█████▊    | 289/500 [03:33<01:13,  2.86it/s] 58%|█████▊    | 291/500 [03:40<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:40<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:40<02:09,  1.59it/s] 59%|█████▉    | 297/500 [03:40<01:34,  2.14it/s] 60%|█████▉    | 299/500 [03:40<01:10,  2.83it/s] 60%|██████    | 301/500 [03:47<03:59,  1.20s/it] 61%|██████    | 303/500 [03:47<02:50,  1.16it/s] 61%|██████    | 305/500 [03:47<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:47<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:47<01:06,  2.89it/s] 62%|██████▏   | 311/500 [03:54<03:47,  1.20s/it] 63%|██████▎   | 313/500 [03:54<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:54<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:54<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:54<01:01,  2.94it/s] 64%|██████▍   | 321/500 [04:01<03:36,  1.21s/it] 65%|██████▍   | 323/500 [04:01<02:34,  1.15it/s] 65%|██████▌   | 325/500 [04:01<01:51,  1.57it/s] 65%|██████▌   | 327/500 [04:01<01:21,  2.13it/s] 66%|██████▌   | 329/500 [04:02<01:00,  2.82it/s] 66%|██████▌   | 331/500 [04:08<03:24,  1.21s/it] 67%|██████▋   | 333/500 [04:08<02:25,  1.15it/s] 67%|██████▋   | 335/500 [04:08<01:44,  1.58it/s] 67%|██████▋   | 337/500 [04:08<01:16,  2.13it/s] 68%|██████▊   | 339/500 [04:09<00:56,  2.83it/s] 68%|██████▊   | 341/500 [04:15<03:11,  1.21s/it]Epoch:  275  	Training Loss: 0.0016180226812139153
Test Loss:  0.001602198462933302
Valid Loss:  0.0018481991719454527
Epoch:  276  	Training Loss: 0.0016158188227564096
Test Loss:  0.001600904855877161
Valid Loss:  0.001845771912485361
Epoch:  277  	Training Loss: 0.0016136838821694255
Test Loss:  0.0015995493158698082
Valid Loss:  0.0018434214871376753
Epoch:  278  	Training Loss: 0.0016115613980218768
Test Loss:  0.001598157687112689
Valid Loss:  0.0018411511555314064
Epoch:  279  	Training Loss: 0.0016094830352813005
Test Loss:  0.0015967010986059904
Valid Loss:  0.0018389292526990175
Epoch:  280  	Training Loss: 0.0016074073500931263
Test Loss:  0.001595226232893765
Valid Loss:  0.0018367505399510264
Epoch:  281  	Training Loss: 0.0016053472645580769
Test Loss:  0.0015937169082462788
Valid Loss:  0.0018346519209444523
Epoch:  282  	Training Loss: 0.0016033353749662638
Test Loss:  0.0015927425120025873
Valid Loss:  0.0018342850962653756
Epoch:  283  	Training Loss: 0.001602668548002839
Test Loss:  0.0015917574055492878
Valid Loss:  0.0018338847439736128
Epoch:  284  	Training Loss: 0.0016020543407648802
Test Loss:  0.0015903436578810215
Valid Loss:  0.0018334160558879375
Epoch:  285  	Training Loss: 0.0016015882138162851
Test Loss:  0.0015889066271483898
Valid Loss:  0.0018328623846173286
Epoch:  286  	Training Loss: 0.0016012020641937852
Test Loss:  0.0015872505027800798
Valid Loss:  0.0018321973038837314
Epoch:  287  	Training Loss: 0.0016008727252483368
Test Loss:  0.0015858779661357403
Valid Loss:  0.0018314201151952147
Epoch:  288  	Training Loss: 0.0016005500219762325
Test Loss:  0.0015847033355385065
Valid Loss:  0.0018305600387975574
Epoch:  289  	Training Loss: 0.001600230927579105
Test Loss:  0.0015836685197427869
Valid Loss:  0.001829655491746962
Epoch:  290  	Training Loss: 0.0015999171882867813
Test Loss:  0.001582736149430275
Valid Loss:  0.0018287204438820481
Epoch:  291  	Training Loss: 0.001599610666744411
Test Loss:  0.001581875723786652
Valid Loss:  0.0018277699127793312
Epoch:  292  	Training Loss: 0.0015993175329640508
Test Loss:  0.0015783029375597835
Valid Loss:  0.0018249957356601954
Epoch:  293  	Training Loss: 0.001597339753061533
Test Loss:  0.0015752739273011684
Valid Loss:  0.0018220122437924147
Epoch:  294  	Training Loss: 0.0015954039990901947
Test Loss:  0.0015726297860965133
Valid Loss:  0.0018189047696068883
Epoch:  295  	Training Loss: 0.0015935692936182022
Test Loss:  0.0015703752869740129
Valid Loss:  0.0018157950835302472
Epoch:  296  	Training Loss: 0.0015919719589874148
Test Loss:  0.001568457344546914
Valid Loss:  0.0018127686344087124
Epoch:  297  	Training Loss: 0.0015905541367828846
Test Loss:  0.0015667061088606715
Valid Loss:  0.0018098141299560666
Epoch:  298  	Training Loss: 0.0015892275841906667
Test Loss:  0.001565081998705864
Valid Loss:  0.0018069278448820114
Epoch:  299  	Training Loss: 0.0015879198908805847
Test Loss:  0.0015636291354894638
Valid Loss:  0.001804116414859891
Epoch:  300  	Training Loss: 0.001586630241945386
Test Loss:  0.0015622376231476665
Valid Loss:  0.0018013865919783711
Epoch:  301  	Training Loss: 0.001585356891155243
Test Loss:  0.0015609085094183683
Valid Loss:  0.0017987724859267473
Epoch:  302  	Training Loss: 0.001584100304171443
Test Loss:  0.0015615662559866905
Valid Loss:  0.001795981079339981
Epoch:  303  	Training Loss: 0.0015839129919186234
Test Loss:  0.0015620270278304815
Valid Loss:  0.0017935528885573149
Epoch:  304  	Training Loss: 0.0015837450046092272
Test Loss:  0.0015623308718204498
Valid Loss:  0.0017914255149662495
Epoch:  305  	Training Loss: 0.0015835881931707263
Test Loss:  0.0015625018859282136
Valid Loss:  0.001789546338841319
Epoch:  306  	Training Loss: 0.0015834413934499025
Test Loss:  0.0015625684754922986
Valid Loss:  0.0017878717044368386
Epoch:  307  	Training Loss: 0.0015833067009225488
Test Loss:  0.0015625428641214967
Valid Loss:  0.0017863695975393057
Epoch:  308  	Training Loss: 0.0015831799246370792
Test Loss:  0.0015624493826180696
Valid Loss:  0.0017850106814876199
Epoch:  309  	Training Loss: 0.0015830602496862411
Test Loss:  0.0015622959472239017
Valid Loss:  0.0017837748164311051
Epoch:  310  	Training Loss: 0.0015829452313482761
Test Loss:  0.001562095945701003
Valid Loss:  0.0017826411640271544
Epoch:  311  	Training Loss: 0.0015828305622562766
Test Loss:  0.0015618589241057634
Valid Loss:  0.001781594823114574
Epoch:  312  	Training Loss: 0.0015827182214707136
Test Loss:  0.00156053202226758
Valid Loss:  0.0017814796883612871
Epoch:  313  	Training Loss: 0.0015826745657250285
Test Loss:  0.0015594793949276209
Valid Loss:  0.0017812279984354973
Epoch:  314  	Training Loss: 0.0015826360322535038
Test Loss:  0.0015586287481710315
Valid Loss:  0.0017808768898248672
Epoch:  315  	Training Loss: 0.001582601573318243
Test Loss:  0.0015579327009618282
Valid Loss:  0.0017804577946662903
Epoch:  316  	Training Loss: 0.0015825688606128097
Test Loss:  0.0015573580749332905
Valid Loss:  0.0017799881752580404
Epoch:  317  	Training Loss: 0.0015825408045202494
Test Loss:  0.0015568672679364681
Valid Loss:  0.0017794857267290354
Epoch:  318  	Training Loss: 0.0015825105365365744
Test Loss:  0.0015564471250399947
Valid Loss:  0.0017789630219340324
Epoch:  319  	Training Loss: 0.0015824860893189907
Test Loss:  0.0015560755273327231
Valid Loss:  0.0017784293740987778
Epoch:  320  	Training Loss: 0.0015824602451175451
Test Loss:  0.0015557478182017803
Valid Loss:  0.0017778938636183739
Epoch:  321  	Training Loss: 0.0015824359143152833
Test Loss:  0.001555452705360949
Valid Loss:  0.001777352299541235
Epoch:  322  	Training Loss: 0.0015824122820049524
Test Loss:  0.0015546143986284733
Valid Loss:  0.0017766370438039303
Epoch:  323  	Training Loss: 0.0015821062261238694
Test Loss:  0.0015540181193500757
Valid Loss:  0.0017758018802851439
Epoch:  324  	Training Loss: 0.0015818116953596473
Test Loss:  0.0015535042621195316
Valid Loss:  0.001774957519955933
Epoch:  325  	Training Loss: 0.0015815180959179997
Test Loss:  0.0015530436066910625
Valid Loss:  0.0017741156043484807
Epoch:  326  	Training Loss: 0.0015812378842383623
Test Loss:  0.0015525706112384796
Valid Loss:  0.001773346564732492
Epoch:  327  	Training Loss: 0.0015809903852641582
Test Loss:  0.0015522364992648363
Valid Loss:  0.0017725341022014618
Epoch:  328  	Training Loss: 0.0015807687304913998
Test Loss:  0.0015519087901338935
Valid Loss:  0.001771753653883934
Epoch:  329  	Training Loss: 0.0015805612783879042
Test Loss:  0.0015515879495069385
Valid Loss:  0.0017710006795823574
Epoch:  330  	Training Loss: 0.0015803516143932939
Test Loss:  0.0015512238023802638
Valid Loss:  0.0017703301273286343
Epoch:  331  	Training Loss: 0.0015801426488906145
Test Loss:  0.0015509576769545674
Valid Loss:  0.001769611262716353
Epoch:  332  	Training Loss: 0.0015799320535734296
Test Loss:  0.0015521787572652102
Valid Loss:  0.001768638496287167
Epoch:  333  	Training Loss: 0.0015777589287608862
Test Loss:  0.001552349654957652
Valid Loss:  0.0017680646851658821
Epoch:  334  	Training Loss: 0.001575652277097106
Test Loss:  0.001551822293549776
Valid Loss:  0.001767713576555252
Epoch:  335  	Training Loss: 0.0015736088389530778
Test Loss:  0.0015508795622736216
Valid Loss:  0.0017674787668511271
Epoch:  336  	Training Loss: 0.0015715928748250008
Test Loss:  0.0015496397390961647
Valid Loss:  0.0017672930844128132
Epoch:  337  	Training Loss: 0.0015696166083216667
Test Loss:  0.0015482384478673339
Valid Loss:  0.0017671147361397743
Epoch:  338  	Training Loss: 0.001567674451507628
Test Loss:  0.0015467863995581865
Valid Loss:  0.0017669184599071741
Epoch:  339  	Training Loss: 0.0015657541807740927
Test Loss:  0.0015452895313501358
Valid Loss:  0.0017666831845417619
Epoch:  340  	Training Loss: 0.001563847647048533
Test Loss:  0.001543766469694674
Valid Loss:  0.0017664055339992046
Epoch:  341  	Training Loss: 0.0015619584592059255
Test Loss:  0.001542168203741312
Valid Loss:  0.00176607770845294
Epoch:  342  	Training Loss: 0.0015601058257743716
Test Loss:  0.0015387580497190356
Valid Loss:  0.0017656288109719753
Epoch:  343  	Training Loss: 0.0015589057002216578
Test Loss:   69%|██████▊   | 343/500 [04:15<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:15<01:36,  1.60it/s] 69%|██████▉   | 347/500 [04:15<01:09,  2.19it/s] 70%|██████▉   | 349/500 [04:15<00:51,  2.95it/s] 70%|███████   | 351/500 [04:22<02:57,  1.19s/it] 71%|███████   | 353/500 [04:22<02:05,  1.17it/s] 71%|███████   | 355/500 [04:22<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:22<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:22<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:29<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:29<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:29<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:29<01:00,  2.22it/s] 74%|███████▍  | 369/500 [04:29<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:36<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:36<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:36<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:36<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:36<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:43<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:43<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:43<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:43<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:43<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:50<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:50<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:50<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:50<00:46,  2.19it/s] 80%|███████▉  | 399/500 [04:50<00:34,  2.96it/s] 80%|████████  | 401/500 [04:56<01:57,  1.18s/it] 81%|████████  | 403/500 [04:56<01:22,  1.18it/s] 81%|████████  | 405/500 [04:57<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:57<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:57<00:30,  2.99it/s] 82%|████████▏ | 411/500 [05:03<01:47,  1.20s/it]0.0015359848039224744
Valid Loss:  0.0017649340443313122
Epoch:  344  	Training Loss: 0.0015577399171888828
Test Loss:  0.001533781411126256
Valid Loss:  0.0017640584846958518
Epoch:  345  	Training Loss: 0.0015565974172204733
Test Loss:  0.0015319236554205418
Valid Loss:  0.0017630422953516245
Epoch:  346  	Training Loss: 0.0015554707497358322
Test Loss:  0.0015303391264751554
Valid Loss:  0.0017619224963709712
Epoch:  347  	Training Loss: 0.0015543571207672358
Test Loss:  0.001529092201963067
Valid Loss:  0.0017607249319553375
Epoch:  348  	Training Loss: 0.0015532511752098799
Test Loss:  0.0015280201332643628
Valid Loss:  0.0017594763776287436
Epoch:  349  	Training Loss: 0.0015521562891080976
Test Loss:  0.0015270684380084276
Valid Loss:  0.0017581867286935449
Epoch:  350  	Training Loss: 0.0015510667581111193
Test Loss:  0.0015262163942679763
Valid Loss:  0.0017568713519722223
Epoch:  351  	Training Loss: 0.0015499836299568415
Test Loss:  0.0015254387399181724
Valid Loss:  0.0017555439844727516
Epoch:  352  	Training Loss: 0.0015489119105041027
Test Loss:  0.0015253411838784814
Valid Loss:  0.0017533277859911323
Epoch:  353  	Training Loss: 0.0015478837303817272
Test Loss:  0.001525047468021512
Valid Loss:  0.0017513097263872623
Epoch:  354  	Training Loss: 0.0015468659112229943
Test Loss:  0.0015246307011693716
Valid Loss:  0.0017494151834398508
Epoch:  355  	Training Loss: 0.001545855775475502
Test Loss:  0.0015241678338497877
Valid Loss:  0.0017476032953709364
Epoch:  356  	Training Loss: 0.001544854836538434
Test Loss:  0.001523714978247881
Valid Loss:  0.001745877554640174
Epoch:  357  	Training Loss: 0.0015439538983628154
Test Loss:  0.0015232744626700878
Valid Loss:  0.0017442333046346903
Epoch:  358  	Training Loss: 0.0015430898638442159
Test Loss:  0.001522818929515779
Valid Loss:  0.001742648659273982
Epoch:  359  	Training Loss: 0.0015422331634908915
Test Loss:  0.0015223599039018154
Valid Loss:  0.0017411119770258665
Epoch:  360  	Training Loss: 0.0015413974178954959
Test Loss:  0.0015219394117593765
Valid Loss:  0.0017396435141563416
Epoch:  361  	Training Loss: 0.0015406095189973712
Test Loss:  0.0015215170569717884
Valid Loss:  0.0017382223159074783
Epoch:  362  	Training Loss: 0.0015398279065266252
Test Loss:  0.0015229247510433197
Valid Loss:  0.0017373166047036648
Epoch:  363  	Training Loss: 0.0015396615490317345
Test Loss:  0.0015235368628054857
Valid Loss:  0.0017367268446832895
Epoch:  364  	Training Loss: 0.0015395816881209612
Test Loss:  0.0015236691106110811
Valid Loss:  0.0017362578073516488
Epoch:  365  	Training Loss: 0.0015395409427583218
Test Loss:  0.001523443846963346
Valid Loss:  0.0017358396435156465
Epoch:  366  	Training Loss: 0.0015395168447867036
Test Loss:  0.0015232065925374627
Valid Loss:  0.00173543905839324
Epoch:  367  	Training Loss: 0.0015394964721053839
Test Loss:  0.0015228554839268327
Valid Loss:  0.0017350275302305818
Epoch:  368  	Training Loss: 0.00153948029037565
Test Loss:  0.0015226500108838081
Valid Loss:  0.0017346239183098078
Epoch:  369  	Training Loss: 0.0015394666697829962
Test Loss:  0.001522326609119773
Valid Loss:  0.0017342123901471496
Epoch:  370  	Training Loss: 0.0015394540969282389
Test Loss:  0.0015221592038869858
Valid Loss:  0.0017338169272989035
Epoch:  371  	Training Loss: 0.0015394436195492744
Test Loss:  0.0015218646731227636
Valid Loss:  0.0017334141302853823
Epoch:  372  	Training Loss: 0.0015394340734928846
Test Loss:  0.001521378755569458
Valid Loss:  0.0017336062155663967
Epoch:  373  	Training Loss: 0.0015365664148703218
Test Loss:  0.0015208632685244083
Valid Loss:  0.0017337272875010967
Epoch:  374  	Training Loss: 0.0015340830432251096
Test Loss:  0.001520492136478424
Valid Loss:  0.0017334625590592623
Epoch:  375  	Training Loss: 0.001531889894977212
Test Loss:  0.0015201747883111238
Valid Loss:  0.0017329445108771324
Epoch:  376  	Training Loss: 0.0015297598438337445
Test Loss:  0.0015194982988759875
Valid Loss:  0.0017325298395007849
Epoch:  377  	Training Loss: 0.001527720713056624
Test Loss:  0.0015182194765657187
Valid Loss:  0.0017321283230558038
Epoch:  378  	Training Loss: 0.0015257855411618948
Test Loss:  0.001516862539574504
Valid Loss:  0.0017317128367722034
Epoch:  379  	Training Loss: 0.0015238731866702437
Test Loss:  0.0015152981504797935
Valid Loss:  0.0017314008437097073
Epoch:  380  	Training Loss: 0.0015219738706946373
Test Loss:  0.0015138600720092654
Valid Loss:  0.0017309141112491488
Epoch:  381  	Training Loss: 0.001520083169452846
Test Loss:  0.001512120827101171
Valid Loss:  0.0017306471709161997
Epoch:  382  	Training Loss: 0.0015182034112513065
Test Loss:  0.001510104164481163
Valid Loss:  0.001730234595015645
Epoch:  383  	Training Loss: 0.0015162568306550384
Test Loss:  0.0015082067111507058
Valid Loss:  0.0017297333106398582
Epoch:  384  	Training Loss: 0.0015143461059778929
Test Loss:  0.0015061907470226288
Valid Loss:  0.0017291398253291845
Epoch:  385  	Training Loss: 0.0015124683268368244
Test Loss:  0.0015043159946799278
Valid Loss:  0.0017284732311964035
Epoch:  386  	Training Loss: 0.0015106182545423508
Test Loss:  0.0015025301836431026
Valid Loss:  0.0017277339939028025
Epoch:  387  	Training Loss: 0.0015087876236066222
Test Loss:  0.0015008090995252132
Valid Loss:  0.0017269377131015062
Epoch:  388  	Training Loss: 0.001506974222138524
Test Loss:  0.001499137026257813
Valid Loss:  0.0017260940512642264
Epoch:  389  	Training Loss: 0.0015051765367388725
Test Loss:  0.001497496385127306
Valid Loss:  0.001725207781419158
Epoch:  390  	Training Loss: 0.0015033960808068514
Test Loss:  0.0014958931133151054
Valid Loss:  0.001724296249449253
Epoch:  391  	Training Loss: 0.0015016302932053804
Test Loss:  0.001494318014010787
Valid Loss:  0.001723361317999661
Epoch:  392  	Training Loss: 0.0014998806873336434
Test Loss:  0.0014937740052118897
Valid Loss:  0.0017208708450198174
Epoch:  393  	Training Loss: 0.0014980868436396122
Test Loss:  0.0014929412864148617
Valid Loss:  0.0017186208860948682
Epoch:  394  	Training Loss: 0.0014963072026148438
Test Loss:  0.0014918858651071787
Valid Loss:  0.0017165399622172117
Epoch:  395  	Training Loss: 0.0014945357106626034
Test Loss:  0.001490679569542408
Valid Loss:  0.0017145826714113355
Epoch:  396  	Training Loss: 0.0014927777228876948
Test Loss:  0.0014893499901518226
Valid Loss:  0.0017127067549154162
Epoch:  397  	Training Loss: 0.0014910255558788776
Test Loss:  0.0014879368245601654
Valid Loss:  0.0017108973115682602
Epoch:  398  	Training Loss: 0.00148927909322083
Test Loss:  0.0014864681288599968
Valid Loss:  0.0017091286135837436
Epoch:  399  	Training Loss: 0.0014875356573611498
Test Loss:  0.0014849533326923847
Valid Loss:  0.0017073870403692126
Epoch:  400  	Training Loss: 0.0014857945498079062
Test Loss:  0.0014834086177870631
Valid Loss:  0.0017056672368198633
Epoch:  401  	Training Loss: 0.0014840555377304554
Test Loss:  0.001481848070397973
Valid Loss:  0.0017039605882018805
Epoch:  402  	Training Loss: 0.0014823246747255325
Test Loss:  0.0014770464040338993
Valid Loss:  0.0016971533186733723
Epoch:  403  	Training Loss: 0.0014788965927436948
Test Loss:  0.0014728307723999023
Valid Loss:  0.001691663172096014
Epoch:  404  	Training Loss: 0.001476191682741046
Test Loss:  0.0014692090917378664
Valid Loss:  0.0016867911908775568
Epoch:  405  	Training Loss: 0.0014739049365743995
Test Loss:  0.0014662062749266624
Valid Loss:  0.001682054135017097
Epoch:  406  	Training Loss: 0.0014717292506247759
Test Loss:  0.0014636546839028597
Valid Loss:  0.0016774837858974934
Epoch:  407  	Training Loss: 0.0014697018777951598
Test Loss:  0.0014614604879170656
Valid Loss:  0.0016732390504330397
Epoch:  408  	Training Loss: 0.0014678883599117398
Test Loss:  0.0014596234541386366
Valid Loss:  0.001669198740273714
Epoch:  409  	Training Loss: 0.001466156099922955
Test Loss:  0.0014580729184672236
Valid Loss:  0.0016652530757710338
Epoch:  410  	Training Loss: 0.0014644904294982553
Test Loss:  0.001456639263778925
Valid Loss:  0.0016616361681371927
Epoch:  411  	Training Loss: 0.001462927320972085
Test Loss:  0.0014553426299244165
Valid Loss:  0.0016581180971115828
 83%|████████▎ | 413/500 [05:04<01:15,  1.15it/s] 83%|████████▎ | 415/500 [05:04<00:53,  1.58it/s] 83%|████████▎ | 417/500 [05:04<00:38,  2.13it/s] 84%|████████▍ | 419/500 [05:04<00:28,  2.83it/s] 84%|████████▍ | 421/500 [05:10<01:35,  1.21s/it] 85%|████████▍ | 423/500 [05:11<01:06,  1.15it/s] 85%|████████▌ | 425/500 [05:11<00:46,  1.60it/s] 85%|████████▌ | 427/500 [05:11<00:33,  2.18it/s] 86%|████████▌ | 429/500 [05:11<00:24,  2.94it/s] 86%|████████▌ | 431/500 [05:17<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:17<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:17<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:18<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:18<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:24<01:09,  1.19s/it] 89%|████████▊ | 443/500 [05:24<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:24<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:25<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:25<00:17,  2.86it/s] 90%|█████████ | 451/500 [05:31<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:31<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:31<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:32<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:32<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:38<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:38<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:38<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:38<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:39<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:45<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:45<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:45<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:45<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:45<00:07,  2.94it/s]Epoch:  412  	Training Loss: 0.0014614418614655733
Test Loss:  0.0014559084083884954
Valid Loss:  0.0016575767658650875
Epoch:  413  	Training Loss: 0.0014590468490496278
Test Loss:  0.001455322839319706
Valid Loss:  0.001657255575992167
Epoch:  414  	Training Loss: 0.0014568101614713669
Test Loss:  0.001454280805774033
Valid Loss:  0.0016570590669289231
Epoch:  415  	Training Loss: 0.0014546173624694347
Test Loss:  0.0014529424952343106
Valid Loss:  0.0016569255385547876
Epoch:  416  	Training Loss: 0.0014524566940963268
Test Loss:  0.001451430143788457
Valid Loss:  0.0016568570863455534
Epoch:  417  	Training Loss: 0.0014503257116302848
Test Loss:  0.0014498624950647354
Valid Loss:  0.0016567467246204615
Epoch:  418  	Training Loss: 0.0014482210390269756
Test Loss:  0.0014480303507298231
Valid Loss:  0.001656597713008523
Epoch:  419  	Training Loss: 0.0014461707323789597
Test Loss:  0.0014461587416008115
Valid Loss:  0.0016564298421144485
Epoch:  420  	Training Loss: 0.001444143825210631
Test Loss:  0.0014443418476730585
Valid Loss:  0.001656163134612143
Epoch:  421  	Training Loss: 0.0014421322848647833
Test Loss:  0.0014425474219024181
Valid Loss:  0.0016558477655053139
Epoch:  422  	Training Loss: 0.0014401382068172097
Test Loss:  0.0014407829148694873
Valid Loss:  0.0016568053979426622
Epoch:  423  	Training Loss: 0.0014392361044883728
Test Loss:  0.001439180108718574
Valid Loss:  0.001657696207985282
Epoch:  424  	Training Loss: 0.001438372302800417
Test Loss:  0.0014377088518813252
Valid Loss:  0.0016585520934313536
Epoch:  425  	Training Loss: 0.0014375475002452731
Test Loss:  0.0014364072121679783
Valid Loss:  0.001659372472204268
Epoch:  426  	Training Loss: 0.0014367620460689068
Test Loss:  0.0014351627323776484
Valid Loss:  0.0016601553652435541
Epoch:  427  	Training Loss: 0.0014360047644004226
Test Loss:  0.0014340055640786886
Valid Loss:  0.0016608951846137643
Epoch:  428  	Training Loss: 0.0014352675061672926
Test Loss:  0.001433033961802721
Valid Loss:  0.001661601709201932
Epoch:  429  	Training Loss: 0.0014345473609864712
Test Loss:  0.0014320940244942904
Valid Loss:  0.0016622741241008043
Epoch:  430  	Training Loss: 0.0014338530600070953
Test Loss:  0.0014310077531263232
Valid Loss:  0.001662913360632956
Epoch:  431  	Training Loss: 0.0014332435093820095
Test Loss:  0.0014300112379714847
Valid Loss:  0.0016634927596896887
Epoch:  432  	Training Loss: 0.001432671444490552
Test Loss:  0.0014255533460527658
Valid Loss:  0.0016625378048047423
Epoch:  433  	Training Loss: 0.0014313285937532783
Test Loss:  0.0014226201456040144
Valid Loss:  0.001660993555560708
Epoch:  434  	Training Loss: 0.0014300942420959473
Test Loss:  0.00142050557769835
Valid Loss:  0.0016591312596574426
Epoch:  435  	Training Loss: 0.0014289066893979907
Test Loss:  0.0014188924105837941
Valid Loss:  0.0016571271698921919
Epoch:  436  	Training Loss: 0.0014277806039899588
Test Loss:  0.0014175582909956574
Valid Loss:  0.0016550584696233273
Epoch:  437  	Training Loss: 0.0014266666257753968
Test Loss:  0.0014164855238050222
Valid Loss:  0.0016529752174392343
Epoch:  438  	Training Loss: 0.001425564056262374
Test Loss:  0.0014155037933960557
Valid Loss:  0.0016509001143276691
Epoch:  439  	Training Loss: 0.0014244726626202464
Test Loss:  0.0014145805034786463
Valid Loss:  0.0016488495748490095
Epoch:  440  	Training Loss: 0.0014233924448490143
Test Loss:  0.001413700170814991
Valid Loss:  0.0016468295361846685
Epoch:  441  	Training Loss: 0.0014223202597349882
Test Loss:  0.0014129491755738854
Valid Loss:  0.001644844887778163
Epoch:  442  	Training Loss: 0.001421257620677352
Test Loss:  0.0014098715037107468
Valid Loss:  0.0016449926188215613
Epoch:  443  	Training Loss: 0.0014200267614796758
Test Loss:  0.0014075393555685878
Valid Loss:  0.0016448700334876776
Epoch:  444  	Training Loss: 0.0014189801877364516
Test Loss:  0.001405877061188221
Valid Loss:  0.0016444276552647352
Epoch:  445  	Training Loss: 0.0014181912411004305
Test Loss:  0.001404961571097374
Valid Loss:  0.0016436439473181963
Epoch:  446  	Training Loss: 0.0014175712130963802
Test Loss:  0.0014041831018403172
Valid Loss:  0.0016428589588031173
Epoch:  447  	Training Loss: 0.0014171046204864979
Test Loss:  0.001404099864885211
Valid Loss:  0.0016415108693763614
Epoch:  448  	Training Loss: 0.001416867831721902
Test Loss:  0.0014040058013051748
Valid Loss:  0.001640178612433374
Epoch:  449  	Training Loss: 0.001416697516106069
Test Loss:  0.0014041510876268148
Valid Loss:  0.0016386969946324825
Epoch:  450  	Training Loss: 0.001416582497768104
Test Loss:  0.0014043955598026514
Valid Loss:  0.001637136097997427
Epoch:  451  	Training Loss: 0.001416494371369481
Test Loss:  0.0014044863637536764
Valid Loss:  0.0016357196727767587
Epoch:  452  	Training Loss: 0.0014164131134748459
Test Loss:  0.0014051501639187336
Valid Loss:  0.0016323481686413288
Epoch:  453  	Training Loss: 0.001416135230101645
Test Loss:  0.0014052134938538074
Valid Loss:  0.0016296138055622578
Epoch:  454  	Training Loss: 0.0014158810954540968
Test Loss:  0.001404905691742897
Valid Loss:  0.0016273052897304296
Epoch:  455  	Training Loss: 0.0014156474499031901
Test Loss:  0.0014044973067939281
Valid Loss:  0.0016251758206635714
Epoch:  456  	Training Loss: 0.0014154361560940742
Test Loss:  0.001403922331519425
Valid Loss:  0.0016232787165790796
Epoch:  457  	Training Loss: 0.00141524663195014
Test Loss:  0.0014032712206244469
Valid Loss:  0.0016215462237596512
Epoch:  458  	Training Loss: 0.001415071776136756
Test Loss:  0.001402594381943345
Valid Loss:  0.0016199410893023014
Epoch:  459  	Training Loss: 0.001414904254488647
Test Loss:  0.0014019175432622433
Valid Loss:  0.001618445967324078
Epoch:  460  	Training Loss: 0.0014147444162517786
Test Loss:  0.0014013898326084018
Valid Loss:  0.0016169246518984437
Epoch:  461  	Training Loss: 0.0014145917957648635
Test Loss:  0.0014005512930452824
Valid Loss:  0.0016157738864421844
Epoch:  462  	Training Loss: 0.0014144519809633493
Test Loss:  0.0013998032081872225
Valid Loss:  0.0016146167181432247
Epoch:  463  	Training Loss: 0.0014126640744507313
Test Loss:  0.0013986986596137285
Valid Loss:  0.0016135969199240208
Epoch:  464  	Training Loss: 0.0014108975883573294
Test Loss:  0.0013974035391584039
Valid Loss:  0.001612636144272983
Epoch:  465  	Training Loss: 0.0014091419288888574
Test Loss:  0.0013959857169538736
Valid Loss:  0.0016116814222186804
Epoch:  466  	Training Loss: 0.001407393254339695
Test Loss:  0.0013944972306489944
Valid Loss:  0.0016107072588056326
Epoch:  467  	Training Loss: 0.001405650982633233
Test Loss:  0.0013929754495620728
Valid Loss:  0.0016097091138362885
Epoch:  468  	Training Loss: 0.0014039145316928625
Test Loss:  0.0013914252631366253
Valid Loss:  0.001608673483133316
Epoch:  469  	Training Loss: 0.0014021811075508595
Test Loss:  0.0013898639008402824
Valid Loss:  0.0016076021129265428
Epoch:  470  	Training Loss: 0.0014004549011588097
Test Loss:  0.0013882999774068594
Valid Loss:  0.0016064937226474285
Epoch:  471  	Training Loss: 0.001398738007992506
Test Loss:  0.0013867344241589308
Valid Loss:  0.0016053528524935246
Epoch:  472  	Training Loss: 0.0013970246072858572
Test Loss:  0.001384079223498702
Valid Loss:  0.0016036916058510542
Epoch:  473  	Training Loss: 0.0013958951458334923
Test Loss:  0.0013819743180647492
Valid Loss:  0.0016017998568713665
Epoch:  474  	Training Loss: 0.0013947918778285384
Test Loss:  0.0013802290195599198
Valid Loss:  0.0015997841255739331
Epoch:  475  	Training Loss: 0.0013937072362750769
Test Loss:  0.0013787689385935664
Valid Loss:  0.0015977153088897467
Epoch:  476  	Training Loss: 0.0013926372630521655
Test Loss:  0.0013775627594441175
Valid Loss:  0.001595633220858872
Epoch:  477  	Training Loss: 0.0013915782328695059
Test Loss:  0.0013764798641204834
Valid Loss:  0.0015935725532472134
Epoch:  478  	Training Loss: 0.0013905296800658107
Test Loss:  0.0013754862593486905
Valid Loss:  0.0015915450640022755
Epoch:  479  	Training Loss: 0.0013894937001168728
Test Loss:  0.0013745656469836831
Valid Loss:  0.001589563675224781
Epoch:  480  	Training Loss: 0.0013884673826396465
Test Loss:   96%|█████████▌| 481/500 [05:52<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:52<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:52<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:52<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:52<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:59<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:59<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:59<00:03,  1.58it/s] 99%|█████████▉| 497/500 [05:59<00:01,  2.15it/s]100%|█████████▉| 499/500 [05:59<00:00,  2.89it/s]100%|██████████| 500/500 [05:59<00:00,  1.39it/s]
0.0013736984692513943
Valid Loss:  0.001587634556926787
Epoch:  481  	Training Loss: 0.001387450727634132
Test Loss:  0.0013728771591559052
Valid Loss:  0.001585761085152626
Epoch:  482  	Training Loss: 0.0013864412903785706
Test Loss:  0.001373034669086337
Valid Loss:  0.001584680867381394
Epoch:  483  	Training Loss: 0.0013863230124115944
Test Loss:  0.0013731027720496058
Valid Loss:  0.0015837025130167603
Epoch:  484  	Training Loss: 0.0013862143969163299
Test Loss:  0.001373098697513342
Valid Loss:  0.0015828122850507498
Epoch:  485  	Training Loss: 0.0013861090410500765
Test Loss:  0.0013730395585298538
Valid Loss:  0.0015819871332496405
Epoch:  486  	Training Loss: 0.001386010553687811
Test Loss:  0.0013729408383369446
Valid Loss:  0.0015812164638191462
Epoch:  487  	Training Loss: 0.00138591299764812
Test Loss:  0.0013728172052651644
Valid Loss:  0.0015804951544851065
Epoch:  488  	Training Loss: 0.0013858177699148655
Test Loss:  0.00137267354875803
Valid Loss:  0.0015798145905137062
Epoch:  489  	Training Loss: 0.0013857233570888638
Test Loss:  0.00137251615524292
Valid Loss:  0.0015791666228324175
Epoch:  490  	Training Loss: 0.0013856309233233333
Test Loss:  0.0013723485171794891
Valid Loss:  0.0015785503201186657
Epoch:  491  	Training Loss: 0.0013855388388037682
Test Loss:  0.0013721815776079893
Valid Loss:  0.0015779593959450722
Epoch:  492  	Training Loss: 0.001385451527312398
Test Loss:  0.0013725119642913342
Valid Loss:  0.0015773298218846321
Epoch:  493  	Training Loss: 0.0013837161241099238
Test Loss:  0.0013720791321247816
Valid Loss:  0.0015769473975524306
Epoch:  494  	Training Loss: 0.0013820119202136993
Test Loss:  0.0013711948413401842
Valid Loss:  0.0015766917495056987
Epoch:  495  	Training Loss: 0.0013803276233375072
Test Loss:  0.001370044774375856
Valid Loss:  0.0015764901181682944
Epoch:  496  	Training Loss: 0.0013786605559289455
Test Loss:  0.001368741737678647
Valid Loss:  0.0015763032715767622
Epoch:  497  	Training Loss: 0.0013770057121291757
Test Loss:  0.0013673512730747461
Valid Loss:  0.0015761058311909437
Epoch:  498  	Training Loss: 0.0013753646053373814
Test Loss:  0.001365911797620356
Valid Loss:  0.0015758901135995984
Epoch:  499  	Training Loss: 0.0013737359549850225
Test Loss:  0.0013644490391016006
Valid Loss:  0.0015756424982100725
Epoch:  500  	Training Loss: 0.0013721180148422718
Test Loss:  0.0013629721943289042
Valid Loss:  0.0015753605403006077
seed is  18
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:40, 12.42it/s]  1%|          | 4/500 [00:00<00:39, 12.40it/s]  1%|          | 6/500 [00:00<00:35, 13.89it/s]  2%|▏         | 8/500 [00:00<00:33, 14.69it/s]  2%|▏         | 10/500 [00:00<00:32, 15.04it/s]  2%|▏         | 12/500 [00:00<00:31, 15.43it/s]  3%|▎         | 14/500 [00:00<00:30, 15.68it/s]  3%|▎         | 16/500 [00:01<00:30, 15.97it/s]  4%|▎         | 18/500 [00:01<00:30, 16.06it/s]  4%|▍         | 20/500 [00:01<00:29, 16.16it/s]  4%|▍         | 22/500 [00:01<00:30, 15.71it/s]  5%|▍         | 24/500 [00:01<00:31, 15.25it/s]  5%|▌         | 26/500 [00:01<00:30, 15.34it/s]  6%|▌         | 28/500 [00:01<00:30, 15.53it/s]  6%|▌         | 30/500 [00:01<00:29, 15.78it/s]  6%|▋         | 32/500 [00:02<00:29, 15.99it/s]  7%|▋         | 34/500 [00:02<00:29, 16.04it/s]  7%|▋         | 36/500 [00:02<00:28, 16.11it/s]  8%|▊         | 38/500 [00:02<00:28, 16.00it/s]  8%|▊         | 40/500 [00:02<00:28, 15.97it/s]  8%|▊         | 42/500 [00:02<00:28, 15.99it/s]  9%|▉         | 44/500 [00:02<00:28, 16.00it/s]  9%|▉         | 46/500 [00:02<00:28, 15.99it/s] 10%|▉         | 48/500 [00:03<00:28, 16.02it/s] 10%|█         | 50/500 [00:03<00:28, 15.53it/s] 10%|█         | 52/500 [00:03<00:28, 15.61it/s] 11%|█         | 54/500 [00:03<00:28, 15.72it/s] 11%|█         | 56/500 [00:03<00:28, 15.61it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.70it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.65it/s] 12%|█▏        | 62/500 [00:03<00:28, 15.27it/s] 13%|█▎        | 64/500 [00:04<00:28, 15.05it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.47it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.66it/s] 14%|█▍        | 70/500 [00:04<00:28, 14.84it/s] 14%|█▍        | 72/500 [00:04<00:30, 13.99it/s] 15%|█▍        | 74/500 [00:04<00:31, 13.40it/s] 15%|█▌        | 76/500 [00:04<00:31, 13.66it/s] 16%|█▌        | 78/500 [00:05<00:29, 14.16it/s] 16%|█▌        | 80/500 [00:05<00:29, 14.09it/s] 16%|█▋        | 82/500 [00:05<00:28, 14.75it/s] 17%|█▋        | 84/500 [00:05<00:27, 15.12it/s] 17%|█▋        | 86/500 [00:05<00:27, 15.06it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.36it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.57it/s] 18%|█▊        | 92/500 [00:06<00:25, 15.82it/s] 19%|█▉        | 94/500 [00:06<00:25, 15.69it/s] 19%|█▉        | 96/500 [00:06<00:28, 14.41it/s] 20%|█▉        | 98/500 [00:06<00:27, 14.72it/s] 20%|██        | 100/500 [00:06<00:28, 14.04it/s] 20%|██        | 102/500 [00:06<00:27, 14.61it/s] 21%|██        | 104/500 [00:06<00:26, 15.10it/s] 21%|██        | 106/500 [00:06<00:25, 15.53it/s] 22%|██▏       | 108/500 [00:07<00:25, 15.24it/s] 22%|██▏       | 110/500 [00:07<00:25, 15.53it/s] 22%|██▏       | 112/500 [00:07<00:25, 15.39it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.62it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.87it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.02it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.05it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.15it/s] 25%|██▍       | 124/500 [00:08<00:23, 15.76it/s]Epoch:  1  	Training Loss: 0.47964414954185486
Test Loss:  10330.79296875
Valid Loss:  10376.15625
Epoch:  2  	Training Loss: 10305.587890625
Test Loss:  1.5117616378850312e+20
Valid Loss:  1.480828241631972e+20
Epoch:  3  	Training Loss: 1.501513485826717e+20
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:24, 15.36it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.48it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.69it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.68it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.81it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.90it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.93it/s] 28%|██▊       | 140/500 [00:09<00:23, 15.01it/s] 28%|██▊       | 142/500 [00:09<00:25, 14.15it/s] 29%|██▉       | 144/500 [00:09<00:24, 14.65it/s] 29%|██▉       | 146/500 [00:09<00:23, 14.78it/s] 30%|██▉       | 148/500 [00:09<00:23, 15.00it/s] 30%|███       | 150/500 [00:09<00:23, 15.11it/s] 30%|███       | 152/500 [00:09<00:22, 15.46it/s] 31%|███       | 154/500 [00:10<00:22, 15.47it/s] 31%|███       | 156/500 [00:10<00:21, 15.70it/s] 32%|███▏      | 158/500 [00:10<00:21, 15.74it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.47it/s] 32%|███▏      | 162/500 [00:10<00:23, 14.23it/s] 33%|███▎      | 164/500 [00:10<00:25, 13.24it/s] 33%|███▎      | 166/500 [00:10<00:24, 13.69it/s] 34%|███▎      | 168/500 [00:11<00:23, 14.37it/s] 34%|███▍      | 170/500 [00:11<00:22, 14.91it/s] 34%|███▍      | 172/500 [00:11<00:21, 15.30it/s] 35%|███▍      | 174/500 [00:11<00:21, 15.31it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.52it/s] 36%|███▌      | 178/500 [00:11<00:22, 14.52it/s] 36%|███▌      | 180/500 [00:11<00:21, 15.02it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.21it/s] 37%|███▋      | 184/500 [00:12<00:20, 15.49it/s] 37%|███▋      | 186/500 [00:12<00:20, 15.57it/s] 38%|███▊      | 188/500 [00:12<00:19, 15.76it/s] 38%|███▊      | 190/500 [00:12<00:19, 15.84it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.00it/s] 39%|███▉      | 194/500 [00:12<00:19, 16.01it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.94it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.45it/s] 40%|████      | 200/500 [00:13<00:19, 15.14it/s] 40%|████      | 202/500 [00:13<00:19, 15.45it/s] 41%|████      | 204/500 [00:13<00:18, 15.68it/s] 41%|████      | 206/500 [00:13<00:19, 14.94it/s] 42%|████▏     | 208/500 [00:13<00:20, 14.02it/s] 42%|████▏     | 210/500 [00:13<00:21, 13.52it/s] 42%|████▏     | 212/500 [00:13<00:20, 14.10it/s] 43%|████▎     | 214/500 [00:14<00:19, 14.69it/s] 43%|████▎     | 216/500 [00:14<00:18, 15.17it/s] 44%|████▎     | 218/500 [00:14<00:18, 15.52it/s] 44%|████▍     | 220/500 [00:14<00:17, 15.69it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.45it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.47it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.71it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.90it/s] 46%|████▌     | 230/500 [00:15<00:16, 15.93it/s] 46%|████▋     | 232/500 [00:15<00:16, 15.83it/s] 47%|████▋     | 234/500 [00:15<00:16, 15.88it/s] 47%|████▋     | 236/500 [00:15<00:18, 14.63it/s] 48%|████▊     | 238/500 [00:15<00:18, 14.03it/s] 48%|████▊     | 240/500 [00:15<00:17, 14.68it/s] 48%|████▊     | 242/500 [00:15<00:17, 14.89it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.31it/s] 49%|████▉     | 246/500 [00:16<00:16, 15.60it/s] 50%|████▉     | 248/500 [00:16<00:16, 15.68it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 15.78it/s] 50%|█████     | 252/500 [00:16<00:15, 15.66it/s] 51%|█████     | 254/500 [00:16<00:15, 15.69it/s] 51%|█████     | 256/500 [00:16<00:15, 15.75it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.92it/s] 52%|█████▏    | 260/500 [00:17<00:15, 16.00it/s] 52%|█████▏    | 262/500 [00:17<00:14, 16.11it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.15it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.12it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.04it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.08it/s] 54%|█████▍    | 272/500 [00:17<00:15, 15.02it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.21it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.19it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.50it/s] 56%|█████▌    | 280/500 [00:18<00:14, 15.53it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.71it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.79it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.77it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.55it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.78it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.75it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.64it/s] 59%|█████▉    | 296/500 [00:19<00:13, 15.61it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.79it/s] 60%|██████    | 300/500 [00:19<00:12, 15.63it/s] 60%|██████    | 302/500 [00:19<00:12, 15.79it/s] 61%|██████    | 304/500 [00:19<00:12, 15.94it/s] 61%|██████    | 306/500 [00:19<00:12, 15.97it/s] 62%|██████▏   | 308/500 [00:20<00:11, 16.07it/s] 62%|██████▏   | 310/500 [00:20<00:11, 15.96it/s] 62%|██████▏   | 312/500 [00:20<00:11, 15.79it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.95it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.98it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.88it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.74it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.91it/s] 65%|██████▍   | 324/500 [00:21<00:10, 16.03it/s] 65%|██████▌   | 326/500 [00:21<00:10, 15.93it/s] 66%|██████▌   | 328/500 [00:21<00:10, 16.01it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.10it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.10it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.13it/s] 67%|██████▋   | 336/500 [00:21<00:11, 14.11it/s] 68%|██████▊   | 338/500 [00:22<00:12, 13.40it/s] 68%|██████▊   | 340/500 [00:22<00:12, 12.84it/s] 68%|██████▊   | 342/500 [00:22<00:12, 12.63it/s] 69%|██████▉   | 344/500 [00:22<00:12, 12.54it/s] 69%|██████▉   | 346/500 [00:22<00:12, 12.64it/s] 70%|██████▉   | 348/500 [00:22<00:11, 13.46it/s] 70%|███████   | 350/500 [00:22<00:10, 14.19it/s] 70%|███████   | 352/500 [00:23<00:10, 13.72it/s] 71%|███████   | 354/500 [00:23<00:10, 13.95it/s] 71%|███████   | 356/500 [00:23<00:09, 14.47it/s] 72%|███████▏  | 358/500 [00:23<00:09, 14.68it/s] 72%|███████▏  | 360/500 [00:23<00:09, 15.01it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.39it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.19it/s] 73%|███████▎  | 366/500 [00:24<00:08, 15.55it/s] 74%|███████▎  | 368/500 [00:24<00:08, 15.75it/s] 74%|███████▍  | 370/500 [00:24<00:08, 15.87it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.64it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:08, 14.71it/s] 75%|███████▌  | 376/500 [00:24<00:08, 14.96it/s] 76%|███████▌  | 378/500 [00:24<00:08, 15.07it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.41it/s] 76%|███████▋  | 382/500 [00:25<00:07, 15.43it/s] 77%|███████▋  | 384/500 [00:25<00:07, 15.25it/s] 77%|███████▋  | 386/500 [00:25<00:07, 15.39it/s] 78%|███████▊  | 388/500 [00:25<00:07, 15.11it/s] 78%|███████▊  | 390/500 [00:25<00:07, 14.10it/s] 78%|███████▊  | 392/500 [00:25<00:07, 14.67it/s] 79%|███████▉  | 394/500 [00:25<00:07, 15.03it/s] 79%|███████▉  | 396/500 [00:26<00:06, 15.45it/s] 80%|███████▉  | 398/500 [00:26<00:06, 15.55it/s] 80%|████████  | 400/500 [00:26<00:06, 15.64it/s] 80%|████████  | 402/500 [00:26<00:06, 15.79it/s] 81%|████████  | 404/500 [00:26<00:06, 15.76it/s] 81%|████████  | 406/500 [00:26<00:05, 15.93it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.03it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.07it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.11it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.74it/s] 83%|████████▎ | 416/500 [00:27<00:05, 14.45it/s] 84%|████████▎ | 418/500 [00:27<00:05, 13.91it/s] 84%|████████▍ | 420/500 [00:27<00:05, 13.48it/s] 84%|████████▍ | 422/500 [00:27<00:05, 14.13it/s] 85%|████████▍ | 424/500 [00:27<00:05, 14.69it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.12it/s] 86%|████████▌ | 428/500 [00:28<00:04, 15.44it/s] 86%|████████▌ | 430/500 [00:28<00:04, 15.44it/s] 86%|████████▋ | 432/500 [00:28<00:04, 15.68it/s] 87%|████████▋ | 434/500 [00:28<00:04, 15.83it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.97it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.06it/s] 88%|████████▊ | 440/500 [00:28<00:04, 14.84it/s] 88%|████████▊ | 442/500 [00:29<00:03, 14.82it/s] 89%|████████▉ | 444/500 [00:29<00:03, 14.87it/s] 89%|████████▉ | 446/500 [00:29<00:03, 15.14it/s] 90%|████████▉ | 448/500 [00:29<00:03, 15.38it/s] 90%|█████████ | 450/500 [00:29<00:03, 15.69it/s] 90%|█████████ | 452/500 [00:29<00:03, 15.83it/s] 91%|█████████ | 454/500 [00:29<00:02, 15.99it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.02it/s] 92%|█████████▏| 458/500 [00:30<00:02, 16.10it/s] 92%|█████████▏| 460/500 [00:30<00:02, 16.07it/s] 92%|█████████▏| 462/500 [00:30<00:02, 16.04it/s] 93%|█████████▎| 464/500 [00:30<00:02, 15.83it/s] 93%|█████████▎| 466/500 [00:30<00:02, 15.94it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.85it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.75it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.70it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.71it/s] 95%|█████████▌| 476/500 [00:31<00:01, 15.82it/s] 96%|█████████▌| 478/500 [00:31<00:01, 15.96it/s] 96%|█████████▌| 480/500 [00:31<00:01, 15.06it/s] 96%|█████████▋| 482/500 [00:31<00:01, 15.27it/s] 97%|█████████▋| 484/500 [00:31<00:01, 15.48it/s] 97%|█████████▋| 486/500 [00:31<00:00, 15.70it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.83it/s] 98%|█████████▊| 490/500 [00:32<00:00, 15.77it/s] 98%|█████████▊| 492/500 [00:32<00:00, 15.69it/s] 99%|█████████▉| 494/500 [00:32<00:00, 15.34it/s] 99%|█████████▉| 496/500 [00:32<00:00, 15.43it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 15.23it/s]100%|██████████| 500/500 [00:32<00:00, 14.10it/s]100%|██████████| 500/500 [00:32<00:00, 15.26it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  18
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:45,  6.22s/it]  1%|          | 3/500 [00:06<13:49,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:55,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:15,  1.19s/it]  7%|▋         | 33/500 [00:26<06:36,  1.18it/s]  7%|▋         | 35/500 [00:27<04:46,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<09:07,  1.19s/it]  9%|▊         | 43/500 [00:33<06:31,  1.17it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:25,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:40<08:47,  1.17s/it] 11%|█         | 53/500 [00:40<06:17,  1.19it/s] 11%|█         | 55/500 [00:40<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:27,  3.00it/s] 12%|█▏        | 61/500 [00:47<08:40,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.22it/s] 14%|█▍        | 69/500 [00:48<02:24,  2.98it/s] 14%|█▍        | 71/500 [00:54<08:26,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:04,  1.17it/s]Epoch:  1  	Training Loss: 0.47964417934417725
Test Loss:  61.15338897705078
Valid Loss:  58.900794982910156
Epoch:  2  	Training Loss: 60.271968841552734
Test Loss:  0.5671594142913818
Valid Loss:  0.5432500839233398
Epoch:  3  	Training Loss: 0.46810585260391235
Test Loss:  0.5670454502105713
Valid Loss:  0.5431414842605591
Epoch:  4  	Training Loss: 0.4680052101612091
Test Loss:  0.5669317841529846
Valid Loss:  0.5430331826210022
Epoch:  5  	Training Loss: 0.46790480613708496
Test Loss:  0.5668182969093323
Valid Loss:  0.5429250001907349
Epoch:  6  	Training Loss: 0.46780461072921753
Test Loss:  0.5667049884796143
Valid Loss:  0.5428170561790466
Epoch:  7  	Training Loss: 0.46770453453063965
Test Loss:  0.5665919780731201
Valid Loss:  0.5427093505859375
Epoch:  8  	Training Loss: 0.4676046371459961
Test Loss:  0.5664790868759155
Valid Loss:  0.5426018238067627
Epoch:  9  	Training Loss: 0.46750497817993164
Test Loss:  0.56636643409729
Valid Loss:  0.5424944758415222
Epoch:  10  	Training Loss: 0.4674055278301239
Test Loss:  0.5662540197372437
Valid Loss:  0.5423873662948608
Epoch:  11  	Training Loss: 0.4673062562942505
Test Loss:  0.5661417841911316
Valid Loss:  0.542280375957489
Epoch:  12  	Training Loss: 0.467207133769989
Test Loss:  0.5660300850868225
Valid Loss:  0.5421741008758545
Epoch:  13  	Training Loss: 0.46710851788520813
Test Loss:  0.5659183263778687
Valid Loss:  0.5420676469802856
Epoch:  14  	Training Loss: 0.46700990200042725
Test Loss:  0.5658065676689148
Valid Loss:  0.5419613122940063
Epoch:  15  	Training Loss: 0.4669111967086792
Test Loss:  0.5656946897506714
Valid Loss:  0.541854739189148
Epoch:  16  	Training Loss: 0.4668124318122864
Test Loss:  0.5655827522277832
Valid Loss:  0.5417481660842896
Epoch:  17  	Training Loss: 0.4667136073112488
Test Loss:  0.5654707551002502
Valid Loss:  0.5416415929794312
Epoch:  18  	Training Loss: 0.4666147232055664
Test Loss:  0.5653587579727173
Valid Loss:  0.5415347814559937
Epoch:  19  	Training Loss: 0.46651577949523926
Test Loss:  0.5652465224266052
Valid Loss:  0.5414280891418457
Epoch:  20  	Training Loss: 0.46641677618026733
Test Loss:  0.5651343464851379
Valid Loss:  0.5413212776184082
Epoch:  21  	Training Loss: 0.466317743062973
Test Loss:  0.5650221109390259
Valid Loss:  0.5412143468856812
Epoch:  22  	Training Loss: 0.46621859073638916
Test Loss:  0.5649122595787048
Valid Loss:  0.5411097407341003
Epoch:  23  	Training Loss: 0.4661215543746948
Test Loss:  0.5648031234741211
Valid Loss:  0.5410056710243225
Epoch:  24  	Training Loss: 0.46602511405944824
Test Loss:  0.5646947622299194
Valid Loss:  0.5409023761749268
Epoch:  25  	Training Loss: 0.4659292995929718
Test Loss:  0.5645871162414551
Valid Loss:  0.5407997965812683
Epoch:  26  	Training Loss: 0.4658341407775879
Test Loss:  0.5644801259040833
Valid Loss:  0.5406978130340576
Epoch:  27  	Training Loss: 0.46573957800865173
Test Loss:  0.5643738508224487
Valid Loss:  0.5405964851379395
Epoch:  28  	Training Loss: 0.46564561128616333
Test Loss:  0.5642682313919067
Valid Loss:  0.5404958724975586
Epoch:  29  	Training Loss: 0.46555233001708984
Test Loss:  0.564163327217102
Valid Loss:  0.5403959155082703
Epoch:  30  	Training Loss: 0.46545958518981934
Test Loss:  0.5640591382980347
Valid Loss:  0.5402965545654297
Epoch:  31  	Training Loss: 0.46536749601364136
Test Loss:  0.5639556646347046
Valid Loss:  0.5401979088783264
Epoch:  32  	Training Loss: 0.46527600288391113
Test Loss:  0.5638459324836731
Valid Loss:  0.5400934815406799
Epoch:  33  	Training Loss: 0.4651791453361511
Test Loss:  0.5637361407279968
Valid Loss:  0.5399889945983887
Epoch:  34  	Training Loss: 0.46508222818374634
Test Loss:  0.5636261701583862
Valid Loss:  0.5398842692375183
Epoch:  35  	Training Loss: 0.46498510241508484
Test Loss:  0.5635160207748413
Valid Loss:  0.5397794246673584
Epoch:  36  	Training Loss: 0.4648878276348114
Test Loss:  0.5634056925773621
Valid Loss:  0.5396744012832642
Epoch:  37  	Training Loss: 0.4647904634475708
Test Loss:  0.5632951855659485
Valid Loss:  0.5395691990852356
Epoch:  38  	Training Loss: 0.46469295024871826
Test Loss:  0.5631846189498901
Valid Loss:  0.5394639372825623
Epoch:  39  	Training Loss: 0.4645952582359314
Test Loss:  0.5630738735198975
Valid Loss:  0.5393584966659546
Epoch:  40  	Training Loss: 0.46449750661849976
Test Loss:  0.5629629492759705
Valid Loss:  0.5392528772354126
Epoch:  41  	Training Loss: 0.4643995761871338
Test Loss:  0.5628517866134644
Valid Loss:  0.539147138595581
Epoch:  42  	Training Loss: 0.4643014669418335
Test Loss:  0.5627440214157104
Valid Loss:  0.5390444397926331
Epoch:  43  	Training Loss: 0.4642063081264496
Test Loss:  0.562636137008667
Valid Loss:  0.5389418005943298
Epoch:  44  	Training Loss: 0.4641111195087433
Test Loss:  0.5625283718109131
Valid Loss:  0.5388392210006714
Epoch:  45  	Training Loss: 0.4640159606933594
Test Loss:  0.5624206066131592
Valid Loss:  0.5387365818023682
Epoch:  46  	Training Loss: 0.46392083168029785
Test Loss:  0.5623127818107605
Valid Loss:  0.5386339426040649
Epoch:  47  	Training Loss: 0.46382564306259155
Test Loss:  0.5622050166130066
Valid Loss:  0.5385313034057617
Epoch:  48  	Training Loss: 0.46373051404953003
Test Loss:  0.5620973110198975
Valid Loss:  0.5384286642074585
Epoch:  49  	Training Loss: 0.4636353850364685
Test Loss:  0.5619894862174988
Valid Loss:  0.5383261442184448
Epoch:  50  	Training Loss: 0.463540256023407
Test Loss:  0.5618817806243896
Valid Loss:  0.5382235050201416
Epoch:  51  	Training Loss: 0.46344518661499023
Test Loss:  0.5617740154266357
Valid Loss:  0.5381208658218384
Epoch:  52  	Training Loss: 0.46334999799728394
Test Loss:  0.5616680979728699
Valid Loss:  0.5380204319953918
Epoch:  53  	Training Loss: 0.4632565379142761
Test Loss:  0.561562180519104
Valid Loss:  0.5379198789596558
Epoch:  54  	Training Loss: 0.46316298842430115
Test Loss:  0.5614560842514038
Valid Loss:  0.5378191471099854
Epoch:  55  	Training Loss: 0.4630693793296814
Test Loss:  0.5613499879837036
Valid Loss:  0.5377183556556702
Epoch:  56  	Training Loss: 0.4629756808280945
Test Loss:  0.5612437725067139
Valid Loss:  0.5376175045967102
Epoch:  57  	Training Loss: 0.462881863117218
Test Loss:  0.5611374378204346
Valid Loss:  0.5375165343284607
Epoch:  58  	Training Loss: 0.4627879858016968
Test Loss:  0.5610310435295105
Valid Loss:  0.5374155044555664
Epoch:  59  	Training Loss: 0.46269404888153076
Test Loss:  0.5609245300292969
Valid Loss:  0.5373143553733826
Epoch:  60  	Training Loss: 0.4625999927520752
Test Loss:  0.5608180165290833
Valid Loss:  0.5372132062911987
Epoch:  61  	Training Loss: 0.46250593662261963
Test Loss:  0.5607113838195801
Valid Loss:  0.5371118783950806
Epoch:  62  	Training Loss: 0.4624117612838745
Test Loss:  0.5606001019477844
Valid Loss:  0.5370060205459595
Epoch:  63  	Training Loss: 0.46231359243392944
Test Loss:  0.5604888200759888
Valid Loss:  0.5368999242782593
Epoch:  64  	Training Loss: 0.4622153639793396
Test Loss:  0.5603773593902588
Valid Loss:  0.5367938876152039
Epoch:  65  	Training Loss: 0.4621170163154602
Test Loss:  0.5602659583091736
Valid Loss:  0.5366877913475037
Epoch:  66  	Training Loss: 0.4620187282562256
Test Loss:  0.5601544380187988
Valid Loss:  0.5365816354751587
Epoch:  67  	Training Loss: 0.4619203805923462
Test Loss:  0.5600429177284241
Valid Loss:  0.5364753603935242
Epoch:  68  	Training Loss: 0.46182185411453247
Test Loss:  0.559931218624115
Valid Loss:  0.5363690853118896
Epoch:  69  	Training Loss: 0.46172335743904114
Test Loss:  0.5598195791244507
Valid Loss:  0.5362627506256104
Epoch:  70  	Training Loss: 0.46162480115890503
Test Loss:  0.5597077012062073
Valid Loss:  0.5361562967300415
Epoch:  71  	Training Loss: 0.46152615547180176
Test Loss:  0.5595959424972534
Valid Loss:  0.5360498428344727
Epoch:  72  	Training Loss: 0.4614275097846985
Test Loss:  0.5594839453697205
Valid Loss:  0.5359431505203247
Epoch:  73  	Training Loss: 0.4613287150859833
Test Loss:  0.5593719482421875
Valid Loss:  0.5358364582061768
Epoch:  74  	Training Loss: 0.46122992038726807
Test Loss:  0.559259831905365
Valid Loss:  0.5357296466827393
 15%|█▌        | 75/500 [00:54<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:54<03:12,  2.19it/s] 16%|█▌        | 79/500 [00:54<02:23,  2.93it/s] 16%|█▌        | 81/500 [01:01<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:01<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:01<04:18,  1.61it/s] 17%|█▋        | 87/500 [01:01<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:01<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:08<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.61it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.20it/s] 20%|█▉        | 99/500 [01:08<02:15,  2.97it/s] 20%|██        | 101/500 [01:15<07:52,  1.18s/it] 21%|██        | 103/500 [01:15<05:39,  1.17it/s] 21%|██        | 105/500 [01:15<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:15<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:15<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:22<07:46,  1.20s/it] 23%|██▎       | 113/500 [01:22<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:22<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:22<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:22<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:28<07:26,  1.18s/it] 25%|██▍       | 123/500 [01:29<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:29<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:35<07:17,  1.19s/it] 27%|██▋       | 133/500 [01:35<05:12,  1.17it/s] 27%|██▋       | 135/500 [01:36<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:36<02:43,  2.21it/s] 28%|██▊       | 139/500 [01:36<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:42<07:03,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:43<02:40,  2.20it/s]Epoch:  75  	Training Loss: 0.4611310362815857
Test Loss:  0.5591477155685425
Valid Loss:  0.5356228351593018
Epoch:  76  	Training Loss: 0.46103209257125854
Test Loss:  0.5590354800224304
Valid Loss:  0.5355159640312195
Epoch:  77  	Training Loss: 0.4609330892562866
Test Loss:  0.5589232444763184
Valid Loss:  0.5354089736938477
Epoch:  78  	Training Loss: 0.4608340859413147
Test Loss:  0.5588108897209167
Valid Loss:  0.535301923751831
Epoch:  79  	Training Loss: 0.4607349634170532
Test Loss:  0.5586984753608704
Valid Loss:  0.5351948738098145
Epoch:  80  	Training Loss: 0.46063584089279175
Test Loss:  0.558586061000824
Valid Loss:  0.5350878238677979
Epoch:  81  	Training Loss: 0.4605366587638855
Test Loss:  0.5584734678268433
Valid Loss:  0.5349805951118469
Epoch:  82  	Training Loss: 0.4604373574256897
Test Loss:  0.5583600997924805
Valid Loss:  0.5348726511001587
Epoch:  83  	Training Loss: 0.4603373408317566
Test Loss:  0.5582467317581177
Valid Loss:  0.5347645878791809
Epoch:  84  	Training Loss: 0.4602372646331787
Test Loss:  0.5581332445144653
Valid Loss:  0.5346565246582031
Epoch:  85  	Training Loss: 0.46013718843460083
Test Loss:  0.5580196380615234
Valid Loss:  0.5345484018325806
Epoch:  86  	Training Loss: 0.4600369930267334
Test Loss:  0.5579060316085815
Valid Loss:  0.5344401597976685
Epoch:  87  	Training Loss: 0.4599367380142212
Test Loss:  0.5577922463417053
Valid Loss:  0.5343317985534668
Epoch:  88  	Training Loss: 0.45983636379241943
Test Loss:  0.5576784014701843
Valid Loss:  0.5342233777046204
Epoch:  89  	Training Loss: 0.4597359597682953
Test Loss:  0.5575644969940186
Valid Loss:  0.5341149568557739
Epoch:  90  	Training Loss: 0.45963549613952637
Test Loss:  0.557450532913208
Valid Loss:  0.5340063571929932
Epoch:  91  	Training Loss: 0.4595348834991455
Test Loss:  0.5573363900184631
Valid Loss:  0.5338976979255676
Epoch:  92  	Training Loss: 0.45943427085876465
Test Loss:  0.5572246313095093
Valid Loss:  0.5337913036346436
Epoch:  93  	Training Loss: 0.4593355357646942
Test Loss:  0.5571129322052002
Valid Loss:  0.5336848497390747
Epoch:  94  	Training Loss: 0.4592369496822357
Test Loss:  0.557001531124115
Valid Loss:  0.5335787534713745
Epoch:  95  	Training Loss: 0.45913851261138916
Test Loss:  0.5568901896476746
Valid Loss:  0.5334725975990295
Epoch:  96  	Training Loss: 0.45904019474983215
Test Loss:  0.556779146194458
Valid Loss:  0.5333666801452637
Epoch:  97  	Training Loss: 0.45894208550453186
Test Loss:  0.5566681623458862
Valid Loss:  0.5332610011100769
Epoch:  98  	Training Loss: 0.45884403586387634
Test Loss:  0.5565573573112488
Valid Loss:  0.5331553816795349
Epoch:  99  	Training Loss: 0.45874619483947754
Test Loss:  0.5564466118812561
Valid Loss:  0.5330499410629272
Epoch:  100  	Training Loss: 0.4586484432220459
Test Loss:  0.5563361048698425
Valid Loss:  0.5329445600509644
Epoch:  101  	Training Loss: 0.4585508406162262
Test Loss:  0.5562257766723633
Valid Loss:  0.5328395366668701
Epoch:  102  	Training Loss: 0.4584534168243408
Test Loss:  0.5561197996139526
Valid Loss:  0.5327385663986206
Epoch:  103  	Training Loss: 0.45835989713668823
Test Loss:  0.5560138821601868
Valid Loss:  0.5326378345489502
Epoch:  104  	Training Loss: 0.4582664966583252
Test Loss:  0.5559080839157104
Valid Loss:  0.532537043094635
Epoch:  105  	Training Loss: 0.45817312598228455
Test Loss:  0.5558023452758789
Valid Loss:  0.5324363708496094
Epoch:  106  	Training Loss: 0.45807981491088867
Test Loss:  0.5556966662406921
Valid Loss:  0.5323357582092285
Epoch:  107  	Training Loss: 0.45798659324645996
Test Loss:  0.5555910468101501
Valid Loss:  0.5322352647781372
Epoch:  108  	Training Loss: 0.457893431186676
Test Loss:  0.5554855465888977
Valid Loss:  0.5321347713470459
Epoch:  109  	Training Loss: 0.4578002691268921
Test Loss:  0.5553799867630005
Valid Loss:  0.5320343971252441
Epoch:  110  	Training Loss: 0.4577072262763977
Test Loss:  0.5552746057510376
Valid Loss:  0.5319340229034424
Epoch:  111  	Training Loss: 0.4576142728328705
Test Loss:  0.5551692247390747
Valid Loss:  0.5318337678909302
Epoch:  112  	Training Loss: 0.45752137899398804
Test Loss:  0.555061936378479
Valid Loss:  0.5317314863204956
Epoch:  113  	Training Loss: 0.45742666721343994
Test Loss:  0.5549546480178833
Valid Loss:  0.5316293835639954
Epoch:  114  	Training Loss: 0.4573320746421814
Test Loss:  0.5548474192619324
Valid Loss:  0.5315272808074951
Epoch:  115  	Training Loss: 0.4572374224662781
Test Loss:  0.5547401905059814
Valid Loss:  0.5314251780509949
Epoch:  116  	Training Loss: 0.4571429193019867
Test Loss:  0.5546330213546753
Valid Loss:  0.5313231348991394
Epoch:  117  	Training Loss: 0.4570484161376953
Test Loss:  0.5545259714126587
Valid Loss:  0.5312210917472839
Epoch:  118  	Training Loss: 0.45695388317108154
Test Loss:  0.5544188618659973
Valid Loss:  0.5311192274093628
Epoch:  119  	Training Loss: 0.4568594992160797
Test Loss:  0.5543117523193359
Valid Loss:  0.5310172438621521
Epoch:  120  	Training Loss: 0.4567650556564331
Test Loss:  0.5542047619819641
Valid Loss:  0.530915379524231
Epoch:  121  	Training Loss: 0.4566706418991089
Test Loss:  0.5540977716445923
Valid Loss:  0.530813455581665
Epoch:  122  	Training Loss: 0.45657631754875183
Test Loss:  0.5539833903312683
Valid Loss:  0.5307045578956604
Epoch:  123  	Training Loss: 0.45647549629211426
Test Loss:  0.5538690090179443
Valid Loss:  0.5305956602096558
Epoch:  124  	Training Loss: 0.45637452602386475
Test Loss:  0.553754448890686
Valid Loss:  0.5304865837097168
Epoch:  125  	Training Loss: 0.45627355575561523
Test Loss:  0.553639829158783
Valid Loss:  0.5303774476051331
Epoch:  126  	Training Loss: 0.4561724066734314
Test Loss:  0.5535251498222351
Valid Loss:  0.5302680730819702
Epoch:  127  	Training Loss: 0.45607122778892517
Test Loss:  0.5534102320671082
Valid Loss:  0.5301587581634521
Epoch:  128  	Training Loss: 0.4559699296951294
Test Loss:  0.5532952547073364
Valid Loss:  0.5300492644309998
Epoch:  129  	Training Loss: 0.45586851239204407
Test Loss:  0.5531802177429199
Valid Loss:  0.5299397110939026
Epoch:  130  	Training Loss: 0.45576703548431396
Test Loss:  0.5530651211738586
Valid Loss:  0.5298300981521606
Epoch:  131  	Training Loss: 0.4556655287742615
Test Loss:  0.5529499053955078
Valid Loss:  0.5297203063964844
Epoch:  132  	Training Loss: 0.45556390285491943
Test Loss:  0.552837073802948
Valid Loss:  0.5296128392219543
Epoch:  133  	Training Loss: 0.45546436309814453
Test Loss:  0.5527242422103882
Valid Loss:  0.5295053720474243
Epoch:  134  	Training Loss: 0.455364853143692
Test Loss:  0.552611231803894
Valid Loss:  0.5293978452682495
Epoch:  135  	Training Loss: 0.45526522397994995
Test Loss:  0.5524983406066895
Valid Loss:  0.5292903184890747
Epoch:  136  	Training Loss: 0.4551656246185303
Test Loss:  0.5523854494094849
Valid Loss:  0.5291826725006104
Epoch:  137  	Training Loss: 0.4550659656524658
Test Loss:  0.552272379398346
Valid Loss:  0.5290751457214355
Epoch:  138  	Training Loss: 0.454966276884079
Test Loss:  0.552159309387207
Valid Loss:  0.5289674401283264
Epoch:  139  	Training Loss: 0.45486658811569214
Test Loss:  0.5520462393760681
Valid Loss:  0.5288597345352173
Epoch:  140  	Training Loss: 0.45476680994033813
Test Loss:  0.5519330501556396
Valid Loss:  0.5287519693374634
Epoch:  141  	Training Loss: 0.45466703176498413
Test Loss:  0.551819920539856
Valid Loss:  0.5286442041397095
Epoch:  142  	Training Loss: 0.45456719398498535
Test Loss:  0.5517149567604065
Valid Loss:  0.5285443067550659
Epoch:  143  	Training Loss: 0.45447468757629395
Test Loss:  0.5516101121902466
Valid Loss:  0.5284445285797119
Epoch:  144  	Training Loss: 0.4543822407722473
Test Loss:  0.5515053272247314
Valid Loss:  0.5283446907997131
Epoch:  145  	Training Loss: 0.45428988337516785
Test Loss:  0.5514006614685059
Valid Loss:  0.5282450914382935
Epoch:  146  	Training Loss: 0.45419758558273315
Test Loss:  0.5512959957122803
Valid Loss:  0.5281454920768738
Epoch:  147  	Training Loss: 0.45410531759262085
Test Loss:  0.551191508769989
Valid Loss:  0.5280458927154541
Epoch:  148  	Training Loss: 0.4540131986141205
Test Loss:  0.551086962223053
Valid Loss:   30%|██▉       | 149/500 [01:43<02:00,  2.90it/s] 30%|███       | 151/500 [01:49<06:57,  1.20s/it] 31%|███       | 153/500 [01:49<04:58,  1.16it/s] 31%|███       | 155/500 [01:49<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:50<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:50<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:56<06:43,  1.19s/it] 33%|███▎      | 163/500 [01:56<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:56<03:27,  1.62it/s] 33%|███▎      | 167/500 [01:56<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:57<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:03<06:36,  1.20s/it] 35%|███▍      | 173/500 [02:03<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:03<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:03<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:04<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:10<06:33,  1.23s/it] 37%|███▋      | 183/500 [02:10<04:41,  1.13it/s] 37%|███▋      | 185/500 [02:11<03:22,  1.56it/s] 37%|███▋      | 187/500 [02:11<02:26,  2.13it/s] 38%|███▊      | 189/500 [02:11<01:48,  2.86it/s] 38%|███▊      | 191/500 [02:17<06:11,  1.20s/it] 39%|███▊      | 193/500 [02:17<04:24,  1.16it/s] 39%|███▉      | 195/500 [02:17<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:18<02:18,  2.19it/s] 40%|███▉      | 199/500 [02:18<01:42,  2.95it/s] 40%|████      | 201/500 [02:24<06:02,  1.21s/it] 41%|████      | 203/500 [02:24<04:18,  1.15it/s] 41%|████      | 205/500 [02:25<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:25<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:25<01:39,  2.92it/s] 42%|████▏     | 211/500 [02:31<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:31<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:31<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:31<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:32<01:34,  2.96it/s] 44%|████▍     | 221/500 [02:38<05:40,  1.22s/it]0.5279463529586792
Epoch:  149  	Training Loss: 0.45392096042633057
Test Loss:  0.5509825348854065
Valid Loss:  0.5278469324111938
Epoch:  150  	Training Loss: 0.45382893085479736
Test Loss:  0.5508781671524048
Valid Loss:  0.5277475714683533
Epoch:  151  	Training Loss: 0.45373696088790894
Test Loss:  0.5507739782333374
Valid Loss:  0.527648389339447
Epoch:  152  	Training Loss: 0.4536449909210205
Test Loss:  0.5506660342216492
Valid Loss:  0.527545690536499
Epoch:  153  	Training Loss: 0.45354992151260376
Test Loss:  0.5505582094192505
Valid Loss:  0.527442991733551
Epoch:  154  	Training Loss: 0.4534548223018646
Test Loss:  0.550450325012207
Valid Loss:  0.527340292930603
Epoch:  155  	Training Loss: 0.45335978269577026
Test Loss:  0.5503426790237427
Valid Loss:  0.5272376537322998
Epoch:  156  	Training Loss: 0.4532647728919983
Test Loss:  0.5502349138259888
Valid Loss:  0.5271351337432861
Epoch:  157  	Training Loss: 0.4531698226928711
Test Loss:  0.5501271486282349
Valid Loss:  0.5270324945449829
Epoch:  158  	Training Loss: 0.4530748426914215
Test Loss:  0.5500194430351257
Valid Loss:  0.5269299745559692
Epoch:  159  	Training Loss: 0.4529799222946167
Test Loss:  0.5499118566513062
Valid Loss:  0.5268275141716003
Epoch:  160  	Training Loss: 0.4528850317001343
Test Loss:  0.5498042702674866
Valid Loss:  0.5267250537872314
Epoch:  161  	Training Loss: 0.4527900815010071
Test Loss:  0.549696683883667
Valid Loss:  0.5266225337982178
Epoch:  162  	Training Loss: 0.45269525051116943
Test Loss:  0.5495893955230713
Valid Loss:  0.5265203714370728
Epoch:  163  	Training Loss: 0.45260071754455566
Test Loss:  0.5494821667671204
Valid Loss:  0.5264182090759277
Epoch:  164  	Training Loss: 0.4525062143802643
Test Loss:  0.5493749380111694
Valid Loss:  0.5263161659240723
Epoch:  165  	Training Loss: 0.4524117708206177
Test Loss:  0.5492679476737976
Valid Loss:  0.5262141227722168
Epoch:  166  	Training Loss: 0.45231735706329346
Test Loss:  0.5491609573364258
Valid Loss:  0.5261120796203613
Epoch:  167  	Training Loss: 0.452223002910614
Test Loss:  0.549053966999054
Valid Loss:  0.526010274887085
Epoch:  168  	Training Loss: 0.45212870836257935
Test Loss:  0.5489469766616821
Valid Loss:  0.5259084105491638
Epoch:  169  	Training Loss: 0.4520344138145447
Test Loss:  0.5488401055335999
Valid Loss:  0.5258066654205322
Epoch:  170  	Training Loss: 0.45194029808044434
Test Loss:  0.5487333536148071
Valid Loss:  0.5257048606872559
Epoch:  171  	Training Loss: 0.4518461227416992
Test Loss:  0.5486266016960144
Valid Loss:  0.525603175163269
Epoch:  172  	Training Loss: 0.4517520070075989
Test Loss:  0.5485190153121948
Valid Loss:  0.5255007147789001
Epoch:  173  	Training Loss: 0.451657235622406
Test Loss:  0.5484113693237305
Valid Loss:  0.5253981947898865
Epoch:  174  	Training Loss: 0.45156237483024597
Test Loss:  0.5483039617538452
Valid Loss:  0.5252959728240967
Epoch:  175  	Training Loss: 0.4514676332473755
Test Loss:  0.5481964349746704
Valid Loss:  0.5251935124397278
Epoch:  176  	Training Loss: 0.45137280225753784
Test Loss:  0.5480889081954956
Valid Loss:  0.5250911712646484
Epoch:  177  	Training Loss: 0.45127809047698975
Test Loss:  0.5479813814163208
Valid Loss:  0.5249888896942139
Epoch:  178  	Training Loss: 0.45118334889411926
Test Loss:  0.5478739738464355
Valid Loss:  0.5248864889144897
Epoch:  179  	Training Loss: 0.4510886073112488
Test Loss:  0.5477665066719055
Valid Loss:  0.5247841477394104
Epoch:  180  	Training Loss: 0.45099392533302307
Test Loss:  0.5476590394973755
Valid Loss:  0.5246818661689758
Epoch:  181  	Training Loss: 0.45089924335479736
Test Loss:  0.5475516319274902
Valid Loss:  0.5245795249938965
Epoch:  182  	Training Loss: 0.45080459117889404
Test Loss:  0.5474417209625244
Valid Loss:  0.5244749784469604
Epoch:  183  	Training Loss: 0.4507077932357788
Test Loss:  0.5473320484161377
Valid Loss:  0.5243704915046692
Epoch:  184  	Training Loss: 0.4506109356880188
Test Loss:  0.5472222566604614
Valid Loss:  0.5242658853530884
Epoch:  185  	Training Loss: 0.45051413774490356
Test Loss:  0.5471124649047852
Valid Loss:  0.5241612195968628
Epoch:  186  	Training Loss: 0.4504173994064331
Test Loss:  0.5470026135444641
Valid Loss:  0.5240566730499268
Epoch:  187  	Training Loss: 0.45032060146331787
Test Loss:  0.5468928813934326
Valid Loss:  0.5239521265029907
Epoch:  188  	Training Loss: 0.45022377371788025
Test Loss:  0.5467829704284668
Valid Loss:  0.5238475203514099
Epoch:  189  	Training Loss: 0.4501269459724426
Test Loss:  0.546673059463501
Valid Loss:  0.5237428545951843
Epoch:  190  	Training Loss: 0.4500300884246826
Test Loss:  0.5465631484985352
Valid Loss:  0.5236382484436035
Epoch:  191  	Training Loss: 0.4499332904815674
Test Loss:  0.5464533567428589
Valid Loss:  0.5235335826873779
Epoch:  192  	Training Loss: 0.4498364329338074
Test Loss:  0.5463471412658691
Valid Loss:  0.5234326124191284
Epoch:  193  	Training Loss: 0.44974285364151
Test Loss:  0.546241044998169
Valid Loss:  0.5233316421508789
Epoch:  194  	Training Loss: 0.44964921474456787
Test Loss:  0.5461347699165344
Valid Loss:  0.5232305526733398
Epoch:  195  	Training Loss: 0.4495556056499481
Test Loss:  0.5460285544395447
Valid Loss:  0.5231295824050903
Epoch:  196  	Training Loss: 0.44946199655532837
Test Loss:  0.5459222793579102
Valid Loss:  0.5230283737182617
Epoch:  197  	Training Loss: 0.44936835765838623
Test Loss:  0.5458162426948547
Valid Loss:  0.5229274034500122
Epoch:  198  	Training Loss: 0.4492747187614441
Test Loss:  0.5457099676132202
Valid Loss:  0.5228264331817627
Epoch:  199  	Training Loss: 0.4491811692714691
Test Loss:  0.5456036329269409
Valid Loss:  0.5227252840995789
Epoch:  200  	Training Loss: 0.4490875005722046
Test Loss:  0.5454975366592407
Valid Loss:  0.5226244330406189
Epoch:  201  	Training Loss: 0.44899386167526245
Test Loss:  0.545391321182251
Valid Loss:  0.5225232243537903
Epoch:  202  	Training Loss: 0.4489002525806427
Test Loss:  0.5452815294265747
Valid Loss:  0.522418737411499
Epoch:  203  	Training Loss: 0.448803573846817
Test Loss:  0.545171856880188
Valid Loss:  0.522314190864563
Epoch:  204  	Training Loss: 0.44870686531066895
Test Loss:  0.5450621843338013
Valid Loss:  0.5222097635269165
Epoch:  205  	Training Loss: 0.4486101269721985
Test Loss:  0.5449523329734802
Valid Loss:  0.5221052169799805
Epoch:  206  	Training Loss: 0.448513388633728
Test Loss:  0.5448424816131592
Valid Loss:  0.522000789642334
Epoch:  207  	Training Loss: 0.44841668009757996
Test Loss:  0.5447327494621277
Valid Loss:  0.521896243095398
Epoch:  208  	Training Loss: 0.4483199715614319
Test Loss:  0.5446228981018066
Valid Loss:  0.5217916369438171
Epoch:  209  	Training Loss: 0.4482231140136719
Test Loss:  0.5445132851600647
Valid Loss:  0.5216870903968811
Epoch:  210  	Training Loss: 0.4481263756752014
Test Loss:  0.5444033145904541
Valid Loss:  0.5215824842453003
Epoch:  211  	Training Loss: 0.44802963733673096
Test Loss:  0.5442935228347778
Valid Loss:  0.5214779376983643
Epoch:  212  	Training Loss: 0.4479328393936157
Test Loss:  0.5441910028457642
Valid Loss:  0.5213804244995117
Epoch:  213  	Training Loss: 0.44784241914749146
Test Loss:  0.5440883636474609
Valid Loss:  0.521282970905304
Epoch:  214  	Training Loss: 0.4477520287036896
Test Loss:  0.5439857244491577
Valid Loss:  0.5211855173110962
Epoch:  215  	Training Loss: 0.4476616382598877
Test Loss:  0.5438833236694336
Valid Loss:  0.5210881233215332
Epoch:  216  	Training Loss: 0.4475713074207306
Test Loss:  0.5437808036804199
Valid Loss:  0.5209907293319702
Epoch:  217  	Training Loss: 0.4474809169769287
Test Loss:  0.5436782240867615
Valid Loss:  0.5208932161331177
Epoch:  218  	Training Loss: 0.44739052653312683
Test Loss:  0.5435757637023926
Valid Loss:  0.5207957625389099
Epoch:  219  	Training Loss: 0.4473002552986145
Test Loss:  0.5434732437133789
Valid Loss:  0.5206984281539917
Epoch:  220  	Training Loss: 0.4472099542617798
Test Loss:  0.54337078332901
Valid Loss:  0.5206011533737183
Epoch:  221  	Training Loss: 0.4471195936203003
Test Loss:  0.5432682633399963
Valid Loss:  0.5205036401748657
Epoch:  222  	Training Loss: 0.4470292925834656
Test Loss:   45%|████▍     | 223/500 [02:38<04:02,  1.14it/s] 45%|████▌     | 225/500 [02:38<02:53,  1.58it/s] 45%|████▌     | 227/500 [02:39<02:06,  2.16it/s] 46%|████▌     | 229/500 [02:39<01:33,  2.90it/s] 46%|████▌     | 231/500 [02:45<05:31,  1.23s/it] 47%|████▋     | 233/500 [02:45<03:55,  1.13it/s] 47%|████▋     | 235/500 [02:46<02:48,  1.57it/s] 47%|████▋     | 237/500 [02:46<02:02,  2.15it/s] 48%|████▊     | 239/500 [02:46<01:30,  2.89it/s] 48%|████▊     | 241/500 [02:52<05:09,  1.19s/it] 49%|████▊     | 243/500 [02:52<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:53<01:55,  2.19it/s] 50%|████▉     | 249/500 [02:53<01:25,  2.92it/s] 50%|█████     | 251/500 [02:59<05:03,  1.22s/it] 51%|█████     | 253/500 [03:00<03:37,  1.13it/s] 51%|█████     | 255/500 [03:00<02:37,  1.56it/s] 51%|█████▏    | 257/500 [03:00<01:55,  2.11it/s] 52%|█████▏    | 259/500 [03:00<01:24,  2.84it/s] 52%|█████▏    | 261/500 [03:06<04:49,  1.21s/it] 53%|█████▎    | 263/500 [03:07<03:26,  1.15it/s] 53%|█████▎    | 265/500 [03:07<02:27,  1.59it/s] 53%|█████▎    | 267/500 [03:07<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:07<01:19,  2.92it/s] 54%|█████▍    | 271/500 [03:13<04:36,  1.21s/it] 55%|█████▍    | 273/500 [03:14<03:16,  1.16it/s] 55%|█████▌    | 275/500 [03:14<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:14<01:15,  2.94it/s] 56%|█████▌    | 281/500 [03:20<04:25,  1.21s/it] 57%|█████▋    | 283/500 [03:21<03:10,  1.14it/s] 57%|█████▋    | 285/500 [03:21<02:17,  1.56it/s] 57%|█████▋    | 287/500 [03:21<01:40,  2.11it/s] 58%|█████▊    | 289/500 [03:21<01:15,  2.80it/s] 58%|█████▊    | 291/500 [03:28<04:14,  1.22s/it] 59%|█████▊    | 293/500 [03:28<03:00,  1.14it/s] 59%|█████▉    | 295/500 [03:28<02:09,  1.58it/s]0.543159008026123
Valid Loss:  0.5203998684883118
Epoch:  223  	Training Loss: 0.44693294167518616
Test Loss:  0.543049693107605
Valid Loss:  0.5202958583831787
Epoch:  224  	Training Loss: 0.4468364715576172
Test Loss:  0.5429402589797974
Valid Loss:  0.5201917886734009
Epoch:  225  	Training Loss: 0.4467400908470154
Test Loss:  0.542830765247345
Valid Loss:  0.5200878381729126
Epoch:  226  	Training Loss: 0.44664350152015686
Test Loss:  0.542721152305603
Valid Loss:  0.51998370885849
Epoch:  227  	Training Loss: 0.4465470314025879
Test Loss:  0.5426115989685059
Valid Loss:  0.5198795795440674
Epoch:  228  	Training Loss: 0.446450412273407
Test Loss:  0.5425020456314087
Valid Loss:  0.5197755098342896
Epoch:  229  	Training Loss: 0.4463537633419037
Test Loss:  0.5423924326896667
Valid Loss:  0.5196712017059326
Epoch:  230  	Training Loss: 0.446257084608078
Test Loss:  0.5422827005386353
Valid Loss:  0.5195668935775757
Epoch:  231  	Training Loss: 0.4461604058742523
Test Loss:  0.542172908782959
Valid Loss:  0.5194625854492188
Epoch:  232  	Training Loss: 0.4460636377334595
Test Loss:  0.5420709252357483
Valid Loss:  0.5193655490875244
Epoch:  233  	Training Loss: 0.44597387313842773
Test Loss:  0.5419691205024719
Valid Loss:  0.5192685127258301
Epoch:  234  	Training Loss: 0.445884108543396
Test Loss:  0.5418673157691956
Valid Loss:  0.5191716551780701
Epoch:  235  	Training Loss: 0.4457944631576538
Test Loss:  0.541765570640564
Valid Loss:  0.5190747976303101
Epoch:  236  	Training Loss: 0.44570478796958923
Test Loss:  0.5416640043258667
Valid Loss:  0.51897794008255
Epoch:  237  	Training Loss: 0.44561532139778137
Test Loss:  0.5415623188018799
Valid Loss:  0.5188812017440796
Epoch:  238  	Training Loss: 0.44552576541900635
Test Loss:  0.5414607524871826
Valid Loss:  0.5187845230102539
Epoch:  239  	Training Loss: 0.44543635845184326
Test Loss:  0.5413594245910645
Valid Loss:  0.5186880230903625
Epoch:  240  	Training Loss: 0.44534701108932495
Test Loss:  0.541257917881012
Valid Loss:  0.5185915231704712
Epoch:  241  	Training Loss: 0.4452577233314514
Test Loss:  0.5411566495895386
Valid Loss:  0.5184952020645142
Epoch:  242  	Training Loss: 0.44516852498054504
Test Loss:  0.5410539507865906
Valid Loss:  0.518397331237793
Epoch:  243  	Training Loss: 0.4450780749320984
Test Loss:  0.5409513115882874
Valid Loss:  0.5182995796203613
Epoch:  244  	Training Loss: 0.4449876546859741
Test Loss:  0.5408487319946289
Valid Loss:  0.5182018280029297
Epoch:  245  	Training Loss: 0.4448973536491394
Test Loss:  0.5407462120056152
Valid Loss:  0.5181041955947876
Epoch:  246  	Training Loss: 0.4448070526123047
Test Loss:  0.5406437516212463
Valid Loss:  0.5180066227912903
Epoch:  247  	Training Loss: 0.44471684098243713
Test Loss:  0.540541410446167
Valid Loss:  0.517909049987793
Epoch:  248  	Training Loss: 0.44462668895721436
Test Loss:  0.5404390096664429
Valid Loss:  0.5178117752075195
Epoch:  249  	Training Loss: 0.4445365369319916
Test Loss:  0.5403367877006531
Valid Loss:  0.5177143812179565
Epoch:  250  	Training Loss: 0.44444650411605835
Test Loss:  0.5402345657348633
Valid Loss:  0.5176170468330383
Epoch:  251  	Training Loss: 0.4443565607070923
Test Loss:  0.5401323437690735
Valid Loss:  0.5175198316574097
Epoch:  252  	Training Loss: 0.44426658749580383
Test Loss:  0.5400255918502808
Valid Loss:  0.5174180865287781
Epoch:  253  	Training Loss: 0.44417256116867065
Test Loss:  0.5399186611175537
Valid Loss:  0.5173163414001465
Epoch:  254  	Training Loss: 0.4440784454345703
Test Loss:  0.5398120284080505
Valid Loss:  0.5172147750854492
Epoch:  255  	Training Loss: 0.44398438930511475
Test Loss:  0.5397053360939026
Valid Loss:  0.5171130895614624
Epoch:  256  	Training Loss: 0.44389039278030396
Test Loss:  0.5395985841751099
Valid Loss:  0.5170114636421204
Epoch:  257  	Training Loss: 0.44379642605781555
Test Loss:  0.5394918918609619
Valid Loss:  0.5169098377227783
Epoch:  258  	Training Loss: 0.4437025189399719
Test Loss:  0.5393852591514587
Valid Loss:  0.5168083906173706
Epoch:  259  	Training Loss: 0.4436085820198059
Test Loss:  0.5392787456512451
Valid Loss:  0.5167068243026733
Epoch:  260  	Training Loss: 0.44351470470428467
Test Loss:  0.5391720533370972
Valid Loss:  0.5166053771972656
Epoch:  261  	Training Loss: 0.4434208273887634
Test Loss:  0.5390655994415283
Valid Loss:  0.5165038704872131
Epoch:  262  	Training Loss: 0.44332700967788696
Test Loss:  0.5389639139175415
Valid Loss:  0.5164072513580322
Epoch:  263  	Training Loss: 0.44323742389678955
Test Loss:  0.5388623476028442
Valid Loss:  0.5163106322288513
Epoch:  264  	Training Loss: 0.4431479871273041
Test Loss:  0.538760781288147
Valid Loss:  0.5162140727043152
Epoch:  265  	Training Loss: 0.4430585205554962
Test Loss:  0.5386593341827393
Valid Loss:  0.5161176323890686
Epoch:  266  	Training Loss: 0.44296908378601074
Test Loss:  0.538557767868042
Valid Loss:  0.5160210132598877
Epoch:  267  	Training Loss: 0.4428797662258148
Test Loss:  0.5384564399719238
Valid Loss:  0.5159246921539307
Epoch:  268  	Training Loss: 0.4427904486656189
Test Loss:  0.5383551120758057
Valid Loss:  0.5158283710479736
Epoch:  269  	Training Loss: 0.44270116090774536
Test Loss:  0.538253664970398
Valid Loss:  0.515731930732727
Epoch:  270  	Training Loss: 0.44261184334754944
Test Loss:  0.5381523966789246
Valid Loss:  0.51563560962677
Epoch:  271  	Training Loss: 0.44252264499664307
Test Loss:  0.5380512475967407
Valid Loss:  0.5155394077301025
Epoch:  272  	Training Loss: 0.4424334764480591
Test Loss:  0.5379555225372314
Valid Loss:  0.5154484510421753
Epoch:  273  	Training Loss: 0.44234931468963623
Test Loss:  0.537860095500946
Valid Loss:  0.5153574347496033
Epoch:  274  	Training Loss: 0.44226521253585815
Test Loss:  0.5377646684646606
Valid Loss:  0.5152666568756104
Epoch:  275  	Training Loss: 0.44218122959136963
Test Loss:  0.53766930103302
Valid Loss:  0.5151758790016174
Epoch:  276  	Training Loss: 0.44209736585617065
Test Loss:  0.5375741720199585
Valid Loss:  0.5150853991508484
Epoch:  277  	Training Loss: 0.44201359152793884
Test Loss:  0.537479043006897
Valid Loss:  0.514994740486145
Epoch:  278  	Training Loss: 0.4419298768043518
Test Loss:  0.5373840928077698
Valid Loss:  0.5149044394493103
Epoch:  279  	Training Loss: 0.44184622168540955
Test Loss:  0.5372891426086426
Valid Loss:  0.514814019203186
Epoch:  280  	Training Loss: 0.4417627155780792
Test Loss:  0.5371944904327393
Valid Loss:  0.5147237777709961
Epoch:  281  	Training Loss: 0.4416791796684265
Test Loss:  0.5370996594429016
Valid Loss:  0.5146336555480957
Epoch:  282  	Training Loss: 0.4415958523750305
Test Loss:  0.5369949340820312
Valid Loss:  0.5145339369773865
Epoch:  283  	Training Loss: 0.441503643989563
Test Loss:  0.5368903875350952
Valid Loss:  0.5144343376159668
Epoch:  284  	Training Loss: 0.4414115250110626
Test Loss:  0.5367857217788696
Valid Loss:  0.5143347978591919
Epoch:  285  	Training Loss: 0.44131937623023987
Test Loss:  0.5366811752319336
Valid Loss:  0.5142351388931274
Epoch:  286  	Training Loss: 0.4412272572517395
Test Loss:  0.5365765690803528
Valid Loss:  0.5141357183456421
Epoch:  287  	Training Loss: 0.4411351680755615
Test Loss:  0.5364720821380615
Valid Loss:  0.514036238193512
Epoch:  288  	Training Loss: 0.4410431385040283
Test Loss:  0.5363677144050598
Valid Loss:  0.5139366984367371
Epoch:  289  	Training Loss: 0.4409511685371399
Test Loss:  0.5362633466720581
Valid Loss:  0.5138373374938965
Epoch:  290  	Training Loss: 0.44085919857025146
Test Loss:  0.5361589193344116
Valid Loss:  0.5137379169464111
Epoch:  291  	Training Loss: 0.4407672882080078
Test Loss:  0.5360545516014099
Valid Loss:  0.5136386156082153
Epoch:  292  	Training Loss: 0.44067537784576416
Test Loss:  0.5359522700309753
Valid Loss:  0.5135412216186523
Epoch:  293  	Training Loss: 0.44058525562286377
Test Loss:  0.5358499884605408
Valid Loss:  0.5134438276290894
Epoch:  294  	Training Loss: 0.44049525260925293
Test Loss:  0.535747766494751
Valid Loss:  0.5133464336395264
Epoch:  295  	Training Loss: 0.4404051899909973
Test Loss:  0.5356453657150269
Valid Loss:  0.5132491588592529
 59%|█████▉    | 297/500 [03:28<01:33,  2.16it/s] 60%|█████▉    | 299/500 [03:28<01:08,  2.92it/s] 60%|██████    | 301/500 [03:35<03:57,  1.19s/it] 61%|██████    | 303/500 [03:35<02:49,  1.16it/s] 61%|██████    | 305/500 [03:35<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:35<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:42<03:50,  1.22s/it] 63%|██████▎   | 313/500 [03:42<02:43,  1.14it/s] 63%|██████▎   | 315/500 [03:42<01:57,  1.58it/s] 63%|██████▎   | 317/500 [03:42<01:24,  2.16it/s] 64%|██████▍   | 319/500 [03:42<01:02,  2.91it/s] 64%|██████▍   | 321/500 [03:49<03:37,  1.21s/it] 65%|██████▍   | 323/500 [03:49<02:34,  1.14it/s] 65%|██████▌   | 325/500 [03:49<01:50,  1.58it/s] 65%|██████▌   | 327/500 [03:49<01:20,  2.16it/s] 66%|██████▌   | 329/500 [03:49<00:58,  2.90it/s] 66%|██████▌   | 331/500 [03:56<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:56<02:23,  1.16it/s] 67%|██████▋   | 335/500 [03:56<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:56<01:14,  2.20it/s] 68%|██████▊   | 339/500 [03:56<00:54,  2.96it/s] 68%|██████▊   | 341/500 [04:03<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:03<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:03<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:03<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:03<00:51,  2.92it/s] 70%|███████   | 351/500 [04:10<03:02,  1.22s/it] 71%|███████   | 353/500 [04:10<02:09,  1.14it/s] 71%|███████   | 355/500 [04:10<01:31,  1.58it/s] 71%|███████▏  | 357/500 [04:10<01:06,  2.16it/s] 72%|███████▏  | 359/500 [04:10<00:48,  2.90it/s] 72%|███████▏  | 361/500 [04:17<02:48,  1.21s/it] 73%|███████▎  | 363/500 [04:17<01:59,  1.14it/s] 73%|███████▎  | 365/500 [04:17<01:26,  1.57it/s] 73%|███████▎  | 367/500 [04:17<01:02,  2.12it/s]Epoch:  296  	Training Loss: 0.440315306186676
Test Loss:  0.5355433225631714
Valid Loss:  0.5131517648696899
Epoch:  297  	Training Loss: 0.4402253031730652
Test Loss:  0.5354411602020264
Valid Loss:  0.513054370880127
Epoch:  298  	Training Loss: 0.4401353597640991
Test Loss:  0.5353391170501709
Valid Loss:  0.5129572153091431
Epoch:  299  	Training Loss: 0.44004547595977783
Test Loss:  0.5352370738983154
Valid Loss:  0.5128600597381592
Epoch:  300  	Training Loss: 0.4399556815624237
Test Loss:  0.5351349115371704
Valid Loss:  0.5127630233764648
Epoch:  301  	Training Loss: 0.4398658871650696
Test Loss:  0.5350329875946045
Valid Loss:  0.512665867805481
Epoch:  302  	Training Loss: 0.43977609276771545
Test Loss:  0.5349152684211731
Valid Loss:  0.5125536918640137
Epoch:  303  	Training Loss: 0.43967241048812866
Test Loss:  0.5347974300384521
Valid Loss:  0.5124414563179016
Epoch:  304  	Training Loss: 0.43956857919692993
Test Loss:  0.5346794128417969
Valid Loss:  0.5123291611671448
Epoch:  305  	Training Loss: 0.4394647479057312
Test Loss:  0.5345613956451416
Valid Loss:  0.5122168064117432
Epoch:  306  	Training Loss: 0.43936073780059814
Test Loss:  0.5344432592391968
Valid Loss:  0.5121042728424072
Epoch:  307  	Training Loss: 0.43925678730010986
Test Loss:  0.534325122833252
Valid Loss:  0.5119916796684265
Epoch:  308  	Training Loss: 0.43915271759033203
Test Loss:  0.5342068672180176
Valid Loss:  0.5118790864944458
Epoch:  309  	Training Loss: 0.4390484094619751
Test Loss:  0.5340883731842041
Valid Loss:  0.5117663741111755
Epoch:  310  	Training Loss: 0.4389442205429077
Test Loss:  0.5339698791503906
Valid Loss:  0.5116536617279053
Epoch:  311  	Training Loss: 0.4388399124145508
Test Loss:  0.5338514447212219
Valid Loss:  0.5115407705307007
Epoch:  312  	Training Loss: 0.43873557448387146
Test Loss:  0.5337293148040771
Valid Loss:  0.5114244818687439
Epoch:  313  	Training Loss: 0.4386281371116638
Test Loss:  0.5336071848869324
Valid Loss:  0.5113081336021423
Epoch:  314  	Training Loss: 0.43852055072784424
Test Loss:  0.5334848165512085
Valid Loss:  0.5111916661262512
Epoch:  315  	Training Loss: 0.4384128749370575
Test Loss:  0.5333623290061951
Valid Loss:  0.5110750794410706
Epoch:  316  	Training Loss: 0.4383050799369812
Test Loss:  0.5332397222518921
Valid Loss:  0.5109582543373108
Epoch:  317  	Training Loss: 0.43819719552993774
Test Loss:  0.5331170558929443
Valid Loss:  0.510841429233551
Epoch:  318  	Training Loss: 0.43808916211128235
Test Loss:  0.5329940915107727
Valid Loss:  0.5107243657112122
Epoch:  319  	Training Loss: 0.4379810690879822
Test Loss:  0.5328711271286011
Valid Loss:  0.5106073021888733
Epoch:  320  	Training Loss: 0.43787282705307007
Test Loss:  0.5327481627464294
Valid Loss:  0.5104900598526001
Epoch:  321  	Training Loss: 0.43776455521583557
Test Loss:  0.5326247811317444
Valid Loss:  0.5103728175163269
Epoch:  322  	Training Loss: 0.43765610456466675
Test Loss:  0.5325162410736084
Valid Loss:  0.5102691650390625
Epoch:  323  	Training Loss: 0.43756037950515747
Test Loss:  0.5324076414108276
Valid Loss:  0.5101657509803772
Epoch:  324  	Training Loss: 0.43746474385261536
Test Loss:  0.5322990417480469
Valid Loss:  0.5100623369216919
Epoch:  325  	Training Loss: 0.4373692274093628
Test Loss:  0.5321906805038452
Valid Loss:  0.5099588632583618
Epoch:  326  	Training Loss: 0.43727368116378784
Test Loss:  0.532082200050354
Valid Loss:  0.5098555684089661
Epoch:  327  	Training Loss: 0.43717825412750244
Test Loss:  0.5319739580154419
Valid Loss:  0.5097523331642151
Epoch:  328  	Training Loss: 0.43708282709121704
Test Loss:  0.5318657755851746
Valid Loss:  0.5096490979194641
Epoch:  329  	Training Loss: 0.4369874894618988
Test Loss:  0.5317573547363281
Valid Loss:  0.5095459818840027
Epoch:  330  	Training Loss: 0.43689218163490295
Test Loss:  0.5316493511199951
Valid Loss:  0.509442925453186
Epoch:  331  	Training Loss: 0.43679696321487427
Test Loss:  0.5315412282943726
Valid Loss:  0.5093398094177246
Epoch:  332  	Training Loss: 0.43670180439949036
Test Loss:  0.5314347147941589
Valid Loss:  0.5092384219169617
Epoch:  333  	Training Loss: 0.4366079568862915
Test Loss:  0.5313282012939453
Valid Loss:  0.5091369152069092
Epoch:  334  	Training Loss: 0.43651413917541504
Test Loss:  0.5312215089797974
Valid Loss:  0.5090352892875671
Epoch:  335  	Training Loss: 0.4364202618598938
Test Loss:  0.5311148166656494
Valid Loss:  0.5089338421821594
Epoch:  336  	Training Loss: 0.4363265335559845
Test Loss:  0.531008243560791
Valid Loss:  0.5088322162628174
Epoch:  337  	Training Loss: 0.43623268604278564
Test Loss:  0.5309014916419983
Valid Loss:  0.5087306499481201
Epoch:  338  	Training Loss: 0.4361388683319092
Test Loss:  0.5307949781417847
Valid Loss:  0.5086292028427124
Epoch:  339  	Training Loss: 0.4360450804233551
Test Loss:  0.5306885242462158
Valid Loss:  0.5085278153419495
Epoch:  340  	Training Loss: 0.435951292514801
Test Loss:  0.5305818319320679
Valid Loss:  0.5084262490272522
Epoch:  341  	Training Loss: 0.43585753440856934
Test Loss:  0.5304752588272095
Valid Loss:  0.5083247423171997
Epoch:  342  	Training Loss: 0.43576371669769287
Test Loss:  0.5303753614425659
Valid Loss:  0.5082296133041382
Epoch:  343  	Training Loss: 0.43567588925361633
Test Loss:  0.5302754640579224
Valid Loss:  0.5081344842910767
Epoch:  344  	Training Loss: 0.43558797240257263
Test Loss:  0.5301755666732788
Valid Loss:  0.5080394744873047
Epoch:  345  	Training Loss: 0.4355001449584961
Test Loss:  0.53007572889328
Valid Loss:  0.5079443454742432
Epoch:  346  	Training Loss: 0.43541234731674194
Test Loss:  0.5299757122993469
Valid Loss:  0.5078493356704712
Epoch:  347  	Training Loss: 0.435324490070343
Test Loss:  0.5298760533332825
Valid Loss:  0.507754385471344
Epoch:  348  	Training Loss: 0.4352368712425232
Test Loss:  0.5297763347625732
Valid Loss:  0.5076595544815063
Epoch:  349  	Training Loss: 0.4351491332054138
Test Loss:  0.5296766757965088
Valid Loss:  0.5075646638870239
Epoch:  350  	Training Loss: 0.43506139516830444
Test Loss:  0.5295767784118652
Valid Loss:  0.507469892501831
Epoch:  351  	Training Loss: 0.43497374653816223
Test Loss:  0.5294772982597351
Valid Loss:  0.5073748826980591
Epoch:  352  	Training Loss: 0.43488621711730957
Test Loss:  0.5293641090393066
Valid Loss:  0.50726717710495
Epoch:  353  	Training Loss: 0.4347865581512451
Test Loss:  0.5292509198188782
Valid Loss:  0.5071593523025513
Epoch:  354  	Training Loss: 0.43468689918518066
Test Loss:  0.5291376113891602
Valid Loss:  0.5070515871047974
Epoch:  355  	Training Loss: 0.4345872104167938
Test Loss:  0.5290244817733765
Valid Loss:  0.5069435834884644
Epoch:  356  	Training Loss: 0.43448758125305176
Test Loss:  0.5289109945297241
Valid Loss:  0.5068356990814209
Epoch:  357  	Training Loss: 0.43438786268234253
Test Loss:  0.5287975072860718
Valid Loss:  0.5067278146743774
Epoch:  358  	Training Loss: 0.4342880845069885
Test Loss:  0.5286842584609985
Valid Loss:  0.5066198706626892
Epoch:  359  	Training Loss: 0.4341883063316345
Test Loss:  0.5285710096359253
Valid Loss:  0.5065118670463562
Epoch:  360  	Training Loss: 0.43408846855163574
Test Loss:  0.528457522392273
Valid Loss:  0.506403923034668
Epoch:  361  	Training Loss: 0.4339887499809265
Test Loss:  0.5283440351486206
Valid Loss:  0.506295919418335
Epoch:  362  	Training Loss: 0.43388888239860535
Test Loss:  0.5282402038574219
Valid Loss:  0.5061968564987183
Epoch:  363  	Training Loss: 0.4337973892688751
Test Loss:  0.5281360745429993
Valid Loss:  0.506097674369812
Epoch:  364  	Training Loss: 0.4337059259414673
Test Loss:  0.5280321836471558
Valid Loss:  0.5059987306594849
Epoch:  365  	Training Loss: 0.4336145222187042
Test Loss:  0.5279281735420227
Valid Loss:  0.5058996081352234
Epoch:  366  	Training Loss: 0.43352311849594116
Test Loss:  0.5278244018554688
Valid Loss:  0.505800724029541
Epoch:  367  	Training Loss: 0.4334317445755005
Test Loss:  0.52772057056427
Valid Loss:  0.5057017207145691
Epoch:  368  	Training Loss: 0.4333404004573822
Test Loss:  0.5276166200637817
Valid Loss:  0.5056028366088867
Epoch:  369  	Training Loss: 0.4332491159439087
Test Loss:   74%|███████▍  | 369/500 [04:17<00:46,  2.82it/s] 74%|███████▍  | 371/500 [04:24<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:24<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:24<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:24<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:24<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:31<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:31<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:31<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:31<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:31<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:38<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:38<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:38<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:38<00:47,  2.16it/s] 80%|███████▉  | 399/500 [04:38<00:34,  2.92it/s] 80%|████████  | 401/500 [04:45<02:00,  1.21s/it] 81%|████████  | 403/500 [04:45<01:24,  1.15it/s] 81%|████████  | 405/500 [04:45<00:59,  1.59it/s] 81%|████████▏ | 407/500 [04:45<00:42,  2.18it/s] 82%|████████▏ | 409/500 [04:45<00:30,  2.94it/s] 82%|████████▏ | 411/500 [04:52<01:46,  1.19s/it] 83%|████████▎ | 413/500 [04:52<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:52<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.20it/s] 84%|████████▍ | 419/500 [04:52<00:27,  2.96it/s] 84%|████████▍ | 421/500 [04:58<01:34,  1.19s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:59<00:46,  1.61it/s] 85%|████████▌ | 427/500 [04:59<00:33,  2.21it/s] 86%|████████▌ | 429/500 [04:59<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:05<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:06<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:06<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:06<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:06<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:12<01:11,  1.21s/it]0.5275126695632935
Valid Loss:  0.5055038928985596
Epoch:  370  	Training Loss: 0.4331577718257904
Test Loss:  0.5274090766906738
Valid Loss:  0.505405068397522
Epoch:  371  	Training Loss: 0.4330665171146393
Test Loss:  0.5273053646087646
Valid Loss:  0.5053061842918396
Epoch:  372  	Training Loss: 0.43297529220581055
Test Loss:  0.5272072553634644
Valid Loss:  0.5052130222320557
Epoch:  373  	Training Loss: 0.43288910388946533
Test Loss:  0.5271093845367432
Valid Loss:  0.505119800567627
Epoch:  374  	Training Loss: 0.4328029155731201
Test Loss:  0.527011513710022
Valid Loss:  0.5050266981124878
Epoch:  375  	Training Loss: 0.43271684646606445
Test Loss:  0.5269136428833008
Valid Loss:  0.5049335956573486
Epoch:  376  	Training Loss: 0.4326307773590088
Test Loss:  0.5268159508705139
Valid Loss:  0.5048405528068542
Epoch:  377  	Training Loss: 0.4325447082519531
Test Loss:  0.5267181992530823
Valid Loss:  0.5047476291656494
Epoch:  378  	Training Loss: 0.432458758354187
Test Loss:  0.526620626449585
Valid Loss:  0.5046547651290894
Epoch:  379  	Training Loss: 0.4323728680610657
Test Loss:  0.5265229940414429
Valid Loss:  0.5045619606971741
Epoch:  380  	Training Loss: 0.4322870969772339
Test Loss:  0.5264254808425903
Valid Loss:  0.504469096660614
Epoch:  381  	Training Loss: 0.43220120668411255
Test Loss:  0.5263280272483826
Valid Loss:  0.5043764114379883
Epoch:  382  	Training Loss: 0.43211543560028076
Test Loss:  0.5262045860290527
Valid Loss:  0.5042588710784912
Epoch:  383  	Training Loss: 0.4320068955421448
Test Loss:  0.5260810852050781
Valid Loss:  0.5041412115097046
Epoch:  384  	Training Loss: 0.431898295879364
Test Loss:  0.5259572267532349
Valid Loss:  0.5040234923362732
Epoch:  385  	Training Loss: 0.4317895472049713
Test Loss:  0.5258334875106812
Valid Loss:  0.5039056539535522
Epoch:  386  	Training Loss: 0.43168067932128906
Test Loss:  0.5257096290588379
Valid Loss:  0.5037877559661865
Epoch:  387  	Training Loss: 0.4315717816352844
Test Loss:  0.5255856513977051
Valid Loss:  0.5036695003509521
Epoch:  388  	Training Loss: 0.4314625859260559
Test Loss:  0.5254616737365723
Valid Loss:  0.5035513639450073
Epoch:  389  	Training Loss: 0.43135344982147217
Test Loss:  0.525337278842926
Valid Loss:  0.5034329891204834
Epoch:  390  	Training Loss: 0.4312441945075989
Test Loss:  0.525212824344635
Valid Loss:  0.503314733505249
Epoch:  391  	Training Loss: 0.43113481998443604
Test Loss:  0.525088369846344
Valid Loss:  0.5031960606575012
Epoch:  392  	Training Loss: 0.4310254454612732
Test Loss:  0.5249800682067871
Valid Loss:  0.5030930042266846
Epoch:  393  	Training Loss: 0.4309301972389221
Test Loss:  0.5248717069625854
Valid Loss:  0.5029900074005127
Epoch:  394  	Training Loss: 0.4308350086212158
Test Loss:  0.5247637033462524
Valid Loss:  0.5028870701789856
Epoch:  395  	Training Loss: 0.4307398796081543
Test Loss:  0.5246553421020508
Valid Loss:  0.5027838349342346
Epoch:  396  	Training Loss: 0.430644690990448
Test Loss:  0.5245469808578491
Valid Loss:  0.5026806592941284
Epoch:  397  	Training Loss: 0.4305495023727417
Test Loss:  0.524438738822937
Valid Loss:  0.5025776624679565
Epoch:  398  	Training Loss: 0.4304542541503906
Test Loss:  0.5243303775787354
Valid Loss:  0.5024744868278503
Epoch:  399  	Training Loss: 0.43035903573036194
Test Loss:  0.5242220163345337
Valid Loss:  0.5023713111877441
Epoch:  400  	Training Loss: 0.43026384711265564
Test Loss:  0.524113655090332
Valid Loss:  0.5022681951522827
Epoch:  401  	Training Loss: 0.43016862869262695
Test Loss:  0.5240052938461304
Valid Loss:  0.5021649599075317
Epoch:  402  	Training Loss: 0.43007344007492065
Test Loss:  0.5238949656486511
Valid Loss:  0.5020598769187927
Epoch:  403  	Training Loss: 0.4299762547016144
Test Loss:  0.5237842798233032
Valid Loss:  0.5019544959068298
Epoch:  404  	Training Loss: 0.42987900972366333
Test Loss:  0.5236738920211792
Valid Loss:  0.5018492937088013
Epoch:  405  	Training Loss: 0.4297819137573242
Test Loss:  0.5235631465911865
Valid Loss:  0.5017439723014832
Epoch:  406  	Training Loss: 0.429684579372406
Test Loss:  0.523452639579773
Valid Loss:  0.5016387701034546
Epoch:  407  	Training Loss: 0.4295874834060669
Test Loss:  0.5233421325683594
Valid Loss:  0.5015334486961365
Epoch:  408  	Training Loss: 0.42949020862579346
Test Loss:  0.523231565952301
Valid Loss:  0.5014281272888184
Epoch:  409  	Training Loss: 0.4293929934501648
Test Loss:  0.5231208801269531
Valid Loss:  0.5013227462768555
Epoch:  410  	Training Loss: 0.42929574847221375
Test Loss:  0.5230103135108948
Valid Loss:  0.5012174248695374
Epoch:  411  	Training Loss: 0.4291985034942627
Test Loss:  0.5228997468948364
Valid Loss:  0.5011119842529297
Epoch:  412  	Training Loss: 0.42910119891166687
Test Loss:  0.522807240486145
Valid Loss:  0.5010241866111755
Epoch:  413  	Training Loss: 0.4290199279785156
Test Loss:  0.5227148532867432
Valid Loss:  0.5009362101554871
Epoch:  414  	Training Loss: 0.42893877625465393
Test Loss:  0.5226226449012756
Valid Loss:  0.5008483529090881
Epoch:  415  	Training Loss: 0.428857684135437
Test Loss:  0.5225303769111633
Valid Loss:  0.5007606148719788
Epoch:  416  	Training Loss: 0.42877650260925293
Test Loss:  0.5224382281303406
Valid Loss:  0.5006729364395142
Epoch:  417  	Training Loss: 0.42869555950164795
Test Loss:  0.5223462581634521
Valid Loss:  0.5005854368209839
Epoch:  418  	Training Loss: 0.42861470580101013
Test Loss:  0.522254467010498
Valid Loss:  0.5004978179931641
Epoch:  419  	Training Loss: 0.4285338521003723
Test Loss:  0.5221624374389648
Valid Loss:  0.5004103183746338
Epoch:  420  	Training Loss: 0.42845314741134644
Test Loss:  0.5220707654953003
Valid Loss:  0.5003229975700378
Epoch:  421  	Training Loss: 0.42837241291999817
Test Loss:  0.5219788551330566
Valid Loss:  0.5002356767654419
Epoch:  422  	Training Loss: 0.42829179763793945
Test Loss:  0.521874725818634
Valid Loss:  0.5001363754272461
Epoch:  423  	Training Loss: 0.4282001852989197
Test Loss:  0.5217703580856323
Valid Loss:  0.5000371932983398
Epoch:  424  	Training Loss: 0.42810845375061035
Test Loss:  0.5216660499572754
Valid Loss:  0.4999380111694336
Epoch:  425  	Training Loss: 0.4280167818069458
Test Loss:  0.5215617418289185
Valid Loss:  0.49983862042427063
Epoch:  426  	Training Loss: 0.42792510986328125
Test Loss:  0.5214576125144958
Valid Loss:  0.4997393488883972
Epoch:  427  	Training Loss: 0.42783355712890625
Test Loss:  0.5213532447814941
Valid Loss:  0.49964025616645813
Epoch:  428  	Training Loss: 0.42774197459220886
Test Loss:  0.5212490558624268
Valid Loss:  0.49954095482826233
Epoch:  429  	Training Loss: 0.4276503324508667
Test Loss:  0.5211448669433594
Valid Loss:  0.4994416832923889
Epoch:  430  	Training Loss: 0.4275587499141693
Test Loss:  0.521040678024292
Valid Loss:  0.4993424713611603
Epoch:  431  	Training Loss: 0.42746710777282715
Test Loss:  0.5209363102912903
Valid Loss:  0.4992434084415436
Epoch:  432  	Training Loss: 0.4273754358291626
Test Loss:  0.5208402872085571
Valid Loss:  0.4991518557071686
Epoch:  433  	Training Loss: 0.4272910952568054
Test Loss:  0.5207444429397583
Valid Loss:  0.49906057119369507
Epoch:  434  	Training Loss: 0.42720675468444824
Test Loss:  0.5206483602523804
Valid Loss:  0.4989691972732544
Epoch:  435  	Training Loss: 0.42712241411209106
Test Loss:  0.5205525159835815
Valid Loss:  0.4988781213760376
Epoch:  436  	Training Loss: 0.4270382523536682
Test Loss:  0.5204566717147827
Valid Loss:  0.49878695607185364
Epoch:  437  	Training Loss: 0.4269540309906006
Test Loss:  0.5203609466552734
Valid Loss:  0.4986957609653473
Epoch:  438  	Training Loss: 0.42686986923217773
Test Loss:  0.5202651619911194
Valid Loss:  0.49860459566116333
Epoch:  439  	Training Loss: 0.42678576707839966
Test Loss:  0.5201693773269653
Valid Loss:  0.498513400554657
Epoch:  440  	Training Loss: 0.4267016649246216
Test Loss:  0.520073652267456
Valid Loss:  0.4984222650527954
Epoch:  441  	Training Loss: 0.4266175627708435
Test Loss:  0.519977867603302
Valid Loss:  0.49833130836486816
Epoch:  442  	Training Loss: 0.42653363943099976
Test Loss:  0.5198845863342285
Valid Loss:  0.4982423186302185
 89%|████████▊ | 443/500 [05:13<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:13<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:13<00:24,  2.14it/s] 90%|████████▉ | 449/500 [05:13<00:17,  2.89it/s] 90%|█████████ | 451/500 [05:19<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:19<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:20<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:26<00:47,  1.22s/it] 93%|█████████▎| 463/500 [05:27<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:27<00:22,  1.59it/s] 93%|█████████▎| 467/500 [05:27<00:15,  2.18it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.93it/s] 94%|█████████▍| 471/500 [05:33<00:35,  1.21s/it] 95%|█████████▍| 473/500 [05:34<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.59it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.18it/s] 96%|█████████▌| 479/500 [05:34<00:07,  2.94it/s] 96%|█████████▌| 481/500 [05:40<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.14it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.58it/s] 97%|█████████▋| 487/500 [05:41<00:06,  2.16it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.90it/s] 98%|█████████▊| 491/500 [05:48<00:11,  1.22s/it] 99%|█████████▊| 493/500 [05:48<00:06,  1.14it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.56it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.10it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.81it/s]100%|██████████| 500/500 [05:48<00:00,  1.43it/s]
Epoch:  443  	Training Loss: 0.4264514446258545
Test Loss:  0.5197913646697998
Valid Loss:  0.4981535077095032
Epoch:  444  	Training Loss: 0.42636948823928833
Test Loss:  0.5196979641914368
Valid Loss:  0.49806472659111023
Epoch:  445  	Training Loss: 0.42628753185272217
Test Loss:  0.5196049213409424
Valid Loss:  0.4979761242866516
Epoch:  446  	Training Loss: 0.42620566487312317
Test Loss:  0.5195118188858032
Valid Loss:  0.49788743257522583
Epoch:  447  	Training Loss: 0.42612385749816895
Test Loss:  0.5194189548492432
Valid Loss:  0.49779900908470154
Epoch:  448  	Training Loss: 0.42604219913482666
Test Loss:  0.5193260312080383
Valid Loss:  0.4977104067802429
Epoch:  449  	Training Loss: 0.42596060037612915
Test Loss:  0.5192331671714783
Valid Loss:  0.4976220726966858
Epoch:  450  	Training Loss: 0.42587900161743164
Test Loss:  0.5191405415534973
Valid Loss:  0.4975337088108063
Epoch:  451  	Training Loss: 0.4257974922657013
Test Loss:  0.5190478563308716
Valid Loss:  0.4974457621574402
Epoch:  452  	Training Loss: 0.4257161021232605
Test Loss:  0.5189511775970459
Valid Loss:  0.49735379219055176
Epoch:  453  	Training Loss: 0.42563125491142273
Test Loss:  0.5188547968864441
Valid Loss:  0.49726197123527527
Epoch:  454  	Training Loss: 0.4255464971065521
Test Loss:  0.5187584161758423
Valid Loss:  0.49717018008232117
Epoch:  455  	Training Loss: 0.42546191811561584
Test Loss:  0.5186622142791748
Valid Loss:  0.4970785081386566
Epoch:  456  	Training Loss: 0.4253772497177124
Test Loss:  0.5185657739639282
Valid Loss:  0.4969866871833801
Epoch:  457  	Training Loss: 0.42529261112213135
Test Loss:  0.5184695720672607
Valid Loss:  0.4968951940536499
Epoch:  458  	Training Loss: 0.42520803213119507
Test Loss:  0.5183732509613037
Valid Loss:  0.4968035817146301
Epoch:  459  	Training Loss: 0.4251234531402588
Test Loss:  0.5182772278785706
Valid Loss:  0.49671223759651184
Epoch:  460  	Training Loss: 0.4250391125679016
Test Loss:  0.5181810855865479
Valid Loss:  0.49662071466445923
Epoch:  461  	Training Loss: 0.42495468258857727
Test Loss:  0.5180850028991699
Valid Loss:  0.4965294897556305
Epoch:  462  	Training Loss: 0.42487025260925293
Test Loss:  0.5179676413536072
Valid Loss:  0.4964176416397095
Epoch:  463  	Training Loss: 0.4247671365737915
Test Loss:  0.5178503394126892
Valid Loss:  0.496305912733078
Epoch:  464  	Training Loss: 0.4246639907360077
Test Loss:  0.5177329182624817
Valid Loss:  0.4961942136287689
Epoch:  465  	Training Loss: 0.4245607852935791
Test Loss:  0.5176154971122742
Valid Loss:  0.4960823357105255
Epoch:  466  	Training Loss: 0.4244576096534729
Test Loss:  0.5174978971481323
Valid Loss:  0.4959704279899597
Epoch:  467  	Training Loss: 0.42435422539711
Test Loss:  0.5173801779747009
Valid Loss:  0.495858371257782
Epoch:  468  	Training Loss: 0.42425090074539185
Test Loss:  0.5172625780105591
Valid Loss:  0.495746374130249
Epoch:  469  	Training Loss: 0.42414724826812744
Test Loss:  0.5171447396278381
Valid Loss:  0.4956343472003937
Epoch:  470  	Training Loss: 0.42404383420944214
Test Loss:  0.5170268416404724
Valid Loss:  0.495522141456604
Epoch:  471  	Training Loss: 0.4239403009414673
Test Loss:  0.5169089436531067
Valid Loss:  0.49540984630584717
Epoch:  472  	Training Loss: 0.42383670806884766
Test Loss:  0.5168189406394958
Valid Loss:  0.49532395601272583
Epoch:  473  	Training Loss: 0.4237574636936188
Test Loss:  0.5167286992073059
Valid Loss:  0.4952383041381836
Epoch:  474  	Training Loss: 0.4236784279346466
Test Loss:  0.5166385173797607
Valid Loss:  0.49515262246131897
Epoch:  475  	Training Loss: 0.42359936237335205
Test Loss:  0.516548752784729
Valid Loss:  0.4950668513774872
Epoch:  476  	Training Loss: 0.4235203266143799
Test Loss:  0.516459047794342
Valid Loss:  0.49498146772384644
Epoch:  477  	Training Loss: 0.42344141006469727
Test Loss:  0.5163693428039551
Valid Loss:  0.49489596486091614
Epoch:  478  	Training Loss: 0.423362672328949
Test Loss:  0.5162796974182129
Valid Loss:  0.4948105216026306
Epoch:  479  	Training Loss: 0.42328402400016785
Test Loss:  0.5161901712417603
Valid Loss:  0.4947252869606018
Epoch:  480  	Training Loss: 0.42320528626441956
Test Loss:  0.5161006450653076
Valid Loss:  0.4946399927139282
Epoch:  481  	Training Loss: 0.42312678694725037
Test Loss:  0.5160114169120789
Valid Loss:  0.49455490708351135
Epoch:  482  	Training Loss: 0.4230482280254364
Test Loss:  0.5159180760383606
Valid Loss:  0.49446597695350647
Epoch:  483  	Training Loss: 0.4229664206504822
Test Loss:  0.5158249139785767
Valid Loss:  0.49437737464904785
Epoch:  484  	Training Loss: 0.422884464263916
Test Loss:  0.5157317519187927
Valid Loss:  0.49428874254226685
Epoch:  485  	Training Loss: 0.422802597284317
Test Loss:  0.5156385898590088
Valid Loss:  0.4942001402378082
Epoch:  486  	Training Loss: 0.4227207899093628
Test Loss:  0.5155455470085144
Valid Loss:  0.49411144852638245
Epoch:  487  	Training Loss: 0.4226391315460205
Test Loss:  0.51545250415802
Valid Loss:  0.4940229058265686
Epoch:  488  	Training Loss: 0.4225573241710663
Test Loss:  0.51535964012146
Valid Loss:  0.4939345121383667
Epoch:  489  	Training Loss: 0.42247581481933594
Test Loss:  0.5152666568756104
Valid Loss:  0.49384605884552
Epoch:  490  	Training Loss: 0.42239415645599365
Test Loss:  0.5151737928390503
Valid Loss:  0.4937577247619629
Epoch:  491  	Training Loss: 0.42231249809265137
Test Loss:  0.5150808691978455
Valid Loss:  0.4936693608760834
Epoch:  492  	Training Loss: 0.4222310185432434
Test Loss:  0.5149881839752197
Valid Loss:  0.4935809373855591
Epoch:  493  	Training Loss: 0.42214956879615784
Test Loss:  0.5148953795433044
Valid Loss:  0.4934927821159363
Epoch:  494  	Training Loss: 0.4220679998397827
Test Loss:  0.5148026943206787
Valid Loss:  0.4934045076370239
Epoch:  495  	Training Loss: 0.4219866394996643
Test Loss:  0.5147103071212769
Valid Loss:  0.4933164119720459
Epoch:  496  	Training Loss: 0.4219052791595459
Test Loss:  0.5146175622940063
Valid Loss:  0.4932282865047455
Epoch:  497  	Training Loss: 0.42182397842407227
Test Loss:  0.5145250558853149
Valid Loss:  0.49313998222351074
Epoch:  498  	Training Loss: 0.42174282670021057
Test Loss:  0.5144327282905579
Valid Loss:  0.4930521547794342
Epoch:  499  	Training Loss: 0.4216616153717041
Test Loss:  0.5143404006958008
Valid Loss:  0.49296435713768005
Epoch:  500  	Training Loss: 0.42158058285713196
Test Loss:  0.5142483711242676
Valid Loss:  0.4928765892982483
seed is  18
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<54:10,  6.51s/it]  1%|          | 3/500 [00:06<14:23,  1.74s/it]  1%|          | 5/500 [00:06<07:14,  1.14it/s]  1%|▏         | 7/500 [00:06<04:22,  1.88it/s]  2%|▏         | 9/500 [00:07<02:55,  2.80it/s]  2%|▏         | 11/500 [00:13<10:56,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:36,  2.18it/s]  6%|▌         | 29/500 [00:20<02:39,  2.94it/s]  6%|▌         | 31/500 [00:33<16:47,  2.15s/it]  7%|▋         | 33/500 [00:33<11:53,  1.53s/it]  7%|▋         | 35/500 [00:33<08:25,  1.09s/it]  7%|▋         | 37/500 [00:34<06:01,  1.28it/s]  8%|▊         | 39/500 [00:34<04:21,  1.77it/s]  8%|▊         | 41/500 [00:40<10:35,  1.38s/it]  9%|▊         | 43/500 [00:40<07:32,  1.01it/s]  9%|▉         | 45/500 [00:41<05:25,  1.40it/s]  9%|▉         | 47/500 [00:41<03:55,  1.92it/s] 10%|▉         | 49/500 [00:41<02:53,  2.60it/s] 10%|█         | 51/500 [00:47<09:15,  1.24s/it] 11%|█         | 53/500 [00:47<06:36,  1.13it/s] 11%|█         | 55/500 [00:48<04:45,  1.56it/s] 11%|█▏        | 57/500 [00:48<03:28,  2.12it/s] 12%|█▏        | 59/500 [00:48<02:34,  2.85it/s] 12%|█▏        | 61/500 [00:54<08:49,  1.21s/it] 13%|█▎        | 63/500 [00:54<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:54<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:55<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:55<02:27,  2.93it/s]Epoch:  1  	Training Loss: 0.47964417934417725
Test Loss:  14.677595138549805
Valid Loss:  14.11651611328125
Epoch:  2  	Training Loss: 15.023250579833984
Test Loss:  11.311927795410156
Valid Loss:  10.182910919189453
Epoch:  3  	Training Loss: 10.045782089233398
Test Loss:  0.38063329458236694
Valid Loss:  0.3762247562408447
Epoch:  4  	Training Loss: 0.34365949034690857
Test Loss:  0.23539143800735474
Valid Loss:  0.26582443714141846
Epoch:  5  	Training Loss: 0.2808190584182739
Test Loss:  0.22841203212738037
Valid Loss:  0.26169463992118835
Epoch:  6  	Training Loss: 0.27477192878723145
Test Loss:  0.22454248368740082
Valid Loss:  0.25872352719306946
Epoch:  7  	Training Loss: 0.26841065287590027
Test Loss:  0.21701954305171967
Valid Loss:  0.2545885443687439
Epoch:  8  	Training Loss: 0.26120051741600037
Test Loss:  0.20866426825523376
Valid Loss:  0.24847786128520966
Epoch:  9  	Training Loss: 0.25305870175361633
Test Loss:  0.19858941435813904
Valid Loss:  0.24135050177574158
Epoch:  10  	Training Loss: 0.24363435804843903
Test Loss:  0.1859249621629715
Valid Loss:  0.23026274144649506
Epoch:  11  	Training Loss: 0.23211537301540375
Test Loss:  0.16893191635608673
Valid Loss:  0.21330496668815613
Epoch:  12  	Training Loss: 0.21679647266864777
Test Loss:  0.11681316047906876
Valid Loss:  0.13456928730010986
Epoch:  13  	Training Loss: 0.14022205770015717
Test Loss:  0.06031801551580429
Valid Loss:  0.065823495388031
Epoch:  14  	Training Loss: 0.07469138503074646
Test Loss:  0.030756168067455292
Valid Loss:  0.033143069595098495
Epoch:  15  	Training Loss: 0.045647382736206055
Test Loss:  0.019226066768169403
Valid Loss:  0.019509397447109222
Epoch:  16  	Training Loss: 0.0309976227581501
Test Loss:  0.014190364629030228
Valid Loss:  0.014217780902981758
Epoch:  17  	Training Loss: 0.024171840399503708
Test Loss:  0.0123505350202322
Valid Loss:  0.012032430619001389
Epoch:  18  	Training Loss: 0.021249711513519287
Test Loss:  0.011170405894517899
Valid Loss:  0.010886328294873238
Epoch:  19  	Training Loss: 0.019467677921056747
Test Loss:  0.010627740994095802
Valid Loss:  0.010374017991125584
Epoch:  20  	Training Loss: 0.018283475190401077
Test Loss:  0.010232776403427124
Valid Loss:  0.010185925289988518
Epoch:  21  	Training Loss: 0.01747341826558113
Test Loss:  0.010075721889734268
Valid Loss:  0.010186118073761463
Epoch:  22  	Training Loss: 0.016908694058656693
Test Loss:  0.008709236979484558
Valid Loss:  0.009842142462730408
Epoch:  23  	Training Loss: 0.014546090736985207
Test Loss:  0.008778335526585579
Valid Loss:  0.008827353827655315
Epoch:  24  	Training Loss: 0.012171277776360512
Test Loss:  0.006963793188333511
Valid Loss:  0.008655658923089504
Epoch:  25  	Training Loss: 0.010557056404650211
Test Loss:  0.007865523919463158
Valid Loss:  0.007960567250847816
Epoch:  26  	Training Loss: 0.010010563768446445
Test Loss:  0.006016555242240429
Valid Loss:  0.008753446862101555
Epoch:  27  	Training Loss: 0.009900318458676338
Test Loss:  0.008866006508469582
Valid Loss:  0.0075233932584524155
Epoch:  28  	Training Loss: 0.010185263119637966
Test Loss:  0.005927578546106815
Valid Loss:  0.010460108518600464
Epoch:  29  	Training Loss: 0.011359410360455513
Test Loss:  0.014734608121216297
Valid Loss:  0.009820700623095036
Epoch:  30  	Training Loss: 0.014290926977992058
Test Loss:  0.011525409296154976
Valid Loss:  0.019849229604005814
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.021134283393621445
Test Loss:  0.005733403377234936
Valid Loss:  0.0069168442860245705
Epoch:  32  	Training Loss: 0.0098341079428792
Test Loss:  0.0060507310554385185
Valid Loss:  0.006562362425029278
Epoch:  33  	Training Loss: 0.009491991251707077
Test Loss:  0.005835357122123241
Valid Loss:  0.006492870859801769
Epoch:  34  	Training Loss: 0.00931583158671856
Test Loss:  0.0057175434194505215
Valid Loss:  0.00641458248719573
Epoch:  35  	Training Loss: 0.009188717231154442
Test Loss:  0.005631720647215843
Valid Loss:  0.006349788513034582
Epoch:  36  	Training Loss: 0.0090972650796175
Test Loss:  0.005548716522753239
Valid Loss:  0.00628677848726511
Epoch:  37  	Training Loss: 0.009026646614074707
Test Loss:  0.005479771178215742
Valid Loss:  0.0062252916395664215
Epoch:  38  	Training Loss: 0.008966265246272087
Test Loss:  0.005410675425082445
Valid Loss:  0.006166327744722366
Epoch:  39  	Training Loss: 0.008911294862627983
Test Loss:  0.005359591916203499
Valid Loss:  0.006111787166446447
Epoch:  40  	Training Loss: 0.008858935907483101
Test Loss:  0.005309245549142361
Valid Loss:  0.006061256397515535
Epoch:  41  	Training Loss: 0.008807926438748837
Test Loss:  0.005269631743431091
Valid Loss:  0.006016822066158056
Epoch:  42  	Training Loss: 0.00875864177942276
Test Loss:  0.005544925108551979
Valid Loss:  0.005938678048551083
Epoch:  43  	Training Loss: 0.00865110382437706
Test Loss:  0.005454245023429394
Valid Loss:  0.005968880373984575
Epoch:  44  	Training Loss: 0.008561277762055397
Test Loss:  0.005463367328047752
Valid Loss:  0.005976717919111252
Epoch:  45  	Training Loss: 0.008479026146233082
Test Loss:  0.0054412418976426125
Valid Loss:  0.005990126170217991
Epoch:  46  	Training Loss: 0.008399972692131996
Test Loss:  0.0054194447584450245
Valid Loss:  0.006002116948366165
Epoch:  47  	Training Loss: 0.00832332018762827
Test Loss:  0.005394682288169861
Valid Loss:  0.006005643401294947
Epoch:  48  	Training Loss: 0.008242398500442505
Test Loss:  0.005370825529098511
Valid Loss:  0.0059995949268341064
Epoch:  49  	Training Loss: 0.0081541258841753
Test Loss:  0.005340655334293842
Valid Loss:  0.005993049591779709
Epoch:  50  	Training Loss: 0.008069956675171852
Test Loss:  0.00532620819285512
Valid Loss:  0.005983689334243536
Epoch:  51  	Training Loss: 0.007986576296389103
Test Loss:  0.005326270125806332
Valid Loss:  0.005975029431283474
Epoch:  52  	Training Loss: 0.007909085601568222
Test Loss:  0.005370748229324818
Valid Loss:  0.00596950389444828
Epoch:  53  	Training Loss: 0.007837063632905483
Test Loss:  0.005364241544157267
Valid Loss:  0.005994892679154873
Epoch:  54  	Training Loss: 0.007790183648467064
Test Loss:  0.005350129213184118
Valid Loss:  0.006004601716995239
Epoch:  55  	Training Loss: 0.0077590253204107285
Test Loss:  0.005346496589481831
Valid Loss:  0.006008397322148085
Epoch:  56  	Training Loss: 0.007732058875262737
Test Loss:  0.005322078708559275
Valid Loss:  0.006004893220961094
Epoch:  57  	Training Loss: 0.0077150920405983925
Test Loss:  0.0053072297014296055
Valid Loss:  0.005991470068693161
Epoch:  58  	Training Loss: 0.007700572721660137
Test Loss:  0.005292943678796291
Valid Loss:  0.005985022522509098
Epoch:  59  	Training Loss: 0.007687509059906006
Test Loss:  0.005281043238937855
Valid Loss:  0.005972676910459995
Epoch:  60  	Training Loss: 0.007676273584365845
Test Loss:  0.005271359346807003
Valid Loss:  0.005959062837064266
Epoch:  61  	Training Loss: 0.0076654162257909775
Test Loss:  0.00526136439293623
Valid Loss:  0.005945709068328142
Epoch:  62  	Training Loss: 0.007654920686036348
Test Loss:  0.0049501145258545876
Valid Loss:  0.005864211358129978
Epoch:  63  	Training Loss: 0.007300343830138445
Test Loss:  0.004868080839514732
Valid Loss:  0.005706394091248512
Epoch:  64  	Training Loss: 0.006998513359576464
Test Loss:  0.00472511351108551
Valid Loss:  0.005588139407336712
Epoch:  65  	Training Loss: 0.006731828209012747
Test Loss:  0.0046263644471764565
Valid Loss:  0.005449836142361164
Epoch:  66  	Training Loss: 0.0065107569098472595
Test Loss:  0.004536406137049198
Valid Loss:  0.005314819980412722
Epoch:  67  	Training Loss: 0.006343272980302572
Test Loss:  0.004461127799004316
Valid Loss:  0.005170507822185755
Epoch:  68  	Training Loss: 0.0061967745423316956
Test Loss:  0.004368407651782036
Valid Loss:  0.005042672157287598
Epoch:  69  	Training Loss: 0.006064129993319511
Test Loss:  0.004282589070498943
Valid Loss:  0.004917008802294731
Epoch:  70  	Training Loss: 0.005937885493040085
Test Loss:  0.004216447472572327
Valid Loss:  0.004786395933479071
 14%|█▍        | 71/500 [01:01<08:31,  1.19s/it] 15%|█▍        | 73/500 [01:01<06:05,  1.17it/s] 15%|█▌        | 75/500 [01:01<04:23,  1.61it/s] 15%|█▌        | 77/500 [01:02<03:11,  2.21it/s] 16%|█▌        | 79/500 [01:02<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:08<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:08<05:59,  1.16it/s] 17%|█▋        | 85/500 [01:08<04:21,  1.59it/s] 17%|█▋        | 87/500 [01:09<03:12,  2.15it/s] 18%|█▊        | 89/500 [01:09<02:22,  2.89it/s] 18%|█▊        | 91/500 [01:15<08:18,  1.22s/it] 19%|█▊        | 93/500 [01:15<05:55,  1.14it/s] 19%|█▉        | 95/500 [01:15<04:15,  1.58it/s] 19%|█▉        | 97/500 [01:16<03:05,  2.17it/s] 20%|█▉        | 99/500 [01:16<02:17,  2.92it/s] 20%|██        | 101/500 [01:22<08:07,  1.22s/it] 21%|██        | 103/500 [01:22<05:48,  1.14it/s] 21%|██        | 105/500 [01:23<04:10,  1.58it/s] 21%|██▏       | 107/500 [01:23<03:02,  2.16it/s] 22%|██▏       | 109/500 [01:23<02:17,  2.85it/s] 22%|██▏       | 111/500 [01:29<07:48,  1.20s/it] 23%|██▎       | 113/500 [01:29<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:30<04:04,  1.58it/s] 23%|██▎       | 117/500 [01:30<03:00,  2.13it/s] 24%|██▍       | 119/500 [01:30<02:15,  2.81it/s] 24%|██▍       | 121/500 [01:36<07:38,  1.21s/it] 25%|██▍       | 123/500 [01:37<05:27,  1.15it/s] 25%|██▌       | 125/500 [01:37<03:55,  1.59it/s] 25%|██▌       | 127/500 [01:37<02:51,  2.18it/s] 26%|██▌       | 129/500 [01:37<02:07,  2.92it/s] 26%|██▌       | 131/500 [01:43<07:31,  1.22s/it] 27%|██▋       | 133/500 [01:44<05:22,  1.14it/s] 27%|██▋       | 135/500 [01:44<03:51,  1.57it/s] 27%|██▋       | 137/500 [01:44<02:48,  2.16it/s] 28%|██▊       | 139/500 [01:44<02:04,  2.90it/s]Epoch:  71  	Training Loss: 0.005816566292196512
Test Loss:  0.004123827442526817
Valid Loss:  0.004667375702410936
Epoch:  72  	Training Loss: 0.005700853653252125
Test Loss:  0.003996315877884626
Valid Loss:  0.0045287348330020905
Epoch:  73  	Training Loss: 0.005578013136982918
Test Loss:  0.0038825373630970716
Valid Loss:  0.004393968731164932
Epoch:  74  	Training Loss: 0.0054661184549331665
Test Loss:  0.0037973159924149513
Valid Loss:  0.004283299669623375
Epoch:  75  	Training Loss: 0.005384598858654499
Test Loss:  0.003723242785781622
Valid Loss:  0.004185908008366823
Epoch:  76  	Training Loss: 0.005312718451023102
Test Loss:  0.003656232263892889
Valid Loss:  0.004097118508070707
Epoch:  77  	Training Loss: 0.0052479165606200695
Test Loss:  0.0035927146673202515
Valid Loss:  0.004015728365629911
Epoch:  78  	Training Loss: 0.005187417380511761
Test Loss:  0.003532608039677143
Valid Loss:  0.003940049558877945
Epoch:  79  	Training Loss: 0.005130358971655369
Test Loss:  0.0034759168047457933
Valid Loss:  0.0038737081922590733
Epoch:  80  	Training Loss: 0.005077340640127659
Test Loss:  0.003424625378102064
Valid Loss:  0.0038465040270239115
Epoch:  81  	Training Loss: 0.0050308736972510815
Test Loss:  0.003375951899215579
Valid Loss:  0.003785930573940277
Epoch:  82  	Training Loss: 0.004985755309462547
Test Loss:  0.003188374452292919
Valid Loss:  0.0037404815666377544
Epoch:  83  	Training Loss: 0.004772741347551346
Test Loss:  0.0031548466067761183
Valid Loss:  0.0035803269129246473
Epoch:  84  	Training Loss: 0.004590525291860104
Test Loss:  0.003051943611353636
Valid Loss:  0.0035172647330909967
Epoch:  85  	Training Loss: 0.004423728212714195
Test Loss:  0.00303397374227643
Valid Loss:  0.003363291034474969
Epoch:  86  	Training Loss: 0.004288094118237495
Test Loss:  0.002971373964101076
Valid Loss:  0.0033301622606813908
Epoch:  87  	Training Loss: 0.004185322672128677
Test Loss:  0.0029765507206320763
Valid Loss:  0.003220225917175412
Epoch:  88  	Training Loss: 0.004106511361896992
Test Loss:  0.0029305608477443457
Valid Loss:  0.0032039510551840067
Epoch:  89  	Training Loss: 0.004035111516714096
Test Loss:  0.002931739669293165
Valid Loss:  0.0031158975325524807
Epoch:  90  	Training Loss: 0.003968474920839071
Test Loss:  0.002875541802495718
Valid Loss:  0.0030944999307394028
Epoch:  91  	Training Loss: 0.003909810446202755
Test Loss:  0.0028621298260986805
Valid Loss:  0.003023102879524231
Epoch:  92  	Training Loss: 0.0038565299473702908
Test Loss:  0.002869818825274706
Valid Loss:  0.0029599755071103573
Epoch:  93  	Training Loss: 0.0037915289867669344
Test Loss:  0.002803307957947254
Valid Loss:  0.002913782373070717
Epoch:  94  	Training Loss: 0.0037383653689175844
Test Loss:  0.002836198080331087
Valid Loss:  0.0028832012321799994
Epoch:  95  	Training Loss: 0.003686759155243635
Test Loss:  0.0027177005540579557
Valid Loss:  0.002837532665580511
Epoch:  96  	Training Loss: 0.0036121115554124117
Test Loss:  0.0026906190905719995
Valid Loss:  0.002786600962281227
Epoch:  97  	Training Loss: 0.003558977972716093
Test Loss:  0.0026867741253226995
Valid Loss:  0.0027553029358386993
Epoch:  98  	Training Loss: 0.003512011840939522
Test Loss:  0.0026092668995261192
Valid Loss:  0.0027177061419934034
Epoch:  99  	Training Loss: 0.0034619125071913004
Test Loss:  0.002649191999807954
Valid Loss:  0.0026939124800264835
Epoch:  100  	Training Loss: 0.0034208977594971657
Test Loss:  0.0025297077372670174
Valid Loss:  0.0026521869003772736
Epoch:  101  	Training Loss: 0.003347823629155755
Test Loss:  0.002496704924851656
Valid Loss:  0.0026032445020973682
Epoch:  102  	Training Loss: 0.0032983783166855574
Test Loss:  0.002479325048625469
Valid Loss:  0.002577671315521002
Epoch:  103  	Training Loss: 0.0032685999758541584
Test Loss:  0.0024616762530058622
Valid Loss:  0.0025529563426971436
Epoch:  104  	Training Loss: 0.0032395326998084784
Test Loss:  0.002442839089781046
Valid Loss:  0.0025290469639003277
Epoch:  105  	Training Loss: 0.0032112309709191322
Test Loss:  0.002422846620902419
Valid Loss:  0.002505677053704858
Epoch:  106  	Training Loss: 0.0031830971129238605
Test Loss:  0.0024035340175032616
Valid Loss:  0.0024826410226523876
Epoch:  107  	Training Loss: 0.0031546438112854958
Test Loss:  0.0023841040674597025
Valid Loss:  0.0024600732140243053
Epoch:  108  	Training Loss: 0.0031267073936760426
Test Loss:  0.002364739775657654
Valid Loss:  0.0024378825910389423
Epoch:  109  	Training Loss: 0.003098746296018362
Test Loss:  0.002344249514862895
Valid Loss:  0.0024159266613423824
Epoch:  110  	Training Loss: 0.003070503706112504
Test Loss:  0.002324142027646303
Valid Loss:  0.0023942780680954456
Epoch:  111  	Training Loss: 0.0030419155955314636
Test Loss:  0.0023043067194521427
Valid Loss:  0.0023734201677143574
Epoch:  112  	Training Loss: 0.003013599431142211
Test Loss:  0.002213213127106428
Valid Loss:  0.002321776235476136
Epoch:  113  	Training Loss: 0.002966456115245819
Test Loss:  0.0021500117145478725
Valid Loss:  0.002244553528726101
Epoch:  114  	Training Loss: 0.002939672442153096
Test Loss:  0.0021020914427936077
Valid Loss:  0.0022017068695276976
Epoch:  115  	Training Loss: 0.002917742356657982
Test Loss:  0.0020769862458109856
Valid Loss:  0.0021407827734947205
Epoch:  116  	Training Loss: 0.0028985287062823772
Test Loss:  0.0020469301380217075
Valid Loss:  0.0021051159128546715
Epoch:  117  	Training Loss: 0.002880358835682273
Test Loss:  0.0020230626687407494
Valid Loss:  0.0020688974764198065
Epoch:  118  	Training Loss: 0.0028639151714742184
Test Loss:  0.0020030089654028416
Valid Loss:  0.0020296270959079266
Epoch:  119  	Training Loss: 0.002848424483090639
Test Loss:  0.001980359433218837
Valid Loss:  0.0020081503316760063
Epoch:  120  	Training Loss: 0.002833617152646184
Test Loss:  0.001967682968825102
Valid Loss:  0.0019698755349963903
Epoch:  121  	Training Loss: 0.002818912733346224
Test Loss:  0.0019462667405605316
Valid Loss:  0.001956379506736994
Epoch:  122  	Training Loss: 0.0028046672232449055
Test Loss:  0.001957228407263756
Valid Loss:  0.0019305093446746469
Epoch:  123  	Training Loss: 0.00277498597279191
Test Loss:  0.001966677373275161
Valid Loss:  0.0019135545007884502
Epoch:  124  	Training Loss: 0.002748042345046997
Test Loss:  0.001975594088435173
Valid Loss:  0.0019022026099264622
Epoch:  125  	Training Loss: 0.002722074743360281
Test Loss:  0.0019822814501821995
Valid Loss:  0.0018949003424495459
Epoch:  126  	Training Loss: 0.00269989762455225
Test Loss:  0.001987111521884799
Valid Loss:  0.001889739534817636
Epoch:  127  	Training Loss: 0.0026800280902534723
Test Loss:  0.001991300145164132
Valid Loss:  0.0018818298121914268
Epoch:  128  	Training Loss: 0.0026609767228364944
Test Loss:  0.001994290854781866
Valid Loss:  0.0018739559454843402
Epoch:  129  	Training Loss: 0.002644151449203491
Test Loss:  0.0019960275385528803
Valid Loss:  0.001867201877757907
Epoch:  130  	Training Loss: 0.0026290081441402435
Test Loss:  0.00199683615937829
Valid Loss:  0.001859885174781084
Epoch:  131  	Training Loss: 0.002615357283502817
Test Loss:  0.0019966186955571175
Valid Loss:  0.0018533669644966722
Epoch:  132  	Training Loss: 0.0026027737185359
Test Loss:  0.0019293648656457663
Valid Loss:  0.0018236630130559206
Epoch:  133  	Training Loss: 0.002564638387411833
Test Loss:  0.00188030197750777
Valid Loss:  0.0018004309386014938
Epoch:  134  	Training Loss: 0.0025323512963950634
Test Loss:  0.0018427178729325533
Valid Loss:  0.0017792999278753996
Epoch:  135  	Training Loss: 0.002502598101273179
Test Loss:  0.0018130021635442972
Valid Loss:  0.0017601633444428444
Epoch:  136  	Training Loss: 0.002473826054483652
Test Loss:  0.0017852431628853083
Valid Loss:  0.0017395967151969671
Epoch:  137  	Training Loss: 0.00244457577355206
Test Loss:  0.0017591501818969846
Valid Loss:  0.001723782392218709
Epoch:  138  	Training Loss: 0.00241554225794971
Test Loss:  0.0017365465173497796
Valid Loss:  0.0017045482527464628
Epoch:  139  	Training Loss: 0.0023860307410359383
Test Loss:  0.0017147848848253489
Valid Loss:  0.0016893529100343585
Epoch:  140  	Training Loss: 0.0023542791604995728
 28%|██▊       | 141/500 [01:51<07:19,  1.22s/it] 29%|██▊       | 143/500 [01:51<05:13,  1.14it/s] 29%|██▉       | 145/500 [01:51<03:45,  1.57it/s] 29%|██▉       | 147/500 [01:51<02:43,  2.15it/s] 30%|██▉       | 149/500 [01:51<02:01,  2.90it/s] 30%|███       | 151/500 [01:58<07:08,  1.23s/it] 31%|███       | 153/500 [01:58<05:07,  1.13it/s] 31%|███       | 155/500 [01:58<03:42,  1.55it/s] 31%|███▏      | 157/500 [01:58<02:43,  2.09it/s] 32%|███▏      | 159/500 [01:58<02:02,  2.78it/s] 32%|███▏      | 161/500 [02:05<07:00,  1.24s/it] 33%|███▎      | 163/500 [02:05<05:00,  1.12it/s] 33%|███▎      | 165/500 [02:05<03:35,  1.56it/s] 33%|███▎      | 167/500 [02:05<02:36,  2.13it/s] 34%|███▍      | 169/500 [02:06<01:55,  2.86it/s] 34%|███▍      | 171/500 [02:12<06:44,  1.23s/it] 35%|███▍      | 173/500 [02:12<04:48,  1.13it/s] 35%|███▌      | 175/500 [02:12<03:27,  1.57it/s] 35%|███▌      | 177/500 [02:13<02:31,  2.14it/s] 36%|███▌      | 179/500 [02:13<01:51,  2.87it/s] 36%|███▌      | 181/500 [02:19<06:27,  1.22s/it] 37%|███▋      | 183/500 [02:19<04:37,  1.14it/s] 37%|███▋      | 185/500 [02:19<03:19,  1.58it/s] 37%|███▋      | 187/500 [02:20<02:24,  2.16it/s] 38%|███▊      | 189/500 [02:20<01:46,  2.91it/s] 38%|███▊      | 191/500 [02:26<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:26<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:26<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:27<02:19,  2.17it/s] 40%|███▉      | 199/500 [02:27<01:42,  2.93it/s] 40%|████      | 201/500 [02:33<05:56,  1.19s/it] 41%|████      | 203/500 [02:33<04:15,  1.16it/s] 41%|████      | 205/500 [02:33<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:34<02:16,  2.15it/s]Test Loss:  0.0016937153413891792
Valid Loss:  0.0016702754655852914
Epoch:  141  	Training Loss: 0.002322687767446041
Test Loss:  0.0016723298467695713
Valid Loss:  0.0016567459097132087
Epoch:  142  	Training Loss: 0.0022886621300131083
Test Loss:  0.0016107216943055391
Valid Loss:  0.0016356894047930837
Epoch:  143  	Training Loss: 0.0022573850583285093
Test Loss:  0.0015748237492516637
Valid Loss:  0.0016075358726084232
Epoch:  144  	Training Loss: 0.0022305482998490334
Test Loss:  0.0015470527578145266
Valid Loss:  0.001579771749675274
Epoch:  145  	Training Loss: 0.00220487080514431
Test Loss:  0.0015232147416099906
Valid Loss:  0.0015540048480033875
Epoch:  146  	Training Loss: 0.0021791146136820316
Test Loss:  0.0015024347230792046
Valid Loss:  0.001531863585114479
Epoch:  147  	Training Loss: 0.002152067609131336
Test Loss:  0.0014833977911621332
Valid Loss:  0.0015113226836547256
Epoch:  148  	Training Loss: 0.0021241619251668453
Test Loss:  0.001465261448174715
Valid Loss:  0.0014922182308509946
Epoch:  149  	Training Loss: 0.0020913623739033937
Test Loss:  0.0014479972887784243
Valid Loss:  0.0014732189010828733
Epoch:  150  	Training Loss: 0.002054007491096854
Test Loss:  0.0014300509355962276
Valid Loss:  0.0014495219802483916
Epoch:  151  	Training Loss: 0.0020124202128499746
Test Loss:  0.0014114824589341879
Valid Loss:  0.0014241309836506844
Epoch:  152  	Training Loss: 0.001971828518435359
Test Loss:  0.001390221412293613
Valid Loss:  0.0014110681368038058
Epoch:  153  	Training Loss: 0.001952869351953268
Test Loss:  0.0013769774232059717
Valid Loss:  0.0013961620861664414
Epoch:  154  	Training Loss: 0.0019345341715961695
Test Loss:  0.0013617320219054818
Valid Loss:  0.0013818861916661263
Epoch:  155  	Training Loss: 0.001916585024446249
Test Loss:  0.0013464707881212234
Valid Loss:  0.001367688295431435
Epoch:  156  	Training Loss: 0.0018987616058439016
Test Loss:  0.0013317284174263477
Valid Loss:  0.0013519837521016598
Epoch:  157  	Training Loss: 0.0018806788139045238
Test Loss:  0.0013167046708986163
Valid Loss:  0.001336540444754064
Epoch:  158  	Training Loss: 0.0018629778642207384
Test Loss:  0.0013019226025789976
Valid Loss:  0.0013213054044172168
Epoch:  159  	Training Loss: 0.0018456528196111321
Test Loss:  0.0012874116655439138
Valid Loss:  0.0013062921352684498
Epoch:  160  	Training Loss: 0.0018286958802491426
Test Loss:  0.00127317663282156
Valid Loss:  0.001291500637307763
Epoch:  161  	Training Loss: 0.0018121465109288692
Test Loss:  0.0012601928319782019
Valid Loss:  0.00127717899158597
Epoch:  162  	Training Loss: 0.0017960239201784134
Test Loss:  0.001252272049896419
Valid Loss:  0.0012683122185990214
Epoch:  163  	Training Loss: 0.0017717129085212946
Test Loss:  0.0012431275099515915
Valid Loss:  0.0012593389255926013
Epoch:  164  	Training Loss: 0.0017494712956249714
Test Loss:  0.001232221140526235
Valid Loss:  0.001251096953637898
Epoch:  165  	Training Loss: 0.001728822709992528
Test Loss:  0.0012208822881802917
Valid Loss:  0.00124287698417902
Epoch:  166  	Training Loss: 0.001709294505417347
Test Loss:  0.001210005022585392
Valid Loss:  0.0012343088164925575
Epoch:  167  	Training Loss: 0.001689510652795434
Test Loss:  0.001196916913613677
Valid Loss:  0.0012256725458428264
Epoch:  168  	Training Loss: 0.0016696006059646606
Test Loss:  0.0011834204196929932
Valid Loss:  0.0012166089145466685
Epoch:  169  	Training Loss: 0.0016482179053127766
Test Loss:  0.0011697504669427872
Valid Loss:  0.0012075724080204964
Epoch:  170  	Training Loss: 0.00162635394372046
Test Loss:  0.0011561713181436062
Valid Loss:  0.0011985653545707464
Epoch:  171  	Training Loss: 0.0016044112853705883
Test Loss:  0.0011399936629459262
Valid Loss:  0.0011895494535565376
Epoch:  172  	Training Loss: 0.0015828923787921667
Test Loss:  0.0010989431757479906
Valid Loss:  0.001146451337262988
Epoch:  173  	Training Loss: 0.001527777872979641
Test Loss:  0.001060784561559558
Valid Loss:  0.0011068449821323156
Epoch:  174  	Training Loss: 0.0014732866548001766
Test Loss:  0.0010252450592815876
Valid Loss:  0.0010704046580940485
Epoch:  175  	Training Loss: 0.0014208980137482285
Test Loss:  0.000991214532405138
Valid Loss:  0.0010366897331550717
Epoch:  176  	Training Loss: 0.0013705724850296974
Test Loss:  0.0009594879811629653
Valid Loss:  0.0010051054414361715
Epoch:  177  	Training Loss: 0.001320061506703496
Test Loss:  0.0009288798319175839
Valid Loss:  0.0009753598715178668
Epoch:  178  	Training Loss: 0.0012693008175119758
Test Loss:  0.0008991042850539088
Valid Loss:  0.0009474226390011609
Epoch:  179  	Training Loss: 0.0012199720367789268
Test Loss:  0.0008701660553924739
Valid Loss:  0.0009209566051140428
Epoch:  180  	Training Loss: 0.001172222662717104
Test Loss:  0.0008429698646068573
Valid Loss:  0.0008964925655163825
Epoch:  181  	Training Loss: 0.0011269740061834455
Test Loss:  0.0008135598036460578
Valid Loss:  0.0008718420285731554
Epoch:  182  	Training Loss: 0.001082514994777739
Test Loss:  0.0007758988649584353
Valid Loss:  0.0008664336055517197
Epoch:  183  	Training Loss: 0.0010699109407141805
Test Loss:  0.0007597537478432059
Valid Loss:  0.0008507538586854935
Epoch:  184  	Training Loss: 0.001061771996319294
Test Loss:  0.0007478634361177683
Valid Loss:  0.0008354465244337916
Epoch:  185  	Training Loss: 0.0010546466801315546
Test Loss:  0.0007378979935310781
Valid Loss:  0.0008218534057959914
Epoch:  186  	Training Loss: 0.0010482512880116701
Test Loss:  0.000729195075109601
Valid Loss:  0.0008098466787487268
Epoch:  187  	Training Loss: 0.0010423690546303988
Test Loss:  0.0007222524145618081
Valid Loss:  0.000798673601821065
Epoch:  188  	Training Loss: 0.0010370928794145584
Test Loss:  0.0007156172068789601
Valid Loss:  0.0007891477434895933
Epoch:  189  	Training Loss: 0.0010321764275431633
Test Loss:  0.0007095603505149484
Valid Loss:  0.0007806542562320828
Epoch:  190  	Training Loss: 0.001027534483000636
Test Loss:  0.0007057219627313316
Valid Loss:  0.000772049359511584
Epoch:  191  	Training Loss: 0.001023368095047772
Test Loss:  0.0007011829293332994
Valid Loss:  0.0007649185135960579
Epoch:  192  	Training Loss: 0.0010194398928433657
Test Loss:  0.0007076642941683531
Valid Loss:  0.0007623287965543568
Epoch:  193  	Training Loss: 0.001016212860122323
Test Loss:  0.0007079907227307558
Valid Loss:  0.0007609918829984963
Epoch:  194  	Training Loss: 0.0010136148193851113
Test Loss:  0.0007066830294206738
Valid Loss:  0.0007596317445859313
Epoch:  195  	Training Loss: 0.001011198852211237
Test Loss:  0.0007047204417176545
Valid Loss:  0.0007579982047900558
Epoch:  196  	Training Loss: 0.0010087670525535941
Test Loss:  0.0007026383536867797
Valid Loss:  0.0007560430094599724
Epoch:  197  	Training Loss: 0.00100623513571918
Test Loss:  0.0007000681362114847
Valid Loss:  0.0007539215730503201
Epoch:  198  	Training Loss: 0.001003775279968977
Test Loss:  0.0006973724812269211
Valid Loss:  0.0007516341283917427
Epoch:  199  	Training Loss: 0.0010013780556619167
Test Loss:  0.0006946410867385566
Valid Loss:  0.0007492106524296105
Epoch:  200  	Training Loss: 0.000999032985419035
Test Loss:  0.0006918831495568156
Valid Loss:  0.0007466743118129671
Epoch:  201  	Training Loss: 0.0009967315709218383
Test Loss:  0.0006890862714499235
Valid Loss:  0.0007440479239448905
Epoch:  202  	Training Loss: 0.0009943874320015311
Test Loss:  0.000689016655087471
Valid Loss:  0.0007331009837798774
Epoch:  203  	Training Loss: 0.0009798542596399784
Test Loss:  0.0006845319294370711
Valid Loss:  0.0007250886410474777
Epoch:  204  	Training Loss: 0.0009650045540183783
Test Loss:  0.0006777106318622828
Valid Loss:  0.0007185933645814657
Epoch:  205  	Training Loss: 0.0009512067190371454
Test Loss:  0.0006700480589643121
Valid Loss:  0.0007127762073650956
Epoch:  206  	Training Loss: 0.0009382000425830483
Test Loss:  0.0006620328058488667
Valid Loss:  0.0007073562010191381
Epoch:  207  	Training Loss: 0.0009259131620638072
Test Loss:  0.0006550444522872567
Valid Loss:  0.0007022309582680464
Epoch:  208  	Training Loss: 0.0009143888019025326
Test Loss:  0.0006475807749666274
Valid Loss:  0.0006971945404075086
 42%|████▏     | 209/500 [02:34<01:42,  2.85it/s] 42%|████▏     | 211/500 [02:40<05:52,  1.22s/it] 43%|████▎     | 213/500 [02:40<04:10,  1.14it/s] 43%|████▎     | 215/500 [02:40<02:59,  1.58it/s] 43%|████▎     | 217/500 [02:41<02:10,  2.17it/s] 44%|████▍     | 219/500 [02:41<01:36,  2.92it/s] 44%|████▍     | 221/500 [02:47<05:41,  1.22s/it] 45%|████▍     | 223/500 [02:47<04:02,  1.14it/s] 45%|████▌     | 225/500 [02:48<02:54,  1.58it/s] 45%|████▌     | 227/500 [02:48<02:06,  2.16it/s] 46%|████▌     | 229/500 [02:48<01:33,  2.90it/s] 46%|████▌     | 231/500 [02:54<05:27,  1.22s/it] 47%|████▋     | 233/500 [02:54<03:53,  1.14it/s] 47%|████▋     | 235/500 [02:55<02:47,  1.58it/s] 47%|████▋     | 237/500 [02:55<02:01,  2.16it/s] 48%|████▊     | 239/500 [02:55<01:29,  2.91it/s] 48%|████▊     | 241/500 [03:01<05:18,  1.23s/it] 49%|████▊     | 243/500 [03:02<03:48,  1.13it/s] 49%|████▉     | 245/500 [03:02<02:44,  1.55it/s] 49%|████▉     | 247/500 [03:02<01:58,  2.13it/s] 50%|████▉     | 249/500 [03:02<01:27,  2.87it/s] 50%|█████     | 251/500 [03:09<05:00,  1.21s/it] 51%|█████     | 253/500 [03:09<03:35,  1.15it/s] 51%|█████     | 255/500 [03:09<02:34,  1.59it/s] 51%|█████▏    | 257/500 [03:09<01:51,  2.17it/s] 52%|█████▏    | 259/500 [03:09<01:22,  2.93it/s] 52%|█████▏    | 261/500 [03:15<04:47,  1.20s/it] 53%|█████▎    | 263/500 [03:16<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:16<02:26,  1.60it/s] 53%|█████▎    | 267/500 [03:16<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:16<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:23<04:38,  1.22s/it] 55%|█████▍    | 273/500 [03:23<03:18,  1.14it/s] 55%|█████▌    | 275/500 [03:23<02:22,  1.58it/s]Epoch:  209  	Training Loss: 0.0009029206703417003
Test Loss:  0.0006409694324247539
Valid Loss:  0.0006922621978446841
Epoch:  210  	Training Loss: 0.0008915327489376068
Test Loss:  0.0006339011597447097
Valid Loss:  0.00068735919194296
Epoch:  211  	Training Loss: 0.0008805989054962993
Test Loss:  0.000626772060059011
Valid Loss:  0.0006823297590017319
Epoch:  212  	Training Loss: 0.0008691371767781675
Test Loss:  0.0006008812924847007
Valid Loss:  0.0006811702041886747
Epoch:  213  	Training Loss: 0.0008519947296008468
Test Loss:  0.0005895913345739245
Valid Loss:  0.0006743820267729461
Epoch:  214  	Training Loss: 0.000837214756757021
Test Loss:  0.0005798040074296296
Valid Loss:  0.0006670787115581334
Epoch:  215  	Training Loss: 0.0008231807150878012
Test Loss:  0.0005704163340851665
Valid Loss:  0.0006598389009013772
Epoch:  216  	Training Loss: 0.0008096219971776009
Test Loss:  0.0005614984547719359
Valid Loss:  0.0006527241785079241
Epoch:  217  	Training Loss: 0.0007960260845720768
Test Loss:  0.0005527051980607212
Valid Loss:  0.0006458238931372762
Epoch:  218  	Training Loss: 0.000783064984716475
Test Loss:  0.0005441889516077936
Valid Loss:  0.0006390469498001039
Epoch:  219  	Training Loss: 0.0007706932374276221
Test Loss:  0.0005359450588002801
Valid Loss:  0.0006323911948129535
Epoch:  220  	Training Loss: 0.0007588292937725782
Test Loss:  0.0005277951713651419
Valid Loss:  0.0006265515694394708
Epoch:  221  	Training Loss: 0.0007468959083780646
Test Loss:  0.0005203267792239785
Valid Loss:  0.0006205459358170629
Epoch:  222  	Training Loss: 0.0007355003617703915
Test Loss:  0.0005078927497379482
Valid Loss:  0.0006019979482516646
Epoch:  223  	Training Loss: 0.0007147663272917271
Test Loss:  0.000494105857796967
Valid Loss:  0.0005872189067304134
Epoch:  224  	Training Loss: 0.0006950701936148107
Test Loss:  0.0004817734588868916
Valid Loss:  0.0005737401079386473
Epoch:  225  	Training Loss: 0.0006746287690475583
Test Loss:  0.00047007057582959533
Valid Loss:  0.0005613084649667144
Epoch:  226  	Training Loss: 0.0006541851325891912
Test Loss:  0.0004592259938362986
Valid Loss:  0.0005495490040630102
Epoch:  227  	Training Loss: 0.0006335749058052897
Test Loss:  0.00044836505549028516
Valid Loss:  0.0005388782592490315
Epoch:  228  	Training Loss: 0.0006134128198027611
Test Loss:  0.0004380684986244887
Valid Loss:  0.0005288876709528267
Epoch:  229  	Training Loss: 0.0005942183779552579
Test Loss:  0.0004282375448383391
Valid Loss:  0.0005194206023588777
Epoch:  230  	Training Loss: 0.000575095706153661
Test Loss:  0.0004187305166851729
Valid Loss:  0.0005106267635710537
Epoch:  231  	Training Loss: 0.0005569473723880947
Test Loss:  0.00040971662383526564
Valid Loss:  0.0005023107514716685
Epoch:  232  	Training Loss: 0.0005397209897637367
Test Loss:  0.00040390907088294625
Valid Loss:  0.0004886010428890586
Epoch:  233  	Training Loss: 0.0005211516981944442
Test Loss:  0.0003923308977391571
Valid Loss:  0.00047682898002676666
Epoch:  234  	Training Loss: 0.0005030833417549729
Test Loss:  0.0003808019100688398
Valid Loss:  0.0004662384162656963
Epoch:  235  	Training Loss: 0.000485650118207559
Test Loss:  0.0003713521873578429
Valid Loss:  0.0004568240256048739
Epoch:  236  	Training Loss: 0.0004694173694588244
Test Loss:  0.0003609354898799211
Valid Loss:  0.00044847631943412125
Epoch:  237  	Training Loss: 0.00045403820695355535
Test Loss:  0.00035283429315313697
Valid Loss:  0.00044075975893065333
Epoch:  238  	Training Loss: 0.0004396419390104711
Test Loss:  0.00034264312125742435
Valid Loss:  0.0004339312727097422
Epoch:  239  	Training Loss: 0.00042567888158373535
Test Loss:  0.00033416191581636667
Valid Loss:  0.00042706579552032053
Epoch:  240  	Training Loss: 0.000412650202633813
Test Loss:  0.00032604963053017855
Valid Loss:  0.00041904387762770057
Epoch:  241  	Training Loss: 0.00040032080141827464
Test Loss:  0.0003183049557264894
Valid Loss:  0.0004111707385163754
Epoch:  242  	Training Loss: 0.00038864611997269094
Test Loss:  0.00030638911994174123
Valid Loss:  0.0004135562339797616
Epoch:  243  	Training Loss: 0.00038129440508782864
Test Loss:  0.0003036757407244295
Valid Loss:  0.0004083743551746011
Epoch:  244  	Training Loss: 0.0003749437164515257
Test Loss:  0.00029943109257146716
Valid Loss:  0.00040419260039925575
Epoch:  245  	Training Loss: 0.0003688725410029292
Test Loss:  0.00029522442491725087
Valid Loss:  0.0003999399486929178
Epoch:  246  	Training Loss: 0.00036296466714702547
Test Loss:  0.0002911492483690381
Valid Loss:  0.0003955571446567774
Epoch:  247  	Training Loss: 0.0003565627848729491
Test Loss:  0.0002870185417123139
Valid Loss:  0.00039139098953455687
Epoch:  248  	Training Loss: 0.0003504296764731407
Test Loss:  0.00028301699785515666
Valid Loss:  0.0003872570814564824
Epoch:  249  	Training Loss: 0.0003445433685556054
Test Loss:  0.00027912226505577564
Valid Loss:  0.00038317631697282195
Epoch:  250  	Training Loss: 0.00033888895995914936
Test Loss:  0.0002752482541836798
Valid Loss:  0.0003791513154283166
Epoch:  251  	Training Loss: 0.00033346813870593905
Test Loss:  0.0002711251436267048
Valid Loss:  0.00037486437940970063
Epoch:  252  	Training Loss: 0.00032825686503201723
Test Loss:  0.0002668122760951519
Valid Loss:  0.0003703372203744948
Epoch:  253  	Training Loss: 0.0003231310402043164
Test Loss:  0.0002628808142617345
Valid Loss:  0.00036616247962228954
Epoch:  254  	Training Loss: 0.0003182494838256389
Test Loss:  0.0002593341050669551
Valid Loss:  0.00036220726906321943
Epoch:  255  	Training Loss: 0.00031304522417485714
Test Loss:  0.00025579973589628935
Valid Loss:  0.00035863538505509496
Epoch:  256  	Training Loss: 0.00030806518043391407
Test Loss:  0.0002523501461837441
Valid Loss:  0.0003553858259692788
Epoch:  257  	Training Loss: 0.0003032910171896219
Test Loss:  0.00024893079535104334
Valid Loss:  0.00035236033727414906
Epoch:  258  	Training Loss: 0.000298692611977458
Test Loss:  0.0002455934009049088
Valid Loss:  0.000349503563484177
Epoch:  259  	Training Loss: 0.0002942612627521157
Test Loss:  0.00024236782337538898
Valid Loss:  0.0003467881469987333
Epoch:  260  	Training Loss: 0.00028994030435569584
Test Loss:  0.00023940100800246
Valid Loss:  0.00034415090340189636
Epoch:  261  	Training Loss: 0.0002854392514564097
Test Loss:  0.0002364591637160629
Valid Loss:  0.0003416268737055361
Epoch:  262  	Training Loss: 0.0002809219586197287
Test Loss:  0.00023122386483009905
Valid Loss:  0.00034074438735842705
Epoch:  263  	Training Loss: 0.00027951240190304816
Test Loss:  0.0002292901190230623
Valid Loss:  0.0003382459399290383
Epoch:  264  	Training Loss: 0.00027862051501870155
Test Loss:  0.00022803647152613848
Valid Loss:  0.00033557950519025326
Epoch:  265  	Training Loss: 0.0002778332564048469
Test Loss:  0.00022699078544974327
Valid Loss:  0.0003330439794808626
Epoch:  266  	Training Loss: 0.00027711960137821734
Test Loss:  0.00022605097910854965
Valid Loss:  0.00033067306503653526
Epoch:  267  	Training Loss: 0.00027646718081086874
Test Loss:  0.00022518771584145725
Valid Loss:  0.0003284589038230479
Epoch:  268  	Training Loss: 0.00027586513897404075
Test Loss:  0.0002243865601485595
Valid Loss:  0.00032638193806633353
Epoch:  269  	Training Loss: 0.00027531053638085723
Test Loss:  0.00022387118951883167
Valid Loss:  0.0003243776736781001
Epoch:  270  	Training Loss: 0.00027482828591018915
Test Loss:  0.0002232342812931165
Valid Loss:  0.0003225840046070516
Epoch:  271  	Training Loss: 0.00027437726384960115
Test Loss:  0.00022260365949478
Valid Loss:  0.00032090628519654274
Epoch:  272  	Training Loss: 0.00027395051438361406
Test Loss:  0.00022082831128500402
Valid Loss:  0.00031650124583393335
Epoch:  273  	Training Loss: 0.00026858330238610506
Test Loss:  0.00021732127061113715
Valid Loss:  0.00031303989817388356
Epoch:  274  	Training Loss: 0.00026344548678025603
Test Loss:  0.00021404243307188153
Valid Loss:  0.0003095061401836574
Epoch:  275  	Training Loss: 0.00025824265321716666
Test Loss:  0.00021083946921862662
Valid Loss:  0.0003058836446143687
Epoch:  276  	Training Loss: 0.00025250203907489777
Test Loss:  0.0002076418895740062
 55%|█████▌    | 277/500 [03:23<01:42,  2.17it/s] 56%|█████▌    | 279/500 [03:23<01:15,  2.92it/s] 56%|█████▌    | 281/500 [03:30<04:26,  1.22s/it] 57%|█████▋    | 283/500 [03:30<03:09,  1.14it/s] 57%|█████▋    | 285/500 [03:30<02:15,  1.58it/s] 57%|█████▋    | 287/500 [03:30<01:38,  2.17it/s] 58%|█████▊    | 289/500 [03:30<01:12,  2.91it/s] 58%|█████▊    | 291/500 [03:37<04:11,  1.21s/it] 59%|█████▊    | 293/500 [03:37<02:59,  1.16it/s] 59%|█████▉    | 295/500 [03:37<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:37<01:33,  2.18it/s] 60%|█████▉    | 299/500 [03:37<01:08,  2.92it/s] 60%|██████    | 301/500 [03:44<04:04,  1.23s/it] 61%|██████    | 303/500 [03:44<02:53,  1.14it/s] 61%|██████    | 305/500 [03:44<02:04,  1.57it/s] 61%|██████▏   | 307/500 [03:44<01:29,  2.15it/s] 62%|██████▏   | 309/500 [03:44<01:05,  2.89it/s] 62%|██████▏   | 311/500 [03:51<03:49,  1.21s/it] 63%|██████▎   | 313/500 [03:51<02:42,  1.15it/s] 63%|██████▎   | 315/500 [03:51<01:56,  1.59it/s] 63%|██████▎   | 317/500 [03:51<01:24,  2.18it/s] 64%|██████▍   | 319/500 [03:51<01:01,  2.93it/s] 64%|██████▍   | 321/500 [03:58<03:33,  1.20s/it] 65%|██████▍   | 323/500 [03:58<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:58<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:58<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:58<00:57,  2.97it/s] 66%|██████▌   | 331/500 [04:05<03:25,  1.21s/it] 67%|██████▋   | 333/500 [04:05<02:25,  1.15it/s] 67%|██████▋   | 335/500 [04:05<01:43,  1.59it/s] 67%|██████▋   | 337/500 [04:05<01:15,  2.15it/s] 68%|██████▊   | 339/500 [04:05<00:56,  2.85it/s] 68%|██████▊   | 341/500 [04:12<03:15,  1.23s/it]Valid Loss:  0.00030240777414292097
Epoch:  277  	Training Loss: 0.00024707597913220525
Test Loss:  0.00020451899035833776
Valid Loss:  0.00029884668765589595
Epoch:  278  	Training Loss: 0.00024193669378291816
Test Loss:  0.00020096104708500206
Valid Loss:  0.0002948499459307641
Epoch:  279  	Training Loss: 0.0002369272115174681
Test Loss:  0.00019699556287378073
Valid Loss:  0.0002909200557041913
Epoch:  280  	Training Loss: 0.00023200247960630804
Test Loss:  0.00019314471865072846
Valid Loss:  0.0002871291362680495
Epoch:  281  	Training Loss: 0.00022732379147782922
Test Loss:  0.00018946257478091866
Valid Loss:  0.0002834509941749275
Epoch:  282  	Training Loss: 0.00022287678439170122
Test Loss:  0.00018710280710365623
Valid Loss:  0.00027971435338258743
Epoch:  283  	Training Loss: 0.00021887361072003841
Test Loss:  0.0001841639750637114
Valid Loss:  0.0002761540818028152
Epoch:  284  	Training Loss: 0.0002150683430954814
Test Loss:  0.0001812474220059812
Valid Loss:  0.0002728567342273891
Epoch:  285  	Training Loss: 0.00021141592878848314
Test Loss:  0.00017833479796536267
Valid Loss:  0.00026972536579705775
Epoch:  286  	Training Loss: 0.00020788618712686002
Test Loss:  0.00017552936333231628
Valid Loss:  0.0002667112275958061
Epoch:  287  	Training Loss: 0.00020446507551241666
Test Loss:  0.00017281394684687257
Valid Loss:  0.000263811758486554
Epoch:  288  	Training Loss: 0.00020117270469199866
Test Loss:  0.0001701997680356726
Valid Loss:  0.0002610154915601015
Epoch:  289  	Training Loss: 0.00019791227532550693
Test Loss:  0.00016765427426435053
Valid Loss:  0.00025825598277151585
Epoch:  290  	Training Loss: 0.00019460577459540218
Test Loss:  0.00016514534945599735
Valid Loss:  0.0002555519458837807
Epoch:  291  	Training Loss: 0.0001912725856527686
Test Loss:  0.0001627061137696728
Valid Loss:  0.0002529537887312472
Epoch:  292  	Training Loss: 0.0001880702911876142
Test Loss:  0.00015928407083265483
Valid Loss:  0.0002521593705751002
Epoch:  293  	Training Loss: 0.00018728796567302197
Test Loss:  0.00015908165369182825
Valid Loss:  0.00025015740538947284
Epoch:  294  	Training Loss: 0.000186781253432855
Test Loss:  0.00015854039520490915
Valid Loss:  0.00024853795184753835
Epoch:  295  	Training Loss: 0.0001863452635006979
Test Loss:  0.00015810801414772868
Valid Loss:  0.0002470478939358145
Epoch:  296  	Training Loss: 0.0001859643671195954
Test Loss:  0.00015771252219565213
Valid Loss:  0.0002456892980262637
Epoch:  297  	Training Loss: 0.00018562801415100694
Test Loss:  0.0001573539339005947
Valid Loss:  0.000244445342104882
Epoch:  298  	Training Loss: 0.00018532777903601527
Test Loss:  0.0001570245949551463
Valid Loss:  0.00024329902953468263
Epoch:  299  	Training Loss: 0.00018505722982808948
Test Loss:  0.0001567213039379567
Valid Loss:  0.00024223857326433063
Epoch:  300  	Training Loss: 0.00018481102597434074
Test Loss:  0.0001564375270390883
Valid Loss:  0.0002412533067399636
Epoch:  301  	Training Loss: 0.00018458579143043607
Test Loss:  0.00015617140161339194
Valid Loss:  0.00024033170484472066
Epoch:  302  	Training Loss: 0.0001843888167059049
Test Loss:  0.00015620142221450806
Valid Loss:  0.0002387405838817358
Epoch:  303  	Training Loss: 0.00018395214283373207
Test Loss:  0.00015592094860039651
Valid Loss:  0.0002374837640672922
Epoch:  304  	Training Loss: 0.000183553303941153
Test Loss:  0.0001556066854391247
Valid Loss:  0.0002363871899433434
Epoch:  305  	Training Loss: 0.00018318166257813573
Test Loss:  0.00015530620294157416
Valid Loss:  0.00023540100664831698
Epoch:  306  	Training Loss: 0.0001828301465138793
Test Loss:  0.00015502268797717988
Valid Loss:  0.00023450309527106583
Epoch:  307  	Training Loss: 0.00018249390996061265
Test Loss:  0.00015475490363314748
Valid Loss:  0.00023366653476841748
Epoch:  308  	Training Loss: 0.00018216879107058048
Test Loss:  0.0001545200211694464
Valid Loss:  0.00023289088858291507
Epoch:  309  	Training Loss: 0.00018185270891990513
Test Loss:  0.00015432444342877716
Valid Loss:  0.00023216602858155966
Epoch:  310  	Training Loss: 0.0001815438736230135
Test Loss:  0.00015413554501719773
Valid Loss:  0.00023148462059907615
Epoch:  311  	Training Loss: 0.00018124042253475636
Test Loss:  0.00015395405353046954
Valid Loss:  0.00023083880660124123
Epoch:  312  	Training Loss: 0.00018094174447469413
Test Loss:  0.00015160773182287812
Valid Loss:  0.0002266464871354401
Epoch:  313  	Training Loss: 0.0001731400261633098
Test Loss:  0.0001472216536058113
Valid Loss:  0.00022344427998177707
Epoch:  314  	Training Loss: 0.00016654611681587994
Test Loss:  0.0001435445446986705
Valid Loss:  0.0002203108451794833
Epoch:  315  	Training Loss: 0.000160708004841581
Test Loss:  0.00014028347504790872
Valid Loss:  0.000217318520299159
Epoch:  316  	Training Loss: 0.00015555278514511883
Test Loss:  0.0001373031991533935
Valid Loss:  0.00021443612058646977
Epoch:  317  	Training Loss: 0.00015094800619408488
Test Loss:  0.00013462165952660143
Valid Loss:  0.00021163908240851015
Epoch:  318  	Training Loss: 0.00014681037282571197
Test Loss:  0.00013214987120591104
Valid Loss:  0.00020893465261906385
Epoch:  319  	Training Loss: 0.00014305599324870855
Test Loss:  0.00012984070053789765
Valid Loss:  0.00020630017388612032
Epoch:  320  	Training Loss: 0.00013960030628368258
Test Loss:  0.00012770688044838607
Valid Loss:  0.00020360926282592118
Epoch:  321  	Training Loss: 0.0001363465707981959
Test Loss:  0.00012573345156852156
Valid Loss:  0.00020087993470951915
Epoch:  322  	Training Loss: 0.00013324874453246593
Test Loss:  0.00012517970753833652
Valid Loss:  0.00019880264881066978
Epoch:  323  	Training Loss: 0.00013247737661004066
Test Loss:  0.0001246797328349203
Valid Loss:  0.00019703185535036027
Epoch:  324  	Training Loss: 0.0001318385184276849
Test Loss:  0.00012427328329067677
Valid Loss:  0.00019546994008123875
Epoch:  325  	Training Loss: 0.00013130471052136272
Test Loss:  0.00012394177610985935
Valid Loss:  0.00019408050866331905
Epoch:  326  	Training Loss: 0.0001308549544773996
Test Loss:  0.00012367311865091324
Valid Loss:  0.00019283682922832668
Epoch:  327  	Training Loss: 0.00013047238462604582
Test Loss:  0.0001234544615726918
Valid Loss:  0.00019171388703398407
Epoch:  328  	Training Loss: 0.00013014314754400402
Test Loss:  0.00012327554577495903
Valid Loss:  0.00019069253175985068
Epoch:  329  	Training Loss: 0.0001298570423386991
Test Loss:  0.00012312838225625455
Valid Loss:  0.0001897580223158002
Epoch:  330  	Training Loss: 0.0001296049013035372
Test Loss:  0.00012300896923989058
Valid Loss:  0.00018889724742621183
Epoch:  331  	Training Loss: 0.00012937987048644572
Test Loss:  0.00012291045277379453
Valid Loss:  0.0001880984054878354
Epoch:  332  	Training Loss: 0.00012919155415147543
Test Loss:  0.00012227155093569309
Valid Loss:  0.00018647836986929178
Epoch:  333  	Training Loss: 0.00012720102677121758
Test Loss:  0.00012123864144086838
Valid Loss:  0.00018501831800676882
Epoch:  334  	Training Loss: 0.00012527918443083763
Test Loss:  0.00012016591063002124
Valid Loss:  0.00018362376431468874
Epoch:  335  	Training Loss: 0.0001234874944202602
Test Loss:  0.0001191408300655894
Valid Loss:  0.00018226233078166842
Epoch:  336  	Training Loss: 0.0001218054021592252
Test Loss:  0.0001181792322313413
Valid Loss:  0.00018088713113684207
Epoch:  337  	Training Loss: 0.00012022188457194716
Test Loss:  0.00011727788660209626
Valid Loss:  0.00017933480557985604
Epoch:  338  	Training Loss: 0.00011872760660480708
Test Loss:  0.00011643297330010682
Valid Loss:  0.0001778178266249597
Epoch:  339  	Training Loss: 0.000117314382805489
Test Loss:  0.00011563708540052176
Valid Loss:  0.00017633571405895054
Epoch:  340  	Training Loss: 0.00011597638513194397
Test Loss:  0.00011488983000162989
Valid Loss:  0.00017489437595941126
Epoch:  341  	Training Loss: 0.00011470894241938367
Test Loss:  0.00011418151552788913
Valid Loss:  0.00017349363770335913
Epoch:  342  	Training Loss: 0.00011350495333317667
Test Loss:  0.00011339311458868906
Valid Loss:  0.0001711794757284224
Epoch:  343  	Training Loss: 0.00011153276136610657
Test Loss:  0.00011230702511966228
Valid Loss:   69%|██████▊   | 343/500 [04:12<02:18,  1.14it/s] 69%|██████▉   | 345/500 [04:12<01:38,  1.57it/s] 69%|██████▉   | 347/500 [04:12<01:11,  2.15it/s] 70%|██████▉   | 349/500 [04:12<00:52,  2.90it/s] 70%|███████   | 351/500 [04:19<02:57,  1.19s/it] 71%|███████   | 353/500 [04:19<02:05,  1.17it/s] 71%|███████   | 355/500 [04:19<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:19<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:19<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:26<02:50,  1.22s/it] 73%|███████▎  | 363/500 [04:26<02:00,  1.13it/s] 73%|███████▎  | 365/500 [04:26<01:26,  1.57it/s] 73%|███████▎  | 367/500 [04:26<01:02,  2.14it/s] 74%|███████▍  | 369/500 [04:26<00:45,  2.89it/s] 74%|███████▍  | 371/500 [04:33<02:35,  1.21s/it] 75%|███████▍  | 373/500 [04:33<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:33<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:33<00:56,  2.17it/s] 76%|███████▌  | 379/500 [04:33<00:41,  2.92it/s] 76%|███████▌  | 381/500 [04:40<02:27,  1.24s/it] 77%|███████▋  | 383/500 [04:40<01:43,  1.13it/s] 77%|███████▋  | 385/500 [04:40<01:13,  1.56it/s] 77%|███████▋  | 387/500 [04:40<00:52,  2.13it/s] 78%|███████▊  | 389/500 [04:41<00:38,  2.85it/s] 78%|███████▊  | 391/500 [04:47<02:12,  1.22s/it] 79%|███████▊  | 393/500 [04:47<01:34,  1.14it/s] 79%|███████▉  | 395/500 [04:47<01:06,  1.57it/s] 79%|███████▉  | 397/500 [04:48<00:47,  2.15it/s] 80%|███████▉  | 399/500 [04:48<00:34,  2.89it/s] 80%|████████  | 401/500 [04:54<01:58,  1.20s/it] 81%|████████  | 403/500 [04:54<01:24,  1.15it/s] 81%|████████  | 405/500 [04:54<01:00,  1.58it/s] 81%|████████▏ | 407/500 [04:55<00:43,  2.13it/s] 82%|████████▏ | 409/500 [04:55<00:32,  2.81it/s]0.00016921033966355026
Epoch:  344  	Training Loss: 0.00010975531040458009
Test Loss:  0.00011126587924081832
Valid Loss:  0.00016735278768464923
Epoch:  345  	Training Loss: 0.00010808614024426788
Test Loss:  0.00011029060988221318
Valid Loss:  0.00016554733156226575
Epoch:  346  	Training Loss: 0.00010649822070263326
Test Loss:  0.00010938793275272474
Valid Loss:  0.0001638113462831825
Epoch:  347  	Training Loss: 0.00010502849181648344
Test Loss:  0.0001085563053493388
Valid Loss:  0.0001621536212041974
Epoch:  348  	Training Loss: 0.00010366497735958546
Test Loss:  0.00010778952128021047
Valid Loss:  0.00016053474973887205
Epoch:  349  	Training Loss: 0.00010239687253488228
Test Loss:  0.00010708011541282758
Valid Loss:  0.00015892781084403396
Epoch:  350  	Training Loss: 0.00010121687228092924
Test Loss:  0.00010642212873790413
Valid Loss:  0.0001573943009134382
Epoch:  351  	Training Loss: 0.00010009761899709702
Test Loss:  0.00010579757508821785
Valid Loss:  0.0001559084194013849
Epoch:  352  	Training Loss: 9.902837336994708e-05
Test Loss:  0.00010489289707038552
Valid Loss:  0.00015509068907704204
Epoch:  353  	Training Loss: 9.806060552364215e-05
Test Loss:  0.00010451097477925941
Valid Loss:  0.00015418915427289903
Epoch:  354  	Training Loss: 9.726526332087815e-05
Test Loss:  0.00010419650061521679
Valid Loss:  0.00015329441521316767
Epoch:  355  	Training Loss: 9.652473090682179e-05
Test Loss:  0.00010389310773462057
Valid Loss:  0.0001524363033240661
Epoch:  356  	Training Loss: 9.582172788213938e-05
Test Loss:  0.0001035936875268817
Valid Loss:  0.00015161819464992732
Epoch:  357  	Training Loss: 9.51559777604416e-05
Test Loss:  0.0001032943109748885
Valid Loss:  0.00015083518519531935
Epoch:  358  	Training Loss: 9.45212523220107e-05
Test Loss:  0.0001029921550070867
Valid Loss:  0.00015008030459284782
Epoch:  359  	Training Loss: 9.391196363139898e-05
Test Loss:  0.0001026665122481063
Valid Loss:  0.0001493157324148342
Epoch:  360  	Training Loss: 9.328326268587261e-05
Test Loss:  0.00010232964268652722
Valid Loss:  0.00014858139911666512
Epoch:  361  	Training Loss: 9.26764914765954e-05
Test Loss:  0.00010199254029430449
Valid Loss:  0.00014789160923101008
Epoch:  362  	Training Loss: 9.209131530951709e-05
Test Loss:  0.00010197334631811827
Valid Loss:  0.00014714011922478676
Epoch:  363  	Training Loss: 9.158119792118669e-05
Test Loss:  0.0001017403046716936
Valid Loss:  0.00014656440180260688
Epoch:  364  	Training Loss: 9.11063834792003e-05
Test Loss:  0.00010144658881472424
Valid Loss:  0.00014604580064769834
Epoch:  365  	Training Loss: 9.064738696906716e-05
Test Loss:  0.00010114731412613764
Valid Loss:  0.00014554914378095418
Epoch:  366  	Training Loss: 9.020262223202735e-05
Test Loss:  0.00010085433314088732
Valid Loss:  0.0001450669951736927
Epoch:  367  	Training Loss: 8.977171091828495e-05
Test Loss:  0.00010057100735139102
Valid Loss:  0.00014459804515354335
Epoch:  368  	Training Loss: 8.935357618611306e-05
Test Loss:  0.00010029537952505052
Valid Loss:  0.00014415229088626802
Epoch:  369  	Training Loss: 8.895206701708958e-05
Test Loss:  9.99563344521448e-05
Valid Loss:  0.0001437353785149753
Epoch:  370  	Training Loss: 8.857517968863249e-05
Test Loss:  9.966487414203584e-05
Valid Loss:  0.00014330977865029126
Epoch:  371  	Training Loss: 8.821010123938322e-05
Test Loss:  9.939429583027959e-05
Valid Loss:  0.00014288884995039552
Epoch:  372  	Training Loss: 8.784823148744181e-05
Test Loss:  9.900859731715173e-05
Valid Loss:  0.00014276924775913358
Epoch:  373  	Training Loss: 8.775013702688739e-05
Test Loss:  9.888902422972023e-05
Valid Loss:  0.00014258403098210692
Epoch:  374  	Training Loss: 8.766568498685956e-05
Test Loss:  9.878705168375745e-05
Valid Loss:  0.00014239337178878486
Epoch:  375  	Training Loss: 8.757903560763225e-05
Test Loss:  9.866716573014855e-05
Valid Loss:  0.00014219367585610598
Epoch:  376  	Training Loss: 8.74862598720938e-05
Test Loss:  9.853442315943539e-05
Valid Loss:  0.00014199978613760322
Epoch:  377  	Training Loss: 8.739471377339214e-05
Test Loss:  9.840072016231716e-05
Valid Loss:  0.0001418062747688964
Epoch:  378  	Training Loss: 8.73039971338585e-05
Test Loss:  9.826765744946897e-05
Valid Loss:  0.0001415957376593724
Epoch:  379  	Training Loss: 8.721407357370481e-05
Test Loss:  9.813433280214667e-05
Valid Loss:  0.0001413829013472423
Epoch:  380  	Training Loss: 8.712463022675365e-05
Test Loss:  9.800046973396093e-05
Valid Loss:  0.00014117546379566193
Epoch:  381  	Training Loss: 8.703579806024209e-05
Test Loss:  9.786730515770614e-05
Valid Loss:  0.0001409925753250718
Epoch:  382  	Training Loss: 8.694254938745871e-05
Test Loss:  9.774317732080817e-05
Valid Loss:  0.0001403294299961999
Epoch:  383  	Training Loss: 8.640924352221191e-05
Test Loss:  9.759271779330447e-05
Valid Loss:  0.0001397166633978486
Epoch:  384  	Training Loss: 8.590669312980026e-05
Test Loss:  9.742580004967749e-05
Valid Loss:  0.0001391396945109591
Epoch:  385  	Training Loss: 8.543019066564739e-05
Test Loss:  9.724863048177212e-05
Valid Loss:  0.0001385915238643065
Epoch:  386  	Training Loss: 8.497521048411727e-05
Test Loss:  9.70581459114328e-05
Valid Loss:  0.00013806900824420154
Epoch:  387  	Training Loss: 8.454141789115965e-05
Test Loss:  9.693554602563381e-05
Valid Loss:  0.00013755704276263714
Epoch:  388  	Training Loss: 8.412871102336794e-05
Test Loss:  9.674392640590668e-05
Valid Loss:  0.0001370963582303375
Epoch:  389  	Training Loss: 8.373332093469799e-05
Test Loss:  9.654980385676026e-05
Valid Loss:  0.00013665811275132
Epoch:  390  	Training Loss: 8.335415623150766e-05
Test Loss:  9.635651804273948e-05
Valid Loss:  0.0001362359762424603
Epoch:  391  	Training Loss: 8.298983448185027e-05
Test Loss:  9.616422903491184e-05
Valid Loss:  0.00013582785322796553
Epoch:  392  	Training Loss: 8.263892232207581e-05
Test Loss:  9.601576311979443e-05
Valid Loss:  0.00013540999498218298
Epoch:  393  	Training Loss: 8.237427391577512e-05
Test Loss:  9.586985834175721e-05
Valid Loss:  0.00013503669470082968
Epoch:  394  	Training Loss: 8.213805267587304e-05
Test Loss:  9.572548151481897e-05
Valid Loss:  0.00013469974510371685
Epoch:  395  	Training Loss: 8.192294626496732e-05
Test Loss:  9.558306192047894e-05
Valid Loss:  0.0001343913609161973
Epoch:  396  	Training Loss: 8.172432717401534e-05
Test Loss:  9.544235217617825e-05
Valid Loss:  0.00013410681276582181
Epoch:  397  	Training Loss: 8.153806265909225e-05
Test Loss:  9.530245006317273e-05
Valid Loss:  0.00013383958139456809
Epoch:  398  	Training Loss: 8.136380347423255e-05
Test Loss:  9.516467252979055e-05
Valid Loss:  0.0001335895067313686
Epoch:  399  	Training Loss: 8.11981299193576e-05
Test Loss:  9.502873581368476e-05
Valid Loss:  0.0001333540421910584
Epoch:  400  	Training Loss: 8.104037260636687e-05
Test Loss:  9.489642980042845e-05
Valid Loss:  0.00013312821101862937
Epoch:  401  	Training Loss: 8.08903350844048e-05
Test Loss:  9.477412095293403e-05
Valid Loss:  0.00013291349750943482
Epoch:  402  	Training Loss: 8.074737706920132e-05
Test Loss:  9.396245877724141e-05
Valid Loss:  0.00013274457887746394
Epoch:  403  	Training Loss: 8.043178968364373e-05
Test Loss:  9.365545702166855e-05
Valid Loss:  0.00013250703341327608
Epoch:  404  	Training Loss: 8.022889232961461e-05
Test Loss:  9.350237087346613e-05
Valid Loss:  0.0001322301832260564
Epoch:  405  	Training Loss: 8.00460547907278e-05
Test Loss:  9.340020187664777e-05
Valid Loss:  0.00013194084749557078
Epoch:  406  	Training Loss: 7.987247954588383e-05
Test Loss:  9.331315231975168e-05
Valid Loss:  0.00013165813288651407
Epoch:  407  	Training Loss: 7.970695151016116e-05
Test Loss:  9.322900586994365e-05
Valid Loss:  0.00013137992937117815
Epoch:  408  	Training Loss: 7.954906322993338e-05
Test Loss:  9.314570343121886e-05
Valid Loss:  0.00013110815780237317
Epoch:  409  	Training Loss: 7.93978979345411e-05
Test Loss:  9.306127321906388e-05
Valid Loss:  0.00013086535909678787
Epoch:  410  	Training Loss: 7.925128738861531e-05
Test Loss:  9.297906944993883e-05
Valid Loss:  0.00013062905054539442
Epoch:  411  	Training Loss: 7.910920248832554e-05
Test Loss:   82%|████████▏ | 411/500 [05:01<01:48,  1.22s/it] 83%|████████▎ | 413/500 [05:01<01:16,  1.14it/s] 83%|████████▎ | 415/500 [05:02<00:54,  1.56it/s] 83%|████████▎ | 417/500 [05:02<00:39,  2.10it/s] 84%|████████▍ | 419/500 [05:02<00:29,  2.78it/s] 84%|████████▍ | 421/500 [05:08<01:36,  1.22s/it] 85%|████████▍ | 423/500 [05:09<01:07,  1.14it/s] 85%|████████▌ | 425/500 [05:09<00:48,  1.55it/s] 85%|████████▌ | 427/500 [05:09<00:34,  2.12it/s] 86%|████████▌ | 429/500 [05:09<00:24,  2.85it/s] 86%|████████▌ | 431/500 [05:15<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:16<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:16<00:41,  1.58it/s] 87%|████████▋ | 437/500 [05:16<00:29,  2.13it/s] 88%|████████▊ | 439/500 [05:16<00:21,  2.81it/s] 88%|████████▊ | 441/500 [05:22<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:23<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:23<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:23<00:24,  2.18it/s] 90%|████████▉ | 449/500 [05:23<00:17,  2.92it/s] 90%|█████████ | 451/500 [05:29<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:30<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:30<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:30<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:30<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:37<00:47,  1.23s/it] 93%|█████████▎| 463/500 [05:37<00:32,  1.13it/s] 93%|█████████▎| 465/500 [05:37<00:22,  1.56it/s] 93%|█████████▎| 467/500 [05:37<00:15,  2.11it/s] 94%|█████████▍| 469/500 [05:37<00:11,  2.79it/s] 94%|█████████▍| 471/500 [05:44<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:44<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:44<00:15,  1.59it/s] 95%|█████████▌| 477/500 [05:44<00:10,  2.17it/s]9.290073649026453e-05
Valid Loss:  0.00013039782061241567
Epoch:  412  	Training Loss: 7.897143223090097e-05
Test Loss:  9.262806997867301e-05
Valid Loss:  0.00013002405466977507
Epoch:  413  	Training Loss: 7.860700134187937e-05
Test Loss:  9.239005157724023e-05
Valid Loss:  0.0001296208065468818
Epoch:  414  	Training Loss: 7.824836211511865e-05
Test Loss:  9.213519660988823e-05
Valid Loss:  0.00012921473535243422
Epoch:  415  	Training Loss: 7.789476512698457e-05
Test Loss:  9.199441410601139e-05
Valid Loss:  0.00012878557026851922
Epoch:  416  	Training Loss: 7.755709521006793e-05
Test Loss:  9.175999730359763e-05
Valid Loss:  0.00012840195267926902
Epoch:  417  	Training Loss: 7.722514419583604e-05
Test Loss:  9.151076665148139e-05
Valid Loss:  0.00012802451965399086
Epoch:  418  	Training Loss: 7.689818448852748e-05
Test Loss:  9.124838106799871e-05
Valid Loss:  0.00012765009887516499
Epoch:  419  	Training Loss: 7.657635433133692e-05
Test Loss:  9.098114969674498e-05
Valid Loss:  0.00012727914145216346
Epoch:  420  	Training Loss: 7.625903526786715e-05
Test Loss:  9.070616215467453e-05
Valid Loss:  0.00012691198207903653
Epoch:  421  	Training Loss: 7.594633643748239e-05
Test Loss:  9.042855526786298e-05
Valid Loss:  0.0001265494793187827
Epoch:  422  	Training Loss: 7.563940016552806e-05
Test Loss:  9.015544492285699e-05
Valid Loss:  0.00012628079275600612
Epoch:  423  	Training Loss: 7.538111822213978e-05
Test Loss:  8.989097841549665e-05
Valid Loss:  0.0001260159770026803
Epoch:  424  	Training Loss: 7.512542651966214e-05
Test Loss:  8.962774882093072e-05
Valid Loss:  0.0001257451222045347
Epoch:  425  	Training Loss: 7.486743561457843e-05
Test Loss:  8.936796803027391e-05
Valid Loss:  0.00012548266386147588
Epoch:  426  	Training Loss: 7.461504719685763e-05
Test Loss:  8.911421173252165e-05
Valid Loss:  0.00012522554607130587
Epoch:  427  	Training Loss: 7.436806481564417e-05
Test Loss:  8.886799332685769e-05
Valid Loss:  0.00012497279385570437
Epoch:  428  	Training Loss: 7.412592822220176e-05
Test Loss:  8.862518734531477e-05
Valid Loss:  0.0001247247855644673
Epoch:  429  	Training Loss: 7.38875096431002e-05
Test Loss:  8.838494250085205e-05
Valid Loss:  0.0001244721352122724
Epoch:  430  	Training Loss: 7.364805060205981e-05
Test Loss:  8.814774628262967e-05
Valid Loss:  0.00012422942381817847
Epoch:  431  	Training Loss: 7.341644231928512e-05
Test Loss:  8.791615255177021e-05
Valid Loss:  0.0001239810953848064
Epoch:  432  	Training Loss: 7.318139250855893e-05
Test Loss:  8.761913341004401e-05
Valid Loss:  0.00012359042011667043
Epoch:  433  	Training Loss: 7.293571252375841e-05
Test Loss:  8.726021042093635e-05
Valid Loss:  0.00012326319119893014
Epoch:  434  	Training Loss: 7.271277718245983e-05
Test Loss:  8.69108407641761e-05
Valid Loss:  0.0001229611225426197
Epoch:  435  	Training Loss: 7.250654743984342e-05
Test Loss:  8.658574370201677e-05
Valid Loss:  0.00012267555575817823
Epoch:  436  	Training Loss: 7.231357449200004e-05
Test Loss:  8.628027717350051e-05
Valid Loss:  0.0001224021689267829
Epoch:  437  	Training Loss: 7.213307253550738e-05
Test Loss:  8.59946885611862e-05
Valid Loss:  0.00012214241723995656
Epoch:  438  	Training Loss: 7.196758815553039e-05
Test Loss:  8.573188097216189e-05
Valid Loss:  0.00012190030247438699
Epoch:  439  	Training Loss: 7.181838736869395e-05
Test Loss:  8.548634650651366e-05
Valid Loss:  0.00012166626402176917
Epoch:  440  	Training Loss: 7.167678268160671e-05
Test Loss:  8.525473094778135e-05
Valid Loss:  0.00012143878120696172
Epoch:  441  	Training Loss: 7.154147169785574e-05
Test Loss:  8.503497519996017e-05
Valid Loss:  0.00012121805048082024
Epoch:  442  	Training Loss: 7.141275273170322e-05
Test Loss:  8.520865230821073e-05
Valid Loss:  0.00012110641546314582
Epoch:  443  	Training Loss: 7.13109620846808e-05
Test Loss:  8.535556116839871e-05
Valid Loss:  0.0001210253540193662
Epoch:  444  	Training Loss: 7.122671377146617e-05
Test Loss:  8.54806785355322e-05
Valid Loss:  0.00012096447608200833
Epoch:  445  	Training Loss: 7.115656626410782e-05
Test Loss:  8.559039997635409e-05
Valid Loss:  0.0001209175752592273
Epoch:  446  	Training Loss: 7.109728903742507e-05
Test Loss:  8.568703924538568e-05
Valid Loss:  0.00012088198127457872
Epoch:  447  	Training Loss: 7.104696851456538e-05
Test Loss:  8.577387779951096e-05
Valid Loss:  0.00012085311027476564
Epoch:  448  	Training Loss: 7.100396032910794e-05
Test Loss:  8.585155592299998e-05
Valid Loss:  0.00012082993634976447
Epoch:  449  	Training Loss: 7.096740591805428e-05
Test Loss:  8.592272934038192e-05
Valid Loss:  0.00012080987653462216
Epoch:  450  	Training Loss: 7.093558087944984e-05
Test Loss:  8.598668500781059e-05
Valid Loss:  0.00012079344742232934
Epoch:  451  	Training Loss: 7.090762665029615e-05
Test Loss:  8.60451182234101e-05
Valid Loss:  0.00012077883002348244
Epoch:  452  	Training Loss: 7.088340498739854e-05
Test Loss:  8.591488585807383e-05
Valid Loss:  0.00012044799950672314
Epoch:  453  	Training Loss: 7.067693513818085e-05
Test Loss:  8.569993951823562e-05
Valid Loss:  0.00012019011774100363
Epoch:  454  	Training Loss: 7.048045517876744e-05
Test Loss:  8.547048491891474e-05
Valid Loss:  0.00011995091335847974
Epoch:  455  	Training Loss: 7.029245898593217e-05
Test Loss:  8.524728764314204e-05
Valid Loss:  0.00011973154323641211
Epoch:  456  	Training Loss: 7.011676643742248e-05
Test Loss:  8.50295036798343e-05
Valid Loss:  0.00011951585474889725
Epoch:  457  	Training Loss: 6.994508294155821e-05
Test Loss:  8.481617987854406e-05
Valid Loss:  0.00011930079199373722
Epoch:  458  	Training Loss: 6.977596058277413e-05
Test Loss:  8.460399112664163e-05
Valid Loss:  0.00011908754822798073
Epoch:  459  	Training Loss: 6.960851897019893e-05
Test Loss:  8.439305383944884e-05
Valid Loss:  0.00011887703294632956
Epoch:  460  	Training Loss: 6.944380584172904e-05
Test Loss:  8.418539073318243e-05
Valid Loss:  0.00011866864224430174
Epoch:  461  	Training Loss: 6.92843459546566e-05
Test Loss:  8.39792046463117e-05
Valid Loss:  0.00011846278357552364
Epoch:  462  	Training Loss: 6.912920071044937e-05
Test Loss:  8.378848724532872e-05
Valid Loss:  0.00011850234295707196
Epoch:  463  	Training Loss: 6.91114182700403e-05
Test Loss:  8.379474456887692e-05
Valid Loss:  0.00011847672431031242
Epoch:  464  	Training Loss: 6.910077354405075e-05
Test Loss:  8.381738734897226e-05
Valid Loss:  0.00011844725668197498
Epoch:  465  	Training Loss: 6.909100920893252e-05
Test Loss:  8.383845124626532e-05
Valid Loss:  0.00011841664672829211
Epoch:  466  	Training Loss: 6.90814558765851e-05
Test Loss:  8.385904948227108e-05
Valid Loss:  0.00011838752834592015
Epoch:  467  	Training Loss: 6.907249917276204e-05
Test Loss:  8.387779234908521e-05
Valid Loss:  0.0001183596978080459
Epoch:  468  	Training Loss: 6.90635060891509e-05
Test Loss:  8.389484719373286e-05
Valid Loss:  0.00011833121970994398
Epoch:  469  	Training Loss: 6.905489135533571e-05
Test Loss:  8.391028677579015e-05
Valid Loss:  0.00011830363655462861
Epoch:  470  	Training Loss: 6.904661131557077e-05
Test Loss:  8.392454765271395e-05
Valid Loss:  0.00011827673006337136
Epoch:  471  	Training Loss: 6.903801113367081e-05
Test Loss:  8.393778989557177e-05
Valid Loss:  0.00011824996181530878
Epoch:  472  	Training Loss: 6.90299057168886e-05
Test Loss:  8.398094360018149e-05
Valid Loss:  0.00011815282050520182
Epoch:  473  	Training Loss: 6.899601430632174e-05
Test Loss:  8.399655052926391e-05
Valid Loss:  0.00011807318514911458
Epoch:  474  	Training Loss: 6.896555714774877e-05
Test Loss:  8.399425132665783e-05
Valid Loss:  0.00011800602806033567
Epoch:  475  	Training Loss: 6.893770478200167e-05
Test Loss:  8.398152567679062e-05
Valid Loss:  0.00011794608144555241
Epoch:  476  	Training Loss: 6.891194789204746e-05
Test Loss:  8.396318298764527e-05
Valid Loss:  0.00011789172276621684
Epoch:  477  	Training Loss: 6.88869331497699e-05
Test Loss:  8.394217729801312e-05
Valid Loss:  0.0001178243473987095
Epoch:  478  	Training Loss: 6.88633881509304e-05
Test Loss:  8.391946903429925e-05
Valid Loss:  0.00011776047176681459
Epoch:  479  	Training Loss: 6.884054164402187e-05
 96%|█████████▌| 479/500 [05:44<00:07,  2.92it/s] 96%|█████████▌| 481/500 [05:51<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:51<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:51<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:51<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:51<00:03,  2.95it/s] 98%|█████████▊| 491/500 [05:58<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:58<00:06,  1.14it/s] 99%|█████████▉| 495/500 [05:58<00:03,  1.56it/s] 99%|█████████▉| 497/500 [05:58<00:01,  2.10it/s]100%|█████████▉| 499/500 [05:58<00:00,  2.77it/s]100%|██████████| 500/500 [05:58<00:00,  1.39it/s]
Test Loss:  8.389602589886636e-05
Valid Loss:  0.0001176985097117722
Epoch:  480  	Training Loss: 6.881861190777272e-05
Test Loss:  8.387271373067051e-05
Valid Loss:  0.00011763912334572524
Epoch:  481  	Training Loss: 6.879730062792078e-05
Test Loss:  8.384999819099903e-05
Valid Loss:  0.00011758191249100491
Epoch:  482  	Training Loss: 6.877652776893228e-05
Test Loss:  8.378247730433941e-05
Valid Loss:  0.00011753823491744697
Epoch:  483  	Training Loss: 6.873234815429896e-05
Test Loss:  8.379737846553326e-05
Valid Loss:  0.00011744848598027602
Epoch:  484  	Training Loss: 6.869157368782908e-05
Test Loss:  8.38083797134459e-05
Valid Loss:  0.00011735891894204542
Epoch:  485  	Training Loss: 6.865239993203431e-05
Test Loss:  8.38145351735875e-05
Valid Loss:  0.00011727129458449781
Epoch:  486  	Training Loss: 6.861434667371213e-05
Test Loss:  8.381640509469435e-05
Valid Loss:  0.00011718473251676187
Epoch:  487  	Training Loss: 6.857801781734452e-05
Test Loss:  8.381539373658597e-05
Valid Loss:  0.00011710001854225993
Epoch:  488  	Training Loss: 6.854253297206014e-05
Test Loss:  8.381286897929385e-05
Valid Loss:  0.00011701739276759326
Epoch:  489  	Training Loss: 6.850820500403643e-05
Test Loss:  8.380804501939565e-05
Valid Loss:  0.00011693744454532862
Epoch:  490  	Training Loss: 6.847480108262971e-05
Test Loss:  8.38024279801175e-05
Valid Loss:  0.00011687200458254665
Epoch:  491  	Training Loss: 6.844490417279303e-05
Test Loss:  8.3719685790129e-05
Valid Loss:  0.00011681248724926263
Epoch:  492  	Training Loss: 6.841497088316828e-05
Test Loss:  8.330634591402486e-05
Valid Loss:  0.00011631022789515555
Epoch:  493  	Training Loss: 6.81663877912797e-05
Test Loss:  8.272306877188385e-05
Valid Loss:  0.00011587163317017257
Epoch:  494  	Training Loss: 6.791684427298605e-05
Test Loss:  8.208869985537603e-05
Valid Loss:  0.00011547160829650238
Epoch:  495  	Training Loss: 6.765958096366376e-05
Test Loss:  8.147952030412853e-05
Valid Loss:  0.00011512469063745812
Epoch:  496  	Training Loss: 6.742715049767867e-05
Test Loss:  8.091402560239658e-05
Valid Loss:  0.00011480557441245764
Epoch:  497  	Training Loss: 6.72140740789473e-05
Test Loss:  8.039358363021165e-05
Valid Loss:  0.0001145039132097736
Epoch:  498  	Training Loss: 6.701578968204558e-05
Test Loss:  7.99136032583192e-05
Valid Loss:  0.0001142164837801829
Epoch:  499  	Training Loss: 6.683070387225598e-05
Test Loss:  7.947057747514918e-05
Valid Loss:  0.00011393978638807312
Epoch:  500  	Training Loss: 6.665570253971964e-05
Test Loss:  7.905928214313462e-05
Valid Loss:  0.0001136719947680831
seed is  19
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:36, 13.56it/s]  1%|          | 4/500 [00:00<00:38, 12.78it/s]  1%|          | 6/500 [00:00<00:35, 14.05it/s]  2%|▏         | 8/500 [00:00<00:33, 14.62it/s]  2%|▏         | 10/500 [00:00<00:32, 15.17it/s]  2%|▏         | 12/500 [00:00<00:32, 15.10it/s]  3%|▎         | 14/500 [00:00<00:31, 15.41it/s]  3%|▎         | 16/500 [00:01<00:33, 14.33it/s]  4%|▎         | 18/500 [00:01<00:33, 14.38it/s]  4%|▍         | 20/500 [00:01<00:32, 14.88it/s]  4%|▍         | 22/500 [00:01<00:33, 14.35it/s]  5%|▍         | 24/500 [00:01<00:35, 13.58it/s]  5%|▌         | 26/500 [00:01<00:36, 13.15it/s]  6%|▌         | 28/500 [00:02<00:36, 12.86it/s]  6%|▌         | 30/500 [00:02<00:35, 13.38it/s]  6%|▋         | 32/500 [00:02<00:33, 14.14it/s]  7%|▋         | 34/500 [00:02<00:31, 14.67it/s]  7%|▋         | 36/500 [00:02<00:30, 15.13it/s]  8%|▊         | 38/500 [00:02<00:30, 15.25it/s]  8%|▊         | 40/500 [00:02<00:30, 15.31it/s]  8%|▊         | 42/500 [00:02<00:29, 15.51it/s]  9%|▉         | 44/500 [00:03<00:29, 15.70it/s]  9%|▉         | 46/500 [00:03<00:28, 15.83it/s] 10%|▉         | 48/500 [00:03<00:28, 15.98it/s] 10%|█         | 50/500 [00:03<00:29, 15.09it/s] 10%|█         | 52/500 [00:03<00:31, 14.14it/s] 11%|█         | 54/500 [00:03<00:32, 13.73it/s] 11%|█         | 56/500 [00:04<00:47,  9.33it/s] 12%|█▏        | 58/500 [00:04<00:56,  7.79it/s] 12%|█▏        | 60/500 [00:04<00:50,  8.69it/s] 12%|█▏        | 62/500 [00:04<00:44,  9.93it/s] 13%|█▎        | 64/500 [00:04<00:39, 11.06it/s] 13%|█▎        | 66/500 [00:05<00:36, 12.03it/s] 14%|█▎        | 68/500 [00:05<00:33, 12.87it/s] 14%|█▍        | 70/500 [00:05<00:31, 13.51it/s] 14%|█▍        | 72/500 [00:05<00:30, 14.10it/s] 15%|█▍        | 74/500 [00:05<00:29, 14.56it/s] 15%|█▌        | 76/500 [00:05<00:28, 14.99it/s] 16%|█▌        | 78/500 [00:05<00:28, 15.05it/s] 16%|█▌        | 80/500 [00:05<00:27, 15.32it/s] 16%|█▋        | 82/500 [00:06<00:27, 15.42it/s] 17%|█▋        | 84/500 [00:06<00:28, 14.85it/s] 17%|█▋        | 86/500 [00:06<00:30, 13.74it/s] 18%|█▊        | 88/500 [00:06<00:29, 14.18it/s] 18%|█▊        | 90/500 [00:06<00:27, 14.73it/s] 18%|█▊        | 92/500 [00:06<00:27, 14.99it/s] 19%|█▉        | 94/500 [00:06<00:27, 14.83it/s] 19%|█▉        | 96/500 [00:07<00:29, 13.48it/s] 20%|█▉        | 98/500 [00:07<00:31, 12.70it/s] 20%|██        | 100/500 [00:07<00:29, 13.59it/s] 20%|██        | 102/500 [00:07<00:28, 13.99it/s] 21%|██        | 104/500 [00:07<00:27, 14.49it/s] 21%|██        | 106/500 [00:07<00:26, 15.01it/s] 22%|██▏       | 108/500 [00:07<00:25, 15.29it/s] 22%|██▏       | 110/500 [00:08<00:25, 15.37it/s] 22%|██▏       | 112/500 [00:08<00:24, 15.64it/s] 23%|██▎       | 114/500 [00:08<00:25, 14.86it/s] 23%|██▎       | 116/500 [00:08<00:27, 13.95it/s] 24%|██▎       | 118/500 [00:08<00:28, 13.45it/s] 24%|██▍       | 120/500 [00:08<00:26, 14.18it/s] 24%|██▍       | 122/500 [00:08<00:26, 14.49it/s] 25%|██▍       | 124/500 [00:08<00:25, 14.76it/s]Epoch:  1  	Training Loss: 0.03900011256337166
Test Loss:  758.0030517578125
Valid Loss:  756.8798828125
Epoch:  2  	Training Loss: 742.4902954101562
Test Loss:  59606680207360.0
Valid Loss:  58405712560128.0
Epoch:  3  	Training Loss: 59295282495488.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:09<00:24, 15.15it/s] 26%|██▌       | 128/500 [00:09<00:24, 15.43it/s] 26%|██▌       | 130/500 [00:09<00:23, 15.70it/s] 26%|██▋       | 132/500 [00:09<00:23, 15.71it/s] 27%|██▋       | 134/500 [00:09<00:23, 15.89it/s] 27%|██▋       | 136/500 [00:09<00:22, 16.00it/s] 28%|██▊       | 138/500 [00:09<00:22, 16.06it/s] 28%|██▊       | 140/500 [00:09<00:22, 16.12it/s] 28%|██▊       | 142/500 [00:10<00:22, 15.94it/s] 29%|██▉       | 144/500 [00:10<00:24, 14.61it/s] 29%|██▉       | 146/500 [00:10<00:24, 14.45it/s] 30%|██▉       | 148/500 [00:10<00:23, 14.93it/s] 30%|███       | 150/500 [00:10<00:22, 15.35it/s] 30%|███       | 152/500 [00:10<00:22, 15.60it/s] 31%|███       | 154/500 [00:10<00:21, 15.74it/s] 31%|███       | 156/500 [00:11<00:22, 15.15it/s] 32%|███▏      | 158/500 [00:11<00:22, 15.45it/s] 32%|███▏      | 160/500 [00:11<00:21, 15.58it/s] 32%|███▏      | 162/500 [00:11<00:21, 15.75it/s] 33%|███▎      | 164/500 [00:11<00:21, 15.86it/s] 33%|███▎      | 166/500 [00:11<00:21, 15.88it/s] 34%|███▎      | 168/500 [00:11<00:21, 15.81it/s] 34%|███▍      | 170/500 [00:11<00:21, 15.71it/s] 34%|███▍      | 172/500 [00:12<00:20, 15.74it/s] 35%|███▍      | 174/500 [00:12<00:20, 15.86it/s] 35%|███▌      | 176/500 [00:12<00:20, 15.98it/s] 36%|███▌      | 178/500 [00:12<00:20, 15.84it/s] 36%|███▌      | 180/500 [00:12<00:20, 15.85it/s] 36%|███▋      | 182/500 [00:12<00:20, 15.89it/s] 37%|███▋      | 184/500 [00:12<00:19, 15.97it/s] 37%|███▋      | 186/500 [00:12<00:19, 16.03it/s] 38%|███▊      | 188/500 [00:13<00:19, 16.11it/s] 38%|███▊      | 190/500 [00:13<00:19, 16.16it/s] 38%|███▊      | 192/500 [00:13<00:19, 15.88it/s] 39%|███▉      | 194/500 [00:13<00:19, 15.70it/s] 39%|███▉      | 196/500 [00:13<00:19, 15.68it/s] 40%|███▉      | 198/500 [00:13<00:19, 15.86it/s] 40%|████      | 200/500 [00:13<00:18, 15.90it/s] 40%|████      | 202/500 [00:13<00:18, 15.96it/s] 41%|████      | 204/500 [00:14<00:18, 16.02it/s] 41%|████      | 206/500 [00:14<00:18, 15.52it/s] 42%|████▏     | 208/500 [00:14<00:18, 15.74it/s] 42%|████▏     | 210/500 [00:14<00:18, 15.84it/s] 42%|████▏     | 212/500 [00:14<00:18, 15.75it/s] 43%|████▎     | 214/500 [00:14<00:17, 15.90it/s] 43%|████▎     | 216/500 [00:14<00:17, 16.05it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.07it/s] 44%|████▍     | 220/500 [00:15<00:17, 15.90it/s] 44%|████▍     | 222/500 [00:15<00:17, 15.98it/s] 45%|████▍     | 224/500 [00:15<00:17, 16.08it/s] 45%|████▌     | 226/500 [00:15<00:16, 16.14it/s] 46%|████▌     | 228/500 [00:15<00:17, 15.96it/s] 46%|████▌     | 230/500 [00:15<00:16, 15.92it/s] 46%|████▋     | 232/500 [00:15<00:16, 15.80it/s] 47%|████▋     | 234/500 [00:15<00:16, 15.79it/s] 47%|████▋     | 236/500 [00:16<00:16, 15.88it/s] 48%|████▊     | 238/500 [00:16<00:16, 16.00it/s] 48%|████▊     | 240/500 [00:16<00:16, 16.05it/s] 48%|████▊     | 242/500 [00:16<00:15, 16.16it/s] 49%|████▉     | 244/500 [00:16<00:15, 16.09it/s] 49%|████▉     | 246/500 [00:16<00:15, 16.14it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.18it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.23it/s] 50%|█████     | 252/500 [00:17<00:15, 16.31it/s] 51%|█████     | 254/500 [00:17<00:15, 16.13it/s] 51%|█████     | 256/500 [00:17<00:15, 16.00it/s] 52%|█████▏    | 258/500 [00:17<00:15, 15.96it/s] 52%|█████▏    | 260/500 [00:17<00:14, 16.10it/s] 52%|█████▏    | 262/500 [00:17<00:14, 16.12it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.14it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.17it/s] 54%|█████▎    | 268/500 [00:18<00:14, 16.24it/s] 54%|█████▍    | 270/500 [00:18<00:14, 16.12it/s] 54%|█████▍    | 272/500 [00:18<00:14, 16.04it/s] 55%|█████▍    | 274/500 [00:18<00:14, 16.07it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.87it/s] 56%|█████▌    | 278/500 [00:18<00:15, 14.54it/s] 56%|█████▌    | 280/500 [00:18<00:14, 14.91it/s] 56%|█████▋    | 282/500 [00:18<00:14, 15.13it/s] 57%|█████▋    | 284/500 [00:19<00:14, 15.40it/s] 57%|█████▋    | 286/500 [00:19<00:13, 15.56it/s] 58%|█████▊    | 288/500 [00:19<00:13, 15.75it/s] 58%|█████▊    | 290/500 [00:19<00:13, 15.78it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.66it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.75it/s] 59%|█████▉    | 296/500 [00:19<00:13, 15.43it/s] 60%|█████▉    | 298/500 [00:20<00:14, 14.26it/s] 60%|██████    | 300/500 [00:20<00:15, 13.08it/s] 60%|██████    | 302/500 [00:20<00:14, 13.71it/s] 61%|██████    | 304/500 [00:20<00:13, 14.27it/s] 61%|██████    | 306/500 [00:20<00:13, 14.79it/s] 62%|██████▏   | 308/500 [00:20<00:12, 15.17it/s] 62%|██████▏   | 310/500 [00:20<00:13, 14.53it/s] 62%|██████▏   | 312/500 [00:21<00:13, 13.58it/s] 63%|██████▎   | 314/500 [00:21<00:13, 13.87it/s] 63%|██████▎   | 316/500 [00:21<00:13, 14.03it/s] 64%|██████▎   | 318/500 [00:21<00:12, 14.65it/s] 64%|██████▍   | 320/500 [00:21<00:11, 15.00it/s] 64%|██████▍   | 322/500 [00:21<00:11, 15.35it/s] 65%|██████▍   | 324/500 [00:21<00:11, 15.63it/s] 65%|██████▌   | 326/500 [00:21<00:11, 15.81it/s] 66%|██████▌   | 328/500 [00:22<00:10, 15.87it/s] 66%|██████▌   | 330/500 [00:22<00:10, 15.93it/s] 66%|██████▋   | 332/500 [00:22<00:10, 15.95it/s] 67%|██████▋   | 334/500 [00:22<00:10, 16.00it/s] 67%|██████▋   | 336/500 [00:22<00:10, 16.05it/s] 68%|██████▊   | 338/500 [00:22<00:10, 16.02it/s] 68%|██████▊   | 340/500 [00:22<00:09, 16.05it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.13it/s] 69%|██████▉   | 344/500 [00:23<00:09, 16.06it/s] 69%|██████▉   | 346/500 [00:23<00:09, 16.05it/s] 70%|██████▉   | 348/500 [00:23<00:09, 16.13it/s] 70%|███████   | 350/500 [00:23<00:09, 16.14it/s] 70%|███████   | 352/500 [00:23<00:09, 16.24it/s] 71%|███████   | 354/500 [00:23<00:09, 16.22it/s] 71%|███████   | 356/500 [00:23<00:08, 16.20it/s] 72%|███████▏  | 358/500 [00:23<00:08, 16.15it/s] 72%|███████▏  | 360/500 [00:24<00:08, 16.04it/s] 72%|███████▏  | 362/500 [00:24<00:08, 16.06it/s] 73%|███████▎  | 364/500 [00:24<00:08, 16.12it/s] 73%|███████▎  | 366/500 [00:24<00:08, 16.16it/s] 74%|███████▎  | 368/500 [00:24<00:08, 16.14it/s] 74%|███████▍  | 370/500 [00:24<00:08, 16.20it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.12it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:08, 14.14it/s] 75%|███████▌  | 376/500 [00:25<00:08, 14.13it/s] 76%|███████▌  | 378/500 [00:25<00:08, 13.75it/s] 76%|███████▌  | 380/500 [00:25<00:09, 13.30it/s] 76%|███████▋  | 382/500 [00:25<00:09, 12.53it/s] 77%|███████▋  | 384/500 [00:25<00:09, 12.63it/s] 77%|███████▋  | 386/500 [00:25<00:09, 12.53it/s] 78%|███████▊  | 388/500 [00:26<00:08, 13.45it/s] 78%|███████▊  | 390/500 [00:26<00:07, 13.93it/s] 78%|███████▊  | 392/500 [00:26<00:07, 13.98it/s] 79%|███████▉  | 394/500 [00:26<00:07, 14.58it/s] 79%|███████▉  | 396/500 [00:26<00:06, 15.00it/s] 80%|███████▉  | 398/500 [00:26<00:06, 15.42it/s] 80%|████████  | 400/500 [00:26<00:06, 15.62it/s] 80%|████████  | 402/500 [00:26<00:06, 15.28it/s] 81%|████████  | 404/500 [00:27<00:06, 15.31it/s] 81%|████████  | 406/500 [00:27<00:06, 15.15it/s] 82%|████████▏ | 408/500 [00:27<00:06, 15.09it/s] 82%|████████▏ | 410/500 [00:27<00:05, 15.33it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.10it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.10it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.33it/s] 84%|████████▎ | 418/500 [00:28<00:05, 15.56it/s] 84%|████████▍ | 420/500 [00:28<00:05, 15.63it/s] 84%|████████▍ | 422/500 [00:28<00:05, 15.32it/s] 85%|████████▍ | 424/500 [00:28<00:04, 15.32it/s] 85%|████████▌ | 426/500 [00:28<00:04, 15.57it/s] 86%|████████▌ | 428/500 [00:28<00:04, 14.57it/s] 86%|████████▌ | 430/500 [00:28<00:05, 13.83it/s] 86%|████████▋ | 432/500 [00:29<00:05, 13.21it/s] 87%|████████▋ | 434/500 [00:29<00:05, 12.77it/s] 87%|████████▋ | 436/500 [00:29<00:05, 12.64it/s] 88%|████████▊ | 438/500 [00:29<00:04, 12.65it/s] 88%|████████▊ | 440/500 [00:29<00:04, 13.49it/s] 88%|████████▊ | 442/500 [00:29<00:04, 14.20it/s] 89%|████████▉ | 444/500 [00:29<00:03, 14.78it/s] 89%|████████▉ | 446/500 [00:30<00:03, 15.17it/s] 90%|████████▉ | 448/500 [00:30<00:03, 15.27it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.35it/s] 90%|█████████ | 452/500 [00:30<00:03, 15.56it/s] 91%|█████████ | 454/500 [00:30<00:02, 15.73it/s] 91%|█████████ | 456/500 [00:30<00:02, 14.97it/s] 92%|█████████▏| 458/500 [00:30<00:02, 14.02it/s] 92%|█████████▏| 460/500 [00:30<00:03, 13.29it/s] 92%|█████████▏| 462/500 [00:31<00:02, 13.55it/s] 93%|█████████▎| 464/500 [00:31<00:02, 14.23it/s] 93%|█████████▎| 466/500 [00:31<00:02, 14.74it/s] 94%|█████████▎| 468/500 [00:31<00:02, 14.91it/s] 94%|█████████▍| 470/500 [00:31<00:01, 15.29it/s] 94%|█████████▍| 472/500 [00:31<00:01, 15.56it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.78it/s] 95%|█████████▌| 476/500 [00:32<00:01, 14.92it/s] 96%|█████████▌| 478/500 [00:32<00:01, 14.02it/s] 96%|█████████▌| 480/500 [00:32<00:01, 13.49it/s] 96%|█████████▋| 482/500 [00:32<00:01, 13.06it/s] 97%|█████████▋| 484/500 [00:32<00:01, 12.85it/s] 97%|█████████▋| 486/500 [00:32<00:01, 12.74it/s] 98%|█████████▊| 488/500 [00:32<00:00, 13.52it/s] 98%|█████████▊| 490/500 [00:33<00:00, 14.20it/s] 98%|█████████▊| 492/500 [00:33<00:00, 14.77it/s] 99%|█████████▉| 494/500 [00:33<00:00, 14.34it/s] 99%|█████████▉| 496/500 [00:33<00:00, 13.67it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 13.89it/s]100%|██████████| 500/500 [00:33<00:00, 14.50it/s]100%|██████████| 500/500 [00:33<00:00, 14.80it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  19
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:21,  6.30s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<11:04,  1.36s/it]  3%|▎         | 13/500 [00:13<07:32,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:45,  2.91it/s]  4%|▍         | 21/500 [00:20<09:53,  1.24s/it]  5%|▍         | 23/500 [00:20<07:00,  1.14it/s]  5%|▌         | 25/500 [00:20<05:00,  1.58it/s]  5%|▌         | 27/500 [00:20<03:38,  2.17it/s]  6%|▌         | 29/500 [00:20<02:41,  2.92it/s]  6%|▌         | 31/500 [00:27<09:26,  1.21s/it]  7%|▋         | 33/500 [00:27<06:44,  1.16it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:36,  2.94it/s]  8%|▊         | 41/500 [00:34<09:06,  1.19s/it]  9%|▊         | 43/500 [00:34<06:30,  1.17it/s]  9%|▉         | 45/500 [00:34<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.21it/s] 10%|▉         | 49/500 [00:34<02:32,  2.97it/s] 10%|█         | 51/500 [00:41<09:16,  1.24s/it] 11%|█         | 53/500 [00:41<06:39,  1.12it/s] 11%|█         | 55/500 [00:41<04:49,  1.53it/s] 11%|█▏        | 57/500 [00:41<03:33,  2.08it/s] 12%|█▏        | 59/500 [00:42<02:39,  2.76it/s] 12%|█▏        | 61/500 [00:48<08:50,  1.21s/it] 13%|█▎        | 63/500 [00:48<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:48<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:49<02:27,  2.92it/s] 14%|█▍        | 71/500 [00:55<08:36,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:10,  1.15it/s]Epoch:  1  	Training Loss: 0.03900011256337166
Test Loss:  54.02452087402344
Valid Loss:  52.74578857421875
Epoch:  2  	Training Loss: 50.73859405517578
Test Loss:  1055.155517578125
Valid Loss:  1010.4703369140625
Epoch:  3  	Training Loss: 1031.428466796875
Test Loss:  0.4336642026901245
Valid Loss:  0.40408942103385925
Epoch:  4  	Training Loss: 0.3565666675567627
Test Loss:  0.4242869019508362
Valid Loss:  0.3952804207801819
Epoch:  5  	Training Loss: 0.3483153283596039
Test Loss:  0.4151054620742798
Valid Loss:  0.3866572380065918
Epoch:  6  	Training Loss: 0.3402460217475891
Test Loss:  0.4061162769794464
Valid Loss:  0.37821656465530396
Epoch:  7  	Training Loss: 0.3323553502559662
Test Loss:  0.3973159193992615
Valid Loss:  0.3699548840522766
Epoch:  8  	Training Loss: 0.3246399760246277
Test Loss:  0.3887009620666504
Valid Loss:  0.3618691563606262
Epoch:  9  	Training Loss: 0.3170965909957886
Test Loss:  0.3802678883075714
Valid Loss:  0.3539559245109558
Epoch:  10  	Training Loss: 0.30972176790237427
Test Loss:  0.3720133602619171
Valid Loss:  0.3462119698524475
Epoch:  11  	Training Loss: 0.30251234769821167
Test Loss:  0.36393406987190247
Valid Loss:  0.338634192943573
Epoch:  12  	Training Loss: 0.2954651713371277
Test Loss:  0.3557983636856079
Valid Loss:  0.3310055732727051
Epoch:  13  	Training Loss: 0.28837645053863525
Test Loss:  0.3478595018386841
Valid Loss:  0.32356342673301697
Epoch:  14  	Training Loss: 0.28146880865097046
Test Loss:  0.3401128053665161
Valid Loss:  0.3163030743598938
Epoch:  15  	Training Loss: 0.27473753690719604
Test Loss:  0.3325532078742981
Valid Loss:  0.30921992659568787
Epoch:  16  	Training Loss: 0.2681780755519867
Test Loss:  0.3251761198043823
Valid Loss:  0.30230948328971863
Epoch:  17  	Training Loss: 0.26178592443466187
Test Loss:  0.3179768919944763
Valid Loss:  0.2955673635005951
Epoch:  18  	Training Loss: 0.25555679202079773
Test Loss:  0.3109511137008667
Valid Loss:  0.28898942470550537
Epoch:  19  	Training Loss: 0.24948647618293762
Test Loss:  0.3040943741798401
Valid Loss:  0.2825714349746704
Epoch:  20  	Training Loss: 0.24357080459594727
Test Loss:  0.2974025011062622
Valid Loss:  0.27630937099456787
Epoch:  21  	Training Loss: 0.2378057837486267
Test Loss:  0.29087138175964355
Valid Loss:  0.27019932866096497
Epoch:  22  	Training Loss: 0.23218759894371033
Test Loss:  0.2845214903354645
Valid Loss:  0.2642590403556824
Epoch:  23  	Training Loss: 0.22673434019088745
Test Loss:  0.2783159017562866
Valid Loss:  0.2584553360939026
Epoch:  24  	Training Loss: 0.22141295671463013
Test Loss:  0.27225130796432495
Valid Loss:  0.2527850568294525
Epoch:  25  	Training Loss: 0.216220423579216
Test Loss:  0.2663247883319855
Valid Loss:  0.24724538624286652
Epoch:  26  	Training Loss: 0.2111538052558899
Test Loss:  0.2605332136154175
Valid Loss:  0.24183329939842224
Epoch:  27  	Training Loss: 0.206210196018219
Test Loss:  0.2548735737800598
Valid Loss:  0.23654597997665405
Epoch:  28  	Training Loss: 0.20138674974441528
Test Loss:  0.24934303760528564
Valid Loss:  0.23138076066970825
Epoch:  29  	Training Loss: 0.19668078422546387
Test Loss:  0.2439386546611786
Valid Loss:  0.226334810256958
Epoch:  30  	Training Loss: 0.1920894831418991
Test Loss:  0.23865766823291779
Valid Loss:  0.22140543162822723
Epoch:  31  	Training Loss: 0.18761023879051208
Test Loss:  0.23349735140800476
Valid Loss:  0.21659010648727417
Epoch:  32  	Training Loss: 0.18324045836925507
Test Loss:  0.22849306464195251
Valid Loss:  0.21192260086536407
Epoch:  33  	Training Loss: 0.1790095418691635
Test Loss:  0.22360284626483917
Valid Loss:  0.2073628306388855
Epoch:  34  	Training Loss: 0.17488189041614532
Test Loss:  0.21882419288158417
Valid Loss:  0.20290839672088623
Epoch:  35  	Training Loss: 0.1708551049232483
Test Loss:  0.21415454149246216
Valid Loss:  0.1985567957162857
Epoch:  36  	Training Loss: 0.1669268012046814
Test Loss:  0.20959147810935974
Valid Loss:  0.19430585205554962
Epoch:  37  	Training Loss: 0.16309472918510437
Test Loss:  0.20513257384300232
Valid Loss:  0.19015318155288696
Epoch:  38  	Training Loss: 0.15935654938220978
Test Loss:  0.20077545940876007
Valid Loss:  0.18609654903411865
Epoch:  39  	Training Loss: 0.15571001172065735
Test Loss:  0.19651785492897034
Valid Loss:  0.1821337640285492
Epoch:  40  	Training Loss: 0.15215304493904114
Test Loss:  0.19235759973526
Valid Loss:  0.17826275527477264
Epoch:  41  	Training Loss: 0.14868351817131042
Test Loss:  0.18829238414764404
Valid Loss:  0.1744813621044159
Epoch:  42  	Training Loss: 0.14529934525489807
Test Loss:  0.18431390821933746
Valid Loss:  0.1707819700241089
Epoch:  43  	Training Loss: 0.1419931948184967
Test Loss:  0.18042850494384766
Valid Loss:  0.16717024147510529
Epoch:  44  	Training Loss: 0.13877028226852417
Test Loss:  0.17663393914699554
Valid Loss:  0.16364407539367676
Epoch:  45  	Training Loss: 0.13562852144241333
Test Loss:  0.17292800545692444
Valid Loss:  0.16020137071609497
Epoch:  46  	Training Loss: 0.13256585597991943
Test Loss:  0.1693086326122284
Valid Loss:  0.15684017539024353
Epoch:  47  	Training Loss: 0.1295803338289261
Test Loss:  0.1657736599445343
Valid Loss:  0.1535584181547165
Epoch:  48  	Training Loss: 0.1266699731349945
Test Loss:  0.16232113540172577
Valid Loss:  0.150354266166687
Epoch:  49  	Training Loss: 0.12383291125297546
Test Loss:  0.15894901752471924
Valid Loss:  0.1472257524728775
Epoch:  50  	Training Loss: 0.12106728553771973
Test Loss:  0.15565542876720428
Valid Loss:  0.1441711187362671
Epoch:  51  	Training Loss: 0.11837130039930344
Test Loss:  0.1524384468793869
Valid Loss:  0.14118854701519012
Epoch:  52  	Training Loss: 0.11574320495128632
Test Loss:  0.14929908514022827
Valid Loss:  0.13829834759235382
Epoch:  53  	Training Loss: 0.11318676918745041
Test Loss:  0.14662706851959229
Valid Loss:  0.13606831431388855
Epoch:  54  	Training Loss: 0.11104533821344376
Test Loss:  0.144840270280838
Valid Loss:  0.13483351469039917
Epoch:  55  	Training Loss: 0.10959303379058838
Test Loss:  0.14359882473945618
Valid Loss:  0.1341109573841095
Epoch:  56  	Training Loss: 0.10855285078287125
Test Loss:  0.14294326305389404
Valid Loss:  0.13364854454994202
Epoch:  57  	Training Loss: 0.107819102704525
Test Loss:  0.1425907164812088
Valid Loss:  0.1333431452512741
Epoch:  58  	Training Loss: 0.10737916827201843
Test Loss:  0.1423918902873993
Valid Loss:  0.13314644992351532
Epoch:  59  	Training Loss: 0.10711643099784851
Test Loss:  0.14225992560386658
Valid Loss:  0.13302300870418549
Epoch:  60  	Training Loss: 0.10695204883813858
Test Loss:  0.14218148589134216
Valid Loss:  0.13295456767082214
Epoch:  61  	Training Loss: 0.10684706270694733
Test Loss:  0.14213620126247406
Valid Loss:  0.13290032744407654
Epoch:  62  	Training Loss: 0.1067708432674408
Test Loss:  0.14210429787635803
Valid Loss:  0.1328563392162323
Epoch:  63  	Training Loss: 0.1067124754190445
Test Loss:  0.14208632707595825
Valid Loss:  0.1328219175338745
Epoch:  64  	Training Loss: 0.10667350143194199
Test Loss:  0.1420709490776062
Valid Loss:  0.13279426097869873
Epoch:  65  	Training Loss: 0.10664297640323639
Test Loss:  0.142059326171875
Valid Loss:  0.13276877999305725
Epoch:  66  	Training Loss: 0.10661759972572327
Test Loss:  0.1420532464981079
Valid Loss:  0.13274957239627838
Epoch:  67  	Training Loss: 0.10659951716661453
Test Loss:  0.14205019176006317
Valid Loss:  0.13273701071739197
Epoch:  68  	Training Loss: 0.10658696293830872
Test Loss:  0.14204779267311096
Valid Loss:  0.13272972404956818
Epoch:  69  	Training Loss: 0.1065785214304924
Test Loss:  0.1420455276966095
Valid Loss:  0.13272403180599213
Epoch:  70  	Training Loss: 0.10657156258821487
Test Loss:  0.14204367995262146
Valid Loss:  0.13271978497505188
Epoch:  71  	Training Loss: 0.1065666601061821
Test Loss:  0.14204218983650208
Valid Loss:  0.13271616399288177
Epoch:  72  	Training Loss: 0.10656306147575378
Test Loss:  0.1420411765575409
Valid Loss:  0.13271385431289673
Epoch:  73  	Training Loss: 0.10655991733074188
Test Loss:  0.1420402079820633
Valid Loss:  0.13271211087703705
Epoch:  74  	Training Loss: 0.10655707865953445
Test Loss:   15%|█▌        | 75/500 [00:55<04:26,  1.59it/s] 15%|█▌        | 77/500 [00:55<03:14,  2.17it/s] 16%|█▌        | 79/500 [00:56<02:25,  2.89it/s] 16%|█▌        | 81/500 [01:02<08:26,  1.21s/it] 17%|█▋        | 83/500 [01:02<06:01,  1.15it/s] 17%|█▋        | 85/500 [01:02<04:20,  1.59it/s] 17%|█▋        | 87/500 [01:02<03:09,  2.17it/s] 18%|█▊        | 89/500 [01:03<02:20,  2.92it/s] 18%|█▊        | 91/500 [01:09<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:09<05:50,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:14,  1.59it/s] 19%|█▉        | 97/500 [01:09<03:08,  2.14it/s] 20%|█▉        | 99/500 [01:10<02:21,  2.84it/s] 20%|██        | 101/500 [01:16<07:55,  1.19s/it] 21%|██        | 103/500 [01:16<05:39,  1.17it/s] 21%|██        | 105/500 [01:16<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:16<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:23<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:23<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:23<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:23<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:23<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:30<07:43,  1.22s/it] 25%|██▍       | 123/500 [01:30<05:31,  1.14it/s] 25%|██▌       | 125/500 [01:30<03:58,  1.57it/s] 25%|██▌       | 127/500 [01:30<02:53,  2.15it/s] 26%|██▌       | 129/500 [01:30<02:08,  2.89it/s] 26%|██▌       | 131/500 [01:37<07:22,  1.20s/it] 27%|██▋       | 133/500 [01:37<05:17,  1.16it/s] 27%|██▋       | 135/500 [01:37<03:50,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:49,  2.14it/s] 28%|██▊       | 139/500 [01:37<02:07,  2.84it/s] 28%|██▊       | 141/500 [01:44<07:11,  1.20s/it] 29%|██▊       | 143/500 [01:44<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:44<03:41,  1.60it/s]0.14203926920890808
Valid Loss:  0.1327105462551117
Epoch:  75  	Training Loss: 0.10655445605516434
Test Loss:  0.14203836023807526
Valid Loss:  0.13270947337150574
Epoch:  76  	Training Loss: 0.10655184835195541
Test Loss:  0.14203743636608124
Valid Loss:  0.1327088475227356
Epoch:  77  	Training Loss: 0.10654924809932709
Test Loss:  0.14203685522079468
Valid Loss:  0.13270820677280426
Epoch:  78  	Training Loss: 0.10654674470424652
Test Loss:  0.14203637838363647
Valid Loss:  0.1327075958251953
Epoch:  79  	Training Loss: 0.1065443903207779
Test Loss:  0.14203593134880066
Valid Loss:  0.13270701467990875
Epoch:  80  	Training Loss: 0.10654223710298538
Test Loss:  0.14203548431396484
Valid Loss:  0.1327064484357834
Epoch:  81  	Training Loss: 0.10654039680957794
Test Loss:  0.1420350968837738
Valid Loss:  0.13270598649978638
Epoch:  82  	Training Loss: 0.10653898119926453
Test Loss:  0.14203503727912903
Valid Loss:  0.13270559906959534
Epoch:  83  	Training Loss: 0.10653770714998245
Test Loss:  0.14203503727912903
Valid Loss:  0.13270524144172668
Epoch:  84  	Training Loss: 0.10653652995824814
Test Loss:  0.14203500747680664
Valid Loss:  0.13270489871501923
Epoch:  85  	Training Loss: 0.10653549432754517
Test Loss:  0.14203497767448425
Valid Loss:  0.13270458579063416
Epoch:  86  	Training Loss: 0.10653465986251831
Test Loss:  0.14203494787216187
Valid Loss:  0.13270431756973267
Epoch:  87  	Training Loss: 0.10653398931026459
Test Loss:  0.14203491806983948
Valid Loss:  0.13270404934883118
Epoch:  88  	Training Loss: 0.10653336346149445
Test Loss:  0.14203491806983948
Valid Loss:  0.13270379602909088
Epoch:  89  	Training Loss: 0.10653285682201385
Test Loss:  0.1420348882675171
Valid Loss:  0.13270363211631775
Epoch:  90  	Training Loss: 0.10653243213891983
Test Loss:  0.1420348584651947
Valid Loss:  0.13270355761051178
Epoch:  91  	Training Loss: 0.1065320298075676
Test Loss:  0.14203482866287231
Valid Loss:  0.13270354270935059
Epoch:  92  	Training Loss: 0.10653173923492432
Test Loss:  0.14203482866287231
Valid Loss:  0.1327035129070282
Epoch:  93  	Training Loss: 0.1065315380692482
Test Loss:  0.14203479886054993
Valid Loss:  0.132703498005867
Epoch:  94  	Training Loss: 0.10653139650821686
Test Loss:  0.14203476905822754
Valid Loss:  0.1327034831047058
Epoch:  95  	Training Loss: 0.10653124749660492
Test Loss:  0.14203475415706635
Valid Loss:  0.13270345330238342
Epoch:  96  	Training Loss: 0.10653115063905716
Test Loss:  0.14203473925590515
Valid Loss:  0.13270343840122223
Epoch:  97  	Training Loss: 0.1065310537815094
Test Loss:  0.14203470945358276
Valid Loss:  0.13270340859889984
Epoch:  98  	Training Loss: 0.10653096437454224
Test Loss:  0.14203469455242157
Valid Loss:  0.13270339369773865
Epoch:  99  	Training Loss: 0.10653087496757507
Test Loss:  0.14203466475009918
Valid Loss:  0.13270336389541626
Epoch:  100  	Training Loss: 0.10653079301118851
Test Loss:  0.142034649848938
Valid Loss:  0.13270333409309387
Epoch:  101  	Training Loss: 0.10653071105480194
Test Loss:  0.1420346200466156
Valid Loss:  0.13270333409309387
Epoch:  102  	Training Loss: 0.10653062164783478
Test Loss:  0.1420346051454544
Valid Loss:  0.13270331919193268
Epoch:  103  	Training Loss: 0.10653056204319
Test Loss:  0.1420345902442932
Valid Loss:  0.13270330429077148
Epoch:  104  	Training Loss: 0.10653051733970642
Test Loss:  0.1420345902442932
Valid Loss:  0.1327032893896103
Epoch:  105  	Training Loss: 0.10653047263622284
Test Loss:  0.1420345902442932
Valid Loss:  0.1327032744884491
Epoch:  106  	Training Loss: 0.10653042048215866
Test Loss:  0.14203457534313202
Valid Loss:  0.1327032744884491
Epoch:  107  	Training Loss: 0.10653036832809448
Test Loss:  0.14203456044197083
Valid Loss:  0.1327032595872879
Epoch:  108  	Training Loss: 0.1065303236246109
Test Loss:  0.14203456044197083
Valid Loss:  0.1327032595872879
Epoch:  109  	Training Loss: 0.10653029382228851
Test Loss:  0.14203456044197083
Valid Loss:  0.1327032595872879
Epoch:  110  	Training Loss: 0.10653026401996613
Test Loss:  0.14203456044197083
Valid Loss:  0.1327032446861267
Epoch:  111  	Training Loss: 0.10653024166822433
Test Loss:  0.14203456044197083
Valid Loss:  0.1327032446861267
Epoch:  112  	Training Loss: 0.10653021931648254
Test Loss:  0.14203454554080963
Valid Loss:  0.13270322978496552
Epoch:  113  	Training Loss: 0.10653018206357956
Test Loss:  0.14203451573848724
Valid Loss:  0.13270321488380432
Epoch:  114  	Training Loss: 0.10653014481067657
Test Loss:  0.14203450083732605
Valid Loss:  0.13270319998264313
Epoch:  115  	Training Loss: 0.10653011500835419
Test Loss:  0.14203448593616486
Valid Loss:  0.13270318508148193
Epoch:  116  	Training Loss: 0.1065300777554512
Test Loss:  0.14203445613384247
Valid Loss:  0.13270315527915955
Epoch:  117  	Training Loss: 0.10653004050254822
Test Loss:  0.14203442633152008
Valid Loss:  0.13270312547683716
Epoch:  118  	Training Loss: 0.10653001815080643
Test Loss:  0.1420344114303589
Valid Loss:  0.13270311057567596
Epoch:  119  	Training Loss: 0.10652998834848404
Test Loss:  0.1420343965291977
Valid Loss:  0.13270309567451477
Epoch:  120  	Training Loss: 0.10652995109558105
Test Loss:  0.1420343816280365
Valid Loss:  0.13270306587219238
Epoch:  121  	Training Loss: 0.10652992129325867
Test Loss:  0.1420343518257141
Valid Loss:  0.1327030509710312
Epoch:  122  	Training Loss: 0.10652989149093628
Test Loss:  0.14203432202339172
Valid Loss:  0.13270303606987
Epoch:  123  	Training Loss: 0.10652986168861389
Test Loss:  0.14203432202339172
Valid Loss:  0.13270303606987
Epoch:  124  	Training Loss: 0.1065298318862915
Test Loss:  0.14203430712223053
Valid Loss:  0.1327030062675476
Epoch:  125  	Training Loss: 0.10652980208396912
Test Loss:  0.14203429222106934
Valid Loss:  0.13270297646522522
Epoch:  126  	Training Loss: 0.10652977228164673
Test Loss:  0.14203427731990814
Valid Loss:  0.13270297646522522
Epoch:  127  	Training Loss: 0.10652974247932434
Test Loss:  0.14203424751758575
Valid Loss:  0.13270294666290283
Epoch:  128  	Training Loss: 0.10652972012758255
Test Loss:  0.14203423261642456
Valid Loss:  0.13270291686058044
Epoch:  129  	Training Loss: 0.10652968287467957
Test Loss:  0.14203420281410217
Valid Loss:  0.13270291686058044
Epoch:  130  	Training Loss: 0.10652966052293777
Test Loss:  0.14203420281410217
Valid Loss:  0.13270288705825806
Epoch:  131  	Training Loss: 0.10652963817119598
Test Loss:  0.14203417301177979
Valid Loss:  0.13270287215709686
Epoch:  132  	Training Loss: 0.106529600918293
Test Loss:  0.1420341432094574
Valid Loss:  0.13270285725593567
Epoch:  133  	Training Loss: 0.1065295860171318
Test Loss:  0.1420341432094574
Valid Loss:  0.13270284235477448
Epoch:  134  	Training Loss: 0.10652956366539001
Test Loss:  0.142034113407135
Valid Loss:  0.13270282745361328
Epoch:  135  	Training Loss: 0.10652954876422882
Test Loss:  0.142034113407135
Valid Loss:  0.1327027976512909
Epoch:  136  	Training Loss: 0.10652953386306763
Test Loss:  0.14203408360481262
Valid Loss:  0.1327027827501297
Epoch:  137  	Training Loss: 0.10652952641248703
Test Loss:  0.14203406870365143
Valid Loss:  0.1327027678489685
Epoch:  138  	Training Loss: 0.10652951151132584
Test Loss:  0.14203405380249023
Valid Loss:  0.1327027529478073
Epoch:  139  	Training Loss: 0.10652949661016464
Test Loss:  0.14203405380249023
Valid Loss:  0.13270273804664612
Epoch:  140  	Training Loss: 0.10652948170900345
Test Loss:  0.14203402400016785
Valid Loss:  0.13270272314548492
Epoch:  141  	Training Loss: 0.10652947425842285
Test Loss:  0.14203400909900665
Valid Loss:  0.13270270824432373
Epoch:  142  	Training Loss: 0.10652945935726166
Test Loss:  0.14203399419784546
Valid Loss:  0.13270267844200134
Epoch:  143  	Training Loss: 0.10652945190668106
Test Loss:  0.14203399419784546
Valid Loss:  0.13270267844200134
Epoch:  144  	Training Loss: 0.10652942955493927
Test Loss:  0.14203396439552307
Valid Loss:  0.13270266354084015
Epoch:  145  	Training Loss: 0.10652942210435867
Test Loss:  0.14203393459320068
Valid Loss:  0.13270264863967896
Epoch:  146  	Training Loss: 0.10652940720319748
Test Loss:  0.14203393459320068
Valid Loss:  0.13270261883735657
 29%|██▉       | 147/500 [01:44<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:44<01:58,  2.95it/s] 30%|███       | 151/500 [01:51<07:05,  1.22s/it] 31%|███       | 153/500 [01:51<05:03,  1.14it/s] 31%|███       | 155/500 [01:51<03:37,  1.58it/s] 31%|███▏      | 157/500 [01:51<02:38,  2.17it/s] 32%|███▏      | 159/500 [01:51<01:57,  2.91it/s] 32%|███▏      | 161/500 [01:58<06:48,  1.21s/it] 33%|███▎      | 163/500 [01:58<04:51,  1.16it/s] 33%|███▎      | 165/500 [01:58<03:29,  1.60it/s] 33%|███▎      | 167/500 [01:58<02:32,  2.18it/s] 34%|███▍      | 169/500 [01:58<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:05<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:05<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:05<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:05<02:27,  2.20it/s] 36%|███▌      | 179/500 [02:05<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:12<06:34,  1.24s/it] 37%|███▋      | 183/500 [02:12<04:41,  1.13it/s] 37%|███▋      | 185/500 [02:12<03:22,  1.56it/s] 37%|███▋      | 187/500 [02:12<02:27,  2.12it/s] 38%|███▊      | 189/500 [02:13<01:49,  2.85it/s] 38%|███▊      | 191/500 [02:19<06:11,  1.20s/it] 39%|███▊      | 193/500 [02:19<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:19<03:13,  1.58it/s] 39%|███▉      | 197/500 [02:20<02:22,  2.13it/s] 40%|███▉      | 199/500 [02:20<01:45,  2.85it/s] 40%|████      | 201/500 [02:26<05:52,  1.18s/it] 41%|████      | 203/500 [02:26<04:13,  1.17it/s] 41%|████      | 205/500 [02:26<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:26<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:26<01:38,  2.97it/s] 42%|████▏     | 209/500 [02:38<01:38,  2.97it/s] 42%|████▏     | 211/500 [02:39<10:21,  2.15s/it] 43%|████▎     | 213/500 [02:39<07:17,  1.52s/it] 43%|████▎     | 215/500 [02:39<05:09,  1.09s/it] 43%|████▎     | 217/500 [02:40<03:40,  1.28it/s]Epoch:  147  	Training Loss: 0.10652938485145569
Test Loss:  0.1420339196920395
Valid Loss:  0.13270261883735657
Epoch:  148  	Training Loss: 0.10652938485145569
Test Loss:  0.1420339047908783
Valid Loss:  0.13270258903503418
Epoch:  149  	Training Loss: 0.1065293699502945
Test Loss:  0.1420338898897171
Valid Loss:  0.13270257413387299
Epoch:  150  	Training Loss: 0.1065293550491333
Test Loss:  0.1420338749885559
Valid Loss:  0.1327025443315506
Epoch:  151  	Training Loss: 0.1065293475985527
Test Loss:  0.14203384518623352
Valid Loss:  0.1327025294303894
Epoch:  152  	Training Loss: 0.1065293401479721
Test Loss:  0.14203384518623352
Valid Loss:  0.1327025145292282
Epoch:  153  	Training Loss: 0.10652931779623032
Test Loss:  0.14203381538391113
Valid Loss:  0.1327025145292282
Epoch:  154  	Training Loss: 0.10652931034564972
Test Loss:  0.14203380048274994
Valid Loss:  0.13270249962806702
Epoch:  155  	Training Loss: 0.10652929544448853
Test Loss:  0.14203378558158875
Valid Loss:  0.13270248472690582
Epoch:  156  	Training Loss: 0.10652928054332733
Test Loss:  0.14203377068042755
Valid Loss:  0.13270245492458344
Epoch:  157  	Training Loss: 0.10652926564216614
Test Loss:  0.14203375577926636
Valid Loss:  0.13270244002342224
Epoch:  158  	Training Loss: 0.10652925819158554
Test Loss:  0.14203375577926636
Valid Loss:  0.13270241022109985
Epoch:  159  	Training Loss: 0.10652924329042435
Test Loss:  0.14203371107578278
Valid Loss:  0.13270241022109985
Epoch:  160  	Training Loss: 0.10652922838926315
Test Loss:  0.14203371107578278
Valid Loss:  0.13270238041877747
Epoch:  161  	Training Loss: 0.10652922093868256
Test Loss:  0.1420336812734604
Valid Loss:  0.13270238041877747
Epoch:  162  	Training Loss: 0.10652921348810196
Test Loss:  0.1420336663722992
Valid Loss:  0.13270236551761627
Epoch:  163  	Training Loss: 0.10652919113636017
Test Loss:  0.142033651471138
Valid Loss:  0.13270235061645508
Epoch:  164  	Training Loss: 0.10652918368577957
Test Loss:  0.1420336365699768
Valid Loss:  0.1327023208141327
Epoch:  165  	Training Loss: 0.10652916878461838
Test Loss:  0.14203360676765442
Valid Loss:  0.1327023208141327
Epoch:  166  	Training Loss: 0.10652916133403778
Test Loss:  0.14203360676765442
Valid Loss:  0.1327022910118103
Epoch:  167  	Training Loss: 0.10652914643287659
Test Loss:  0.14203359186649323
Valid Loss:  0.1327022910118103
Epoch:  168  	Training Loss: 0.1065291315317154
Test Loss:  0.14203357696533203
Valid Loss:  0.13270226120948792
Epoch:  169  	Training Loss: 0.1065291240811348
Test Loss:  0.14203354716300964
Valid Loss:  0.13270223140716553
Epoch:  170  	Training Loss: 0.1065291091799736
Test Loss:  0.14203354716300964
Valid Loss:  0.13270223140716553
Epoch:  171  	Training Loss: 0.106529101729393
Test Loss:  0.14203353226184845
Valid Loss:  0.13270220160484314
Epoch:  172  	Training Loss: 0.10652908682823181
Test Loss:  0.14203350245952606
Valid Loss:  0.13270217180252075
Epoch:  173  	Training Loss: 0.10652906447649002
Test Loss:  0.14203348755836487
Valid Loss:  0.13270217180252075
Epoch:  174  	Training Loss: 0.10652905702590942
Test Loss:  0.14203348755836487
Valid Loss:  0.13270217180252075
Epoch:  175  	Training Loss: 0.10652904957532883
Test Loss:  0.14203345775604248
Valid Loss:  0.13270214200019836
Epoch:  176  	Training Loss: 0.10652902722358704
Test Loss:  0.14203345775604248
Valid Loss:  0.13270212709903717
Epoch:  177  	Training Loss: 0.10652902722358704
Test Loss:  0.1420334279537201
Valid Loss:  0.13270211219787598
Epoch:  178  	Training Loss: 0.10652900487184525
Test Loss:  0.1420334130525589
Valid Loss:  0.1327020823955536
Epoch:  179  	Training Loss: 0.10652899742126465
Test Loss:  0.1420333981513977
Valid Loss:  0.1327020823955536
Epoch:  180  	Training Loss: 0.10652898252010345
Test Loss:  0.14203336834907532
Valid Loss:  0.1327020525932312
Epoch:  181  	Training Loss: 0.10652896761894226
Test Loss:  0.14203335344791412
Valid Loss:  0.13270203769207
Epoch:  182  	Training Loss: 0.10652896016836166
Test Loss:  0.14203333854675293
Valid Loss:  0.1327020227909088
Epoch:  183  	Training Loss: 0.10652893781661987
Test Loss:  0.14203332364559174
Valid Loss:  0.13270200788974762
Epoch:  184  	Training Loss: 0.10652893036603928
Test Loss:  0.14203330874443054
Valid Loss:  0.13270199298858643
Epoch:  185  	Training Loss: 0.10652892291545868
Test Loss:  0.14203330874443054
Valid Loss:  0.13270197808742523
Epoch:  186  	Training Loss: 0.10652890801429749
Test Loss:  0.14203327894210815
Valid Loss:  0.13270196318626404
Epoch:  187  	Training Loss: 0.10652889311313629
Test Loss:  0.14203326404094696
Valid Loss:  0.13270193338394165
Epoch:  188  	Training Loss: 0.1065288856625557
Test Loss:  0.14203324913978577
Valid Loss:  0.13270193338394165
Epoch:  189  	Training Loss: 0.1065288707613945
Test Loss:  0.14203321933746338
Valid Loss:  0.13270190358161926
Epoch:  190  	Training Loss: 0.1065288558602333
Test Loss:  0.14203320443630219
Valid Loss:  0.13270188868045807
Epoch:  191  	Training Loss: 0.10652884840965271
Test Loss:  0.142033189535141
Valid Loss:  0.13270188868045807
Epoch:  192  	Training Loss: 0.10652883350849152
Test Loss:  0.142033189535141
Valid Loss:  0.13270185887813568
Epoch:  193  	Training Loss: 0.10652882605791092
Test Loss:  0.1420331597328186
Valid Loss:  0.1327018439769745
Epoch:  194  	Training Loss: 0.10652881115674973
Test Loss:  0.1420331448316574
Valid Loss:  0.1327018290758133
Epoch:  195  	Training Loss: 0.10652880370616913
Test Loss:  0.14203312993049622
Valid Loss:  0.1327018141746521
Epoch:  196  	Training Loss: 0.10652878135442734
Test Loss:  0.14203312993049622
Valid Loss:  0.1327017992734909
Epoch:  197  	Training Loss: 0.10652877390384674
Test Loss:  0.14203310012817383
Valid Loss:  0.1327017843723297
Epoch:  198  	Training Loss: 0.10652875900268555
Test Loss:  0.14203308522701263
Valid Loss:  0.13270176947116852
Epoch:  199  	Training Loss: 0.10652874410152435
Test Loss:  0.14203307032585144
Valid Loss:  0.13270175457000732
Epoch:  200  	Training Loss: 0.10652872920036316
Test Loss:  0.14203305542469025
Valid Loss:  0.13270172476768494
Epoch:  201  	Training Loss: 0.10652872174978256
Test Loss:  0.14203304052352905
Valid Loss:  0.13270170986652374
Epoch:  202  	Training Loss: 0.10652871429920197
Test Loss:  0.14203301072120667
Valid Loss:  0.13270169496536255
Epoch:  203  	Training Loss: 0.10652870684862137
Test Loss:  0.14203301072120667
Valid Loss:  0.13270169496536255
Epoch:  204  	Training Loss: 0.10652868449687958
Test Loss:  0.14203298091888428
Valid Loss:  0.13270166516304016
Epoch:  205  	Training Loss: 0.10652866959571838
Test Loss:  0.14203298091888428
Valid Loss:  0.13270163536071777
Epoch:  206  	Training Loss: 0.10652865469455719
Test Loss:  0.1420329511165619
Valid Loss:  0.13270163536071777
Epoch:  207  	Training Loss: 0.10652865469455719
Test Loss:  0.1420329511165619
Valid Loss:  0.13270160555839539
Epoch:  208  	Training Loss: 0.106528639793396
Test Loss:  0.1420329213142395
Valid Loss:  0.13270160555839539
Epoch:  209  	Training Loss: 0.1065286248922348
Test Loss:  0.1420329064130783
Valid Loss:  0.132701575756073
Epoch:  210  	Training Loss: 0.10652860999107361
Test Loss:  0.14203289151191711
Valid Loss:  0.1327015608549118
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.10652860254049301
Test Loss:  0.14203289151191711
Valid Loss:  0.1327015459537506
Epoch:  212  	Training Loss: 0.10652859508991241
Test Loss:  0.14203286170959473
Valid Loss:  0.1327015459537506
Epoch:  213  	Training Loss: 0.10652858763933182
Test Loss:  0.14203286170959473
Valid Loss:  0.13270153105258942
Epoch:  214  	Training Loss: 0.10652858763933182
Test Loss:  0.14203286170959473
Valid Loss:  0.13270153105258942
Epoch:  215  	Training Loss: 0.10652858018875122
Test Loss:  0.14203286170959473
Valid Loss:  0.13270153105258942
Epoch:  216  	Training Loss: 0.10652858018875122
Test Loss:  0.14203284680843353
Valid Loss:  0.13270151615142822
Epoch:  217  	Training Loss: 0.10652856528759003
Test Loss:  0.14203283190727234
Valid Loss:  0.13270151615142822
 44%|████▍     | 219/500 [02:40<02:38,  1.77it/s] 44%|████▍     | 221/500 [02:52<10:35,  2.28s/it] 45%|████▍     | 223/500 [02:52<07:27,  1.61s/it] 45%|████▌     | 225/500 [02:59<09:47,  2.14s/it] 45%|████▌     | 227/500 [02:59<06:53,  1.52s/it] 46%|████▌     | 229/500 [02:59<04:52,  1.08s/it] 46%|████▌     | 231/500 [03:12<11:51,  2.65s/it] 47%|████▋     | 233/500 [03:12<08:21,  1.88s/it] 47%|████▋     | 235/500 [03:19<10:06,  2.29s/it] 47%|████▋     | 237/500 [03:19<07:06,  1.62s/it] 48%|████▊     | 239/500 [03:19<05:01,  1.16s/it] 48%|████▊     | 241/500 [03:32<11:41,  2.71s/it] 49%|████▊     | 243/500 [03:32<08:12,  1.92s/it] 49%|████▉     | 245/500 [03:38<09:46,  2.30s/it] 49%|████▉     | 247/500 [03:38<06:52,  1.63s/it] 50%|████▉     | 249/500 [03:38<04:51,  1.16s/it] 50%|████▉     | 249/500 [03:48<04:51,  1.16s/it] 50%|█████     | 251/500 [03:51<11:12,  2.70s/it] 51%|█████     | 253/500 [03:51<07:52,  1.91s/it] 51%|█████     | 255/500 [03:57<09:18,  2.28s/it] 51%|█████▏    | 257/500 [03:58<06:33,  1.62s/it] 52%|█████▏    | 259/500 [03:58<04:37,  1.15s/it] 52%|█████▏    | 259/500 [04:08<04:37,  1.15s/it] 52%|█████▏    | 261/500 [04:11<10:53,  2.73s/it] 53%|█████▎    | 263/500 [04:11<07:38,  1.93s/it] 53%|█████▎    | 265/500 [04:17<08:58,  2.29s/it] 53%|█████▎    | 267/500 [04:17<06:18,  1.62s/it] 54%|█████▍    | 269/500 [04:17<04:27,  1.16s/it] 54%|█████▍    | 271/500 [04:24<06:44,  1.77s/it] 55%|█████▍    | 273/500 [04:24<04:45,  1.26s/it] 55%|█████▌    | 275/500 [04:30<06:56,  1.85s/it] 55%|█████▌    | 277/500 [04:30<04:53,  1.32s/it]Epoch:  218  	Training Loss: 0.10652855783700943
Test Loss:  0.14203283190727234
Valid Loss:  0.13270150125026703
Epoch:  219  	Training Loss: 0.10652855038642883
Test Loss:  0.14203281700611115
Valid Loss:  0.13270148634910583
Epoch:  220  	Training Loss: 0.10652855038642883
Test Loss:  0.14203281700611115
Valid Loss:  0.13270147144794464
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.10652854293584824
Test Loss:  0.14203280210494995
Valid Loss:  0.13270147144794464
Epoch:  222  	Training Loss: 0.10652853548526764
Test Loss:  0.14203280210494995
Valid Loss:  0.13270147144794464
Epoch:  223  	Training Loss: 0.10652853548526764
Test Loss:  0.14203280210494995
Valid Loss:  0.13270147144794464
Epoch:  224  	Training Loss: 0.10652853548526764
Test Loss:  0.14203280210494995
Valid Loss:  0.13270145654678345
Epoch:  225  	Training Loss: 0.10652853548526764
Test Loss:  0.14203278720378876
Valid Loss:  0.13270145654678345
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.10652852803468704
Test Loss:  0.14203278720378876
Valid Loss:  0.13270145654678345
Epoch:  227  	Training Loss: 0.10652852803468704
Test Loss:  0.14203278720378876
Valid Loss:  0.13270145654678345
Epoch:  228  	Training Loss: 0.10652852803468704
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  229  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  230  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.10652852803468704
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  232  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  233  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  234  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  235  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  237  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  238  	Training Loss: 0.10652851313352585
Test Loss:  0.14203278720378876
Valid Loss:  0.13270144164562225
Epoch:  239  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  240  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  242  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  243  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  244  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  245  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  247  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  248  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  249  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  250  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  252  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  253  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  254  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  255  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  257  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  258  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  259  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  260  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.10652852058410645
Test Loss:  0.14203275740146637
Valid Loss:  0.13270144164562225
Epoch:  262  	Training Loss: 0.10652851313352585
Test Loss:  0.14203275740146637
Valid Loss:  0.13270142674446106
Epoch:  263  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  264  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  265  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  267  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  268  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  269  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  270  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  271  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  272  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  273  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  274  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  275  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  277  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
 56%|█████▌    | 279/500 [04:30<03:28,  1.06it/s] 56%|█████▌    | 281/500 [04:43<09:22,  2.57s/it] 57%|█████▋    | 283/500 [04:43<06:34,  1.82s/it] 57%|█████▋    | 285/500 [04:50<07:57,  2.22s/it] 57%|█████▋    | 287/500 [04:50<05:35,  1.58s/it] 58%|█████▊    | 289/500 [04:50<03:56,  1.12s/it] 58%|█████▊    | 291/500 [05:03<09:23,  2.69s/it] 59%|█████▊    | 293/500 [05:03<06:34,  1.91s/it] 59%|█████▉    | 295/500 [05:09<07:55,  2.32s/it] 59%|█████▉    | 297/500 [05:09<05:33,  1.64s/it] 60%|█████▉    | 299/500 [05:10<03:55,  1.17s/it] 60%|██████    | 301/500 [05:22<09:07,  2.75s/it] 61%|██████    | 303/500 [05:23<06:23,  1.95s/it] 61%|██████    | 305/500 [05:29<07:32,  2.32s/it] 61%|██████▏   | 307/500 [05:29<05:18,  1.65s/it] 62%|██████▏   | 309/500 [05:29<03:45,  1.18s/it] 62%|██████▏   | 311/500 [05:44<09:18,  2.95s/it] 62%|██████▏   | 312/500 [05:44<07:41,  2.45s/it] 63%|██████▎   | 314/500 [05:44<05:08,  1.66s/it] 63%|██████▎   | 316/500 [05:52<07:27,  2.43s/it] 63%|██████▎   | 317/500 [05:52<06:05,  2.00s/it] 64%|██████▍   | 319/500 [05:52<04:00,  1.33s/it] 64%|██████▍   | 320/500 [06:00<07:50,  2.61s/it] 64%|██████▍   | 321/500 [06:08<11:08,  3.73s/it] 64%|██████▍   | 322/500 [06:08<08:29,  2.86s/it] 65%|██████▍   | 324/500 [06:08<05:04,  1.73s/it] 65%|██████▌   | 325/500 [06:16<09:08,  3.13s/it] 65%|██████▌   | 327/500 [06:16<05:34,  1.93s/it] 66%|██████▌   | 329/500 [06:16<03:36,  1.26s/it] 66%|██████▌   | 329/500 [06:28<03:36,  1.26s/it] 66%|██████▌   | 331/500 [06:31<09:19,  3.31s/it] 67%|██████▋   | 333/500 [06:31<06:17,  2.26s/it] 67%|██████▋   | 335/500 [06:39<07:44,  2.81s/it]Epoch:  278  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  279  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  280  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  282  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  283  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  284  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  285  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  287  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  288  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  289  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  290  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  292  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  293  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  294  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  295  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  297  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  298  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  299  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  300  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  302  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  303  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  304  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  305  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.10652850568294525
Test Loss:  0.14203275740146637
Valid Loss:  0.13270144164562225
Epoch:  307  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  308  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  309  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  310  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  312  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  313  	Training Loss: 0.10652851313352585
Test Loss:  0.14203275740146637
Valid Loss:  0.13270144164562225
Epoch:  314  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  315  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  317  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  318  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  319  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  320  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  322  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  323  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  324  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  325  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  327  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  328  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  329  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  330  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  332  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  333  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  334  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  335  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
 67%|██████▋   | 337/500 [06:39<05:19,  1.96s/it] 68%|██████▊   | 339/500 [06:39<03:42,  1.38s/it] 68%|██████▊   | 340/500 [06:46<06:07,  2.30s/it] 68%|██████▊   | 341/500 [06:52<08:13,  3.10s/it] 69%|██████▊   | 343/500 [06:52<05:10,  1.98s/it] 69%|██████▉   | 345/500 [06:58<06:12,  2.41s/it] 69%|██████▉   | 347/500 [06:59<04:09,  1.63s/it] 70%|██████▉   | 349/500 [06:59<02:50,  1.13s/it] 70%|███████   | 351/500 [07:11<06:51,  2.76s/it] 71%|███████   | 353/500 [07:12<04:43,  1.93s/it] 71%|███████   | 355/500 [07:18<05:35,  2.31s/it] 71%|███████▏  | 357/500 [07:18<03:53,  1.63s/it] 72%|███████▏  | 359/500 [07:18<02:43,  1.16s/it] 72%|███████▏  | 359/500 [07:28<02:43,  1.16s/it] 72%|███████▏  | 361/500 [07:32<06:33,  2.83s/it] 73%|███████▎  | 363/500 [07:32<04:34,  2.00s/it] 73%|███████▎  | 365/500 [07:38<05:17,  2.35s/it] 73%|███████▎  | 367/500 [07:38<03:41,  1.67s/it] 74%|███████▍  | 369/500 [07:38<02:35,  1.18s/it] 74%|███████▍  | 369/500 [07:48<02:35,  1.18s/it] 74%|███████▍  | 371/500 [07:51<05:51,  2.73s/it] 75%|███████▍  | 373/500 [07:51<04:05,  1.93s/it] 75%|███████▌  | 375/500 [07:57<04:48,  2.30s/it] 75%|███████▌  | 377/500 [07:58<03:20,  1.63s/it] 76%|███████▌  | 379/500 [07:58<02:20,  1.16s/it] 76%|███████▌  | 379/500 [08:08<02:20,  1.16s/it] 76%|███████▌  | 381/500 [08:10<05:20,  2.69s/it] 77%|███████▋  | 383/500 [08:10<03:43,  1.91s/it] 77%|███████▋  | 385/500 [08:17<04:23,  2.29s/it] 77%|███████▋  | 387/500 [08:17<03:03,  1.62s/it] 78%|███████▊  | 389/500 [08:17<02:08,  1.16s/it] 78%|███████▊  | 389/500 [08:29<02:08,  1.16s/it] 78%|███████▊  | 391/500 [08:30<04:52,  2.69s/it] 78%|███████▊  | 392/500 [08:30<04:01,  2.23s/it] 79%|███████▉  | 394/500 [08:30<02:39,  1.51s/it]Epoch:  337  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  338  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  339  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  340  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  342  	Training Loss: 0.10652850568294525
Test Loss:  0.14203275740146637
Valid Loss:  0.13270144164562225
Epoch:  343  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  344  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  345  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  347  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  348  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  349  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  350  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  352  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  353  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  354  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  355  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  357  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  358  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  359  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  360  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  362  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  363  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  364  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  365  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  367  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  368  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  369  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  370  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  372  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  373  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  374  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  375  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  377  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  378  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  379  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  380  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  382  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  383  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  384  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  385  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  387  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  388  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  389  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  390  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  392  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  393  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  394  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  395  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
 79%|███████▉  | 396/500 [08:36<03:34,  2.06s/it] 80%|███████▉  | 398/500 [08:36<02:25,  1.43s/it] 80%|████████  | 400/500 [08:43<03:18,  1.98s/it] 80%|████████  | 401/500 [08:49<04:31,  2.75s/it] 81%|████████  | 403/500 [08:49<02:57,  1.83s/it] 81%|████████  | 405/500 [08:55<03:34,  2.26s/it] 81%|████████▏ | 407/500 [08:56<02:25,  1.56s/it] 82%|████████▏ | 409/500 [08:56<01:39,  1.09s/it] 82%|████████▏ | 411/500 [09:08<04:00,  2.70s/it] 83%|████████▎ | 413/500 [09:08<02:44,  1.89s/it] 83%|████████▎ | 415/500 [09:15<03:14,  2.29s/it] 83%|████████▎ | 417/500 [09:15<02:13,  1.61s/it] 84%|████████▍ | 419/500 [09:15<01:32,  1.15s/it] 84%|████████▍ | 421/500 [09:28<03:37,  2.75s/it] 85%|████████▍ | 423/500 [09:28<02:29,  1.94s/it] 85%|████████▌ | 425/500 [09:34<02:53,  2.32s/it] 85%|████████▌ | 427/500 [09:35<01:59,  1.64s/it] 86%|████████▌ | 429/500 [09:35<01:22,  1.17s/it] 86%|████████▌ | 431/500 [09:47<03:08,  2.73s/it] 87%|████████▋ | 433/500 [09:48<02:09,  1.93s/it] 87%|████████▋ | 435/500 [09:54<02:29,  2.31s/it] 87%|████████▋ | 437/500 [09:54<01:43,  1.64s/it] 88%|████████▊ | 439/500 [09:54<01:11,  1.17s/it] 88%|████████▊ | 441/500 [10:07<02:40,  2.72s/it] 89%|████████▊ | 443/500 [10:07<01:49,  1.93s/it] 89%|████████▉ | 445/500 [10:14<02:07,  2.31s/it] 89%|████████▉ | 447/500 [10:14<01:27,  1.64s/it] 90%|████████▉ | 449/500 [10:14<00:59,  1.17s/it] 90%|█████████ | 451/500 [10:26<02:11,  2.69s/it] 91%|█████████ | 453/500 [10:26<01:29,  1.91s/it]Epoch:  396  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  397  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  398  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  399  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  400  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  402  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  403  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  404  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  405  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  407  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  408  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  409  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  410  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  412  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  413  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  414  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  415  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  417  	Training Loss: 0.10652851313352585
Test Loss:  0.14203275740146637
Valid Loss:  0.13270144164562225
Epoch:  418  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  419  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  420  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  422  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  423  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  424  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  425  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  427  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  428  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  429  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  430  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  432  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  433  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  434  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  435  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  437  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  438  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  439  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  440  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.10652850568294525
Test Loss:  0.14203275740146637
Valid Loss:  0.13270144164562225
Epoch:  442  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  443  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  444  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  445  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  447  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  448  	Training Loss: 0.10652850568294525
Test Loss:  0.14203275740146637
Valid Loss:  0.13270142674446106
Epoch:  449  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  450  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  452  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  453  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  454  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  455  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
 91%|█████████ | 455/500 [10:33<01:43,  2.30s/it] 91%|█████████▏| 457/500 [10:33<01:10,  1.63s/it] 92%|█████████▏| 459/500 [10:33<00:47,  1.17s/it] 92%|█████████▏| 461/500 [10:46<01:44,  2.69s/it] 93%|█████████▎| 463/500 [10:46<01:10,  1.90s/it] 93%|█████████▎| 465/500 [10:52<01:20,  2.29s/it] 93%|█████████▎| 467/500 [10:52<00:53,  1.62s/it] 94%|█████████▍| 469/500 [10:52<00:35,  1.15s/it] 94%|█████████▍| 471/500 [11:05<01:18,  2.70s/it] 95%|█████████▍| 473/500 [11:05<00:51,  1.92s/it] 95%|█████████▌| 475/500 [11:12<00:57,  2.29s/it] 95%|█████████▌| 477/500 [11:12<00:37,  1.63s/it] 96%|█████████▌| 479/500 [11:12<00:24,  1.16s/it] 96%|█████████▌| 481/500 [11:24<00:51,  2.69s/it] 97%|█████████▋| 483/500 [11:25<00:32,  1.91s/it] 97%|█████████▋| 485/500 [11:31<00:34,  2.28s/it] 97%|█████████▋| 487/500 [11:31<00:21,  1.63s/it] 98%|█████████▊| 489/500 [11:31<00:12,  1.16s/it] 98%|█████████▊| 491/500 [11:44<00:24,  2.72s/it] 99%|█████████▊| 493/500 [11:44<00:13,  1.93s/it] 99%|█████████▉| 495/500 [11:51<00:11,  2.35s/it] 99%|█████████▉| 497/500 [11:51<00:05,  1.67s/it]100%|█████████▉| 499/500 [11:51<00:01,  1.20s/it]100%|██████████| 500/500 [11:58<00:00,  2.11s/it]100%|██████████| 500/500 [11:58<00:00,  1.44s/it]
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  457  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  458  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  459  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  460  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  462  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  463  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  464  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  465  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  467  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  468  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  469  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  470  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  472  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  473  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  474  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  475  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  477  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  478  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  479  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  480  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  482  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  483  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  484  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  485  	Training Loss: 0.10652851313352585
Test Loss:  0.14203275740146637
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  487  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  488  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  489  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  490  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  492  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  493  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  494  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  495  	Training Loss: 0.10652852058410645
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  497  	Training Loss: 0.10652850568294525
Test Loss:  0.14203277230262756
Valid Loss:  0.13270145654678345
Epoch:  498  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270142674446106
Epoch:  499  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
Epoch:  500  	Training Loss: 0.10652851313352585
Test Loss:  0.14203277230262756
Valid Loss:  0.13270144164562225
**************************************************learning rate decay**************************************************
seed is  19
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:45,  6.34s/it]  1%|          | 3/500 [00:06<14:03,  1.70s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:17,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.85it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:47,  1.23s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:20<05:01,  1.58it/s]  5%|▌         | 27/500 [00:20<03:41,  2.13it/s]  6%|▌         | 29/500 [00:20<02:44,  2.86it/s]  6%|▌         | 31/500 [00:27<09:31,  1.22s/it]  7%|▋         | 33/500 [00:27<06:49,  1.14it/s]  7%|▋         | 35/500 [00:33<12:13,  1.58s/it]  7%|▋         | 37/500 [00:34<08:41,  1.13s/it]  8%|▊         | 39/500 [00:34<06:11,  1.24it/s]  8%|▊         | 41/500 [00:40<11:43,  1.53s/it]  9%|▊         | 43/500 [00:40<08:20,  1.10s/it]  9%|▉         | 45/500 [00:40<05:58,  1.27it/s]  9%|▉         | 47/500 [00:41<04:18,  1.75it/s] 10%|▉         | 49/500 [00:41<03:08,  2.39it/s] 10%|█         | 51/500 [00:47<09:25,  1.26s/it] 11%|█         | 53/500 [00:47<06:46,  1.10it/s] 11%|█         | 55/500 [00:47<04:54,  1.51it/s] 11%|█▏        | 57/500 [00:48<03:36,  2.04it/s] 12%|█▏        | 59/500 [00:48<02:40,  2.74it/s] 12%|█▏        | 61/500 [00:54<09:00,  1.23s/it] 13%|█▎        | 63/500 [00:54<06:26,  1.13it/s] 13%|█▎        | 65/500 [00:55<04:38,  1.56it/s] 13%|█▎        | 67/500 [00:55<03:23,  2.13it/s] 14%|█▍        | 69/500 [00:55<02:30,  2.87it/s]Epoch:  1  	Training Loss: 0.03900011256337166
Test Loss:  5.328176498413086
Valid Loss:  5.189913749694824
Epoch:  2  	Training Loss: 5.491892337799072
Test Loss:  53.92289733886719
Valid Loss:  51.20673751831055
Epoch:  3  	Training Loss: 53.494293212890625
Test Loss:  0.7149701118469238
Valid Loss:  0.7233973741531372
Epoch:  4  	Training Loss: 0.7538653612136841
Test Loss:  0.7149252891540527
Valid Loss:  0.7232932448387146
Epoch:  5  	Training Loss: 0.7537702322006226
Test Loss:  0.7148828506469727
Valid Loss:  0.7231945991516113
Epoch:  6  	Training Loss: 0.7536834478378296
Test Loss:  0.7148417234420776
Valid Loss:  0.72310870885849
Epoch:  7  	Training Loss: 0.7536066174507141
Test Loss:  0.7148100137710571
Valid Loss:  0.7230374217033386
Epoch:  8  	Training Loss: 0.7535414695739746
Test Loss:  0.7147852778434753
Valid Loss:  0.7229716181755066
Epoch:  9  	Training Loss: 0.753476619720459
Test Loss:  0.7147561311721802
Valid Loss:  0.7229106426239014
Epoch:  10  	Training Loss: 0.7534093856811523
Test Loss:  0.7147223949432373
Valid Loss:  0.7228472232818604
Epoch:  11  	Training Loss: 0.7533437013626099
Test Loss:  0.7146879434585571
Valid Loss:  0.7227869033813477
Epoch:  12  	Training Loss: 0.7532824277877808
Test Loss:  0.099571593105793
Valid Loss:  0.08247636258602142
Epoch:  13  	Training Loss: 0.0857999175786972
Test Loss:  0.003922187723219395
Valid Loss:  0.006538250483572483
Epoch:  14  	Training Loss: 0.010702047497034073
Test Loss:  0.003854325506836176
Valid Loss:  0.006316294893622398
Epoch:  15  	Training Loss: 0.010262356139719486
Test Loss:  0.003801692044362426
Valid Loss:  0.006120188161730766
Epoch:  16  	Training Loss: 0.009870929643511772
Test Loss:  0.0037582586519420147
Valid Loss:  0.005943037569522858
Epoch:  17  	Training Loss: 0.00951845571398735
Test Loss:  0.0037198318168520927
Valid Loss:  0.00577987264841795
Epoch:  18  	Training Loss: 0.009197717532515526
Test Loss:  0.003683578222990036
Valid Loss:  0.005627147853374481
Epoch:  19  	Training Loss: 0.008903112262487411
Test Loss:  0.003647636156529188
Valid Loss:  0.005482361651957035
Epoch:  20  	Training Loss: 0.008630270138382912
Test Loss:  0.0036108624190092087
Valid Loss:  0.005343779921531677
Epoch:  21  	Training Loss: 0.008375776931643486
Test Loss:  0.0035726092755794525
Valid Loss:  0.005210215225815773
Epoch:  22  	Training Loss: 0.008136953227221966
Test Loss:  0.014027082361280918
Valid Loss:  0.01016388088464737
Epoch:  23  	Training Loss: 0.010942645370960236
Test Loss:  0.06625071167945862
Valid Loss:  0.077660471200943
Epoch:  24  	Training Loss: 0.06543038785457611
Test Loss:  0.0201351810246706
Valid Loss:  0.020349804311990738
Epoch:  25  	Training Loss: 0.01712283492088318
Test Loss:  0.0023425493855029345
Valid Loss:  0.002513373037800193
Epoch:  26  	Training Loss: 0.00364859402179718
Test Loss:  0.0018163669155910611
Valid Loss:  0.0013037718599662185
Epoch:  27  	Training Loss: 0.001967495307326317
Test Loss:  0.0007526413537561893
Valid Loss:  0.0012349544558674097
Epoch:  28  	Training Loss: 0.0017419455107301474
Test Loss:  0.00142355402931571
Valid Loss:  0.0011225888738408685
Epoch:  29  	Training Loss: 0.001550712389871478
Test Loss:  0.0008070688927546144
Valid Loss:  0.0012190837878733873
Epoch:  30  	Training Loss: 0.0014767393004149199
Test Loss:  0.0011963800061494112
Valid Loss:  0.0011234527919441462
Epoch:  31  	Training Loss: 0.001423398032784462
Test Loss:  0.0008666191715747118
Valid Loss:  0.0011925860308110714
Epoch:  32  	Training Loss: 0.001393774407915771
Test Loss:  0.003955130465328693
Valid Loss:  0.0025851749815046787
Epoch:  33  	Training Loss: 0.003254307433962822
Test Loss:  0.02716706320643425
Valid Loss:  0.03165017068386078
Epoch:  34  	Training Loss: 0.03139606863260269
Test Loss:  0.18642094731330872
Valid Loss:  0.17084121704101562
Epoch:  35  	Training Loss: 0.15724550187587738
Test Loss:  0.09085948765277863
Valid Loss:  0.07938190549612045
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.07805430889129639
Test Loss:  0.08744627237319946
Valid Loss:  0.07625066488981247
Epoch:  37  	Training Loss: 0.07491347938776016
Test Loss:  0.08618075400590897
Valid Loss:  0.0751178190112114
Epoch:  38  	Training Loss: 0.07370917499065399
Test Loss:  0.08493822067975998
Valid Loss:  0.07400615513324738
Epoch:  39  	Training Loss: 0.0725284144282341
Test Loss:  0.08371824771165848
Valid Loss:  0.07291529327630997
Epoch:  40  	Training Loss: 0.07137064635753632
Test Loss:  0.08252041041851044
Valid Loss:  0.071844682097435
Epoch:  41  	Training Loss: 0.07023538649082184
Test Loss:  0.0813441276550293
Valid Loss:  0.07079380750656128
Epoch:  42  	Training Loss: 0.06912200897932053
Test Loss:  0.08018024265766144
Valid Loss:  0.06975443661212921
Epoch:  43  	Training Loss: 0.06802123039960861
Test Loss:  0.07903651893138885
Valid Loss:  0.06873355060815811
Epoch:  44  	Training Loss: 0.06694099307060242
Test Loss:  0.07791253179311752
Valid Loss:  0.06773076206445694
Epoch:  45  	Training Loss: 0.06588085740804672
Test Loss:  0.07698938250541687
Valid Loss:  0.06696580350399017
Epoch:  46  	Training Loss: 0.06515531241893768
Test Loss:  0.07679367065429688
Valid Loss:  0.06676708161830902
Epoch:  47  	Training Loss: 0.06503330171108246
Test Loss:  0.07672850787639618
Valid Loss:  0.06666665524244308
Epoch:  48  	Training Loss: 0.06498044729232788
Test Loss:  0.07669100165367126
Valid Loss:  0.06660618633031845
Epoch:  49  	Training Loss: 0.06494913250207901
Test Loss:  0.07666493952274323
Valid Loss:  0.06656655669212341
Epoch:  50  	Training Loss: 0.06492791324853897
Test Loss:  0.07664676010608673
Valid Loss:  0.06653690338134766
Epoch:  51  	Training Loss: 0.0649106502532959
Test Loss:  0.07663710415363312
Valid Loss:  0.0665162205696106
Epoch:  52  	Training Loss: 0.0648990049958229
Test Loss:  0.014206557534635067
Valid Loss:  0.012713227421045303
Epoch:  53  	Training Loss: 0.010268546640872955
Test Loss:  0.006696903612464666
Valid Loss:  0.006817345041781664
Epoch:  54  	Training Loss: 0.005980218760669231
Test Loss:  0.005263805855065584
Valid Loss:  0.00579982902854681
Epoch:  55  	Training Loss: 0.005578882060945034
Test Loss:  0.004885805305093527
Valid Loss:  0.005536051467061043
Epoch:  56  	Training Loss: 0.005515946075320244
Test Loss:  0.004758698400110006
Valid Loss:  0.005437131505459547
Epoch:  57  	Training Loss: 0.005483585875481367
Test Loss:  0.0047010090202093124
Valid Loss:  0.005382317118346691
Epoch:  58  	Training Loss: 0.005454285070300102
Test Loss:  0.004663755651563406
Valid Loss:  0.005340472795069218
Epoch:  59  	Training Loss: 0.005425556097179651
Test Loss:  0.004632904659956694
Valid Loss:  0.005302704870700836
Epoch:  60  	Training Loss: 0.005397091619670391
Test Loss:  0.004604322370141745
Valid Loss:  0.005266375839710236
Epoch:  61  	Training Loss: 0.0053688399493694305
Test Loss:  0.004576546140015125
Valid Loss:  0.005230744369328022
Epoch:  62  	Training Loss: 0.005340767093002796
Test Loss:  0.009884374216198921
Valid Loss:  0.007934875786304474
Epoch:  63  	Training Loss: 0.007154983468353748
Test Loss:  0.0031977579928934574
Valid Loss:  0.005336728412657976
Epoch:  64  	Training Loss: 0.008463900536298752
Test Loss:  0.0038083286490291357
Valid Loss:  0.004954679403454065
Epoch:  65  	Training Loss: 0.005996342282742262
Test Loss:  0.004396825563162565
Valid Loss:  0.005167429335415363
Epoch:  66  	Training Loss: 0.005582548677921295
Test Loss:  0.004554351791739464
Valid Loss:  0.005198434926569462
Epoch:  67  	Training Loss: 0.0054312534630298615
Test Loss:  0.004549173638224602
Valid Loss:  0.005147120915353298
Epoch:  68  	Training Loss: 0.005368271376937628
Test Loss:  0.0045180972665548325
Valid Loss:  0.0050790212117135525
Epoch:  69  	Training Loss: 0.005325693171471357
Test Loss:  0.0044769528321921825
Valid Loss:  0.005025722086429596
Epoch:  70  	Training Loss: 0.005300533026456833
Test Loss:  0.004444888327270746
Valid Loss:  0.004984083119779825
Epoch:  71  	Training Loss: 0.005283412989228964
Test Loss:  0.0044200909323990345
 14%|█▍        | 71/500 [01:01<08:37,  1.21s/it] 15%|█▍        | 73/500 [01:01<06:09,  1.16it/s] 15%|█▌        | 75/500 [01:02<04:25,  1.60it/s] 15%|█▌        | 77/500 [01:02<03:13,  2.19it/s] 16%|█▌        | 79/500 [01:02<02:23,  2.94it/s] 16%|█▌        | 81/500 [01:08<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:08<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:09<04:20,  1.59it/s] 17%|█▋        | 87/500 [01:09<03:10,  2.17it/s] 18%|█▊        | 89/500 [01:09<02:20,  2.92it/s] 18%|█▊        | 91/500 [01:15<08:16,  1.21s/it] 19%|█▊        | 93/500 [01:15<05:54,  1.15it/s] 19%|█▉        | 95/500 [01:16<04:14,  1.59it/s] 19%|█▉        | 97/500 [01:16<03:05,  2.17it/s] 20%|█▉        | 99/500 [01:16<02:17,  2.93it/s] 20%|██        | 101/500 [01:22<07:56,  1.19s/it] 21%|██        | 103/500 [01:22<05:39,  1.17it/s] 21%|██        | 105/500 [01:22<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:23<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:23<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:29<07:46,  1.20s/it] 23%|██▎       | 113/500 [01:29<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:29<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:30<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:30<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:36<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:36<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:36<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:36<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:37<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:43<07:21,  1.20s/it] 27%|██▋       | 133/500 [01:43<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:43<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:43<02:45,  2.20it/s] 28%|██▊       | 139/500 [01:44<02:02,  2.95it/s]Valid Loss:  0.004954854492098093
Epoch:  72  	Training Loss: 0.00527089973911643
Test Loss:  0.004389830864965916
Valid Loss:  0.004908859264105558
Epoch:  73  	Training Loss: 0.0052349683828651905
Test Loss:  0.004357888363301754
Valid Loss:  0.004866098053753376
Epoch:  74  	Training Loss: 0.005202155094593763
Test Loss:  0.0043256874196231365
Valid Loss:  0.0048245713114738464
Epoch:  75  	Training Loss: 0.005170978605747223
Test Loss:  0.004292820114642382
Valid Loss:  0.004784709773957729
Epoch:  76  	Training Loss: 0.005140991881489754
Test Loss:  0.004260553978383541
Valid Loss:  0.004745944868773222
Epoch:  77  	Training Loss: 0.00511165801435709
Test Loss:  0.004228658974170685
Valid Loss:  0.004708176478743553
Epoch:  78  	Training Loss: 0.005083175376057625
Test Loss:  0.0041962843388319016
Valid Loss:  0.0046706367284059525
Epoch:  79  	Training Loss: 0.0050554233603179455
Test Loss:  0.0041637481190264225
Valid Loss:  0.0046335021033883095
Epoch:  80  	Training Loss: 0.005028264597058296
Test Loss:  0.004130700137466192
Valid Loss:  0.004597053863108158
Epoch:  81  	Training Loss: 0.005001621786504984
Test Loss:  0.004097538068890572
Valid Loss:  0.004561163485050201
Epoch:  82  	Training Loss: 0.004975444637238979
Test Loss:  0.004035893827676773
Valid Loss:  0.004517664201557636
Epoch:  83  	Training Loss: 0.004859771579504013
Test Loss:  0.003988313488662243
Valid Loss:  0.004489690996706486
Epoch:  84  	Training Loss: 0.004819651134312153
Test Loss:  0.003951985854655504
Valid Loss:  0.0044683064334094524
Epoch:  85  	Training Loss: 0.004797096364200115
Test Loss:  0.003920028917491436
Valid Loss:  0.004452047869563103
Epoch:  86  	Training Loss: 0.004777875728905201
Test Loss:  0.003893740940839052
Valid Loss:  0.004443036857992411
Epoch:  87  	Training Loss: 0.004762584809213877
Test Loss:  0.0038738646544516087
Valid Loss:  0.004435475450009108
Epoch:  88  	Training Loss: 0.0047514354810118675
Test Loss:  0.0038574470672756433
Valid Loss:  0.004428523126989603
Epoch:  89  	Training Loss: 0.004741843789815903
Test Loss:  0.0038433014415204525
Valid Loss:  0.0044229463674128056
Epoch:  90  	Training Loss: 0.004733790177851915
Test Loss:  0.003831180278211832
Valid Loss:  0.004418515134602785
Epoch:  91  	Training Loss: 0.004726657178252935
Test Loss:  0.0038212104700505733
Valid Loss:  0.004414420109242201
Epoch:  92  	Training Loss: 0.004720347002148628
Test Loss:  0.003750795964151621
Valid Loss:  0.004276149440556765
Epoch:  93  	Training Loss: 0.004297404084354639
Test Loss:  0.0037225272972136736
Valid Loss:  0.004247337579727173
Epoch:  94  	Training Loss: 0.004278464708477259
Test Loss:  0.0036945631727576256
Valid Loss:  0.004218848422169685
Epoch:  95  	Training Loss: 0.004259736742824316
Test Loss:  0.00366689870133996
Valid Loss:  0.004190675914287567
Epoch:  96  	Training Loss: 0.0042412169277668
Test Loss:  0.0036399459931999445
Valid Loss:  0.004163481295108795
Epoch:  97  	Training Loss: 0.00422325823456049
Test Loss:  0.0036283289082348347
Valid Loss:  0.004156825132668018
Epoch:  98  	Training Loss: 0.004216739907860756
Test Loss:  0.003627124708145857
Valid Loss:  0.004156329669058323
Epoch:  99  	Training Loss: 0.004215541295707226
Test Loss:  0.0036266057286411524
Valid Loss:  0.0041560223326087
Epoch:  100  	Training Loss: 0.0042144604958593845
Test Loss:  0.0036263593938201666
Valid Loss:  0.004155722446739674
Epoch:  101  	Training Loss: 0.004213595762848854
Test Loss:  0.0036261738277971745
Valid Loss:  0.004155436065047979
Epoch:  102  	Training Loss: 0.0042128246277570724
Test Loss:  0.0036261670757085085
Valid Loss:  0.004155261907726526
Epoch:  103  	Training Loss: 0.004212368745356798
Test Loss:  0.00362616078928113
Valid Loss:  0.004155088681727648
Epoch:  104  	Training Loss: 0.0042119137942790985
Test Loss:  0.0036261538043618202
Valid Loss:  0.004154915921390057
Epoch:  105  	Training Loss: 0.004211457911878824
Test Loss:  0.0036261496134102345
Valid Loss:  0.0041547431610524654
Epoch:  106  	Training Loss: 0.004210976883769035
Test Loss:  0.0036261435598134995
Valid Loss:  0.004154561553150415
Epoch:  107  	Training Loss: 0.004210439044982195
Test Loss:  0.0036261368077248335
Valid Loss:  0.004154370166361332
Epoch:  108  	Training Loss: 0.004209864418953657
Test Loss:  0.003626129124313593
Valid Loss:  0.004154175519943237
Epoch:  109  	Training Loss: 0.00420928793027997
Test Loss:  0.003626121673732996
Valid Loss:  0.004153981804847717
Epoch:  110  	Training Loss: 0.004208708647638559
Test Loss:  0.003626115620136261
Valid Loss:  0.004153786227107048
Epoch:  111  	Training Loss: 0.004208098631352186
Test Loss:  0.0036261084023863077
Valid Loss:  0.004153578542172909
Epoch:  112  	Training Loss: 0.00420744763687253
Test Loss:  0.0022628686856478453
Valid Loss:  0.002419932745397091
Epoch:  113  	Training Loss: 0.002376432530581951
Test Loss:  0.002199131529778242
Valid Loss:  0.0017518732929602265
Epoch:  114  	Training Loss: 0.0018158312886953354
Test Loss:  0.0009615255985409021
Valid Loss:  0.0011458444641903043
Epoch:  115  	Training Loss: 0.0014676123391836882
Test Loss:  0.0013679630355909467
Valid Loss:  0.0010031464044004679
Epoch:  116  	Training Loss: 0.0012057996354997158
Test Loss:  0.0005609450163319707
Valid Loss:  0.0007120531518012285
Epoch:  117  	Training Loss: 0.0010386083740741014
Test Loss:  0.0009545354405418038
Valid Loss:  0.0007238688413053751
Epoch:  118  	Training Loss: 0.0009301606914959848
Test Loss:  0.00047314033145084977
Valid Loss:  0.0005823427345603704
Epoch:  119  	Training Loss: 0.0008484588470309973
Test Loss:  0.0007158867083489895
Valid Loss:  0.000617975601926446
Epoch:  120  	Training Loss: 0.0007989943260326982
Test Loss:  0.0004851826233789325
Valid Loss:  0.0005696478183381259
Epoch:  121  	Training Loss: 0.0007670695777051151
Test Loss:  0.0006093871197663248
Valid Loss:  0.0005974204395897686
Epoch:  122  	Training Loss: 0.0007478888146579266
Test Loss:  0.0004477289621718228
Valid Loss:  0.0005100835696794093
Epoch:  123  	Training Loss: 0.0006429249187931418
Test Loss:  0.0003660661168396473
Valid Loss:  0.0004725674516521394
Epoch:  124  	Training Loss: 0.0005877956282347441
Test Loss:  0.0003256024210713804
Valid Loss:  0.0004547152784653008
Epoch:  125  	Training Loss: 0.0005559330456890166
Test Loss:  0.000303374050417915
Valid Loss:  0.00044292162056080997
Epoch:  126  	Training Loss: 0.0005354356253519654
Test Loss:  0.0002899624523706734
Valid Loss:  0.0004346705100033432
Epoch:  127  	Training Loss: 0.000520136090926826
Test Loss:  0.00028068877873010933
Valid Loss:  0.00042854895582422614
Epoch:  128  	Training Loss: 0.0005078137037344277
Test Loss:  0.00027438689721748233
Valid Loss:  0.00042349877185188234
Epoch:  129  	Training Loss: 0.0004974285257048905
Test Loss:  0.00026976349181495607
Valid Loss:  0.00041965063428506255
Epoch:  130  	Training Loss: 0.0004884122754447162
Test Loss:  0.00026744609931483865
Valid Loss:  0.0004166577709838748
Epoch:  131  	Training Loss: 0.00048023619456216693
Test Loss:  0.0002673252602107823
Valid Loss:  0.0004142370307818055
Epoch:  132  	Training Loss: 0.0004725945182144642
Test Loss:  0.00029306369833648205
Valid Loss:  0.00038728007348254323
Epoch:  133  	Training Loss: 0.00041220959974452853
Test Loss:  0.0003002726298291236
Valid Loss:  0.00038060496444813907
Epoch:  134  	Training Loss: 0.00039352086605504155
Test Loss:  0.0002980411518365145
Valid Loss:  0.0003749866154976189
Epoch:  135  	Training Loss: 0.0003801783896051347
Test Loss:  0.00029463693499565125
Valid Loss:  0.0003699733642861247
Epoch:  136  	Training Loss: 0.00036895577795803547
Test Loss:  0.0002906604204326868
Valid Loss:  0.0003657159977592528
Epoch:  137  	Training Loss: 0.0003590720007196069
Test Loss:  0.00028667738661170006
Valid Loss:  0.000361891055945307
Epoch:  138  	Training Loss: 0.00035058046341873705
Test Loss:  0.0002830603043548763
Valid Loss:  0.0003584266232792288
Epoch:  139  	Training Loss: 0.00034334545489400625
Test Loss:  0.00027934793615713716
Valid Loss:  0.0003550220571924001
Epoch:  140  	Training Loss: 0.00033663096837699413
Test Loss:  0.00027591059915721416
Valid Loss:   28%|██▊       | 141/500 [01:50<07:11,  1.20s/it] 29%|██▊       | 143/500 [01:50<05:07,  1.16it/s] 29%|██▉       | 145/500 [01:50<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:50<02:43,  2.16it/s] 30%|██▉       | 149/500 [01:51<02:00,  2.91it/s] 30%|███       | 151/500 [02:03<12:28,  2.14s/it] 31%|███       | 153/500 [02:03<08:48,  1.52s/it] 31%|███       | 155/500 [02:04<06:14,  1.09s/it] 31%|███▏      | 157/500 [02:04<04:27,  1.28it/s] 32%|███▏      | 159/500 [02:04<03:12,  1.77it/s] 32%|███▏      | 161/500 [02:10<07:34,  1.34s/it] 33%|███▎      | 163/500 [02:10<05:25,  1.04it/s] 33%|███▎      | 165/500 [02:10<03:54,  1.43it/s] 33%|███▎      | 167/500 [02:11<02:51,  1.94it/s] 34%|███▍      | 169/500 [02:11<02:08,  2.57it/s] 34%|███▍      | 171/500 [02:17<06:46,  1.23s/it] 35%|███▍      | 173/500 [02:17<04:49,  1.13it/s] 35%|███▌      | 175/500 [02:17<03:28,  1.56it/s] 35%|███▌      | 177/500 [02:18<02:31,  2.13it/s] 36%|███▌      | 179/500 [02:18<01:51,  2.87it/s] 36%|███▌      | 181/500 [02:24<06:31,  1.23s/it] 37%|███▋      | 183/500 [02:24<04:41,  1.13it/s] 37%|███▋      | 185/500 [02:25<03:21,  1.56it/s] 37%|███▋      | 187/500 [02:25<02:26,  2.13it/s] 38%|███▊      | 189/500 [02:25<01:48,  2.87it/s] 38%|███▊      | 191/500 [02:32<06:30,  1.26s/it] 39%|███▊      | 193/500 [02:32<04:38,  1.10it/s] 39%|███▉      | 195/500 [02:32<03:20,  1.52it/s] 39%|███▉      | 197/500 [02:32<02:26,  2.07it/s] 40%|███▉      | 199/500 [02:32<01:49,  2.74it/s] 40%|████      | 201/500 [02:39<06:08,  1.23s/it] 41%|████      | 203/500 [02:39<04:22,  1.13it/s] 41%|████      | 205/500 [02:39<03:08,  1.56it/s]0.00035181184648536146
Epoch:  141  	Training Loss: 0.0003306121798232198
Test Loss:  0.00027317574131302536
Valid Loss:  0.00034893208066932857
Epoch:  142  	Training Loss: 0.0003252138558309525
Test Loss:  0.0002888508315663785
Valid Loss:  0.000354219286236912
Epoch:  143  	Training Loss: 0.00032231968361884356
Test Loss:  0.0002587724884506315
Valid Loss:  0.00035018863854929805
Epoch:  144  	Training Loss: 0.0003209677233826369
Test Loss:  0.00028858997393399477
Valid Loss:  0.00035805688821710646
Epoch:  145  	Training Loss: 0.00032066760468296707
Test Loss:  0.00024839077377691865
Valid Loss:  0.0003525707870721817
Epoch:  146  	Training Loss: 0.0003210454888176173
Test Loss:  0.00029547003214247525
Valid Loss:  0.00036322162486612797
Epoch:  147  	Training Loss: 0.0003225102263968438
Test Loss:  0.0002384956751484424
Valid Loss:  0.0003561537014320493
Epoch:  148  	Training Loss: 0.00032622477738186717
Test Loss:  0.0003144610091112554
Valid Loss:  0.00037284090649336576
Epoch:  149  	Training Loss: 0.00033130403608083725
Test Loss:  0.0002285630616825074
Valid Loss:  0.0003645879332907498
Epoch:  150  	Training Loss: 0.00034174733445979655
Test Loss:  0.00035304471384733915
Valid Loss:  0.00039398600347340107
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0003557736927177757
Test Loss:  0.0002775561879388988
Valid Loss:  0.000353930372511968
Epoch:  152  	Training Loss: 0.000316173885948956
Test Loss:  0.00027715289616025984
Valid Loss:  0.00035421914071775973
Epoch:  153  	Training Loss: 0.0003160519408993423
Test Loss:  0.00027676825993694365
Valid Loss:  0.0003545049112290144
Epoch:  154  	Training Loss: 0.00031593788298778236
Test Loss:  0.0002764000673778355
Valid Loss:  0.0003547866363078356
Epoch:  155  	Training Loss: 0.0003158308390993625
Test Loss:  0.00027604802744463086
Valid Loss:  0.0003550641122274101
Epoch:  156  	Training Loss: 0.000315730256261304
Test Loss:  0.00027571123791858554
Valid Loss:  0.0003553374554030597
Epoch:  157  	Training Loss: 0.0003156359598506242
Test Loss:  0.00027538876747712493
Valid Loss:  0.0003556058800313622
Epoch:  158  	Training Loss: 0.0003155475133098662
Test Loss:  0.0002750801795627922
Valid Loss:  0.00035587040474638343
Epoch:  159  	Training Loss: 0.0003154648293275386
Test Loss:  0.00027478463016450405
Valid Loss:  0.00035613018553704023
Epoch:  160  	Training Loss: 0.0003153870056848973
Test Loss:  0.0002745016827248037
Valid Loss:  0.0003563848731573671
Epoch:  161  	Training Loss: 0.0003153141587972641
Test Loss:  0.0002742307260632515
Valid Loss:  0.00035663560265675187
Epoch:  162  	Training Loss: 0.00031524570658802986
Test Loss:  0.00026851322036236525
Valid Loss:  0.00035392033169046044
Epoch:  163  	Training Loss: 0.0003112474223598838
Test Loss:  0.0002638516016304493
Valid Loss:  0.0003515499411150813
Epoch:  164  	Training Loss: 0.0003077187284361571
Test Loss:  0.0002599780564196408
Valid Loss:  0.00034944372600875795
Epoch:  165  	Training Loss: 0.00030454754596576095
Test Loss:  0.0002567805349826813
Valid Loss:  0.00034753602812997997
Epoch:  166  	Training Loss: 0.0003016849223058671
Test Loss:  0.00025413266848772764
Valid Loss:  0.0003458036226220429
Epoch:  167  	Training Loss: 0.00029909599106758833
Test Loss:  0.0002519374538678676
Valid Loss:  0.0003442280867602676
Epoch:  168  	Training Loss: 0.00029675953555852175
Test Loss:  0.0002500783884897828
Valid Loss:  0.00034276721999049187
Epoch:  169  	Training Loss: 0.00029459840152412653
Test Loss:  0.0002485426375642419
Valid Loss:  0.00034139055060222745
Epoch:  170  	Training Loss: 0.0002925505395978689
Test Loss:  0.00024724885588511825
Valid Loss:  0.00034008355578407645
Epoch:  171  	Training Loss: 0.0002905946457758546
Test Loss:  0.0002461932599544525
Valid Loss:  0.00033883959986269474
Epoch:  172  	Training Loss: 0.0002887300797738135
Test Loss:  0.0002518965338822454
Valid Loss:  0.00034005107590928674
Epoch:  173  	Training Loss: 0.00028632627800107
Test Loss:  0.00025444928905926645
Valid Loss:  0.00034116918686777353
Epoch:  174  	Training Loss: 0.00028571588336490095
Test Loss:  0.000255399732850492
Valid Loss:  0.00034195181797258556
Epoch:  175  	Training Loss: 0.00028543255757540464
Test Loss:  0.0002554888487793505
Valid Loss:  0.00034248025622218847
Epoch:  176  	Training Loss: 0.00028523412765935063
Test Loss:  0.0002553533995524049
Valid Loss:  0.00034290109761059284
Epoch:  177  	Training Loss: 0.0002850532182492316
Test Loss:  0.00025514228036627173
Valid Loss:  0.0003432540688663721
Epoch:  178  	Training Loss: 0.00028488290263339877
Test Loss:  0.00025490846019238234
Valid Loss:  0.00034355412935838103
Epoch:  179  	Training Loss: 0.00028472370468080044
Test Loss:  0.0002546718460507691
Valid Loss:  0.0003438149578869343
Epoch:  180  	Training Loss: 0.000284571317024529
Test Loss:  0.0002544432645663619
Valid Loss:  0.0003440405707806349
Epoch:  181  	Training Loss: 0.00028442300390452147
Test Loss:  0.00025422408361919224
Valid Loss:  0.00034423175384290516
Epoch:  182  	Training Loss: 0.0002842794347088784
Test Loss:  0.0002525224117562175
Valid Loss:  0.0003431287477724254
Epoch:  183  	Training Loss: 0.00028270171605981886
Test Loss:  0.0002509044425096363
Valid Loss:  0.0003420813591219485
Epoch:  184  	Training Loss: 0.0002812150924000889
Test Loss:  0.0002493774227332324
Valid Loss:  0.00034109398256987333
Epoch:  185  	Training Loss: 0.0002798238710965961
Test Loss:  0.00024792994372546673
Valid Loss:  0.0003401519497856498
Epoch:  186  	Training Loss: 0.0002785015385597944
Test Loss:  0.0002465582510922104
Valid Loss:  0.00033925403840839863
Epoch:  187  	Training Loss: 0.00027724713436327875
Test Loss:  0.00024525573826394975
Valid Loss:  0.00033840176183730364
Epoch:  188  	Training Loss: 0.0002760585048235953
Test Loss:  0.00024401419796049595
Valid Loss:  0.00033759514917619526
Epoch:  189  	Training Loss: 0.00027492630761116743
Test Loss:  0.00024282948288600892
Valid Loss:  0.0003368253819644451
Epoch:  190  	Training Loss: 0.000273845624178648
Test Loss:  0.00024169321113731712
Valid Loss:  0.0003360861446708441
Epoch:  191  	Training Loss: 0.000272811739705503
Test Loss:  0.00024060573196038604
Valid Loss:  0.00033538081333972514
Epoch:  192  	Training Loss: 0.00027182407211512327
Test Loss:  0.00024488550843670964
Valid Loss:  0.00033650678233243525
Epoch:  193  	Training Loss: 0.00027095439145341516
Test Loss:  0.00024526240304112434
Valid Loss:  0.00033656274899840355
Epoch:  194  	Training Loss: 0.0002706528175622225
Test Loss:  0.0002450824249535799
Valid Loss:  0.00033643958158791065
Epoch:  195  	Training Loss: 0.00027036573737859726
Test Loss:  0.00024481629952788353
Valid Loss:  0.00033628923119977117
Epoch:  196  	Training Loss: 0.0002700839831959456
Test Loss:  0.000244544236920774
Valid Loss:  0.0003361374547239393
Epoch:  197  	Training Loss: 0.0002698114258237183
Test Loss:  0.0002442754339426756
Valid Loss:  0.0003359944385010749
Epoch:  198  	Training Loss: 0.000269542244495824
Test Loss:  0.0002440365933580324
Valid Loss:  0.00033585159690119326
Epoch:  199  	Training Loss: 0.0002692759153433144
Test Loss:  0.00024381476396229118
Valid Loss:  0.00033570980303920805
Epoch:  200  	Training Loss: 0.00026901281671598554
Test Loss:  0.000243609378230758
Valid Loss:  0.00033557545975781977
Epoch:  201  	Training Loss: 0.00026875396724790335
Test Loss:  0.0002433555928291753
Valid Loss:  0.0003354198415763676
Epoch:  202  	Training Loss: 0.00026849989080801606
Test Loss:  0.00024088600184768438
Valid Loss:  0.00033387739676982164
Epoch:  203  	Training Loss: 0.00026622950099408627
Test Loss:  0.00023895717458799481
Valid Loss:  0.0003324525314383209
Epoch:  204  	Training Loss: 0.00026414828607812524
Test Loss:  0.00023743257042951882
Valid Loss:  0.0003311281616333872
Epoch:  205  	Training Loss: 0.0002622343599796295
Test Loss:  0.00023619324201717973
Valid Loss:  0.0003298706724308431
Epoch:  206  	Training Loss: 0.00026042351964861155
Test Loss:  0.00023518039961345494
Valid Loss:  0.00032867564004845917
 41%|████▏     | 207/500 [02:39<02:17,  2.13it/s] 42%|████▏     | 209/500 [02:39<01:42,  2.84it/s] 42%|████▏     | 211/500 [02:46<05:53,  1.22s/it] 43%|████▎     | 213/500 [02:46<04:11,  1.14it/s] 43%|████▎     | 215/500 [02:46<03:00,  1.58it/s] 43%|████▎     | 217/500 [02:46<02:11,  2.16it/s] 44%|████▍     | 219/500 [02:46<01:36,  2.90it/s] 44%|████▍     | 221/500 [02:53<05:39,  1.22s/it] 45%|████▍     | 223/500 [02:53<04:01,  1.15it/s] 45%|████▌     | 225/500 [02:53<02:53,  1.59it/s] 45%|████▌     | 227/500 [02:53<02:05,  2.17it/s] 46%|████▌     | 229/500 [02:54<01:32,  2.92it/s] 46%|████▌     | 231/500 [03:00<05:23,  1.20s/it] 47%|████▋     | 233/500 [03:00<03:52,  1.15it/s] 47%|████▋     | 235/500 [03:00<02:48,  1.58it/s] 47%|████▋     | 237/500 [03:00<02:03,  2.13it/s] 48%|████▊     | 239/500 [03:01<01:31,  2.86it/s] 48%|████▊     | 241/500 [03:07<05:09,  1.19s/it] 49%|████▊     | 243/500 [03:07<03:39,  1.17it/s] 49%|████▉     | 245/500 [03:07<02:37,  1.62it/s] 49%|████▉     | 247/500 [03:07<01:54,  2.21it/s] 50%|████▉     | 249/500 [03:07<01:24,  2.97it/s] 50%|█████     | 251/500 [03:14<05:00,  1.21s/it] 51%|█████     | 253/500 [03:14<03:33,  1.15it/s] 51%|█████     | 255/500 [03:14<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:14<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:14<01:22,  2.93it/s] 52%|█████▏    | 261/500 [03:21<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:21<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:21<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:21<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:21<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:28<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:28<03:14,  1.17it/s]Epoch:  207  	Training Loss: 0.0002587040944490582
Test Loss:  0.00023437640629708767
Valid Loss:  0.00032753031700849533
Epoch:  208  	Training Loss: 0.00025705189909785986
Test Loss:  0.00023371211136691272
Valid Loss:  0.0003264294355176389
Epoch:  209  	Training Loss: 0.00025546044344082475
Test Loss:  0.00023317841987591237
Valid Loss:  0.0003253691247664392
Epoch:  210  	Training Loss: 0.0002539276611059904
Test Loss:  0.00023275958665180951
Valid Loss:  0.00032435404136776924
Epoch:  211  	Training Loss: 0.00025246437871828675
Test Loss:  0.0002324069500900805
Valid Loss:  0.000323373795254156
Epoch:  212  	Training Loss: 0.0002510574122425169
Test Loss:  0.00023240552400238812
Valid Loss:  0.00032337300945073366
Epoch:  213  	Training Loss: 0.0002510569174773991
Test Loss:  0.00023240456357598305
Valid Loss:  0.00032337201992049813
Epoch:  214  	Training Loss: 0.00025105595705099404
Test Loss:  0.00023240289010573179
Valid Loss:  0.0003233710303902626
Epoch:  215  	Training Loss: 0.0002510552294552326
Test Loss:  0.00023240182781592011
Valid Loss:  0.0003233703027945012
Epoch:  216  	Training Loss: 0.000251054298132658
Test Loss:  0.00023240047448780388
Valid Loss:  0.0003233694878872484
Epoch:  217  	Training Loss: 0.00025105359964072704
Test Loss:  0.00023239933943841606
Valid Loss:  0.0003233685274608433
Epoch:  218  	Training Loss: 0.00025105284294113517
Test Loss:  0.00023239810252562165
Valid Loss:  0.00032336771255359054
Epoch:  219  	Training Loss: 0.0002510520862415433
Test Loss:  0.00023239693837240338
Valid Loss:  0.0003233667812310159
Epoch:  220  	Training Loss: 0.0002510513586457819
Test Loss:  0.0002323958178749308
Valid Loss:  0.0003233661991544068
Epoch:  221  	Training Loss: 0.00025105063105002046
Test Loss:  0.00023239459551405162
Valid Loss:  0.0003233657334931195
Epoch:  222  	Training Loss: 0.0002510500489734113
Test Loss:  0.0002323649823665619
Valid Loss:  0.0003227499546483159
Epoch:  223  	Training Loss: 0.00025083974469453096
Test Loss:  0.00023230662918649614
Valid Loss:  0.00032214957172982395
Epoch:  224  	Training Loss: 0.0002506240562070161
Test Loss:  0.00023222847084980458
Valid Loss:  0.00032157651730813086
Epoch:  225  	Training Loss: 0.00025040804757736623
Test Loss:  0.00023213672102428973
Valid Loss:  0.00032103381818160415
Epoch:  226  	Training Loss: 0.00025019526947289705
Test Loss:  0.00023203721502795815
Valid Loss:  0.00032051882590167224
Epoch:  227  	Training Loss: 0.0002499883412383497
Test Loss:  0.00023193353263195604
Valid Loss:  0.0003200389910489321
Epoch:  228  	Training Loss: 0.00024978816509246826
Test Loss:  0.00023183232406154275
Valid Loss:  0.0003195928002241999
Epoch:  229  	Training Loss: 0.0002495948865544051
Test Loss:  0.00023172447981778532
Valid Loss:  0.0003191678551957011
Epoch:  230  	Training Loss: 0.00024940638104453683
Test Loss:  0.0002316097088623792
Valid Loss:  0.0003187719266861677
Epoch:  231  	Training Loss: 0.0002492207568138838
Test Loss:  0.00023149396292865276
Valid Loss:  0.0003184075467288494
Epoch:  232  	Training Loss: 0.00024904406745918095
Test Loss:  0.00023476312344428152
Valid Loss:  0.0003191879950463772
Epoch:  233  	Training Loss: 0.0002481199917383492
Test Loss:  0.0002362331870244816
Valid Loss:  0.0003196089237462729
Epoch:  234  	Training Loss: 0.00024786265566945076
Test Loss:  0.00023678582510910928
Valid Loss:  0.00031975089223124087
Epoch:  235  	Training Loss: 0.00024772778851911426
Test Loss:  0.00023697660071775317
Valid Loss:  0.0003197714395355433
Epoch:  236  	Training Loss: 0.00024761303211562335
Test Loss:  0.00023700823658145964
Valid Loss:  0.00031973543809726834
Epoch:  237  	Training Loss: 0.0002475024666637182
Test Loss:  0.00023696920834481716
Valid Loss:  0.0003196733305230737
Epoch:  238  	Training Loss: 0.0002473918139003217
Test Loss:  0.00023689215595368296
Valid Loss:  0.0003195884055458009
Epoch:  239  	Training Loss: 0.000247275602305308
Test Loss:  0.00023679847072344273
Valid Loss:  0.00031949306139722466
Epoch:  240  	Training Loss: 0.0002471531624905765
Test Loss:  0.00023669177608098835
Valid Loss:  0.00031937577296048403
Epoch:  241  	Training Loss: 0.0002470237377565354
Test Loss:  0.00023658260761294514
Valid Loss:  0.0003192545264028013
Epoch:  242  	Training Loss: 0.0002468943130224943
Test Loss:  0.00023526069708168507
Valid Loss:  0.00031839724397286773
Epoch:  243  	Training Loss: 0.0002457048394717276
Test Loss:  0.00023400520149152726
Valid Loss:  0.00031759042758494616
Epoch:  244  	Training Loss: 0.0002445750287733972
Test Loss:  0.00023282782058231533
Valid Loss:  0.00031682176631875336
Epoch:  245  	Training Loss: 0.00024351071624550968
Test Loss:  0.0002317040489288047
Valid Loss:  0.00031608587596565485
Epoch:  246  	Training Loss: 0.00024249996931757778
Test Loss:  0.00023063004482537508
Valid Loss:  0.00031538092298433185
Epoch:  247  	Training Loss: 0.00024153990671038628
Test Loss:  0.00022959908528719097
Valid Loss:  0.0003147049865219742
Epoch:  248  	Training Loss: 0.00024062697775661945
Test Loss:  0.00022861867910251021
Valid Loss:  0.000314068456646055
Epoch:  249  	Training Loss: 0.00023976407828740776
Test Loss:  0.00022767869813833386
Valid Loss:  0.0003134559083264321
Epoch:  250  	Training Loss: 0.0002389419823884964
Test Loss:  0.00022679346147924662
Valid Loss:  0.0003128962707705796
Epoch:  251  	Training Loss: 0.00023816000611986965
Test Loss:  0.0002259455795865506
Valid Loss:  0.00031237330404110253
Epoch:  252  	Training Loss: 0.00023741283803246915
Test Loss:  0.0002280154440086335
Valid Loss:  0.0003128894022665918
Epoch:  253  	Training Loss: 0.00023681478342041373
Test Loss:  0.0002287931856699288
Valid Loss:  0.0003130333498120308
Epoch:  254  	Training Loss: 0.00023650380899198353
Test Loss:  0.00022900791373103857
Valid Loss:  0.0003129754913970828
Epoch:  255  	Training Loss: 0.00023624388268217444
Test Loss:  0.00022897578310221434
Valid Loss:  0.00031282095005735755
Epoch:  256  	Training Loss: 0.00023599041742272675
Test Loss:  0.00022883378551341593
Valid Loss:  0.0003126210067421198
Epoch:  257  	Training Loss: 0.0002357402554480359
Test Loss:  0.00022865553910378367
Valid Loss:  0.0003123928909189999
Epoch:  258  	Training Loss: 0.0002354904863750562
Test Loss:  0.00022846387582831085
Valid Loss:  0.00031215179478749633
Epoch:  259  	Training Loss: 0.0002352376759517938
Test Loss:  0.00022826678468845785
Valid Loss:  0.0003119138418696821
Epoch:  260  	Training Loss: 0.00023498194059357047
Test Loss:  0.00022808992071077228
Valid Loss:  0.0003116758307442069
Epoch:  261  	Training Loss: 0.00023472748580388725
Test Loss:  0.00022791308583691716
Valid Loss:  0.00031143787782639265
Epoch:  262  	Training Loss: 0.0002344743988942355
Test Loss:  0.00022759352577850223
Valid Loss:  0.0003111991682089865
Epoch:  263  	Training Loss: 0.0002343255910091102
Test Loss:  0.000227277196245268
Valid Loss:  0.00031096162274479866
Epoch:  264  	Training Loss: 0.00023418021737597883
Test Loss:  0.00022698096290696412
Valid Loss:  0.0003107341763097793
Epoch:  265  	Training Loss: 0.00023404162493534386
Test Loss:  0.00022668740712106228
Valid Loss:  0.00031050859251990914
Epoch:  266  	Training Loss: 0.0002339041093364358
Test Loss:  0.0002263978822156787
Valid Loss:  0.000310283328872174
Epoch:  267  	Training Loss: 0.00023376769968308508
Test Loss:  0.00022611662279814482
Valid Loss:  0.0003100647882092744
Epoch:  268  	Training Loss: 0.00023363230866380036
Test Loss:  0.00022583817190025002
Valid Loss:  0.0003098527085967362
Epoch:  269  	Training Loss: 0.00023349799448624253
Test Loss:  0.00022556234034709632
Valid Loss:  0.0003096414147876203
Epoch:  270  	Training Loss: 0.00023336453887168318
Test Loss:  0.0002252889098599553
Valid Loss:  0.00030943029560148716
Epoch:  271  	Training Loss: 0.00023323140339925885
Test Loss:  0.00022502274077851325
Valid Loss:  0.0003092261031270027
Epoch:  272  	Training Loss: 0.00023309732205234468
Test Loss:  0.00022482489293906838
Valid Loss:  0.0003091645776294172
Epoch:  273  	Training Loss: 0.00023306238290388137
Test Loss:  0.0002246802469016984
Valid Loss:  0.00030910479836165905
 55%|█████▌    | 275/500 [03:28<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:28<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:28<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:35<04:21,  1.20s/it] 57%|█████▋    | 283/500 [03:35<03:06,  1.17it/s] 57%|█████▋    | 285/500 [03:35<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:35<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:35<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:42<04:12,  1.21s/it] 59%|█████▊    | 293/500 [03:42<02:59,  1.15it/s] 59%|█████▉    | 295/500 [03:42<02:08,  1.59it/s] 59%|█████▉    | 297/500 [03:42<01:33,  2.18it/s] 60%|█████▉    | 299/500 [03:42<01:08,  2.93it/s] 60%|██████    | 301/500 [03:49<03:58,  1.20s/it] 61%|██████    | 303/500 [03:49<02:50,  1.16it/s] 61%|██████    | 305/500 [03:49<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:49<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:49<01:06,  2.88it/s] 62%|██████▏   | 311/500 [03:56<03:50,  1.22s/it] 63%|██████▎   | 313/500 [03:56<02:44,  1.14it/s] 63%|██████▎   | 315/500 [03:56<01:58,  1.56it/s] 63%|██████▎   | 317/500 [03:56<01:26,  2.12it/s] 64%|██████▍   | 319/500 [03:56<01:03,  2.83it/s] 64%|██████▍   | 321/500 [04:03<03:44,  1.26s/it] 65%|██████▍   | 323/500 [04:03<02:39,  1.11it/s] 65%|██████▌   | 325/500 [04:03<01:54,  1.52it/s] 65%|██████▌   | 327/500 [04:04<01:23,  2.07it/s] 66%|██████▌   | 329/500 [04:04<01:01,  2.79it/s] 66%|██████▌   | 331/500 [04:10<03:24,  1.21s/it] 67%|██████▋   | 333/500 [04:10<02:25,  1.15it/s] 67%|██████▋   | 335/500 [04:10<01:43,  1.59it/s] 67%|██████▋   | 337/500 [04:11<01:15,  2.17it/s] 68%|██████▊   | 339/500 [04:11<00:55,  2.92it/s]Epoch:  274  	Training Loss: 0.00023302814224734902
Test Loss:  0.0002245697396574542
Valid Loss:  0.0003090467653237283
Epoch:  275  	Training Loss: 0.00023299417807720602
Test Loss:  0.00022448098752647638
Valid Loss:  0.00030898931436240673
Epoch:  276  	Training Loss: 0.00023296050494536757
Test Loss:  0.0002244066126877442
Valid Loss:  0.00030893192160874605
Epoch:  277  	Training Loss: 0.00023292656987905502
Test Loss:  0.00022434092534240335
Valid Loss:  0.00030887575121596456
Epoch:  278  	Training Loss: 0.0002328927512280643
Test Loss:  0.00022428225202020258
Valid Loss:  0.0003088192897848785
Epoch:  279  	Training Loss: 0.0002328590489923954
Test Loss:  0.00022422726033255458
Valid Loss:  0.0003087632358074188
Epoch:  280  	Training Loss: 0.00023282531765289605
Test Loss:  0.000224174844333902
Valid Loss:  0.0003087069489993155
Epoch:  281  	Training Loss: 0.00023279145534615964
Test Loss:  0.0002241232432425022
Valid Loss:  0.00030865106964483857
Epoch:  282  	Training Loss: 0.00023275756393559277
Test Loss:  0.0002243101771455258
Valid Loss:  0.0003082837793044746
Epoch:  283  	Training Loss: 0.0002327261900063604
Test Loss:  0.00022437919687945396
Valid Loss:  0.00030795339262112975
Epoch:  284  	Training Loss: 0.00023269979283213615
Test Loss:  0.00022437822190113366
Valid Loss:  0.00030764928669668734
Epoch:  285  	Training Loss: 0.00023267572396434844
Test Loss:  0.00022433878621086478
Valid Loss:  0.00030736566986888647
Epoch:  286  	Training Loss: 0.00023265415802598
Test Loss:  0.00022427717340178788
Valid Loss:  0.00030709797283634543
Epoch:  287  	Training Loss: 0.00023263416369445622
Test Loss:  0.00022420499590225518
Valid Loss:  0.00030684401281178
Epoch:  288  	Training Loss: 0.00023261595924850553
Test Loss:  0.00022412757971324027
Valid Loss:  0.00030660207266919315
Epoch:  289  	Training Loss: 0.00023259891895577312
Test Loss:  0.00022404898481909186
Valid Loss:  0.00030637148302048445
Epoch:  290  	Training Loss: 0.00023258320288732648
Test Loss:  0.00022397117572836578
Valid Loss:  0.00030615157447755337
Epoch:  291  	Training Loss: 0.0002325687964912504
Test Loss:  0.00022389486548490822
Valid Loss:  0.00030594109557569027
Epoch:  292  	Training Loss: 0.00023255568521562964
Test Loss:  0.0002240233006887138
Valid Loss:  0.00030575579148717225
Epoch:  293  	Training Loss: 0.0002325463283341378
Test Loss:  0.00022414023987948895
Valid Loss:  0.00030559132574126124
Epoch:  294  	Training Loss: 0.00023253855761140585
Test Loss:  0.00022424572671297938
Valid Loss:  0.0003054451080970466
Epoch:  295  	Training Loss: 0.00023253244580700994
Test Loss:  0.00022434102720580995
Valid Loss:  0.00030531437369063497
Epoch:  296  	Training Loss: 0.00023252758546732366
Test Loss:  0.00022442667977884412
Valid Loss:  0.0003051979292649776
Epoch:  297  	Training Loss: 0.0002325235545868054
Test Loss:  0.0002245039795525372
Valid Loss:  0.00030509353382512927
Epoch:  298  	Training Loss: 0.000232520469580777
Test Loss:  0.00022457438171841204
Valid Loss:  0.0003050011000595987
Epoch:  299  	Training Loss: 0.00023251766106113791
Test Loss:  0.00022463759523816407
Valid Loss:  0.00030491777579300106
Epoch:  300  	Training Loss: 0.00023251568200066686
Test Loss:  0.00022469458053819835
Valid Loss:  0.0003048438229598105
Epoch:  301  	Training Loss: 0.00023251393577083945
Test Loss:  0.00022474589059129357
Valid Loss:  0.0003047778154723346
Epoch:  302  	Training Loss: 0.00023251250968314707
Test Loss:  0.00022489807452075183
Valid Loss:  0.00030483529553748667
Epoch:  303  	Training Loss: 0.00023242585302796215
Test Loss:  0.0002249825920443982
Valid Loss:  0.00030486995819956064
Epoch:  304  	Training Loss: 0.0002323494991287589
Test Loss:  0.00022503265063278377
Valid Loss:  0.0003048898361157626
Epoch:  305  	Training Loss: 0.00023228602367453277
Test Loss:  0.00022505824745167047
Valid Loss:  0.0003048984508495778
Epoch:  306  	Training Loss: 0.0002322260697837919
Test Loss:  0.00022506571258418262
Valid Loss:  0.0003048974904231727
Epoch:  307  	Training Loss: 0.0002321701031178236
Test Loss:  0.0002250614925287664
Valid Loss:  0.0003048919315915555
Epoch:  308  	Training Loss: 0.00023211775987874717
Test Loss:  0.0002250524121336639
Valid Loss:  0.0003048850630875677
Epoch:  309  	Training Loss: 0.00023207260528579354
Test Loss:  0.00022503634681925178
Valid Loss:  0.0003048758953809738
Epoch:  310  	Training Loss: 0.0002320286730537191
Test Loss:  0.00022501109924633056
Valid Loss:  0.0003048632061108947
Epoch:  311  	Training Loss: 0.00023198816052172333
Test Loss:  0.00022498617181554437
Valid Loss:  0.0003048510116059333
Epoch:  312  	Training Loss: 0.00023195010726340115
Test Loss:  0.00022504208027385175
Valid Loss:  0.0003048662911169231
Epoch:  313  	Training Loss: 0.00023188843624666333
Test Loss:  0.00022500297927763313
Valid Loss:  0.0003048469661734998
Epoch:  314  	Training Loss: 0.000231827623792924
Test Loss:  0.0002249246754217893
Valid Loss:  0.0003048144862987101
Epoch:  315  	Training Loss: 0.00023176759714260697
Test Loss:  0.000224831877858378
Valid Loss:  0.00030477438122034073
Epoch:  316  	Training Loss: 0.0002317079488420859
Test Loss:  0.0002247330266982317
Valid Loss:  0.0003047384088858962
Epoch:  317  	Training Loss: 0.0002316499303560704
Test Loss:  0.00022464906214736402
Valid Loss:  0.0003047058708034456
Epoch:  318  	Training Loss: 0.00023159824195317924
Test Loss:  0.00022455996077042073
Valid Loss:  0.0003046710044145584
Epoch:  319  	Training Loss: 0.00023154664086177945
Test Loss:  0.0002244695497211069
Valid Loss:  0.00030463471193797886
Epoch:  320  	Training Loss: 0.00023149512708187103
Test Loss:  0.000224377479753457
Valid Loss:  0.000304597633657977
Epoch:  321  	Training Loss: 0.0002314450975973159
Test Loss:  0.00022429533419199288
Valid Loss:  0.0003045617777388543
Epoch:  322  	Training Loss: 0.0002313974837306887
Test Loss:  0.00022414950944948941
Valid Loss:  0.0003043529868591577
Epoch:  323  	Training Loss: 0.00023126370797399431
Test Loss:  0.00022400356829166412
Valid Loss:  0.00030414172215387225
Epoch:  324  	Training Loss: 0.00023112741473596543
Test Loss:  0.00022385486226994544
Valid Loss:  0.00030393004999496043
Epoch:  325  	Training Loss: 0.0002309911942575127
Test Loss:  0.00022370280930772424
Valid Loss:  0.00030371692264452577
Epoch:  326  	Training Loss: 0.00023085280554369092
Test Loss:  0.0002235499123344198
Valid Loss:  0.00030349951703101397
Epoch:  327  	Training Loss: 0.00023071457690093666
Test Loss:  0.00022339768474921584
Valid Loss:  0.00030327780405059457
Epoch:  328  	Training Loss: 0.00023057476209942251
Test Loss:  0.00022324189194478095
Valid Loss:  0.0003030510270036757
Epoch:  329  	Training Loss: 0.00023043087276164442
Test Loss:  0.0002230866375612095
Valid Loss:  0.00030282323132269084
Epoch:  330  	Training Loss: 0.00023028693976812065
Test Loss:  0.00022293215442914516
Valid Loss:  0.00030259363120421767
Epoch:  331  	Training Loss: 0.00023014329781290144
Test Loss:  0.00022277559037320316
Valid Loss:  0.0003023602475877851
Epoch:  332  	Training Loss: 0.0002299975894857198
Test Loss:  0.00022086204262450337
Valid Loss:  0.00030108034843578935
Epoch:  333  	Training Loss: 0.00022831579553894699
Test Loss:  0.0002194304543081671
Valid Loss:  0.000299962266581133
Epoch:  334  	Training Loss: 0.0002267304516863078
Test Loss:  0.00021829843171872199
Valid Loss:  0.0002989443892147392
Epoch:  335  	Training Loss: 0.00022520383936353028
Test Loss:  0.00021734664915129542
Valid Loss:  0.0002979920245707035
Epoch:  336  	Training Loss: 0.0002237209992017597
Test Loss:  0.00021652280702255666
Valid Loss:  0.0002970849454868585
Epoch:  337  	Training Loss: 0.00022227680892683566
Test Loss:  0.0002157827839255333
Valid Loss:  0.00029621314024552703
Epoch:  338  	Training Loss: 0.00022087080287747085
Test Loss:  0.00021508739155251533
Valid Loss:  0.0002953681396320462
Epoch:  339  	Training Loss: 0.0002195007837144658
Test Loss:  0.0002144284953828901
Valid Loss:  0.00029454907053150237
Epoch:  340  	Training Loss: 0.0002181653690058738
Test Loss:  0.00021378655219450593
Valid Loss:  0.0002937481040135026
 68%|██████▊   | 341/500 [04:17<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:17<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:17<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:18<01:10,  2.18it/s] 70%|██████▉   | 349/500 [04:18<00:51,  2.93it/s] 70%|███████   | 351/500 [04:24<02:57,  1.19s/it] 71%|███████   | 353/500 [04:24<02:05,  1.17it/s] 71%|███████   | 355/500 [04:24<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:24<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:25<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:31<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:31<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:31<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:31<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:32<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:38<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:38<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:38<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:38<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:38<00:41,  2.95it/s] 76%|███████▌  | 381/500 [04:45<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:45<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:45<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:45<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:45<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:52<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:52<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:52<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:52<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:52<00:33,  3.00it/s] 80%|████████  | 401/500 [04:59<01:59,  1.21s/it] 81%|████████  | 403/500 [04:59<01:24,  1.15it/s] 81%|████████  | 405/500 [04:59<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:59<00:42,  2.18it/s]Epoch:  341  	Training Loss: 0.00021686007676180452
Test Loss:  0.00021316065976861864
Valid Loss:  0.0002929645706899464
Epoch:  342  	Training Loss: 0.0002155845140805468
Test Loss:  0.00021313218167051673
Valid Loss:  0.0002929462934844196
Epoch:  343  	Training Loss: 0.00021555699640884995
Test Loss:  0.00021310316515155137
Valid Loss:  0.00029292801627889276
Epoch:  344  	Training Loss: 0.00021552969701588154
Test Loss:  0.0002130751236109063
Valid Loss:  0.00029290950624272227
Epoch:  345  	Training Loss: 0.00021550239762291312
Test Loss:  0.00021304695110302418
Valid Loss:  0.0002928909088950604
Epoch:  346  	Training Loss: 0.000215475243749097
Test Loss:  0.00021301856031641364
Valid Loss:  0.00029287306824699044
Epoch:  347  	Training Loss: 0.00021544803166761994
Test Loss:  0.0002129904751200229
Valid Loss:  0.000292854878352955
Epoch:  348  	Training Loss: 0.00021542093600146472
Test Loss:  0.0002129625208908692
Valid Loss:  0.00029283665935508907
Epoch:  349  	Training Loss: 0.00021539375302381814
Test Loss:  0.0002129345666617155
Valid Loss:  0.0002928184694610536
Epoch:  350  	Training Loss: 0.00021536661370191723
Test Loss:  0.00021290704899001867
Valid Loss:  0.0002928007743321359
Epoch:  351  	Training Loss: 0.0002153395616915077
Test Loss:  0.00021287963318172842
Valid Loss:  0.00029278272995725274
Epoch:  352  	Training Loss: 0.00021531266975216568
Test Loss:  0.00021197905880399048
Valid Loss:  0.0002918801037594676
Epoch:  353  	Training Loss: 0.00021417762036435306
Test Loss:  0.00021155014110263437
Valid Loss:  0.0002910285256803036
Epoch:  354  	Training Loss: 0.00021308651776053011
Test Loss:  0.00021126752835698426
Valid Loss:  0.0002902101259678602
Epoch:  355  	Training Loss: 0.0002120325225405395
Test Loss:  0.00021104919142089784
Valid Loss:  0.00028942018980160356
Epoch:  356  	Training Loss: 0.00021101335005369037
Test Loss:  0.00021086241758894175
Valid Loss:  0.000288655748590827
Epoch:  357  	Training Loss: 0.00021002808352932334
Test Loss:  0.0002106947940774262
Valid Loss:  0.0002879185485653579
Epoch:  358  	Training Loss: 0.00020908145233988762
Test Loss:  0.00021053758973721415
Valid Loss:  0.00028720893897116184
Epoch:  359  	Training Loss: 0.0002081759157590568
Test Loss:  0.00021038173872511834
Valid Loss:  0.00028653076151385903
Epoch:  360  	Training Loss: 0.00020729927928186953
Test Loss:  0.00021023501176387072
Valid Loss:  0.00028588081477209926
Epoch:  361  	Training Loss: 0.00020645634504035115
Test Loss:  0.0002100997226079926
Valid Loss:  0.0002852565376088023
Epoch:  362  	Training Loss: 0.0002056508674286306
Test Loss:  0.00021020359417889267
Valid Loss:  0.0002851931203622371
Epoch:  363  	Training Loss: 0.0002055777149507776
Test Loss:  0.00021027648472227156
Valid Loss:  0.0002851297613233328
Epoch:  364  	Training Loss: 0.00020550761837512255
Test Loss:  0.00021032804215792567
Valid Loss:  0.00028506485978141427
Epoch:  365  	Training Loss: 0.00020543887512758374
Test Loss:  0.0002103603328578174
Valid Loss:  0.00028499934705905616
Epoch:  366  	Training Loss: 0.00020537094678729773
Test Loss:  0.00021037604892626405
Valid Loss:  0.00028493136051110923
Epoch:  367  	Training Loss: 0.0002053044445347041
Test Loss:  0.0002103788428939879
Valid Loss:  0.000284865265712142
Epoch:  368  	Training Loss: 0.0002052388445008546
Test Loss:  0.0002103704318869859
Valid Loss:  0.000284797977656126
Epoch:  369  	Training Loss: 0.0002051744086202234
Test Loss:  0.00021034639212302864
Valid Loss:  0.0002847286523319781
Epoch:  370  	Training Loss: 0.00020511118054855615
Test Loss:  0.00021030911011621356
Valid Loss:  0.00028465985087677836
Epoch:  371  	Training Loss: 0.00020504945132415742
Test Loss:  0.0002102612634189427
Valid Loss:  0.0002845895360223949
Epoch:  372  	Training Loss: 0.00020498860976658762
Test Loss:  0.0002097430406138301
Valid Loss:  0.0002842002431862056
Epoch:  373  	Training Loss: 0.00020447456336114556
Test Loss:  0.00020924833370372653
Valid Loss:  0.0002838245709426701
Epoch:  374  	Training Loss: 0.00020398577908053994
Test Loss:  0.00020877404313068837
Valid Loss:  0.00028346345061436296
Epoch:  375  	Training Loss: 0.0002035197103396058
Test Loss:  0.00020831709844060242
Valid Loss:  0.0002831140300258994
Epoch:  376  	Training Loss: 0.0002030722243944183
Test Loss:  0.0002078757097478956
Valid Loss:  0.00028277418459765613
Epoch:  377  	Training Loss: 0.00020264089107513428
Test Loss:  0.00020745082292705774
Valid Loss:  0.00028244522400200367
Epoch:  378  	Training Loss: 0.00020222595776431262
Test Loss:  0.00020704134658444673
Valid Loss:  0.0002821270900312811
Epoch:  379  	Training Loss: 0.0002018279628828168
Test Loss:  0.00020664808107540011
Valid Loss:  0.00028181858942843974
Epoch:  380  	Training Loss: 0.00020144444715697318
Test Loss:  0.0002062685089185834
Valid Loss:  0.00028151788865216076
Epoch:  381  	Training Loss: 0.00020107379532419145
Test Loss:  0.00020590012718457729
Valid Loss:  0.0002812249003909528
Epoch:  382  	Training Loss: 0.00020071379549335688
Test Loss:  0.0002101945865433663
Valid Loss:  0.0002822761016432196
Epoch:  383  	Training Loss: 0.00019935102318413556
Test Loss:  0.00021125792409293354
Valid Loss:  0.00028263323474675417
Epoch:  384  	Training Loss: 0.00019925387459807098
Test Loss:  0.00021148062660358846
Valid Loss:  0.0002826808486133814
Epoch:  385  	Training Loss: 0.00019921959028579295
Test Loss:  0.0002115095849148929
Valid Loss:  0.00028265052242204547
Epoch:  386  	Training Loss: 0.00019918871112167835
Test Loss:  0.00021149450913071632
Valid Loss:  0.0002826033451128751
Epoch:  387  	Training Loss: 0.0001991581084439531
Test Loss:  0.0002114690578309819
Valid Loss:  0.00028255197685211897
Epoch:  388  	Training Loss: 0.00019912736024707556
Test Loss:  0.00021144229685887694
Valid Loss:  0.00028249938623048365
Epoch:  389  	Training Loss: 0.00019909739785362035
Test Loss:  0.00021141454635653645
Valid Loss:  0.0002824468829203397
Epoch:  390  	Training Loss: 0.000199066853383556
Test Loss:  0.00021138691226951778
Valid Loss:  0.0002823944669216871
Epoch:  391  	Training Loss: 0.00019903676002286375
Test Loss:  0.00021135929273441434
Valid Loss:  0.0002823422255460173
Epoch:  392  	Training Loss: 0.00019900673942174762
Test Loss:  0.00021110111265443265
Valid Loss:  0.0002821524685714394
Epoch:  393  	Training Loss: 0.00019886865629814565
Test Loss:  0.00021084747277200222
Valid Loss:  0.0002819604706019163
Epoch:  394  	Training Loss: 0.00019873128621838987
Test Loss:  0.00021059777645859867
Valid Loss:  0.0002817677450366318
Epoch:  395  	Training Loss: 0.00019859537133015692
Test Loss:  0.00021036059479229152
Valid Loss:  0.00028157493215985596
Epoch:  396  	Training Loss: 0.00019846284703817219
Test Loss:  0.00021012630895711482
Valid Loss:  0.00028138153720647097
Epoch:  397  	Training Loss: 0.00019833110854960978
Test Loss:  0.00020989583572372794
Valid Loss:  0.00028118788031861186
Epoch:  398  	Training Loss: 0.0001982021058211103
Test Loss:  0.00020968494936823845
Valid Loss:  0.00028099725022912025
Epoch:  399  	Training Loss: 0.00019807838543783873
Test Loss:  0.00020948181918356568
Valid Loss:  0.00028081590426154435
Epoch:  400  	Training Loss: 0.00019795795378740877
Test Loss:  0.00020928875892423093
Valid Loss:  0.0002806426491588354
Epoch:  401  	Training Loss: 0.0001978404907276854
Test Loss:  0.00020910050079692155
Valid Loss:  0.0002804695686791092
Epoch:  402  	Training Loss: 0.00019772362429648638
Test Loss:  0.0002090596972266212
Valid Loss:  0.0002804153482429683
Epoch:  403  	Training Loss: 0.00019768801575992256
Test Loss:  0.00020901905372738838
Valid Loss:  0.0002803620882332325
Epoch:  404  	Training Loss: 0.00019765297474805266
Test Loss:  0.00020897839567624032
Valid Loss:  0.00028030836256220937
Epoch:  405  	Training Loss: 0.0001976175990421325
Test Loss:  0.00020893794135190547
Valid Loss:  0.0002802557428367436
Epoch:  406  	Training Loss: 0.0001975826162379235
Test Loss:  0.00020889754523523152
Valid Loss:  0.00028020457830280066
Epoch:  407  	Training Loss: 0.00019754750246647745
Test Loss:  0.00020885796402581036
Valid Loss:  0.0002801555674523115
 82%|████████▏ | 409/500 [04:59<00:31,  2.93it/s] 82%|████████▏ | 411/500 [05:06<01:46,  1.20s/it] 83%|████████▎ | 413/500 [05:06<01:14,  1.16it/s] 83%|████████▎ | 415/500 [05:06<00:52,  1.61it/s] 83%|████████▎ | 417/500 [05:06<00:37,  2.19it/s] 84%|████████▍ | 419/500 [05:06<00:27,  2.94it/s] 84%|████████▍ | 421/500 [05:13<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:13<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:13<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:13<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:13<00:24,  2.96it/s] 86%|████████▌ | 431/500 [05:20<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:20<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:20<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:20<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:20<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:26<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:27<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:27<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:27<00:24,  2.21it/s] 90%|████████▉ | 449/500 [05:27<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:33<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:34<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:34<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:34<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:34<00:14,  2.92it/s] 92%|█████████▏| 461/500 [05:41<00:47,  1.23s/it] 93%|█████████▎| 463/500 [05:41<00:32,  1.13it/s] 93%|█████████▎| 465/500 [05:41<00:22,  1.55it/s] 93%|█████████▎| 467/500 [05:41<00:15,  2.11it/s] 94%|█████████▍| 469/500 [05:41<00:10,  2.85it/s] 94%|█████████▍| 471/500 [05:48<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:48<00:23,  1.14it/s]Epoch:  408  	Training Loss: 0.0001975136110559106
Test Loss:  0.0002088183828163892
Valid Loss:  0.00028010670212097466
Epoch:  409  	Training Loss: 0.00019748008344322443
Test Loss:  0.00020877922361250967
Valid Loss:  0.00028005754575133324
Epoch:  410  	Training Loss: 0.00019744668679777533
Test Loss:  0.00020874150504823774
Valid Loss:  0.0002800111542455852
Epoch:  411  	Training Loss: 0.0001974155311472714
Test Loss:  0.0002087039320031181
Valid Loss:  0.0002799651410896331
Epoch:  412  	Training Loss: 0.00019738441915251315
Test Loss:  0.00020780207705684006
Valid Loss:  0.0002792789600789547
Epoch:  413  	Training Loss: 0.00019641913240775466
Test Loss:  0.00020705221686512232
Valid Loss:  0.0002786654804367572
Epoch:  414  	Training Loss: 0.00019549652643036097
Test Loss:  0.00020641324226744473
Valid Loss:  0.0002781178627628833
Epoch:  415  	Training Loss: 0.0001946081465575844
Test Loss:  0.00020585760648828
Valid Loss:  0.00027760863304138184
Epoch:  416  	Training Loss: 0.0001937496563186869
Test Loss:  0.0002053572388831526
Valid Loss:  0.0002771300496533513
Epoch:  417  	Training Loss: 0.0001929157879203558
Test Loss:  0.00020490167662501335
Valid Loss:  0.00027667407994158566
Epoch:  418  	Training Loss: 0.00019210507161915302
Test Loss:  0.00020447716815397143
Valid Loss:  0.00027623531059361994
Epoch:  419  	Training Loss: 0.0001913146988954395
Test Loss:  0.0002040742547251284
Valid Loss:  0.00027581010363064706
Epoch:  420  	Training Loss: 0.00019054103177040815
Test Loss:  0.00020368726109154522
Valid Loss:  0.00027539601433090866
Epoch:  421  	Training Loss: 0.00018978430307470262
Test Loss:  0.00020331802079454064
Valid Loss:  0.0002749938576016575
Epoch:  422  	Training Loss: 0.00018904751050285995
Test Loss:  0.00020334347209427506
Valid Loss:  0.0002749624545685947
Epoch:  423  	Training Loss: 0.0001890382554847747
Test Loss:  0.0002033691416727379
Valid Loss:  0.0002749331179074943
Epoch:  424  	Training Loss: 0.00018902913143392652
Test Loss:  0.00020339334150776267
Valid Loss:  0.00027490395586937666
Epoch:  425  	Training Loss: 0.0001890200946945697
Test Loss:  0.00020341703202575445
Valid Loss:  0.00027487569605000317
Epoch:  426  	Training Loss: 0.0001890112180262804
Test Loss:  0.00020344035874586552
Valid Loss:  0.0002748493861872703
Epoch:  427  	Training Loss: 0.00018900251598097384
Test Loss:  0.00020346237579360604
Valid Loss:  0.0002748228725977242
Epoch:  428  	Training Loss: 0.0001889937266241759
Test Loss:  0.00020348417456261814
Valid Loss:  0.0002747972612269223
Epoch:  429  	Training Loss: 0.00018898508278653026
Test Loss:  0.00020350428530946374
Valid Loss:  0.0002747727558016777
Epoch:  430  	Training Loss: 0.00018897629342973232
Test Loss:  0.000203524628886953
Valid Loss:  0.0002747488906607032
Epoch:  431  	Training Loss: 0.00018896759138442576
Test Loss:  0.00020354401203803718
Valid Loss:  0.000274725811323151
Epoch:  432  	Training Loss: 0.00018895920948125422
Test Loss:  0.0002029195602517575
Valid Loss:  0.00027430185582488775
Epoch:  433  	Training Loss: 0.0001883506338344887
Test Loss:  0.000202331313630566
Valid Loss:  0.00027390208560973406
Epoch:  434  	Training Loss: 0.00018777056538965553
Test Loss:  0.00020177765691187233
Valid Loss:  0.00027352405595593154
Epoch:  435  	Training Loss: 0.00018721725791692734
Test Loss:  0.00020125569426454604
Valid Loss:  0.0002731680579017848
Epoch:  436  	Training Loss: 0.00018669207929633558
Test Loss:  0.00020076836517546326
Valid Loss:  0.0002728389808908105
Epoch:  437  	Training Loss: 0.00018619385082274675
Test Loss:  0.0002003070549108088
Valid Loss:  0.0002725278027355671
Epoch:  438  	Training Loss: 0.00018571513646747917
Test Loss:  0.00019987041014246643
Valid Loss:  0.0002722318167798221
Epoch:  439  	Training Loss: 0.00018525408813729882
Test Loss:  0.0001994571357499808
Valid Loss:  0.00027194718131795526
Epoch:  440  	Training Loss: 0.00018480970175005496
Test Loss:  0.00019906650413759053
Valid Loss:  0.00027167683583684266
Epoch:  441  	Training Loss: 0.00018438426195643842
Test Loss:  0.00019869219977408648
Valid Loss:  0.0002714159491006285
Epoch:  442  	Training Loss: 0.00018397376697976142
Test Loss:  0.0001987894793273881
Valid Loss:  0.00027139048324897885
Epoch:  443  	Training Loss: 0.0001839522155933082
Test Loss:  0.00019886574591509998
Valid Loss:  0.0002713643480092287
Epoch:  444  	Training Loss: 0.00018393128993920982
Test Loss:  0.0001989245938602835
Valid Loss:  0.00027133768890053034
Epoch:  445  	Training Loss: 0.00018391082994639874
Test Loss:  0.0001989700540434569
Valid Loss:  0.00027130989474244416
Epoch:  446  	Training Loss: 0.00018389118486084044
Test Loss:  0.00019900422194041312
Valid Loss:  0.00027128332294523716
Epoch:  447  	Training Loss: 0.00018387268937658519
Test Loss:  0.0001990281161852181
Valid Loss:  0.00027125567430630326
Epoch:  448  	Training Loss: 0.0001838544412748888
Test Loss:  0.00019904377404600382
Valid Loss:  0.000271228258498013
Epoch:  449  	Training Loss: 0.00018383623682893813
Test Loss:  0.00019905467343050987
Valid Loss:  0.0002711999695748091
Epoch:  450  	Training Loss: 0.00018381855625193566
Test Loss:  0.0001990603923331946
Valid Loss:  0.0002711711567826569
Epoch:  451  	Training Loss: 0.00018380068650003523
Test Loss:  0.00019906251691281796
Valid Loss:  0.00027114374097436666
Epoch:  452  	Training Loss: 0.000183784868568182
Test Loss:  0.00019963261729571968
Valid Loss:  0.0002711317501962185
Epoch:  453  	Training Loss: 0.0001833320566220209
Test Loss:  0.00020003033569082618
Valid Loss:  0.00027110736118629575
Epoch:  454  	Training Loss: 0.00018294928304385394
Test Loss:  0.00020029574807267636
Valid Loss:  0.00027106457855552435
Epoch:  455  	Training Loss: 0.00018260421347804368
Test Loss:  0.00020046503050252795
Valid Loss:  0.00027100450824946165
Epoch:  456  	Training Loss: 0.00018228079716209322
Test Loss:  0.0002005641581490636
Valid Loss:  0.00027093017706647515
Epoch:  457  	Training Loss: 0.00018196998280473053
Test Loss:  0.00020061296527273953
Valid Loss:  0.00027084455359727144
Epoch:  458  	Training Loss: 0.00018166794325225055
Test Loss:  0.00020062616385985166
Valid Loss:  0.00027074996614828706
Epoch:  459  	Training Loss: 0.0001813724375097081
Test Loss:  0.00020061354734934866
Valid Loss:  0.00027064906316809356
Epoch:  460  	Training Loss: 0.00018108230142388493
Test Loss:  0.00020058310474269092
Valid Loss:  0.00027054338715970516
Epoch:  461  	Training Loss: 0.00018079666187986732
Test Loss:  0.00020054170454386622
Valid Loss:  0.0002704343060031533
Epoch:  462  	Training Loss: 0.00018051528604701161
Test Loss:  0.00020149104238953441
Valid Loss:  0.00027076731203123927
Epoch:  463  	Training Loss: 0.00018039325368590653
Test Loss:  0.00020196737023070455
Valid Loss:  0.00027094868710264564
Epoch:  464  	Training Loss: 0.00018036484834738076
Test Loss:  0.0002021823893301189
Valid Loss:  0.0002710336702875793
Epoch:  465  	Training Loss: 0.00018035934772342443
Test Loss:  0.00020228633366059512
Valid Loss:  0.0002710751723498106
Epoch:  466  	Training Loss: 0.00018035803805105388
Test Loss:  0.00020233645045664161
Valid Loss:  0.00027109545771963894
Epoch:  467  	Training Loss: 0.00018035765970125794
Test Loss:  0.00020236053387634456
Valid Loss:  0.00027110520750284195
Epoch:  468  	Training Loss: 0.00018035760149359703
Test Loss:  0.00020237202988937497
Valid Loss:  0.00027110977680422366
Epoch:  469  	Training Loss: 0.00018035757238976657
Test Loss:  0.00020237760327290744
Valid Loss:  0.00027111213421449065
Epoch:  470  	Training Loss: 0.00018035755783785135
Test Loss:  0.00020238023716956377
Valid Loss:  0.0002711131819523871
Epoch:  471  	Training Loss: 0.00018035751418210566
Test Loss:  0.00020238150318618864
Valid Loss:  0.0002711135894060135
Epoch:  472  	Training Loss: 0.00018035751418210566
Test Loss:  0.00020095454237889498
Valid Loss:  0.00027080762083642185
Epoch:  473  	Training Loss: 0.00018011758220382035
Test Loss:  0.00019980402430519462
Valid Loss:  0.0002705371589399874
Epoch:  474  	Training Loss: 0.00017993166693486273
Test Loss:  0.00019886631343979388
Valid Loss:  0.0002702868659980595
 95%|█████████▌| 475/500 [05:48<00:15,  1.57it/s] 95%|█████████▌| 477/500 [05:48<00:10,  2.15it/s] 96%|█████████▌| 479/500 [05:48<00:07,  2.87it/s] 96%|█████████▌| 481/500 [05:55<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:55<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:55<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:55<00:06,  2.16it/s] 98%|█████████▊| 489/500 [05:55<00:03,  2.90it/s] 98%|█████████▊| 491/500 [06:02<00:10,  1.21s/it] 99%|█████████▊| 493/500 [06:02<00:06,  1.15it/s] 99%|█████████▉| 495/500 [06:02<00:03,  1.58it/s] 99%|█████████▉| 497/500 [06:02<00:01,  2.17it/s]100%|█████████▉| 499/500 [06:02<00:00,  2.91it/s]100%|██████████| 500/500 [06:02<00:00,  1.38it/s]
Epoch:  475  	Training Loss: 0.00017978189862333238
Test Loss:  0.00019809589139185846
Valid Loss:  0.0002700507757253945
Epoch:  476  	Training Loss: 0.00017965584993362427
Test Loss:  0.00019745712052099407
Valid Loss:  0.0002698229509405792
Epoch:  477  	Training Loss: 0.00017954727809410542
Test Loss:  0.00019692524801939726
Valid Loss:  0.00026960292598232627
Epoch:  478  	Training Loss: 0.0001794513373170048
Test Loss:  0.00019647734006866813
Valid Loss:  0.000269386189756915
Epoch:  479  	Training Loss: 0.00017936270160134882
Test Loss:  0.00019609728769864887
Valid Loss:  0.00026917201466858387
Epoch:  480  	Training Loss: 0.00017927924636751413
Test Loss:  0.00019577136845327914
Valid Loss:  0.0002689598477445543
Epoch:  481  	Training Loss: 0.00017919938545674086
Test Loss:  0.00019548978889361024
Valid Loss:  0.000268749485258013
Epoch:  482  	Training Loss: 0.0001791234826669097
Test Loss:  0.00019543146481737494
Valid Loss:  0.0002686436637304723
Epoch:  483  	Training Loss: 0.0001790571550372988
Test Loss:  0.00019537287880666554
Valid Loss:  0.0002685372601263225
Epoch:  484  	Training Loss: 0.00017899097292684019
Test Loss:  0.00019531475845724344
Valid Loss:  0.0002684324572328478
Epoch:  485  	Training Loss: 0.00017892534378916025
Test Loss:  0.00019525691459421068
Valid Loss:  0.00026832701405510306
Epoch:  486  	Training Loss: 0.00017885956913232803
Test Loss:  0.00019519965280778706
Valid Loss:  0.00026822194922715425
Epoch:  487  	Training Loss: 0.00017879407096188515
Test Loss:  0.0001951417070813477
Valid Loss:  0.0002681170008145273
Epoch:  488  	Training Loss: 0.00017872857279144228
Test Loss:  0.00019508454715833068
Valid Loss:  0.0002680119941942394
Epoch:  489  	Training Loss: 0.00017866310372482985
Test Loss:  0.00019502692157402635
Valid Loss:  0.0002679075696505606
Epoch:  490  	Training Loss: 0.00017859817307908088
Test Loss:  0.00019497046014294028
Valid Loss:  0.00026780401822179556
Epoch:  491  	Training Loss: 0.00017853404278866947
Test Loss:  0.0001949147554114461
Valid Loss:  0.00026770311524160206
Epoch:  492  	Training Loss: 0.00017847266281023622
Test Loss:  0.00019348549540154636
Valid Loss:  0.00026718463050201535
Epoch:  493  	Training Loss: 0.00017797641339711845
Test Loss:  0.0001929057907545939
Valid Loss:  0.00026673218235373497
Epoch:  494  	Training Loss: 0.0001775341952452436
Test Loss:  0.00019263880676589906
Valid Loss:  0.00026630947832018137
Epoch:  495  	Training Loss: 0.00017711022519506514
Test Loss:  0.00019249397155363113
Valid Loss:  0.00026590764173306525
Epoch:  496  	Training Loss: 0.0001767009380273521
Test Loss:  0.0001923999225255102
Valid Loss:  0.0002655226271599531
Epoch:  497  	Training Loss: 0.00017630473303142935
Test Loss:  0.00019232623162679374
Valid Loss:  0.0002651521936058998
Epoch:  498  	Training Loss: 0.0001759216102072969
Test Loss:  0.0001922637311508879
Valid Loss:  0.0002647952060215175
Epoch:  499  	Training Loss: 0.00017554996884427965
Test Loss:  0.00019220833200961351
Valid Loss:  0.0002644512860570103
Epoch:  500  	Training Loss: 0.0001751920353854075
Test Loss:  0.00019216281361877918
Valid Loss:  0.00026412541046738625
seed is  20
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:34, 14.23it/s]  1%|          | 4/500 [00:00<00:32, 15.29it/s]  1%|          | 6/500 [00:00<00:31, 15.49it/s]  2%|▏         | 8/500 [00:00<00:31, 15.57it/s]  2%|▏         | 10/500 [00:00<00:31, 15.66it/s]  2%|▏         | 12/500 [00:00<00:30, 15.89it/s]  3%|▎         | 14/500 [00:00<00:31, 15.56it/s]  3%|▎         | 16/500 [00:01<00:31, 15.58it/s]  4%|▎         | 18/500 [00:01<00:30, 15.66it/s]  4%|▍         | 20/500 [00:01<00:30, 15.79it/s]  4%|▍         | 22/500 [00:01<00:30, 15.69it/s]  5%|▍         | 24/500 [00:01<00:33, 14.04it/s]  5%|▌         | 26/500 [00:01<00:34, 13.88it/s]  6%|▌         | 28/500 [00:01<00:32, 14.54it/s]  6%|▌         | 30/500 [00:01<00:31, 14.97it/s]  6%|▋         | 32/500 [00:02<00:30, 15.23it/s]  7%|▋         | 34/500 [00:02<00:30, 15.42it/s]  7%|▋         | 36/500 [00:02<00:30, 15.45it/s]  8%|▊         | 38/500 [00:02<00:30, 15.02it/s]  8%|▊         | 40/500 [00:02<00:33, 13.91it/s]  8%|▊         | 42/500 [00:02<00:33, 13.83it/s]  9%|▉         | 44/500 [00:02<00:31, 14.44it/s]  9%|▉         | 46/500 [00:03<00:30, 14.85it/s] 10%|▉         | 48/500 [00:03<00:32, 14.03it/s] 10%|█         | 50/500 [00:03<00:34, 13.21it/s] 10%|█         | 52/500 [00:03<00:34, 12.92it/s] 11%|█         | 54/500 [00:03<00:32, 13.69it/s] 11%|█         | 56/500 [00:03<00:31, 14.25it/s] 12%|█▏        | 58/500 [00:03<00:30, 14.61it/s] 12%|█▏        | 60/500 [00:04<00:29, 14.99it/s] 12%|█▏        | 62/500 [00:04<00:28, 15.36it/s] 13%|█▎        | 64/500 [00:04<00:28, 15.53it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.73it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.89it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.92it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.94it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.91it/s] 15%|█▌        | 76/500 [00:05<00:26, 15.97it/s] 16%|█▌        | 78/500 [00:05<00:27, 15.62it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.71it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.78it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.56it/s] 17%|█▋        | 86/500 [00:05<00:27, 14.94it/s] 18%|█▊        | 88/500 [00:05<00:27, 15.02it/s] 18%|█▊        | 90/500 [00:05<00:27, 14.88it/s] 18%|█▊        | 92/500 [00:06<00:26, 15.32it/s] 19%|█▉        | 94/500 [00:06<00:26, 15.35it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.60it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.67it/s] 20%|██        | 100/500 [00:06<00:25, 15.85it/s] 20%|██        | 102/500 [00:06<00:24, 15.96it/s] 21%|██        | 104/500 [00:06<00:24, 16.01it/s] 21%|██        | 106/500 [00:06<00:24, 16.07it/s] 22%|██▏       | 108/500 [00:07<00:24, 16.03it/s] 22%|██▏       | 110/500 [00:07<00:25, 15.46it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.58it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.65it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.88it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.91it/s] 24%|██▍       | 120/500 [00:07<00:23, 15.99it/s] 24%|██▍       | 122/500 [00:08<00:23, 16.01it/s] 25%|██▍       | 124/500 [00:08<00:24, 15.58it/s]Epoch:  1  	Training Loss: 0.20486688613891602
Test Loss:  3303.94775390625
Valid Loss:  3302.748779296875
Epoch:  2  	Training Loss: 3313.3330078125
Test Loss:  582644858880.0
Valid Loss:  570798112768.0
Epoch:  3  	Training Loss: 578538242048.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 15.78it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.90it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.94it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.79it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.78it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.22it/s] 28%|██▊       | 138/500 [00:09<00:23, 15.50it/s] 28%|██▊       | 140/500 [00:09<00:22, 15.69it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.84it/s] 29%|██▉       | 144/500 [00:09<00:22, 16.02it/s] 29%|██▉       | 146/500 [00:09<00:22, 16.08it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.17it/s] 30%|███       | 150/500 [00:09<00:21, 16.06it/s] 30%|███       | 152/500 [00:09<00:21, 16.03it/s] 31%|███       | 154/500 [00:10<00:21, 16.06it/s] 31%|███       | 156/500 [00:10<00:21, 16.08it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.00it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.83it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.86it/s] 33%|███▎      | 164/500 [00:10<00:22, 15.03it/s] 33%|███▎      | 166/500 [00:10<00:22, 14.80it/s] 34%|███▎      | 168/500 [00:10<00:21, 15.14it/s] 34%|███▍      | 170/500 [00:11<00:21, 15.46it/s] 34%|███▍      | 172/500 [00:11<00:21, 15.53it/s] 35%|███▍      | 174/500 [00:11<00:20, 15.78it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.59it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.68it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.64it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.79it/s] 37%|███▋      | 184/500 [00:11<00:19, 15.90it/s] 37%|███▋      | 186/500 [00:12<00:19, 15.87it/s] 38%|███▊      | 188/500 [00:12<00:19, 15.88it/s] 38%|███▊      | 190/500 [00:12<00:19, 15.73it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.91it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.93it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.03it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.70it/s] 40%|████      | 200/500 [00:12<00:20, 14.70it/s] 40%|████      | 202/500 [00:13<00:20, 14.90it/s] 41%|████      | 204/500 [00:13<00:20, 14.36it/s] 41%|████      | 206/500 [00:13<00:21, 13.57it/s] 42%|████▏     | 208/500 [00:13<00:21, 13.85it/s] 42%|████▏     | 210/500 [00:13<00:20, 14.48it/s] 42%|████▏     | 212/500 [00:13<00:19, 14.46it/s] 43%|████▎     | 214/500 [00:13<00:19, 14.86it/s] 43%|████▎     | 216/500 [00:14<00:19, 14.93it/s] 44%|████▎     | 218/500 [00:14<00:19, 14.61it/s] 44%|████▍     | 220/500 [00:14<00:19, 14.59it/s] 44%|████▍     | 222/500 [00:14<00:18, 14.93it/s] 45%|████▍     | 224/500 [00:14<00:18, 15.10it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.37it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.57it/s] 46%|████▌     | 230/500 [00:15<00:17, 15.76it/s] 46%|████▋     | 232/500 [00:15<00:16, 15.95it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.00it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.00it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.06it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.76it/s] 48%|████▊     | 242/500 [00:15<00:17, 14.38it/s] 49%|████▉     | 244/500 [00:15<00:18, 13.51it/s] 49%|████▉     | 246/500 [00:16<00:19, 12.93it/s] 50%|████▉     | 248/500 [00:16<00:19, 12.89it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:18, 13.69it/s] 50%|█████     | 252/500 [00:16<00:17, 13.89it/s] 51%|█████     | 254/500 [00:16<00:17, 14.42it/s] 51%|█████     | 256/500 [00:16<00:16, 14.85it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.13it/s] 52%|█████▏    | 260/500 [00:17<00:15, 15.21it/s] 52%|█████▏    | 262/500 [00:17<00:15, 15.26it/s] 53%|█████▎    | 264/500 [00:17<00:15, 15.40it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.65it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.78it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.83it/s] 54%|█████▍    | 272/500 [00:17<00:14, 15.87it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.61it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.43it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.66it/s] 56%|█████▌    | 280/500 [00:18<00:14, 15.61it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.68it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.71it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.77it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.89it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.83it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.95it/s] 59%|█████▉    | 294/500 [00:19<00:12, 15.99it/s] 59%|█████▉    | 296/500 [00:19<00:12, 15.98it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.98it/s] 60%|██████    | 300/500 [00:19<00:12, 16.04it/s] 60%|██████    | 302/500 [00:19<00:12, 16.02it/s] 61%|██████    | 304/500 [00:19<00:12, 15.67it/s] 61%|██████    | 306/500 [00:20<00:12, 14.95it/s] 62%|██████▏   | 308/500 [00:20<00:13, 14.52it/s] 62%|██████▏   | 310/500 [00:20<00:13, 14.26it/s] 62%|██████▏   | 312/500 [00:20<00:12, 14.74it/s] 63%|██████▎   | 314/500 [00:20<00:12, 14.94it/s] 63%|██████▎   | 316/500 [00:20<00:12, 14.58it/s] 64%|██████▎   | 318/500 [00:20<00:12, 15.01it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.14it/s] 64%|██████▍   | 322/500 [00:21<00:11, 15.37it/s] 65%|██████▍   | 324/500 [00:21<00:11, 15.46it/s] 65%|██████▌   | 326/500 [00:21<00:11, 15.62it/s] 66%|██████▌   | 328/500 [00:21<00:10, 15.70it/s] 66%|██████▌   | 330/500 [00:21<00:10, 15.75it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.50it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.38it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.51it/s] 68%|██████▊   | 338/500 [00:22<00:10, 15.66it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.80it/s] 68%|██████▊   | 342/500 [00:22<00:09, 15.91it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.05it/s] 69%|██████▉   | 346/500 [00:22<00:09, 15.88it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.65it/s] 70%|███████   | 350/500 [00:22<00:09, 15.30it/s] 70%|███████   | 352/500 [00:22<00:09, 15.35it/s] 71%|███████   | 354/500 [00:23<00:09, 15.45it/s] 71%|███████   | 356/500 [00:23<00:09, 15.52it/s] 72%|███████▏  | 358/500 [00:23<00:09, 15.70it/s] 72%|███████▏  | 360/500 [00:23<00:08, 15.77it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.71it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.83it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.96it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.00it/s] 74%|███████▍  | 370/500 [00:24<00:08, 15.87it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.84it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 15.80it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.83it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.94it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.07it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.93it/s] 77%|███████▋  | 384/500 [00:25<00:07, 15.99it/s] 77%|███████▋  | 386/500 [00:25<00:07, 15.91it/s] 78%|███████▊  | 388/500 [00:25<00:07, 15.88it/s] 78%|███████▊  | 390/500 [00:25<00:06, 15.84it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.76it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.86it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.98it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.02it/s] 80%|████████  | 400/500 [00:26<00:06, 16.05it/s] 80%|████████  | 402/500 [00:26<00:06, 16.10it/s] 81%|████████  | 404/500 [00:26<00:05, 16.08it/s] 81%|████████  | 406/500 [00:26<00:05, 15.86it/s] 82%|████████▏ | 408/500 [00:26<00:06, 14.68it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.05it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.29it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.44it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.64it/s] 84%|████████▎ | 418/500 [00:27<00:05, 15.75it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.61it/s] 84%|████████▍ | 422/500 [00:27<00:04, 15.70it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.76it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.90it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.91it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.03it/s] 86%|████████▋ | 432/500 [00:28<00:04, 15.07it/s] 87%|████████▋ | 434/500 [00:28<00:04, 14.12it/s] 87%|████████▋ | 436/500 [00:28<00:04, 14.20it/s] 88%|████████▊ | 438/500 [00:28<00:04, 14.61it/s] 88%|████████▊ | 440/500 [00:28<00:03, 15.03it/s] 88%|████████▊ | 442/500 [00:28<00:04, 14.47it/s] 89%|████████▉ | 444/500 [00:28<00:04, 13.64it/s] 89%|████████▉ | 446/500 [00:29<00:04, 13.06it/s] 90%|████████▉ | 448/500 [00:29<00:04, 12.82it/s] 90%|█████████ | 450/500 [00:29<00:03, 12.65it/s] 90%|█████████ | 452/500 [00:29<00:03, 13.22it/s] 91%|█████████ | 454/500 [00:29<00:03, 13.99it/s] 91%|█████████ | 456/500 [00:29<00:03, 14.59it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.01it/s] 92%|█████████▏| 460/500 [00:30<00:02, 15.22it/s] 92%|█████████▏| 462/500 [00:30<00:02, 15.23it/s] 93%|█████████▎| 464/500 [00:30<00:02, 15.44it/s] 93%|█████████▎| 466/500 [00:30<00:02, 15.60it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.77it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.79it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.77it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.82it/s] 95%|█████████▌| 476/500 [00:31<00:01, 15.94it/s] 96%|█████████▌| 478/500 [00:31<00:01, 16.00it/s] 96%|█████████▌| 480/500 [00:31<00:01, 15.68it/s] 96%|█████████▋| 482/500 [00:31<00:01, 15.61it/s] 97%|█████████▋| 484/500 [00:31<00:01, 15.58it/s] 97%|█████████▋| 486/500 [00:31<00:00, 15.68it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.80it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.95it/s] 98%|█████████▊| 492/500 [00:32<00:00, 15.76it/s] 99%|█████████▉| 494/500 [00:32<00:00, 15.64it/s] 99%|█████████▉| 496/500 [00:32<00:00, 15.84it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 15.88it/s]100%|██████████| 500/500 [00:32<00:00, 15.76it/s]100%|██████████| 500/500 [00:32<00:00, 15.33it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  20
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:34,  6.32s/it]  1%|          | 3/500 [00:06<14:03,  1.70s/it]  1%|          | 5/500 [00:06<07:08,  1.16it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<11:09,  1.37s/it]  3%|▎         | 13/500 [00:13<07:37,  1.06it/s]  3%|▎         | 15/500 [00:13<05:18,  1.52it/s]  3%|▎         | 17/500 [00:13<03:47,  2.12it/s]  4%|▍         | 19/500 [00:13<02:46,  2.88it/s]  4%|▍         | 21/500 [00:20<09:46,  1.22s/it]  4%|▍         | 22/500 [00:20<08:08,  1.02s/it]  5%|▍         | 24/500 [00:20<05:35,  1.42it/s]  5%|▌         | 26/500 [00:20<03:57,  1.99it/s]  6%|▌         | 28/500 [00:20<02:52,  2.74it/s]  6%|▌         | 30/500 [00:21<02:07,  3.68it/s]  6%|▋         | 32/500 [00:27<09:14,  1.18s/it]  7%|▋         | 34/500 [00:27<06:32,  1.19it/s]  7%|▋         | 36/500 [00:27<04:41,  1.65it/s]  8%|▊         | 38/500 [00:27<03:24,  2.26it/s]  8%|▊         | 40/500 [00:28<02:31,  3.04it/s]  8%|▊         | 42/500 [00:34<08:59,  1.18s/it]  9%|▉         | 44/500 [00:34<06:24,  1.19it/s]  9%|▉         | 46/500 [00:34<04:36,  1.64it/s] 10%|▉         | 48/500 [00:34<03:23,  2.22it/s] 10%|█         | 50/500 [00:34<02:33,  2.93it/s] 10%|█         | 52/500 [00:41<09:08,  1.22s/it] 11%|█         | 54/500 [00:41<06:31,  1.14it/s] 11%|█         | 56/500 [00:41<04:41,  1.58it/s] 12%|█▏        | 58/500 [00:41<03:24,  2.16it/s] 12%|█▏        | 60/500 [00:42<02:31,  2.90it/s] 12%|█▏        | 62/500 [00:48<08:45,  1.20s/it] 13%|█▎        | 64/500 [00:48<06:14,  1.16it/s] 13%|█▎        | 66/500 [00:48<04:29,  1.61it/s] 14%|█▎        | 68/500 [00:48<03:16,  2.20it/s] 14%|█▍        | 70/500 [00:48<02:25,  2.96it/s]Epoch:  1  	Training Loss: 0.20486688613891602
Test Loss:  341.6033935546875
Valid Loss:  329.1597900390625
Epoch:  2  	Training Loss: 331.0924377441406
Test Loss:  0.8009319305419922
Valid Loss:  0.7540631890296936
Epoch:  3  	Training Loss: 0.6709874272346497
Test Loss:  0.6251833438873291
Valid Loss:  0.5875520706176758
Epoch:  4  	Training Loss: 0.5155696868896484
Test Loss:  0.530853271484375
Valid Loss:  0.49819791316986084
Epoch:  5  	Training Loss: 0.4333091974258423
Test Loss:  0.4513135850429535
Valid Loss:  0.4229606091976166
Epoch:  6  	Training Loss: 0.36449629068374634
Test Loss:  0.3842325210571289
Valid Loss:  0.3596045672893524
Epoch:  7  	Training Loss: 0.3069564700126648
Test Loss:  0.32764172554016113
Valid Loss:  0.3062435984611511
Epoch:  8  	Training Loss: 0.2588593661785126
Test Loss:  0.2798815071582794
Valid Loss:  0.2612876892089844
Epoch:  9  	Training Loss: 0.21866603195667267
Test Loss:  0.23955345153808594
Valid Loss:  0.22339819371700287
Epoch:  10  	Training Loss: 0.18508431315422058
Test Loss:  0.2054799497127533
Valid Loss:  0.191448375582695
Epoch:  11  	Training Loss: 0.1570298969745636
Test Loss:  0.1766701638698578
Valid Loss:  0.16449080407619476
Epoch:  12  	Training Loss: 0.13359399139881134
Test Loss:  0.15384268760681152
Valid Loss:  0.14308270812034607
Epoch:  13  	Training Loss: 0.11531084775924683
Test Loss:  0.13427305221557617
Valid Loss:  0.12476932257413864
Epoch:  14  	Training Loss: 0.09981660544872284
Test Loss:  0.11747711896896362
Valid Loss:  0.10908706486225128
Epoch:  15  	Training Loss: 0.08667904883623123
Test Loss:  0.10304461419582367
Valid Loss:  0.0956432893872261
Epoch:  16  	Training Loss: 0.07553347200155258
Test Loss:  0.09062763303518295
Valid Loss:  0.0841052457690239
Epoch:  17  	Training Loss: 0.06607207655906677
Test Loss:  0.07993091642856598
Valid Loss:  0.07419086992740631
Epoch:  18  	Training Loss: 0.05803503096103668
Test Loss:  0.07070367783308029
Valid Loss:  0.06566078960895538
Epoch:  19  	Training Loss: 0.051202867180109024
Test Loss:  0.06273286044597626
Valid Loss:  0.05831184983253479
Epoch:  20  	Training Loss: 0.04539016634225845
Test Loss:  0.0558372437953949
Valid Loss:  0.05197152867913246
Epoch:  21  	Training Loss: 0.040440287441015244
Test Loss:  0.049862612038850784
Valid Loss:  0.04649309068918228
Epoch:  22  	Training Loss: 0.03622080385684967
Test Loss:  0.04462922737002373
Valid Loss:  0.04171033948659897
Epoch:  23  	Training Loss: 0.03258734941482544
Test Loss:  0.04008643329143524
Valid Loss:  0.03757024556398392
Epoch:  24  	Training Loss: 0.0294878501445055
Test Loss:  0.036136288195848465
Valid Loss:  0.03398009017109871
Epoch:  25  	Training Loss: 0.026840049773454666
Test Loss:  0.03269527107477188
Valid Loss:  0.03086096979677677
Epoch:  26  	Training Loss: 0.024574432522058487
Test Loss:  0.029692096635699272
Valid Loss:  0.028145626187324524
Epoch:  27  	Training Loss: 0.022632259875535965
Test Loss:  0.027065850794315338
Valid Loss:  0.025776740163564682
Epoch:  28  	Training Loss: 0.02096383459866047
Test Loss:  0.024764496833086014
Valid Loss:  0.02370540425181389
Epoch:  29  	Training Loss: 0.019527189433574677
Test Loss:  0.022743534296751022
Valid Loss:  0.021889952942728996
Epoch:  30  	Training Loss: 0.018286850303411484
Test Loss:  0.020964864641427994
Valid Loss:  0.020294737070798874
Epoch:  31  	Training Loss: 0.017212821170687675
Test Loss:  0.01939585618674755
Valid Loss:  0.018889376893639565
Epoch:  32  	Training Loss: 0.016279781237244606
Test Loss:  0.01800532639026642
Valid Loss:  0.0176455769687891
Epoch:  33  	Training Loss: 0.01546497642993927
Test Loss:  0.01677326112985611
Valid Loss:  0.016544029116630554
Epoch:  34  	Training Loss: 0.01475213561207056
Test Loss:  0.01567889377474785
Valid Loss:  0.015565533190965652
Epoch:  35  	Training Loss: 0.014125828631222248
Test Loss:  0.014704330824315548
Valid Loss:  0.01469364482909441
Epoch:  36  	Training Loss: 0.013573025353252888
Test Loss:  0.013834232464432716
Valid Loss:  0.013914273120462894
Epoch:  37  	Training Loss: 0.013082718476653099
Test Loss:  0.01305529847741127
Valid Loss:  0.013215300627052784
Epoch:  38  	Training Loss: 0.012645579874515533
Test Loss:  0.012356102466583252
Valid Loss:  0.012586340308189392
Epoch:  39  	Training Loss: 0.012253748252987862
Test Loss:  0.011726776137948036
Valid Loss:  0.01201845146715641
Epoch:  40  	Training Loss: 0.011900583282113075
Test Loss:  0.011158776469528675
Valid Loss:  0.011503931134939194
Epoch:  41  	Training Loss: 0.011580459773540497
Test Loss:  0.010644732974469662
Valid Loss:  0.0110361622646451
Epoch:  42  	Training Loss: 0.011288633570075035
Test Loss:  0.010181708261370659
Valid Loss:  0.010612046346068382
Epoch:  43  	Training Loss: 0.011022339574992657
Test Loss:  0.009760070592164993
Valid Loss:  0.010223543271422386
Epoch:  44  	Training Loss: 0.010776642709970474
Test Loss:  0.009375114925205708
Valid Loss:  0.009866486303508282
Epoch:  45  	Training Loss: 0.010548732243478298
Test Loss:  0.009022670798003674
Valid Loss:  0.009537219069898129
Epoch:  46  	Training Loss: 0.010336213745176792
Test Loss:  0.008699143305420876
Valid Loss:  0.009232592768967152
Epoch:  47  	Training Loss: 0.010137071833014488
Test Loss:  0.008401361294090748
Valid Loss:  0.008949873968958855
Epoch:  48  	Training Loss: 0.009949592873454094
Test Loss:  0.008126570843160152
Valid Loss:  0.008686663582921028
Epoch:  49  	Training Loss: 0.00977232214063406
Test Loss:  0.007872328162193298
Valid Loss:  0.00844088476151228
Epoch:  50  	Training Loss: 0.009604014456272125
Test Loss:  0.007636531256139278
Valid Loss:  0.008210726082324982
Epoch:  51  	Training Loss: 0.009443631395697594
Test Loss:  0.007417299784719944
Valid Loss:  0.007994601503014565
Epoch:  52  	Training Loss: 0.009290281683206558
Test Loss:  0.007212599739432335
Valid Loss:  0.007790745701640844
Epoch:  53  	Training Loss: 0.009142926894128323
Test Loss:  0.00702144019305706
Valid Loss:  0.007598362397402525
Epoch:  54  	Training Loss: 0.009001202881336212
Test Loss:  0.006842503324151039
Valid Loss:  0.0074163684621453285
Epoch:  55  	Training Loss: 0.008864561095833778
Test Loss:  0.006674634292721748
Valid Loss:  0.007243799511343241
Epoch:  56  	Training Loss: 0.008732527494430542
Test Loss:  0.00651682261377573
Valid Loss:  0.007079824805259705
Epoch:  57  	Training Loss: 0.008604689501225948
Test Loss:  0.0063681453466415405
Valid Loss:  0.006923690438270569
Epoch:  58  	Training Loss: 0.008480694144964218
Test Loss:  0.006227811798453331
Valid Loss:  0.006774744484573603
Epoch:  59  	Training Loss: 0.008360251784324646
Test Loss:  0.0060950713232159615
Valid Loss:  0.006632393226027489
Epoch:  60  	Training Loss: 0.00824308767914772
Test Loss:  0.005969277583062649
Valid Loss:  0.006496112793684006
Epoch:  61  	Training Loss: 0.008128991350531578
Test Loss:  0.005849891342222691
Valid Loss:  0.0063654715195298195
Epoch:  62  	Training Loss: 0.008017758838832378
Test Loss:  0.005736194550991058
Valid Loss:  0.006239946000277996
Epoch:  63  	Training Loss: 0.007909223437309265
Test Loss:  0.005627918988466263
Valid Loss:  0.006119254510849714
Epoch:  64  	Training Loss: 0.007803240790963173
Test Loss:  0.005524647422134876
Valid Loss:  0.0060030873864889145
Epoch:  65  	Training Loss: 0.007699682377278805
Test Loss:  0.005425984039902687
Valid Loss:  0.00589112751185894
Epoch:  66  	Training Loss: 0.007598430849611759
Test Loss:  0.005331621039658785
Valid Loss:  0.0057831257581710815
Epoch:  67  	Training Loss: 0.007499389350414276
Test Loss:  0.005241227801889181
Valid Loss:  0.005678821820765734
Epoch:  68  	Training Loss: 0.007402455434203148
Test Loss:  0.00515452865511179
Valid Loss:  0.005578001029789448
Epoch:  69  	Training Loss: 0.007307557389140129
Test Loss:  0.005071274936199188
Valid Loss:  0.005480465013533831
Epoch:  70  	Training Loss: 0.0072146193124353886
Test Loss:  0.004991225898265839
Valid Loss:  0.005386030301451683
Epoch:  71  	Training Loss: 0.007123580202460289
Test Loss:  0.004914198070764542
Valid Loss:  0.005294532980769873
Epoch:  72  	Training Loss: 0.007034368813037872
Test Loss:  0.004840070381760597
 14%|█▍        | 72/500 [00:55<08:32,  1.20s/it] 15%|█▍        | 74/500 [00:55<06:05,  1.16it/s] 15%|█▌        | 76/500 [00:55<04:23,  1.61it/s] 16%|█▌        | 78/500 [00:55<03:12,  2.19it/s] 16%|█▌        | 80/500 [00:55<02:22,  2.94it/s] 16%|█▋        | 82/500 [01:02<08:38,  1.24s/it] 17%|█▋        | 84/500 [01:02<06:09,  1.12it/s] 17%|█▋        | 86/500 [01:02<04:25,  1.56it/s] 18%|█▊        | 88/500 [01:03<03:13,  2.13it/s] 18%|█▊        | 90/500 [01:03<02:22,  2.88it/s] 18%|█▊        | 92/500 [01:09<08:09,  1.20s/it] 19%|█▉        | 94/500 [01:09<05:48,  1.16it/s] 19%|█▉        | 96/500 [01:09<04:10,  1.61it/s] 20%|█▉        | 98/500 [01:09<03:03,  2.19it/s] 20%|██        | 100/500 [01:10<02:16,  2.94it/s] 20%|██        | 102/500 [01:16<07:57,  1.20s/it] 21%|██        | 104/500 [01:16<05:41,  1.16it/s] 21%|██        | 106/500 [01:16<04:05,  1.60it/s] 22%|██▏       | 108/500 [01:16<02:58,  2.19it/s] 22%|██▏       | 110/500 [01:17<02:12,  2.95it/s] 22%|██▏       | 112/500 [01:23<07:42,  1.19s/it] 23%|██▎       | 114/500 [01:23<05:32,  1.16it/s] 23%|██▎       | 116/500 [01:23<03:59,  1.60it/s] 24%|██▎       | 118/500 [01:23<02:54,  2.19it/s] 24%|██▍       | 120/500 [01:23<02:09,  2.94it/s] 24%|██▍       | 122/500 [01:30<07:31,  1.19s/it] 25%|██▍       | 124/500 [01:30<05:22,  1.17it/s] 25%|██▌       | 126/500 [01:30<03:51,  1.61it/s] 26%|██▌       | 128/500 [01:30<02:48,  2.21it/s] 26%|██▌       | 130/500 [01:30<02:05,  2.96it/s] 26%|██▋       | 132/500 [01:37<07:21,  1.20s/it] 27%|██▋       | 134/500 [01:37<05:16,  1.16it/s] 27%|██▋       | 136/500 [01:37<03:50,  1.58it/s] 28%|██▊       | 138/500 [01:37<02:49,  2.14it/s] 28%|██▊       | 140/500 [01:37<02:04,  2.88it/s]Valid Loss:  0.005205920897424221
Epoch:  73  	Training Loss: 0.006947013083845377
Test Loss:  0.004768566694110632
Valid Loss:  0.0051199463196098804
Epoch:  74  	Training Loss: 0.0068613821640610695
Test Loss:  0.004699556156992912
Valid Loss:  0.005036497488617897
Epoch:  75  	Training Loss: 0.006777423433959484
Test Loss:  0.004632886499166489
Valid Loss:  0.0049554528668522835
Epoch:  76  	Training Loss: 0.006695101503282785
Test Loss:  0.004568420350551605
Valid Loss:  0.004876716062426567
Epoch:  77  	Training Loss: 0.006614371668547392
Test Loss:  0.004506038501858711
Valid Loss:  0.0048001715913414955
Epoch:  78  	Training Loss: 0.006535191088914871
Test Loss:  0.004445635713636875
Valid Loss:  0.0047257449477910995
Epoch:  79  	Training Loss: 0.006457529496401548
Test Loss:  0.0043870992958545685
Valid Loss:  0.00465334253385663
Epoch:  80  	Training Loss: 0.006381351966410875
Test Loss:  0.004330345429480076
Valid Loss:  0.004582897759974003
Epoch:  81  	Training Loss: 0.006306622177362442
Test Loss:  0.004275284707546234
Valid Loss:  0.004514317959547043
Epoch:  82  	Training Loss: 0.006233304738998413
Test Loss:  0.004221364855766296
Valid Loss:  0.004447347018867731
Epoch:  83  	Training Loss: 0.006161404773592949
Test Loss:  0.004169042222201824
Valid Loss:  0.004382145591080189
Epoch:  84  	Training Loss: 0.006090864073485136
Test Loss:  0.004118232987821102
Valid Loss:  0.004318661522120237
Epoch:  85  	Training Loss: 0.006021654233336449
Test Loss:  0.0040688710287213326
Valid Loss:  0.004256829619407654
Epoch:  86  	Training Loss: 0.005953748244792223
Test Loss:  0.004020890686661005
Valid Loss:  0.004196596331894398
Epoch:  87  	Training Loss: 0.00588712003082037
Test Loss:  0.003974234685301781
Valid Loss:  0.004137900657951832
Epoch:  88  	Training Loss: 0.0058217435143888
Test Loss:  0.003928845748305321
Valid Loss:  0.004080708604305983
Epoch:  89  	Training Loss: 0.005757591221481562
Test Loss:  0.0038846789393574
Valid Loss:  0.004024963825941086
Epoch:  90  	Training Loss: 0.005694644059985876
Test Loss:  0.003841674653813243
Valid Loss:  0.003970623016357422
Epoch:  91  	Training Loss: 0.005632875021547079
Test Loss:  0.0037998028565198183
Valid Loss:  0.003917647525668144
Epoch:  92  	Training Loss: 0.005572262220084667
Test Loss:  0.003759948071092367
Valid Loss:  0.0038663814775645733
Epoch:  93  	Training Loss: 0.0055127693340182304
Test Loss:  0.003721036482602358
Valid Loss:  0.0038163482677191496
Epoch:  94  	Training Loss: 0.005454385653138161
Test Loss:  0.0036830450408160686
Valid Loss:  0.0037675276398658752
Epoch:  95  	Training Loss: 0.005397097207605839
Test Loss:  0.00364594254642725
Valid Loss:  0.003719886764883995
Epoch:  96  	Training Loss: 0.005340881645679474
Test Loss:  0.0036097061820328236
Valid Loss:  0.003673393977805972
Epoch:  97  	Training Loss: 0.005285713821649551
Test Loss:  0.0035743089392781258
Valid Loss:  0.003628028091043234
Epoch:  98  	Training Loss: 0.005231574643403292
Test Loss:  0.003539725672453642
Valid Loss:  0.003583755809813738
Epoch:  99  	Training Loss: 0.005178452935069799
Test Loss:  0.0035059466026723385
Valid Loss:  0.0035405580420047045
Epoch:  100  	Training Loss: 0.005126318894326687
Test Loss:  0.003472939133644104
Valid Loss:  0.0034984080120921135
Epoch:  101  	Training Loss: 0.005075161345303059
Test Loss:  0.0034406837075948715
Valid Loss:  0.003457277547568083
Epoch:  102  	Training Loss: 0.005024958401918411
Test Loss:  0.0034089917317032814
Valid Loss:  0.003417043015360832
Epoch:  103  	Training Loss: 0.004975622519850731
Test Loss:  0.0033780387602746487
Valid Loss:  0.003377787536010146
Epoch:  104  	Training Loss: 0.0049272035248577595
Test Loss:  0.003347790101543069
Valid Loss:  0.003339494578540325
Epoch:  105  	Training Loss: 0.004879692569375038
Test Loss:  0.0033182331826537848
Valid Loss:  0.0033021443523466587
Epoch:  106  	Training Loss: 0.004833065904676914
Test Loss:  0.0032893551979213953
Valid Loss:  0.003265701700001955
Epoch:  107  	Training Loss: 0.004787315148860216
Test Loss:  0.003261132398620248
Valid Loss:  0.003230163361877203
Epoch:  108  	Training Loss: 0.004742415621876717
Test Loss:  0.0032335584983229637
Valid Loss:  0.0031954955775290728
Epoch:  109  	Training Loss: 0.004698357544839382
Test Loss:  0.003206605324521661
Valid Loss:  0.0031616934575140476
Epoch:  110  	Training Loss: 0.0046551222912967205
Test Loss:  0.0031802633311599493
Valid Loss:  0.003128722310066223
Epoch:  111  	Training Loss: 0.004612691700458527
Test Loss:  0.0031545236706733704
Valid Loss:  0.003096571657806635
Epoch:  112  	Training Loss: 0.004571056924760342
Test Loss:  0.003128942335024476
Valid Loss:  0.003065073862671852
Epoch:  113  	Training Loss: 0.004530180245637894
Test Loss:  0.003103972878307104
Valid Loss:  0.00303438026458025
Epoch:  114  	Training Loss: 0.004490070976316929
Test Loss:  0.0030796006321907043
Valid Loss:  0.0030044675804674625
Epoch:  115  	Training Loss: 0.004450709093362093
Test Loss:  0.003055806737393141
Valid Loss:  0.0029753129929304123
Epoch:  116  	Training Loss: 0.004412080626934767
Test Loss:  0.0030325697734951973
Valid Loss:  0.0029469039291143417
Epoch:  117  	Training Loss: 0.004374169744551182
Test Loss:  0.003009883454069495
Valid Loss:  0.002919222693890333
Epoch:  118  	Training Loss: 0.004336973186582327
Test Loss:  0.002987719839438796
Valid Loss:  0.002892248798161745
Epoch:  119  	Training Loss: 0.004300468601286411
Test Loss:  0.0029660859145224094
Valid Loss:  0.00286596966907382
Epoch:  120  	Training Loss: 0.004264644347131252
Test Loss:  0.002944950945675373
Valid Loss:  0.0028403750620782375
Epoch:  121  	Training Loss: 0.0042294906452298164
Test Loss:  0.0029243084136396646
Valid Loss:  0.0028154312167316675
Epoch:  122  	Training Loss: 0.004194990731775761
Test Loss:  0.002904578810557723
Valid Loss:  0.0027912617661058903
Epoch:  123  	Training Loss: 0.00416113855317235
Test Loss:  0.002885279478505254
Valid Loss:  0.002767710480839014
Epoch:  124  	Training Loss: 0.0041279178112745285
Test Loss:  0.002866398310288787
Valid Loss:  0.002744763158261776
Epoch:  125  	Training Loss: 0.004095318727195263
Test Loss:  0.0028479252941906452
Valid Loss:  0.002722407691180706
Epoch:  126  	Training Loss: 0.004063329193741083
Test Loss:  0.0028298604302108288
Valid Loss:  0.002700630109757185
Epoch:  127  	Training Loss: 0.0040319375693798065
Test Loss:  0.002812192076817155
Valid Loss:  0.0026794238947331905
Epoch:  128  	Training Loss: 0.004001130815595388
Test Loss:  0.0027949130162596703
Valid Loss:  0.00265877740457654
Epoch:  129  	Training Loss: 0.003970899153500795
Test Loss:  0.002778007183223963
Valid Loss:  0.002638666657730937
Epoch:  130  	Training Loss: 0.003941231872886419
Test Loss:  0.0027614871505647898
Valid Loss:  0.0026190942153334618
Epoch:  131  	Training Loss: 0.003912119194865227
Test Loss:  0.0027453338261693716
Valid Loss:  0.002600045409053564
Epoch:  132  	Training Loss: 0.003883552271872759
Test Loss:  0.002729203552007675
Valid Loss:  0.0025814271066337824
Epoch:  133  	Training Loss: 0.0038555231876671314
Test Loss:  0.0027134553529322147
Valid Loss:  0.0025633233599364758
Epoch:  134  	Training Loss: 0.003828018205240369
Test Loss:  0.0026980889961123466
Valid Loss:  0.0025457204319536686
Epoch:  135  	Training Loss: 0.0038010277785360813
Test Loss:  0.002683090977370739
Valid Loss:  0.002528600860387087
Epoch:  136  	Training Loss: 0.00377454049885273
Test Loss:  0.0026684566400945187
Valid Loss:  0.002511959057301283
Epoch:  137  	Training Loss: 0.003748546354472637
Test Loss:  0.00265416968613863
Valid Loss:  0.0024957824498414993
Epoch:  138  	Training Loss: 0.0037230392917990685
Test Loss:  0.002640228718519211
Valid Loss:  0.0024800614919513464
Epoch:  139  	Training Loss: 0.00369800953194499
Test Loss:  0.0026266195345669985
Valid Loss:  0.002464784774929285
Epoch:  140  	Training Loss: 0.0036734440363943577
Test Loss:  0.002613336779177189
Valid Loss:  0.002449943218380213
Epoch:  141  	Training Loss: 0.003649338148534298
Test Loss:  0.0026003732345998287
Valid Loss:  0.002435521688312292
Epoch:  142  	Training Loss: 0.0036256839521229267
 28%|██▊       | 142/500 [01:44<07:11,  1.21s/it] 29%|██▉       | 144/500 [01:44<05:09,  1.15it/s] 29%|██▉       | 146/500 [01:44<03:44,  1.58it/s] 30%|██▉       | 148/500 [01:44<02:45,  2.13it/s] 30%|███       | 150/500 [01:45<02:01,  2.87it/s] 30%|███       | 152/500 [01:51<07:06,  1.23s/it] 31%|███       | 154/500 [01:51<05:03,  1.14it/s] 31%|███       | 156/500 [01:51<03:38,  1.57it/s] 32%|███▏      | 158/500 [01:51<02:39,  2.14it/s] 32%|███▏      | 160/500 [01:52<01:58,  2.86it/s] 32%|███▏      | 162/500 [01:58<06:44,  1.20s/it] 33%|███▎      | 164/500 [01:58<04:48,  1.16it/s] 33%|███▎      | 166/500 [01:58<03:29,  1.60it/s] 34%|███▎      | 168/500 [01:58<02:34,  2.15it/s] 34%|███▍      | 170/500 [01:59<01:55,  2.86it/s] 34%|███▍      | 172/500 [02:05<06:42,  1.23s/it] 35%|███▍      | 174/500 [02:05<04:48,  1.13it/s] 35%|███▌      | 176/500 [02:05<03:26,  1.57it/s] 36%|███▌      | 178/500 [02:06<02:30,  2.14it/s] 36%|███▌      | 180/500 [02:06<01:51,  2.87it/s] 36%|███▋      | 182/500 [02:12<06:32,  1.23s/it] 37%|███▋      | 184/500 [02:12<04:39,  1.13it/s] 37%|███▋      | 186/500 [02:13<03:21,  1.56it/s] 38%|███▊      | 188/500 [02:13<02:26,  2.13it/s] 38%|███▊      | 190/500 [02:13<01:48,  2.87it/s] 38%|███▊      | 192/500 [02:19<06:03,  1.18s/it] 39%|███▉      | 194/500 [02:19<04:19,  1.18it/s] 39%|███▉      | 196/500 [02:19<03:06,  1.63it/s] 40%|███▉      | 198/500 [02:20<02:15,  2.23it/s] 40%|████      | 200/500 [02:20<01:40,  3.00it/s] 40%|████      | 202/500 [02:26<05:58,  1.20s/it] 41%|████      | 204/500 [02:26<04:14,  1.16it/s] 41%|████      | 206/500 [02:26<03:03,  1.61it/s] 42%|████▏     | 208/500 [02:27<02:13,  2.19it/s] 42%|████▏     | 210/500 [02:27<01:38,  2.94it/s]Test Loss:  0.0025879661552608013
Valid Loss:  0.002421582117676735
Epoch:  143  	Training Loss: 0.0036024986766278744
Test Loss:  0.0025758538395166397
Valid Loss:  0.0024080423172563314
Epoch:  144  	Training Loss: 0.0035797497257590294
Test Loss:  0.002564006019383669
Valid Loss:  0.0023948894813656807
Epoch:  145  	Training Loss: 0.003557425457984209
Test Loss:  0.002552430611103773
Valid Loss:  0.0023821191862225533
Epoch:  146  	Training Loss: 0.003535517491400242
Test Loss:  0.0025411206297576427
Valid Loss:  0.0023697263095527887
Epoch:  147  	Training Loss: 0.003514019073918462
Test Loss:  0.002530067227780819
Valid Loss:  0.0023576891981065273
Epoch:  148  	Training Loss: 0.0034929190296679735
Test Loss:  0.0025192738976329565
Valid Loss:  0.002346016000956297
Epoch:  149  	Training Loss: 0.003472215961664915
Test Loss:  0.002508732723072171
Valid Loss:  0.002334692981094122
Epoch:  150  	Training Loss: 0.0034518996253609657
Test Loss:  0.0024984367191791534
Valid Loss:  0.002323712455108762
Epoch:  151  	Training Loss: 0.0034319597762078047
Test Loss:  0.0024883830919861794
Valid Loss:  0.002313067205250263
Epoch:  152  	Training Loss: 0.0034123945515602827
Test Loss:  0.00247835461050272
Valid Loss:  0.0023027120623737574
Epoch:  153  	Training Loss: 0.0033931825309991837
Test Loss:  0.002468574559316039
Valid Loss:  0.0022926838137209415
Epoch:  154  	Training Loss: 0.003374328836798668
Test Loss:  0.002459038980305195
Valid Loss:  0.0022829691879451275
Epoch:  155  	Training Loss: 0.0033558281138539314
Test Loss:  0.00244974996894598
Valid Loss:  0.0022735679522156715
Epoch:  156  	Training Loss: 0.003337673144415021
Test Loss:  0.002440693788230419
Valid Loss:  0.0022644726559519768
Epoch:  157  	Training Loss: 0.003319855546578765
Test Loss:  0.002431867877021432
Valid Loss:  0.002255663275718689
Epoch:  158  	Training Loss: 0.0033023725263774395
Test Loss:  0.0024232622236013412
Valid Loss:  0.0022471467964351177
Epoch:  159  	Training Loss: 0.0032852133736014366
Test Loss:  0.0024148719385266304
Valid Loss:  0.002238914603367448
Epoch:  160  	Training Loss: 0.0032683778554201126
Test Loss:  0.002406700048595667
Valid Loss:  0.0022309529595077038
Epoch:  161  	Training Loss: 0.003251852933317423
Test Loss:  0.002398730255663395
Valid Loss:  0.002223264891654253
Epoch:  162  	Training Loss: 0.0032356386072933674
Test Loss:  0.002391099464148283
Valid Loss:  0.0022158403880894184
Epoch:  163  	Training Loss: 0.0032197008840739727
Test Loss:  0.002383660525083542
Valid Loss:  0.0022086743265390396
Epoch:  164  	Training Loss: 0.003204063978046179
Test Loss:  0.0023763994686305523
Valid Loss:  0.002201756229624152
Epoch:  165  	Training Loss: 0.003188719507306814
Test Loss:  0.002369313733652234
Valid Loss:  0.002195078181102872
Epoch:  166  	Training Loss: 0.003173660021275282
Test Loss:  0.0023624044843018055
Valid Loss:  0.002188638783991337
Epoch:  167  	Training Loss: 0.0031588857527822256
Test Loss:  0.002355670789256692
Valid Loss:  0.0021824301220476627
Epoch:  168  	Training Loss: 0.0031443811021745205
Test Loss:  0.0023490972816944122
Valid Loss:  0.0021764514967799187
Epoch:  169  	Training Loss: 0.0031301521230489016
Test Loss:  0.0023426918778568506
Valid Loss:  0.0021706935949623585
Epoch:  170  	Training Loss: 0.0031161881051957607
Test Loss:  0.0023364489898085594
Valid Loss:  0.0021651536226272583
Epoch:  171  	Training Loss: 0.0031024848576635122
Test Loss:  0.0023303618654608727
Valid Loss:  0.0021598234307020903
Epoch:  172  	Training Loss: 0.0030890346970409155
Test Loss:  0.002324431436136365
Valid Loss:  0.0021546995267271996
Epoch:  173  	Training Loss: 0.003075839951634407
Test Loss:  0.0023186535108834505
Valid Loss:  0.002149776788428426
Epoch:  174  	Training Loss: 0.0030628894455730915
Test Loss:  0.0023130220361053944
Valid Loss:  0.0021450559142977
Epoch:  175  	Training Loss: 0.0030501815490424633
Test Loss:  0.002307533985003829
Valid Loss:  0.0021405238658189774
Epoch:  176  	Training Loss: 0.0030377097427845
Test Loss:  0.0023021979723125696
Valid Loss:  0.0021361801773309708
Epoch:  177  	Training Loss: 0.0030254703015089035
Test Loss:  0.0022969981655478477
Valid Loss:  0.0021320218220353127
Epoch:  178  	Training Loss: 0.0030134618282318115
Test Loss:  0.002291940152645111
Valid Loss:  0.002128039486706257
Epoch:  179  	Training Loss: 0.0030016747768968344
Test Loss:  0.0022870153188705444
Valid Loss:  0.002124234102666378
Epoch:  180  	Training Loss: 0.002990110544487834
Test Loss:  0.0022822199389338493
Valid Loss:  0.002120597753673792
Epoch:  181  	Training Loss: 0.002978759817779064
Test Loss:  0.002277554012835026
Valid Loss:  0.0021171304397284985
Epoch:  182  	Training Loss: 0.0029676235280930996
Test Loss:  0.002273101359605789
Valid Loss:  0.00211382657289505
Epoch:  183  	Training Loss: 0.002956686308607459
Test Loss:  0.0022687609307467937
Valid Loss:  0.002110677072778344
Epoch:  184  	Training Loss: 0.0029459544457495213
Test Loss:  0.0022645359858870506
Valid Loss:  0.0021073902025818825
Epoch:  185  	Training Loss: 0.0029353732243180275
Test Loss:  0.0022601354867219925
Valid Loss:  0.0021041748113930225
Epoch:  186  	Training Loss: 0.0029248688369989395
Test Loss:  0.0022558681666851044
Valid Loss:  0.0021010665223002434
Epoch:  187  	Training Loss: 0.0029145334847271442
Test Loss:  0.002251452999189496
Valid Loss:  0.002097293734550476
Epoch:  188  	Training Loss: 0.0029042414389550686
Test Loss:  0.0022471854463219643
Valid Loss:  0.0020934350322932005
Epoch:  189  	Training Loss: 0.002894141711294651
Test Loss:  0.0022430543322116137
Valid Loss:  0.0020897192880511284
Epoch:  190  	Training Loss: 0.002884153975173831
Test Loss:  0.0022386801429092884
Valid Loss:  0.002086062217131257
Epoch:  191  	Training Loss: 0.0028742500580847263
Test Loss:  0.0022342209704220295
Valid Loss:  0.0020825485698878765
Epoch:  192  	Training Loss: 0.0028644441626966
Test Loss:  0.0022298097610473633
Valid Loss:  0.002079127123579383
Epoch:  193  	Training Loss: 0.002854759804904461
Test Loss:  0.0022252853959798813
Valid Loss:  0.002075765747576952
Epoch:  194  	Training Loss: 0.0028450540266931057
Test Loss:  0.002220665104687214
Valid Loss:  0.002072468865662813
Epoch:  195  	Training Loss: 0.002835374791175127
Test Loss:  0.002215953078120947
Valid Loss:  0.0020692371763288975
Epoch:  196  	Training Loss: 0.0028256657533347607
Test Loss:  0.002211175626143813
Valid Loss:  0.002066070679575205
Epoch:  197  	Training Loss: 0.0028159699868410826
Test Loss:  0.0022065595258027315
Valid Loss:  0.002063036896288395
Epoch:  198  	Training Loss: 0.002806394826620817
Test Loss:  0.0022015287540853024
Valid Loss:  0.002060068305581808
Epoch:  199  	Training Loss: 0.0027968059293925762
Test Loss:  0.0021964292973279953
Valid Loss:  0.0020569164771586657
Epoch:  200  	Training Loss: 0.002787233330309391
Test Loss:  0.0021915086545050144
Valid Loss:  0.0020537707023322582
Epoch:  201  	Training Loss: 0.002777817891910672
Test Loss:  0.002186758443713188
Valid Loss:  0.0020507448352873325
Epoch:  202  	Training Loss: 0.0027685605455189943
Test Loss:  0.0021839262917637825
Valid Loss:  0.002048250287771225
Epoch:  203  	Training Loss: 0.002760442206636071
Test Loss:  0.002181116957217455
Valid Loss:  0.0020455894991755486
Epoch:  204  	Training Loss: 0.002752447035163641
Test Loss:  0.0021783264819532633
Valid Loss:  0.002043001353740692
Epoch:  205  	Training Loss: 0.0027445710729807615
Test Loss:  0.0021755658090114594
Valid Loss:  0.0020404886454343796
Epoch:  206  	Training Loss: 0.00273681478574872
Test Loss:  0.0021727976854890585
Valid Loss:  0.0020380625501275063
Epoch:  207  	Training Loss: 0.0027291756123304367
Test Loss:  0.0021695245523005724
Valid Loss:  0.0020357125904411077
Epoch:  208  	Training Loss: 0.0027216491289436817
Test Loss:  0.0021660909987986088
Valid Loss:  0.0020334466826170683
Epoch:  209  	Training Loss: 0.0027142358012497425
Test Loss:  0.0021626888774335384
Valid Loss:  0.0020312548149377108
Epoch:  210  	Training Loss: 0.0027069048956036568
Test Loss:  0.002158941701054573
Valid Loss:  0.0020290391985327005
Epoch:  211  	Training Loss: 0.002699440810829401
 42%|████▏     | 212/500 [02:33<05:41,  1.19s/it] 43%|████▎     | 214/500 [02:33<04:03,  1.18it/s] 43%|████▎     | 216/500 [02:33<02:54,  1.62it/s] 44%|████▎     | 218/500 [02:33<02:07,  2.21it/s] 44%|████▍     | 220/500 [02:34<01:35,  2.92it/s] 44%|████▍     | 222/500 [02:40<05:37,  1.21s/it] 45%|████▍     | 224/500 [02:40<04:01,  1.14it/s] 45%|████▌     | 226/500 [02:40<02:52,  1.59it/s] 46%|████▌     | 228/500 [02:40<02:05,  2.17it/s] 46%|████▌     | 230/500 [02:41<01:32,  2.92it/s] 46%|████▋     | 232/500 [02:47<05:25,  1.21s/it] 47%|████▋     | 234/500 [02:47<03:51,  1.15it/s] 47%|████▋     | 236/500 [02:47<02:46,  1.59it/s] 48%|████▊     | 238/500 [02:48<02:00,  2.18it/s] 48%|████▊     | 240/500 [02:48<01:28,  2.93it/s] 48%|████▊     | 242/500 [02:54<05:06,  1.19s/it] 49%|████▉     | 244/500 [02:54<03:37,  1.18it/s] 49%|████▉     | 246/500 [02:54<02:36,  1.63it/s] 50%|████▉     | 248/500 [02:54<01:53,  2.22it/s] 50%|█████     | 250/500 [02:55<01:23,  2.98it/s] 50%|█████     | 252/500 [03:01<04:53,  1.18s/it] 51%|█████     | 254/500 [03:01<03:29,  1.18it/s] 51%|█████     | 256/500 [03:01<02:30,  1.62it/s] 52%|█████▏    | 258/500 [03:01<01:49,  2.22it/s] 52%|█████▏    | 260/500 [03:01<01:20,  2.98it/s] 52%|█████▏    | 262/500 [03:08<04:47,  1.21s/it] 53%|█████▎    | 264/500 [03:08<03:25,  1.15it/s] 53%|█████▎    | 266/500 [03:08<02:27,  1.58it/s] 54%|█████▎    | 268/500 [03:08<01:47,  2.17it/s] 54%|█████▍    | 270/500 [03:08<01:18,  2.92it/s] 54%|█████▍    | 272/500 [03:15<04:30,  1.19s/it] 55%|█████▍    | 274/500 [03:15<03:12,  1.17it/s] 55%|█████▌    | 276/500 [03:15<02:17,  1.62it/s] 56%|█████▌    | 278/500 [03:15<01:40,  2.22it/s]Test Loss:  0.002155061811208725
Valid Loss:  0.0020268510561436415
Epoch:  212  	Training Loss: 0.002691914327442646
Test Loss:  0.002151658060029149
Valid Loss:  0.002024993998929858
Epoch:  213  	Training Loss: 0.002685053274035454
Test Loss:  0.002148302737623453
Valid Loss:  0.0020231446251273155
Epoch:  214  	Training Loss: 0.0026782811619341373
Test Loss:  0.00214500748552382
Valid Loss:  0.00202135369181633
Epoch:  215  	Training Loss: 0.002671534661203623
Test Loss:  0.002141490112990141
Valid Loss:  0.002019551582634449
Epoch:  216  	Training Loss: 0.002664736472070217
Test Loss:  0.002138040494173765
Valid Loss:  0.0020178034901618958
Epoch:  217  	Training Loss: 0.002658020704984665
Test Loss:  0.0021346500143408775
Valid Loss:  0.0020161131396889687
Epoch:  218  	Training Loss: 0.0026513610500842333
Test Loss:  0.0021311850287020206
Valid Loss:  0.0020144463051110506
Epoch:  219  	Training Loss: 0.0026447155978530645
Test Loss:  0.0021277882624417543
Valid Loss:  0.002012836281210184
Epoch:  220  	Training Loss: 0.0026381199713796377
Test Loss:  0.002124328864738345
Valid Loss:  0.002011168748140335
Epoch:  221  	Training Loss: 0.002631537616252899
Test Loss:  0.002120929304510355
Valid Loss:  0.0020094290375709534
Epoch:  222  	Training Loss: 0.0026250313967466354
Test Loss:  0.0021178130991756916
Valid Loss:  0.002007867209613323
Epoch:  223  	Training Loss: 0.0026186550967395306
Test Loss:  0.002114635892212391
Valid Loss:  0.0020063233096152544
Epoch:  224  	Training Loss: 0.0026123011484742165
Test Loss:  0.0021113953553140163
Valid Loss:  0.0020048129372298717
Epoch:  225  	Training Loss: 0.002606022171676159
Test Loss:  0.002108137123286724
Valid Loss:  0.0020031884778290987
Epoch:  226  	Training Loss: 0.002599818166345358
Test Loss:  0.002104939892888069
Valid Loss:  0.002001457381993532
Epoch:  227  	Training Loss: 0.0025936788879334927
Test Loss:  0.0021016739774495363
Valid Loss:  0.001999706495553255
Epoch:  228  	Training Loss: 0.002587534487247467
Test Loss:  0.0020984718576073647
Valid Loss:  0.0019979949574917555
Epoch:  229  	Training Loss: 0.002581444103270769
Test Loss:  0.002095205709338188
Valid Loss:  0.0019962957594543695
Epoch:  230  	Training Loss: 0.0025753527879714966
Test Loss:  0.0020919996313750744
Valid Loss:  0.0019946361426264048
Epoch:  231  	Training Loss: 0.002569332718849182
Test Loss:  0.0020888359285891056
Valid Loss:  0.0019930184353142977
Epoch:  232  	Training Loss: 0.002563379006460309
Test Loss:  0.002085716463625431
Valid Loss:  0.0019915003795176744
Epoch:  233  	Training Loss: 0.002557518659159541
Test Loss:  0.0020825122483074665
Valid Loss:  0.001990026328712702
Epoch:  234  	Training Loss: 0.0025517239701002836
Test Loss:  0.002079359022900462
Valid Loss:  0.001988585339859128
Epoch:  235  	Training Loss: 0.0025459961034357548
Test Loss:  0.002076254226267338
Valid Loss:  0.0019871853291988373
Epoch:  236  	Training Loss: 0.0025403317995369434
Test Loss:  0.002073192736133933
Valid Loss:  0.001985820708796382
Epoch:  237  	Training Loss: 0.0025347350165247917
Test Loss:  0.0020701794419437647
Valid Loss:  0.001984492177143693
Epoch:  238  	Training Loss: 0.00252919876947999
Test Loss:  0.0020672068931162357
Valid Loss:  0.001983199268579483
Epoch:  239  	Training Loss: 0.0025237277150154114
Test Loss:  0.0020642783492803574
Valid Loss:  0.0019819410517811775
Epoch:  240  	Training Loss: 0.002518315799534321
Test Loss:  0.002061388688161969
Valid Loss:  0.001980715896934271
Epoch:  241  	Training Loss: 0.002512965817004442
Test Loss:  0.0020585423335433006
Valid Loss:  0.0019794644322246313
Epoch:  242  	Training Loss: 0.002507675439119339
Test Loss:  0.002055702032521367
Valid Loss:  0.0019782185554504395
Epoch:  243  	Training Loss: 0.0025024577043950558
Test Loss:  0.0020528235472738743
Valid Loss:  0.0019769698847085238
Epoch:  244  	Training Loss: 0.0024972273968160152
Test Loss:  0.002049991860985756
Valid Loss:  0.0019757563713937998
Epoch:  245  	Training Loss: 0.0024920448195189238
Test Loss:  0.0020471145398914814
Valid Loss:  0.001974535873159766
Epoch:  246  	Training Loss: 0.0024868594482541084
Test Loss:  0.0020442886743694544
Valid Loss:  0.0019733477383852005
Epoch:  247  	Training Loss: 0.0024817297235131264
Test Loss:  0.0020414991304278374
Valid Loss:  0.001972186379134655
Epoch:  248  	Training Loss: 0.0024766535498201847
Test Loss:  0.002038753591477871
Valid Loss:  0.001971050165593624
Epoch:  249  	Training Loss: 0.0024716320913285017
Test Loss:  0.0020360462367534637
Valid Loss:  0.001969943754374981
Epoch:  250  	Training Loss: 0.0024666660465300083
Test Loss:  0.002033376134932041
Valid Loss:  0.0019688629545271397
Epoch:  251  	Training Loss: 0.0024617519229650497
Test Loss:  0.0020307437516748905
Valid Loss:  0.0019678021781146526
Epoch:  252  	Training Loss: 0.0024568878579884768
Test Loss:  0.002028282266110182
Valid Loss:  0.0019667563028633595
Epoch:  253  	Training Loss: 0.0024520880542695522
Test Loss:  0.0020257739815860987
Valid Loss:  0.001965711358934641
Epoch:  254  	Training Loss: 0.0024472789373248816
Test Loss:  0.002023292239755392
Valid Loss:  0.0019646906293928623
Epoch:  255  	Training Loss: 0.0024425177834928036
Test Loss:  0.0020208244677633047
Valid Loss:  0.0019636962097138166
Epoch:  256  	Training Loss: 0.0024378057569265366
Test Loss:  0.0020182684529572725
Valid Loss:  0.001962718553841114
Epoch:  257  	Training Loss: 0.002433128422126174
Test Loss:  0.002015678444877267
Valid Loss:  0.0019617455545812845
Epoch:  258  	Training Loss: 0.0024284529499709606
Test Loss:  0.0020131070632487535
Valid Loss:  0.001960735535249114
Epoch:  259  	Training Loss: 0.0024238238111138344
Test Loss:  0.002010564785450697
Valid Loss:  0.0019596933852881193
Epoch:  260  	Training Loss: 0.002419239841401577
Test Loss:  0.002008042996749282
Valid Loss:  0.0019586056005209684
Epoch:  261  	Training Loss: 0.002414691261947155
Test Loss:  0.0020054844208061695
Valid Loss:  0.0019574672915041447
Epoch:  262  	Training Loss: 0.0024101147428154945
Test Loss:  0.002002808265388012
Valid Loss:  0.0019563508685678244
Epoch:  263  	Training Loss: 0.0024055277463048697
Test Loss:  0.0020001018419861794
Valid Loss:  0.0019552274607121944
Epoch:  264  	Training Loss: 0.0024009556509554386
Test Loss:  0.0019974280148744583
Valid Loss:  0.0019541222136467695
Epoch:  265  	Training Loss: 0.002396422903984785
Test Loss:  0.001994780031964183
Valid Loss:  0.0019529818091541529
Epoch:  266  	Training Loss: 0.0023919320665299892
Test Loss:  0.0019921662751585245
Valid Loss:  0.001951801124960184
Epoch:  267  	Training Loss: 0.0023874808102846146
Test Loss:  0.001989583019167185
Valid Loss:  0.0019506348762661219
Epoch:  268  	Training Loss: 0.002383054932579398
Test Loss:  0.0019869732204824686
Valid Loss:  0.0019494021544232965
Epoch:  269  	Training Loss: 0.00237862765789032
Test Loss:  0.00198433268815279
Valid Loss:  0.001948120421729982
Epoch:  270  	Training Loss: 0.0023741815239191055
Test Loss:  0.0019816644489765167
Valid Loss:  0.0019468239042907953
Epoch:  271  	Training Loss: 0.002369734225794673
Test Loss:  0.001979026710614562
Valid Loss:  0.0019453836139291525
Epoch:  272  	Training Loss: 0.0023653232492506504
Test Loss:  0.0019763512536883354
Valid Loss:  0.0019438947783783078
Epoch:  273  	Training Loss: 0.0023609097115695477
Test Loss:  0.0019737021066248417
Valid Loss:  0.0019424175843596458
Epoch:  274  	Training Loss: 0.0023565294686704874
Test Loss:  0.001971079967916012
Valid Loss:  0.0019409498199820518
Epoch:  275  	Training Loss: 0.002352186944335699
Test Loss:  0.0019684908911585808
Valid Loss:  0.0019394892733544111
Epoch:  276  	Training Loss: 0.00234788004308939
Test Loss:  0.001965923700481653
Valid Loss:  0.0019380392041057348
Epoch:  277  	Training Loss: 0.002343606436625123
Test Loss:  0.0019633849151432514
Valid Loss:  0.0019366027554497123
Epoch:  278  	Training Loss: 0.002339343074709177
Test Loss:  0.0019607762806117535
Valid Loss:  0.0019351295195519924
Epoch:  279  	Training Loss: 0.0023350503761321306
Test Loss:  0.001958190929144621
Valid Loss:  0.0019336059922352433
Epoch:  280  	Training Loss: 0.0023307898081839085
 56%|█████▌    | 280/500 [03:15<01:13,  2.98it/s] 56%|█████▋    | 282/500 [03:22<04:17,  1.18s/it] 57%|█████▋    | 284/500 [03:22<03:03,  1.18it/s] 57%|█████▋    | 286/500 [03:22<02:11,  1.63it/s] 58%|█████▊    | 288/500 [03:22<01:35,  2.22it/s] 58%|█████▊    | 290/500 [03:22<01:10,  2.98it/s] 58%|█████▊    | 292/500 [03:29<04:15,  1.23s/it] 59%|█████▉    | 294/500 [03:29<03:01,  1.13it/s] 59%|█████▉    | 296/500 [03:29<02:10,  1.56it/s] 60%|█████▉    | 298/500 [03:29<01:35,  2.12it/s] 60%|██████    | 300/500 [03:29<01:10,  2.86it/s] 60%|██████    | 302/500 [03:36<04:00,  1.22s/it] 61%|██████    | 304/500 [03:36<02:51,  1.14it/s] 61%|██████    | 306/500 [03:36<02:02,  1.58it/s] 62%|██████▏   | 308/500 [03:36<01:28,  2.16it/s] 62%|██████▏   | 310/500 [03:36<01:05,  2.91it/s] 62%|██████▏   | 312/500 [03:43<03:45,  1.20s/it] 63%|██████▎   | 314/500 [03:43<02:40,  1.16it/s] 63%|██████▎   | 316/500 [03:43<01:54,  1.61it/s] 64%|██████▎   | 318/500 [03:43<01:22,  2.20it/s] 64%|██████▍   | 320/500 [03:43<01:00,  2.95it/s] 64%|██████▍   | 322/500 [03:50<03:34,  1.20s/it] 65%|██████▍   | 324/500 [03:50<02:31,  1.16it/s] 65%|██████▌   | 326/500 [03:50<01:48,  1.60it/s] 66%|██████▌   | 328/500 [03:50<01:18,  2.19it/s] 66%|██████▌   | 330/500 [03:50<00:57,  2.94it/s] 66%|██████▋   | 332/500 [03:57<03:24,  1.22s/it] 67%|██████▋   | 334/500 [03:57<02:25,  1.14it/s] 67%|██████▋   | 336/500 [03:57<01:43,  1.58it/s] 68%|██████▊   | 338/500 [03:57<01:14,  2.16it/s] 68%|██████▊   | 340/500 [03:57<00:54,  2.91it/s] 68%|██████▊   | 342/500 [04:04<03:09,  1.20s/it] 69%|██████▉   | 344/500 [04:04<02:13,  1.17it/s] 69%|██████▉   | 346/500 [04:04<01:35,  1.61it/s] 70%|██████▉   | 348/500 [04:04<01:09,  2.20it/s]Test Loss:  0.001955627230927348
Valid Loss:  0.0019320700084790587
Epoch:  281  	Training Loss: 0.0023265634663403034
Test Loss:  0.0019530938006937504
Valid Loss:  0.001930536120198667
Epoch:  282  	Training Loss: 0.0023223443422466516
Test Loss:  0.0019504877272993326
Valid Loss:  0.0019288946641609073
Epoch:  283  	Training Loss: 0.0023180467542260885
Test Loss:  0.001947904471307993
Valid Loss:  0.0019272619392722845
Epoch:  284  	Training Loss: 0.00231377687305212
Test Loss:  0.0019453379791229963
Valid Loss:  0.0019256381783634424
Epoch:  285  	Training Loss: 0.0023095393553376198
Test Loss:  0.0019427505321800709
Valid Loss:  0.0019240013789385557
Epoch:  286  	Training Loss: 0.0023052929900586605
Test Loss:  0.0019401363097131252
Valid Loss:  0.0019223790150135756
Epoch:  287  	Training Loss: 0.0023010745644569397
Test Loss:  0.0019375086994841695
Valid Loss:  0.0019207573495805264
Epoch:  288  	Training Loss: 0.002296887803822756
Test Loss:  0.001934895757585764
Valid Loss:  0.001919143134728074
Epoch:  289  	Training Loss: 0.002292727353051305
Test Loss:  0.001932302606292069
Valid Loss:  0.001917536836117506
Epoch:  290  	Training Loss: 0.002288595773279667
Test Loss:  0.0019297199323773384
Valid Loss:  0.0019159403163939714
Epoch:  291  	Training Loss: 0.0022844842169433832
Test Loss:  0.0019271227065473795
Valid Loss:  0.0019143314566463232
Epoch:  292  	Training Loss: 0.0022803673055022955
Test Loss:  0.0019242726266384125
Valid Loss:  0.0019126854604110122
Epoch:  293  	Training Loss: 0.002276166807860136
Test Loss:  0.0019214506028220057
Valid Loss:  0.0019110431894659996
Epoch:  294  	Training Loss: 0.0022719933185726404
Test Loss:  0.0019186551216989756
Valid Loss:  0.0019094015005975962
Epoch:  295  	Training Loss: 0.0022678454406559467
Test Loss:  0.0019158858340233564
Valid Loss:  0.0019077686592936516
Epoch:  296  	Training Loss: 0.002263723872601986
Test Loss:  0.0019131260924041271
Valid Loss:  0.0019061332568526268
Epoch:  297  	Training Loss: 0.0022596283815801144
Test Loss:  0.0019103451631963253
Valid Loss:  0.0019044463988393545
Epoch:  298  	Training Loss: 0.0022555594332516193
Test Loss:  0.001907591475173831
Valid Loss:  0.001902767107822001
Epoch:  299  	Training Loss: 0.0022515091113746166
Test Loss:  0.0019048294052481651
Valid Loss:  0.0019010727992281318
Epoch:  300  	Training Loss: 0.002247463446110487
Test Loss:  0.0019020457984879613
Valid Loss:  0.0018993858247995377
Epoch:  301  	Training Loss: 0.0022434412967413664
Test Loss:  0.0018992660334333777
Valid Loss:  0.001897703856229782
Epoch:  302  	Training Loss: 0.002239435911178589
Test Loss:  0.001896324334666133
Valid Loss:  0.0018959167646244168
Epoch:  303  	Training Loss: 0.0022353262174874544
Test Loss:  0.0018933784449473023
Valid Loss:  0.0018941204762086272
Epoch:  304  	Training Loss: 0.002231219317764044
Test Loss:  0.001890406128950417
Valid Loss:  0.0018923336174339056
Epoch:  305  	Training Loss: 0.002227136632427573
Test Loss:  0.001887451857328415
Valid Loss:  0.0018905432661995292
Epoch:  306  	Training Loss: 0.0022230730392038822
Test Loss:  0.0018844660371541977
Valid Loss:  0.001888741971924901
Epoch:  307  	Training Loss: 0.00221899151802063
Test Loss:  0.0018815039657056332
Valid Loss:  0.001886940561234951
Epoch:  308  	Training Loss: 0.0022149314172565937
Test Loss:  0.0018785489955917
Valid Loss:  0.0018851503264158964
Epoch:  309  	Training Loss: 0.002210890408605337
Test Loss:  0.001875613583251834
Valid Loss:  0.0018833281937986612
Epoch:  310  	Training Loss: 0.0022068736143410206
Test Loss:  0.0018726903945207596
Valid Loss:  0.0018814976792782545
Epoch:  311  	Training Loss: 0.0022028768435120583
Test Loss:  0.0018697846680879593
Valid Loss:  0.0018796751974150538
Epoch:  312  	Training Loss: 0.002198900794610381
Test Loss:  0.0018665860407054424
Valid Loss:  0.001877718372270465
Epoch:  313  	Training Loss: 0.002194805070757866
Test Loss:  0.001863384386524558
Valid Loss:  0.0018757575890049338
Epoch:  314  	Training Loss: 0.002190724713727832
Test Loss:  0.001860165735706687
Valid Loss:  0.001873787958174944
Epoch:  315  	Training Loss: 0.0021866399329155684
Test Loss:  0.001856973860412836
Valid Loss:  0.0018718168139457703
Epoch:  316  	Training Loss: 0.002182574477046728
Test Loss:  0.0018538014264777303
Valid Loss:  0.0018698471831157804
Epoch:  317  	Training Loss: 0.002178526483476162
Test Loss:  0.0018506499473005533
Valid Loss:  0.001867861719802022
Epoch:  318  	Training Loss: 0.0021745008416473866
Test Loss:  0.0018475044053047895
Valid Loss:  0.001865867874585092
Epoch:  319  	Training Loss: 0.002170490100979805
Test Loss:  0.0018443565350025892
Valid Loss:  0.00186387007124722
Epoch:  320  	Training Loss: 0.002166489837691188
Test Loss:  0.001841226825490594
Valid Loss:  0.0018618755275383592
Epoch:  321  	Training Loss: 0.0021625084336847067
Test Loss:  0.0018381092231720686
Valid Loss:  0.0018598733004182577
Epoch:  322  	Training Loss: 0.002158546354621649
Test Loss:  0.0018347499426454306
Valid Loss:  0.0018576474394649267
Epoch:  323  	Training Loss: 0.002154398011043668
Test Loss:  0.0018313941545784473
Valid Loss:  0.001855423441156745
Epoch:  324  	Training Loss: 0.002150267828255892
Test Loss:  0.0018280567601323128
Valid Loss:  0.0018531971145421267
Epoch:  325  	Training Loss: 0.002146156970411539
Test Loss:  0.0018247327534481883
Valid Loss:  0.0018509754445403814
Epoch:  326  	Training Loss: 0.002142063807696104
Test Loss:  0.0018214304000139236
Valid Loss:  0.0018487516790628433
Epoch:  327  	Training Loss: 0.002137988805770874
Test Loss:  0.001818138058297336
Valid Loss:  0.0018465281464159489
Epoch:  328  	Training Loss: 0.002133930567651987
Test Loss:  0.0018148598028346896
Valid Loss:  0.0018443034496158361
Epoch:  329  	Training Loss: 0.002129889791831374
Test Loss:  0.0018115935381501913
Valid Loss:  0.0018420836422592402
Epoch:  330  	Training Loss: 0.0021258657798171043
Test Loss:  0.0018083404283970594
Valid Loss:  0.0018398649990558624
Epoch:  331  	Training Loss: 0.002121859695762396
Test Loss:  0.001805098494514823
Valid Loss:  0.0018376462394371629
Epoch:  332  	Training Loss: 0.002117869909852743
Test Loss:  0.001801404170691967
Valid Loss:  0.0018352444749325514
Epoch:  333  	Training Loss: 0.0021136607974767685
Test Loss:  0.0017977382522076368
Valid Loss:  0.0018328382866457105
Epoch:  334  	Training Loss: 0.0021094665862619877
Test Loss:  0.0017940998077392578
Valid Loss:  0.0018304334953427315
Epoch:  335  	Training Loss: 0.002105291932821274
Test Loss:  0.0017904900014400482
Valid Loss:  0.0018280241638422012
Epoch:  336  	Training Loss: 0.0021011349745094776
Test Loss:  0.0017869051080197096
Valid Loss:  0.00182561413384974
Epoch:  337  	Training Loss: 0.0020969966426491737
Test Loss:  0.0017833546735346317
Valid Loss:  0.0018232172587886453
Epoch:  338  	Training Loss: 0.0020928815938532352
Test Loss:  0.00177982565946877
Valid Loss:  0.0018208338879048824
Epoch:  339  	Training Loss: 0.002088785171508789
Test Loss:  0.001776315039023757
Valid Loss:  0.001818458316847682
Epoch:  340  	Training Loss: 0.002084704115986824
Test Loss:  0.001772827934473753
Valid Loss:  0.0018160906620323658
Epoch:  341  	Training Loss: 0.0020806409884244204
Test Loss:  0.0017693790141493082
Valid Loss:  0.0018137150909751654
Epoch:  342  	Training Loss: 0.0020765941590070724
Test Loss:  0.0017654630355536938
Valid Loss:  0.0018111427780240774
Epoch:  343  	Training Loss: 0.0020723072811961174
Test Loss:  0.00176157895475626
Valid Loss:  0.0018085899064317346
Epoch:  344  	Training Loss: 0.002068042289465666
Test Loss:  0.0017577472608536482
Valid Loss:  0.0018060436705127358
Epoch:  345  	Training Loss: 0.002063809195533395
Test Loss:  0.001753944787196815
Valid Loss:  0.0018034992972388864
Epoch:  346  	Training Loss: 0.002059600315988064
Test Loss:  0.0017502098344266415
Valid Loss:  0.0018009648192673922
Epoch:  347  	Training Loss: 0.0020554345101118088
Test Loss:  0.0017464931588619947
Valid Loss:  0.001798431039787829
Epoch:  348  	Training Loss: 0.0020512891933321953
Test Loss:  0.001742812804877758
Valid Loss:  0.00179590517655015
 70%|███████   | 350/500 [04:04<00:51,  2.92it/s] 70%|███████   | 352/500 [04:11<02:57,  1.20s/it] 71%|███████   | 354/500 [04:11<02:05,  1.16it/s] 71%|███████   | 356/500 [04:11<01:29,  1.60it/s] 72%|███████▏  | 358/500 [04:11<01:04,  2.19it/s] 72%|███████▏  | 360/500 [04:11<00:47,  2.93it/s] 72%|███████▏  | 362/500 [04:18<02:46,  1.21s/it] 73%|███████▎  | 364/500 [04:18<01:57,  1.16it/s] 73%|███████▎  | 366/500 [04:18<01:23,  1.60it/s] 74%|███████▎  | 368/500 [04:18<01:00,  2.17it/s] 74%|███████▍  | 370/500 [04:18<00:45,  2.87it/s] 74%|███████▍  | 372/500 [04:25<02:36,  1.22s/it] 75%|███████▍  | 374/500 [04:25<01:50,  1.14it/s] 75%|███████▌  | 376/500 [04:25<01:18,  1.58it/s] 76%|███████▌  | 378/500 [04:25<00:56,  2.17it/s] 76%|███████▌  | 380/500 [04:25<00:41,  2.92it/s] 76%|███████▋  | 382/500 [04:32<02:19,  1.18s/it] 77%|███████▋  | 384/500 [04:32<01:38,  1.18it/s] 77%|███████▋  | 386/500 [04:32<01:09,  1.63it/s] 78%|███████▊  | 388/500 [04:32<00:50,  2.23it/s] 78%|███████▊  | 390/500 [04:32<00:36,  3.00it/s] 78%|███████▊  | 392/500 [04:39<02:09,  1.20s/it] 79%|███████▉  | 394/500 [04:39<01:31,  1.16it/s] 79%|███████▉  | 396/500 [04:39<01:04,  1.61it/s] 80%|███████▉  | 398/500 [04:39<00:46,  2.20it/s] 80%|████████  | 400/500 [04:39<00:34,  2.93it/s] 80%|████████  | 402/500 [04:46<02:00,  1.22s/it] 81%|████████  | 404/500 [04:46<01:24,  1.14it/s] 81%|████████  | 406/500 [04:46<00:59,  1.58it/s] 82%|████████▏ | 408/500 [04:46<00:42,  2.16it/s] 82%|████████▏ | 410/500 [04:46<00:30,  2.91it/s] 82%|████████▏ | 412/500 [04:53<01:45,  1.20s/it] 83%|████████▎ | 414/500 [04:53<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:53<00:52,  1.61it/s]Epoch:  349  	Training Loss: 0.0020471736788749695
Test Loss:  0.0017391567816957831
Valid Loss:  0.0017934136558324099
Epoch:  350  	Training Loss: 0.0020430744625627995
Test Loss:  0.0017355139134451747
Valid Loss:  0.0017909310990944505
Epoch:  351  	Training Loss: 0.0020389899145811796
Test Loss:  0.0017318892059847713
Valid Loss:  0.0017884457483887672
Epoch:  352  	Training Loss: 0.0020349202677607536
Test Loss:  0.0017279008170589805
Valid Loss:  0.00178566575050354
Epoch:  353  	Training Loss: 0.002030584029853344
Test Loss:  0.0017239325679838657
Valid Loss:  0.0017828885465860367
Epoch:  354  	Training Loss: 0.002026262693107128
Test Loss:  0.0017199856229126453
Valid Loss:  0.0017801052890717983
Epoch:  355  	Training Loss: 0.00202195905148983
Test Loss:  0.0017160587012767792
Valid Loss:  0.0017773294821381569
Epoch:  356  	Training Loss: 0.0020176826510578394
Test Loss:  0.0017121814889833331
Valid Loss:  0.001774623990058899
Epoch:  357  	Training Loss: 0.002013441175222397
Test Loss:  0.0017083175480365753
Valid Loss:  0.0017719209427013993
Epoch:  358  	Training Loss: 0.0020092125050723553
Test Loss:  0.0017044749110937119
Valid Loss:  0.0017692241817712784
Epoch:  359  	Training Loss: 0.0020050005987286568
Test Loss:  0.0017006414709612727
Valid Loss:  0.0017665280029177666
Epoch:  360  	Training Loss: 0.002000804990530014
Test Loss:  0.0016968593699857593
Valid Loss:  0.0017638476565480232
Epoch:  361  	Training Loss: 0.001996657345443964
Test Loss:  0.0016931184800341725
Valid Loss:  0.0017611710354685783
Epoch:  362  	Training Loss: 0.001992523903027177
Test Loss:  0.001688894466497004
Valid Loss:  0.0017582520376890898
Epoch:  363  	Training Loss: 0.001988120609894395
Test Loss:  0.0016848022351041436
Valid Loss:  0.001755368197336793
Epoch:  364  	Training Loss: 0.0019837855361402035
Test Loss:  0.0016807857900857925
Valid Loss:  0.0017524885479360819
Epoch:  365  	Training Loss: 0.001979466527700424
Test Loss:  0.0016767901834100485
Valid Loss:  0.001749608083628118
Epoch:  366  	Training Loss: 0.0019751638174057007
Test Loss:  0.0016728162299841642
Valid Loss:  0.0017467335565015674
Epoch:  367  	Training Loss: 0.001970881363376975
Test Loss:  0.0016689058393239975
Valid Loss:  0.0017438794020563364
Epoch:  368  	Training Loss: 0.0019666519947350025
Test Loss:  0.001665008720010519
Valid Loss:  0.0017410304863005877
Epoch:  369  	Training Loss: 0.0019624358974397182
Test Loss:  0.0016611253377050161
Valid Loss:  0.001738187507726252
Epoch:  370  	Training Loss: 0.0019582356326282024
Test Loss:  0.0016572572058066726
Valid Loss:  0.0017353460425511003
Epoch:  371  	Training Loss: 0.001954050734639168
Test Loss:  0.0016534016467630863
Valid Loss:  0.0017325144726783037
Epoch:  372  	Training Loss: 0.0019498853944242
Test Loss:  0.0016489032423123717
Valid Loss:  0.001729684299789369
Epoch:  373  	Training Loss: 0.001945550786331296
Test Loss:  0.0016444581560790539
Valid Loss:  0.0017268508672714233
Epoch:  374  	Training Loss: 0.001941231545060873
Test Loss:  0.0016400530003011227
Valid Loss:  0.0017240107990801334
Epoch:  375  	Training Loss: 0.0019369288347661495
Test Loss:  0.0016356956912204623
Valid Loss:  0.0017211718950420618
Epoch:  376  	Training Loss: 0.0019326410256326199
Test Loss:  0.0016313801752403378
Valid Loss:  0.0017183265881612897
Epoch:  377  	Training Loss: 0.0019283704459667206
Test Loss:  0.0016271054046228528
Valid Loss:  0.0017154805827885866
Epoch:  378  	Training Loss: 0.0019241152331233025
Test Loss:  0.0016228682361543179
Valid Loss:  0.0017126272432506084
Epoch:  379  	Training Loss: 0.0019198748050257564
Test Loss:  0.001618669950403273
Valid Loss:  0.0017097770469263196
Epoch:  380  	Training Loss: 0.0019156490452587605
Test Loss:  0.0016145011177286506
Valid Loss:  0.0017069278983399272
Epoch:  381  	Training Loss: 0.0019114661263301969
Test Loss:  0.0016104320529848337
Valid Loss:  0.0017040971433743834
Epoch:  382  	Training Loss: 0.0019073404837399721
Test Loss:  0.0016064021037891507
Valid Loss:  0.0017012751195579767
Epoch:  383  	Training Loss: 0.0019032710697501898
Test Loss:  0.001602391479536891
Valid Loss:  0.001698496751487255
Epoch:  384  	Training Loss: 0.001899213995784521
Test Loss:  0.0015984086785465479
Valid Loss:  0.001695798011496663
Epoch:  385  	Training Loss: 0.0018951704259961843
Test Loss:  0.001594444504007697
Valid Loss:  0.0016931002028286457
Epoch:  386  	Training Loss: 0.001891142688691616
Test Loss:  0.0015905022155493498
Valid Loss:  0.0016904119402170181
Epoch:  387  	Training Loss: 0.0018871277570724487
Test Loss:  0.0015865833265706897
Valid Loss:  0.0016877204179763794
Epoch:  388  	Training Loss: 0.0018831318011507392
Test Loss:  0.0015828260220587254
Valid Loss:  0.001685085240751505
Epoch:  389  	Training Loss: 0.0018792644841596484
Test Loss:  0.001579082803800702
Valid Loss:  0.0016824542544782162
Epoch:  390  	Training Loss: 0.0018754123011603951
Test Loss:  0.0015753795159980655
Valid Loss:  0.0016798292053863406
Epoch:  391  	Training Loss: 0.0018715725746005774
Test Loss:  0.0015717782080173492
Valid Loss:  0.0016773244133219123
Epoch:  392  	Training Loss: 0.0018677456537261605
Test Loss:  0.0015686897095292807
Valid Loss:  0.0016751312650740147
Epoch:  393  	Training Loss: 0.001864233985543251
Test Loss:  0.0015655939932912588
Valid Loss:  0.00167295360006392
Epoch:  394  	Training Loss: 0.001860735472291708
Test Loss:  0.001562568941153586
Valid Loss:  0.001670871744863689
Epoch:  395  	Training Loss: 0.001857247669249773
Test Loss:  0.001559584867209196
Valid Loss:  0.001668946584686637
Epoch:  396  	Training Loss: 0.0018537689466029406
Test Loss:  0.0015565910143777728
Valid Loss:  0.0016670282930135727
Epoch:  397  	Training Loss: 0.0018503025639802217
Test Loss:  0.0015535998390987515
Valid Loss:  0.0016651181504130363
Epoch:  398  	Training Loss: 0.0018468478228896856
Test Loss:  0.0015506005147472024
Valid Loss:  0.0016632145270705223
Epoch:  399  	Training Loss: 0.0018434027442708611
Test Loss:  0.0015476036351174116
Valid Loss:  0.001661424059420824
Epoch:  400  	Training Loss: 0.0018399946857243776
Test Loss:  0.0015446802135556936
Valid Loss:  0.0016596735222265124
Epoch:  401  	Training Loss: 0.0018366596195846796
Test Loss:  0.0015418240800499916
Valid Loss:  0.0016579482471570373
Epoch:  402  	Training Loss: 0.0018333673942834139
Test Loss:  0.001539470860734582
Valid Loss:  0.0016564071411266923
Epoch:  403  	Training Loss: 0.0018304022960364819
Test Loss:  0.001537091564387083
Valid Loss:  0.0016548754647374153
Epoch:  404  	Training Loss: 0.001827465370297432
Test Loss:  0.0015347665175795555
Valid Loss:  0.0016533760353922844
Epoch:  405  	Training Loss: 0.0018245725659653544
Test Loss:  0.0015324247069656849
Valid Loss:  0.0016518859192728996
Epoch:  406  	Training Loss: 0.0018216868629679084
Test Loss:  0.0015300569357350469
Valid Loss:  0.0016504100058227777
Epoch:  407  	Training Loss: 0.001818808726966381
Test Loss:  0.001527672167867422
Valid Loss:  0.0016489413101226091
Epoch:  408  	Training Loss: 0.0018159463070333004
Test Loss:  0.0015253496821969748
Valid Loss:  0.0016475000884383917
Epoch:  409  	Training Loss: 0.0018131404649466276
Test Loss:  0.0015230049612000585
Valid Loss:  0.0016460709739476442
Epoch:  410  	Training Loss: 0.0018103437032550573
Test Loss:  0.0015206453390419483
Valid Loss:  0.0016446502413600683
Epoch:  411  	Training Loss: 0.0018075746484100819
Test Loss:  0.001518420409411192
Valid Loss:  0.0016432711854577065
Epoch:  412  	Training Loss: 0.0018049044301733375
Test Loss:  0.0015166134107857943
Valid Loss:  0.0016419942257925868
Epoch:  413  	Training Loss: 0.0018024251330643892
Test Loss:  0.001514843781478703
Valid Loss:  0.0016407514922320843
Epoch:  414  	Training Loss: 0.0018000005511566997
Test Loss:  0.0015130480751395226
Valid Loss:  0.0016395188868045807
Epoch:  415  	Training Loss: 0.0017975843511521816
Test Loss:  0.0015112232649698853
Valid Loss:  0.0016383000183850527
Epoch:  416  	Training Loss: 0.0017951733898371458
Test Loss:  0.0015093686524778605
Valid Loss:  0.0016370934899896383
Epoch:  417  	Training Loss: 0.0017927710432559252
Test Loss:  0.0015075772535055876 84%|████████▎ | 418/500 [04:53<00:37,  2.20it/s] 84%|████████▍ | 420/500 [04:53<00:27,  2.95it/s] 84%|████████▍ | 422/500 [05:00<01:33,  1.20s/it] 85%|████████▍ | 424/500 [05:00<01:05,  1.16it/s] 85%|████████▌ | 426/500 [05:00<00:45,  1.61it/s] 86%|████████▌ | 428/500 [05:00<00:32,  2.20it/s] 86%|████████▌ | 430/500 [05:00<00:23,  2.97it/s] 86%|████████▋ | 432/500 [05:07<01:22,  1.22s/it] 87%|████████▋ | 434/500 [05:07<00:57,  1.14it/s] 87%|████████▋ | 436/500 [05:07<00:40,  1.57it/s] 88%|████████▊ | 438/500 [05:07<00:28,  2.15it/s] 88%|████████▊ | 440/500 [05:07<00:20,  2.89it/s] 88%|████████▊ | 442/500 [05:14<01:10,  1.21s/it] 89%|████████▉ | 444/500 [05:14<00:48,  1.15it/s] 89%|████████▉ | 446/500 [05:14<00:33,  1.59it/s] 90%|████████▉ | 448/500 [05:14<00:23,  2.18it/s] 90%|█████████ | 450/500 [05:14<00:17,  2.93it/s] 90%|█████████ | 452/500 [05:21<00:57,  1.20s/it] 91%|█████████ | 454/500 [05:21<00:39,  1.16it/s] 91%|█████████ | 456/500 [05:21<00:27,  1.60it/s] 92%|█████████▏| 458/500 [05:21<00:19,  2.19it/s] 92%|█████████▏| 460/500 [05:21<00:13,  2.94it/s] 92%|█████████▏| 462/500 [05:28<00:45,  1.20s/it] 93%|█████████▎| 464/500 [05:28<00:30,  1.17it/s] 93%|█████████▎| 466/500 [05:28<00:21,  1.61it/s] 94%|█████████▎| 468/500 [05:28<00:14,  2.17it/s] 94%|█████████▍| 470/500 [05:28<00:10,  2.87it/s] 94%|█████████▍| 472/500 [05:35<00:34,  1.22s/it] 95%|█████████▍| 474/500 [05:35<00:22,  1.15it/s] 95%|█████████▌| 476/500 [05:35<00:15,  1.59it/s] 96%|█████████▌| 478/500 [05:35<00:10,  2.17it/s] 96%|█████████▌| 480/500 [05:35<00:06,  2.92it/s] 96%|█████████▋| 482/500 [05:42<00:21,  1.20s/it] 97%|█████████▋| 484/500 [05:42<00:13,  1.16it/s]
Valid Loss:  0.001635900465771556
Epoch:  418  	Training Loss: 0.0017903721891343594
Test Loss:  0.0015057792188599706
Valid Loss:  0.0016347154742106795
Epoch:  419  	Training Loss: 0.0017879828810691833
Test Loss:  0.0015040369471535087
Valid Loss:  0.0016335409600287676
Epoch:  420  	Training Loss: 0.0017855979967862368
Test Loss:  0.0015023074811324477
Valid Loss:  0.0016323723830282688
Epoch:  421  	Training Loss: 0.0017832207959145308
Test Loss:  0.0015005595050752163
Valid Loss:  0.001631216611713171
Epoch:  422  	Training Loss: 0.001780871651135385
Test Loss:  0.0014990305062383413
Valid Loss:  0.0016301472205668688
Epoch:  423  	Training Loss: 0.00177865126170218
Test Loss:  0.001497494289651513
Valid Loss:  0.0016290866769850254
Epoch:  424  	Training Loss: 0.0017764352960512042
Test Loss:  0.0014960215194150805
Valid Loss:  0.0016280366107821465
Epoch:  425  	Training Loss: 0.0017742272466421127
Test Loss:  0.0014945317525416613
Valid Loss:  0.0016269945772364736
Epoch:  426  	Training Loss: 0.001772026065737009
Test Loss:  0.0014930226607248187
Valid Loss:  0.0016259587137028575
Epoch:  427  	Training Loss: 0.0017698290757834911
Test Loss:  0.001491493545472622
Valid Loss:  0.0016249301843345165
Epoch:  428  	Training Loss: 0.001767637673765421
Test Loss:  0.0014899545349180698
Valid Loss:  0.0016239092219620943
Epoch:  429  	Training Loss: 0.0017654600087553263
Test Loss:  0.0014884674455970526
Valid Loss:  0.001622909214347601
Epoch:  430  	Training Loss: 0.0017633296083658934
Test Loss:  0.0014869653386995196
Valid Loss:  0.0016219206154346466
Epoch:  431  	Training Loss: 0.001761216321028769
Test Loss:  0.0014855151530355215
Valid Loss:  0.0016209520399570465
Epoch:  432  	Training Loss: 0.0017591649666428566
Test Loss:  0.0014842182863503695
Valid Loss:  0.001620043651200831
Epoch:  433  	Training Loss: 0.0017571930075064301
Test Loss:  0.0014829009305685759
Valid Loss:  0.0016191441100090742
Epoch:  434  	Training Loss: 0.0017552280332893133
Test Loss:  0.0014815640170127153
Valid Loss:  0.0016182478284463286
Epoch:  435  	Training Loss: 0.0017532662022858858
Test Loss:  0.0014802032383158803
Valid Loss:  0.001617365749552846
Epoch:  436  	Training Loss: 0.0017513104248791933
Test Loss:  0.0014788262778893113
Valid Loss:  0.0016164873959496617
Epoch:  437  	Training Loss: 0.0017493602354079485
Test Loss:  0.0014774336013942957
Valid Loss:  0.0016156142810359597
Epoch:  438  	Training Loss: 0.0017474126070737839
Test Loss:  0.001476028235629201
Valid Loss:  0.0016147498972713947
Epoch:  439  	Training Loss: 0.0017454721964895725
Test Loss:  0.0014746044762432575
Valid Loss:  0.001613890752196312
Epoch:  440  	Training Loss: 0.001743534579873085
Test Loss:  0.0014731712872162461
Valid Loss:  0.0016130346339195967
Epoch:  441  	Training Loss: 0.0017416023183614016
Test Loss:  0.0014717294834554195
Valid Loss:  0.0016121817752718925
Epoch:  442  	Training Loss: 0.0017396743642166257
Test Loss:  0.00147032190579921
Valid Loss:  0.0016113497549667954
Epoch:  443  	Training Loss: 0.0017377703916281462
Test Loss:  0.0014689674135297537
Valid Loss:  0.0016105378745123744
Epoch:  444  	Training Loss: 0.0017359082121402025
Test Loss:  0.0014675981365144253
Valid Loss:  0.0016097264597192407
Epoch:  445  	Training Loss: 0.0017340490594506264
Test Loss:  0.001466216053813696
Valid Loss:  0.0016089283162727952
Epoch:  446  	Training Loss: 0.001732219010591507
Test Loss:  0.0014648853102698922
Valid Loss:  0.0016081483336165547
Epoch:  447  	Training Loss: 0.0017304152715951204
Test Loss:  0.0014635446714237332
Valid Loss:  0.0016073714941740036
Epoch:  448  	Training Loss: 0.001728617586195469
Test Loss:  0.0014621911104768515
Valid Loss:  0.00160659896209836
Epoch:  449  	Training Loss: 0.0017268232768401504
Test Loss:  0.001460823230445385
Valid Loss:  0.0016058317851275206
Epoch:  450  	Training Loss: 0.001725033507682383
Test Loss:  0.0014594481326639652
Valid Loss:  0.0016050718259066343
Epoch:  451  	Training Loss: 0.0017232490936294198
Test Loss:  0.001458062557503581
Valid Loss:  0.001604311284609139
Epoch:  452  	Training Loss: 0.0017214674735441804
Test Loss:  0.001456739380955696
Valid Loss:  0.0016035274602472782
Epoch:  453  	Training Loss: 0.001719682477414608
Test Loss:  0.001455398858524859
Valid Loss:  0.0016027430538088083
Epoch:  454  	Training Loss: 0.0017179001588374376
Test Loss:  0.0014540512347593904
Valid Loss:  0.001601967727765441
Epoch:  455  	Training Loss: 0.0017161250580102205
Test Loss:  0.0014527544844895601
Valid Loss:  0.0016012107953429222
Epoch:  456  	Training Loss: 0.0017143988516181707
Test Loss:  0.0014514487702399492
Valid Loss:  0.0016004587523639202
Epoch:  457  	Training Loss: 0.0017126969760283828
Test Loss:  0.0014502310659736395
Valid Loss:  0.0015997299924492836
Epoch:  458  	Training Loss: 0.0017110251355916262
Test Loss:  0.0014490492176264524
Valid Loss:  0.0015990105457603931
Epoch:  459  	Training Loss: 0.0017093571368604898
Test Loss:  0.0014478559605777264
Valid Loss:  0.00159829156473279
Epoch:  460  	Training Loss: 0.0017076930962502956
Test Loss:  0.0014466478023678064
Valid Loss:  0.0015975800342857838
Epoch:  461  	Training Loss: 0.0017060337122529745
Test Loss:  0.0014454299816861749
Valid Loss:  0.0015968710649758577
Epoch:  462  	Training Loss: 0.0017043778207153082
Test Loss:  0.0014441623352468014
Valid Loss:  0.0015962080797180533
Epoch:  463  	Training Loss: 0.0017027071444317698
Test Loss:  0.0014429485891014338
Valid Loss:  0.0015955391572788358
Epoch:  464  	Training Loss: 0.0017010427545756102
Test Loss:  0.0014417293714359403
Valid Loss:  0.0015948762884363532
Epoch:  465  	Training Loss: 0.0016993816243484616
Test Loss:  0.0014405110850930214
Valid Loss:  0.001594208413735032
Epoch:  466  	Training Loss: 0.0016977221239358187
Test Loss:  0.0014392882585525513
Valid Loss:  0.0015935431001707911
Epoch:  467  	Training Loss: 0.0016960679786279798
Test Loss:  0.0014380589127540588
Valid Loss:  0.0015928808134049177
Epoch:  468  	Training Loss: 0.001694417092949152
Test Loss:  0.0014368327101692557
Valid Loss:  0.0015922181773930788
Epoch:  469  	Training Loss: 0.0016927715623751283
Test Loss:  0.0014356030151247978
Valid Loss:  0.0015915496041998267
Epoch:  470  	Training Loss: 0.0016911274287849665
Test Loss:  0.0014343687798827887
Valid Loss:  0.001590888830833137
Epoch:  471  	Training Loss: 0.0016894876025617123
Test Loss:  0.001433137571439147
Valid Loss:  0.0015902224695309997
Epoch:  472  	Training Loss: 0.0016878523165360093
Test Loss:  0.0014319582842290401
Valid Loss:  0.001589509192854166
Epoch:  473  	Training Loss: 0.0016861924668774009
Test Loss:  0.0014307696837931871
Valid Loss:  0.0015887932386249304
Epoch:  474  	Training Loss: 0.0016845385544002056
Test Loss:  0.0014295779401436448
Valid Loss:  0.0015880824066698551
Epoch:  475  	Training Loss: 0.0016828870866447687
Test Loss:  0.0014283963246271014
Valid Loss:  0.0015873746015131474
Epoch:  476  	Training Loss: 0.001681238180026412
Test Loss:  0.0014272874686866999
Valid Loss:  0.0015866679605096579
Epoch:  477  	Training Loss: 0.0016795940464362502
Test Loss:  0.001426175469532609
Valid Loss:  0.0015859587583690882
Epoch:  478  	Training Loss: 0.0016779538709670305
Test Loss:  0.001425057416781783
Valid Loss:  0.0015852542128413916
Epoch:  479  	Training Loss: 0.00167631555814296
Test Loss:  0.001423935405910015
Valid Loss:  0.0015845480374991894
Epoch:  480  	Training Loss: 0.0016746839974075556
Test Loss:  0.0014228143263608217
Valid Loss:  0.0015838437248021364
Epoch:  481  	Training Loss: 0.001673052553087473
Test Loss:  0.0014216869603842497
Valid Loss:  0.0015831418568268418
Epoch:  482  	Training Loss: 0.0016714457888156176
Test Loss:  0.0014205866027623415
Valid Loss:  0.0015824628062546253
Epoch:  483  	Training Loss: 0.0016698513645678759
Test Loss:  0.0014194796094670892
Valid Loss:  0.001581785036250949
Epoch:  484  	Training Loss: 0.0016682586865499616
Test Loss:  0.0014183734310790896
Valid Loss:  0.0015811818884685636
Epoch:  485  	Training Loss: 0.0016666726442053914
Test Loss:  0.0014172607334330678
Valid Loss:  0.0015805978327989578
 97%|█████████▋| 486/500 [05:42<00:08,  1.60it/s] 98%|█████████▊| 488/500 [05:42<00:05,  2.19it/s] 98%|█████████▊| 490/500 [05:42<00:03,  2.92it/s] 98%|█████████▊| 492/500 [05:49<00:09,  1.20s/it] 99%|█████████▉| 494/500 [05:49<00:05,  1.15it/s] 99%|█████████▉| 496/500 [05:49<00:02,  1.59it/s]100%|█████████▉| 498/500 [05:49<00:00,  2.17it/s]100%|██████████| 500/500 [05:49<00:00,  2.90it/s]100%|██████████| 500/500 [05:49<00:00,  1.43it/s]
Epoch:  486  	Training Loss: 0.0016650879988446832
Test Loss:  0.001416143961250782
Valid Loss:  0.0015800129622220993
Epoch:  487  	Training Loss: 0.0016635082429274917
Test Loss:  0.001415026606991887
Valid Loss:  0.0015794325154274702
Epoch:  488  	Training Loss: 0.0016619308153167367
Test Loss:  0.00141390529461205
Valid Loss:  0.0015788484597578645
Epoch:  489  	Training Loss: 0.0016603557160124183
Test Loss:  0.001412786077708006
Valid Loss:  0.001578266965225339
Epoch:  490  	Training Loss: 0.001658785855397582
Test Loss:  0.0014116604579612613
Valid Loss:  0.0015776848886162043
Epoch:  491  	Training Loss: 0.0016572184395045042
Test Loss:  0.0014105348382145166
Valid Loss:  0.001577101880684495
Epoch:  492  	Training Loss: 0.001655653351917863
Test Loss:  0.0014093895442783833
Valid Loss:  0.0015765224816277623
Epoch:  493  	Training Loss: 0.0016540699871256948
Test Loss:  0.0014083250425755978
Valid Loss:  0.0015759463422000408
Epoch:  494  	Training Loss: 0.001652490464039147
Test Loss:  0.001407257979735732
Valid Loss:  0.001575364964082837
Epoch:  495  	Training Loss: 0.0016509124543517828
Test Loss:  0.0014061927795410156
Valid Loss:  0.0015747856814414263
Epoch:  496  	Training Loss: 0.00164933898486197
Test Loss:  0.00140512571670115
Valid Loss:  0.0015742054674774408
Epoch:  497  	Training Loss: 0.0016477761091664433
Test Loss:  0.0014041174435988069
Valid Loss:  0.0015736357308924198
Epoch:  498  	Training Loss: 0.0016462549101561308
Test Loss:  0.0014031047467142344
Valid Loss:  0.0015730693703517318
Epoch:  499  	Training Loss: 0.0016447380185127258
Test Loss:  0.0014020883245393634
Valid Loss:  0.001572504173964262
Epoch:  500  	Training Loss: 0.0016432234551757574
Test Loss:  0.0014010705053806305
Valid Loss:  0.0015719361836090684
seed is  20
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:09,  6.27s/it]  1%|          | 3/500 [00:06<13:56,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.93it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:30,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:53,  1.24s/it]  5%|▍         | 23/500 [00:20<07:00,  1.13it/s]  5%|▌         | 25/500 [00:20<05:03,  1.57it/s]  5%|▌         | 27/500 [00:20<03:42,  2.12it/s]  6%|▌         | 29/500 [00:20<02:47,  2.81it/s]  6%|▌         | 31/500 [00:27<09:37,  1.23s/it]  7%|▋         | 33/500 [00:27<06:51,  1.13it/s]  7%|▋         | 35/500 [00:27<04:56,  1.57it/s]  7%|▋         | 37/500 [00:27<03:36,  2.14it/s]  8%|▊         | 39/500 [00:28<02:41,  2.86it/s]  8%|▊         | 41/500 [00:34<09:19,  1.22s/it]  9%|▊         | 43/500 [00:34<06:41,  1.14it/s]  9%|▉         | 45/500 [00:34<04:48,  1.58it/s]  9%|▉         | 47/500 [00:34<03:31,  2.14it/s] 10%|▉         | 49/500 [00:35<02:37,  2.86it/s] 10%|█         | 51/500 [00:41<09:04,  1.21s/it] 11%|█         | 53/500 [00:41<06:28,  1.15it/s] 11%|█         | 55/500 [00:41<04:39,  1.59it/s] 11%|█▏        | 57/500 [00:42<03:24,  2.17it/s] 12%|█▏        | 59/500 [00:42<02:31,  2.91it/s] 12%|█▏        | 61/500 [00:48<08:53,  1.22s/it] 13%|█▎        | 63/500 [00:48<06:21,  1.15it/s] 13%|█▎        | 65/500 [00:55<11:29,  1.59s/it] 13%|█▎        | 67/500 [00:55<08:10,  1.13s/it] 14%|█▍        | 69/500 [00:55<05:50,  1.23it/s] 14%|█▍        | 71/500 [01:01<10:55,  1.53s/it]Epoch:  1  	Training Loss: 0.20486688613891602
Test Loss:  63.68516159057617
Valid Loss:  61.207542419433594
Epoch:  2  	Training Loss: 63.48272705078125
Test Loss:  362.35693359375
Valid Loss:  342.363037109375
Epoch:  3  	Training Loss: 361.3753967285156
Test Loss:  14.340788841247559
Valid Loss:  14.576979637145996
Epoch:  4  	Training Loss: 15.642133712768555
Test Loss:  14.335273742675781
Valid Loss:  14.563497543334961
Epoch:  5  	Training Loss: 15.624847412109375
Test Loss:  14.329805374145508
Valid Loss:  14.552144050598145
Epoch:  6  	Training Loss: 15.607818603515625
Test Loss:  14.324438095092773
Valid Loss:  14.541006088256836
Epoch:  7  	Training Loss: 15.591207504272461
Test Loss:  14.31911849975586
Valid Loss:  14.52996826171875
Epoch:  8  	Training Loss: 15.574701309204102
Test Loss:  14.313835144042969
Valid Loss:  14.519020080566406
Epoch:  9  	Training Loss: 15.558727264404297
Test Loss:  14.308767318725586
Valid Loss:  14.508533477783203
Epoch:  10  	Training Loss: 15.543411254882812
Test Loss:  14.3037691116333
Valid Loss:  14.498133659362793
Epoch:  11  	Training Loss: 15.528186798095703
Test Loss:  14.298815727233887
Valid Loss:  14.488899230957031
Epoch:  12  	Training Loss: 15.513067245483398
Test Loss:  897.0848388671875
Valid Loss:  851.0203247070312
Epoch:  13  	Training Loss: 876.6082763671875
Test Loss:  1.300938606262207
Valid Loss:  1.6245653629302979
Epoch:  14  	Training Loss: 2.8797073364257812
Test Loss:  1.245800256729126
Valid Loss:  1.5702948570251465
Epoch:  15  	Training Loss: 2.804663896560669
Test Loss:  1.2159048318862915
Valid Loss:  1.541123390197754
Epoch:  16  	Training Loss: 2.765183687210083
Test Loss:  1.1961325407028198
Valid Loss:  1.5242422819137573
Epoch:  17  	Training Loss: 2.7385382652282715
Test Loss:  1.1833680868148804
Valid Loss:  1.5114974975585938
Epoch:  18  	Training Loss: 2.7191290855407715
Test Loss:  1.1740272045135498
Valid Loss:  1.4998801946640015
Epoch:  19  	Training Loss: 2.702256202697754
Test Loss:  1.1665233373641968
Valid Loss:  1.4903311729431152
Epoch:  20  	Training Loss: 2.6882176399230957
Test Loss:  1.160221815109253
Valid Loss:  1.481428861618042
Epoch:  21  	Training Loss: 2.6755268573760986
Test Loss:  1.1549358367919922
Valid Loss:  1.4734876155853271
Epoch:  22  	Training Loss: 2.6648852825164795
Test Loss:  11.104644775390625
Valid Loss:  9.828712463378906
Epoch:  23  	Training Loss: 11.122272491455078
Test Loss:  1.8781524896621704
Valid Loss:  2.1011881828308105
Epoch:  24  	Training Loss: 2.115968704223633
Test Loss:  0.7044609785079956
Valid Loss:  0.8429967164993286
Epoch:  25  	Training Loss: 1.1912121772766113
Test Loss:  0.4154849052429199
Valid Loss:  0.6015631556510925
Epoch:  26  	Training Loss: 0.9575200080871582
Test Loss:  0.38675278425216675
Valid Loss:  0.5786166191101074
Epoch:  27  	Training Loss: 0.9221718907356262
Test Loss:  0.3715820610523224
Valid Loss:  0.5647380352020264
Epoch:  28  	Training Loss: 0.9024819135665894
Test Loss:  0.3628557026386261
Valid Loss:  0.5547994375228882
Epoch:  29  	Training Loss: 0.8894277215003967
Test Loss:  0.3558664321899414
Valid Loss:  0.5469319820404053
Epoch:  30  	Training Loss: 0.8791184425354004
Test Loss:  0.3502299189567566
Valid Loss:  0.540622353553772
Epoch:  31  	Training Loss: 0.8709423542022705
Test Loss:  0.34546801447868347
Valid Loss:  0.5350471138954163
Epoch:  32  	Training Loss: 0.8637936115264893
Test Loss:  0.1842244267463684
Valid Loss:  0.15688690543174744
Epoch:  33  	Training Loss: 0.3760504722595215
Test Loss:  0.15210890769958496
Valid Loss:  0.13998499512672424
Epoch:  34  	Training Loss: 0.3710669279098511
Test Loss:  0.1430138498544693
Valid Loss:  0.1356012225151062
Epoch:  35  	Training Loss: 0.37057235836982727
Test Loss:  0.14023810625076294
Valid Loss:  0.13430720567703247
Epoch:  36  	Training Loss: 0.37052080035209656
Test Loss:  0.13937172293663025
Valid Loss:  0.13390778005123138
Epoch:  37  	Training Loss: 0.3705146908760071
Test Loss:  0.13909921050071716
Valid Loss:  0.13378256559371948
Epoch:  38  	Training Loss: 0.3705134391784668
Test Loss:  0.13901323080062866
Valid Loss:  0.1337430477142334
Epoch:  39  	Training Loss: 0.37051278352737427
Test Loss:  0.13898596167564392
Valid Loss:  0.1337304413318634
Epoch:  40  	Training Loss: 0.3705122470855713
Test Loss:  0.1389772742986679
Valid Loss:  0.13372641801834106
Epoch:  41  	Training Loss: 0.37051165103912354
Test Loss:  0.1389743983745575
Valid Loss:  0.13372500240802765
Epoch:  42  	Training Loss: 0.37051117420196533
Test Loss:  0.13880035281181335
Valid Loss:  0.13346236944198608
Epoch:  43  	Training Loss: 0.3703001141548157
Test Loss:  0.13895994424819946
Valid Loss:  0.13353516161441803
Epoch:  44  	Training Loss: 0.370299369096756
Test Loss:  0.13897402584552765
Valid Loss:  0.13354156911373138
Epoch:  45  	Training Loss: 0.3702988624572754
Test Loss:  0.138975128531456
Valid Loss:  0.133542001247406
Epoch:  46  	Training Loss: 0.3702983260154724
Test Loss:  0.1389750838279724
Valid Loss:  0.13354188203811646
Epoch:  47  	Training Loss: 0.3702978789806366
Test Loss:  0.13897490501403809
Valid Loss:  0.13354170322418213
Epoch:  48  	Training Loss: 0.3702974021434784
Test Loss:  0.13897472620010376
Valid Loss:  0.13354156911373138
Epoch:  49  	Training Loss: 0.3702968955039978
Test Loss:  0.13897456228733063
Valid Loss:  0.13354140520095825
Epoch:  50  	Training Loss: 0.3702964186668396
Test Loss:  0.1389743983745575
Valid Loss:  0.1335412710905075
Epoch:  51  	Training Loss: 0.3702959418296814
Test Loss:  0.13897423446178436
Valid Loss:  0.13354112207889557
Epoch:  52  	Training Loss: 0.3702954649925232
Test Loss:  0.13761834800243378
Valid Loss:  0.13267745077610016
Epoch:  53  	Training Loss: 0.3696078658103943
Test Loss:  0.13770607113838196
Valid Loss:  0.132717102766037
Epoch:  54  	Training Loss: 0.3696061372756958
Test Loss:  0.13778682053089142
Valid Loss:  0.13275359570980072
Epoch:  55  	Training Loss: 0.36960455775260925
Test Loss:  0.13786104321479797
Valid Loss:  0.13278715312480927
Epoch:  56  	Training Loss: 0.3696029782295227
Test Loss:  0.13792935013771057
Valid Loss:  0.1328180879354477
Epoch:  57  	Training Loss: 0.3696015477180481
Test Loss:  0.13799214363098145
Valid Loss:  0.13284647464752197
Epoch:  58  	Training Loss: 0.3696001172065735
Test Loss:  0.1380499005317688
Valid Loss:  0.13287261128425598
Epoch:  59  	Training Loss: 0.3695988059043884
Test Loss:  0.13810302317142487
Valid Loss:  0.13289664685726166
Epoch:  60  	Training Loss: 0.3695974349975586
Test Loss:  0.1381518840789795
Valid Loss:  0.13291877508163452
Epoch:  61  	Training Loss: 0.36959609389305115
Test Loss:  0.13819676637649536
Valid Loss:  0.13293908536434174
Epoch:  62  	Training Loss: 0.3695945739746094
Test Loss:  0.182649165391922
Valid Loss:  0.13829950988292694
Epoch:  63  	Training Loss: 0.23885905742645264
Test Loss:  0.05115830898284912
Valid Loss:  0.10982337594032288
Epoch:  64  	Training Loss: 0.30100175738334656
Test Loss:  0.7119859457015991
Valid Loss:  0.5330756902694702
Epoch:  65  	Training Loss: 0.6086475849151611
Test Loss:  0.0937550738453865
Valid Loss:  0.07616982609033585
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.18324901163578033
Test Loss:  0.0791921317577362
Valid Loss:  0.06595952808856964
Epoch:  67  	Training Loss: 0.172842875123024
Test Loss:  0.06914032250642776
Valid Loss:  0.05947849527001381
Epoch:  68  	Training Loss: 0.16573718190193176
Test Loss:  0.06159086897969246
Valid Loss:  0.05514160916209221
Epoch:  69  	Training Loss: 0.16045138239860535
Test Loss:  0.055909186601638794
Valid Loss:  0.05232904106378555
Epoch:  70  	Training Loss: 0.156516432762146
Test Loss:  0.05162550508975983
Valid Loss:  0.05059436708688736
Epoch:  71  	Training Loss: 0.15358629822731018
Test Loss:  0.04838985204696655
Valid Loss:  0.04961329698562622
Epoch:  72  	Training Loss: 0.15140405297279358
Test Loss:  0.053683362901210785
Valid Loss:  0.05167863517999649
Epoch:  73  	Training Loss: 0.15109562873840332
Test Loss:  0.05070105940103531
Valid Loss:  0.050490524619817734
 15%|█▍        | 73/500 [01:02<07:46,  1.09s/it] 15%|█▌        | 75/500 [01:02<05:33,  1.27it/s] 15%|█▌        | 77/500 [01:02<04:00,  1.76it/s] 16%|█▌        | 79/500 [01:02<02:56,  2.39it/s] 16%|█▌        | 81/500 [01:09<08:54,  1.28s/it] 17%|█▋        | 83/500 [01:09<06:20,  1.10it/s] 17%|█▋        | 85/500 [01:09<04:35,  1.51it/s] 17%|█▋        | 87/500 [01:09<03:22,  2.04it/s] 18%|█▊        | 89/500 [01:09<02:31,  2.72it/s] 18%|█▊        | 91/500 [01:16<08:19,  1.22s/it] 19%|█▊        | 93/500 [01:16<05:56,  1.14it/s] 19%|█▉        | 95/500 [01:16<04:16,  1.58it/s] 19%|█▉        | 97/500 [01:16<03:06,  2.16it/s] 20%|█▉        | 99/500 [01:16<02:18,  2.90it/s] 20%|██        | 101/500 [01:23<08:10,  1.23s/it] 21%|██        | 103/500 [01:23<05:52,  1.13it/s] 21%|██        | 105/500 [01:23<04:13,  1.56it/s] 21%|██▏       | 107/500 [01:23<03:04,  2.13it/s] 22%|██▏       | 109/500 [01:23<02:16,  2.87it/s] 22%|██▏       | 111/500 [01:36<14:01,  2.16s/it] 23%|██▎       | 113/500 [01:36<09:54,  1.54s/it] 23%|██▎       | 115/500 [01:36<07:03,  1.10s/it] 23%|██▎       | 117/500 [01:37<05:02,  1.27it/s] 24%|██▍       | 119/500 [01:37<03:38,  1.74it/s] 24%|██▍       | 121/500 [01:43<08:47,  1.39s/it] 25%|██▍       | 123/500 [01:43<06:14,  1.01it/s] 25%|██▌       | 125/500 [01:44<04:28,  1.40it/s] 25%|██▌       | 127/500 [01:44<03:14,  1.92it/s] 26%|██▌       | 129/500 [01:44<02:23,  2.58it/s] 26%|██▌       | 131/500 [01:50<07:47,  1.27s/it] 27%|██▋       | 133/500 [01:51<05:32,  1.10it/s] 27%|██▋       | 135/500 [01:51<03:58,  1.53it/s] 27%|██▋       | 137/500 [01:51<02:53,  2.10it/s] 28%|██▊       | 139/500 [01:51<02:07,  2.83it/s] 28%|██▊       | 141/500 [01:57<07:15,  1.21s/it] 29%|██▊       | 143/500 [01:58<05:10,  1.15it/s]Epoch:  74  	Training Loss: 0.15104162693023682
Test Loss:  0.051724497228860855
Valid Loss:  0.05087509751319885
Epoch:  75  	Training Loss: 0.15103000402450562
Test Loss:  0.051358774304389954
Valid Loss:  0.05072934180498123
Epoch:  76  	Training Loss: 0.15102526545524597
Test Loss:  0.05149867385625839
Valid Loss:  0.05078157037496567
Epoch:  77  	Training Loss: 0.15102329850196838
Test Loss:  0.051475830376148224
Valid Loss:  0.05077171325683594
Epoch:  78  	Training Loss: 0.151022270321846
Test Loss:  0.05150316655635834
Valid Loss:  0.05078234523534775
Epoch:  79  	Training Loss: 0.15102137625217438
Test Loss:  0.051478806883096695
Valid Loss:  0.050772227346897125
Epoch:  80  	Training Loss: 0.15102049708366394
Test Loss:  0.05150017887353897
Valid Loss:  0.05078056454658508
Epoch:  81  	Training Loss: 0.15101957321166992
Test Loss:  0.05149323493242264
Valid Loss:  0.05077791586518288
Epoch:  82  	Training Loss: 0.1510186791419983
Test Loss:  0.051492802798748016
Valid Loss:  0.05077764391899109
Epoch:  83  	Training Loss: 0.15083622932434082
Test Loss:  0.051485151052474976
Valid Loss:  0.05077465623617172
Epoch:  84  	Training Loss: 0.15083563327789307
Test Loss:  0.05147963762283325
Valid Loss:  0.0507725365459919
Epoch:  85  	Training Loss: 0.15083558857440948
Test Loss:  0.051475681364536285
Valid Loss:  0.05077100545167923
Epoch:  86  	Training Loss: 0.1508355587720871
Test Loss:  0.051472850143909454
Valid Loss:  0.050769902765750885
Epoch:  87  	Training Loss: 0.1508355289697647
Test Loss:  0.0514708012342453
Valid Loss:  0.050769105553627014
Epoch:  88  	Training Loss: 0.15083548426628113
Test Loss:  0.05146932601928711
Valid Loss:  0.05076853185892105
Epoch:  89  	Training Loss: 0.15083545446395874
Test Loss:  0.05146827548742294
Valid Loss:  0.05076812207698822
Epoch:  90  	Training Loss: 0.15083542466163635
Test Loss:  0.05146751552820206
Valid Loss:  0.05076783150434494
Epoch:  91  	Training Loss: 0.15083539485931396
Test Loss:  0.05146694928407669
Valid Loss:  0.05076761171221733
Epoch:  92  	Training Loss: 0.15083536505699158
Test Loss:  0.05025884509086609
Valid Loss:  0.050893448293209076
Epoch:  93  	Training Loss: 0.1380344033241272
Test Loss:  0.05141838267445564
Valid Loss:  0.0515352338552475
Epoch:  94  	Training Loss: 0.13047155737876892
Test Loss:  0.05152100697159767
Valid Loss:  0.05300723388791084
Epoch:  95  	Training Loss: 0.12427587807178497
Test Loss:  0.05041510611772537
Valid Loss:  0.05441214516758919
Epoch:  96  	Training Loss: 0.11945205926895142
Test Loss:  0.049313925206661224
Valid Loss:  0.056023333221673965
Epoch:  97  	Training Loss: 0.11525632441043854
Test Loss:  0.04836967587471008
Valid Loss:  0.05833561718463898
Epoch:  98  	Training Loss: 0.1108003556728363
Test Loss:  0.04775543138384819
Valid Loss:  0.06057450920343399
Epoch:  99  	Training Loss: 0.1066560447216034
Test Loss:  0.046817488968372345
Valid Loss:  0.06288085877895355
Epoch:  100  	Training Loss: 0.10265480726957321
Test Loss:  0.04530633985996246
Valid Loss:  0.0645187571644783
Epoch:  101  	Training Loss: 0.09749167412519455
Test Loss:  0.044065121561288834
Valid Loss:  0.06489598751068115
Epoch:  102  	Training Loss: 0.09108132123947144
Test Loss:  0.03932415693998337
Valid Loss:  0.06584761291742325
Epoch:  103  	Training Loss: 0.08277151733636856
Test Loss:  0.038113534450531006
Valid Loss:  0.0595506951212883
Epoch:  104  	Training Loss: 0.07379359006881714
Test Loss:  0.03462078422307968
Valid Loss:  0.05784390866756439
Epoch:  105  	Training Loss: 0.06973065435886383
Test Loss:  0.03889857605099678
Valid Loss:  0.05915740877389908
Epoch:  106  	Training Loss: 0.06964719295501709
Test Loss:  0.03246082738041878
Valid Loss:  0.05667927488684654
Epoch:  107  	Training Loss: 0.07204361259937286
Test Loss:  0.041909608989953995
Valid Loss:  0.057210758328437805
Epoch:  108  	Training Loss: 0.07298171520233154
Test Loss:  0.03187135234475136
Valid Loss:  0.057075079530477524
Epoch:  109  	Training Loss: 0.07453864067792892
Test Loss:  0.04755782335996628
Valid Loss:  0.05968853831291199
Epoch:  110  	Training Loss: 0.07694724202156067
Test Loss:  0.03375634923577309
Valid Loss:  0.06096400320529938
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.08122891187667847
Test Loss:  0.03033815510571003
Valid Loss:  0.05238204449415207
Epoch:  112  	Training Loss: 0.07034698128700256
Test Loss:  0.029696330428123474
Valid Loss:  0.051067911088466644
Epoch:  113  	Training Loss: 0.06986117362976074
Test Loss:  0.029138777405023575
Valid Loss:  0.04988861829042435
Epoch:  114  	Training Loss: 0.06943845748901367
Test Loss:  0.028654396533966064
Valid Loss:  0.04882904142141342
Epoch:  115  	Training Loss: 0.06907051801681519
Test Loss:  0.028233569115400314
Valid Loss:  0.04787581413984299
Epoch:  116  	Training Loss: 0.06875013560056686
Test Loss:  0.02786792442202568
Valid Loss:  0.0470171757042408
Epoch:  117  	Training Loss: 0.06847113370895386
Test Loss:  0.02755023166537285
Valid Loss:  0.0462430864572525
Epoch:  118  	Training Loss: 0.0682281106710434
Test Loss:  0.027274183928966522
Valid Loss:  0.045544251799583435
Epoch:  119  	Training Loss: 0.06801619380712509
Test Loss:  0.02703430876135826
Valid Loss:  0.044912464916706085
Epoch:  120  	Training Loss: 0.06783151626586914
Test Loss:  0.026825837790966034
Valid Loss:  0.044340744614601135
Epoch:  121  	Training Loss: 0.0676702931523323
Test Loss:  0.026644788682460785
Valid Loss:  0.043823059648275375
Epoch:  122  	Training Loss: 0.06752943992614746
Test Loss:  0.027599340304732323
Valid Loss:  0.04396195709705353
Epoch:  123  	Training Loss: 0.06734644621610641
Test Loss:  0.027837788686156273
Valid Loss:  0.04401245713233948
Epoch:  124  	Training Loss: 0.06733560562133789
Test Loss:  0.02788839116692543
Valid Loss:  0.04401753097772598
Epoch:  125  	Training Loss: 0.06733351945877075
Test Loss:  0.027895435690879822
Valid Loss:  0.044011082500219345
Epoch:  126  	Training Loss: 0.06733186542987823
Test Loss:  0.027892641723155975
Valid Loss:  0.044002000242471695
Epoch:  127  	Training Loss: 0.06733022630214691
Test Loss:  0.027887629345059395
Valid Loss:  0.04399231821298599
Epoch:  128  	Training Loss: 0.06732860207557678
Test Loss:  0.027882125228643417
Valid Loss:  0.043982524424791336
Epoch:  129  	Training Loss: 0.06732698529958725
Test Loss:  0.027876537293195724
Valid Loss:  0.04397270828485489
Epoch:  130  	Training Loss: 0.06732536852359772
Test Loss:  0.027870919555425644
Valid Loss:  0.04396290332078934
Epoch:  131  	Training Loss: 0.06732375919818878
Test Loss:  0.027865298092365265
Valid Loss:  0.04395311325788498
Epoch:  132  	Training Loss: 0.06732213497161865
Test Loss:  0.027865640819072723
Valid Loss:  0.043953731656074524
Epoch:  133  	Training Loss: 0.06731575727462769
Test Loss:  0.027865968644618988
Valid Loss:  0.043954361230134964
Epoch:  134  	Training Loss: 0.06730946898460388
Test Loss:  0.027866283431649208
Valid Loss:  0.04395496845245361
Epoch:  135  	Training Loss: 0.0673035979270935
Test Loss:  0.027866585180163383
Valid Loss:  0.04395555332303047
Epoch:  136  	Training Loss: 0.06729806214570999
Test Loss:  0.027866868302226067
Valid Loss:  0.04395611584186554
Epoch:  137  	Training Loss: 0.06729268282651901
Test Loss:  0.02786714769899845
Valid Loss:  0.043956685811281204
Epoch:  138  	Training Loss: 0.06728729605674744
Test Loss:  0.02786741778254509
Valid Loss:  0.043957263231277466
Epoch:  139  	Training Loss: 0.06728193163871765
Test Loss:  0.027867663651704788
Valid Loss:  0.043957799673080444
Epoch:  140  	Training Loss: 0.06727674603462219
Test Loss:  0.027867909520864487
Valid Loss:  0.043958358466625214
Epoch:  141  	Training Loss: 0.06727166473865509
Test Loss:  0.02786814421415329
Valid Loss:  0.043959006667137146
Epoch:  142  	Training Loss: 0.06726683676242828
Test Loss:  0.02786833792924881
Valid Loss:  0.04395988583564758
Epoch:  143  	Training Loss: 0.06726221740245819
Test Loss:  0.027868501842021942
Valid Loss:  0.04396069794893265
Epoch:  144  	Training Loss: 0.06725797057151794
Test Loss:   29%|██▉       | 145/500 [01:58<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:58<02:43,  2.16it/s] 30%|██▉       | 149/500 [01:58<02:00,  2.91it/s] 30%|███       | 151/500 [02:04<06:57,  1.20s/it] 31%|███       | 153/500 [02:05<04:59,  1.16it/s] 31%|███       | 155/500 [02:05<03:35,  1.60it/s] 31%|███▏      | 157/500 [02:05<02:36,  2.19it/s] 32%|███▏      | 159/500 [02:05<01:55,  2.94it/s] 32%|███▏      | 161/500 [02:11<06:49,  1.21s/it] 33%|███▎      | 163/500 [02:12<04:51,  1.15it/s] 33%|███▎      | 165/500 [02:12<03:29,  1.60it/s] 33%|███▎      | 167/500 [02:12<02:32,  2.18it/s] 34%|███▍      | 169/500 [02:12<01:52,  2.93it/s] 34%|███▍      | 171/500 [02:18<06:37,  1.21s/it] 35%|███▍      | 173/500 [02:19<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:19<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:19<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:19<01:50,  2.92it/s] 36%|███▌      | 181/500 [02:26<06:29,  1.22s/it] 37%|███▋      | 183/500 [02:26<04:38,  1.14it/s] 37%|███▋      | 185/500 [02:26<03:20,  1.57it/s] 37%|███▋      | 187/500 [02:26<02:25,  2.15it/s] 38%|███▊      | 189/500 [02:26<01:48,  2.88it/s] 38%|███▊      | 191/500 [02:33<06:30,  1.26s/it] 38%|███▊      | 192/500 [02:33<05:32,  1.08s/it] 39%|███▊      | 193/500 [02:33<04:35,  1.12it/s] 39%|███▉      | 194/500 [02:33<03:40,  1.39it/s] 39%|███▉      | 196/500 [02:34<02:21,  2.15it/s] 40%|███▉      | 198/500 [02:34<01:37,  3.10it/s] 40%|████      | 200/500 [02:34<01:10,  4.24it/s] 40%|████      | 202/500 [02:40<06:10,  1.24s/it] 41%|████      | 204/500 [02:41<04:17,  1.15it/s] 41%|████      | 206/500 [02:41<03:01,  1.62it/s] 42%|████▏     | 208/500 [02:41<02:10,  2.23it/s] 42%|████▏     | 210/500 [02:41<01:35,  3.02it/s] 42%|████▏     | 212/500 [02:48<05:58,  1.24s/it] 43%|████▎     | 214/500 [02:48<04:14,  1.13it/s]0.027868665754795074
Valid Loss:  0.04396152123808861
Epoch:  145  	Training Loss: 0.06725373864173889
Test Loss:  0.027868814766407013
Valid Loss:  0.04396234452724457
Epoch:  146  	Training Loss: 0.06724950671195984
Test Loss:  0.02786894515156746
Valid Loss:  0.04396316409111023
Epoch:  147  	Training Loss: 0.06724526733160019
Test Loss:  0.02786909230053425
Valid Loss:  0.04396400600671768
Epoch:  148  	Training Loss: 0.06724107265472412
Test Loss:  0.02786920592188835
Valid Loss:  0.04396512359380722
Epoch:  149  	Training Loss: 0.0672370120882988
Test Loss:  0.02786930464208126
Valid Loss:  0.043966226279735565
Epoch:  150  	Training Loss: 0.06723297387361526
Test Loss:  0.02786940708756447
Valid Loss:  0.04396732151508331
Epoch:  151  	Training Loss: 0.06722906231880188
Test Loss:  0.027869490906596184
Valid Loss:  0.04396851733326912
Epoch:  152  	Training Loss: 0.06722520291805267
Test Loss:  0.027854938060045242
Valid Loss:  0.04396567493677139
Epoch:  153  	Training Loss: 0.06722146272659302
Test Loss:  0.027849379926919937
Valid Loss:  0.04396539181470871
Epoch:  154  	Training Loss: 0.06721782684326172
Test Loss:  0.027846936136484146
Valid Loss:  0.043966129422187805
Epoch:  155  	Training Loss: 0.0672144740819931
Test Loss:  0.027845554053783417
Valid Loss:  0.04396715760231018
Epoch:  156  	Training Loss: 0.06721121072769165
Test Loss:  0.027844559401273727
Valid Loss:  0.04396827146410942
Epoch:  157  	Training Loss: 0.067207932472229
Test Loss:  0.027843685820698738
Valid Loss:  0.04396941885352135
Epoch:  158  	Training Loss: 0.06720472872257233
Test Loss:  0.02784285694360733
Valid Loss:  0.04397055506706238
Epoch:  159  	Training Loss: 0.06720161437988281
Test Loss:  0.027842044830322266
Valid Loss:  0.04397168755531311
Epoch:  160  	Training Loss: 0.06719852983951569
Test Loss:  0.027841225266456604
Valid Loss:  0.04397279769182205
Epoch:  161  	Training Loss: 0.0671955943107605
Test Loss:  0.02784041315317154
Valid Loss:  0.043973855674266815
Epoch:  162  	Training Loss: 0.06719274073839188
Test Loss:  0.02779611572623253
Valid Loss:  0.04380183294415474
Epoch:  163  	Training Loss: 0.06715837121009827
Test Loss:  0.02774583175778389
Valid Loss:  0.04363653436303139
Epoch:  164  	Training Loss: 0.06712643802165985
Test Loss:  0.027690596878528595
Valid Loss:  0.043476857244968414
Epoch:  165  	Training Loss: 0.06709641218185425
Test Loss:  0.02763129398226738
Valid Loss:  0.043322037905454636
Epoch:  166  	Training Loss: 0.06706790626049042
Test Loss:  0.027569059282541275
Valid Loss:  0.04317166283726692
Epoch:  167  	Training Loss: 0.06704066693782806
Test Loss:  0.027504414319992065
Valid Loss:  0.043025337159633636
Epoch:  168  	Training Loss: 0.06701461225748062
Test Loss:  0.027437835931777954
Valid Loss:  0.042882632464170456
Epoch:  169  	Training Loss: 0.06698949635028839
Test Loss:  0.027369804680347443
Valid Loss:  0.042743243277072906
Epoch:  170  	Training Loss: 0.06696542352437973
Test Loss:  0.027300767600536346
Valid Loss:  0.042606886476278305
Epoch:  171  	Training Loss: 0.06694228947162628
Test Loss:  0.02723109722137451
Valid Loss:  0.04247365519404411
Epoch:  172  	Training Loss: 0.0669199526309967
Test Loss:  0.027027413249015808
Valid Loss:  0.04240848124027252
Epoch:  173  	Training Loss: 0.06691278517246246
Test Loss:  0.02695396915078163
Valid Loss:  0.04238585755228996
Epoch:  174  	Training Loss: 0.06691180169582367
Test Loss:  0.026927141472697258
Valid Loss:  0.042377665638923645
Epoch:  175  	Training Loss: 0.06691164523363113
Test Loss:  0.02691725455224514
Valid Loss:  0.042374614626169205
Epoch:  176  	Training Loss: 0.06691162288188934
Test Loss:  0.026913585141301155
Valid Loss:  0.04237343743443489
Epoch:  177  	Training Loss: 0.06691160798072815
Test Loss:  0.02691219560801983
Valid Loss:  0.042372927069664
Epoch:  178  	Training Loss: 0.06691159307956696
Test Loss:  0.026911646127700806
Valid Loss:  0.04237266629934311
Epoch:  179  	Training Loss: 0.06691158562898636
Test Loss:  0.026911407709121704
Valid Loss:  0.04237249866127968
Epoch:  180  	Training Loss: 0.06691157817840576
Test Loss:  0.02691126987338066
Valid Loss:  0.042372364550828934
Epoch:  181  	Training Loss: 0.06691157817840576
Test Loss:  0.026911191642284393
Valid Loss:  0.04237225279211998
Epoch:  182  	Training Loss: 0.06691156327724457
Test Loss:  0.026880010962486267
Valid Loss:  0.0422343835234642
Epoch:  183  	Training Loss: 0.06688931584358215
Test Loss:  0.02683829516172409
Valid Loss:  0.04209965094923973
Epoch:  184  	Training Loss: 0.06686871498823166
Test Loss:  0.026788828894495964
Valid Loss:  0.04196770116686821
Epoch:  185  	Training Loss: 0.06684930622577667
Test Loss:  0.02673383057117462
Valid Loss:  0.04183836281299591
Epoch:  186  	Training Loss: 0.0668308287858963
Test Loss:  0.02667500264942646
Valid Loss:  0.04171149805188179
Epoch:  187  	Training Loss: 0.06681311130523682
Test Loss:  0.026613600552082062
Valid Loss:  0.04158704727888107
Epoch:  188  	Training Loss: 0.06679607927799225
Test Loss:  0.026550624519586563
Valid Loss:  0.04146495461463928
Epoch:  189  	Training Loss: 0.06677967309951782
Test Loss:  0.026486782357096672
Valid Loss:  0.04134521633386612
Epoch:  190  	Training Loss: 0.06676384806632996
Test Loss:  0.026422634720802307
Valid Loss:  0.04122774302959442
Epoch:  191  	Training Loss: 0.06674857437610626
Test Loss:  0.026358554139733315
Valid Loss:  0.04111256077885628
Epoch:  192  	Training Loss: 0.06673381477594376
Test Loss:  0.026164580136537552
Valid Loss:  0.0409516766667366
Epoch:  193  	Training Loss: 0.06671346724033356
Test Loss:  0.026079457253217697
Valid Loss:  0.04082251712679863
Epoch:  194  	Training Loss: 0.06669525802135468
Test Loss:  0.026006657630205154
Valid Loss:  0.040698930621147156
Epoch:  195  	Training Loss: 0.06667778640985489
Test Loss:  0.02593659795820713
Valid Loss:  0.0405784547328949
Epoch:  196  	Training Loss: 0.06666088849306107
Test Loss:  0.0258682519197464
Valid Loss:  0.04046076536178589
Epoch:  197  	Training Loss: 0.06664451956748962
Test Loss:  0.025801481679081917
Valid Loss:  0.04034573957324028
Epoch:  198  	Training Loss: 0.06662870943546295
Test Loss:  0.02573620341718197
Valid Loss:  0.04023323208093643
Epoch:  199  	Training Loss: 0.0666135847568512
Test Loss:  0.025672420859336853
Valid Loss:  0.04012328386306763
Epoch:  200  	Training Loss: 0.06659895181655884
Test Loss:  0.02561022900044918
Valid Loss:  0.04001577943563461
Epoch:  201  	Training Loss: 0.06658477336168289
Test Loss:  0.02554949000477791
Valid Loss:  0.039910707622766495
Epoch:  202  	Training Loss: 0.06657104939222336
Test Loss:  0.025564927607774734
Valid Loss:  0.03901821747422218
Epoch:  203  	Training Loss: 0.05843055248260498
Test Loss:  0.025345586240291595
Valid Loss:  0.037686027586460114
Epoch:  204  	Training Loss: 0.05243830755352974
Test Loss:  0.024945005774497986
Valid Loss:  0.036588698625564575
Epoch:  205  	Training Loss: 0.04784145578742027
Test Loss:  0.024278290569782257
Valid Loss:  0.0356966070830822
Epoch:  206  	Training Loss: 0.044099703431129456
Test Loss:  0.023689160123467445
Valid Loss:  0.03500897437334061
Epoch:  207  	Training Loss: 0.041130393743515015
Test Loss:  0.02320355921983719
Valid Loss:  0.0345001146197319
Epoch:  208  	Training Loss: 0.03871206194162369
Test Loss:  0.022830309346318245
Valid Loss:  0.034132134169340134
Epoch:  209  	Training Loss: 0.036704543977975845
Test Loss:  0.022554093971848488
Valid Loss:  0.033888936042785645
Epoch:  210  	Training Loss: 0.035025306046009064
Test Loss:  0.022372402250766754
Valid Loss:  0.03373056650161743
Epoch:  211  	Training Loss: 0.03352132812142372
Test Loss:  0.022268623113632202
Valid Loss:  0.033641934394836426
Epoch:  212  	Training Loss: 0.03214094787836075
Test Loss:  0.02218914031982422
Valid Loss:  0.033472634851932526
Epoch:  213  	Training Loss: 0.03208358585834503
Test Loss:  0.02211177349090576
Valid Loss:  0.03330680727958679
Epoch:  214  	Training Loss: 0.032027777284383774
Test Loss:  0.022036436945199966
Valid Loss:  0.03314431756734848
Epoch:  215  	Training Loss: 0.031973473727703094
Test Loss:  0.02196311019361019
Valid Loss:   43%|████▎     | 216/500 [02:48<03:01,  1.56it/s] 44%|████▎     | 218/500 [02:48<02:11,  2.14it/s] 44%|████▍     | 220/500 [02:48<01:37,  2.88it/s] 44%|████▍     | 222/500 [02:55<05:41,  1.23s/it] 45%|████▍     | 224/500 [02:55<04:04,  1.13it/s] 45%|████▌     | 226/500 [02:55<02:56,  1.55it/s] 46%|████▌     | 228/500 [02:55<02:09,  2.10it/s] 46%|████▌     | 230/500 [02:55<01:35,  2.84it/s] 46%|████▋     | 232/500 [03:02<05:25,  1.21s/it] 47%|████▋     | 234/500 [03:02<03:51,  1.15it/s] 47%|████▋     | 236/500 [03:02<02:45,  1.59it/s] 48%|████▊     | 238/500 [03:02<02:00,  2.17it/s] 48%|████▊     | 240/500 [03:02<01:28,  2.93it/s] 48%|████▊     | 242/500 [03:09<05:12,  1.21s/it] 49%|████▉     | 244/500 [03:09<03:42,  1.15it/s] 49%|████▉     | 246/500 [03:09<02:39,  1.59it/s] 50%|████▉     | 248/500 [03:09<01:55,  2.18it/s] 50%|█████     | 250/500 [03:16<05:39,  1.36s/it] 50%|█████     | 251/500 [03:23<09:18,  2.24s/it] 51%|█████     | 253/500 [03:23<06:14,  1.52s/it] 51%|█████     | 255/500 [03:23<04:16,  1.05s/it] 51%|█████▏    | 257/500 [03:23<02:58,  1.36it/s] 52%|█████▏    | 259/500 [03:23<02:07,  1.90it/s] 52%|█████▏    | 261/500 [03:29<05:23,  1.35s/it] 53%|█████▎    | 263/500 [03:30<03:47,  1.04it/s] 53%|█████▎    | 265/500 [03:30<02:41,  1.45it/s] 53%|█████▎    | 267/500 [03:30<01:56,  2.00it/s] 54%|█████▍    | 269/500 [03:30<01:24,  2.72it/s] 54%|█████▍    | 271/500 [03:36<04:38,  1.22s/it] 55%|█████▍    | 273/500 [03:37<03:18,  1.14it/s] 55%|█████▌    | 275/500 [03:37<02:22,  1.58it/s] 55%|█████▌    | 277/500 [03:37<01:43,  2.16it/s] 56%|█████▌    | 279/500 [03:37<01:15,  2.91it/s] 56%|█████▌    | 281/500 [03:43<04:27,  1.22s/it] 57%|█████▋    | 283/500 [03:44<03:10,  1.14it/s]0.03298515826463699
Epoch:  216  	Training Loss: 0.031920649111270905
Test Loss:  0.02189173549413681
Valid Loss:  0.03282921761274338
Epoch:  217  	Training Loss: 0.03186924755573273
Test Loss:  0.0218222476541996
Valid Loss:  0.03267642483115196
Epoch:  218  	Training Loss: 0.03181925415992737
Test Loss:  0.02175460197031498
Valid Loss:  0.03252674639225006
Epoch:  219  	Training Loss: 0.03177060931921005
Test Loss:  0.021688755601644516
Valid Loss:  0.03238006681203842
Epoch:  220  	Training Loss: 0.031723275780677795
Test Loss:  0.021624645218253136
Valid Loss:  0.032236333936452866
Epoch:  221  	Training Loss: 0.031677234917879105
Test Loss:  0.021562237292528152
Valid Loss:  0.03209548443555832
Epoch:  222  	Training Loss: 0.0316324345767498
Test Loss:  0.02129537984728813
Valid Loss:  0.032088812440633774
Epoch:  223  	Training Loss: 0.03143593668937683
Test Loss:  0.021107811480760574
Valid Loss:  0.0320829376578331
Epoch:  224  	Training Loss: 0.03130895271897316
Test Loss:  0.020967092365026474
Valid Loss:  0.03206644207239151
Epoch:  225  	Training Loss: 0.03122018277645111
Test Loss:  0.020854637026786804
Valid Loss:  0.03203601762652397
Epoch:  226  	Training Loss: 0.03115248493850231
Test Loss:  0.020759636536240578
Valid Loss:  0.03199209272861481
Epoch:  227  	Training Loss: 0.031096437945961952
Test Loss:  0.020675726234912872
Valid Loss:  0.03193645179271698
Epoch:  228  	Training Loss: 0.031046897172927856
Test Loss:  0.020599083974957466
Valid Loss:  0.03187127411365509
Epoch:  229  	Training Loss: 0.031001035124063492
Test Loss:  0.020527323707938194
Valid Loss:  0.03179863467812538
Epoch:  230  	Training Loss: 0.030957307666540146
Test Loss:  0.02045898139476776
Valid Loss:  0.03172032907605171
Epoch:  231  	Training Loss: 0.030914869159460068
Test Loss:  0.020393090322613716
Valid Loss:  0.031637825071811676
Epoch:  232  	Training Loss: 0.0308732520788908
Test Loss:  0.020456749945878983
Valid Loss:  0.03133229911327362
Epoch:  233  	Training Loss: 0.029536323621869087
Test Loss:  0.020477326586842537
Valid Loss:  0.031087733805179596
Epoch:  234  	Training Loss: 0.028492093086242676
Test Loss:  0.020413512364029884
Valid Loss:  0.030885275453329086
Epoch:  235  	Training Loss: 0.027635589241981506
Test Loss:  0.020349428057670593
Valid Loss:  0.030717290937900543
Epoch:  236  	Training Loss: 0.02696365863084793
Test Loss:  0.020285066217184067
Valid Loss:  0.03057447262108326
Epoch:  237  	Training Loss: 0.02643274888396263
Test Loss:  0.020220454782247543
Valid Loss:  0.03044985793530941
Epoch:  238  	Training Loss: 0.026000160723924637
Test Loss:  0.020155608654022217
Valid Loss:  0.030338289216160774
Epoch:  239  	Training Loss: 0.025623543187975883
Test Loss:  0.020090557634830475
Valid Loss:  0.030236899852752686
Epoch:  240  	Training Loss: 0.02531295083463192
Test Loss:  0.020025335252285004
Valid Loss:  0.03014354407787323
Epoch:  241  	Training Loss: 0.025020239874720573
Test Loss:  0.019959960132837296
Valid Loss:  0.030057115480303764
Epoch:  242  	Training Loss: 0.024754438549280167
Test Loss:  0.01978922076523304
Valid Loss:  0.030843494459986687
Epoch:  243  	Training Loss: 0.02410157024860382
Test Loss:  0.019855808466672897
Valid Loss:  0.031137416139245033
Epoch:  244  	Training Loss: 0.024062763899564743
Test Loss:  0.019878439605236053
Valid Loss:  0.03121507167816162
Epoch:  245  	Training Loss: 0.024060439318418503
Test Loss:  0.01988433487713337
Valid Loss:  0.031234340742230415
Epoch:  246  	Training Loss: 0.02406030148267746
Test Loss:  0.01988578960299492
Valid Loss:  0.031239043921232224
Epoch:  247  	Training Loss: 0.024060294032096863
Test Loss:  0.019886132329702377
Valid Loss:  0.031240206211805344
Epoch:  248  	Training Loss: 0.024060288444161415
Test Loss:  0.01988622546195984
Valid Loss:  0.03124047815799713
Epoch:  249  	Training Loss: 0.024060290306806564
Test Loss:  0.019886251538991928
Valid Loss:  0.031240548938512802
Epoch:  250  	Training Loss: 0.024060288444161415
Test Loss:  0.019886257126927376
Valid Loss:  0.031240567564964294
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.024060288444161415
Test Loss:  0.01947261020541191
Valid Loss:  0.03052009642124176
Epoch:  252  	Training Loss: 0.023754820227622986
Test Loss:  0.019350148737430573
Valid Loss:  0.030307196080684662
Epoch:  253  	Training Loss: 0.023663442581892014
Test Loss:  0.019230298697948456
Valid Loss:  0.030098801478743553
Epoch:  254  	Training Loss: 0.023573745042085648
Test Loss:  0.01911291852593422
Valid Loss:  0.029894672334194183
Epoch:  255  	Training Loss: 0.023485636338591576
Test Loss:  0.018997909501194954
Valid Loss:  0.029694654047489166
Epoch:  256  	Training Loss: 0.023399032652378082
Test Loss:  0.01888512447476387
Valid Loss:  0.029498528689146042
Epoch:  257  	Training Loss: 0.023313861340284348
Test Loss:  0.018774427473545074
Valid Loss:  0.029306143522262573
Epoch:  258  	Training Loss: 0.02323004975914955
Test Loss:  0.018665742129087448
Valid Loss:  0.02911733277142048
Epoch:  259  	Training Loss: 0.023147519677877426
Test Loss:  0.018558986485004425
Valid Loss:  0.028931954875588417
Epoch:  260  	Training Loss: 0.023066218942403793
Test Loss:  0.018454037606716156
Valid Loss:  0.0287498626857996
Epoch:  261  	Training Loss: 0.022986089810729027
Test Loss:  0.01835082843899727
Valid Loss:  0.028570910915732384
Epoch:  262  	Training Loss: 0.022907080128788948
Test Loss:  0.01835111528635025
Valid Loss:  0.028574736788868904
Epoch:  263  	Training Loss: 0.022906089201569557
Test Loss:  0.018351424485445023
Valid Loss:  0.0285785049200058
Epoch:  264  	Training Loss: 0.022905122488737106
Test Loss:  0.0183517225086689
Valid Loss:  0.028582245111465454
Epoch:  265  	Training Loss: 0.022904176265001297
Test Loss:  0.018352031707763672
Valid Loss:  0.02858591452240944
Epoch:  266  	Training Loss: 0.02290325239300728
Test Loss:  0.018352342769503593
Valid Loss:  0.028589554131031036
Epoch:  267  	Training Loss: 0.02290235459804535
Test Loss:  0.018352650105953217
Valid Loss:  0.02859313413500786
Epoch:  268  	Training Loss: 0.022901475429534912
Test Loss:  0.018352966755628586
Valid Loss:  0.02859666757285595
Epoch:  269  	Training Loss: 0.022900616750121117
Test Loss:  0.018353290855884552
Valid Loss:  0.028600161895155907
Epoch:  270  	Training Loss: 0.02289978414773941
Test Loss:  0.018353596329689026
Valid Loss:  0.028603587299585342
Epoch:  271  	Training Loss: 0.022898968309164047
Test Loss:  0.018353920429944992
Valid Loss:  0.028606995940208435
Epoch:  272  	Training Loss: 0.02289816364645958
Test Loss:  0.018147563561797142
Valid Loss:  0.02823321893811226
Epoch:  273  	Training Loss: 0.022745920345187187
Test Loss:  0.01794988289475441
Valid Loss:  0.02787218987941742
Epoch:  274  	Training Loss: 0.022600125521421432
Test Loss:  0.017760513350367546
Valid Loss:  0.0275234654545784
Epoch:  275  	Training Loss: 0.022460512816905975
Test Loss:  0.0175790973007679
Valid Loss:  0.027186572551727295
Epoch:  276  	Training Loss: 0.02232683263719082
Test Loss:  0.017405308783054352
Valid Loss:  0.026861075311899185
Epoch:  277  	Training Loss: 0.022198813036084175
Test Loss:  0.017238812521100044
Valid Loss:  0.026546556502580643
Epoch:  278  	Training Loss: 0.022076230496168137
Test Loss:  0.0170793104916811
Valid Loss:  0.02624259516596794
Epoch:  279  	Training Loss: 0.02195884846150875
Test Loss:  0.01692649908363819
Valid Loss:  0.025948818773031235
Epoch:  280  	Training Loss: 0.02184644527733326
Test Loss:  0.01678011380136013
Valid Loss:  0.02566484734416008
Epoch:  281  	Training Loss: 0.021738804876804352
Test Loss:  0.01663985848426819
Valid Loss:  0.02539030835032463
Epoch:  282  	Training Loss: 0.021635737270116806
Test Loss:  0.01663840375840664
Valid Loss:  0.02539367787539959
Epoch:  283  	Training Loss: 0.02163304015994072
Test Loss:  0.016636986285448074
Valid Loss:  0.025397032499313354
Epoch:  284  	Training Loss: 0.021630387753248215
Test Loss:  0.016635574400424957
Valid Loss:  0.02540038526058197
Epoch:  285  	Training Loss: 0.021627768874168396
Test Loss:   57%|█████▋    | 285/500 [03:44<02:16,  1.58it/s] 57%|█████▋    | 287/500 [03:44<01:38,  2.16it/s] 58%|█████▊    | 289/500 [03:44<01:12,  2.90it/s] 58%|█████▊    | 291/500 [03:50<04:11,  1.20s/it] 59%|█████▊    | 293/500 [03:51<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:51<02:07,  1.60it/s] 59%|█████▉    | 297/500 [03:51<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:51<01:08,  2.95it/s] 60%|██████    | 301/500 [03:57<03:58,  1.20s/it] 61%|██████    | 303/500 [03:57<02:49,  1.16it/s] 61%|██████    | 305/500 [03:58<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:58<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:58<01:04,  2.96it/s] 62%|██████▏   | 311/500 [04:05<03:53,  1.23s/it] 63%|██████▎   | 313/500 [04:05<02:46,  1.13it/s] 63%|██████▎   | 315/500 [04:05<01:59,  1.54it/s] 63%|██████▎   | 317/500 [04:05<01:27,  2.09it/s] 64%|██████▍   | 319/500 [04:05<01:04,  2.80it/s] 64%|██████▍   | 321/500 [04:12<03:35,  1.20s/it] 65%|██████▍   | 323/500 [04:12<02:32,  1.16it/s] 65%|██████▌   | 325/500 [04:12<01:49,  1.60it/s] 65%|██████▌   | 327/500 [04:12<01:18,  2.19it/s] 66%|██████▌   | 329/500 [04:12<00:58,  2.95it/s] 66%|██████▌   | 331/500 [04:19<03:23,  1.20s/it] 67%|██████▋   | 333/500 [04:19<02:24,  1.15it/s] 67%|██████▋   | 335/500 [04:19<01:44,  1.58it/s] 67%|██████▋   | 337/500 [04:19<01:16,  2.14it/s] 68%|██████▊   | 339/500 [04:19<00:56,  2.83it/s] 68%|██████▊   | 341/500 [04:26<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:26<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:26<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:26<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:26<00:51,  2.93it/s] 70%|███████   | 351/500 [04:33<02:58,  1.20s/it] 71%|███████   | 353/500 [04:33<02:06,  1.16it/s] 71%|███████   | 355/500 [04:33<01:30,  1.61it/s]0.01663421466946602
Valid Loss:  0.02540373057126999
Epoch:  286  	Training Loss: 0.02162519097328186
Test Loss:  0.016632866114377975
Valid Loss:  0.02540704607963562
Epoch:  287  	Training Loss: 0.02162265218794346
Test Loss:  0.01663154736161232
Valid Loss:  0.025410359725356102
Epoch:  288  	Training Loss: 0.021620146930217743
Test Loss:  0.016630258411169052
Valid Loss:  0.025413673371076584
Epoch:  289  	Training Loss: 0.02161768078804016
Test Loss:  0.016628997400403023
Valid Loss:  0.025416966527700424
Epoch:  290  	Training Loss: 0.021615248173475266
Test Loss:  0.016627749428153038
Valid Loss:  0.025420265272259712
Epoch:  291  	Training Loss: 0.021612858399748802
Test Loss:  0.01662653125822544
Valid Loss:  0.025423545390367508
Epoch:  292  	Training Loss: 0.021610502153635025
Test Loss:  0.016406452283263206
Valid Loss:  0.024996627122163773
Epoch:  293  	Training Loss: 0.02144724503159523
Test Loss:  0.01619991660118103
Valid Loss:  0.02459144778549671
Epoch:  294  	Training Loss: 0.021293889731168747
Test Loss:  0.016005896031856537
Valid Loss:  0.024206627160310745
Epoch:  295  	Training Loss: 0.021149691194295883
Test Loss:  0.01582348346710205
Valid Loss:  0.023840900510549545
Epoch:  296  	Training Loss: 0.021013978868722916
Test Loss:  0.015651848167181015
Valid Loss:  0.023493122309446335
Epoch:  297  	Training Loss: 0.020886117592453957
Test Loss:  0.015490178018808365
Valid Loss:  0.023162180557847023
Epoch:  298  	Training Loss: 0.020765531808137894
Test Loss:  0.015337762422859669
Valid Loss:  0.022847041487693787
Epoch:  299  	Training Loss: 0.02065168134868145
Test Loss:  0.01519392803311348
Valid Loss:  0.02254674583673477
Epoch:  300  	Training Loss: 0.02054406888782978
Test Loss:  0.015058042481541634
Valid Loss:  0.022260434925556183
Epoch:  301  	Training Loss: 0.020442230626940727
Test Loss:  0.014929535798728466
Valid Loss:  0.021987223997712135
Epoch:  302  	Training Loss: 0.020345747470855713
Test Loss:  0.014553478918969631
Valid Loss:  0.02115597389638424
Epoch:  303  	Training Loss: 0.020064914599061012
Test Loss:  0.01424154732376337
Valid Loss:  0.02044399082660675
Epoch:  304  	Training Loss: 0.01983064040541649
Test Loss:  0.01397967990487814
Valid Loss:  0.019829869270324707
Epoch:  305  	Training Loss: 0.019632581621408463
Test Loss:  0.01375696063041687
Valid Loss:  0.019296418875455856
Epoch:  306  	Training Loss: 0.019462743774056435
Test Loss:  0.013564908877015114
Valid Loss:  0.018829751759767532
Epoch:  307  	Training Loss: 0.019314952194690704
Test Loss:  0.013396961614489555
Valid Loss:  0.018418628722429276
Epoch:  308  	Training Loss: 0.019184434786438942
Test Loss:  0.01324799656867981
Valid Loss:  0.018053894862532616
Epoch:  309  	Training Loss: 0.01905902661383152
Test Loss:  0.0130978524684906
Valid Loss:  0.0177234448492527
Epoch:  310  	Training Loss: 0.01891350746154785
Test Loss:  0.012963897548615932
Valid Loss:  0.01742251217365265
Epoch:  311  	Training Loss: 0.01878649741411209
Test Loss:  0.012847362086176872
Valid Loss:  0.01715582236647606
Epoch:  312  	Training Loss: 0.018675804138183594
Test Loss:  0.012805068865418434
Valid Loss:  0.017135972157120705
Epoch:  313  	Training Loss: 0.018625691533088684
Test Loss:  0.012770628556609154
Valid Loss:  0.017123524099588394
Epoch:  314  	Training Loss: 0.018591314554214478
Test Loss:  0.012745101936161518
Valid Loss:  0.01711488515138626
Epoch:  315  	Training Loss: 0.018566321581602097
Test Loss:  0.012726491317152977
Valid Loss:  0.017103007063269615
Epoch:  316  	Training Loss: 0.018547939136624336
Test Loss:  0.012708629481494427
Valid Loss:  0.017090322449803352
Epoch:  317  	Training Loss: 0.01853133738040924
Test Loss:  0.0126918014138937
Valid Loss:  0.0170777328312397
Epoch:  318  	Training Loss: 0.01851711794734001
Test Loss:  0.012676754966378212
Valid Loss:  0.01706407219171524
Epoch:  319  	Training Loss: 0.018504314124584198
Test Loss:  0.012664491310715675
Valid Loss:  0.017048563808202744
Epoch:  320  	Training Loss: 0.01849403604865074
Test Loss:  0.012652489356696606
Valid Loss:  0.017032736912369728
Epoch:  321  	Training Loss: 0.01848467066884041
Test Loss:  0.012642202898859978
Valid Loss:  0.017015524208545685
Epoch:  322  	Training Loss: 0.018476560711860657
Test Loss:  0.012618295848369598
Valid Loss:  0.016946345567703247
Epoch:  323  	Training Loss: 0.018458832055330276
Test Loss:  0.012595446780323982
Valid Loss:  0.016879992559552193
Epoch:  324  	Training Loss: 0.018442140892148018
Test Loss:  0.01257424708455801
Valid Loss:  0.016815517097711563
Epoch:  325  	Training Loss: 0.018426794558763504
Test Loss:  0.012554680928587914
Valid Loss:  0.01675287075340748
Epoch:  326  	Training Loss: 0.018412534147500992
Test Loss:  0.012536305002868176
Valid Loss:  0.016692373901605606
Epoch:  327  	Training Loss: 0.01839899644255638
Test Loss:  0.012518826872110367
Valid Loss:  0.016634277999401093
Epoch:  328  	Training Loss: 0.018385980278253555
Test Loss:  0.012502431869506836
Valid Loss:  0.01657847687602043
Epoch:  329  	Training Loss: 0.018373463302850723
Test Loss:  0.012486944906413555
Valid Loss:  0.016524501144886017
Epoch:  330  	Training Loss: 0.01836189068853855
Test Loss:  0.012472639791667461
Valid Loss:  0.016471952199935913
Epoch:  331  	Training Loss: 0.01835104264318943
Test Loss:  0.0124590415507555
Valid Loss:  0.016421131789684296
Epoch:  332  	Training Loss: 0.018340900540351868
Test Loss:  0.011948137544095516
Valid Loss:  0.01625605672597885
Epoch:  333  	Training Loss: 0.017870992422103882
Test Loss:  0.011594838462769985
Valid Loss:  0.016181576997041702
Epoch:  334  	Training Loss: 0.017558187246322632
Test Loss:  0.011348899453878403
Valid Loss:  0.016160881146788597
Epoch:  335  	Training Loss: 0.017349960282444954
Test Loss:  0.011176394298672676
Valid Loss:  0.016170669347047806
Epoch:  336  	Training Loss: 0.017211338505148888
Test Loss:  0.011054391041398048
Valid Loss:  0.016196414828300476
Epoch:  337  	Training Loss: 0.017119063064455986
Test Loss:  0.010967334732413292
Valid Loss:  0.016229234635829926
Epoch:  338  	Training Loss: 0.0170576311647892
Test Loss:  0.010904606431722641
Valid Loss:  0.01626388356089592
Epoch:  339  	Training Loss: 0.017016736790537834
Test Loss:  0.010858960449695587
Valid Loss:  0.016297385096549988
Epoch:  340  	Training Loss: 0.016989506781101227
Test Loss:  0.01082539651542902
Valid Loss:  0.016328204423189163
Epoch:  341  	Training Loss: 0.01697138138115406
Test Loss:  0.010800467804074287
Valid Loss:  0.01635568216443062
Epoch:  342  	Training Loss: 0.01695932075381279
Test Loss:  0.010777237825095654
Valid Loss:  0.016313429921865463
Epoch:  343  	Training Loss: 0.016940390691161156
Test Loss:  0.010754533112049103
Valid Loss:  0.01627209037542343
Epoch:  344  	Training Loss: 0.01692206785082817
Test Loss:  0.010732414200901985
Valid Loss:  0.016231229528784752
Epoch:  345  	Training Loss: 0.016904018819332123
Test Loss:  0.010710790753364563
Valid Loss:  0.016191260889172554
Epoch:  346  	Training Loss: 0.016886556521058083
Test Loss:  0.010689498856663704
Valid Loss:  0.0161515474319458
Epoch:  347  	Training Loss: 0.016869209706783295
Test Loss:  0.010668491944670677
Valid Loss:  0.016112085431814194
Epoch:  348  	Training Loss: 0.016851969063282013
Test Loss:  0.010647602379322052
Valid Loss:  0.016072861850261688
Epoch:  349  	Training Loss: 0.016834832727909088
Test Loss:  0.010627103969454765
Valid Loss:  0.016033880412578583
Epoch:  350  	Training Loss: 0.016817843541502953
Test Loss:  0.010606950148940086
Valid Loss:  0.015995346009731293
Epoch:  351  	Training Loss: 0.016801126301288605
Test Loss:  0.010587301105260849
Valid Loss:  0.015957243740558624
Epoch:  352  	Training Loss: 0.01678471453487873
Test Loss:  0.01054321601986885
Valid Loss:  0.015994839370250702
Epoch:  353  	Training Loss: 0.01676470786333084
Test Loss:  0.010514901950955391
Valid Loss:  0.0160212405025959
Epoch:  354  	Training Loss: 0.016753679141402245
Test Loss:  0.010495621711015701
Valid Loss:  0.01603833958506584
Epoch:  355  	Training Loss: 0.016746845096349716
Test Loss:  0.010481715202331543
Valid Loss:  0.016048315912485123
 71%|███████▏  | 357/500 [04:33<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:33<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:40<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:40<01:58,  1.15it/s] 73%|███████▎  | 365/500 [04:40<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:40<01:01,  2.17it/s] 74%|███████▍  | 369/500 [04:40<00:44,  2.92it/s] 74%|███████▍  | 371/500 [04:46<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:47<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:47<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:47<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:47<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:53<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:54<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:54<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:54<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:54<00:37,  2.95it/s] 78%|███████▊  | 391/500 [05:00<02:11,  1.20s/it] 79%|███████▊  | 393/500 [05:01<01:33,  1.15it/s] 79%|███████▉  | 395/500 [05:01<01:06,  1.57it/s] 79%|███████▉  | 397/500 [05:01<00:48,  2.13it/s] 80%|███████▉  | 399/500 [05:01<00:35,  2.87it/s] 80%|████████  | 401/500 [05:07<01:58,  1.19s/it] 81%|████████  | 403/500 [05:08<01:23,  1.17it/s] 81%|████████  | 405/500 [05:08<00:59,  1.59it/s] 81%|████████▏ | 407/500 [05:08<00:43,  2.14it/s] 82%|████████▏ | 409/500 [05:08<00:32,  2.84it/s] 82%|████████▏ | 411/500 [05:15<01:48,  1.22s/it] 83%|████████▎ | 413/500 [05:15<01:16,  1.14it/s] 83%|████████▎ | 415/500 [05:15<00:54,  1.57it/s] 83%|████████▎ | 417/500 [05:15<00:39,  2.12it/s] 84%|████████▍ | 419/500 [05:15<00:28,  2.80it/s] 84%|████████▍ | 421/500 [05:22<01:35,  1.21s/it] 85%|████████▍ | 423/500 [05:22<01:07,  1.14it/s] 85%|████████▌ | 425/500 [05:22<00:47,  1.58it/s]Epoch:  356  	Training Loss: 0.016741974279284477
Test Loss:  0.010471092537045479
Valid Loss:  0.01605307124555111
Epoch:  357  	Training Loss: 0.01673801988363266
Test Loss:  0.010462548583745956
Valid Loss:  0.01605408266186714
Epoch:  358  	Training Loss: 0.016734488308429718
Test Loss:  0.01045534759759903
Valid Loss:  0.016052475199103355
Epoch:  359  	Training Loss: 0.01673116721212864
Test Loss:  0.010449010878801346
Valid Loss:  0.016049034893512726
Epoch:  360  	Training Loss: 0.01672794297337532
Test Loss:  0.010443265549838543
Valid Loss:  0.016044320538640022
Epoch:  361  	Training Loss: 0.016724757850170135
Test Loss:  0.010437914170324802
Valid Loss:  0.016038738191127777
Epoch:  362  	Training Loss: 0.01672159880399704
Test Loss:  0.010437766090035439
Valid Loss:  0.016038423404097557
Epoch:  363  	Training Loss: 0.016721483319997787
Test Loss:  0.010437618009746075
Valid Loss:  0.01603812351822853
Epoch:  364  	Training Loss: 0.016721360385417938
Test Loss:  0.010437466204166412
Valid Loss:  0.01603780686855316
Epoch:  365  	Training Loss: 0.016721241176128387
Test Loss:  0.010437319055199623
Valid Loss:  0.016037501394748688
Epoch:  366  	Training Loss: 0.016721125692129135
Test Loss:  0.01043717097491026
Valid Loss:  0.016037190333008766
Epoch:  367  	Training Loss: 0.016721008345484734
Test Loss:  0.010437024757266045
Valid Loss:  0.01603688672184944
Epoch:  368  	Training Loss: 0.016720883548259735
Test Loss:  0.010436872020363808
Valid Loss:  0.01603657938539982
Epoch:  369  	Training Loss: 0.01672077178955078
Test Loss:  0.010436725802719593
Valid Loss:  0.0160362645983696
Epoch:  370  	Training Loss: 0.016720646992325783
Test Loss:  0.010436578653752804
Valid Loss:  0.01603594981133938
Epoch:  371  	Training Loss: 0.01672052964568138
Test Loss:  0.01043643057346344
Valid Loss:  0.016035648062825203
Epoch:  372  	Training Loss: 0.01672041229903698
Test Loss:  0.010427797213196754
Valid Loss:  0.01601933129131794
Epoch:  373  	Training Loss: 0.01671408861875534
Test Loss:  0.010419134981930256
Valid Loss:  0.01600317284464836
Epoch:  374  	Training Loss: 0.016707777976989746
Test Loss:  0.010410431772470474
Valid Loss:  0.01598718762397766
Epoch:  375  	Training Loss: 0.016701482236385345
Test Loss:  0.010401718318462372
Valid Loss:  0.015971342101693153
Epoch:  376  	Training Loss: 0.016695205122232437
Test Loss:  0.010392975062131882
Valid Loss:  0.015955621376633644
Epoch:  377  	Training Loss: 0.016688942909240723
Test Loss:  0.010384217835962772
Valid Loss:  0.015940027311444283
Epoch:  378  	Training Loss: 0.016682691872119904
Test Loss:  0.01037544384598732
Valid Loss:  0.015924513339996338
Epoch:  379  	Training Loss: 0.01667645201086998
Test Loss:  0.01036666240543127
Valid Loss:  0.015909112989902496
Epoch:  380  	Training Loss: 0.01667023077607155
Test Loss:  0.010357867926359177
Valid Loss:  0.015893802046775818
Epoch:  381  	Training Loss: 0.01666402444243431
Test Loss:  0.010349072515964508
Valid Loss:  0.015878569334745407
Epoch:  382  	Training Loss: 0.01665782555937767
Test Loss:  0.010349041782319546
Valid Loss:  0.015854433178901672
Epoch:  383  	Training Loss: 0.01632089354097843
Test Loss:  0.010348952375352383
Valid Loss:  0.01583610102534294
Epoch:  384  	Training Loss: 0.016008004546165466
Test Loss:  0.010348797775804996
Valid Loss:  0.015823058784008026
Epoch:  385  	Training Loss: 0.01571378856897354
Test Loss:  0.010348586365580559
Valid Loss:  0.015814820304512978
Epoch:  386  	Training Loss: 0.015435860492289066
Test Loss:  0.010348324663937092
Valid Loss:  0.015811040997505188
Epoch:  387  	Training Loss: 0.015185162425041199
Test Loss:  0.010348012670874596
Valid Loss:  0.015811089426279068
Epoch:  388  	Training Loss: 0.014958985149860382
Test Loss:  0.010347646661102772
Valid Loss:  0.015814445912837982
Epoch:  389  	Training Loss: 0.014754906296730042
Test Loss:  0.010347247123718262
Valid Loss:  0.01582062616944313
Epoch:  390  	Training Loss: 0.014570718631148338
Test Loss:  0.010346803814172745
Valid Loss:  0.0158291794359684
Epoch:  391  	Training Loss: 0.014404453337192535
Test Loss:  0.01034632883965969
Valid Loss:  0.015839744359254837
Epoch:  392  	Training Loss: 0.014251423068344593
Test Loss:  0.010325140319764614
Valid Loss:  0.01579730585217476
Epoch:  393  	Training Loss: 0.0142336655408144
Test Loss:  0.01030423678457737
Valid Loss:  0.0157554242759943
Epoch:  394  	Training Loss: 0.014216168783605099
Test Loss:  0.010283617302775383
Valid Loss:  0.015714259818196297
Epoch:  395  	Training Loss: 0.014198951423168182
Test Loss:  0.010263179428875446
Valid Loss:  0.015673350542783737
Epoch:  396  	Training Loss: 0.014181884005665779
Test Loss:  0.010242917574942112
Valid Loss:  0.015632718801498413
Epoch:  397  	Training Loss: 0.014164961874485016
Test Loss:  0.010223147459328175
Valid Loss:  0.015592548064887524
Epoch:  398  	Training Loss: 0.014148330315947533
Test Loss:  0.010203635320067406
Valid Loss:  0.015552656725049019
Epoch:  399  	Training Loss: 0.014131912961602211
Test Loss:  0.010184455662965775
Valid Loss:  0.015513379126787186
Epoch:  400  	Training Loss: 0.014115909114480019
Test Loss:  0.010165632702410221
Valid Loss:  0.015474716201424599
Epoch:  401  	Training Loss: 0.014100262895226479
Test Loss:  0.010146965272724628
Valid Loss:  0.0154363252222538
Epoch:  402  	Training Loss: 0.014084741473197937
Test Loss:  0.009990492835640907
Valid Loss:  0.015123458579182625
Epoch:  403  	Training Loss: 0.013962864875793457
Test Loss:  0.009843851439654827
Valid Loss:  0.014829304069280624
Epoch:  404  	Training Loss: 0.01384819857776165
Test Loss:  0.009705916047096252
Valid Loss:  0.014552093110978603
Epoch:  405  	Training Loss: 0.013739928603172302
Test Loss:  0.00957571342587471
Valid Loss:  0.014290278777480125
Epoch:  406  	Training Loss: 0.0136373620480299
Test Loss:  0.009452388621866703
Valid Loss:  0.01404245663434267
Epoch:  407  	Training Loss: 0.013539895415306091
Test Loss:  0.009335211478173733
Valid Loss:  0.013807429932057858
Epoch:  408  	Training Loss: 0.013447011820971966
Test Loss:  0.009223541244864464
Valid Loss:  0.013584047555923462
Epoch:  409  	Training Loss: 0.013358250260353088
Test Loss:  0.009116804227232933
Valid Loss:  0.01337135024368763
Epoch:  410  	Training Loss: 0.013273214921355247
Test Loss:  0.009014526382088661
Valid Loss:  0.013168442994356155
Epoch:  411  	Training Loss: 0.013191567733883858
Test Loss:  0.008916264399886131
Valid Loss:  0.012974550947546959
Epoch:  412  	Training Loss: 0.013113010674715042
Test Loss:  0.008815014734864235
Valid Loss:  0.012902956455945969
Epoch:  413  	Training Loss: 0.013026160188019276
Test Loss:  0.008721696212887764
Valid Loss:  0.012829544022679329
Epoch:  414  	Training Loss: 0.012948138639330864
Test Loss:  0.008634594269096851
Valid Loss:  0.012754024937748909
Epoch:  415  	Training Loss: 0.012876991182565689
Test Loss:  0.00855240784585476
Valid Loss:  0.012676279060542583
Epoch:  416  	Training Loss: 0.012811249122023582
Test Loss:  0.008474178612232208
Valid Loss:  0.012596388347446918
Epoch:  417  	Training Loss: 0.01274979580193758
Test Loss:  0.00839916244149208
Valid Loss:  0.012514505535364151
Epoch:  418  	Training Loss: 0.012691782787442207
Test Loss:  0.0083268191665411
Valid Loss:  0.012430842965841293
Epoch:  419  	Training Loss: 0.012636569328606129
Test Loss:  0.00825672596693039
Valid Loss:  0.012345637194812298
Epoch:  420  	Training Loss: 0.012583654373884201
Test Loss:  0.00818856805562973
Valid Loss:  0.012259162962436676
Epoch:  421  	Training Loss: 0.012532681226730347
Test Loss:  0.008122090250253677
Valid Loss:  0.01217164471745491
Epoch:  422  	Training Loss: 0.012483356520533562
Test Loss:  0.00805710069835186
Valid Loss:  0.012083272449672222
Epoch:  423  	Training Loss: 0.012435444630682468
Test Loss:  0.007993461564183235
Valid Loss:  0.011994346976280212
Epoch:  424  	Training Loss: 0.012388789094984531
Test Loss:  0.007931077852845192
Valid Loss:  0.011905061081051826
Epoch:  425  	Training Loss: 0.012343274429440498
Test Loss:  0.007869850844144821
Valid Loss:  0.011815601959824562
Epoch:  426  	Training Loss: 0.01229878980666399
Test Loss:   85%|████████▌ | 427/500 [05:22<00:33,  2.16it/s] 86%|████████▌ | 429/500 [05:22<00:24,  2.90it/s] 86%|████████▌ | 431/500 [05:29<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:29<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:29<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:29<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:29<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:36<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:36<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:36<00:34,  1.59it/s] 89%|████████▉ | 447/500 [05:36<00:24,  2.17it/s] 90%|████████▉ | 449/500 [05:36<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:43<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:43<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:43<00:28,  1.59it/s] 91%|█████████▏| 457/500 [05:43<00:19,  2.17it/s] 92%|█████████▏| 459/500 [05:43<00:14,  2.89it/s] 92%|█████████▏| 461/500 [05:50<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:50<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:50<00:21,  1.59it/s] 93%|█████████▎| 467/500 [05:50<00:15,  2.17it/s] 94%|█████████▍| 469/500 [05:50<00:10,  2.93it/s] 94%|█████████▍| 471/500 [05:57<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:57<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:57<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:57<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:57<00:07,  2.96it/s] 96%|█████████▌| 481/500 [06:03<00:22,  1.19s/it] 97%|█████████▋| 483/500 [06:04<00:14,  1.17it/s] 97%|█████████▋| 485/500 [06:04<00:09,  1.62it/s] 97%|█████████▋| 487/500 [06:04<00:05,  2.22it/s] 98%|█████████▊| 489/500 [06:04<00:03,  2.98it/s] 98%|█████████▊| 491/500 [06:10<00:10,  1.19s/it] 99%|█████████▊| 493/500 [06:11<00:06,  1.16it/s] 99%|█████████▉| 495/500 [06:11<00:03,  1.61it/s]0.007809713948518038
Valid Loss:  0.011726133525371552
Epoch:  427  	Training Loss: 0.012255249544978142
Test Loss:  0.007750607095658779
Valid Loss:  0.011636817827820778
Epoch:  428  	Training Loss: 0.012212604284286499
Test Loss:  0.0076924944296479225
Valid Loss:  0.011547764763236046
Epoch:  429  	Training Loss: 0.012170795351266861
Test Loss:  0.007635315880179405
Valid Loss:  0.011459112167358398
Epoch:  430  	Training Loss: 0.012129783630371094
Test Loss:  0.0075790490955114365
Valid Loss:  0.011370926164090633
Epoch:  431  	Training Loss: 0.012089528143405914
Test Loss:  0.007523670792579651
Valid Loss:  0.011283324100077152
Epoch:  432  	Training Loss: 0.012050011195242405
Test Loss:  0.007507916074246168
Valid Loss:  0.011247646063566208
Epoch:  433  	Training Loss: 0.012036810629069805
Test Loss:  0.007492473348975182
Valid Loss:  0.01121283508837223
Epoch:  434  	Training Loss: 0.01202385500073433
Test Loss:  0.007477482780814171
Valid Loss:  0.01117928046733141
Epoch:  435  	Training Loss: 0.012011165730655193
Test Loss:  0.0074627213180065155
Valid Loss:  0.011146552860736847
Epoch:  436  	Training Loss: 0.011998672038316727
Test Loss:  0.007448132615536451
Valid Loss:  0.011114212684333324
Epoch:  437  	Training Loss: 0.011986322700977325
Test Loss:  0.007433759514242411
Valid Loss:  0.01108265109360218
Epoch:  438  	Training Loss: 0.011974126100540161
Test Loss:  0.007419551722705364
Valid Loss:  0.011051472276449203
Epoch:  439  	Training Loss: 0.011962046846747398
Test Loss:  0.007405496668070555
Valid Loss:  0.011020660400390625
Epoch:  440  	Training Loss: 0.011950083076953888
Test Loss:  0.007391656748950481
Valid Loss:  0.010990597307682037
Epoch:  441  	Training Loss: 0.01193825900554657
Test Loss:  0.007377975154668093
Valid Loss:  0.010960882529616356
Epoch:  442  	Training Loss: 0.01192653551697731
Test Loss:  0.00731069128960371
Valid Loss:  0.010976369492709637
Epoch:  443  	Training Loss: 0.011891431175172329
Test Loss:  0.007266616448760033
Valid Loss:  0.010976441204547882
Epoch:  444  	Training Loss: 0.011869370937347412
Test Loss:  0.007233860902488232
Valid Loss:  0.010964672081172466
Epoch:  445  	Training Loss: 0.011852147057652473
Test Loss:  0.007207006216049194
Valid Loss:  0.010944876819849014
Epoch:  446  	Training Loss: 0.011836755089461803
Test Loss:  0.007183410692960024
Valid Loss:  0.010919961147010326
Epoch:  447  	Training Loss: 0.01182209700345993
Test Loss:  0.00716170622035861
Valid Loss:  0.010891919955611229
Epoch:  448  	Training Loss: 0.0118077602237463
Test Loss:  0.00714115472510457
Valid Loss:  0.01086202822625637
Epoch:  449  	Training Loss: 0.011793598532676697
Test Loss:  0.0071213264018297195
Valid Loss:  0.010831079445779324
Epoch:  450  	Training Loss: 0.011779560707509518
Test Loss:  0.0071019744500517845
Valid Loss:  0.010799562558531761
Epoch:  451  	Training Loss: 0.011765631847083569
Test Loss:  0.0070830159820616245
Valid Loss:  0.010768160223960876
Epoch:  452  	Training Loss: 0.011751849204301834
Test Loss:  0.007083012722432613
Valid Loss:  0.010767024010419846
Epoch:  453  	Training Loss: 0.011510264128446579
Test Loss:  0.007083013188093901
Valid Loss:  0.010769396089017391
Epoch:  454  	Training Loss: 0.011291601695120335
Test Loss:  0.007083006203174591
Valid Loss:  0.010774750262498856
Epoch:  455  	Training Loss: 0.011093681678175926
Test Loss:  0.0070830038748681545
Valid Loss:  0.010782673954963684
Epoch:  456  	Training Loss: 0.010911124758422375
Test Loss:  0.007082996889948845
Valid Loss:  0.010793270543217659
Epoch:  457  	Training Loss: 0.010733530856668949
Test Loss:  0.0070829838514328
Valid Loss:  0.010805940255522728
Epoch:  458  	Training Loss: 0.010571524500846863
Test Loss:  0.007082981988787651
Valid Loss:  0.010820368304848671
Epoch:  459  	Training Loss: 0.010423025116324425
Test Loss:  0.007082967087626457
Valid Loss:  0.01083665993064642
Epoch:  460  	Training Loss: 0.010281383991241455
Test Loss:  0.007082959171384573
Valid Loss:  0.010854275897145271
Epoch:  461  	Training Loss: 0.010151663795113564
Test Loss:  0.007082940079271793
Valid Loss:  0.01087300106883049
Epoch:  462  	Training Loss: 0.010032858699560165
Test Loss:  0.007078118622303009
Valid Loss:  0.010862147435545921
Epoch:  463  	Training Loss: 0.010029058903455734
Test Loss:  0.007073315791785717
Valid Loss:  0.01085134781897068
Epoch:  464  	Training Loss: 0.010025277733802795
Test Loss:  0.007068539969623089
Valid Loss:  0.010840569622814655
Epoch:  465  	Training Loss: 0.010021507740020752
Test Loss:  0.007063780911266804
Valid Loss:  0.010829834267497063
Epoch:  466  	Training Loss: 0.01001775823533535
Test Loss:  0.007059046998620033
Valid Loss:  0.010819132439792156
Epoch:  467  	Training Loss: 0.010014022700488567
Test Loss:  0.007054340094327927
Valid Loss:  0.010808473452925682
Epoch:  468  	Training Loss: 0.010010307654738426
Test Loss:  0.007049648556858301
Valid Loss:  0.010797846131026745
Epoch:  469  	Training Loss: 0.010006610304117203
Test Loss:  0.007044973783195019
Valid Loss:  0.010787256993353367
Epoch:  470  	Training Loss: 0.010002926923334599
Test Loss:  0.0070403264835476875
Valid Loss:  0.010776709765195847
Epoch:  471  	Training Loss: 0.009999258443713188
Test Loss:  0.007035700138658285
Valid Loss:  0.010766178369522095
Epoch:  472  	Training Loss: 0.009995607659220695
Test Loss:  0.0069505395367741585
Valid Loss:  0.010625068098306656
Epoch:  473  	Training Loss: 0.009926296770572662
Test Loss:  0.006867123302072287
Valid Loss:  0.010486312210559845
Epoch:  474  	Training Loss: 0.009858762845396996
Test Loss:  0.00678544444963336
Valid Loss:  0.010349936783313751
Epoch:  475  	Training Loss: 0.009792957454919815
Test Loss:  0.006705448497086763
Valid Loss:  0.010215953923761845
Epoch:  476  	Training Loss: 0.009728830307722092
Test Loss:  0.006627116352319717
Valid Loss:  0.010084371082484722
Epoch:  477  	Training Loss: 0.00966633576899767
Test Loss:  0.006550420541316271
Valid Loss:  0.009955169633030891
Epoch:  478  	Training Loss: 0.009605429135262966
Test Loss:  0.006475328002125025
Valid Loss:  0.009828353300690651
Epoch:  479  	Training Loss: 0.009546072222292423
Test Loss:  0.006401802413165569
Valid Loss:  0.00970388762652874
Epoch:  480  	Training Loss: 0.009488221257925034
Test Loss:  0.006329817697405815
Valid Loss:  0.00958175491541624
Epoch:  481  	Training Loss: 0.009431840851902962
Test Loss:  0.006259347312152386
Valid Loss:  0.009461931884288788
Epoch:  482  	Training Loss: 0.0093768872320652
Test Loss:  0.006250824313610792
Valid Loss:  0.009441712871193886
Epoch:  483  	Training Loss: 0.009369500912725925
Test Loss:  0.006242423318326473
Valid Loss:  0.009421813301742077
Epoch:  484  	Training Loss: 0.009362242184579372
Test Loss:  0.006234130822122097
Valid Loss:  0.00940211582928896
Epoch:  485  	Training Loss: 0.009355108253657818
Test Loss:  0.0062259491533041
Valid Loss:  0.009382633492350578
Epoch:  486  	Training Loss: 0.009348075836896896
Test Loss:  0.00621784757822752
Valid Loss:  0.009363281540572643
Epoch:  487  	Training Loss: 0.009341098368167877
Test Loss:  0.006209815852344036
Valid Loss:  0.009344053454697132
Epoch:  488  	Training Loss: 0.009334180504083633
Test Loss:  0.006201856303960085
Valid Loss:  0.009324951097369194
Epoch:  489  	Training Loss: 0.009327326901257038
Test Loss:  0.006193977314978838
Valid Loss:  0.009305973537266254
Epoch:  490  	Training Loss: 0.009320531971752644
Test Loss:  0.006186199374496937
Valid Loss:  0.009287199936807156
Epoch:  491  	Training Loss: 0.009313849732279778
Test Loss:  0.006178488954901695
Valid Loss:  0.009268552996218204
Epoch:  492  	Training Loss: 0.009307222440838814
Test Loss:  0.006127018481492996
Valid Loss:  0.009186090901494026
Epoch:  493  	Training Loss: 0.009266523644328117
Test Loss:  0.0060763172805309296
Valid Loss:  0.009104507975280285
Epoch:  494  	Training Loss: 0.00922657735645771
Test Loss:  0.0060263932682573795
Valid Loss:  0.009023815393447876
Epoch:  495  	Training Loss: 0.009187368676066399
Test Loss:  0.005977220833301544
Valid Loss:  0.008944042026996613
Epoch:  496  	Training Loss: 0.009148873388767242
Test Loss:  0.005928799510002136
 99%|█████████▉| 497/500 [06:11<00:01,  2.19it/s]100%|█████████▉| 499/500 [06:11<00:00,  2.94it/s]100%|██████████| 500/500 [06:11<00:00,  1.35it/s]
Valid Loss:  0.008865196257829666
Epoch:  497  	Training Loss: 0.009111076593399048
Test Loss:  0.0058811018243432045
Valid Loss:  0.008787032216787338
Epoch:  498  	Training Loss: 0.009073987603187561
Test Loss:  0.005834128707647324
Valid Loss:  0.008709834888577461
Epoch:  499  	Training Loss: 0.009037565439939499
Test Loss:  0.0057878652587533
Valid Loss:  0.008633626624941826
Epoch:  500  	Training Loss: 0.009001798927783966
Test Loss:  0.005742297507822514
Valid Loss:  0.008558385074138641
