/nishome/yui/ModifiedNGD/utils/modified_fisher_inverse.py:165: SyntaxWarning: invalid escape sequence '\s'
  '''
/nishome/yui/ModifiedNGD/utils/readData.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/nishome/yui/anaconda3/envs/ng/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train info: 
 train data shape: torch.Size([512, 1]), 
 train lable shape: torch.Size([512, 1]), 
 positive / negative: 0.021206805482506752 / 0.978793203830719, 
 discrepancy norm error: 5.045955617788422e-07
Test info: 
 test data shape: torch.Size([128, 1]), 
 test lable shape: torch.Size([128, 1]), , 
 positive / negative: -0.030759211629629135 / 1.0307592153549194, 
 discrepancy norm error: 2.750667249529215e-07
Valid info: 
 valid data shape: torch.Size([128, 1]), valid lable shape: torch.Size([128, 1]), 
 positive / negative: 0.015859205275774002 / 0.9841408133506775, 
 discrepancy norm error: 2.3576444618811365e-07
torch.Size([512, 1]) torch.Size([512])
seed is  2191
---------------------------------------- NGD ----------------------------------------
OUTPUT CHECK:  torch.Size([512]) tensor(0.0590, device='cuda:0', grad_fn=<MaxBackward1>) tensor(-0.2447, device='cuda:0', grad_fn=<MinBackward1>) 
TARGET:  torch.Size([512]) tensor(0.5000, device='cuda:0') tensor(-0.5000, device='cuda:0')
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 0/10 [00:00<?, ?it/s]Epoch:   1
Test train Loss:  0.05464249104261398
Test train Acc:  0.0
Test Loss:  0.0616748183965683
Test Acc:  0.0
Valid Loss:  0.05691187083721161
Valid Acc:  0.0
max of grad d_p:  tensor(0.0106, device='cuda:0')
min of grad d_p:  tensor(-0.0819, device='cuda:0')
max|min: (J_L, Jta/N)  (0.01059434562921524, 0.05017261207103729, ratio: 4.7357916831970215)|(-0.08188621699810028, -0.08188624680042267)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0594, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0396, device='cuda:0') norm:  tensor(1.2835, device='cuda:0') MSE:  tensor(2.4099e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(3.6665e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0061, device='cuda:0') MSE:  tensor(1.1442e-08, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0094, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  1  
Training Loss: 0.054250793167739175
Test Loss:  0.06109918653964996
Test Acc:  0.0
Valid Loss:  0.05642188340425491
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 1/10 [00:02<00:22,  2.54s/it]Epoch:   2
max of grad d_p:  tensor(0.0161, device='cuda:0')
min of grad d_p:  tensor(-0.0965, device='cuda:0')
max|min: (J_L, Jta/N)  (0.016058888286352158, 0.05368426442146301, ratio: 3.3429627418518066)|(-0.09653478115797043, -0.09653475135564804)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0417, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0376, device='cuda:0') norm:  tensor(1.5468, device='cuda:0') MSE:  tensor(2.9042e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0028, device='cuda:0') mean:  tensor(3.6851e-05, device='cuda:0') min:  tensor(5.2296e-12, device='cuda:0') norm:  tensor(0.0851, device='cuda:0') MSE:  tensor(1.5987e-07, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  2  
Training Loss: 0.053878042846918106
Test Loss:  0.06082470715045929
Test Acc:  0.0
Valid Loss:  0.05615900829434395
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 2/10 [00:04<00:19,  2.49s/it]Epoch:   3
max of grad d_p:  tensor(0.0156, device='cuda:0')
min of grad d_p:  tensor(-0.0958, device='cuda:0')
max|min: (J_L, Jta/N)  (0.015582269057631493, 0.049048855900764465, ratio: 3.147735118865967)|(-0.09583920985460281, -0.09583920240402222)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0368, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0335, device='cuda:0') norm:  tensor(1.3756, device='cuda:0') MSE:  tensor(2.5828e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0008, device='cuda:0') mean:  tensor(1.2313e-05, device='cuda:0') min:  tensor(1.1369e-13, device='cuda:0') norm:  tensor(0.0288, device='cuda:0') MSE:  tensor(5.4143e-08, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0028, device='cuda:0')
min of d_p_list:  tensor(-0.0036, device='cuda:0')
Epoch:  3  
Training Loss: 0.053474992513656616
Test Loss:  0.06039295345544815
Test Acc:  0.0
Valid Loss:  0.055749282240867615
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 3/10 [00:07<00:17,  2.47s/it]Epoch:   4
max of grad d_p:  tensor(0.0142, device='cuda:0')
min of grad d_p:  tensor(-0.0939, device='cuda:0')
max|min: (J_L, Jta/N)  (0.014246017672121525, 0.05640191584825516, ratio: 3.9591355323791504)|(-0.0938790887594223, -0.0938790887594223)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0516, device='cuda:0') mean:  tensor(-0.0003, device='cuda:0') min:  tensor(-0.0422, device='cuda:0') norm:  tensor(1.7192, device='cuda:0') MSE:  tensor(3.2279e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(9.9114e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0233, device='cuda:0') MSE:  tensor(4.3754e-08, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0013, device='cuda:0')
Epoch:  4  
Training Loss: 0.05322451889514923
Test Loss:  0.06012904644012451
Test Acc:  0.0
Valid Loss:  0.05549217760562897
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 4/10 [00:09<00:14,  2.46s/it]Epoch:   5
max of grad d_p:  tensor(0.0143, device='cuda:0')
min of grad d_p:  tensor(-0.0935, device='cuda:0')
max|min: (J_L, Jta/N)  (0.014342445880174637, 0.05379859358072281, ratio: 3.7510054111480713)|(-0.09347330033779144, -0.09347333759069443)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0424, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0395, device='cuda:0') norm:  tensor(1.5310, device='cuda:0') MSE:  tensor(2.8745e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(1.4975e-05, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0349, device='cuda:0') MSE:  tensor(6.5595e-08, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0006, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  5  
Training Loss: 0.052973415702581406
Test Loss:  0.05986598879098892
Test Acc:  0.0
Valid Loss:  0.055232249200344086
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 5/10 [00:12<00:12,  2.46s/it]Epoch:   6
max of grad d_p:  tensor(0.0151, device='cuda:0')
min of grad d_p:  tensor(-0.0928, device='cuda:0')
max|min: (J_L, Jta/N)  (0.015092117711901665, 0.05084715038537979, ratio: 3.369119644165039)|(-0.09283334016799927, -0.09283330291509628)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0374, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0358, device='cuda:0') norm:  tensor(1.3363, device='cuda:0') MSE:  tensor(2.5090e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(6.4141e-06, device='cuda:0') min:  tensor(3.4106e-13, device='cuda:0') norm:  tensor(0.0118, device='cuda:0') MSE:  tensor(2.2098e-08, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0034, device='cuda:0')
min of d_p_list:  tensor(-0.0025, device='cuda:0')
Epoch:  6  
Training Loss: 0.05256833881139755
Test Loss:  0.05933056399226189
Test Acc:  0.0
Valid Loss:  0.05465054512023926
Valid Acc:  0.0
std:  0.00044349826280630766 
thres:  5.322386175394058e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 6/10 [00:14<00:09,  2.43s/it]Epoch:   7
max of grad d_p:  tensor(0.0119, device='cuda:0')
min of grad d_p:  tensor(-0.0841, device='cuda:0')
max|min: (J_L, Jta/N)  (0.011938730254769325, 0.060540102422237396, ratio: 5.070899486541748)|(-0.08411385118961334, -0.08411385118961334)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0485, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0486, device='cuda:0') norm:  tensor(1.8900, device='cuda:0') MSE:  tensor(3.5486e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(6.5978e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0127, device='cuda:0') MSE:  tensor(2.3904e-08, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0011, device='cuda:0')
min of d_p_list:  tensor(-0.0017, device='cuda:0')
Epoch:  7  
Training Loss: 0.05228670686483383
Test Loss:  0.059037938714027405
Test Acc:  0.0
Valid Loss:  0.054370004683732986
Valid Acc:  0.0
std:  0.0004306483223590352 
thres:  5.290559455752373e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 7/10 [00:17<00:07,  2.40s/it]Epoch:   8
max of grad d_p:  tensor(0.0118, device='cuda:0')
min of grad d_p:  tensor(-0.0835, device='cuda:0')
max|min: (J_L, Jta/N)  (0.011773727834224701, 0.056375857442617416, ratio: 4.788275718688965)|(-0.08350379019975662, -0.08350375294685364)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0447, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0446, device='cuda:0') norm:  tensor(1.7046, device='cuda:0') MSE:  tensor(3.2005e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0009, device='cuda:0') mean:  tensor(8.8919e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0180, device='cuda:0') MSE:  tensor(3.3782e-08, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0058, device='cuda:0')
Epoch:  8  
Training Loss: 0.051824040710926056
Test Loss:  0.05860200524330139
Test Acc:  0.0
Valid Loss:  0.054006997495889664
Valid Acc:  0.0
std:  0.0004955211816678089 
thres:  5.2575404196977616e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 8/10 [00:19<00:04,  2.42s/it]Epoch:   9
max of grad d_p:  tensor(0.0157, device='cuda:0')
min of grad d_p:  tensor(-0.0876, device='cuda:0')
max|min: (J_L, Jta/N)  (0.015654150396585464, 0.061104387044906616, ratio: 3.9033985137939453)|(-0.08762994408607483, -0.08762992918491364)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0579, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0455, device='cuda:0') norm:  tensor(1.5624, device='cuda:0') MSE:  tensor(2.9335e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0039, device='cuda:0') mean:  tensor(4.7935e-05, device='cuda:0') min:  tensor(1.5234e-11, device='cuda:0') norm:  tensor(0.0953, device='cuda:0') MSE:  tensor(1.7886e-07, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0017, device='cuda:0')
min of d_p_list:  tensor(-0.0028, device='cuda:0')
Epoch:  9  
Training Loss: 0.051551297307014465
Test Loss:  0.05834130570292473
Test Acc:  0.0
Valid Loss:  0.05375354737043381
Valid Acc:  0.0
std:  0.0005089630912934319 
thres:  5.224075987935066e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 9/10 [00:21<00:02,  2.43s/it]Epoch:   10
max of grad d_p:  tensor(0.0155, device='cuda:0')
min of grad d_p:  tensor(-0.0867, device='cuda:0')
max|min: (J_L, Jta/N)  (0.015466496348381042, 0.061852745711803436, ratio: 3.9991440773010254)|(-0.0867457315325737, -0.0867457464337349)

 check Jacobi res:  torch.Size([532609]) max:  tensor(0.0628, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0464, device='cuda:0') norm:  tensor(1.5564, device='cuda:0') MSE:  tensor(2.9223e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([532609, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(7.1881e-06, device='cuda:0') min:  tensor(4.5475e-13, device='cuda:0') norm:  tensor(0.0160, device='cuda:0') MSE:  tensor(2.9963e-08, device='cuda:0')
Shape check:  torch.Size([532609, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0014, device='cuda:0')
Epoch:  10  
Training Loss: 0.0513186939060688
Test Loss:  0.05809880420565605
Test Acc:  0.0
Valid Loss:  0.053517721593379974
Valid Acc:  0.0
std:  0.0004606554896002776 
thres:  5.190981552004814e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|██████████| 10/10 [00:24<00:00,  2.44s/it]100%|██████████| 10/10 [00:24<00:00,  2.44s/it]
