{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ng (Python 3.12.3)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=614\n",
    "alpha = torch.randn(n).to('cuda',dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape check:  torch.Size([153, 532609]) torch.Size([153]) torch.Size([153, 153]) torch.Size([153, 153]) torch.Size([153])\n",
      "condition number:  tensor(1.0699, device='cuda:0', dtype=torch.float64)\n",
      "rank check:  tensor(153, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "J = torch.randn(n,532609).to('cuda',dtype=torch.float64)\n",
    "# J = torch.concat([J, J+1e-4*torch.randn(256,532609)], dim=0)\n",
    "K = torch.matmul(J, J.T)\n",
    "# U, Lambda2, Vh = torch.linalg.svd(K)\n",
    "Lambda2, U= torch.linalg.eigh(K)\n",
    "print('shape check: ', J.shape, alpha.shape, K.shape, U.shape, Lambda2.shape)\n",
    "print('condition number: ', torch.max(Lambda2)/torch.min(Lambda2))\n",
    "print('rank check: ', torch.sum(Lambda2>1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape check:  torch.Size([614, 299137]) torch.Size([614]) torch.Size([614, 614]) torch.Size([614, 614]) torch.Size([614])\n",
      "condition number:  tensor(2.3302e+15, device='cuda:0', dtype=torch.float64)\n",
      "rank check:  tensor(456, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "J = torch.load('Check_J.pt').to('cuda',dtype=torch.float64)\n",
    "loss_scale = float(np.load('loss_scale.npy'))\n",
    "K = torch.matmul(J, J.T)#.to(dtype=torch.float64)\n",
    "U, Lambda2, Vh = torch.linalg.svd(K)\n",
    "# Lambda2, U= torch.linalg.eigh(K)\n",
    "print('shape check: ', J.shape, alpha.shape, K.shape, U.shape, Lambda2.shape)\n",
    "print('condition number: ', torch.max(Lambda2)/torch.min(Lambda2))\n",
    "print('rank check: ', torch.sum(Lambda2>1e-4))\n",
    "J = J*(1/loss_scale)\n",
    "K = K*(1/loss_scale)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion check: \n",
      "Mean:  tensor(0.6267, device='cuda:0', dtype=torch.float64) \n",
      "Std:  tensor(3.0935, device='cuda:0', dtype=torch.float64) \n",
      "ABS Max:  tensor(64.5720, device='cuda:0', dtype=torch.float64) \n",
      "ABS Min:  tensor(1.8032e-08, device='cuda:0', dtype=torch.float64)\n",
      "Criterion check:  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0', dtype=torch.float64) tensor(407, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "uTa = (U.mH @ alpha)\n",
    "# Solved_true = torch.linalg.solve(K@K, K@alpha)\n",
    "Solved_true = torch.linalg.solve(torch.matmul(K,K), torch.matmul(K,alpha.reshape(-1,1)))\n",
    "Solved_true = (J.T@Solved_true).reshape(-1,1)\n",
    "criterion = (U.T@(J@Solved_true)).reshape(-1)/(uTa)\n",
    "print(\"Criterion check: \\nMean: \", torch.mean(criterion), \"\\nStd: \", torch.std(criterion), \"\\nABS Max: \", torch.max(torch.abs(criterion)), \"\\nABS Min: \", torch.min(torch.abs(criterion)))\n",
    "print(\"Criterion check: \", criterion[:10], torch.sum(criterion>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max:  tensor(1.2984, device='cuda:0', dtype=torch.float64) tensor(5.8087, device='cuda:0')\n",
      "Min:  tensor(-0.7252, device='cuda:0', dtype=torch.float64) tensor(-5.9129, device='cuda:0')\n",
      "Mean:  tensor(-0.0023, device='cuda:0', dtype=torch.float64) tensor(7.2858e-05, device='cuda:0')\n",
      "Std:  tensor(0.0257, device='cuda:0', dtype=torch.float64) tensor(1.0000, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0030, 0.0434, 0.0027,  ..., 0.0024, 0.0000, 1.0000], device='cuda:0',\n",
       "       dtype=torch.float64),\n",
       "indices=tensor([436, 351, 328,  ..., 448,   0,   0], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Max: ',  torch.max(J), torch.max(torch.randn(*J.shape, device=device)))\n",
    "print('Min: ', torch.min(J), torch.min(torch.randn(*J.shape, device=device)))\n",
    "print('Mean: ', torch.mean(J), torch.mean(torch.randn(*J.shape, device=device)))\n",
    "print('Std: ', torch.std(J), torch.std(torch.randn(*J.shape, device=device)))\n",
    "torch.max(torch.abs(J),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.matmul(J, J.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,14):\n",
    "    newK = K*(1/loss_scale*i)**2\n",
    "    newJ = J*(1/loss_scale*i)  # torch.linalg.norm(J@J.T-K): 10 for 0., 12 for 11.51, 13 for 31.89\n",
    "    print(torch.max(newJ), torch.min(newJ), torch.mean(newJ), torch.std(newJ))\n",
    "    print(f\"error {i}: \", torch.linalg.norm(torch.matmul(newJ, newJ.T)-newK))\n",
    "# newK = K*(1/loss_scale*12.)**2\n",
    "# newJ = J*(1/loss_scale*12.)  # torch.linalg.norm(J@J.T-K): 10 for 0., 12 for 11.51, 13 for 31.89\n",
    "\n",
    "# print(f\"error {i}: \", torch.linalg.norm(torch.matmul(newJ, newJ.T)-newK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,14):\n",
    "    newK = K*(1/loss_scale*i)**2\n",
    "    newJ = J*(1/loss_scale*i)  # torch.linalg.norm(J@J.T-K): 10 for 0., 12 for 11.51, 13 for 31.89\n",
    "    # print(torch.max(newJ), torch.min(newJ), torch.mean(newJ), torch.std(newJ))\n",
    "    print(f\"error {i}: \", torch.linalg.norm(torch.matmul(newJ, newJ.T)-newK))\n",
    "# newK = K*(1/loss_scale*12.)**2\n",
    "# newJ = J*(1/loss_scale*12.)  # torch.linalg.norm(J@J.T-K): 10 for 0., 12 for 11.51, 13 for 31.89\n",
    "\n",
    "# print(f\"error {i}: \", torch.linalg.norm(torch.matmul(newJ, newJ.T)-newK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b7bac97c2fe58e7e4da8563e4be44dc793212e84f9cecbb414d450eaca3e3d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
